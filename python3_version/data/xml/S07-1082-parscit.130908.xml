<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061048">
<title confidence="0.977508">
UCD-PN: Classification of Semantic Relations Between Nominals
using WordNet and Web Counts
</title>
<author confidence="0.997926">
Paul Nulty
</author>
<affiliation confidence="0.980852">
School of Computer Science and Informatics
University College Dublin
</affiliation>
<address confidence="0.698955">
Dublin, Ireland
</address>
<email confidence="0.998265">
paul.nulty@ucd.ie
</email>
<sectionHeader confidence="0.995628" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999910388888889">
For our system we use the SMO implemen-
tation of a support vector machine provided
with the WEKA machine learning toolkit.
As with all machine learning approaches,
the most important step is to choose a set of
features which reliably help to predict the
label of the example. We used 76 features
drawn from two very different knowledge
sources. The first 48 features are boolean
values indicating whether or not each of the
nominals in the sentence are linked to cer-
tain other words in the WordNet hypernym
and meronym networks. The remaining 28
features are web frequency counts for the
two nominals joined by certain common
prepositions and verbs. Our system per-
formed well on all but two of the relations;
theme-tool and origin entity.
</bodyText>
<sectionHeader confidence="0.985025" genericHeader="categories and subject descriptors">
1 Introduction and Related Work
</sectionHeader>
<bodyText confidence="0.999940297872341">
This paper describes a system for participating
in SemEval 2007 task 4; “Classification of Seman-
tic Relations Between Nominals”. This SemEval
task required systems to establish whether or not a
particular semantic relation held between two
nominals in a sentence. There were 7 semantic re-
lations, with approximately 70 positive and 70
negative example sentences for each relation.
There were approximately 70 examples in the test
sets for each relation.
This task is similar to the problem of determin-
ing what semantic relation holds between the con-
stituents of a noun-noun compound. Work in this
area has used both statistical information about the
frequencies of lexical patterns and hand-built
knowledge databases such as WordNet and the-
saura. In our system we combine these two knowl-
edge sources and build a set of features to use as
input to a Support Vector Machine learning algo-
rithm.
The use of hit counts from web search engines
to obtain lexical information was introduced by
Turney (2001). The idea of searching a large cor-
pus for specific lexico-syntactic phrases to indicate
a semantic relation of interest was first described
by Hearst (1992). A lexical pattern specific enough
to indicate a particular semantic relation is usually
not very frequent, and using the web as a corpus
alleviates the data sparseness problem. However, it
also introduces some problems. The number of
results returned is unstable as pages are created and
deleted all the time, and the major search engines
return only rounded frequency estimates and do
not allow a very sophisticated query interface. Na-
kov and Hearst (2005) examined the use of web-
based n-gram frequencies for an NLP task and
concluded that these issues do not greatly impact
the interpretation of the results.
Turney and Littman (2005) use web queries to
the AltaVista search engine as the basis for their
system to assign semantic relations to modifier-
noun phrases. They use a set of 64 short preposi-
tional and conjunctive phrases (joining terms) to
generate exact queries of the form “noun joining
term modifier”, and “modifier joining term noun”.
Using 64 joining terms and trying the noun and
modifier in either order resulted in a vector of 128
</bodyText>
<page confidence="0.984859">
374
</page>
<bodyText confidence="0.99078545945946">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 374–377,
Prague, June 2007. c�2007 Association for Computational Linguistics
hit counts for each noun-modifier pair. These hit
counts were used with a supervised (nearest
neighbor) algorithm to label the modifier-noun
phrases.
Nakov and Hearst (2006) use queries of the form
“noun that * modifier” where &apos;*&apos; is a wildcard
operator. By retrieving the words that most
commonly occurred in the place of the wildcard
they were able to identify very specific predicates
that are likely to represent the relation between
noun and modifier.
There have also been several approaches which
used hand built knowledge sources. Rosario and
Hearst (2001) used MeSH, a lexical hierarchy of
medical terms. They use this hierarchy to assign
semantic properties to head and modifier words in
the medical domain. They use a neural network
trained on these attributes to assign the noun
phrases a semantic relation.
Nastase and Szpakowicz (2003) use the position
of the noun and modifier words within general se-
mantic hierarchies (Roget&apos;s Thesaurus and Word-
Net) as attributes for their learning algorithms.
They experiment with decision trees, a rule induc-
tion system, a relational learner and memory based
learning. They conclude that the rule induction
system is capable of generalizing to characterize
the noun phrases.
Moldovan et al (2004) also use WordNet. They
experiment with a Bayesian algorithm, decision
trees, and their own algorithm; semantic scattering.
As far as we are aware ours is the first system to
combine features derived from a hand-built lexical
database with corpus frequencies of lexical
patterns.
</bodyText>
<sectionHeader confidence="0.95682" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.986125">
2.1 WordNet Features
</subsectionHeader>
<bodyText confidence="0.999857529411765">
Our system uses both features derived from
WordNet and features obtained by collecting web
frequencies for lexical patterns. We did not use any
information from the sentence in which the two
nominals appeared, nor did we use the query used
to retrieve the examples. We did make use of the
WordNet sense for the features we obtained from
WordNet.
There are 48 features derived from WordNet.
Most of these are boolean values indicating
whether or not each of the nominals in the sentence
appear below certain other high-level concepts in
the hypernym hierarchy. We chose 22 high level
concepts we believed may be good predictors of
whether or not a nominal could be an argument of
the semantic relations used in this task. These
concepts are listed below in table 1.
</bodyText>
<figure confidence="0.978142727272727">
physical_entity physical_object
grouping substance
attribute matter
psychological_feature process
quantity causal_agent
container tool
act device
work content
being event
natural_object unit
instrumentation state
</figure>
<tableCaption confidence="0.98742">
Table 1. Concepts in the WordNet hierarchy used to
generate features.
</tableCaption>
<bodyText confidence="0.999890444444444">
For each of these WordNet entries we checked
whether or not each of the nominals in the example
sentence appeared below the entry in the WordNet
hypernym tree. This gave us 44 features. We also
checked whether the first nominal was a hypernym
of the second; and vice-versa; and whether the first
nominal was a meronym of the second; and vice
versa. This gives us in total 48 boolean features
derived from WordNet.
</bodyText>
<subsectionHeader confidence="0.998501">
2.2 Web Frequencies
</subsectionHeader>
<bodyText confidence="0.962799111111111">
The remaining features were numerical values
obtained by retrieving the frequencies of web
searches for the two nominals joined by certain
common prepositions and verbs. These joining
terms are listed below in table 2.
of produces
for used for
in has
on contains
</bodyText>
<tableCaption confidence="0.75735825">
at from
with causes
about made from
Table 2. Joining terms used to generate features.
</tableCaption>
<page confidence="0.997772">
375
</page>
<bodyText confidence="0.999357434782609">
To obtain the frequencies we used the API to the
“MSN Live” search engine.
Choosing a set of joining terms in a principled
manner is not an easy task, but there is certainly
some correlation between a prepositional term or
short linking verb and a semantic relation. For ex-
ample, “contains” tends to indicate a spatial rela-
tion, while the preposition “in” indicates a locative
relation, either temporal or spatial.
When collecting web frequencies we took ad-
vantage of the OR operator provided by the search
engine. For each joining term, we wanted to sum
the number of hits for the term on its own, the term
followed by &apos;a&apos;, and the term followed by &apos;the&apos;. In-
stead of conducting separate queries for each of
these forms, we were able to sum the results with
just one search. For example, if the two nominals
in the sentence were “battery” and “phone”; one of
the queries would be:
“battery in phone” OR “battery in a phone” OR
“battery in the phone”
These features were numeric values; the raw num-
ber of documents returned by the query.
</bodyText>
<subsectionHeader confidence="0.99933">
2.3 Learning Algorithm
</subsectionHeader>
<bodyText confidence="0.999919384615385">
All of the features were used as input to our
learning algorithm, which was a Support Vector
Machine (SVM). An SVM is a method for creating
a classification function which works by trying to
find a hypersurface in the space of possible inputs
that splits the positive examples from the negative
examples for each class. We did not normalize
these values as normalization is handled by the
WEKA implementation which we used.
WEKA is a machine learning toolkit written in
Java (Witten and Frank, 1999). The algorithm we
used was an SVM trained with the Sequential
Minimal Optimization method provided by Weka.
</bodyText>
<sectionHeader confidence="0.999791" genericHeader="evaluation">
3. Results
</sectionHeader>
<bodyText confidence="0.99989175">
The average f-value obtained by our system using
all of the training data was 65.4. There was a sig-
nificant difference in performance across different
relations. The results for each relation are below.
</bodyText>
<table confidence="0.998357777777778">
Relation Pre Rec F Acc
cause-effect 61.7 90.2 73.3 66.2
instrument-agency 59.3 84.2 69.6 64.1
product-producer 70.9 98.4 82.4 72.0
origin-entity 51.4 50.0 50.7 56.8
theme-tool 52.9 31.0 39.1 60.6
part-whole 66.7 69.2 67.9 76.4
content-container 71.4 78.9 75.0 73.0
Average 62.0 71.7 65.4 67.
</table>
<bodyText confidence="0.9998764">
The standard deviation of the f-values is 13.9.
The average of the f-values is brought down by
two of the relations; origin-entity and theme-tool.
The poor performance of these relations was noted
during early experimentation with the training
data; and the list of WordNet concepts and joining
terms was amended to try to improve classifica-
tion, but no improvement was achieved. If the re-
sults for these relations are omitted the average f-
score rises to 73.6
</bodyText>
<subsectionHeader confidence="0.996165">
3.1 Information Gain
</subsectionHeader>
<bodyText confidence="0.939649095238095">
In order to evaluate which features were the
most useful for each relation, we used the Informa-
tion Gain feature ranking tool in WEKA. This tool
measures the change in entropy attributed to each
feature and ranks them accordingly. In some cases
we found that the high ranking features for a rela-
tion were ones which were intuitively relevant to
predicting that relation; however some features still
had high Information Gain despite seeming
unlikely to be predictive of the relation.
The eight most informative features for the
Cause-Effect and Content-Container relations are
shown below. WordNet features are in normal
quantity
at
used for2
grouping
object2
substance
substance2
instrumentation2
</bodyText>
<tableCaption confidence="0.9434475">
Table 3. The features with the highest information gain
for cause-effect and content-container.
</tableCaption>
<figure confidence="0.9954588">
Cause-Effect
Content-Container
Instrumentation2
Container2
contains
physical_object2
physical_entity2
psychological_feature
substance2
device2
</figure>
<page confidence="0.997054">
376
</page>
<bodyText confidence="0.999971769230769">
font; the joining terms for web searches in italics.
The &apos;2&apos; after a feature indicates that the web search
was of the form &amp;quot;N2 joining term N1&amp;quot;; or that the
WordNet property holds for N2; where the relation
is relation(N1,N2).
Most of these features make sense. For example,
the search query “contains” and the Wordnet entry
“Container” linked to the second noun are the sec-
ond and third most informative for the content con-
tainer class, and the query “N2 used for N1” ranks
highly in the cause-effect relation. However, it is
unclear why being a hyponym of “quantity” would
provide information about the cause-effect relation.
</bodyText>
<sectionHeader confidence="0.997038" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999989566666667">
This paper describes a system for participating in
SemEval 2007 task 4; “Classification of Semantic
Relations Between Nominals”. Our system com-
bines features generated by analyzing the WordNet
hypernym tree with features which indicate the
frequencies of certain lexical patterns involving the
nominals and common prepositions, using the web
as a corpus.
The performance of the system was above the
average score of other systems which used the
WordNet sense of the training examples but not the
query used to obtain them. The system was held
back particularly by two relations, theme-tool and
origin-entity.
There are many potential avenues for future work
in this area. We chose 48 features based on Word-
Net and 28 lexical patterns to search the web for.
These were chosen arbitrarily on the basis that they
looked like they would be informative in general,
over all seven relations. A more principled ap-
proach would be to begin with a much larger num-
ber of features and use information gain to select
the most informative features for each relation in-
dividually. This should improve performance by
ensuring that only the most relevant features for a
specific relation are used to train the classifier for
that relation.
Also, there is room for more investigation into how
short prepositional joining phrases map onto un-
derlying semantic relations (Girjiu 2006).
</bodyText>
<sectionHeader confidence="0.99637" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999220694444445">
Roxana Girju. 2006. Out-of-context noun phrase seman-
tic interpretation with cross-linguistic evidence. In
Proceedings of the 15th ACM international confer-
ence on Information and knowledge management
Marti A. Hearst: 1992. Automatic Acquisition of Hypo-
nyms from Large Text Corpora. COLING:539-545
Dan Moldovan, Adriana Badulescu, Marta Tatu, Daniel
Antohe and Roxana Girju. 2004. Models for the Se-
mantic Classification of Noun Phrases. In Proceed-
ings of the HLT/NAACL Workshop on Computational
Lexical Semantics. Boston , MA.
Preslav Nakov and Marti Hearst. 2006. Using Verbs to
Characterize Noun-Noun Relations, in the Proceed-
ings of AIMSA 2006,
Preslav Nakov and Marti Hearst. 2005. Using the Web
as an Implicit Training Set: Application to Structural
Ambiguity Resolution, in HLT/EMNLP&apos;05,
Vivi Nastase and Stan Szpakowicz. 2003. Exploring
Noun-Modifier Semantic Relations. International
Workshop on Computational Semantics, Tillburg,
Netherlands, 2003
Barbara Rosario and Marti A. Hearst. 2001. Classifying
the semantic relations in noun compounds via a do-
main-specific lexical hierarchy. In Proceedings of the
2001 Conference on Empirical Methods in Natural
Language Processing. ACL
Peter D. Turney. 2001. Mining the web for synonyms:
PM-IR vs LSA on TOEFL, Proceedings of the
Twelth European Conference on machine learning,
Peter D. Turney and Michael L. Littman. 2005. Corpus-
based learning of analogies and semantic relations.
Machine Learning, 60(1–3):251–278
Ian H. Witten and Eibe Frank. 1999. Data Mining:
Practical Machine Learning Tools and Techniques
with Java Implementations, Morgan Kaufmann
(1999)
</reference>
<page confidence="0.998354">
377
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909388">
<title confidence="0.993271">UCD-PN: Classification of Semantic Relations Between Nominals using WordNet and Web Counts</title>
<author confidence="0.999963">Paul Nulty</author>
<affiliation confidence="0.9991965">School of Computer Science and Informatics University College Dublin</affiliation>
<address confidence="0.977578">Dublin, Ireland</address>
<email confidence="0.985053">paul.nulty@ucd.ie</email>
<abstract confidence="0.99778547368421">For our system we use the SMO implementation of a support vector machine provided with the WEKA machine learning toolkit. As with all machine learning approaches, the most important step is to choose a set of features which reliably help to predict the label of the example. We used 76 features drawn from two very different knowledge sources. The first 48 features are boolean values indicating whether or not each of the nominals in the sentence are linked to certain other words in the WordNet hypernym and meronym networks. The remaining 28 features are web frequency counts for the two nominals joined by certain common prepositions and verbs. Our system performed well on all but two of the relations; theme-tool and origin entity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
</authors>
<title>Out-of-context noun phrase semantic interpretation with cross-linguistic evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international conference on Information and knowledge management</booktitle>
<marker>Girju, 2006</marker>
<rawString>Roxana Girju. 2006. Out-of-context noun phrase semantic interpretation with cross-linguistic evidence. In Proceedings of the 15th ACM international conference on Information and knowledge management</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic Acquisition of Hyponyms from Large Text Corpora.</title>
<date>1992</date>
<pages>539--545</pages>
<contexts>
<context position="2140" citStr="Hearst (1992)" startWordPosition="344" endWordPosition="345">he constituents of a noun-noun compound. Work in this area has used both statistical information about the frequencies of lexical patterns and hand-built knowledge databases such as WordNet and thesaura. In our system we combine these two knowledge sources and build a set of features to use as input to a Support Vector Machine learning algorithm. The use of hit counts from web search engines to obtain lexical information was introduced by Turney (2001). The idea of searching a large corpus for specific lexico-syntactic phrases to indicate a semantic relation of interest was first described by Hearst (1992). A lexical pattern specific enough to indicate a particular semantic relation is usually not very frequent, and using the web as a corpus alleviates the data sparseness problem. However, it also introduces some problems. The number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow a very sophisticated query interface. Nakov and Hearst (2005) examined the use of webbased n-gram frequencies for an NLP task and concluded that these issues do not greatly impact the interpretation of </context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst: 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. COLING:539-545</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Adriana Badulescu</author>
<author>Marta Tatu</author>
<author>Daniel Antohe</author>
<author>Roxana Girju</author>
</authors>
<title>Models for the Semantic Classification of Noun Phrases.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT/NAACL Workshop on Computational Lexical Semantics.</booktitle>
<location>Boston , MA.</location>
<contexts>
<context position="4613" citStr="Moldovan et al (2004)" startWordPosition="736" endWordPosition="739"> hierarchy to assign semantic properties to head and modifier words in the medical domain. They use a neural network trained on these attributes to assign the noun phrases a semantic relation. Nastase and Szpakowicz (2003) use the position of the noun and modifier words within general semantic hierarchies (Roget&apos;s Thesaurus and WordNet) as attributes for their learning algorithms. They experiment with decision trees, a rule induction system, a relational learner and memory based learning. They conclude that the rule induction system is capable of generalizing to characterize the noun phrases. Moldovan et al (2004) also use WordNet. They experiment with a Bayesian algorithm, decision trees, and their own algorithm; semantic scattering. As far as we are aware ours is the first system to combine features derived from a hand-built lexical database with corpus frequencies of lexical patterns. 2 System Description 2.1 WordNet Features Our system uses both features derived from WordNet and features obtained by collecting web frequencies for lexical patterns. We did not use any information from the sentence in which the two nominals appeared, nor did we use the query used to retrieve the examples. We did make </context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Girju, 2004</marker>
<rawString>Dan Moldovan, Adriana Badulescu, Marta Tatu, Daniel Antohe and Roxana Girju. 2004. Models for the Semantic Classification of Noun Phrases. In Proceedings of the HLT/NAACL Workshop on Computational Lexical Semantics. Boston , MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti Hearst</author>
</authors>
<title>Using Verbs to Characterize Noun-Noun Relations,</title>
<date>2006</date>
<booktitle>in the Proceedings of AIMSA</booktitle>
<contexts>
<context position="3539" citStr="Nakov and Hearst (2006)" startWordPosition="564" endWordPosition="567">se a set of 64 short prepositional and conjunctive phrases (joining terms) to generate exact queries of the form “noun joining term modifier”, and “modifier joining term noun”. Using 64 joining terms and trying the noun and modifier in either order resulted in a vector of 128 374 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 374–377, Prague, June 2007. c�2007 Association for Computational Linguistics hit counts for each noun-modifier pair. These hit counts were used with a supervised (nearest neighbor) algorithm to label the modifier-noun phrases. Nakov and Hearst (2006) use queries of the form “noun that * modifier” where &apos;*&apos; is a wildcard operator. By retrieving the words that most commonly occurred in the place of the wildcard they were able to identify very specific predicates that are likely to represent the relation between noun and modifier. There have also been several approaches which used hand built knowledge sources. Rosario and Hearst (2001) used MeSH, a lexical hierarchy of medical terms. They use this hierarchy to assign semantic properties to head and modifier words in the medical domain. They use a neural network trained on these attributes to</context>
</contexts>
<marker>Nakov, Hearst, 2006</marker>
<rawString>Preslav Nakov and Marti Hearst. 2006. Using Verbs to Characterize Noun-Noun Relations, in the Proceedings of AIMSA 2006,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti Hearst</author>
</authors>
<title>Using the Web as an Implicit Training Set: Application to Structural Ambiguity Resolution,</title>
<date>2005</date>
<note>in HLT/EMNLP&apos;05,</note>
<contexts>
<context position="2599" citStr="Nakov and Hearst (2005)" startWordPosition="415" endWordPosition="419"> (2001). The idea of searching a large corpus for specific lexico-syntactic phrases to indicate a semantic relation of interest was first described by Hearst (1992). A lexical pattern specific enough to indicate a particular semantic relation is usually not very frequent, and using the web as a corpus alleviates the data sparseness problem. However, it also introduces some problems. The number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow a very sophisticated query interface. Nakov and Hearst (2005) examined the use of webbased n-gram frequencies for an NLP task and concluded that these issues do not greatly impact the interpretation of the results. Turney and Littman (2005) use web queries to the AltaVista search engine as the basis for their system to assign semantic relations to modifiernoun phrases. They use a set of 64 short prepositional and conjunctive phrases (joining terms) to generate exact queries of the form “noun joining term modifier”, and “modifier joining term noun”. Using 64 joining terms and trying the noun and modifier in either order resulted in a vector of 128 374 Pr</context>
</contexts>
<marker>Nakov, Hearst, 2005</marker>
<rawString>Preslav Nakov and Marti Hearst. 2005. Using the Web as an Implicit Training Set: Application to Structural Ambiguity Resolution, in HLT/EMNLP&apos;05,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Exploring Noun-Modifier Semantic Relations.</title>
<date>2003</date>
<booktitle>International Workshop on Computational Semantics,</booktitle>
<location>Tillburg, Netherlands,</location>
<contexts>
<context position="4214" citStr="Nastase and Szpakowicz (2003)" startWordPosition="674" endWordPosition="677">” where &apos;*&apos; is a wildcard operator. By retrieving the words that most commonly occurred in the place of the wildcard they were able to identify very specific predicates that are likely to represent the relation between noun and modifier. There have also been several approaches which used hand built knowledge sources. Rosario and Hearst (2001) used MeSH, a lexical hierarchy of medical terms. They use this hierarchy to assign semantic properties to head and modifier words in the medical domain. They use a neural network trained on these attributes to assign the noun phrases a semantic relation. Nastase and Szpakowicz (2003) use the position of the noun and modifier words within general semantic hierarchies (Roget&apos;s Thesaurus and WordNet) as attributes for their learning algorithms. They experiment with decision trees, a rule induction system, a relational learner and memory based learning. They conclude that the rule induction system is capable of generalizing to characterize the noun phrases. Moldovan et al (2004) also use WordNet. They experiment with a Bayesian algorithm, decision trees, and their own algorithm; semantic scattering. As far as we are aware ours is the first system to combine features derived f</context>
</contexts>
<marker>Nastase, Szpakowicz, 2003</marker>
<rawString>Vivi Nastase and Stan Szpakowicz. 2003. Exploring Noun-Modifier Semantic Relations. International Workshop on Computational Semantics, Tillburg, Netherlands, 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti A Hearst</author>
</authors>
<title>Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<publisher>ACL</publisher>
<contexts>
<context position="3929" citStr="Rosario and Hearst (2001)" startWordPosition="628" endWordPosition="631">, June 2007. c�2007 Association for Computational Linguistics hit counts for each noun-modifier pair. These hit counts were used with a supervised (nearest neighbor) algorithm to label the modifier-noun phrases. Nakov and Hearst (2006) use queries of the form “noun that * modifier” where &apos;*&apos; is a wildcard operator. By retrieving the words that most commonly occurred in the place of the wildcard they were able to identify very specific predicates that are likely to represent the relation between noun and modifier. There have also been several approaches which used hand built knowledge sources. Rosario and Hearst (2001) used MeSH, a lexical hierarchy of medical terms. They use this hierarchy to assign semantic properties to head and modifier words in the medical domain. They use a neural network trained on these attributes to assign the noun phrases a semantic relation. Nastase and Szpakowicz (2003) use the position of the noun and modifier words within general semantic hierarchies (Roget&apos;s Thesaurus and WordNet) as attributes for their learning algorithms. They experiment with decision trees, a rule induction system, a relational learner and memory based learning. They conclude that the rule induction syste</context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>Barbara Rosario and Marti A. Hearst. 2001. Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing. ACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Mining the web for synonyms: PM-IR vs LSA on TOEFL,</title>
<date>2001</date>
<booktitle>Proceedings of the Twelth European Conference on machine learning,</booktitle>
<contexts>
<context position="1983" citStr="Turney (2001)" startWordPosition="319" endWordPosition="320"> were approximately 70 examples in the test sets for each relation. This task is similar to the problem of determining what semantic relation holds between the constituents of a noun-noun compound. Work in this area has used both statistical information about the frequencies of lexical patterns and hand-built knowledge databases such as WordNet and thesaura. In our system we combine these two knowledge sources and build a set of features to use as input to a Support Vector Machine learning algorithm. The use of hit counts from web search engines to obtain lexical information was introduced by Turney (2001). The idea of searching a large corpus for specific lexico-syntactic phrases to indicate a semantic relation of interest was first described by Hearst (1992). A lexical pattern specific enough to indicate a particular semantic relation is usually not very frequent, and using the web as a corpus alleviates the data sparseness problem. However, it also introduces some problems. The number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow a very sophisticated query interface. Nakov a</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Peter D. Turney. 2001. Mining the web for synonyms: PM-IR vs LSA on TOEFL, Proceedings of the Twelth European Conference on machine learning,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Corpusbased learning of analogies and semantic relations.</title>
<date>2005</date>
<booktitle>Machine Learning,</booktitle>
<pages>60--1</pages>
<contexts>
<context position="2778" citStr="Turney and Littman (2005)" startWordPosition="446" endWordPosition="449">attern specific enough to indicate a particular semantic relation is usually not very frequent, and using the web as a corpus alleviates the data sparseness problem. However, it also introduces some problems. The number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow a very sophisticated query interface. Nakov and Hearst (2005) examined the use of webbased n-gram frequencies for an NLP task and concluded that these issues do not greatly impact the interpretation of the results. Turney and Littman (2005) use web queries to the AltaVista search engine as the basis for their system to assign semantic relations to modifiernoun phrases. They use a set of 64 short prepositional and conjunctive phrases (joining terms) to generate exact queries of the form “noun joining term modifier”, and “modifier joining term noun”. Using 64 joining terms and trying the noun and modifier in either order resulted in a vector of 128 374 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 374–377, Prague, June 2007. c�2007 Association for Computational Linguistics hit counts f</context>
</contexts>
<marker>Turney, Littman, 2005</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2005. Corpusbased learning of analogies and semantic relations. Machine Learning, 60(1–3):251–278</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations,</booktitle>
<publisher>Morgan Kaufmann</publisher>
<contexts>
<context position="8329" citStr="Witten and Frank, 1999" startWordPosition="1357" endWordPosition="1360">in the phone” These features were numeric values; the raw number of documents returned by the query. 2.3 Learning Algorithm All of the features were used as input to our learning algorithm, which was a Support Vector Machine (SVM). An SVM is a method for creating a classification function which works by trying to find a hypersurface in the space of possible inputs that splits the positive examples from the negative examples for each class. We did not normalize these values as normalization is handled by the WEKA implementation which we used. WEKA is a machine learning toolkit written in Java (Witten and Frank, 1999). The algorithm we used was an SVM trained with the Sequential Minimal Optimization method provided by Weka. 3. Results The average f-value obtained by our system using all of the training data was 65.4. There was a significant difference in performance across different relations. The results for each relation are below. Relation Pre Rec F Acc cause-effect 61.7 90.2 73.3 66.2 instrument-agency 59.3 84.2 69.6 64.1 product-producer 70.9 98.4 82.4 72.0 origin-entity 51.4 50.0 50.7 56.8 theme-tool 52.9 31.0 39.1 60.6 part-whole 66.7 69.2 67.9 76.4 content-container 71.4 78.9 75.0 73.0 Average 62.0</context>
</contexts>
<marker>Witten, Frank, 1999</marker>
<rawString>Ian H. Witten and Eibe Frank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations, Morgan Kaufmann (1999)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>