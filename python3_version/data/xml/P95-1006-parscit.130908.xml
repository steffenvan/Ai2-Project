<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000540">
<title confidence="0.969312666666667">
Robust Parsing Based on Discourse Information:
Completing partial parses of ill-formed sentences
on the basis of discourse information
</title>
<author confidence="0.984457">
Tetsuya Nasulcawa
</author>
<affiliation confidence="0.959651">
IBM Research, Tokyo Research Laboratory
</affiliation>
<address confidence="0.929143">
1623-14, Shimotsuruma, Yamato-shi, Kanagawa-ken 242, Japan
</address>
<email confidence="0.999161">
nasukawa@trl.vnet.ibm.com
</email>
<sectionHeader confidence="0.997392" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999911357142857">
In a consistent text, many words and
phrases are repeatedly used in more than
one sentence. When an identical phrase
(a set of consecutive words) is repeated in
different sentences, the constituent words
of those sentences tend to be associated in
identical modification patterns with identi-
cal parts of speech and identical modifiee-
modifier relationships. Thus, when a
syntactic parser cannot parse a sentence
as a unified structure, parts of speech
and modifiee-modifier relationships among
morphologically identical words in com-
plete parses of other sentences within the
same text provide useful information for
obtaining partial parses of the sentence.
In this paper, we describe a method for
completing partial parses by maintaining
consistency among morphologically identi-
cal words within the same text as regards
their part of speech and their modifiee-
modifier relationship. The experimental
results obtained by using this method with
technical documents offer good prospects
for improving the accuracy of sentence
analysis in a broad-coverage natural lan-
guage processing system such as a machine
translation system.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998653428571429">
In order to develop a practical natural language pro-
cessing (NLP) system, it is essential to deal with
ill-formed sentences that cannot be parsed correctly
according to the grammar rules in the system. In
this paper, an &amp;quot;ill-formed sentence&amp;quot; means one that
cannot be parsed as a unified structure. A syntac-
tic parser with general grammar rules is often un-
able to analyze not only sentences with grammati-
cal errors and ellipses, but also long sentences, ow-
ing to their complexity. Thus, ill-formed sentences
include not only ungrammatical sentences, but also
some grammatical sentences that cannot be parsed
as unified structures owing to the presence of un-
known words or to a lack of completeness in the
syntactic parser. In texts from a restricted domain,
such as computer manuals, most sentences are gram-
matically correct. However, even a well-established
syntactic parser usually fails to generate a unified
parsed structure for about 10 to 20 percent of all the
sentences in such texts, and the failure to generate
a unified parsed structure in syntactic analysis leads
to a failure in the output of a NLP system. Thus,
it is indispensable to establish a correct analysis for
such a sentence.
To handle such sentences, most previous ap-
proaches apply various heuristic rules (Jensen et
al., 1992; Douglas and Dale, 1992; Richardson and
Braden-Harder, 1988), including
</bodyText>
<listItem confidence="0.99958625">
• Relaxing constraints in the condition part of a
grammatical rule, such as number and gender
constraints
• Joining partial parses by using meta rules.
</listItem>
<bodyText confidence="0.999929045454546">
Either way, the output reflects the general plausibil-
ity of an analysis that can be obtained from infor-
mation in the sentence; however, the interpretation
of a sentence depends on its discourse, and incon-
sistency with recovered parses that contain different
analyses of the same phrase in other sentences in the
discourse often results in odd outputs of the natural
language processing system.
Starting from the viewpoint that an interpretation
of a sentence must be consistent in its discourse, we
worked on completing incomplete parses by using
information extracted from complete parses in the
discourse. The results were encouraging. Since most
words in a sentence are repeatedly used in other sen-
tences in the discourse, the complete parses of well-
formed sentences usually provided some useful infor-
mation for completing incomplete parses in the same
discourse. Thus, rather than trying to enhance a
syntactic parser&apos;s grammar rules in order to support
ill-formed sentences, which seems to be an endless
task after the parser has obtained enough coverage
to parse general grammatical sentences, we treat the
</bodyText>
<page confidence="0.998881">
39
</page>
<bodyText confidence="0.998558346153846">
syntactic parser as a black box and complete incom-
plete parses, in the form of partially parsed chunks
that a bottom-up parser outputs for ill-formed sen-
tences, by using information extracted from the dis-
course.
In the next section, the effectiveness of using in-
formation extracted from the discourse to complete
syntactic analysis of ill-formed sentences. After that,
we propose an algorithm for completing incomplete
parses by using discourse information, and give the
results of an experiment on completing incomplete
parses in technical documents.
2 Discourse information for
completing incomplete parses
In this section, we use the word &amp;quot;discourse&amp;quot; to
denote a set of sentences that forms a text con-
cerning related topics. Gale (Gale et al., 1992) and
Nasukawa (Nasukawa, 1993) reported that polyse-
mous words within the same discourse have the same
word sense with a high probability (98% accord-
ing to (Gale et al., 1992),) and the results of our
analysis indicate that most content words are fre-
quently repeated in the discourse, as is shown in
Table 1; moreover, collocation (modifier-modifiee re-
lationship) patterns are also repeated frequently in
the same discourse, as is shown in Figure 1. This
figure reflects the analysis of structurally ambiguous
phrases in a computer manual consisting of 791 con-
secutive sentences for discourse sizes ranging from
10 to 791 sentences. For each structurally ambigu-
ous phrase, more than one candidate collocation pat-
tern was formed by associating the structurally am-
biguous phrase with its candidate modifiees 1, and a
collocation pattern identical with or similar to each
of these candidate collocation patterns was searched
for in the discourse. An identical collocation pattern
is one in which both modifiee and modifier sides con-
sist of words that are morphologically identical with
those in the sentence being analyzed, and that stand
in an identical relationship. A similar collocation
pattern is one in which either the modifiee or modi-
fier side has a word that is morphologically identical
with the corresponding word in the sentence being
analyzed, while the other has a synonym. Again,
the relationship of the two sides is identical with
that in the sentence being analyzed. Except in the
case where all 791 sentences were referred to as a
discourse, the results indicate the averages obtained
by referring to each of several sample areas as a dis-
course. For example, to obtain data for the case in
which the size of a discourse was 20 sentences, we
examined 32 areas each consisting of 20 sentences,
</bodyText>
<equation confidence="0.528102">
&apos;For example, in the sentence
You can use the folder on the desktop,
</equation>
<bodyText confidence="0.99195779245283">
the ambiguous phrase, on the desktop, forms two candi-
date collocation patterns:
&amp;quot;use —(on)— desktop&amp;quot; and &amp;quot;folder —(on)— desktop.&amp;quot;
such as the 1st sentence to the 20th, the 51st to the
70th, and the 701st to the 720th. Thus, Figure 1
indicates that a collocation pattern either identical
with or similar to at least one of the candidate collo-
cation patterns of a structurally ambiguous phrase
was found within the discourse in more than 70% of
cases, provided the discourse contained more than
300 consecutive sentences.
On the assumption that this feature of words in a
discourse provides a clue to improving the accuracy
of sentence analysis, we conducted an experiment
on sentences for which a syntactic parser generated
more than one parse tree, owing to the presence of
words that can be assigned to more than one part
of speech, or to the presence of complicated coor-
dinate structures, or for various other reasons. If
the constituent words tend to be associated in iden-
tical modification patterns with an identical part
of speech and identical modifiee-modifier relation-
ship when an identical phrase (a set of consecutive
words) is repeated in different sentences within the
discourse, the candidate parse that shares the most
collocation patterns with other sentences in the dis-
course should be selected as the correct analysis.
Out of 736 consecutive sentences in a computer man-
ual, the ESG parser (McCord, 1991) generated mul-
tiple parses for 150 sentences. In this experiment, we
divided the original 736 sentences into two texts, one
a discourse of 400 sentences and the other a discourse
of 336 sentences. Of the 150 sentences with multiple
parses, 24 were incorrectly analyzed in all candidate
parses or had identical candidate parses; we there-
fore focused on the other 126 sentences. In each
candidate parse of these sentences, we assigned a
score for each collocation that was repeated in other
sentences in the discourse (in the form of either an
identical collocation or a similar collocation), and
added up the collocation scores to assign a prefer-
ence value to the candidate parse. Out of the 126
sentences, different preference values were assigned
to candidate parses in 54 sentences, and the highest
value was assigned to a correct parse in 48 (88.9%)
of the 54 sentences. Thus, there is a strong tendency
for identical collocations to be actually repeated in
the discourse, and when an identical phrase (a set
of consecutive words) is repeated in different sen-
tences, their constituent words tend to be associated
in identical modification patterns.
Figure 2 shows the output of the PEG parser
(Jensen, 1992) for the following sentence:
</bodyText>
<construct confidence="0.672273666666667">
(2.1) As you can see, you can choose from many
topics to find out what information is available
about the AS/400 system.
</construct>
<bodyText confidence="0.9999052">
This is the 53rd sentence in Chapter 6 of a computer
manual (IBM, 1992), and every word of it is repeat-
edly used in other sentences in the same chapter, as
shown in Table 2. For example, the 39th sentence
in the same chapter contains &amp;quot;As you can see,&amp;quot; as
</bodyText>
<page confidence="0.999065">
40
</page>
<tableCaption confidence="0.999788">
Table 1: Frequency of morphologically identical words in computer manuals
</tableCaption>
<table confidence="0.995033363636364">
Part Freq. of morph. identical words Proportion of all content words
of
speech
Two or more Five or more Total number of Proportion
times (%) times (%) appearances (words) (%)
Noun 90.7 76.2 99047 59.8
Verb 94.9 83.6 35622 21.5
Adjective 88.9 71.0 16941 10.2
Adverb 85.9 68.8 4993 3.0
Pronoun 98.0 94.8 8911 5.4
Total 91.6 78.0 165514 —
</table>
<figure confidence="0.876130875">
Rate of repetition (%)
100.00
80.00
60.00
40.00
20.00
0.00 Size of discourse
0 200 400 600 800 (Number of sentences)
</figure>
<figureCaption confidence="0.999986">
Figure 1: Rate of finding identical or similar collocation patterns in relation to the size of the discourse
</figureCaption>
<bodyText confidence="0.965352083333333">
shown in Figure 3. The sentences that contain some
words in common with sentence (2.1) provide infor-
mation that is very useful for deriving a correct parse
of the sentence. Table 2 also shows that the parts
of speech (POS) for most words in sentence (2.1)
can be derived from words repeated in other sen-
tences in the same chapter. In this table, the up-
percase letters below the top sentence indicate the
parts of speech that can be assigned to the words
above. Underneath the candidate part of speech, re-
peated phases in other sentences are presented along
with the part of speech of each word in those sen-
tences; thus, the first word of sentence (2.1), &amp;quot;As,&amp;quot;
can be a conjunction, an adverb, or a preposition,
but complete parses of the 39th and 175th sentences
indicate that in this discourse the word is used as a
conjunction when it is used in the phrase &amp;quot;As you
can see.&amp;quot;
Furthermore, information on the dependencies
among most words in sentence (2.1) can be extracted
from phrases repeated in other sentences in the same
chapter, as shown in Figure 4.2
2Thick arrows indicate dependencies extracted from
the discourse information.
</bodyText>
<sectionHeader confidence="0.994574" genericHeader="introduction">
3 Implementation
</sectionHeader>
<subsectionHeader confidence="0.996154">
3.1 Algorithm
</subsectionHeader>
<bodyText confidence="0.996662681818182">
As we showed in the previous section, information
that is very useful for obtaining correct parses of ill-
formed sentences is provided by complete parses of
other sentences in the same discourse in cases where
a parser cannot construct a parse tree by using its
grammar rules. In this section, we describe an al-
gorithm for completing incomplete parses by using
this information.
The first step of the procedure is to extract from
an input text discourse information that the system
can refer to in the next step in order to complete in-
complete parses. The procedure for extracting dis-
course information is as follows:
1. Each sentence in the whole text given as a dis-
course is processed by a syntactic parser. Then,
except for sentences with incomplete parses and
multiple parses, the results of each parse are
stored as discourse information. To be pre-
cise, the position and the part of speech of
each instance of every lemma are stored along
with the lemma&apos;s modifiee-modifier relation-
ships with other content words extracted from
</bodyText>
<page confidence="0.993344">
41
</page>
<table confidence="0.99597554054054">
&amp;quot;.&amp;quot;)) 0)
((XXXX (COMMENT(CONJ
(NP
(AUXP
(VERB*
(PUNC ”,n)
(VP (NP
(AUXP
(VERB*
(PP
(VP* (INFCL
(NP
(VERB*
(UP
(PUNC
&amp;quot;as&amp;quot;)
(PRIM* &amp;quot;you&amp;quot; (&amp;quot;you&amp;quot; (SG PL))))
(VERB* &amp;quot;can&amp;quot; (&amp;quot;can&amp;quot; PS)))
&amp;quot;see&amp;quot; (&amp;quot;see&amp;quot; PS)))
(PRON* &amp;quot;you&amp;quot; (&amp;quot;you&amp;quot; (SG PL))))
(VERB* &amp;quot;can&amp;quot; (&amp;quot;can&amp;quot; PS)))
&amp;quot;choose&amp;quot; (&amp;quot;choose&amp;quot; PS))
(PP (PREP* &amp;quot;from&amp;quot;))
(QUANP (ADJ* &amp;quot;many&amp;quot; (&amp;quot;many&amp;quot; BS)))
(NOUN* &amp;quot;topics&amp;quot; (&amp;quot;topic&amp;quot; PL))))
(INFTO (PREP* &amp;quot;to&amp;quot;))
(VERB* &amp;quot;find&amp;quot; (&amp;quot;find&amp;quot; PS))
(COMPCL (COMPL &amp;quot;)
(VERB* &amp;quot;out&amp;quot; (&amp;quot;out&amp;quot; PS))
(NP (PRON* &amp;quot;what&amp;quot; (&amp;quot;what&amp;quot; (SG PL))))))
(NOUN* &amp;quot;information&amp;quot; (&amp;quot;information&amp;quot; SG)))
&amp;quot;is&amp;quot; (&amp;quot;be&amp;quot; PS))
(ADJ* &amp;quot;available&amp;quot; (&amp;quot;available&amp;quot; BS))
(PP (PP (PREP* &amp;quot;about&amp;quot;))
(DETP (ADJ* &amp;quot;the&amp;quot; (&amp;quot;the&amp;quot; BS)))
(NP (NOUN* &amp;quot;AS/400&amp;quot; (&amp;quot;AS/400&amp;quot; (SG PL))))
(NOUN* &amp;quot;system&amp;quot; (&amp;quot;system&amp;quot; SG)))))
</table>
<figureCaption confidence="0.969939">
Figure 2: Example of an incomplete parse obtained by the PEG parser
</figureCaption>
<bodyText confidence="0.9021335">
As you can see, the help display provides additional information about the menu options
available, as well as a list of related topics.
</bodyText>
<table confidence="0.994958">
((DECL (SUBCL (CONJ &amp;quot;as&amp;quot;)
(NP (PRON* &amp;quot;you&amp;quot; (&amp;quot;you&amp;quot; (SG PL))))
(AUXP (VERB* &amp;quot;can&amp;quot; (&amp;quot;can&amp;quot; PS)))
(VERB* &amp;quot;see&amp;quot; (&amp;quot;see&amp;quot; PS))
(PUNC &amp;quot;,&amp;quot;))
(NP (DETP (ADJ* &amp;quot;the&amp;quot; (&amp;quot;the&amp;quot; BS)))
(NP (NOUN* &amp;quot;help&amp;quot; (&amp;quot;help&amp;quot; SG)))
(NOUN* &amp;quot;display&amp;quot; (&amp;quot;display&amp;quot; SG)))
(VERB* &amp;quot;provides&amp;quot; (&amp;quot;provide&amp;quot; PS))
</table>
<figureCaption confidence="0.984403">
Figure 3: Thirty-ninth sentence of Chapter 6 and a part of its parse
</figureCaption>
<bodyText confidence="0.9723505">
the parse data. Table 3 shows an example of
such information. In this table, CFRAME
</bodyText>
<sectionHeader confidence="0.45682" genericHeader="method">
-LJLJULJULJ
</sectionHeader>
<bodyText confidence="0.976703368421053">
indicates an instance of cursor in the discourse;
information on the position and on the whole
sentence can be extracted from each occurrence
of CFRAME. In accumulating discourse informa-
tion, a score of 1.0 is awarded for each definite
modifiee-modifier relationship. A lower score,
0.1, is awarded for each ambiguous modifiee-
modifier relationship, since such relationships
are less reliable.
2. When all the sentences have been parsed, the
discourse information is used to select the most
preferable candidate for sentences with multi-
ple possible parses, and the data of the selected
parse are added to the discourse information.
After all the sentences except the ill-formed sen-
tences that caused incomplete parses have provided
data for use as discourse information, the parse com-
pletion procedure begins.
The initial data used in the completion procedure
are a set of partial parses generated by a bottom-up
parser as an incomplete parse tree. For example, the
PEG parser generated three partial parses for sen-
tence (2.1), consisting of &amp;quot;As you can see,&amp;quot; &amp;quot;you can
choose from many topics,&amp;quot; and &amp;quot;to find out what
information is available about the AS/400 system,&amp;quot;
as shown in Figure 2. Since partial parses are gen-
erated by means of grammar rules in a parser, we
decided to restructure each partial parse and unify
them according to the discourse information, rather
than construct the whole parse tree from discourse
information.
The completion procedure consists of two steps:
Step 1: Inspecting each partial parse and
restructuring it on the basis of the discourse
information
For each word in a partial parse, the part of speech
and the modifiee-modifier relationships with other
words are inspected. If they are different from those
</bodyText>
<page confidence="0.999639">
42
</page>
<tableCaption confidence="0.998932">
Table 2: Selecting POS candidates on the basis of discourse information
</tableCaption>
<table confidence="0.98462403125">
As you can see, you can choose from many topics to find out
Candidates CJ PN N N PN N V PP AJ N PP N PP
for the POS AV V V V N V N
of each word PP PN AV PP
V
Phrases As you can see, appears in sentences 39, 175.
repeated CJ PN V V
within the
discourse
you can choose appears in sentences 179.
PN V V
many appears in sentences 49.
AJ topics find out what
N (PN)
appears in sentences 39, 140, 145, 160, 161 167 169... to find
PP V
appears in, sentences 236.
appears in sentences 32. V PP
POS CJ PN V V PN V V PP Al N PP V PP
what information is available about the AS/400 system.
Candidates Al N V AJ AJ DET N N
for the POS AV AV
of each word PN PP
Phrases what information is available about the appears in sentences 49.
repeated Al N V AJ PP DET
within the
discourse
appears in sentences 6, 109, 115. the AS/400 system.
DET N N
POS PN N V Al PP DET N N
Al
N=noun PN=pronoun V=verb AJ=adjective AV=adverb CJ= conjunction PP= preposition DET=deterrniner
</table>
<figureCaption confidence="0.767835333333333">
Figure 4: Constructing a dependency structure by
combining dependencies existing within phrases that
occur in other sentences of the same chapter
</figureCaption>
<bodyText confidence="0.95398795">
in the discourse information, the partial parse is re-
structured according to the discourse information.
For example, Figure 5 shows an incomplete parse
of the following sentence, which is the 43rd sentence
in a technical text that consists of 175 sentences.3
(3.1) Fig. 3 is an isometric view of the magazine
taken from the operator&apos;s side with one car-
tridge shown in an unprocessed position and
two cartridges shown in a processed position.
In the second partial parse, the word &amp;quot;side&amp;quot; is an-
alyzed as a verb. The same word appears fifteen
times in the discourse information extracted from
well-formed sentences, and is analyzed as a noun ev-
ery time it appears in complete parses; furthermore,
there are no data on the noun &amp;quot;operator&amp;quot; modify-
ing the verb &amp;quot;take&amp;quot; through the preposition &amp;quot;from,&amp;quot;
while there is information on the noun &amp;quot;operator&apos;s&amp;quot;
modifying the noun &amp;quot;side,&amp;quot; as in sentence (3.2), and
on the noun &amp;quot;side&amp;quot; modifying the verb &amp;quot;take,&amp;quot; as in
sentence (3.3).
</bodyText>
<footnote confidence="0.876530555555556">
(3.2) In the operation of the invention, an oper-
ator loads cartridges into the magazine from
3This structure resulting from an incomplete parse
does not indicate that the grammar of the parser lacks a
rule for handling a possessive case indicated by an apos-
trophe and an s. When the parser fails to generate a
unified parse, it outputs partial parses in such a manner
that fewer partial parses cover every word in the input
sentence.
</footnote>
<page confidence="0.999877">
43
</page>
<tableCaption confidence="0.998754">
Table 3: Discourse information on modifiees and modifiers of a noun &amp;quot;cursor&amp;quot;
</tableCaption>
<table confidence="0.997532666666667">
Modifiers
POS Relation Word (CFRAMEs preference value)
Noun of display (CFRAME106873 0.1)
in protected area (CFRAME106872 1)
to left (CFRAME106407 0.1) right(CFRAME106338 0.1)
DIRECT position (CFRAME106405 1)
Adjective up line (CFRAME106295 0.1)
DIRECT your (CFRAME106690 CFRAME106550 2)
Modifiees
POS Relation Word (CFRAMEs preference value)
Verb with play (CFRAME106928 0.1) be (CFRAME106927 0.1)
up move (CFRAME106688 1)
SUBJ stop (CFRAME106572 1) reach (CFRAME106346 1) move (CFRAME106248 1)
OBJ move (CFRAME106402 CFRAME106335 CFRAME106292 3) confuse (CFRAME106548 1)
RECIPIENT move (CFRAME106304 1)
</table>
<figure confidence="0.964220074074074">
with
and (conj)
Li one cartridge (n)
shown (v)
in unprocessed position (n)
f H magazine (n)
taken (v)
Li. from 1-1 operator (n)
side (v)
two cartridges (n)
shown (v)
processed position (n)
unprocessed position (n)
processed position (n)
of j magazine (n)I
taken (v)
from .
side (n) H operator (n)
......
with
and (conj)
ione cartridge (n))
shown (v)
two cartridges (n)
Lishown (v)
in
. •
</figure>
<figureCaption confidence="0.9430885">
Figure 5: Example of an incomplete parse by the
ESG parser
</figureCaption>
<bodyText confidence="0.924545">
the operator&apos;s side as seen in Figs. 3 and 12.
(151st sentence)
(3.3) Fig. 4 is an isometric view of the magazine
taken from the machine side with one cartridge
shown in the unprocessed position and two car-
tridges shown in the processed position. (44th
sentence)
Therefore, these two partial parses are restructured
by changing the part of speech of the word &amp;quot;side&amp;quot;
to noun, and the modifiee of the noun &amp;quot;operator&amp;quot; to
</bodyText>
<figureCaption confidence="0.997512">
Figure 6: Example of a completed parse
</figureCaption>
<bodyText confidence="0.9696573">
the noun &amp;quot;side,&amp;quot; while at the same time changing
the modifiee of the noun &amp;quot;side&amp;quot; to the verb &amp;quot;take.&amp;quot;
As a result, a unified parse is obtained, as shown in
Figure 6.
Step 2: Joining partial parses on the basis of
the discourse information
If the partial parses are not unified into a single
structure in the previous step, they are joined to-
gether on the basis of the discourse information until
a unified parse is obtained.
</bodyText>
<page confidence="0.998061">
44
</page>
<bodyText confidence="0.999276457142857">
Partial parses are joined as follows:
First, the possibility of joining the first two partial
parses is examined, then, either the unification of
the first two parses or the second parse is examined
to determine whether it can be joined to the third
parse, then the examination moves to the next parse,
and so on.
Two partial parses are joined if the root (head
node) of either parse tree can modify a node in
the other parse without crossing the modification of
other nodes.
To examine the possibility of modification, dis-
course information is applied at three different lev-
els. First, for a candidate modifier and modifiee,
an identical pattern containing the modifier word
and the modifiee word in the same part of speech
and in the same relationship is searched for in the
discourse information. Next, if there is no identi-
cal pattern, a modification pattern with a synonym
(Collins, 1984) of the node on one side is searched
for in the discourse information. Then, if this also
fails, a modification pattern containing a word that
has the same part of speech as the word on one side
of the node is searched for.
Since the discourse information consists of mod-
ification patterns extracted from complete parses,
it reflects the grammar rules of the parser, and a
matching pattern with a part of speech rather than
an actual word on one side can be regarded as a
relaxation rule, in the sense that syntactic and se-
mantic constraints are less restrictive than the cor-
responding grammar rule in the parser.
These matching conditions at different levels are
applied in such a manner that partial parses are
joined through the most preferable nodes.
</bodyText>
<subsectionHeader confidence="0.569688">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999986566037736">
We have implemented this method on an English-to-
Japanese machine translation system called Shalt2
(Takeda et al., 1992), and conducted experiments
to evaluate the effectiveness of this method. Ta-
ble 4 gives the result of our experiments on two
technical documents of different kinds, one a patent
document (text 1), and the other a computer man-
ual (text 2). Since text 1 contained longer and
more complex sentences than text 2, our ESG parser
failed to generate unified parses more often in text
1; on the other hand, the frequency of morpholog-
ically identical words and collocation patterns was
higher in text 1, and our method was more effec-
tive in text 1. In both texts, the discourse infor-
mation provided enough information to unify par-
tial parses of an incomplete parse in more than half
of the cases. However, the resulting unified parses
were not always correct. Since sentences with in-
complete parses are usually quite long and contain
complicated structures, it is hard to obtain a per-
fect analysis for those sentences. Thus, in order to
evaluate the improvement in the output translation
rather than the improvement in the rate of success
in syntactic analysis, in which only perfect analy-
ses are counted, we compared output translations
generated with and without the application of our
method. When our method was not applied, partial
parses of an incomplete parse were joined by means
of some heuristic rules such as the one that joins a
partial parse with &amp;quot;NP&amp;quot; in its root node to a partial
parse with &amp;quot;VP&amp;quot; in its root node, and the root node
of the second partial parse was joined to the last
node of the first partial parse by default. When the
discourse information did not provide enough infor-
mation to unify partial parses with the application
of our method, the heuristic rules were applied. In
such cases the default rule of joining the root node of
the second partial parse to the last node of the first
partial parse was mostly applied, since the least re-
strictive matching patterns in our method were sim-
ilar to the heuristic rules. Thus, the system gen-
erated a unified parse for each sentence regardless
of the discourse information, and we compared the
output translations generated with and without the
application of our method. The results are shown in
Table 4. The translations were compared by check-
ing how well the output Japanese sentence conveyed
the meaning of the input English sentence. Since
most unified parses contained various errors, such as
incorrect modification patterns and incorrect parts
of speech assigned to some words, fewer errors gen-
erally resulted in better translations, but incorrect
parts of speech resulted in worse translations.
</bodyText>
<sectionHeader confidence="0.998308" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99999556">
We have proposed a method for completing partial
parses of ill-formed sentences on the basis of informa-
tion extracted from complete parses of well-formed
sentences in the discourse. Our approach to han-
dling ill-formed sentences is fundamentally different
from previous ones in that it reanalyzes the part of
speech and modifiee-modifier relationships of each
word in an ill-formed sentence by using information
extracted from analyses of other sentences in the
same text, thus, attempting to generate the analy-
sis most appropriate to the discourse. The results
of our experiments show the effectiveness of this
method; moreover, implementation of this method
on a machine translation system improved the accu-
racy of its translation. Since this method has a sim-
ple framework that does not require any extra knowl-
edge resources or inference mechanisms, it is robust
and suitable for a practical natural language pro-
cessing system. Furthermore, in terms of the turn-
around time (TAT) of the whole translation pro-
cedure, the improvement in the parses achieved by
using this method along with other disambiguation
methods involving discourse information, as shown
in another paper (Nasukawa, 1995), shortened the
TAT in the late stages of the translation procedure,
</bodyText>
<page confidence="0.999726">
45
</page>
<tableCaption confidence="0.999645">
Table 4: Results of completing incomplete parses on the basis of discourse information
</tableCaption>
<table confidence="0.9902001875">
Textl Text2
Number of sentences in discourse 175 354
Incomplete parses 32 31
Unified into a single parse 18 (56.3%) 17 (54.8%)
Improvement Better 7 7
in
translation
Even 10 7
Worse 1 3
Partially joined or restructured 12 (37.5%) 8 (25.8%)
Improvement Better 4 2
in
translation
Even 7 3
Worse 1 3
Not changed 2 (6.3%) 6 (19.4%)
</table>
<bodyText confidence="0.999844666666667">
and compensated for the extra TAT required as a
result of using the discourse information, provided
the size of the discourse was kept to between 100
and 300 sentences.
In this paper, the term &amp;quot;discourse&amp;quot; is used as a
set of words in a text together with the usage of
each of those words in that text — namely, a part
of speech and modifiee-modifier relationships with
other words. The basic idea of our method is to im-
prove the accuracy of sentence analysis simply by
maintaining consistency in the usage of morphologi-
cally identical words within the same text. Thus, the
effectiveness of this method is highly dependent on
the source text, since it presupposes that morpholog-
ically identical words are likely to be repeated in the
same text. However, the results have been encourag-
ing at least with technical documents such as com-
puter manuals, where words with the same lemma
are frequently repeated in a small area of text. More-
over, our method improves the translation accuracy,
especially for frequently repeated phrases, which are
usually considered to be important, and leads to an
improvement in the overall accuracy of the natural
language processing system.
</bodyText>
<sectionHeader confidence="0.99133" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999788142857143">
I would like to thank Michael McDonald for in-
valuable help in proofreading this paper. I would
also like to thank Taijiro Tsutsumi, Masayuki Mo-
rohashi, Koichi Takeda, Hiroshi Maruyama, Hiroshi
Nomiyama, Hideo Watanabe, Shiho Ogino, and the
anonymous reviewers for their comments and sug-
gestions.
</bodyText>
<sectionHeader confidence="0.997847" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999736323529412">
Douglas, S. and Dale, R. 1992. Towards Robust
PATR. In Proceedings of COLING-92.
Gale, W.A., Church, K.W., and Yarowsky, D. 1992.
One Sense per Discourse. In Proceedings of the 4th
DARPA Speech and Natural Language Workshop.
Jensen, K., Heidorn, G.E., Miller, L.A. and Ravin,
Y. 1983. Parse Fitting and Prose Fixing: Getting
a Hold on Ill-Formedness. Computational Linguis-
tics, Vol. 9, Nos. 3-4.
Jensen, K. 1992. PEG: The PLNLP English Gram-
mar. Natural Language Processing: The PLNLP
Approach, K. Jensen, G. Heidorn, and S. Richard-
son, eds., Boston, Mass.: Kluwer Academic Pub-
lishers.
McCord, M. 1991. The Slot Grammar System. IBM
Research Report, RC17313.
Nasukawa, T. 1993. Discourse Constraint in Com-
puter Manuals. In Proceedings of TMI-93.
Nasukawa, T. 1995. Shallow and Robust Context
Processing for a Practical MT System. To appear
in Proceedings of IJCAI-95 Workshop on &amp;quot;Context
in Natural Language Processing.&amp;quot;
Richardson, S.D. and Braden-Harder, L.C. 1988.
The Experience of Developing a Large-Scale Nat-
ural Language Text Processing System: CRI-
TIQUE. In Proceedings of ANLP-88.
Takeda, K., Uramoto, N., Nasukawa, T., and Tsut-
sumi, T. 1992. Shalt2 — A Symmetric Machine
Translation System with Conceptual Transfer. In
Proceedings of COLING-92.
IBM 1992. IBM Application System/400 New
User&apos;s Guide Version 2. IBM Corp.
COLLINS 1984. The New Collins Thesaurus.
Collins Publishers, Glasgow.
</reference>
<page confidence="0.999612">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.972788">
<title confidence="0.997290666666667">Robust Parsing Based on Discourse Information: Completing partial parses of ill-formed sentences on the basis of discourse information</title>
<author confidence="0.995713">Tetsuya Nasulcawa</author>
<affiliation confidence="0.999993">IBM Research, Tokyo Research Laboratory</affiliation>
<address confidence="0.992031">1623-14, Shimotsuruma, Yamato-shi, Kanagawa-ken 242, Japan</address>
<email confidence="0.999753">nasukawa@trl.vnet.ibm.com</email>
<abstract confidence="0.999727413793104">In a consistent text, many words and phrases are repeatedly used in more than one sentence. When an identical phrase (a set of consecutive words) is repeated in different sentences, the constituent words of those sentences tend to be associated in identical modification patterns with identiparts of speech and identical modifieemodifier relationships. Thus, when a syntactic parser cannot parse a sentence as a unified structure, parts of speech and modifiee-modifier relationships among morphologically identical words in complete parses of other sentences within the same text provide useful information for obtaining partial parses of the sentence. In this paper, we describe a method for completing partial parses by maintaining consistency among morphologically identical words within the same text as regards their part of speech and their modifieemodifier relationship. The experimental results obtained by using this method with technical documents offer good prospects for improving the accuracy of sentence analysis in a broad-coverage natural language processing system such as a machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Douglas</author>
<author>R Dale</author>
</authors>
<title>Towards Robust PATR.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING-92.</booktitle>
<contexts>
<context position="2748" citStr="Douglas and Dale, 1992" startWordPosition="417" endWordPosition="420">the syntactic parser. In texts from a restricted domain, such as computer manuals, most sentences are grammatically correct. However, even a well-established syntactic parser usually fails to generate a unified parsed structure for about 10 to 20 percent of all the sentences in such texts, and the failure to generate a unified parsed structure in syntactic analysis leads to a failure in the output of a NLP system. Thus, it is indispensable to establish a correct analysis for such a sentence. To handle such sentences, most previous approaches apply various heuristic rules (Jensen et al., 1992; Douglas and Dale, 1992; Richardson and Braden-Harder, 1988), including • Relaxing constraints in the condition part of a grammatical rule, such as number and gender constraints • Joining partial parses by using meta rules. Either way, the output reflects the general plausibility of an analysis that can be obtained from information in the sentence; however, the interpretation of a sentence depends on its discourse, and inconsistency with recovered parses that contain different analyses of the same phrase in other sentences in the discourse often results in odd outputs of the natural language processing system. Start</context>
</contexts>
<marker>Douglas, Dale, 1992</marker>
<rawString>Douglas, S. and Dale, R. 1992. Towards Robust PATR. In Proceedings of COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>One Sense per Discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the 4th DARPA Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="4817" citStr="Gale et al., 1992" startWordPosition="741" endWordPosition="744"> for ill-formed sentences, by using information extracted from the discourse. In the next section, the effectiveness of using information extracted from the discourse to complete syntactic analysis of ill-formed sentences. After that, we propose an algorithm for completing incomplete parses by using discourse information, and give the results of an experiment on completing incomplete parses in technical documents. 2 Discourse information for completing incomplete parses In this section, we use the word &amp;quot;discourse&amp;quot; to denote a set of sentences that forms a text concerning related topics. Gale (Gale et al., 1992) and Nasukawa (Nasukawa, 1993) reported that polysemous words within the same discourse have the same word sense with a high probability (98% according to (Gale et al., 1992),) and the results of our analysis indicate that most content words are frequently repeated in the discourse, as is shown in Table 1; moreover, collocation (modifier-modifiee relationship) patterns are also repeated frequently in the same discourse, as is shown in Figure 1. This figure reflects the analysis of structurally ambiguous phrases in a computer manual consisting of 791 consecutive sentences for discourse sizes ra</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, W.A., Church, K.W., and Yarowsky, D. 1992. One Sense per Discourse. In Proceedings of the 4th DARPA Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jensen</author>
<author>G E Heidorn</author>
<author>L A Miller</author>
<author>Y Ravin</author>
</authors>
<title>Parse Fitting and Prose Fixing: Getting a Hold on Ill-Formedness.</title>
<date>1983</date>
<journal>Computational Linguistics,</journal>
<volume>9</volume>
<pages>3--4</pages>
<marker>Jensen, Heidorn, Miller, Ravin, 1983</marker>
<rawString>Jensen, K., Heidorn, G.E., Miller, L.A. and Ravin, Y. 1983. Parse Fitting and Prose Fixing: Getting a Hold on Ill-Formedness. Computational Linguistics, Vol. 9, Nos. 3-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jensen</author>
</authors>
<title>PEG: The PLNLP English Grammar. Natural Language Processing: The PLNLP Approach,</title>
<date>1992</date>
<editor>K. Jensen, G. Heidorn, and S. Richardson, eds.,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Boston, Mass.:</location>
<contexts>
<context position="9322" citStr="Jensen, 1992" startWordPosition="1487" endWordPosition="1488">ded up the collocation scores to assign a preference value to the candidate parse. Out of the 126 sentences, different preference values were assigned to candidate parses in 54 sentences, and the highest value was assigned to a correct parse in 48 (88.9%) of the 54 sentences. Thus, there is a strong tendency for identical collocations to be actually repeated in the discourse, and when an identical phrase (a set of consecutive words) is repeated in different sentences, their constituent words tend to be associated in identical modification patterns. Figure 2 shows the output of the PEG parser (Jensen, 1992) for the following sentence: (2.1) As you can see, you can choose from many topics to find out what information is available about the AS/400 system. This is the 53rd sentence in Chapter 6 of a computer manual (IBM, 1992), and every word of it is repeatedly used in other sentences in the same chapter, as shown in Table 2. For example, the 39th sentence in the same chapter contains &amp;quot;As you can see,&amp;quot; as 40 Table 1: Frequency of morphologically identical words in computer manuals Part Freq. of morph. identical words Proportion of all content words of speech Two or more Five or more Total number o</context>
</contexts>
<marker>Jensen, 1992</marker>
<rawString>Jensen, K. 1992. PEG: The PLNLP English Grammar. Natural Language Processing: The PLNLP Approach, K. Jensen, G. Heidorn, and S. Richardson, eds., Boston, Mass.: Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M McCord</author>
</authors>
<title>The Slot Grammar System.</title>
<date>1991</date>
<tech>IBM Research Report, RC17313.</tech>
<contexts>
<context position="8112" citStr="McCord, 1991" startWordPosition="1287" endWordPosition="1288">e than one part of speech, or to the presence of complicated coordinate structures, or for various other reasons. If the constituent words tend to be associated in identical modification patterns with an identical part of speech and identical modifiee-modifier relationship when an identical phrase (a set of consecutive words) is repeated in different sentences within the discourse, the candidate parse that shares the most collocation patterns with other sentences in the discourse should be selected as the correct analysis. Out of 736 consecutive sentences in a computer manual, the ESG parser (McCord, 1991) generated multiple parses for 150 sentences. In this experiment, we divided the original 736 sentences into two texts, one a discourse of 400 sentences and the other a discourse of 336 sentences. Of the 150 sentences with multiple parses, 24 were incorrectly analyzed in all candidate parses or had identical candidate parses; we therefore focused on the other 126 sentences. In each candidate parse of these sentences, we assigned a score for each collocation that was repeated in other sentences in the discourse (in the form of either an identical collocation or a similar collocation), and added</context>
</contexts>
<marker>McCord, 1991</marker>
<rawString>McCord, M. 1991. The Slot Grammar System. IBM Research Report, RC17313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nasukawa</author>
</authors>
<title>Discourse Constraint in Computer Manuals.</title>
<date>1993</date>
<booktitle>In Proceedings of TMI-93.</booktitle>
<contexts>
<context position="4847" citStr="Nasukawa, 1993" startWordPosition="747" endWordPosition="748">ng information extracted from the discourse. In the next section, the effectiveness of using information extracted from the discourse to complete syntactic analysis of ill-formed sentences. After that, we propose an algorithm for completing incomplete parses by using discourse information, and give the results of an experiment on completing incomplete parses in technical documents. 2 Discourse information for completing incomplete parses In this section, we use the word &amp;quot;discourse&amp;quot; to denote a set of sentences that forms a text concerning related topics. Gale (Gale et al., 1992) and Nasukawa (Nasukawa, 1993) reported that polysemous words within the same discourse have the same word sense with a high probability (98% according to (Gale et al., 1992),) and the results of our analysis indicate that most content words are frequently repeated in the discourse, as is shown in Table 1; moreover, collocation (modifier-modifiee relationship) patterns are also repeated frequently in the same discourse, as is shown in Figure 1. This figure reflects the analysis of structurally ambiguous phrases in a computer manual consisting of 791 consecutive sentences for discourse sizes ranging from 10 to 791 sentences</context>
</contexts>
<marker>Nasukawa, 1993</marker>
<rawString>Nasukawa, T. 1993. Discourse Constraint in Computer Manuals. In Proceedings of TMI-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nasukawa</author>
</authors>
<title>Shallow and Robust Context Processing for a Practical MT System. To appear in</title>
<date>1995</date>
<booktitle>Proceedings of IJCAI-95 Workshop on &amp;quot;Context in Natural Language Processing.&amp;quot;</booktitle>
<contexts>
<context position="25805" citStr="Nasukawa, 1995" startWordPosition="4270" endWordPosition="4271">nts show the effectiveness of this method; moreover, implementation of this method on a machine translation system improved the accuracy of its translation. Since this method has a simple framework that does not require any extra knowledge resources or inference mechanisms, it is robust and suitable for a practical natural language processing system. Furthermore, in terms of the turnaround time (TAT) of the whole translation procedure, the improvement in the parses achieved by using this method along with other disambiguation methods involving discourse information, as shown in another paper (Nasukawa, 1995), shortened the TAT in the late stages of the translation procedure, 45 Table 4: Results of completing incomplete parses on the basis of discourse information Textl Text2 Number of sentences in discourse 175 354 Incomplete parses 32 31 Unified into a single parse 18 (56.3%) 17 (54.8%) Improvement Better 7 7 in translation Even 10 7 Worse 1 3 Partially joined or restructured 12 (37.5%) 8 (25.8%) Improvement Better 4 2 in translation Even 7 3 Worse 1 3 Not changed 2 (6.3%) 6 (19.4%) and compensated for the extra TAT required as a result of using the discourse information, provided the size of th</context>
</contexts>
<marker>Nasukawa, 1995</marker>
<rawString>Nasukawa, T. 1995. Shallow and Robust Context Processing for a Practical MT System. To appear in Proceedings of IJCAI-95 Workshop on &amp;quot;Context in Natural Language Processing.&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Richardson</author>
<author>L C Braden-Harder</author>
</authors>
<title>The Experience of Developing a Large-Scale Natural Language Text Processing System: CRITIQUE.</title>
<date>1988</date>
<booktitle>In Proceedings of ANLP-88.</booktitle>
<contexts>
<context position="2785" citStr="Richardson and Braden-Harder, 1988" startWordPosition="421" endWordPosition="424"> texts from a restricted domain, such as computer manuals, most sentences are grammatically correct. However, even a well-established syntactic parser usually fails to generate a unified parsed structure for about 10 to 20 percent of all the sentences in such texts, and the failure to generate a unified parsed structure in syntactic analysis leads to a failure in the output of a NLP system. Thus, it is indispensable to establish a correct analysis for such a sentence. To handle such sentences, most previous approaches apply various heuristic rules (Jensen et al., 1992; Douglas and Dale, 1992; Richardson and Braden-Harder, 1988), including • Relaxing constraints in the condition part of a grammatical rule, such as number and gender constraints • Joining partial parses by using meta rules. Either way, the output reflects the general plausibility of an analysis that can be obtained from information in the sentence; however, the interpretation of a sentence depends on its discourse, and inconsistency with recovered parses that contain different analyses of the same phrase in other sentences in the discourse often results in odd outputs of the natural language processing system. Starting from the viewpoint that an interp</context>
</contexts>
<marker>Richardson, Braden-Harder, 1988</marker>
<rawString>Richardson, S.D. and Braden-Harder, L.C. 1988. The Experience of Developing a Large-Scale Natural Language Text Processing System: CRITIQUE. In Proceedings of ANLP-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
<author>N Uramoto</author>
<author>T Nasukawa</author>
<author>T Tsutsumi</author>
</authors>
<date>1992</date>
<booktitle>Shalt2 — A Symmetric Machine Translation System with Conceptual Transfer. In Proceedings of COLING-92.</booktitle>
<contexts>
<context position="22032" citStr="Takeda et al., 1992" startWordPosition="3647" endWordPosition="3650">f modification patterns extracted from complete parses, it reflects the grammar rules of the parser, and a matching pattern with a part of speech rather than an actual word on one side can be regarded as a relaxation rule, in the sense that syntactic and semantic constraints are less restrictive than the corresponding grammar rule in the parser. These matching conditions at different levels are applied in such a manner that partial parses are joined through the most preferable nodes. 3.2 Results We have implemented this method on an English-toJapanese machine translation system called Shalt2 (Takeda et al., 1992), and conducted experiments to evaluate the effectiveness of this method. Table 4 gives the result of our experiments on two technical documents of different kinds, one a patent document (text 1), and the other a computer manual (text 2). Since text 1 contained longer and more complex sentences than text 2, our ESG parser failed to generate unified parses more often in text 1; on the other hand, the frequency of morphologically identical words and collocation patterns was higher in text 1, and our method was more effective in text 1. In both texts, the discourse information provided enough inf</context>
</contexts>
<marker>Takeda, Uramoto, Nasukawa, Tsutsumi, 1992</marker>
<rawString>Takeda, K., Uramoto, N., Nasukawa, T., and Tsutsumi, T. 1992. Shalt2 — A Symmetric Machine Translation System with Conceptual Transfer. In Proceedings of COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IBM</author>
</authors>
<title>IBM Application System/400 New User&apos;s Guide Version 2.</title>
<date>1992</date>
<publisher>IBM Corp.</publisher>
<contexts>
<context position="9543" citStr="IBM, 1992" startWordPosition="1527" endWordPosition="1528">o a correct parse in 48 (88.9%) of the 54 sentences. Thus, there is a strong tendency for identical collocations to be actually repeated in the discourse, and when an identical phrase (a set of consecutive words) is repeated in different sentences, their constituent words tend to be associated in identical modification patterns. Figure 2 shows the output of the PEG parser (Jensen, 1992) for the following sentence: (2.1) As you can see, you can choose from many topics to find out what information is available about the AS/400 system. This is the 53rd sentence in Chapter 6 of a computer manual (IBM, 1992), and every word of it is repeatedly used in other sentences in the same chapter, as shown in Table 2. For example, the 39th sentence in the same chapter contains &amp;quot;As you can see,&amp;quot; as 40 Table 1: Frequency of morphologically identical words in computer manuals Part Freq. of morph. identical words Proportion of all content words of speech Two or more Five or more Total number of Proportion times (%) times (%) appearances (words) (%) Noun 90.7 76.2 99047 59.8 Verb 94.9 83.6 35622 21.5 Adjective 88.9 71.0 16941 10.2 Adverb 85.9 68.8 4993 3.0 Pronoun 98.0 94.8 8911 5.4 Total 91.6 78.0 165514 — Rat</context>
</contexts>
<marker>IBM, 1992</marker>
<rawString>IBM 1992. IBM Application System/400 New User&apos;s Guide Version 2. IBM Corp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>COLLINS</author>
</authors>
<title>The New Collins Thesaurus.</title>
<date>1984</date>
<publisher>Collins Publishers,</publisher>
<location>Glasgow.</location>
<marker>COLLINS, 1984</marker>
<rawString>COLLINS 1984. The New Collins Thesaurus. Collins Publishers, Glasgow.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>