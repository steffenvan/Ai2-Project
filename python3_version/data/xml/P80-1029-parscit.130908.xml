<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000333">
<note confidence="0.836569666666667">
STRATEGIE SELECT/ON FOR AN ATN SYNTACTIC PARSER
Giacomo Ferrari and Oliviero Stock
Istituto di Linguistica Computazionale — CNR, Pisa
</note>
<bodyText confidence="0.735405307692308">
Performance evaluation in the field of natural language processing is
generally recognised as being extremely complex. There are, so far, no
pre—established criteria to deal with this problem.
1. It is impossible to measure the merits of a grammar, seen as the
component of an analyser, in absolute terms. An &amp;quot;ad hoc&amp;quot; grammar, constructed
for a limited set of sentences is, without doubt, more efficient in dealing with
those particular sentences than a grammar constructed for a larger set.
Therefore, the first rudimentary criterion, when evaluating the relationship
between a grammar and a set of sentences, should be to establish whether this
grammar is capable of analysing these sentences. This is the determination of
linguistic coverage, and necessitates the definition of the linguistic
phenomena, independently of the linguistic theory which has been adopted to
recognise these phenomena.
</bodyText>
<listItem confidence="0.979435">
2. In addition to its ability to recognise and coherently describe
linguistic phenomena, a grammar should be judged by its capacity to resolve
ambiguity, to bypass irrelevant errors in the text being analysed, and so on.
This aspect of a grammar could he regarded as its &amp;quot;robustness&amp;quot; (P.Fayes, R.Reddy
19791.
3. Examining other aspects of the problem, in the analysis that we propose we
will assume a grammar which is capable of dealing with the texts which we will
submit to it.
</listItem>
<bodyText confidence="0.975829703703704">
Let an ATN grammar N, with n nodes, be of this type. N will be maintained
constant for the following discussion.
By text we intend a series of sentences, or of utterances by one of the
speakers in a dialogue. When analysing such a text, once a constant N has been
assumed, it is likely that, in addition to the content (the argument of the
discourse) indications will appear on the grammatical choices made by the author
of the text (or the speaker) when expressing himself on that argument (how the
argument is expressed).
When these indications have been adequately quantified, they can be used to
correctly select the perceptive strategies (as defined in (Kaplan 721) to be
adopted in order to achieve greater efficiency in the analysis of the following
part of the text.
4. For our experiments we have used ATNSYS (Stock 761, and an Italian
grammar with n 50 (127 arcs) (Cappelli et al.771. In this system, search is
depth—first and the parser interacts with a heuristic mechanism which
orders the arcs according to a probability evaluation. This probability
evaluation is dependent on the path which led to the current node and is also a
function of the statistical data accumulated during previous analyses of a
&amp;quot;coherent&amp;quot; text.
The mechanism can be divided into two stages. The first stage consists of the
acquisition of statistical data; i.e. the frequency, for each arc exiting from a
node, of the passages across that arc, in relation to the arc of arrival: for
each arriving arc there are as many counters as there are exiting arcs.
Fig. 1
In this way, in Fig. I arc I has been crossed x times coming from a and y times
coming from b. In the second stage, during parsing, in state S, if coming from
a and w x, arc 2 is tried first.
</bodyText>
<page confidence="0.995404">
113
</page>
<subsectionHeader confidence="0.613691">
4.1 Thus, a first evaluation of the linguistic choices made is provided by the
</subsectionHeader>
<bodyText confidence="0.921678095238095">
set of probability values associated to each arc. These figures can to some
extent describe the &amp;quot;style&amp;quot; of any &amp;quot;coherent&amp;quot; text analysed. (For this one
should also take into account the different linguistic significance of each arc.
In fact a CAT or PUSH arc directly corresponds to a certain linguistic
component, while a JUMP or VIRT arc occurs in relation to the technique by which
the network has been built, the linguistic theory adopted, and other variables.)
4.2 The second part of the mechanism, the dynamic reordering of the arcs,
coincides with a reordering of the comprehension strategies. In this way, a
matrix can be associated to each node, giving the order of the strategies for
each arc in arrival.
For each text T, there is a set of strategies S,, ordered as described above.
While the analysis of the probability values for two distinct texts T and T&apos; can
give global indications of their linguistic characteristics, if we focus on the
comprehension of the sentence, it is more meaningful to give evaluations in
relation to the sets of strategies, ST and SI. , which are selected.
Fig. 2 shows , for some nodes, a comparison between the orders of the arcs for
the first 11 sentences from two texts, a science fiction novel (SFN, upper
boxes) and a handbook of food chemistry (FC. lower boxes). The arc numbers are
referred to the order in the original network. The figures which appear after
the m in the heading indicate the number of parses for each sentence. An empty
box indicates the same order as that shown in the previous box.
</bodyText>
<table confidence="0.99774848">
.• .. P7424 S171-1 0 :2142-4 SFN3-2. 5E144.1 5FN5.• 5 •:• kSEN7, , .1 -39
1 tSETI,6,..
t,SZFIR: SFR&apos;) 0:14 ;gill 01 .1 57 5-4.
5 ,52 123 132
312
•••• 312
312 i
.&apos;•fl 312
312
Lots 51 miryi 513 24 51342 _
4 52134 57111
51 234
/50501 51234
41 235 4 51 23
431 5
GV/1 4123 41 23 41 21
4214 2413 4 71 1
GP ,,,1
123
51 213 211
123
larman 123
1
123
0J/FPN42 1 123
</table>
<page confidence="0.275826">
23
</page>
<bodyText confidence="0.57462175">
5.1 It is to be expected that this mechanism, in so far as it introduces a
heuristics, will increase the efficiency of the system used for the linguistic
analysis. The results of our experiments so far confirm this. This improved
efficiency can be measured in three ways:
</bodyText>
<equation confidence="0.652683">
a) locally, in terms of the computational load, due to non—determinism, which is
</equation>
<bodyText confidence="0.9940136">
saved in each node. In fact, by some experiments, it is possible to
quantify the computational load of each type of arc. The computational load
of a node is then a linear combination of these values and one can compare it
with the actual load determined by the sequence of arcs attempted in that
point after the reordering.
</bodyText>
<subsectionHeader confidence="0.555085">
b) in terms of an overall reduction in computing time;
</subsectionHeader>
<bodyText confidence="0.749553">
c) in terms of penetrance, i.e. the ratio between the number of choices which
actually lead to a solution and the total number of choices made.
</bodyText>
<subsectionHeader confidence="0.866405">
5.2 If T is a text containing r sentences, the average penetrance will be:
</subsectionHeader>
<bodyText confidence="0.909256">
P (s-r,1-)
where .4;,. stands for each of the sentences in T.
If T is analysed using the set of strategies chosen for a different text, T&apos;,
then the penetrance is, on average, no greater than withST •
</bodyText>
<page confidence="0.997236">
114
</page>
<bodyText confidence="0.906261391304348">
In our experiments, for instance, the averag,s nenetrance for the first text
(SFN) parsed with its own strategies (Sww) is Y„,(S,0.0SFN) 0.52, while parsed
with the strategies of the second text (51.4) is ?..,(S.SFN) m 0.39.
We have attempted to evaluate experimentally the relationship between the
difference of the average penetrances. which we call discrepancy
D s„ sr, )T L - L (Sr.,
and the distance between two sets of strategies. However we think we need more
experimentation before formalizing this relationship.
Returning to our science fiction novel, the discrevancY using its set of
strategies and the one inferred by the food chemistry text is
0.13
9■41
6. In addition to the definition of a heuristic mechanism which is capable of
improving the efficiency of natural language processing, and which can be
evaluated as described above, our research aims at providing a means to
characterise a text by evaluating the grammatical choices made by the author
while expressing his argument.
We are also attempting to take into account the expectations of the listener.
In our opinion, the listener&apos;s expectations are not limited to the argument of
the discourse but are also related to the way in which the argument is
expressed; this is the equivalent of the choice of a sub-grammar (Kittredge 791
• We intend to verify the existence of such expectations not only in literature
or when listening to long speeches, hut also in dialogue.
</bodyText>
<sectionHeader confidence="0.999078" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.9999222">
1. Cappelli A., Ferrari G., Moretti L., Prodanof I., Stock O.- &apos;An
Experimental ATN Parser for Italian Texts&apos; Technical Report, LLC-CNR, Pisa
1977.
2. Kaplan R.- &apos;Augmented Transition Networks as Psychological Models of
Sentence Comprehension&apos; Artificial Intelligence 3 1972, Amsterdam - New York
Oxford.
3. Hayes P., Reddy R. - &apos;An anatomy of Graceful Interaction in Spoken and
written Man-Machine Communication&apos;, CMU-CS-79-144, Pittsburgh PA, 1979.
4. Kittredge R.- &apos;Textual Cohesion Within Sublanguages: Implications for
Automatic Analysis and Synthesis&apos;, COLING 78, lergen, 1978.
5. Stevens A., Rumelhart D.- &apos;Errors in Reading:An Analysis Using an Augmented
Transition Network Model of Grammar&apos; in Norman D., Rumelhart D. eds.,
Explorations in Cognition, Freeman, S.Francisco, 1975, pp. 136-155.
6. Stock o. - &apos;ATNSYS: Un sistema per l&apos;analisi grammaticale automatics delle
lingua naturali&apos;, NI-R76-29, MI, Pisa, 1976.
</reference>
<page confidence="0.999027">
115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.003430">
<title confidence="0.997611">STRATEGIE SELECT/ON FOR AN ATN SYNTACTIC PARSER</title>
<author confidence="0.999777">Giacomo Ferrari</author>
<author confidence="0.999777">Oliviero Stock</author>
<affiliation confidence="0.864062">Istituto di Linguistica Computazionale — CNR, Pisa</affiliation>
<abstract confidence="0.9814238">Performance evaluation in the field of natural language processing is generally recognised as being extremely complex. There are, so far, no pre—established criteria to deal with this problem. 1. It is impossible to measure the merits of a grammar, seen as the component of an analyser, in absolute terms. An &amp;quot;ad hoc&amp;quot; grammar, constructed for a limited set of sentences is, without doubt, more efficient in dealing with those particular sentences than a grammar constructed for a larger set. Therefore, the first rudimentary criterion, when evaluating the relationship between a grammar and a set of sentences, should be to establish whether this grammar is capable of analysing these sentences. This is the determination of linguistic coverage, and necessitates the definition of the linguistic phenomena, independently of the linguistic theory which has been adopted to recognise these phenomena. 2. In addition to its ability to recognise and coherently describe linguistic phenomena, a grammar should be judged by its capacity to resolve ambiguity, to bypass irrelevant errors in the text being analysed, and so on. This aspect of a grammar could he regarded as its &amp;quot;robustness&amp;quot; (P.Fayes, R.Reddy 19791. 3. Examining other aspects of the problem, in the analysis that we propose we will assume a grammar which is capable of dealing with the texts which we will submit to it. Let an ATN grammar N, with n nodes, be of this type. N will be maintained constant for the following discussion. By text we intend a series of sentences, or of utterances by one of the in a dialogue. When analysing such a text, constant N has been assumed, it is likely that, in addition to the content (the argument of the indications will appear on the grammatical choices the author of the text (or the speaker) when expressing himself on that argument (how the argument is expressed). When these indications have been adequately quantified, they can be used to select strategies (as defined in (Kaplan 721) to be adopted in order to achieve greater efficiency in the analysis of the following part of the text. 4. For our experiments we have used ATNSYS (Stock 761, and an Italian with n arcs) (Cappelli et al.771. In this system, search is depth—first and the parser interacts with a heuristic mechanism which orders the arcs according to a probability evaluation. This probability evaluation is dependent on the path which led to the current node and is also a function of the statistical data accumulated during previous analyses of a &amp;quot;coherent&amp;quot; text. The mechanism can be divided into two stages. The first stage consists of the acquisition of statistical data; i.e. the frequency, for each arc exiting from a node, of the passages across that arc, in relation to the arc of arrival: for arriving arc are as many counters there are exiting arcs. Fig. 1 this way, in Fig. I arc been crossed x times coming from a and y times coming from b. In the second stage, during parsing, in state S, if coming from a and w x, arc 2 is tried first. 113 4.1 Thus, a first evaluation of the linguistic choices made is provided by the set of probability values associated to each arc. These figures can to some extent describe the &amp;quot;style&amp;quot; of any &amp;quot;coherent&amp;quot; text analysed. (For this one should also take into account the different linguistic significance of each arc. In fact a CAT or PUSH arc directly corresponds to a certain linguistic component, while a JUMP or VIRT arc occurs in relation to the technique by which the network has been built, the linguistic theory adopted, and other variables.) 4.2 The second part of the mechanism, the dynamic reordering of the arcs, coincides with a reordering of the comprehension strategies. In this way, a matrix can be associated to each node, giving the order of the strategies for each arc in arrival. For each text T, there is a set of strategies S,, ordered as described above. While the analysis of the probability values for two distinct texts T and T&apos; can global indications linguistic characteristics, if we focus on the comprehension of the sentence, it is more meaningful to give evaluations in to the sets of strategies, and , which are selected. , for some nodes, a comparison between the orders of the arcs for first from two texts, a science fiction novel (SFN, upper boxes) and a handbook of food chemistry (FC. lower boxes). The arc numbers are referred to the order in the original network. The figures which appear after the m in the heading indicate the number of parses for each sentence. An empty box indicates the same order as that shown in the previous box. .• .. P7424 S171-1 0 :2142-4 5E144.1 5FN5.• 5 •:• , .1 -39 1 5 ,52 123 132 312 •••• 312 312 i .&apos;•fl 312 312 Lots 51 miryi 513 24 51342 _</abstract>
<phone confidence="0.725001">4 52134 57111 51 234 /50501 51234 41 235 4 51 23 431 5 GV/1 4123 41 23 41 21 4214 2413 4 71 1</phone>
<affiliation confidence="0.548677">GP</affiliation>
<address confidence="0.566235">123</address>
<phone confidence="0.749296">51 213 211</phone>
<abstract confidence="0.928981914893617">123 larman 123 1 123 0J/FPN42 1 123 23 5.1 It is to be expected that this mechanism, in so far as it introduces a heuristics, will increase the efficiency of the system used for the linguistic analysis. The results of our experiments so far confirm this. This improved efficiency can be measured in three ways: locally, in terms of the computational load, non—determinism, which is in each node. In fact, by some experiments, it is possible to the computational load each type of arc. The computational is then a linear combination values and one can compare it the actual load determined by the sequence arcs attempted in that the reordering. b) in terms of an overall reduction in computing time; c) in terms of penetrance, i.e. the ratio between the number of choices which actually lead to a solution and the total number of choices made. If T a containing sentences, the average penetrance will be: for each of the sentences in T. T is analysed using the set chosen for different text, then the penetrance is, on average, no greater than withST • 114 In our experiments, for instance, the averag,s nenetrance for the first text parsed with its own strategies is Y„,(S,0.0SFN) 0.52, while parsed the strategies of the second text is ?..,(S.SFN) m 0.39. We have attempted to evaluate experimentally the relationship between the difference of the average penetrances. which we call discrepancy s„ L - L the distance between two sets of strategies. However we think we experimentation before formalizing this relationship. Returning to our science fiction novel, the discrevancY using its set of strategies and the one inferred by the food chemistry text is 0.13 9■41 6. In addition to the definition of a heuristic mechanism which is capable of improving the efficiency of natural language processing, and which can be evaluated as described above, our research aims at providing a means to characterise a text by evaluating the grammatical choices made by the author while expressing his argument. We are also attempting to take into account the expectations of the listener. In our opinion, the listener&apos;s expectations are not limited to the argument of the discourse but are also related to the way in which the argument is expressed; this is the equivalent of the choice of a sub-grammar (Kittredge 791 • We intend to verify the existence of such expectations not only in literature or when listening to long speeches, hut also in dialogue.</abstract>
<note confidence="0.966464529411765">References 1. Cappelli A., Ferrari G., Moretti L., Prodanof I., Stock O.- &apos;An Experimental ATN Parser for Italian Texts&apos; Technical Report, LLC-CNR, Pisa 1977. 2. Kaplan R.- &apos;Augmented Transition Networks as Psychological Models of Comprehension&apos; Artificial Intelligence 3 1972, Amsterdam - Oxford. 3. Hayes P., Reddy R. - &apos;An anatomy of Graceful Interaction in Spoken and written Man-Machine Communication&apos;, CMU-CS-79-144, Pittsburgh PA, 1979. 4. Kittredge R.- &apos;Textual Cohesion Within Sublanguages: Implications for Automatic Analysis and Synthesis&apos;, COLING 78, lergen, 1978. 5. Stevens A., Rumelhart D.- &apos;Errors in Reading:An Analysis Using an Augmented Network Model in Norman D., Rumelhart D. eds., Explorations in Cognition, Freeman, S.Francisco, 1975, pp. 136-155. 6. Stock o. - &apos;ATNSYS: Un sistema per l&apos;analisi grammaticale automatics delle lingua naturali&apos;, NI-R76-29, MI, Pisa, 1976. 115</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>A Cappelli</author>
<author>G Ferrari</author>
<author>L Moretti</author>
<author>I Prodanof</author>
<author>Stock O-</author>
</authors>
<title>An Experimental ATN Parser for Italian Texts&apos;</title>
<tech>Technical Report,</tech>
<location>LLC-CNR, Pisa</location>
<marker>1.</marker>
<rawString>Cappelli A., Ferrari G., Moretti L., Prodanof I., Stock O.- &apos;An Experimental ATN Parser for Italian Texts&apos; Technical Report, LLC-CNR, Pisa</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaplan R-</author>
</authors>
<title>Augmented Transition Networks as Psychological Models of Sentence Comprehension&apos;</title>
<date>1972</date>
<journal>Artificial Intelligence</journal>
<volume>3</volume>
<location>Amsterdam - New York Oxford.</location>
<marker>2.</marker>
<rawString>Kaplan R.- &apos;Augmented Transition Networks as Psychological Models of Sentence Comprehension&apos; Artificial Intelligence 3 1972, Amsterdam - New York Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hayes</author>
<author>R Reddy</author>
</authors>
<title>An anatomy of Graceful Interaction</title>
<date>1979</date>
<booktitle>in Spoken and written Man-Machine Communication&apos;,</booktitle>
<pages>79--144</pages>
<location>Pittsburgh PA,</location>
<marker>3.</marker>
<rawString>Hayes P., Reddy R. - &apos;An anatomy of Graceful Interaction in Spoken and written Man-Machine Communication&apos;, CMU-CS-79-144, Pittsburgh PA, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kittredge R-</author>
</authors>
<title>Textual Cohesion Within Sublanguages: Implications for Automatic Analysis and Synthesis&apos;, COLING 78, lergen,</title>
<date>1978</date>
<marker>4.</marker>
<rawString>Kittredge R.- &apos;Textual Cohesion Within Sublanguages: Implications for Automatic Analysis and Synthesis&apos;, COLING 78, lergen, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stevens</author>
<author>Rumelhart D-</author>
</authors>
<title>Errors in Reading:An Analysis Using an Augmented Transition Network Model of Grammar&apos;</title>
<date>1975</date>
<booktitle>Explorations in Cognition, Freeman, S.Francisco,</booktitle>
<pages>136--155</pages>
<editor>in Norman D., Rumelhart D. eds.,</editor>
<marker>5.</marker>
<rawString>Stevens A., Rumelhart D.- &apos;Errors in Reading:An Analysis Using an Augmented Transition Network Model of Grammar&apos; in Norman D., Rumelhart D. eds., Explorations in Cognition, Freeman, S.Francisco, 1975, pp. 136-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>o Stock</author>
</authors>
<title>ATNSYS: Un sistema per l&apos;analisi grammaticale automatics delle lingua naturali&apos;,</title>
<date>1976</date>
<pages>76--29</pages>
<location>MI, Pisa,</location>
<marker>6.</marker>
<rawString>Stock o. - &apos;ATNSYS: Un sistema per l&apos;analisi grammaticale automatics delle lingua naturali&apos;, NI-R76-29, MI, Pisa, 1976.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>