<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000373">
<title confidence="0.992317">
Classifying Temporal Relations with Rich Linguistic Knowledge
</title>
<author confidence="0.981867">
Jennifer D’Souza and Vincent Ng
</author>
<affiliation confidence="0.990643">
Human Language Technology Research Institute
University of Texas at Dallas
</affiliation>
<address confidence="0.917924">
Richardson, TX 75083-0688
</address>
<email confidence="0.999452">
fjld082000,vincel@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998833833333333">
We examine the task of temporal relation clas-
sification. Unlike existing approaches to this
task, we (1) classify an event-event or event-
time pair as one of the 14 temporal relations
defined in the TimeBank corpus, rather than
as one of the six relations collapsed from the
original 14; (2) employ sophisticated linguis-
tic knowledge derived from a variety of se-
mantic and discourse relations, rather than fo-
cusing on morpho-syntactic knowledge; and
(3) leverage a novel combination of rule-based
and learning-based approaches, rather than re-
lying solely on one or the other. Experiments
with the TimeBank corpus demonstrate that
our knowledge-rich, hybrid approach yields
a 15–16% relative reduction in error over a
state-of-the-art learning-based baseline sys-
tem.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997758583333333">
Recent years have seen a surge of interest in tem-
poral information extraction (IE). Temporal relation
classification, one of the most important temporal
IE tasks, involves classifying a given event-event
pair or event-time pair as one of a set of predefined
temporal relations. The creation of the TimeBank
corpus (Pustejovsky et al., 2003) and the organiza-
tion of the TempEval-1 (Verhagen et al., 2007) and
TempEval-2 (Verhagen et al., 2010) evaluation ex-
ercises have facilitated the development and evalua-
tion of temporal relation classification systems.
Our goal in this paper is to advance the state of
the art in temporal relation classification. Our work
differs from existing work with respect to both the
complexity of the task we are addressing and the ap-
proach we adopt. Regarding task complexity, rather
than focus on six temporal relations as is typically
done in previous work (see Section 2 for more infor-
mation), we address an arguably more challenging
version of the task where we consider all the 14 re-
lations originally defined in the TimeBank corpus.
Our approach to temporal relation classification
can be distinguished from existing approaches in
two respects. The first involves a large-scale ex-
pansion of the linguistic features made available
to the classification system. Recall that exist-
ing approaches have relied primarily on morpho-
syntactic features as well as a few semantic fea-
tures extracted from WordNet synsets and VerbO-
cean’s (Chklovski and Pantel, 2004) semantic rela-
tions. On the other hand, we propose not only novel
lexical and grammatical features, but also sophis-
ticated features involving semantics and discourse.
Most notably, we propose (1) semantic features en-
coding a variety of semantic relations, including
PropBank-style predicate-argument relations as well
as those extracted from the Merriam-Webster dictio-
nary, and (2) discourse features encoding automat-
ically computed Penn Discourse TreeBank (PDTB)
style (Prasad et al., 2008) discourse relations.
Second, while the vast majority of existing ap-
proaches to temporal relation classification are
learning-based, we propose a system architecture in
which we combine a learning-based approach and a
rule-based approach. Our motivation behind adopt-
ing a hybrid approach stems from two hypotheses.
First, a rule-based method could better handle the
skewed class distribution underlying the dataset for
</bodyText>
<page confidence="0.957085">
918
</page>
<note confidence="0.4734685">
Proceedings of NAACL-HLT 2013, pages 918–927,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999941046511628">
our 14-class classification problem. Second, better
decision rules could be formed by leveraging hu-
man insights to combine the available linguistic fea-
tures than by using fully automatic machine learn-
ing methods. Note that while rule-based approaches
have been shown to underperform learning-based
approaches on this task (Mani et al., 2006), to our
knowledge they have not been used in combination
with learning-based approaches. Moreover, while
the rules employed in previous work are created
based on intuition (e.g., Mani et al. (2006), Pus¸cas¸u
(2007)), our rules are created in a data-driven man-
ner via a manual inspection of the annotated tempo-
ral relations in the TimeBank corpus.
Experiments on the TimeBank corpus demon-
strate the effectiveness of our knowledge-rich, hy-
brid approach to temporal relation classification: it
yields a 15–16% relative reduction in error over a
state-of-the-art learning-based baseline system.
To our knowledge, we are the first to (1) report re-
sults for the 14-class temporal relation classification
task on the TimeBank (v1.2) corpus; (2) success-
fully employ automatically computed PDTB-style
discourse relations to improve performance on this
task; and (3) show that a hybrid approach to this
task can yield better results than either a rule-based
or learning-based approach. Note that hybrid ap-
proaches in this spirit were popular in the natural
language processing community back in the mid-90s
(Klavans and Resnik, 1994). We believe that they
are among the most competitive approaches to lan-
guage processing tasks that require complex reason-
ing and should be given more attention in the com-
munity. We release the complete set of rules that we
mined from the TimeBank corpus and used in our
rule-based approach in hopes that our insights into
how features can be combined as decision rules can
benefit researchers interested in this task.
The rest of the paper is organized as follows. Sec-
tion 2 provides an overview of the TimeBank cor-
pus. Sections 3 and 4 describe the baseline system
and our approach, respectively. We present evalua-
tion results in Section 5 and conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.990679" genericHeader="introduction">
2 Corpus
</sectionHeader>
<bodyText confidence="0.993625846153846">
For evaluation, we use the TimeBank (v1.2) cor-
pus, which consists of 183 newswire articles. In
each article, the events, times, and their temporal re-
lations are marked up. An event, which can be a
tensed verb, adjective, or nominal, contains various
attributes, including the class of event, tense, aspect,
polarity, and modality. A time expression has a class
attribute, which specifies whether it is a date, time,
duration, or set, and its value is normalized based on
TIMEX3. A temporal relation can be an order rela-
tion, which orders two events (as in sentence (1)), or
an anchor relation, which anchors an event to a time
expression (as in sentence (2)).
</bodyText>
<listItem confidence="0.998544666666667">
(1) A steep rise in world oil prices fol-
lowed the Kuwait invasion.
(2) We are there to stay for a long period.
</listItem>
<bodyText confidence="0.999786696969697">
Each temporal relation has a type. For example,
the relation defined on rise and invasion in (1) has
type After, whereas the relation defined on stay and
period in (2) has type During. Note that a temporal
relation is defined on an ordered pair. For exam-
ple, in (1), the pair (rise, invasion) has type After,
whereas the pair (invasion, rise) has type Before).
14 relation types are defined and used to annotate
the temporal relations in the TimeBank corpus. Ta-
ble 1 provides a brief description of these relation
types and the relevant statistics.
In our experiments, we assume that our tempo-
ral relation classification system is given an event-
event or event-time pair that is known to belong to
one of the 14 relation types defined in TimeBank and
aims to determine its relation type. Following pre-
vious evaluations of the temporal relation classifica-
tion task on the TimeBank corpus (e.g., Mani et al.
(2006), Chambers et al. (2007)) and in TempEval-
1/2, we assume as input gold events and time ex-
pressions.
Unlike Mani et al. (2006) and Chambers et al.
(2007), who focus on six relation types (Simul-
taneous, Before, IBefore, Begins, Ends, and In-
cludes), we report results on 14 relation types. Note
that the aforementioned six relation types are cho-
sen by (1) discarding During, During Inv, and
Identity, and (2) combining the two relation types
in each of the five pairs, namely (Before, After),
(IBefore, IAfter), (Includes, Is Included), (Be-
gins, Begun By), and (Ends, Ended By), into a sin-
gle type because they are inverses of each other. In
other words, if a relation instance (e1, e2) is anno-
</bodyText>
<page confidence="0.997953">
919
</page>
<table confidence="0.996976133333333">
Id Relation Description Total % E-E E-T
1 Simultaneous e1 and e2 happen at the same time or are temporally distinguishable 660 (13.3) 599 61
2 Identity e1 and e2 are coreferent 702 (14.1) 696 6
3 Before e1 happens before e2 in time 689 (13.9) 639 50
4 After e1 happens after e2 in time 744 (15) 681 63
5 IBefore e1 happens immediately before e2 in time 39 (0.8) 38 1
6 IAfter e1 happens immediately after e2 in time 28 (0.6) 25 3
7 Includes As in Ed arrived in Seoul last Sunday (e1=last Sunday; e2=arrived) 758 (15.3) 318 440
8 Is Included As in Ed arrived in Seoul last Sunday (e1=arrived; e2=last Sunday) 762 (15.3) 201 561
9 During e1 persists throughout duration e2 102 (2.1) 19 83
10 During Inv e2 persists throughout duration e1 124 (2.5) 44 80
11 Begins e1 marks the beginning of e2 66 (1.3) 44 22
12 Begun By e2 marks the beginning of e1 61 (1.2) 32 29
13 Ends e1 marks the end of e2 66 (1.3) 21 45
14 Ended By e2 marks the end of e1 170 (3.42) 93 77
</table>
<tableCaption confidence="0.92796575">
Table 1: The 14 temporal relations and their frequency of occurrences in TimeBank (v1.2). Each relation is defined
on an ordered event-event or event-time pair (e1,e2). The “Total” and “%” columns show the number and percentage
of instances annotated with the corresponding relation in the corpus, respectively, and the “E-E” and “E-T” columns
show the breakdown by the number of event-event pairs and event-time pairs.
</tableCaption>
<bodyText confidence="0.999346125">
tated as After, it is replaced with the instance (e2,
e1) with class Before, and subsequently a relation
classifier is presented with (e2, e1) but not (e1, e2).
On the other hand, our 14-class task is arguably
more challenging since our system has to further dis-
tinguish a relation type from its inverse given an in-
stance in which the two elements are in arbitrary or-
der.
</bodyText>
<sectionHeader confidence="0.987855" genericHeader="method">
3 Baseline Temporal Relation Classifier
</sectionHeader>
<bodyText confidence="0.989298173913044">
Since the currently best-performing systems for
temporal relation classification are learning-based,
we will employ a learning-based system as our base-
line. Below we describe how we train this baseline.
Without loss of generality, assume that (e1,e2) is
an event-event/event-time pair such that (1) e1 pre-
cedes e2 in the associated text and (2) (e1,e2) be-
longs to one of the 14 TimeBank temporal rela-
tion types. We create one training instance for each
event-event/event-time pair in a training document
that satisfies the two conditions above, labeling it
with the relation type that exists between e1 and e2.
To build a strong baseline, we represent each
instance using 68 linguistic features modeled af-
ter the top-performing temporal relation classifica-
tion systems on TimeBank (e.g., Mani et al. (2006),
Chambers et al. (2007)) and in the TempEval shared
tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et
al. (2010), Llorens et al. (2010), Mirroshandel and
Ghassem-Sani (2011)).1 These features can be di-
vided into six categories, as described below.
Lexical (5). The strings of e1 and e2, the head
words of e1 and e2, and a binary feature indicating
whether e1 and e2 have the same string.
Grammatical (33). The POS tags of the head
words of e1 and e2, the POS tags of the five to-
kens preceding and following e1 and e2, the POS
bigram formed from the head word of e1 and its pre-
ceding token, the POS bigram formed from the head
word of e2 and its preceding token, the POS tag pair
formed from the head words of e1 and e2, the prepo-
sitional lexeme of the prepositional phrase (PP) if e1
is headed by a PP (Chambers et al., 2007), the prepo-
sitional lexeme of the PP if e2 is headed by a PP, the
prepositional lexeme of the PP if e1 is governed by
a PP (Mirroshandel and Ghassem-Sani, 2011), the
prepositional lexeme of the PP if e2 is governed by
a PP, the POS of the head of the verb phrase (VP) if
e1 is governed by a VP, the POS of the head of the
VP if e2 is governed by a VP, whether e1 syntacti-
cally dominates e2 (Chambers et al., 2007), and the
shortest path from e1 to e2 in the associated syntac-
tic parse tree. We obtain parse trees and POS tags
using the Stanford CoreNLP tool.2
1Note, however, that these features were designed for the
arguably simpler 6-class temporal relation classification tasks.
</bodyText>
<footnote confidence="0.9598975">
2http://nlp.stanford.edu/software/
corenlp.shtml
</footnote>
<page confidence="0.993315">
920
</page>
<bodyText confidence="0.999917678571428">
Entity attributes (13). The tense, aspect, modal-
ity, polarity, and event type of e1 and e2 if they are
events (if one of them is a time expression, then the
class attribute will be set to its class and the rest of
them will have the value NULL), pairwise features
formed by pairing up the tense values, the aspect
values, and the class values of e1 and e2.
Semantic (7). The subordinating temporal role to-
ken of e1 if it appears within a temporal semantic
role argument (Llorens et al., 2010), the subordinat-
ing temporal role token of e2 if it appears within a
temporal semantic role argument, the first WordNet
synset to which e1 belongs, the first WordNet synset
to which e2 belongs, and whether e1 and e2 are in the
happens-before, happens-after, and similar relation
according to VerbOcean.3
Distance (1). Are e1 and e2 in the same sentence?
DCT related (3). The temporal relation type be-
tween e1 and the document creation time (DCT) [its
value can be one of the 14 relation types, or NULL
if no relation exists], the temporal relation type be-
tween e2 and the DCT, and whether e1 and e2 have
different relation types with the DCT.
After creating the training instances, we train
a 14-class classifier on them using SVM multiclass
(Tsochantaridis et al., 2004).4 We then use it to
make predictions on the test instances, which are
generated in the same way as the training instances.
</bodyText>
<sectionHeader confidence="0.987584" genericHeader="method">
4 Our Hybrid Approach
</sectionHeader>
<bodyText confidence="0.990173882352941">
In this section, we describe our hybrid learning-
based and rule-based approach to temporal relation
classification. Section 4.1 describes our novel fea-
tures, which will be used to augment the baseline
feature set (see Section 3) to train a temporal rela-
tion classifier. Section 4.2 outlines our manual rule
creation process. Section 4.3 discusses how we com-
bine our hand-crafted rules and the learned classifier
to make predictions in our hybrid approach.
3happens-after is not a relation in VerbOcean: we create this
relation simply by inverting the happens-before relation.
4For all the experiments involving SVMmulticlass, we set C,
the regularization parameter, to 10,000, since preliminary ex-
periments indicate that preferring generalization to overfitting
(by setting C to a small value) tends to yield poorer classifica-
tion performance. The remaining learning parameters are set to
their default values.
</bodyText>
<subsectionHeader confidence="0.988312">
4.1 Six Types of New Features
4.1.1 Pairwise Features
</subsectionHeader>
<bodyText confidence="0.999969235294118">
Recall that some of the features in the baseline fea-
ture set are computed based on either e1 or e2 but
not both. Since our task is to predict the relation be-
tween them, we hypothesize that pairwise features,
which are computed based on both elements, could
better capture the relationship between them.
Specifically, we introduce pairwise versions of the
head word feature and the two prepositional lexeme-
based features in the baseline. In addition, we create
two quadruple-wise features, one by pairing up the
tense and class attribute values of e1 with those of
e2, and the other by pairing up their tense and as-
pect values. Next, we create two trace features, one
based on prepositions and the other on verbs, since
prepositions and verb tenses have been shown to
play an important role in temporal relation classifi-
cation The preposition trace feature is computed by
</bodyText>
<listItem confidence="0.950073833333333">
(1) collecting the list of prepositions along the path
from e1/e2 to the root of its syntactic parse trees, and
(2) concatenating the resulting lists computed from
e1 and e2. The verb trace feature is computed in a
similar manner, except that we collect the POS tags
of the verbs appearing in the corresponding paths.
</listItem>
<subsubsectionHeader confidence="0.589161">
4.1.2 Dependency Relations
</subsubsectionHeader>
<bodyText confidence="0.9996725">
We introduce features computed based on de-
pendency parse trees obtained via the Stanford
CoreNLP tool, motivated by our observation that
some dependency relation types are more closely
associated with certain temporal relation types than
with others. Let us illustrate with an example:
</bodyText>
<listItem confidence="0.9847805">
(3) Ed changed his plans as the mood took
him.
</listItem>
<bodyText confidence="0.999961833333333">
In (3), there is a adverbial clause modifier depen-
dency between changed and took, because took ap-
pears in an adverbial clause (headed by as) modify-
ing changed. Intuitively, if the two events partici-
pate in this type of dependency relation and the ad-
verbial clause is headed by as and there is a tempo-
ral relation between them, then it is likely that this
temporal relation is Simultaneous. While the tem-
poral relation type is dependent on the connective
heading the adverbial clause, in general an adverbial
clause modifier dependency between two events im-
plies that their temporal relation is likely to be Si-
</bodyText>
<page confidence="0.990139">
921
</page>
<bodyText confidence="0.9963335">
multaneous, Before, or After.
Given the potential usefulness of dependency re-
lations for temporal relation classification, we cre-
ate dependency-based features as follows. For each
of the 25 dependency relation types produced by
the Stanford parser, we create four binary features:
whether e1/e2 is the governing entity in the relation,
and whether e1/e2 is the dependent in the relation.
</bodyText>
<subsectionHeader confidence="0.671032">
4.1.3 Webster Relations
</subsectionHeader>
<bodyText confidence="0.991967413793103">
Some events are not connected by a dependency re-
lation but by a lexical relation. We hypothesize that
some of these lexical relations could be useful for
temporal relation classification. Consider the fol-
lowing example.
(4) The phony war has finished and the real
referendum campaign has begun.
In this sentence, the two events, finished and be-
gun, are connected by an antonym relation. Statisti-
cally speaking, if (1) two events are in two clauses
connected by a coordinating conjunction (e.g., and),
(2) one is an antonym of the other, and (3) there is
a temporal relation between them, then the temporal
relation is likely to be Simultaneous.
Given the potential usefulness of lexical rela-
tions for temporal relation classification, we cre-
ate features based on four types of lexical re-
lations present in Webster’s online thesaurus5,
namely synonyms, related-words, near-antonyms,
and antonyms. Specifically, for each event e appear-
ing in TimeBank, we first use the head word of e to
retrieve four lists, which are the lists corresponding
to the synonyms, related words, near-antonyms, and
antonyms of e. Then, given a training/test instance
involving e1 and e2, we create eight binary features:
whether e1 appears in e2’s list of synonyms/related
words/near-antonyms/antonyms, and whether e2 ap-
pears in e1’s list of synonyms/related words/near-
antonyms/antonyms.
</bodyText>
<subsectionHeader confidence="0.499441">
4.1.4 WordNet Relations
</subsectionHeader>
<bodyText confidence="0.9981968">
Previous uses of WordNet for temporal relation clas-
sification are limited to synsets (e.g., Llorens et al.
(2010)). We hypothesize that other WordNet lexical
relations could also be useful for the task. Specif-
ically, we employ four types of WordNet relations,
</bodyText>
<footnote confidence="0.870675">
5http://www.merriam-webster.com/
</footnote>
<bodyText confidence="0.999902">
namely hypernyms, hyponyms, troponyms, and sim-
ilar, to create eight binary features for temporal rela-
tion classification. These eight features are created
from the four WordNet relations in the same way as
the eight features were created from the four Web-
ster relations in the previous subsection.
</bodyText>
<subsectionHeader confidence="0.437338">
4.1.5 Predicate-Argument Relations
</subsectionHeader>
<bodyText confidence="0.997014142857143">
So far we have exploited lexical and dependency
relations for temporal relation classification. We
hypothesize that semantic relations, in particular
predicate-argument relations, could be useful for the
task. Consider the following example.
(5) “What sector is stepping forward to
pick up the slack?” he asked.
Using SENNA (Collobert et al., 2011), a PropBank-
style semantic role labeler, we know that forward is
in the directional argument of the predicate stepping.
This enables us to infer that an Includes relation ex-
ists between stepping and forward since intuitively
an action includes a direction.
As another example, consider another PropBank-
style predicate-argument relation, cause. Assuming
that e2 is in e1’s cause argument, we can infer that
e2 occurs Before e1 since intuitively the cause of an
action precedes the action.
Consequently, we create features for tempo-
ral relation classification based on four types
of PropBank-style predicate-argument relations,
namely directional, manner, temporal, and cause.
Specifically, using SENNA’s output, we create four
binary features that encode whether argument e2 is
related to predicate e1 through the four types of rela-
tions, and we create another four binary features that
encode whether argument e1 is related to predicate
e2 through the four types of relations.
</bodyText>
<subsectionHeader confidence="0.682637">
4.1.6 Discourse Relations
</subsectionHeader>
<bodyText confidence="0.9999496">
Rhetorical relations such as causation, elaboration
and enablement could aid in tracking the temporal
progression of the discourse (Hitzeman et al., 1995).
Hence, unlike syntactic dependencies and predicate-
argument relations through which we can identify
intra-sentential temporal relations, discourse rela-
tions can potentially be exploited to discover both
inter-sentential and intra-sentential temporal rela-
tions. However, no recent work has attempted to
use discourse relations for temporal relation clas-
</bodyText>
<page confidence="0.975777">
922
</page>
<listItem confidence="0.9759145">
(6) { Arg1 Hewlett-Packard Co. said it raised its stake in Octel Communications Corp. to 8.5% of the
common shares outstanding. Arg1} { Arg2 RESTATEMENT In a Securities and Exchange Commis-
sion filing, Hewlett-Packard said it now holds 1,384,119 Octel common shares Arg2}.
(7) { Arg1 Reports said that Saudi Arabia told U.S. oil companies of a 15–20 percent cutback in its oil
supply in September. Arg1} { Conn SYNCHRONY Meanwhile Conn} { Arg2 Egypt’s Middle East
Agency said Thursday that Saddam was the target of an assassination attempt. Arg2}
</listItem>
<tableCaption confidence="0.995919">
Table 2: Examples illustrating the usefulness of discourse relations for temporal relation classification.
</tableCaption>
<bodyText confidence="0.9998965">
sification. In this subsection, we examine whether
we can improve a temporal relation identifier via
explicit and implicit PDTB-style discourse relations
automatically extracted by Lin et al.’s (2013) end-to-
end discourse parser.
Let us first review PDTB-style discourse rela-
tions. Each relation is represented by a triple (Arg],
sense, Arg2), where Arg] and Arg2 are the two ar-
guments of the relation and sense is the sense/type
of the relation. A discourse relation can be explicit
or implicit. An explicit relation is triggered by a dis-
course connective. On the other hand, an implicit
relation is not triggered by a discourse connective,
and may exist only between two consecutive sen-
tences. Generally, implicit relations are much harder
to identify than their explicit counterparts.
Next, to motivate why discourse relations can be
useful for temporal relation classification, we use
two examples (see Table 2), one involving an im-
plicit relation (Example (6)) and the other an explicit
relation (Example (7)). For convenience, both sen-
tences are also annotated using Lin et al.’s (2013)
discourse parser, which marks up the two arguments
with the Arg1 and Arg2 tags and outputs the rela-
tion sense next to the beginning of Arg2.
In (6), we aim to determine the order relation be-
tween the reporting event said and the occurrence
event filing. The parser determines that a RESTATE-
MENT implicit relation exists between the two sen-
tences. Intuitively, if no asynchronous relations can
be found among the events in two discourse units
connected by the RESTATEMENT relation, then the
temporal relation between two temporally linked
events within these units is likely to be either Iden-
tity or Simultaneous. In this case, we can rule out
Identity: since said and filing belong to different
event classes, they are not coreferent.
In (7), we aim to determine the anchor relation
between the reporting event said and the date Thurs-
day. The parser determines that a SYNCHRONY
explicit relation triggered by Meanwhile exists be-
tween the two sentences. Intuitively, if a temporally
related reporting event and date occur within differ-
ent discourse units connected by the SYNCHRONY
relation, then it is likely that the event Is Included
in the date. Note that without this discourse relation,
it could be difficult for a machine to confidently as-
sociate a reporting event with a date occurring in a
different discourse segment.
Given the potential usefulness of discourse rela-
tions for temporal relation classification, we create
four features based on discourse relations. In the
first feature, if e1 is in Arg1, e2 is in Arg2, and Arg1
and Arg2 possess an explicit relation with sense s,
then its feature value is s; otherwise its value is
NULL. In the second feature, if e2 is in Arg1, e1 is in
Arg2, and Arg1 and Arg2 possess a explicit relation
with sense s, then its feature value is s; otherwise
its value is NULL. The third and fourth features are
computed in the same way as the first two features,
except that they are computed over implicit rather
than explicit relations.
</bodyText>
<subsectionHeader confidence="0.992634">
4.2 Manual Rule Creation
</subsectionHeader>
<bodyText confidence="0.999926916666667">
As noted before, we adopt a hybrid learning-based
and rule-based approach to temporal relation clas-
sification. Hence, in addition to training a tempo-
ral relation classifier, we also manually design a set
of rules in which each rule returns a temporal rela-
tion type for a given test instance. We hypothesize
that a rule-based approach can complement a purely
learning-based approach, since a human could com-
bine the available linguistic features into rules using
commonsense knowledge that may not be accessible
to a learning algorithm.
The design of the rules is partly based on intu-
</bodyText>
<page confidence="0.997404">
923
</page>
<bodyText confidence="0.999965222222222">
ition and partly data-driven: we first use our intu-
ition to come up with a rule and then manually re-
fine it based on the observations we made on the
TimeBank data. For this purpose, we partition the
TimeBank documents into five folds of roughly the
same size, reserving three folds for developing our
rules and using the remaining two folds for evaluat-
ing final system performance. We order these rules
in decreasing order of accuracy, where the accuracy
of a rule is defined as the number of times the rule
yields the correct temporal relation type divided by
the number of times it is applied, as measured on the
three development folds. A new instance is classi-
fied using the first applicable rule in the ruleset.
Some of these rules were shown in the previ-
ous subsection when we motivated each feature type
with examples. The complete set of rules can be ac-
cessed via our website.6
</bodyText>
<subsectionHeader confidence="0.999845">
4.3 Combining Rules and Machine Learning
</subsectionHeader>
<bodyText confidence="0.9999934">
We investigate three ways to combine the hand-
crafted rules and the machine-learned classifier.
In the first method, we employ all of the rules as
additional features for training the classifier. The
value of each such feature is the temporal relation
type predicted by the corresponding rule.
The second method can be viewed as an extension
of the first one. Given a test instance, we first apply
to it the ruleset composed only of rules that are at
least 80% accurate. If none of the rules is applicable,
we classify it using the classifier employed in the
first method.7
The third method is essentially the same as the
second, except we do not employ the rules as fea-
tures when training the classifier.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.995276">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99504125">
Dataset. As mentioned before, we partition the
183 documents in the TimeBank (v1.2) corpus into
five folds of roughly the same size, reserving three
folds (say Folds 1–3) for manual rule development
</bodyText>
<footnote confidence="0.9893468">
6http://www.hlt.utdallas.edu/˜jld082000/
temporal-relations/
7Although this classifier is applied to only those test in-
stances that the rules cannot handle, we did not retrain it on
only those training instances that the rules cannot handle.
</footnote>
<bodyText confidence="0.999959944444444">
and using the remaining two folds (say Folds 4–5)
for testing. We perform two-fold cross-validation
experiments using the two test folds. In the first fold
experiment, we train a temporal relation classifier on
Folds 1–4 and test on Fold 5; and in the second fold
experiment, we train the classifier on all but Fold 4
and test on Fold 4. The results reported in the rest of
the paper are averaged over the two test folds.
Evaluation metrics. We employ accuracy (Acc)
and macro F-score (F,a). Accuracy is the per-
centage of correctly classified test instances, and is
the standard evaluation metric for temporal relation
classification. Since each test instance belongs to
one of the 14 temporal relation types, accuracy is the
same as micro F-score. On the other hand, macro F-
score is rarely used to evaluate this task. We chose it
because it could provide insights into how well our
approach performs on the minority classes.
</bodyText>
<subsectionHeader confidence="0.955703">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999010535714286">
Table 3 shows the two-fold cross-validation results
for our 14-class temporal relation classification task.
The six columns of the table correspond to six dif-
ferent system architectures. The “Feature” column
corresponds to a purely learning-based architecture
where the results are obtained simply by training a
temporal relation classifier using the available fea-
tures. The next two columns correspond to two
purely rule-based architectures, differing by whether
all rules are used regardless of their accuracy or
whether only high-accuracy rules (i.e., those that are
at least 80% accurate) are used. The rightmost three
columns correspond to the three ways of combining
rules and machine learning described in Section 4.3.
On the other hand, the rows of the table differ in
terms of what features are available to a system. In
row 1, only the baseline features are available. In the
subsequent rows, the six types of features discussed
in Section 4 are added incrementally to the baseline
feature set. This means that the last row corresponds
to the case where all feature types are used.
A point merits clarification. It may not be imme-
diately clear how to interpret the results under, for
instance, the “All Rules” column. In other words,
it may not be clear what it means to add the six
types of features incrementally to a rule-based sys-
tem. Recall that one of our goals is to compare
a purely learning-based system with a purely rule-
</bodyText>
<page confidence="0.993456">
924
</page>
<table confidence="0.9998238">
Feature Type Features All Rules All Rules with Features + Rules + Rules + Features +
Acc Fma Acc Fma accuracy &gt; 0.8 Rules as Features Features Rules as Features
Acc Fma Acc Fma Acc Fma Acc Fma
Baseline 45.3 24.9 – – – – – – – – – –
+ Pairwise 46.5 25.8 37.6 26.5 5.1 13.9 46.7 26.5 48.0 31.9 48.2 32.1
+ Dependencies 47.0 25.9 39.0 27.8 6.9 15.7 47.2 26.7 49.2 32.3 49.2 32.6
+ WordNet 46.9 26.0 43.5 30.4 6.9 15.7 47.5 26.8 49.2 32.3 49.5 32.8
+ Webster 46.9 25.8 43.3 29.9 6.9 15.7 48.1 26.8 49.2 32.0 50.1 33.1
+ PropBank 47.2 26.0 44.3 30.5 8.1 16.6 48.0 26.8 49.5 32.2 50.0 33.0
+ Discourse 48.1 26.6 47.5 35.1 12.8 23.3 48.9 27.5 53.0 36.0 53.4 36.6
</table>
<figure confidence="0.828259833333333">
1
2
3
4
5
6
</figure>
<page confidence="0.706091">
7
</page>
<tableCaption confidence="0.998904">
Table 3: Two-fold cross-validation accuracies and macro F-scores as features are added incrementally to the baseline.
</tableCaption>
<bodyText confidence="0.999608114285714">
based system, since we hypothesized that humans
may be better at combining the available features
to form rules than a learning algorithm would be.
To facilitate this comparison, all and only those fea-
tures that are available to a learning-based system in
a given row can be used in hand-crafting the rules
of the rule-based system in the same row. The other
columns involving the use of rules can be interpreted
in a similar manner.
The highest accuracy and macro F-score are
achieved when all types of features are used in
combination with the “Rules + Features + Rules
as Features” architecture. Specifically, this system
achieves an accuracy of 53.4% and a macro F-score
of 36.6% on the 2000-instance test set. This trans-
lates to a relative error reduction of 15–16% in com-
parison to the baseline result shown in row 1. A
closer examination of these results reveals that the
hand-crafted rules used by the system correctly clas-
sify 239 of the 305 test instances to which they are
applicable. In other words, the rules achieve a preci-
sion of 78.3% and a recall of 15.3% on the test data.
Our results suggest that the rules are effective at
improving performance when they are used to make
classification decisions prior to the application of
the classifier, as the performance of the “Rules +
Features + Rules as Features” architecture is sig-
nificantly better than that of the “Features + Rules
as Features” architecture.8 On the other hand, the
“Rules + Features + Rules as Features” architecture
does not benefit from the use of rules as features,
as its performance is statistically indistinguishable
from that of the “Rules + Features” architecture.
Nevertheless, both “Rules + Features + Rules as
Features” and “Rules + Features” are significantly
</bodyText>
<footnote confidence="0.8509505">
8Unless otherwise stated, all statistical significance tests are
paired t-tests, with p &lt; 0.05.
</footnote>
<bodyText confidence="0.999964027027027">
better than the remaining four architectures. This
suggests that the best-performing approach for our
14-class temporal relation classification task is the
hybrid approach where high-accuracy rules are first
applied and then the learned classifier is used to clas-
sify those cases that cannot be handled by the rules.
Among the remaining four architectures, “All
Rules with accuracy &gt; 0.8”, the version of the rule-
based architecture where only the high-accuracy
rules are used, performs significantly worse than the
others, presumably because the coverage of the rule-
set is low. The results of the two feature-based archi-
tectures, “Features” and “Features + Rules as Fea-
tures”, are statistically indistinguishable from each
other at the p &lt; 0.01 level. At the p &lt; 0.05
level, however, their results are mixed: “Features +
Rules as Features” is better than “Features” accord-
ing to accuracy, whereas the reverse is true accord-
ing to macro F-score. Combining these results with
those we discussed above concerning the “Rules +
Features” and “Rules + Features + Rules as Fea-
tures” architectures, we can conclude that the fea-
tures encoding the hand-crafted rules are (mildly)
useful only when used in combination with a weak-
performing system. Finally, comparing the “Fea-
tures” architecture and the “All Rules” architecture,
we also see mixed results: “Features” is better than
“All Rules” according to accuracy, whereas the re-
verse is true according to macro F-score. These
results confirm our earlier hypothesis that the rule-
based system is indeed better at identifying instances
of minority relation types.
Next, to determine whether the addition of a par-
ticular type of features to the feature set is use-
ful, we apply the paired t-test to each pair of ad-
jacent rows in Table 3. We found that adding
pairwise features, dependency relations, and most
</bodyText>
<page confidence="0.998167">
925
</page>
<tableCaption confidence="0.984494">
Table 4: Event-event and event-time classification results
of our best system (Rules + Features+ Rules as features).
</tableCaption>
<bodyText confidence="0.999931484848485">
importantly, discourse relations significantly im-
proves both accuracy and macro F-score (p &lt; 0.05).
Adding the Webster relations improves accuracy at a
slightly lower significance level (p &lt; 0.07) but does
not significantly improve macro F-score. Some-
what counter-intuitively, the WordNet and predicate-
argument relations are not useful. We speculate that
their failure to improve performance could be at-
tributed to the fact that these relations are extracted
by imperfect analyzers. Additional experiments in-
volving the use of gold-standard quality features are
needed to precisely determine the reason.
Recall that the results shown in Table 3 were com-
puted over both the order (i.e., event-event) and an-
chor (i.e., event-time) temporal relations. To gain
additional insights into our best-performing system,
we show in Table 4 its performance on classify-
ing event-event and event-time relations separately.
In comparison to the baseline, both accuracy and
macro F-score increase significantly when our sys-
tem is used in combination with all feature types.
In particular, our system yields a relative error re-
duction of 16–25% for event-event classification and
6–9% for event-time classification over the base-
line. The pairwise features, as well as dependency
relations and discourse relations, contribute signif-
icantly to the classification of both event-event and
event-time relations.
Finally, we show in Table 5 the per-class results
of the baseline system and our best-performing sys-
tem. As we can see, our system performs signifi-
cantly better than the baseline on all relation types,
owing to a simultaneous rise in recall and precision.
</bodyText>
<sectionHeader confidence="0.999709" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999801">
We have investigated a knowledge-rich, hybrid ap-
proach to the 14-class temporal relation classifica-
</bodyText>
<table confidence="0.9997744375">
Relation R Baseline F Our System
P R P F
Simultaneous 22.5 30.5 25.9 29.5 39.5 33.8
Identity 56.5 51.5 53.9 59.0 57.5 58.2
Before 39.5 38.5 39.0 50.5 50.5 50.5
After 50.5 35.0 41.4 59.5 44.5 50.9
IBefore 0.0 0.0 0.0 32.5 85.5 47.1
IAfter 0.0 0.0 0.0 5.5 50.0 9.9
Includes 54.5 50.5 52.4 61.0 55.5 58.1
Is Included 71.5 64.5 67.8 74.5 65.0 69.4
During 11.0 31.0 16.2 19.0 34.5 24.5
During Inv 14.0 20.0 16.5 19.5 40.5 26.3
Begins 4.5 10.0 6.2 37.0 43.5 40.0
Begun By 6.5 14.5 9.0 35.0 44.0 39.0
Ends 6.5 10.0 7.9 23.5 70.0 35.2
Ended By 9.0 10.0 9.5 29.0 26.5 27.7
</table>
<tableCaption confidence="0.990112">
Table 5: Per-class results of the baseline system and our
best system (Rules + Features+ Rules as features).
</tableCaption>
<bodyText confidence="0.999916090909091">
tion task. Results on the TimeBank corpus show
that our approach achieves a relative error reduction
of 15–16% over a learning-based baseline that em-
ploys a state-of-the-art feature set. Our results sug-
gest that (1) the pairwise features, dependency rela-
tions, and discourse relations are useful for temporal
relation classification; and (2) hand-crafted rules can
better handle the skewed class distribution underly-
ing our dataset via improving minority class predic-
tion. To our knowledge, we are the first to (1) re-
port results for the 14-class temporal relation clas-
sification task on TimeBank; (2) successfully em-
ploy PDTB-style discourse relations to improve this
task; and (3) show that a hybrid approach to this task
can yield better results than either a rule-based or
learning-based approach. To stimulate research on
this task, we make our complete set of hand-crafted
rules available to other researchers. We believe that
hybrid rule-based and learning-based approaches are
promising approaches to language processing tasks
that require complex reasoning and hope that they
will be given more attention in the community.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999704714285714">
We thank the three anonymous reviewers for their
detailed and insightful comments on an earlier draft
of the paper. This work was supported in part by
NSF Grants IIS-1147644 and IIS-1219142. Any
opinions, findings, or conclusions expressed in this
paper are those of the authors and do not necessarily
reflect the views or official policies of NSF.
</bodyText>
<table confidence="0.997894777777778">
Feature Type Event-Event Event-Time
Acc F&amp;quot; Acc F&amp;quot;
Baseline 36.7 15.6 63.3 19.2
+ Pairwise 40.4 25.4 64.7 24.2
+ Dependencies 42.4 28.4 64.9 25.4
+ WordNet 42.6 28.1 64.7 25.3
+ Webster 43.0 29.7 64.6 25.3
+ PropBank 43.2 28.6 64.3 25.1
+ Discourse 46.8 36.3 65.4 26.4
</table>
<figure confidence="0.933075142857143">
1
2
3
4
5
6
7
</figure>
<page confidence="0.994573">
926
</page>
<sectionHeader confidence="0.998067" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999863481927711">
Nathanael Chambers, Shan Wang, and Dan Jurafsky.
2007. Classifying temporal relations between events.
In Proceedings ofthe 45th Annual Meeting ofthe Asso-
ciation for Computational Linguistics Companion Vol-
ume: Proceedings of the Demo and Poster Sessions,
pages 173–176.
Timothy Chklovski and Patrick Pantel. 2004. Verbo-
cean: Mining the web for fine-grained semantic verb
relations. In Proceedings of the 2004 Conference on
Empirical Methods in Natural Language Processing,
pages 33–40.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.
Eun Young Ha, Alok Baikadi, Carlyle Licata, and James
Lester. 2010. NCSU: Modeling temporal relations
with markov logic and lexical ontology. In Proceed-
ings of the 5th International Workshop on Semantic
Evaluation, pages 341–344.
Janet Hitzeman, Marc Moens, and Claire Grover. 1995.
Algorithms for analysing the temporal structure of dis-
course. In Proceedings of the 7th Conference of the
European Chapter of the Association for Computa-
tional Linguistics, pages 253–260.
Judith Klavans and Philip Resnik, editors. 1994. The
Balancing Act: Combining Symbolic and Statistical
Approaches to Language. Association for Computa-
tional Linguistics.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2013.
A PDTB-styled end-to-end discourse parser. Natural
Language Engineering (to appear).
Hector Llorens, Estela Saquete, and Borja Navarro.
2010. TIPSem (English and Spanish): Evaluating
CRFs and semantic roles in TempEval-2. In Proceed-
ings of the 5th International Workshop on Semantic
Evaluation, pages 284–291.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and 44th Annual Meeting of the Association for Com-
putational Linguistics, pages 753–760.
Congmin Min, Munirathnam Srikanth, and Abraham
Fowler. 2007. LCC-TE: A hybrid approach to tem-
poral relation identification in news text. In Proceed-
ings of the Fourth International Workshop on Semantic
Evaluations (SemEval-2007), pages 219–222.
Seyed Abolghasem Mirroshandel and Gholamreza
Ghassem-Sani. 2011. Temporal relation extraction
using expectation maximization. In Proceedings of the
International Conference Recent Advances in Natural
Language Processing 2011, pages 218–225.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0. In
Proceedings of the 6th International Conference on
Language Resources and Evaluation.
Georgiana Pus¸cas¸u. 2007. WVALI: Temporal relation
identification by syntactico-semantic analysis. In Pro-
ceedings of the Fourth International Workshop on Se-
mantic Evaluations (SemEval-2007), pages 484–487.
James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew
See, David Day, Lisa Ferro, Robert Gaizauskas, Mar-
cia Lazo, Andrea Setzer, and Beth Sundheim. 2003.
The TimeBank corpus. In Corpus Linguistics, pages
647–656.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings ofthe 21st International
Conference on Machine Learning, pages 104–112.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 Task 15: TempEval tempo-
ral relation identification. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), pages 75–80.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 Task 13:
TempEval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57–62.
</reference>
<page confidence="0.997114">
927
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.662307">
<title confidence="0.998626">Classifying Temporal Relations with Rich Linguistic Knowledge</title>
<author confidence="0.852201">D’Souza</author>
<affiliation confidence="0.999396">Human Language Technology Research Institute University of Texas at Dallas</affiliation>
<address confidence="0.987605">Richardson, TX 75083-0688</address>
<abstract confidence="0.988809526315789">We examine the task of temporal relation classification. Unlike existing approaches to this task, we (1) classify an event-event or eventtime pair as one of the 14 temporal relations defined in the TimeBank corpus, rather than as one of the six relations collapsed from the original 14; (2) employ sophisticated linguistic knowledge derived from a variety of semantic and discourse relations, rather than focusing on morpho-syntactic knowledge; and (3) leverage a novel combination of rule-based and learning-based approaches, rather than relying solely on one or the other. Experiments with the TimeBank corpus demonstrate that our knowledge-rich, hybrid approach yields a 15–16% relative reduction in error over a state-of-the-art learning-based baseline system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Shan Wang</author>
<author>Dan Jurafsky</author>
</authors>
<title>Classifying temporal relations between events.</title>
<date>2007</date>
<booktitle>In Proceedings ofthe 45th Annual Meeting ofthe Association for Computational Linguistics Companion Volume: Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>173--176</pages>
<contexts>
<context position="7400" citStr="Chambers et al. (2007)" startWordPosition="1165" endWordPosition="1168">eas the pair (invasion, rise) has type Before). 14 relation types are defined and used to annotate the temporal relations in the TimeBank corpus. Table 1 provides a brief description of these relation types and the relevant statistics. In our experiments, we assume that our temporal relation classification system is given an eventevent or event-time pair that is known to belong to one of the 14 relation types defined in TimeBank and aims to determine its relation type. Following previous evaluations of the temporal relation classification task on the TimeBank corpus (e.g., Mani et al. (2006), Chambers et al. (2007)) and in TempEval1/2, we assume as input gold events and time expressions. Unlike Mani et al. (2006) and Chambers et al. (2007), who focus on six relation types (Simultaneous, Before, IBefore, Begins, Ends, and Includes), we report results on 14 relation types. Note that the aforementioned six relation types are chosen by (1) discarding During, During Inv, and Identity, and (2) combining the two relation types in each of the five pairs, namely (Before, After), (IBefore, IAfter), (Includes, Is Included), (Begins, Begun By), and (Ends, Ended By), into a single type because they are inverses of e</context>
<context position="10692" citStr="Chambers et al. (2007)" startWordPosition="1744" endWordPosition="1747">ut loss of generality, assume that (e1,e2) is an event-event/event-time pair such that (1) e1 precedes e2 in the associated text and (2) (e1,e2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the POS bigram formed from </context>
</contexts>
<marker>Chambers, Wang, Jurafsky, 2007</marker>
<rawString>Nathanael Chambers, Shan Wang, and Dan Jurafsky. 2007. Classifying temporal relations between events. In Proceedings ofthe 45th Annual Meeting ofthe Association for Computational Linguistics Companion Volume: Proceedings of the Demo and Poster Sessions, pages 173–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>Verbocean: Mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="2508" citStr="Chklovski and Pantel, 2004" startWordPosition="380" endWordPosition="383">cally done in previous work (see Section 2 for more information), we address an arguably more challenging version of the task where we consider all the 14 relations originally defined in the TimeBank corpus. Our approach to temporal relation classification can be distinguished from existing approaches in two respects. The first involves a large-scale expansion of the linguistic features made available to the classification system. Recall that existing approaches have relied primarily on morphosyntactic features as well as a few semantic features extracted from WordNet synsets and VerbOcean’s (Chklovski and Pantel, 2004) semantic relations. On the other hand, we propose not only novel lexical and grammatical features, but also sophisticated features involving semantics and discourse. Most notably, we propose (1) semantic features encoding a variety of semantic relations, including PropBank-style predicate-argument relations as well as those extracted from the Merriam-Webster dictionary, and (2) discourse features encoding automatically computed Penn Discourse TreeBank (PDTB) style (Prasad et al., 2008) discourse relations. Second, while the vast majority of existing approaches to temporal relation classificat</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. Verbocean: Mining the web for fine-grained semantic verb relations. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel P Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="19545" citStr="Collobert et al., 2011" startWordPosition="3212" endWordPosition="3215">ate eight binary features for temporal relation classification. These eight features are created from the four WordNet relations in the same way as the eight features were created from the four Webster relations in the previous subsection. 4.1.5 Predicate-Argument Relations So far we have exploited lexical and dependency relations for temporal relation classification. We hypothesize that semantic relations, in particular predicate-argument relations, could be useful for the task. Consider the following example. (5) “What sector is stepping forward to pick up the slack?” he asked. Using SENNA (Collobert et al., 2011), a PropBankstyle semantic role labeler, we know that forward is in the directional argument of the predicate stepping. This enables us to infer that an Includes relation exists between stepping and forward since intuitively an action includes a direction. As another example, consider another PropBankstyle predicate-argument relation, cause. Assuming that e2 is in e1’s cause argument, we can infer that e2 occurs Before e1 since intuitively the cause of an action precedes the action. Consequently, we create features for temporal relation classification based on four types of PropBank-style pred</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eun Young Ha</author>
<author>Alok Baikadi</author>
<author>Carlyle Licata</author>
<author>James Lester</author>
</authors>
<title>NCSU: Modeling temporal relations with markov logic and lexical ontology.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>341--344</pages>
<contexts>
<context position="10787" citStr="Ha et al. (2010)" startWordPosition="1761" endWordPosition="1764">s e2 in the associated text and (2) (e1,e2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the POS bigram formed from the head word of e2 and its preceding token, the POS tag pair formed from the head words of e1 </context>
</contexts>
<marker>Ha, Baikadi, Licata, Lester, 2010</marker>
<rawString>Eun Young Ha, Alok Baikadi, Carlyle Licata, and James Lester. 2010. NCSU: Modeling temporal relations with markov logic and lexical ontology. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 341–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Hitzeman</author>
<author>Marc Moens</author>
<author>Claire Grover</author>
</authors>
<title>Algorithms for analysing the temporal structure of discourse.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>253--260</pages>
<contexts>
<context position="20702" citStr="Hitzeman et al., 1995" startWordPosition="3386" endWordPosition="3389">elation classification based on four types of PropBank-style predicate-argument relations, namely directional, manner, temporal, and cause. Specifically, using SENNA’s output, we create four binary features that encode whether argument e2 is related to predicate e1 through the four types of relations, and we create another four binary features that encode whether argument e1 is related to predicate e2 through the four types of relations. 4.1.6 Discourse Relations Rhetorical relations such as causation, elaboration and enablement could aid in tracking the temporal progression of the discourse (Hitzeman et al., 1995). Hence, unlike syntactic dependencies and predicateargument relations through which we can identify intra-sentential temporal relations, discourse relations can potentially be exploited to discover both inter-sentential and intra-sentential temporal relations. However, no recent work has attempted to use discourse relations for temporal relation clas922 (6) { Arg1 Hewlett-Packard Co. said it raised its stake in Octel Communications Corp. to 8.5% of the common shares outstanding. Arg1} { Arg2 RESTATEMENT In a Securities and Exchange Commission filing, Hewlett-Packard said it now holds 1,384,11</context>
</contexts>
<marker>Hitzeman, Moens, Grover, 1995</marker>
<rawString>Janet Hitzeman, Marc Moens, and Claire Grover. 1995. Algorithms for analysing the temporal structure of discourse. In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics, pages 253–260.</rawString>
</citation>
<citation valid="true">
<title>The Balancing Act: Combining Symbolic and Statistical Approaches to Language. Association for Computational Linguistics.</title>
<date>1994</date>
<editor>Judith Klavans and Philip Resnik, editors.</editor>
<marker>1994</marker>
<rawString>Judith Klavans and Philip Resnik, editors. 1994. The Balancing Act: Combining Symbolic and Statistical Approaches to Language. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>A PDTB-styled end-to-end discourse parser.</title>
<date>2013</date>
<journal>Natural Language Engineering</journal>
<note>(to appear).</note>
<marker>Lin, Ng, Kan, 2013</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2013. A PDTB-styled end-to-end discourse parser. Natural Language Engineering (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja Navarro</author>
</authors>
<title>TIPSem (English and Spanish): Evaluating CRFs and semantic roles in TempEval-2.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>284--291</pages>
<contexts>
<context position="10810" citStr="Llorens et al. (2010)" startWordPosition="1765" endWordPosition="1768">ated text and (2) (e1,e2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the POS bigram formed from the head word of e2 and its preceding token, the POS tag pair formed from the head words of e1 and e2, the preposition</context>
<context position="12728" citStr="Llorens et al., 2010" startWordPosition="2121" endWordPosition="2124">ed for the arguably simpler 6-class temporal relation classification tasks. 2http://nlp.stanford.edu/software/ corenlp.shtml 920 Entity attributes (13). The tense, aspect, modality, polarity, and event type of e1 and e2 if they are events (if one of them is a time expression, then the class attribute will be set to its class and the rest of them will have the value NULL), pairwise features formed by pairing up the tense values, the aspect values, and the class values of e1 and e2. Semantic (7). The subordinating temporal role token of e1 if it appears within a temporal semantic role argument (Llorens et al., 2010), the subordinating temporal role token of e2 if it appears within a temporal semantic role argument, the first WordNet synset to which e1 belongs, the first WordNet synset to which e2 belongs, and whether e1 and e2 are in the happens-before, happens-after, and similar relation according to VerbOcean.3 Distance (1). Are e1 and e2 in the same sentence? DCT related (3). The temporal relation type between e1 and the document creation time (DCT) [its value can be one of the 14 relation types, or NULL if no relation exists], the temporal relation type between e2 and the DCT, and whether e1 and e2 h</context>
<context position="18684" citStr="Llorens et al. (2010)" startWordPosition="3087" endWordPosition="3090">, and antonyms. Specifically, for each event e appearing in TimeBank, we first use the head word of e to retrieve four lists, which are the lists corresponding to the synonyms, related words, near-antonyms, and antonyms of e. Then, given a training/test instance involving e1 and e2, we create eight binary features: whether e1 appears in e2’s list of synonyms/related words/near-antonyms/antonyms, and whether e2 appears in e1’s list of synonyms/related words/nearantonyms/antonyms. 4.1.4 WordNet Relations Previous uses of WordNet for temporal relation classification are limited to synsets (e.g., Llorens et al. (2010)). We hypothesize that other WordNet lexical relations could also be useful for the task. Specifically, we employ four types of WordNet relations, 5http://www.merriam-webster.com/ namely hypernyms, hyponyms, troponyms, and similar, to create eight binary features for temporal relation classification. These eight features are created from the four WordNet relations in the same way as the eight features were created from the four Webster relations in the previous subsection. 4.1.5 Predicate-Argument Relations So far we have exploited lexical and dependency relations for temporal relation classif</context>
</contexts>
<marker>Llorens, Saquete, Navarro, 2010</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja Navarro. 2010. TIPSem (English and Spanish): Evaluating CRFs and semantic roles in TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 284–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>753--760</pages>
<contexts>
<context position="3892" citStr="Mani et al., 2006" startWordPosition="578" endWordPosition="581">rid approach stems from two hypotheses. First, a rule-based method could better handle the skewed class distribution underlying the dataset for 918 Proceedings of NAACL-HLT 2013, pages 918–927, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics our 14-class classification problem. Second, better decision rules could be formed by leveraging human insights to combine the available linguistic features than by using fully automatic machine learning methods. Note that while rule-based approaches have been shown to underperform learning-based approaches on this task (Mani et al., 2006), to our knowledge they have not been used in combination with learning-based approaches. Moreover, while the rules employed in previous work are created based on intuition (e.g., Mani et al. (2006), Pus¸cas¸u (2007)), our rules are created in a data-driven manner via a manual inspection of the annotated temporal relations in the TimeBank corpus. Experiments on the TimeBank corpus demonstrate the effectiveness of our knowledge-rich, hybrid approach to temporal relation classification: it yields a 15–16% relative reduction in error over a state-of-the-art learning-based baseline system. To our </context>
<context position="7376" citStr="Mani et al. (2006)" startWordPosition="1161" endWordPosition="1164">has type After, whereas the pair (invasion, rise) has type Before). 14 relation types are defined and used to annotate the temporal relations in the TimeBank corpus. Table 1 provides a brief description of these relation types and the relevant statistics. In our experiments, we assume that our temporal relation classification system is given an eventevent or event-time pair that is known to belong to one of the 14 relation types defined in TimeBank and aims to determine its relation type. Following previous evaluations of the temporal relation classification task on the TimeBank corpus (e.g., Mani et al. (2006), Chambers et al. (2007)) and in TempEval1/2, we assume as input gold events and time expressions. Unlike Mani et al. (2006) and Chambers et al. (2007), who focus on six relation types (Simultaneous, Before, IBefore, Begins, Ends, and Includes), we report results on 14 relation types. Note that the aforementioned six relation types are chosen by (1) discarding During, During Inv, and Identity, and (2) combining the two relation types in each of the five pairs, namely (Before, After), (IBefore, IAfter), (Includes, Is Included), (Begins, Begun By), and (Ends, Ended By), into a single type becaus</context>
<context position="10668" citStr="Mani et al. (2006)" startWordPosition="1740" endWordPosition="1743">this baseline. Without loss of generality, assume that (e1,e2) is an event-event/event-time pair such that (1) e1 precedes e2 in the associated text and (2) (e1,e2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 753–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Congmin Min</author>
<author>Munirathnam Srikanth</author>
<author>Abraham Fowler</author>
</authors>
<title>LCC-TE: A hybrid approach to temporal relation identification in news text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>219--222</pages>
<contexts>
<context position="10751" citStr="Min et al. (2007)" startWordPosition="1755" endWordPosition="1758">nt-time pair such that (1) e1 precedes e2 in the associated text and (2) (e1,e2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the POS bigram formed from the head word of e2 and its preceding token, the POS tag pa</context>
</contexts>
<marker>Min, Srikanth, Fowler, 2007</marker>
<rawString>Congmin Min, Munirathnam Srikanth, and Abraham Fowler. 2007. LCC-TE: A hybrid approach to temporal relation identification in news text. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 219–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seyed Abolghasem Mirroshandel</author>
<author>Gholamreza Ghassem-Sani</author>
</authors>
<title>Temporal relation extraction using expectation maximization.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<pages>218--225</pages>
<contexts>
<context position="10848" citStr="Mirroshandel and Ghassem-Sani (2011)" startWordPosition="1769" endWordPosition="1772">2) belongs to one of the 14 TimeBank temporal relation types. We create one training instance for each event-event/event-time pair in a training document that satisfies the two conditions above, labeling it with the relation type that exists between e1 and e2. To build a strong baseline, we represent each instance using 68 linguistic features modeled after the top-performing temporal relation classification systems on TimeBank (e.g., Mani et al. (2006), Chambers et al. (2007)) and in the TempEval shared tasks (e.g., Min et al. (2007), Pus¸cas¸u (2007), Ha et al. (2010), Llorens et al. (2010), Mirroshandel and Ghassem-Sani (2011)).1 These features can be divided into six categories, as described below. Lexical (5). The strings of e1 and e2, the head words of e1 and e2, and a binary feature indicating whether e1 and e2 have the same string. Grammatical (33). The POS tags of the head words of e1 and e2, the POS tags of the five tokens preceding and following e1 and e2, the POS bigram formed from the head word of e1 and its preceding token, the POS bigram formed from the head word of e2 and its preceding token, the POS tag pair formed from the head words of e1 and e2, the prepositional lexeme of the prepositional phrase </context>
</contexts>
<marker>Mirroshandel, Ghassem-Sani, 2011</marker>
<rawString>Seyed Abolghasem Mirroshandel and Gholamreza Ghassem-Sani. 2011. Temporal relation extraction using expectation maximization. In Proceedings of the International Conference Recent Advances in Natural Language Processing 2011, pages 218–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The penn discourse treebank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="2999" citStr="Prasad et al., 2008" startWordPosition="450" endWordPosition="453">syntactic features as well as a few semantic features extracted from WordNet synsets and VerbOcean’s (Chklovski and Pantel, 2004) semantic relations. On the other hand, we propose not only novel lexical and grammatical features, but also sophisticated features involving semantics and discourse. Most notably, we propose (1) semantic features encoding a variety of semantic relations, including PropBank-style predicate-argument relations as well as those extracted from the Merriam-Webster dictionary, and (2) discourse features encoding automatically computed Penn Discourse TreeBank (PDTB) style (Prasad et al., 2008) discourse relations. Second, while the vast majority of existing approaches to temporal relation classification are learning-based, we propose a system architecture in which we combine a learning-based approach and a rule-based approach. Our motivation behind adopting a hybrid approach stems from two hypotheses. First, a rule-based method could better handle the skewed class distribution underlying the dataset for 918 Proceedings of NAACL-HLT 2013, pages 918–927, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics our 14-class classification problem. Second, bet</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. In Proceedings of the 6th International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Pus¸cas¸u</author>
</authors>
<title>WVALI: Temporal relation identification by syntactico-semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>484--487</pages>
<marker>Pus¸cas¸u, 2007</marker>
<rawString>Georgiana Pus¸cas¸u. 2007. WVALI: Temporal relation identification by syntactico-semantic analysis. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 484–487.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>David Day</author>
<author>Lisa Ferro</author>
<author>Robert Gaizauskas</author>
<author>Marcia Lazo</author>
<author>Andrea Setzer</author>
<author>Beth Sundheim</author>
</authors>
<title>The TimeBank corpus. In Corpus Linguistics,</title>
<date>2003</date>
<pages>647--656</pages>
<contexts>
<context position="1359" citStr="Pustejovsky et al., 2003" startWordPosition="196" endWordPosition="199"> and learning-based approaches, rather than relying solely on one or the other. Experiments with the TimeBank corpus demonstrate that our knowledge-rich, hybrid approach yields a 15–16% relative reduction in error over a state-of-the-art learning-based baseline system. 1 Introduction Recent years have seen a surge of interest in temporal information extraction (IE). Temporal relation classification, one of the most important temporal IE tasks, involves classifying a given event-event pair or event-time pair as one of a set of predefined temporal relations. The creation of the TimeBank corpus (Pustejovsky et al., 2003) and the organization of the TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Verhagen et al., 2010) evaluation exercises have facilitated the development and evaluation of temporal relation classification systems. Our goal in this paper is to advance the state of the art in temporal relation classification. Our work differs from existing work with respect to both the complexity of the task we are addressing and the approach we adopt. Regarding task complexity, rather than focus on six temporal relations as is typically done in previous work (see Section 2 for more information), we address a</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Day, Ferro, Gaizauskas, Lazo, Setzer, Sundheim, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, David Day, Lisa Ferro, Robert Gaizauskas, Marcia Lazo, Andrea Setzer, and Beth Sundheim. 2003. The TimeBank corpus. In Corpus Linguistics, pages 647–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings ofthe 21st International Conference on Machine Learning,</booktitle>
<pages>104--112</pages>
<contexts>
<context position="13499" citStr="Tsochantaridis et al., 2004" startWordPosition="2253" endWordPosition="2256">ngs, the first WordNet synset to which e2 belongs, and whether e1 and e2 are in the happens-before, happens-after, and similar relation according to VerbOcean.3 Distance (1). Are e1 and e2 in the same sentence? DCT related (3). The temporal relation type between e1 and the document creation time (DCT) [its value can be one of the 14 relation types, or NULL if no relation exists], the temporal relation type between e2 and the DCT, and whether e1 and e2 have different relation types with the DCT. After creating the training instances, we train a 14-class classifier on them using SVM multiclass (Tsochantaridis et al., 2004).4 We then use it to make predictions on the test instances, which are generated in the same way as the training instances. 4 Our Hybrid Approach In this section, we describe our hybrid learningbased and rule-based approach to temporal relation classification. Section 4.1 describes our novel features, which will be used to augment the baseline feature set (see Section 3) to train a temporal relation classifier. Section 4.2 outlines our manual rule creation process. Section 4.3 discusses how we combine our hand-crafted rules and the learned classifier to make predictions in our hybrid approach.</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings ofthe 21st International Conference on Machine Learning, pages 104–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 Task 15: TempEval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>75--80</pages>
<contexts>
<context position="1422" citStr="Verhagen et al., 2007" startWordPosition="207" endWordPosition="210">or the other. Experiments with the TimeBank corpus demonstrate that our knowledge-rich, hybrid approach yields a 15–16% relative reduction in error over a state-of-the-art learning-based baseline system. 1 Introduction Recent years have seen a surge of interest in temporal information extraction (IE). Temporal relation classification, one of the most important temporal IE tasks, involves classifying a given event-event pair or event-time pair as one of a set of predefined temporal relations. The creation of the TimeBank corpus (Pustejovsky et al., 2003) and the organization of the TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Verhagen et al., 2010) evaluation exercises have facilitated the development and evaluation of temporal relation classification systems. Our goal in this paper is to advance the state of the art in temporal relation classification. Our work differs from existing work with respect to both the complexity of the task we are addressing and the approach we adopt. Regarding task complexity, rather than focus on six temporal relations as is typically done in previous work (see Section 2 for more information), we address an arguably more challenging version of the task where we consid</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval temporal relation identification. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 75–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>57--62</pages>
<contexts>
<context position="1461" citStr="Verhagen et al., 2010" startWordPosition="213" endWordPosition="216">Bank corpus demonstrate that our knowledge-rich, hybrid approach yields a 15–16% relative reduction in error over a state-of-the-art learning-based baseline system. 1 Introduction Recent years have seen a surge of interest in temporal information extraction (IE). Temporal relation classification, one of the most important temporal IE tasks, involves classifying a given event-event pair or event-time pair as one of a set of predefined temporal relations. The creation of the TimeBank corpus (Pustejovsky et al., 2003) and the organization of the TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Verhagen et al., 2010) evaluation exercises have facilitated the development and evaluation of temporal relation classification systems. Our goal in this paper is to advance the state of the art in temporal relation classification. Our work differs from existing work with respect to both the complexity of the task we are addressing and the approach we adopt. Regarding task complexity, rather than focus on six temporal relations as is typically done in previous work (see Section 2 for more information), we address an arguably more challenging version of the task where we consider all the 14 relations originally defi</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57–62.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>