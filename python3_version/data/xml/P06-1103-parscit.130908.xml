<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001236">
<title confidence="0.997733">
Weakly Supervised Named Entity Transliteration and Discovery from
Multilingual Comparable Corpora
</title>
<author confidence="0.998843">
Alexandre Klementiev Dan Roth
</author>
<affiliation confidence="0.9990335">
Dept. of Computer Science
University of Illinois
</affiliation>
<address confidence="0.814476">
Urbana, IL 61801
</address>
<email confidence="0.999238">
klementi,danr @uiuc.edu
</email>
<sectionHeader confidence="0.9939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906481481481">
Named Entity recognition (NER) is an
important part of many natural language
processing tasks. Current approaches of-
ten employ machine learning techniques
and require supervised data. However,
many languages lack such resources. This
paper presents an (almost) unsupervised
learning algorithm for automatic discov-
ery of Named Entities (NEs) in a resource
free language, given a bilingual corpora in
which it is weakly temporally aligned with
a resource rich language. NEs have similar
time distributions across such corpora, and
often some of the tokens in a multi-word
NE are transliterated. We develop an algo-
rithm that exploits both observations itera-
tively. The algorithm makes use of a new,
frequency based, metric for time distribu-
tions and a resource free discriminative ap-
proach to transliteration. Seeded with a
small number of transliteration pairs, our
algorithm discovers multi-word NEs, and
takes advantage of a dictionary (if one ex-
ists) to account for translated or partially
translated NEs. We evaluate the algorithm
on an English-Russian corpus, and show
high level of NEs discovery in Russian.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999843688888889">
Named Entity recognition has been getting much
attention in NLP research in recent years, since it
is seen as significant component of higher level
NLP tasks such as information distillation and
question answering. Most successful approaches
to NER employ machine learning techniques,
which require supervised training data. However,
for many languages, these resources do not ex-
ist. Moreover, it is often difficult to find experts
in these languages both for the expensive anno-
tation effort and even for language specific clues.
On the other hand, comparable multilingual data
(such as multilingual news streams) are becoming
increasingly available (see section 4).
In this work, we make two independent obser-
vations about Named Entities encountered in such
corpora, and use them to develop an algorithm that
extracts pairs of NEs across languages. Specifi-
cally, given a bilingual corpora that is weakly tem-
porally aligned, and a capability to annotate the
text in one of the languages with NEs, our algo-
rithm identifies the corresponding NEs in the sec-
ond language text, and annotates them with the ap-
propriate type, as in the source text.
The first observation is that NEs in one language
in such corpora tend to co-occur with their coun-
terparts in the other. E.g., Figure 1 shows a his-
togram of the number of occurrences of the word
Hussein and its Russian transliteration in our bilin-
gual news corpus spanning years 2001 through
late 2005. One can see several common peaks
in the two histograms, largest one being around
the time of the beginning of the war in Iraq. The
word Russia, on the other hand, has a distinctly
different temporal signature. We can exploit such
weak synchronicity of NEs across languages to
associate them. In order to score a pair of enti-
ties across languages, we compute the similarity
of their time distributions.
The second observation is that NEs often con-
tain or are entirely made up of words that are pho-
netically transliterated or have a common etymo-
logical origin across languages (e.g. parliament in
English and , its Russian translation),
and thus are phonetically similar. Figure 2 shows
</bodyText>
<page confidence="0.955954">
817
</page>
<note confidence="0.896065">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 817–824,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<figure confidence="0.882362">
01/01/01 10/05/05
Time
</figure>
<figureCaption confidence="0.985712">
Figure 1: Temporal histograms for Hussein (top),
its Russian transliteration (middle), and of the
word Russia (bottom).
</figureCaption>
<bodyText confidence="0.997885896551724">
an example list of NEs and their possible Russian
transliterations.
Approaches that attempt to use these two
characteristics separately to identify NEs across
languages would have significant shortcomings.
Transliteration based approaches require a good
model, typically handcrafted or trained on a clean
set of transliteration pairs. On the other hand, time
sequence similarity based approaches would in-
correctly match words which happen to have sim-
ilar time signatures (e.g., Taliban and Afghanistan
in recent news).
We introduce an algorithm we call co-ranking
which exploits these observations simultaneously
to match NEs on one side of the bilingual cor-
pus to their counterparts on the other. We use a
Discrete Fourier Transform (Arfken, 1985) based
metric for computing similarity of time distribu-
tions, and show that it has significant advantages
over other metrics traditionally used. We score
NEs similarity with a linear transliteration model.
We first train a transliteration model on single-
word NEs. During training, for a given NE in one
language, the current model chooses a list of top
ranked transliteration candidates in another lan-
guage. Time sequence scoring is then used to re-
rank the list and choose the candidate best tem-
porally aligned with the NE. Pairs of NEs and the
best candidates are then used to iteratively train the
</bodyText>
<figureCaption confidence="0.870736333333333">
Figure 2: Example English NEs and their translit-
erated Russian counterparts.
transliteration model.
</figureCaption>
<bodyText confidence="0.995950666666667">
Once the model is trained, NE discovery pro-
ceeds as follows. For a given NE, transliteration
model selects a candidate list for each constituent
word. If a dictionary is available, each candidate
list is augmented with translations (if they exist).
Translations will be the correct choice for some
NE words (e.g. for queen in Queen Victoria),
and transliterations for others (e.g. Bush in Steven
Bush). We expect temporal sequence alignment to
resolve many of such ambiguities. It is used to
select the best translation/transliteration candidate
from each word’s candidate set, which are then
merged into a possible NE in the other language.
Finally, we verify that the NE is actually contained
in the target corpus.
A major challenge inherent in discovering
transliterated NEs is the fact that a single en-
tity may be represented by multiple transliteration
strings. One reason is language morphology. For
example, in Russian, depending on a case being
used, the same noun may appear with various end-
ings. Another reason is the lack of translitera-
tion standards. Again, in Russian, several possible
transliterations of an English entity may be accept-
able, as long as they are phonetically similar to the
source.
Thus, in order to rely on the time sequences we
obtain, we need to be able to group variants of
the same NE into an equivalence class, and collect
their aggregate mention counts. We would then
score time sequences of these equivalence classes.
For instance, we would like to count the aggregate
number of occurrences of Herzegovina, Herce-
govina on the English side in order to map it ac-
curately to the equivalence class of that NE’s vari-
ants we may see on the Russian side of our cor-
pus (e.g.
).
One of the objectives for this work was to use as
</bodyText>
<figure confidence="0.999771625">
’hussein’ (Russian)
’hussein’ (English)
’russia’ (English)
Number of Occurences 20
15
10
5
2 0
15
10
5
2 0
15
10
5
0
</figure>
<page confidence="0.98785">
818
</page>
<bodyText confidence="0.999977181818182">
little of the knowledge of both languages as pos-
sible. In order to effectively rely on the quality of
time sequence scoring, we used a simple, knowl-
edge poor approach to group NE variants for the
languages of our corpus (see 3.2.1).
In the rest of the paper, whenever we refer to a
Named Entity or an NE constituent word, we im-
ply its equivalence class. Note that although we
expect that better use of language specific knowl-
edge would improve the results, it would defeat
one of the goals of this work.
</bodyText>
<sectionHeader confidence="0.984789" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999987755555556">
There has been other work to automati-
cally discover NE with minimal supervision.
Both (Cucerzan and Yarowsky, 1999) and (Collins
and Singer, 1999) present algorithms to obtain
NEs from untagged corpora. However, they focus
on the classification stage of already segmented
entities, and make use of contextual and mor-
phological clues that require knowledge of the
language beyond the level we want to assume
with respect to the target language.
The use of similarity of time distributions for
information extraction, in general, and NE extrac-
tion, in particular, is not new. (Hetland, 2004)
surveys recent methods for scoring time sequences
for similarity. (Shinyama and Sekine, 2004) used
the idea to discover NEs, but in a single language,
English, across two news sources.
A large amount of previous work exists on
transliteration models. Most are generative and
consider the task of producing an appropriate
transliteration for a given word, and thus require
considerable knowledge of the languages. For
example, (AbdulJaleel and Larkey, 2003; Jung
et al., 2000) train English-Arabic and English-
Korean generative transliteration models, respec-
tively. (Knight and Graehl, 1997) build a gen-
erative model for backward transliteration from
Japanese to English.
While generative models are often robust, they
tend to make independence assumptions that do
not hold in data. The discriminative learning
framework argued for in (Roth, 1998; Roth, 1999)
as an alternative to generative models is now used
widely in NLP, even in the context of word align-
ment (Taskar et al., 2005; Moore, 2005). We
make use of it here too, to learn a discriminative
transliteration model that requires little knowledge
of the target language.
We extend our preliminary work in (Kle-
mentiev and Roth, 2006) to discover multi-word
Named Entities and to take advantage of a dictio-
nary (if one exists) to handle NEs which are par-
tially or entirely translated. We take advantage of
dynamically growing feature space to reduce the
number of supervised training examples.
</bodyText>
<sectionHeader confidence="0.999185" genericHeader="method">
3 Co-Ranking: An Algorithm for NE
Discovery
</sectionHeader>
<subsectionHeader confidence="0.999932">
3.1 The algorithm
</subsectionHeader>
<bodyText confidence="0.985010444444444">
In essence, the algorithm we present uses tem-
poral alignment as a supervision signal to itera-
tively train a transliteration model. On each iter-
ation, it selects a list of top ranked transliteration
candidates for each NE according to the current
model (line 6). It then uses temporal alignment
(with thresholding) to re-rank the list and select
the best transliteration candidate for the next round
of training (lines 8, and 9).
Once the training is complete, lines 4 through
10 are executed without thresholding for each con-
stituent NE word. If a dictionary is available,
transliteration candidate lists on line 6 are
augmented with translations. We then combine
the best candidates (as chosen on line 8, without
thresholding) into complete target language NE.
Finally, we discard transliterations which do not
actually appear in the target corpus.
</bodyText>
<listItem confidence="0.4698145">
Algorithm 1: Iterative transliteration model
training.
</listItem>
<bodyText confidence="0.552205333333333">
Input: Bilingual, comparable corpus ( ,✝), set of
named entities from , threshold
Output: Transliteration model
</bodyText>
<figure confidence="0.964396266666667">
1 Initialize ;
3 repeat
4 ;
5 for each do
6 Use to collect a list of candidates
with high transliteration scores;
7 collect time distribution ;
8 Select candidate with the best
;
9 if exceeds , add tuple to ;
10 end
11 Use to train ;
12 until D stops changing between iterations ;
, collect time distribution ;
2
</figure>
<page confidence="0.978917">
819
</page>
<subsectionHeader confidence="0.996918">
3.2 Time sequence generation and matching
</subsectionHeader>
<bodyText confidence="0.999899833333333">
In order to generate time sequence for a word, we
divide the corpus into a sequence of temporal bins,
and count the number of occurrences of the word
in each bin. We then normalize the sequence.
We use a method called the F-index (Hetland,
2004) to implement the similarity function
on line 8 of the algorithm. We first run a Discrete
Fourier Transform on a time sequence to extract its
Fourier expansion coefficients. The score of a pair
of time sequences is then computed as a Euclidean
distance between their expansion coefficient vec-
tors.
</bodyText>
<subsubsectionHeader confidence="0.41965">
3.2.1 Equivalence Classes
</subsubsectionHeader>
<bodyText confidence="0.999976375">
As we mentioned in the introduction, an NE
may map to more than one transliteration in an-
other language. Identification of the entity’s
equivalence class of transliterations is important
for obtaining its accurate time sequence.
In order to keep to our objective of requiring as
little language knowledge as possible, we took a
rather simplistic approach for both languages of
our corpus. For Russian, two words were consid-
ered variants of the same NE if they share a prefix
of size five or longer. Each unique word had its
own equivalence class for the English side of the
corpus, although, in principal, ideas such as in (Li
et al., 2004) could be incorporated.
A cumulative distribution was then collected
for such equivalence classes.
</bodyText>
<subsectionHeader confidence="0.983266">
3.3 Transliteration model
</subsectionHeader>
<bodyText confidence="0.998903658536585">
Unlike most of the previous work considering gen-
erative transliteration models, we take the discrim-
inative approach. We train a linear model to decide
whether a word is a transliteration of an
NE . The words in the pair are partitioned
into a set of substrings and up to a particular
length (including the empty string ). Couplings of
the substrings from both sets produce fea-
tures we use for training. Note that couplings with
the empty string represent insertions/omissions.
Consider the following example: ( , ) =
(powell, pauel). We build a feature vector from
this example in the following manner:
First, we split both words into all possible
substrings of up to size two:
We build a feature vector by coupling sub-
strings from the two sets:
We use the observation that transliteration tends
to preserve phonetic sequence to limit the number
of couplings. For example, we can disallow the
coupling of substrings whose starting positions are
too far apart: thus, we might not consider a pairing
in the above example. In our experiments,
we paired substrings if their positions in their re-
spective words differed by -1, 0, or 1.
We use the perceptron (Rosenblatt, 1958) algo-
rithm to train the model. The model activation
provides the score we use to select best translit-
erations on line 6. Our version of perceptron takes
variable number of features in its examples; each
example is a subset of all features seen so far that
are active in the input. As the iterative algorithm
observes more data, it discovers and makes use of
more features. This model is called the infinite at-
tribute model (Blum, 1992) and it follows the per-
ceptron version of SNoW (Roth, 1998).
Positive examples used for iterative training are
pairs of NEs and their best temporally aligned
(thresholded) transliteration candidates. Negative
examples are English non-NEs paired with ran-
dom Russian words.
</bodyText>
<sectionHeader confidence="0.997567" genericHeader="method">
4 Experimental Study
</sectionHeader>
<bodyText confidence="0.999955">
We ran experiments using a bilingual comparable
English-Russian news corpus we built by crawl-
ing a Russian news web site (www.lenta.ru).
The site provides loose translations of (and
pointers to) the original English texts. We col-
lected pairs of articles spanning from 1/1/2001
through 10/05/2005. The corpus consists of
2,327 documents, with 0-8 documents per day.
The corpus is available on our web page at
http://L2R.cs.uiuc.edu/ cogcomp/.
The English side was tagged with a publicly
available NER system based on the SNoW learn-
ing architecture (Roth, 1998), that is available
on the same site. This set of English NEs was
hand-pruned to remove incorrectly classified
words to obtain 978 single word NEs.
In order to reduce running time, some lim-
ited pre-processing was done on the Russian side.
All classes, whose temporal distributions were
close to uniform (i.e. words with a similar like-
lihood of occurrence throughout the corpus) were
</bodyText>
<page confidence="0.982013">
820
</page>
<figure confidence="0.9920385">
Accuracy (%)
Accuracy (%)
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
Iteration
</figure>
<figureCaption confidence="0.993922">
Figure 3: Proportion of correctly discovered NE
pairs vs. training iteration. Complete algorithm
outperforms both transliteration model and tempo-
ral sequence matching when used on their own.
</figureCaption>
<bodyText confidence="0.983912666666666">
deemed common and not considered as NE can-
didates. Unique words were thus grouped into
14,781 equivalence classes.
Unless mentioned otherwise, the transliteration
model was initialized with a set of 20 pairs of En-
glish NEs and their Russian transliterations. Nega-
tive examples here and during the rest of the train-
ing were pairs of randomly selected non-NE En-
glish and Russian words.
New features were discovered throughout train-
ing; all but top 3000 features from positive and
3000 from negative examples were pruned based
on the number of their occurrences so far. Fea-
tures remaining at the end of training were used
for NE discovery.
Insertions/omissions features were not used in
the experiments as they provided no tangible ben-
efit for the languages of our corpus.
In each iteration, we used the current transliter-
ation model to find a list of 30 best transliteration
equivalence classes for each NE. We then com-
puted time sequence similarity score between NE
and each class from its list to find the one with
the best matching time sequence. If its similar-
ity score surpassed a set threshold, it was added
to the list of positive examples for the next round
of training. Positive examples were constructed
by pairing an NE with the common stem of its
transliteration equivalence class. We used the
same number of positive and negative examples.
</bodyText>
<figure confidence="0.9083355">
0 1 2 3 4 5
Iteration
</figure>
<figureCaption confidence="0.6896834">
Figure 4: Proportion of correctly discovered NE
pairs vs. the initial example set size. As long as
the size is large enough, decreasing the number of
examples does not have a significant impact on the
performance of the later iterations.
</figureCaption>
<bodyText confidence="0.999996066666667">
We used the Mueller English-Russian dictio-
nary to obtain translations in our multi-word NE
experiments. We only considered the first dictio-
nary definition as a candidate.
For evaluation, random 727 of the total of 978
NEs were matched to correct transliterations by a
language expert (partly due to the fact that some of
the English NEs were not mentioned in the Rus-
sian side of the corpus). Accuracy was computed
as the percentage of NEs correctly identified by
the algorithm.
In the multi-word NE experiment, 282 random
multi-word (2 or more) NEs and their translit-
erations/translations discovered by the algorithm
were verified by a language expert.
</bodyText>
<subsectionHeader confidence="0.994785">
4.1 NE discovery
</subsectionHeader>
<bodyText confidence="0.99941">
Figure 3 shows the proportion of correctly dis-
covered NE transliteration equivalence classes
throughout the training stage. The figure also
shows the accuracy if transliterations are selected
according to the current transliteration model (top
scoring candidate) and temporal sequence match-
ing alone.
The transliteration model alone achieves an ac-
curacy of about 38%, while the time sequence
alone gets about 41%. The combined algorithm
achieves about 63%, giving a significant improve-
ment.
</bodyText>
<figure confidence="0.992070625">
40
20
80
70
60
50
30
10
0
Complete Algorithm
Transliteration Model Only
Temporal Sequence Only
40
20
80
70
60
50
30
10
0
5 examples
20 examples
80 examples
</figure>
<page confidence="0.981862">
821
</page>
<table confidence="0.998898666666667">
Cosine 41.3 5.8 1.7
Pearson 41.1 5.8 1.7
DFT 41.0 12.4 4.8
</table>
<tableCaption confidence="0.9645866">
Table 1: Proportion of correctly discovered NEs
vs. corpus misalignment ( ) for each of the three
measures. DFT based measure provides signifi-
cant advantages over commonly used metrics for
weakly aligned corpora.
</tableCaption>
<table confidence="0.999765">
Cosine 5.8 13.5 18.4
Pearson 5.8 13.5 18.2
DFT 12.4 20.6 27.9
</table>
<tableCaption confidence="0.99695">
Table 2: Proportion of correctly discovered NEs
</tableCaption>
<bodyText confidence="0.986142558823529">
vs. sliding window size ( ) for each of the three
measures.
In order to understand what happens to the
transliteration model as the training proceeds, let
us consider the following example. Figure 5 shows
parts of transliteration lists for NE forsyth for two
iterations of the algorithm. The weak translitera-
tion model selects the correct transliteration (ital-
icized) as the 24th best transliteration in the first
iteration. Time sequence scoring function chooses
it to be one of the training examples for the next
round of training of the model. By the eighth iter-
ation, the model has improved to select it as a best
transliteration.
Not all correct transliterations make it to the top
of the candidates list (transliteration model by it-
self is never as accurate as the complete algorithm
on Figure 3). That is not required, however, as the
model only needs to be good enough to place the
correct transliteration anywhere in the candidate
list.
Not surprisingly, some of the top translitera-
tion candidates start sounding like the NE itself,
as training progresses. On Figure 5, candidates for
forsyth on iteration 7 include fross and fossett.
Once the transliteration model was trained, we
ran the algorithm to discover multi-word NEs,
augmenting candidate sets of dictionary words
with their translations as described in Section 3.1.
We achieved the accuracy of about 66%. The
correctly discovered Russian NEs included en-
tirely transliterated, partially translated, and en-
tirely translated NEs. Some of them are shown on
Figure 6.
</bodyText>
<subsectionHeader confidence="0.990236">
4.2 Initial example set size
</subsectionHeader>
<bodyText confidence="0.999994696969697">
We ran a series of experiments to see how the size
of the initial training set affects the accuracy of the
model as training progresses (Figure 4). Although
the performance of the early iterations is signif-
icantly affected by the size of the initial training
example set, the algorithm quickly improves its
performance. As we decrease the size from 80 to
20, the accuracy of the first iteration drops by over
20%, but a few iterations later the two have sim-
ilar performance. However, when initialized with
the set of size 5, the algorithm never manages to
improve.
The intuition is the following. The few ex-
amples in the initial training set produce features
corresponding to substring pairs characteristic for
English-Russian transliterations. Model trained
on these (few) examples chooses other transliter-
ations containing these same substring pairs. In
turn, the chosen positive examples contain other
characteristic substring pairs, which will be used
by the model to select more positive examples on
the next round, and so on. On the other hand, if
the initial set is too small, too few of the character-
istic transliteration features are extracted to select
a clean enough training set on the next round of
training.
In general, one would expect the size of the
training set necessary for the algorithm to improve
to depend on the level of temporal alignment of
the two sides of the corpus. Indeed, the weaker the
temporal supervision the more we need to endow
the model so that it can select cleaner candidates
in the early iterations.
</bodyText>
<subsectionHeader confidence="0.9592645">
4.3 Comparison of time sequence scoring
functions
</subsectionHeader>
<bodyText confidence="0.999391857142857">
We compared the performance of the DFT-based
time sequence similarity scoring function we use
in this paper to the commonly used cosine (Salton
and McGill, 1986) and Pearson’s correlation mea-
sures.
We perturbed the Russian side of the corpus
in the following way. Articles from each day
were randomly moved (with uniform probabil-
ity) within a -day window. We ran single word
NE temporal sequence matching alone on the per-
turbed corpora using each of the three measures
(Table 1).
Some accuracy drop due to misalignment could
be accommodated for by using a larger temporal
</bodyText>
<page confidence="0.994404">
822
</page>
<figureCaption confidence="0.9965305">
Figure 5: Transliteration lists for forsyth for two iterations of the algorithm. As transliteration model
improves, the correct transliteration moves up the list.
</figureCaption>
<bodyText confidence="0.9996721">
bin for collecting occurrence counts. We tried var-
ious (sliding) window size for a perturbed cor-
pus with (Table 2).
DFT metric outperforms the other measures sig-
nificantly in most cases. NEs tend to have dis-
tributions with few pronounced peaks. If two
such distributions are not well aligned, we expect
both Pearson and Cosine measures to produce low
scores, whereas the DFT metric should catch their
similarities in the frequency domain.
</bodyText>
<sectionHeader confidence="0.999481" genericHeader="method">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.994927038461538">
We have proposed a novel algorithm for cross
lingual multi-word NE discovery in a bilingual
weakly temporally aligned corpus. We have
demonstrated that using two independent sources
of information (transliteration and temporal simi-
larity) together to guide NE extraction gives better
performance than using either of them alone (see
Figure 3).
We developed a linear discriminative transliter-
ation model, and presented a method to automati-
cally generate features. For time sequence match-
ing, we used a scoring metric novel in this domain.
We provided experimental evidence that this met-
ric outperforms other scoring metrics traditionally
used.
In keeping with our objective to provide as lit-
tle language knowledge as possible, we introduced
a simplistic approach to identifying transliteration
equivalence classes, which sometimes produced
erroneous groupings (e.g. an equivalence class
for NE congolese in Russian included both congo
and congolese on Figure 6). We expect that more
language specific knowledge used to discover ac-
curate equivalence classes would result in perfor-
mance improvements.
Other type of supervision was in the form of a
</bodyText>
<figureCaption confidence="0.994894">
Figure 6: Example of correct transliterations dis-
covered by the algorithm.
</figureCaption>
<bodyText confidence="0.829976">
very small bootstrapping transliteration set.
</bodyText>
<sectionHeader confidence="0.999537" genericHeader="discussions">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999985363636364">
The algorithm can be naturally extended to com-
parable corpora of more than two languages.
Pair-wise time sequence scoring and translitera-
tion models should give better confidence in NE
matches.
The ultimate goal of this work is to automati-
cally tag NEs so that they can be used for training
of an NER system for a new language. To this end,
we would like to compare the performance of an
NER system trained on a corpus tagged using this
approach to one trained on a hand-tagged corpus.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9983375">
We thank Richard Sproat, ChengXiang Zhai, and
Kevin Small for their useful feedback during this
work, and the anonymous referees for their help-
ful comments. This research is supported by
the Advanced Research and Development Activity
(ARDA)’s Advanced Question Answering for In-
telligence (AQUAINT) Program and a DOI grant
under the Reflex program.
</bodyText>
<page confidence="0.998316">
823
</page>
<sectionHeader confidence="0.995873" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999694611940299">
Nasreen AbdulJaleel and Leah S. Larkey. 2003. Statis-
tical transliteration for english-arabic cross language
information retrieval. In Proceedings of CIKM,
pages 139–146, New York, NY, USA.
George Arfken. 1985. Mathematical Methods for
Physicists. Academic Press.
Avrim Blum. 1992. Learning boolean functions
in an infinite attribute space. Machine Learning,
9(4):373–386.
Michael Collins and Yoram Singer. 1999. Unsuper-
vised models for named entity classification. In
Proc. of the Conference on Empirical Methods for
Natural Language Processing (EMNLP).
Silviu Cucerzan and David Yarowsky. 1999. Lan-
guage independent named entity recognition com-
bining morphological and contextual evidence. In
Proc. of the Conference on Empirical Methods for
Natural Language Processing (EMNLP).
Magnus Lie Hetland, 2004. Data Mining in Time Se-
ries Databases, chapter A Survey of Recent Meth-
ods for Efficient Retrieval of Similar Time Se-
quences. World Scientific.
Sung Young Jung, SungLim Hong, and Eunok Paek.
2000. An english to korean transliteration model
of extended markov window. In Proc. the Inter-
national Conference on Computational Linguistics
(COLING), pages 383–389.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proc. of the Annual
Meeting of the North American Association of Com-
putational Linguistics (NAACL).
Kevin Knight and Jonathan Graehl. 1997. Machine
transliteration. In Proc. of the Meeting of the Eu-
ropean Association of Computational Linguistics,
pages 128–135.
Xin Li, Paul Morie, and Dan Roth. 2004. Identifi-
cation and tracing of ambiguous names: Discrimi-
native and generative approaches. In Proceedings
of the National Conference on Artifzcial Intelligence
(AAAI), pages 419–424.
Robert C. Moore. 2005. A discriminative framework
for bilingual word alignment. In Proc. of the Con-
ference on Empirical Methodsfor Natural Language
Processing (EMNLP), pages 81–88.
Frank Rosenblatt. 1958. The perceptron: A probabilis-
tic model for information storage and organization in
the brain. Psychological Review, 65.
Dan Roth. 1998. Learning to resolve natural language
ambiguities: A unified approach. In Proceedings
of the National Conference on Artifzcial Intelligence
(AAAI), pages 806–813.
Dan Roth. 1999. Learning in natural language. In
Proc. of the International Joint Conference on Arti-
fzcial Intelligence (IJCAI), pages 898–904.
Gerard Salton and Michael J. McGill. 1986. Intro-
duction to Modern Information Retrieval. McGraw-
Hill, Inc., New York, NY, USA.
Yusuke Shinyama and Satoshi Sekine. 2004. Named
entity discovery using comparable news articles. In
Proc. the International Conference on Computa-
tional Linguistics (COLING), pages 848–853.
Ben Taskar, Simon Lacoste-Julien, and Michael Jor-
dan. 2005. Structured prediction via the extra-
gradient method. In The Conference on Advances
in Neural Information Processing Systems (NIPS).
MIT Press.
</reference>
<page confidence="0.998691">
824
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965363">
<title confidence="0.9907425">Weakly Supervised Named Entity Transliteration and Discovery from Multilingual Comparable Corpora</title>
<author confidence="0.999908">Alexandre Klementiev Dan Roth</author>
<affiliation confidence="0.999964">Dept. of Computer Science University of Illinois</affiliation>
<address confidence="0.999813">Urbana, IL 61801</address>
<email confidence="0.997818">klementi,danr@uiuc.edu</email>
<abstract confidence="0.999471">Named Entity recognition (NER) is an important part of many natural language processing tasks. Current approaches often employ machine learning techniques and require supervised data. However, many languages lack such resources. This paper presents an (almost) unsupervised learning algorithm for automatic discovery of Named Entities (NEs) in a resource free language, given a bilingual corpora in which it is weakly temporally aligned with a resource rich language. NEs have similar time distributions across such corpora, and often some of the tokens in a multi-word NE are transliterated. We develop an algorithm that exploits both observations iteratively. The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration. Seeded with a small number of transliteration pairs, our algorithm discovers multi-word NEs, and takes advantage of a dictionary (if one exists) to account for translated or partially translated NEs. We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nasreen AbdulJaleel</author>
<author>Leah S Larkey</author>
</authors>
<title>Statistical transliteration for english-arabic cross language information retrieval.</title>
<date>2003</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>139--146</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="8720" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="1402" endWordPosition="1405">ct to the target language. The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources. A large amount of previous work exists on transliteration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative tra</context>
</contexts>
<marker>AbdulJaleel, Larkey, 2003</marker>
<rawString>Nasreen AbdulJaleel and Leah S. Larkey. 2003. Statistical transliteration for english-arabic cross language information retrieval. In Proceedings of CIKM, pages 139–146, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Arfken</author>
</authors>
<title>Mathematical Methods for Physicists.</title>
<date>1985</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="4576" citStr="Arfken, 1985" startWordPosition="710" endWordPosition="711"> to identify NEs across languages would have significant shortcomings. Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs. On the other hand, time sequence similarity based approaches would incorrectly match words which happen to have similar time signatures (e.g., Taliban and Afghanistan in recent news). We introduce an algorithm we call co-ranking which exploits these observations simultaneously to match NEs on one side of the bilingual corpus to their counterparts on the other. We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and show that it has significant advantages over other metrics traditionally used. We score NEs similarity with a linear transliteration model. We first train a transliteration model on singleword NEs. During training, for a given NE in one language, the current model chooses a list of top ranked transliteration candidates in another language. Time sequence scoring is then used to rerank the list and choose the candidate best temporally aligned with the NE. Pairs of NEs and the best candidates are then used to iteratively train the </context>
</contexts>
<marker>Arfken, 1985</marker>
<rawString>George Arfken. 1985. Mathematical Methods for Physicists. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
</authors>
<title>Learning boolean functions in an infinite attribute space.</title>
<date>1992</date>
<booktitle>Machine Learning,</booktitle>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="14093" citStr="Blum, 1992" startWordPosition="2301" endWordPosition="2302">ng in the above example. In our experiments, we paired substrings if their positions in their respective words differed by -1, 0, or 1. We use the perceptron (Rosenblatt, 1958) algorithm to train the model. The model activation provides the score we use to select best transliterations on line 6. Our version of perceptron takes variable number of features in its examples; each example is a subset of all features seen so far that are active in the input. As the iterative algorithm observes more data, it discovers and makes use of more features. This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version of SNoW (Roth, 1998). Positive examples used for iterative training are pairs of NEs and their best temporally aligned (thresholded) transliteration candidates. Negative examples are English non-NEs paired with random Russian words. 4 Experimental Study We ran experiments using a bilingual comparable English-Russian news corpus we built by crawling a Russian news web site (www.lenta.ru). The site provides loose translations of (and pointers to) the original English texts. We collected pairs of articles spanning from 1/1/2001 through 10/05/2005. The corpus</context>
</contexts>
<marker>Blum, 1992</marker>
<rawString>Avrim Blum. 1992. Learning boolean functions in an infinite attribute space. Machine Learning, 9(4):373–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Yoram Singer</author>
</authors>
<title>Unsupervised models for named entity classification.</title>
<date>1999</date>
<booktitle>In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7821" citStr="Collins and Singer, 1999" startWordPosition="1263" endWordPosition="1266"> as possible. In order to effectively rely on the quality of time sequence scoring, we used a simple, knowledge poor approach to group NE variants for the languages of our corpus (see 3.2.1). In the rest of the paper, whenever we refer to a Named Entity or an NE constituent word, we imply its equivalence class. Note that although we expect that better use of language specific knowledge would improve the results, it would defeat one of the goals of this work. 2 Previous work There has been other work to automatically discover NE with minimal supervision. Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora. However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language. The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, Engli</context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Michael Collins and Yoram Singer. 1999. Unsupervised models for named entity classification. In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
<author>David Yarowsky</author>
</authors>
<title>Language independent named entity recognition combining morphological and contextual evidence.</title>
<date>1999</date>
<booktitle>In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7790" citStr="Cucerzan and Yarowsky, 1999" startWordPosition="1258" endWordPosition="1261">of the knowledge of both languages as possible. In order to effectively rely on the quality of time sequence scoring, we used a simple, knowledge poor approach to group NE variants for the languages of our corpus (see 3.2.1). In the rest of the paper, whenever we refer to a Named Entity or an NE constituent word, we imply its equivalence class. Note that although we expect that better use of language specific knowledge would improve the results, it would defeat one of the goals of this work. 2 Previous work There has been other work to automatically discover NE with minimal supervision. Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora. However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language. The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, </context>
</contexts>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>Silviu Cucerzan and David Yarowsky. 1999. Language independent named entity recognition combining morphological and contextual evidence. In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Lie Hetland</author>
</authors>
<title>Data Mining in Time Series Databases, chapter A Survey of Recent Methods for Efficient Retrieval of Similar Time Sequences. World Scientific.</title>
<date>2004</date>
<contexts>
<context position="8264" citStr="Hetland, 2004" startWordPosition="1335" endWordPosition="1336">is work. 2 Previous work There has been other work to automatically discover NE with minimal supervision. Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora. However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language. The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources. A large amount of previous work exists on transliteration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a g</context>
<context position="11398" citStr="Hetland, 2004" startWordPosition="1847" endWordPosition="1848">ion model 1 Initialize ; 3 repeat 4 ; 5 for each do 6 Use to collect a list of candidates with high transliteration scores; 7 collect time distribution ; 8 Select candidate with the best ; 9 if exceeds , add tuple to ; 10 end 11 Use to train ; 12 until D stops changing between iterations ; , collect time distribution ; 2 819 3.2 Time sequence generation and matching In order to generate time sequence for a word, we divide the corpus into a sequence of temporal bins, and count the number of occurrences of the word in each bin. We then normalize the sequence. We use a method called the F-index (Hetland, 2004) to implement the similarity function on line 8 of the algorithm. We first run a Discrete Fourier Transform on a time sequence to extract its Fourier expansion coefficients. The score of a pair of time sequences is then computed as a Euclidean distance between their expansion coefficient vectors. 3.2.1 Equivalence Classes As we mentioned in the introduction, an NE may map to more than one transliteration in another language. Identification of the entity’s equivalence class of transliterations is important for obtaining its accurate time sequence. In order to keep to our objective of requiring </context>
</contexts>
<marker>Hetland, 2004</marker>
<rawString>Magnus Lie Hetland, 2004. Data Mining in Time Series Databases, chapter A Survey of Recent Methods for Efficient Retrieval of Similar Time Sequences. World Scientific.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sung Young Jung</author>
<author>SungLim Hong</author>
<author>Eunok Paek</author>
</authors>
<title>An english to korean transliteration model of extended markov window.</title>
<date>2000</date>
<booktitle>In Proc. the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>383--389</pages>
<contexts>
<context position="8740" citStr="Jung et al., 2000" startWordPosition="1406" endWordPosition="1409"> use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources. A large amount of previous work exists on transliteration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model t</context>
</contexts>
<marker>Jung, Hong, Paek, 2000</marker>
<rawString>Sung Young Jung, SungLim Hong, and Eunok Paek. 2000. An english to korean transliteration model of extended markov window. In Proc. the International Conference on Computational Linguistics (COLING), pages 383–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="9455" citStr="Klementiev and Roth, 2006" startWordPosition="1518" endWordPosition="1522">(Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated. We take advantage of dynamically growing feature space to reduce the number of supervised training examples. 3 Co-Ranking: An Algorithm for NE Discovery 3.1 The algorithm In essence, the algorithm we present uses temporal alignment as a supervision signal to iteratively train a transliteration model. On each iteration, it selects a list of top ranked transliteration candidates for each NE according to the current model (line 6). It then uses tem</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Named entity transliteration and discovery from multilingual comparable corpora. In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1997</date>
<booktitle>In Proc. of the Meeting of the European Association of Computational Linguistics,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="8854" citStr="Knight and Graehl, 1997" startWordPosition="1420" endWordPosition="1423">cular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources. A large amount of previous work exists on transliteration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1997. Machine transliteration. In Proc. of the Meeting of the European Association of Computational Linguistics, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Li</author>
<author>Paul Morie</author>
<author>Dan Roth</author>
</authors>
<title>Identification and tracing of ambiguous names: Discriminative and generative approaches.</title>
<date>2004</date>
<booktitle>In Proceedings of the National Conference on Artifzcial Intelligence (AAAI),</booktitle>
<pages>419--424</pages>
<contexts>
<context position="12362" citStr="Li et al., 2004" startWordPosition="2007" endWordPosition="2010">ntroduction, an NE may map to more than one transliteration in another language. Identification of the entity’s equivalence class of transliterations is important for obtaining its accurate time sequence. In order to keep to our objective of requiring as little language knowledge as possible, we took a rather simplistic approach for both languages of our corpus. For Russian, two words were considered variants of the same NE if they share a prefix of size five or longer. Each unique word had its own equivalence class for the English side of the corpus, although, in principal, ideas such as in (Li et al., 2004) could be incorporated. A cumulative distribution was then collected for such equivalence classes. 3.3 Transliteration model Unlike most of the previous work considering generative transliteration models, we take the discriminative approach. We train a linear model to decide whether a word is a transliteration of an NE . The words in the pair are partitioned into a set of substrings and up to a particular length (including the empty string ). Couplings of the substrings from both sets produce features we use for training. Note that couplings with the empty string represent insertions/omissions</context>
</contexts>
<marker>Li, Morie, Roth, 2004</marker>
<rawString>Xin Li, Paul Morie, and Dan Roth. 2004. Identification and tracing of ambiguous names: Discriminative and generative approaches. In Proceedings of the National Conference on Artifzcial Intelligence (AAAI), pages 419–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A discriminative framework for bilingual word alignment.</title>
<date>2005</date>
<booktitle>In Proc. of the Conference on Empirical Methodsfor Natural Language Processing (EMNLP),</booktitle>
<pages>81--88</pages>
<contexts>
<context position="9261" citStr="Moore, 2005" startWordPosition="1489" endWordPosition="1490"> knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated. We take advantage of dynamically growing feature space to reduce the number of supervised training examples. 3 Co-Ranking: An Algorithm for NE Discovery 3.1 The algorithm In essence, the algorithm we present uses temporal alignment as a supervision signal</context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>Robert C. Moore. 2005. A discriminative framework for bilingual word alignment. In Proc. of the Conference on Empirical Methodsfor Natural Language Processing (EMNLP), pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Rosenblatt</author>
</authors>
<title>The perceptron: A probabilistic model for information storage and organization in the brain.</title>
<date>1958</date>
<journal>Psychological Review,</journal>
<volume>65</volume>
<contexts>
<context position="13658" citStr="Rosenblatt, 1958" startWordPosition="2224" endWordPosition="2225">ector from this example in the following manner: First, we split both words into all possible substrings of up to size two: We build a feature vector by coupling substrings from the two sets: We use the observation that transliteration tends to preserve phonetic sequence to limit the number of couplings. For example, we can disallow the coupling of substrings whose starting positions are too far apart: thus, we might not consider a pairing in the above example. In our experiments, we paired substrings if their positions in their respective words differed by -1, 0, or 1. We use the perceptron (Rosenblatt, 1958) algorithm to train the model. The model activation provides the score we use to select best transliterations on line 6. Our version of perceptron takes variable number of features in its examples; each example is a subset of all features seen so far that are active in the input. As the iterative algorithm observes more data, it discovers and makes use of more features. This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version of SNoW (Roth, 1998). Positive examples used for iterative training are pairs of NEs and their best temporally aligned (thresh</context>
</contexts>
<marker>Rosenblatt, 1958</marker>
<rawString>Frank Rosenblatt. 1958. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
</authors>
<title>Learning to resolve natural language ambiguities: A unified approach.</title>
<date>1998</date>
<booktitle>In Proceedings of the National Conference on Artifzcial Intelligence (AAAI),</booktitle>
<pages>806--813</pages>
<contexts>
<context position="9109" citStr="Roth, 1998" startWordPosition="1461" endWordPosition="1462">teration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated. We take advantage of dynamically growing feature space to reduce the number of supervised training exam</context>
<context position="14152" citStr="Roth, 1998" startWordPosition="2312" endWordPosition="2313">trings if their positions in their respective words differed by -1, 0, or 1. We use the perceptron (Rosenblatt, 1958) algorithm to train the model. The model activation provides the score we use to select best transliterations on line 6. Our version of perceptron takes variable number of features in its examples; each example is a subset of all features seen so far that are active in the input. As the iterative algorithm observes more data, it discovers and makes use of more features. This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version of SNoW (Roth, 1998). Positive examples used for iterative training are pairs of NEs and their best temporally aligned (thresholded) transliteration candidates. Negative examples are English non-NEs paired with random Russian words. 4 Experimental Study We ran experiments using a bilingual comparable English-Russian news corpus we built by crawling a Russian news web site (www.lenta.ru). The site provides loose translations of (and pointers to) the original English texts. We collected pairs of articles spanning from 1/1/2001 through 10/05/2005. The corpus consists of 2,327 documents, with 0-8 documents per day. T</context>
</contexts>
<marker>Roth, 1998</marker>
<rawString>Dan Roth. 1998. Learning to resolve natural language ambiguities: A unified approach. In Proceedings of the National Conference on Artifzcial Intelligence (AAAI), pages 806–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
</authors>
<title>Learning in natural language.</title>
<date>1999</date>
<booktitle>In Proc. of the International Joint Conference on Artifzcial Intelligence (IJCAI),</booktitle>
<pages>898--904</pages>
<contexts>
<context position="9122" citStr="Roth, 1999" startWordPosition="1463" endWordPosition="1464">els. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated. We take advantage of dynamically growing feature space to reduce the number of supervised training examples. 3 Co-Ra</context>
</contexts>
<marker>Roth, 1999</marker>
<rawString>Dan Roth. 1999. Learning in natural language. In Proc. of the International Joint Conference on Artifzcial Intelligence (IJCAI), pages 898–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1986</date>
<publisher>McGrawHill, Inc.,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="22238" citStr="Salton and McGill, 1986" startWordPosition="3642" endWordPosition="3645"> features are extracted to select a clean enough training set on the next round of training. In general, one would expect the size of the training set necessary for the algorithm to improve to depend on the level of temporal alignment of the two sides of the corpus. Indeed, the weaker the temporal supervision the more we need to endow the model so that it can select cleaner candidates in the early iterations. 4.3 Comparison of time sequence scoring functions We compared the performance of the DFT-based time sequence similarity scoring function we use in this paper to the commonly used cosine (Salton and McGill, 1986) and Pearson’s correlation measures. We perturbed the Russian side of the corpus in the following way. Articles from each day were randomly moved (with uniform probability) within a -day window. We ran single word NE temporal sequence matching alone on the perturbed corpora using each of the three measures (Table 1). Some accuracy drop due to misalignment could be accommodated for by using a larger temporal 822 Figure 5: Transliteration lists for forsyth for two iterations of the algorithm. As transliteration model improves, the correct transliteration moves up the list. bin for collecting occ</context>
</contexts>
<marker>Salton, McGill, 1986</marker>
<rawString>Gerard Salton and Michael J. McGill. 1986. Introduction to Modern Information Retrieval. McGrawHill, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Named entity discovery using comparable news articles.</title>
<date>2004</date>
<booktitle>In Proc. the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>848--853</pages>
<contexts>
<context position="8358" citStr="Shinyama and Sekine, 2004" startWordPosition="1346" endWordPosition="1349">th minimal supervision. Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora. However, they focus on the classification stage of already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language. The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new. (Hetland, 2004) surveys recent methods for scoring time sequences for similarity. (Shinyama and Sekine, 2004) used the idea to discover NEs, but in a single language, English, across two news sources. A large amount of previous work exists on transliteration models. Most are generative and consider the task of producing an appropriate transliteration for a given word, and thus require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models</context>
</contexts>
<marker>Shinyama, Sekine, 2004</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2004. Named entity discovery using comparable news articles. In Proc. the International Conference on Computational Linguistics (COLING), pages 848–853.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Michael Jordan</author>
</authors>
<title>Structured prediction via the extragradient method.</title>
<date>2005</date>
<booktitle>In The Conference on Advances in Neural Information Processing Systems (NIPS).</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9247" citStr="Taskar et al., 2005" startWordPosition="1485" endWordPosition="1488"> require considerable knowledge of the languages. For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and EnglishKorean generative transliteration models, respectively. (Knight and Graehl, 1997) build a generative model for backward transliteration from Japanese to English. While generative models are often robust, they tend to make independence assumptions that do not hold in data. The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005). We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language. We extend our preliminary work in (Klementiev and Roth, 2006) to discover multi-word Named Entities and to take advantage of a dictionary (if one exists) to handle NEs which are partially or entirely translated. We take advantage of dynamically growing feature space to reduce the number of supervised training examples. 3 Co-Ranking: An Algorithm for NE Discovery 3.1 The algorithm In essence, the algorithm we present uses temporal alignment as a supe</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Jordan, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien, and Michael Jordan. 2005. Structured prediction via the extragradient method. In The Conference on Advances in Neural Information Processing Systems (NIPS). MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>