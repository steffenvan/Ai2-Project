<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.097208">
<title confidence="0.99639">
Pre- and Postprocessing for Statistical Machine Translation into Germanic
Languages
</title>
<author confidence="0.996271">
Sara Stymne
</author>
<affiliation confidence="0.9827845">
Department of Computer and Information Science
Link¨oping University, Link¨oping, Sweden
</affiliation>
<email confidence="0.993735">
sara.stymne@liu.se
</email>
<sectionHeader confidence="0.993802" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999934666666667">
In this thesis proposal I present my thesis
work, about pre- and postprocessing for sta-
tistical machine translation, mainly into Ger-
manic languages. I focus my work on four ar-
eas: compounding, definite noun phrases, re-
ordering, and error correction. Initial results
are positive within all four areas, and there are
promising possibilities for extending these ap-
proaches. In addition I also focus on methods
for performing thorough error analysis of ma-
chine translation output, which can both moti-
vate and evaluate the studies performed.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935754385965">
Statistical machine translation (SMT) is based on
training statistical models from large corpora of hu-
man translations. It has the advantage that it is very
fast to train, if there are available corpora, compared
to rule-based systems, and SMT systems are often
relatively good at lexical disambiguation. A large
drawback of SMT systems is that they use no or lit-
tle grammatical knowledge, relying mainly on a tar-
get language model for producing correct target lan-
guage texts, often resulting in ungrammatical out-
put. Thus, methods to include some, possibly shal-
low, linguistic knowledge seem reasonable.
The main focus for SMT to date has been on
translation into English, for which the models work
relatively well, especially for source languages that
are structurally similar to English. There has been
less research on translation out of English, or be-
tween other language pairs. Methods that are useful
for translation into English have problems in many
cases, for instance for translation into morpholog-
ically rich languages. Word order differences and
morphological complexity of a language have been
shown to be explanatory variables for the perfor-
mance of phrase-based SMT systems (Birch et al.,
2008). German and the Scandinavian languages are
a good sample of languages, I believe, since they are
both more morphologically complex than English to
a varying degree, and the word order differ to some
extent, with mostly local differences between En-
glish and Scandinavian, and also long distance dif-
ferences with German, especially for verbs.
Some problems with SMT into German and
Swedish are exemplified in Table 1. In the Ger-
man example, the translation of the verb welcome
is missing in the SMT output. Missing and mis-
placed verbs are common error types, since the
German verb should appear last in the sentence
in this context, as in the reference, begr¨ußen.
There is also an idiomatic compound, redebeitrag
(speech+contribution; intervention) in the refer-
ence, which is produced as the single word beitrag in
the SMT output. In the Swedish example, there are
problems with a definite NP, which has the wrong
gender of the definite article, den instead of det, and
is missing a definite suffix on the noun syns¨att(et)
((the) approach).
In this proposal I outline my thesis work which
aims to improve statistical machine translation, par-
ticularly into Germanic languages, by using pre- and
postprocessing on one or both language sides, with
an additional focus on error analysis. In section 2 I
present a thesis overview, and in section 3 I briefly
overview MT evaluation techniques, and discuss my
work on MT error analysis. In section 4 I describe
my work on pre- and postprocessing, which is fo-
cused on compounding, definite noun phrases, word
order, and error correction.
</bodyText>
<page confidence="0.984747">
12
</page>
<note confidence="0.538619">
Proceedings of the ACL-HLT 2011 Student Session, pages 12–17,
</note>
<table confidence="0.9130905">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
En source I too would like to welcome Mr Prodi’s forceful and meaningful intervention.
De SMT Ich m¨ochte auch herrn Prodis energisch und sinnvollen Beitrag.
De reference Ich m¨ochte meinerseits auch den klaren und substanziellen Redebeitrag von Pr¨asident Prodi
begr¨ußen.
En source So much for the scientific approach.
Se SMT Simycket f¨or den vetenskapliga syns¨att.
Se reference Simycket f¨or den vetenskapliga infallsvinkeln.
</table>
<tableCaption confidence="0.999898">
Table 1: Examples of problematic PBSMT output
</tableCaption>
<sectionHeader confidence="0.89552" genericHeader="method">
2 Thesis Overview
</sectionHeader>
<bodyText confidence="0.999915122448979">
My main research focus is how pre- and postpro-
cessing can be used to improve statistical MT, with
a focus on translation into Germanic languages. The
idea behind preprocessing is to change the training
corpus on the source side and/or on the target side
in order to make them more similar, which makes
the SMT task easier, since the standard SMT mod-
els work better for more similar languages. Post-
processing is needed after the translation when the
target language has been preprocessed, in order to
restore it to the normal target language. Postpro-
cessing can also be used on standard MT output, in
order to correct some of the errors from the MT sys-
tem. I focus my work about pre- and postprocessing
on four areas: compounding, definite noun phrases,
word order, and error correction. In addition I am
making an effort into error analysis, to identify and
classify errors in the MT output, both in order to fo-
cus my research effort, and to evaluate and compare
systems.
My work is based on the phrase-based approach
to statistical machine translation (PBSMT, Koehn et
al. (2003)). I further use the framework of factored
machine translation, where each word is represented
as a vector of factors, such as surface word, lemma
and part-of-speech, rather than only as surface words
(Koehn and Hoang, 2007). I mostly utilize factors to
translate into both words and (morphological) part-
of-speech, and can then use an additional sequence
model based on part-of-speech, which potentially
can improve word order and agreement. I take ad-
vantage of available tools, such as the Moses toolkit
(Koehn et al., 2007) for factored phrase-based trans-
lation.
I have chosen to focus on PBSMT, which is a very
successful MT approach, and have received much
research focus. Other SMT approaches, such as hi-
erarchical and syntactical SMT (e.g. Chiang (2007),
Zhang et al. (2007a)) can potentially overcome some
language differences that are problematic for PB-
SMT, such as long-distance word order differences.
Many of these models have had good results, but
they have the drawback of being more complex than
PBSMT, and some methods do not scale well to
large corpora. While these models at least in princi-
ple address some of the drawbacks of the flat struc-
ture in PBSMT, Wang et al. (2010) showed that a
syntactic SMT system can still gain from prepro-
cessing such as parse-tree modification.
</bodyText>
<sectionHeader confidence="0.982305" genericHeader="method">
3 Evaluation and Error Analysis
</sectionHeader>
<bodyText confidence="0.999966125">
Machine translation systems are often only evalu-
ated quantitatively by using automatic metrics, such
as Bleu (Papineni et al., 2002), which compares the
system output to one or more human reference trans-
lations. While this type of evaluation has its advan-
tages, mainly that it is fast and cheap, its correla-
tion with human judgments is often low, especially
for translation out of English (Callison-Burch et al.,
2009). In order to overcome these problems to some
extent I use several metrics in my studies, instead of
only Bleu. Despite this, metrics only give a single
score per sentence batch and system, which even us-
ing several metrics gives us little information on the
particular problems with a system, or about what the
possible improvements are.
One alternative to automatic metrics is human
judgments, either absolute scores, for instance for
adequacy or fluency, or by ranking sentences or seg-
ments. Such evaluations are a valuable complement
to automatic metrics, but they are costly and time-
consuming, and while they are useful for comparing
systems they also fail to pinpoint specific problems.
I mainly take advantage of this type of evaluation as
part of participating with my research group in MT
</bodyText>
<page confidence="0.994505">
13
</page>
<bodyText confidence="0.999975107142857">
shared tasks with large evaluation campaigns such
as WMT (e.g. Callison-Burch et al. (2009)).
To overcome the limitation of quantitative evalu-
ations, I focus on error analysis (EA) of MT output
in my thesis. EA is the task of annotating and clas-
sifying the errors in MT output, which gives a qual-
itative view. It can be used to evaluate and compare
systems, but is also useful in order to focus the re-
search effort on common problems for the language
pair in question. There have been previous attempts
of describing typologies for EA for MT, but they are
not unproblematic. Vilar et al. (2006) suggested a ty-
pology with five main categories: missing, incorrect,
unknown, word order, and punctuation, which have
also been used by other researchers, mainly for eval-
uation. However, this typology is relatively shallow
and mixes classification of errors with causes of er-
rors. Farr´us et al. (2010) suggested a typology based
on linguistic categories, such as orthography and se-
mantics, but their descriptions of these categories
and their subcategories are not detailed. Thus, as
part of my research, I am in the progress of design-
ing a fine-grained typology and guidelines for EA.
I have also created a tool for performing MT error
analysis (Stymne, 2011a). Initial annotations have
helped to focus my research efforts, and will be dis-
cussed below. I also plan to use EA as one means of
evaluating my work on pre- and postprocessing.
</bodyText>
<sectionHeader confidence="0.969631" genericHeader="method">
4 Main Research Problems
</sectionHeader>
<bodyText confidence="0.997318333333333">
In this section I describe the four main problem ar-
eas I will focus on in my thesis project. I summarize
briefly previous work in each area, and outline my
own current and planned contributions. Sample re-
sults from the different studies are shown in Table
2.
</bodyText>
<subsectionHeader confidence="0.997646">
4.1 Compounding
</subsectionHeader>
<bodyText confidence="0.9999896875">
In most Germanic languages, compounds are writ-
ten without spaces or other word boundaries, which
makes them problematic for SMT, mainly due to
sparse data problems. The standard method for treat-
ing compounds for translation from Germanic lan-
guages is to split them in both the training data
and translation input (e.g. (Nießen and Ney, 2000;
Koehn and Knight, 2003; Popovi´c et al., 2006)).
Koehn and Knight (2003) also suggested a corpus-
based compound splitting method that has been
much used for SMT, where compounds are split
based on corpus frequencies of its parts.
If compounds are split for translation into Ger-
manic languages, the SMT system produces output
with split compounds, which need to be postpro-
cessed into full compounds. There has been very
little research into this problem. For this process to
be successful, it is important that the SMT system
produces the split compound parts in a correct word
order. To encourage this I have used a factored trans-
lation system that outputs parts-of-speech and uses a
sequence model on parts-of-speech. I extended the
part-of-speech tagset to use special part-of-speech
tags for split compound parts, which depend on the
head part-of-speech of the compound. For instance,
the Swedish noun p¨arontr¨ad (pear tree) would be
tagged as p¨aron|N-part tr¨ad|N when split. Using
this model the number of compound parts that were
produced in the wrong order was reduced drastically
compared to not using a part-of-speech sequence
model for translation into German (Stymne, 2009a).
I also designed an algorithm for the merging
task that uses these part-of-speech tags to merge
compounds only when the next part-of-speech tag
matches. This merging method outperforms reim-
plementations and variations of previous merging
suggestions (Popovi´c et al., 2006), and methods
adapted from morphology merging (Virpioja et al.,
2007) for translation into German (Stymne, 2009a).
It also has the advantage over previous merging
methods that it can produce novel compounds, while
at the same time reducing the risk of merging parts
into non-words. I have also shown that these com-
pound processing methods work equally well for
translation into Swedish (Stymne and Holmqvist,
2008). Currently I am working on methods for fur-
ther improving compound merging, with promising
initial results.
</bodyText>
<subsectionHeader confidence="0.972694">
4.2 Definite Noun Phrases
</subsectionHeader>
<bodyText confidence="0.999607714285714">
In Scandinavian languages there are two ways to
express definiteness in noun phrases, either by a
definite article, or by a suffix on the noun. This
leads to problems when translating into these lan-
guages, such as superfluous definite articles and
wrong forms of nouns. I am not aware of any
published research in this area, but an unpublished
</bodyText>
<page confidence="0.994538">
14
</page>
<table confidence="0.999058526315789">
Language pair Corpus Corpus size Testset size In article System Bleu NIST
Stymne (2008) BL 19.31 5.727
En-De Europarl 439,513 2,000
+Comp 19.73 5.854
Stymne and BL 21.63 6.109
En-Se Europarl 701,157 2,000
Holmqvist (2008) +Comp 22.12 6.143
Stymne (2009b) BL 70.91 8.816
En-Da Automotive 168,046 1,000
+Def 76.35 9.363
Stymne (2011b) BL 21.63 6.109
En-Se Europarl 701,157 1,000
+Def 22.03 6.178
Stymne (2011c) BL 19.32 5.901
En-De Europarl 439,513 2,000
+Reo 19.59 5.936
Stymne and BL 19.44 5.381
En-Se Europarl 701,157 335
Ahrenberg (2010) +EC 22.12 5.447
</table>
<tableCaption confidence="0.9499165">
Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of
sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with
iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set
for error correction only contains sentences that are affected by the error correction.
</tableCaption>
<bodyText confidence="0.999927653846154">
report shows no gain for a simple pre-processing
strategy for translation from German to Swedish
(Samuelsson, 2006). There is similar work on other
phenomena, such as Nießen and Ney (2000), who
move German separated verb prefixes, to imitate the
English phrasal verb structure.
I address definiteness by preprocessing the source
language, to make definite NPs structurally simi-
lar to target language NPs. The transformations
are rule-based, using part-of-speech tags. Definite
NPs in Scandinavian languages are mimicked in the
source language by removing superfluous definite
articles, and/or adding definite suffixes to nouns. In
an initial study, this gave very good results, with rel-
ative Bleu improvements of up to 22.1% for trans-
lation into Danish (Stymne, 2009b). In Swedish
and Norwegian, the distribution of definite suffixes
is more complex than in Danish, and the basic strat-
egy that worked well for Danish was not successful
(Stymne, 2011b). A small modification to the ba-
sic strategy, so that superfluous English articles were
removed, but no suffixes were added, was success-
ful for translation from English into Swedish and
Norwegian. A planned extension is to integrate the
transformations into a lattice that is fed to the de-
coder, in the spirit of (Dyer et al., 2008).
</bodyText>
<subsectionHeader confidence="0.999591">
4.3 Word Order
</subsectionHeader>
<bodyText confidence="0.999946483870968">
There has been a lot of research on how to handle
word order differences between languages. Prepro-
cessing approaches can use either hand-written rules
targeting known language differences (e.g. Collins
et al. (2005), Li et al. (2009)), or automatically learnt
rules (e.g. Xia and McCord (2004), Zhang et al.
(2007b)), which are basically language independent.
I have performed an initial study on a language
independent word order strategy where reordering
rule learning and word alignment are performed iter-
atively, since they both depend on the other process
(Stymne, 2011c). There were no overall improve-
ments as measured by Bleu, but an investigation of
the reordering rules showed that the rules learned
in the different iterations are different with regard
to the linguistic phenomena they handle, indicating
that it is possible to learn new information from iter-
ating rule learning and word alignment. In this study
I only choose the 1-best reordering as input to the
SMT system. I plan to extend this by presenting sev-
eral reorderings to the decoder as a lattice, which has
been successful in previous work (see e.g. Zhang et
al. (2007b)).
My preliminary error analysis has shown that
there are two main word order difficulties for trans-
lation between English and Swedish, adverb place-
ment, and V2 errors, where the verb is not placed
in the correct position when it should be placed
before the subject. I plan to design a preprocess-
ing scheme to tackle these particular problems for
English-Swedish translation.
</bodyText>
<page confidence="0.994129">
15
</page>
<subsectionHeader confidence="0.876476">
4.4 Error Correction
</subsectionHeader>
<bodyText confidence="0.9998685">
Postprocessing can be used to correct MT output
that has not been preprocessed, for instance in or-
der to improve the grammaticality. There has not
been much research in this area. A few examples
are Elming (2006), who use transformation-based
learning for word substitution based on aligned hu-
man post-edited sentences, and Guzm´an (2007) who
used regular expression to correct regular Spanish
errors. I have applied error correction suggestions
given by a grammar checker to the MT output, show-
ing that it can improve certain types of errors, such
as NP agreement and word order, with a high pre-
cision, but unfortunately with a low recall (Stymne
and Ahrenberg, 2010). Since the recall is low, the
positive effect on metrics such as Bleu is small on
general test sets, but there are improvements on test
sets which only contains sentences that are affected
by the postprocessing. An error analysis showed that
68–74% of the corrections made were useful, and
only around 10% of the changes made were harm-
ful. I believe that this approach could be even more
useful for similar languages, such as Danish and
Swedish, where a spell-checker might also be use-
ful.
The initial error analysis I have performed has
helped to identify common errors in SMT output,
and shown that many of them are quite regular. A
strategy I intend to pursue is to further identify com-
mon and regular problems, and to either construct
rules or to train a machine learning classifier to iden-
tify them, in order to be able to postprocess them. It
might also be possible to use the annotations from
the error analysis as part of the training data for such
a classifier.
</bodyText>
<sectionHeader confidence="0.998117" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999984088235294">
The main focus of my thesis will be on designing
and evaluating methods for pre- and postprocess-
ing of statistical MT, where I will contribute meth-
ods that can improve translation within the four ar-
eas discussed in section 4. The effort is focused
on translation into Germanic languages, including
German, on which there has been much previous
research, and Swedish and other Scandinavian lan-
guages, where there has been little previous re-
search. I believe that both language-pair dependent
and independent methods for pre- and postprocess-
ing can be useful. It is also the case that some
language-pair dependent methods carry over to other
(similar) language pairs with no or little modifica-
tion. So far I have mostly used rule-based process-
ing, but I plan to extend this with investigating ma-
chine learning methods, and compare the two main
approaches.
I strongly believe that it is important for MT re-
searchers to perform qualitative evaluations, both for
identifying problems with MT systems, and for eval-
uating and comparing systems. In my experience it
is often the case that a change to the system to im-
prove one aspect, such as compounding, also leads
to many other changes, in the case of compounding
for instance because of the possibility of improved
alignments, which I think we lack a proper under-
standing of.
My planned thesis contributions are to design a
detailed error typology, guidelines, and a tool, tar-
geted at MT researchers, for performing error anno-
tation, and to improve statistical machine translation
in four problem areas, using several methods of pre-
and postprocessing.
</bodyText>
<sectionHeader confidence="0.998183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999139333333333">
Alexandra Birch, Miles Osborne, and Philipp Koehn.
2008. Predicting success in machine translation. In
Proceedings of EMNLP, pages 745–754, Honolulu,
Hawaii, USA.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In Pro-
ceedings of WMT, pages 1–28, Athens, Greece.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):202–228.
Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a.
2005. Clause restructuring for statistical machine
translation. In Proceedings of ACL, pages 531–540,
Ann Arbor, Michigan, USA.
Christopher Dyer, Smaranda Muresan, and Philip Resnik.
2008. Generalizing word lattice translation. In Pro-
ceedings of ACL, pages 1012–1020, Columbus, Ohio,
USA.
Jakob Elming. 2006. Transformation-based correction
of rule-based MT. In Proceedings of EAMT, pages
219–226, Oslo, Norway.
Mireia Farr´us, Marta R. Costa-juss`a, Jos´e B. Mari˜no, and
Jos´e A. R. Fonollosa. 2010. Linguistic-based evalu-
ation criteria to identify statistical machine translation
</reference>
<page confidence="0.988288">
16
</page>
<reference confidence="0.999845029411765">
errors. In Proceedings of EAMT, pages 52–57, Saint
Rapha¨el, France.
Rafael Guzm´an. 2007. Advanced automatic MT
post-editing using regular expressions. Multilingual,
18(6):49–52.
Philipp Koehn and Hieu Hoang. 2007. Factored transla-
tion models. In Proceedings of EMNLP/CoNLL, pages
868–876, Prague, Czech Republic.
Philipp Koehn and Kevin Knight. 2003. Empirical meth-
ods for compound splitting. In Proceedings of EACL,
pages 187–193, Budapest, Hungary.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of NAACL, pages 48–54, Edmonton, Alberta,
Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of ACL, demonstration session, pages 177–180,
Prague, Czech Republic.
Jin-Ji Li, Jungi Kim, Dong-Il Kim, and Jong-Hyeok
Lee. 2009. Chinese syntactic reordering for ade-
quate generation of Korean verbal phrases in Chinese-
to-Korean SMT. In Proceedings of WMT, pages 190–
196, Athens, Greece.
Sonja Nießen and Hermann Ney. 2000. Improving SMT
quality with morpho-syntactic analysis. In Proceed-
ings of CoLing, pages 1081–1085, Saarbr¨ucken, Ger-
many.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic eval-
uation of machine translation. In Proceedings of ACL,
pages 311–318, Philadelphia, Pennsylvania, USA.
Maja Popovi´c, Daniel Stein, and Hermann Ney. 2006.
Statistical machine translation of German compound
words. In Proceedings of FinTAL – 5th International
Conference on Natural Language Processing, pages
616–624, Turku, Finland. Springer Verlag, LNCS.
Yvonne Samuelsson. 2006. Nouns in statistical ma-
chine translation. Unpublished manuscript: Term pa-
per, Statistical Machine Translation.
Sara Stymne and Lars Ahrenberg. 2010. Using a gram-
mar checker for evaluation and postprocessing of sta-
tistical machine translation. In Proceedings of LREC,
pages 2175–2181, Valetta, Malta.
Sara Stymne and Maria Holmqvist. 2008. Processing of
Swedish compounds for phrase-based statistical ma-
chine translation. In Proceedings of EAMT, pages
180–189, Hamburg, Germany.
Sara Stymne. 2008. German compounds in factored sta-
tistical machine translation. In Proceedings of Go-
TAL – 6th International Conference on Natural Lan-
guage Processing, pages 464–475, Gothenburg, Swe-
den. Springer Verlag, LNCS/LNAI.
Sara Stymne. 2009a. A comparison of merging strategies
for translation of German compounds. In Proceedings
of EACL, Student Research Workshop, pages 61–69,
Athens, Greece.
Sara Stymne. 2009b. Definite noun phrases in statistical
machine translation into Danish. In Proceedings of the
Workshop on Extracting and Using Constructions in
NLP, pages 4–9, Odense, Denmark.
Sara Stymne. 2011a. Blast: A tool for error analysis of
machine translation output. In Proceedings of ACL,
demonstration session, Portland, Oregon, USA.
Sara Stymne. 2011b. Definite noun phrases in statistical
machine translation into Scandinavian languages. In
Proceedings of EAMT, Leuven, Belgium.
Sara Stymne. 2011c. Iterative reordering and word
alignment for statistical MT. In Proceedings of the
18th Nordic Conference on Computational Linguis-
tics, Riga, Latvia.
David Vilar, Jia Xu, Luis Fernando D’Haro, and Her-
mann Ney. 2006. Error analysis of machine transla-
tion output. In Proceedings of LREC, pages 697–702,
Genoa, Italy.
Sami Virpioja, Jaako J. V¨ayrynen, Mathias Creutz, and
Markus Sadeniemi. 2007. Morphology-aware statis-
tical machine translation based on morphs induced in
an unsupervised manner. In Proceedings of MT Sum-
mit XI, pages 491–498, Copenhagen, Denmark.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, re-labeling, and re-
aligning for syntax-based machine translation. Com-
putational Linguistics, 36(2):247–277.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical MT system with automatically learned rewrite
patterns. In Proceedings of CoLing, pages 508–514,
Geneva, Switzerland.
Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, Sheng Li,
and Chew Lim Tan. 2007a. A tree-to-tree alignment-
based model for statistical machine translation. In
Proceedings of MT Summit XI, pages 535–542, Copen-
hagen, Denmark.
Yuqi Zhang, Richard Zens, and Hermann Ney. 2007b.
Improved chunk-level reordering for statistical ma-
chine translation. In Proceedings of the International
Workshop on Spoken Language Translation, pages 21–
28, Trento, Italy.
</reference>
<page confidence="0.999411">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898632">
<title confidence="0.9983575">Preand Postprocessing for Statistical Machine Translation into Germanic Languages</title>
<author confidence="0.992822">Sara</author>
<affiliation confidence="0.9992495">Department of Computer and Information Link¨oping University, Link¨oping,</affiliation>
<email confidence="0.971067">sara.stymne@liu.se</email>
<abstract confidence="0.995004538461538">In this thesis proposal I present my thesis work, about preand postprocessing for statistical machine translation, mainly into Germanic languages. I focus my work on four areas: compounding, definite noun phrases, reordering, and error correction. Initial results are positive within all four areas, and there are promising possibilities for extending these approaches. In addition I also focus on methods for performing thorough error analysis of machine translation output, which can both motivate and evaluate the studies performed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
<author>Philipp Koehn</author>
</authors>
<title>Predicting success in machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>745--754</pages>
<location>Honolulu, Hawaii, USA.</location>
<contexts>
<context position="1976" citStr="Birch et al., 2008" startWordPosition="299" endWordPosition="302">m reasonable. The main focus for SMT to date has been on translation into English, for which the models work relatively well, especially for source languages that are structurally similar to English. There has been less research on translation out of English, or between other language pairs. Methods that are useful for translation into English have problems in many cases, for instance for translation into morphologically rich languages. Word order differences and morphological complexity of a language have been shown to be explanatory variables for the performance of phrase-based SMT systems (Birch et al., 2008). German and the Scandinavian languages are a good sample of languages, I believe, since they are both more morphologically complex than English to a varying degree, and the word order differ to some extent, with mostly local differences between English and Scandinavian, and also long distance differences with German, especially for verbs. Some problems with SMT into German and Swedish are exemplified in Table 1. In the German example, the translation of the verb welcome is missing in the SMT output. Missing and misplaced verbs are common error types, since the German verb should appear last i</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2008</marker>
<rawString>Alexandra Birch, Miles Osborne, and Philipp Koehn. 2008. Predicting success in machine translation. In Proceedings of EMNLP, pages 745–754, Honolulu, Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<date>2009</date>
<booktitle>Findings of the 2009 Workshop on Statistical Machine Translation. In Proceedings of WMT,</booktitle>
<pages>1--28</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="7025" citStr="Callison-Burch et al., 2009" startWordPosition="1126" endWordPosition="1129">ss some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are often only evaluated quantitatively by using automatic metrics, such as Bleu (Papineni et al., 2002), which compares the system output to one or more human reference translations. While this type of evaluation has its advantages, mainly that it is fast and cheap, its correlation with human judgments is often low, especially for translation out of English (Callison-Burch et al., 2009). In order to overcome these problems to some extent I use several metrics in my studies, instead of only Bleu. Despite this, metrics only give a single score per sentence batch and system, which even using several metrics gives us little information on the particular problems with a system, or about what the possible improvements are. One alternative to automatic metrics is human judgments, either absolute scores, for instance for adequacy or fluency, or by ranking sentences or segments. Such evaluations are a valuable complement to automatic metrics, but they are costly and timeconsuming, an</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Schroeder, 2009</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, and Josh Schroeder. 2009. Findings of the 2009 Workshop on Statistical Machine Translation. In Proceedings of WMT, pages 1–28, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="6040" citStr="Chiang (2007)" startWordPosition="964" endWordPosition="965"> and part-of-speech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are o</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):202–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>531--540</pages>
<location>Ann Arbor, Michigan, USA.</location>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In Proceedings of ACL, pages 531–540, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
<author>Smaranda Muresan</author>
<author>Philip Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1012--1020</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="14522" citStr="Dyer et al., 2008" startWordPosition="2339" endWordPosition="2342">ood results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent. I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iteratively, since they both depend on the other process (Stymne, 2011c). There</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008. Generalizing word lattice translation. In Proceedings of ACL, pages 1012–1020, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Elming</author>
</authors>
<title>Transformation-based correction of rule-based MT.</title>
<date>2006</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<pages>219--226</pages>
<location>Oslo,</location>
<contexts>
<context position="16296" citStr="Elming (2006)" startWordPosition="2632" endWordPosition="2633">)). My preliminary error analysis has shown that there are two main word order difficulties for translation between English and Swedish, adverb placement, and V2 errors, where the verb is not placed in the correct position when it should be placed before the subject. I plan to design a preprocessing scheme to tackle these particular problems for English-Swedish translation. 15 4.4 Error Correction Postprocessing can be used to correct MT output that has not been preprocessed, for instance in order to improve the grammaticality. There has not been much research in this area. A few examples are Elming (2006), who use transformation-based learning for word substitution based on aligned human post-edited sentences, and Guzm´an (2007) who used regular expression to correct regular Spanish errors. I have applied error correction suggestions given by a grammar checker to the MT output, showing that it can improve certain types of errors, such as NP agreement and word order, with a high precision, but unfortunately with a low recall (Stymne and Ahrenberg, 2010). Since the recall is low, the positive effect on metrics such as Bleu is small on general test sets, but there are improvements on test sets wh</context>
</contexts>
<marker>Elming, 2006</marker>
<rawString>Jakob Elming. 2006. Transformation-based correction of rule-based MT. In Proceedings of EAMT, pages 219–226, Oslo, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mireia Farr´us</author>
<author>Marta R Costa-juss`a</author>
<author>Jos´e B Mari˜no</author>
<author>Jos´e A R Fonollosa</author>
</authors>
<title>Linguistic-based evaluation criteria to identify statistical machine translation errors.</title>
<date>2010</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<pages>52--57</pages>
<location>Saint Rapha¨el, France.</location>
<marker>Farr´us, Costa-juss`a, Mari˜no, Fonollosa, 2010</marker>
<rawString>Mireia Farr´us, Marta R. Costa-juss`a, Jos´e B. Mari˜no, and Jos´e A. R. Fonollosa. 2010. Linguistic-based evaluation criteria to identify statistical machine translation errors. In Proceedings of EAMT, pages 52–57, Saint Rapha¨el, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafael Guzm´an</author>
</authors>
<title>Advanced automatic MT post-editing using regular expressions.</title>
<date>2007</date>
<journal>Multilingual,</journal>
<volume>18</volume>
<issue>6</issue>
<marker>Guzm´an, 2007</marker>
<rawString>Rafael Guzm´an. 2007. Advanced automatic MT post-editing using regular expressions. Multilingual, 18(6):49–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP/CoNLL,</booktitle>
<pages>868--876</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5505" citStr="Koehn and Hoang, 2007" startWordPosition="876" endWordPosition="879"> and postprocessing on four areas: compounding, definite noun phrases, word order, and error correction. In addition I am making an effort into error analysis, to identify and classify errors in the MT output, both in order to focus my research effort, and to evaluate and compare systems. My work is based on the phrase-based approach to statistical machine translation (PBSMT, Koehn et al. (2003)). I further use the framework of factored machine translation, where each word is represented as a vector of factors, such as surface word, lemma and part-of-speech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language di</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of EMNLP/CoNLL, pages 868–876, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>187--193</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="9923" citStr="Koehn and Knight, 2003" startWordPosition="1614" endWordPosition="1617"> describe the four main problem areas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample results from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are written without spaces or other word boundaries, which makes them problematic for SMT, mainly due to sparse data problems. The standard method for treating compounds for translation from Germanic languages is to split them in both the training data and translation input (e.g. (Nießen and Ney, 2000; Koehn and Knight, 2003; Popovi´c et al., 2006)). Koehn and Knight (2003) also suggested a corpusbased compound splitting method that has been much used for SMT, where compounds are split based on corpus frequencies of its parts. If compounds are split for translation into Germanic languages, the SMT system produces output with split compounds, which need to be postprocessed into full compounds. There has been very little research into this problem. For this process to be successful, it is important that the SMT system produces the split compound parts in a correct word order. To encourage this I have used a factore</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical methods for compound splitting. In Proceedings of EACL, pages 187–193, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>48--54</pages>
<location>Edmonton, Alberta, Canada.</location>
<contexts>
<context position="5281" citStr="Koehn et al. (2003)" startWordPosition="840" endWordPosition="843">age has been preprocessed, in order to restore it to the normal target language. Postprocessing can also be used on standard MT output, in order to correct some of the errors from the MT system. I focus my work about pre- and postprocessing on four areas: compounding, definite noun phrases, word order, and error correction. In addition I am making an effort into error analysis, to identify and classify errors in the MT output, both in order to focus my research effort, and to evaluate and compare systems. My work is based on the phrase-based approach to statistical machine translation (PBSMT, Koehn et al. (2003)). I further use the framework of factored machine translation, where each word is represented as a vector of factors, such as surface word, lemma and part-of-speech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, wh</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of NAACL, pages 48–54, Edmonton, Alberta, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL, demonstration session,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="5806" citStr="Koehn et al., 2007" startWordPosition="924" endWordPosition="927">ed on the phrase-based approach to statistical machine translation (PBSMT, Koehn et al. (2003)). I further use the framework of factored machine translation, where each word is represented as a vector of factors, such as surface word, lemma and part-of-speech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some o</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL, demonstration session, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Ji Li</author>
<author>Jungi Kim</author>
<author>Dong-Il Kim</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Chinese syntactic reordering for adequate generation of Korean verbal phrases in Chineseto-Korean SMT.</title>
<date>2009</date>
<booktitle>In Proceedings of WMT,</booktitle>
<pages>190--196</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="14772" citStr="Li et al. (2009)" startWordPosition="2379" endWordPosition="2382">was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent. I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iteratively, since they both depend on the other process (Stymne, 2011c). There were no overall improvements as measured by Bleu, but an investigation of the reordering rules showed that the rules learned in the different iterations are different with regard to the linguistic phenomena they handle, indicating that it is possibl</context>
</contexts>
<marker>Li, Kim, Kim, Lee, 2009</marker>
<rawString>Jin-Ji Li, Jungi Kim, Dong-Il Kim, and Jong-Hyeok Lee. 2009. Chinese syntactic reordering for adequate generation of Korean verbal phrases in Chineseto-Korean SMT. In Proceedings of WMT, pages 190– 196, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonja Nießen</author>
<author>Hermann Ney</author>
</authors>
<title>Improving SMT quality with morpho-syntactic analysis.</title>
<date>2000</date>
<booktitle>In Proceedings of CoLing,</booktitle>
<pages>1081--1085</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="9899" citStr="Nießen and Ney, 2000" startWordPosition="1610" endWordPosition="1613">lems In this section I describe the four main problem areas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample results from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are written without spaces or other word boundaries, which makes them problematic for SMT, mainly due to sparse data problems. The standard method for treating compounds for translation from Germanic languages is to split them in both the training data and translation input (e.g. (Nießen and Ney, 2000; Koehn and Knight, 2003; Popovi´c et al., 2006)). Koehn and Knight (2003) also suggested a corpusbased compound splitting method that has been much used for SMT, where compounds are split based on corpus frequencies of its parts. If compounds are split for translation into Germanic languages, the SMT system produces output with split compounds, which need to be postprocessed into full compounds. There has been very little research into this problem. For this process to be successful, it is important that the SMT system produces the split compound parts in a correct word order. To encourage th</context>
<context position="13427" citStr="Nießen and Ney (2000)" startWordPosition="2166" endWordPosition="2169">5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set for error correction only contains sentences that are affected by the error correction. report shows no gain for a simple pre-processing strategy for translation from German to Swedish (Samuelsson, 2006). There is similar work on other phenomena, such as Nießen and Ney (2000), who move German separated verb prefixes, to imitate the English phrasal verb structure. I address definiteness by preprocessing the source language, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Nor</context>
</contexts>
<marker>Nießen, Ney, 2000</marker>
<rawString>Sonja Nießen and Hermann Ney. 2000. Improving SMT quality with morpho-syntactic analysis. In Proceedings of CoLing, pages 1081–1085, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania, USA.</location>
<contexts>
<context position="6739" citStr="Papineni et al., 2002" startWordPosition="1078" endWordPosition="1081">at are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are often only evaluated quantitatively by using automatic metrics, such as Bleu (Papineni et al., 2002), which compares the system output to one or more human reference translations. While this type of evaluation has its advantages, mainly that it is fast and cheap, its correlation with human judgments is often low, especially for translation out of English (Callison-Burch et al., 2009). In order to overcome these problems to some extent I use several metrics in my studies, instead of only Bleu. Despite this, metrics only give a single score per sentence batch and system, which even using several metrics gives us little information on the particular problems with a system, or about what the pos</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of ACL, pages 311–318, Philadelphia, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maja Popovi´c</author>
<author>Daniel Stein</author>
<author>Hermann Ney</author>
</authors>
<title>Statistical machine translation of German compound words.</title>
<date>2006</date>
<booktitle>In Proceedings of FinTAL – 5th International Conference on Natural Language Processing,</booktitle>
<pages>616--624</pages>
<publisher>Springer Verlag, LNCS.</publisher>
<location>Turku, Finland.</location>
<marker>Popovi´c, Stein, Ney, 2006</marker>
<rawString>Maja Popovi´c, Daniel Stein, and Hermann Ney. 2006. Statistical machine translation of German compound words. In Proceedings of FinTAL – 5th International Conference on Natural Language Processing, pages 616–624, Turku, Finland. Springer Verlag, LNCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yvonne Samuelsson</author>
</authors>
<title>Nouns in statistical machine translation. Unpublished manuscript: Term paper, Statistical Machine Translation.</title>
<date>2006</date>
<contexts>
<context position="13354" citStr="Samuelsson, 2006" startWordPosition="2155" endWordPosition="2156">BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set for error correction only contains sentences that are affected by the error correction. report shows no gain for a simple pre-processing strategy for translation from German to Swedish (Samuelsson, 2006). There is similar work on other phenomena, such as Nießen and Ney (2000), who move German separated verb prefixes, to imitate the English phrasal verb structure. I address definiteness by preprocessing the source language, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up</context>
</contexts>
<marker>Samuelsson, 2006</marker>
<rawString>Yvonne Samuelsson. 2006. Nouns in statistical machine translation. Unpublished manuscript: Term paper, Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>Lars Ahrenberg</author>
</authors>
<title>Using a grammar checker for evaluation and postprocessing of statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>2175--2181</pages>
<location>Valetta,</location>
<contexts>
<context position="16752" citStr="Stymne and Ahrenberg, 2010" startWordPosition="2703" endWordPosition="2706">output that has not been preprocessed, for instance in order to improve the grammaticality. There has not been much research in this area. A few examples are Elming (2006), who use transformation-based learning for word substitution based on aligned human post-edited sentences, and Guzm´an (2007) who used regular expression to correct regular Spanish errors. I have applied error correction suggestions given by a grammar checker to the MT output, showing that it can improve certain types of errors, such as NP agreement and word order, with a high precision, but unfortunately with a low recall (Stymne and Ahrenberg, 2010). Since the recall is low, the positive effect on metrics such as Bleu is small on general test sets, but there are improvements on test sets which only contains sentences that are affected by the postprocessing. An error analysis showed that 68–74% of the corrections made were useful, and only around 10% of the changes made were harmful. I believe that this approach could be even more useful for similar languages, such as Danish and Swedish, where a spell-checker might also be useful. The initial error analysis I have performed has helped to identify common errors in SMT output, and shown tha</context>
</contexts>
<marker>Stymne, Ahrenberg, 2010</marker>
<rawString>Sara Stymne and Lars Ahrenberg. 2010. Using a grammar checker for evaluation and postprocessing of statistical machine translation. In Proceedings of LREC, pages 2175–2181, Valetta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>Maria Holmqvist</author>
</authors>
<title>Processing of Swedish compounds for phrase-based statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<pages>180--189</pages>
<location>Hamburg, Germany.</location>
<contexts>
<context position="11775" citStr="Stymne and Holmqvist, 2008" startWordPosition="1904" endWordPosition="1907"> these part-of-speech tags to merge compounds only when the next part-of-speech tag matches. This merging method outperforms reimplementations and variations of previous merging suggestions (Popovi´c et al., 2006), and methods adapted from morphology merging (Virpioja et al., 2007) for translation into German (Stymne, 2009a). It also has the advantage over previous merging methods that it can produce novel compounds, while at the same time reducing the risk of merging parts into non-words. I have also shown that these compound processing methods work equally well for translation into Swedish (Stymne and Holmqvist, 2008). Currently I am working on methods for further improving compound merging, with promising initial results. 4.2 Definite Noun Phrases In Scandinavian languages there are two ways to express definiteness in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 4</context>
</contexts>
<marker>Stymne, Holmqvist, 2008</marker>
<rawString>Sara Stymne and Maria Holmqvist. 2008. Processing of Swedish compounds for phrase-based statistical machine translation. In Proceedings of EAMT, pages 180–189, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>German compounds in factored statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of GoTAL – 6th International Conference on Natural Language Processing,</booktitle>
<pages>464--475</pages>
<publisher>Springer Verlag, LNCS/LNAI.</publisher>
<location>Gothenburg,</location>
<contexts>
<context position="12343" citStr="Stymne (2008)" startWordPosition="2000" endWordPosition="2001">ion into Swedish (Stymne and Holmqvist, 2008). Currently I am working on methods for further improving compound merging, with promising initial results. 4.2 Definite Noun Phrases In Scandinavian languages there are two ways to express definiteness in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL </context>
</contexts>
<marker>Stymne, 2008</marker>
<rawString>Sara Stymne. 2008. German compounds in factored statistical machine translation. In Proceedings of GoTAL – 6th International Conference on Natural Language Processing, pages 464–475, Gothenburg, Sweden. Springer Verlag, LNCS/LNAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>A comparison of merging strategies for translation of German compounds.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL, Student Research Workshop,</booktitle>
<pages>61--69</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="11085" citStr="Stymne, 2009" startWordPosition="1801" endWordPosition="1802">ord order. To encourage this I have used a factored translation system that outputs parts-of-speech and uses a sequence model on parts-of-speech. I extended the part-of-speech tagset to use special part-of-speech tags for split compound parts, which depend on the head part-of-speech of the compound. For instance, the Swedish noun p¨arontr¨ad (pear tree) would be tagged as p¨aron|N-part tr¨ad|N when split. Using this model the number of compound parts that were produced in the wrong order was reduced drastically compared to not using a part-of-speech sequence model for translation into German (Stymne, 2009a). I also designed an algorithm for the merging task that uses these part-of-speech tags to merge compounds only when the next part-of-speech tag matches. This merging method outperforms reimplementations and variations of previous merging suggestions (Popovi´c et al., 2006), and methods adapted from morphology merging (Virpioja et al., 2007) for translation into German (Stymne, 2009a). It also has the advantage over previous merging methods that it can produce novel compounds, while at the same time reducing the risk of merging parts into non-words. I have also shown that these compound proc</context>
<context position="12508" citStr="Stymne (2009" startWordPosition="2026" endWordPosition="2027">Noun Phrases In Scandinavian languages there are two ways to express definiteness in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with gram</context>
<context position="14005" citStr="Stymne, 2009" startWordPosition="2254" endWordPosition="2255">ena, such as Nießen and Ney (2000), who move German separated verb prefixes, to imitate the English phrasal verb structure. I address definiteness by preprocessing the source language, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order diffe</context>
</contexts>
<marker>Stymne, 2009</marker>
<rawString>Sara Stymne. 2009a. A comparison of merging strategies for translation of German compounds. In Proceedings of EACL, Student Research Workshop, pages 61–69, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>Definite noun phrases in statistical machine translation into Danish.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Extracting and Using Constructions in NLP,</booktitle>
<pages>4--9</pages>
<location>Odense, Denmark.</location>
<contexts>
<context position="11085" citStr="Stymne, 2009" startWordPosition="1801" endWordPosition="1802">ord order. To encourage this I have used a factored translation system that outputs parts-of-speech and uses a sequence model on parts-of-speech. I extended the part-of-speech tagset to use special part-of-speech tags for split compound parts, which depend on the head part-of-speech of the compound. For instance, the Swedish noun p¨arontr¨ad (pear tree) would be tagged as p¨aron|N-part tr¨ad|N when split. Using this model the number of compound parts that were produced in the wrong order was reduced drastically compared to not using a part-of-speech sequence model for translation into German (Stymne, 2009a). I also designed an algorithm for the merging task that uses these part-of-speech tags to merge compounds only when the next part-of-speech tag matches. This merging method outperforms reimplementations and variations of previous merging suggestions (Popovi´c et al., 2006), and methods adapted from morphology merging (Virpioja et al., 2007) for translation into German (Stymne, 2009a). It also has the advantage over previous merging methods that it can produce novel compounds, while at the same time reducing the risk of merging parts into non-words. I have also shown that these compound proc</context>
<context position="12508" citStr="Stymne (2009" startWordPosition="2026" endWordPosition="2027">Noun Phrases In Scandinavian languages there are two ways to express definiteness in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with gram</context>
<context position="14005" citStr="Stymne, 2009" startWordPosition="2254" endWordPosition="2255">ena, such as Nießen and Ney (2000), who move German separated verb prefixes, to imitate the English phrasal verb structure. I address definiteness by preprocessing the source language, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order diffe</context>
</contexts>
<marker>Stymne, 2009</marker>
<rawString>Sara Stymne. 2009b. Definite noun phrases in statistical machine translation into Danish. In Proceedings of the Workshop on Extracting and Using Constructions in NLP, pages 4–9, Odense, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>Blast: A tool for error analysis of machine translation output.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL, demonstration session,</booktitle>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="9079" citStr="Stymne, 2011" startWordPosition="1471" endWordPosition="1472"> missing, incorrect, unknown, word order, and punctuation, which have also been used by other researchers, mainly for evaluation. However, this typology is relatively shallow and mixes classification of errors with causes of errors. Farr´us et al. (2010) suggested a typology based on linguistic categories, such as orthography and semantics, but their descriptions of these categories and their subcategories are not detailed. Thus, as part of my research, I am in the progress of designing a fine-grained typology and guidelines for EA. I have also created a tool for performing MT error analysis (Stymne, 2011a). Initial annotations have helped to focus my research efforts, and will be discussed below. I also plan to use EA as one means of evaluating my work on pre- and postprocessing. 4 Main Research Problems In this section I describe the four main problem areas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample results from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are written without spaces or other word boundaries, which makes them problematic </context>
<context position="12586" citStr="Stymne (2011" startWordPosition="2038" endWordPosition="2039">ess in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set for error correction only contains </context>
<context position="14188" citStr="Stymne, 2011" startWordPosition="2284" endWordPosition="2285">, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatica</context>
</contexts>
<marker>Stymne, 2011</marker>
<rawString>Sara Stymne. 2011a. Blast: A tool for error analysis of machine translation output. In Proceedings of ACL, demonstration session, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>Definite noun phrases in statistical machine translation into Scandinavian languages.</title>
<date>2011</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Leuven, Belgium.</location>
<contexts>
<context position="9079" citStr="Stymne, 2011" startWordPosition="1471" endWordPosition="1472"> missing, incorrect, unknown, word order, and punctuation, which have also been used by other researchers, mainly for evaluation. However, this typology is relatively shallow and mixes classification of errors with causes of errors. Farr´us et al. (2010) suggested a typology based on linguistic categories, such as orthography and semantics, but their descriptions of these categories and their subcategories are not detailed. Thus, as part of my research, I am in the progress of designing a fine-grained typology and guidelines for EA. I have also created a tool for performing MT error analysis (Stymne, 2011a). Initial annotations have helped to focus my research efforts, and will be discussed below. I also plan to use EA as one means of evaluating my work on pre- and postprocessing. 4 Main Research Problems In this section I describe the four main problem areas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample results from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are written without spaces or other word boundaries, which makes them problematic </context>
<context position="12586" citStr="Stymne (2011" startWordPosition="2038" endWordPosition="2039">ess in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set for error correction only contains </context>
<context position="14188" citStr="Stymne, 2011" startWordPosition="2284" endWordPosition="2285">, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatica</context>
</contexts>
<marker>Stymne, 2011</marker>
<rawString>Sara Stymne. 2011b. Definite noun phrases in statistical machine translation into Scandinavian languages. In Proceedings of EAMT, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>Iterative reordering and word alignment for statistical MT.</title>
<date>2011</date>
<booktitle>In Proceedings of the 18th Nordic Conference on Computational Linguistics,</booktitle>
<location>Riga, Latvia.</location>
<contexts>
<context position="9079" citStr="Stymne, 2011" startWordPosition="1471" endWordPosition="1472"> missing, incorrect, unknown, word order, and punctuation, which have also been used by other researchers, mainly for evaluation. However, this typology is relatively shallow and mixes classification of errors with causes of errors. Farr´us et al. (2010) suggested a typology based on linguistic categories, such as orthography and semantics, but their descriptions of these categories and their subcategories are not detailed. Thus, as part of my research, I am in the progress of designing a fine-grained typology and guidelines for EA. I have also created a tool for performing MT error analysis (Stymne, 2011a). Initial annotations have helped to focus my research efforts, and will be discussed below. I also plan to use EA as one means of evaluating my work on pre- and postprocessing. 4 Main Research Problems In this section I describe the four main problem areas I will focus on in my thesis project. I summarize briefly previous work in each area, and outline my own current and planned contributions. Sample results from the different studies are shown in Table 2. 4.1 Compounding In most Germanic languages, compounds are written without spaces or other word boundaries, which makes them problematic </context>
<context position="12586" citStr="Stymne (2011" startWordPosition="2038" endWordPosition="2039">ess in noun phrases, either by a definite article, or by a suffix on the noun. This leads to problems when translating into these languages, such as superfluous definite articles and wrong forms of nouns. I am not aware of any published research in this area, but an unpublished 14 Language pair Corpus Corpus size Testset size In article System Bleu NIST Stymne (2008) BL 19.31 5.727 En-De Europarl 439,513 2,000 +Comp 19.73 5.854 Stymne and BL 21.63 6.109 En-Se Europarl 701,157 2,000 Holmqvist (2008) +Comp 22.12 6.143 Stymne (2009b) BL 70.91 8.816 En-Da Automotive 168,046 1,000 +Def 76.35 9.363 Stymne (2011b) BL 21.63 6.109 En-Se Europarl 701,157 1,000 +Def 22.03 6.178 Stymne (2011c) BL 19.32 5.901 En-De Europarl 439,513 2,000 +Reo 19.59 5.936 Stymne and BL 19.44 5.381 En-Se Europarl 701,157 335 Ahrenberg (2010) +EC 22.12 5.447 Table 2: A selection of results for the four pre- and postprocessing strategies. Corpus sizes are given as number of sentences. BL is baseline systems, +Comp with compound processing, +Def with definite processing, +Reo with iterative reordering and alignment and monotone decoding, +EC with grammar checker error correction. The test set for error correction only contains </context>
<context position="14188" citStr="Stymne, 2011" startWordPosition="2284" endWordPosition="2285">, to make definite NPs structurally similar to target language NPs. The transformations are rule-based, using part-of-speech tags. Definite NPs in Scandinavian languages are mimicked in the source language by removing superfluous definite articles, and/or adding definite suffixes to nouns. In an initial study, this gave very good results, with relative Bleu improvements of up to 22.1% for translation into Danish (Stymne, 2009b). In Swedish and Norwegian, the distribution of definite suffixes is more complex than in Danish, and the basic strategy that worked well for Danish was not successful (Stymne, 2011b). A small modification to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatica</context>
</contexts>
<marker>Stymne, 2011</marker>
<rawString>Sara Stymne. 2011c. Iterative reordering and word alignment for statistical MT. In Proceedings of the 18th Nordic Conference on Computational Linguistics, Riga, Latvia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vilar</author>
<author>Jia Xu</author>
<author>Luis Fernando D’Haro</author>
<author>Hermann Ney</author>
</authors>
<title>Error analysis of machine translation output.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>697--702</pages>
<location>Genoa, Italy.</location>
<marker>Vilar, Xu, D’Haro, Ney, 2006</marker>
<rawString>David Vilar, Jia Xu, Luis Fernando D’Haro, and Hermann Ney. 2006. Error analysis of machine translation output. In Proceedings of LREC, pages 697–702, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sami Virpioja</author>
<author>Jaako J V¨ayrynen</author>
<author>Mathias Creutz</author>
<author>Markus Sadeniemi</author>
</authors>
<title>Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner.</title>
<date>2007</date>
<booktitle>In Proceedings of MT Summit XI,</booktitle>
<pages>491--498</pages>
<location>Copenhagen, Denmark.</location>
<marker>Virpioja, V¨ayrynen, Creutz, Sadeniemi, 2007</marker>
<rawString>Sami Virpioja, Jaako J. V¨ayrynen, Mathias Creutz, and Markus Sadeniemi. 2007. Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner. In Proceedings of MT Summit XI, pages 491–498, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Re-structuring, re-labeling, and realigning for syntax-based machine translation.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="6472" citStr="Wang et al. (2010)" startWordPosition="1037" endWordPosition="1040">hosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are often only evaluated quantitatively by using automatic metrics, such as Bleu (Papineni et al., 2002), which compares the system output to one or more human reference translations. While this type of evaluation has its advantages, mainly that it is fast and cheap, its correlation with human judgments is often low, especially for translation out of English (Callison-Burch et al., 2009). In order to overcome these problems to some e</context>
</contexts>
<marker>Wang, May, Knight, Marcu, 2010</marker>
<rawString>Wei Wang, Jonathan May, Kevin Knight, and Daniel Marcu. 2010. Re-structuring, re-labeling, and realigning for syntax-based machine translation. Computational Linguistics, 36(2):247–277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of CoLing,</booktitle>
<pages>508--514</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="14832" citStr="Xia and McCord (2004)" startWordPosition="2388" endWordPosition="2391">n to the basic strategy, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent. I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iteratively, since they both depend on the other process (Stymne, 2011c). There were no overall improvements as measured by Bleu, but an investigation of the reordering rules showed that the rules learned in the different iterations are different with regard to the linguistic phenomena they handle, indicating that it is possible to learn new information from iterating rule learning and </context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of CoLing, pages 508–514, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Hongfei Jiang</author>
<author>Ai Ti Aw</author>
<author>Jun Sun</author>
<author>Sheng Li</author>
<author>Chew Lim Tan</author>
</authors>
<title>A tree-to-tree alignmentbased model for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT Summit XI,</booktitle>
<pages>535--542</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="6060" citStr="Zhang et al. (2007" startWordPosition="966" endWordPosition="969">eech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are often only evaluated </context>
<context position="14852" citStr="Zhang et al. (2007" startWordPosition="2392" endWordPosition="2395">, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent. I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iteratively, since they both depend on the other process (Stymne, 2011c). There were no overall improvements as measured by Bleu, but an investigation of the reordering rules showed that the rules learned in the different iterations are different with regard to the linguistic phenomena they handle, indicating that it is possible to learn new information from iterating rule learning and word alignment. In t</context>
</contexts>
<marker>Zhang, Jiang, Aw, Sun, Li, Tan, 2007</marker>
<rawString>Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, Sheng Li, and Chew Lim Tan. 2007a. A tree-to-tree alignmentbased model for statistical machine translation. In Proceedings of MT Summit XI, pages 535–542, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuqi Zhang</author>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improved chunk-level reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>21--28</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="6060" citStr="Zhang et al. (2007" startWordPosition="966" endWordPosition="969">eech, rather than only as surface words (Koehn and Hoang, 2007). I mostly utilize factors to translate into both words and (morphological) partof-speech, and can then use an additional sequence model based on part-of-speech, which potentially can improve word order and agreement. I take advantage of available tools, such as the Moses toolkit (Koehn et al., 2007) for factored phrase-based translation. I have chosen to focus on PBSMT, which is a very successful MT approach, and have received much research focus. Other SMT approaches, such as hierarchical and syntactical SMT (e.g. Chiang (2007), Zhang et al. (2007a)) can potentially overcome some language differences that are problematic for PBSMT, such as long-distance word order differences. Many of these models have had good results, but they have the drawback of being more complex than PBSMT, and some methods do not scale well to large corpora. While these models at least in principle address some of the drawbacks of the flat structure in PBSMT, Wang et al. (2010) showed that a syntactic SMT system can still gain from preprocessing such as parse-tree modification. 3 Evaluation and Error Analysis Machine translation systems are often only evaluated </context>
<context position="14852" citStr="Zhang et al. (2007" startWordPosition="2392" endWordPosition="2395">, so that superfluous English articles were removed, but no suffixes were added, was successful for translation from English into Swedish and Norwegian. A planned extension is to integrate the transformations into a lattice that is fed to the decoder, in the spirit of (Dyer et al., 2008). 4.3 Word Order There has been a lot of research on how to handle word order differences between languages. Preprocessing approaches can use either hand-written rules targeting known language differences (e.g. Collins et al. (2005), Li et al. (2009)), or automatically learnt rules (e.g. Xia and McCord (2004), Zhang et al. (2007b)), which are basically language independent. I have performed an initial study on a language independent word order strategy where reordering rule learning and word alignment are performed iteratively, since they both depend on the other process (Stymne, 2011c). There were no overall improvements as measured by Bleu, but an investigation of the reordering rules showed that the rules learned in the different iterations are different with regard to the linguistic phenomena they handle, indicating that it is possible to learn new information from iterating rule learning and word alignment. In t</context>
</contexts>
<marker>Zhang, Zens, Ney, 2007</marker>
<rawString>Yuqi Zhang, Richard Zens, and Hermann Ney. 2007b. Improved chunk-level reordering for statistical machine translation. In Proceedings of the International Workshop on Spoken Language Translation, pages 21– 28, Trento, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>