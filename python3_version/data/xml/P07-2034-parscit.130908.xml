<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000727">
<title confidence="0.976667">
Building Emotion Lexicon from Weblog Corpora
</title>
<author confidence="0.970513">
Changhua Yang Kevin Hsin-Yih Lin Hsin-Hsi Chen
</author>
<affiliation confidence="0.985296">
Department of Computer Science and Information Engineering
National Taiwan University
</affiliation>
<address confidence="0.902788">
#1 Roosevelt Rd. Sec. 4, Taipei, Taiwan 106
</address>
<email confidence="0.998646">
{d91013, f93141, hhchen}@csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.993877" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999918777777778">
An emotion lexicon is an indispensable re-
source for emotion analysis. This paper
aims to mine the relationships between
words and emotions using weblog corpora.
A collocation model is proposed to learn
emotion lexicons from weblog articles.
Emotion classification at sentence level is
experimented by using the mined lexicons
to demonstrate their usefulness.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999850869565218">
Weblog (blog) is one of the most widely used cy-
bermedia in our internet lives that captures and
shares moments of our day-to-day experiences,
anytime and anywhere. Blogs are web sites that
timestamp posts from an individual or a group of
people, called bloggers. Bloggers may not follow
formal writing styles to express emotional states.
In some cases, they must post in pure text, so they
add printable characters, such as “:-)” (happy) and
“:-(“ (sad), to express their feelings. In other cases,
they type sentences with an internet messenger-
style interface, where they can attach a special set
of graphic icons, or emoticons. Different kinds of
emoticons are introduced into text expressions to
convey bloggers’ emotions.
Since thousands of blog articles are created eve-
ryday, emotional expressions can be collected to
form a large-scale corpus which guides us to build
vocabularies that are more emotionally expressive.
Our approach can create an emotion lexicon free of
laborious efforts of the experts who must be famil-
iar with both linguistic and psychological knowl-
edge.
</bodyText>
<sectionHeader confidence="0.999223" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.99974505882353">
Some previous works considered emoticons from
weblogs as categories for text classification.
Mishne (2005), and Yang and Chen (2006) used
emoticons as tags to train SVM (Cortes and Vap-
nik, 1995) classifiers at document or sentence level.
In their studies, emoticons were taken as moods or
emotion tags, and textual keywords were taken as
features. Wu et al. (2006) proposed a sentence-
level emotion recognition method using dialogs as
their corpus. “Happy, “Unhappy”, or “Neutral”
was assigned to each sentence as its emotion cate-
gory. Yang et al. (2006) adopted Thayer’s model
(1989) to classify music emotions. Each music
segment can be classified into four classes of
moods. In sentiment analysis research, Read (2005)
used emoticons in newsgroup articles to extract
instances relevant for training polarity classifiers.
</bodyText>
<sectionHeader confidence="0.923191" genericHeader="method">
3 Training and Testing Blog Corpora
</sectionHeader>
<bodyText confidence="0.999859136363637">
We select Yahoo! Kimo Blog1 posts as our source
of emotional expressions. Yahoo! Kimo Blog
service has 40 emoticons which are shown in Table
1. When an editing article, a blogger can insert an
emoticon by either choosing it or typing in the
corresponding codes. However, not all articles
contain emoticons. That is, users can decide
whether to insert emoticons into articles/sentences
or not. In this paper, we treat these icons as
emotion categories and taggings on the
corresponding text expressions.
The dataset we adopt consists of 5,422,420 blog
articles published at Yahoo! Kimo Blog from
January to July, 2006, spanning a period of 212
days. In total, 336,161 bloggers’ articles were col-
lected. Each blogger posts 16 articles on average.
We used the articles from January to June as the
training set and the articles in July as the testing set.
Table 2 shows the statistics of each set. On aver-
age, 14.10% of the articles contain emotion-tagged
expressions. The average length of articles with
tagged emotions, i.e., 272.58 characters, is shorter
</bodyText>
<footnote confidence="0.974274">
1 http://tw.blog.yahoo.com/
</footnote>
<page confidence="0.959542">
133
</page>
<note confidence="0.62208">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 133–136,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<tableCaption confidence="0.999646">
Table 1. Yahoo! Kimo Blog Emoticon Set.
</tableCaption>
<table confidence="0.970702625">
ID Emoticon Code Description ID Emoticon Code Description ID Emoticon Code Description ID Emoticon Code Description
1 :) happy 11 :O surprise 21 0:) angel 31 (: |yawn
2 :( sad 12 X-( angry 22 :-B nerd 32 =P~ drooling
3 ;) winking 13 :&gt; smug 23 =; talk to 33 :-? thinking
the d
:D big grin 14 han4 cool 24 I-) asleep 34 ;)) hee hee
B-)
5 ;;) batting 15 :-S worried 25 8-) rolling eyes 35 =D&gt;
eyelashes applause6
:-/ confused 16 &gt;:) devil 26 :-gi sick 36 [-o&lt; praying
7 :x love struck 17 :(( crying 27 :-$ don&apos;t tell 37 :-&lt; sigh
anyone
8 :”&gt; blushing 18 :)) laughing 28 [-( not talking 38 &gt;:P phbbbbt
9 :p tongue 19 : |straight face 29 :o) clown 39 @};- rose
10 :* kiss 20 /:) raised 30 @-) hypnotized 40 :@) pig
eyebrow
</table>
<tableCaption confidence="0.998946">
Table 2. Statistics of the Weblog Dataset.
</tableCaption>
<table confidence="0.98387975">
Dataset Article # Tagged # Percentage Tagged Len. Untagged L.
Training 4,187,737 575,009 13.86% 269.77 chrs. 468.14 chrs.
Testing 1,234,683 182,999 14.92% 281.42 chrs. 455.82 chrs.
Total 5,422,420 764,788 14.10% 272.58 chrs. 465.37 chrs.
</table>
<figureCaption confidence="0.997703">
Figure 1. Emotion Lexicon Construction and Evaluation.
</figureCaption>
<bodyText confidence="0.999778307692308">
than that of articles without tagging, i.e., 465.37
characters. It seems that people tend to use emoti-
cons to replace certain amount of text expressions
to make their articles more succinct.
Figure 1 shows the three phases for the con-
struction and evaluation of emotion lexicons. In
phase 1, 1,185,131 sentences containing only one
emoticon are extracted to form a training set to
build emotion lexicons. In phase 2, sentence-level
emotion classifiers are constructed using the mined
lexicons. In phase 3, a testing set consisting of
307,751 sentences is used to evaluate the classifi-
ers.
</bodyText>
<sectionHeader confidence="0.984999" genericHeader="method">
4 Emotion Lexicon Construction
</sectionHeader>
<bodyText confidence="0.999530428571428">
The blog corpus contains a collection of bloggers’
emotional expressions which can be analyzed to
construct an emotion lexicon consisting of words
that collocate with emoticons. We adopt a variation
of pointwise mutual information (Manning and
Schütze, 1999) to measure the collocation strength
co(e,w) between an emotion e and a word w:
</bodyText>
<equation confidence="0.8864495">
P(e , w) (1)
P(e)P(w)
</equation>
<bodyText confidence="0.999968761904762">
where P(e,w)=c(e,w)/N, P(e)=c(e)/N, P(w)=c(w)/N,
c(e) and c(w) are the total occurrences of emoticon
e and word w in a tagged corpus, respectively,
c(e,w) is total co-occurrences of e and w, and N
denotes the total word occurrences.
A word entry of a lexicon may contain several
emotion senses. They are ordered by the colloca-
tion strength co. Figure 2 shows two Chinese ex-
ample words, “ a a ” (ha1ha1) and “ 可 惡 ”
(ke3wu4). The former collocates with “laughing”
and “big grin” emoticons with collocation strength
25154.50 and 2667.11, respectively. Similarly, the
latter collocates with “angry” and “phbbbbt”.
When all collocations (i.e., word-emotion pairs)
are listed in a descending order of co, we can
choose top n collocations to build an emotion lexi-
con. In this paper, two lexicons (Lexicons A and B)
are extracted by setting n to 25k and 50k. Lexicon
A contains 4,776 entries with 25,000 sense pairs
and Lexicon B contains 11,243 entries and 50,000
sense pairs.
</bodyText>
<sectionHeader confidence="0.996387" genericHeader="method">
5 Emotion Classification
</sectionHeader>
<bodyText confidence="0.99874075">
Suppose a sentence S to be classified consists of n
emotion words. The emotion of S is derived by a
mapping from a set of n emotion words to m emo-
tion categories as follows:
</bodyText>
<figure confidence="0.928102909090909">
{ 1 ,..., }
ew ewn → ee{e1,...,em
classification
Extraction
Blog
Articles
Training Set
Testing Set
Lexicon
Construction
Features
Evaluation
Classifiers
Emotion
Lexicon
Phase 1
Phase 3
Phase 2
c e w = c e w x
o( , ) ( , ) log
S→
}
</figure>
<page confidence="0.76123">
134
</page>
<figureCaption confidence="0.999816">
Figure 2. Some Example Words in a Lexicon.
</figureCaption>
<bodyText confidence="0.8910338">
For each emotion word ewi, we may find several
emotion senses with the corresponding collocation
strength co by looking up the lexicon. Three alter-
natives are proposed as follows to label a sentence
S with an emotion:
</bodyText>
<listItem confidence="0.81003">
(a) Method 1
(1) Consider all senses of ewi as votes. Label S
with the emotion that receives the most votes.
(2) If more than two emotions get the same num-
ber of votes, then label S with the emotion that
has the maximum co.
(b) Method 2
</listItem>
<bodyText confidence="0.982178631578948">
Collect emotion senses from all ewi. Label S
with the emotion that has the maximum co.
(c) Method 3
The same as Method 1 except that each ewi v-
otes only one sense that has the maximum co.
In past research, the approach used by Yang et
al. (2006) was based on the Thayer’s model (1989),
which divided emotions into 4 categories. In sen-
timent analysis research, such as Read’s study
(2006), a polarity classifier separated instances into
positive and negative classes. In our experiments,
we not only adopt fine-grain classification, but also
coarse-grain classification. We first select 40
emoticons as a category set, and also adopt the
Thayer’s model to divide the emoticons into 4
quadrants of the emotion space. As shown in Fig-
ure 3, the top-right side collects the emotions that
are more positive and energetic and the bottom-left
side is more negative and silent. A polarity classi-
</bodyText>
<subsectionHeader confidence="0.884651">
Arousal (energetic)
</subsectionHeader>
<bodyText confidence="0.999949">
fier uses the right side as positive and the left side
as negative.
</bodyText>
<sectionHeader confidence="0.999215" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9998803125">
Table 3 shows the performance under various
combinations of lexicons, emotion categories and
classification methods. “Hit #” stands for the
number of correctly-answered instances. The base-
line represents the precision of predicting the ma-
jority category, such as “happy” or “positive”, as
the answer. The baseline method’s precision in-
creases as the number of emotion classes decreases.
The upper bound recall indicates the upper limit on
the fraction of the 307,751 instances solvable by
the corresponding method and thus reflects the
limitation of the method. The closer a method’s
actual recall is to the upper bound recall, the better
the method. For example, at most 40,855 instances
(14.90%) can be answered using Method 1 in
combination with Lexicon A. But the actual recall
is 4.55% only, meaning that Method 1’s recall is
more than 10% behind its upper bound. Methods
which have a larger set of candidate answers have
higher upper bound recalls, because the probability
that the correct answer is in their set of candidate
answers is greater.
Experiment results show that all methods utiliz-
ing Lexicon A have performance figures lower
than the baseline, so Lexicon A is not useful. In
contrast, Lexicon B, which provides a larger col-
lection of vocabularies and emotion senses, outper-
forms Lexicon A and the baseline. Although
Method 3 has the smallest candidate answer set
and thus has the smallest upper bound recall, it
outperforms the other two methods in most cases.
Method 2 achieves better precisions when using
</bodyText>
<figure confidence="0.5218466875">
aoao (ha1ha1) “hah hah”
Sense 1. (laughing) – co: 25154.50
e.g., aoao... AA JktP,AT~
“hah hah... I am getting lucky~”
Sense 2. (big grin) – co: 2667.11
e.g., ��,XNItT*-ilkairriF,~aoao
“I only memorized vowels today~ haha ”
?,S (ke3wu4) “darn”
Sense 1. (angry) – co: 2797.82
e.g., 駭W-AA什麼...?,S
“What&apos;s the hacker doing... darn it ”
Sense 2. (phbbbbt) – co: 619.24
e.g., ?,S����...
“Damn those aliens ”
(silent)
unassigned:
</figure>
<figureCaption confidence="0.913181">
Figure 3. Emoticons on Thayer’s model.
</figureCaption>
<figure confidence="0.982158333333333">
Valence
(positive)
(negative)
</figure>
<page confidence="0.995422">
135
</page>
<tableCaption confidence="0.999771">
Table 3. Evaluation Results.
</tableCaption>
<table confidence="0.987284666666666">
Baseline Method 1 (M1) Method 2 (M2) Method 3 (M3)
Upp. R. Hit # Prec. Reca. Upp. R. Hit # Prec. Reca. Upp. R. Hit # Prec. Reca.
Lexicon A 8.04% 14.90% 14,009 4.86% 4.55% 14.90% 9,392 3.26% 3.05% 6.49% 13,929 4.83% 4.52%
40 classes
Lexicon A 38.38% 48.70% 90,332 32.46% 29.35% 48.70% 64,689 23.25% 21.02% 35.94% 93,285 33.53% 30.31%
Thayer
Lexicon A 63.49% 60.74% 150,946 54.25% 49.05% 60.74% 120,237 43.21% 39.07% 54.97% 153,292 55.09% 49.81%
Polarity
Lexicon B 8.04% 73.18% 45,075 15.65% 14.65% 73.18% 43,637 15.15% 14.18% 27.89% 45,604 15.83% 14.81%
40 classes
Lexicon B 38.38% 89.11% 104,094 37.40% 33.82% 89.11% 118,392 42.55% 38.47% 63.74% 110,904 39.86% 36.04%
Thayer
Lexicon B 63.49% 91.12% 192,653 69.24% 62.60% 91.12% 188,434 67.72% 61.23% 81.92% 195,190 70.15% 63.42%
Polarity
Upp. R. – upper bound recall; Prec. – precision; Reca. – recall
</table>
<tableCaption confidence="0.996917">
Table 4. SVM Performance.
</tableCaption>
<table confidence="0.999777">
Method Upp. R. Hit # Prec. Reca. F
Lexicon B M3 81.92% 195,190 70.15% 63.42% 66.62%
SVM 25 features 15.80% 38,651 79.49% 12.56% 21.69%
SVM 50 features 26.27% 62,999 77.93% 20.47% 32.42%
SVM 75 features 36.74% 84,638 74.86% 27.50% 40.23%
SVM 100 features 45.49% 101,934 72.81% 33.12% 45.53%
</table>
<equation confidence="0.723387">
(Svm-25 + M3) 90.41% 196,147 70.05% 63.73% 66.74%
(Svm-50 + M3) 90.41% 195,835 70.37% 63.64% 66.83%
(Svm-75 + M3) 90.41% 195,229 70.16% 63.44% 66.63%
(Svm-100 + M3) 90.41% 195,054 70.01% 63.38% 66.53%
F = 2×(Precision×Recall)/(Precision+Recall)
</equation>
<bodyText confidence="0.999514181818182">
Thayer’s emotion categories. Method 1 treats the
vote to every sense equally. Hence, it loses some
differentiation abilities. Method 1 performs the
best in the first case (Lexicon A, 40 classes).
We can also apply machine learning to the data-
set to train a high-precision classification model.
To experiment with this idea, we adopt LIBSVM
(Fan et al., 2005) as the SVM kernel to deal with
the binary polarity classification problem. The
SVM classifier chooses top k (k = 25, 50, 75, and
100) emotion words as features. Since the SVM
classifier uses a small feature set, there are testing
instances which do not contain any features seen
previously by the SVM classifier. To deal with
this problem, we use the class prediction from
Method 3 for any testing instances without any
features that the SVM classifier can recognize. In
Table 4, the SVM classifier employing 25 features
has the highest precision. On the other hand, the
SVM classifier employing 50 features has the
highest F measure when used in conjunction with
Method 3.
</bodyText>
<sectionHeader confidence="0.993799" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999824888888889">
Our methods for building an emotional lexicon
utilize emoticons from blog articles collaboratively
contributed by bloggers. Since thousands of blog
articles are created everyday, we expect the set of
emotional expressions to keep expanding. In the
experiments, the method of employing each emo-
tion word to vote only one emotion category
achieves the best performance in both fine-grain
and coarse-grain classification.
</bodyText>
<sectionHeader confidence="0.98284" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.9951162">
Research of this paper was partially supported by
Excellent Research Projects of National Taiwan
University, under the contract of 95R0062-AE00-
02. We thank Yahoo! Taiwan Inc. for providing
the dataset for researches.
</bodyText>
<sectionHeader confidence="0.998908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999536111111111">
Corinna Cortes and V. Vapnik. 1995. Support-Vector
Network. Machine Learning, 20:273–297.
Rong-En Fan, Pai-Hsuen Chen and Chih-Jen Lin. 2005.
Working Set Selection Using Second Order Informa-
tion for Training Support Vector Machines. Journal
of Machine Learning Research, 6:1889–1918.
Gilad Mishne. 2005. Experiments with Mood Classifi-
cation in Blog Posts. Proceedings of 1st Workshop on
Stylistic Analysis of Text for Information Access.
Jonathon Read. 2005. Using Emotions to Reduce De-
pendency in Machine Learning Techniques for Sen-
timent Classification. Proceedings of the ACL Stu-
dent Research Workshop, 43-48.
Robert E. Thayer. 1989. The Biopsychology of Mood
and Arousal, Oxford University Press.
Changhua Yang and Hsin-Hsi Chen. 2006. A Study of
Emotion Classification Using Blog Articles. Pro-
ceedings of Conference on Computational Linguistics
and Speech Processing, 253-269.
Yi-Hsuan Yang, Chia-Chu Liu, and Homer H. Chen.
2006. Music Emotion Classification: A Fuzzy Ap-
proach. Proceedings of ACM Multimedia, 81-84.
Chung-Hsien Wu, Ze-Jing Chuang, and Yu-Chung Lin.
2006. Emotion Recognition from Text Using Seman-
tic Labels and Separable Mixture Models. ACM
Transactions on Asian Language Information Proc-
essing, 5(2):165-182.
</reference>
<page confidence="0.998794">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.514752">
<title confidence="0.999926">Building Emotion Lexicon from Weblog Corpora</title>
<author confidence="0.999857">Changhua Yang Kevin Hsin-Yih Lin Hsin-Hsi Chen</author>
<affiliation confidence="0.9998375">Department of Computer Science and Information Engineering National Taiwan University</affiliation>
<address confidence="0.520908">{d91013, f93141, hhchen}@csie.ntu.edu.tw</address>
<abstract confidence="0.9983755">An emotion lexicon is an indispensable resource for emotion analysis. This paper aims to mine the relationships between words and emotions using weblog corpora. A collocation model is proposed to learn emotion lexicons from weblog articles. Emotion classification at sentence level is experimented by using the mined lexicons to demonstrate their usefulness.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>V Vapnik</author>
</authors>
<title>Support-Vector Network.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<pages>20--273</pages>
<contexts>
<context position="1935" citStr="Cortes and Vapnik, 1995" startWordPosition="292" endWordPosition="296">roduced into text expressions to convey bloggers’ emotions. Since thousands of blog articles are created everyday, emotional expressions can be collected to form a large-scale corpus which guides us to build vocabularies that are more emotionally expressive. Our approach can create an emotion lexicon free of laborious efforts of the experts who must be familiar with both linguistic and psychological knowledge. 2 Related Works Some previous works considered emoticons from weblogs as categories for text classification. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis research, Read (2005) used emoticons in newsgroup articles to extract instances relevant for tr</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and V. Vapnik. 1995. Support-Vector Network. Machine Learning, 20:273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Pai-Hsuen Chen</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Working Set Selection Using Second Order Information for Training Support Vector Machines.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>6--1889</pages>
<contexts>
<context position="12610" citStr="Fan et al., 2005" startWordPosition="2071" endWordPosition="2074">33.12% 45.53% (Svm-25 + M3) 90.41% 196,147 70.05% 63.73% 66.74% (Svm-50 + M3) 90.41% 195,835 70.37% 63.64% 66.83% (Svm-75 + M3) 90.41% 195,229 70.16% 63.44% 66.63% (Svm-100 + M3) 90.41% 195,054 70.01% 63.38% 66.53% F = 2×(Precision×Recall)/(Precision+Recall) Thayer’s emotion categories. Method 1 treats the vote to every sense equally. Hence, it loses some differentiation abilities. Method 1 performs the best in the first case (Lexicon A, 40 classes). We can also apply machine learning to the dataset to train a high-precision classification model. To experiment with this idea, we adopt LIBSVM (Fan et al., 2005) as the SVM kernel to deal with the binary polarity classification problem. The SVM classifier chooses top k (k = 25, 50, 75, and 100) emotion words as features. Since the SVM classifier uses a small feature set, there are testing instances which do not contain any features seen previously by the SVM classifier. To deal with this problem, we use the class prediction from Method 3 for any testing instances without any features that the SVM classifier can recognize. In Table 4, the SVM classifier employing 25 features has the highest precision. On the other hand, the SVM classifier employing 50 </context>
</contexts>
<marker>Fan, Chen, Lin, 2005</marker>
<rawString>Rong-En Fan, Pai-Hsuen Chen and Chih-Jen Lin. 2005. Working Set Selection Using Second Order Information for Training Support Vector Machines. Journal of Machine Learning Research, 6:1889–1918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilad Mishne</author>
</authors>
<title>Experiments with Mood Classification in Blog Posts.</title>
<date>2005</date>
<booktitle>Proceedings of 1st Workshop on Stylistic Analysis of Text for Information Access.</booktitle>
<contexts>
<context position="1847" citStr="Mishne (2005)" startWordPosition="278" endWordPosition="279">cial set of graphic icons, or emoticons. Different kinds of emoticons are introduced into text expressions to convey bloggers’ emotions. Since thousands of blog articles are created everyday, emotional expressions can be collected to form a large-scale corpus which guides us to build vocabularies that are more emotionally expressive. Our approach can create an emotion lexicon free of laborious efforts of the experts who must be familiar with both linguistic and psychological knowledge. 2 Related Works Some previous works considered emoticons from weblogs as categories for text classification. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis researc</context>
</contexts>
<marker>Mishne, 2005</marker>
<rawString>Gilad Mishne. 2005. Experiments with Mood Classification in Blog Posts. Proceedings of 1st Workshop on Stylistic Analysis of Text for Information Access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathon Read</author>
</authors>
<title>Using Emotions to Reduce Dependency</title>
<date>2005</date>
<booktitle>in Machine Learning Techniques for Sentiment Classification. Proceedings of the ACL Student Research Workshop,</booktitle>
<pages>43--48</pages>
<contexts>
<context position="2461" citStr="Read (2005)" startWordPosition="378" endWordPosition="379">nd Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis research, Read (2005) used emoticons in newsgroup articles to extract instances relevant for training polarity classifiers. 3 Training and Testing Blog Corpora We select Yahoo! Kimo Blog1 posts as our source of emotional expressions. Yahoo! Kimo Blog service has 40 emoticons which are shown in Table 1. When an editing article, a blogger can insert an emoticon by either choosing it or typing in the corresponding codes. However, not all articles contain emoticons. That is, users can decide whether to insert emoticons into articles/sentences or not. In this paper, we treat these icons as emotion categories and taggin</context>
</contexts>
<marker>Read, 2005</marker>
<rawString>Jonathon Read. 2005. Using Emotions to Reduce Dependency in Machine Learning Techniques for Sentiment Classification. Proceedings of the ACL Student Research Workshop, 43-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Thayer</author>
</authors>
<title>The Biopsychology of Mood and Arousal,</title>
<date>1989</date>
<publisher>University Press.</publisher>
<location>Oxford</location>
<marker>Thayer, 1989</marker>
<rawString>Robert E. Thayer. 1989. The Biopsychology of Mood and Arousal, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changhua Yang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>A Study of Emotion Classification Using Blog Articles.</title>
<date>2006</date>
<booktitle>Proceedings of Conference on Computational Linguistics and Speech Processing,</booktitle>
<pages>253--269</pages>
<contexts>
<context position="1873" citStr="Yang and Chen (2006)" startWordPosition="281" endWordPosition="284"> icons, or emoticons. Different kinds of emoticons are introduced into text expressions to convey bloggers’ emotions. Since thousands of blog articles are created everyday, emotional expressions can be collected to form a large-scale corpus which guides us to build vocabularies that are more emotionally expressive. Our approach can create an emotion lexicon free of laborious efforts of the experts who must be familiar with both linguistic and psychological knowledge. 2 Related Works Some previous works considered emoticons from weblogs as categories for text classification. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis research, Read (2005) used emotic</context>
</contexts>
<marker>Yang, Chen, 2006</marker>
<rawString>Changhua Yang and Hsin-Hsi Chen. 2006. A Study of Emotion Classification Using Blog Articles. Proceedings of Conference on Computational Linguistics and Speech Processing, 253-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Hsuan Yang</author>
<author>Chia-Chu Liu</author>
<author>Homer H Chen</author>
</authors>
<title>Music Emotion Classification: A Fuzzy Approach.</title>
<date>2006</date>
<booktitle>Proceedings of ACM Multimedia,</booktitle>
<pages>81--84</pages>
<contexts>
<context position="2294" citStr="Yang et al. (2006)" startWordPosition="351" endWordPosition="354">ith both linguistic and psychological knowledge. 2 Related Works Some previous works considered emoticons from weblogs as categories for text classification. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis research, Read (2005) used emoticons in newsgroup articles to extract instances relevant for training polarity classifiers. 3 Training and Testing Blog Corpora We select Yahoo! Kimo Blog1 posts as our source of emotional expressions. Yahoo! Kimo Blog service has 40 emoticons which are shown in Table 1. When an editing article, a blogger can insert an emoticon by either choosing it or typing in the corresponding codes. However, not all articles contai</context>
<context position="8045" citStr="Yang et al. (2006)" startWordPosition="1339" endWordPosition="1342">ng collocation strength co by looking up the lexicon. Three alternatives are proposed as follows to label a sentence S with an emotion: (a) Method 1 (1) Consider all senses of ewi as votes. Label S with the emotion that receives the most votes. (2) If more than two emotions get the same number of votes, then label S with the emotion that has the maximum co. (b) Method 2 Collect emotion senses from all ewi. Label S with the emotion that has the maximum co. (c) Method 3 The same as Method 1 except that each ewi votes only one sense that has the maximum co. In past research, the approach used by Yang et al. (2006) was based on the Thayer’s model (1989), which divided emotions into 4 categories. In sentiment analysis research, such as Read’s study (2006), a polarity classifier separated instances into positive and negative classes. In our experiments, we not only adopt fine-grain classification, but also coarse-grain classification. We first select 40 emoticons as a category set, and also adopt the Thayer’s model to divide the emoticons into 4 quadrants of the emotion space. As shown in Figure 3, the top-right side collects the emotions that are more positive and energetic and the bottom-left side is mo</context>
</contexts>
<marker>Yang, Liu, Chen, 2006</marker>
<rawString>Yi-Hsuan Yang, Chia-Chu Liu, and Homer H. Chen. 2006. Music Emotion Classification: A Fuzzy Approach. Proceedings of ACM Multimedia, 81-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-Hsien Wu</author>
<author>Ze-Jing Chuang</author>
<author>Yu-Chung Lin</author>
</authors>
<title>Emotion Recognition from Text Using Semantic Labels and Separable Mixture Models.</title>
<date>2006</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<pages>5--2</pages>
<contexts>
<context position="2105" citStr="Wu et al. (2006)" startWordPosition="321" endWordPosition="324">rpus which guides us to build vocabularies that are more emotionally expressive. Our approach can create an emotion lexicon free of laborious efforts of the experts who must be familiar with both linguistic and psychological knowledge. 2 Related Works Some previous works considered emoticons from weblogs as categories for text classification. Mishne (2005), and Yang and Chen (2006) used emoticons as tags to train SVM (Cortes and Vapnik, 1995) classifiers at document or sentence level. In their studies, emoticons were taken as moods or emotion tags, and textual keywords were taken as features. Wu et al. (2006) proposed a sentencelevel emotion recognition method using dialogs as their corpus. “Happy, “Unhappy”, or “Neutral” was assigned to each sentence as its emotion category. Yang et al. (2006) adopted Thayer’s model (1989) to classify music emotions. Each music segment can be classified into four classes of moods. In sentiment analysis research, Read (2005) used emoticons in newsgroup articles to extract instances relevant for training polarity classifiers. 3 Training and Testing Blog Corpora We select Yahoo! Kimo Blog1 posts as our source of emotional expressions. Yahoo! Kimo Blog service has 40</context>
</contexts>
<marker>Wu, Chuang, Lin, 2006</marker>
<rawString>Chung-Hsien Wu, Ze-Jing Chuang, and Yu-Chung Lin. 2006. Emotion Recognition from Text Using Semantic Labels and Separable Mixture Models. ACM Transactions on Asian Language Information Processing, 5(2):165-182.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>