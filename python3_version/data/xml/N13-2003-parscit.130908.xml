<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.226081">
<title confidence="0.999515">
A Machine Learning Approach to Automatic Term Extraction
using a Rich Feature Set*
</title>
<author confidence="0.980916">
Merley da Silva Conrado, Thiago A. Salgueiro Pardo, and Solange Oliveira Rezende
</author>
<affiliation confidence="0.98347925">
Laboratory of Computational Intelligence,
An Interinstitutional Center for Research and Development in Computational Linguistic,
Institute of Mathematical and Computer Sciences,
University of Sao Paulo (USP),
</affiliation>
<address confidence="0.96961">
P.O. Box 668, 13561-970, Sao Carlos-SP, Brazil
</address>
<email confidence="0.999622">
{merleyc,taspardo,solange}@icmc.usp.br
</email>
<sectionHeader confidence="0.998676" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.991115888888889">
In this paper we propose an automatic term
extraction approach that uses machine learn-
ing incorporating varied and rich features of
candidate terms. In our preliminary experi-
ments, we also tested different attribute se-
lection methods to verify which features are
more relevant for automatic term extraction.
We achieved state of the art results for uni-
gram extraction in Brazilian Portuguese.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891842105263">
Terms are terminological units from specialised
texts (Castellv´ı et al., 2001). A term may be: (i) sim-
ple1 (a single element), such as “biodiversity”, or (ii)
complex (more than one element), such as “aquatic
ecosystem” and “natural resource management”.
Automatic term extraction (ATE) methods aim to
identify terminological units in specific domain cor-
pora (Castellv´ı et al., 2001). Such information is ex-
tremely useful for several tasks, from the linguistic
perspective of building dictionaries, taxonomies and
ontologies, to computational applications as infor-
mation retrieval, extraction, and summarisation.
Although ATE has been researched for more than
20 years, there is still room for improvement. There
are four major ATE problems. The first one is that
the ATE approaches may extract terms that are not
actual terms (“noise”) or do not extract actual terms
(“silence”). Considering the ecology domain, an ex-
ample of silence is when a term (e.g., pollination),
</bodyText>
<footnote confidence="0.977671">
*This research was supported by FAPESP (Proc. No.
2009/16142-3 and 2012/09375-4), Brazil.
1When we refer to unigrams, we mean simple terms.
</footnote>
<page confidence="0.990434">
16
</page>
<bodyText confidence="0.999948558823529">
with low frequency, is not considered a candidate
term (CT), and, therefore, it will not appear in the
extracted term list if we consider its frequency. Re-
garding noise, if we consider that nouns may be
terms and that adjectives may not, if an adjective
(e.g., ecological) is mistakenly tagged as a noun, it
will be wrongly extracted as a term. The second
problem is the difficulty in dealing with extremely
high number of candidates (called the high dimen-
sionality of candidate representation) that requires
time to process them. Since the ATE approaches ge-
nerate large lists of TCs, we have the third problem
that is the time and human effort spent for validat-
ing the TCs, which usually is manually performed.
The fourth problem is that the results are still not sa-
tisfactory and there is a natural ATE challenge since
the difficulty in obtaining a consensus among the ex-
perts about which words are terms of a specific do-
main (Vivaldi and Rodr´ıguez, 2007).
Our proposed ATE approach uses machine learn-
ing (ML), since it has been achieving high precision
values (Zhang et al., 2008; Foo and Merkel, 2010;
Zhang et al., 2010; Loukachevitch, 2012). Although
ML may also generate noise and silence, it facili-
tates the use of a large number of TCs and their fea-
tures, since ML techniques learn by themselves how
to recognize a term and then they save time extract-
ing them.
Our approach differs from others because we
adopt a rich feature set using varied knowledge lev-
els. With this, it is possible to decrease the silence
and noise and, consequently, to improve the ATE
results. Our features range from simple statistical
(e.g., term frequency) and linguistic (e.g., part of
</bodyText>
<note confidence="0.856354">
Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16–23,
Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999919407407407">
speech - POS) knowledge to more sophisticated hy-
brid knowledge, such as the analysis of the term
context. As far as we know, the combined use of
this specific knowledge has not been applied before.
Another difference is that we apply 3 statistical fea-
tures (Term Variance (Liu et al., 2005), Term Vari-
ance Quality (Dhillon et al., 2003), and Term Con-
tribution (Liu et al., 2003)) that to date have only
been used for attribute selection and not for term ex-
traction. As far as we know, the combined use of
this specific knowledge and feature feedback has not
been applied before. We also propose 4 new linguis-
tic features for ATE. All these features are detailed in
Section 4. Finally, for the first time, ML is being ap-
plied in the task of ATE in Brazilian Portuguese (BP)
corpora. Our approach may also be easily adapted to
other languages.
We focus on extracting only unigram terms, since
this is already a complex task. We run our experi-
ments on 3 different corpora. Our main contribution
is the improvement of precision (in the best case, we
improve the results 11 times) and F-measure (in the
best case, we improve 2 times).
Section 2 presents the main related work. Section
3 describes our ATE approach. Section 4 details the
experiments, and Section 5 reports the results. Con-
clusions and future work are presented in Section 6.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99922675">
There are several recent and interesting studies that
are not focused on extracting unigrams (Estop`a et
al., 2000; Almeida and Vale, 2008; Zhang et al.,
2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al.,
2012; Lopes, 2012). Normally, ATE studies use cor-
pora of different domain and language and, in some
cases, the authors use different evaluation measures.
Regardless of variation (e.g., the size of the test cor-
pora), we mention studies that have highlighted re-
sults for unigrams2. When possible, we show the
best precision (P) of the related work and its recall
(R).
(Ventura and Silva, 2008) extracted terms using
statistical measures that consider the predecessors
and successors of TCs. They achieved, for English,
P=81.5% and R=55.4% and, for Spanish, P=78.2%
</bodyText>
<footnote confidence="0.9602355">
2It is not specified if (Zhang et al., 2010) extracted simple or
complex terms.
</footnote>
<bodyText confidence="0.999772368421053">
and R=60.8%. For Spanish, the Greek forms of a
candidate and their prefix may help to extract terms
(e.g., the Greek formant laring that belongs to the
term laringoespasm in the medical domain) (Vivaldi
and Rodriguez, 2007), achieving about P=55.4%
and R=58.1%. For Spanish, (Gelbukh et al., 2010)
compared TCs of a domain with words of a general
corpus using Likelihood ratio based distance. They
achieved P=92.5%. For Brazilian Portuguese, the
ExPorTer methods are the only previous work that
uniquely extract unigrams (Zavaglia et al., 2007).
Therefore, they are the state of the art for unigrams
extraction for BP. The linguistic ExPorTer consid-
ers terms that belong to some POS patterns and uses
indicative phrases (such as is defined as) that may
identify where terms are. It achieved P=2.74% and
R=89.18%. The hybrid ExPorTer used these lin-
guistic features with frequency and Likelihood ratio.
The latter one obtained P=12.76% and R=23.25%.
</bodyText>
<sectionHeader confidence="0.964944" genericHeader="method">
3 Term Extraction Approach based on
</sectionHeader>
<subsectionHeader confidence="0.772384">
Machine Learning
</subsectionHeader>
<bodyText confidence="0.999939727272727">
In order to model the ATE task as a machine learn-
ing solution, we consider each word in the input
texts3 of a specific domain (except the stopwords)
as a learning instance (candidate term). For each in-
stance, we identify a set of features over which the
classification is performed. The classification pre-
dicts which words are terms (unigrams) of a specific
domain. We test different attribute selection meth-
ods in order to verify which features are more rele-
vant to classify a term.
We start by preprocessing the input texts, as
shown in Figure 1. This step consists of POS tag-
ging the corpora and normalizing4 the words of the
texts. The normalization minimizes the second ATE
problem because it allows working with a lower CT
representation dimensionality. When working with
a lower dimensionality, the words that do not help
identify terms are eliminated. Consequently, fewer
candidates should to be validated or refuted as terms
(it would minimize the third ATE problem). When
working with fewer candidates it also may improve
the result quality (it handles the fourth ATE prob-
</bodyText>
<footnote confidence="0.99919">
3When we refer to texts, we mean documents.
4Normalization consists of standardizing the words by re-
ducing their variations.
</footnote>
<page confidence="0.999141">
17
</page>
<bodyText confidence="0.99998315">
lem), and, definitely, it spends less time and fewer
resources to carry out the experiments. By improv-
ing the results, consequently, we minimize silence
and noise, which handles the first ATE problem.
Afterwards, we remove stopwords.
In order to identify a set of features over which
the classification is performed, we studied and tested
several measures. The feature identification is the
most important step of our approach. We divide the
features into two types: (i) the features that obtain
statistical, linguistic, and hybrid knowledge from the
input corpus, such as TFIDF and POS, and (ii) the
features that obtain these knowledge from measures
that use other corpora besides the input corpus. The
corpora belong to another domain that is different of
the input corpus domain (called contrastive corpora)
or not belong to any specific domain (called general
corpora). Our hypothesis is that, with the joining of
features of different levels of knowledge, it is possi-
ble to improve the ATE.
</bodyText>
<figureCaption confidence="0.997151">
Figure 1: Term extraction approach proposed.
</figureCaption>
<sectionHeader confidence="0.997496" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999765581818182">
At this point, for obtaining the knowledge in order
to extract terms, we tested 17 features that do not
depend on general or contrastive corpora and 2 fea-
tures that depend on these corpora. We intend to
explore more features (and we will possibly propose
new measures) that use contrastive or general cor-
pora or any taxonomic structure. The experiments
that expand the number of features are ongoing now.
We used 3 corpora of different domains in the
Portuguese language. The EaD corpus (Souza and
Di Felippo, 2010) has 347 texts about distance edu-
cation and has a gold standard with 118 terms5 (Gi-
5(Gianoti and Di Felippo, 2011) stated that the EaD unigram
gold standard has 59 terms, but in this paper we used 118 uni-
grams that the authors provided us prior to their work.
anoti and Di Felippo, 2011). The second one is the
ECO6 corpus (Zavaglia et al., 2007). It contains 390
texts of ecology domain and its gold standard has
322 unigrams. The latter is the Nanoscience and
Nanotechnology (N&amp;N) corpus (Coleti et al., 2008)
that contains 1,057 texts. Its gold standard has 1,794
unigrams (Coleti et al., 2008; Coleti et al., 2009).
In order to preprocess these corpora, we POS
tagged them using the PALAVRAS parser (Bick,
2000) and normalized their words using a stem-
ming7 technique. Stemming was chosen because of
its capacity to group similar word meanings, and its
use decreases representation dimensionality of can-
didate terms, which minimizes the second and third
ATE problems. Afterwards, we removed the stop-
words8, the conjugation of the verb “to be”, punctu-
ation, numbers, accents, and the words composed of
only one character are removed.
We identify and calculate 19 features in which 11
features are used for ATE in the literature, 3 features
are normally applied to the attribute selection tasks
(identified by *), 1 normally used for Named Entity
Recognition (identified by **), and we created 4 new
features (identified by Δ). These features are shown
in Table 1, accompanied by the hypotheses that un-
derlie their use. They are also divided into 3 levels
of knowledge: statistical, linguistic, and hybrid.
For the S feature, we removed stopwords at the
beginning and at the end of these phrases. For
POS, we assumed that terms may also be adjectives
(Almeida and Vale, 2008), besides nouns and verbs.
For GC and Freq GC, we used the NILC Corpus9 as
a general corpus, which contains 40 million words.
We created and used 40 indicative phrases (NPs).
For example, considering are composed of as an IP
in All organisms are composed of one or more cells,
we would consider organisms and cells as TCs. For
features related to CT stem, we analyzed, e.g., the
words educative, educators, education and educate
that came from the stem educ. Therefore, educ may
</bodyText>
<footnote confidence="0.9750995">
6ECO corpus - http://www.nilc.icmc.usp.br/
nilc/projects/bloc-eco.htm
7PTStemmer: A Stemming toolkit for the Portuguese lan-
guage - http://code.google.com/p/ptstemmer/
8Stoplist and Indicative Phrase list are avaiable in
http://www2.icmc.usp.br/ merleyc/
9NILC Corpus - http://www.nilc.icmc.usp.br/
nilc/tools/corpora.htm
</footnote>
<page confidence="0.998086">
18
</page>
<tableCaption confidence="0.99569">
Table 1: Features of candidate terms.
</tableCaption>
<table confidence="0.999029407407407">
Feature Description Hypothesis
The eight linguistic features
S noun and prepositional phrases terms are noun phrases and, sometimes, prepositional phrases
N S head of phrases heads of noun and prepositional phrases
POS noun, proper noun, and adjective terms follow some patterns
IP indicative phrases IPs may identify definitions/descriptions that may be terms
N noun ° number of nouns stemmed terms come from
higher number of nouns
than adjectives or verbs
N adj ° number of adjectives
N verb ° number of verbs
N PO ° total of words from which stemmed TCs come from
The seven statistical features
SG** n-gram length each domain has a term pattern
TF Term Frequency terms have neither low nor very high frequencies
DF Document Frequency terms appear in at least certain number of documents
TFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus
(Salton and Buckley, 1987) but they occur in few documents in this corpus
TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents
TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a
non-uniform distribution throughout corpus (higher variance)
TVQ* Term Variance Quality (Dhillon et al., 2003)
The four hybrid features
GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus
Freq GC CT frequency in GC
C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms
NC-value CT context (Frantzi et al., 1998) candidate context helps to extract terms
</table>
<bodyText confidence="0.999873037037037">
have as features N Noun = 2 (educators and educa-
tion), N Adj = 1 educative, N Verb = 1 (educate),
and N PO = 4 (total number of words). Our hy-
pothesis is that stemmed candidates that were origi-
nated from a higher number of nouns than adjectives
or verbs will be terms. Finally, we used NC-Value
adapted to unigrams (Barr´on-Cede˜no et al., 2009).
After calculating the features for each unigram
(candidate term), the CT representation has high di-
mensionality (it is the second ATE problem) and,
hence, the experiments may take a considerable
amount of time to be executed. To decrease this di-
mensionality and, consequently, the number of TCs
(which corresponds to the second and third ATE
problems, respectively), we tested two different cut-
offs, which preserve only TCs that occur in at least
two documents in the corpus. The first cut-off is
called C1. In the second one (called C2), the can-
didates must be noun and prepositional phrases and
also follow some of these POS: nouns, proper nouns,
verbs, and adjectives. The number of obtained can-
didates (stems) was 10,524, 14,385, and 46,203,
for the ECO, EaD, and N&amp;N corpora, respectively.
When using the C1 cut-off, we decreased to 55,15%,
45,82%, and 57,04%, and C2 decreased 63.10%,
63.18%, 66.94% in relation to the number of all the
obtained candidates (without cutt-offs).
</bodyText>
<sectionHeader confidence="0.986946" genericHeader="evaluation">
5 Experimental Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999844307692308">
The first evaluation aimed to identify which fea-
tures must be used for ATE (see Section 3). For
that, we applied 2 methods that select attributes by
evaluating the attribute subsets. Their evaluation is
based on consistency (CBF) and correlation (CFS).
We also tested search methods. The combination
of these methods, available in WEKA (Hall et al.,
2009), is: CFS SubsetEval using the RankSearch
Filter as search method (CFS R), CFS SubsetEval
using the BestFirst as search method (CFS BF),
CBF SubsetEval using the Ranking Filter (C R),
and CBF SubsetEval using the Greedy Stepwise
(C G). These methods return feature sets that are
considered the most representative for the term clas-
sification (Table 2). For the EaD corpus, the CG at-
tribute selection method did not select any feature.
For our experiments, we also considered all the fea-
tures (referred by All). Additionally, we compared
the use of two cut-off types for each feature set, C1
and C2, detailed in Section 4.
For both evaluations8, we chose largely known
inductors in the machine learning area. They rep-
resent different learning paradigms: JRip (Rule In-
duction), Naive Bayes (Probabilistic), J48 (Decision
Tree) with confidence factor of 25%, and SMO (Sta-
tistical Learning). All of these algorithms are avail-
</bodyText>
<page confidence="0.999714">
19
</page>
<tableCaption confidence="0.969516">
Table 2: Features chosen by the attribute selection meth-
ods.
</tableCaption>
<table confidence="0.995535210526316">
Methods Corpora
EaD ECO N&amp;N
CFS R TFIDF, TV, TVQ, TFIDF, TV, TVQ, Freq, TFIDF, TVQ,
IP, N Noun, N Adj POS, N Noun IP, Cvalue, N Noun,
POS, N Adj, N PO
CFS BF Same as in the TFIDF, TVQ, Freq, TFIDF, TV,
CFS R method. TCo, POS IP, Cvalue, N Noun,
POS, N Adj, N PO
C R Freq, DF, TFIDF, Freq, DF, TFIDF, Freq, DF, TFIDF,
TV, TVQ, TCo, IP, TV, TVQ, TCo, GC, TV, TVQ, TCo, GC,
GC, POS, FreqGC, Cvalue, NCvalue, IP, S, Cvalue, POS,
NCvalue, Cvalue, IP, S, N S, POS, NCvalue, N S,
N Adj, N Noun, N Noun, N Adj, N Noun, N Adj,
N Verb, N PO N Verb, N PO N Verb, N PO
C G Method did Freq, DF, TFIDF, Freq, DF, TFIDF, S,
not select any TV, TVQ, GC, IP, TV, TVQ, TCo, IP,
feature. N S, NCvalue, NCvalue, N S, POS,
S, N Noun, POS, GC, N Noun, N PO,
N Adj, N PO N Verb, N Adj
</table>
<bodyText confidence="0.998809097560976">
able in WEKA and described in (Witten and Frank,
2005). We run the experiments on a 10 fold cross-
validation and calculated the precision, recall, and
F-measure scores of term classification according to
the gold standard of unigrams of each corpus. Using
default parameter values for SMO, the results were
lower than the other inductors. Due to this fact and
the lack of space in the paper, we do not present the
SMO results here.
The best precision obtained for the EaD corpus
using the term classification, 66.66%, was achieved
by the C R attribute selection method with the C2
cut-off (C R-C2) using the JRIP inductor. The best
recall score, 20.96%, was obtained using Naive
Bayes with the CFS R-C1 method. The best F-
measure was 17.58% using the J48 inductor with
C R-C2. For the ECO corpus, the best precision
was 60% obtained with the J48 inductor with con-
fidence factor of 25% and the C R-C1 method. The
best recall was 21.40% with JRIP and the C G-C1
method. Our best F-measure was 24.26% obtained
with Naive Bayes using the CFS R-C1 method.
For the N&amp;N corpus, the best precision score was
61.03% using JRIP. The best recall was 52.53% and
the best F-measure score was 54.04%, both using
J48 inductor with confidence factor of 25%. The
three results used the All-C2 method.
Table 3 shows the comparison of our best results
with 2 baselines, which are the well-known term fre-
quency and TFIDF, using our stoplist. We also con-
sidered all the stemmed words of these corpora as
CT, except the stopwords, and we calculated the pre-
cision, recall, and F-measure scores for these words
as well. Finally, we compared our results with the
third baseline, which is the only previous work that
uniquely extracts unigrams (Zavaglia et al., 2007),
described in Section 2. Therefore, this is the state
of the art for unigrams extraction for Portuguese. In
order to compare this work with our results of the
EaD and N&amp;N corpora, we implemented the ATE
method of Zavaglia et al. We have to mention that
this method uses the normalization technique called
lemmatization instead of stemming, which we used
in our method. The only difference between our im-
plementation descriptions and the original method is
that we POS tagged and lemmatizated the texts using
the same parser (PALAVRAS10 (Bick, 2000)) used
in our experiments instead of the MXPOST tagger
(Ratnaparkhi, 1996).
For all used corpora, we obtained better results of
precision and F-measure comparing with the base-
lines. In general, we improve the ATE precision
scores, for the EaD corpus, eleven times (from 6.1%
to 66.66%) and, for the N&amp;N corpus, one and a half
times (from 35.4% to 61.03%), both comparing our
results with the use of TFIDF. For the ECO corpus,
we improve four and a half times (from 12.9% to
60%), by comparing with the use of frequency. We
improve the ATE F-measure scores, for the EaD cor-
pus, one and a half times (from 10.93% to 17.58%);
for the ECO corpus, we slightly improve the results
(from 20.64% to 24.26%); and, for the N&amp;N cor-
pus, two times (from 28.12% to 54.04%). The last
three cases are based on the best F-measure values
obtained using TFIDF. Regarding recall, on the one
hand, the linguistic ExPorTer method (detailed in
Section 2), to which we also compare our results,
achieved better recall for all used corpora, about
89%. On the other hand, its precision (about 2%)
and F-measure (about 4%) were significantly lower
than our results.
Finally, if we compare our results with the results
of all stemmed words, with the exception of the stop-
words, the recall values of the latter are high (about
76%) for all used corpora. However, the precision
scores are extremely low (about 1.26%), because it
used almost all words of the texts.
10As all NLP tools for general domains, PALAVRAS is not
excellent for specific domains. However, as it would be expen-
sive (time and manual work) to customize it for each specific
domain that we presented in this paper, we decided use it, even
though there are error tagging.
</bodyText>
<page confidence="0.996745">
20
</page>
<tableCaption confidence="0.999956">
Table 3: Comparison with baselines.
</tableCaption>
<table confidence="0.999635575757576">
Method Precision Recall F-Measure
(%) (%) (%)
The EaD corpus
JRIP with C R-C2 66.66 8.06 14.38
Naive Bayes 13.19 20.96 16.19
with CFS R-C1
J48 with F.C. of 27.58 12.9 17.58
0.25 with C R-C2
Ling. ExPorTer 0.33 89.70 0.66
Hyb. ExPorTer 0.07 17.64 0.15
Frequency 5.9 50.86 10.57
TFIDF 6.1 52.58 10.93
All the corpus 0.52 62.9 1.04
The ECO corpus
J48 with F.C. of 60.00 6.02 10.94
0.25 with C R-C1
JRIP with C G-C1 23.44 21.40 22.38
Naive Bayes 33.33 19.06 24.26
with CFS R-C1
Ling. ExPorTer 2.74 89.18 5.32
Hyb. ExPorTer 12.76 23.25 16.48
Frequency 12.9 43.28 19.87
TFIDF 13.4 44.96 20.64
All the corpus 1.48 99.07 2.92
The N&amp;N corpus
JRIP with All-C2 61.03 27.73 38.14
J48 with F.C. of 55.64 52.53 54.04
0.25 with All-C2
Ling. ExPorTer 3.75 89.40 7.20
Hyb. ExPorTer 1.68 35.35 3.22
Frequency 31.6 20.83 25.1
TFIDF 35.4 23.33 28.12
All the corpus 1.83 66.99 3.57
</table>
<sectionHeader confidence="0.99336" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999990237288136">
This paper described ongoing experiments about
unigrams extraction using ML. Our first contribution
regarding the experiments was to create 4 features
and to test 4 features that normally are applied to
other tasks and not for automatic term extraction.
Our second contribution is related to the first and
fourth ATE problems, which are the existence of si-
lence and noise and low ATE results, respectively.
We achieved state of art results for unigrams in
Brazilian Portuguese. We improved, for all used cor-
pora, precision (in the best case, we improve the re-
sults 11 times using the EaD corpus) and F-measure
(in the best case, 2 times using the N&amp;N corpus)
and, consequently, we minimized silence and noise.
The third contribution is about the features that
are better for extracting domain terms. All the tested
attribute selection methods indicated the TFIDF as
an essential feature for ATE. 90.9% of the meth-
ods selected N Noun and TVQ, and 81.81% selected
TV, IP, N adj, and POS as relevant features. How-
ever, only one of these methods chose Freq GC, and
none of them chose the SG feature. Regarding the
levels of knowledge - statistical, linguistic, and hy-
brid - in which each feature was classified, at least
45.45% of the methods chose 6 statistical, 5 linguis-
tic, and 3 hybrid features. We also observed that the
best F-measures (see Tables 2 and 3) were obtained
when using at least linguistic and statistical features
together. This fact proves that our main hypothesis is
true, because we improved the ATE results by join-
ing features of different levels of knowledge. Addi-
tionally, we allow the user to choose the features that
are better for term extraction.
As the fourth contribution, we minimized the
problem of high dimensionality (as mentioned, the
second ATE problem) by means of the use of two
different cut-offs (C1 and C2). By reducing the
number of TCs, fewer candidates were validated or
refuted as terms and, consequently, we minimized
the third ATE problem, which is the time and human
effort for validating the TCs. However, we still per-
ceived the need to reduce more the number of can-
didates. Therefore, for future work, we intend to use
instance selection techniques to reduce the term rep-
resentation.
We believe to have achieved significant results for
the experiments realized to date. Experiments using
more features that dependent on general corpus are
ongoing. We will also possibly propose new features
and will use taxonomic structure in order to improve
more the results. For using the taxonomic structure,
we intend to create a conventional taxonomy (Mi-
iller and Dorre, 1999) is created using the input cor-
pus. Therefore, we may identify more features for
the instances considering this taxonomy. For exam-
ple, normally in a taxonomy’s leaf specific words
of a domain happen, consequently, terms should ap-
pear there. Additionally, we are encouraged to adapt
these features for bigram and trigram terms as well.
</bodyText>
<sectionHeader confidence="0.997171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.7884195">
G. M. B. Almeida and O. A. Vale. 2008. Do texto
ao termo: interac¸˜ao entre terminologia, morfologia e
</reference>
<page confidence="0.994531">
21
</page>
<reference confidence="0.999335122641509">
lingufstica de corpus na extrac¸˜ao semi-autom´atica de
termos. In A. N. Isquerdo and M. J. B. Finatto, edi-
tors, As Ciˆencias do L´exico: Lexicologia, Lexicografia
e Terminologia, volume IV, pages 483–499. UFMS,
MS, Brazil, 1 edition.
A. Barr´on-Cede˜no, G. Sierra, P. Drouin, and S. Anani-
adou. 2009. An improved automatic term recogni-
tion method for spanish. In Proc of the 10th Int. CNF
on Computational Linguistics and Intelligent Text Pro-
cessing, pages 125–136, Berlin, Heidelberg. Springer-
Verlag.
E. Bick. 2000. The Parsing System “PALAVRAS”. Auto-
matic Grammatical Analysis of Portuguese in a Con-
straint Grammar Framework. University of Arhus,
Arhus.
M. T. Cabr´e Castellvf, R. Estop`a Bagot, and Jordi Vivaldi
Palatresi. 2001. Automatic term detection: a review
of current systems. In D. Bourigault, C. Jacquemin,
and M-C. L’Homme, editors, Recent Advances in
Computational Terminology, pages 53–88, Amster-
dam/Philadelphia. John Benjamins.
J. S. Coleti, D. F. Mattos, L. C. Genoves Junior, A. Can-
dido Junior, A. Di Felippo, G. M. B. Almeida,
S. M. Alufsio, and O. N. Oliveira Junior. 2008.
Compilac¸˜ao de Corpus em Lingua Portuguesa na
´area de Nanociˆencia/Nanotecnologia: Problemas e
soluc¸˜oes, volume 1. Tagnin and Vale., SP, Brazil, 192
edition.
J. S. Coleti, D. F. Mattos, and G. M. B. Almeida. 2009.
Primeiro dicion´ario de nanociˆencia e nanotecnolo-
gia em lfngua portuguesa. In Marcelo Fila Pecenin,
Valdemir Miotello, and Talita Aparecida Oliveira, ed-
itors, II Encontro Acadˆemico de Letras (EALE), pages
1–10. Caderno de Resumos do II EALE.
I. Dhillon, J. Kogan, and C. Nicholas. 2003. Feature
selection and document clustering. In M. W. Berry,
editor, Survey of Text Mining, pages 73–100. Springer.
R. Estop`a, J. Vivaldi, and M. T. Cabr´e. 2000. Use of
greek and latin forms for term detection. In Proc of
the 2nd on LREC, pages 855–861, Greece. ELRA.
J. Foo and M. Merkel. 2010. Using machine learning
to perform automatic term recognition. In N. Bel,
B. Daille, and A. Vasiljevs, editors, Proc of the 7th
LREC - Wksp on Methods for automatic acquisition
of Language Resources and their Evaluation Methods,
pages 49–54.
K. T. Frantzi, S. Ananiadou, and J. I. Tsujii. 1998.
The C-value/NC-value method of automatic recogni-
tion for multi-word terms. In Proc of the 2nd ECDL,
pages 585–604, London, UK. Springer-Verlag.
A. F. Gelbukh, G. Sidorov, E. Lavin-Villa, and
L. Chanona-Hern´andez. 2010. Automatic term ex-
traction using log-likelihood based comparison with
general reference corpus. In NLDB, pages 248–255.
A. C. Gianoti and A. Di Felippo. 2011. Extrac¸˜ao de con-
hecimento terminol´ogico no projeto TermiNet. Tech-
nical Report NILC-TR-11-01, Instituto de Ciˆencias
Matem´aticas e de Computac¸˜ao (ICMC) - USP, SP,
Brazil.
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-
mann, and I. H. Witten. 2009. The WEKA data
mining software: An update. In SIGKDD-ACM, vol-
ume 11, pages 10–18.
T. Liu, S. Liu, and Z. Chen. 2003. An evaluation on
feature selection for text clustering. In Proceedings of
the 10th Int. CNF on Machine Learning, pages 488–
495, San Francisco, CA, USA. Morgan Kaufmann.
L. Liu, J. Kang, J. Yu, and Z. Wang. 2005. A compar-
ative study on unsupervised feature selection methods
for text clustering. In Proc of IEEE NLP-KE, pages
597–601.
L. Lopes. 2012. Extrac¸˜ao autom´atica de conceitos a par-
tir de textos em lingua portugesa. Ph.D. thesis, Porto
Alegre, RS. Pontif´ıcia Universidade do Rio Grande do
Sul (PUCRS).
N. Loukachevitch. 2012. Automatic term recognition
needs multiple evidence. In N. Calzolari, K. Choukri,
T. Declerck, M. Dogan, B. Maegaard, J. Mariani,
Odijk, and S. Piperidis, editors, Proc of the 8th on
LREC, pages 2401–2407, Istanbul, Turkey. ELRA.
A. Miiller and J. Dorre. 1999. The taxgen frame-
work: Automating the generation of a taxonomy for
a large document collection. In Proceedings of the
Thirty-Second Annual Hawaii International Confer-
ence on System Sciences (HICSS), volume 2, pages
2034–2042, Washington, DC, USA. IEEE Computer
Society.
R. Nazar. 2011. A statistical approach to term extraction.
Int. Journal of English Studies, 11(2).
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. Proc of the CNF on EMNLP,
pages 491–497.
G. Salton and C. Buckley. 1987. Term weighting ap-
proaches in automatic text retrieval. Technical report,
Ithaca, NY, USA.
J. W. C. Souza and A. Di Felippo. 2010. Um exercfcio
em ling¨uistica de corpus no ˆambito do projeto Ter-
miNet. Technical Report NILC-TR-10-08, ICMC -
USP, SP, Brazil.
J. Ventura and J. F. Silva. 2008. Ranking and extrac-
tion of relevant single words in text. In Cesare Rossi,
editor, Brain, Vision and AI, pages 265–284. InTech,
Education and Publishing.
J. Vivaldi and H. Rodrfguez. 2007. Evaluation of terms
and term extraction systems: A practical approach.
Terminology, 13(2):225–248.
</reference>
<page confidence="0.972467">
22
</page>
<reference confidence="0.999696576923077">
J. Vivaldi, L. A. Cabrera-Diego, G. Sierra, and M. Pozzi.
2012. Using wikipedia to validate the terminology
found in a corpus of basic textbooks. In N. Calzolari,
K. Choukri, T. Declerck, M. U. Dogan, B. Maegaard,
J. Mariani, J. Odijk, and S. Piperidis, editors, Proc of
the 8th Int. CNF on LREC, Istanbul, Turkey. ELRA.
I. H. Witten and E. Frank. 2005. Data Mining: Practi-
cal Machine Learning Tools and Techniques, Second
Edition (Morgan Kaufmann Series in Data Manage-
ment Systems). Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
C. Zavaglia, L. H. M. Oliveira, M. G. V. Nunes, and
S. M. Alu´ısio. 2007. Estrutura ontol´ogica e unidades
lexicais: uma aplicac¸˜ao computacional no dom´ınio da
ecologia. In Proc. of the 5th Wksp em Tecnologia da
Informac¸˜ao e da Linguagem Humana, pages 1575–
1584, RJ, Brazil. SBC.
Z. Zhang, J. Iria, C. Brewster, and F. Ciravegna. 2008.
A comparative evaluation of term recognition algo-
rithms. In N. Calzolari (CNF Chair), K. Choukri,
B. Maegaard, J. Mariani, J. Odjik, S. Piperidis, and
D. Tapias, editors, Proc of the 6th on LREC, pages
2108–2113, Marrakech, Morocco. ELRA.
X. Zhang, Y. Song, and A. Fang. 2010. Term recogni-
tion using conditional random fields. In Proc of IEEE
NLP-KE, pages 333–336.
</reference>
<page confidence="0.998934">
23
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402294">
<title confidence="0.99995">A Machine Learning Approach to Automatic Term Extraction</title>
<author confidence="0.880615">a Rich Feature Merley da Silva Conrado</author>
<author confidence="0.880615">Thiago A Salgueiro Pardo</author>
<author confidence="0.880615">Solange Oliveira</author>
<affiliation confidence="0.98528725">Laboratory of Computational An Interinstitutional Center for Research and Development in Computational Institute of Mathematical and Computer University of Sao Paulo</affiliation>
<address confidence="0.778176">P.O. Box 668, 13561-970, Sao Carlos-SP,</address>
<abstract confidence="0.966903">In this paper we propose an automatic term extraction approach that uses machine learning incorporating varied and rich features of candidate terms. In our preliminary experiments, we also tested different attribute selection methods to verify which features are more relevant for automatic term extraction. We achieved state of the art results for unigram extraction in Brazilian Portuguese.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G M B Almeida</author>
<author>O A Vale</author>
</authors>
<title>Do texto ao termo: interac¸˜ao entre terminologia, morfologia e lingufstica de corpus na extrac¸˜ao semi-autom´atica de termos.</title>
<date>2008</date>
<booktitle>As Ciˆencias do L´exico: Lexicologia, Lexicografia e Terminologia, volume IV,</booktitle>
<volume>1</volume>
<pages>483--499</pages>
<editor>In A. N. Isquerdo and M. J. B. Finatto, editors,</editor>
<contexts>
<context position="5310" citStr="Almeida and Vale, 2008" startWordPosition="858" endWordPosition="861">ly unigram terms, since this is already a complex task. We run our experiments on 3 different corpora. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and </context>
<context position="11589" citStr="Almeida and Vale, 2008" startWordPosition="1892" endWordPosition="1895">alculate 19 features in which 11 features are used for ATE in the literature, 3 features are normally applied to the attribute selection tasks (identified by *), 1 normally used for Named Entity Recognition (identified by **), and we created 4 new features (identified by Δ). These features are shown in Table 1, accompanied by the hypotheses that underlie their use. They are also divided into 3 levels of knowledge: statistical, linguistic, and hybrid. For the S feature, we removed stopwords at the beginning and at the end of these phrases. For POS, we assumed that terms may also be adjectives (Almeida and Vale, 2008), besides nouns and verbs. For GC and Freq GC, we used the NILC Corpus9 as a general corpus, which contains 40 million words. We created and used 40 indicative phrases (NPs). For example, considering are composed of as an IP in All organisms are composed of one or more cells, we would consider organisms and cells as TCs. For features related to CT stem, we analyzed, e.g., the words educative, educators, education and educate that came from the stem educ. Therefore, educ may 6ECO corpus - http://www.nilc.icmc.usp.br/ nilc/projects/bloc-eco.htm 7PTStemmer: A Stemming toolkit for the Portuguese l</context>
</contexts>
<marker>Almeida, Vale, 2008</marker>
<rawString>G. M. B. Almeida and O. A. Vale. 2008. Do texto ao termo: interac¸˜ao entre terminologia, morfologia e lingufstica de corpus na extrac¸˜ao semi-autom´atica de termos. In A. N. Isquerdo and M. J. B. Finatto, editors, As Ciˆencias do L´exico: Lexicologia, Lexicografia e Terminologia, volume IV, pages 483–499. UFMS, MS, Brazil, 1 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Barr´on-Cede˜no</author>
<author>G Sierra</author>
<author>P Drouin</author>
<author>S Ananiadou</author>
</authors>
<title>An improved automatic term recognition method for spanish.</title>
<date>2009</date>
<booktitle>In Proc of the 10th Int. CNF on Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>125--136</pages>
<publisher>SpringerVerlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Barr´on-Cede˜no, Sierra, Drouin, Ananiadou, 2009</marker>
<rawString>A. Barr´on-Cede˜no, G. Sierra, P. Drouin, and S. Ananiadou. 2009. An improved automatic term recognition method for spanish. In Proc of the 10th Int. CNF on Computational Linguistics and Intelligent Text Processing, pages 125–136, Berlin, Heidelberg. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>The Parsing System “PALAVRAS”. Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework.</title>
<date>2000</date>
<journal>University of Arhus, Arhus.</journal>
<contexts>
<context position="10528" citStr="Bick, 2000" startWordPosition="1719" endWordPosition="1720">ppo, 2011) stated that the EaD unigram gold standard has 59 terms, but in this paper we used 118 unigrams that the authors provided us prior to their work. anoti and Di Felippo, 2011). The second one is the ECO6 corpus (Zavaglia et al., 2007). It contains 390 texts of ecology domain and its gold standard has 322 unigrams. The latter is the Nanoscience and Nanotechnology (N&amp;N) corpus (Coleti et al., 2008) that contains 1,057 texts. Its gold standard has 1,794 unigrams (Coleti et al., 2008; Coleti et al., 2009). In order to preprocess these corpora, we POS tagged them using the PALAVRAS parser (Bick, 2000) and normalized their words using a stemming7 technique. Stemming was chosen because of its capacity to group similar word meanings, and its use decreases representation dimensionality of candidate terms, which minimizes the second and third ATE problems. Afterwards, we removed the stopwords8, the conjugation of the verb “to be”, punctuation, numbers, accents, and the words composed of only one character are removed. We identify and calculate 19 features in which 11 features are used for ATE in the literature, 3 features are normally applied to the attribute selection tasks (identified by *), </context>
<context position="19767" citStr="Bick, 2000" startWordPosition="3293" endWordPosition="3294">s work that uniquely extracts unigrams (Zavaglia et al., 2007), described in Section 2. Therefore, this is the state of the art for unigrams extraction for Portuguese. In order to compare this work with our results of the EaD and N&amp;N corpora, we implemented the ATE method of Zavaglia et al. We have to mention that this method uses the normalization technique called lemmatization instead of stemming, which we used in our method. The only difference between our implementation descriptions and the original method is that we POS tagged and lemmatizated the texts using the same parser (PALAVRAS10 (Bick, 2000)) used in our experiments instead of the MXPOST tagger (Ratnaparkhi, 1996). For all used corpora, we obtained better results of precision and F-measure comparing with the baselines. In general, we improve the ATE precision scores, for the EaD corpus, eleven times (from 6.1% to 66.66%) and, for the N&amp;N corpus, one and a half times (from 35.4% to 61.03%), both comparing our results with the use of TFIDF. For the ECO corpus, we improve four and a half times (from 12.9% to 60%), by comparing with the use of frequency. We improve the ATE F-measure scores, for the EaD corpus, one and a half times (f</context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>E. Bick. 2000. The Parsing System “PALAVRAS”. Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. University of Arhus, Arhus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Cabr´e Castellvf</author>
<author>R Estop`a Bagot</author>
<author>Jordi Vivaldi Palatresi</author>
</authors>
<title>Automatic term detection: a review of current systems.</title>
<date>2001</date>
<booktitle>Recent Advances in Computational Terminology,</booktitle>
<pages>53--88</pages>
<editor>In D. Bourigault, C. Jacquemin, and M-C. L’Homme, editors,</editor>
<publisher>Amsterdam/Philadelphia. John Benjamins.</publisher>
<marker>Castellvf, Bagot, Palatresi, 2001</marker>
<rawString>M. T. Cabr´e Castellvf, R. Estop`a Bagot, and Jordi Vivaldi Palatresi. 2001. Automatic term detection: a review of current systems. In D. Bourigault, C. Jacquemin, and M-C. L’Homme, editors, Recent Advances in Computational Terminology, pages 53–88, Amsterdam/Philadelphia. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleti</author>
<author>D F Mattos</author>
<author>L C Genoves Junior</author>
<author>A Candido Junior</author>
<author>A Di Felippo</author>
<author>G M B Almeida</author>
<author>S M Alufsio</author>
<author>O N Oliveira Junior</author>
</authors>
<date>2008</date>
<booktitle>Compilac¸˜ao de Corpus em Lingua Portuguesa na ´area de Nanociˆencia/Nanotecnologia: Problemas e soluc¸˜oes,</booktitle>
<volume>1</volume>
<pages>edition.</pages>
<marker>Coleti, Mattos, Junior, Junior, Di Felippo, Almeida, Alufsio, Junior, 2008</marker>
<rawString>J. S. Coleti, D. F. Mattos, L. C. Genoves Junior, A. Candido Junior, A. Di Felippo, G. M. B. Almeida, S. M. Alufsio, and O. N. Oliveira Junior. 2008. Compilac¸˜ao de Corpus em Lingua Portuguesa na ´area de Nanociˆencia/Nanotecnologia: Problemas e soluc¸˜oes, volume 1. Tagnin and Vale., SP, Brazil, 192 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleti</author>
<author>D F Mattos</author>
<author>G M B Almeida</author>
</authors>
<title>Primeiro dicion´ario de nanociˆencia e nanotecnologia em lfngua portuguesa.</title>
<date>2009</date>
<booktitle>In Marcelo Fila Pecenin, Valdemir Miotello, and Talita Aparecida Oliveira, editors, II Encontro Acadˆemico de Letras (EALE),</booktitle>
<pages>1--10</pages>
<contexts>
<context position="10431" citStr="Coleti et al., 2009" startWordPosition="1701" endWordPosition="1704">0) has 347 texts about distance education and has a gold standard with 118 terms5 (Gi5(Gianoti and Di Felippo, 2011) stated that the EaD unigram gold standard has 59 terms, but in this paper we used 118 unigrams that the authors provided us prior to their work. anoti and Di Felippo, 2011). The second one is the ECO6 corpus (Zavaglia et al., 2007). It contains 390 texts of ecology domain and its gold standard has 322 unigrams. The latter is the Nanoscience and Nanotechnology (N&amp;N) corpus (Coleti et al., 2008) that contains 1,057 texts. Its gold standard has 1,794 unigrams (Coleti et al., 2008; Coleti et al., 2009). In order to preprocess these corpora, we POS tagged them using the PALAVRAS parser (Bick, 2000) and normalized their words using a stemming7 technique. Stemming was chosen because of its capacity to group similar word meanings, and its use decreases representation dimensionality of candidate terms, which minimizes the second and third ATE problems. Afterwards, we removed the stopwords8, the conjugation of the verb “to be”, punctuation, numbers, accents, and the words composed of only one character are removed. We identify and calculate 19 features in which 11 features are used for ATE in the</context>
</contexts>
<marker>Coleti, Mattos, Almeida, 2009</marker>
<rawString>J. S. Coleti, D. F. Mattos, and G. M. B. Almeida. 2009. Primeiro dicion´ario de nanociˆencia e nanotecnologia em lfngua portuguesa. In Marcelo Fila Pecenin, Valdemir Miotello, and Talita Aparecida Oliveira, editors, II Encontro Acadˆemico de Letras (EALE), pages 1–10. Caderno de Resumos do II EALE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dhillon</author>
<author>J Kogan</author>
<author>C Nicholas</author>
</authors>
<title>Feature selection and document clustering.</title>
<date>2003</date>
<booktitle>Survey of Text Mining,</booktitle>
<pages>73--100</pages>
<editor>In M. W. Berry, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="4157" citStr="Dhillon et al., 2003" startWordPosition="656" endWordPosition="659">ntly, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16–23, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics speech - POS) knowledge to more sophisticated hybrid knowledge, such as the analysis of the term context. As far as we know, the combined use of this specific knowledge has not been applied before. Another difference is that we apply 3 statistical features (Term Variance (Liu et al., 2005), Term Variance Quality (Dhillon et al., 2003), and Term Contribution (Liu et al., 2003)) that to date have only been used for attribute selection and not for term extraction. As far as we know, the combined use of this specific knowledge and feature feedback has not been applied before. We also propose 4 new linguistic features for ATE. All these features are detailed in Section 4. Finally, for the first time, ML is being applied in the task of ATE in Brazilian Portuguese (BP) corpora. Our approach may also be easily adapted to other languages. We focus on extracting only unigram terms, since this is already a complex task. We run our ex</context>
<context position="13677" citStr="Dhillon et al., 2003" startWordPosition="2215" endWordPosition="2218">in has a term pattern TF Term Frequency terms have neither low nor very high frequencies DF Document Frequency terms appear in at least certain number of documents TFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus (Salton and Buckley, 1987) but they occur in few documents in this corpus TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a non-uniform distribution throughout corpus (higher variance) TVQ* Term Variance Quality (Dhillon et al., 2003) The four hybrid features GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus Freq GC CT frequency in GC C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms NC-value CT context (Frantzi et al., 1998) candidate context helps to extract terms have as features N Noun = 2 (educators and education), N Adj = 1 educative, N Verb = 1 (educate), and N PO = 4 (total number of words). Our hypothesis is that stemmed candidates that were originated from a higher number of nouns than adjectives or verbs will be terms.</context>
</contexts>
<marker>Dhillon, Kogan, Nicholas, 2003</marker>
<rawString>I. Dhillon, J. Kogan, and C. Nicholas. 2003. Feature selection and document clustering. In M. W. Berry, editor, Survey of Text Mining, pages 73–100. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Estop`a</author>
<author>J Vivaldi</author>
<author>M T Cabr´e</author>
</authors>
<title>Use of greek and latin forms for term detection.</title>
<date>2000</date>
<booktitle>In Proc of the 2nd on LREC,</booktitle>
<pages>855--861</pages>
<publisher>ELRA.</publisher>
<marker>Estop`a, Vivaldi, Cabr´e, 2000</marker>
<rawString>R. Estop`a, J. Vivaldi, and M. T. Cabr´e. 2000. Use of greek and latin forms for term detection. In Proc of the 2nd on LREC, pages 855–861, Greece. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Foo</author>
<author>M Merkel</author>
</authors>
<title>Using machine learning to perform automatic term recognition. In</title>
<date>2010</date>
<booktitle>Proc of the 7th LREC - Wksp on Methods for automatic acquisition of Language Resources and their Evaluation Methods,</booktitle>
<pages>49--54</pages>
<editor>N. Bel, B. Daille, and A. Vasiljevs, editors,</editor>
<contexts>
<context position="3097" citStr="Foo and Merkel, 2010" startWordPosition="479" endWordPosition="482">entation) that requires time to process them. Since the ATE approaches generate large lists of TCs, we have the third problem that is the time and human effort spent for validating the TCs, which usually is manually performed. The fourth problem is that the results are still not satisfactory and there is a natural ATE challenge since the difficulty in obtaining a consensus among the experts about which words are terms of a specific domain (Vivaldi and Rodr´ıguez, 2007). Our proposed ATE approach uses machine learning (ML), since it has been achieving high precision values (Zhang et al., 2008; Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012). Although ML may also generate noise and silence, it facilitates the use of a large number of TCs and their features, since ML techniques learn by themselves how to recognize a term and then they save time extracting them. Our approach differs from others because we adopt a rich feature set using varied knowledge levels. With this, it is possible to decrease the silence and noise and, consequently, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 20</context>
</contexts>
<marker>Foo, Merkel, 2010</marker>
<rawString>J. Foo and M. Merkel. 2010. Using machine learning to perform automatic term recognition. In N. Bel, B. Daille, and A. Vasiljevs, editors, Proc of the 7th LREC - Wksp on Methods for automatic acquisition of Language Resources and their Evaluation Methods, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K T Frantzi</author>
<author>S Ananiadou</author>
<author>J I Tsujii</author>
</authors>
<title>The C-value/NC-value method of automatic recognition for multi-word terms.</title>
<date>1998</date>
<booktitle>In Proc of the 2nd ECDL,</booktitle>
<pages>585--604</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="13889" citStr="Frantzi et al., 1998" startWordPosition="2256" endWordPosition="2259">terms are very common in the corpus (Salton and Buckley, 1987) but they occur in few documents in this corpus TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a non-uniform distribution throughout corpus (higher variance) TVQ* Term Variance Quality (Dhillon et al., 2003) The four hybrid features GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus Freq GC CT frequency in GC C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms NC-value CT context (Frantzi et al., 1998) candidate context helps to extract terms have as features N Noun = 2 (educators and education), N Adj = 1 educative, N Verb = 1 (educate), and N PO = 4 (total number of words). Our hypothesis is that stemmed candidates that were originated from a higher number of nouns than adjectives or verbs will be terms. Finally, we used NC-Value adapted to unigrams (Barr´on-Cede˜no et al., 2009). After calculating the features for each unigram (candidate term), the CT representation has high dimensionality (it is the second ATE</context>
</contexts>
<marker>Frantzi, Ananiadou, Tsujii, 1998</marker>
<rawString>K. T. Frantzi, S. Ananiadou, and J. I. Tsujii. 1998. The C-value/NC-value method of automatic recognition for multi-word terms. In Proc of the 2nd ECDL, pages 585–604, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F Gelbukh</author>
<author>G Sidorov</author>
<author>E Lavin-Villa</author>
<author>L Chanona-Hern´andez</author>
</authors>
<title>Automatic term extraction using log-likelihood based comparison with general reference corpus.</title>
<date>2010</date>
<booktitle>In NLDB,</booktitle>
<pages>248--255</pages>
<marker>Gelbukh, Sidorov, Lavin-Villa, Chanona-Hern´andez, 2010</marker>
<rawString>A. F. Gelbukh, G. Sidorov, E. Lavin-Villa, and L. Chanona-Hern´andez. 2010. Automatic term extraction using log-likelihood based comparison with general reference corpus. In NLDB, pages 248–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Gianoti</author>
<author>A Di Felippo</author>
</authors>
<title>Extrac¸˜ao de conhecimento terminol´ogico no projeto TermiNet.</title>
<date>2011</date>
<booktitle>Instituto de Ciˆencias Matem´aticas e de Computac¸˜ao (ICMC) - USP, SP,</booktitle>
<tech>Technical Report NILC-TR-11-01,</tech>
<marker>Gianoti, Di Felippo, 2011</marker>
<rawString>A. C. Gianoti and A. Di Felippo. 2011. Extrac¸˜ao de conhecimento terminol´ogico no projeto TermiNet. Technical Report NILC-TR-11-01, Instituto de Ciˆencias Matem´aticas e de Computac¸˜ao (ICMC) - USP, SP, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hall</author>
<author>E Frank</author>
<author>G Holmes</author>
<author>B Pfahringer</author>
<author>P Reutemann</author>
<author>I H Witten</author>
</authors>
<title>The WEKA data mining software: An update.</title>
<date>2009</date>
<booktitle>In SIGKDD-ACM,</booktitle>
<volume>11</volume>
<pages>10--18</pages>
<contexts>
<context position="15733" citStr="Hall et al., 2009" startWordPosition="2564" endWordPosition="2567">EaD, and N&amp;N corpora, respectively. When using the C1 cut-off, we decreased to 55,15%, 45,82%, and 57,04%, and C2 decreased 63.10%, 63.18%, 66.94% in relation to the number of all the obtained candidates (without cutt-offs). 5 Experimental Evaluation and Results The first evaluation aimed to identify which features must be used for ATE (see Section 3). For that, we applied 2 methods that select attributes by evaluating the attribute subsets. Their evaluation is based on consistency (CBF) and correlation (CFS). We also tested search methods. The combination of these methods, available in WEKA (Hall et al., 2009), is: CFS SubsetEval using the RankSearch Filter as search method (CFS R), CFS SubsetEval using the BestFirst as search method (CFS BF), CBF SubsetEval using the Ranking Filter (C R), and CBF SubsetEval using the Greedy Stepwise (C G). These methods return feature sets that are considered the most representative for the term classification (Table 2). For the EaD corpus, the CG attribute selection method did not select any feature. For our experiments, we also considered all the features (referred by All). Additionally, we compared the use of two cut-off types for each feature set, C1 and C2, d</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. 2009. The WEKA data mining software: An update. In SIGKDD-ACM, volume 11, pages 10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Liu</author>
<author>S Liu</author>
<author>Z Chen</author>
</authors>
<title>An evaluation on feature selection for text clustering.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Int. CNF on Machine Learning,</booktitle>
<pages>488--495</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="4199" citStr="Liu et al., 2003" startWordPosition="664" endWordPosition="667"> range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16–23, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics speech - POS) knowledge to more sophisticated hybrid knowledge, such as the analysis of the term context. As far as we know, the combined use of this specific knowledge has not been applied before. Another difference is that we apply 3 statistical features (Term Variance (Liu et al., 2005), Term Variance Quality (Dhillon et al., 2003), and Term Contribution (Liu et al., 2003)) that to date have only been used for attribute selection and not for term extraction. As far as we know, the combined use of this specific knowledge and feature feedback has not been applied before. We also propose 4 new linguistic features for ATE. All these features are detailed in Section 4. Finally, for the first time, ML is being applied in the task of ATE in Brazilian Portuguese (BP) corpora. Our approach may also be easily adapted to other languages. We focus on extracting only unigram terms, since this is already a complex task. We run our experiments on 3 different corpora. Our main</context>
<context position="13419" citStr="Liu et al., 2003" startWordPosition="2176" endWordPosition="2179">mber of nouns stemmed terms come from higher number of nouns than adjectives or verbs N adj ° number of adjectives N verb ° number of verbs N PO ° total of words from which stemmed TCs come from The seven statistical features SG** n-gram length each domain has a term pattern TF Term Frequency terms have neither low nor very high frequencies DF Document Frequency terms appear in at least certain number of documents TFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus (Salton and Buckley, 1987) but they occur in few documents in this corpus TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a non-uniform distribution throughout corpus (higher variance) TVQ* Term Variance Quality (Dhillon et al., 2003) The four hybrid features GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus Freq GC CT frequency in GC C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms NC-value CT context (Frantzi et al., 1998) candidate context helps to extract terms have as fe</context>
</contexts>
<marker>Liu, Liu, Chen, 2003</marker>
<rawString>T. Liu, S. Liu, and Z. Chen. 2003. An evaluation on feature selection for text clustering. In Proceedings of the 10th Int. CNF on Machine Learning, pages 488– 495, San Francisco, CA, USA. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Liu</author>
<author>J Kang</author>
<author>J Yu</author>
<author>Z Wang</author>
</authors>
<title>A comparative study on unsupervised feature selection methods for text clustering.</title>
<date>2005</date>
<booktitle>In Proc of IEEE NLP-KE,</booktitle>
<pages>597--601</pages>
<contexts>
<context position="4111" citStr="Liu et al., 2005" startWordPosition="648" endWordPosition="651">crease the silence and noise and, consequently, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16–23, Atlanta, Georgia, 13 June 2013. c�2013 Association for Computational Linguistics speech - POS) knowledge to more sophisticated hybrid knowledge, such as the analysis of the term context. As far as we know, the combined use of this specific knowledge has not been applied before. Another difference is that we apply 3 statistical features (Term Variance (Liu et al., 2005), Term Variance Quality (Dhillon et al., 2003), and Term Contribution (Liu et al., 2003)) that to date have only been used for attribute selection and not for term extraction. As far as we know, the combined use of this specific knowledge and feature feedback has not been applied before. We also propose 4 new linguistic features for ATE. All these features are detailed in Section 4. Finally, for the first time, ML is being applied in the task of ATE in Brazilian Portuguese (BP) corpora. Our approach may also be easily adapted to other languages. We focus on extracting only unigram terms, since</context>
<context position="13506" citStr="Liu et al., 2005" startWordPosition="2190" endWordPosition="2193"> adj ° number of adjectives N verb ° number of verbs N PO ° total of words from which stemmed TCs come from The seven statistical features SG** n-gram length each domain has a term pattern TF Term Frequency terms have neither low nor very high frequencies DF Document Frequency terms appear in at least certain number of documents TFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus (Salton and Buckley, 1987) but they occur in few documents in this corpus TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a non-uniform distribution throughout corpus (higher variance) TVQ* Term Variance Quality (Dhillon et al., 2003) The four hybrid features GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus Freq GC CT frequency in GC C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms NC-value CT context (Frantzi et al., 1998) candidate context helps to extract terms have as features N Noun = 2 (educators and education), N Adj = 1 educative, N Verb = 1 (educate),</context>
</contexts>
<marker>Liu, Kang, Yu, Wang, 2005</marker>
<rawString>L. Liu, J. Kang, J. Yu, and Z. Wang. 2005. A comparative study on unsupervised feature selection methods for text clustering. In Proc of IEEE NLP-KE, pages 597–601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lopes</author>
</authors>
<title>Extrac¸˜ao autom´atica de conceitos a partir de textos em lingua portugesa.</title>
<date>2012</date>
<booktitle>Ph.D. thesis, Porto Alegre, RS. Pontif´ıcia Universidade do Rio Grande do Sul (PUCRS).</booktitle>
<contexts>
<context position="5399" citStr="Lopes, 2012" startWordPosition="876" endWordPosition="877">ra. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spanish, P=78.2% 2It is not specified if (Zhang et al., 2010) extracted </context>
</contexts>
<marker>Lopes, 2012</marker>
<rawString>L. Lopes. 2012. Extrac¸˜ao autom´atica de conceitos a partir de textos em lingua portugesa. Ph.D. thesis, Porto Alegre, RS. Pontif´ıcia Universidade do Rio Grande do Sul (PUCRS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Loukachevitch</author>
</authors>
<title>Automatic term recognition needs multiple evidence. In</title>
<date>2012</date>
<booktitle>Proc of the 8th on LREC,</booktitle>
<pages>2401--2407</pages>
<editor>N. Calzolari, K. Choukri, T. Declerck, M. Dogan, B. Maegaard, J. Mariani, Odijk, and S. Piperidis, editors,</editor>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="3139" citStr="Loukachevitch, 2012" startWordPosition="487" endWordPosition="488">em. Since the ATE approaches generate large lists of TCs, we have the third problem that is the time and human effort spent for validating the TCs, which usually is manually performed. The fourth problem is that the results are still not satisfactory and there is a natural ATE challenge since the difficulty in obtaining a consensus among the experts about which words are terms of a specific domain (Vivaldi and Rodr´ıguez, 2007). Our proposed ATE approach uses machine learning (ML), since it has been achieving high precision values (Zhang et al., 2008; Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012). Although ML may also generate noise and silence, it facilitates the use of a large number of TCs and their features, since ML techniques learn by themselves how to recognize a term and then they save time extracting them. Our approach differs from others because we adopt a rich feature set using varied knowledge levels. With this, it is possible to decrease the silence and noise and, consequently, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16–23,</context>
</contexts>
<marker>Loukachevitch, 2012</marker>
<rawString>N. Loukachevitch. 2012. Automatic term recognition needs multiple evidence. In N. Calzolari, K. Choukri, T. Declerck, M. Dogan, B. Maegaard, J. Mariani, Odijk, and S. Piperidis, editors, Proc of the 8th on LREC, pages 2401–2407, Istanbul, Turkey. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Miiller</author>
<author>J Dorre</author>
</authors>
<title>The taxgen framework: Automating the generation of a taxonomy for a large document collection.</title>
<date>1999</date>
<booktitle>In Proceedings of the Thirty-Second Annual Hawaii International Conference on System Sciences (HICSS),</booktitle>
<volume>2</volume>
<pages>2034--2042</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<marker>Miiller, Dorre, 1999</marker>
<rawString>A. Miiller and J. Dorre. 1999. The taxgen framework: Automating the generation of a taxonomy for a large document collection. In Proceedings of the Thirty-Second Annual Hawaii International Conference on System Sciences (HICSS), volume 2, pages 2034–2042, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nazar</author>
</authors>
<title>A statistical approach to term extraction.</title>
<date>2011</date>
<journal>Int. Journal of English Studies,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="5363" citStr="Nazar, 2011" startWordPosition="870" endWordPosition="871">ur experiments on 3 different corpora. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spanish, P=78.2% 2It is not specifie</context>
</contexts>
<marker>Nazar, 2011</marker>
<rawString>R. Nazar. 2011. A statistical approach to term extraction. Int. Journal of English Studies, 11(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>Proc of the CNF on EMNLP,</booktitle>
<pages>491--497</pages>
<contexts>
<context position="19841" citStr="Ratnaparkhi, 1996" startWordPosition="3304" endWordPosition="3305">cribed in Section 2. Therefore, this is the state of the art for unigrams extraction for Portuguese. In order to compare this work with our results of the EaD and N&amp;N corpora, we implemented the ATE method of Zavaglia et al. We have to mention that this method uses the normalization technique called lemmatization instead of stemming, which we used in our method. The only difference between our implementation descriptions and the original method is that we POS tagged and lemmatizated the texts using the same parser (PALAVRAS10 (Bick, 2000)) used in our experiments instead of the MXPOST tagger (Ratnaparkhi, 1996). For all used corpora, we obtained better results of precision and F-measure comparing with the baselines. In general, we improve the ATE precision scores, for the EaD corpus, eleven times (from 6.1% to 66.66%) and, for the N&amp;N corpus, one and a half times (from 35.4% to 61.03%), both comparing our results with the use of TFIDF. For the ECO corpus, we improve four and a half times (from 12.9% to 60%), by comparing with the use of frequency. We improve the ATE F-measure scores, for the EaD corpus, one and a half times (from 10.93% to 17.58%); for the ECO corpus, we slightly improve the results</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. Proc of the CNF on EMNLP, pages 491–497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<title>Term weighting approaches in automatic text retrieval.</title>
<date>1987</date>
<tech>Technical report,</tech>
<location>Ithaca, NY, USA.</location>
<contexts>
<context position="13330" citStr="Salton and Buckley, 1987" startWordPosition="2160" endWordPosition="2163">rns IP indicative phrases IPs may identify definitions/descriptions that may be terms N noun ° number of nouns stemmed terms come from higher number of nouns than adjectives or verbs N adj ° number of adjectives N verb ° number of verbs N PO ° total of words from which stemmed TCs come from The seven statistical features SG** n-gram length each domain has a term pattern TF Term Frequency terms have neither low nor very high frequencies DF Document Frequency terms appear in at least certain number of documents TFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus (Salton and Buckley, 1987) but they occur in few documents in this corpus TCo* Term Contribution (Liu et al., 2003) terms help to distinguish the different documents TV* Term Variance (Liu et al., 2005) terms do not have low frequency in documents and maintain a non-uniform distribution throughout corpus (higher variance) TVQ* Term Variance Quality (Dhillon et al., 2003) The four hybrid features GC CT occurrence in general corpus terms do not occur with high frequency in a general corpus Freq GC CT frequency in GC C-value the potential of a CT to be a term (Frantzi et al., 1998) the C-value helps to extract terms NC-va</context>
</contexts>
<marker>Salton, Buckley, 1987</marker>
<rawString>G. Salton and C. Buckley. 1987. Term weighting approaches in automatic text retrieval. Technical report, Ithaca, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W C Souza</author>
<author>A Di Felippo</author>
</authors>
<title>Um exercfcio em ling¨uistica de corpus no ˆambito do projeto TermiNet.</title>
<date>2010</date>
<tech>Technical Report NILC-TR-10-08, ICMC -USP, SP,</tech>
<marker>Souza, Di Felippo, 2010</marker>
<rawString>J. W. C. Souza and A. Di Felippo. 2010. Um exercfcio em ling¨uistica de corpus no ˆambito do projeto TermiNet. Technical Report NILC-TR-10-08, ICMC -USP, SP, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ventura</author>
<author>J F Silva</author>
</authors>
<title>Ranking and extraction of relevant single words in text.</title>
<date>2008</date>
<pages>265--284</pages>
<editor>In Cesare Rossi, editor, Brain, Vision and AI,</editor>
<publisher>InTech, Education and Publishing.</publisher>
<contexts>
<context position="5772" citStr="Ventura and Silva, 2008" startWordPosition="936" endWordPosition="939">ction 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spanish, P=78.2% 2It is not specified if (Zhang et al., 2010) extracted simple or complex terms. and R=60.8%. For Spanish, the Greek forms of a candidate and their prefix may help to extract terms (e.g., the Greek formant laring that belongs to the term laringoespasm in the medical domain) (Vivaldi and Rodriguez, 2007), achieving about P=55.4% and R=58.1%. For Spanish, (Gelbukh et al., 2010) compared TCs of a domain with words of a general c</context>
</contexts>
<marker>Ventura, Silva, 2008</marker>
<rawString>J. Ventura and J. F. Silva. 2008. Ranking and extraction of relevant single words in text. In Cesare Rossi, editor, Brain, Vision and AI, pages 265–284. InTech, Education and Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Vivaldi</author>
<author>H Rodrfguez</author>
</authors>
<title>Evaluation of terms and term extraction systems: A practical approach.</title>
<date>2007</date>
<journal>Terminology,</journal>
<volume>13</volume>
<issue>2</issue>
<marker>Vivaldi, Rodrfguez, 2007</marker>
<rawString>J. Vivaldi and H. Rodrfguez. 2007. Evaluation of terms and term extraction systems: A practical approach. Terminology, 13(2):225–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Vivaldi</author>
<author>L A Cabrera-Diego</author>
<author>G Sierra</author>
<author>M Pozzi</author>
</authors>
<title>Using wikipedia to validate the terminology found in a corpus of basic textbooks.</title>
<date>2012</date>
<booktitle>Proc of the 8th Int. CNF on LREC,</booktitle>
<editor>In N. Calzolari, K. Choukri, T. Declerck, M. U. Dogan, B. Maegaard, J. Mariani, J. Odijk, and S. Piperidis, editors,</editor>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="5385" citStr="Vivaldi et al., 2012" startWordPosition="872" endWordPosition="875">s on 3 different corpora. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spanish, P=78.2% 2It is not specified if (Zhang et al., 20</context>
</contexts>
<marker>Vivaldi, Cabrera-Diego, Sierra, Pozzi, 2012</marker>
<rawString>J. Vivaldi, L. A. Cabrera-Diego, G. Sierra, and M. Pozzi. 2012. Using wikipedia to validate the terminology found in a corpus of basic textbooks. In N. Calzolari, K. Choukri, T. Declerck, M. U. Dogan, B. Maegaard, J. Mariani, J. Odijk, and S. Piperidis, editors, Proc of the 8th Int. CNF on LREC, Istanbul, Turkey. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining:</title>
<date>2005</date>
<booktitle>Practical Machine Learning Tools and Techniques, Second Edition (Morgan Kaufmann Series in Data Management Systems).</booktitle>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="17533" citStr="Witten and Frank, 2005" startWordPosition="2906" endWordPosition="2909">FIDF, TV, CFS R method. TCo, POS IP, Cvalue, N Noun, POS, N Adj, N PO C R Freq, DF, TFIDF, Freq, DF, TFIDF, Freq, DF, TFIDF, TV, TVQ, TCo, IP, TV, TVQ, TCo, GC, TV, TVQ, TCo, GC, GC, POS, FreqGC, Cvalue, NCvalue, IP, S, Cvalue, POS, NCvalue, Cvalue, IP, S, N S, POS, NCvalue, N S, N Adj, N Noun, N Noun, N Adj, N Noun, N Adj, N Verb, N PO N Verb, N PO N Verb, N PO C G Method did Freq, DF, TFIDF, Freq, DF, TFIDF, S, not select any TV, TVQ, GC, IP, TV, TVQ, TCo, IP, feature. N S, NCvalue, NCvalue, N S, POS, S, N Noun, POS, GC, N Noun, N PO, N Adj, N PO N Verb, N Adj able in WEKA and described in (Witten and Frank, 2005). We run the experiments on a 10 fold crossvalidation and calculated the precision, recall, and F-measure scores of term classification according to the gold standard of unigrams of each corpus. Using default parameter values for SMO, the results were lower than the other inductors. Due to this fact and the lack of space in the paper, we do not present the SMO results here. The best precision obtained for the EaD corpus using the term classification, 66.66%, was achieved by the C R attribute selection method with the C2 cut-off (C R-C2) using the JRIP inductor. The best recall score, 20.96%, w</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I. H. Witten and E. Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques, Second Edition (Morgan Kaufmann Series in Data Management Systems). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zavaglia</author>
<author>L H M Oliveira</author>
<author>M G V Nunes</author>
<author>S M Alu´ısio</author>
</authors>
<title>Estrutura ontol´ogica e unidades lexicais: uma aplicac¸˜ao computacional no dom´ınio da ecologia.</title>
<date>2007</date>
<booktitle>In Proc. of the 5th Wksp em Tecnologia da Informac¸˜ao e da Linguagem Humana,</booktitle>
<pages>1575--1584</pages>
<publisher>SBC.</publisher>
<marker>Zavaglia, Oliveira, Nunes, Alu´ısio, 2007</marker>
<rawString>C. Zavaglia, L. H. M. Oliveira, M. G. V. Nunes, and S. M. Alu´ısio. 2007. Estrutura ontol´ogica e unidades lexicais: uma aplicac¸˜ao computacional no dom´ınio da ecologia. In Proc. of the 5th Wksp em Tecnologia da Informac¸˜ao e da Linguagem Humana, pages 1575– 1584, RJ, Brazil. SBC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhang</author>
<author>J Iria</author>
<author>C Brewster</author>
<author>F Ciravegna</author>
</authors>
<title>A comparative evaluation of term recognition algorithms.</title>
<date>2008</date>
<booktitle>Proc of the 6th on LREC,</booktitle>
<pages>2108--2113</pages>
<editor>In N. Calzolari (CNF Chair), K. Choukri, B. Maegaard, J. Mariani, J. Odjik, S. Piperidis, and D. Tapias, editors,</editor>
<publisher>ELRA.</publisher>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="3075" citStr="Zhang et al., 2008" startWordPosition="475" endWordPosition="478"> of candidate representation) that requires time to process them. Since the ATE approaches generate large lists of TCs, we have the third problem that is the time and human effort spent for validating the TCs, which usually is manually performed. The fourth problem is that the results are still not satisfactory and there is a natural ATE challenge since the difficulty in obtaining a consensus among the experts about which words are terms of a specific domain (Vivaldi and Rodr´ıguez, 2007). Our proposed ATE approach uses machine learning (ML), since it has been achieving high precision values (Zhang et al., 2008; Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012). Although ML may also generate noise and silence, it facilitates the use of a large number of TCs and their features, since ML techniques learn by themselves how to recognize a term and then they save time extracting them. Our approach differs from others because we adopt a rich feature set using varied knowledge levels. With this, it is possible to decrease the silence and noise and, consequently, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedin</context>
<context position="5330" citStr="Zhang et al., 2008" startWordPosition="862" endWordPosition="865">this is already a complex task. We run our experiments on 3 different corpora. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spa</context>
</contexts>
<marker>Zhang, Iria, Brewster, Ciravegna, 2008</marker>
<rawString>Z. Zhang, J. Iria, C. Brewster, and F. Ciravegna. 2008. A comparative evaluation of term recognition algorithms. In N. Calzolari (CNF Chair), K. Choukri, B. Maegaard, J. Mariani, J. Odjik, S. Piperidis, and D. Tapias, editors, Proc of the 6th on LREC, pages 2108–2113, Marrakech, Morocco. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhang</author>
<author>Y Song</author>
<author>A Fang</author>
</authors>
<title>Term recognition using conditional random fields.</title>
<date>2010</date>
<booktitle>In Proc of IEEE NLP-KE,</booktitle>
<pages>333--336</pages>
<contexts>
<context position="3117" citStr="Zhang et al., 2010" startWordPosition="483" endWordPosition="486">s time to process them. Since the ATE approaches generate large lists of TCs, we have the third problem that is the time and human effort spent for validating the TCs, which usually is manually performed. The fourth problem is that the results are still not satisfactory and there is a natural ATE challenge since the difficulty in obtaining a consensus among the experts about which words are terms of a specific domain (Vivaldi and Rodr´ıguez, 2007). Our proposed ATE approach uses machine learning (ML), since it has been achieving high precision values (Zhang et al., 2008; Foo and Merkel, 2010; Zhang et al., 2010; Loukachevitch, 2012). Although ML may also generate noise and silence, it facilitates the use of a large number of TCs and their features, since ML techniques learn by themselves how to recognize a term and then they save time extracting them. Our approach differs from others because we adopt a rich feature set using varied knowledge levels. With this, it is possible to decrease the silence and noise and, consequently, to improve the ATE results. Our features range from simple statistical (e.g., term frequency) and linguistic (e.g., part of Proceedings of the NAACL HLT 2013 Student Research </context>
<context position="5350" citStr="Zhang et al., 2010" startWordPosition="866" endWordPosition="869">mplex task. We run our experiments on 3 different corpora. Our main contribution is the improvement of precision (in the best case, we improve the results 11 times) and F-measure (in the best case, we improve 2 times). Section 2 presents the main related work. Section 3 describes our ATE approach. Section 4 details the experiments, and Section 5 reports the results. Conclusions and future work are presented in Section 6. 2 Related Work There are several recent and interesting studies that are not focused on extracting unigrams (Estop`a et al., 2000; Almeida and Vale, 2008; Zhang et al., 2008; Zhang et al., 2010; Nazar, 2011; Vivaldi et al., 2012; Lopes, 2012). Normally, ATE studies use corpora of different domain and language and, in some cases, the authors use different evaluation measures. Regardless of variation (e.g., the size of the test corpora), we mention studies that have highlighted results for unigrams2. When possible, we show the best precision (P) of the related work and its recall (R). (Ventura and Silva, 2008) extracted terms using statistical measures that consider the predecessors and successors of TCs. They achieved, for English, P=81.5% and R=55.4% and, for Spanish, P=78.2% 2It is</context>
</contexts>
<marker>Zhang, Song, Fang, 2010</marker>
<rawString>X. Zhang, Y. Song, and A. Fang. 2010. Term recognition using conditional random fields. In Proc of IEEE NLP-KE, pages 333–336.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>