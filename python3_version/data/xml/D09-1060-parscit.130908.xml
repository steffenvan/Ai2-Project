<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997646">
Improving Dependency Parsing with Subtrees from Auto-Parsed Data
</title>
<author confidence="0.996741">
Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa
</author>
<affiliation confidence="0.9932245">
Language Infrastructure Group, MASTAR Project
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.916535">
3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289
</address>
<email confidence="0.958114">
{chenwl, kazama, uchimoto, torisawa}@nict.go.jp
</email>
<sectionHeader confidence="0.994288" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987666666667">
This paper presents a simple and effective
approach to improve dependency parsing
by using subtrees from auto-parsed data.
First, we use a baseline parser to parse
large-scale unannotated data. Then we ex-
tract subtrees from dependency parse trees
in the auto-parsed data. Finally, we con-
struct new subtree-based features for pars-
ing algorithms. To demonstrate the ef-
fectiveness of our proposed approach, we
present the experimental results on the En-
glish Penn Treebank and the Chinese Penn
Treebank. These results show that our ap-
proach significantly outperforms baseline
systems. And, it achieves the best accu-
racy for the Chinese data and an accuracy
which is competitive with the best known
systems for the English data.
</bodyText>
<sectionHeader confidence="0.998126" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.987994927272727">
Dependency parsing, which attempts to build de-
pendency links between words in a sentence, has
experienced a surge of interest in recent times,
owing to its usefulness in such applications as
machine translation (Nakazawa et al., 2006) and
question answering (Cui et al., 2005). To ob-
tain dependency parsers with high accuracy, super-
vised techniques require a large amount of hand-
annotated data. While hand-annotated data are
very expensive, large-scale unannotated data can
be obtained easily. Therefore, the use of large-
scale unannotated data in training is an attractive
idea to improve dependency parsing performance.
In this paper, we present an approach that ex-
tracts subtrees from dependency trees in auto-
parsed data to improve dependency parsing. The
auto-parsed data are generated from large-scale
unannotated data by using a baseline parser. Then,
from dependency trees in the data, we extract dif-
ferent types of subtrees. Finally, we represent
subtree-based features on training data to train de-
pendency parsers.
The use of auto-parsed data is not new. How-
ever, unlike most of the previous studies (Sagae
and Tsujii, 2007; Steedman et al., 2003) that im-
proved the performance by using entire trees from
auto-parsed data, we exploit partial information
(i.e., subtrees) in auto-parsed data. In their ap-
proaches, they used entire auto-parsed trees as
newly labeled data to train the parsing models,
while we use subtree-based features and employ
the original gold-standard data to train the mod-
els. The use of subtrees instead of complete trees
can be justified by the fact that the accuracy of par-
tial dependencies is much higher than that of en-
tire dependency trees. Previous studies (McDon-
ald and Pereira, 2006; Yamada and Matsumoto,
2003; Zhang and Clark, 2008) show that the accu-
racies of complete trees are about 40% for English
and about 35% for Chinese, while the accuracies
of relations between two words are much higher:
about 90% for English and about 85% for Chinese.
From these observations, we may conjecture that
it is possible to conduct a more effective selection
by using subtrees as the unit of information.
The use of word pairs in auto-parsed data was
tried in van Noord (2007) and Chen et al. (2008).
However, the information on word pairs is limited.
To provide richer information, we consider more
words besides word pairs. Specifically, we use
subtrees containing two or three words extracted
from dependency trees in the auto-parsed data. To
demonstrate the effectiveness of our proposed ap-
proach, we present experimental results on En-
570
</bodyText>
<note confidence="0.9990855">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 570–579,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999523888888889">
glish and Chinese data. We show that this sim-
ple approach greatly improves the accuracy and
that the use of richer structures (i.e, word triples)
indeed gives additional improvement. We also
demonstrate that our approach and other improve-
ment techniques (Koo et al., 2008; Nivre and Mc-
Donald, 2008) are complementary and that we can
achieve very high accuracies when we combine
our method with other improvement techniques.
Specifically, we achieve the best accuracy for the
Chinese data.
The rest of this paper is as follows: Section 2
introduces the background of dependency parsing.
Section 3 proposes an approach for extracting sub-
trees and represents the subtree-based features for
dependency parsers. Section 4 explains the ex-
perimental results and Section 5 discusses related
work. Finally, in section 6 we draw conclusions.
</bodyText>
<sectionHeader confidence="0.977607" genericHeader="method">
2 Dependency parsing
</sectionHeader>
<bodyText confidence="0.996172888888889">
Dependency parsing assigns head-dependent rela-
tions between the words in a sentence. A sim-
ple example is shown in Figure 1, where an arc
between two words indicates a dependency rela-
tion between them. For example, the arc between
“ate” and “fish” indicates that “ate” is the head of
“fish” and “fish” is the dependent. The arc be-
tween “ROOT” and “ate” indicates that “ate” is the
ROOT of the sentence.
</bodyText>
<figureCaption confidence="0.988315">
Figure 1: Example for dependency structure
</figureCaption>
<subsectionHeader confidence="0.99589">
2.1 Parsing approach
</subsectionHeader>
<bodyText confidence="0.9993298125">
For dependency parsing, there are two main
types of parsing models (Nivre and McDonald,
2008): graph-based model and transition-based
model, which achieved state-of-the-art accuracy
for a wide range of languages as shown in recent
CoNLL shared tasks (Buchholz et al., 2006; Nivre
et al., 2007). Our subtree-based features can be
applied in both of the two parsing models.
In this paper, as the base parsing system, we
employ the graph-based MST parsing model pro-
posed by McDonald et al. (2005) and McDonald
and Pereira (2006), which uses the idea of Max-
imum Spanning Trees of a graph and large mar-
gin structured learning algorithms. The details
of parsing model were presented in McDonald et
al. (2005) and McDonald and Pereira (2006).
</bodyText>
<subsectionHeader confidence="0.999223">
2.2 Baseline Parser
</subsectionHeader>
<bodyText confidence="0.999837727272727">
In the MST parsing model, there are two well-used
modes: the first-order and the second-order. The
first-order model uses first-order features that are
defined over single graph edges and the second-
order model adds second-order features that are
defined on adjacent edges.
For the parsing of unannotated data, we use the
first-order MST parsing model, because we need
to parse a large number of sentences and the parser
must be fast. We call this parser the Baseline
Parser.
</bodyText>
<sectionHeader confidence="0.948772" genericHeader="method">
3 Our approach
</sectionHeader>
<bodyText confidence="0.999977285714286">
In this section, we describe our approach of ex-
tracting subtrees from unannotated data. First,
we preprocess unannotated data using the Baseline
Parser and obtain auto-parsed data. Subsequently,
we extract the subtrees from dependency trees in
the auto-parsed data. Finally, we generate subtree-
based features for the parsing models.
</bodyText>
<subsectionHeader confidence="0.999352">
3.1 Subtrees extraction
</subsectionHeader>
<bodyText confidence="0.988887666666666">
To ease explanation, we transform the dependency
structure into a more tree-like structure as shown
in Figure 2, the sentence is the same as the one in
</bodyText>
<figureCaption confidence="0.48804">
Figure 1.
</figureCaption>
<figure confidence="0.754431">
ROOT
ate
I ate the fish with a fork .
</figure>
<figureCaption confidence="0.788947">
Figure 2: Example for dependency structure in
tree-format
</figureCaption>
<bodyText confidence="0.99886">
Our task is to extract subtrees from dependency
trees. If a subtree contains two nodes, we call it a
bigram-subtree. If a subtree contains three nodes,
we call it a trigram-subtree.
</bodyText>
<subsectionHeader confidence="0.999956">
3.2 List of subtrees
</subsectionHeader>
<bodyText confidence="0.999616333333333">
We extract subtrees from dependency trees and
store them in list Lst. First, we extract bigram-
subtrees that contain two words. If two words have
</bodyText>
<figure confidence="0.8935008">
ROOT I ate the fish with a fork .
I fish with .
the fork
a
571
</figure>
<bodyText confidence="0.998554631578947">
a dependency relation in a tree, we add these two
words as a subtree into list Lst. Similarly, we can
extract trigram-subtrees. Note that the dependency
direction and the order of the words in the original
sentence are important in the extraction. To enable
this, the subtrees are encoded in the string format
that is expressed as st = w : wid : hid(−w :
wid : hidW, where w refers to a word in the
subtree, wid refers to the ID (starting from 1) of
a word in the subtree (words are ordered accord-
ing to the positions of the original sentence)2 , and
hid refers to an ID of the head of the word (hid=0
means that this word is the root of a subtree). For
example, “ate” and “fish” have a right dependency
arc in the sentence shown in Figure 2. So the
subtree is encoded as “ate:1:0-fish:2:1”. Figure 3
shows all the subtrees extracted from the sentence
in Figure 2, where the subtrees in (a) are bigram-
subtrees and the ones in (b) are trigram-subtrees.
</bodyText>
<figure confidence="0.887711875">
ate I:1:1-ate:2:0 ate ate:1:0-with:2:1 fish
I with the:1:1-fish:2:0
the
ate ate:1:0-fish:2:1 . ate:1:0-.:2:1
fork a:1:1-fork:2:0 with with:1:0-fork:2:1
a fork
(a)
(b)
</figure>
<figureCaption confidence="0.999957">
Figure 3: Examples of subtrees
</figureCaption>
<bodyText confidence="0.990090173913044">
Note that we only used the trigram-subtrees
containing a head, its dependent d1, and d1’s
leftmost right sibling3. We could not consider
the case where two children are on different
sides4 of the head (for instance, “I” and “fish”
for “ate” in Figure 2). We also do not use the
child-parent-grandparent type (grandparent-type
in short) trigram-subtrees. These are due to the
limitations of the parsing algorithm of (McDonald
and Pereira, 2006), which does not allow the fea-
tures defined on those types of trigram-subtrees.
We extract the subtrees from the auto-parsed
data, then merge the same subtrees into one en-
try, and count their frequency. We eliminate all
subtrees that occur only once in the data.
1+ refers to matching the preceding element one or more
times and is the same as a regular expression in Perl.
2So, wid is in fact redundant but we include it for ease of
understanding.
3Note that the order of the siblings is based on the order
of the words in the original sentence.
4Here, “side” means the position of a word relative to the
head in the original sentence.
</bodyText>
<subsectionHeader confidence="0.998246">
3.3 Subtree-based features
</subsectionHeader>
<bodyText confidence="0.999996521739131">
We represent new features based on the extracted
subtrees and call them subtree-based features. The
features based on bigram-subtrees correspond to
the first-order features in the MST parsing model
and those based on trigram-subtrees features cor-
respond to the second-order features.
We first group the extracted subtrees into dif-
ferent sets based on their frequencies. After ex-
periments with many different threshold settings
on development data sets, we chose the follow-
ing way. We group the subtrees into three sets
corresponding to three levels of frequency: “high-
frequency (HF)”, “middle-frequency (MF)”, and
“low-frequency (LF)”. HF, MF, and LF are used
as set IDs for the three sets. The following are the
settings: if a subtree is one of the TOP-10% most
frequent subtrees, it is in set HF; else if a subtree is
one of the TOP-20% subtrees, it is in set MF; else
it is in set LF. Note that we compute these levels
within a set of subtrees with the same number of
nodes. We store the set ID for every subtree in
Lst. For example, if subtree “ate:1:0-with:2:1” is
among the TOP-10%, its set ID is HF.
</bodyText>
<subsectionHeader confidence="0.724965">
3.3.1 First-order subtree-based features
</subsectionHeader>
<bodyText confidence="0.99972375">
The first-order features are based on bigram-
subtrees that are related to word pairs. We gener-
ate new features for a head h and a dependent d in
the parsing process. Figure 4-(a)5 shows the words
and their surrounding words, where h_1 refers to
the word to the left of the head in the sentence,
h+1 refers to the word to the right of the head, d_1
refers to the word to the left of the dependent, and
d+1 refers to the word to the right of the depen-
dent. Temporary bigram-subtrees are formed by
word pairs that are linked by dashed-lines in the
figure. Then we retrieve these subtrees in Lst to
get their set IDs (if a subtree is not included in
Lst, its set ID is ZERO. That is, we have four sets:
HF, MF, LF, and ZERO.).
Then we generate first-order subtree-based fea-
tures, consisting of indicator functions for set IDs
of the retrieved bigram-subtrees. When generating
subtree-based features, each dashed line in Figure
4-(a) triggers a different feature.
To demonstrate how to generate first-order
subtree-based features, we use an example that is
as follows. Suppose that we are going to parse the
sentence “He ate the cake with a fork.” as shown
</bodyText>
<figure confidence="0.987771454545454">
5Please note that d could be before h.
fish
ate
fish with
ate
ate:1:0-fish:2:1-with:3:1
ate
with .
ate:1:0-with:2:1-.:3:1
572
(b)
</figure>
<figureCaption confidence="0.8993635">
Figure 4: Word pairs and triple for feature repre-
sentation
</figureCaption>
<bodyText confidence="0.996533357142857">
in Figure 5, where h is “ate” and d is “with”.
We can generate the features for the pairs linked
by dashed-lines, such as h − d, h − d+1 and so
on. Then we have the temporary bigram-subtrees
“ate:1:0-with:2:1” for h − d and “ate:1:0-a:2:1”
for h − d+1, and so on. If we can find subtree
“ate:1:0-with:2:1” for h − d from Lst with set ID
HF, we generate the feature “H-D:HF”, and if we
find subtree “ate:1:0-a:2:1” for h−d+1 with set ID
ZERO, we generate the feature “H-D+1:ZERO”.
The other three features are also generated simi-
larly.
ate the cake with a fork .
h h+, d-, d d+,
</bodyText>
<figureCaption confidence="0.975583">
Figure 5: First-order subtree-based features
</figureCaption>
<subsectionHeader confidence="0.711925">
3.3.2 Second-order subtree-based features
</subsectionHeader>
<bodyText confidence="0.985844243243243">
The second-order features are based on trigram-
subtrees that are related to triples of words. We
generate features for a triple of a head h, its de-
pendent d1, and d1’s right-leftmost sibling d2.
The triple is shown in Figure 4-(b). A temporary
trigram-subtree is formed by the word forms of h,
d1, and d2. Then we retrieve the subtree in Lst to
get its set ID. In addition, we consider the triples
of “h-NULL”6, d1, and d2, which means that we
only check the words of sibling nodes without
checking the head word.
Then, we generate second-order subtree-based
features, consisting of indicator functions for set
IDs of the retrieved trigram-subtrees.
6h-NULL is a dummy token
We also generate combined features involving
the set IDs and part-of-speech tags of heads, and
the set IDs and word forms of heads. Specifically,
for any feature related to word form, we remove
this feature if the word is not one of the Top-N
most frequent words in the training data. We used
N=1000 for the experiments in this paper. This
method can reduce the size of the feature sets.
In this paper, we only used bigram-subtrees and
the limited form of trigram-subtrees, though in
theory we can use k-gram-subtrees, which are lim-
ited in the same way as our trigram subtrees, in
(k-1)th-order MST parsing models mentioned in
McDonald and Pereira (2006) or use grandparent-
type trigram-subtrees in parsing models of Car-
reras (2007). Although the higher-order MST
parsing models will be slow with exact inference,
requiring O(nk) time (McDonald and Pereira,
2006), it might be possible to use higher-order k-
gram subtrees with approximated parsing model
in the future. Of course, our method can also be
easily extended to the labeled dependency case.
</bodyText>
<sectionHeader confidence="0.999254" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999098541666667">
In order to evaluate the effectiveness of the
subtree-based features, we conducted experiments
on English data and Chinese Data.
For English, we used the Penn Treebank (Mar-
cus et al., 1993) in our experiments and the tool
“Penn2Malt”7 to convert the data into dependency
structures using a standard set of head rules (Ya-
mada and Matsumoto, 2003). To match previ-
ous work (McDonald et al., 2005; McDonald and
Pereira, 2006; Koo et al., 2008), we split the data
into a training set (sections 2-21), a development
set (Section 22), and a test set (section 23). Fol-
lowing the work of Koo et al. (2008), we used
the MXPOST (Ratnaparkhi, 1996) tagger trained
on training data to provide part-of-speech tags for
the development and the test set, and we used 10-
way jackknifing to generate tags for the training
set. For the unannotated data, we used the BLLIP
corpus (Charniak et al., 2000) that contains about
43 million words of WSJ text.8 We used the MX-
POST tagger trained on training data to assign
part-of-speech tags and used the Basic Parser to
process the sentences of the BLLIP corpus.
For Chinese, we used the Chinese Treebank
</bodyText>
<footnote confidence="0.945894333333333">
7http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html
8We ensured that the text used for extracting subtrees did
not include the sentences of the Penn Treebank.
</footnote>
<figure confidence="0.89222375">
... h_1 h h+1 ... d_1 d d+1 ...
(a)
... h ... d1 ... d2 ...
573
</figure>
<bodyText confidence="0.998502083333333">
(CTB) version 4.09 in the experiments. We also
used the “Penn2Malt” tool to convert the data and
created a data split: files 1-270 and files 400-931
for training, files 271-300 for testing, and files
301-325 for development. We used gold standard
segmentation and part-of-speech tags in the CTB.
The data partition and part-of-speech settings were
chosen to match previous work (Chen et al., 2008;
Yu et al., 2008). For the unannotated data, we
used the PFR corpus10, which has approximately
15 million words whose segmentation and POS
tags are given. We used its original segmentation
though there are differences in segmentation pol-
icy between CTB and this corpus. As for POS
tags, we discarded the original POS tags and as-
signed CTB style POS tags using a TNT-based
tagger (Brants, 2000) trained on the training data.
We used the Basic Parser to process all the sen-
tences of the PFR corpus.
We measured the parser quality by the unla-
beled attachment score (UAS), i.e., the percentage
of tokens (excluding all punctuation tokens) with
the correct HEAD. And we also evaluated on com-
plete dependency analysis.
</bodyText>
<subsectionHeader confidence="0.992956">
4.1 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9987638">
In our experiments, we used MSTParser, a
freely available implementation11 of the first- and
second-order MST parsing models. For baseline
systems, we used the first- and second-order basic
features, which were the same as the features used
by McDonald and Pereira (2006), and we used
the default settings of MSTParser throughout the
paper: iters=10; training-k=1; decode-type=proj.
We implemented our systems based on the MST-
Parser by incorporating the subtree-based features.
</bodyText>
<table confidence="0.945900888888889">
4.1.1 Main results of English data
English
UAS Complete
Ord1 90.95 37.45
Ord1s 91.76(+0.81) 40.68
Ord2 91.71 42.88
Ord2s 92.51(+0.80) 46.19
Ord2b 92.28(+0.57) 45.44
Ord2t 92.06(+0.35) 42.96
</table>
<tableCaption confidence="0.999525">
Table 1: Dependency parsing results for English
</tableCaption>
<footnote confidence="0.866371333333333">
9http://www.cis.upenn.edu/˜chinese/.
10http://www.icl.pku.edu.
11http://mstparser.sourceforge.net
</footnote>
<bodyText confidence="0.99994284">
The results are shown in Table 1, where
Ord1/Ord2 refers to a first-/second-order
MSTParser with basic features, Ord1s/Ord2s
refers to a first-/second-order MSTParser with
basic+subtree-based features, and the improve-
ments by the subtree-based features over the basic
features are shown in parentheses. Note that
we use both the bigram- and trigram- subtrees
in Ord2s. The parsers using the subtree-based
features consistently outperformed those using
the basic features. For the first-order parser,
we found that there is an absolute improvement
of 0.81 points (UAS) by adding subtree-based
features. For the second-order parser, we got an
absolute improvement of 0.8 points (UAS) by
including subtree-based features. The improve-
ments of parsing with subtree-based features were
significant in McNemar’s Test (p &lt; 10−6).
We also checked the sole effect of bigram- and
trigram-subtrees. The results are also shown in
Table 1, where Ord2b/Ord2t refers to a second-
order MSTParser with bigram-/trigram-subtrees
only. The results showed that trigram-subtrees can
provide further improvement, although the effect
of the bigram-subtrees seemed larger.
</bodyText>
<subsectionHeader confidence="0.521442">
4.1.2 Comparative results of English data
</subsectionHeader>
<bodyText confidence="0.99965936">
Table 2 shows the performance of the systems
that were compared, where Y&amp;M2003 refers to
the parser of Yamada and Matsumoto (2003),
CO2006 refers to the parser of Corston-Oliver et
al. (2006), Hall2006 refers to the parser of Hall
et al. (2006), Wang2007 refers to the parser of
Wang et al. (2007), Z&amp;C 2008 refers to the combi-
nation graph-based and transition-based system of
Zhang and Clark (2008), KOO08-dep1c/KOO08-
dep2c refers to a graph-based system with first-
/second-order cluster-based features by Koo et al.
(2008), and Carreras2008 refers to the paper of
Carreras et al. (2008). The results showed that
Ord2s performed better than the first five systems.
The second-order system of Koo et al. (2008) per-
formed better than our systems. The reason may
be that the MSTParser only uses sibling interac-
tions for second-order, while Koo et al. (2008)
uses both sibling and grandparent interactions, and
uses cluster-based features. Carreras et al. (2008)
reported a very high accuracy using information of
constituent structure of the TAG grammar formal-
ism. In our systems, we did not use such knowl-
edge.
Our subtree-based features could be combined
</bodyText>
<page confidence="0.638883">
574
</page>
<bodyText confidence="0.9998778">
with the techniques presented in other work,
such as the cluster-based features in Koo et al.
(2008), the integrating methods of Zhang and
Clark (2008), and Nivre and McDonald (2008),
and the parsing methods of Carreras et al. (2008).
</bodyText>
<table confidence="0.999058272727272">
English
UAS Complete
Y&amp;M2003 90.3 38.4
CO2006 90.8 37.6
Hall2006 89.4 36.4
Wang2007 89.2 34.4
Z&amp;C2008 92.1 45.4
KOO08-dep1c 92.23 –
KOO08-dep2c 93.16 –
Carreras2008 93.5 –
Ord1 90.95 37.45
Ord1s 91.76 40.68
Ord1c 91.88 40.71
Ord1i 91.68 41.43
Ord1sc 92.20 42.98
Ord1sci 92.60 44.28
Ord2 91.71 42.88
Ord2s 92.51 46.19
Ord2c 92.40 44.08
Ord2i 92.12 44.37
Ord2sc 92.70 46.56
Ord2sci 93.16 47.15
</table>
<tableCaption confidence="0.988632">
Table 2: Dependency parsing results for English,
</tableCaption>
<bodyText confidence="0.98857064">
for our parsers and previous work
To demonstrate that our approach and other
work are complementary, we thus implemented
a system using all the techniques we had at hand
that used subtree- and cluster-based features
and applied the integrating method of Nivre and
McDonald (2008). We used the word clustering
tool12, which was used by Koo et al. (2008), to
produce word clusters on the BLLIP corpus. The
cluster-based features were the same as the fea-
tures used by Koo et al. (2008). For the integrating
method, we used the transition MaxEnt-based
parser of Zhao and Kit (2008) because it was
faster than the MaltParser. The results are shown
in the bottom part of Table 2, where Ord1c/Ord2c
refers to a first-/second-order MSTParser with
cluster-based features, Ord1i/Ordli refers to a first-
/second-order MSTParser with integrating-based
features, Ord1sc/Ord2sc refers to a first-/second-
order MSTParser with subtree-based+cluster-
based features, and Ord1sci/Ord2sci refers to
a first-/second-order MSTParser with subtree-
based+cluster-based+integrating-based features.
Ord1c/Ord2c was worse than KOO08-dep1c/-
dep2c, but Ord1sci outperformed KOO08-dep1c
</bodyText>
<equation confidence="0.4893585">
12http://www.cs.berkeley.edu/˜pliang/software/brown-
cluster-1.2.zip
</equation>
<bodyText confidence="0.9995332">
and Ord2sci performed similarly to KOO08-dep2c
by using all of the techniques we had. These
results indicated that subtree-based features can
provide different information and work well with
other techniques.
</bodyText>
<subsectionHeader confidence="0.834351">
4.1.3 Main results of Chinese data
</subsectionHeader>
<bodyText confidence="0.998506416666667">
The results are shown in Table 3 where abbrevia-
tions are the same as in Table 1. As in the English
experiments, parsers with the subtree-based fea-
tures outperformed parsers with the basic features,
and second-order parsers outperformed first-order
parsers. For the first-order parser, the subtree-
based features provided 1.3 absolute points im-
provement. For the second-order parser, the
subtree-based features achieved an absolute im-
provement of 1.25 points. The improvements of
parsing with subtree-based features were signifi-
cant in McNemar’s Test (p &lt; 10−5).
</bodyText>
<table confidence="0.995983875">
Chinese
UAS Complete
Ord1 86.38 40.80
Ord1s 87.68(+1.30) 42.24
Ord2 88.18 47.12
Ord2s 89.43(+1.25) 47.53
Ord2b 89.16(+0.98) 47.12
Ord2t 88.55(+0.37) 47.12
</table>
<tableCaption confidence="0.99945">
Table 3: Dependency parsing results for Chinese.
</tableCaption>
<subsectionHeader confidence="0.454193">
4.1.4 Comparative results of Chinese data
</subsectionHeader>
<bodyText confidence="0.9470858">
Table 4 shows the comparative results, where
Wang2007 refers to the parser of Wang et
al. (2007), Chen2008 refers to the parser of Chen
et al. (2008), and Yu2008 refers to the parser of
Yu et al. (2008) that is the best reported results
for this data set. And “all words” refers to all the
sentences in test set and “&lt; 40 words”13 refers to
the sentences with the length up to 40. The table
shows that our parsers outperformed previous sys-
tems.
We also implemented integrating systems for
Chinese data as well. When we applied the
cluster-based features, the performance dropped a
little. The reason may be that we are using gold-
POS tags for Chinese data14. Thus we did not
13Wang et al. (2007) and Chen et al. (2008) reported the
scores on these sentences.
14We tried to use the cluster-based features for Chinese
with the same setting of POS tags as English data, then the
cluster-based features did provide improvement.
</bodyText>
<page confidence="0.832606">
575
</page>
<bodyText confidence="0.98934725">
use cluster-based features for the integrating sys-
tems. The results are shown in Table 4, where
Ord1si/Ord2si refers to the first-order/second-
order system with subtree-based+intergrating-
smhe tag
based features. We found that the integrating sys-
tems provided better results. Overall, we have
achieved a high accuracy, which is the best known
result for this dataset.
Zhang and Clark (2008) and Duan et al. (2007)
reported results on a different data split of Penn
Chinese Treebank. We also ran our systems
(Ord2s) on their data and provided UAS 86.70
(for non-root words)/77.39 (for root words), better
than their results: 86.21/76.26 in Zhang and Clark
(2008) and 84.36/73.70 in Duan et al. (2007).
</bodyText>
<table confidence="0.991431272727273">
Chinese
all words &lt; 40 words
UAS Complete UAS Complete
Wang2007 – – 86.6 28.4
Chen2008 86.52 – 88.4 –
Yu2008 87.26 – – –
Ord1s 87.68 42.24 91.11 54.40
Ord1si 88.24 43.96 91.32 55.93
Ord2s 89.43 47.53 91.67 59.77
Ord2si 89.91 48.56 92.34 62.83
hdsem
</table>
<tableCaption confidence="0.9207295">
Table 4: Dependency parsing results for Chinese,
for our parsers and for previous work
</tableCaption>
<note confidence="0.343709">
4.1.5 Effect of different sizes of unannotated
data
</note>
<bodyText confidence="0.998781888888889">
Here, we consider the improvement relative to the
sizes of the unannotated data. Figure 6 shows the
results of first-order parsers with different num-
bers of words in the unannotated data. Please note
that the size of full English unannotated data is
43M and the size of full Chinese unannotated data
is 15M. From the figure, we found that the parser
obtained more benefits as we added more unanno-
tated data.
</bodyText>
<figureCaption confidence="0.8303775">
Figure 6: Results with different sizes of large-
scale unannotated data.
</figureCaption>
<figure confidence="0.9917555">
0 1 2 3 4 5 6
Number of unknown words
</figure>
<figureCaption confidence="0.7696155">
Figure 7: Improvement relative to unknown words
for English
</figureCaption>
<figure confidence="0.995529">
0 1 2 3 4 5 6
Number of unknown words
</figure>
<figureCaption confidence="0.927671">
Figure 8: Improvement relative to unknown words
for Chinese
</figureCaption>
<subsectionHeader confidence="0.999529">
4.2 Additional Analysis
</subsectionHeader>
<bodyText confidence="0.999996">
In this section, we investigated the results on
sentence level from different views. For Fig-
ures 7-12, we classified each sentence into one of
three classes: “Better” for those where the pro-
posed parsers provided better results relative to
the parsers with basic features, “Worse” for those
where the proposed parsers provided worse results
relative to the basic parsers, and “NoChange” for
those where the accuracies remained the same.
</bodyText>
<subsectionHeader confidence="0.492455">
4.2.1 Unknown words
</subsectionHeader>
<bodyText confidence="0.993668307692308">
Here, we consider the unknown word15 problem,
which is an important issue for parsing. We cal-
culated the number of unknown words in one sen-
tence, and listed the changes of the sentences with
unknown words. Here, we compared the Ord1
system and the Ord1s system.
Figures 7 and 8 show the results, where the x
axis refers to the number of unknown words in one
sentence and the y axis shows the percentages of
the three classes. For example, for the sentences
having three unknown words in the Chinese data,
31.58% improved, 23.68% worsened, and 44.74%
were unchanged. We did not show the results of
</bodyText>
<figure confidence="0.979946375">
15An unknown word is a word that is not included in the
training data.
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Better
NoChange
Worse
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Better
NoChange
Worse
d
P
P
576
4
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Better
NoChange
Worse
0 1 2 3
Number of CCs
</figure>
<figureCaption confidence="0.9482435">
Figure 9: Improvement relative to number of
conjunctions for English
Figure 10: Improvement relative to number of
conjunctions for Chinese
</figureCaption>
<bodyText confidence="0.971263416666666">
(moth Pentag
the sentences with more than six unknown words
because their numbers were very small. The Bet-
ter and Worse curves showed that our approach al-
ways provided better results. The results indicated
that the improvements apparently became larger
when the sentences had more unknown words for
the Chinese data. And for the English data, the
graph also showed the similar trend, although the
improvements for the sentences have three and
four unknown words were slightly less than the
others.
</bodyText>
<subsectionHeader confidence="0.70779">
4.2.2 Coordinating conjunctions
</subsectionHeader>
<bodyText confidence="0.999983294117647">
We analyzed our new parsers’ behavior for coordi-
nating conjunction structures, which is a very dif-
ficult problem for parsing (Kawahara and Kuro-
hashi, 2008). Here, we compared the Ord2 system
with the Ord2s system.
Figures 9 and 10 show how the subtree-based
features affect accuracy as a function of the num-
ber of conjunctions, where the x axis refers to the
number of conjunctions in one sentence and the
y axis shows the percentages of the three classes.
The figures indicated that the subtree-based fea-
tures improved the coordinating conjunction prob-
lem. In the trigram-subtree list, many subtrees
are related to coordinating conjunctions, such as
“utilities:1:3 and:2:3 businesses:3:0” and “pull:1:0
and:2:1 protect:3:1”. These subtrees can provide
additional information for parsing models.
</bodyText>
<subsubsectionHeader confidence="0.624217">
4.2.3 PP attachment
</subsubsectionHeader>
<bodyText confidence="0.999990545454546">
We analyzed our new parsers’ behavior for
preposition-phrase attachment, which is also a dif-
ficult task for parsing (Ratnaparkhi et al., 1994).
We compared the Ord2 system with the Ord2s sys-
tem. Figures 11 and 12 show how the subtree-
based features affect accuracy as a function of the
number of prepositions, where the x axis refers to
the number of prepositions in one sentence and the
y axis shows the percentages of the three classes.
The figures indicated that the subtree-based fea-
tures improved preposition-phrase attachment.
</bodyText>
<sectionHeader confidence="0.99996" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999890470588235">
Our approach is to incorporate unannotated data
into parsing models for dependency parsing. Sev-
eral previous studies relevant to our approach have
been conducted.
Chen et al. (2008) previously proposed an ap-
proach that used the information on short de-
pendency relations for Chinese dependency pars-
ing. They only used the word pairs within two
word distances for a transition-based parsing al-
gorithm. The approach in this paper differs in
that we use richer information on trigram-subtrees
besides bigram-subtrees that contain word pairs.
And our work is focused on graph-based parsing
models as opposed to transition-based models. Yu
et al. (2008) constructed case structures from auto-
parsed data and utilized them in parsing. Com-
pared with their method, our method is much sim-
pler but has great effects.
Koo et al. (2008) used the Brown algorithm to
produce word clusters on large-scale unannotated
data and represented new features based on the
clusters for parsing models. The cluster-based fea-
tures provided very impressive results. In addition,
they used the parsing model by Carreras (2007)
that applied second-order features on both sibling
and grandparent interactions. Note that our ap-
proach and their approach are complementary in
that we can use both subtree- and cluster-based
features for parsing models. The experimental re-
sults showed that we achieved better accuracy for
first-order models when we used both of these two
types of features.
Sagae and Tsujii (2007) presented an co-
training approach for dependency parsing adap-
</bodyText>
<figure confidence="0.991379764705882">
577
6 7
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Better
NoChange
Worse
0 1 2 3
Number of prepositions
</figure>
<figureCaption confidence="0.9659205">
Figure 11: Improvement relative to number of
prepositions for English
Figure 12: Improvement relative to number of
prepositions for Chinese
</figureCaption>
<bodyText confidence="0.9667394375">
Penta (smoe
tation. They used two parsers to parse the sen-
tences in unannotated data and selected only iden-
tical results produced by the two parsers. Then,
they retrained a parser on newly parsed sentences
and the original labeled data. Our approach repre-
sents subtree-based features on the original gold-
standard data to retrain parsers. McClosky et
al. (2006) presented a self-training approach for
phrase structure parsing and the approach was
shown to be effective in practice. However,
their approach depends on a high-quality reranker,
while we simply augment the features of an ex-
isting parser. Moreover, we could use the output
of our systems for co-training/self-training tech-
niques.
</bodyText>
<sectionHeader confidence="0.999285" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999997071428571">
We present a simple and effective approach to
improve dependency parsing using subtrees from
auto-parsed data. In our method, first we use a
baseline parser to parse large-scale unannotated
data, and then we extract subtrees from depen-
dency parsing trees in the auto-parsed data. Fi-
nally, we construct new subtree-based features for
parsing models. The results show that our ap-
proach significantly outperforms baseline systems.
We also show that our approach and other tech-
niques are complementary, and then achieve the
best reported accuracy for the Chinese data and an
accuracy that is competitive with the best known
systems for the English data.
</bodyText>
<sectionHeader confidence="0.996463" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999961170212766">
T. Brants. 2000. TnT–a statistical part-of-speech tag-
ger. Proceedings of ANLP, pages 224–231.
S. Buchholz, E. Marsi, A. Dubey, and Y. Krymolowski.
2006. CoNLL-X shared task on multilingual depen-
dency parsing. Proceedings of CoNLL-X.
Xavier Carreras, Michael Collins, and Terry Koo.
2008. Tag, dynamic programming, and the percep-
tron for efficient, feature-rich parsing. In Proceed-
ings of CoNLL 2008, pages 9–16, Manchester, Eng-
land, August. Coling 2008 Organizing Committee.
X. Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proceedings of
the CoNLL Shared Task Session of EMNLP-CoNLL
2007, pages 957–961.
E. Charniak, D. Blaheta, N. Ge, K. Hall, J. Hale, and
M. Johnson. 2000. BLLIP 1987-89 WSJ Corpus
Release 1, LDC2000T43. Linguistic Data Consor-
tium.
WL. Chen, D. Kawahara, K. Uchimoto, YJ. Zhang, and
H. Isahara. 2008. Dependency parsing with short
dependency relations in unlabeled data. In Proceed-
ings of IJCNLP 2008.
S. Corston-Oliver, A. Aue, Kevin. Duh, and Eric Ring-
ger. 2006. Multilingual dependency parsing using
bayes point machines. In HLT-NAACL2006.
H. Cui, RX. Sun, KY. Li, MY. Kan, and TS. Chua.
2005. Question answering passage retrieval us-
ing dependency relations. In Proceedings of SIGIR
2005, pages 400–407, New York, NY, USA. ACM.
Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Proba-
bilistic models for action-based chinese dependency
parsing. In Proceedings of ECML/ECPPKDD, War-
saw, Poland.
Johan Hall, Joakim Nivre, and Jens Nilsson. 2006.
Discriminative classifiers for deterministic depen-
dency parsing. In In Proceedings of CoLING-ACL.
D. Kawahara and S. Kurohashi. 2008. Coordination
disambiguation without any similarities. In Pro-
ceedings of Coling 2008, pages 425–432, Manch-
ester, UK, August.
T. Koo, X. Carreras, and M. Collins. 2008. Simple
semi-supervised dependency parsing. In Proceed-
ings of ACL-08: HLT, Columbus, Ohio, June.
M. Marcus, B. Santorini, and M. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: the Penn Treebank. Computational Linguis-
ticss, 19(2):313–330.
</reference>
<page confidence="0.507123">
578
</page>
<reference confidence="0.999923262295082">
D. McClosky, E. Charniak, and M. Johnson. 2006.
Reranking and self-training for parser adaptation. In
Proceedings of Coling-ACL, pages 337–344.
R. McDonald and F. Pereira. 2006. Online learning
of approximate dependency parsing algorithms. In
Proc. of EACL2006.
R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line large-margin training of dependency parsers. In
Proc. of ACL 2005.
T. Nakazawa, K. Yu, D. Kawahara, and S. Kurohashi.
2006. Example-based machine translation based on
deeper nlp. In Proceedings of IWSLT 2006, pages
64–70, Kyoto, Japan.
J. Nivre and R. McDonald. 2008. Integrating graph-
based and transition-based dependency parsers. In
Proceedings of ACL-08: HLT, Columbus, Ohio,
June.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing. In Proceed-
ings of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007, pages 915–932.
A. Ratnaparkhi, J. Reynar, and S. Roukos. 1994. A
maximum entropy model for prepositional phrase at-
tachment. In Proceedings of HLT, pages 250–255.
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In Proceedings of EMNLP,
pages 133–142.
K. Sagae and J. Tsujii. 2007. Dependency parsing and
domain adaptation with LR models and parser en-
sembles. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 1044–1050.
M. Steedman, M. Osborne, A. Sarkar, S. Clark,
R. Hwa, J. Hockenmaier, P. Ruhlen, S. Baker, and
J. Crim. 2003. Bootstrapping statistical parsers
from small datasets. In Proceedings of EACL 2003,
pages 331–338.
Gertjan van Noord. 2007. Using self-trained bilexical
preferences to improve disambiguation accuracy. In
Proceedings of IWPT-07, June.
Qin Iris Wang, Dekang Lin, and Dale Schuurmans.
2007. Simple training of dependency parsers via
structured boosting. In Proceedings of IJCAI2007.
H. Yamada and Y. Matsumoto. 2003. Statistical de-
pendency analysis with support vector machines. In
Proceedings of IWPT2003, pages 195–206.
K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chi-
nese dependency parsing with large scale automat-
ically constructed case structures. In Proceedings
of Coling 2008, pages 1049–1056, Manchester, UK,
August.
Y. Zhang and S. Clark. 2008. A tale of two
parsers: Investigating and combining graph-based
and transition-based dependency parsing. In Pro-
ceedings of EMNLP 2008, pages 562–571, Hon-
olulu, Hawaii, October.
H. Zhao and CY. Kit. 2008. Parsing syntactic and
semantic dependencies with two single-stage max-
imum entropy models. In Proceedings of CoNLL
2008, pages 203–207, Manchester, England, Au-
gust.
</reference>
<page confidence="0.940296">
579
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.699101">
<title confidence="0.994273">Improving Dependency Parsing with Subtrees from Auto-Parsed Data</title>
<author confidence="0.764862">Wenliang Chen</author>
<author confidence="0.764862">Jun’ichi Kazama</author>
<author confidence="0.764862">Kiyotaka Uchimoto</author>
<author confidence="0.764862">Kentaro</author>
<affiliation confidence="0.9181635">Language Infrastructure Group, MASTAR National Institute of Information and Communications</affiliation>
<address confidence="0.992444">3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan,</address>
<email confidence="0.985816">kazama,uchimoto,</email>
<abstract confidence="0.997195263157895">This paper presents a simple and effective approach to improve dependency parsing by using subtrees from auto-parsed data. First, we use a baseline parser to parse large-scale unannotated data. Then we extract subtrees from dependency parse trees in the auto-parsed data. Finally, we construct new subtree-based features for parsing algorithms. To demonstrate the effectiveness of our proposed approach, we present the experimental results on the English Penn Treebank and the Chinese Penn Treebank. These results show that our approach significantly outperforms baseline systems. And, it achieves the best accuracy for the Chinese data and an accuracy which is competitive with the best known systems for the English data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT–a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>Proceedings of ANLP,</booktitle>
<pages>224--231</pages>
<contexts>
<context position="16712" citStr="Brants, 2000" startWordPosition="2791" endWordPosition="2792">for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008). For the unannotated data, we used the PFR corpus10, which has approximately 15 million words whose segmentation and POS tags are given. We used its original segmentation though there are differences in segmentation policy between CTB and this corpus. As for POS tags, we discarded the original POS tags and assigned CTB style POS tags using a TNT-based tagger (Brants, 2000) trained on the training data. We used the Basic Parser to process all the sentences of the PFR corpus. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens (excluding all punctuation tokens) with the correct HEAD. And we also evaluated on complete dependency analysis. 4.1 Experimental Results In our experiments, we used MSTParser, a freely available implementation11 of the first- and second-order MST parsing models. For baseline systems, we used the first- and second-order basic features, which were the same as the features used by McDonald an</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000. TnT–a statistical part-of-speech tagger. Proceedings of ANLP, pages 224–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
<author>A Dubey</author>
<author>Y Krymolowski</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>Proceedings of CoNLL-X.</booktitle>
<contexts>
<context position="5421" citStr="Buchholz et al., 2006" startWordPosition="847" endWordPosition="850">ure 1, where an arc between two words indicates a dependency relation between them. For example, the arc between “ate” and “fish” indicates that “ate” is the head of “fish” and “fish” is the dependent. The arc between “ROOT” and “ate” indicates that “ate” is the ROOT of the sentence. Figure 1: Example for dependency structure 2.1 Parsing approach For dependency parsing, there are two main types of parsing models (Nivre and McDonald, 2008): graph-based model and transition-based model, which achieved state-of-the-art accuracy for a wide range of languages as shown in recent CoNLL shared tasks (Buchholz et al., 2006; Nivre et al., 2007). Our subtree-based features can be applied in both of the two parsing models. In this paper, as the base parsing system, we employ the graph-based MST parsing model proposed by McDonald et al. (2005) and McDonald and Pereira (2006), which uses the idea of Maximum Spanning Trees of a graph and large margin structured learning algorithms. The details of parsing model were presented in McDonald et al. (2005) and McDonald and Pereira (2006). 2.2 Baseline Parser In the MST parsing model, there are two well-used modes: the first-order and the second-order. The first-order model</context>
</contexts>
<marker>Buchholz, Marsi, Dubey, Krymolowski, 2006</marker>
<rawString>S. Buchholz, E. Marsi, A. Dubey, and Y. Krymolowski. 2006. CoNLL-X shared task on multilingual dependency parsing. Proceedings of CoNLL-X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>9--16</pages>
<location>Manchester, England,</location>
<contexts>
<context position="19647" citStr="Carreras et al. (2008)" startWordPosition="3221" endWordPosition="3224">mparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et al. (2008) uses both sibling and grandparent interactions, and uses cluster-based features. Carreras et al. (2008) reported a very high accuracy using information of constituent structure of the TAG grammar formalism. In our systems, we did not use such knowledge. Our subtree-based features could be combined 574 with the techniques presented</context>
</contexts>
<marker>Carreras, Collins, Koo, 2008</marker>
<rawString>Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL 2008, pages 9–16, Manchester, England, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
</authors>
<title>Experiments with a higher-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>957--961</pages>
<contexts>
<context position="14236" citStr="Carreras (2007)" startWordPosition="2375" endWordPosition="2377">forms of heads. Specifically, for any feature related to word form, we remove this feature if the word is not one of the Top-N most frequent words in the training data. We used N=1000 for the experiments in this paper. This method can reduce the size of the feature sets. In this paper, we only used bigram-subtrees and the limited form of trigram-subtrees, though in theory we can use k-gram-subtrees, which are limited in the same way as our trigram subtrees, in (k-1)th-order MST parsing models mentioned in McDonald and Pereira (2006) or use grandparenttype trigram-subtrees in parsing models of Carreras (2007). Although the higher-order MST parsing models will be slow with exact inference, requiring O(nk) time (McDonald and Pereira, 2006), it might be possible to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependen</context>
<context position="30345" citStr="Carreras (2007)" startWordPosition="4952" endWordPosition="4953">ubtrees besides bigram-subtrees that contain word pairs. And our work is focused on graph-based parsing models as opposed to transition-based models. Yu et al. (2008) constructed case structures from autoparsed data and utilized them in parsing. Compared with their method, our method is much simpler but has great effects. Koo et al. (2008) used the Brown algorithm to produce word clusters on large-scale unannotated data and represented new features based on the clusters for parsing models. The cluster-based features provided very impressive results. In addition, they used the parsing model by Carreras (2007) that applied second-order features on both sibling and grandparent interactions. Note that our approach and their approach are complementary in that we can use both subtree- and cluster-based features for parsing models. The experimental results showed that we achieved better accuracy for first-order models when we used both of these two types of features. Sagae and Tsujii (2007) presented an cotraining approach for dependency parsing adap577 6 7 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Better NoChange Worse 0 1 2 3 Number of prepositions Figure 11: Improvement relative to number of prepositions</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>X. Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>D Blaheta</author>
<author>N Ge</author>
<author>K Hall</author>
<author>J Hale</author>
<author>M Johnson</author>
</authors>
<date>2000</date>
<booktitle>BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43. Linguistic Data Consortium.</booktitle>
<contexts>
<context position="15451" citStr="Charniak et al., 2000" startWordPosition="2578" endWordPosition="2581">ependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags for the training set. For the unannotated data, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ text.8 We used the MXPOST tagger trained on training data to assign part-of-speech tags and used the Basic Parser to process the sentences of the BLLIP corpus. For Chinese, we used the Chinese Treebank 7http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html 8We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. ... h_1 h h+1 ... d_1 d d+1 ... (a) ... h ... d1 ... d2 ... 573 (CTB) version 4.09 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-27</context>
</contexts>
<marker>Charniak, Blaheta, Ge, Hall, Hale, Johnson, 2000</marker>
<rawString>E. Charniak, D. Blaheta, N. Ge, K. Hall, J. Hale, and M. Johnson. 2000. BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara Chen</author>
<author>K Uchimoto</author>
<author>YJ Zhang</author>
<author>H Isahara</author>
</authors>
<title>Dependency parsing with short dependency relations in unlabeled data.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP</booktitle>
<contexts>
<context position="3334" citStr="Chen et al. (2008)" startWordPosition="518" endWordPosition="521">dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada and Matsumoto, 2003; Zhang and Clark, 2008) show that the accuracies of complete trees are about 40% for English and about 35% for Chinese, while the accuracies of relations between two words are much higher: about 90% for English and about 85% for Chinese. From these observations, we may conjecture that it is possible to conduct a more effective selection by using subtrees as the unit of information. The use of word pairs in auto-parsed data was tried in van Noord (2007) and Chen et al. (2008). However, the information on word pairs is limited. To provide richer information, we consider more words besides word pairs. Specifically, we use subtrees containing two or three words extracted from dependency trees in the auto-parsed data. To demonstrate the effectiveness of our proposed approach, we present experimental results on En570 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 570–579, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP glish and Chinese data. We show that this simple approach greatly improves the accuracy and that the use</context>
<context position="16318" citStr="Chen et al., 2008" startWordPosition="2722" endWordPosition="2725">tp://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html 8We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. ... h_1 h h+1 ... d_1 d d+1 ... (a) ... h ... d1 ... d2 ... 573 (CTB) version 4.09 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008). For the unannotated data, we used the PFR corpus10, which has approximately 15 million words whose segmentation and POS tags are given. We used its original segmentation though there are differences in segmentation policy between CTB and this corpus. As for POS tags, we discarded the original POS tags and assigned CTB style POS tags using a TNT-based tagger (Brants, 2000) trained on the training data. We used the Basic Parser to process all the sentences of the PFR corpus. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens</context>
<context position="23314" citStr="Chen et al. (2008)" startWordPosition="3774" endWordPosition="3777">s improvement. For the second-order parser, the subtree-based features achieved an absolute improvement of 1.25 points. The improvements of parsing with subtree-based features were significant in McNemar’s Test (p &lt; 10−5). Chinese UAS Complete Ord1 86.38 40.80 Ord1s 87.68(+1.30) 42.24 Ord2 88.18 47.12 Ord2s 89.43(+1.25) 47.53 Ord2b 89.16(+0.98) 47.12 Ord2t 88.55(+0.37) 47.12 Table 3: Dependency parsing results for Chinese. 4.1.4 Comparative results of Chinese data Table 4 shows the comparative results, where Wang2007 refers to the parser of Wang et al. (2007), Chen2008 refers to the parser of Chen et al. (2008), and Yu2008 refers to the parser of Yu et al. (2008) that is the best reported results for this data set. And “all words” refers to all the sentences in test set and “&lt; 40 words”13 refers to the sentences with the length up to 40. The table shows that our parsers outperformed previous systems. We also implemented integrating systems for Chinese data as well. When we applied the cluster-based features, the performance dropped a little. The reason may be that we are using goldPOS tags for Chinese data14. Thus we did not 13Wang et al. (2007) and Chen et al. (2008) reported the scores on these se</context>
<context position="29430" citStr="Chen et al. (2008)" startWordPosition="4805" endWordPosition="4808">rsing (Ratnaparkhi et al., 1994). We compared the Ord2 system with the Ord2s system. Figures 11 and 12 show how the subtreebased features affect accuracy as a function of the number of prepositions, where the x axis refers to the number of prepositions in one sentence and the y axis shows the percentages of the three classes. The figures indicated that the subtree-based features improved preposition-phrase attachment. 5 Related work Our approach is to incorporate unannotated data into parsing models for dependency parsing. Several previous studies relevant to our approach have been conducted. Chen et al. (2008) previously proposed an approach that used the information on short dependency relations for Chinese dependency parsing. They only used the word pairs within two word distances for a transition-based parsing algorithm. The approach in this paper differs in that we use richer information on trigram-subtrees besides bigram-subtrees that contain word pairs. And our work is focused on graph-based parsing models as opposed to transition-based models. Yu et al. (2008) constructed case structures from autoparsed data and utilized them in parsing. Compared with their method, our method is much simpler</context>
</contexts>
<marker>Chen, Uchimoto, Zhang, Isahara, 2008</marker>
<rawString>WL. Chen, D. Kawahara, K. Uchimoto, YJ. Zhang, and H. Isahara. 2008. Dependency parsing with short dependency relations in unlabeled data. In Proceedings of IJCNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duh</author>
<author>Eric Ringger</author>
</authors>
<title>Multilingual dependency parsing using bayes point machines.</title>
<date>2006</date>
<booktitle>In HLT-NAACL2006.</booktitle>
<marker>Duh, Ringger, 2006</marker>
<rawString>S. Corston-Oliver, A. Aue, Kevin. Duh, and Eric Ringger. 2006. Multilingual dependency parsing using bayes point machines. In HLT-NAACL2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KY Li Sun</author>
<author>MY Kan</author>
<author>TS Chua</author>
</authors>
<title>Question answering passage retrieval using dependency relations.</title>
<date>2005</date>
<booktitle>In Proceedings of SIGIR 2005,</booktitle>
<pages>400--407</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Sun, Kan, Chua, 2005</marker>
<rawString>H. Cui, RX. Sun, KY. Li, MY. Kan, and TS. Chua. 2005. Question answering passage retrieval using dependency relations. In Proceedings of SIGIR 2005, pages 400–407, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangyu Duan</author>
<author>Jun Zhao</author>
<author>Bo Xu</author>
</authors>
<title>Probabilistic models for action-based chinese dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of ECML/ECPPKDD,</booktitle>
<location>Warsaw, Poland.</location>
<contexts>
<context position="24503" citStr="Duan et al. (2007)" startWordPosition="3975" endWordPosition="3978">ported the scores on these sentences. 14We tried to use the cluster-based features for Chinese with the same setting of POS tags as English data, then the cluster-based features did provide improvement. 575 use cluster-based features for the integrating systems. The results are shown in Table 4, where Ord1si/Ord2si refers to the first-order/secondorder system with subtree-based+intergratingsmhe tag based features. We found that the integrating systems provided better results. Overall, we have achieved a high accuracy, which is the best known result for this dataset. Zhang and Clark (2008) and Duan et al. (2007) reported results on a different data split of Penn Chinese Treebank. We also ran our systems (Ord2s) on their data and provided UAS 86.70 (for non-root words)/77.39 (for root words), better than their results: 86.21/76.26 in Zhang and Clark (2008) and 84.36/73.70 in Duan et al. (2007). Chinese all words &lt; 40 words UAS Complete UAS Complete Wang2007 – – 86.6 28.4 Chen2008 86.52 – 88.4 – Yu2008 87.26 – – – Ord1s 87.68 42.24 91.11 54.40 Ord1si 88.24 43.96 91.32 55.93 Ord2s 89.43 47.53 91.67 59.77 Ord2si 89.91 48.56 92.34 62.83 hdsem Table 4: Dependency parsing results for Chinese, for our parser</context>
</contexts>
<marker>Duan, Zhao, Xu, 2007</marker>
<rawString>Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Probabilistic models for action-based chinese dependency parsing. In Proceedings of ECML/ECPPKDD, Warsaw, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Hall</author>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Discriminative classifiers for deterministic dependency parsing. In</title>
<date>2006</date>
<booktitle>In Proceedings of CoLING-ACL.</booktitle>
<contexts>
<context position="19303" citStr="Hall et al. (2006)" startWordPosition="3167" endWordPosition="3170"> 10−6). We also checked the sole effect of bigram- and trigram-subtrees. The results are also shown in Table 1, where Ord2b/Ord2t refers to a secondorder MSTParser with bigram-/trigram-subtrees only. The results showed that trigram-subtrees can provide further improvement, although the effect of the bigram-subtrees seemed larger. 4.1.2 Comparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et</context>
</contexts>
<marker>Hall, Nivre, Nilsson, 2006</marker>
<rawString>Johan Hall, Joakim Nivre, and Jens Nilsson. 2006. Discriminative classifiers for deterministic dependency parsing. In In Proceedings of CoLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara</author>
<author>S Kurohashi</author>
</authors>
<title>Coordination disambiguation without any similarities.</title>
<date>2008</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>425--432</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="28041" citStr="Kawahara and Kurohashi, 2008" startWordPosition="4586" endWordPosition="4590">rds because their numbers were very small. The Better and Worse curves showed that our approach always provided better results. The results indicated that the improvements apparently became larger when the sentences had more unknown words for the Chinese data. And for the English data, the graph also showed the similar trend, although the improvements for the sentences have three and four unknown words were slightly less than the others. 4.2.2 Coordinating conjunctions We analyzed our new parsers’ behavior for coordinating conjunction structures, which is a very difficult problem for parsing (Kawahara and Kurohashi, 2008). Here, we compared the Ord2 system with the Ord2s system. Figures 9 and 10 show how the subtree-based features affect accuracy as a function of the number of conjunctions, where the x axis refers to the number of conjunctions in one sentence and the y axis shows the percentages of the three classes. The figures indicated that the subtree-based features improved the coordinating conjunction problem. In the trigram-subtree list, many subtrees are related to coordinating conjunctions, such as “utilities:1:3 and:2:3 businesses:3:0” and “pull:1:0 and:2:1 protect:3:1”. These subtrees can provide ad</context>
</contexts>
<marker>Kawahara, Kurohashi, 2008</marker>
<rawString>D. Kawahara and S. Kurohashi. 2008. Coordination disambiguation without any similarities. In Proceedings of Coling 2008, pages 425–432, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>X Carreras</author>
<author>M Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="4101" citStr="Koo et al., 2008" startWordPosition="636" endWordPosition="639">trees containing two or three words extracted from dependency trees in the auto-parsed data. To demonstrate the effectiveness of our proposed approach, we present experimental results on En570 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 570–579, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP glish and Chinese data. We show that this simple approach greatly improves the accuracy and that the use of richer structures (i.e, word triples) indeed gives additional improvement. We also demonstrate that our approach and other improvement techniques (Koo et al., 2008; Nivre and McDonald, 2008) are complementary and that we can achieve very high accuracies when we combine our method with other improvement techniques. Specifically, we achieve the best accuracy for the Chinese data. The rest of this paper is as follows: Section 2 introduces the background of dependency parsing. Section 3 proposes an approach for extracting subtrees and represents the subtree-based features for dependency parsers. Section 4 explains the experimental results and Section 5 discusses related work. Finally, in section 6 we draw conclusions. 2 Dependency parsing Dependency parsing</context>
<context position="15007" citStr="Koo et al., 2008" startWordPosition="2500" endWordPosition="2503">to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags for the training set. For the unannotated data, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ text.8 We used the MXPOST tagger trained on training data to assign part-of-speech tags and used the Basic Pars</context>
<context position="19583" citStr="Koo et al. (2008)" startWordPosition="3210" endWordPosition="3213">h the effect of the bigram-subtrees seemed larger. 4.1.2 Comparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et al. (2008) uses both sibling and grandparent interactions, and uses cluster-based features. Carreras et al. (2008) reported a very high accuracy using information of constituent structure of the TAG grammar formalism. In our systems, we did not use such knowledge. Our subtree-ba</context>
<context position="21246" citStr="Koo et al. (2008)" startWordPosition="3481" endWordPosition="3484"> 90.95 37.45 Ord1s 91.76 40.68 Ord1c 91.88 40.71 Ord1i 91.68 41.43 Ord1sc 92.20 42.98 Ord1sci 92.60 44.28 Ord2 91.71 42.88 Ord2s 92.51 46.19 Ord2c 92.40 44.08 Ord2i 92.12 44.37 Ord2sc 92.70 46.56 Ord2sci 93.16 47.15 Table 2: Dependency parsing results for English, for our parsers and previous work To demonstrate that our approach and other work are complementary, we thus implemented a system using all the techniques we had at hand that used subtree- and cluster-based features and applied the integrating method of Nivre and McDonald (2008). We used the word clustering tool12, which was used by Koo et al. (2008), to produce word clusters on the BLLIP corpus. The cluster-based features were the same as the features used by Koo et al. (2008). For the integrating method, we used the transition MaxEnt-based parser of Zhao and Kit (2008) because it was faster than the MaltParser. The results are shown in the bottom part of Table 2, where Ord1c/Ord2c refers to a first-/second-order MSTParser with cluster-based features, Ord1i/Ordli refers to a first/second-order MSTParser with integrating-based features, Ord1sc/Ord2sc refers to a first-/secondorder MSTParser with subtree-based+clusterbased features, and Or</context>
<context position="30071" citStr="Koo et al. (2008)" startWordPosition="4909" endWordPosition="4912">approach that used the information on short dependency relations for Chinese dependency parsing. They only used the word pairs within two word distances for a transition-based parsing algorithm. The approach in this paper differs in that we use richer information on trigram-subtrees besides bigram-subtrees that contain word pairs. And our work is focused on graph-based parsing models as opposed to transition-based models. Yu et al. (2008) constructed case structures from autoparsed data and utilized them in parsing. Compared with their method, our method is much simpler but has great effects. Koo et al. (2008) used the Brown algorithm to produce word clusters on large-scale unannotated data and represented new features based on the clusters for parsing models. The cluster-based features provided very impressive results. In addition, they used the parsing model by Carreras (2007) that applied second-order features on both sibling and grandparent interactions. Note that our approach and their approach are complementary in that we can use both subtree- and cluster-based features for parsing models. The experimental results showed that we achieved better accuracy for first-order models when we used bot</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>T. Koo, X. Carreras, and M. Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL-08: HLT, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguisticss,</title>
<date>1993</date>
<contexts>
<context position="14757" citStr="Marcus et al., 1993" startWordPosition="2456" endWordPosition="2460">ald and Pereira (2006) or use grandparenttype trigram-subtrees in parsing models of Carreras (2007). Although the higher-order MST parsing models will be slow with exact inference, requiring O(nk) time (McDonald and Pereira, 2006), it might be possible to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags fo</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguisticss, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McClosky</author>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Reranking and self-training for parser adaptation.</title>
<date>2006</date>
<booktitle>In Proceedings of Coling-ACL,</booktitle>
<pages>337--344</pages>
<contexts>
<context position="31388" citStr="McClosky et al. (2006)" startWordPosition="5121" endWordPosition="5124">dependency parsing adap577 6 7 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Better NoChange Worse 0 1 2 3 Number of prepositions Figure 11: Improvement relative to number of prepositions for English Figure 12: Improvement relative to number of prepositions for Chinese Penta (smoe tation. They used two parsers to parse the sentences in unannotated data and selected only identical results produced by the two parsers. Then, they retrained a parser on newly parsed sentences and the original labeled data. Our approach represents subtree-based features on the original goldstandard data to retrain parsers. McClosky et al. (2006) presented a self-training approach for phrase structure parsing and the approach was shown to be effective in practice. However, their approach depends on a high-quality reranker, while we simply augment the features of an existing parser. Moreover, we could use the output of our systems for co-training/self-training techniques. 6 Conclusions We present a simple and effective approach to improve dependency parsing using subtrees from auto-parsed data. In our method, first we use a baseline parser to parse large-scale unannotated data, and then we extract subtrees from dependency parsing trees</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>D. McClosky, E. Charniak, and M. Johnson. 2006. Reranking and self-training for parser adaptation. In Proceedings of Coling-ACL, pages 337–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL2006.</booktitle>
<contexts>
<context position="2826" citStr="McDonald and Pereira, 2006" startWordPosition="428" endWordPosition="432">ious studies (Sagae and Tsujii, 2007; Steedman et al., 2003) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data. In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models. The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada and Matsumoto, 2003; Zhang and Clark, 2008) show that the accuracies of complete trees are about 40% for English and about 35% for Chinese, while the accuracies of relations between two words are much higher: about 90% for English and about 85% for Chinese. From these observations, we may conjecture that it is possible to conduct a more effective selection by using subtrees as the unit of information. The use of word pairs in auto-parsed data was tried in van Noord (2007) and Chen et al. (2008). However, the information on word pairs is limited. To provide richer information, we consi</context>
<context position="5674" citStr="McDonald and Pereira (2006)" startWordPosition="891" endWordPosition="894">at “ate” is the ROOT of the sentence. Figure 1: Example for dependency structure 2.1 Parsing approach For dependency parsing, there are two main types of parsing models (Nivre and McDonald, 2008): graph-based model and transition-based model, which achieved state-of-the-art accuracy for a wide range of languages as shown in recent CoNLL shared tasks (Buchholz et al., 2006; Nivre et al., 2007). Our subtree-based features can be applied in both of the two parsing models. In this paper, as the base parsing system, we employ the graph-based MST parsing model proposed by McDonald et al. (2005) and McDonald and Pereira (2006), which uses the idea of Maximum Spanning Trees of a graph and large margin structured learning algorithms. The details of parsing model were presented in McDonald et al. (2005) and McDonald and Pereira (2006). 2.2 Baseline Parser In the MST parsing model, there are two well-used modes: the first-order and the second-order. The first-order model uses first-order features that are defined over single graph edges and the secondorder model adds second-order features that are defined on adjacent edges. For the parsing of unannotated data, we use the first-order MST parsing model, because we need t</context>
<context position="9014" citStr="McDonald and Pereira, 2006" startWordPosition="1463" endWordPosition="1466">2:0 ate ate:1:0-with:2:1 fish I with the:1:1-fish:2:0 the ate ate:1:0-fish:2:1 . ate:1:0-.:2:1 fork a:1:1-fork:2:0 with with:1:0-fork:2:1 a fork (a) (b) Figure 3: Examples of subtrees Note that we only used the trigram-subtrees containing a head, its dependent d1, and d1’s leftmost right sibling3. We could not consider the case where two children are on different sides4 of the head (for instance, “I” and “fish” for “ate” in Figure 2). We also do not use the child-parent-grandparent type (grandparent-type in short) trigram-subtrees. These are due to the limitations of the parsing algorithm of (McDonald and Pereira, 2006), which does not allow the features defined on those types of trigram-subtrees. We extract the subtrees from the auto-parsed data, then merge the same subtrees into one entry, and count their frequency. We eliminate all subtrees that occur only once in the data. 1+ refers to matching the preceding element one or more times and is the same as a regular expression in Perl. 2So, wid is in fact redundant but we include it for ease of understanding. 3Note that the order of the siblings is based on the order of the words in the original sentence. 4Here, “side” means the position of a word relative t</context>
<context position="14159" citStr="McDonald and Pereira (2006)" startWordPosition="2362" endWordPosition="2365">eatures involving the set IDs and part-of-speech tags of heads, and the set IDs and word forms of heads. Specifically, for any feature related to word form, we remove this feature if the word is not one of the Top-N most frequent words in the training data. We used N=1000 for the experiments in this paper. This method can reduce the size of the feature sets. In this paper, we only used bigram-subtrees and the limited form of trigram-subtrees, though in theory we can use k-gram-subtrees, which are limited in the same way as our trigram subtrees, in (k-1)th-order MST parsing models mentioned in McDonald and Pereira (2006) or use grandparenttype trigram-subtrees in parsing models of Carreras (2007). Although the higher-order MST parsing models will be slow with exact inference, requiring O(nk) time (McDonald and Pereira, 2006), it might be possible to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) i</context>
<context position="17328" citStr="McDonald and Pereira (2006)" startWordPosition="2888" endWordPosition="2891">ants, 2000) trained on the training data. We used the Basic Parser to process all the sentences of the PFR corpus. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens (excluding all punctuation tokens) with the correct HEAD. And we also evaluated on complete dependency analysis. 4.1 Experimental Results In our experiments, we used MSTParser, a freely available implementation11 of the first- and second-order MST parsing models. For baseline systems, we used the first- and second-order basic features, which were the same as the features used by McDonald and Pereira (2006), and we used the default settings of MSTParser throughout the paper: iters=10; training-k=1; decode-type=proj. We implemented our systems based on the MSTParser by incorporating the subtree-based features. 4.1.1 Main results of English data English UAS Complete Ord1 90.95 37.45 Ord1s 91.76(+0.81) 40.68 Ord2 91.71 42.88 Ord2s 92.51(+0.80) 46.19 Ord2b 92.28(+0.57) 45.44 Ord2t 92.06(+0.35) 42.96 Table 1: Dependency parsing results for English 9http://www.cis.upenn.edu/˜chinese/. 10http://www.icl.pku.edu. 11http://mstparser.sourceforge.net The results are shown in Table 1, where Ord1/Ord2 refers </context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="5642" citStr="McDonald et al. (2005)" startWordPosition="886" endWordPosition="889">OOT” and “ate” indicates that “ate” is the ROOT of the sentence. Figure 1: Example for dependency structure 2.1 Parsing approach For dependency parsing, there are two main types of parsing models (Nivre and McDonald, 2008): graph-based model and transition-based model, which achieved state-of-the-art accuracy for a wide range of languages as shown in recent CoNLL shared tasks (Buchholz et al., 2006; Nivre et al., 2007). Our subtree-based features can be applied in both of the two parsing models. In this paper, as the base parsing system, we employ the graph-based MST parsing model proposed by McDonald et al. (2005) and McDonald and Pereira (2006), which uses the idea of Maximum Spanning Trees of a graph and large margin structured learning algorithms. The details of parsing model were presented in McDonald et al. (2005) and McDonald and Pereira (2006). 2.2 Baseline Parser In the MST parsing model, there are two well-used modes: the first-order and the second-order. The first-order model uses first-order features that are defined over single graph edges and the secondorder model adds second-order features that are defined on adjacent edges. For the parsing of unannotated data, we use the first-order MST </context>
<context position="14960" citStr="McDonald et al., 2005" startWordPosition="2492" endWordPosition="2495">(McDonald and Pereira, 2006), it might be possible to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags for the training set. For the unannotated data, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ text.8 We used the MXPOST tagger trained on training data to ass</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc. of ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nakazawa</author>
<author>K Yu</author>
<author>D Kawahara</author>
<author>S Kurohashi</author>
</authors>
<title>Example-based machine translation based on deeper nlp.</title>
<date>2006</date>
<booktitle>In Proceedings of IWSLT</booktitle>
<pages>64--70</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="1339" citStr="Nakazawa et al., 2006" startWordPosition="191" endWordPosition="194">onstrate the effectiveness of our proposed approach, we present the experimental results on the English Penn Treebank and the Chinese Penn Treebank. These results show that our approach significantly outperforms baseline systems. And, it achieves the best accuracy for the Chinese data and an accuracy which is competitive with the best known systems for the English data. 1 Introduction Dependency parsing, which attempts to build dependency links between words in a sentence, has experienced a surge of interest in recent times, owing to its usefulness in such applications as machine translation (Nakazawa et al., 2006) and question answering (Cui et al., 2005). To obtain dependency parsers with high accuracy, supervised techniques require a large amount of handannotated data. While hand-annotated data are very expensive, large-scale unannotated data can be obtained easily. Therefore, the use of largescale unannotated data in training is an attractive idea to improve dependency parsing performance. In this paper, we present an approach that extracts subtrees from dependency trees in autoparsed data to improve dependency parsing. The auto-parsed data are generated from large-scale unannotated data by using a </context>
</contexts>
<marker>Nakazawa, Yu, Kawahara, Kurohashi, 2006</marker>
<rawString>T. Nakazawa, K. Yu, D. Kawahara, and S. Kurohashi. 2006. Example-based machine translation based on deeper nlp. In Proceedings of IWSLT 2006, pages 64–70, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>R McDonald</author>
</authors>
<title>Integrating graphbased and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="4128" citStr="Nivre and McDonald, 2008" startWordPosition="640" endWordPosition="644">wo or three words extracted from dependency trees in the auto-parsed data. To demonstrate the effectiveness of our proposed approach, we present experimental results on En570 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 570–579, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP glish and Chinese data. We show that this simple approach greatly improves the accuracy and that the use of richer structures (i.e, word triples) indeed gives additional improvement. We also demonstrate that our approach and other improvement techniques (Koo et al., 2008; Nivre and McDonald, 2008) are complementary and that we can achieve very high accuracies when we combine our method with other improvement techniques. Specifically, we achieve the best accuracy for the Chinese data. The rest of this paper is as follows: Section 2 introduces the background of dependency parsing. Section 3 proposes an approach for extracting subtrees and represents the subtree-based features for dependency parsers. Section 4 explains the experimental results and Section 5 discusses related work. Finally, in section 6 we draw conclusions. 2 Dependency parsing Dependency parsing assigns head-dependent rel</context>
<context position="20400" citStr="Nivre and McDonald (2008)" startWordPosition="3343" endWordPosition="3346">rmed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et al. (2008) uses both sibling and grandparent interactions, and uses cluster-based features. Carreras et al. (2008) reported a very high accuracy using information of constituent structure of the TAG grammar formalism. In our systems, we did not use such knowledge. Our subtree-based features could be combined 574 with the techniques presented in other work, such as the cluster-based features in Koo et al. (2008), the integrating methods of Zhang and Clark (2008), and Nivre and McDonald (2008), and the parsing methods of Carreras et al. (2008). English UAS Complete Y&amp;M2003 90.3 38.4 CO2006 90.8 37.6 Hall2006 89.4 36.4 Wang2007 89.2 34.4 Z&amp;C2008 92.1 45.4 KOO08-dep1c 92.23 – KOO08-dep2c 93.16 – Carreras2008 93.5 – Ord1 90.95 37.45 Ord1s 91.76 40.68 Ord1c 91.88 40.71 Ord1i 91.68 41.43 Ord1sc 92.20 42.98 Ord1sci 92.60 44.28 Ord2 91.71 42.88 Ord2s 92.51 46.19 Ord2c 92.40 44.08 Ord2i 92.12 44.37 Ord2sc 92.70 46.56 Ord2sci 93.16 47.15 Table 2: Dependency parsing results for English, for our parsers and previous work To demonstrate that our approach and other work are complementary, we th</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>J. Nivre and R. McDonald. 2008. Integrating graphbased and transition-based dependency parsers. In Proceedings of ACL-08: HLT, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
<author>J Reynar</author>
<author>S Roukos</author>
</authors>
<title>A maximum entropy model for prepositional phrase attachment.</title>
<date>1994</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>250--255</pages>
<contexts>
<context position="28844" citStr="Ratnaparkhi et al., 1994" startWordPosition="4709" endWordPosition="4712"> the x axis refers to the number of conjunctions in one sentence and the y axis shows the percentages of the three classes. The figures indicated that the subtree-based features improved the coordinating conjunction problem. In the trigram-subtree list, many subtrees are related to coordinating conjunctions, such as “utilities:1:3 and:2:3 businesses:3:0” and “pull:1:0 and:2:1 protect:3:1”. These subtrees can provide additional information for parsing models. 4.2.3 PP attachment We analyzed our new parsers’ behavior for preposition-phrase attachment, which is also a difficult task for parsing (Ratnaparkhi et al., 1994). We compared the Ord2 system with the Ord2s system. Figures 11 and 12 show how the subtreebased features affect accuracy as a function of the number of prepositions, where the x axis refers to the number of prepositions in one sentence and the y axis shows the percentages of the three classes. The figures indicated that the subtree-based features improved preposition-phrase attachment. 5 Related work Our approach is to incorporate unannotated data into parsing models for dependency parsing. Several previous studies relevant to our approach have been conducted. Chen et al. (2008) previously pr</context>
</contexts>
<marker>Ratnaparkhi, Reynar, Roukos, 1994</marker>
<rawString>A. Ratnaparkhi, J. Reynar, and S. Roukos. 1994. A maximum entropy model for prepositional phrase attachment. In Proceedings of HLT, pages 250–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>133--142</pages>
<contexts>
<context position="15204" citStr="Ratnaparkhi, 1996" startWordPosition="2538" endWordPosition="2539">te the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags for the training set. For the unannotated data, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ text.8 We used the MXPOST tagger trained on training data to assign part-of-speech tags and used the Basic Parser to process the sentences of the BLLIP corpus. For Chinese, we used the Chinese Treebank 7http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html 8We ensured that the text used for extracting subtree</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of EMNLP, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>J Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>1044--1050</pages>
<contexts>
<context position="2236" citStr="Sagae and Tsujii, 2007" startWordPosition="332" endWordPosition="335">use of largescale unannotated data in training is an attractive idea to improve dependency parsing performance. In this paper, we present an approach that extracts subtrees from dependency trees in autoparsed data to improve dependency parsing. The auto-parsed data are generated from large-scale unannotated data by using a baseline parser. Then, from dependency trees in the data, we extract different types of subtrees. Finally, we represent subtree-based features on training data to train dependency parsers. The use of auto-parsed data is not new. However, unlike most of the previous studies (Sagae and Tsujii, 2007; Steedman et al., 2003) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data. In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models. The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada a</context>
<context position="30728" citStr="Sagae and Tsujii (2007)" startWordPosition="5010" endWordPosition="5013">ce word clusters on large-scale unannotated data and represented new features based on the clusters for parsing models. The cluster-based features provided very impressive results. In addition, they used the parsing model by Carreras (2007) that applied second-order features on both sibling and grandparent interactions. Note that our approach and their approach are complementary in that we can use both subtree- and cluster-based features for parsing models. The experimental results showed that we achieved better accuracy for first-order models when we used both of these two types of features. Sagae and Tsujii (2007) presented an cotraining approach for dependency parsing adap577 6 7 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Better NoChange Worse 0 1 2 3 Number of prepositions Figure 11: Improvement relative to number of prepositions for English Figure 12: Improvement relative to number of prepositions for Chinese Penta (smoe tation. They used two parsers to parse the sentences in unannotated data and selected only identical results produced by the two parsers. Then, they retrained a parser on newly parsed sentences and the original labeled data. Our approach represents subtree-based features on the original </context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>K. Sagae and J. Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 1044–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
<author>M Osborne</author>
<author>A Sarkar</author>
<author>S Clark</author>
<author>R Hwa</author>
<author>J Hockenmaier</author>
<author>P Ruhlen</author>
<author>S Baker</author>
<author>J Crim</author>
</authors>
<title>Bootstrapping statistical parsers from small datasets.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL</booktitle>
<pages>331--338</pages>
<contexts>
<context position="2260" citStr="Steedman et al., 2003" startWordPosition="336" endWordPosition="339">tated data in training is an attractive idea to improve dependency parsing performance. In this paper, we present an approach that extracts subtrees from dependency trees in autoparsed data to improve dependency parsing. The auto-parsed data are generated from large-scale unannotated data by using a baseline parser. Then, from dependency trees in the data, we extract different types of subtrees. Finally, we represent subtree-based features on training data to train dependency parsers. The use of auto-parsed data is not new. However, unlike most of the previous studies (Sagae and Tsujii, 2007; Steedman et al., 2003) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data. In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models. The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada and Matsumoto, 2003; Zhan</context>
</contexts>
<marker>Steedman, Osborne, Sarkar, Clark, Hwa, Hockenmaier, Ruhlen, Baker, Crim, 2003</marker>
<rawString>M. Steedman, M. Osborne, A. Sarkar, S. Clark, R. Hwa, J. Hockenmaier, P. Ruhlen, S. Baker, and J. Crim. 2003. Bootstrapping statistical parsers from small datasets. In Proceedings of EACL 2003, pages 331–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Using self-trained bilexical preferences to improve disambiguation accuracy.</title>
<date>2007</date>
<booktitle>In Proceedings of IWPT-07,</booktitle>
<marker>van Noord, 2007</marker>
<rawString>Gertjan van Noord. 2007. Using self-trained bilexical preferences to improve disambiguation accuracy. In Proceedings of IWPT-07, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Iris Wang</author>
<author>Dekang Lin</author>
<author>Dale Schuurmans</author>
</authors>
<title>Simple training of dependency parsers via structured boosting.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI2007.</booktitle>
<contexts>
<context position="19356" citStr="Wang et al. (2007)" startWordPosition="3177" endWordPosition="3180">d trigram-subtrees. The results are also shown in Table 1, where Ord2b/Ord2t refers to a secondorder MSTParser with bigram-/trigram-subtrees only. The results showed that trigram-subtrees can provide further improvement, although the effect of the bigram-subtrees seemed larger. 4.1.2 Comparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et al. (2008) uses both sibling and grandparent interac</context>
<context position="23261" citStr="Wang et al. (2007)" startWordPosition="3764" endWordPosition="3767">the subtreebased features provided 1.3 absolute points improvement. For the second-order parser, the subtree-based features achieved an absolute improvement of 1.25 points. The improvements of parsing with subtree-based features were significant in McNemar’s Test (p &lt; 10−5). Chinese UAS Complete Ord1 86.38 40.80 Ord1s 87.68(+1.30) 42.24 Ord2 88.18 47.12 Ord2s 89.43(+1.25) 47.53 Ord2b 89.16(+0.98) 47.12 Ord2t 88.55(+0.37) 47.12 Table 3: Dependency parsing results for Chinese. 4.1.4 Comparative results of Chinese data Table 4 shows the comparative results, where Wang2007 refers to the parser of Wang et al. (2007), Chen2008 refers to the parser of Chen et al. (2008), and Yu2008 refers to the parser of Yu et al. (2008) that is the best reported results for this data set. And “all words” refers to all the sentences in test set and “&lt; 40 words”13 refers to the sentences with the length up to 40. The table shows that our parsers outperformed previous systems. We also implemented integrating systems for Chinese data as well. When we applied the cluster-based features, the performance dropped a little. The reason may be that we are using goldPOS tags for Chinese data14. Thus we did not 13Wang et al. (2007) a</context>
</contexts>
<marker>Wang, Lin, Schuurmans, 2007</marker>
<rawString>Qin Iris Wang, Dekang Lin, and Dale Schuurmans. 2007. Simple training of dependency parsers via structured boosting. In Proceedings of IJCAI2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT2003,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="2854" citStr="Yamada and Matsumoto, 2003" startWordPosition="433" endWordPosition="436">ii, 2007; Steedman et al., 2003) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data. In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models. The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada and Matsumoto, 2003; Zhang and Clark, 2008) show that the accuracies of complete trees are about 40% for English and about 35% for Chinese, while the accuracies of relations between two words are much higher: about 90% for English and about 85% for Chinese. From these observations, we may conjecture that it is possible to conduct a more effective selection by using subtrees as the unit of information. The use of word pairs in auto-parsed data was tried in van Noord (2007) and Chen et al. (2008). However, the information on word pairs is limited. To provide richer information, we consider more words besides word </context>
<context position="14913" citStr="Yamada and Matsumoto, 2003" startWordPosition="2482" endWordPosition="2486">l be slow with exact inference, requiring O(nk) time (McDonald and Pereira, 2006), it might be possible to use higher-order kgram subtrees with approximated parsing model in the future. Of course, our method can also be easily extended to the labeled dependency case. 4 Experiments In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data. For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool “Penn2Malt”7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003). To match previous work (McDonald et al., 2005; McDonald and Pereira, 2006; Koo et al., 2008), we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of Koo et al. (2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10- way jackknifing to generate tags for the training set. For the unannotated data, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ text.8 We used th</context>
<context position="19189" citStr="Yamada and Matsumoto (2003)" startWordPosition="3147" endWordPosition="3150">ing subtree-based features. The improvements of parsing with subtree-based features were significant in McNemar’s Test (p &lt; 10−6). We also checked the sole effect of bigram- and trigram-subtrees. The results are also shown in Table 1, where Ord2b/Ord2t refers to a secondorder MSTParser with bigram-/trigram-subtrees only. The results showed that trigram-subtrees can provide further improvement, although the effect of the bigram-subtrees seemed larger. 4.1.2 Comparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better th</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT2003, pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yu</author>
<author>D Kawahara</author>
<author>S Kurohashi</author>
</authors>
<title>Chinese dependency parsing with large scale automatically constructed case structures.</title>
<date>2008</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>1049--1056</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="16336" citStr="Yu et al., 2008" startWordPosition="2726" endWordPosition="2729">˜nivre/research/Penn2Malt.html 8We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. ... h_1 h h+1 ... d_1 d d+1 ... (a) ... h ... d1 ... d2 ... 573 (CTB) version 4.09 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008). For the unannotated data, we used the PFR corpus10, which has approximately 15 million words whose segmentation and POS tags are given. We used its original segmentation though there are differences in segmentation policy between CTB and this corpus. As for POS tags, we discarded the original POS tags and assigned CTB style POS tags using a TNT-based tagger (Brants, 2000) trained on the training data. We used the Basic Parser to process all the sentences of the PFR corpus. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens (excluding all pu</context>
<context position="23367" citStr="Yu et al. (2008)" startWordPosition="3785" endWordPosition="3788">-based features achieved an absolute improvement of 1.25 points. The improvements of parsing with subtree-based features were significant in McNemar’s Test (p &lt; 10−5). Chinese UAS Complete Ord1 86.38 40.80 Ord1s 87.68(+1.30) 42.24 Ord2 88.18 47.12 Ord2s 89.43(+1.25) 47.53 Ord2b 89.16(+0.98) 47.12 Ord2t 88.55(+0.37) 47.12 Table 3: Dependency parsing results for Chinese. 4.1.4 Comparative results of Chinese data Table 4 shows the comparative results, where Wang2007 refers to the parser of Wang et al. (2007), Chen2008 refers to the parser of Chen et al. (2008), and Yu2008 refers to the parser of Yu et al. (2008) that is the best reported results for this data set. And “all words” refers to all the sentences in test set and “&lt; 40 words”13 refers to the sentences with the length up to 40. The table shows that our parsers outperformed previous systems. We also implemented integrating systems for Chinese data as well. When we applied the cluster-based features, the performance dropped a little. The reason may be that we are using goldPOS tags for Chinese data14. Thus we did not 13Wang et al. (2007) and Chen et al. (2008) reported the scores on these sentences. 14We tried to use the cluster-based features</context>
<context position="29896" citStr="Yu et al. (2008)" startWordPosition="4878" endWordPosition="4881">unannotated data into parsing models for dependency parsing. Several previous studies relevant to our approach have been conducted. Chen et al. (2008) previously proposed an approach that used the information on short dependency relations for Chinese dependency parsing. They only used the word pairs within two word distances for a transition-based parsing algorithm. The approach in this paper differs in that we use richer information on trigram-subtrees besides bigram-subtrees that contain word pairs. And our work is focused on graph-based parsing models as opposed to transition-based models. Yu et al. (2008) constructed case structures from autoparsed data and utilized them in parsing. Compared with their method, our method is much simpler but has great effects. Koo et al. (2008) used the Brown algorithm to produce word clusters on large-scale unannotated data and represented new features based on the clusters for parsing models. The cluster-based features provided very impressive results. In addition, they used the parsing model by Carreras (2007) that applied second-order features on both sibling and grandparent interactions. Note that our approach and their approach are complementary in that w</context>
</contexts>
<marker>Yu, Kawahara, Kurohashi, 2008</marker>
<rawString>K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chinese dependency parsing with large scale automatically constructed case structures. In Proceedings of Coling 2008, pages 1049–1056, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>562--571</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="2878" citStr="Zhang and Clark, 2008" startWordPosition="437" endWordPosition="440">003) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data. In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models. The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees. Previous studies (McDonald and Pereira, 2006; Yamada and Matsumoto, 2003; Zhang and Clark, 2008) show that the accuracies of complete trees are about 40% for English and about 35% for Chinese, while the accuracies of relations between two words are much higher: about 90% for English and about 85% for Chinese. From these observations, we may conjecture that it is possible to conduct a more effective selection by using subtrees as the unit of information. The use of word pairs in auto-parsed data was tried in van Noord (2007) and Chen et al. (2008). However, the information on word pairs is limited. To provide richer information, we consider more words besides word pairs. Specifically, we </context>
<context position="19458" citStr="Zhang and Clark (2008)" startWordPosition="3193" endWordPosition="3196">er MSTParser with bigram-/trigram-subtrees only. The results showed that trigram-subtrees can provide further improvement, although the effect of the bigram-subtrees seemed larger. 4.1.2 Comparative results of English data Table 2 shows the performance of the systems that were compared, where Y&amp;M2003 refers to the parser of Yamada and Matsumoto (2003), CO2006 refers to the parser of Corston-Oliver et al. (2006), Hall2006 refers to the parser of Hall et al. (2006), Wang2007 refers to the parser of Wang et al. (2007), Z&amp;C 2008 refers to the combination graph-based and transition-based system of Zhang and Clark (2008), KOO08-dep1c/KOO08- dep2c refers to a graph-based system with first/second-order cluster-based features by Koo et al. (2008), and Carreras2008 refers to the paper of Carreras et al. (2008). The results showed that Ord2s performed better than the first five systems. The second-order system of Koo et al. (2008) performed better than our systems. The reason may be that the MSTParser only uses sibling interactions for second-order, while Koo et al. (2008) uses both sibling and grandparent interactions, and uses cluster-based features. Carreras et al. (2008) reported a very high accuracy using inf</context>
<context position="24480" citStr="Zhang and Clark (2008)" startWordPosition="3970" endWordPosition="3973">) and Chen et al. (2008) reported the scores on these sentences. 14We tried to use the cluster-based features for Chinese with the same setting of POS tags as English data, then the cluster-based features did provide improvement. 575 use cluster-based features for the integrating systems. The results are shown in Table 4, where Ord1si/Ord2si refers to the first-order/secondorder system with subtree-based+intergratingsmhe tag based features. We found that the integrating systems provided better results. Overall, we have achieved a high accuracy, which is the best known result for this dataset. Zhang and Clark (2008) and Duan et al. (2007) reported results on a different data split of Penn Chinese Treebank. We also ran our systems (Ord2s) on their data and provided UAS 86.70 (for non-root words)/77.39 (for root words), better than their results: 86.21/76.26 in Zhang and Clark (2008) and 84.36/73.70 in Duan et al. (2007). Chinese all words &lt; 40 words UAS Complete UAS Complete Wang2007 – – 86.6 28.4 Chen2008 86.52 – 88.4 – Yu2008 87.26 – – – Ord1s 87.68 42.24 91.11 54.40 Ord1si 88.24 43.96 91.32 55.93 Ord2s 89.43 47.53 91.67 59.77 Ord2si 89.91 48.56 92.34 62.83 hdsem Table 4: Dependency parsing results for </context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of EMNLP 2008, pages 562–571, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kit</author>
</authors>
<title>Parsing syntactic and semantic dependencies with two single-stage maximum entropy models.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>203--207</pages>
<location>Manchester, England,</location>
<contexts>
<context position="21471" citStr="Kit (2008)" startWordPosition="3522" endWordPosition="3523">ncy parsing results for English, for our parsers and previous work To demonstrate that our approach and other work are complementary, we thus implemented a system using all the techniques we had at hand that used subtree- and cluster-based features and applied the integrating method of Nivre and McDonald (2008). We used the word clustering tool12, which was used by Koo et al. (2008), to produce word clusters on the BLLIP corpus. The cluster-based features were the same as the features used by Koo et al. (2008). For the integrating method, we used the transition MaxEnt-based parser of Zhao and Kit (2008) because it was faster than the MaltParser. The results are shown in the bottom part of Table 2, where Ord1c/Ord2c refers to a first-/second-order MSTParser with cluster-based features, Ord1i/Ordli refers to a first/second-order MSTParser with integrating-based features, Ord1sc/Ord2sc refers to a first-/secondorder MSTParser with subtree-based+clusterbased features, and Ord1sci/Ord2sci refers to a first-/second-order MSTParser with subtreebased+cluster-based+integrating-based features. Ord1c/Ord2c was worse than KOO08-dep1c/- dep2c, but Ord1sci outperformed KOO08-dep1c 12http://www.cs.berkeley</context>
</contexts>
<marker>Kit, 2008</marker>
<rawString>H. Zhao and CY. Kit. 2008. Parsing syntactic and semantic dependencies with two single-stage maximum entropy models. In Proceedings of CoNLL 2008, pages 203–207, Manchester, England, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>