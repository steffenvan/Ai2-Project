<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000690">
<title confidence="0.997222">
Evaluating Multilanguage-Comparability of Subjectivity Analysis
Systems
</title>
<author confidence="0.997462">
Jungi Kim, Jin-Ji Li and Jong-Hyeok Lee
</author>
<affiliation confidence="0.999721">
Division of Electrical and Computer Engineering
Pohang University of Science and Technology, Pohang, Republic of Korea
</affiliation>
<email confidence="0.998697">
{yangpa,ljj,jhlee}@postech.ac.kr
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999842285714286">
Subjectivity analysis is a rapidly grow-
ing field of study. Along with its ap-
plications to various NLP tasks, much
work have put efforts into multilingual
subjectivity learning from existing re-
sources. Multilingual subjectivity analy-
sis requires language-independent crite-
ria for comparable outcomes across lan-
guages. This paper proposes to mea-
sure the multilanguage-comparability of
subjectivity analysis tools, and provides
meaningful comparisons of multilingual
subjectivity analysis from various points
of view.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858476190476">
The field of NLP has seen a recent surge in the
amount of research on subjectivity analysis. Along
with its applications to various NLP tasks, there
have been efforts made to extend the resources
and tools created for the English language to other
languages. These endeavors have been success-
ful in constructing lexicons, annotated corpora,
and tools for subjectivity analysis in multiple lan-
guages.
There are multilingual subjectivity analysis sys-
tems available that have been built to monitor and
analyze various concerns and opinions on the In-
ternet; among the better known are OASYS from
the University of Maryland that analyzes opinions
on topics from news article searches in multiple
languages (Cesarano et al., 2007)1 and TextMap,
an entity search engine developed by Stony Brook
University for sentiment analysis along with other
functionalities (Bautin et al., 2008).2 Though these
systems currently rely on English analysis tools
and a machine translation (MT) technology to
</bodyText>
<footnote confidence="0.999773">
1http://oasys.umiacs.umd.edu/oasysnew/
2http://www.textmap.com/
</footnote>
<bodyText confidence="0.999583609756098">
translate other languages into English, up-to-date
research provides various ways to analyze subjec-
tivity in multilingual environments.
Given sentiment analysis systems in differ-
ent languages, there are many situations when
the analysis outcomes need to be multilanguage-
comparable. For example, it has been common
these days for the Internet users across the world
to share their views and opinions on various top-
ics including music, books, movies, and global af-
fairs and incidents, and also multinational compa-
nies such as Apple and Samsung need to analyze
customer feedbacks for their products and services
from many countries in different languages. Gov-
ernments may also be interested in monitoring ter-
rorist web forums or its global reputation. Sur-
veying these opinions and sentiments in various
languages involves merging the analysis outcomes
into a single database, thereby objectively compar-
ing the result across languages.
If there exists an ideal subjectivity analy-
sis system for each language, evaluating the
multilanguage-comparability would be unneces-
sary because the analysis in each language would
correctly identify the exact meanings of all in-
put texts regardless of the language. However, this
requirement is not fulfilled with current technol-
ogy, thus the need for defining and measuring the
multilanguage-comparability of subjectivity anal-
ysis systems is evident.
This paper proposes to evaluate the
multilanguage-comparability of multilingual
subjectivity analysis systems. We build a number
of subjectivity classifiers that distinguishes sub-
jective texts from objective ones, and measure
the multilanguage-comparability according to our
proposed evaluation method. Since subjectivity
analysis tools in languages other than English are
not readily available, we focus our experiments on
comparing different methods to build multilingual
analysis systems from the resources and systems
</bodyText>
<page confidence="0.9802">
595
</page>
<note confidence="0.943536">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 595–603,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9967505">
created for English. These approaches enable us to
extend a monolingual system to many languages
with a number of freely available NLP resources
and tools.
</bodyText>
<sectionHeader confidence="0.999801" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.976286446808511">
Much research have been put into developing
methods for multilingual subjectivity analysis re-
cently. With the high availability of subjectivity re-
sources and tools in English, an easy and straight-
forward approach would be to employ a machine
translation (MT) system to translate input texts
in target languages into English then carry out
the analyses using an existing subjectivity analy-
sis tool (Kim and Hovy, 2006; Bautin et al., 2008;
Banea et al., 2008). Mihalcea et al. (2007) and
Banea et al. (2008) proposed a number of ap-
proaches exploiting a bilingual dictionary, a paral-
lel corpus, and an MT system to port the resources
and systems available in English to languages with
limited resources.
For subjectivity lexicons translation, Mihalcea
et al. (2007) and Wan (2008) used the first sense in
a bilingual dictionary, Kim and Hovy (2006) used
a parallel corpus and a word alignment tool to ex-
tract translation pairs, and Kim et al. (2009) used
a dictionary to translate and a link analysis algo-
rithm to refine the matching intensity.
To overcome the shortcomings of available re-
sources and to take advantage of ensemble sys-
tems, Wan (2008) and Wan (2009) explored meth-
ods for developing a hybrid system for Chinese us-
ing English and Chinese sentiment analyzers. Ab-
basi et al. (2008) and Boiy and Moens (2009) have
created manually annotated gold standards in tar-
get languages and studied various feature selec-
tion and learning techniques in machine learning
approaches to analyze sentiments in multilingual
web documents.
For learning multilingual subjectivity, the lit-
erature tentatively concludes that translating lex-
icon is less dependable in terms of preserving sub-
jectivity than corpus translation (Mihalcea et al.,
2007; Wan, 2008), and though corpus translation
results in modest performance degradation, it pro-
vides a viable approach because no manual la-
bor is required (Banea et al., 2008; Brooke et al.,
2009).
Based on the observation that the performances
of subjectivity analysis systems in comparable
experimental settings for two languages differ,
Texts with an identical negative sentiment:
* The iPad could cannibalize the e-reader market.
</bodyText>
<equation confidence="0.409921142857143">
* o}off-1.!!7}(iPad) ;14;M AJJ-&amp;-(e-reader market)
-qGAJ4 T 5i+(could cannibalize).
Texts with different strengths of positive sentiments:
* Samsung cell phones have excellent battery life.
* -IJJ(Samsung) 4q;1IA(cell phone) &apos;alBIF-Ii
(battery) aqAlq(somehow or other) 44&amp;+(last
long).
</equation>
<figureCaption confidence="0.9546725">
Figure 1: Examples of sentiments in multilingual
text
</figureCaption>
<bodyText confidence="0.997956285714286">
Banea et al. (2008) have attributed the variations
in the difficulty level of subjectivity learning to
the differences in language construction. Bautin et
al. (2008)’s system analyzes the sentiment scores
of entities in multilingual news and blogs and ad-
justed the sentiment scores using entity sentiment
probabilities of languages.
</bodyText>
<sectionHeader confidence="0.930433" genericHeader="method">
3 Multilanguage-Comparability
</sectionHeader>
<subsectionHeader confidence="0.998541">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999969785714286">
The quality of a subjectivity analysis tool is mea-
sured by its ability to distinguish subjectivity from
objectivity and/or positive sentiments from nega-
tive sentiments. Additionally, a multilingual sub-
jectivity analysis system is required to generate
unbiased analysis results across languages; the
system should base its outcome solely on the sub-
jective meanings of input texts irrespective of the
language, and the equalities and inequalities of
subjectivity labels and intensities must be useful
within and throughout the languages.
Let us consider two cases where the pairs of
multilingual inputs in English and Korean have
identical and different subjectivity meanings (Fig-
ure 1). The first pair of texts carry a negative sen-
timent about how the release of a new electronics
device might affect an emerging business market.
When a multilanguage-comparable system is in-
putted with such a pair, its output should appropri-
ately reflect the negative sentiment, and be identi-
cal for both texts. The second pair of texts share
a similar positive sentiment about a mobile de-
vice’s battery capacity but with different strengths.
A good multilingual system must be able to iden-
tify the positive sentiments and distinguish the dif-
ferences in their intensities.
However, these kinds of conditions cannot be
measured with performance evaluations indepen-
</bodyText>
<page confidence="0.997647">
596
</page>
<bodyText confidence="0.999921076923077">
dently carried out on each language; A system
with a dissimilar ability to analyze subjective ex-
pressions from one language to another may de-
liver opposite labels or biased scores on texts with
an identical subjective meaning, and vice versa,
but still might produce similar performances on
the evaluation data.
Macro evaluations on individual languages can-
not provide any conclusions on the system’s
multilanguage-comparability capability. To mea-
sure how much of a system’s judgment principles
are preserved across languages, an evaluation from
a different perspective is necessary.
</bodyText>
<subsectionHeader confidence="0.999716">
3.2 Evaluation Approach
</subsectionHeader>
<bodyText confidence="0.999935583333333">
An evaluation of multilanguage-comparability
may be done in two ways: measuring agreements
in the outcomes of a pair of multilingual texts with
an identical subjective meaning, or measuring the
consistencies in the label and/or accordance in the
order of intensity of a pair of texts with different
subjectivities.
There are advantages and disadvantages to each
approaches. The first approach requires multi-
lingual texts aligned at the level of specificity,
for instance, document, sentence and phrase, that
the subjectivity analysis system works. Text cor-
pora for MT evaluation such as newspapers,
books, technical manuals, and government offi-
cial records provide a wide variety of parallel
texts, typically at the sentence level. Annotating
these types of corpus can be efficient; as par-
allel texts must have identical semantic mean-
ings, subjectivity–related annotations for one lan-
guage can be projected into other languages with-
out much loss of accuracy.
The latter approach accepts any pair of multi-
lingual texts as long as they are annotated with la-
bels and/or intensity. In this case, evaluating the la-
bel consistency of a multilingual system is only as
difficult as evaluating that of a monolingual sys-
tem; we can produce all possible pairs of texts
from test corpora annotated with labels for each
language. Evaluating with intensity is not easy for
the latter approach; if test corpora already exist
with intensity annotations for both languages, nor-
malizing the intensity scores to a comparable scale
is necessary (yet is uncertain unless every pair is
checked manually), otherwise every pair of mul-
tilingual texts needs a manual annotation with its
relative order of intensity.
In this paper, we utilize the first approach be-
cause it provides a more rational means; we can
reasonably hypothesize that text translated into an-
other language by a skilled translator carries an
identical semantic meaning and thereby conveys
identical subjectivity. Therefore the required re-
source is more easily attained in relatively inex-
pensive ways.
For evaluation, we measure the consistency in
the subjectivity labels and the correlation of sub-
jectivity intensity scores of parallel texts. Section
5.1 describes the details of evaluation metrics.
</bodyText>
<sectionHeader confidence="0.970393" genericHeader="method">
4 Multilingual Subjectivity System
</sectionHeader>
<bodyText confidence="0.9999905">
We create a number of multilingual systems con-
sisting of multiple subsystems each processing a
language, where one system analyzes English, and
the other systems analyze the Korean, Chinese,
and Japanese languages. We try to reproduce a set
of systems using diverse methods in order to com-
pare the systems and find out which methods are
more suitable for multilanguage-comparability.
</bodyText>
<subsectionHeader confidence="0.999884">
4.1 Source Language System
</subsectionHeader>
<bodyText confidence="0.99890056">
We adopt the three systems described below as our
source language systems: a state-of-the-art sub-
jectivity classifier, a corpus-based, and a lexicon-
based systems. The resources needed for devel-
oping the systems or the system itself are readily
available for research purposes. In addition, these
systems cover the general spectrum of current ap-
proaches to subjectivity analysis.
State-of-the-art (S-SA): OpinionFinder is a
publicly-available NLP tool for subjectivity analy-
sis (Wiebe and Riloff, 2005; Wilson et al., 2005).3
The software and its resources have been widely
used in the field of subjectivity analysis, and it
has been the de facto standard system against
which new systems are validated. We use a high-
coverage classifier from the OpinionFinder’s two
sentence-level subjectivity classifiers. This Naive
Bayes classifier builds upon a corpus annotated by
a high-precision classifier with the bootstrapping
of the corpus and extraction patterns. The classi-
fier assesses a sentence’s subjectivity with a label
and a score for confidence in its judgment.
Corpus-based (S-CB): The MPQA opinion cor-
pus is a collection of 535 newspaper articles in En-
glish annotated with opinions and private states at
</bodyText>
<footnote confidence="0.9939765">
3http://www.cs.pitt.edu/mpqa/opinionfinderrelease/, ver-
sion 1.5
</footnote>
<page confidence="0.99567">
597
</page>
<bodyText confidence="0.982947487179487">
the sub-sentence level (Wiebe et al., 2003).4 We
retrieve the sentence level subjectivity labels for
11,111 sentences using the set of rules described
in (Wiebe and Riloff, 2005). The corpus provides
a relatively balanced corpus with 55% subjective
sentences. We train an ML-based classifier us-
ing the corpus. Previous studies have found that,
among several ML-based approaches, the SVM
classifier generally performs well in many subjec-
tivity analysis tasks (Pang et al., 2002; Banea et
al., 2008).
We use SVMLzght with its default configura-
tions,5 inputted with a sentence represented as a
feature vector of word unigrams and their counts
in the sentence. An SVM score (a margin or the
distance from a learned decision boundary) with a
positive value predicts the input as being subjec-
tive, and negative value as objective.
Lexicon-based (S-LB): OpinionFinder contains a
list of English subjectivity clue words with in-
tensity labels (Wilson et al., 2005). The lexicon
is compiled from several manually and automati-
cally built resources and contains 6885 unique en-
tries.
Riloff and Wiebe (2003) constructed a high-
precision classifier for contiguous sentences us-
ing the number of strong and weak subjective
words in current and nearby sentences. Unlike pre-
vious work, we do not (or rather, cannot) main-
tain assumptions about the proximity of input text.
Using the lexicon, we build a simple and high-
coverage rule-based subjectivity classifier. Setting
the scores of strong and weak subjective words as
1.0 and 0.5, we evaluate the subjectivity of a given
sentence as the sum of subjectivity scores; above
a threshold, the input is subjective, and otherwise
objective. The threshold value is optimized for an
F-measure using the MPQA corpus, and is set to
1.0 throughout our experiments.
</bodyText>
<subsectionHeader confidence="0.998594">
4.2 Target Language System
</subsectionHeader>
<bodyText confidence="0.94371875">
To construct a target language system leveraging
on available resources in the source language, we
consider three approaches from previous litera-
ture:
</bodyText>
<listItem confidence="0.477358">
1. translating test sentences in target language
into source language and inputting them into
</listItem>
<footnote confidence="0.976179666666667">
4http://www.cs.pitt.edu/mpqa/databaserelease/, version
1.2
5http://svmlight.joachims.org/, version 6.02
</footnote>
<bodyText confidence="0.5907245">
a source language system (Kim and Hovy,
2006; Bautin et al., 2008; Banea et al., 2008)
</bodyText>
<listItem confidence="0.995343125">
2. translating a source language training corpus
into target language and creating a corpus-
based system in target language (Banea et al.,
2008)
3. translating a subjectivity lexicon from source
language to target language and creating a
lexicon-based system in target language (Mi-
halcea et al., 2007)
</listItem>
<bodyText confidence="0.997983473684211">
Each approach has its advantages and disadvan-
tages. The advantage of the first approach is its
simple architecture, clear separation of subjectiv-
ity and MT systems, and that it has only one sub-
jectivity system, and is thus easier to maintain.
Its disadvantage is that the time-consuming MT
has to be executed for each text input. In the sec-
ond and third approaches, a subjectivity system in
the target language is constructed sharing corpora,
rules, and/or features with the source language
system. Later on, it may also include its own set
of resources specifically engineered for the target
language as a performance improvement. How-
ever, keeping the systems up-to-date would require
as much effort as the number of languages. All
three approaches use MT, and would suffer sig-
nificantly if the translation results are poor.
Using the first approach, we can easily adopt all
three source language systems;
</bodyText>
<listItem confidence="0.99852">
• Target input translated into source, analyzed
by source language system S-SA
• Target input translated into source, analyzed
by source language system S-CB
• Target input translated into source, analyzed
by source language system S-LB
</listItem>
<bodyText confidence="0.672911">
The second and the third approaches are carried
out as follows:
Corpus-based (T-CB): We translate the MPQA
corpus into the target languages sentence by sen-
tence using a web-based service.6 Using the same
method for S-CB, we train an SVM model for
each language with the translated training corpora.
Lexicon-based (T-LB): This classifier is identi-
cal to S-LB, where the English lexicon is replaced
by one of the target languages. We automatically
translate the lexicon using free bilingual dictionar-
ies.7 First, the entries in the lexicon are looked
</bodyText>
<footnote confidence="0.99689825">
6Google Translate (http://translate.google.com/)
7quick english-korean, quick eng-zh CN, and JMDict
from StarDict (http://stardict.sourceforge.net/) licensed under
GPL and EDRDG.
</footnote>
<page confidence="0.9947">
598
</page>
<tableCaption confidence="0.948907">
Table 1: Agreement on subjectivity (S for subjec-
tive, O objective) of 859 sentence chunks in Ko-
rean between two annotators (An. 1 and An. 2).
</tableCaption>
<table confidence="0.9741304">
An. 2
S O Total
S 371 93 464
O 23 372 395
Total 394 465 859
</table>
<tableCaption confidence="0.814431">
Table 2: Agreement on projection of subjectivity
(S for subjective, O objective) from Korean (KR)
to English (EN) by one annotator.
</tableCaption>
<table confidence="0.970754714285714">
EN
S O Total
S 458 6 464
O 12 383 395
Total 470 389 859
An. 1
KR
</table>
<bodyText confidence="0.999730363636364">
up in the dictionary, if they are found, we se-
lect the first word in the first sense of the def-
inition. If the entry is not in the dictionary, we
lemmatize it,8 then repeat the search. Our sim-
ple approach produces moderate-sized lexicons
(3,808, 3,980, 3,027 for Korean, Chinese, and
Japanese) compared to Mihalcea et al. (2007)’s
complicated translation approach (4,983 Roma-
nian words). The threshold values are optimized
using the MPQA corpus translated into each tar-
get language.9
</bodyText>
<sectionHeader confidence="0.999794" genericHeader="method">
5 Experiment
</sectionHeader>
<subsectionHeader confidence="0.9013955">
5.1 Experimental Setup
Test Corpus
</subsectionHeader>
<bodyText confidence="0.999929555555556">
Our evaluation corpus consists of 50 parallel
newspaper articles from the Donga Daily News
Website.10 The website provides news articles in
Korean and their human translations in English,
Japanese, and Chinese. We selected articles that
contain Editorial in its English title from a 30-
day period. Three human annotators who are flu-
ent in the two languages manually annotated N-
to-N sentence alignments for each language pairs
(KR-EN, KR-CH, KR-JP). By keeping only the
sentence chunks whose Korean chunk appears in
all language pairs, we were left with 859 sentence
chunk pairs.
The corpus was preprocessed with NLP tools
for each language,11 and the Korean, Chinese, and
Japanese texts were translated into English with
the same web-based service used to translate the
training corpus in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.751649">
Manual Annotation and Agreement Study
</subsectionHeader>
<footnote confidence="0.997397">
8JWI (http://projects.csail.mit.edu/jwi/)
9Korean 1.0, Chinese 1.0, and Japanese 0.5
10http://www.donga.com/
11Stanford POS Tagger 1.5.1 and Stanford Chinese Word
Segmenter 2008-05-21 (http://nlp.stanford.edu/software/),
Chasen 2.4.4 (http://chasen-legacy.sourceforge.jp/), Korean
Morphological Analyzer (KoMA) (http://kle.postech.ac.kr/)
</footnote>
<bodyText confidence="0.999966487804878">
To assess the performance of our subjectiv-
ity analysis systems, the Korean sentence chunks
were manually annotated by two native speakers
of Korean with Subjective and Objective labels
(Table 1). A proportion agreement of 0.86 and a
kappa value of 0.73 indicate a substantial agree-
ment between the two annotators. We set aside
743 sentence chunks that both annotators agreed
on for the automatic evaluation of subjectivity
analysis systems, thereby removing the borderline
cases, which are difficult even for humans to as-
sess. The corresponding sentence chunks for other
languages were extracted and tagged with labels
equivalent to Korean chunks.
In addition, to verify how consistently the sub-
jectivity of the original texts is projected to the
translated, we carried out another manual annota-
tion and agreement study with Korean and English
sentence chunks (Table 2).
Note that our cross-lingual agreement study is
similar to the one carried out by Mihalcea et
al. (2007), where two annotators labeled the sen-
tence subjectivity of a parallel text in different lan-
guages. They reported that, similarly to monolin-
gual annotations, most cases of disagreements on
annotations are due to the differences in the anno-
tators’ judgments on subjectivity, and the rest from
subjective meanings lost in the translation process
and figurative language such as irony.
To avoid the role played by annotators’ pri-
vate views from disagreements, the subjectivity of
sentence chunks in English were manually anno-
tated by one of the annotators for the Korean text.
Judged by the same annotator, we speculate that
the disagreement in the annotation should account
only for the inconsistency in the subjectivity pro-
jection. By proportion, the agreement between the
annotation of Korean and English is 0.97, and the
kappa is 0.96, suggesting an almost perfect agree-
ment. Only a small number of sentence chunk
pairs have inconsistent labels; six chunks in Ko-
</bodyText>
<page confidence="0.998065">
599
</page>
<table confidence="0.94809325">
Implicit sentiment expressed through translation:
* A]7_101 ���(with time) a ZiJk}71(disparity/gap)
1t017,1:2 5aL}(widening).
* Worse, the (economic) disparity (between South
Korea and North Korea) is worsening with time.
Sentiment lost in translation:
* of�-91 F}F} 71 oJk}A.t} i(India&apos;s Tata Motors)
2200z�;F}T_j 71 oJk} 1-+_-z(2,200-dollar
automobile Nano) q�k01(presented) T z �° L}
(drew attention).
* India&apos;s Tata Motors has produced the 2,200-dollar
subcompact Nano.
</table>
<figureCaption confidence="0.959709">
Figure 2: Excerpts from Donga Daily News with
differing sentiments between parallel texts
</figureCaption>
<bodyText confidence="0.9995005">
rean lost subjectivity in translation, and implied
subjective meanings in twelve chunks were ex-
pressed explicitly through interpretation. Excerpts
from our corpus show two such cases (Figure 2).
</bodyText>
<subsectionHeader confidence="0.54265">
Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999984631578947">
To evaluate the multilanguage-comparability of
subjectivity analysis systems, we measure 1) how
consistently the system assigns subjectivity labels
and 2) how closely numeric scores for systems’
confidences correlate with regard to parallel texts
in different languages.
In particular, we use Cohen’s kappa coefficient
for the first and Pearson’s correlation coefficient
for the latter. These widely used metrics provide
useful comparability measures for categorical and
quantitative data.
Both coefficients are scaled from −1 to +1, in-
dicating negative to positive correlations. Kappa
measures are corrected for chance, thereby yield-
ing better measurements than agreement by pro-
portion. The characteristics of Pearson’s correla-
tion coefficient that it measures linear relation-
ships and is independent of change in origin, scale,
and unit comply with our experiments.
</bodyText>
<subsectionHeader confidence="0.999011">
5.2 Subjectivity Classification
</subsectionHeader>
<bodyText confidence="0.988675205882353">
Our multilingual subjectivity analysis systems
were evaluated on the test corpora described in
Section 5.1 (Table 3).
Due to the difference in testbeds, the perfor-
mance of the state-of-the-art English system (S-
SA) on our corpus is lower by about 10% rela-
tively than the performance reported on the MPQA
corpus.12 However, it still performs sufficiently
12precision, recall, and F-measure of 79.4, 70.6, and 74.7.
well and provides the most balanced results among
the three source language systems; The corpus-
based system (S-CB) classifies with a high pre-
cision, and the lexicon-based (S-LB) with a high
recall. The source language systems (S-SA,-CB,-
LB) lose a small percentage in precision when in-
putted with translations, but the recalls are gener-
ally on a par or even higher in the target languages.
For the systems created from target language re-
sources, Corpus-based systems (T-CB) generally
perform better than the ones with source language
resource (S-CB), and lexicon-based systems (T-
LB) perform worse than (S-LB). Similarly to sys-
tems with source language resources, T-CB clas-
sifies with a high precision and T-LB with a high
recall, but the gap is less. Among the target lan-
guages, Korean tends to have a higher precision,
and Japanese a higher recall than other languages
in most systems.
Overall, S-SA provides easy accessibility when
analyzing both the source and the target languages,
with a balanced precision and recall performance.
Among the other approaches, only T-CB is bet-
ter in all measures than S-SA, and S-LB performs
best on F-measure evaluations.
</bodyText>
<subsectionHeader confidence="0.99976">
5.3 Multilanguage-Comparability
</subsectionHeader>
<bodyText confidence="0.999976416666667">
The evaluation results on multilanguage-
comparability are presented in Table 4. The
subjectivity analysis systems are evaluated with
all language pairs with kappa and Pearson’s
correlation coefficients. Kappa and Pearson’s
correlation values are consistent with each other;
Pearson’s correlation between the two evaluation
measures is 0.91.
We observe a distinct contrast in performances
between corpus-based systems (S-CB and T-CB)
and lexicon-based systems (S-LB and T-LB); All
corpus-based systems show moderate agreements
while agreements on lexicon-based systems are
only fair.
Within corpus-based systems, S-CB performs
better with language pairs that include English,
and T-CB performs better with language pairs of
the target languages.
For lexicon-based systems, systems in the tar-
get languages (T-LB) performs the worst with
only slight to fair agreements between languages.
Lexicon-based systems and state-of-the-art sys-
tems in the source language (S-LB and S-SA) re-
sult in average performances.
</bodyText>
<page confidence="0.998533">
600
</page>
<tableCaption confidence="0.989299333333333">
Table 3: Performance of subjectivity analysis with precision (P), recall (R), and F-measure (F). S-SA,-
CB,-LB systems in Korean, Chinese, Japanese indicate English analysis systems inputted with transla-
tions of the target languages into English.
</tableCaption>
<table confidence="0.999900571428571">
English Korean Chinese Japanese
P R F P R F P R F P R F
S-SA 71.1 63.5 67.1 70.7 61.1 65.6 67.3 68.8 68.0 69.1 67.5 68.3
S-CB 74.4 53.9 62.5 74.5 52.2 61.4 71.1 63.3 67.0 72.9 65.3 68.9
S-LB 62.5 87.7 73.0 62.9 87.7 73.3 59.9 91.5 72.4 61.8 94.1 74.6
T-CB 72.4 67.5 69.8 75.0 66.2 70.3 72.5 70.3 71.4
T-LB 59.4 71.0 64.7 58.4 82.3 68.2 56.9 92.4 70.4
</table>
<tableCaption confidence="0.80784625">
Table 4: Performance of multilanguage-comparability: kappa coefficient (K) for measuring comparability
of classification labels and Pearson’s correlation coefficient (p) for classification scores for English (EN),
Korean (KR), Chinese (CH), and Japanese (JP). Evaluations of T-CB,-LB for language pairs including
English are carried out with results from S-CB,-LB for English and T-CB,-LB for target languages.
</tableCaption>
<table confidence="0.999892666666667">
S-SA S-CB S-LB T-CB T-LB
K p K p K p K p K p
EN &amp; KR 0.41 0.55 0.45 0.60 0.37 0.59 0.42 0.60 0.25 0.41
EN &amp; CH 0.39 0.54 0.41 0.62 0.33 0.52 0.39 0.57 0.22 0.38
EN &amp; JP 0.39 0.53 0.43 0.65 0.30 0.59 0.40 0.59 0.15 0.33
KR &amp; CH 0.36 0.54 0.39 0.59 0.28 0.57 0.46 0.64 0.23 0.37
KR &amp; JP 0.37 0.60 0.44 0.69 0.50 0.69 0.63 0.76 0.18 0.38
CH &amp; JP 0.37 0.53 0.49 0.66 0.29 0.57 0.46 0.63 0.22 0.46
Average 0.38 0.55 0.44 0.64 0.35 0.59 0.46 0.63 0.21 0.39
</table>
<figureCaption confidence="0.999498">
Figure 3: Scatter plots of English (x-axis) and Korean (y-axis) subjectivity scores from state-of-the-art
(S-SA), corpus-based (S-CB), and lexicon-based (S-LB) systems of the source language, and corpus-
based with translated corpora (T-CB), and lexicon-based with translated lexicon (T-LB) systems. Slanted
lines in figures are best-fit lines through the origins.
</figureCaption>
<figure confidence="0.998554513513514">
-100 -50 0 50 100 -4 -3 -2 -1 0 1 2 3 4 -10 -5 0 5 10
(a) S-SA (b) S-CB (c) S-LB
4
3
2
1
0
-1
-2
-3
-4
-4 -3 -2 -1 0 1 2 3 4 -10 -5 0 5 10
(d) T-CB (e) T-LB
-1
4
3
2
0
1
-2
-3
-4
100
50
0
-50
-1
10
5
0
-5
-1
-1
10
-5
5
0
</figure>
<page confidence="0.990618">
601
</page>
<bodyText confidence="0.999875230769231">
Figure 3 shows scatter plots of subjectivity
scores of our English and Korean test corpora eval-
uated on different systems; the data points on the
first and the third quadrants are occurrences of la-
bel agreements, and the second and the fourth are
disagreements. Linearly scattered data points are
more correlated regardless of the slope.
Figure 3a shows a moderate correlation for mul-
tilingual results from the state-of-the-art system
(S-SA). Agreements on objective instances are
clustered together while agreements on subjective
instances are diffused over a wide region.
Agreements between the source language
corpus-based system (S-CB) and the corpus-based
system trained with translated resources (T-CB)
are more distinctively correlated than the results
for other pairs of systems (Figures 3b and 3d). We
notice that S-CB seems to have a lower number of
outliers than T-CB, but slightly more diffusive.
Lexicon-based systems (S-LB, T-LB) gener-
ate noticeably uncorrelated scores (Figures 3c and
3e). We observe that the results from the English
system with translated inputs (S-LB) is more cor-
related than those from systems with translated
lexicons (T-LB), and that analysis results from
both systems are biased toward subjective scores.
</bodyText>
<sectionHeader confidence="0.999817" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999255285714285">
Which approach is most suitable for multilingual
subjectivity analysis?
In our experiments, the corpus-based sys-
tems trained on corpora translated from English
to the target languages (T-CB) perform well
for subjectivity classification and multilanguage-
comparability measures on the whole. However,
the methods we employed to expand the languages
were naively carried out without much considera-
tions for optimization. Further adjustments could
improve the other systems for both classification
and multilanguage-comparability performances.
Is there a correlation between classification per-
formance and multilanguage-comparability?
Lexicon-based systems in the source language
(S-LB) have good overall classification perfor-
mances, especially on recall and F-measures.
However, these systems performs worse on
multilanguage-comparability than other systems
with poorer classification performances. Intrigued
by the observation, we tried to measure which
criteria for classification performance influences
multilanguage-comparability. We again employed
Pearson’s correlation metrics to measure the corre-
lations of precision (P), recall (R), and F-measures
(F) to kappa (n) and Pearson’s correlation (p) val-
ues.
Specifically, we measure the correlations be-
tween the sums of P, the sums of R, and the
sums of F to n and p for all pairs of systems.13
The correlations of P with n and p are 0.78
and 0.68, R −0.38 and −0.28, and F −0.20
and −0.05. These numbers strongly suggest that
multilanguage-comparability correlates with the
precisions of classifiers.
However, we cannot always expect a high-
precision multilingual subjectivity classifier to be
multilanguage-comparable as well. For example,
the S-SA system has a much higher precision
than S-LB consistently over all languages, but
their multilanguage-comparability performances
differed only by small amounts.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.996114">
Multilanguage-comparability is an analysis sys-
tem’s ability to retain its decision criteria across
different languages. We implemented a number of
previously proposed approaches to learning mul-
tilingual subjectivity, and evaluated the systems
on multilanguage-comparability as well as clas-
sification performance. Our experimental results
provide meaningful comparisons of the multilin-
gual subjectivity analysis systems across various
aspects.
Also, we developed a multilingual subjectivity
evaluation corpus from a parallel text, and studied
inter-annotator, inter-language agreements on sub-
jectivity, and observed persistent subjectivity pro-
jections from one language to another from a par-
allel text.
For future work, we aim extend this work to
constructing a multilingual sentiment analysis sys-
tem and evaluate it with multilingual datasets
such as product reviews collected from different
countries. We also plan to resolve the lexicon-
based classifiers’ classification bias towards sub-
jective meanings with a list of objective words
(Esuli and Sebastiani, 2006) and their multilin-
gual expansion (Kim et al., 2009), and evaluate
the multilanguage-comparability of systems con-
structed with resources from different sources.
13Pairs of values such as 71.1 + 70.7 and 0.41 for preci-
sions and Kappa of S-SA for English and Korean.
</bodyText>
<page confidence="0.997955">
602
</page>
<sectionHeader confidence="0.992166" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999897125">
We thank the anonymous reviewers for valuable
comments and helpful suggestions. This work is
supported in part by Basic Science Research Pro-
gram through the National Research Foundation
of Korea (NRF) funded by the Ministry of Edu-
cation, Science and Technology (MEST) (2009-
0075211), and in part by the BK 21 project in
2010.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999882505376344">
Ahmed Abbasi, Hsinchun Chen, and Arab Salem.
2008. Sentiment analysis in multiple languages:
Feature selection for opinion classification in web
forums. ACM Transactions on Information Systems,
26(3):1–34.
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity
analysis using machine translation. In EMNLP ’08:
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 127–
135, Morristown, NJ, USA.
Mikhail Bautin, Lohit Vijayarenu, and Steven Skiena.
2008. International sentiment analysis for news and
blogs. In Proceedings of the International Confer-
ence on Weblogs and Social Media (ICWSM).
Erik Boiy and Marie-Francine Moens. 2009. A
machine learning approach to sentiment analysis
in multlingual Web texts. Information Retrieval,
12:526–558.
Julian Brooke, Milan Tofiloski, and Maite Taboada.
2009. Cross-linguistic sentiment analysis: From en-
glish to spanish. In Proceedings of RANLP 2009,
Borovets, Bulgaria.
Carmine Cesarano, Antonio Picariello, Diego Refor-
giato, and V.S. Subrahmanian. 2007. The oasys 2.0
opinion analysis system: A demo. In Proceedings of
the International Conference on Weblogs and Social
Media (ICWSM).
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In Proceedings of the 5th Con-
ference on Language Resources and Evaluation
(LREC’06), pages 417–422, Geneva, IT.
Soo-Min Kim and Eduard Hovy. 2006. Identifying
and analyzing judgment opinions. In Proceedings
of the Human Language Technology Conference of
the NAACL (HLT/NAACL’06), pages 200–207, New
York, USA.
Jungi Kim, Hun-Young Jung, Sang-Hyob Nam, Yeha
Lee, and Jong-Hyeok Lee. 2009. Found in trans-
lation: Conveying subjectivity of a lexicon of one
language into another using a bilingual dictionary
and a link analysis algorithm. In ICCPOL ’09: Pro-
ceedings of the 22nd International Conference on
Computer Processing of Oriental Languages. Lan-
guage Technology for the Knowledge-based Econ-
omy, pages 112–121, Berlin, Heidelberg.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2007. Learning multilingual subjective language via
cross-lingual projections. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics (ACL’07), pages 976–983, Prague, CZ.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 79–86.
Ellen Riloff and Janyce Wiebe. 2003. Learning ex-
traction patterns for subjective expressions. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP).
Xiaojun Wan. 2008. Using bilingual knowledge and
ensemble techniques for unsupervised Chinese sen-
timent analysis. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, pages 553–561, Honolulu, Hawaii, Oc-
tober. Association for Computational Linguistics.
Xiaojun Wan. 2009. Co-training for cross-lingual sen-
timent classification. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Nat-
ural Language Processing of the AFNLP, pages
235–243, Suntec, Singapore, August. Association
for Computational Linguistics.
Janyce Wiebe and Ellen Riloff. 2005. Creating subjec-
tive and objective sentence classifiers from unanno-
tated texts. In Proceedings of the 6th International
Conference on Intelligent Text Processing and Com-
putational Linguistics (CICLing-2005), pages 486–
497, Mexico City, Mexico.
Janyce Wiebe, E. Breck, Christopher Buckley, Claire
Cardie, P. Davis, B. Fraser, Diane Litman, D. Pierce,
Ellen Riloff, Theresa Wilson, D. Day, and Mark
Maybury. 2003. Recognizing and organizing opin-
ions expressed in the world press. In Proceedings
of the 2003 AAAI Spring Symposium on New Direc-
tions in Question Answering.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the Con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing
(HLT-EMNLP’05), pages 347–354, Vancouver, CA.
</reference>
<page confidence="0.999119">
603
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.975469">
<title confidence="0.99965">Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</title>
<author confidence="0.996078">Jungi Kim</author>
<author confidence="0.996078">Jin-Ji Li</author>
<author confidence="0.996078">Jong-Hyeok Lee</author>
<affiliation confidence="0.994953">Division of Electrical and Computer Engineering Pohang University of Science and Technology, Pohang, Republic of Korea</affiliation>
<abstract confidence="0.999305466666667">Subjectivity analysis is a rapidly growing field of study. Along with its applications to various NLP tasks, much work have put efforts into multilingual subjectivity learning from existing resources. Multilingual subjectivity analysis requires language-independent criteria for comparable outcomes across languages. This paper proposes to measure the multilanguage-comparability of subjectivity analysis tools, and provides meaningful comparisons of multilingual subjectivity analysis from various points of view.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ahmed Abbasi</author>
<author>Hsinchun Chen</author>
<author>Arab Salem</author>
</authors>
<title>Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums.</title>
<date>2008</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="5412" citStr="Abbasi et al. (2008)" startWordPosition="798" endWordPosition="802">guages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corpus translation results in modest performance degradation, it provides a viable approach because no manual labor is required (Ban</context>
</contexts>
<marker>Abbasi, Chen, Salem, 2008</marker>
<rawString>Ahmed Abbasi, Hsinchun Chen, and Arab Salem. 2008. Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums. ACM Transactions on Information Systems, 26(3):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
<author>Samer Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>In EMNLP ’08: Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>127--135</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4579" citStr="Banea et al., 2008" startWordPosition="657" endWordPosition="660">r English. These approaches enable us to extend a monolingual system to many languages with a number of freely available NLP resources and tools. 2 Related Work Much research have been put into developing methods for multilingual subjectivity analysis recently. With the high availability of subjectivity resources and tools in English, an easy and straightforward approach would be to employ a machine translation (MT) system to translate input texts in target languages into English then carry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the</context>
<context position="6027" citStr="Banea et al., 2008" startWordPosition="891" endWordPosition="894">08) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corpus translation results in modest performance degradation, it provides a viable approach because no manual labor is required (Banea et al., 2008; Brooke et al., 2009). Based on the observation that the performances of subjectivity analysis systems in comparable experimental settings for two languages differ, Texts with an identical negative sentiment: * The iPad could cannibalize the e-reader market. * o}off-1.!!7}(iPad) ;14;M AJJ-&amp;-(e-reader market) -qGAJ4 T 5i+(could cannibalize). Texts with different strengths of positive sentiments: * Samsung cell phones have excellent battery life. * -IJJ(Samsung) 4q;1IA(cell phone) &apos;alBIF-Ii (battery) aqAlq(somehow or other) 44&amp;+(last long). Figure 1: Examples of sentiments in multilingual text </context>
<context position="13427" citStr="Banea et al., 2008" startWordPosition="2007" endWordPosition="2010">English annotated with opinions and private states at 3http://www.cs.pitt.edu/mpqa/opinionfinderrelease/, version 1.5 597 the sub-sentence level (Wiebe et al., 2003).4 We retrieve the sentence level subjectivity labels for 11,111 sentences using the set of rules described in (Wiebe and Riloff, 2005). The corpus provides a relatively balanced corpus with 55% subjective sentences. We train an ML-based classifier using the corpus. Previous studies have found that, among several ML-based approaches, the SVM classifier generally performs well in many subjectivity analysis tasks (Pang et al., 2002; Banea et al., 2008). We use SVMLzght with its default configurations,5 inputted with a sentence represented as a feature vector of word unigrams and their counts in the sentence. An SVM score (a margin or the distance from a learned decision boundary) with a positive value predicts the input as being subjective, and negative value as objective. Lexicon-based (S-LB): OpinionFinder contains a list of English subjectivity clue words with intensity labels (Wilson et al., 2005). The lexicon is compiled from several manually and automatically built resources and contains 6885 unique entries. Riloff and Wiebe (2003) co</context>
<context position="15178" citStr="Banea et al., 2008" startWordPosition="2277" endWordPosition="2280"> subjective, and otherwise objective. The threshold value is optimized for an F-measure using the MPQA corpus, and is set to 1.0 throughout our experiments. 4.2 Target Language System To construct a target language system leveraging on available resources in the source language, we consider three approaches from previous literature: 1. translating test sentences in target language into source language and inputting them into 4http://www.cs.pitt.edu/mpqa/databaserelease/, version 1.2 5http://svmlight.joachims.org/, version 6.02 a source language system (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008) 2. translating a source language training corpus into target language and creating a corpusbased system in target language (Banea et al., 2008) 3. translating a subjectivity lexicon from source language to target language and creating a lexicon-based system in target language (Mihalcea et al., 2007) Each approach has its advantages and disadvantages. The advantage of the first approach is its simple architecture, clear separation of subjectivity and MT systems, and that it has only one subjectivity system, and is thus easier to maintain. Its disadvantage is that the time-consuming MT has to b</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>Carmen Banea, Rada Mihalcea, Janyce Wiebe, and Samer Hassan. 2008. Multilingual subjectivity analysis using machine translation. In EMNLP ’08: Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 127– 135, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bautin</author>
<author>Lohit Vijayarenu</author>
<author>Steven Skiena</author>
</authors>
<title>International sentiment analysis for news and blogs.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="1679" citStr="Bautin et al., 2008" startWordPosition="237" endWordPosition="240">s. These endeavors have been successful in constructing lexicons, annotated corpora, and tools for subjectivity analysis in multiple languages. There are multilingual subjectivity analysis systems available that have been built to monitor and analyze various concerns and opinions on the Internet; among the better known are OASYS from the University of Maryland that analyzes opinions on topics from news article searches in multiple languages (Cesarano et al., 2007)1 and TextMap, an entity search engine developed by Stony Brook University for sentiment analysis along with other functionalities (Bautin et al., 2008).2 Though these systems currently rely on English analysis tools and a machine translation (MT) technology to 1http://oasys.umiacs.umd.edu/oasysnew/ 2http://www.textmap.com/ translate other languages into English, up-to-date research provides various ways to analyze subjectivity in multilingual environments. Given sentiment analysis systems in different languages, there are many situations when the analysis outcomes need to be multilanguagecomparable. For example, it has been common these days for the Internet users across the world to share their views and opinions on various topics including</context>
<context position="4558" citStr="Bautin et al., 2008" startWordPosition="653" endWordPosition="656">inguistics created for English. These approaches enable us to extend a monolingual system to many languages with a number of freely available NLP resources and tools. 2 Related Work Much research have been put into developing methods for multilingual subjectivity analysis recently. With the high availability of subjectivity resources and tools in English, an easy and straightforward approach would be to employ a machine translation (MT) system to translate input texts in target languages into English then carry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching inten</context>
<context position="6792" citStr="Bautin et al. (2008)" startWordPosition="996" endWordPosition="999">wo languages differ, Texts with an identical negative sentiment: * The iPad could cannibalize the e-reader market. * o}off-1.!!7}(iPad) ;14;M AJJ-&amp;-(e-reader market) -qGAJ4 T 5i+(could cannibalize). Texts with different strengths of positive sentiments: * Samsung cell phones have excellent battery life. * -IJJ(Samsung) 4q;1IA(cell phone) &apos;alBIF-Ii (battery) aqAlq(somehow or other) 44&amp;+(last long). Figure 1: Examples of sentiments in multilingual text Banea et al. (2008) have attributed the variations in the difficulty level of subjectivity learning to the differences in language construction. Bautin et al. (2008)’s system analyzes the sentiment scores of entities in multilingual news and blogs and adjusted the sentiment scores using entity sentiment probabilities of languages. 3 Multilanguage-Comparability 3.1 Motivation The quality of a subjectivity analysis tool is measured by its ability to distinguish subjectivity from objectivity and/or positive sentiments from negative sentiments. Additionally, a multilingual subjectivity analysis system is required to generate unbiased analysis results across languages; the system should base its outcome solely on the subjective meanings of input texts irrespec</context>
<context position="15157" citStr="Bautin et al., 2008" startWordPosition="2273" endWordPosition="2276">reshold, the input is subjective, and otherwise objective. The threshold value is optimized for an F-measure using the MPQA corpus, and is set to 1.0 throughout our experiments. 4.2 Target Language System To construct a target language system leveraging on available resources in the source language, we consider three approaches from previous literature: 1. translating test sentences in target language into source language and inputting them into 4http://www.cs.pitt.edu/mpqa/databaserelease/, version 1.2 5http://svmlight.joachims.org/, version 6.02 a source language system (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008) 2. translating a source language training corpus into target language and creating a corpusbased system in target language (Banea et al., 2008) 3. translating a subjectivity lexicon from source language to target language and creating a lexicon-based system in target language (Mihalcea et al., 2007) Each approach has its advantages and disadvantages. The advantage of the first approach is its simple architecture, clear separation of subjectivity and MT systems, and that it has only one subjectivity system, and is thus easier to maintain. Its disadvantage is that the time-</context>
</contexts>
<marker>Bautin, Vijayarenu, Skiena, 2008</marker>
<rawString>Mikhail Bautin, Lohit Vijayarenu, and Steven Skiena. 2008. International sentiment analysis for news and blogs. In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Boiy</author>
<author>Marie-Francine Moens</author>
</authors>
<title>A machine learning approach to sentiment analysis in multlingual Web texts. Information Retrieval,</title>
<date>2009</date>
<pages>12--526</pages>
<contexts>
<context position="5438" citStr="Boiy and Moens (2009)" startWordPosition="804" endWordPosition="807">rces. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corpus translation results in modest performance degradation, it provides a viable approach because no manual labor is required (Banea et al., 2008; Brooke et</context>
</contexts>
<marker>Boiy, Moens, 2009</marker>
<rawString>Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multlingual Web texts. Information Retrieval, 12:526–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Maite Taboada</author>
</authors>
<title>Cross-linguistic sentiment analysis: From english to spanish.</title>
<date>2009</date>
<booktitle>In Proceedings of RANLP 2009, Borovets,</booktitle>
<contexts>
<context position="6049" citStr="Brooke et al., 2009" startWordPosition="895" endWordPosition="898">ns (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corpus translation results in modest performance degradation, it provides a viable approach because no manual labor is required (Banea et al., 2008; Brooke et al., 2009). Based on the observation that the performances of subjectivity analysis systems in comparable experimental settings for two languages differ, Texts with an identical negative sentiment: * The iPad could cannibalize the e-reader market. * o}off-1.!!7}(iPad) ;14;M AJJ-&amp;-(e-reader market) -qGAJ4 T 5i+(could cannibalize). Texts with different strengths of positive sentiments: * Samsung cell phones have excellent battery life. * -IJJ(Samsung) 4q;1IA(cell phone) &apos;alBIF-Ii (battery) aqAlq(somehow or other) 44&amp;+(last long). Figure 1: Examples of sentiments in multilingual text Banea et al. (2008) ha</context>
</contexts>
<marker>Brooke, Tofiloski, Taboada, 2009</marker>
<rawString>Julian Brooke, Milan Tofiloski, and Maite Taboada. 2009. Cross-linguistic sentiment analysis: From english to spanish. In Proceedings of RANLP 2009, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmine Cesarano</author>
<author>Antonio Picariello</author>
<author>Diego Reforgiato</author>
<author>V S Subrahmanian</author>
</authors>
<title>The oasys 2.0 opinion analysis system: A demo.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="1527" citStr="Cesarano et al., 2007" startWordPosition="215" endWordPosition="218">h its applications to various NLP tasks, there have been efforts made to extend the resources and tools created for the English language to other languages. These endeavors have been successful in constructing lexicons, annotated corpora, and tools for subjectivity analysis in multiple languages. There are multilingual subjectivity analysis systems available that have been built to monitor and analyze various concerns and opinions on the Internet; among the better known are OASYS from the University of Maryland that analyzes opinions on topics from news article searches in multiple languages (Cesarano et al., 2007)1 and TextMap, an entity search engine developed by Stony Brook University for sentiment analysis along with other functionalities (Bautin et al., 2008).2 Though these systems currently rely on English analysis tools and a machine translation (MT) technology to 1http://oasys.umiacs.umd.edu/oasysnew/ 2http://www.textmap.com/ translate other languages into English, up-to-date research provides various ways to analyze subjectivity in multilingual environments. Given sentiment analysis systems in different languages, there are many situations when the analysis outcomes need to be multilanguagecomp</context>
</contexts>
<marker>Cesarano, Picariello, Reforgiato, Subrahmanian, 2007</marker>
<rawString>Carmine Cesarano, Antonio Picariello, Diego Reforgiato, and V.S. Subrahmanian. 2007. The oasys 2.0 opinion analysis system: A demo. In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<pages>417--422</pages>
<location>Geneva, IT.</location>
<contexts>
<context position="31945" citStr="Esuli and Sebastiani, 2006" startWordPosition="4877" endWordPosition="4880">ects. Also, we developed a multilingual subjectivity evaluation corpus from a parallel text, and studied inter-annotator, inter-language agreements on subjectivity, and observed persistent subjectivity projections from one language to another from a parallel text. For future work, we aim extend this work to constructing a multilingual sentiment analysis system and evaluate it with multilingual datasets such as product reviews collected from different countries. We also plan to resolve the lexiconbased classifiers’ classification bias towards subjective meanings with a list of objective words (Esuli and Sebastiani, 2006) and their multilingual expansion (Kim et al., 2009), and evaluate the multilanguage-comparability of systems constructed with resources from different sources. 13Pairs of values such as 71.1 + 70.7 and 0.41 for precisions and Kappa of S-SA for English and Korean. 602 Acknowledgement We thank the anonymous reviewers for valuable comments and helpful suggestions. This work is supported in part by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology (MEST) (2009- 0075211), and in part by the BK 21 proje</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06), pages 417–422, Geneva, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying and analyzing judgment opinions.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL (HLT/NAACL’06),</booktitle>
<pages>200--207</pages>
<location>New York, USA.</location>
<contexts>
<context position="4537" citStr="Kim and Hovy, 2006" startWordPosition="649" endWordPosition="652"> for Computational Linguistics created for English. These approaches enable us to extend a monolingual system to many languages with a number of freely available NLP resources and tools. 2 Related Work Much research have been put into developing methods for multilingual subjectivity analysis recently. With the high availability of subjectivity resources and tools in English, an easy and straightforward approach would be to employ a machine translation (MT) system to translate input texts in target languages into English then carry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refi</context>
<context position="15136" citStr="Kim and Hovy, 2006" startWordPosition="2269" endWordPosition="2272">y scores; above a threshold, the input is subjective, and otherwise objective. The threshold value is optimized for an F-measure using the MPQA corpus, and is set to 1.0 throughout our experiments. 4.2 Target Language System To construct a target language system leveraging on available resources in the source language, we consider three approaches from previous literature: 1. translating test sentences in target language into source language and inputting them into 4http://www.cs.pitt.edu/mpqa/databaserelease/, version 1.2 5http://svmlight.joachims.org/, version 6.02 a source language system (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008) 2. translating a source language training corpus into target language and creating a corpusbased system in target language (Banea et al., 2008) 3. translating a subjectivity lexicon from source language to target language and creating a lexicon-based system in target language (Mihalcea et al., 2007) Each approach has its advantages and disadvantages. The advantage of the first approach is its simple architecture, clear separation of subjectivity and MT systems, and that it has only one subjectivity system, and is thus easier to maintain. Its disadvant</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. In Proceedings of the Human Language Technology Conference of the NAACL (HLT/NAACL’06), pages 200–207, New York, USA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jungi Kim</author>
<author>Hun-Young Jung</author>
<author>Sang-Hyob Nam</author>
<author>Yeha Lee</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Found in translation: Conveying subjectivity of a lexicon of one language into another using a bilingual dictionary and a link analysis algorithm.</title>
<date>2009</date>
<booktitle>In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy,</booktitle>
<pages>112--121</pages>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="5068" citStr="Kim et al. (2009)" startWordPosition="740" endWordPosition="743">arry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning mul</context>
</contexts>
<marker>Kim, Jung, Nam, Lee, Lee, 2009</marker>
<rawString>Jungi Kim, Hun-Young Jung, Sang-Hyob Nam, Yeha Lee, and Jong-Hyeok Lee. 2009. Found in translation: Conveying subjectivity of a lexicon of one language into another using a bilingual dictionary and a link analysis algorithm. In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledge-based Economy, pages 112–121, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carmen Banea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07),</booktitle>
<pages>976--983</pages>
<location>Prague, CZ.</location>
<contexts>
<context position="4603" citStr="Mihalcea et al. (2007)" startWordPosition="661" endWordPosition="664">oaches enable us to extend a monolingual system to many languages with a number of freely available NLP resources and tools. 2 Related Work Much research have been put into developing methods for multilingual subjectivity analysis recently. With the high availability of subjectivity resources and tools in English, an easy and straightforward approach would be to employ a machine translation (MT) system to translate input texts in target languages into English then carry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of availab</context>
<context position="5855" citStr="Mihalcea et al., 2007" startWordPosition="863" endWordPosition="866">age of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corpus translation results in modest performance degradation, it provides a viable approach because no manual labor is required (Banea et al., 2008; Brooke et al., 2009). Based on the observation that the performances of subjectivity analysis systems in comparable experimental settings for two languages differ, Texts with an identical negative sentiment: * The iPad could cannibalize the e-reader market. * o}off-1.!!7}(iPad) ;14;M AJJ-&amp;-(e-reader market) -qGAJ4 T 5i+(could cannibalize). Texts with different strengths of positive sentiments: * Samsung cell phones have ex</context>
<context position="15479" citStr="Mihalcea et al., 2007" startWordPosition="2323" endWordPosition="2327">approaches from previous literature: 1. translating test sentences in target language into source language and inputting them into 4http://www.cs.pitt.edu/mpqa/databaserelease/, version 1.2 5http://svmlight.joachims.org/, version 6.02 a source language system (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008) 2. translating a source language training corpus into target language and creating a corpusbased system in target language (Banea et al., 2008) 3. translating a subjectivity lexicon from source language to target language and creating a lexicon-based system in target language (Mihalcea et al., 2007) Each approach has its advantages and disadvantages. The advantage of the first approach is its simple architecture, clear separation of subjectivity and MT systems, and that it has only one subjectivity system, and is thus easier to maintain. Its disadvantage is that the time-consuming MT has to be executed for each text input. In the second and third approaches, a subjectivity system in the target language is constructed sharing corpora, rules, and/or features with the source language system. Later on, it may also include its own set of resources specifically engineered for the target langua</context>
<context position="18083" citStr="Mihalcea et al. (2007)" startWordPosition="2756" endWordPosition="2759">en two annotators (An. 1 and An. 2). An. 2 S O Total S 371 93 464 O 23 372 395 Total 394 465 859 Table 2: Agreement on projection of subjectivity (S for subjective, O objective) from Korean (KR) to English (EN) by one annotator. EN S O Total S 458 6 464 O 12 383 395 Total 470 389 859 An. 1 KR up in the dictionary, if they are found, we select the first word in the first sense of the definition. If the entry is not in the dictionary, we lemmatize it,8 then repeat the search. Our simple approach produces moderate-sized lexicons (3,808, 3,980, 3,027 for Korean, Chinese, and Japanese) compared to Mihalcea et al. (2007)’s complicated translation approach (4,983 Romanian words). The threshold values are optimized using the MPQA corpus translated into each target language.9 5 Experiment 5.1 Experimental Setup Test Corpus Our evaluation corpus consists of 50 parallel newspaper articles from the Donga Daily News Website.10 The website provides news articles in Korean and their human translations in English, Japanese, and Chinese. We selected articles that contain Editorial in its English title from a 30- day period. Three human annotators who are fluent in the two languages manually annotated Nto-N sentence alig</context>
<context position="20441" citStr="Mihalcea et al. (2007)" startWordPosition="3100" endWordPosition="3103">both annotators agreed on for the automatic evaluation of subjectivity analysis systems, thereby removing the borderline cases, which are difficult even for humans to assess. The corresponding sentence chunks for other languages were extracted and tagged with labels equivalent to Korean chunks. In addition, to verify how consistently the subjectivity of the original texts is projected to the translated, we carried out another manual annotation and agreement study with Korean and English sentence chunks (Table 2). Note that our cross-lingual agreement study is similar to the one carried out by Mihalcea et al. (2007), where two annotators labeled the sentence subjectivity of a parallel text in different languages. They reported that, similarly to monolingual annotations, most cases of disagreements on annotations are due to the differences in the annotators’ judgments on subjectivity, and the rest from subjective meanings lost in the translation process and figurative language such as irony. To avoid the role played by annotators’ private views from disagreements, the subjectivity of sentence chunks in English were manually annotated by one of the annotators for the Korean text. Judged by the same annotat</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07), pages 976–983, Prague, CZ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>79--86</pages>
<contexts>
<context position="13406" citStr="Pang et al., 2002" startWordPosition="2003" endWordPosition="2006">spaper articles in English annotated with opinions and private states at 3http://www.cs.pitt.edu/mpqa/opinionfinderrelease/, version 1.5 597 the sub-sentence level (Wiebe et al., 2003).4 We retrieve the sentence level subjectivity labels for 11,111 sentences using the set of rules described in (Wiebe and Riloff, 2005). The corpus provides a relatively balanced corpus with 55% subjective sentences. We train an ML-based classifier using the corpus. Previous studies have found that, among several ML-based approaches, the SVM classifier generally performs well in many subjectivity analysis tasks (Pang et al., 2002; Banea et al., 2008). We use SVMLzght with its default configurations,5 inputted with a sentence represented as a feature vector of word unigrams and their counts in the sentence. An SVM score (a margin or the distance from a learned decision boundary) with a positive value predicts the input as being subjective, and negative value as objective. Lexicon-based (S-LB): OpinionFinder contains a list of English subjectivity clue words with intensity labels (Wilson et al., 2005). The lexicon is compiled from several manually and automatically built resources and contains 6885 unique entries. Rilof</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="14024" citStr="Riloff and Wiebe (2003)" startWordPosition="2103" endWordPosition="2106"> 2002; Banea et al., 2008). We use SVMLzght with its default configurations,5 inputted with a sentence represented as a feature vector of word unigrams and their counts in the sentence. An SVM score (a margin or the distance from a learned decision boundary) with a positive value predicts the input as being subjective, and negative value as objective. Lexicon-based (S-LB): OpinionFinder contains a list of English subjectivity clue words with intensity labels (Wilson et al., 2005). The lexicon is compiled from several manually and automatically built resources and contains 6885 unique entries. Riloff and Wiebe (2003) constructed a highprecision classifier for contiguous sentences using the number of strong and weak subjective words in current and nearby sentences. Unlike previous work, we do not (or rather, cannot) maintain assumptions about the proximity of input text. Using the lexicon, we build a simple and highcoverage rule-based subjectivity classifier. Setting the scores of strong and weak subjective words as 1.0 and 0.5, we evaluate the subjectivity of a given sentence as the sum of subjectivity scores; above a threshold, the input is subjective, and otherwise objective. The threshold value is opti</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
</authors>
<title>Using bilingual knowledge and ensemble techniques for unsupervised Chinese sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>553--561</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="4899" citStr="Wan (2008)" startWordPosition="711" endWordPosition="712">nglish, an easy and straightforward approach would be to employ a machine translation (MT) system to translate input texts in target languages into English then carry out the analyses using an existing subjectivity analysis tool (Kim and Hovy, 2006; Bautin et al., 2008; Banea et al., 2008). Mihalcea et al. (2007) and Banea et al. (2008) proposed a number of approaches exploiting a bilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target lan</context>
</contexts>
<marker>Wan, 2008</marker>
<rawString>Xiaojun Wan. 2008. Using bilingual knowledge and ensemble techniques for unsupervised Chinese sentiment analysis. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 553–561, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
</authors>
<title>Co-training for cross-lingual sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>235--243</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="5284" citStr="Wan (2009)" startWordPosition="779" endWordPosition="780">ilingual dictionary, a parallel corpus, and an MT system to port the resources and systems available in English to languages with limited resources. For subjectivity lexicons translation, Mihalcea et al. (2007) and Wan (2008) used the first sense in a bilingual dictionary, Kim and Hovy (2006) used a parallel corpus and a word alignment tool to extract translation pairs, and Kim et al. (2009) used a dictionary to translate and a link analysis algorithm to refine the matching intensity. To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers. Abbasi et al. (2008) and Boiy and Moens (2009) have created manually annotated gold standards in target languages and studied various feature selection and learning techniques in machine learning approaches to analyze sentiments in multilingual web documents. For learning multilingual subjectivity, the literature tentatively concludes that translating lexicon is less dependable in terms of preserving subjectivity than corpus translation (Mihalcea et al., 2007; Wan, 2008), and though corp</context>
</contexts>
<marker>Wan, 2009</marker>
<rawString>Xiaojun Wan. 2009. Co-training for cross-lingual sentiment classification. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 235–243, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating subjective and objective sentence classifiers from unannotated texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2005),</booktitle>
<pages>486--497</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="12153" citStr="Wiebe and Riloff, 2005" startWordPosition="1814" endWordPosition="1817">pare the systems and find out which methods are more suitable for multilanguage-comparability. 4.1 Source Language System We adopt the three systems described below as our source language systems: a state-of-the-art subjectivity classifier, a corpus-based, and a lexiconbased systems. The resources needed for developing the systems or the system itself are readily available for research purposes. In addition, these systems cover the general spectrum of current approaches to subjectivity analysis. State-of-the-art (S-SA): OpinionFinder is a publicly-available NLP tool for subjectivity analysis (Wiebe and Riloff, 2005; Wilson et al., 2005).3 The software and its resources have been widely used in the field of subjectivity analysis, and it has been the de facto standard system against which new systems are validated. We use a highcoverage classifier from the OpinionFinder’s two sentence-level subjectivity classifiers. This Naive Bayes classifier builds upon a corpus annotated by a high-precision classifier with the bootstrapping of the corpus and extraction patterns. The classifier assesses a sentence’s subjectivity with a label and a score for confidence in its judgment. Corpus-based (S-CB): The MPQA opini</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating subjective and objective sentence classifiers from unannotated texts. In Proceedings of the 6th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2005), pages 486– 497, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>E Breck</author>
<author>Christopher Buckley</author>
<author>Claire Cardie</author>
<author>P Davis</author>
<author>B Fraser</author>
<author>Diane Litman</author>
<author>D Pierce</author>
<author>Ellen Riloff</author>
<author>Theresa Wilson</author>
<author>D Day</author>
<author>Mark Maybury</author>
</authors>
<title>Recognizing and organizing opinions expressed in the world press.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 AAAI Spring Symposium on New Directions in Question Answering.</booktitle>
<contexts>
<context position="12973" citStr="Wiebe et al., 2003" startWordPosition="1937" endWordPosition="1940">. We use a highcoverage classifier from the OpinionFinder’s two sentence-level subjectivity classifiers. This Naive Bayes classifier builds upon a corpus annotated by a high-precision classifier with the bootstrapping of the corpus and extraction patterns. The classifier assesses a sentence’s subjectivity with a label and a score for confidence in its judgment. Corpus-based (S-CB): The MPQA opinion corpus is a collection of 535 newspaper articles in English annotated with opinions and private states at 3http://www.cs.pitt.edu/mpqa/opinionfinderrelease/, version 1.5 597 the sub-sentence level (Wiebe et al., 2003).4 We retrieve the sentence level subjectivity labels for 11,111 sentences using the set of rules described in (Wiebe and Riloff, 2005). The corpus provides a relatively balanced corpus with 55% subjective sentences. We train an ML-based classifier using the corpus. Previous studies have found that, among several ML-based approaches, the SVM classifier generally performs well in many subjectivity analysis tasks (Pang et al., 2002; Banea et al., 2008). We use SVMLzght with its default configurations,5 inputted with a sentence represented as a feature vector of word unigrams and their counts in </context>
</contexts>
<marker>Wiebe, Breck, Buckley, Cardie, Davis, Fraser, Litman, Pierce, Riloff, Wilson, Day, Maybury, 2003</marker>
<rawString>Janyce Wiebe, E. Breck, Christopher Buckley, Claire Cardie, P. Davis, B. Fraser, Diane Litman, D. Pierce, Ellen Riloff, Theresa Wilson, D. Day, and Mark Maybury. 2003. Recognizing and organizing opinions expressed in the world press. In Proceedings of the 2003 AAAI Spring Symposium on New Directions in Question Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP’05),</booktitle>
<pages>347--354</pages>
<location>Vancouver, CA.</location>
<contexts>
<context position="12175" citStr="Wilson et al., 2005" startWordPosition="1818" endWordPosition="1821">d out which methods are more suitable for multilanguage-comparability. 4.1 Source Language System We adopt the three systems described below as our source language systems: a state-of-the-art subjectivity classifier, a corpus-based, and a lexiconbased systems. The resources needed for developing the systems or the system itself are readily available for research purposes. In addition, these systems cover the general spectrum of current approaches to subjectivity analysis. State-of-the-art (S-SA): OpinionFinder is a publicly-available NLP tool for subjectivity analysis (Wiebe and Riloff, 2005; Wilson et al., 2005).3 The software and its resources have been widely used in the field of subjectivity analysis, and it has been the de facto standard system against which new systems are validated. We use a highcoverage classifier from the OpinionFinder’s two sentence-level subjectivity classifiers. This Naive Bayes classifier builds upon a corpus annotated by a high-precision classifier with the bootstrapping of the corpus and extraction patterns. The classifier assesses a sentence’s subjectivity with a label and a score for confidence in its judgment. Corpus-based (S-CB): The MPQA opinion corpus is a collect</context>
<context position="13885" citStr="Wilson et al., 2005" startWordPosition="2081" endWordPosition="2084">nd that, among several ML-based approaches, the SVM classifier generally performs well in many subjectivity analysis tasks (Pang et al., 2002; Banea et al., 2008). We use SVMLzght with its default configurations,5 inputted with a sentence represented as a feature vector of word unigrams and their counts in the sentence. An SVM score (a margin or the distance from a learned decision boundary) with a positive value predicts the input as being subjective, and negative value as objective. Lexicon-based (S-LB): OpinionFinder contains a list of English subjectivity clue words with intensity labels (Wilson et al., 2005). The lexicon is compiled from several manually and automatically built resources and contains 6885 unique entries. Riloff and Wiebe (2003) constructed a highprecision classifier for contiguous sentences using the number of strong and weak subjective words in current and nearby sentences. Unlike previous work, we do not (or rather, cannot) maintain assumptions about the proximity of input text. Using the lexicon, we build a simple and highcoverage rule-based subjectivity classifier. Setting the scores of strong and weak subjective words as 1.0 and 0.5, we evaluate the subjectivity of a given s</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP’05), pages 347–354, Vancouver, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>