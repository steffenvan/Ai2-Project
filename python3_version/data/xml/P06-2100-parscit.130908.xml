<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9990845">
Morphological Richness Offsets Resource Demand- Experiences in
Constructing a POS Tagger for Hindi
</title>
<author confidence="0.995152">
Smriti Singh Kuhoo Gupta Manish Shrivastava Pushpak Bhattacharyya
</author>
<affiliation confidence="0.88784375">
Department of Computer Science and Engineering
Indian Institute of Technology, Bombay
Powai, Mumbai
400076 Maharashtra, India
</affiliation>
<email confidence="0.997771">
{smriti,kuhoo,manshri,pb}@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.998648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997418952380953">
In this paper we report our work on
building a POS tagger for a morpholog-
ically rich language- Hindi. The theme
of the research is to vindicate the stand
that- if morphology is strong and har-
nessable, then lack of training corpora is
not debilitating. We establish a method-
ology of POS tagging which the re-
source disadvantaged (lacking annotated
corpora) languages can make use of. The
methodology makes use of locally an-
notated modestly-sized corpora (15,562
words), exhaustive morpohological anal-
ysis backed by high-coverage lexicon
and a decision tree based learning algo-
rithm (CN2). The evaluation of the sys-
tem was done with 4-fold cross valida-
tion of the corpora in the news domain
(www.bbc.co.uk/hindi). The current ac-
curacy of POS tagging is 93.45% and can
be further improved.
</bodyText>
<sectionHeader confidence="0.897094" genericHeader="categories and subject descriptors">
1 Motivation and Problem Definition
</sectionHeader>
<bodyText confidence="0.999958097560976">
Part-Of-Speech (POS) tagging is a complex
task fraught with challenges like ambiguity of
parts of speech and handling of “lexical ab-
sence” (proper nouns, foreign words, deriva-
tionally morphed words, spelling variations and
other unknown words) (Manning and Schutze,
2002). For English there are many POS tag-
gers, employing machine learning techniques
like transformation-based error-driven learning
(Brill, 1995), decision trees (Black et al., 1992),
markov model (Cutting et al. 1992), maxi-
mum entropy methods (Ratnaparkhi, 1996) etc.
There are also taggers which are hybrid using
both stochastic and rule-based approaches, such
as CLAWS (Garside and Smith, 1997). The
accuracy of these taggers ranges from 93-98%
approximately. English has annotated corpora
in abundance, enabling usage of powerful data
driven machine learning methods. But, very few
languages in the world have the resource advan-
tage that English enjoys.
In this scenario, POS tagging of highly in-
flectional languages presents an interesting case
study. Morphologically rich languages are char-
acterized by a large number of morphemes in
a single word, where morpheme boundaries are
difficult to detect because they are fused to-
gether. They are typically free-word ordered,
which causes fixed-context systems to be hardly
adequate for statistical approaches (Samuelsson
and Voutilainen, 1997). Morphology-based POS
tagging of some languages like Turkish (Oflazer
and Kuruoz, 1994), Arabic (Guiassa, 2006),
Czech (Hajic et al., 2001), Modern Greek (Or-
phanos et al., 1999) and Hungarian (Megyesi,
1999) has been tried out using a combination of
hand-crafted rules and statistical learning. These
systems use large amount of corpora along with
morphological analysis to POS tag the texts. It
may be noted that a purely rule-based or a purely
stochastic approach will not be effective for such
</bodyText>
<page confidence="0.968624">
779
</page>
<note confidence="0.726336">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.998151666666667">
languages, since the former demands subtle lin-
guistic expertise and the latter variously per-
muted corpora.
</bodyText>
<subsectionHeader confidence="0.887813">
1.1 Previous Work on Hindi POS Tagging
</subsectionHeader>
<bodyText confidence="0.9999684375">
There is some amount of work done on
morphology-based disambiguation in Hindi POS
tagging. Bharati et al. (1995) in their work
on computational Paninian parser, describe a
technique where POS tagging is implicit and is
merged with the parsing phase. Ray et al. (2003)
proposed an algorithm that identifies Hindi word
groups on the basis of the lexical tags of the indi-
vidual words. Their partial POS tagger (as they
call it) reduces the number of possible tags for a
given sentence by imposing some constraints on
the sequence of lexical categories that are pos-
sible in a Hindi sentence. UPENN also has an
online Hindi morphological tagger&apos; but there ex-
ists no literature discussing the performance of
the tagger.
</bodyText>
<subsectionHeader confidence="0.99581">
1.2 Our Approach
</subsectionHeader>
<bodyText confidence="0.999968636363636">
We present in this paper a POS tagger for
Hindi- the national language of India, spoken
by 500 million people and ranking 4th in the
world. We establish a methodology of POS tag-
ging which the resource disadvantaged (lack-
ing annotated corpora) languages can make
use of. This methodology uses locally anno-
tated modestly sized corpora (15,562 words), ex-
haustive morphological analysis backed by high-
coverage lexicon and a decision tree based learn-
ing algorithm- CN2 (Clark and Niblett, 1989).
To the best of our knowledge, such an approach
has never been tried out for Hindi. The heart of
the system is the detailed linguistic analysis of
morphosyntactic phenomena, adroit handling of
suffixes, accurate verb group identification and
learning of disambiguation rules.
The approach can be used for other inflec-
tional languages by providing the language spe-
cific resources in the form of suffix replacement
rules (SRRs), lexicon, group identification and
morpheme analysis rules etc. and keeping the
</bodyText>
<subsectionHeader confidence="0.853372">
1http://ccat.sas.upenn.edu/plc/tamilweb/hindi.html
</subsectionHeader>
<bodyText confidence="0.999537">
processes the same as shown in Figure 1. The
similar kind of work exploiting morphological
information to assign POS tags is under progress
for Marathi which is also an Indian language.
In what follows, we discuss in section 2 the
challenges in Hindi POS tagging followed by
a section on morphological structure of Hindi.
Section 4 presents the design of Hindi POS tag-
ger. The experimental setup and results are given
in sections 5 and 6. Section 7 concludes the pa-
per.
</bodyText>
<sectionHeader confidence="0.585848" genericHeader="method">
2 Challenges of POS Tagging in Hindi
</sectionHeader>
<bodyText confidence="0.982641913043478">
The inter-POS ambiguity surfaces when a word
or a morpheme displays an ambiguity across
POS categories. Such a word has multiple en-
tries in the lexicon (one for each category). After
stemming, the word would be assigned all pos-
sible POS tags based on the number of entries it
has in the lexicon. The complexity of the task
can be understood looking at the following En-
glish sentence where the word ‘back’ falls into
three different POS categories-
“I get back to the back seat to give rest to my
back.”
The complexity further increases when it
comes to tagging a free-word order language like
Hindi where almost all the permutations of words
in a clause are possible (Shrivastava et al., 2005).
This phenomenon in the language, makes the
task of a stochastic tagger difficult.
Intra-POS ambiguity arises when a word has
one POS with different feature values, e.g., the
word ‘ ’ {laDke} (boys/boy) in Hindi is a
noun but can be analyzed in two ways in terms
of its feature values:
</bodyText>
<listItem confidence="0.898675">
1. POS: Noun, Number: Sg, Case: Oblique
</listItem>
<bodyText confidence="0.88779025">
.
maine laDke ko ek aam diyaa.
I-erg boy to one mango gave.
I gave a mango to the boy.
</bodyText>
<listItem confidence="0.849587">
2. POS: Noun, Number: Pl, Case: Direct
</listItem>
<bodyText confidence="0.892025">
.
laDke aam khaate hain.
Boys mangoes eat.
Boys eat mangoes.
</bodyText>
<page confidence="0.988658">
780
</page>
<bodyText confidence="0.999685733333333">
One of the difficult tasks here is to choose the
appropriate tag based on the morphology of the
word and the context used. Also, new words ap-
pear all the time in the texts. Thus, a method
for determining the tag of a new word is needed
when it is not present in the lexicon. This is
done using context information and the informa-
tion coded in the affixes, as affixes in Hindi (es-
pecially in nouns and verbs) are strong indica-
tors of a word’s POS category. For example, it
is possible to determine that the word ‘ ’
{jaaegaa} (will go) is a verb, based on the envi-
ronment in which it appears and the knowledge
that it carries the inflectional suffix - {egaa}
that attaches to the base verb ‘ ’ {jaa}.
</bodyText>
<subsectionHeader confidence="0.9932">
2.1 Ambiguity Schemes
</subsectionHeader>
<bodyText confidence="0.999972846153846">
The criterion to decide whether the tag of a word
is a Noun or a Verb is entirely different from that
of whether a word is an Adjective or an Adverb.
For example, the word ‘ ’ can occur as con-
junction, post-position or a noun (as shown pre-
viously), hence it falls in an Ambiguity Scheme
‘Conjunction-Noun-Postposition’. We grouped
all the ambiguous words into sets according to
the Ambiguity Schemes that are possible in Hindi,
e.g., Adjective-Noun, Adjective-Adverb, Noun-
Verb, etc. This idea was first proposed by Or-
phanos et al. (1999) for Modern Greek POS tag-
ging.
</bodyText>
<sectionHeader confidence="0.9529" genericHeader="method">
3 Morphological Structure Of Hindi
</sectionHeader>
<bodyText confidence="0.9996289">
In Hindi, Nouns inflect for number and case.
To capture their morphological variations, they
can be categorized into various paradigms2
(Narayana, 1994) based on their vowel ending,
gender, number and case information. We have a
list of around 29,000 Hindi nouns that are catego-
rized into such paradigms3. Looking at the mor-
phological patterns of the words in a paradigm,
suffix-replacement rules have been developed.
These rules help in separating out a valid suffix
</bodyText>
<tableCaption confidence="0.445059">
2A paradigm systematically arranges and identifies the
uninflected forms of the words that share similar inflec-
tional patterns.
3Anusaaraka system developed at IIT Kanpur (INDIA)
uses similar noun sets in the form of paradigms
</tableCaption>
<bodyText confidence="0.9950628">
from an inflected word to output the correct stem
and consequently, get the correct root.
Hindi Adjectives may be inflected or unin-
flected, e.g., ‘ ’ {chamkiilaa} (shiny),
‘ ’ {acchaa} (nice), ‘ ’ {lambaa} (long)
inflect based on the number and case values of
their head nouns while ‘ ’ {sundar} (beauti-
ful), ‘ ’ {bhaarii} (heavy) etc. do not inflect.
Hindi Verbs inflect for the following grammat-
ical properties (GNPTAM):
</bodyText>
<listItem confidence="0.9831007">
1. Gender: Masculine, Feminine, Non-
specific
2. Number: Singular, Plural, Non-specific
3. Person: 1st, 2nd and 3rd
4. Tense: Past, Present, Future
5. Aspect: Perfective, Completive, Frequenta-
tive, Habitual, Durative, Inceptive, Stative
6. Modality: Imperative, Probabilitive, Sub-
junctive, Conditional, Deontic, Abilitive,
Permissive
</listItem>
<bodyText confidence="0.99991285">
The morphemes attached to a verb along with
their corresponding analyses help identify values
for GNPTAM features for a given verb form.
Division of Information Load in Hindi Verb
Groups
A Verb Group (VG) primarily comprises main
verb and auxiliaries. Constituents like particles,
negation markers, conjunction, etc. can also
occur within a VG. It is important to know how
much of GNPTAM feature information is stored
in VG constituents individually and what is the
load division in the absence or presence of auxil-
iaries. In a Hindi VG, when there is no auxiliary
present, the complete information load falls on
the main verb which carries information for
GNPTAM features. In presence of auxiliaries,
the load gets shared between the main verb and
auxiliaries, and is represented in the form of
different morphemes (inflected or uninflected),
e.g., in the sentence -
</bodyText>
<page confidence="0.989085">
781
</page>
<bodyText confidence="0.8964905">
main bol paa rahaa hoon
I am able to speak
</bodyText>
<listItem confidence="0.996738888888889">
1. Main verb ‘ ’ {bol} is uninflected and
does not carry any information for any of
the GNPTAM features.
2. ‘ ’ {paa} is uninflected and gives modality
information, i.e., Abilitive.
3. ‘ ’ {rahaa} gives Number (Sg), Gender
(Masculine), Aspect (Durative)
4. ‘ ’ {hoon} gives Number (Sg), Person
(1st), Tense (Present)
</listItem>
<subsectionHeader confidence="0.711392">
Gerund Identification
</subsectionHeader>
<bodyText confidence="0.999795142857143">
In Hindi, the attachment of verbal suffixes like
‘ ’ {naa} and ‘ ’ {ne} to a verb root results
either in a gerund like ‘ ’ {tairnaa} (swim-
ming) or in an infinitival verb form like ‘ ’
{tairnaa} (to swim). We observed that it is easy
to detect a gerund if it is followed by a case-
marker or by any other infinitival verb form.
</bodyText>
<sectionHeader confidence="0.97883" genericHeader="method">
4 Design of Hindi POS Tagger
</sectionHeader>
<subsectionHeader confidence="0.967309">
4.1 Morphology Driven Tagger
</subsectionHeader>
<bodyText confidence="0.9998779375">
Morphology driven tagger makes use of the affix
information stored in a word and assigns a POS
tag using no contextual information. Though,
it does take into account the previous and the
next word in a VG to correctly identify the main
verb and the auxiliaries, other POS categories
are identified through lexicon lookup of the root
form. The current lexicon4 has around 42,000
entries belonging to the major categories as men-
tioned in Figure 3. The format of each entry is
(word),(paradigm),(category).
The process does not involve learning or dis-
ambiguation of any sort and is completely driven
by hand-crafted morphology rules. The architec-
ture of the tagger is shown in Figure 1. The work
progresses at two levels:
</bodyText>
<subsectionHeader confidence="0.553473">
4The lexicon was developed us-
</subsectionHeader>
<bodyText confidence="0.898465264705882">
ing the wordlist from Hindi Wordnet
(http://www.cfilt.iitb.ac.in/wordnet/webhwn/) and par-
tial noun list from Anusaraka. It is being enhanced by
adding new words from the corpus and removing the
inconsistencies.
1. At Word Level: A stemmer is used in con-
junction with lexicon and Suffix Replace-
ment Rules (SRRs) to output all possible
root-suffix pairs along with POS category
label for a word. There is a possibility that
the input word is not found in the lexicon
and does not carry any inflectional suffix. In
such a case, derivational morphology rules
are applied.
2. At Group Level: At this level a Morpho-
logical Analyzer (MA) uses the information
encoded in the extracted suffix to add mor-
phological information to the word. For
nouns, the information provided by the suf-
fixes is restricted only to ‘Number’. ‘Case’
can be inferred later by looking at the neigh-
bouring words.
For verbs, GNP values are found at the word
level, while TAM values are identified dur-
ing the VG Identification phase, described
later. The analysis of the suffix is done in
a discrete manner, i.e., each component of
the suffix is analyzed separately. A mor-
pheme analysis table comprising individ-
ual morphemes with their paradigm infor-
mation and analyses is used for this pur-
pose. MA’s output for the word
{khaaoongii} (will eat) looks like -
Stem: (eat)
</bodyText>
<table confidence="0.8574376">
Suffix: Category: Verb
Morpheme 1: Analysis: 1 Per, Sg
Morpheme 2: Analysis: Future
Morpheme 3: Analysis: Feminine
4.1.1 Verb Group Identification
</table>
<bodyText confidence="0.999391363636364">
The structure of a Hindi VG is relatively rigid
and can be captured well using simple syntac-
tic rules. In Hindi, certain auxiliaries like ’ ’
{rah}, ’ ’ {paa}, ’ ’, {sak} or ’ ’ {paD}
can also occur as main verbs in some contexts.
VG identification deals with identifying the main
verb and the auxiliaries of a VG while dis-
counting for particles, conjunctions and negation
markers. The VG identification goes left to right
by marking the first constituent as the main verb
or copula verb and making every other verb con-
</bodyText>
<page confidence="0.995629">
782
</page>
<figureCaption confidence="0.990864">
Figure 1: Overall Architecture of the Tagger
</figureCaption>
<tableCaption confidence="0.930793">
Table 1: Average Accuracy(%) Comparison of
Various Approaches
</tableCaption>
<table confidence="0.7814695">
LLB LLBD MD BL LB
61.19 86.77 73.62 82.63 93.45
</table>
<bodyText confidence="0.9989957">
struct an auxiliary till a non-VG constituent is en-
countered. Main verb and copula verb can take
the head position of a VG and can occur with or
without auxiliary verbs. Auxiliary verbs, on the
other hand, always come along with a main verb
or a copula verb. This results in a very high ac-
curacy of 99.5% for verb auxiliaries. Ambiguity
between a main verb and a copula verb remains
unresolved at this level and asks for disambigua-
tion rules.
</bodyText>
<subsectionHeader confidence="0.499451">
4.2 Need for Disambiguation
</subsectionHeader>
<bodyText confidence="0.999995044444445">
The accuracy obtained by simple lexicon lookup
based approach (LLB) comes out to be 61.19%.
The morphology-driven tagger, on the other
hand, performs better than just lexicon lookup
but still results in considerable ambiguity. These
results are significant as they present a strong
case in favor of using detailed morphological
analysis. Similar observation has been presented
by Uchimoto et al. (2001) for Japanese language.
According to the tagging performed by SRRs
and the lexicon, a word receives n tags if it be-
longs to n POSs. If we consider multiple tags for
a word as an error of the tagger (even when the
options contain the correct tag for a word), then
the accuracy of the tagger comes to be 73.62%
(as shown in Table 1). The goal is to keep the
contextually appropriate tag and eliminate oth-
ers which can be achieved by devising a disam-
biguation technique. The disambiguation task
can be naively addressed by choosing the most
frequent tag for a word. This approach is also
known as baseline (BL) tagging. The baseline
accuracy turns out to be 82.63% which is still
higher than that of the morphology-driven tag-
ger5. The drawback with baseline tagging is that
its accuracy cannot be further improved. On the
other hand, there is enough room for improving
upon the accuracy of morphology-driven (MD)
tagger. It is quite evident that though the MD
tagger works well for VG and many close cate-
gories, around 30% of the words are either am-
biguous or unknown. Hence, a disambiguation
stage is needed to shoot up the accuracy.
The common choice for disambiguation rule
learning in POS tagging task is usually ma-
chine learning techniques mainly focussing
on decision tree based algorithms (Orphanos
and Christodoulalds, 1999), neural networks
(Schmid, 1994), etc. Among the various decision
tree based algorithms like ID3, AQR, ASSIS-
TANT and CN2, CN2 is known to perform better
than the rest (Clark and Niblett, 1989). Since no
such machine learning technique has been used
for Hindi language, we thought of choosing CN2
as it performs well on noisy data6.
</bodyText>
<footnote confidence="0.6476554">
5These numbers may change if we experiment on a dif-
ferent dataset
6The training annotated corpora becomes noisy by
virtue of intuitions of different annotators (trained native
Hindi speakers)
</footnote>
<page confidence="0.994659">
783
</page>
<subsubsectionHeader confidence="0.503576">
4.2.1 Training Corpora
</subsubsectionHeader>
<bodyText confidence="0.999950714285714">
We set up a corpus, collecting sentences from
BBC news site7 and let the morphology-driven
tagger assign morphosyntactic tags to all the
words. For an ambiguous word, the contextually
appropriate POS tag is manually chosen. Un-
known words are assigned a correct tag based on
their context and usage.
</bodyText>
<subsectionHeader confidence="0.949346">
4.2.2 Learning
</subsectionHeader>
<bodyText confidence="0.999791666666666">
Out of the completely manually corrected cor-
pora of 15,562 tokens, we created training in-
stances for each Ambiguity Scheme and for Un-
known words. These training instances take into
account the POS categories of the neighbouring
words and not the feature values8. The experi-
ments were carried out for different context win-
dow sizes ranging from 2 to 20 to find the best
configuration.
</bodyText>
<subsectionHeader confidence="0.699484">
4.2.3 Rule Generation
</subsectionHeader>
<bodyText confidence="0.999992368421053">
The rules are generated from the training cor-
pora by extracting the ambiguity scheme (AS) of
each word. If the word is not present in the lexi-
con then its AS is set as ‘unknown’. Once the AS
is identified, a training instance is formed. This
training instance contains the neighbouring cor-
rect POS categories as attributes. The number
of neighbours included in the training instance is
the window size for CN2. After all the ambigu-
ous words are processed and training instances
for all seen ASs are created, the CN2 algorithm
is applied over the training instances to gener-
ate actual rule-sets for each AS. The CN2 algo-
rithm gives one set of If-Then rules (either or-
dered or unordered) for each AS including ‘un-
known’9. The AS of every ambiguous word is
formed while tagging. A corresponding rule-set
for that AS is then identified and traversed to get
the contextually appropriate rule. The resultant
</bodyText>
<subsectionHeader confidence="0.410268">
7http://www.bbc.co.uk/hindi/
</subsectionHeader>
<bodyText confidence="0.874148615384615">
8Considering that a tag encodes 0 to 6 morphosyntactic
features and each feature takes either one or a disjunction
of 2 to 7 values, the total number of different tags can count
up to several hundreds
9We used the CN2 algorithm implementation (1990)
by Robin Boswell. The software is available at
ftp://ftp.cs.utexas.edu/pub/pclark/cn2.tar.Z
category outputted by this rule is then assigned
to the ambiguous word. The traversal rule differs
for ordered and unordered implementation. The
POS of an unknown word is guessed by travers-
ing the rule-set for unknown words10 and assign-
ing it the resultant tag.
</bodyText>
<sectionHeader confidence="0.994339" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9986258">
The experimentation involved, first, identifying
the best parameter values for the CN2 algorithm
and second, evaluating the performance of the
disambiguation rules generated by CN2 for the
POS tagging task.
</bodyText>
<subsectionHeader confidence="0.974864">
5.1 CN2 Parameters
</subsectionHeader>
<bodyText confidence="0.999927375">
The various parameters in CN2 algorithm are:
rule type (ordered or unordered), star size, sig-
nificance threshold and size of the training in-
stances (window size). The best results are em-
pirically achieved with ordered rules, star size as
1, significance threshold as 10 and window size
4, i.e., two neighbours on either side are used to
generate the training instances.
</bodyText>
<subsectionHeader confidence="0.996313">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999965666666667">
The tests are performed on contiguous partitions
of the corpora (15,562 words) that are 75%
training set and 25% testing set.
</bodyText>
<figure confidence="0.875311">
no. of single correct tags
Accuracy =
</figure>
<figureCaption confidence="0.888343">
total no. of tokens
</figureCaption>
<bodyText confidence="0.999944857142857">
The results are obtained by performing a 4-
fold cross validation over the corpora. Figure
2 gives the learning curve of the disambiguation
module for varying corpora sizes starting from
1000 to the complete training corpora size. The
accuracy for known and unknown words is also
measured separately.
</bodyText>
<sectionHeader confidence="0.999364" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.950823">
The average accuracy of the learning based (LB)
tagger after 4-fold cross validation is 93.45%. To
10Most of the unknown words are proper nouns, which
cannot be stored in the lexicon extensively. So, it also helps
in named-entity detection.
</bodyText>
<page confidence="0.993694">
784
</page>
<figure confidence="0.9908675">
0 2000 4000 6000 8000 10000 12000
Number of Words in Training Corpus
</figure>
<figureCaption confidence="0.999529">
Figure 2: POS Learning Curve
</figureCaption>
<bodyText confidence="0.999629108108108">
the best of our knowledge no comparable results
have been reported so far for Hindi.
From Table 1, we can see that the disam-
biguation module brings up the accuracy of sim-
ple lexicon lookup based approach by around
25% (LLBD). The overall average accuracy is
also brought up by around 20% by augmenting
the morphology-driven (MD) tagger by a dis-
ambiguation module; hence justifying our belief
that a disambiguation module over a morphology
driven approach yields better results.
One interesting observation is the performance
of the tagger on individual POS categories. Fig-
ure 3 shows clearly that the per POS accuracies
of the LB tagger highly exceeds those of the MD
and BL tagger for most categories. This means
that the disambiguation module correctly dis-
ambiguates and correctly identifies the unknown
words too. The accuracy on unknown words, as
earlier shown in Figure 2, is very high at 92.08%.
The percentage of unknown words in the test cor-
pora is 0.013. It seems independent of the size
of training corpus because the corpora is unbal-
anced having most of the unknowns as proper
nouns. The rules are formed on this bias, and
hence the application of these rules assigns PPN
tag to an unknown which is mostly the case.
From Figure 3 again we see that the accuracy
on some categories remains very low even after
disambiguation. This calls for some detailed fail-
ure analysis. By looking at the categories hav-
ing low accuracy, such as pronoun, intensifier,
demonstratives and verb copula, we find that all
of them are highly ambiguous and, almost invari-
ably, very rare in the corpus. Also, most of them
are hard to disambiguate without any semantic
information.
</bodyText>
<sectionHeader confidence="0.998268" genericHeader="conclusions">
7 Conclusions &amp; Future Work
</sectionHeader>
<bodyText confidence="0.999943413793104">
We have described in this paper a POS tagger for
Hindi which can overcome the handicap of anno-
tated corpora scarcity by exploiting the rich mor-
phology of the language and the relatively rigid
word-order within a VG. The whole work was
driven by hunting down the factors that lower the
accuracy of Verbs and weeding them out. A de-
tailed study of accuracy distribution across the
POS tags pointed out the cases calling for elab-
orate disambiguation rules. A major strength of
the work is the learning of disambiguation rules,
which otherwise would have been hand-coded,
thus demanding exhaustive analysis of language
phenomena. Attaining an accuracy of close to
94%, from a corpora of just about 15,562 words
lends credence to the belief that “morphological
richness can offset resource scarcity”. The work
could lead such efforts of POS tag building for
all those languages which have rich morphology,
but cannot afford to invest a lot in creating large
annotated corpora.
Several interesting future directions suggest
themselves. It will be worthwhile to investigate
a statistical approach like Conditional Random
Fields in which the feature functions would be
constructed from morphology. The next logi-
cal step from the POS tagger is a chunker for
Hindi. In fact a start on this has already been
made through VG identification.
</bodyText>
<sectionHeader confidence="0.998725" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.955290875">
A. Ratnaparakhi. 1996. A Maximum Entropy Part-
Of-Speech Tagger. EMNLP 1996
A. Bharati, V. Chaitanya, R. Sangal 1995. Natural
Language Processing : A Paninian Perspective .
Prentice Hall India.
A. Kuba, A. Hcza, J. Csirik 2004. POS Tagging
of Hungarian with Combined Statistical and Rule-
Based Methods. TSD 2004
</reference>
<figure confidence="0.996190692307692">
Overall Accuracy
Known Words Accuracy
Unknown Words Accuracy
Accuracy 94.5
94
93.5
93
92.5
92
91.5
91
90.5
90
</figure>
<page confidence="0.796179">
785
</page>
<figureCaption confidence="0.995488">
Figure 3: Per-POS Accuracy Distribution
</figureCaption>
<figure confidence="0.9980677">
20
0
Accuracy
60
40
100
80
BL
MD
LB
</figure>
<reference confidence="0.999866032258065">
B. Megyesi. 1999. Improving Brill’s POS tagger for
an agglutinative language. Joint Sigdat Confer-
ence EMNLP/VLC 1999.
C. D. Manning and H. Schutze. 2002. Foundations
of Statistical Natural Language Processing, MIT
Press 2002.
D. Cutting et al. 1992. A practical part-of-speech
tagger. In Proc. of the Third Conf. on Applied Nat-
ural Language Processing. ACL 1992.
E. Brill. 1995. Transformation-Based Error Driven
Learning and Natural Language Processing: A
Case Study in Part-of-Speech Tagging . Compu-
tational Linguistics 21(94): 543-566. 1995.
E. Black et al. 1992. Decision tree models applied to
the labeling of text with parts-of-speech. In Darpa
Workshop on Speech and Natural Language 1992.
G. Leech, R. Garside and M. Bryant. 1992. Auto-
matic POS-Tagging of the corpus. BNC2 POS-
tagging Manual.
G. Orphanos, D. Kalles, A. Papagelis, D.
Christodoulakis. 1999 Decision trees and NLP:
A Case Study in POS Tagging. In proceedings of
ACAI 1999.
H. Schmid 1994 Part-of-Speech Tagging with Neural
Networks. In proceedings of COLING 1994.
J. Hajic, P. Krbec, P. Kveton, K. Oliva, V. Petkevic
2001 A Case Study in Czech Tagging. In Pro-
ceedings of the 39th Annual Meeting of the ACL
2001
K. Uchimoto, S. Sekine, H. Isahara. 2001. The Un-
known Word Problem: a Morphological Analysis
of Japanese Using Maximum Entropy Aided by a
Dictionary. In Proceedings of the Conference on
EMNLP 2001
K. Oflazer and I. Kuruoz. 1994. Tagging and mor-
phological disambiguation of Turkish text. In Pro-
ceedings of the 4 ACL Conference on Applied Nat-
ural Language Processing Conference 1994
M. Shrivastava, N. Agrawal, S. Singh, P. Bhat-
tacharya. 2005. Harnessing Morphological Anal-
ysis in POS Tagging Task. In Proceedings of the
ICON 2005
P. R. Ray , V. Harish, A. Basu and S. Sarkar 2003.
Part of Speech Tagging and Local Word Group-
ing Techniques for Natural Language Parsing in
Hindi. In Proceedings of ICON 2003
P. Clark and T. Niblett 1989. The CN2 Induction
Algorithm. Journal of Machine Learning, vol(3),
pages 261-283, 1989
R. Garside, N. Smith 1997. A hybrid grammatical
tagger: CLAWS4 . In R. Garside, G. Leech, A.
McEnery (eds.) Corpus annotation: Linguistic in-
formation from computer text corpora. Longman.
Pp. 102-121.
C. Samuelsson and A. Voutilainen 1997. Compar-
ing a Linguistic and a Stochastic Tagger. In Procs.
Joint 35th Annual Meeting of the ACL and 8th
Conference of the European Chapter of the ACL
1997.
Y. Tlili-Guiassa 2006. Hybrid Method for Tagging
Arabic Text. Journal of Computer Science 2 (3):
245-248, 2006
</reference>
<page confidence="0.998411">
786
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9990145">Morphological Richness Offsets Resource Demand- Experiences in Constructing a POS Tagger for Hindi</title>
<author confidence="0.998868">Smriti Singh Kuhoo Gupta Manish Shrivastava Pushpak Bhattacharyya</author>
<affiliation confidence="0.9893715">Department of Computer Science and Engineering Indian Institute of Technology, Bombay</affiliation>
<address confidence="0.9757645">Powai, Mumbai 400076 Maharashtra, India</address>
<abstract confidence="0.993927786729858">In this paper we report our work on building a POS tagger for a morphologically rich language- Hindi. The theme of the research is to vindicate the stand thatif morphology is strong and harnessable, then lack of training corpora is not debilitating. We establish a methodology of POS tagging which the resource disadvantaged (lacking annotated corpora) languages can make use of. The methodology makes use of locally annotated modestly-sized corpora (15,562 words), exhaustive morpohological analysis backed by high-coverage lexicon and a decision tree based learning algorithm (CN2). The evaluation of the system was done with 4-fold cross validation of the corpora in the news domain (www.bbc.co.uk/hindi). The current accuracy of POS tagging is 93.45% and can be further improved. 1 Motivation and Problem Definition Part-Of-Speech (POS) tagging is a complex fraught with challenges like of of speech of “lexical absence” (proper nouns, foreign words, derivamorphed words, spelling variations unknown words) and Schutze, 2002). For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), markov model (Cutting et al. 1992), maxientropy methods (Ratnaparkhi, 1996) There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997). The accuracy of these taggers ranges from 93-98% approximately. English has annotated corpora in abundance, enabling usage of powerful data driven machine learning methods. But, very few languages in the world have the resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 of the COLING/ACL 2006 Main Conference Poster pages 779–786, July 2006. Association for Computational Linguistics languages, since the former demands subtle linguistic expertise and the latter variously permuted corpora. 1.1 Previous Work on Hindi POS Tagging There is some amount of work done on morphology-based disambiguation in Hindi POS Bharati al. in their work on computational Paninian parser, describe a technique where POS tagging is implicit and is with the parsing phase. Ray al. proposed an algorithm that identifies Hindi word groups on the basis of the lexical tags of the individual words. Their partial POS tagger (as they call it) reduces the number of possible tags for a given sentence by imposing some constraints on the sequence of lexical categories that are possible in a Hindi sentence. UPENN also has an Hindi morphological there exists no literature discussing the performance of the tagger. 1.2 Our Approach We present in this paper a POS tagger for Hindithe national language of India, spoken by 500 million people and ranking 4th in the world. We establish a methodology of POS tagging which the resource disadvantaged (lacking annotated corpora) languages can make use of. This methodology uses locally annotated modestly sized corpora (15,562 words), exhaustive morphological analysis backed by highcoverage lexicon and a decision tree based learning algorithm- CN2 (Clark and Niblett, 1989). To the best of our knowledge, such an approach has never been tried out for Hindi. The heart of the system is the detailed linguistic analysis of morphosyntactic phenomena, adroit handling of suffixes, accurate verb group identification and learning of disambiguation rules. The approach can be used for other inflectional languages by providing the language specific resources in the form of suffix replacement rules (SRRs), lexicon, group identification and analysis rules keeping the processes the same as shown in Figure 1. The similar kind of work exploiting morphological information to assign POS tags is under progress for Marathi which is also an Indian language. In what follows, we discuss in section 2 the challenges in Hindi POS tagging followed by a section on morphological structure of Hindi. Section 4 presents the design of Hindi POS tagger. The experimental setup and results are given in sections 5 and 6. Section 7 concludes the paper. 2 Challenges of POS Tagging in Hindi The inter-POS ambiguity surfaces when a word or a morpheme displays an ambiguity across POS categories. Such a word has multiple entries in the lexicon (one for each category). After stemming, the word would be assigned all possible POS tags based on the number of entries it has in the lexicon. The complexity of the task can be understood looking at the following English sentence where the word ‘back’ falls into different POS categories- “I get back to the back seat to give rest to my back.” The complexity further increases when it comes to tagging a free-word order language like Hindi where almost all the permutations of words in a clause are possible (Shrivastava et al., 2005). This phenomenon in the language, makes the task of a stochastic tagger difficult. Intra-POS ambiguity arises when a word has POS with different feature values, the ‘ ’ Hindi is a noun but can be analyzed in two ways in terms of its feature values: POS: Number: Case: . maine laDke ko ek aam diyaa. I-erg boy to one mango gave. I gave a mango to the boy. POS: Number: Case: . laDke aam khaate hain. Boys mangoes eat. Boys eat mangoes. 780 One of the difficult tasks here is to choose the appropriate tag based on the morphology of the word and the context used. Also, new words appear all the time in the texts. Thus, a method for determining the tag of a new word is needed when it is not present in the lexicon. This is done using context information and the information coded in the affixes, as affixes in Hindi (especially in nouns and verbs) are strong indicators of a word’s POS category. For example, it is possible to determine that the word ‘ ’ go) a verb, based on the environment in which it appears and the knowledge it carries the inflectional suffix attaches to the base verb ‘ ’ 2.1 Ambiguity Schemes The criterion to decide whether the tag of a word a a entirely different from that whether a word is an an example, the word ‘ ’ can occur as cona shown prehence it falls in an Scheme We grouped all the ambiguous words into sets according to Schemes are possible in Hindi, Noun- This idea was first proposed by Oral. for Modern Greek POS tagging. 3 Morphological Structure Of Hindi Hindi, for number and case. To capture their morphological variations, they be categorized into various 1994) based on their ending, number We have a list of around 29,000 Hindi nouns that are categointo such Looking at the morphological patterns of the words in a paradigm, suffix-replacement rules have been developed. These rules help in separating out a valid suffix paradigm systematically arranges and identifies the uninflected forms of the words that share similar inflectional patterns. system developed at IIT Kanpur (INDIA) uses similar noun sets in the form of paradigms from an inflected word to output the correct stem and consequently, get the correct root. be inflected or unin- ‘ ’ ’ ‘ ’ (long) inflect based on the number and case values of head nouns while ‘ ’ (beauti- ‘ ’ do not inflect. for the following grammatical properties (GNPTAM):</abstract>
<note confidence="0.75221775">Gender: Masculine, Feminine, specific 2. Number: Singular, Plural, Non-specific 3. Person: 1st, 2nd and 3rd 4. Tense: Past, Present, Future 5. Aspect: Perfective, Completive, Frequentative, Habitual, Durative, Inceptive, Stative 6. Modality: Imperative, Probabilitive, Sub-</note>
<email confidence="0.508486">junctive,Conditional,Deontic,Abilitive,</email>
<abstract confidence="0.947047551724138">Permissive The morphemes attached to a verb along with their corresponding analyses help identify values for GNPTAM features for a given verb form. Division of Information Load in Hindi Verb Groups Group primarily comprises main verb and auxiliaries. Constituents like particles, markers, conjunction, can also occur within a VG. It is important to know how much of GNPTAM feature information is stored in VG constituents individually and what is the load division in the absence or presence of auxiliaries. In a Hindi VG, when there is no auxiliary present, the complete information load falls on the main verb which carries information for GNPTAM features. In presence of auxiliaries, the load gets shared between the main verb and auxiliaries, and is represented in the form of different morphemes (inflected or uninflected), in the sentence - 781 main bol paa rahaa hoon I am able to speak Main verb ‘ ’ uninflected and does not carry any information for any of the GNPTAM features. ‘ ’ uninflected and gives modality Abilitive.</abstract>
<note confidence="0.74619275">Number (Sg), Gender (Masculine), Aspect (Durative) ‘ ’ Number (Sg), Person (1st), Tense (Present)</note>
<title confidence="0.784762">Gerund Identification</title>
<abstract confidence="0.99304625862069">In Hindi, the attachment of verbal suffixes like ’ ‘ ’ a verb root results in a gerund like ‘ ’ (swimin an infinitival verb form like ‘ ’ We observed that it is easy to detect a gerund if it is followed by a casemarker or by any other infinitival verb form. 4 Design of Hindi POS Tagger 4.1 Morphology Driven Tagger Morphology driven tagger makes use of the affix information stored in a word and assigns a POS tag using no contextual information. Though, it does take into account the previous and the next word in a VG to correctly identify the main verb and the auxiliaries, other POS categories are identified through lexicon lookup of the root The current has around 42,000 entries belonging to the major categories as mentioned in Figure 3. The format of each entry is The process does not involve learning or disambiguation of any sort and is completely driven by hand-crafted morphology rules. The architecture of the tagger is shown in Figure 1. The work progresses at two levels: lexicon was developed using the wordlist from Hindi Wordnet (http://www.cfilt.iitb.ac.in/wordnet/webhwn/) and partial noun list from Anusaraka. It is being enhanced by adding new words from the corpus and removing the inconsistencies. At Word Level: A used in conjunction with lexicon and Suffix Replacement Rules (SRRs) to output all possible root-suffix pairs along with POS category label for a word. There is a possibility that the input word is not found in the lexicon and does not carry any inflectional suffix. In a case, morphology rules are applied. At Group Level: At this level a Morpho- Analyzer uses the information encoded in the extracted suffix to add morphological information to the word. For nouns, the information provided by the sufis restricted only to can be inferred later by looking at the neighbouring words. For verbs, GNP values are found at the word level, while TAM values are identified during the VG Identification phase, described later. The analysis of the suffix is done in discrete manner, each component of the suffix is analyzed separately. A morpheme analysis table comprising individual morphemes with their paradigm information and analyses is used for this purpose. MA’s output for the word eat) like -</abstract>
<note confidence="0.6775754">Category: 1: Analysis: Per, Sg 2: Analysis: 3: Analysis: 4.1.1 Verb Group Identification</note>
<abstract confidence="0.980042542735043">The structure of a Hindi VG is relatively rigid and can be captured well using simple syntactic rules. In Hindi, certain auxiliaries like ’ ’ ’ ’ ’ ’, ’ ’ can also occur as main verbs in some contexts. VG identification deals with identifying the main verb and the auxiliaries of a VG while discounting for particles, conjunctions and negation markers. The VG identification goes left to right by marking the first constituent as the main verb copula verb and making every other verb con- 782 Figure 1: Overall Architecture of the Tagger Table 1: Average Accuracy(%) Comparison of Various Approaches LLB LLBD MD BL LB 61.19 86.77 73.62 82.63 93.45 struct an auxiliary till a non-VG constituent is encountered. Main verb and copula verb can take the head position of a VG and can occur with or without auxiliary verbs. Auxiliary verbs, on the other hand, always come along with a main verb or a copula verb. This results in a very high accuracy of 99.5% for verb auxiliaries. Ambiguity between a main verb and a copula verb remains unresolved at this level and asks for disambiguation rules. 4.2 Need for Disambiguation The accuracy obtained by simple lexicon lookup based approach (LLB) comes out to be 61.19%. The morphology-driven tagger, on the other hand, performs better than just lexicon lookup but still results in considerable ambiguity. These results are significant as they present a strong case in favor of using detailed morphological analysis. Similar observation has been presented Uchimoto al. for Japanese language. According to the tagging performed by SRRs the lexicon, a word receives if it beto If we consider multiple tags for a word as an error of the tagger (even when the options contain the correct tag for a word), then the accuracy of the tagger comes to be 73.62% (as shown in Table 1). The goal is to keep the contextually appropriate tag and eliminate others which can be achieved by devising a disambiguation technique. The disambiguation task can be naively addressed by choosing the most frequent tag for a word. This approach is also known as baseline (BL) tagging. The baseline accuracy turns out to be 82.63% which is still higher than that of the morphology-driven tag- The drawback with baseline tagging is that its accuracy cannot be further improved. On the other hand, there is enough room for improving upon the accuracy of morphology-driven (MD) tagger. It is quite evident that though the MD tagger works well for VG and many close categories, around 30% of the words are either ambiguous or unknown. Hence, a disambiguation stage is needed to shoot up the accuracy. The common choice for disambiguation rule learning in POS tagging task is usually machine learning techniques mainly focussing on decision tree based algorithms (Orphanos and Christodoulalds, 1999), neural networks 1994), Among the various decision tree based algorithms like ID3, AQR, ASSIS- TANT and CN2, CN2 is known to perform better than the rest (Clark and Niblett, 1989). Since no such machine learning technique has been used for Hindi language, we thought of choosing CN2 it performs well on noisy numbers may change if we experiment on a different dataset training annotated corpora becomes noisy by virtue of intuitions of different annotators (trained native Hindi speakers) 783 4.2.1 Training Corpora We set up a corpus, collecting sentences from news and let the morphology-driven tagger assign morphosyntactic tags to all the words. For an ambiguous word, the contextually appropriate POS tag is manually chosen. Unknown words are assigned a correct tag based on their context and usage. 4.2.2 Learning Out of the completely manually corrected corpora of 15,562 tokens, we created training infor each Scheme for Un- These training instances take into account the POS categories of the neighbouring and not the feature The experiments were carried out for different context window sizes ranging from 2 to 20 to find the best configuration. 4.2.3 Rule Generation The rules are generated from the training corpora by extracting the ambiguity scheme (AS) of each word. If the word is not present in the lexicon then its AS is set as ‘unknown’. Once the AS is identified, a training instance is formed. This training instance contains the neighbouring correct POS categories as attributes. The number of neighbours included in the training instance is the window size for CN2. After all the ambiguous words are processed and training instances for all seen ASs are created, the CN2 algorithm is applied over the training instances to generate actual rule-sets for each AS. The CN2 algogives one set of (either ordered or unordered) for each AS including ‘un- The AS of every ambiguous word is formed while tagging. A corresponding rule-set for that AS is then identified and traversed to get the contextually appropriate rule. The resultant that a tag encodes 0 to 6 morphosyntactic features and each feature takes either one or a disjunction of 2 to 7 values, the total number of different tags can count up to several hundreds used the CN2 algorithm implementation (1990) by Robin Boswell. The software is available at ftp://ftp.cs.utexas.edu/pub/pclark/cn2.tar.Z category outputted by this rule is then assigned to the ambiguous word. The traversal rule differs for ordered and unordered implementation. The POS of an unknown word is guessed by traversthe rule-set for unknown and assigning it the resultant tag. 5 Experimental Setup The experimentation involved, first, identifying the best parameter values for the CN2 algorithm and second, evaluating the performance of the disambiguation rules generated by CN2 for the POS tagging task. 5.1 CN2 Parameters The various parameters in CN2 algorithm are: rule type (ordered or unordered), star size, significance threshold and size of the training instances (window size). The best results are empirically achieved with ordered rules, star size as 1, significance threshold as 10 and window size two neighbours on either side are used to generate the training instances. 5.2 Evaluation The tests are performed on contiguous partitions of the corpora (15,562 words) that are 75% training set and 25% testing set. no. of single correct tags total no. of tokens The results are obtained by performing a 4fold cross validation over the corpora. Figure 2 gives the learning curve of the disambiguation module for varying corpora sizes starting from 1000 to the complete training corpora size. The accuracy for known and unknown words is also measured separately. 6 Results and Discussion The average accuracy of the learning based (LB) tagger after 4-fold cross validation is 93.45%. To of the unknown words are proper nouns, which cannot be stored in the lexicon extensively. So, it also helps 784 0 2000 4000 6000 8000 10000 12000 Number of Words in Training Corpus Figure 2: POS Learning Curve the best of our knowledge no comparable results have been reported so far for Hindi. From Table 1, we can see that the disambiguation module brings up the accuracy of simple lexicon lookup based approach by around 25% (LLBD). The overall average accuracy is also brought up by around 20% by augmenting the morphology-driven (MD) tagger by a disambiguation module; hence justifying our belief that a disambiguation module over a morphology driven approach yields better results. One interesting observation is the performance of the tagger on individual POS categories. Figure 3 shows clearly that the per POS accuracies of the LB tagger highly exceeds those of the MD and BL tagger for most categories. This means that the disambiguation module correctly disambiguates and correctly identifies the unknown words too. The accuracy on unknown words, as earlier shown in Figure 2, is very high at 92.08%. The percentage of unknown words in the test corpora is 0.013. It seems independent of the size of training corpus because the corpora is unbalanced having most of the unknowns as proper nouns. The rules are formed on this bias, and hence the application of these rules assigns PPN tag to an unknown which is mostly the case. From Figure 3 again we see that the accuracy on some categories remains very low even after disambiguation. This calls for some detailed failure analysis. By looking at the categories having low accuracy, such as pronoun, intensifier, demonstratives and verb copula, we find that all of them are highly ambiguous and, almost invariably, very rare in the corpus. Also, most of them are hard to disambiguate without any semantic information. 7 Conclusions &amp; Future Work We have described in this paper a POS tagger for Hindi which can overcome the handicap of annotated corpora scarcity by exploiting the rich morphology of the language and the relatively rigid word-order within a VG. The whole work was driven by hunting down the factors that lower the of weeding them out. A detailed study of accuracy distribution across the POS tags pointed out the cases calling for elaborate disambiguation rules. A major strength of the work is the learning of disambiguation rules, which otherwise would have been hand-coded, thus demanding exhaustive analysis of language phenomena. Attaining an accuracy of close to 94%, from a corpora of just about 15,562 words credence to the belief that can offset resource The work could lead such efforts of POS tag building for all those languages which have rich morphology, but cannot afford to invest a lot in creating large annotated corpora. Several interesting future directions suggest themselves. It will be worthwhile to investigate a statistical approach like Conditional Random Fields in which the feature functions would be constructed from morphology. The next logical step from the POS tagger is a chunker for Hindi. In fact a start on this has already been made through VG identification.</abstract>
<note confidence="0.9368155">References Ratnaparakhi. 1996. Maximum Entropy Part- Tagger. 1996 Bharati, V. Chaitanya, R. Sangal 1995.</note>
<title confidence="0.764678">Processing : A Paninian Perspective</title>
<address confidence="0.5400705">Prentice Hall India. Kuba, A. Hcza, J. Csirik 2004. Tagging of Hungarian with Combined Statistical and Rule- Methods. 2004</address>
<title confidence="0.791151666666667">Overall Accuracy Known Words Accuracy Unknown Words Accuracy</title>
<note confidence="0.822276657894737">Accuracy 94.5 94 93.5 93 92.5 92 91.5 91 90.5 90 785 Figure 3: Per-POS Accuracy Distribution 20 0 Accuracy 60 40 100 80 BL MD LB Megyesi. 1999. Brill’s POS tagger for agglutinative language. Sigdat Conference EMNLP/VLC 1999. D. Manning and H. Schutze. 2002. Statistical Natural Language Processing, Press 2002. Cutting et al. 1992. practical part-of-speech Proc. of the Third Conf. on Applied Natural Language Processing. ACL 1992. Brill. 1995. Error Driven Learning and Natural Language Processing: A Study in Part-of-Speech Tagging Computational Linguistics 21(94): 543-566. 1995. Black et al. 1992. tree models applied to labeling of text with parts-of-speech. Darpa Workshop on Speech and Natural Language 1992. Leech, R. Garside and M. Bryant. 1992. Auto- POS-Tagging of the BNC2 POStagging Manual. G. Orphanos, D. Kalles, A. Papagelis, D. 1999 trees and NLP: Case Study in POS In proceedings of ACAI 1999. Schmid 1994 Tagging with Neural In proceedings of COLING 1994. J. Hajic, P. Krbec, P. Kveton, K. Oliva, V. Petkevic Case Study in Czech Tagging. Proceedings of the 39th Annual Meeting of the ACL 2001 Uchimoto, S. Sekine, H. Isahara. 2001. Unknown Word Problem: a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Proceedings of the Conference on EMNLP 2001 Oflazer and I. Kuruoz. 1994. and mordisambiguation of Turkish text. Proceedings of the 4 ACL Conference on Applied Natural Language Processing Conference 1994 M. Shrivastava, N. Agrawal, S. Singh, P. Bhat- 2005. Morphological Analin POS Tagging Task. Proceedings of the ICON 2005 P. R. Ray , V. Harish, A. Basu and S. Sarkar 2003. Part of Speech Tagging and Local Word Grouping Techniques for Natural Language Parsing in In Proceedings of ICON 2003 Clark and T. Niblett 1989. CN2 Induction of Machine Learning, vol(3), pages 261-283, 1989 Garside, N. Smith 1997. hybrid grammatical CLAWS4 In R. Garside, G. Leech, A. McEnery (eds.) Corpus annotation: Linguistic information from computer text corpora. Longman. Pp. 102-121. Samuelsson and A. Voutilainen 1997. Compara Linguistic and a Stochastic Tagger. Procs. Joint 35th Annual Meeting of the ACL and 8th Conference of the European Chapter of the ACL 1997. Tlili-Guiassa 2006. Method for Tagging Journal of Computer Science 2 (3): 245-248, 2006 786</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Ratnaparakhi</author>
</authors>
<title>A Maximum Entropy PartOf-Speech Tagger.</title>
<date>1996</date>
<publisher>EMNLP</publisher>
<marker>Ratnaparakhi, 1996</marker>
<rawString>A. Ratnaparakhi. 1996. A Maximum Entropy PartOf-Speech Tagger. EMNLP 1996</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>V Chaitanya</author>
<author>R Sangal</author>
</authors>
<title>Natural Language Processing : A Paninian Perspective .</title>
<date>1995</date>
<publisher>Prentice Hall</publisher>
<contexts>
<context position="3435" citStr="Bharati et al. (1995)" startWordPosition="510" endWordPosition="513">ning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 2006. c�2006 Association for Computational Linguistics languages, since the former demands subtle linguistic expertise and the latter variously permuted corpora. 1.1 Previous Work on Hindi POS Tagging There is some amount of work done on morphology-based disambiguation in Hindi POS tagging. Bharati et al. (1995) in their work on computational Paninian parser, describe a technique where POS tagging is implicit and is merged with the parsing phase. Ray et al. (2003) proposed an algorithm that identifies Hindi word groups on the basis of the lexical tags of the individual words. Their partial POS tagger (as they call it) reduces the number of possible tags for a given sentence by imposing some constraints on the sequence of lexical categories that are possible in a Hindi sentence. UPENN also has an online Hindi morphological tagger&apos; but there exists no literature discussing the performance of the tagger</context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, 1995</marker>
<rawString>A. Bharati, V. Chaitanya, R. Sangal 1995. Natural Language Processing : A Paninian Perspective . Prentice Hall India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kuba</author>
<author>A Hcza</author>
<author>J Csirik</author>
</authors>
<date>2004</date>
<booktitle>POS Tagging of Hungarian with Combined Statistical and RuleBased Methods. TSD</booktitle>
<marker>Kuba, Hcza, Csirik, 2004</marker>
<rawString>A. Kuba, A. Hcza, J. Csirik 2004. POS Tagging of Hungarian with Combined Statistical and RuleBased Methods. TSD 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Megyesi</author>
</authors>
<title>Improving Brill’s POS tagger for an agglutinative language.</title>
<date>1999</date>
<booktitle>Joint Sigdat Conference EMNLP/VLC</booktitle>
<contexts>
<context position="2732" citStr="Megyesi, 1999" startWordPosition="403" endWordPosition="404">of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 2006. c�2006 Association for Computational Linguistics languages, since the former demands subtle linguistic expertise and the latter variously permuted corpora. 1.1 Previous Work on Hindi POS Tagging There is </context>
</contexts>
<marker>Megyesi, 1999</marker>
<rawString>B. Megyesi. 1999. Improving Brill’s POS tagger for an agglutinative language. Joint Sigdat Conference EMNLP/VLC 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schutze</author>
</authors>
<date>2002</date>
<booktitle>Foundations of Statistical Natural Language Processing,</booktitle>
<publisher>MIT Press</publisher>
<contexts>
<context position="1434" citStr="Manning and Schutze, 2002" startWordPosition="210" endWordPosition="213"> exhaustive morpohological analysis backed by high-coverage lexicon and a decision tree based learning algorithm (CN2). The evaluation of the system was done with 4-fold cross validation of the corpora in the news domain (www.bbc.co.uk/hindi). The current accuracy of POS tagging is 93.45% and can be further improved. 1 Motivation and Problem Definition Part-Of-Speech (POS) tagging is a complex task fraught with challenges like ambiguity of parts of speech and handling of “lexical absence” (proper nouns, foreign words, derivationally morphed words, spelling variations and other unknown words) (Manning and Schutze, 2002). For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), markov model (Cutting et al. 1992), maximum entropy methods (Ratnaparkhi, 1996) etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997). The accuracy of these taggers ranges from 93-98% approximately. English has annotated corpora in abundance, enabling usage of powerful data driven machine learning methods. But, very few languages in the w</context>
</contexts>
<marker>Manning, Schutze, 2002</marker>
<rawString>C. D. Manning and H. Schutze. 2002. Foundations of Statistical Natural Language Processing, MIT Press 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cutting</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proc. of the Third Conf. on Applied Natural Language Processing. ACL</booktitle>
<marker>Cutting, 1992</marker>
<rawString>D. Cutting et al. 1992. A practical part-of-speech tagger. In Proc. of the Third Conf. on Applied Natural Language Processing. ACL 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-Based Error Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging .</title>
<date>1995</date>
<journal>Computational Linguistics</journal>
<volume>21</volume>
<issue>94</issue>
<pages>543--566</pages>
<contexts>
<context position="1575" citStr="Brill, 1995" startWordPosition="230" endWordPosition="231">ne with 4-fold cross validation of the corpora in the news domain (www.bbc.co.uk/hindi). The current accuracy of POS tagging is 93.45% and can be further improved. 1 Motivation and Problem Definition Part-Of-Speech (POS) tagging is a complex task fraught with challenges like ambiguity of parts of speech and handling of “lexical absence” (proper nouns, foreign words, derivationally morphed words, spelling variations and other unknown words) (Manning and Schutze, 2002). For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), markov model (Cutting et al. 1992), maximum entropy methods (Ratnaparkhi, 1996) etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997). The accuracy of these taggers ranges from 93-98% approximately. English has annotated corpora in abundance, enabling usage of powerful data driven machine learning methods. But, very few languages in the world have the resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting </context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Transformation-Based Error Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging . Computational Linguistics 21(94): 543-566. 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Black</author>
</authors>
<title>Decision tree models applied to the labeling of text with parts-of-speech.</title>
<date>1992</date>
<booktitle>In Darpa Workshop on Speech and Natural Language</booktitle>
<marker>Black, 1992</marker>
<rawString>E. Black et al. 1992. Decision tree models applied to the labeling of text with parts-of-speech. In Darpa Workshop on Speech and Natural Language 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
<author>R Garside</author>
<author>M Bryant</author>
</authors>
<title>Automatic POS-Tagging of the corpus. BNC2 POStagging Manual.</title>
<date>1992</date>
<marker>Leech, Garside, Bryant, 1992</marker>
<rawString>G. Leech, R. Garside and M. Bryant. 1992. Automatic POS-Tagging of the corpus. BNC2 POStagging Manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Orphanos</author>
<author>D Kalles</author>
<author>A Papagelis</author>
<author>D Christodoulakis</author>
</authors>
<title>Decision trees and NLP: A Case Study in POS Tagging.</title>
<date>1999</date>
<booktitle>In proceedings of ACAI</booktitle>
<contexts>
<context position="2702" citStr="Orphanos et al., 1999" startWordPosition="396" endWordPosition="400">enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 2006. c�2006 Association for Computational Linguistics languages, since the former demands subtle linguistic expertise and the latter variously permuted corpora. 1.1 Previous Work </context>
<context position="8076" citStr="Orphanos et al. (1999)" startWordPosition="1312" endWordPosition="1316">onal suffix - {egaa} that attaches to the base verb ‘ ’ {jaa}. 2.1 Ambiguity Schemes The criterion to decide whether the tag of a word is a Noun or a Verb is entirely different from that of whether a word is an Adjective or an Adverb. For example, the word ‘ ’ can occur as conjunction, post-position or a noun (as shown previously), hence it falls in an Ambiguity Scheme ‘Conjunction-Noun-Postposition’. We grouped all the ambiguous words into sets according to the Ambiguity Schemes that are possible in Hindi, e.g., Adjective-Noun, Adjective-Adverb, NounVerb, etc. This idea was first proposed by Orphanos et al. (1999) for Modern Greek POS tagging. 3 Morphological Structure Of Hindi In Hindi, Nouns inflect for number and case. To capture their morphological variations, they can be categorized into various paradigms2 (Narayana, 1994) based on their vowel ending, gender, number and case information. We have a list of around 29,000 Hindi nouns that are categorized into such paradigms3. Looking at the morphological patterns of the words in a paradigm, suffix-replacement rules have been developed. These rules help in separating out a valid suffix 2A paradigm systematically arranges and identifies the uninflected</context>
</contexts>
<marker>Orphanos, Kalles, Papagelis, Christodoulakis, 1999</marker>
<rawString>G. Orphanos, D. Kalles, A. Papagelis, D. Christodoulakis. 1999 Decision trees and NLP: A Case Study in POS Tagging. In proceedings of ACAI 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Part-of-Speech Tagging with Neural Networks.</title>
<date>1994</date>
<booktitle>In proceedings of COLING</booktitle>
<contexts>
<context position="16372" citStr="Schmid, 1994" startWordPosition="2702" endWordPosition="2703">seline tagging is that its accuracy cannot be further improved. On the other hand, there is enough room for improving upon the accuracy of morphology-driven (MD) tagger. It is quite evident that though the MD tagger works well for VG and many close categories, around 30% of the words are either ambiguous or unknown. Hence, a disambiguation stage is needed to shoot up the accuracy. The common choice for disambiguation rule learning in POS tagging task is usually machine learning techniques mainly focussing on decision tree based algorithms (Orphanos and Christodoulalds, 1999), neural networks (Schmid, 1994), etc. Among the various decision tree based algorithms like ID3, AQR, ASSISTANT and CN2, CN2 is known to perform better than the rest (Clark and Niblett, 1989). Since no such machine learning technique has been used for Hindi language, we thought of choosing CN2 as it performs well on noisy data6. 5These numbers may change if we experiment on a different dataset 6The training annotated corpora becomes noisy by virtue of intuitions of different annotators (trained native Hindi speakers) 783 4.2.1 Training Corpora We set up a corpus, collecting sentences from BBC news site7 and let the morpholo</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid 1994 Part-of-Speech Tagging with Neural Networks. In proceedings of COLING 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>P Krbec</author>
<author>P Kveton</author>
<author>K Oliva</author>
<author>V</author>
</authors>
<title>Petkevic</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the ACL</booktitle>
<contexts>
<context position="2664" citStr="Hajic et al., 2001" startWordPosition="390" endWordPosition="393">he resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 2006. c�2006 Association for Computational Linguistics languages, since the former demands subtle linguistic expertise and the latter variousl</context>
</contexts>
<marker>Hajic, Krbec, Kveton, Oliva, V, 2001</marker>
<rawString>J. Hajic, P. Krbec, P. Kveton, K. Oliva, V. Petkevic 2001 A Case Study in Czech Tagging. In Proceedings of the 39th Annual Meeting of the ACL 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Uchimoto</author>
<author>S Sekine</author>
<author>H Isahara</author>
</authors>
<title>The Unknown Word Problem: a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference on EMNLP</booktitle>
<contexts>
<context position="15011" citStr="Uchimoto et al. (2001)" startWordPosition="2466" endWordPosition="2469">a verb. This results in a very high accuracy of 99.5% for verb auxiliaries. Ambiguity between a main verb and a copula verb remains unresolved at this level and asks for disambiguation rules. 4.2 Need for Disambiguation The accuracy obtained by simple lexicon lookup based approach (LLB) comes out to be 61.19%. The morphology-driven tagger, on the other hand, performs better than just lexicon lookup but still results in considerable ambiguity. These results are significant as they present a strong case in favor of using detailed morphological analysis. Similar observation has been presented by Uchimoto et al. (2001) for Japanese language. According to the tagging performed by SRRs and the lexicon, a word receives n tags if it belongs to n POSs. If we consider multiple tags for a word as an error of the tagger (even when the options contain the correct tag for a word), then the accuracy of the tagger comes to be 73.62% (as shown in Table 1). The goal is to keep the contextually appropriate tag and eliminate others which can be achieved by devising a disambiguation technique. The disambiguation task can be naively addressed by choosing the most frequent tag for a word. This approach is also known as baseli</context>
</contexts>
<marker>Uchimoto, Sekine, Isahara, 2001</marker>
<rawString>K. Uchimoto, S. Sekine, H. Isahara. 2001. The Unknown Word Problem: a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary. In Proceedings of the Conference on EMNLP 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>I Kuruoz</author>
</authors>
<title>Tagging and morphological disambiguation of Turkish text.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4 ACL Conference on Applied Natural Language Processing Conference</booktitle>
<contexts>
<context position="2612" citStr="Oflazer and Kuruoz, 1994" startWordPosition="382" endWordPosition="385">rning methods. But, very few languages in the world have the resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 2006. c�2006 Association for Computational Linguistics languages, since the former demands</context>
</contexts>
<marker>Oflazer, Kuruoz, 1994</marker>
<rawString>K. Oflazer and I. Kuruoz. 1994. Tagging and morphological disambiguation of Turkish text. In Proceedings of the 4 ACL Conference on Applied Natural Language Processing Conference 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shrivastava</author>
<author>N Agrawal</author>
<author>S Singh</author>
<author>P Bhattacharya</author>
</authors>
<title>Harnessing Morphological Analysis in POS Tagging Task.</title>
<date>2005</date>
<booktitle>In Proceedings of the ICON</booktitle>
<contexts>
<context position="6299" citStr="Shrivastava et al., 2005" startWordPosition="985" endWordPosition="988">s an ambiguity across POS categories. Such a word has multiple entries in the lexicon (one for each category). After stemming, the word would be assigned all possible POS tags based on the number of entries it has in the lexicon. The complexity of the task can be understood looking at the following English sentence where the word ‘back’ falls into three different POS categories“I get back to the back seat to give rest to my back.” The complexity further increases when it comes to tagging a free-word order language like Hindi where almost all the permutations of words in a clause are possible (Shrivastava et al., 2005). This phenomenon in the language, makes the task of a stochastic tagger difficult. Intra-POS ambiguity arises when a word has one POS with different feature values, e.g., the word ‘ ’ {laDke} (boys/boy) in Hindi is a noun but can be analyzed in two ways in terms of its feature values: 1. POS: Noun, Number: Sg, Case: Oblique . maine laDke ko ek aam diyaa. I-erg boy to one mango gave. I gave a mango to the boy. 2. POS: Noun, Number: Pl, Case: Direct . laDke aam khaate hain. Boys mangoes eat. Boys eat mangoes. 780 One of the difficult tasks here is to choose the appropriate tag based on the morp</context>
</contexts>
<marker>Shrivastava, Agrawal, Singh, Bhattacharya, 2005</marker>
<rawString>M. Shrivastava, N. Agrawal, S. Singh, P. Bhattacharya. 2005. Harnessing Morphological Analysis in POS Tagging Task. In Proceedings of the ICON 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Harish</author>
<author>A Basu</author>
<author>S Sarkar</author>
</authors>
<title>Part of Speech Tagging and Local Word Grouping Techniques for Natural Language Parsing in Hindi.</title>
<date>2003</date>
<booktitle>In Proceedings of ICON</booktitle>
<marker>Harish, Basu, Sarkar, 2003</marker>
<rawString>P. R. Ray , V. Harish, A. Basu and S. Sarkar 2003. Part of Speech Tagging and Local Word Grouping Techniques for Natural Language Parsing in Hindi. In Proceedings of ICON 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clark</author>
<author>T Niblett</author>
</authors>
<title>The CN2 Induction Algorithm.</title>
<date>1989</date>
<journal>Journal of Machine Learning,</journal>
<volume>3</volume>
<pages>261--283</pages>
<contexts>
<context position="4543" citStr="Clark and Niblett, 1989" startWordPosition="695" endWordPosition="698">so has an online Hindi morphological tagger&apos; but there exists no literature discussing the performance of the tagger. 1.2 Our Approach We present in this paper a POS tagger for Hindi- the national language of India, spoken by 500 million people and ranking 4th in the world. We establish a methodology of POS tagging which the resource disadvantaged (lacking annotated corpora) languages can make use of. This methodology uses locally annotated modestly sized corpora (15,562 words), exhaustive morphological analysis backed by highcoverage lexicon and a decision tree based learning algorithm- CN2 (Clark and Niblett, 1989). To the best of our knowledge, such an approach has never been tried out for Hindi. The heart of the system is the detailed linguistic analysis of morphosyntactic phenomena, adroit handling of suffixes, accurate verb group identification and learning of disambiguation rules. The approach can be used for other inflectional languages by providing the language specific resources in the form of suffix replacement rules (SRRs), lexicon, group identification and morpheme analysis rules etc. and keeping the 1http://ccat.sas.upenn.edu/plc/tamilweb/hindi.html processes the same as shown in Figure 1. T</context>
<context position="16532" citStr="Clark and Niblett, 1989" startWordPosition="2728" endWordPosition="2731">-driven (MD) tagger. It is quite evident that though the MD tagger works well for VG and many close categories, around 30% of the words are either ambiguous or unknown. Hence, a disambiguation stage is needed to shoot up the accuracy. The common choice for disambiguation rule learning in POS tagging task is usually machine learning techniques mainly focussing on decision tree based algorithms (Orphanos and Christodoulalds, 1999), neural networks (Schmid, 1994), etc. Among the various decision tree based algorithms like ID3, AQR, ASSISTANT and CN2, CN2 is known to perform better than the rest (Clark and Niblett, 1989). Since no such machine learning technique has been used for Hindi language, we thought of choosing CN2 as it performs well on noisy data6. 5These numbers may change if we experiment on a different dataset 6The training annotated corpora becomes noisy by virtue of intuitions of different annotators (trained native Hindi speakers) 783 4.2.1 Training Corpora We set up a corpus, collecting sentences from BBC news site7 and let the morphology-driven tagger assign morphosyntactic tags to all the words. For an ambiguous word, the contextually appropriate POS tag is manually chosen. Unknown words are</context>
</contexts>
<marker>Clark, Niblett, 1989</marker>
<rawString>P. Clark and T. Niblett 1989. The CN2 Induction Algorithm. Journal of Machine Learning, vol(3), pages 261-283, 1989</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
<author>N Smith</author>
</authors>
<title>A hybrid grammatical tagger: CLAWS4 .</title>
<date>1997</date>
<booktitle>Corpus annotation: Linguistic information from computer text corpora. Longman. Pp.</booktitle>
<pages>102--121</pages>
<editor>In R. Garside, G. Leech, A. McEnery (eds.)</editor>
<contexts>
<context position="1827" citStr="Garside and Smith, 1997" startWordPosition="267" endWordPosition="270">x task fraught with challenges like ambiguity of parts of speech and handling of “lexical absence” (proper nouns, foreign words, derivationally morphed words, spelling variations and other unknown words) (Manning and Schutze, 2002). For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), markov model (Cutting et al. 1992), maximum entropy methods (Ratnaparkhi, 1996) etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997). The accuracy of these taggers ranges from 93-98% approximately. English has annotated corpora in abundance, enabling usage of powerful data driven machine learning methods. But, very few languages in the world have the resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-co</context>
</contexts>
<marker>Garside, Smith, 1997</marker>
<rawString>R. Garside, N. Smith 1997. A hybrid grammatical tagger: CLAWS4 . In R. Garside, G. Leech, A. McEnery (eds.) Corpus annotation: Linguistic information from computer text corpora. Longman. Pp. 102-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
<author>A Voutilainen</author>
</authors>
<title>Comparing a Linguistic and a Stochastic Tagger.</title>
<date>1997</date>
<booktitle>In Procs. Joint 35th Annual Meeting of the ACL and 8th Conference of the European Chapter of the ACL</booktitle>
<contexts>
<context position="2524" citStr="Samuelsson and Voutilainen, 1997" startWordPosition="370" endWordPosition="373">. English has annotated corpora in abundance, enabling usage of powerful data driven machine learning methods. But, very few languages in the world have the resource advantage that English enjoys. In this scenario, POS tagging of highly inflectional languages presents an interesting case study. Morphologically rich languages are characterized by a large number of morphemes in a single word, where morpheme boundaries are difficult to detect because they are fused together. They are typically free-word ordered, which causes fixed-context systems to be hardly adequate for statistical approaches (Samuelsson and Voutilainen, 1997). Morphology-based POS tagging of some languages like Turkish (Oflazer and Kuruoz, 1994), Arabic (Guiassa, 2006), Czech (Hajic et al., 2001), Modern Greek (Orphanos et al., 1999) and Hungarian (Megyesi, 1999) has been tried out using a combination of hand-crafted rules and statistical learning. These systems use large amount of corpora along with morphological analysis to POS tag the texts. It may be noted that a purely rule-based or a purely stochastic approach will not be effective for such 779 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 779–786, Sydney, July 20</context>
</contexts>
<marker>Samuelsson, Voutilainen, 1997</marker>
<rawString>C. Samuelsson and A. Voutilainen 1997. Comparing a Linguistic and a Stochastic Tagger. In Procs. Joint 35th Annual Meeting of the ACL and 8th Conference of the European Chapter of the ACL 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tlili-Guiassa</author>
</authors>
<title>Hybrid Method for Tagging Arabic Text.</title>
<date>2006</date>
<journal>Journal of Computer Science</journal>
<volume>2</volume>
<issue>3</issue>
<pages>245--248</pages>
<marker>Tlili-Guiassa, 2006</marker>
<rawString>Y. Tlili-Guiassa 2006. Hybrid Method for Tagging Arabic Text. Journal of Computer Science 2 (3): 245-248, 2006</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>