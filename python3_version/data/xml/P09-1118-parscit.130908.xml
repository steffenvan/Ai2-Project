<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006658">
<title confidence="0.915919">
Word or Phrase?
Learning Which Unit to Stress for Information Retrieval*
</title>
<author confidence="0.936071">
Young-In Song† and Jung-Tae Lee‡ and Hae-Chang Rim‡†Microsoft Research Asia, Beijing, China
</author>
<affiliation confidence="0.941611">
‡Dept. of Computer &amp; Radio Communications Engineering, Korea University, Seoul, Korea
</affiliation>
<email confidence="0.994971">
yosong@microsoft.com†, {jtlee,rim}@nlp.korea.ac.kr‡
</email>
<sectionHeader confidence="0.99735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999894777777778">
The use of phrases in retrieval models has
been proven to be helpful in the literature,
but no particular research addresses the
problem of discriminating phrases that are
likely to degrade the retrieval performance
from the ones that do not. In this paper, we
present a retrieval framework that utilizes
both words and phrases flexibly, followed
by a general learning-to-rank method for
learning the potential contribution of a
phrase in retrieval. We also present use-
ful features that reflect the compositional-
ity and discriminative power of a phrase
and its constituent words for optimizing
the weights of phrase use in phrase-based
retrieval models. Experimental results on
the TREC collections show that our pro-
posed method is effective.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993379">
Various researches have improved the quality
of information retrieval by relaxing the tradi-
tional ‘bag-of-words’ assumption with the use of
phrases. (Miller et al., 1999; Song and Croft,
1999) explore the use n-grams in retrieval mod-
els. (Fagan, 1987; Gao et al., 2004; Met-
zler and Croft, 2005; Tao and Zhai, 2007) use
statistically-captured term dependencies within a
query. (Strzalkowski et al., 1994; Kraaij and
Pohlmann, 1998; Arampatzis et al., 2000) study
the utility of various kinds of syntactic phrases.
Although use of phrases clearly helps, there still
exists a fundamental but unsolved question: Do all
phrases contribute an equal amount of increase in
the performance of information retrieval models?
Let us consider a search query ‘World Bank Crit-
icism’, which has the following phrases: ‘world
*This work was done while Young-In Song was with the
Dept. of Computer &amp; Radio Communications Engineering,
Korea University.
bank’ and ‘bank criticism’. Intuitively, the for-
mer should be given more importance than its con-
stituents ‘world’ and ‘bank’, since the meaning
of the original phrase cannot be predicted from
the meaning of either constituent. In contrast, a
relatively less attention could be paid to the lat-
ter ‘bank criticism’, because there may be alter-
nate expressions, of which the meaning is still pre-
served, that could possibly occur in relevant docu-
ments. However, virtually all the researches ig-
nore the relation between a phrase and its con-
stituent words when combining both words and
phrases in a retrieval model.
Our approach to phrase-based retrieval is moti-
vated from the following linguistic intuitions: a)
phrases have relatively different degrees of signif-
icance, and b) the influence of a phrase should be
differentiated based on the phrase’s constituents in
retrieval models. In this paper, we start out by
presenting a simple language modeling-based re-
trieval model that utilizes both words and phrases
in ranking with use of parameters that differenti-
ate the relative contributions of phrases and words.
Moreover, we propose a general learning-to-rank
based framework to optimize the parameters of
phrases against their constituent words for re-
trieval models that utilize both words and phrases.
In order to estimate such parameters, we adapt the
use of a cost function together with a gradient de-
scent method that has been proven to be effective
for optimizing information retrieval models with
multiple parameters (Taylor et al., 2006; Metzler,
2007). We also propose a number of potentially
useful features that reflect not only the characteris-
tics of a phrase but also the information of its con-
stituent words for minimizing the cost function.
Our experimental results demonstrate that 1) dif-
ferentiating the weights of each phrase over words
yields statistically significant improvement in re-
trieval performance, 2) the gradient descent-based
parameter optimization is reasonably appropriate
</bodyText>
<page confidence="0.944201">
1048
</page>
<note confidence="0.999605">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 1048–1056,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999784111111111">
to our task, and 3) the proposed features can dis-
tinguish good phrases that make contributions to
the retrieval performance.
The rest of this paper is organized as follows.
The next section discusses previous work. Section
3 presents our learning-based retrieval framework
and features. Section 4 reports the evaluations of
our techniques. Section 5 finally concludes the pa-
per and discusses future work.
</bodyText>
<sectionHeader confidence="0.998463" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999985069767442">
To date, there have been numerous researches to
utilize phrases in retrieval models. One of the
most earliest work on phrase-based retrieval was
done by (Fagan, 1987). In (Fagan, 1987), the ef-
fectiveness of proximity-based phrases (i.e. words
occurring within a certain distance) in retrieval
was investigated with varying criteria to extract
phrases from text. Subsequently, various types
of phrases, such as sequential n-grams (Mitra et
al., 1997), head-modifier pairs extracted from syn-
tactic structures (Lewis and Croft, 1990; Zhai,
1997; Dillon and Gray, 1983; Strzalkowski et al.,
1994), proximity-based phrases (Turpin and Mof-
fat, 1999), were examined with conventional re-
trieval models (e.g. vector space model). The ben-
efit of using phrases for improving the retrieval
performance over simple ‘bag-of-words’ models
was far less than expected; the overall perfor-
mance improvement was only marginal and some-
times even inconsistent, specifically when a rea-
sonably good weighting scheme was used (Mitra
et al., 1997). Many researchers argued that this
was due to the use of improper retrieval models
in the experiments. In many cases, the early re-
searches on phrase-based retrieval have only fo-
cused on extracting phrases, not concerning about
how to devise a retrieval model that effectively
considers both words and phrases in ranking. For
example, the direct use of traditional vector space
model combining a phrase weight and a word
weight virtually yields the result assuming inde-
pendence between a phrase and its constituent
words (Srikanth and Srihari, 2003).
In order to complement the weakness, a number
of research efforts were devoted to the modeling
of dependencies between words directly within re-
trieval models instead of using phrases over the
years (van Rijsbergen, 1977; Wong et al., 1985;
Croft et al., 1991; Losee, 1994). Most stud-
ies were conducted on the probabilistic retrieval
framework, such as the BIM model, and aimed on
producing a better retrieval model by relaxing the
word independence assumption based on the co-
occurrence information of words in text. Although
those approaches theoretically explain the relation
between words and phrases in the retrieval con-
text, they also showed little or no improvements
in retrieval effectiveness, mainly because of their
statistical nature. While a phrase-based approach
selectively incorporated potentially-useful relation
between words, the probabilistic approaches force
to estimate parameters for all possible combina-
tions of words in text. This not only brings
parameter estimation problems but causes a re-
trieval system to fail by considering semantically-
meaningless dependency of words in matching.
Recently, a number of retrieval approaches have
been attempted to utilize a phrase in retrieval mod-
els. These approaches have focused to model sta-
tistical or syntactic phrasal relations under the lan-
guage modeling method for information retrieval.
(Srikanth and Srihari, 2003; Maisonnasse et al.,
2005) examined the effectiveness of syntactic re-
lations in a query by using language modeling
framework. (Song and Croft, 1999; Miller et al.,
1999; Gao et al., 2004; Metzler and Croft, 2005)
investigated the effectiveness of language model-
ing approach in modeling statistical phrases such
as n-grams or proximity-based phrases. Some of
them showed promising results in their experi-
ments by taking advantages of phrases soundly in
a retrieval model.
Although such approaches have made clear dis-
tinctions by integrating phrases and their con-
stituents effectively in retrieval models, they did
not concern the different contributions of phrases
over their constituents in retrieval performances.
Usually a phrase score (or probability) is simply
combined with scores of its constituent words by
using a uniform interpolation parameter, which
implies that a uniform contribution of phrases
over constituent words is assumed. Our study is
clearly distinguished from previous phrase-based
approaches; we differentiate the influence of each
phrase according to its constituent words, instead
of allowing equal influence for all phrases.
</bodyText>
<sectionHeader confidence="0.994938" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.995816666666667">
In this section, we present a phrase-based retrieval
framework that utilizes both words and phrases ef-
fectively in ranking.
</bodyText>
<page confidence="0.992609">
1049
</page>
<subsectionHeader confidence="0.998491">
3.1 Basic Phrase-based Retrieval Model
</subsectionHeader>
<bodyText confidence="0.998255142857143">
We start out by presenting a simple phrase-based
language modeling retrieval model that assumes
uniform contribution of words and phrases. For-
mally, the model ranks a document D according to
the probability of D generating phrases in a given
query Q, assuming that the phrases occur indepen-
dently:
</bodyText>
<equation confidence="0.9992595">
s(Q; D) = P(Q|D) Pz Y |Q |P(qi|qhi, D) (1)
i=1
</equation>
<bodyText confidence="0.997975">
where qi is the ith query word, qhi is the head word
of qi, and |Q |is the query size. To simplify the
mathematical derivations, we modify Eq. 1 using
logarithm as follows:
</bodyText>
<equation confidence="0.999191">
s(Q; D) a X |Q |log[P(qi|qhi, D)] (2)
i=1
</equation>
<bodyText confidence="0.9995595">
In practice, the phrase probability is mixed with
the word probability (i.e. deleted interpolation) as:
</bodyText>
<equation confidence="0.998986">
P(qi|qhi,D)PzAP(qi|qhi,D)+(1−A)P(qi|D) (3)
</equation>
<bodyText confidence="0.999756666666667">
where A is a parameter that controls the impact of
the phrase probability against the word probability
in the retrieval model.
</bodyText>
<subsectionHeader confidence="0.999962">
3.2 Adding Multiple Parameters
</subsectionHeader>
<bodyText confidence="0.99997005882353">
Given a phrase-based retrieval model that uti-
lizes both words and phrases, one would definitely
raise a fundamental question on how much weight
should be given to the phrase information com-
pared to the word information. In this paper, we
propose to differentiate the value of A in Eq. 3
according to the importance of each phrase by
adding multiple free parameters to the retrieval
model. Specifically, we replace A with well-
known logistic function, which allows both nu-
merical and categorical variables as input, whereas
the output is bounded to values between 0 and 1.
Formally, the input of a logistic function is a
set of evidences (i.e. feature vector) X generated
from a given phrase and its constituents, whereas
the output is the probability predicted by fitting X
to a logistic curve. Therefore, A is replaced as fol-
</bodyText>
<equation confidence="0.89972925">
lows:
1
A(X) =
1 + e_f(X) �α (4)
</equation>
<bodyText confidence="0.9979335">
where α is a scaling factor to confine the output to
values between 0 and α.
</bodyText>
<equation confidence="0.9911565">
f(X)=00+ X |X |Qixi (5)
i=1
</equation>
<bodyText confidence="0.999934">
where xi is the ith feature, Qi is the coefficient pa-
rameter of xi, and Q0 is the ‘intercept’, which is
the value of f(X) when all feature values are zero.
</bodyText>
<subsectionHeader confidence="0.999532">
3.3 RankNet-based Parameter Optimization
</subsectionHeader>
<bodyText confidence="0.9999901875">
The Q parameters in Eq. 5 are the ones we wish
to learn for resulting retrieval performance via pa-
rameter optimization methods. In many cases, pa-
rameters in a retrieval model are empirically de-
termined through a series of experiments or auto-
matically tuned via machine learning to maximize
a retrieval metric of choice (e.g. mean average
precision). The most simple but guaranteed way
would be to directly perform brute force search
for the global optimum over the entire parame-
ter space. However, not only the computational
cost of this so-called direct search would become
undoubtfully expensive as the number of parame-
ters increase, but most retrieval metrics are non-
smooth with respect to model parameters (Met-
zler, 2007). For these reasons, we propose to adapt
a learning-to-rank framework that optimizes mul-
tiple parameters of phrase-based retrieval models
effectively with less computation cost and without
any specific retrieval metric.
Specifically, we use a gradient descent method
with the RankNet cost function (Burges et al.,
2005) to perform effective parameter optimiza-
tions, as in (Taylor et al., 2006; Metzler, 2007).
The basic idea is to find a local minimum of a cost
function defined over pairwise document prefer-
ence. Assume that, given a query Q, there is
a set of document pairs RQ based on relevance
judgements, such that (D1, D2) E RQ implies
document D1 should be ranked higher than D2.
Given a defined set of pairwise preferences R, the
RankNet cost function is computed as:
</bodyText>
<equation confidence="0.986728">
C(Q, R) = X X log(1 + eY ) (6)
VQEQ V(D1,D2)EIZQ
</equation>
<bodyText confidence="0.9974916">
where Q is the set of queries, and Y = s(Q; D2)−
s(Q; D1) using the current parameter setting.
In order to minimize the cost function, we com-
pute gradients of Eq. 6 with respect to each pa-
rameter Qi by applying the chain rule:
</bodyText>
<equation confidence="0.958485357142857">
SY (7)
Sai
where ��
�Y and �Y
��i are computed as:
exp[s(Q; D2) − s(Q; D1)] (8)
1 + exp[s(Q; D2) − s(Q; D1)]
SC X= X SC
Sai VQEQ V(D1,D2)EIZQ SY
SC =
SY
1050
Js(Q; D1) (9)
Joi
</equation>
<bodyText confidence="0.965538">
With the retrieval model in Eq. 2 and A(X),
f(X) in Eq. 4 and 5, the partial derivate of
s(Q; D) with respect to Oi is computed as follows:
</bodyText>
<equation confidence="0.994350333333333">
xiλ(X)(1� λ�X�
α )�(P (qi|qhi,D)�P(qi|D)) (10)
λ(X)P(qi|qhi, D) + (1 - λ(X))P(qi  |D)
</equation>
<subsectionHeader confidence="0.656037">
3.4 Features
</subsectionHeader>
<bodyText confidence="0.99997675">
We experimented with various features that are
potentially useful for not only discriminating a
phrase itself but characterizing its constituents. In
this section, we report only the ones that have
made positive contributions to the overall retrieval
performance. The two main criteria considered
in the selection of the features are the followings:
compositionality and discriminative power.
</bodyText>
<sectionHeader confidence="0.543033" genericHeader="method">
Compositionality Features
</sectionHeader>
<bodyText confidence="0.998517692307692">
Features on phrase compositionality are designed
to measure how likely a phrase can be represented
as its constituent words without forming a phrase;
if a phrase in a query has very high composition-
ality, there is a high probability that its relevant
documents do not contain the phrase. In this case,
emphasizing the phrase unit could be very risky in
retrieval. In the opposite case that a phrase is un-
compositional, it is obvious that occurrence of a
phrase in a document can be a stronger evidence
of relevance than its constituent words.
Compositionality of a phrase can be roughly
measured by using corpus statistics or its linguis-
tic characteristics; we have observed that, in many
times, an extremely-uncompositional phrase ap-
pears as a noun phrase, and the distance between
its constituent words is generally fixed within a
short distance. In addition, it has a tendency to be
used repeatedly in a document because its seman-
tics cannot be represented with individual con-
stituent words. Based on these intuitions, we de-
vise the following features:
Ratio of multiple occurrences (RMO): This is a
real-valued feature that measures the ratio of the
phrase repeatedly used in a document. The value
of this feature is calculated as follows:
</bodyText>
<equation confidence="0.992999">
E
VD;count(wi—whi ,D)&gt;1 count(wi --+whi� D)
count(wi — whi� C) +&apos;y
</equation>
<bodyText confidence="0.999364125">
where wi —* whi is a phrase in a given query,
count(x, y) is the count of x in y, and -y is a small-
valued constant to prevent unreliable estimation
by very rarely-occurred phrases.
Ratio of single-occurrences (RSO): This is a bi-
nary feature that indicates whether or not a phrase
occurs once in most documents containing it. This
can be regarded as a supplementary feature of
RMO.
Preferred phrasal type (PPT): This feature indi-
cates the phrasal type that the phrase prefers in a
collection. We consider only two cases (whether
the phrase prefers verb phrase or adjective-noun
phrase types) as features in the experiments1.
Preferred distance (PD): This is a binary feature
indicating whether or not the phrase prefers long
distance (&gt; 1) between constituents in the docu-
ment collection.
Uncertainty ofpreferred distance (UPD): We also
use the entropy (H) of the modification distance
(d) of the given phrase in the collection to measure
the compositionality; if the distance is not fixed
and is highly uncertain, the phrase may be very
compositional. The entropy is computed as:
</bodyText>
<equation confidence="0.998068">
x = H(p(d = x|wi —* whi)) (12)
</equation>
<bodyText confidence="0.999951769230769">
where d E 1, 2, 3, long and all probabilities are
estimated with discount smoothing. We simply
use two binary features regarding the uncertainty
of distance; one indicates whether the uncertainty
of a phrase is very high (&gt; 0.85), and the other
indicates whether the uncertainty is very low (&lt;
0.05)2.
Uncertainty ofpreferred phrasal type (UPPT): As
similar to the uncertainty of preferred distance, the
uncertainty of the preferred phrasal type of the
phrase can be also used as a feature. We consider
this factor as a form of a binary feature indicating
whether the uncertainty is very high or not.
</bodyText>
<sectionHeader confidence="0.67005" genericHeader="method">
Discriminative Power Features
</sectionHeader>
<bodyText confidence="0.9268388125">
In some cases, the occurrence of a phrase can be a
valuable evidence even if the phrase is very likely
to be compositional. For example, it is well known
that the use of a phrase can be effective in retrieval
when its constituent words appear very frequently
in the collection, because each word would have a
very low discriminative power for relevance. On
the contrary, if a constituent word occurs very
1For other phrasal types, significant differences were not
observed in the experiments.
2Although it may be more natural to use a real-valued fea-
ture, we use these binary features because of the two practical
reasons; firstly, it could be very difficult to find an adequate
transformation function with real values, and secondly, the
two intervals at tails were observed to be more important than
the rest.
</bodyText>
<equation confidence="0.98691575">
JY Js(Q; D2)
=
Joi Joi
δs(Q;D) |Q|
=
δβi i=1
x =
(11)
</equation>
<page confidence="0.855557">
1051
</page>
<bodyText confidence="0.983548789473684">
rarely in the collection, it could not be effective
to use the phrase even if the phrase is highly un-
compositional. Similarly, if the probability that a
phrase occurs in a document where its constituent
words co-occur is very high, we might not need to
place more emphasis on the phrase than on words,
because co-occurrence information naturally in-
corporated in retrieval models may have enough
power to distinguish relevant documents. Based
on these intuitions, we define the following fea-
tures:
Document frequency of constituents (DF): We
use the document frequency of a constituent as
two binary features: one indicating whether the
word has very high document frequency (&gt;10%
of documents in a collection) and the other one
indicating whether it has very low document fre-
quency (&lt;0.2% of documents, which is approxi-
mately 1,000 in our experiments).
</bodyText>
<subsubsectionHeader confidence="0.900686">
Probability of constituents as phrase (CPP): This
</subsubsectionHeader>
<bodyText confidence="0.999973368421053">
feature is computed as a relative frequency of doc-
uments containing a phrase over documents where
two constituent words appear together.
One interesting fact that we observe is that doc-
ument frequency of the modifier is generally a
stronger evidence on the utility of a phrase in re-
trieval than of the headword. In the case of the
headword, we could not find an evidence that it
has to be considered in phrase weighting. It seems
to be a natural conclusion, because the importance
of the modifier word in retrieval is subordinate to
the relation to its headword, but the headword is
not in many phrases. For example, in the case of
the query ‘tropical storms’, retrieving a document
only containing tropical can be meaningless, but a
document about storm can be meaningful. Based
on this observation, we only incorporate document
frequency features of syntactic modifiers in the ex-
periments.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999955333333333">
In this section, we report the retrieval perfor-
mances of the proposed method with appropriate
baselines over a range of training sets.
</bodyText>
<subsectionHeader confidence="0.966524">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999192870370371">
Retrieval models: We have set two retrieval mod-
els, namely the word model and the (phrase-based)
oneparameter model, as baselines. The ranking
function of the word model is equivalent to Eq. 2,
with A in Eq. 3 being set to zero (i.e. the phrase
probability makes no effect on the ranking). The
ranking function of the one-parameter model is
also equivalent to Eq. 2, with A in Eq. 3 used “as
is” (i.e. as a constant parameter value optimized
using gradient descent method, without being re-
placed to a logistic function). Both baseline mod-
els cannot differentiate the importance of phrases
in a query. To make a distinction from the base-
line models, we will name our proposed method
as a multiparameter model.
In our experiments, all the probabilities in all
retrieval models are smoothed with the collection
statistics by using dirichlet priors (Zhai and Laf-
ferty, 2001).
Corpus (Training/Test): We have conducted
large-scale experiments on three sets of TREC’s
Ad Hoc Test Collections, namely TREC-6, TREC-
7, and TREC-8. Three query sets, TREC-6 top-
ics 301-350, TREC-7 topics 351-400, and TREC-
8 topics 401-450, along with their relevance judg-
ments have been used. We only used the title field
as query.
When performing experiments on each query
set with the one-parameter and the multi-
parameter models, the other two query sets have
been used for learning the optimal parameters. For
each query in the training set, we have generated
document pairs for training by the following strat-
egy: first, we have gathered top m ranked doc-
uments from retrieval results by using the word
model and the one-parameter model (by manually
setting A in Eq. 3 to the fixed constants, 0 and 0.1
respectively). Then, we have sampled at most r
relevant documents and n non-relevant documents
from each one and generated document pairs from
them. In our experiments, m, r, and n is set to
100, 10, and 40, respectively.
Phrase extraction and indexing: We evaluate
our proposed method on two different types of
phrases: syntactic head-modifier pairs (syntac-
tic phrases) and simple bigram phrases (statisti-
cal phrases). To index the syntactic phrases, we
use the method proposed in (Strzalkowski et al.,
1994) with Connexor FDG parser3, the syntactic
parser based on the functional dependency gram-
mar (Tapanainen and Jarvinen, 1997). All neces-
sary information for feature values were indexed
together for both syntactic and statistical phrases.
To maintain indexes in a manageable size, phrases
</bodyText>
<footnote confidence="0.994685">
3Connexor FDG parser is a commercial parser; the demo
is available at: http://www.connexor.com/demo
</footnote>
<page confidence="0.961082">
1052
</page>
<table confidence="0.995906333333334">
Test set &lt;-- Training set
6 &lt; --7+8 7 &lt; --6+8 8 &lt; --6+7
Model Metric \ Query all partial all partial all partial
Word MAP 0.2135 0.1433 0.1883 0.1876 0.2380 0.2576
(Baseline 1)
R-Prec 0.2575 0.1894 0.2351 0.2319 0.2828 0.2990
P@10 0.3660 0.3333 0.4100 0.4324 0.4520 0.4517
One-parameter MAP 0.2254 0.16331 0.1988 0.2031 0.2352 0.2528
(Baseline 2)
R-Prec 0.2738 0.2165 0.2503 0.2543 0.2833 0.2998
P@10 0.3820 0.3600 0.4540 0.4971 0.4580 0.4621
Multi-parameter MAP 0.2293$ 0.1697$ 0.20381 0.21051 0.2452 0.2701
(Proposed)
R-Prec 0.2773 0.2225 0.2534 0.2589 0.2891 0.3099
P@10 0.4020 0.3933 0.4540 0.4971 0.4700 0.4828
</table>
<tableCaption confidence="0.999679">
Table 1: Retrieval performance of different models on syntactic phrases. Italicized MAP values with
</tableCaption>
<bodyText confidence="0.8800608">
symbols 1 and $ indicate statistically significant improvements over the word model according to Stu-
dent’s t-test at p &lt; 0.05 level and p &lt; 0.01 level, respectively. Bold figures indicate the best performed
case for each metric.
that occurred less than 10 times in the document
collections were not indexed.
</bodyText>
<subsectionHeader confidence="0.980323">
4.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999794444444444">
Table 1 shows the experimental results of the three
retrieval models on the syntactic phrase (head-
modifier pair). In the table, partial denotes the
performance evaluated on queries containing more
than one phrase that appeared in the document col-
lection4; this shows the actual performance differ-
ence between models. Note that the ranking re-
sults of all retrieval models would be the same as
the result of the word model if a query does not
contain any phrases in the document collection,
because P(qj|qhi, D) would be calculated as zero
eventually. As evaluation measures, we used the
mean average precision (MAP), R-precision (R-
Prec), and precisions at top 10 ranks (P@10).
As shown in Table 1, when a syntactic phrase is
used for retrieval, one-parameter model trained by
gradient-descent method generally performs bet-
ter than the word model, but the benefits are in-
consistent; it achieves approximately 15% and 8%
improvements on the partial query set of TREC-
6 and 7 over the word model, but it fails to show
any improvement on TREC-8 queries. This may
be a natural result since the one-parameter model
is very sensitive to the averaged contribution of
phrases used for training. Compared to the queries
in TREC-6 and 7, the TREC-8 queries contain
more phrases that are not effective for retrieval
</bodyText>
<footnote confidence="0.8505885">
4The number of queries containing a phrase in TREC-6,
7, and 8 query set is 31, 34, and 29, respectively.
</footnote>
<bodyText confidence="0.999784121212121">
(i.e. ones that hurt the retrieval performance when
used). This indicates that without distinguishing
effective phrases from ineffective phrases for re-
trieval, the model trained from one training set for
phrase would not work consistently on other un-
seen query sets.
Note that the proposed model outperforms all
the baselines over all query sets; this shows that
differentiating relative contributions of phrases
can improve the retrieval performance of the one-
parameter model considerably and consistently.
As shown in the table, the multi-parameter model
improves by approximately 18% and 12% on the
TREC-6 and 7 partial query sets, and it also
significantly outperforms both the word model
and the one-parameter model on the TREC-8
query set. Specifically, the improvement on the
TREC-8 query set shows one advantage of using
our proposed method; by separating potentially-
ineffective phrases and effective phrases based on
the features, it not only improves the retrieval
performance for each query but makes parameter
learning less sensitive to the training set.
Figure 1 shows some examples demonstrating
the different behaviors of the one-parameter model
and the multi-parameters model. On the figure, the
un-dotted lines indicate the variation of average
precision scores when A value in Eq. 3 is manu-
ally set. As A gets closer to 0, the ranking formula
becomes equivalent to the word model.
As shown in the figure, the optimal point of A is
quiet different from query to query. For example,
in cases of the query ‘ferry sinking’ and industrial
</bodyText>
<page confidence="0.978603">
1053
</page>
<figure confidence="0.999189054545455">
Performance variation for the query ‘ferry sinking’
0 0.1 0.2 0.3 0.4 0.5
lambda
A
lambda
Performance variation for the query ‘industrial espionage’
0 0.1 0.2 0.3 0.4 0.5
lambda
Performance variation for the query ‘amazon rain forest’
varing lambda
one-parameter
multiple-parameter
0 0.1 0.2 0.3 0.4 0.5
lambda
varing lambda
one-parameter
multiple-parameter
varing lambda
one-parameter
multiple-parameter
0.39
0.38
0.37
0.36
0.35
0.34
0.33
0.32
Performance variation for the query ‘ declining birth rates’
varing lambda
one-parameter
multiple-parameter
0.7
0.65
0.6
0.55
0.5
0.45
0.4
0.35
0.65
0.6
0.55
0.5
0.45
0.4
0.35
0.3
0.45
0.4
0.35
0.3
0.25
0.2
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
</figure>
<figureCaption confidence="0.988338">
Figure 1: Performance variations for the queries ‘ferry sinking’, ‘industrial espionage’, ‘declining birth
rate’ and ‘Amazon rain forest’ according to A in Eq. 3.
</figureCaption>
<bodyText confidence="0.999588422222222">
espionage’ on the upper side, the optimal point is
the value close to 0 and 1 respectively. This means
that the occurrences of the phrase ‘ferry sinking’
in a document is better to be less-weighted in
retrieval while ‘industrial espionage’ should be
treated as a much more important evidence than its
constituent words. Obviously, such differences are
not good for one-parameter model assuming rela-
tive contributions of phrases uniformly. For both
opposite cases, the multi-parameter model signifi-
cantly outperforms one-parameter model.
The two examples at the bottom of Figure 1
show the difficulty of optimizing phrase-based re-
trieval using one uniform parameter. For example,
the query ‘declining birth rate’ contains two dif-
ferent phrases, ‘declining rate’ and ‘birth rate’,
which have potentially-different effectiveness in
retrieval; the phrase ‘declining rate’ would not
be helpful for retrieval because it is highly com-
positional, but the phrase ‘birth rate’ could be a
very strong evidence for relevance since it is con-
ventionally used as a phrase. In this case, we
can get only small benefit from the one-parameter
model even if we find optimal A from gradient
descent, because it will be just a compromised
value between two different, optimized As. For
such query, the multi-parameter model could be
more effective than the one-parameter model by
enabling to set different As on phrases accord-
ing to their predicted contributions. Note that the
multi-parameter model significantly outperforms
the one-parameter model and all manually-set As
for the queries ‘declining birth rate’ and ‘Amazon
rain forest’, which also has one effective phrase,
‘rain forest’, and one non-effective phrase, ‘Ama-
zon forest’.
Since our method is not limited to a particular
type of phrases, we have also conducted experi-
ments on statistical phrases (bigrams) with a re-
duced set of features directed applicable; RMO,
RSO, PD5, DF, and CPP; the features requiring
linguistic preprocessing (e.g. PPT) are not used,
because it is unrealistic to use them under bigram-
based retrieval setting. Moreover, the feature UPD
is not used in the experiments because the uncer-
</bodyText>
<footnote confidence="0.973348">
5In most cases, the distance between words in a bigram
is 1, but sometimes, it could be more than 1 because of the
effect of stopword removal.
</footnote>
<page confidence="0.92209">
1054
</page>
<table confidence="0.999844857142857">
Test &lt;-- Training
Model Metric 6&lt;-- 7+8 7&lt;-- 6+8 8&lt;-- 6+7
Word MAP 0.2135 0.1883 0.2380
(Baseline 1)
R-Prec 0.2575 0.2351 0.2828
P@10 0.3660 0.4100 0.4520
One-parameter MAP 0.2229 0.1979 0.2492†
(Baseline 2)
R-Prec 0.2716 0.2456 0.2959
P@10 0.3720 0.4500 0.4620
Multi-parameter MAP 0.2224 0.2025† 0.2499†
(Proposed)
R-Prec 0.2707 0.2457 0.2952
P@10 0.3780 0.4520 0.4600
</table>
<tableCaption confidence="0.999669">
Table 2: Retrieval performance of different models, using statistical phrases.
</tableCaption>
<bodyText confidence="0.999114617021277">
tainty of preferred distance does not vary much for
bigram phrases. The results are shown in Table 2.
The results of experiments using statistical
phrases show that multi-parameter model yields
additional performance improvement against
baselines in many cases, but the benefit is in-
significant and inconsistent. As shown in Table 2,
according to the MAP score, the multi-parameter
model outperforms the one-parameter model on
the TREC-7 and 8 query sets, but it performs
slightly worse on the TREC-6 query set.
We suspect that this is because of the lack
of features to distinguish an effective statistical
phrases from ineffective statistical phrase. In our
observation, the bigram phrases also show a very
similar behavior in retrieval; some of them are
very effective while others can deteriorate the per-
formance of retrieval models. However, in case
of using statistical phrases, the A computed by our
multi-parameter model would be often similar to
the one computed by the one-parameter model,
when there is no sufficient evidence to differen-
tiate a phrase. Moreover, the insufficient amount
of features may have caused the multi-parameter
model to overfit to the training set easily.
The small size of training corpus could be an an-
other reason. The number of queries we used for
training is less than 80 when removing a query not
containing a phrase, which is definitely not a suf-
ficient amount to learn optimal parameters. How-
ever, if we recall that the multi-parameter model
worked reasonably in the experiments using syn-
tactic phrases with the same training sets, the lack
of features would be a more important reason.
Although we have not mainly focused on fea-
tures in this paper, it would be strongly necessary
to find other useful features, not only for statistical
phrases, but also for syntactic phrases. For exam-
ple, statistics from query logs and the probability
of snippet containing a same phrase in a query is
clicked by user could be considered as useful fea-
tures. Also, the size of the training data (queries)
and the document collection may not be sufficient
enough to conclude the effectiveness of our pro-
posed method; our method should be examined in
a larger collection with more queries. Those will
be one of our future works.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999988090909091">
In this paper, we present a novel method to differ-
entiate impacts of phrases in retrieval according
to their relative contribution over the constituent
words. The contributions of this paper can be sum-
marized in three-fold: a) we proposed a general
framework to learn the potential contribution of
phrases in retrieval by “parameterizing” the fac-
tor interpolating the phrase weight and the word
weight on features and optimizing the parameters
using RankNet-based gradient descent algorithm,
b) we devised a set of potentially useful features
to distinguish effective and non-effective phrases,
and c) we showed that the proposed method can be
effective in terms of retrieval by conducting a se-
ries of experiments on the TREC test collections.
As mentioned earlier, the finding of additional
features, specifically for statistical phrases, would
be necessary. Moreover, for a thorough analysis
on the effect of our framework, additional experi-
ments on larger and more realistic collections (e.g.
the Web environment) would be required. These
will be our future work.
</bodyText>
<page confidence="0.990003">
1055
</page>
<sectionHeader confidence="0.998338" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999305516483517">
Avi Arampatzis, Theo P. van der Weide, Cornelis H. A.
Koster, and P. van Bommel. 2000. Linguistically-
motivated information retrieval. In Encyclopedia of
Library and Information Science.
Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier,
Matt Deeds, Nicole Hamilton, and Greg Hullender.
2005. Learning to rank using gradient descent. In
Proceedings of ICML ’05, pages 89–96.
W. Bruce Croft, Howard R. Turtle, and David D. Lewis.
1991. The use of phrases and structured queries in
information retrieval. In Proceedings of SIGIR ’91,
pages 32–45.
Martin Dillon and Ann S. Gray. 1983. Fasit: A
fully automatic syntactically based indexing system.
Journal of the American Society for Information Sci-
ence, 34(2):99–108.
Joel L. Fagan. 1987. Automatic phrase indexing for
document retrieval. In Proceedings of SIGIR ’87,
pages 91–101.
Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and Gui-
hong Cao. 2004. Dependence language model for
information retrieval. In Proceedings of SIGIR ’04,
pages 170–177.
Wessel Kraaij and Ren´ee Pohlmann. 1998. Comparing
the effect of syntactic vs. statistical phrase indexing
strategies for dutch. In Proceedings of ECDL ’98,
pages 605–617.
David D. Lewis and W. Bruce Croft. 1990. Term clus-
tering of syntactic phrases. In Proceedings of SIGIR
’90, pages 385–404.
Robert M. Losee, Jr. 1994. Term dependence: truncat-
ing the bahadur lazarsfeld expansion. Information
Processing and Management, 30(2):293–303.
Loic Maisonnasse, Gilles Serasset, and Jean-Pierre
Chevallet. 2005. Using syntactic dependency and
language model x-iota ir system for clips mono and
bilingual experiments in clef 2005. In Working
Notes for the CLEF 2005 Workshop.
Donald Metzler and W. Bruce Croft. 2005. A markov
random field model for term dependencies. In Pro-
ceedings of SIGIR ’05, pages 472–479.
Donald Metzler. 2007. Using gradient descent to opti-
mize language modeling smoothing parameters. In
Proceedings of SIGIR ’07, pages 687–688.
David R. H. Miller, Tim Leek, and Richard M.
Schwartz. 1999. A hidden markov model informa-
tion retrieval system. In Proceedings of SIGIR ’99,
pages 214–221.
Mandar Mitra, Chris Buckley, Amit Singhal, and Claire
Cardie. 1997. An analysis of statistical and syn-
tactic phrases. In Proceedings of RIAO ’97, pages
200–214.
Fei Song and W. Bruce Croft. 1999. A general lan-
guage model for information retrieval. In Proceed-
ings of CIKM ’99, pages 316–321.
Munirathnam Srikanth and Rohini Srihari. 2003. Ex-
ploiting syntactic structure of queries in a language
modeling approach to ir. In Proceedings of CIKM
’03, pages 476–483.
Tomek Strzalkowski, Jose Perez-Carballo, and Mihnea
Marinescu. 1994. Natural language information re-
trieval: Trec-3 report. In Proceedings of TREC-3,
pages 39–54.
Tao Tao and ChengXiang Zhai. 2007. An exploration
of proximity measures in information retrieval. In
Proceedings of SIGIR ’07, pages 295–302.
Pasi Tapanainen and Timo Jarvinen. 1997. A non-
projective dependency parser. In Proceedings of
ANLP ’97, pages 64–71.
Michael Taylor, Hugo Zaragoza, Nick Craswell,
Stephen Robertson, and Chris Burges. 2006. Opti-
misation methods for ranking functions with multi-
ple parameters. In Proceedings of CIKM ’06, pages
585–593.
Andrew Turpin and Alistair Moffat. 1999. Statisti-
cal phrases for vector-space information retrieval. In
Proceedings of SIGIR ’99, pages 309–310.
C. J. van Rijsbergen. 1977. A theoretical basis for the
use of co-occurrence data in information retrieval.
Journal of Documentation, 33(2):106–119.
S. K. M. Wong, Wojciech Ziarko, and Patrick C. N.
Wong. 1985. Generalized vector spaces model in
information retrieval. In Proceedings of SIGIR ’85,
pages 18–25.
Chengxiang Zhai and John Lafferty. 2001. A study
of smoothing methods for language models applied
to ad hoc information retrieval. In Proceedings of
SIGIR ’01, pages 334–342.
Chengxiang Zhai. 1997. Fast statistical parsing of
noun phrases for document indexing. In Proceed-
ings of ANLP ’97, pages 312–319.
</reference>
<page confidence="0.993185">
1056
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.277436">
<title confidence="0.9577515">Word or Phrase? Which Unit to Stress for Information</title>
<address confidence="0.4824555">Research Asia, Beijing, China of Computer &amp; Radio Communications Engineering, Korea University, Seoul, Korea</address>
<abstract confidence="0.996055789473684">The use of phrases in retrieval models has been proven to be helpful in the literature, but no particular research addresses the problem of discriminating phrases that are likely to degrade the retrieval performance from the ones that do not. In this paper, we present a retrieval framework that utilizes both words and phrases flexibly, followed by a general learning-to-rank method for learning the potential contribution of a phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Avi Arampatzis</author>
<author>Theo P van der Weide</author>
<author>Cornelis H A Koster</author>
<author>P van Bommel</author>
</authors>
<title>Linguisticallymotivated information retrieval.</title>
<date>2000</date>
<booktitle>In Encyclopedia of Library and Information Science.</booktitle>
<marker>Arampatzis, van der Weide, Koster, van Bommel, 2000</marker>
<rawString>Avi Arampatzis, Theo P. van der Weide, Cornelis H. A. Koster, and P. van Bommel. 2000. Linguisticallymotivated information retrieval. In Encyclopedia of Library and Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Burges</author>
<author>Tal Shaked</author>
<author>Erin Renshaw</author>
<author>Ari Lazier</author>
<author>Matt Deeds</author>
<author>Nicole Hamilton</author>
<author>Greg Hullender</author>
</authors>
<title>Learning to rank using gradient descent.</title>
<date>2005</date>
<booktitle>In Proceedings of ICML ’05,</booktitle>
<pages>89--96</pages>
<contexts>
<context position="11953" citStr="Burges et al., 2005" startWordPosition="1866" endWordPosition="1869">e search for the global optimum over the entire parameter space. However, not only the computational cost of this so-called direct search would become undoubtfully expensive as the number of parameters increase, but most retrieval metrics are nonsmooth with respect to model parameters (Metzler, 2007). For these reasons, we propose to adapt a learning-to-rank framework that optimizes multiple parameters of phrase-based retrieval models effectively with less computation cost and without any specific retrieval metric. Specifically, we use a gradient descent method with the RankNet cost function (Burges et al., 2005) to perform effective parameter optimizations, as in (Taylor et al., 2006; Metzler, 2007). The basic idea is to find a local minimum of a cost function defined over pairwise document preference. Assume that, given a query Q, there is a set of document pairs RQ based on relevance judgements, such that (D1, D2) E RQ implies document D1 should be ranked higher than D2. Given a defined set of pairwise preferences R, the RankNet cost function is computed as: C(Q, R) = X X log(1 + eY ) (6) VQEQ V(D1,D2)EIZQ where Q is the set of queries, and Y = s(Q; D2)− s(Q; D1) using the current parameter setting</context>
</contexts>
<marker>Burges, Shaked, Renshaw, Lazier, Deeds, Hamilton, Hullender, 2005</marker>
<rawString>Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to rank using gradient descent. In Proceedings of ICML ’05, pages 89–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Bruce Croft</author>
<author>Howard R Turtle</author>
<author>David D Lewis</author>
</authors>
<title>The use of phrases and structured queries in information retrieval.</title>
<date>1991</date>
<booktitle>In Proceedings of SIGIR ’91,</booktitle>
<pages>32--45</pages>
<contexts>
<context position="6419" citStr="Croft et al., 1991" startWordPosition="989" endWordPosition="992">acting phrases, not concerning about how to devise a retrieval model that effectively considers both words and phrases in ranking. For example, the direct use of traditional vector space model combining a phrase weight and a word weight virtually yields the result assuming independence between a phrase and its constituent words (Srikanth and Srihari, 2003). In order to complement the weakness, a number of research efforts were devoted to the modeling of dependencies between words directly within retrieval models instead of using phrases over the years (van Rijsbergen, 1977; Wong et al., 1985; Croft et al., 1991; Losee, 1994). Most studies were conducted on the probabilistic retrieval framework, such as the BIM model, and aimed on producing a better retrieval model by relaxing the word independence assumption based on the cooccurrence information of words in text. Although those approaches theoretically explain the relation between words and phrases in the retrieval context, they also showed little or no improvements in retrieval effectiveness, mainly because of their statistical nature. While a phrase-based approach selectively incorporated potentially-useful relation between words, the probabilisti</context>
</contexts>
<marker>Croft, Turtle, Lewis, 1991</marker>
<rawString>W. Bruce Croft, Howard R. Turtle, and David D. Lewis. 1991. The use of phrases and structured queries in information retrieval. In Proceedings of SIGIR ’91, pages 32–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Dillon</author>
<author>Ann S Gray</author>
</authors>
<title>Fasit: A fully automatic syntactically based indexing system.</title>
<date>1983</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="5153" citStr="Dillon and Gray, 1983" startWordPosition="789" endWordPosition="792">des the paper and discusses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In many cases, the early researches on </context>
</contexts>
<marker>Dillon, Gray, 1983</marker>
<rawString>Martin Dillon and Ann S. Gray. 1983. Fasit: A fully automatic syntactically based indexing system. Journal of the American Society for Information Science, 34(2):99–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel L Fagan</author>
</authors>
<title>Automatic phrase indexing for document retrieval.</title>
<date>1987</date>
<booktitle>In Proceedings of SIGIR ’87,</booktitle>
<pages>91--101</pages>
<contexts>
<context position="1320" citStr="Fagan, 1987" startWordPosition="193" endWordPosition="194">the potential contribution of a phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song w</context>
<context position="4755" citStr="Fagan, 1987" startWordPosition="733" endWordPosition="734">09. c�2009 ACL and AFNLP to our task, and 3) the proposed features can distinguish good phrases that make contributions to the retrieval performance. The rest of this paper is organized as follows. The next section discusses previous work. Section 3 presents our learning-based retrieval framework and features. Section 4 reports the evaluations of our techniques. Section 5 finally concludes the paper and discusses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving th</context>
</contexts>
<marker>Fagan, 1987</marker>
<rawString>Joel L. Fagan. 1987. Automatic phrase indexing for document retrieval. In Proceedings of SIGIR ’87, pages 91–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Jian-Yun Nie</author>
<author>Guangyuan Wu</author>
<author>Guihong Cao</author>
</authors>
<title>Dependence language model for information retrieval.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGIR ’04,</booktitle>
<pages>170--177</pages>
<contexts>
<context position="1338" citStr="Gao et al., 2004" startWordPosition="195" endWordPosition="198"> contribution of a phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song was with the Dept. </context>
<context position="7732" citStr="Gao et al., 2004" startWordPosition="1185" endWordPosition="1188">t only brings parameter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval models, they did not concern the different contributions of phrases over their constituents in retrieval performances. Usually a phrase score (or probability) is simply combined with scores </context>
</contexts>
<marker>Gao, Nie, Wu, Cao, 2004</marker>
<rawString>Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and Guihong Cao. 2004. Dependence language model for information retrieval. In Proceedings of SIGIR ’04, pages 170–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wessel Kraaij</author>
<author>Ren´ee Pohlmann</author>
</authors>
<title>Comparing the effect of syntactic vs. statistical phrase indexing strategies for dutch.</title>
<date>1998</date>
<booktitle>In Proceedings of ECDL ’98,</booktitle>
<pages>605--617</pages>
<contexts>
<context position="1499" citStr="Kraaij and Pohlmann, 1998" startWordPosition="219" endWordPosition="222">onstituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song was with the Dept. of Computer &amp; Radio Communications Engineering, Korea University. bank’ and ‘bank criticism’. Intuitively, the former should be given more importance than its co</context>
</contexts>
<marker>Kraaij, Pohlmann, 1998</marker>
<rawString>Wessel Kraaij and Ren´ee Pohlmann. 1998. Comparing the effect of syntactic vs. statistical phrase indexing strategies for dutch. In Proceedings of ECDL ’98, pages 605–617.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>W Bruce Croft</author>
</authors>
<title>Term clustering of syntactic phrases.</title>
<date>1990</date>
<booktitle>In Proceedings of SIGIR ’90,</booktitle>
<pages>385--404</pages>
<contexts>
<context position="5118" citStr="Lewis and Croft, 1990" startWordPosition="783" endWordPosition="786">echniques. Section 5 finally concludes the paper and discusses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In m</context>
</contexts>
<marker>Lewis, Croft, 1990</marker>
<rawString>David D. Lewis and W. Bruce Croft. 1990. Term clustering of syntactic phrases. In Proceedings of SIGIR ’90, pages 385–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Losee</author>
</authors>
<title>Term dependence: truncating the bahadur lazarsfeld expansion.</title>
<date>1994</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="6433" citStr="Losee, 1994" startWordPosition="993" endWordPosition="994">concerning about how to devise a retrieval model that effectively considers both words and phrases in ranking. For example, the direct use of traditional vector space model combining a phrase weight and a word weight virtually yields the result assuming independence between a phrase and its constituent words (Srikanth and Srihari, 2003). In order to complement the weakness, a number of research efforts were devoted to the modeling of dependencies between words directly within retrieval models instead of using phrases over the years (van Rijsbergen, 1977; Wong et al., 1985; Croft et al., 1991; Losee, 1994). Most studies were conducted on the probabilistic retrieval framework, such as the BIM model, and aimed on producing a better retrieval model by relaxing the word independence assumption based on the cooccurrence information of words in text. Although those approaches theoretically explain the relation between words and phrases in the retrieval context, they also showed little or no improvements in retrieval effectiveness, mainly because of their statistical nature. While a phrase-based approach selectively incorporated potentially-useful relation between words, the probabilistic approaches f</context>
</contexts>
<marker>Losee, 1994</marker>
<rawString>Robert M. Losee, Jr. 1994. Term dependence: truncating the bahadur lazarsfeld expansion. Information Processing and Management, 30(2):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Maisonnasse</author>
<author>Gilles Serasset</author>
<author>Jean-Pierre Chevallet</author>
</authors>
<title>Using syntactic dependency and language model x-iota ir system for clips mono and bilingual experiments in clef</title>
<date>2005</date>
<booktitle>In Working Notes for the CLEF 2005 Workshop.</booktitle>
<contexts>
<context position="7572" citStr="Maisonnasse et al., 2005" startWordPosition="1158" endWordPosition="1161">incorporated potentially-useful relation between words, the probabilistic approaches force to estimate parameters for all possible combinations of words in text. This not only brings parameter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval models, they did not concern t</context>
</contexts>
<marker>Maisonnasse, Serasset, Chevallet, 2005</marker>
<rawString>Loic Maisonnasse, Gilles Serasset, and Jean-Pierre Chevallet. 2005. Using syntactic dependency and language model x-iota ir system for clips mono and bilingual experiments in clef 2005. In Working Notes for the CLEF 2005 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>W Bruce Croft</author>
</authors>
<title>A markov random field model for term dependencies.</title>
<date>2005</date>
<booktitle>In Proceedings of SIGIR ’05,</booktitle>
<pages>472--479</pages>
<contexts>
<context position="1363" citStr="Metzler and Croft, 2005" startWordPosition="199" endWordPosition="203"> phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song was with the Dept. of Computer &amp; Radio Commu</context>
<context position="7758" citStr="Metzler and Croft, 2005" startWordPosition="1189" endWordPosition="1192">meter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval models, they did not concern the different contributions of phrases over their constituents in retrieval performances. Usually a phrase score (or probability) is simply combined with scores of its constituent words b</context>
</contexts>
<marker>Metzler, Croft, 2005</marker>
<rawString>Donald Metzler and W. Bruce Croft. 2005. A markov random field model for term dependencies. In Proceedings of SIGIR ’05, pages 472–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
</authors>
<title>Using gradient descent to optimize language modeling smoothing parameters.</title>
<date>2007</date>
<booktitle>In Proceedings of SIGIR ’07,</booktitle>
<pages>687--688</pages>
<contexts>
<context position="3561" citStr="Metzler, 2007" startWordPosition="547" endWordPosition="548">ling-based retrieval model that utilizes both words and phrases in ranking with use of parameters that differentiate the relative contributions of phrases and words. Moreover, we propose a general learning-to-rank based framework to optimize the parameters of phrases against their constituent words for retrieval models that utilize both words and phrases. In order to estimate such parameters, we adapt the use of a cost function together with a gradient descent method that has been proven to be effective for optimizing information retrieval models with multiple parameters (Taylor et al., 2006; Metzler, 2007). We also propose a number of potentially useful features that reflect not only the characteristics of a phrase but also the information of its constituent words for minimizing the cost function. Our experimental results demonstrate that 1) differentiating the weights of each phrase over words yields statistically significant improvement in retrieval performance, 2) the gradient descent-based parameter optimization is reasonably appropriate 1048 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 1048–1056, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and</context>
<context position="11634" citStr="Metzler, 2007" startWordPosition="1821" endWordPosition="1823">ization methods. In many cases, parameters in a retrieval model are empirically determined through a series of experiments or automatically tuned via machine learning to maximize a retrieval metric of choice (e.g. mean average precision). The most simple but guaranteed way would be to directly perform brute force search for the global optimum over the entire parameter space. However, not only the computational cost of this so-called direct search would become undoubtfully expensive as the number of parameters increase, but most retrieval metrics are nonsmooth with respect to model parameters (Metzler, 2007). For these reasons, we propose to adapt a learning-to-rank framework that optimizes multiple parameters of phrase-based retrieval models effectively with less computation cost and without any specific retrieval metric. Specifically, we use a gradient descent method with the RankNet cost function (Burges et al., 2005) to perform effective parameter optimizations, as in (Taylor et al., 2006; Metzler, 2007). The basic idea is to find a local minimum of a cost function defined over pairwise document preference. Assume that, given a query Q, there is a set of document pairs RQ based on relevance j</context>
</contexts>
<marker>Metzler, 2007</marker>
<rawString>Donald Metzler. 2007. Using gradient descent to optimize language modeling smoothing parameters. In Proceedings of SIGIR ’07, pages 687–688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R H Miller</author>
<author>Tim Leek</author>
<author>Richard M Schwartz</author>
</authors>
<title>A hidden markov model information retrieval system.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGIR ’99,</booktitle>
<pages>214--221</pages>
<contexts>
<context position="1239" citStr="Miller et al., 1999" startWordPosition="177" endWordPosition="180">h words and phrases flexibly, followed by a general learning-to-rank method for learning the potential contribution of a phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, </context>
<context position="7714" citStr="Miller et al., 1999" startWordPosition="1181" endWordPosition="1184">ords in text. This not only brings parameter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval models, they did not concern the different contributions of phrases over their constituents in retrieval performances. Usually a phrase score (or probability) is simply com</context>
</contexts>
<marker>Miller, Leek, Schwartz, 1999</marker>
<rawString>David R. H. Miller, Tim Leek, and Richard M. Schwartz. 1999. A hidden markov model information retrieval system. In Proceedings of SIGIR ’99, pages 214–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mandar Mitra</author>
<author>Chris Buckley</author>
<author>Amit Singhal</author>
<author>Claire Cardie</author>
</authors>
<title>An analysis of statistical and syntactic phrases.</title>
<date>1997</date>
<booktitle>In Proceedings of RIAO ’97,</booktitle>
<pages>200--214</pages>
<contexts>
<context position="5038" citStr="Mitra et al., 1997" startWordPosition="772" endWordPosition="775">d retrieval framework and features. Section 4 reports the evaluations of our techniques. Section 5 finally concludes the paper and discusses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued th</context>
</contexts>
<marker>Mitra, Buckley, Singhal, Cardie, 1997</marker>
<rawString>Mandar Mitra, Chris Buckley, Amit Singhal, and Claire Cardie. 1997. An analysis of statistical and syntactic phrases. In Proceedings of RIAO ’97, pages 200–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Song</author>
<author>W Bruce Croft</author>
</authors>
<title>A general language model for information retrieval.</title>
<date>1999</date>
<booktitle>In Proceedings of CIKM ’99,</booktitle>
<pages>316--321</pages>
<contexts>
<context position="1262" citStr="Song and Croft, 1999" startWordPosition="181" endWordPosition="184">lexibly, followed by a general learning-to-rank method for learning the potential contribution of a phrase in retrieval. We also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following</context>
<context position="7693" citStr="Song and Croft, 1999" startWordPosition="1177" endWordPosition="1180">ible combinations of words in text. This not only brings parameter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval models, they did not concern the different contributions of phrases over their constituents in retrieval performances. Usually a phrase score (or proba</context>
</contexts>
<marker>Song, Croft, 1999</marker>
<rawString>Fei Song and W. Bruce Croft. 1999. A general language model for information retrieval. In Proceedings of CIKM ’99, pages 316–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Munirathnam Srikanth</author>
<author>Rohini Srihari</author>
</authors>
<title>Exploiting syntactic structure of queries in a language modeling approach to ir.</title>
<date>2003</date>
<booktitle>In Proceedings of CIKM ’03,</booktitle>
<pages>476--483</pages>
<contexts>
<context position="6159" citStr="Srikanth and Srihari, 2003" startWordPosition="946" endWordPosition="949">ifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In many cases, the early researches on phrase-based retrieval have only focused on extracting phrases, not concerning about how to devise a retrieval model that effectively considers both words and phrases in ranking. For example, the direct use of traditional vector space model combining a phrase weight and a word weight virtually yields the result assuming independence between a phrase and its constituent words (Srikanth and Srihari, 2003). In order to complement the weakness, a number of research efforts were devoted to the modeling of dependencies between words directly within retrieval models instead of using phrases over the years (van Rijsbergen, 1977; Wong et al., 1985; Croft et al., 1991; Losee, 1994). Most studies were conducted on the probabilistic retrieval framework, such as the BIM model, and aimed on producing a better retrieval model by relaxing the word independence assumption based on the cooccurrence information of words in text. Although those approaches theoretically explain the relation between words and phr</context>
<context position="7545" citStr="Srikanth and Srihari, 2003" startWordPosition="1154" endWordPosition="1157">-based approach selectively incorporated potentially-useful relation between words, the probabilistic approaches force to estimate parameters for all possible combinations of words in text. This not only brings parameter estimation problems but causes a retrieval system to fail by considering semanticallymeaningless dependency of words in matching. Recently, a number of retrieval approaches have been attempted to utilize a phrase in retrieval models. These approaches have focused to model statistical or syntactic phrasal relations under the language modeling method for information retrieval. (Srikanth and Srihari, 2003; Maisonnasse et al., 2005) examined the effectiveness of syntactic relations in a query by using language modeling framework. (Song and Croft, 1999; Miller et al., 1999; Gao et al., 2004; Metzler and Croft, 2005) investigated the effectiveness of language modeling approach in modeling statistical phrases such as n-grams or proximity-based phrases. Some of them showed promising results in their experiments by taking advantages of phrases soundly in a retrieval model. Although such approaches have made clear distinctions by integrating phrases and their constituents effectively in retrieval mod</context>
</contexts>
<marker>Srikanth, Srihari, 2003</marker>
<rawString>Munirathnam Srikanth and Rohini Srihari. 2003. Exploiting syntactic structure of queries in a language modeling approach to ir. In Proceedings of CIKM ’03, pages 476–483.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Jose Perez-Carballo</author>
<author>Mihnea Marinescu</author>
</authors>
<title>Natural language information retrieval: Trec-3 report.</title>
<date>1994</date>
<booktitle>In Proceedings of TREC-3,</booktitle>
<pages>39--54</pages>
<contexts>
<context position="1472" citStr="Strzalkowski et al., 1994" startWordPosition="215" endWordPosition="218">power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song was with the Dept. of Computer &amp; Radio Communications Engineering, Korea University. bank’ and ‘bank criticism’. Intuitively, the former should be given </context>
<context position="5181" citStr="Strzalkowski et al., 1994" startWordPosition="793" endWordPosition="796">sses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In many cases, the early researches on phrase-based retrieval have </context>
<context position="21597" citStr="Strzalkowski et al., 1994" startWordPosition="3495" endWordPosition="3498">y using the word model and the one-parameter model (by manually setting A in Eq. 3 to the fixed constants, 0 and 0.1 respectively). Then, we have sampled at most r relevant documents and n non-relevant documents from each one and generated document pairs from them. In our experiments, m, r, and n is set to 100, 10, and 40, respectively. Phrase extraction and indexing: We evaluate our proposed method on two different types of phrases: syntactic head-modifier pairs (syntactic phrases) and simple bigram phrases (statistical phrases). To index the syntactic phrases, we use the method proposed in (Strzalkowski et al., 1994) with Connexor FDG parser3, the syntactic parser based on the functional dependency grammar (Tapanainen and Jarvinen, 1997). All necessary information for feature values were indexed together for both syntactic and statistical phrases. To maintain indexes in a manageable size, phrases 3Connexor FDG parser is a commercial parser; the demo is available at: http://www.connexor.com/demo 1052 Test set &lt;-- Training set 6 &lt; --7+8 7 &lt; --6+8 8 &lt; --6+7 Model Metric \ Query all partial all partial all partial Word MAP 0.2135 0.1433 0.1883 0.1876 0.2380 0.2576 (Baseline 1) R-Prec 0.2575 0.1894 0.2351 0.23</context>
</contexts>
<marker>Strzalkowski, Perez-Carballo, Marinescu, 1994</marker>
<rawString>Tomek Strzalkowski, Jose Perez-Carballo, and Mihnea Marinescu. 1994. Natural language information retrieval: Trec-3 report. In Proceedings of TREC-3, pages 39–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>ChengXiang Zhai</author>
</authors>
<title>An exploration of proximity measures in information retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings of SIGIR ’07,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="1384" citStr="Tao and Zhai, 2007" startWordPosition="204" endWordPosition="207">also present useful features that reflect the compositionality and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models. Experimental results on the TREC collections show that our proposed method is effective. 1 Introduction Various researches have improved the quality of information retrieval by relaxing the traditional ‘bag-of-words’ assumption with the use of phrases. (Miller et al., 1999; Song and Croft, 1999) explore the use n-grams in retrieval models. (Fagan, 1987; Gao et al., 2004; Metzler and Croft, 2005; Tao and Zhai, 2007) use statistically-captured term dependencies within a query. (Strzalkowski et al., 1994; Kraaij and Pohlmann, 1998; Arampatzis et al., 2000) study the utility of various kinds of syntactic phrases. Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models? Let us consider a search query ‘World Bank Criticism’, which has the following phrases: ‘world *This work was done while Young-In Song was with the Dept. of Computer &amp; Radio Communications Engineering</context>
</contexts>
<marker>Tao, Zhai, 2007</marker>
<rawString>Tao Tao and ChengXiang Zhai. 2007. An exploration of proximity measures in information retrieval. In Proceedings of SIGIR ’07, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pasi Tapanainen</author>
<author>Timo Jarvinen</author>
</authors>
<title>A nonprojective dependency parser.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP ’97,</booktitle>
<pages>64--71</pages>
<contexts>
<context position="21720" citStr="Tapanainen and Jarvinen, 1997" startWordPosition="3513" endWordPosition="3516">spectively). Then, we have sampled at most r relevant documents and n non-relevant documents from each one and generated document pairs from them. In our experiments, m, r, and n is set to 100, 10, and 40, respectively. Phrase extraction and indexing: We evaluate our proposed method on two different types of phrases: syntactic head-modifier pairs (syntactic phrases) and simple bigram phrases (statistical phrases). To index the syntactic phrases, we use the method proposed in (Strzalkowski et al., 1994) with Connexor FDG parser3, the syntactic parser based on the functional dependency grammar (Tapanainen and Jarvinen, 1997). All necessary information for feature values were indexed together for both syntactic and statistical phrases. To maintain indexes in a manageable size, phrases 3Connexor FDG parser is a commercial parser; the demo is available at: http://www.connexor.com/demo 1052 Test set &lt;-- Training set 6 &lt; --7+8 7 &lt; --6+8 8 &lt; --6+7 Model Metric \ Query all partial all partial all partial Word MAP 0.2135 0.1433 0.1883 0.1876 0.2380 0.2576 (Baseline 1) R-Prec 0.2575 0.1894 0.2351 0.2319 0.2828 0.2990 P@10 0.3660 0.3333 0.4100 0.4324 0.4520 0.4517 One-parameter MAP 0.2254 0.16331 0.1988 0.2031 0.2352 0.252</context>
</contexts>
<marker>Tapanainen, Jarvinen, 1997</marker>
<rawString>Pasi Tapanainen and Timo Jarvinen. 1997. A nonprojective dependency parser. In Proceedings of ANLP ’97, pages 64–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Taylor</author>
<author>Hugo Zaragoza</author>
<author>Nick Craswell</author>
<author>Stephen Robertson</author>
<author>Chris Burges</author>
</authors>
<title>Optimisation methods for ranking functions with multiple parameters.</title>
<date>2006</date>
<booktitle>In Proceedings of CIKM ’06,</booktitle>
<pages>585--593</pages>
<contexts>
<context position="3545" citStr="Taylor et al., 2006" startWordPosition="543" endWordPosition="546"> simple language modeling-based retrieval model that utilizes both words and phrases in ranking with use of parameters that differentiate the relative contributions of phrases and words. Moreover, we propose a general learning-to-rank based framework to optimize the parameters of phrases against their constituent words for retrieval models that utilize both words and phrases. In order to estimate such parameters, we adapt the use of a cost function together with a gradient descent method that has been proven to be effective for optimizing information retrieval models with multiple parameters (Taylor et al., 2006; Metzler, 2007). We also propose a number of potentially useful features that reflect not only the characteristics of a phrase but also the information of its constituent words for minimizing the cost function. Our experimental results demonstrate that 1) differentiating the weights of each phrase over words yields statistically significant improvement in retrieval performance, 2) the gradient descent-based parameter optimization is reasonably appropriate 1048 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 1048–1056, Suntec, Singapore, 2-7 August 2009</context>
<context position="12026" citStr="Taylor et al., 2006" startWordPosition="1878" endWordPosition="1881">not only the computational cost of this so-called direct search would become undoubtfully expensive as the number of parameters increase, but most retrieval metrics are nonsmooth with respect to model parameters (Metzler, 2007). For these reasons, we propose to adapt a learning-to-rank framework that optimizes multiple parameters of phrase-based retrieval models effectively with less computation cost and without any specific retrieval metric. Specifically, we use a gradient descent method with the RankNet cost function (Burges et al., 2005) to perform effective parameter optimizations, as in (Taylor et al., 2006; Metzler, 2007). The basic idea is to find a local minimum of a cost function defined over pairwise document preference. Assume that, given a query Q, there is a set of document pairs RQ based on relevance judgements, such that (D1, D2) E RQ implies document D1 should be ranked higher than D2. Given a defined set of pairwise preferences R, the RankNet cost function is computed as: C(Q, R) = X X log(1 + eY ) (6) VQEQ V(D1,D2)EIZQ where Q is the set of queries, and Y = s(Q; D2)− s(Q; D1) using the current parameter setting. In order to minimize the cost function, we compute gradients of Eq. 6 w</context>
</contexts>
<marker>Taylor, Zaragoza, Craswell, Robertson, Burges, 2006</marker>
<rawString>Michael Taylor, Hugo Zaragoza, Nick Craswell, Stephen Robertson, and Chris Burges. 2006. Optimisation methods for ranking functions with multiple parameters. In Proceedings of CIKM ’06, pages 585–593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Turpin</author>
<author>Alistair Moffat</author>
</authors>
<title>Statistical phrases for vector-space information retrieval.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGIR ’99,</booktitle>
<pages>309--310</pages>
<contexts>
<context position="5232" citStr="Turpin and Moffat, 1999" startWordPosition="799" endWordPosition="803"> been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In many cases, the early researches on phrase-based retrieval have only focused on extracting phrases, not concerning </context>
</contexts>
<marker>Turpin, Moffat, 1999</marker>
<rawString>Andrew Turpin and Alistair Moffat. 1999. Statistical phrases for vector-space information retrieval. In Proceedings of SIGIR ’99, pages 309–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>A theoretical basis for the use of co-occurrence data in information retrieval.</title>
<date>1977</date>
<journal>Journal of Documentation,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>van Rijsbergen, 1977</marker>
<rawString>C. J. van Rijsbergen. 1977. A theoretical basis for the use of co-occurrence data in information retrieval. Journal of Documentation, 33(2):106–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K M Wong</author>
<author>Wojciech Ziarko</author>
<author>Patrick C N Wong</author>
</authors>
<title>Generalized vector spaces model in information retrieval.</title>
<date>1985</date>
<booktitle>In Proceedings of SIGIR ’85,</booktitle>
<pages>18--25</pages>
<contexts>
<context position="6399" citStr="Wong et al., 1985" startWordPosition="985" endWordPosition="988">nly focused on extracting phrases, not concerning about how to devise a retrieval model that effectively considers both words and phrases in ranking. For example, the direct use of traditional vector space model combining a phrase weight and a word weight virtually yields the result assuming independence between a phrase and its constituent words (Srikanth and Srihari, 2003). In order to complement the weakness, a number of research efforts were devoted to the modeling of dependencies between words directly within retrieval models instead of using phrases over the years (van Rijsbergen, 1977; Wong et al., 1985; Croft et al., 1991; Losee, 1994). Most studies were conducted on the probabilistic retrieval framework, such as the BIM model, and aimed on producing a better retrieval model by relaxing the word independence assumption based on the cooccurrence information of words in text. Although those approaches theoretically explain the relation between words and phrases in the retrieval context, they also showed little or no improvements in retrieval effectiveness, mainly because of their statistical nature. While a phrase-based approach selectively incorporated potentially-useful relation between wor</context>
</contexts>
<marker>Wong, Ziarko, Wong, 1985</marker>
<rawString>S. K. M. Wong, Wojciech Ziarko, and Patrick C. N. Wong. 1985. Generalized vector spaces model in information retrieval. In Proceedings of SIGIR ’85, pages 18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to ad hoc information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR ’01,</booktitle>
<pages>334--342</pages>
<contexts>
<context position="20281" citStr="Zhai and Lafferty, 2001" startWordPosition="3277" endWordPosition="3281">robability makes no effect on the ranking). The ranking function of the one-parameter model is also equivalent to Eq. 2, with A in Eq. 3 used “as is” (i.e. as a constant parameter value optimized using gradient descent method, without being replaced to a logistic function). Both baseline models cannot differentiate the importance of phrases in a query. To make a distinction from the baseline models, we will name our proposed method as a multiparameter model. In our experiments, all the probabilities in all retrieval models are smoothed with the collection statistics by using dirichlet priors (Zhai and Lafferty, 2001). Corpus (Training/Test): We have conducted large-scale experiments on three sets of TREC’s Ad Hoc Test Collections, namely TREC-6, TREC7, and TREC-8. Three query sets, TREC-6 topics 301-350, TREC-7 topics 351-400, and TREC8 topics 401-450, along with their relevance judgments have been used. We only used the title field as query. When performing experiments on each query set with the one-parameter and the multiparameter models, the other two query sets have been used for learning the optimal parameters. For each query in the training set, we have generated document pairs for training by the f</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Chengxiang Zhai and John Lafferty. 2001. A study of smoothing methods for language models applied to ad hoc information retrieval. In Proceedings of SIGIR ’01, pages 334–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
</authors>
<title>Fast statistical parsing of noun phrases for document indexing.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP ’97,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="5130" citStr="Zhai, 1997" startWordPosition="787" endWordPosition="788">nally concludes the paper and discusses future work. 2 Previous Work To date, there have been numerous researches to utilize phrases in retrieval models. One of the most earliest work on phrase-based retrieval was done by (Fagan, 1987). In (Fagan, 1987), the effectiveness of proximity-based phrases (i.e. words occurring within a certain distance) in retrieval was investigated with varying criteria to extract phrases from text. Subsequently, various types of phrases, such as sequential n-grams (Mitra et al., 1997), head-modifier pairs extracted from syntactic structures (Lewis and Croft, 1990; Zhai, 1997; Dillon and Gray, 1983; Strzalkowski et al., 1994), proximity-based phrases (Turpin and Moffat, 1999), were examined with conventional retrieval models (e.g. vector space model). The benefit of using phrases for improving the retrieval performance over simple ‘bag-of-words’ models was far less than expected; the overall performance improvement was only marginal and sometimes even inconsistent, specifically when a reasonably good weighting scheme was used (Mitra et al., 1997). Many researchers argued that this was due to the use of improper retrieval models in the experiments. In many cases, t</context>
</contexts>
<marker>Zhai, 1997</marker>
<rawString>Chengxiang Zhai. 1997. Fast statistical parsing of noun phrases for document indexing. In Proceedings of ANLP ’97, pages 312–319.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>