<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.987924">
Hindi-to-Urdu Machine Translation Through Transliteration
</title>
<author confidence="0.98034">
Nadir Durrani Hassan Sajjad Alexander Fraser Helmut Schmid
</author>
<affiliation confidence="0.991163">
Institute for Natural Language Processing
University of Stuttgart
</affiliation>
<email confidence="0.991291">
{durrani,sajjad,fraser,schmid}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.994608" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998406">
We present a novel approach to integrate
transliteration into Hindi-to-Urdu statisti-
cal machine translation. We propose two
probabilistic models, based on conditional
and joint probability formulations, that are
novel solutions to the problem. Our mod-
els consider both transliteration and trans-
lation when translating a particular Hindi
word given the context whereas in pre-
vious work transliteration is only used
for translating OOV (out-of-vocabulary)
words. We use transliteration as a tool
for disambiguation of Hindi homonyms
which can be both translated or translit-
erated or transliterated differently based
on different contexts. We obtain final
BLEU scores of 19.35 (conditional prob-
ability model) and 19.00 (joint probability
model) as compared to 14.30 for a base-
line phrase-based system and 16.25 for a
system which transliterates OOV words in
the baseline system. This indicates that
transliteration is useful for more than only
translating OOV words for language pairs
like Hindi-Urdu.
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999814269230769">
Hindi is an official language of India and is writ-
ten in Devanagari script. Urdu is the national lan-
guage of Pakistan, and also one of the state lan-
guages in India, and is written in Perso-Arabic
script. Hindi inherits its vocabulary from Sanskrit
while Urdu descends from several languages in-
cluding Arabic, Farsi (Persian), Turkish and San-
skrit. Hindi and Urdu share grammatical structure
and a large proportion of vocabulary that they both
inherited from Sanskrit. Most of the verbs and
closed-class words (pronouns, auxiliaries, case-
markers, etc) are the same. Because both lan-
guages have lived together for centuries, some
Urdu words which originally came from Arabic
and Farsi have also mixed into Hindi and are now
part of the Hindi vocabulary. The spoken form of
the two languages is very similar.
The extent of overlap between Hindi and Urdu
vocabulary depends upon the domain of the text.
Text coming from the literary domain like novels
or history tend to have more Sanskrit (for Hindi)
and Persian/Arabic (for Urdu) vocabulary. How-
ever, news wire that contains text related to me-
dia, sports and politics, etc., is more likely to have
common vocabulary.
In an initial study on a small news corpus of
5000 words, randomly selected from BBC1 News,
we found that approximately 62% of the Hindi
types are also part of Urdu vocabulary and thus
can be transliterated while only 38% have to be
translated. This provides a strong motivation to
implement an end-to-end translation system which
strongly relies on high quality transliteration from
Hindi to Urdu.
Hindi and Urdu have similar sound systems but
transliteration from Hindi to Urdu is still very hard
because some phonemes in Hindi have several or-
thographic equivalents in Urdu. For example the
“z” sound2 can only be written as whenever it
occurs in a Hindi word but can be written as ,
, and in an Urdu word. Transliteration
becomes non-trivial in cases where the multiple
orthographic equivalents for a Hindi word are all
valid Urdu words. Context is required to resolve
ambiguity in such cases. Our transliterator (de-
scribed in sections 3.1.2 and 4.1.3) gives an accu-
racy of 81.6% and a 25-best accuracy of 92.3%.
Transliteration has been previously used only as
a back-off measure to translate NEs (Name Enti-
ties) and OOV words in a pre- or post-processing
step. The problem we are solving is more difficult
than techniques aimed at handling OOV words,
</bodyText>
<footnote confidence="0.9977315">
1http://www.bbc.co.uk/hindi/index.shtml
2All sounds are represented using SAMPA notation.
</footnote>
<page confidence="0.977854">
465
</page>
<note confidence="0.98531">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 465–474,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.60719">
Hindi Urdu SAMPA Gloss
/ Am Mango/Ordinary
/ d ZAli Fake/Net
/ Ser Lion/Verse
</table>
<tableCaption confidence="0.8105485">
Table 1: Hindi Words That Can Be Transliterated
Differently in Different Contexts
</tableCaption>
<bodyText confidence="0.9989635">
which focus primarily on name transliteration, be-
cause we need different transliterations in differ-
ent contexts; in their case context is irrelevant. For
example: consider the problem of transliterating
the English word “read” to a phoneme represen-
tation in the context “I will read” versus the con-
text “I have read”. An example of this for Hindi
to Urdu transliteration: the two Urdu words
(face/condition) and (chapter of the Koran)
are both written as (sur@t d) in Hindi. The
two are pronounced identically in Urdu but writ-
ten differently. In such cases we hope to choose
the correct transliteration by using context. Some
other examples are shown in Table 1.
Sometimes there is also an ambiguity of
whether to translate or transliterate a particular
word. The Hindi word , for example, will
be translated to (peace, s@kun) when it is a
common noun but transliterated to (Shanti,
SAnt di) when it is a proper name. We try to
model whether to translate or transliterate in a
given situation. Some other examples are shown
in Table 2.
The remainder of this paper is organized as fol-
lows. Section 2 provides a review of previous
work. Section 3 introduces two probabilistic mod-
els for integrating translations and transliterations
into a translation model which are based on condi-
tional and joint probability distributions. Section 4
discusses the training data, parameter optimization
and the initial set of experiments that compare our
two models with a baseline Hindi-Urdu phrase-
based system and with two transliteration-aided
phrase-based systems in terms of BLEU scores
(Papineni et al., 2001). Section 5 performs an er-
ror analysis showing interesting weaknesses in the
initial formulations. We remedy the problems by
adding some heuristics and modifications to our
models which show improvements in the results as
discussed in section 6. Section 7 gives two exam-
ples illustrating how our model decides whether
to translate or transliterate and how it is able to
choose among different valid transliterations given
the context. Section 8 concludes the paper.
</bodyText>
<sectionHeader confidence="0.99181" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999855923076923">
There has been a significant amount of work on
transliteration. We can break down previous work
into three groups. The first group is generic
transliteration work, which is evaluated outside of
the context of translation. This work uses either
grapheme or phoneme based models to translit-
erate words lists (Knight and Graehl, 1998; Li
et al., 2004; Ekbal et al., 2006; Malik et al.,
2008). The work by Malik et al. addresses Hindi to
Urdu transliteration using hand-crafted rules and
a phonemic representation; it ignores translation
context.
A second group deals with out-of-vocabulary
words for SMT systems built on large parallel cor-
pora, and therefore focuses on name translitera-
tion, which is largely independent of context. Al-
Onaizan and Knight (2002) transliterate Arabic
NEs into English and score them against their re-
spective translations using a modified IBM Model
1. The options are further re-ranked based on dif-
ferent measures such as web counts and using co-
reference to resolve ambiguity. These re-ranking
methodologies can not be performed in SMT at
the decoding time. An efficient way to compute
and re-rank the transliterations of NEs and inte-
grate them on the fly might be possible. However,
this is not practical in our case as our model con-
siders transliterations of all input words and not
just NEs. A log-linear block transliteration model
is applied to OOV NEs in Arabic to English SMT
by Zhao et al. (2007). This work is also translit-
erating only NEs and not doing any disambigua-
tion. The best method proposed by Kashani et
al. (2007) integrates translations provided by ex-
ternal sources such as transliteration or rule-base
translation of numbers and dates, for an arbitrary
number of entries within the input text. Our work
is different from Kashani et al. (2007) in that our
model compares transliterations with translations
</bodyText>
<table confidence="0.579208166666667">
Hindi Urdu SAMPA Gloss
/ simA Border/Seema
/ Amb@r Sky/Ambar
/ vId Ze Victory/Vijay
Table 2: Hindi Words That Can Be Translated or
Transliterated in Different Contexts
</table>
<page confidence="0.999725">
466
</page>
<bodyText confidence="0.999960285714286">
on the fly whereas transliterations in Kashani et al.
do not compete with internal phrase tables. They
only compete amongst themselves during a sec-
ond pass of decoding. Hermjakob et al. (2008) use
a tagger to identify good candidates for translit-
eration (which are mostly NEs) in input text and
add transliterations to the SMT phrase table dy-
namically such that they can directly compete with
translations during decoding. This is closer to
our approach except that we use transliteration as
an alternative to translation for all Hindi words.
Our focus is disambiguation of Hindi homonyms
whereas they are concentrating only on translit-
erating NE’s. Moreover, they are working with
a large bitext so they can rely on their transla-
tion model and only need to transliterate NEs and
OOVs. Our translation model is based on data
which is both sparse and noisy. Therefore we pit
transliterations against translations for every input
word. Sinha (2009) presents a rule-based MT sys-
tem that uses Hindi as a pivot to translate from En-
glish to Urdu. This work also uses transliteration
only for the translation of unknown words. Their
work can not be used for direct translation from
Hindi to Urdu (independently of English) “due to
various ambiguous mappings that have to be re-
solved”.
The third group uses transliteration models in-
side of a cross-lingual IR system (AbdulJaleel and
Larkey, 2003; Virga and Khudanpur, 2003; Pirkola
et al., 2003). Picking a single best transliteration
or translation in context is not important in an IR
system. Instead, all the options are used by giv-
ing them weights and context is typically not taken
into account.
</bodyText>
<sectionHeader confidence="0.961514" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999846454545455">
Both of our models combine a character-based
transliteration model with a word-based transla-
tion model. Our models look for the most probable
Urdu token sequence un1 for a given Hindi token
sequence hn1. We assume that each Hindi token is
mapped to exactly one Urdu token and that there is
no reordering. The assumption of no reordering is
reasonable given the fact that Hindi and Urdu have
identical grammar structure and the same word or-
der. An Urdu token might consist of more than one
Urdu word3. The following sections give a math-
</bodyText>
<footnote confidence="0.818169666666667">
3This occurs frequently in case markers with nouns,
derivational affixes and compounds etc. These are written
as single words in Hindi as opposed to Urdu where they are
</footnote>
<bodyText confidence="0.9266655">
ematical formulation of our two models, Model-1
and Model-2.
</bodyText>
<subsectionHeader confidence="0.997792">
3.1 Model-1 : Conditional Probability Model
</subsectionHeader>
<bodyText confidence="0.9995545">
Applying a noisy channel model to compute the
most probable translation fin1, we get:
</bodyText>
<equation confidence="0.9790705">
arg max p(un1jhn1) = arg max p(un1)p(hn1jun1)
un un
1
(1)
</equation>
<subsectionHeader confidence="0.52046">
3.1.1 Language Model
</subsectionHeader>
<bodyText confidence="0.9999225">
The language model (LM) p(un1) is implemented
as an n-gram model using the SRILM-Toolkit
(Stolcke, 2002) with Kneser-Ney smoothing. The
parameters of the language model are learned from
a monolingual Urdu corpus. The language model
is defined as:
</bodyText>
<equation confidence="0.724643">
pLM(uijui−1
i−k) (2)
</equation>
<bodyText confidence="0.995786058823529">
where k is a parameter indicating the amount of
context used (e.g., k = 4 means 5-gram model).
ui can be a single or a multi-word token. A
multi-word token consists of two or more Urdu
words. For a multi-word ui we do multiple lan-
guage model look-ups, one for each ui. in ui =
uil, ... , ui. and take their product to obtain the
value pLM(uijui−1
i−k).
Language Model for Unknown Words: Our
model generates transliterations that can be known
or unknown to the language model and the trans-
lation model. We refer to the words known to
the language model and to the translation model
as LM-known and TM-known words respectively
and to words that are unknown as LM-unknown
and TM-unknown respectively.
We assign a special value 0 to the LM-unknown
words. If one or more ui. in a multi-word ui are
LM-unknown we assign a language model score
pLM(uijui−1
i−k) = 0 for the entire ui, meaning
that we consider partially known transliterations
to be as bad as fully unknown transliterations. The
parameter 0 controls the trade-off between LM-
known and LM-unknown transliterations. It does
not influence translation options because they are
always LM-known in our case. This is because our
monolingual corpus also contains the Urdu part of
translation corpus. The optimization of 0 is de-
scribed in section 4.2.1.
written as two words. For example (beautiful ; xub-
sur@t d) and (your’s ; ApkA) are written as
and respectively in Urdu.
</bodyText>
<equation confidence="0.984032333333333">
n
p(un1) =
i=1
</equation>
<page confidence="0.988332">
467
</page>
<subsubsectionHeader confidence="0.543042">
3.1.2 Translation Model
</subsubsectionHeader>
<bodyText confidence="0.964928">
The translation model (TM) p(hn1|un1) is approx-
imated with a context-independent model:
</bodyText>
<equation confidence="0.983856">
n
p(hn1|un1) = p(hi|ui) (3)
i=1
</equation>
<bodyText confidence="0.9979896">
where hi and ui are Hindi and Urdu tokens re-
spectively. Our model estimates the conditional
probability p(hi|ui) by interpolating a word-
based model and a character-based (translitera-
tion) model.
</bodyText>
<equation confidence="0.9994">
p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi|ui) (4)
</equation>
<bodyText confidence="0.999862857142857">
The parameters of the word-based translation
model pw(h|u) are estimated from the word align-
ments of a small parallel corpus. We only retain
1-1/1-N (1 Hindi word, 1 or more Urdu words)
alignments and throw away N-1 and M-N align-
ments for our models. This is further discussed in
section 4.1.1.
The character-based transliteration model
pc(h|u) is computed in terms of pc(h, u), a joint
character model, which is also used for Chinese-
English back-transliteration (Li et al., 2004) and
Bengali-English name transliteration (Ekbal et al.,
2006). The character-based transliteration proba-
bility is defined as follows:
</bodyText>
<equation confidence="0.960884857142857">
pc(h, u) = � p(an1)
ai ∈align(h,u)
language model:
p(ci|ci−1
i−k) (7)
The parameters p(ci|ci−1
i−k) are estimated from
</equation>
<bodyText confidence="0.9847595">
the Urdu part of the character-aligned translitera-
tion corpus. Replacing (6) in (4) we get:
</bodyText>
<equation confidence="0.99479">
p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi, ui) (8)
pc(ui)
</equation>
<bodyText confidence="0.995395666666667">
Having all the components of our model defined
we insert (8) and (2) in (1) to obtain the final equa-
tion:
</bodyText>
<equation confidence="0.99727775">
pLM(ui|ui−1
i−k)[λpw(hi|ui)
+ (1 − λ)pc(hi, ui)� (9)
pc (ui )
</equation>
<bodyText confidence="0.999725">
The optimization of the interpolating factor λ is
discussed in section 4.2.1.
</bodyText>
<subsectionHeader confidence="0.999124">
3.2 Model-2 : Joint Probability Model
</subsectionHeader>
<bodyText confidence="0.9911185">
This section briefly defines a variant of our model
where we interpolate joint probabilities instead of
conditional probabilities. Again, the translation
model p(hn1|un1) is approximated with a context-
</bodyText>
<equation confidence="0.9603899">
independent model:
pc(u) = �m
i=1
un1 = arg max
u�
1
n
i=1
�= n p(ai|ai−1 p(hn1|un1) = n p(hi|ui) = n p(hi, ui) (10)
ai ∈align(h,u) i=1 i−k) (5) i=1 i=1 p(ui)
</equation>
<bodyText confidence="0.997992230769231">
where ai is a pair consisting of the i-th Hindi char-
acter hi and the sequence of 0 or more Urdu char-
acters that it is aligned with. A sample alignment
is shown in Table 3(b) in section 4.1.3. Our best
results are obtained with a 5-gram model. The
parameters p(ai|ai−1
i−k) are estimated from a small
transliteration corpus which we automatically ex-
tracted from the translation corpus. The extrac-
tion details are also discussed in section 4.1.3. Be-
cause our overall model is a conditional probabil-
ity model, joint-probabilities are marginalized us-
ing character-based prior probabilities:
</bodyText>
<equation confidence="0.99389">
pc(h|u) = pc(h, u) (6)
pc(u)
</equation>
<bodyText confidence="0.980162428571429">
The prior probability pc(u) of the character se-
quence u = cm1 is defined with a character-based
The joint probability p(hi, ui) of a Hindi and an
Urdu word is estimated by interpolating a word-
based model and a character-based model.
p(hi, ui) = λpw(hi, ui) +(1− λ)pc(hi, ui) (11)
and the prior probability p(ui) is estimated as:
</bodyText>
<equation confidence="0.998623">
p(ui) = λpw(ui) + (1 − λ)pc(ui) (12)
</equation>
<bodyText confidence="0.999715625">
The parameters of the translation model pw(hi, ui)
and the word-based prior probabilities pw(ui) are
estimated from the 1-1/1-N word-aligned corpus
(the one that we also used to estimate translation
probabilities pw(hi|ui) previously).
The character-based transliteration probability
pc(hi, ui) and the character-based prior probabil-
ity pc(ui) are defined by (5) and (7) respectively in
</bodyText>
<page confidence="0.996909">
468
</page>
<bodyText confidence="0.9538845">
the previous section. Putting (11) and (12) in (10)
we get
</bodyText>
<equation confidence="0.932181333333333">
λpw(hi, ui) + (1 − λ)pc(hi, ui)
λpw(ui) + (1 − λ)pc(ui)
(13)
</equation>
<bodyText confidence="0.997044">
The idea is to interpolate joint probabilities and di-
vide them by the interpolated marginals. The final
equation for Model-2 is given as:
</bodyText>
<subsectionHeader confidence="0.997504">
3.3 Search
</subsectionHeader>
<bodyText confidence="0.99998272">
The decoder performs a stack-based search using
a beam-search algorithm similar to the one used
in Pharoah (Koehn, 2004a). It searches for an
Urdu string that maximizes the product of trans-
lation probability and the language model proba-
bility (equation 1) by translating one Hindi word
at a time. It is implemented as a two-level pro-
cess. At the lower level, it computes n-best
transliterations for each Hindi word hi accord-
ing to pc(h, u). The joint probabilities given by
pc(h, u) are marginalized for each Urdu transliter-
ation to give pc(h|u). At the higher level, translit-
eration probabilities are interpolated with pw(h|u)
and then multiplied with language model probabil-
ities to give the probability of a hypothesis. We use
20-best translations and 25-best transliterations for
pw(h|u) and pc(h|u) respectively and a 5-gram
language model.
To keep the search space manageable and time
complexity polynomial we apply pruning and re-
combination. Since our model uses monotonic de-
coding we only need to recombine hypotheses that
have the same context (last n-1 words). Next we
do histogram-based pruning, maintaining the 100-
best hypotheses for each stack.
</bodyText>
<sectionHeader confidence="0.99906" genericHeader="method">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.969676">
4.1 Training
</subsectionHeader>
<bodyText confidence="0.9999335">
This section discusses the training of the different
model components.
</bodyText>
<subsubsectionHeader confidence="0.798433">
4.1.1 Translation Corpus
</subsubsectionHeader>
<bodyText confidence="0.999437621621622">
We used the freely available EMILLE Corpus
as our bilingual resource which contains roughly
13,000 Urdu and 12,300 Hindi sentences. From
these we were able to sentence-align 7000 sen-
tence pairs using the sentence alignment algorithm
given by Moore (2002).
The word alignments for this task were ex-
tracted by using GIZA++ (Och and Ney, 2003) in
both directions. We extracted a total of 107323
alignment pairs (5743 N-1 alignments, 8404 M-
N alignments and 93176 1-1/1-N alignments). Of
these alignments M-N and N-1 alignment pairs
were ignored. We manually inspected a sample of
1000 instances of M-N/N-1 alignments and found
that more than 70% of these were (totally or par-
tially) wrong. Of the 30% correct alignments,
roughly one-third constitute N-1 alignments. Most
of these are cases where the Urdu part of the align-
ment actually consists of two (or three) words
but was written without space because of lack of
standard writing convention in Urdu. For exam-
ple (can go ; d ZA s@kt de) is alterna-
tively written as (can go ; d ZAs@kt de)
i.e. without space. We learned that these N-1
translations could be safely dropped because we
can generate a separate Urdu word for each Hindi
word. For valid M-N alignments we observed that
these could be broken into 1-1/1-N alignments in
most of the cases. We also observed that we usu-
ally have coverage of the resulting 1-1 and 1-N
alignments in our translation corpus. Looking at
the noise in the incorrect alignments we decided
to drop N-1 and M-N cases. We do not model
deletions and insertions so we ignored null align-
ments. Also 1-N alignments with gaps were ig-
nored. Only the alignments with contiguous words
were kept.
</bodyText>
<subsubsectionHeader confidence="0.47926">
4.1.2 Monolingual Corpus
</subsubsectionHeader>
<bodyText confidence="0.9996748">
Our monolingual Urdu corpus consists of roughly
114K sentences. This comprises 108K sentences
from the data made available by the University of
Leipzig4 + 5600 sentences from the training data
of each fold during cross validation.
</bodyText>
<subsubsectionHeader confidence="0.752067">
4.1.3 Transliteration Corpus
</subsubsectionHeader>
<bodyText confidence="0.999683285714286">
The training corpus for transliteration is extracted
from the 1-1/1-N word-alignments of the EMILLE
corpus discussed in section 4.1.1. We use an edit
distance algorithm to align this training corpus at
the character level and we eliminate translation
pairs with high edit distance which are unlikely to
be transliterations.
</bodyText>
<equation confidence="0.955901444444444">
4http://corpora.informatik.uni-leipzig.de/
n
p(hn1|un1) =
i=1
fin1 = arg max n pLM(ui|ui−1
u1 i=1 i−k)X
(14)
λpw(ui) + (1 − λ)pc(ui)
λpw(hi, ui) + (1 − λ)pc(hi, ui)
</equation>
<page confidence="0.995342">
469
</page>
<bodyText confidence="0.999971033333333">
We used our knowledge of the Hindi and Urdu
scripts to define the initial character mapping. The
mapping was further extended by looking into
available Hindi-Urdu transliteration systems[5,6]
and other resources (Gupta, 2004; Malik et al.,
2008; Jawaid and Ahmed, 2009). Each pair in the
character map is assigned a cost. A Hindi charac-
ter that always map to only one Urdu character is
assigned a cost of 0 whereas the Hindi characters
that map to different Urdu characters are assigned
a cost of 0.2. The edit distance metric allows
insert, delete and replace operations. The hand-
crafted pairs define the cost of replace operations.
We set a cost of 0.6 for deletions and insertions.
These costs were optimized on held out data. The
details of optimization are not mentioned due to
limited space. Using this metric we filter out the
word pairs with high edit-distance to extract our
transliteration corpus. We were able to extract
roughly 2100 unique pairs along with their align-
ments. The resulting alignments are modified by
merging unaligned 0 —* 1 (no character on source
side, 1 character on target side) or 0 —* N align-
ments with the preceding alignment pair. If there
is no preceding alignment pair then it is merged
with the following pair. Table 3 gives an example
showing initial alignment (a) and the final align-
ment (b) after applying the merge operation. Our
model retains 1 —* 0 and N —* 0 alignments as
deletion operations.
</bodyText>
<listItem confidence="0.660185333333333">
a) Hindi 0 b c 0 e f
Urdu A XY C D 0 F
b) Hindi b c e f
</listItem>
<tableCaption confidence="0.688485">
Urdu AXY CD 0 F
Table 3: Alignment (a) Before (b) After Merge
</tableCaption>
<bodyText confidence="0.99876475">
The parameters p,(h, u) and p,(u) are trained
on the aligned corpus using the SRILM toolkit.
We use Add-1 smoothing for unigrams and
Kneser-Ney smoothing for higher n-grams.
</bodyText>
<subsectionHeader confidence="0.879027">
4.1.4 Diacritic Removal and Normalization
</subsectionHeader>
<bodyText confidence="0.999601166666667">
In Urdu, short vowels are represented with diacrit-
ics but these are rarely written in practice. In or-
der to keep the data consistent, all diacritics are
removed. This loss of information is not harm-
ful when transliterating/translating from Hindi to
Urdu because undiacritized text is equally read-
</bodyText>
<footnote confidence="0.9994075">
5CRULP: http://www.crulp.org/software/langproc.htm
6Malerkotla.org: http://translate.malerkotla.co.in
</footnote>
<bodyText confidence="0.999032142857143">
able to native speakers as its diacritized counter
part. However leaving occasional diacritics in the
corpus can worsen the problem of data sparsity by
creating spurious ambiguity7.
There are a few Urdu characters that have mul-
tiple equivalent Unicodes. All such forms are nor-
malized to have only one representation8.
</bodyText>
<subsectionHeader confidence="0.983678">
4.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99964375">
We perform a 5-fold cross validation taking 4/5 of
the data as training and 1/5 as test data. Each fold
comprises roughly 1400 test sentences and 5600
training sentences.
</bodyText>
<subsubsectionHeader confidence="0.971611">
4.2.1 Parameter Optimization
</subsubsectionHeader>
<bodyText confidence="0.998380285714286">
Our model contains two parameters A (the inter-
polating factor between translation and transliter-
ation modules) and 0 (the factor that controls the
trade-off between LM-known and LM-unknown
transliterations). The interpolating factor A is ini-
tialized, inspired by Written-Bell smoothing, with
a value of � 9. We chose a very low value
</bodyText>
<equation confidence="0.543606">
��B
</equation>
<bodyText confidence="0.999292">
1e−40 for the factor 0 initially, favoring LM-
known transliterations very strongly. Both of these
parameters are optimized as described below.
Because our training data is very sparse we do
not use held-out data for parameter optimization.
Instead we optimize these parameters by perform-
ing a 2-fold optimization for each of the 5 folds.
Each fold is divided into two halves. The param-
eters A and 0 are optimized on the first half and
the other half is used for testing, then optimiza-
tion is done on the second half and the first half is
used for testing. The optimal value for parameter
A occurs between 0.7-0.84 and for the parameter
0 between 1e−5 and 1e−10.
</bodyText>
<sectionHeader confidence="0.689329" genericHeader="method">
4.2.2 Results
</sectionHeader>
<bodyText confidence="0.996357833333333">
Baseline Pb0: We ran Moses (Koehn et al., 2007)
using Koehn’s training scripts10, doing a 5-fold
cross validation with no reordering11. For the
other parameters we use the default values i.e.
5-gram language model and maximum phrase-
length= 6. Again, the language model is imple-
</bodyText>
<footnote confidence="0.983416888888889">
7It should be noted though that diacritics play a very im-
portant role when transliterating in the reverse direction be-
cause these are virtually always written in Hindi as dependent
vowels.
8www.crulp.org/software/langproc/urdunormalization.htm
9N is the number of aligned word pairs (tokens) and B is
the number of different aligned word pairs (types).
10http://statmt.org/wmt08/baseline.html
11Results are worse with reordering enabled.
</footnote>
<page confidence="0.986698">
470
</page>
<table confidence="0.987866">
M Pb0 Pb1 Pb2 M1 M2
BLEU 14.3 16.25 16.13 18.6 17.05
</table>
<tableCaption confidence="0.985761">
Table 4: Comparing Model-1 and Model-2 with
Phrase-based Systems
</tableCaption>
<bodyText confidence="0.984790151515151">
mented as an n-gram model using the SRILM-
Toolkit with Kneser-Ney smoothing. Each fold
comprises roughly 1400 test sentences, 5000 in
training and 600 in dev12. We also used two meth-
ods to incorporate transliterations in the phrase-
based system:
Post-process Pb1: All the OOV words in the
phrase-based output are replaced with their top-
candidate transliteration as given by our translit-
eration system.
Pre-process Pb2: Instead of adding translit-
erations as a post process we do a second pass
by adding the unknown words with their top-
candidate transliteration to the training corpus and
rerun Koehn’s training script with the new training
corpus. Table 4 shows results (taking arithmetic
average over 5 folds) from Model-1 and Model-
2 in comparison with three baselines discussed
above.
Both our systems (Model-1 and Model-2) beat
the baseline phrase-based system with a BLEU
point difference of 4.30 and 2.75 respectively. The
transliteration aided phrase-based systems Pb1
and Pb2 are closer to our Model-2 results but are
way below Model-1 results. The difference of
2.35 BLEU points between M1 and Pb1 indicates
that transliteration is useful for more than only
translating OOV words for language pairs like
Hindi-Urdu. Our models choose between trans-
lations and transliterations based on context un-
like the phrase-based systems Pb1 and Pb2 which
use transliteration only as a tool to translate OOV
words.
</bodyText>
<sectionHeader confidence="0.996655" genericHeader="method">
5 Error Analysis
</sectionHeader>
<bodyText confidence="0.865342545454545">
Based on preliminary experiments we found three
major flaws in our initial formulations. This sec-
tion discusses each one of them and provides some
heuristics and modifications that we employ to try
to correct deficiencies we found in the two models
described in section 3.1 and 3.2.
12After having the MERT parameters, we add the 600 dev
sentences back into the training corpus, retrain GIZA, and
then estimate a new phrase table on all 5600 sentences. We
then use the MERT parameters obtained before together with
the newer (larger) phrase-table set.
</bodyText>
<subsectionHeader confidence="0.991016">
5.1 Heuristic-1
</subsectionHeader>
<bodyText confidence="0.999915333333333">
A lot of errors occur because our translation model
is built on very sparse and noisy data. The moti-
vation for this heuristic is to counter wrong align-
ments at least in the case of verbs and functional
words (which are often transliterations). This
heuristic favors translations that also appear in the
n-best transliteration list over only-translation and
only-transliteration options. We modify the trans-
lation model for both the conditional and the joint
model by adding another factor which strongly
weighs translation+transliteration options by tak-
ing the square-root of the product of the translation
and transliteration probabilities. Thus modifying
equations (8) and (11) in Model-1 and Model-2
we obtain equations (15) and (16) respectively:
</bodyText>
<equation confidence="0.999795857142857">
p(hi|ui) _ A1pw(hi|ui) + A2pc(hi, ui)
pc(ui)
+ A3 pw(hi |ui)pc(hi, ui) (15)
pc(ui)
p(hi, ui) _ A1pw(hi, ui) + A2pc(hi, ui)
V/
+ A3 pw(hi, ui)pc(hi, ui) (16)
</equation>
<bodyText confidence="0.997618333333333">
For the optimization of lambda parameters we
hold the value of the translation coefficient A113
and the transliteration coefficient A2 constant (us-
ing the optimized values as discussed in section
4.2.1) and optimize A3 again using 2-fold opti-
mization on all the folds as described above14.
</bodyText>
<subsectionHeader confidence="0.999682">
5.2 Heuristic-2
</subsectionHeader>
<bodyText confidence="0.9725264">
When an unknown Hindi word occurs for which
all transliteration options are LM-unknown then
the best transliteration should be selected. The
problem in our original models is that a fixed LM
probability 0 is used for LM-unknown transliter-
ations. Hence our model selects the translitera-
tion that has the best pc(hi,ui) score i.e. we max-
pc(ui)
imize pc(hilui) instead of pc(uilhi) (or equiva-
lently pc(hi, ui)). The reason is an inconsistency
in our models. The language model probabil-
ity of unknown words is uniform (and equal to
0) whereas the translation model uses the non-
uniform prior probability pc(ui) for these words.
There is another reason why we can not use the
</bodyText>
<footnote confidence="0.981542">
13The translation coefficient a1 is same as a used in previ-
ous models and the transliteration coefficient a2 = 1 − a
14After optimization we normalize the lambdas to make
their sum equal to 1.
</footnote>
<page confidence="0.997891">
471
</page>
<bodyText confidence="0.999354909090909">
value ψ in this case. Our transliterator model also
produces space inserted words. The value of ψ is
very small because of which transliterations that
are actually LM-unknown, but are mistakenly bro-
ken into constituents that are LM-known, will al-
ways be preferred over their counter parts. An ex-
ample of this is (America) for which two
possible transliterations as given by our model are
(AmerIkA, without space) and (AmerI
kA, with space). The latter version is LM-known
as its constituents are LM-known. Our models al-
ways favor the latter version. Space insertion is an
important feature of our transliteration model. We
want our transliterator to tackle compound words,
derivational affixes, case-markers with nouns that
are written as one word in Hindi but as two or more
words in Urdu. Examples were already shown in
section 3’s footnote.
We eliminate the inconsistency by using pc(ui)
as the 0-gram back-off probability distribution in
the language model. For an LM-unknown translit-
erations we now get in Model-1:
</bodyText>
<equation confidence="0.952052555555556">
= p(ui|ui−1
i−k)[(1 − λ)pc(hi, ui)
pc(ui) ]
α(ui−1
i−j)pc(ui)[(1 − λ)pc(hi, ui)
]
pc(ui)
α(ui−1
i−j)[(1 − λ)pc(hi, ui)]
</equation>
<bodyText confidence="0.951934666666667">
where Hkj=0 α(ui−1
i−j) is just the constant that
SRILM returns for unknown words. The last
line of the calculation shows that we simply drop
pc(ui) if ui is LM-unknown and use the constant
Hkj=0 α(ui−1
i−j) instead of ψ. A similar calculation
for Model-2 gives Hkj=0 α(ui−1
i−j)pc(hi, ui).
</bodyText>
<subsectionHeader confidence="0.999319">
5.3 Heuristic-3
</subsectionHeader>
<bodyText confidence="0.8217714">
This heuristic discusses a flaw in Model-2. For
transliteration options that are TM-unknown, the
pw(h, u) and pw(u) factors becomes zero and the
translation model probability as given by equation
(13) becomes:
</bodyText>
<equation confidence="0.832382">
(1 − λ)pc(hi, ui)
(1 − λ)pc(ui)
</equation>
<bodyText confidence="0.9805805">
In such cases the λ factor cancels out and no
weighting of word translation vs. transliteration
</bodyText>
<note confidence="0.608786">
H1 H2 H12
</note>
<table confidence="0.6393145">
M1 18.86 18.97 19.35
M2 17.56 17.85 18.34
</table>
<tableCaption confidence="0.8933055">
Table 5: Applying Heuristics 1 and 2 and their
Combinations to Model-1 and Model-2
</tableCaption>
<table confidence="0.7331345">
H3 H13 H23 H123
M2 18.52 18.93 18.55 19.00
</table>
<tableCaption confidence="0.930338">
Table 6: Applying Heuristic 3 and its Combina-
tions with other Heuristics to Model-2
</tableCaption>
<bodyText confidence="0.992706222222222">
occurs anymore. As a result of this, translitera-
tions are sometimes incorrectly favored over their
translation alternatives.
In order to remedy this problem we assign a
minimal probability β to the word-based prior
pw(ui) in case of TM-unknown transliterations,
which prevents it from ever being zero. Because
of this addition the translation model probability
for LM-unknown words becomes:
</bodyText>
<equation confidence="0.9410465">
(1 − λ)pc(hi, ui) where β = 1
λβ + (1 − λ)pc(ui) Urdu Types in TM
</equation>
<sectionHeader confidence="0.996653" genericHeader="method">
6 Final Results
</sectionHeader>
<bodyText confidence="0.999966958333333">
This section shows the improvement in BLEU
score by applying heuristics and combinations of
heuristics in both the models. Tables 5 and 6 show
the improvements achieved by using the differ-
ent heuristics and modifications discussed in sec-
tion 5. We refer to the results as MxHy where x
denotes the model number, 1 for the conditional
probability model and 2 for the joint probability
model and y denotes a heuristic or a combination
of heuristics applied to that model15.
Both heuristics (H1 and H2) show improve-
ments over their base models M1 and M2.
Heuristic-1 shows notable improvement for both
models in parts of test data which has high num-
ber of common vocabulary words. Using heuris-
tic 2 we were able to properly score LM-unknown
transliterations against each other. Using these
heuristics together we obtain a gain of 0.75 over
M-1 and again of 1.29 over M-2.
Heuristic-3 remedies the flaw in M2 by assign-
ing a special value to the word-based prior pw(ui)
for TM-unknown words which prevents the can-
celation of interpolating parameter λ. M2 com-
bined with heuristic 3 (M2H3) results in a 1.47
</bodyText>
<footnote confidence="0.862239666666667">
15For example M1H1 refers to the results when heuristic-
1 is applied to model-1 whereas M2H12 refers to the results
when heuristics 1 and 2 are together applied to model 2.
</footnote>
<equation confidence="0.905277">
p(ui|ui−1
i−k)[λpw(hi|ui) + (1 − λ)pc(hi, ui)
pc(ui) ]
k
= ri
j=0
k
= ri
j=0
pc(hi, ui)
pc(ui)
</equation>
<page confidence="0.995254">
472
</page>
<bodyText confidence="0.999964875">
BLEU point improvement and combined with all
the heuristics (M2H123) gives an overall gain of
1.95 BLEU points and is close to our best results
(M1H12). We also performed significance test
by concatenating all the fold results. Both our best
systems M1H12 and M2H123 are statistically sig-
nificant (p &lt; 0.05)16 over all the baselines dis-
cussed in section 4.2.2.
One important issue that has not been investi-
gated yet is that BLEU has not yet been shown
to have good performance in morphologically rich
target languages like Urdu, but there is no metric
known to work better. We observed that some-
times on data where the translators preferred to
translate rather than doing transliteration our sys-
tem is penalized by BLEU even though our out-
put string is a valid translation. For other parts of
the data where the translators have heavily used
transliteration, the system may receive a higher
BLEU score. We feel that this is an interesting
area of research for automatic metric developers,
and that a large scale task of translation to Urdu
which would involve a human evaluation cam-
paign would be very interesting.
</bodyText>
<sectionHeader confidence="0.981586" genericHeader="method">
7 Sample Output
</sectionHeader>
<bodyText confidence="0.9998314375">
This section gives two examples showing how our
model (M1H2) performs disambiguation. Given
below are some test sentences that have Hindi
homonyms (underlined in the examples) along
with Urdu output given by our system. In the first
example (given in Figure 1) Hindi word can be
transliterated to ( Lion) or (Verse) depend-
ing upon the context. Our model correctly identi-
fies which transliteration to choose given the con-
text.
In the second example (shown in Figure 2)
Hindi word can be translated to (peace,
s@kun) when it is a common noun but transliter-
ated to (Shanti, SAnt di) when it is a proper
name. Our model successfully decides whether to
translate or transliterate given the context.
</bodyText>
<sectionHeader confidence="0.998274" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9996065">
We have presented a novel way to integrate
transliterations into machine translation. In
closely related language pairs such as Hindi-Urdu
with a significant amount of vocabulary overlap,
</bodyText>
<footnote confidence="0.512806666666667">
16We used Kevin Gimpel’s tester
(http://www.ark.cs.cmu.edu/MT/) which uses bootstrap
resampling (Koehn, 2004b), with 1000 samples.
</footnote>
<bodyText confidence="0.9926235">
Ser d Z@ngl kA rAd ZA he
“Lion is the king of jungle”
AIqbAl kA Aek xub sur@t d Ser he
“There is a beautiful verse from Iqbal”
</bodyText>
<figureCaption confidence="0.9578665">
Figure 1: Different Transliterations in Different
Contexts
</figureCaption>
<bodyText confidence="0.95197725">
p hIr b hi vh s@kun se n@he˜rh s@kt dA
“Even then he can’t live peacefully”
Aom SAnt di Aom frhA xAn ki d dusri fIl@m he
“Om Shanti Om is Farah Khan’s second film”
</bodyText>
<figureCaption confidence="0.998525">
Figure 2: Translation or Transliteration
</figureCaption>
<bodyText confidence="0.999888666666667">
transliteration can be very effective in machine
translation for more than just translating OOV
words. We have addressed two problems. First,
transliteration helps overcome the problem of data
sparsity and noisy alignments. We are able to gen-
erate word translations that are unseen in the trans-
lation corpus but known to the language model.
Additionally, we can generate novel translitera-
tions (that are LM-Unknown). Second, generat-
ing multiple transliterations for homograph Hindi
words and using language model context helps us
solve the problem of disambiguation. We found
that the joint probability model performs almost as
well as the conditional probability model but that
it was more complex to make it work well.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999847">
The first two authors were funded by the Higher
Education Commission (HEC) of Pakistan. The
third author was funded by Deutsche Forschungs-
gemeinschaft grants SFB 732 and MorphoSynt.
The fourth author was funded by Deutsche
Forschungsgemeinschaft grant SFB 732.
</bodyText>
<page confidence="0.999117">
473
</page>
<sectionHeader confidence="0.993815" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999378927272727">
Nasreen AbdulJaleel and Leah S. Larkey. 2003. Sta-
tistical transliteration for English-Arabic cross lan-
guage information retrieval. In CIKM 03: Proceed-
ings of the twelfth international conference on In-
formation and knowledge management, pages 139–
146.
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing named entities using monolingual and bilingual
resources. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 400–408.
Asif Ekbal, Sudip Kumar Naskar, and Sivaji Bandy-
opadhyay. 2006. A modified joint source-channel
model for transliteration. In Proceedings of the
COLING/ACL poster sessions, pages 191–198, Syd-
ney, Australia. Association for Computational Lin-
guistics.
Swati Gupta. 2004. Aligning Hindi and Urdu bilin-
gual corpora for robust projection. Masters project
dissertation, Department of Computer Science, Uni-
versity of Sheffield.
Ulf Hermjakob, Kevin Knight, and Hal Daum´e III.
2008. Name translation in statistical machine trans-
lation - learning when to transliterate. In Proceed-
ings of ACL-08: HLT, pages 389–397, Columbus,
Ohio. Association for Computational Linguistics.
Bushra Jawaid and Tafseer Ahmed. 2009. Hindi to
Urdu conversion: beyond simple transliteration. In
Conference on Language and Technology 2009, La-
hore, Pakistan.
Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George
Foster, and Fred Popowich. 2007. Integration of an
Arabic transliteration module into a statistical ma-
chine translation system. In Proceedings of the Sec-
ond Workshop on Statistical Machine Translation,
pages 17–24, Prague, Czech Republic. Association
for Computational Linguistics.
Kevin Knight and Jonathan Graehl. 1998. Ma-
chine transliteration. Computational Linguistics,
24(4):599–612.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation for Computational Linguistics, Demonstra-
tion Program, Prague, Czech Republic.
Philipp Koehn. 2004a. Pharaoh: A beam search de-
coder for phrase-based statistical machine transla-
tion models. In AMTA, pages 115–124.
Philipp Koehn. 2004b. Statistical significance tests for
machine translation evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388–395, Barcelona, Spain, July. Association
for Computational Linguistics.
Haizhou Li, Zhang Min, and Su Jian. 2004. A joint
source-channel model for machine transliteration.
In ACL ’04: Proceedings of the 42nd Annual Meet-
ing on Association for Computational Linguistics,
pages 159–166, Barcelona, Spain. Association for
Computational Linguistics.
M G Abbas Malik, Christian Boitet, and Pushpak Bhat-
tacharyya. 2008. Hindi Urdu machine translitera-
tion using finite-state transducers. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics, Manchester, UK.
Robert C. Moore. 2002. Fast and accurate sentence
alignment of bilingual corpora. In Conference of the
Association for Machine Translation in the Ameri-
cas (AMTA).
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Kishore A. Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2001. BLEU: a method for auto-
matic evaluation of machine translation. Technical
Report RC22176 (W0109-022), IBM Research Di-
vision, Thomas J. Watson Research Center, York-
town Heights, NY.
Ari Pirkola, Jarmo Toivonen, Heikki Keskustalo, Kari
Visala, and Kalervo J¨arvelin. 2003. Fuzzy trans-
lation of cross-lingual spelling variants. In SIGIR
’03: Proceedings of the 26th annual international
ACM SIGIR conference on Research and develop-
ment in informaion retrieval, pages 345–352, New
York, NY, USA. ACM.
R. Mahesh K. Sinha. 2009. Developing English-Urdu
machine translation via Hindi. In Third Workshop
on Computational Approaches to Arabic Script-
based Languages (CAASL3), MT Summit XII, Ot-
tawa, Canada.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Intl. Conf. Spoken Lan-
guage Processing, Denver, Colorado.
Paola Virga and Sanjeev Khudanpur. 2003. Translit-
eration of proper names in cross-lingual information
retrieval. In Proceedings of the ACL 2003 workshop
on Multilingual and mixed-language named entity
recognition, pages 57–64, Morristown, NJ, USA.
Association for Computational Linguistics.
Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-
gel. 2007. A log-linear block transliteration model
based on bi-stream HMMs. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 364–371, Rochester, New York. Associ-
ation for Computational Linguistics.
</reference>
<page confidence="0.998986">
474
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.877129">
<title confidence="0.999895">Hindi-to-Urdu Machine Translation Through Transliteration</title>
<author confidence="0.989667">Nadir Durrani Hassan Sajjad Alexander Fraser Helmut Schmid</author>
<affiliation confidence="0.9967535">Institute for Natural Language Processing University of Stuttgart</affiliation>
<abstract confidence="0.995735461538461">We present a novel approach to integrate transliteration into Hindi-to-Urdu statistical machine translation. We propose two probabilistic models, based on conditional and joint probability formulations, that are novel solutions to the problem. Our models consider both transliteration and translation when translating a particular Hindi word given the context whereas in previous work transliteration is only used for translating OOV (out-of-vocabulary) words. We use transliteration as a tool for disambiguation of Hindi homonyms which can be both translated or transliterated or transliterated differently based on different contexts. We obtain final BLEU scores of 19.35 (conditional probability model) and 19.00 (joint probability model) as compared to 14.30 for a baseline phrase-based system and 16.25 for a system which transliterates OOV words in the baseline system. This indicates that transliteration is useful for more than only translating OOV words for language pairs like Hindi-Urdu.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nasreen AbdulJaleel</author>
<author>Leah S Larkey</author>
</authors>
<title>Statistical transliteration for English-Arabic cross language information retrieval.</title>
<date>2003</date>
<booktitle>In CIKM 03: Proceedings of the twelfth international conference on Information and knowledge management,</booktitle>
<pages>139--146</pages>
<contexts>
<context position="9612" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="1534" endWordPosition="1537">ransliterate NEs and OOVs. Our translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead, all the options are used by giving them weights and context is typically not taken into account. 3 Our Approach Both of our models combine a character-based transliteration model with a word-based translation model. Our models look for the most probable Urdu token sequence un1 for a given Hindi token sequence hn1. We assume that each Hindi token is mapped to exactly one Urdu token and that there is no reordering. The assumption of no reo</context>
</contexts>
<marker>AbdulJaleel, Larkey, 2003</marker>
<rawString>Nasreen AbdulJaleel and Leah S. Larkey. 2003. Statistical transliteration for English-Arabic cross language information retrieval. In CIKM 03: Proceedings of the twelfth international conference on Information and knowledge management, pages 139– 146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating named entities using monolingual and bilingual resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>400--408</pages>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Translating named entities using monolingual and bilingual resources. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 400–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
<author>Sudip Kumar Naskar</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>A modified joint source-channel model for transliteration.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL poster sessions,</booktitle>
<pages>191--198</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="6567" citStr="Ekbal et al., 2006" startWordPosition="1033" endWordPosition="1036"> in section 6. Section 7 gives two examples illustrating how our model decides whether to translate or transliterate and how it is able to choose among different valid transliterations given the context. Section 8 concludes the paper. 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and usi</context>
<context position="13492" citStr="Ekbal et al., 2006" startWordPosition="2183" endWordPosition="2186">-based (transliteration) model. p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi|ui) (4) The parameters of the word-based translation model pw(h|u) are estimated from the word alignments of a small parallel corpus. We only retain 1-1/1-N (1 Hindi word, 1 or more Urdu words) alignments and throw away N-1 and M-N alignments for our models. This is further discussed in section 4.1.1. The character-based transliteration model pc(h|u) is computed in terms of pc(h, u), a joint character model, which is also used for ChineseEnglish back-transliteration (Li et al., 2004) and Bengali-English name transliteration (Ekbal et al., 2006). The character-based transliteration probability is defined as follows: pc(h, u) = � p(an1) ai ∈align(h,u) language model: p(ci|ci−1 i−k) (7) The parameters p(ci|ci−1 i−k) are estimated from the Urdu part of the character-aligned transliteration corpus. Replacing (6) in (4) we get: p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi, ui) (8) pc(ui) Having all the components of our model defined we insert (8) and (2) in (1) to obtain the final equation: pLM(ui|ui−1 i−k)[λpw(hi|ui) + (1 − λ)pc(hi, ui)� (9) pc (ui ) The optimization of the interpolating factor λ is discussed in section 4.2.1. 3.2 Model-2 : Joi</context>
</contexts>
<marker>Ekbal, Naskar, Bandyopadhyay, 2006</marker>
<rawString>Asif Ekbal, Sudip Kumar Naskar, and Sivaji Bandyopadhyay. 2006. A modified joint source-channel model for transliteration. In Proceedings of the COLING/ACL poster sessions, pages 191–198, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swati Gupta</author>
</authors>
<title>Aligning Hindi and Urdu bilingual corpora for robust projection.</title>
<date>2004</date>
<institution>Department of Computer Science, University of Sheffield.</institution>
<note>Masters project dissertation,</note>
<contexts>
<context position="20066" citStr="Gupta, 2004" startWordPosition="3264" endWordPosition="3265"> discussed in section 4.1.1. We use an edit distance algorithm to align this training corpus at the character level and we eliminate translation pairs with high edit distance which are unlikely to be transliterations. 4http://corpora.informatik.uni-leipzig.de/ n p(hn1|un1) = i=1 fin1 = arg max n pLM(ui|ui−1 u1 i=1 i−k)X (14) λpw(ui) + (1 − λ)pc(ui) λpw(hi, ui) + (1 − λ)pc(hi, ui) 469 We used our knowledge of the Hindi and Urdu scripts to define the initial character mapping. The mapping was further extended by looking into available Hindi-Urdu transliteration systems[5,6] and other resources (Gupta, 2004; Malik et al., 2008; Jawaid and Ahmed, 2009). Each pair in the character map is assigned a cost. A Hindi character that always map to only one Urdu character is assigned a cost of 0 whereas the Hindi characters that map to different Urdu characters are assigned a cost of 0.2. The edit distance metric allows insert, delete and replace operations. The handcrafted pairs define the cost of replace operations. We set a cost of 0.6 for deletions and insertions. These costs were optimized on held out data. The details of optimization are not mentioned due to limited space. Using this metric we filte</context>
</contexts>
<marker>Gupta, 2004</marker>
<rawString>Swati Gupta. 2004. Aligning Hindi and Urdu bilingual corpora for robust projection. Masters project dissertation, Department of Computer Science, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Hal Daum´e</author>
</authors>
<title>Name translation in statistical machine translation - learning when to transliterate.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>389--397</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008. Name translation in statistical machine translation - learning when to transliterate. In Proceedings of ACL-08: HLT, pages 389–397, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bushra Jawaid</author>
<author>Tafseer Ahmed</author>
</authors>
<title>Hindi to Urdu conversion: beyond simple transliteration.</title>
<date>2009</date>
<booktitle>In Conference on Language and Technology</booktitle>
<location>Lahore, Pakistan.</location>
<contexts>
<context position="20111" citStr="Jawaid and Ahmed, 2009" startWordPosition="3270" endWordPosition="3273">se an edit distance algorithm to align this training corpus at the character level and we eliminate translation pairs with high edit distance which are unlikely to be transliterations. 4http://corpora.informatik.uni-leipzig.de/ n p(hn1|un1) = i=1 fin1 = arg max n pLM(ui|ui−1 u1 i=1 i−k)X (14) λpw(ui) + (1 − λ)pc(ui) λpw(hi, ui) + (1 − λ)pc(hi, ui) 469 We used our knowledge of the Hindi and Urdu scripts to define the initial character mapping. The mapping was further extended by looking into available Hindi-Urdu transliteration systems[5,6] and other resources (Gupta, 2004; Malik et al., 2008; Jawaid and Ahmed, 2009). Each pair in the character map is assigned a cost. A Hindi character that always map to only one Urdu character is assigned a cost of 0 whereas the Hindi characters that map to different Urdu characters are assigned a cost of 0.2. The edit distance metric allows insert, delete and replace operations. The handcrafted pairs define the cost of replace operations. We set a cost of 0.6 for deletions and insertions. These costs were optimized on held out data. The details of optimization are not mentioned due to limited space. Using this metric we filter out the word pairs with high edit-distance </context>
</contexts>
<marker>Jawaid, Ahmed, 2009</marker>
<rawString>Bushra Jawaid and Tafseer Ahmed. 2009. Hindi to Urdu conversion: beyond simple transliteration. In Conference on Language and Technology 2009, Lahore, Pakistan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehdi M Kashani</author>
<author>Eric Joanis</author>
<author>Roland Kuhn</author>
<author>George Foster</author>
<author>Fred Popowich</author>
</authors>
<title>Integration of an Arabic transliteration module into a statistical machine translation system.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7759" citStr="Kashani et al. (2007)" startWordPosition="1232" endWordPosition="1235">es such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Hindi Urdu SAMPA Gloss / simA Border/Seema / Amb@r Sky/Ambar / vId Ze Victory/Vijay Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts 466 on the fly whereas transliterations in Kashani et al. do not compete with internal phrase tables. They only compete amongst themselves</context>
</contexts>
<marker>Kashani, Joanis, Kuhn, Foster, Popowich, 2007</marker>
<rawString>Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George Foster, and Fred Popowich. 2007. Integration of an Arabic transliteration module into a statistical machine translation system. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 17–24, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="6530" citStr="Knight and Graehl, 1998" startWordPosition="1025" endWordPosition="1028">w improvements in the results as discussed in section 6. Section 7 gives two examples illustrating how our model decides whether to translate or transliterate and how it is able to choose among different valid transliterations given the context. Section 8 concludes the paper. 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on differen</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599–612.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Demonstration Program,</booktitle>
<location>Alexandra</location>
<contexts>
<context position="23615" citStr="Koehn et al., 2007" startWordPosition="3859" endWordPosition="3862">ters are optimized as described below. Because our training data is very sparse we do not use held-out data for parameter optimization. Instead we optimize these parameters by performing a 2-fold optimization for each of the 5 folds. Each fold is divided into two halves. The parameters A and 0 are optimized on the first half and the other half is used for testing, then optimization is done on the second half and the first half is used for testing. The optimal value for parameter A occurs between 0.7-0.84 and for the parameter 0 between 1e−5 and 1e−10. 4.2.2 Results Baseline Pb0: We ran Moses (Koehn et al., 2007) using Koehn’s training scripts10, doing a 5-fold cross validation with no reordering11. For the other parameters we use the default values i.e. 5-gram language model and maximum phraselength= 6. Again, the language model is imple7It should be noted though that diacritics play a very important role when transliterating in the reverse direction because these are virtually always written in Hindi as dependent vowels. 8www.crulp.org/software/langproc/urdunormalization.htm 9N is the number of aligned word pairs (tokens) and B is the number of different aligned word pairs (types). 10http://statmt.o</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Demonstration Program, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: A beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In AMTA,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="16234" citStr="Koehn, 2004" startWordPosition="2642" endWordPosition="2643">o used to estimate translation probabilities pw(hi|ui) previously). The character-based transliteration probability pc(hi, ui) and the character-based prior probability pc(ui) are defined by (5) and (7) respectively in 468 the previous section. Putting (11) and (12) in (10) we get λpw(hi, ui) + (1 − λ)pc(hi, ui) λpw(ui) + (1 − λ)pc(ui) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: 3.3 Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc(h, u). The joint probabilities given by pc(h, u) are marginalized for each Urdu transliteration to give pc(h|u). At the higher level, transliteration probabilities are interpolated with pw(h|u) and then multiplied with language model probabilities to give the probability of a hypothes</context>
<context position="34503" citStr="Koehn, 2004" startWordPosition="5646" endWordPosition="5647">tion to choose given the context. In the second example (shown in Figure 2) Hindi word can be translated to (peace, s@kun) when it is a common noun but transliterated to (Shanti, SAnt di) when it is a proper name. Our model successfully decides whether to translate or transliterate given the context. 8 Conclusion We have presented a novel way to integrate transliterations into machine translation. In closely related language pairs such as Hindi-Urdu with a significant amount of vocabulary overlap, 16We used Kevin Gimpel’s tester (http://www.ark.cs.cmu.edu/MT/) which uses bootstrap resampling (Koehn, 2004b), with 1000 samples. Ser d Z@ngl kA rAd ZA he “Lion is the king of jungle” AIqbAl kA Aek xub sur@t d Ser he “There is a beautiful verse from Iqbal” Figure 1: Different Transliterations in Different Contexts p hIr b hi vh s@kun se n@he˜rh s@kt dA “Even then he can’t live peacefully” Aom SAnt di Aom frhA xAn ki d dusri fIl@m he “Om Shanti Om is Farah Khan’s second film” Figure 2: Translation or Transliteration transliteration can be very effective in machine translation for more than just translating OOV words. We have addressed two problems. First, transliteration helps overcome the problem o</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004a. Pharaoh: A beam search decoder for phrase-based statistical machine translation models. In AMTA, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>388--395</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="16234" citStr="Koehn, 2004" startWordPosition="2642" endWordPosition="2643">o used to estimate translation probabilities pw(hi|ui) previously). The character-based transliteration probability pc(hi, ui) and the character-based prior probability pc(ui) are defined by (5) and (7) respectively in 468 the previous section. Putting (11) and (12) in (10) we get λpw(hi, ui) + (1 − λ)pc(hi, ui) λpw(ui) + (1 − λ)pc(ui) (13) The idea is to interpolate joint probabilities and divide them by the interpolated marginals. The final equation for Model-2 is given as: 3.3 Search The decoder performs a stack-based search using a beam-search algorithm similar to the one used in Pharoah (Koehn, 2004a). It searches for an Urdu string that maximizes the product of translation probability and the language model probability (equation 1) by translating one Hindi word at a time. It is implemented as a two-level process. At the lower level, it computes n-best transliterations for each Hindi word hi according to pc(h, u). The joint probabilities given by pc(h, u) are marginalized for each Urdu transliteration to give pc(h|u). At the higher level, transliteration probabilities are interpolated with pw(h|u) and then multiplied with language model probabilities to give the probability of a hypothes</context>
<context position="34503" citStr="Koehn, 2004" startWordPosition="5646" endWordPosition="5647">tion to choose given the context. In the second example (shown in Figure 2) Hindi word can be translated to (peace, s@kun) when it is a common noun but transliterated to (Shanti, SAnt di) when it is a proper name. Our model successfully decides whether to translate or transliterate given the context. 8 Conclusion We have presented a novel way to integrate transliterations into machine translation. In closely related language pairs such as Hindi-Urdu with a significant amount of vocabulary overlap, 16We used Kevin Gimpel’s tester (http://www.ark.cs.cmu.edu/MT/) which uses bootstrap resampling (Koehn, 2004b), with 1000 samples. Ser d Z@ngl kA rAd ZA he “Lion is the king of jungle” AIqbAl kA Aek xub sur@t d Ser he “There is a beautiful verse from Iqbal” Figure 1: Different Transliterations in Different Contexts p hIr b hi vh s@kun se n@he˜rh s@kt dA “Even then he can’t live peacefully” Aom SAnt di Aom frhA xAn ki d dusri fIl@m he “Om Shanti Om is Farah Khan’s second film” Figure 2: Translation or Transliteration transliteration can be very effective in machine translation for more than just translating OOV words. We have addressed two problems. First, transliteration helps overcome the problem o</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004b. Statistical significance tests for machine translation evaluation. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 388–395, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Zhang Min</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>159--166</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Barcelona,</location>
<contexts>
<context position="6547" citStr="Li et al., 2004" startWordPosition="1029" endWordPosition="1032">ults as discussed in section 6. Section 7 gives two examples illustrating how our model decides whether to translate or transliterate and how it is able to choose among different valid transliterations given the context. Section 8 concludes the paper. 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such a</context>
<context position="13430" citStr="Li et al., 2004" startWordPosition="2175" endWordPosition="2178">p(hi|ui) by interpolating a wordbased model and a character-based (transliteration) model. p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi|ui) (4) The parameters of the word-based translation model pw(h|u) are estimated from the word alignments of a small parallel corpus. We only retain 1-1/1-N (1 Hindi word, 1 or more Urdu words) alignments and throw away N-1 and M-N alignments for our models. This is further discussed in section 4.1.1. The character-based transliteration model pc(h|u) is computed in terms of pc(h, u), a joint character model, which is also used for ChineseEnglish back-transliteration (Li et al., 2004) and Bengali-English name transliteration (Ekbal et al., 2006). The character-based transliteration probability is defined as follows: pc(h, u) = � p(an1) ai ∈align(h,u) language model: p(ci|ci−1 i−k) (7) The parameters p(ci|ci−1 i−k) are estimated from the Urdu part of the character-aligned transliteration corpus. Replacing (6) in (4) we get: p(hi|ui) = λpw(hi|ui) + (1 − λ)pc(hi, ui) (8) pc(ui) Having all the components of our model defined we insert (8) and (2) in (1) to obtain the final equation: pLM(ui|ui−1 i−k)[λpw(hi|ui) + (1 − λ)pc(hi, ui)� (9) pc (ui ) The optimization of the interpola</context>
</contexts>
<marker>Li, Min, Jian, 2004</marker>
<rawString>Haizhou Li, Zhang Min, and Su Jian. 2004. A joint source-channel model for machine transliteration. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 159–166, Barcelona, Spain. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Abbas Malik</author>
<author>Christian Boitet</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Hindi Urdu machine transliteration using finite-state transducers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="6588" citStr="Malik et al., 2008" startWordPosition="1037" endWordPosition="1040">on 7 gives two examples illustrating how our model decides whether to translate or transliterate and how it is able to choose among different valid transliterations given the context. Section 8 concludes the paper. 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The first group is generic transliteration work, which is evaluated outside of the context of translation. This work uses either grapheme or phoneme based models to transliterate words lists (Knight and Graehl, 1998; Li et al., 2004; Ekbal et al., 2006; Malik et al., 2008). The work by Malik et al. addresses Hindi to Urdu transliteration using hand-crafted rules and a phonemic representation; it ignores translation context. A second group deals with out-of-vocabulary words for SMT systems built on large parallel corpora, and therefore focuses on name transliteration, which is largely independent of context. AlOnaizan and Knight (2002) transliterate Arabic NEs into English and score them against their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to res</context>
<context position="20086" citStr="Malik et al., 2008" startWordPosition="3266" endWordPosition="3269"> section 4.1.1. We use an edit distance algorithm to align this training corpus at the character level and we eliminate translation pairs with high edit distance which are unlikely to be transliterations. 4http://corpora.informatik.uni-leipzig.de/ n p(hn1|un1) = i=1 fin1 = arg max n pLM(ui|ui−1 u1 i=1 i−k)X (14) λpw(ui) + (1 − λ)pc(ui) λpw(hi, ui) + (1 − λ)pc(hi, ui) 469 We used our knowledge of the Hindi and Urdu scripts to define the initial character mapping. The mapping was further extended by looking into available Hindi-Urdu transliteration systems[5,6] and other resources (Gupta, 2004; Malik et al., 2008; Jawaid and Ahmed, 2009). Each pair in the character map is assigned a cost. A Hindi character that always map to only one Urdu character is assigned a cost of 0 whereas the Hindi characters that map to different Urdu characters are assigned a cost of 0.2. The edit distance metric allows insert, delete and replace operations. The handcrafted pairs define the cost of replace operations. We set a cost of 0.6 for deletions and insertions. These costs were optimized on held out data. The details of optimization are not mentioned due to limited space. Using this metric we filter out the word pairs</context>
</contexts>
<marker>Malik, Boitet, Bhattacharyya, 2008</marker>
<rawString>M G Abbas Malik, Christian Boitet, and Pushpak Bhattacharyya. 2008. Hindi Urdu machine transliteration using finite-state transducers. In Proceedings of the 22nd International Conference on Computational Linguistics, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Fast and accurate sentence alignment of bilingual corpora.</title>
<date>2002</date>
<booktitle>In Conference of the Association for Machine Translation in the Americas (AMTA).</booktitle>
<contexts>
<context position="17651" citStr="Moore (2002)" startWordPosition="2865" endWordPosition="2866">uning and recombination. Since our model uses monotonic decoding we only need to recombine hypotheses that have the same context (last n-1 words). Next we do histogram-based pruning, maintaining the 100- best hypotheses for each stack. 4 Evaluation 4.1 Training This section discusses the training of the different model components. 4.1.1 Translation Corpus We used the freely available EMILLE Corpus as our bilingual resource which contains roughly 13,000 Urdu and 12,300 Hindi sentences. From these we were able to sentence-align 7000 sentence pairs using the sentence alignment algorithm given by Moore (2002). The word alignments for this task were extracted by using GIZA++ (Och and Ney, 2003) in both directions. We extracted a total of 107323 alignment pairs (5743 N-1 alignments, 8404 MN alignments and 93176 1-1/1-N alignments). Of these alignments M-N and N-1 alignment pairs were ignored. We manually inspected a sample of 1000 instances of M-N/N-1 alignments and found that more than 70% of these were (totally or partially) wrong. Of the 30% correct alignments, roughly one-third constitute N-1 alignments. Most of these are cases where the Urdu part of the alignment actually consists of two (or th</context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>Robert C. Moore. 2002. Fast and accurate sentence alignment of bilingual corpora. In Conference of the Association for Machine Translation in the Americas (AMTA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17737" citStr="Och and Ney, 2003" startWordPosition="2879" endWordPosition="2882"> recombine hypotheses that have the same context (last n-1 words). Next we do histogram-based pruning, maintaining the 100- best hypotheses for each stack. 4 Evaluation 4.1 Training This section discusses the training of the different model components. 4.1.1 Translation Corpus We used the freely available EMILLE Corpus as our bilingual resource which contains roughly 13,000 Urdu and 12,300 Hindi sentences. From these we were able to sentence-align 7000 sentence pairs using the sentence alignment algorithm given by Moore (2002). The word alignments for this task were extracted by using GIZA++ (Och and Ney, 2003) in both directions. We extracted a total of 107323 alignment pairs (5743 N-1 alignments, 8404 MN alignments and 93176 1-1/1-N alignments). Of these alignments M-N and N-1 alignment pairs were ignored. We manually inspected a sample of 1000 instances of M-N/N-1 alignments and found that more than 70% of these were (totally or partially) wrong. Of the 30% correct alignments, roughly one-third constitute N-1 alignments. Most of these are cases where the Urdu part of the alignment actually consists of two (or three) words but was written without space because of lack of standard writing conventio</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore A Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<journal>IBM Research Division, Thomas J. Watson Research</journal>
<tech>Technical Report RC22176 (W0109-022),</tech>
<location>Center, Yorktown Heights, NY.</location>
<contexts>
<context position="5718" citStr="Papineni et al., 2001" startWordPosition="896" endWordPosition="899"> given situation. Some other examples are shown in Table 2. The remainder of this paper is organized as follows. Section 2 provides a review of previous work. Section 3 introduces two probabilistic models for integrating translations and transliterations into a translation model which are based on conditional and joint probability distributions. Section 4 discusses the training data, parameter optimization and the initial set of experiments that compare our two models with a baseline Hindi-Urdu phrasebased system and with two transliteration-aided phrase-based systems in terms of BLEU scores (Papineni et al., 2001). Section 5 performs an error analysis showing interesting weaknesses in the initial formulations. We remedy the problems by adding some heuristics and modifications to our models which show improvements in the results as discussed in section 6. Section 7 gives two examples illustrating how our model decides whether to translate or transliterate and how it is able to choose among different valid transliterations given the context. Section 8 concludes the paper. 2 Previous Work There has been a significant amount of work on transliteration. We can break down previous work into three groups. The</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore A. Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2001. BLEU: a method for automatic evaluation of machine translation. Technical Report RC22176 (W0109-022), IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ari Pirkola</author>
<author>Jarmo Toivonen</author>
<author>Heikki Keskustalo</author>
<author>Kari Visala</author>
<author>Kalervo J¨arvelin</author>
</authors>
<title>Fuzzy translation of cross-lingual spelling variants.</title>
<date>2003</date>
<booktitle>In SIGIR ’03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval,</booktitle>
<pages>345--352</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Pirkola, Toivonen, Keskustalo, Visala, J¨arvelin, 2003</marker>
<rawString>Ari Pirkola, Jarmo Toivonen, Heikki Keskustalo, Kari Visala, and Kalervo J¨arvelin. 2003. Fuzzy translation of cross-lingual spelling variants. In SIGIR ’03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 345–352, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mahesh K Sinha</author>
</authors>
<title>Developing English-Urdu machine translation via Hindi. In</title>
<date>2009</date>
<booktitle>Third Workshop on Computational Approaches to Arabic Scriptbased Languages (CAASL3), MT Summit XII,</booktitle>
<location>Ottawa, Canada.</location>
<contexts>
<context position="9171" citStr="Sinha (2009)" startWordPosition="1461" endWordPosition="1462">table dynamically such that they can directly compete with translations during decoding. This is closer to our approach except that we use transliteration as an alternative to translation for all Hindi words. Our focus is disambiguation of Hindi homonyms whereas they are concentrating only on transliterating NE’s. Moreover, they are working with a large bitext so they can rely on their translation model and only need to transliterate NEs and OOVs. Our translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead, </context>
</contexts>
<marker>Sinha, 2009</marker>
<rawString>R. Mahesh K. Sinha. 2009. Developing English-Urdu machine translation via Hindi. In Third Workshop on Computational Approaches to Arabic Scriptbased Languages (CAASL3), MT Summit XII, Ottawa, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Intl. Conf. Spoken Language Processing,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="10961" citStr="Stolcke, 2002" startWordPosition="1762" endWordPosition="1763">consist of more than one Urdu word3. The following sections give a math3This occurs frequently in case markers with nouns, derivational affixes and compounds etc. These are written as single words in Hindi as opposed to Urdu where they are ematical formulation of our two models, Model-1 and Model-2. 3.1 Model-1 : Conditional Probability Model Applying a noisy channel model to compute the most probable translation fin1, we get: arg max p(un1jhn1) = arg max p(un1)p(hn1jun1) un un 1 (1) 3.1.1 Language Model The language model (LM) p(un1) is implemented as an n-gram model using the SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. The parameters of the language model are learned from a monolingual Urdu corpus. The language model is defined as: pLM(uijui−1 i−k) (2) where k is a parameter indicating the amount of context used (e.g., k = 4 means 5-gram model). ui can be a single or a multi-word token. A multi-word token consists of two or more Urdu words. For a multi-word ui we do multiple language model look-ups, one for each ui. in ui = uil, ... , ui. and take their product to obtain the value pLM(uijui−1 i−k). Language Model for Unknown Words: Our model generates transliterations that can be </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Intl. Conf. Spoken Language Processing, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-lingual information retrieval.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multilingual and mixed-language named entity recognition,</booktitle>
<pages>57--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9639" citStr="Virga and Khudanpur, 2003" startWordPosition="1538" endWordPosition="1541"> translation model is based on data which is both sparse and noisy. Therefore we pit transliterations against translations for every input word. Sinha (2009) presents a rule-based MT system that uses Hindi as a pivot to translate from English to Urdu. This work also uses transliteration only for the translation of unknown words. Their work can not be used for direct translation from Hindi to Urdu (independently of English) “due to various ambiguous mappings that have to be resolved”. The third group uses transliteration models inside of a cross-lingual IR system (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Pirkola et al., 2003). Picking a single best transliteration or translation in context is not important in an IR system. Instead, all the options are used by giving them weights and context is typically not taken into account. 3 Our Approach Both of our models combine a character-based transliteration model with a word-based translation model. Our models look for the most probable Urdu token sequence un1 for a given Hindi token sequence hn1. We assume that each Hindi token is mapped to exactly one Urdu token and that there is no reordering. The assumption of no reordering is reasonable given</context>
</contexts>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-lingual information retrieval. In Proceedings of the ACL 2003 workshop on Multilingual and mixed-language named entity recognition, pages 57–64, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Nguyen Bach</author>
<author>Ian Lane</author>
<author>Stephan Vogel</author>
</authors>
<title>A log-linear block transliteration model based on bi-stream HMMs.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>364--371</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York.</location>
<contexts>
<context position="7631" citStr="Zhao et al. (2007)" startWordPosition="1209" endWordPosition="1212">ainst their respective translations using a modified IBM Model 1. The options are further re-ranked based on different measures such as web counts and using coreference to resolve ambiguity. These re-ranking methodologies can not be performed in SMT at the decoding time. An efficient way to compute and re-rank the transliterations of NEs and integrate them on the fly might be possible. However, this is not practical in our case as our model considers transliterations of all input words and not just NEs. A log-linear block transliteration model is applied to OOV NEs in Arabic to English SMT by Zhao et al. (2007). This work is also transliterating only NEs and not doing any disambiguation. The best method proposed by Kashani et al. (2007) integrates translations provided by external sources such as transliteration or rule-base translation of numbers and dates, for an arbitrary number of entries within the input text. Our work is different from Kashani et al. (2007) in that our model compares transliterations with translations Hindi Urdu SAMPA Gloss / simA Border/Seema / Amb@r Sky/Ambar / vId Ze Victory/Vijay Table 2: Hindi Words That Can Be Translated or Transliterated in Different Contexts 466 on the</context>
</contexts>
<marker>Zhao, Bach, Lane, Vogel, 2007</marker>
<rawString>Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vogel. 2007. A log-linear block transliteration model based on bi-stream HMMs. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 364–371, Rochester, New York. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>