<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9950025">
Chinese Named Entity Recognition Combining a Statistical Model with
Human Knowledge
</title>
<author confidence="0.93125">
Youzheng WU Jun ZHAO Bo XU
</author>
<affiliation confidence="0.9355375">
National Laboratory of Pattern Recognition
Institute of Automation Chinese Academy of Sciences
</affiliation>
<address confidence="0.943667">
No.95 Zhongguancun East Road, 100080, Beijing, China
</address>
<email confidence="0.998355">
(yzwu, jzhao,boxu)@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.99663" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999751285714286">
Named Entity Recognition is one of the
key techniques in the fields of natural
language processing, information retrieval,
question answering and so on.
Unfortunately, Chinese Named Entity
Recognition (NER) is more difficult for
the lack of capitalization information and
the uncertainty in word segmentation. In
this paper, we present a hybrid algorithm
which can combine a class-based
statistical model with various types of
human knowledge very well. In order to
avoid data sparseness problem, we
employ a back-off model and
/TONG YI CI CI LIN , a Chinese
thesaurus, to smooth the parameters in the
model. The F-measure of person names,
location names, and organization names
on the newswire test data for the 1999
IEER evaluation in Mandarin is 86.84%,
84.40% and 76.22% respectively.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996815875">
The NER task was first introduced as Message
Understanding Conference (MUC) subtask in 1995
(MUC-6). Named Entities were defined as entity
names (organizations, persons and locations),
temporal expressions (dates and times) and number
expressions (monetary values and percentages).
Compared with the entity name recognition, the
recognition of temporal and number expressions is
simpler. So, our research focuses on the
recognition of person, location and organization
names.
The Multilingual NE task first started in
1995(MET-1), including Chinese, Japanese, and
Spanish in that year, and continued for Chinese,
Japanese in 1998(MET-2). Compared with English
NER, Chinese NER is more difficult. We think the
main differences between Chinese NER and
English NER lie in:
First, unlike English, Chinese lacks the
capitalization information that plays an important
role in signaling named entities.
Second, there is no space between words in
Chinese, and we have to segment the text before
NER. However, the errors in word segmentation
will affect the result of NER.
Third, Different types of named entities have
different structures, especially for abbreviative
entities. Therefore, a single unified model can’t
capture all the types of entities. Typical structures
of Chinese person name (CN), location name (LN)
and organization name (ON) are as follows:
CN--&gt;&lt;surname&gt; &lt;given name&gt;
LN--&gt;&lt;name part&gt;* &lt;a salient word&gt;
ON--&gt;{[person name] [organization name] [place
name] [kernel name] }* [organization type] &lt;a
salient word&gt;
Here &lt;&gt;* means repeating one or several times.
{}* means selecting at least one of items.
Fourth, there are few openly available resources
for Chinese NER. Thus we have to resort to the
algorithm that doesn’t rely on large NER-tagged
text corpus.
Based on the above analysis, we present a
hybrid algorithm that incorporating various types
of human knowledge into a statistical model. The
innovative points of our paper are as follows.
First, the hybrid algorithm can make the best
use of existing limited resources to develop an
effective NER system. These resources include
one-month’s Chinese People’s Daily tagged with
NER tags by Peking University (which contains
about two-million Chinese characters) and various
types of human knowledge.
Second, in order to compensate for the lack of
labeled corpus, we use several types of human
knowledge, such as /TONG YI CI
CI LIN [Mei.J.J, et al. 1983], a general location
names list, the list of the salient words in location
name, the list of the salient words in organization
names, a Chinese surnames list, the list of Chinese
characters that could be included in transliterated
person names, and so on.
Third, we emphasize that human knowledge
and statistical information should be combined
very well. For example, a general LN list and a
general famous ON list are used in our system.
However, we only accept words in the lists as
entity candidates with a probability. Whether it is
a LN or ON depends on the context. This is
different from other systems which accept them as
a LN or ON once the system meets them. More
details refer to section 4.
This paper will be organized as follows. Section
2 is the background of NER. Section 3 describes
the class-based statistical baseline Chinese NER
model. Section 4 describes different types of
human knowledge for different named entities
recognitions and how to combine them with a
statistical model organically in details. Section 5 is
the evaluation and section 6 is the conclusion.
</bodyText>
<sectionHeader confidence="0.975397" genericHeader="introduction">
2 Backgroud
</sectionHeader>
<bodyText confidence="0.999922458333333">
The researches on English NER have made
impressive achievement. The best NER system
[Mikheev, et al. 1999] in MUC7 achieved 95%
precision and 92% recall. Recent methods for
English NER focus on machine-learning
algorithms such as DL-CoTrain, CoBoost [Collins
and Singer 1999], HMM [Daniel M. Bikel 1997],
maximum entropy model [Borthwick, et al, 1999]
and so on.
However, Chinese NER is still at its immature
phase. Typical Chinese NER systems are as
follows.
NTU system [Hsin-His Chen, et al. 1997] relied
on a statistical model when recognizing person
names, but rules when recognizing location and
organization names. In the formal run of MET-2,
the total F-measure is 79.61%. As a result, they
may miss the person names whose probability is
lower than the threshold, the location and
organization names may also be missed for those
which don’t accord with the rules.
[Yu et al. 1998] uses both a contextual model
and a morphological model. However, their system
requires information of POS tags, semantic tags
and NE lists. The system obtains 86.38% F-
measure.
[CHUA et al. 2000] employs a combination of
template-based rules supplemented by the default-
exception trees and decision tree that obtains over
91% F-measure on MET-2 test data. It also uses
HowNet [Dong &amp; Dong 2000] to cluster
semantically related words.
[Jian Sun, 2002] presents a class-based
language model for Chinese NER which achieves
81.79% F-measure on MET-2 test set and 78.75%
F-measure on IEER test data. However, the model
heavily depends on statistical information, and
must be trained on large labeled corpus.
For Chinese NER, we can’t achieve satisfactory
performance if we use only a statistical model or
handcrafted heuristic rules. Therefore, we have to
resort to the algorithm that can incorporate human
knowledge into a statistical model.
In the following sections, we will introduce a
statistical Chinese NER model first, and then
incorporate various types of human knowledge into
the statistical model in order to show the power of
human knowledge for Chinese NER.
</bodyText>
<sectionHeader confidence="0.942373" genericHeader="method">
3 The Baseline Class-based Statistical
Model
</sectionHeader>
<bodyText confidence="0.784852333333333">
We regard NER as a tagging problem. Given a
sequence of Chinese string W = w1w2 L wn, the task
of NER is to find the most likely sequence of class
sequence C* = c1c2 L cm (m &lt;= n) that maximizes
the probability P(C  |W). We use Bayes’ Rule to
rewrite P(C  |W) as equation (3.1):
</bodyText>
<equation confidence="0.998741">
P(C  |W) = P(C, W) = P(W  |C) × P(C) (3.1)
P( W) P(W)
</equation>
<bodyText confidence="0.99517">
So, the class-based baseline model can be
expressed as equation (3.2).
</bodyText>
<equation confidence="0.991385">
C* arg max ( ( ) ( ))
= P W C P C
 |×
C
= arg max(P(w1 w2 ... wn  |c1 c2 ... cm) × P(c1 c2 ... cm ))
C
arg max m wi1 ... wij  |ci )× P(ci  |ci−1 ))
C   ∏ P(
 i = 1
(3.2)
</equation>
<bodyText confidence="0.78433925">
We call P(C) as the contextual model and
P(W  |C) as the morphological model. Formally, we
can regard such a class-based statistical model as
ITMM. The classes used in our model are shown in
</bodyText>
<tableCaption confidence="0.93991">
Table 1, where |V |means the size of vocabulary
used for word segmentation.
</tableCaption>
<table confidence="0.999204125">
Class Description
PN Person Name
LN Location Name
ON Organization Name
TM Time Name
NM Number Name
Other One word is on Class
Total |V |+ 5
</table>
<tableCaption confidence="0.999532">
Table 1 Classes used in our model
</tableCaption>
<subsectionHeader confidence="0.979933">
3.1 Contextual Model
</subsectionHeader>
<bodyText confidence="0.978859888888889">
Due to our small-sized labeled corpus, we use a
statistical bi-gram language model as the
contextual model. This model can be described as
equation (3.3).
= 1
Theoretically, trigram is more powerful for
NER than bi-gram, however when training corpus
is small, trigram can’t work effectively. Using bi-
gram model, we still need ( )2
</bodyText>
<equation confidence="0.956556">
V + 5 transmission
</equation>
<bodyText confidence="0.998744">
probabilities, some of which can’t be observed in
our small-sized labeled corpus and some of which
are unauthentic. That is, data sparseness is still
serious. We will explain how to resolve data
sparseness problem in details in section 3 and 4.
</bodyText>
<subsectionHeader confidence="0.992421">
3.2 Morphological Model
</subsectionHeader>
<bodyText confidence="0.92874375">
TN) is a character-based tri
-states unigram model.
In principle, Chinese person name is composed
of a surname (including single-character surname
like &amp;quot; /wu&amp;quot; and double-character surname like&amp;quot;
P( /wu
The model for three-character-CN recognition
is described as equation (3.5).
</bodyText>
<equation confidence="0.998248545454545">
P(wj1wj2wj3  |cj = CN)
P(wj
cj = surCN)
P(wj2
≅
1
×
cj = midCN)
P(wj3 c
×
j =endCN)
</equation>
<bodyText confidence="0.9751665">
The model for two-character-CN recognition is
described as equation (3.6).
</bodyText>
<equation confidence="0.9955954">
P w w c CN
(  |= )
j j j
1 2
≅ P(wj1  |surCN)× P(wj2  |endCN)
</equation>
<bodyText confidence="0.999885">
For location names recognition, we use a word-
based bi-state unigram model, and divide words
used in the location name into two parts: location-
end-words (LE) and non-location-end words
(NLE). That means the probability of the word
used in the end position of location name is
different fr om that of in other position.
The model for location name recognition is
shown in equation (3.8).
</bodyText>
<equation confidence="0.997365">
P (wj1 wj2 ... wjk  |cj = LN) ≅
P(wji|cj = NLE)× P(wjk cj = LE)
</equation>
<bodyText confidence="0.981326">
om labeled training corpus.
estimated fr
i
/Ouyang&amp;quot;) and a given name (one or two
characters like &amp;quot; /peng&amp;quot; or &amp;quot; /youzheng&amp;quot;). So
we divide Chinese name words into three parts as
the surname (surCN), the middle name (midCN)
and the end name (endCN), which means the
probability of a specific character used in different
position in person names
</bodyText>
<equation confidence="0.9355271875">
equal. For example,
c; = surCN)
isn’t
|
≠ P( /wu  |c; = secCN) (3.4)
≠ P( /wu  |c; =endCN)
(3.5)
i = −
k 1
∏
i
= 1
i m
=
P( C)≅∏ P(ci  |ci−1) (3.3)
Recognition of Person Names
</equation>
<bodyText confidence="0.693702076923077">
The model of person names recognition
(including Chinese person names abbreviated to
CN and Transliterated person names abbreviated to
(3.6)
where
cj = CN)means the probability
of emitting the candidate person name
under the state of CN.
For TN, we
divide transliterated name
words into several different parts. That is, the
probability of a word used in different position in
TN is same. The model is as follows.
</bodyText>
<figure confidence="0.9073863125">
i=k
P(wj
k cj = TN)
P(wj
cj = TN)(3.7)
Must be mentioned is that all these probabilities
are estimated fr
P(wj1wj2wj3|
wj1wj2wj3
don’t
1
j2...
j
≅∏
i
i =
</figure>
<table confidence="0.721890666666667">
om labeled corpus using maximum
likelihood estimation.
Recognition of Location Names
(3.8)
The parameters in equation (3.8) are also
Recognition of Organization Names P = number of correct responses
</table>
<bodyText confidence="0.98293525">
For the model of organization names
recognition, we use bi-state unigram that is similar
to the location morphological model shown as
equation (3.9):
</bodyText>
<equation confidence="0.877217">
P(wj1wj2 ... wjk  |cj =ON) = (3.9)
</equation>
<bodyText confidence="0.99985025">
where OE means the word used in the end position
of organization name, while NOE is not.
The parameters in equation (3.9) are also
estimated from the labeled training corpus.
</bodyText>
<subsectionHeader confidence="0.84816">
Back-off Models to Smooth
</subsectionHeader>
<bodyText confidence="0.9998373">
Data sparseness problem still exists. As some
parameters were never observed in trained corpus,
the model will back off to a less-powerful model.
We employ escape probability to smooth the
statistical model [Teahan, et al. 1999].
An escape probability is the probability that a
previously unseen character will occur. There is no
theoretical basis for choosing the escape
probability optimally. Here we estimate the escape
probability in a particular context as:
</bodyText>
<equation confidence="0.984672666666667">
0. 5d
λ = (3.10)
n
</equation>
<bodyText confidence="0.9989295">
The probability of a word ci that has occurred c
times in that context ci-1 is:
</bodyText>
<equation confidence="0.99469">
P(ci  |ci−1) = c − 0.5 (3.11)
n
</equation>
<bodyText confidence="0.969765">
While the probability of a word that has never
occurred in that context is:
</bodyText>
<equation confidence="0.925775">
P(ci  |ci−1) = λ × P(ci) (3.12)
</equation>
<bodyText confidence="0.998948666666667">
where n is the number of times that context has
appeared and d is the number of different symbols
that have directly followed it.
As a example, if we observe the bi-gram &amp;quot;A B&amp;quot;
once in training corpus and “A C&amp;quot; three times, and
nowhere else did we see the word &amp;quot;A&amp;quot;, then
</bodyText>
<equation confidence="0.9742">
P(C  |A) = 3 − 1+3 3 , while the escape probability
0. 5 2
×
λ = and unseen transition probability of
1+3
P(D  |A) = λ× P(D) .
</equation>
<bodyText confidence="0.810332">
The Evaluation for the Baseline
The baseline model was evaluated in terms of
precision (P), recall (R) and F-measure (F) metrics.
number of responses
number of correct responses
number of all NE
</bodyText>
<equation confidence="0.9951605">
(β2 +1)× ×
P R (3.13)
( P) R
β × +
</equation>
<bodyText confidence="0.9966775">
where β is a weighted constant often set to 1.
We test the baseline system on the newswire
test data for the 1999 IEER evaluation in Mandarin
(http://www.nist.gov/speech/tests/ie-r/er_99/er_ 99.
htm). Table 2 in section 4 summarizes the result of
baseline model.
</bodyText>
<table confidence="0.9998696">
Precision Recall F-measure
PN 80.23% 89.55% 84.63%
LN 45.05% 66.96% 53.86%
ON 42.98% 61.45% 50.58%
Total 52.61% 71.53% 60.63%
</table>
<tableCaption confidence="0.999205">
Table 2 The Performance of The Baseline
</tableCaption>
<sectionHeader confidence="0.863267" genericHeader="method">
4 The Hybrid Model Incorporating
Human Knowledge into the Baseline
</sectionHeader>
<bodyText confidence="0.999961153846154">
From table 1, we find that the performance of
the above statistical baseline model isn’t
satisfactory. The problems mainly lie in:
Data sparseness is still serious though we
only use bi-gram contextual model, unigram
morphological model and smooth the parameters
with a back-off model.
In order to recognize the named entities,
we have to estimate the probability of every word
in text as named entities. Thus redundant
candidates not only enlarge search space but also
result in many unpredictable errors.
Abbreviative named entities especially
organization abbreviation can’t be resolved by the
baseline model. Because abbreviations have weak
statistical regularities, so can’t be captured by such
a baseline model.
We try to resolve these problems by
incorporating human knowledge. In fact, human
being usually uses prior knowledge when
recognizing named entities. In this section, we
introduce the human knowledge that is used for
NER and the method of how to incorporate them
into the baseline model.
Given a sequence of Chinese characters, the
recognition process after combined with human
</bodyText>
<equation confidence="0.956282">
P(wji  |cj = OE)× P(wjk  |cj = NOE)
=1
i
i k
= − 1
∏
R =
F=
</equation>
<bodyText confidence="0.699158">
knowledge consists of the five steps shown in Figure1.
</bodyText>
<figure confidence="0.993019333333333">
NE Pools
Text
Word Segmentation
Recognition Nested
Organization Names
Named Entities
Extract
Organization Kernel
PN and LN
</figure>
<figureCaption confidence="0.744375">
Figure 1 Recognition Process of the Hybrid Model
</figureCaption>
<figure confidence="0.99844775">
Human Knowledge
Generate
NE Candidates
TONG YI CI CI LIN
Search the Max.
P(C|W)
Nested Organization
Name Templates
</figure>
<subsectionHeader confidence="0.5735845">
4.1 Incorporate Knowledge for Person Name
Recognition
</subsectionHeader>
<bodyText confidence="0.998682535714286">
Chinese person names are composed of a
surname and a given name. Usually the characters
used for Chinese person names are limited.
[Maosong Sun, Changning Huang, 1994] presents
365 most high frequently used surnames cover
99% Chinese surnames. 1141 most high frequently
used characters cover 99% Chinese given names.
Similarly the characters used for transliterated
names are also limited. We extract about 476
transliterated characters from the training corpus.
The following is the human knowledge used for
person name recognition and the method of how to
incorporate them into the baseline.
A Chinese single and plural surname list:
Only those characters in the surname list can
trigger person name recognition.
A list of person title list: Only when the
current character belongs to the surname list and
the next word is in the title list, candidates are
accepted.
A transliterated character list: Only
those consecutive characters in the transliterated
character list form a candidate transliterated name.
Person name can’t span any punctuation
and the length of CN can’t exceed 8 characters
while the length of TN is unrestrained.
All these knowledge are used for restricting
search space.
</bodyText>
<subsectionHeader confidence="0.987751">
4.2 Incorporate Knowledge for Location
Name Recognition
</subsectionHeader>
<bodyText confidence="0.979798972972973">
A complete location name is composed of the
name part and a salient word. For the location
name &amp;quot; /Beijing City&amp;quot;, the name part is &amp;quot;
/Beijing&amp;quot; and the salient word is &amp;quot; /city&amp;quot;.
Unfortunately, the salient word is omitted in many
occasions. So it is unfeasible to trigger LN
recognition only depending on the salient words in
location name. In order to improve the precision
and recall of LN recognition, we use the following
human knowledge. The method of incorporating
them is also explained.
A general location name list: The list
includes the names of Chinese provinces and
counties, foreign country and its capitals, some
famous geographical names and foreign cities. If
the current word is in the list, we accept it as a
candidate LN.
A location salient word list: If the word
w; belongs to the list, 2~6 words before the salient
word are accepted as candidate LNs.
A general word list (such as verbs and
prepositions) which usually is followed by a
location name, such as &amp;quot; /at&amp;quot;, &amp;quot; /go&amp;quot;. If the
word w; is in the list, 2~6 words following it are
accepted as candidate LNs.
An abbreviative location name list: If the
current word is in the list, we accept it as a
candidate LN such as &amp;quot; /China&amp;quot;, &amp;quot; /America&amp;quot;.
Coordinate LN recognition: If w;_2 is a
candidate LN and w;_1 is &amp;quot; &amp;quot;(a punctuation
denoting coordinate relation), LN recognition is
triggered at the position of word w;.
Location name can’t span punctuations and
its length couldn’t exceed 6 words.
Knowledge , , , , can restrict
search space while knowledge deals with
abbreviative location name.
</bodyText>
<subsectionHeader confidence="0.999585">
4.3 Incorporate Knowledge for Organization
Name Recognition
</subsectionHeader>
<bodyText confidence="0.99926765">
The organization names recognition is the most
difficult task. The reasons lie in nested ONs and
abbreviative ONs especially.
Nested ON means there are one or more
location names, person names and/or organization
names embedded in organization name. Typical
structure of ON has been given in section 1. We
can capture most of the nested organization names
by several ON templates mentioned in the
following section.
Abbreviative ONs include continuous and
discrete abbreviation which omits some words in
the full name. Take &amp;quot;
&amp;quot; as example, abbreviative ON of it may omit LN &amp;quot;
/Shanghai&amp;quot;, organization types like&amp;quot;
/supermarket&amp;quot;, &amp;quot; /stock&amp;quot;, &amp;quot; /limited&amp;quot;, and
salient word like &amp;quot; /company&amp;quot; from full names
but usually remains organization kernel &amp;quot;
/Hualian&amp;quot;. Table 3 lists some examples of
abbreviative ONs.
</bodyText>
<table confidence="0.996796333333333">
Continuous Shanghai Hualian Shanghai
Abbreviation Co.,Ltd Hualian
Tsinghua niversity Tsinghua
Discrete Shanghai Stock Shanghai
Abbreviation Exchange Stock
Peking University Bei Da
</table>
<tableCaption confidence="0.988096">
Table 3 Nest Organization Full Names and Its
Abbreviative Names
</tableCaption>
<bodyText confidence="0.981473181818182">
So it is important to extract organization kernel
from the full name in order to recognize
abbreviative ON like &amp;quot; &amp;quot;. Moreover, an
organization&apos;s abbreviative names usually occur
after its&apos; full name, unless it is a well-known
organization. So this strategy for abbreviation
organization name recognition is effective.
The following is the human knowledge used for
ON recognition and the method of how to
incorporate them.
An organization salient word (OrgSws)
list: If the current word w; is in OrgSws list, 2~6
words before OrgSw are accepted as the candidate
ONs.
A general famous organization name list:
If the current word is in the list, we accept it as a
candidate ON such as &amp;quot; / State Department&amp;quot;,
&amp;quot; / U.N. &amp;quot;.
An organization names template list: We
mainly use organization name templates to
recognize the nested ONs. Some of these templates
are as follows:
</bodyText>
<sectionHeader confidence="0.781626333333333" genericHeader="method">
ON--&gt;LN D* OrgSw
ON--&gt;PN D* OrgSw
ON--&gt;ON OrgSw
</sectionHeader>
<bodyText confidence="0.9990821875">
D means words used in the middle of organization
names. D* means repeating zero or more times.
This component runs in the end stage of
recognition process shown in Figure 1.
An organization type list: The list is used
to extract organization kernels from recognized
ONs. We have a pool which memorizes ONs
recognized in current paragraph and its kernel. If
the current word belongs to organization kernel in
pool, we accept it as a candidate ON. The idea is
effective especially in financial domain which
contains many stocks such as&amp;quot; /Shanghai
Hualian&amp;quot;, &amp;quot; /Changjiang Technology&amp;quot;.
Knowledge , , restrict search space
while knowledge deals with abbreviative
organization name.
</bodyText>
<subsectionHeader confidence="0.9979325">
4.4 Semantic Similarity Computation for
Data Sparseness
</subsectionHeader>
<bodyText confidence="0.884492636363636">
/TONG YI CI CI LIN classifies
the words in terms of semantic similarity. Here we
use it to resolve data sparseness problem. If current
transmission probability doesn’t exist, we resort to
its synonym transmission. In statistical sense,
synonym transmissions are approximate. Take an
example, the probability of P(A|B) doesn’t exist,
but there has P(C|B), meanwhile, the word A and
C are thesaurus according to /TONG
YI CI CI LIN , then we use P(C|B) to replace
P(A|B).
</bodyText>
<sectionHeader confidence="0.993947" genericHeader="evaluation">
5 Results of Evaluation
</sectionHeader>
<bodyText confidence="0.96369">
We also test our hybrid model on IEER-99 neswire
test data. The performance is shown in Table 4.
</bodyText>
<table confidence="0.9998162">
Precision Recall F-measure
PN 83.30% 92.28% 87.56%
LN 88.31% 84.69% 86.47%
ON 84.49% 71.08% 77.21%
Total 86.09% 83.18% 84.61%
</table>
<tableCaption confidence="0.999755">
Table 4 The Performance of the Hybrid Model
</tableCaption>
<bodyText confidence="0.984971136363637">
Comparing Table 1 with 4, we find that the
performance of the hybrid model increases
remarkably. More specifically, the precision and
the recall of PNs increase from 80.23% to 83.30%
and from 89.55% to 92.28% respectively. The
precision and recall of LNs increase from 45.05%
to 82.18% and from 66.96% to 86.74%
respectively. The precision and recall of ONs
increase from 42.98% to 80.86% and from 61.45%
to 72.09% respectively. The reason that the
improvement of PNs is slighter than that of ONs
and LNs is that the statistical information
estimated from labeled corpus for PNs is good
enough but not for LNs and ONs.
Must be mentioned is that, in our evaluation,
only NEs with both correct boundary and correct
type label are considered as the correct
recognitions, which is a little different from other
evaluation systems.
We also test our system on data set of sport,
finance, news and entertainment domains. These
test data are downloaded from Internet shown in
</bodyText>
<tableCaption confidence="0.884099">
Table 4.
</tableCaption>
<table confidence="0.99714975">
Domain Number of NE File
size
PN LN ON
Sport(S) 954 510 609 91K
Finance(F) 212 406 461 80K
News(N) 526 961 437 76K
Entertainment(E) 1016 511 133 100K
Total 2708 2388 1640 247K
</table>
<tableCaption confidence="0.8863165">
Table 4 Statistic of Multi-field Test Data
The results are shown in Table 5.
</tableCaption>
<table confidence="0.999986357142857">
Precision Recall F-measure
PN S 80.17% 91.10% 85.28%
F 61.35% 94.34% 74.35%
N 88.66% 83.27% 85.88%
E 82.20% 82.28% 82.24%
LN S 82.90% 81.76% 82.33%
F 83.72% 81.03% 82.35%
N 91.95% 91.56% 91.75%
E 81.64% 87.87% 84.64%
ON S 73.43% 67.16% 70.15%
F 65.88% 60.30% 62.97%
N 92.52% 84.70% 88.44%
E 78.30% 62.41% 69.46%
Total 81.01% 81.24% 81.12%
</table>
<tableCaption confidence="0.999655">
Table 5 Results on different domain
</tableCaption>
<bodyText confidence="0.973871192307692">
Table 5 shows that the performance on financial
domain is much lower. The reason is that, in
financial domain, there are many stock names
which are the abbreviation of organization names.
Moreover, organization full name never appear in
the text. So the system can’t recognize them as an
organization name. However, on many occasions,
they are recognized as person names. As a result,
the precision of PNs declines, meanwhile, the
precision and recall of ONs can’t be high.
Based on the above analysis, we find that the
main sources of errors in our system are as follows.
First, we still have not found a good strategy for
the abbreviation location names and organization
names. Because abbreviative LNs and ONs
sometimes appear before full LN, sometimes not,
so the pool strategy can’t work well.
Second, some famous organization names that
always appear in the shape of abbreviation can’t be
recognized as ON because the full name never
appear such as /GaoTong, /Xinlang.
However, these ONs are often recognized as PNs.
Such errors are especially serious in finance
domain shown Table 5.
Third, many words can’t be found in
/TONG YI CI CI LIN .
</bodyText>
<sectionHeader confidence="0.999317" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9999125">
Chinese NER is a more difficult task than English
NER. Though many approaches have been tried,
the result is still not satisfactory. In this paper, we
present a hybrid algorithm of incorporating human
knowledge into statistical model. Thus we only
need a relative small-sized labeled corpus (one-
month’s Chinese People’s Daily tagged with NER
tags at Peking University) and human knowledge,
but can achieve better performance. The main
contribution of this paper is putting forward an
approach which can make up for the limitation of
using the statistical model or human knowledge
purely by combining them organically.
Our lab was mainly devoted to cross-language
information processing and its application. So in
the future we will shift our algorithm to other
languages. And fine-tune to a specific domain such
as sports.
</bodyText>
<sectionHeader confidence="0.999648" genericHeader="acknowledgments">
ACKNOWLEDGEMENT
</sectionHeader>
<bodyText confidence="0.998061">
This paper is supported by the National “973”
project G1998030501A-06 and the Natural Science
Foundation of China 60272041.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993989346938776">
Jian Sun, et al. 2002. Chinese Named Entity
Identification Using Class-based Language Model.
Proceedings of the 19th International Conference on
Computational Linguistics
Hsin-His Chen, et al. 1997. Description of the NTU
System Used for MET2. Proceedings of the Seventh
Message Understanding Conference
Tat-Seng Chua, et al. 2002. Learning Pattern Rules for
Chinese Named Entity Extraction. Proceedings of
AAAI’02
W.J.Teahan, et al. 1999. A Compression-based
Algorithm for Chinese Word Segmentation.
Computational Linguistic 26(2000) 375-393
Maosong Sun, et al. 1994. Identifying Chinese Names in
Unrestricted Texts. Journal of Chinese Information
Processing. 1994,8(2)
Collins, Singer. 1999. Unsupervised Models for Named
Entity Classification. Proceedings of 1999 Joint
SIGDAT Conference on Empirical Methods in NLP
and Very Large Corpora
Daniel M. Bikel, et al. 1997. Nymble: a High-
Performance Learning Name-finder. Proceedings of
ANLP-97, page 194-201, 1997
Yu et al. 1998. Description of the Kent Ridge Digital
Labs System Used for MUC-7. Proceedings of the
Seventh Message Understanding Conference
Silviu Cucerzan, David Yarowsky. 1999. Language
Independent Named Entity Recognition Combining
Morphological and Contextual Evidence.
Proceedings 1999 Joint SIGDAT Conference on
EMNLP and VLC
Peter F.Brown, et al. 1992. Class-Based n-gram Model
of Natural Language. 1992 Association for
Computational Linguistics
A.Mikheev, M.Moens, and C.Grover. 1999. Named
entity recognition without gazetteers. Proceedings of
the Ninth Conference of the European Chapter of the
Association for Computational Linguistics. Bergen,
Norway
Borthwich. A. 1999. A Maximum Entropy Approach to
Named Entity Recognition. PhD Dissertation
Dong &amp; Dong. 2000. Hownet. At: http://www.keenage.
com
Yu.S.W. 1999. The Specification and Manual of
Chinese Word Segmentation and Part of Speech
Tagging. At: http://www.icl.pku.edu.cn/Introduction/
corpustagging. htm
Mei.J.J, et al. 1983. /TONG YI CI CI
LIN . Shanghai CISHU Press
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.519584">
<title confidence="0.924079">Chinese Named Entity Recognition Combining a Statistical Model Human Knowledge</title>
<author confidence="0.995951">Youzheng WU Jun ZHAO Bo XU</author>
<affiliation confidence="0.9992775">National Laboratory of Pattern Recognition Institute of Automation Chinese Academy of Sciences</affiliation>
<address confidence="0.998252">No.95 Zhongguancun East Road, 100080, Beijing, China</address>
<email confidence="0.993819">(yzwu,jzhao,boxu)@nlpr.ia.ac.cn</email>
<abstract confidence="0.978661454545455">Named Entity Recognition is one of the key techniques in the fields of natural language processing, information retrieval, question answering and so on. Unfortunately, Chinese Named Entity Recognition (NER) is more difficult for the lack of capitalization information and the uncertainty in word segmentation. In this paper, we present a hybrid algorithm which can combine a class-based statistical model with various types of human knowledge very well. In order to avoid data sparseness problem, we employ a back-off model and YI CI CI LIN a Chinese thesaurus, to smooth the parameters in the model. The F-measure of person names, location names, and organization names on the newswire test data for the 1999 IEER evaluation in Mandarin is 86.84%, 84.40% and 76.22% respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jian Sun</author>
</authors>
<title>Chinese Named Entity Identification Using Class-based Language Model.</title>
<date>2002</date>
<booktitle>Proceedings of the 19th International Conference on Computational Linguistics</booktitle>
<contexts>
<context position="5960" citStr="Sun, 2002" startWordPosition="934" endWordPosition="935">ose probability is lower than the threshold, the location and organization names may also be missed for those which don’t accord with the rules. [Yu et al. 1998] uses both a contextual model and a morphological model. However, their system requires information of POS tags, semantic tags and NE lists. The system obtains 86.38% Fmeasure. [CHUA et al. 2000] employs a combination of template-based rules supplemented by the defaultexception trees and decision tree that obtains over 91% F-measure on MET-2 test data. It also uses HowNet [Dong &amp; Dong 2000] to cluster semantically related words. [Jian Sun, 2002] presents a class-based language model for Chinese NER which achieves 81.79% F-measure on MET-2 test set and 78.75% F-measure on IEER test data. However, the model heavily depends on statistical information, and must be trained on large labeled corpus. For Chinese NER, we can’t achieve satisfactory performance if we use only a statistical model or handcrafted heuristic rules. Therefore, we have to resort to the algorithm that can incorporate human knowledge into a statistical model. In the following sections, we will introduce a statistical Chinese NER model first, and then incorporate variou</context>
</contexts>
<marker>Sun, 2002</marker>
<rawString>Jian Sun, et al. 2002. Chinese Named Entity Identification Using Class-based Language Model. Proceedings of the 19th International Conference on Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-His Chen</author>
</authors>
<title>Description of the NTU System Used for MET2.</title>
<date>1997</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference</booktitle>
<marker>Chen, 1997</marker>
<rawString>Hsin-His Chen, et al. 1997. Description of the NTU System Used for MET2. Proceedings of the Seventh Message Understanding Conference</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tat-Seng Chua</author>
</authors>
<title>Learning Pattern Rules for Chinese Named Entity Extraction.</title>
<date>2002</date>
<booktitle>Proceedings of AAAI’02</booktitle>
<marker>Chua, 2002</marker>
<rawString>Tat-Seng Chua, et al. 2002. Learning Pattern Rules for Chinese Named Entity Extraction. Proceedings of AAAI’02</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Teahan</author>
</authors>
<title>A Compression-based Algorithm for Chinese Word Segmentation.</title>
<date>1999</date>
<journal>Computational Linguistic</journal>
<volume>26</volume>
<issue>2000</issue>
<pages>375--393</pages>
<marker>Teahan, 1999</marker>
<rawString>W.J.Teahan, et al. 1999. A Compression-based Algorithm for Chinese Word Segmentation. Computational Linguistic 26(2000) 375-393</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maosong Sun</author>
</authors>
<title>Identifying Chinese Names in Unrestricted Texts.</title>
<date>1994</date>
<journal>Journal of Chinese Information Processing.</journal>
<volume>8</volume>
<issue>2</issue>
<marker>Sun, 1994</marker>
<rawString>Maosong Sun, et al. 1994. Identifying Chinese Names in Unrestricted Texts. Journal of Chinese Information Processing. 1994,8(2)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Singer Collins</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>Proceedings of 1999 Joint SIGDAT Conference on Empirical Methods in NLP and Very Large Corpora</booktitle>
<marker>Collins, 1999</marker>
<rawString>Collins, Singer. 1999. Unsupervised Models for Named Entity Classification. Proceedings of 1999 Joint SIGDAT Conference on Empirical Methods in NLP and Very Large Corpora</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>Nymble: a HighPerformance Learning Name-finder.</title>
<date>1997</date>
<booktitle>Proceedings of ANLP-97,</booktitle>
<pages>194--201</pages>
<contexts>
<context position="4927" citStr="Bikel 1997" startWordPosition="764" endWordPosition="765">escribes the class-based statistical baseline Chinese NER model. Section 4 describes different types of human knowledge for different named entities recognitions and how to combine them with a statistical model organically in details. Section 5 is the evaluation and section 6 is the conclusion. 2 Backgroud The researches on English NER have made impressive achievement. The best NER system [Mikheev, et al. 1999] in MUC7 achieved 95% precision and 92% recall. Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al, 1999] and so on. However, Chinese NER is still at its immature phase. Typical Chinese NER systems are as follows. NTU system [Hsin-His Chen, et al. 1997] relied on a statistical model when recognizing person names, but rules when recognizing location and organization names. In the formal run of MET-2, the total F-measure is 79.61%. As a result, they may miss the person names whose probability is lower than the threshold, the location and organization names may also be missed for those which don’t accord with the rules. [Yu et al. 1998] uses both a co</context>
</contexts>
<marker>Bikel, 1997</marker>
<rawString>Daniel M. Bikel, et al. 1997. Nymble: a HighPerformance Learning Name-finder. Proceedings of ANLP-97, page 194-201, 1997</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu</author>
</authors>
<title>Description of the Kent Ridge Digital Labs System Used for MUC-7.</title>
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference</booktitle>
<marker>Yu, 1998</marker>
<rawString>Yu et al. 1998. Description of the Kent Ridge Digital Labs System Used for MUC-7. Proceedings of the Seventh Message Understanding Conference</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
<author>David Yarowsky</author>
</authors>
<title>Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence.</title>
<date>1999</date>
<booktitle>Proceedings 1999 Joint SIGDAT Conference on EMNLP and VLC</booktitle>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>Silviu Cucerzan, David Yarowsky. 1999. Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence. Proceedings 1999 Joint SIGDAT Conference on EMNLP and VLC</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
</authors>
<title>Class-Based n-gram Model of Natural Language.</title>
<date>1992</date>
<journal>Association for Computational Linguistics</journal>
<marker>Brown, 1992</marker>
<rawString>Peter F.Brown, et al. 1992. Class-Based n-gram Model of Natural Language. 1992 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moens A Mikheev</author>
<author>C Grover</author>
</authors>
<title>Named entity recognition without gazetteers.</title>
<date>1999</date>
<booktitle>Proceedings of the Ninth Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<location>Bergen, Norway</location>
<marker>Mikheev, Grover, 1999</marker>
<rawString>A.Mikheev, M.Moens, and C.Grover. 1999. Named entity recognition without gazetteers. Proceedings of the Ninth Conference of the European Chapter of the Association for Computational Linguistics. Bergen, Norway</rawString>
</citation>
<citation valid="true">
<authors>
<author>A</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<journal>PhD Dissertation Dong</journal>
<note>Hownet. At: http://www.keenage. com</note>
<marker>A, 1999</marker>
<rawString>Borthwich. A. 1999. A Maximum Entropy Approach to Named Entity Recognition. PhD Dissertation Dong &amp; Dong. 2000. Hownet. At: http://www.keenage. com</rawString>
</citation>
<citation valid="true">
<authors>
<author>S W Yu</author>
</authors>
<title>The Specification and Manual of Chinese Word Segmentation and Part of Speech Tagging. At: http://www.icl.pku.edu.cn/Introduction/ corpustagging. htm</title>
<date>1999</date>
<marker>Yu, 1999</marker>
<rawString>Yu.S.W. 1999. The Specification and Manual of Chinese Word Segmentation and Part of Speech Tagging. At: http://www.icl.pku.edu.cn/Introduction/ corpustagging. htm</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Mei</author>
</authors>
<date>1983</date>
<journal>TONG YI CI CI LIN . Shanghai</journal>
<publisher>CISHU Press</publisher>
<marker>Mei, 1983</marker>
<rawString>Mei.J.J, et al. 1983. /TONG YI CI CI LIN . Shanghai CISHU Press</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>