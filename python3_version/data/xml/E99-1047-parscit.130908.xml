<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003613">
<note confidence="0.717611">
Proceedings of EACL &apos;99
</note>
<title confidence="0.973276">
p-TBL Lite: A Small, Extendible
Transformation-Based Learner
</title>
<author confidence="0.995213">
Torbjorn Lager
</author>
<affiliation confidence="0.8006255">
Department of Linguistics
Uppsala University
SWEDEN
Torbjorn.Lager©ling.uu.se
</affiliation>
<sectionHeader confidence="0.994852" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9930146">
This short paper describes — and in fact
gives the complete source for — a tiny
Prolog program implementing a flexi-
ble and fairly efficient Transformation-
Based Learning (TBL) system.
</bodyText>
<sectionHeader confidence="0.999378" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999420555555556">
Transformation-Based Learning (Brill, 1995) is a
well-established learning method in NLP circles.
This short paper presents a &apos;light&apos; version of the
1L-TBL system — a general, logically transparent,
flexible and efficient transformation-based learner
presented in (Lager, 1999). It turns out that
a transformation-based learner, complete with a
compiler for templates, can be implemented in less
than one page of Prolog code.
</bodyText>
<sectionHeader confidence="0.834625" genericHeader="method">
2 p-TBL Rules &amp; Representations
</sectionHeader>
<bodyText confidence="0.975673193548387">
The point of departure for TBL is a tagged initial-
state corpus and a correctly tagged training cor-
pus. Assuming the part-of-speech tagging task,
corpus data can be represented by means of three
kinds of clauses:
vd(P,W) is true if the word W is at position P in the
corpus
tag(P,A) is true if the word at position P in the
corpus is tagged A
tag(A,B,P) is true if the word at P is tagged A and
the correct tag for the word at P is B
Although this representation may seem a bit re-
dundant, it provides exactly the kind of indexing
into the data that is needed.&apos; A decent Prolog
system can deal with millions of such clauses.
lAssuming a Prolog with first argument indexing.
The A-TBI, systems are implemented in SICStus Pro-
log.
The object of TBL is to learn an ordered se-
quence of transformation rules. Such rules dictate
when — based on the context — a word should have
its tag changed. An example would be &amp;quot;replace
tag vb with nn if the word immediately to the left
has a tag dt.&amp;quot; Here is how this rule is represented
in the it-TBL rule/template formalism:
tag : vb&gt;nn. &lt;- tag: dt0 [-1] .
Conditions may refer to different features, and
complex conditions may be composed from sim-
pler ones. For example, here is a rule saying &amp;quot;re-
place tag rb with jj, if the current word is &amp;quot;only&amp;quot;,
and if one of the previous two tags is dt.&amp;quot;:
</bodyText>
<equation confidence="0.913153">
tag:rb&gt;jj &lt;- wd:only@[0] &amp; tag:dte[-1,-2].
</equation>
<bodyText confidence="0.97068775">
Rules that can be learned in TBL are instances
of templates, such as &amp;quot;replace tag A with B if the
word immediately to the left has tag C&amp;quot;, where A,
B and C are variables. In the /L-TBL formalism:
</bodyText>
<equation confidence="0.957384">
t3(A,B,c) # tag:A&gt;B &lt;- tag:C@[-1].
</equation>
<bodyText confidence="0.999637">
Positive and negative instances of rules that are
instances of this template can be generated by
means of the following clauses:
</bodyText>
<equation confidence="0.99904075">
pos(t3(A,B,C)) :-
dif(A,B),tag(A,B,P),P1 is P-1,tag(P1,C).
neg(t3(A,B,C)) :-
tag(A,A,P),P1 is P-1,tag(P1,C).
</equation>
<bodyText confidence="0.8383115">
Tied to each template is also a procedure that will
apply rules that are instances of the template:
</bodyText>
<equation confidence="0.88539">
app(t3(A,B,C)) :-
(tag(A,X,P), P1 is P-1, tag(P1,C),
</equation>
<construct confidence="0.701218">
retract (tag (A , X ,P) ) , retract (tag (P , A) ) ,
assert (tag (B , X ,P)) , assert (tag (P ,B) ) ,
fail ; true).
</construct>
<sectionHeader confidence="0.996421" genericHeader="method">
3 The p-TBL Template Compiler
</sectionHeader>
<bodyText confidence="0.9998694">
To write clauses such as the above by hand for
large sets of templates would be tedious and prone
to errors. Instead, Prolog&apos;s term expansion facil-
ity, and a couple of DCG rules, can be used to
compile templates into Prolog code, as follows:
</bodyText>
<page confidence="0.960659">
279
</page>
<equation confidence="0.936027">
Proceedings of EACL &apos;99
A&lt;-Cs),
(G3,fail;true))])
), list2goal(L1,G1),
), list2goal(L2,G2),
), list2goal(L3,G3).
pos((F:A&gt;B&lt;-Cs)) --&gt;
fG =.. [F,A,B,P7I,[dif(A,B),G], cond(Cs,P)
neg((F:A&gt;_&lt;-Cs)) --&gt;
=.. [F,A,A,P11, [G], cond(Cs,P).
app((F:A&gt;B&lt;-Cs)) --&gt;
fG1 =.. [F,A,X,P], G2 =.. [F,P,A],
G3 =.. [F,B,X,P], G4 =.. [F,P,B]1,
[G1], cond(Cs,P), [retract(G1),
retract(G2), assert(G3), assert(G4)].
cond((=s),P) --&gt; cond(C,P), cond(Cs,P).
cond(FACPos,P0) --&gt; pos(Pos,PO,P), feat(FA,P).
pos(Pos,PO,P) --&gt;
[nember(Offset,Pos), P is PO+Offset].
feat(F:A,P) --&gt; =.. [F,P,A]l, [G].
</equation>
<sectionHeader confidence="0.811437" genericHeader="method">
4 The p-TI3L Lite Learner
</sectionHeader>
<bodyText confidence="0.999828">
Given corpus data, compiled templates, and a
value for Threshold, the predicate tb1/1 imple-
ments the p,-TBL main loop, and writes a se-
quence of rules to the screen:
</bodyText>
<equation confidence="0.974767818181818">
tbl(Threshold) :-
( setof(N-Rule,L-(bagof(.,pos(Rule),L),
length(L,N), N &gt;= Threshold),FL),
reverse(FL,RevFL),
bestof(RevFL,dummy,Threshold,Winner),
dif(Winner,dummy)
-&gt; write(Winner),n1,
app(Winner),
tbl(Threshold)
; true
).
</equation>
<bodyText confidence="0.999017833333333">
The call to the setof-bagof combination generates
a frequency listing of all positive instances of all
templates, based on which the call to bestof /4
then selects the rule with the highest score. tb1/1
terminates if the score for that rule is less than the
threshold, else it applies the rule and goes on to
learn more rules from there.
To compute the rule with the highest score,
bestof/4 traverses the frequency listing, keeping
track of a leading rule and its score. The score of
a rule is calculated as the difference between the
number of its positive instances and its negative
instances. When the list of rules is empty or the
number of positive instances of the most frequent
rule in what remains of the list is less than the
leading rules score, the leader is declared winner.
The following procedure implements the count-
ing of negative instances in an efficient way:
</bodyText>
<equation confidence="0.8078432">
countO(G,M,N) :-
( bb_put(c,0), G, bb_get(c,N0),
N is NO+1, bb_put(c,N), N &gt; M
-&gt; fail
; bb_get(c,N)
</equation>
<sectionHeader confidence="0.982437" genericHeader="conclusions">
5 ii-TI3L Lite Performance
</sectionHeader>
<bodyText confidence="0.99016192">
The learner was benchmarked on a 250Mhz Sun
Ultra Enterprise 3000, training on Swedish cor-
pora of three different sizes, with 23 different
tags, and the 26 templates that Brill uses in
his context-rule learner2. In each case, the ac-
curacy of the resulting sequence of rules was
measured on a test corpus consisting of 40k
words, with an initial-state accuracy of 93.3%.
The following table summarizes the results:
Size Thrshld Runtime # of rules Acc.
30k 2 15 min 99 95.5%
60k 4 24 min 85 95.7%
120k 6 60 min 92 95.8%
By comparison, it took Brill&apos;s C-implemented
context-rule learner 90 minutes, 185 minutes,
and 560 minutes, respectively, to train on these
corpora, producing similar sequences of rules.
Thus p-TBL Lite is an order of magnitude faster
than Brill&apos;s learner. The full p.-TBL system
presented in (Lager, 1999) is even faster, uses
less memory, and is in certain respects more
general. Small is beautiful, however, and the
light version may also have a greater pedagogi-
cal value. Both versions can be downloaded from
http: //www. ling .gu . se/,,,lager/mutbl .html.
</bodyText>
<sectionHeader confidence="0.989287" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.83581">
Lager, Torbj8rn. 1999. The p-TBL System:
</bodyText>
<figure confidence="0.996309">
term_expansionUID #
[(pos(ID) :-
(neg(ID) :-
(app(ID) :-
pos((A&lt;-Cs),L1,E]
neg((A&lt;-Cs),L2,[]
app((A&lt;-Cs),L3,0
</figure>
<table confidence="0.8636227">
bestof(FLO,Leader,HiScore,Winner) :- Logic Programming Tools for Transformation-
( FLO = [Pos-RuleIFL], Based Learning, In: Proceedings of CoNLL-99,
Pos &gt; HiScore Bergen.
-&gt; Max is Pos-HiScore, Brill, Eric. 1995. Transformation-Based Error-
( count0(neg(Rule),Max,Neg) Driven Learning and Natural Language Process-
-&gt; bestof(FL,Rule,Pos-Neg,Winner) ing: A Case Study in Part of Speech Tagging.
; bestof(FL,Leader,HiScore,Winner) Computational Linguistics, December 1995.
; Winner = Leader
).
2 Available from http://www.cs.jhu.eduk-,brill.
</table>
<page confidence="0.981694">
280
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.181728">
<note confidence="0.522994">Proceedings of EACL &apos;99</note>
<title confidence="0.9588535">A Small, Extendible Transformation-Based Learner</title>
<author confidence="0.998939">Torbjorn Lager</author>
<affiliation confidence="0.9998775">Department of Linguistics Uppsala University</affiliation>
<address confidence="0.715166">SWEDEN</address>
<email confidence="0.738052">Torbjorn.Lager©ling.uu.se</email>
<abstract confidence="0.940152">This short paper describes — and in fact gives the complete source for — a tiny Prolog program implementing a flexible and fairly efficient Transformation- Based Learning (TBL) system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>