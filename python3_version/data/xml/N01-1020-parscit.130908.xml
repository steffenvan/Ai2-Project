<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014057">
<figure confidence="0.979187074074074">
English
English
(source)
via dictionary
via dictionary via probabilistic
Romance Family
Slavic Family
(bridge)
Spanish
Czech
via probabilistic
cognate models (targets)
cognate models
Portuguese
Italian
French
Romanian
Polish
Slovak
Ukrainian
Russian
French
Spanish
Portuguese
Italian
Romanian
Evaluation Pairs
</figure>
<table confidence="0.988150666666667">
Model Spanish-Portuguese French-Portuguese
cognate full cognate full
vocab (68%) vocab vocab (39%) vocab
L Levenshtein 92.3 67.9 66.4 32.0
H Hidden Markov Model 82.2 58.6 62.7 30.0
S Stochastic Transducer 92.3 67.1 78.6 38.5
L-V Levenshtein w/vowel sensitive distance 91.9 67.9 68.4 33.8
L-A Levenshtein w/learned weights (pan-family) 92.9 67.9 80.1 40.5
L-S Levenshtein w/learned weights (single language) 94.7 69.8 84.3 42.3
</table>
<tableCaption confidence="0.99913">
Table 1: Direct Translation Lexicon Induction Performance
</tableCaption>
<bodyText confidence="0.993887">
within an edit-distance of 3) from the remain-
ing word-pairs as training data. Train on those
pairs.
</bodyText>
<listItem confidence="0.9148792">
3. For each word in the source language choose
the closest word (with respect to the current
distance function) in the target language from
the list of 100.
4. Count a hypothesized translation pair as being
correct if it matches the translation given in the
reference dictionary, incorrect otherwise. (Our
assumption is that there is only one translation
per word. We are investigating models yielding
multiple translations for each word.)
</listItem>
<bodyText confidence="0.9997939">
For this set of experiments, Portuguese was chosen
as the target language and Spanish, French, Italian
and Romanian the source languages (Figure 2). The
Spanish-Portuguese dictionary contained 1000 word
pairs, while the others contained 900 pairs. 10(9)-
fold cross-validation experiments were performed in
each case. The number of training pairs for the
adaptive methods which remained after filtering out
unlikely cognate pairs ranged from 621 (for Spanish)
to 232 (for Romanian).
For the purpose of evaluation, we constrained the
candidate test set to have exactly one translation
per source word. However, this property was not
used to improve candidate alignment (e.g. via the
pigeonhole principle).
Table 1 shows results for different candidate dis-
tance functions for Spanish-Portuguese and French-
Portuguese translation induction. The metrics de-
picted in the first three lines, namely Levenshtein
distance (L), the HMM fenonic model (H), and the
stochastic transducer (S), were previously described
in Section 2. The other three methods are variants of
Levenshtein distance where the costs for edit opera-
tions have been modified. In L-V, the substitution
operations between vowels are changed from 1 to 0.5.
Two adaptively trained variants, L-S and L-A,
are shown in the last two lines of Table 1. The
weights in these two systems were produced by fil-
tering the probabilities obtained from the stochastic
transducer into three weight classes: 0.5, 0.75, and 1.
Identity substitutions were assigned a cost of zero.
For L-S, the cost matrix was separately trained for
each language pair, and for L-A, it was trained col-
lectively over all the Romance languages.
Table 2 shows some of the highest probability
consonant-to-consonant edit operations computed
by the stochastic transducer (S). Most of these top-
ranking derived transformations have been observed
to be relatively low distance by either linguistic anal-
ysis of historical sound changes or by phonological
classification, notably: nasal sonorants (&amp;quot;n&amp;quot; ,
unvoiced stops (&amp;quot;p&amp;quot;, &amp;quot;f&amp;quot;), and voiced stops (&amp;quot;c&amp;quot;,
&amp;quot;g&amp;quot;, &amp;quot;t&amp;quot;, &amp;quot;d&amp;quot;). Other pairs are derivationally rea-
sonable: (&amp;quot;b&amp;quot; , &amp;quot;v&amp;quot;), (&amp;quot;x&amp;quot; , &amp;quot;s&amp;quot;) and (&amp;quot;s&amp;quot; , &amp;quot;c&amp;quot;); while
some may be noise: (&amp;quot;g&amp;quot;, &amp;quot;n&amp;quot;) and (&amp;quot;g&amp;quot;, &amp;quot;v&amp;quot;). Not
shown are vowel-to-vowel substitutions which in gen-
eral were the most highly ranked; also not shown
are tight correspondences between accented and un-
accented vowel variants which were also learned by
the stochastic transducer.
</bodyText>
<figure confidence="0.808013">
fr pt fr pt
n m x s
c g s c
P f c 9
g n g v
b v t d
</figure>
<tableCaption confidence="0.803365">
Table 2: Most Probable Consonant-Consonant Sub-
stitutions Induced for French-Portuguese
</tableCaption>
<bodyText confidence="0.999258266666667">
As can be observed from Table 1, pure Leven-
shtein distance (L) works surprisingly well. Dy-
namic adaptation via the stochastic transducers (S)
also gives a notable boost on French-Portuguese (in-
creasing cognate accuracy from 66% to 79%) but of-
fer little improvement for Spanish-Portuguese (per-
haps because pure Levenshtein needs no diffusion for
relatively close languages while more complex map-
pings benefit from training). Similarly, a slight im-
provment is observed for Romanian-Portuguese un-
der S, but no improvement for Italian-Portuguese.
Also, empirical evidence suggests that the best
method is achieved through learning weights with
stochastic transducers and then using these weights
in the L-S framework.
</bodyText>
<figure confidence="0.960016">
via probabilistic
via dictionary
cognate models
Spanish
English Portuguese
French
via probabilistic
via dictionary
cognate models
English
Ukrainian
Czech
Russian
Polish
Serbian
</figure>
<table confidence="0.9830052">
Spanish Source Target Method Method&apos;s Top Choice Score Rank
Portuguese (Portuguese)
top correct correct
caminar ( walk ) andar L cozinhar (cook) 3 4 8
S ano (year) 37.3 37.3 2
L-S andar 2 2 1
kilogramos (kilograms) quilogramas L quilogramas 3 3 1
S pickup (pickup truck) 114.4 414.6 21
L-S quilogramas 2 2 1
mostaza (mustard) mostarda L mostarda 2 2 1
S metros (meters) 46.6 64.3 3
L-S mostarda 1.5 1.5 1
freno (brake) freio L feno (hay) 1 1 2
S freio 18.6 18.6 1
L-S freio 0.75 0.75 1
</table>
<tableCaption confidence="0.997612">
Table 5: Direct Translation Induction Examples
</tableCaption>
<bodyText confidence="0.974866108108108">
for each word o E 0
for each bridge language B
Translate o b E B
Vt E T, Calculate D(b,t)
Rank t by D(b,t)
Score t using information from all bridges
Select highest scored t
Produce mapping o t
Two scoring methods were investigated for the
above algorithm: one based on rank and the other
on distance.
The rank-based scoring method takes each pro-
posed target and combines the rank of that proposal
across all classifiers, and chooses the translation with
the lowest resulting rank (rank 1 is the best proposed
translation). Since including all the hypothesized
translations regardless of ranking performed poorly,
we only include the ones with a ranking lower than
some threshold N.
The distance-based scoring method selects the hy-
pothesized target word with the smallest distance
from a translation in any of the bridge languages.
We also tested one alternative dist-rank
which uses ranks (as described above) to break ties
in the distance-based method, with similar perfor-
mance.
In Table 6, we present the results obtained by ap-
plying different combination algorithms for the path-
way from English to Portuguese using one of the
other Romance languages (Spanish, Italian, French,
and Romanian) as bridges and compare with the sin-
gle best path (English-Spanish-Portuguese). These
results are presented for unrestricted matching on
the full dictionary lexicon (1097 words in each lan-
guage)2. This is a more difficult task than that
used for direct induction (selecting between 100 and
900 potential translation candidates for each source-
</bodyText>
<footnote confidence="0.910612">
2We used L-V (Levenshtein with vowel substitutions at .5)
as the distance function instead of the best performer (L-S).
</footnote>
<table confidence="0.9997172">
en-es-pt Subset Union Intersection
full full
cog full
en-es-pt 74.0 57.7 53.2 60.0
Rank-1 60.5 46.0 43.0 50.0
Rank-2 60.9 47.0 43.7 51.4
Rank-5 56.2 43.0 40.4 46.0
Rank-100 44.0 33.0 31.1 33.0
Distance 77.0 59.9 55.5 62.7
Dist-Rank 78.7 60.4 55.7 63.6
Oracle-1 82.8 67.2 62.1 70.8
Oracle-2 86.9 71.3 65.8 74.1
Oracle-5 90.5 75.5 69.7 77.7
Oracle-20 93.6 80.4 74.2 83.0
Oracle-100 95.1 87.7 80.9 89.0
</table>
<tableCaption confidence="0.991626">
Table 6: Multipath Translation Induction (L-V)
</tableCaption>
<bodyText confidence="0.99969175">
language word), so the system&apos;s performance is lower
than the Section 3 results.
Since all available dictionaries are incomplete, it
is difficult to decide which set of English words to
compare against. Table 6 presents results for dif-
ferent choices of word coverage: the subset of exist-
ing pairs for English-Spanish, the union over all lan-
guages, and the intersection of all languages. Trends
across subsets are relatively consistent. As an il-
lustration, Table 7 shows consensus formation on
English-Norweigian and English-Portuguese transla-
tion mappings via multiple bridge languages. Note
that the English-French dictionary used here has no
entry for &amp;quot;bait&amp;quot;, preventing its use as a bridge lan-
guage for this word.
As can be seen in Table 6, the distance-based com-
bination methods are more successful at combining
the different proposals than the rank-N combina-
tions. One possible explanation for this is that rank-
based classifiers pick the candidate with the best all-
around distance, while distance-based combinations
choose the single best candidate. Choosing the best
all-around performer is detrimental when cognates
exist for some languages but not for others.
</bodyText>
<table confidence="0.999752714285715">
English Bridge language Bridge Word Target Word Score Rank
bay (NORWEGIAN)
Danish bugt bukt 1 1
German bucht bukt 2 1
Dutch baai baug (bow) 1.5 1
bukt 2.5 25
distance-based method: bukt 1 1
rank-based method: bukt 27 1
(PORTUGUESE)
bait Italian esca isca .5 1
nada (nothing) 3 54
Spanish carnada corneta (trumpet) 2 1
nada 3 12
isca 3.5 153
Romanian nada, nada (nothing) 0.5 1
isca 3.5 153
French N/A N/A N/A N/A
distance-based method: isca 0.5 1
nada 0.5 2
rank-based method: nada 67 1
isca 307 20
</table>
<tableCaption confidence="0.999263">
Table 7: End-to-End Multipath Translation Induction
</tableCaption>
<bodyText confidence="0.999900777777778">
The performance of an oracle, if allowed to choose
the correct translation if it appears within the top-N
in any language, would provide an upper bound for
the performance of the combination methods. Re-
sults for such oracles are also reported in Table 6.
The methods corresponding to &amp;quot;oracle-1&amp;quot; and &amp;quot;dis-
tance&amp;quot; are choosing from the same set of proposed
targets, and the &amp;quot;distance&amp;quot; method achieves perfor-
mance close to that of the oracle (77 vs. 82.8).
</bodyText>
<sectionHeader confidence="0.993354" genericHeader="abstract">
6 Path Differences
</sectionHeader>
<bodyText confidence="0.99586275">
This section investigates the effect of different path-
way configurations on the performance of the final
multi-path system by examining the following situ-
ations:
</bodyText>
<listItem confidence="0.998197125">
• English to Portuguese, using the other Romance
languages as bridges.
• English to Norwegian, using the Germanic lan-
guages as bridges.
• English to Ukrainian, using the Slavic languages
as bridges.
• Portuguese to English, using the Germanic lan-
guages and French as bridges.
</listItem>
<bodyText confidence="0.890651153846154">
The results of these experiments are shown in Ta-
ble 8.3
3Key: en=English, pt=Portuguese, fr=French, it=Italian,
es=Spanish, ro=Romanian, du=Dutch, no=Norwegian,
de=German, da=Danish, cz=Czech, uk=Ukrainian,
po=Polish, sr=Serbian, ru=Russian
The data sets used in these experiments were ap-
proximately the same size as those used in the previ-
ous experiment 1100-1300 translation word pairs.
Dictionaries for Russian and Ukrainian were con-
verted into romanized pronunciation dictionaries.
There are three observations which can be made
from the multipath results.
</bodyText>
<listItem confidence="0.966619166666667">
1. Adding more pathways usually results in an ac-
curacy improvement. When there is a drop in
accuracy on the cognate vocabulary by adding
an additional bridge language there tends to be
an improvement in accuracy on the full vocabu-
lary due to significantly more cognate pathways
(yielding greater coverage).
2. It is difficult to substantially improve upon the
performance of the single closest bridge lan-
guage, especially when they are as close as en-
es-pt. Improvements on performance relative to
the single best ranged from 2% to 20%.
3. Several mediocre pathways can be combined to
improve performance. Though it is always bet-
ter to find one high-performing pathway, it is
often possible to get good performance from
the combination of several, less well-performing
pathways (e.g. en-[sr po]-uk vs. en-ru-uk).
</listItem>
<bodyText confidence="0.999897666666667">
In Table 8 &amp;quot;Cvg&amp;quot; or cognate coverage is the per-
centage words in the source language for which any
of the bridge languages contains a cognate to the
target translation. Italian and French bridges, for
example, offer additional translation pathways to
Portuguese which augment the Spanish pathways.
</bodyText>
<table confidence="0.999790909090909">
Path Accuracy on Accuracy on Cog
Full Vocab Cognate Vocab Cvg
en-es-pt 58.7 86.7 65.5
en-it-pt 44.0 85.4 31.9
en-fr-pt 30.6 74.3 24.8
en-[fr it]-pt 41.2 79.4 42.2
en-[fr it es]-pt 60.2 84.2 70.3
en-da-no 71.9 92.4 75.4
en-du-no 36.1 76.7 39.8
en-de-no 36.1 74.7 38.9
en-[du de]-no 42.3 72.2 54.3
en-[da du de]-no 77.0 87.5 87.4
en-ru-uk 48.8 89.0 44.7
en-po-uk 38.1 87.8 31.9
en-sr-uk 31.9 86.7 30.8
en-[sr po]-uk 45.0 82.0 50.3
en-[ru sr po]-uk 58.4 74.6 71.0
pt-du-en 29.1 69.0 38.4
pt-fr-en 28.1 84.0 24.2
pt-de-en 25.3 68.4 32.1
pt-[de fr]-en 36.5 72.5 48.5
pt-[de fr du]-en 47.0 69.7 66.6
</table>
<tableCaption confidence="0.98612">
Table 8: Translation Accuracy via Different Bridge
Language Paths (using L-A model)
</tableCaption>
<bodyText confidence="0.9986212">
Using all languages together improves coverage, al-
though this often does not improve performance over
using the best single bridge language.
As a final note, Table 9 shows the cross-language
translation rates for some of the investigated lan-
guages. When translating from English to one of
the Romance languages, using Spanish as the bridge
language achieves the highest accuracy; and using
Russian as the bridge language achieves the best
performance when translating from English to the
Slavic languages. However, note that using English
alone without a bridge language when translating
to the Romance languages still achieves reasonable
performance, due to the substantial French and Lati-
nate presence in English vocabulary.
</bodyText>
<sectionHeader confidence="0.999244" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999686588235294">
Probabilistic string edit distance learning techniques
have been studied by Ristad and Yianilos (1998) for
use in pronunciation modeling for speech recogni-
tion. Satta and Henderson (1997) propose a trans-
formation learning method for generic string trans-
duction. Brill and Moore (2000) propose an alterna-
tive string distance metric and learning algorithm.
While early statistical machine translation mod-
els, such as Brown et al. (1993), did not use
any cognate based information to seed their word-
to-word translation probabilities, subsequent mod-
els (Chen, 1993 and Simard et al., 1992) incor-
porated some simple deterministic heuristics to in-
crease the translation model probabilities for cog-
nates. Other methods have been demonstrated for
building bilingual dictionaries using simple heuristic
rules includes Kirschner (1982) for English/Czech
dictionaries and Chen (1998) for Chinese/English
proper names. Tiedemann (1999) improves on these
alignment seedings by learning all-or-nothing rules
for detecting Swedish/English cognates. Hajie et al.
(2000) has studied the exploitation of language simi-
larity for use in machine translation in the case of the
very closely related languages (Czech/Slovak). Cov-
ington (1998) uses an algorithm based on heuristic
orthographic changes to find cognate words for pur-
poses of historical comparison.
Perhaps the most comprehensive study of word
alignment via string transduction methods was pi-
oneered by Knight and Graehl (1998). While re-
stricted to single language transliteration, it very ef-
fectively used intermediary phonological models to
bridge direct lexical borrowing across distant lan-
guages.
</bodyText>
<sectionHeader confidence="0.973889" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999951102564102">
The experiments reported in this paper extend prior
research in a number of directions. The novel prob-
abilistic paradigm for inducing translation lexicons
for words from unaligned word lists is introduced.
The set of languages on which we demonstrate these
methods is broader than previously examined. Fi-
nally, the use of multiple bridge languages and of
the high degree of intra-family language similarity
for dictionary induction is new.
There are a number of open questions. The first is
whether there exists a better string transformation
algorithm to use in the induction step. One possible
area of investigation is to use larger dictionaries and
assess how much better stochastic transducers, and
distance metrics derived from them, perform with
more training data. Another option is to investi-
gate the use of multi-vowel or multi-consonant com-
pounds which better reflect the underlying phonetic
units, using an more sophisticated edit distance mea-
sure.
In this paper, we explore ways of using cognate
pairs to create translation lexicons. It is an in-
teresting research question as to whether we can
augment these methods with translation probabil-
ities estimated from statistical frequency informa-
tion gleaned from loosely aligned or unaligned bilin-
gual corpora for non-cognate pairs. Various machine
learning techniques, including co-training and mu-
tual bootstrapping, could employ these additional
measures in creating better estimates.
The techniques presented here are useful for lan-
guage pairs where an on-line translation lexicon does
not already exist, including the large majority of the
world&apos;s lower-density languages. For language pairs
with existing translation lexicons, these methods can
help improve coverage, especially for technical vo-
cabulary and other more recent borrowings which
are often cognate but frequently missing from exist-
ing dictionaries. In both cases, the great potential of
</bodyText>
<table confidence="0.99991895">
English -x Romance Languages
Accuracy on Cognate Vocab (35-68%)
TL Bridge Language
pt it es fr ro 0
pt (100) 85.6 86.7 74.3 72.1 79.4
it 83.7 (100) 85.1 75.5 82.1 78.0
es 85.8 84.0 (100) 78.1 82.1 79.3
fr 73.9 75.5 76.7 (100) 75.2 78.7
ro 72.8 84.4 82.8 76.1 (100) 78.3
av 78.2 82.0 82.2 75.7 77.7 78.4
English -x Romance Languages
Accuracy on Full Vocab
TL Bridge Language
pt it es fr ro 0
pt (100) 42.6 58.7 29.8 28.4 23.1
it 42.0 (100) 45.6 33.8 34.8 21.3
es 57.5 44.3 (100) 31.8 29.7 22.5
fr 30.7 35.2 32.7 (100) 33.3 24.9
ro 28.5 35.7 30.5 35.0 (100) 23.9
av 39.2 39.0 41.2 32.0 31.0 22.6
English -x Slavic Languages
Accuracy on Cognate Vocab
TL Bridge Language
cz ru pl sr uk 0
cz (100) 70.3 81.4 81.0 81.4 75.0
ru 72.7 (100) 84.1 80.3 87.3 73.9
pl 81.2 85.7 (100) 84.5 88.2 78.2
sr 85.7 82.9 85.8 (100) 85.5 76.7
uk 83.6 89.1 87.9 86.0 (100) 73.9
av 80.2 81.5 84.2 82.7 85.2 75
English -x Slavic Languages
Accuracy on Full Vocab
TL Bridge Language
cz ru pl sr uk 0
cz (100) 20.5 25.5 27.3 25.4 12.0
ru 23.3 (100) 29.9 27.3 47.1 13.4
pl 27.6 30.3 (100) 27.8 36.8 15.0
sr 31.0 29.6 29.4 (100) 33.1 18.5
uk 27.0 48.7 38.0 31.4 (100) 15.7
av 27 31.7 30.2 28 35.2 14.6
</table>
<tableCaption confidence="0.8588205">
Table 9: Accuracy of English to TL (Target Language) via One Bridge Language (using L-A model)
(0 = direct mapping - no bridge)
</tableCaption>
<bodyText confidence="0.9998086">
this work is the ability to leverage a single bilingual
dictionary into translation lexicons for its entire lan-
guage family, without any additional resources be-
yond raw wordlists for the other languages in the
family.
</bodyText>
<sectionHeader confidence="0.993401" genericHeader="acknowledgments">
9 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999914833333333">
The authors would like to thank the following people
for their insightful comments and feedback on drafts
of this work: Radu Florian, Jan Hajie, Ellen Riloff,
Charles Schafer, and Richard Wicentowski. Thanks
also to the Johns Hopkins NLP lab in general for the
productive and stimulating environment.
</bodyText>
<sectionHeader confidence="0.998717" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998407906976745">
E. Brill and R. Moore. 2000. An improved error-
model for noisy channel spelling correction. Proc.
of ACL, pages 286-293.
P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and
R. Mercer. 1993. The mathematics of statistical
machine translation. Computational Linguistics,
19(2):263-311.
C.D. Buck. 1949. A Dictionary of Selected Syn-
onyms in the Principal Indo-European Languages.
Chicago:University of Chicago Press.
H-H. Chen, S-J. Huang, Y-W. Ding, and S-C. Tsai.
1998. Proper name translation in cross-language
information retrieval. Proc. of ACL/COLING,
pages 232-236.
S. Chen. 1993. Aligning sentences in bilingual cor-
pora using lexical information. Proc. of ACL,
pages 9-16.
M. Covington. 1998. Aligning multiple languages
for historical comparison. Proc. of COLING-
ACL, pages 275-280.
J. Hajie, J. Hric, and V. Kubori. 2000. Cesilko :
Machine translation between closely related lan-
guages. Proc. of ANLP, pages 7-12.
F. Jelinek. 1997. Statistical Methods for Speech
Recognition. Boston:MIT Press.
Z. Kirshner. 1982. A dependency based analysis of
english for the purpose of machine translation.
Explizite Beschreibung der Sprache und automa-
tische Textbearbeitung, IX:73.
K. Knight and J. Graehl. 1998. Machine transliter-
ation. Computational Linguistics, 24(4):599-612.
E. Ristad and P. Yianilos. 1998. Learning string
edit distance. IEEE Trans. PAMI, 20(5):522-532.
G. Satta and J. Henderson. 1997. String transfor-
mation learning. Proc. of ACL/EACL, pages 444-
451.
M. Simard, G.F. Foster, and P. Isabelle. 1992. Using
cognates to align sentences in bilingual corpora.
Proc. of TMI-92, Montreal, Quebec, pages 67-82.
J. Tiedemann. 1999. Automatic construction of
weighted string similarity measures. Proc. of Em-
pirical Methods in Natural Language Processing
and Very Large Corpora, pages 213-219.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.846272">English</title>
<abstract confidence="0.899371916666667">English (source) via dictionary via dictionary via probabilistic Romance Family Slavic Family (bridge) Spanish Czech via probabilistic cognate models (targets) cognate models</abstract>
<title confidence="0.849039333333333">Portuguese Italian French Romanian Polish Slovak Ukrainian Russian French Spanish Portuguese Italian Romanian Evaluation Pairs Model Spanish-Portuguese French-Portuguese</title>
<abstract confidence="0.970712890909091">vocab (68%) vocab vocab (39%) vocab L Levenshtein 92.3 67.9 66.4 32.0 H Hidden Markov Model 82.2 58.6 62.7 30.0 S Stochastic Transducer 92.3 67.1 78.6 38.5 L-V Levenshtein w/vowel sensitive distance 91.9 67.9 68.4 33.8 L-A Levenshtein w/learned weights (pan-family) 92.9 67.9 80.1 40.5 L-S Levenshtein w/learned weights (single language) 94.7 69.8 84.3 42.3 Table 1: Direct Translation Lexicon Induction Performance within an edit-distance of 3) from the remaining word-pairs as training data. Train on those pairs. 3. For each word in the source language choose the closest word (with respect to the current distance function) in the target language from the list of 100. 4. Count a hypothesized translation pair as being correct if it matches the translation given in the reference dictionary, incorrect otherwise. (Our assumption is that there is only one translation per word. We are investigating models yielding multiple translations for each word.) For this set of experiments, Portuguese was chosen as the target language and Spanish, French, Italian and Romanian the source languages (Figure 2). The Spanish-Portuguese dictionary contained 1000 word pairs, while the others contained 900 pairs. 10(9)fold cross-validation experiments were performed in each case. The number of training pairs for the adaptive methods which remained after filtering out unlikely cognate pairs ranged from 621 (for Spanish) to 232 (for Romanian). For the purpose of evaluation, we constrained the candidate test set to have exactly one translation per source word. However, this property was not used to improve candidate alignment (e.g. via the pigeonhole principle). Table 1 shows results for different candidate distance functions for Spanish-Portuguese and French- Portuguese translation induction. The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2. The other three methods are variants of Levenshtein distance where the costs for edit operations have been modified. In L-V, the substitution operations between vowels are changed from 1 to 0.5. Two adaptively trained variants, L-S and L-A, are shown in the last two lines of Table 1. The weights in these two systems were produced by filtering the probabilities obtained from the stochastic transducer into three weight classes: 0.5, 0.75, and 1. Identity substitutions were assigned a cost of zero. For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages. Table 2 shows some of the highest probability consonant-to-consonant edit operations computed by the stochastic transducer (S). Most of these topranking derived transformations have been observed to be relatively low distance by either linguistic analysis of historical sound changes or by phonological classification, notably: nasal sonorants (&amp;quot;n&amp;quot; , unvoiced stops (&amp;quot;p&amp;quot;, &amp;quot;f&amp;quot;), and voiced stops (&amp;quot;c&amp;quot;, &amp;quot;g&amp;quot;, &amp;quot;t&amp;quot;, &amp;quot;d&amp;quot;). Other pairs are derivationally reasonable: (&amp;quot;b&amp;quot; , &amp;quot;v&amp;quot;), (&amp;quot;x&amp;quot; , &amp;quot;s&amp;quot;) and (&amp;quot;s&amp;quot; , &amp;quot;c&amp;quot;); while some may be noise: (&amp;quot;g&amp;quot;, &amp;quot;n&amp;quot;) and (&amp;quot;g&amp;quot;, &amp;quot;v&amp;quot;). Not shown are vowel-to-vowel substitutions which in general were the most highly ranked; also not shown are tight correspondences between accented and unaccented vowel variants which were also learned by the stochastic transducer. fr pt fr pt n m x s c g s c P f c 9 g n g v b v t d Table 2: Most Probable Consonant-Consonant Substitutions Induced for French-Portuguese As can be observed from Table 1, pure Levenshtein distance (L) works surprisingly well. Dynamic adaptation via the stochastic transducers (S) also gives a notable boost on French-Portuguese (increasing cognate accuracy from 66% to 79%) but offer little improvement for Spanish-Portuguese (perhaps because pure Levenshtein needs no diffusion for relatively close languages while more complex mappings benefit from training). Similarly, a slight improvment is observed for Romanian-Portuguese under S, but no improvement for Italian-Portuguese. Also, empirical evidence suggests that the best method is achieved through learning weights with stochastic transducers and then using these weights in the L-S framework. via probabilistic via dictionary cognate models Spanish English Portuguese French via probabilistic via dictionary cognate models English Ukrainian Czech Russian Polish Serbian Spanish Source Target Portuguese Method Method&apos;s Top Choice (Portuguese) Score Rank top correct correct caminar ( walk ) andar L S cozinhar (cook) ano (year) 3 4 8 37.3 37.3 2 L-S andar 2 2 1 kilogramos (kilograms) quilogramas L quilogramas 3 3 1 S pickup (pickup truck) 114.4 414.6 21 L-S quilogramas 2 2 1 mostaza (mustard) mostarda L mostarda 2 2 1 S metros (meters) 46.6 64.3 3 L-S mostarda 1.5 1.5 1 freno (brake) freio L feno (hay) 1 1 2 S freio 18.6 18.6 1 L-S freio 0.75 0.75 1 Table 5: Direct Translation Induction Examples each word each bridge language b E information from all bridges highest scored mapping Two scoring methods were investigated for the above algorithm: one based on rank and the other on distance. The rank-based scoring method takes each proposed target and combines the rank of that proposal across all classifiers, and chooses the translation with the lowest resulting rank (rank 1 is the best proposed translation). Since including all the hypothesized translations regardless of ranking performed poorly, we only include the ones with a ranking lower than threshold The distance-based scoring method selects the hypothesized target word with the smallest distance from a translation in any of the bridge languages. We also tested one alternative dist-rank which uses ranks (as described above) to break ties in the distance-based method, with similar performance. In Table 6, we present the results obtained by applying different combination algorithms for the pathway from English to Portuguese using one of the other Romance languages (Spanish, Italian, French, and Romanian) as bridges and compare with the single best path (English-Spanish-Portuguese). These results are presented for unrestricted matching on the full dictionary lexicon (1097 words in each lan- This is a more difficult task than that used for direct induction (selecting between 100 and potential translation candidates for each sourceused with vowel substitutions at .5) the distance function instead of the best performer en-es-pt Subset Union full Intersection full cog full en-es-pt 74.0 57.7 53.2 60.0</abstract>
<note confidence="0.779915545454546">Rank-1 60.5 46.0 43.0 50.0 Rank-2 60.9 47.0 43.7 51.4 Rank-5 56.2 43.0 40.4 46.0 Rank-100 44.0 33.0 31.1 33.0 Distance 77.0 59.9 55.5 62.7 Dist-Rank 78.7 60.4 55.7 63.6 Oracle-1 82.8 67.2 62.1 70.8 Oracle-2 86.9 71.3 65.8 74.1 Oracle-5 90.5 75.5 69.7 77.7 Oracle-20 93.6 80.4 74.2 83.0 Oracle-100 95.1 87.7 80.9 89.0</note>
<abstract confidence="0.939304644230769">6: Multipath Translation Induction language word), so the system&apos;s performance is lower than the Section 3 results. Since all available dictionaries are incomplete, it is difficult to decide which set of English words to compare against. Table 6 presents results for different choices of word coverage: the subset of existing pairs for English-Spanish, the union over all languages, and the intersection of all languages. Trends across subsets are relatively consistent. As an illustration, Table 7 shows consensus formation on English-Norweigian and English-Portuguese translation mappings via multiple bridge languages. Note that the English-French dictionary used here has no entry for &amp;quot;bait&amp;quot;, preventing its use as a bridge language for this word. As can be seen in Table 6, the distance-based combination methods are more successful at combining the different proposals than the rank-N combinations. One possible explanation for this is that rankbased classifiers pick the candidate with the best allaround distance, while distance-based combinations choose the single best candidate. Choosing the best all-around performer is detrimental when cognates exist for some languages but not for others. English Bridge language Bridge Word Target Word Score Rank bay (NORWEGIAN) Danish German Dutch bugt bucht baai bukt bukt baug (bow) bukt 1 1 1 1 25 2 1.5 2.5 distance-based method: bukt 1 1 rank-based method: bukt 27 1 (PORTUGUESE) bait Italian esca isca .5 1 nada (nothing) 3 54 Spanish carnada corneta (trumpet) 2 1 nada 3 12 isca 3.5 153 Romanian nada, nada (nothing) 0.5 1 isca 3.5 153 French N/A N/A N/A N/A distance-based method: isca 0.5 1 nada 0.5 2 rank-based method: nada 67 1 isca 307 20 Table 7: End-to-End Multipath Translation Induction The performance of an oracle, if allowed to choose the correct translation if it appears within the top-N in any language, would provide an upper bound for the performance of the combination methods. Results for such oracles are also reported in Table 6. The methods corresponding to &amp;quot;oracle-1&amp;quot; and &amp;quot;distance&amp;quot; are choosing from the same set of proposed targets, and the &amp;quot;distance&amp;quot; method achieves performance close to that of the oracle (77 vs. 82.8). 6 Path Differences This section investigates the effect of different pathway configurations on the performance of the final multi-path system by examining the following situations: • English to Portuguese, using the other Romance languages as bridges. • English to Norwegian, using the Germanic languages as bridges. • English to Ukrainian, using the Slavic languages as bridges. • Portuguese to English, using the Germanic languages and French as bridges. The results of these experiments are shown in Taen=English, pt=Portuguese, fr=French, it=Italian, es=Spanish, ro=Romanian, du=Dutch, no=Norwegian, de=German, da=Danish, cz=Czech, uk=Ukrainian, po=Polish, sr=Serbian, ru=Russian The data sets used in these experiments were apthe same size as those used in the previous experiment 1100-1300 translation word Dictionaries for Russian and Ukrainian were converted into romanized pronunciation dictionaries. There are three observations which can be made from the multipath results. 1. Adding more pathways usually results in an accuracy improvement. When there is a drop in accuracy on the cognate vocabulary by adding an additional bridge language there tends to be an improvement in accuracy on the full vocabulary due to significantly more cognate pathways (yielding greater coverage). 2. It is difficult to substantially improve upon the performance of the single closest bridge language, especially when they are as close as enes-pt. Improvements on performance relative to the single best ranged from 2% to 20%. 3. Several mediocre pathways can be combined to improve performance. Though it is always better to find one high-performing pathway, it is often possible to get good performance from the combination of several, less well-performing pathways (e.g. en-[sr po]-uk vs. en-ru-uk). In Table 8 &amp;quot;Cvg&amp;quot; or cognate coverage is the percentage words in the source language for which any of the bridge languages contains a cognate to the target translation. Italian and French bridges, for example, offer additional translation pathways to Portuguese which augment the Spanish pathways. Path Accuracy on Full Vocab Accuracy Cvg Cognate Vocab en-es-pt 58.7 86.7 65.5 en-it-pt 44.0 85.4 31.9 en-fr-pt 30.6 74.3 24.8 en-[fr it]-pt 41.2 79.4 42.2 en-[fr it es]-pt 60.2 84.2 70.3 en-da-no 71.9 92.4 75.4 en-du-no 36.1 76.7 39.8 en-de-no 36.1 74.7 38.9 en-[du de]-no 42.3 72.2 54.3 en-[da du de]-no 77.0 87.5 87.4 en-ru-uk 48.8 89.0 44.7 en-po-uk 38.1 87.8 31.9 en-sr-uk 31.9 86.7 30.8 en-[sr po]-uk 45.0 82.0 50.3 en-[ru sr po]-uk 58.4 74.6 71.0 pt-du-en 29.1 69.0 38.4 pt-fr-en 28.1 84.0 24.2 pt-de-en 25.3 68.4 32.1 pt-[de fr]-en 36.5 72.5 48.5 pt-[de fr du]-en 47.0 69.7 66.6 Table 8: Translation Accuracy via Different Bridge Language Paths (using L-A model) Using all languages together improves coverage, although this often does not improve performance over using the best single bridge language. As a final note, Table 9 shows the cross-language translation rates for some of the investigated languages. When translating from English to one of the Romance languages, using Spanish as the bridge language achieves the highest accuracy; and using Russian as the bridge language achieves the best performance when translating from English to the Slavic languages. However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak). Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison. Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998). While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages. 8 Conclusion The experiments reported in this paper extend prior research in a number of directions. The novel probabilistic paradigm for inducing translation lexicons for words from unaligned word lists is introduced. The set of languages on which we demonstrate these methods is broader than previously examined. Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new. There are a number of open questions. The first is whether there exists a better string transformation algorithm to use in the induction step. One possible area of investigation is to use larger dictionaries and assess how much better stochastic transducers, and distance metrics derived from them, perform with more training data. Another option is to investigate the use of multi-vowel or multi-consonant compounds which better reflect the underlying phonetic units, using an more sophisticated edit distance measure. In this paper, we explore ways of using cognate pairs to create translation lexicons. It is an interesting research question as to whether we can augment these methods with translation probabilities estimated from statistical frequency information gleaned from loosely aligned or unaligned bilingual corpora for non-cognate pairs. Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates. The techniques presented here are useful for language pairs where an on-line translation lexicon does not already exist, including the large majority of the world&apos;s lower-density languages. For language pairs with existing translation lexicons, these methods can help improve coverage, especially for technical vocabulary and other more recent borrowings which are often cognate but frequently missing from existing dictionaries. In both cases, the great potential of English -x Romance Accuracy on Cognate Vocab (35-68%) TL Bridge Language pt it es fr ro 0 pt (100) 85.6 86.7 74.3 72.1 79.4 it 83.7 (100) 85.1 75.5 82.1 78.0 es 85.8 84.0 (100) 78.1 82.1 79.3 fr 73.9 75.5 76.7 (100) 75.2 78.7 ro 72.8 84.4 82.8 76.1 (100) 78.3 av 78.2 82.0 82.2 75.7 77.7 78.4 English -x Romance Accuracy on Full Vocab TL Bridge Language pt it es fr ro 0 pt (100) 42.6 58.7 29.8 28.4 23.1 it 42.0 (100) 45.6 33.8 34.8 21.3 es 57.5 44.3 (100) 31.8 29.7 22.5 fr 30.7 35.2 32.7 (100) 33.3 24.9 ro 28.5 35.7 30.5 35.0 (100) 23.9 av 39.2 39.0 41.2 32.0 31.0 22.6 English -x Slavic Accuracy on Cognate Vocab TL Bridge Language cz ru pl sr uk 0 cz (100) 70.3 81.4 81.0 81.4 75.0 ru 72.7 (100) 84.1 80.3 87.3 73.9 pl 81.2 85.7 (100) 84.5 88.2 78.2 sr 85.7 82.9 85.8 (100) 85.5 76.7 uk 83.6 89.1 87.9 86.0 (100) 73.9 av 80.2 81.5 84.2 82.7 85.2 75 English -x Slavic Accuracy on Full Vocab TL Bridge Language cz ru pl sr uk 0 cz (100) 20.5 25.5 27.3 25.4 12.0 ru 23.3 (100) 29.9 27.3 47.1 13.4 pl 27.6 30.3 (100) 27.8 36.8 15.0 sr 31.0 29.6 29.4 (100) 33.1 18.5 uk 27.0 48.7 38.0 31.4 (100) 15.7 av 27 31.7 30.2 28 35.2 14.6 Table 9: Accuracy of English to TL (Target Language) via One Bridge Language (using L-A model) (0 = direct mapping no bridge) this work is the ability to leverage a single bilingual dictionary into translation lexicons for its entire language family, without any additional resources beyond raw wordlists for the other languages in the family. 9 Acknowledgements The authors would like to thank the following people for their insightful comments and feedback on drafts of this work: Radu Florian, Jan Hajie, Ellen Riloff, Charles Schafer, and Richard Wicentowski. Thanks also to the Johns Hopkins NLP lab in general for the productive and stimulating environment. References E. Brill and R. Moore. 2000. An improved errorfor noisy channel spelling correction. ACL, 286-293. P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R. Mercer. 1993. The mathematics of statistical translation. Linguistics, 19(2):263-311. Buck. 1949. A of Selected Synonyms in the Principal Indo-European Languages. Chicago:University of Chicago Press. H-H. Chen, S-J. Huang, Y-W. Ding, and S-C. Tsai. 1998. Proper name translation in cross-language retrieval. of ACL/COLING, pages 232-236. Chen. 1993. Aligning sentences in bilingual corusing lexical information. of ACL, pages 9-16. M. Covington. 1998. Aligning multiple languages historical comparison. of COLING- 275-280. J. Hajie, J. Hric, and V. Kubori. 2000. Cesilko : Machine translation between closely related lanof ANLP, 7-12. Jelinek. 1997. Methods for Speech Press. Z. Kirshner. 1982. A dependency based analysis of english for the purpose of machine translation. Explizite Beschreibung der Sprache und automa- Textbearbeitung, Knight and J. Graehl. 1998. Machine transliter- Linguistics, E. Ristad and P. Yianilos. 1998. Learning string distance. Trans. PAMI, G. Satta and J. Henderson. 1997. String transforlearning. of ACL/EACL, 444- 451. M. Simard, G.F. Foster, and P. Isabelle. 1992. Using cognates to align sentences in bilingual corpora.</abstract>
<note confidence="0.6021986">of TMI-92, Montreal, Quebec, 67-82. J. Tiedemann. 1999. Automatic construction of string similarity measures. of Empirical Methods in Natural Language Processing Very Large Corpora, 213-219.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>R Moore</author>
</authors>
<title>An improved errormodel for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>Proc. of ACL,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="13453" citStr="Brill and Moore (2000)" startWordPosition="2129" endWordPosition="2132"> bridge language achieves the best performance when translating from English to the Slavic languages. However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>E. Brill and R. Moore. 2000. An improved errormodel for noisy channel spelling correction. Proc. of ACL, pages 286-293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="13603" citStr="Brown et al. (1993)" startWordPosition="2152" endWordPosition="2155">idge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation. Computational Linguistics, 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Buck</author>
</authors>
<title>A Dictionary of Selected Synonyms in the Principal Indo-European Languages.</title>
<date>1949</date>
<publisher>Chicago:University of Chicago Press.</publisher>
<marker>Buck, 1949</marker>
<rawString>C.D. Buck. 1949. A Dictionary of Selected Synonyms in the Principal Indo-European Languages. Chicago:University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-H Chen</author>
<author>S-J Huang</author>
<author>Y-W Ding</author>
<author>S-C Tsai</author>
</authors>
<title>Proper name translation in cross-language information retrieval.</title>
<date>1998</date>
<booktitle>Proc. of ACL/COLING,</booktitle>
<pages>232--236</pages>
<marker>Chen, Huang, Ding, Tsai, 1998</marker>
<rawString>H-H. Chen, S-J. Huang, Y-W. Ding, and S-C. Tsai. 1998. Proper name translation in cross-language information retrieval. Proc. of ACL/COLING, pages 232-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chen</author>
</authors>
<title>Aligning sentences in bilingual corpora using lexical information.</title>
<date>1993</date>
<booktitle>Proc. of ACL,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="13729" citStr="Chen, 1993" startWordPosition="2173" endWordPosition="2174">te presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very</context>
</contexts>
<marker>Chen, 1993</marker>
<rawString>S. Chen. 1993. Aligning sentences in bilingual corpora using lexical information. Proc. of ACL, pages 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Covington</author>
</authors>
<title>Aligning multiple languages for historical comparison.</title>
<date>1998</date>
<booktitle>Proc. of COLINGACL,</booktitle>
<pages>275--280</pages>
<contexts>
<context position="14388" citStr="Covington (1998)" startWordPosition="2264" endWordPosition="2266"> simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak). Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison. Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998). While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages. 8 Conclusion The experiments reported in this paper extend prior research in a number of directions. The novel probabilistic paradigm for inducing translation lexicons for words </context>
</contexts>
<marker>Covington, 1998</marker>
<rawString>M. Covington. 1998. Aligning multiple languages for historical comparison. Proc. of COLINGACL, pages 275-280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajie</author>
<author>J Hric</author>
<author>V Kubori</author>
</authors>
<title>Cesilko : Machine translation between closely related languages.</title>
<date>2000</date>
<booktitle>Proc. of ANLP,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="14222" citStr="Hajie et al. (2000)" startWordPosition="2237" endWordPosition="2240">, did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak). Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison. Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998). While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages. 8 Conclusion</context>
</contexts>
<marker>Hajie, Hric, Kubori, 2000</marker>
<rawString>J. Hajie, J. Hric, and V. Kubori. 2000. Cesilko : Machine translation between closely related languages. Proc. of ANLP, pages 7-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Statistical Methods for Speech Recognition.</title>
<date>1997</date>
<publisher>Boston:MIT Press.</publisher>
<marker>Jelinek, 1997</marker>
<rawString>F. Jelinek. 1997. Statistical Methods for Speech Recognition. Boston:MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Kirshner</author>
</authors>
<title>A dependency based analysis of english for the purpose of machine translation. Explizite Beschreibung der Sprache und automatische Textbearbeitung,</title>
<date>1982</date>
<marker>Kirshner, 1982</marker>
<rawString>Z. Kirshner. 1982. A dependency based analysis of english for the purpose of machine translation. Explizite Beschreibung der Sprache und automatische Textbearbeitung, IX:73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="14636" citStr="Knight and Graehl (1998)" startWordPosition="2301" endWordPosition="2304"> dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak). Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison. Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998). While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages. 8 Conclusion The experiments reported in this paper extend prior research in a number of directions. The novel probabilistic paradigm for inducing translation lexicons for words from unaligned word lists is introduced. The set of languages on which we demonstrate these methods is broader than previously examined. Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for di</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ristad</author>
<author>P Yianilos</author>
</authors>
<title>Learning string edit distance.</title>
<date>1998</date>
<journal>IEEE Trans. PAMI,</journal>
<pages>20--5</pages>
<contexts>
<context position="13271" citStr="Ristad and Yianilos (1998)" startWordPosition="2101" endWordPosition="2104">of the investigated languages. When translating from English to one of the Romance languages, using Spanish as the bridge language achieves the highest accuracy; and using Russian as the bridge language achieves the best performance when translating from English to the Slavic languages. However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Othe</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>E. Ristad and P. Yianilos. 1998. Learning string edit distance. IEEE Trans. PAMI, 20(5):522-532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Satta</author>
<author>J Henderson</author>
</authors>
<title>String transformation learning.</title>
<date>1997</date>
<booktitle>Proc. of ACL/EACL,</booktitle>
<pages>444--451</pages>
<contexts>
<context position="13356" citStr="Satta and Henderson (1997)" startWordPosition="2114" endWordPosition="2117">nguages, using Spanish as the bridge language achieves the highest accuracy; and using Russian as the bridge language achieves the best performance when translating from English to the Slavic languages. However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heu</context>
</contexts>
<marker>Satta, Henderson, 1997</marker>
<rawString>G. Satta and J. Henderson. 1997. String transformation learning. Proc. of ACL/EACL, pages 444-451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G F Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using cognates to align sentences in bilingual corpora.</title>
<date>1992</date>
<booktitle>Proc. of TMI-92,</booktitle>
<pages>67--82</pages>
<location>Montreal, Quebec,</location>
<contexts>
<context position="13754" citStr="Simard et al., 1992" startWordPosition="2176" endWordPosition="2179">English vocabulary. 7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition. Satta and Henderson (1997) propose a transformation learning method for generic string transduction. Brill and Moore (2000) propose an alternative string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related language</context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>M. Simard, G.F. Foster, and P. Isabelle. 1992. Using cognates to align sentences in bilingual corpora. Proc. of TMI-92, Montreal, Quebec, pages 67-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tiedemann</author>
</authors>
<title>Automatic construction of weighted string similarity measures.</title>
<date>1999</date>
<booktitle>Proc. of Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>213--219</pages>
<contexts>
<context position="14092" citStr="Tiedemann (1999)" startWordPosition="2222" endWordPosition="2223"> string distance metric and learning algorithm. While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates. Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names. Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates. Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak). Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison. Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998). While restricted to single language transliteration, i</context>
</contexts>
<marker>Tiedemann, 1999</marker>
<rawString>J. Tiedemann. 1999. Automatic construction of weighted string similarity measures. Proc. of Empirical Methods in Natural Language Processing and Very Large Corpora, pages 213-219.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>