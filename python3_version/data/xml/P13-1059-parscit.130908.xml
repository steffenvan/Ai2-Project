<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000030">
<title confidence="0.788133">
Name-aware Machine Translation
</title>
<author confidence="0.79002">
Haibo Li† Jing Zheng‡ Heng Ji† Qi Li† Wen Wang‡
</author>
<affiliation confidence="0.747867">
† Computer Science Department and Linguistics Department ‡ Speech Technology &amp; Research Laboratory
Queens College and Graduate Center, City University of New York SRI International
</affiliation>
<address confidence="0.846335">
New York, NY, USA 10016 Menlo Park, CA, USA 94025
</address>
<email confidence="0.982433">
flihaibo.c, hengjicuny, liqiearth}@gmail.com fzj, wwang}@speech.sri.com
</email>
<sectionHeader confidence="0.994672" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999435">
We propose a Name-aware Machine
Translation (MT) approach which can
tightly integrate name processing into MT
model, by jointly annotating parallel cor-
pora, extracting name-aware translation
grammar and rules, adding name phrase
table and name translation driven decod-
ing. Additionally, we also propose a new
MT metric to appropriately evaluate the
translation quality of informative words,
by assigning different weights to differ-
ent words according to their importance
values in a document. Experiments on
Chinese-English translation demonstrated
the effectiveness of our approach on en-
hancing the quality of overall translation,
name translation and word alignment over
a high-quality MT baseline1.
</bodyText>
<sectionHeader confidence="0.998781" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927875">
A shrinking fraction of the world’s Web pages are
written in English, therefore the ability to access
pages across a range of languages is becoming in-
creasingly important. This need can be addressed
in part by cross-lingual information access tasks
such as entity linking (McNamee et al., 2011; Cas-
sidy et al., 2012), event extraction (Hakkani-Tur
et al., 2007), slot filling (Snover et al., 2011) and
question answering (Parton et al., 2009; Parton
and McKeown, 2010). A key bottleneck of high-
quality cross-lingual information access lies in the
performance of Machine Translation (MT). Tradi-
tional MT approaches focus on the fluency and
accuracy of the overall translation but fall short
in their ability to translate certain content word-
s including critical information, especially names.
</bodyText>
<footnote confidence="0.999804333333333">
1Some of the resources and open source programs devel-
oped in this work are made freely available for research pur-
pose at http://nlp.cs.qc.cuny.edu/NAMT.tgz
</footnote>
<bodyText confidence="0.999646">
A typical statistical MT system can only trans-
late 60% person names correctly (Ji et al., 2009).
Incorrect segmentation and translation of names
which often carry central meanings of a sentence
can also yield incorrect translation of long con-
texts. Names have been largely neglected in the
prior MT research due to the following reasons:
</bodyText>
<listItem confidence="0.902446090909091">
• The current dominant automatic MT scoring
metrics (such as Bilingual Evaluation Under-
study (BLEU) (Papineni et al., 2002)) treat
all words equally, but names have relative low
frequency in text (about 6% in newswire and
only 3% in web documents) and thus are vast-
ly outnumbered by function words and com-
mon nouns, etc..
• Name translations pose a greater complexity
because the set of names is open and highly
dynamic. It is also important to acknowledge
that there are many fundamental differences
between the translation of names and other
tokens, depending on whether a name is ren-
dered phonetically, semantically, or a mixture
of both (Ji et al., 2009).
• The artificial settings of assigning low
weights to information translation (compared
to overall word translation) in some large-
scale government evaluations have discour-
aged MT developers to spend time and ex-
plore resources to tackle this problem.
</listItem>
<bodyText confidence="0.994625">
We propose a novel Name-aware MT (NAMT)
approach which can tightly integrate name pro-
cessing into the training and decoding processes of
an end-to-end MT pipeline, and a new name-aware
metric to evaluate MT which can assign different
weights to different tokens according to their im-
portance values in a document. Compared to pre-
vious methods, the novel contributions of our ap-
proach are:
</bodyText>
<listItem confidence="0.5845445">
1. Tightly integrate joint bilingual name tag-
ging into MT training by coordinating tagged
</listItem>
<page confidence="0.963324">
604
</page>
<note confidence="0.9143625">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 604–614,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.990844666666667">
names in parallel corpora, updating word seg-
mentation, word alignment and grammar ex-
traction (Section 3.1).
</bodyText>
<listItem confidence="0.9922893">
2. Tightly integrate name tagging and transla-
tion into MT decoding via name-aware gram-
mar (Section 3.2).
3. Optimize name translation and context trans-
lation simultaneously and conduct name
translation driven decoding with language
model (LM) based selection (Section 3.2).
4. Propose a new MT evaluation metric which
can discriminate names and non-informative
words (Section 4).
</listItem>
<sectionHeader confidence="0.992726" genericHeader="method">
2 Baseline NIT
</sectionHeader>
<bodyText confidence="0.999529375">
As our baseline, we apply a high-performing
Chinese-English MT system (Zheng, 2008; Zheng
et al., 2009) based on hierarchical phrase-based
translation framework (Chiang, 2005). It is based
on a weighted synchronous context-free grammar
(SCFG). All SCFG rules are associated with a set
of features that are used to compute derivation
probabilities. The features include:
</bodyText>
<listItem confidence="0.974926818181818">
• Relative frequency in two directions P(-y|α)
and P(α|-y), estimating the likelihoods of one
side of the rule r: X →&lt; -y, α &gt; translating
into the other side, where -y and α are strings
of terminals and non-terminals in the source
side and target side. Non-terminals in -y and
α are in one-to-one correspondence.
• Lexical weights in two directions: P,,,(-y|α)
and P,,,(α|-y), estimating likelihoods of word-
s in one side of the rule r: X →&lt; -y, α &gt;
translating into the other side (Koehn et al.,
2003).
• Phrase penalty: a penalty exp(1) for a rule
with no non-terminal being used in deriva-
tion.
• Rule penalty: a penalty exp(1) for a rule
with at least one non-terminal being used in
derivation.
• Glue rule penalty: a penalty exp(1) if a glue
rule used in derivation.
• Translation length: number of words in trans-
lation output.
</listItem>
<bodyText confidence="0.998667703703704">
Our previous work showed that combining mul-
tiple LMs trained from different sources can lead
to significant improvement. The LM used for de-
coding is a log-linear combination of four word
n-gram LMs which are built on different English
corpora (details described in section 5.1), with
the LM weights optimized on a development set
and determined by minimum error rate training
(MERT), to estimate the probability of a word giv-
en the preceding words. All four LMs were trained
using modified Kneser-Ney smoothing algorithm
(Chen and Goodman, 1996) and converted into
Bloom filter LMs (Talbot and Brants, 2008) sup-
porting memory map.
The scaling factors for all features are optimized
by minimum error rate training algorithm to max-
imize BLEU score (Och, 2003). Given an input
sentence in the source language, translation into
the target language is cast as a search problem,
where the goal is to find the highest-probability
derivation that generates the source-side sentence,
using the rules in our SCFG. The source-side
derivation corresponds to a synchronous target-
side derivation and the terminal yield of this target-
side derivation is the output of the system. We em-
ploy our CKY-style chart decoder, named SRInter-
p, to solve the search problem.
</bodyText>
<sectionHeader confidence="0.999126" genericHeader="method">
3 Name-aware NIT
</sectionHeader>
<bodyText confidence="0.999983333333333">
We tightly integrate name processing into the
above baseline to construct a NAMT model. Fig-
ure 1 depicts the general procedure.
</bodyText>
<subsectionHeader confidence="0.998824">
3.1 Training
</subsectionHeader>
<bodyText confidence="0.999956409090909">
This basic training process of NAMT requires us
to apply a bilingual name tagger to annotate par-
allel training corpora. Traditional name tagging
approaches for single languages cannot address
this requirement because they were all built on da-
ta and resources which are specific to each lan-
guage without using any cross-lingual features.
In addition, due to separate decoding processes
the results on parallel data may not be consistent
across languages. We developed a bilingual joint
name tagger (Li et al., 2012) based on condition-
al random fields that incorporates both monolin-
gual and cross-lingual features and conducts join-
t inference, so that name tagging from two lan-
guages can mutually enhance each other and there-
fore inconsistent results can be corrected simulta-
neously. This joint name tagger achieved 86.3%
bilingual pair F-measure with manual alignment
and 84.4% bilingual pair F-measure with automat-
ic alignment as reported in (Li et al., 2012). Given
a parallel sentence pair we first apply Giza++ (Och
and Ney, 2003) to align words, and apply this join-
</bodyText>
<page confidence="0.998941">
605
</page>
<figureCaption confidence="0.999927">
Figure 1: Architecture of Name-aware Machine Translation System.
</figureCaption>
<bodyText confidence="0.999191823529412">
t bilingual name tagger to extract three types of
names: (Person (PER), Organization (ORG) and
Geo-political entities (GPE)) from both the source
side and the target side. We pair two entities from
two languages, if they have the same entity type
and are mapped together by word alignment. We
ignore two kinds of names: multi-word names
with conflicting boundaries in two languages and
names only identified in one side of a parallel sen-
tence.
We built a NAMT system from such name-
tagged parallel corpora. First, we replace tagged
name pairs with their entity types, and then
use Giza++ and symmetrization heuristics to re-
generate word alignment. Since the name tags ap-
pear very frequently, the existence of such tags
yields improvement in word alignment quality.
The re-aligned parallel corpora are used to train
our NAMT system based on SCFG. Since the joint
name tagger ensures that each tagged source name
has a corresponding translation on the target side
(and vice versa), we can extract SCFG rules by
treating the tagged names as non-terminals.
However, the original parallel corpora contain
many high-frequency names, which can already be
handled well by the baseline MT. Some of these
names carry special meanings that may influence
translations of the neighboring words, and thus re-
placing them with non-terminals can lead to infor-
mation loss and weaken the translation model. To
address this issue, we merged the name-replaced
parallel data with the original parallel data and ex-
tract grammars from the combined corpus. For ex-
ample, given the following sentence pair:
</bodyText>
<listItem confidence="0.970027571428571">
• rpW RXf �* *)1 1iA ��-&amp;quot;fEL �+J� .
• China appeals to world for non involvement
in Angola conflict.
after name tagging it becomes
• GPE &amp;Xf, �F* *)j J A GPE �+J .
• GPE appeals to world for non involvement in
GPE conflict.
</listItem>
<bodyText confidence="0.867989">
Both sentence pairs are kept in the combined data
to build the translation model.
</bodyText>
<subsectionHeader confidence="0.999188">
3.2 Decoding
</subsectionHeader>
<bodyText confidence="0.999958034482758">
During decoding phase, we extract names with
the baseline monolingual name tagger described
in (Li et al., 2012) from a source document. It-
s performance is comparable to the best report-
ed results on Chinese name tagging on Automat-
ic Content Extraction (ACE) data (Ji and Grish-
man, 2006; Florian et al., 2006; Zitouni and Flo-
rian, 2008; Nguyen et al., 2010). Then we ap-
ply a state-of-the-art name translation system (Ji
et al., 2009) to translate names into the target lan-
guage. The name translation system is composed
of the following steps: (1) Dictionary matching
based on 150,041 name translation pairs; (2) Sta-
tistical name transliteration based on a structured
perceptron model and a character based MT mod-
el (Dayne and Shahram, 2007); (3) Context infor-
mation extraction based re-ranking.
In our NAMT framework, we add the following
extensions to name translation.
We developed a name origin classifier based on
Chinese last name list (446 name characters) and
name structure parsing features to distinguish Chi-
nese person names and foreign person names (Ji,
2009), so that pinyin conversion is applied for Chi-
nese names while name transliteration is applied
only for foreign names. This classifier works rea-
sonably well in most cases (about 92% classifica-
tion accuracy), except when a common Chinese
last name appears as the first character of a foreign
</bodyText>
<page confidence="0.998399">
606
</page>
<bodyText confidence="0.999978172413793">
name, such as “*AV” which can be translated ei-
ther as “Jolie” or “Zhu Li”.
For those names with fewer than five instances
in the training data, we use the name translation
system to provide translations; for the rest of the
names, we leave them to the baseline MT mod-
el to handle. The joint bilingual name tagger was
also exploited to mine bilingual name translation
pairs from parallel training corpora. The mapping
score between a Chinese name and an English
name was computed by the number of aligned to-
kens. A name pair is extracted if the mapping
score is the highest among all combinations and
the name types on both sides are identical. It is
necessary to incorporate word alignment as addi-
tional constraints because the order of names is of-
ten changed after translation. Finally, the extract-
ed 9,963 unique name translation pairs were also
used to create an additional name phrase table for
NAMT. Manual evaluation on 2,000 name pairs
showed the accuracy is 86%.
The non-terminals in SCFG rules are rewritten
to the extracted names during decoding, therefore
allow unseen names in the test data to be trans-
lated. Finally, based on LMs, our decoder ex-
ploits the dynamically created phrase table from
name translation, competing with originally ex-
tracted rules, to find the best translation for the
input sentence.
</bodyText>
<sectionHeader confidence="0.993474" genericHeader="method">
4 Name-aware MT Evaluation
</sectionHeader>
<bodyText confidence="0.9998845625">
Traditional MT evaluation metrics such as
BLEU (Papineni et al., 2002) and Translation Ed-
it Rate (TER) (Snover et al., 2006) assign the
same weights to all tokens equally. For exam-
ple, incorrect translations of “the” and “Bush” will
receive the same penalty. However, for cross-
lingual information processing applications, we
should acknowledge that certain informationally
critical words are more important than other com-
mon words. In order to properly evaluate the trans-
lation quality of NAMT methods, we propose to
modify the BLEU metric so that they can dynam-
ically assign more weights to names during evalu-
ation.
BLEU considers the correspondence between a
system translation and a human translation:
</bodyText>
<equation confidence="0.965122571428571">
N
BLEU = BP · exp ( 1: wn log pn/ (1)
n=1
where BP is brevity penalty defined as follows:
�
1 if c &gt; r,
BP = e(1−r/c) if c ≤ r.
</equation>
<bodyText confidence="0.9999212">
where wn is a set of positive weights summing to
one and usually uniformly set as wn = 1/N, c is
the length of the system translation and r is the
length of reference translation, and pn is modified
n-gram precision defined as:
</bodyText>
<equation confidence="0.86466">
E E Countclip(n-gram)
CECandidates n-gramEC
pn = E E Countclip(n-gram&apos;)
Candidates n-gram&apos;EC&apos;
(3)
</equation>
<bodyText confidence="0.999703428571429">
where C and C&apos; are translation candidates in the
candidate sentence set, if a source sentence is
translated to many candidate sentences.
As in BLEU metric, we first count the maxi-
mum number of times an n-gram occurs in any s-
ingle reference translation. The total count of each
candidate n-gram is clipped at sentence level by it-
s maximum reference count. Then we add up the
weights of clipped n-grams and divide them by the
total weight of all n-grams.
Based on BLEU score, we design a name-aware
BLEU metric as follows. Depending on whether a
token t is contained in a name in reference trans-
lation, we assign a weight weightt to t as follows:
</bodyText>
<equation confidence="0.9946425">
weights =
�
1 − e−sf(s,d)·idf(s,D), if t never appears in names (4)
1+ PZE ,if t occurs in name(s)
</equation>
<bodyText confidence="0.989938333333333">
where PE is the sum of penalties of non-name
tokens and Z is the number of tokens within all
names:
</bodyText>
<equation confidence="0.8430885">
PE = E e−tf(t,d)·idf(t,D) (5)
t never appears in names
</equation>
<bodyText confidence="0.999969">
In this paper, the tf · idf score is computed at sen-
tence level, therefore, D is the sentence set and
each d E D is a sentence.
The weight of an n-gram in reference translation
is the sum of weights of all tokens it contains.
</bodyText>
<equation confidence="0.953617">
�weightngram = weightt (6)
tEngram
</equation>
<bodyText confidence="0.996890666666667">
Next, we compute the weighted modified n-
gram precision Countweight−clip(n-gram) as fol-
lows:
</bodyText>
<equation confidence="0.970247">
Countweight−clip(n-gram) =
� weightngrami (7)
</equation>
<bodyText confidence="0.787668">
if the ngrami is correctly translated
</bodyText>
<figure confidence="0.779054">
(2)
C&apos;E
</figure>
<page confidence="0.978979">
607
</page>
<bodyText confidence="0.9998765">
The Countclip(n-gram) in the equation 3 is
substituted with above Countweight−clip(n-gram).
When we sum up the total weight of all n-grams of
a candidate translation, some n-grams may contain
tokens which do not exist in reference translation.
We assign the lowest weight of tokens in reference
translation to these rare tokens.
We also add an item, name penalty NP, to
penalize the output sentences which contain too
many or too few names:
</bodyText>
<equation confidence="0.965934">
NP = e−(&apos;; −1)2/2v (8)
</equation>
<bodyText confidence="0.9992256">
where u is the number of name tokens in system
translation and v is the number of name tokens in
reference translation.
Finally the name-aware BLEU score is defined
as:
</bodyText>
<equation confidence="0.988792333333333">
N
BLEUNA = BP · NP · exp CE wn log wpn (9)
n=1
</equation>
<bodyText confidence="0.9990005">
This new metric can also be applied to evalu-
ate MT approaches which emphasize other types
of facts such as events, by simply replacing name
tokens by other fact tokens.
</bodyText>
<sectionHeader confidence="0.99866" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9998745">
In this section we present the experimental results
of NAMT compared to the baseline MT.
</bodyText>
<subsectionHeader confidence="0.99719">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999980588235295">
We used a large Chinese-English MT training cor-
pus from various sources and genres (including
newswire, web text, broadcast news and broadcast
conversations) for our experiments. We also used
some translation lexicon data and Wikipedia trans-
lations. The majority of the data sets were col-
lected or made available by LDC for U.S. DARPA
Translingual Information Detection, Extraction
and Summarization (TIDES) program, Global Au-
tonomous Language Exploitation (GALE) pro-
gram, Broad Operational Language Translation
(BOLT) program and National Institute of Stan-
dards and Technology (NIST) MT evaluations.
The training corpus includes 1,686,458 sentence
pairs. The joint name tagger extracted 1,890,335
name pairs (295,087 Persons, 1,269,056 Geo-
political entities and 326,192 Organizations).
Four LMs, denoted LM1, LM2, LM3, and
LM4, were trained from different English cor-
pora. LM1 is a 7-gram LM trained on the tar-
get side of Chinese-English and Egyptian Arabic-
English parallel text, English monolingual discus-
sion forums data R1-R4 released in BOLT Phase
1 (LDC2012E04, LDC2012E16, LDC2012E21,
LDC2012E54), and English Gigaword Fifth Edi-
tion (LDC2011T07). LM2 is a 7-gram LM trained
only on the English monolingual discussion fo-
rums data listed above. LM3 is a 4-gram LM
trained on the web genre among the target side
of all parallel text (i.e., web text from pre-BOLT
parallel text and BOLT released discussion fo-
rum parallel text). LM4 is a 4-gram LM trained
on the English broadcast news and conversation
transcripts released under the DARPA GALE pro-
gram. Note that for LM4 training data, some tran-
scripts were quick transcripts and quick rich tran-
scripts released by LDC, and some were generated
by running flexible alignment of closed captions or
speech recognition output from LDC on the audio
data (Venkataraman et al., 2004).
In order to demonstrate the effectiveness and
generality of our approach, we evaluated our ap-
proach on seven test sets from multiple genres and
domains. We asked four annotators to annotate
names in four reference translations of each sen-
tence and an expert annotator to adjudicate result-
s. The detailed statistics and name distribution of
each test data set is shown in Table 1. The per-
centage of names occurred fewer than 5 times in
training data are listed in the brackets in the last
column of the table.
</bodyText>
<subsectionHeader confidence="0.998779">
5.2 Overall Performance
</subsectionHeader>
<bodyText confidence="0.965151058823529">
Besides the new name-aware MT metric, we also
adopt two traditional metrics, TER to evaluate the
overall translation performance and Named Entity
Weak Accuracy (NEWA) (Hermjakob et al., 2008)
to evaluate the name translation performance.
TER measures the amount of edits required to
change a system output into one of the reference
translations. Specifically:
# of edits
TER = (10)
average # of reference words
Possible edits include insertion, substitution dele-
tion and shifts of words.
The NEWA metric is defined as follows. Us-
ing a manually assembled name variant table, we
also support the matching of name variants (e.g.,
“World Health Organization” and “WHO”).
</bodyText>
<footnote confidence="0.553412666666667">
Count # of correctly translated names
NEWA = (11)
Count # of names in references
</footnote>
<page confidence="0.962198">
608
</page>
<table confidence="0.999426666666667">
Corpus Genre Sentence # Word # Token # GPE(%) PER(%) ORG(%) All names
in source in reference (% occurred &lt; 5)
BOLT 1 forum 1,200 20,968 24,193 875(82.9) 90(8.5) 91(8.6) 1,056 (51.4)
BOLT 2 forum 1,283 23,707 25,759 815(73.7) 141(12.8) 149(13.5) 1,105 (65.9)
BOLT 3 forum 2,000 38,595 42,519 1,664(80.4) 204(9.8) 204(9.8) 2,072 (47.4)
BOLT 4 forum 1,918 41,759 47,755 1,852(80.0) 348(25.0) 113(5.0) 2,313 (53.3)
BOLT 5 blog 950 23,930 26,875 352(42.5) 235(28.3) 242(29.2) 829 (55.3)
NIST2006 news&amp;blog 1,664 38,442 45,914 1,660(58.2) 568(19.9) 625(21.9) 2,853 (73.1)
NIST2008 news&amp;blog 1,357 32,646 37,315 700(47.9) 367(25.1) 395(27.0) 1,462 (72.0)
</table>
<tableCaption confidence="0.991759">
Table 1: Statistics and Name Distribution of Test Data Sets.
</tableCaption>
<table confidence="0.999989818181818">
Metric System BOLT 1 BOLT 2 BOLT 3 BOLT 4 BOLT 5 NIST2006 NIST2008
Baseline 14.2 14.0 17.3 15.6 15.3 35.5 29.3
BLEU NPhrase 14.1 14.4 17.1 15.4 15.3 35.4 29.3
NAMT 14.2 14.6 16.9 15.7 15.5 36.3 30.0
Baseline 18.2 17.9 18.6 17.6 18.3 36.1 31.7
Name-aware BLEU NPhrase 18.1 18.8 18.5 18.1 18.0 35.8 31.8
NAMT 18.4 19.5 19.7 18.2 18.9 39.4 33.1
Baseline 70.6 71.0 69.4 70.3 67.1 58.7 61.0
TER NPhrase 70.6 70.4 69.4 70.4 67.1 58.7 60.9
NAMT 70.3 70.2 69.2 70.1 66.6 57.7 60.5
Baseline 69.7 70.1 73.9 72.3 60.6 66.5 60.4
All NPhrase 69.8 71.1 73.8 72.5 60.6 68.3 61.9
NAMT 71.4 72.0 77.7 75.1 62.7 72.9 63.2
NEWA GPE Baseline 72.8 78.4 80.0 78.7 81.3 79.2 76.0
NPhrase 73.6 79.3 79.2 78.9 82.3 82.6 79.5
NAMT 74.2 80.2 82.8 80.4 79.3 85.5 79.3
Baseline 53.3 44.7 45.1 49.4 48.9 54.2 51.2
PER NPhrase 52.2 45.4 48.9 48.5 47.6 55.1 50.9
NAMT 55.6 45.4 58.8 55.2 56.2 60.0 52.3
Baseline 56.0 49.0 52.9 38.1 41.7 44.0 41.3
ORG NPhrase 50.5 50.3 54.4 40.7 41.3 42.2 40.7
NAMT 60.4 52.3 55.4 41.6 45.0 51.0 44.8
</table>
<tableCaption confidence="0.999009">
Table 2: Translation Performance (%).
</tableCaption>
<bodyText confidence="0.998718020408163">
For better comparison with NAMT, besides the
original baseline, we develop the other baseline
system by adding name translation table into the
phrase table (NPhrase).
Table 2 presents the performance of overal-
l translation and name translation. We can see
that except for the BOLT3 data set with BLEU
metric, our NAMT approach consistently outper-
formed the baseline system for all data sets with
all metrics, and provided up to 23.6% relative er-
ror reduction on name translation. According to
Wilcoxon Matched-Pairs Signed-Ranks Test, the
improvement is not significant with BLEU metric,
but is significant at 98% confidence level with all
of the other metrics. The gains are more signifi-
cant for formal genres than informal genres main-
ly because most of the training data for name tag-
ging and name translation were from newswire.
Furthermore, using external name translation table
only did not improve translation quality in most
test sets except for BOLT2. Therefore, it is im-
portant to use name-replaced corpora for rule ex-
traction to fully take advantage of improved word
alignment.
Many errors from the baseline MT approach oc-
curred because some parts of out-of-vocabulary
names were mistakenly segmented into common
words. For example, the baseline MT system mis-
takenly translated a person name “-4�_IN (Sun
Honglei)” into “Sun red thunder”. In informal
genres such as discussion forums and web blogs,
even common names often appear in rare form-
s due to misspelling or morphing. For example,
“A (Obama)” was mistakenly translated into
“Ma Olympic”. Such errors can be compounded
when word re-ordering was applied. For example,
the following sentence: “ XXMfi -A)ZA
)ON,-A)ZI i ,ERA (Guo Meimei’s strength real-
ly is formidable, I really admire her)” was mis-
takenly translated into “Guo the strength of the
America and the America also really strong, ah
, really admire her” by the baseline MT system
because the person name “#3XX (Guomeimei)”
was mistakenly segmented into three words “#3
(Guo)”, “X (the America)” and “X (the Ameri-
ca)”. But our NAMT approach successfully iden-
tified and translated this name and also generated
better overall translation: “Guo Meimei ’s power
is also really strong, ah , really admire her”.
</bodyText>
<page confidence="0.997627">
609
</page>
<table confidence="0.972389538461539">
Words Method P R F
Overall Baseline Giza++ 69.8 47.8 56.7
Words
Joint Name 70.4 48.1 57.1
Tagging
Ground-truth 71.3 48.9 58.0
Name Tagging
(Upper-bound)
Words Baseline Giza++ 86.0 31.4 46.0
Within
Names
Joint Name 77.6 37.2 50.3
Tagging
</table>
<tableCaption confidence="0.972377">
Table 3: Impact of Joint Bilingual Name Tagging on Word
</tableCaption>
<figure confidence="0.989048620689655">
Alignment (%).
baseline
NAMT
BLEU Name-aware
BLEU
H u m . 1 H u m . 2 H u m . 3
Score
20
1 8
1 6
1 4
1 2
1 0
8
6
4
2
0
Score
4.0
3.5
3.0
2.5
2.0
0.5
0.0
1 .5
1 .0
Automatic Metrics Human Evaluation
</figure>
<figureCaption confidence="0.9826225">
Figure 2: Scores based on Automatic Metrics and Human
Evaluation.
</figureCaption>
<subsectionHeader confidence="0.489014">
5.3 Name-aware BLEU vs The Human
Evaluation
</subsectionHeader>
<bodyText confidence="0.999951083333333">
In order to investigate the correlation between
name-aware BLEU scores and human judgment
results, we asked three bi-lingual speakers to judge
our translation output from the baseline system
and the NAMT system, on a Chinese subset of 250
sentences (each sentence has two corresponding
translations from baseline and NAMT) extracted
randomly from 7 test corpora. The annotators rat-
ed each translation from 1 (very bad) to 5 (very
good) and made their judgments based on whether
the translation is understandable and conveys the
same meaning.
We computed the name-aware BLEU scores on
the subset and also the aggregated average scores
from human judgments. Figure 2 shows that
NAMT consistently achieved higher scores with
both name-aware BLEU metric and human judge-
ment. Furthermore, we calculated three Pearson
product-moment correlation coefficients between
human judgment scores and name-aware BLEU s-
cores of these two MT systems. Give the sample
size and the correlation coefficient value, the high
significance value of 0.99 indicates that name-
aware BLEU tracks human judgment well.
</bodyText>
<subsectionHeader confidence="0.990903">
5.4 Word Alignment
</subsectionHeader>
<bodyText confidence="0.997951655172414">
It is also important to investigate the impact of our
NAMT approach on improving word alignmen-
t. We conducted the experiment on the Chinese-
English Parallel Treebank (Li et al., 2010) with
ground-truth word alignment. The detailed pro-
cedure following NAMT framework is as follows:
(1) Ran the joint bilingual name tagger; (2) Re-
placed each name string with its name type (PER,
ORG or GPE), and ran Giza++ on the replaced
sentences; (3) Ran Giza++ on the words within
each name pair. (4) Merged (2) and (3) to pro-
duce the final word alignment results. In order to
compare with the upper-bound gains, we also mea-
sured the performance of applying ground-truth
name tagging with the above procedures.
The experiment results are shown in Table 3.
For the words within names, our approach provid-
ed significant gains by enhancing F-measure from
46.0% to 50.3%. Only 10.6% words are within
names, therefore the upper-bound gains on over-
all word alignment is only 1.3%. Our joint name
tagging approach achieved 0.4% (statistically sig-
nificant) improvement over the baseline. In Fig-
ure 3 we categorized the sentences according to
the percentage of name words in each sentence and
measured the improvement for each category. We
can clearly see that as the sentences include more
names, the gains achieved by our approach tend to
be greater.
</bodyText>
<subsectionHeader confidence="0.994999">
5.5 Remaining Error Analysis
</subsectionHeader>
<bodyText confidence="0.99812425">
Although the proposed model has significantly en-
hanced translation quality, some challenges re-
main. We analyze some major sources of the re-
maining errors as follows.
</bodyText>
<listItem confidence="0.70224">
1. Name Structure Parsing.
</listItem>
<bodyText confidence="0.997278555555556">
We found that the gains of our NAMT approach
were mainly achieved for names with one or two
components. When the name structure becomes
too complicated to parse, name tagging and name
translation are likely to produce errors, especially
for long nested organizations. For example, “W�
-9 ,R &amp;it ” (Anti-malfeasance Bureau of
Gutian County Procuratorate) consists of a nested
organization name with a GPE as modifier: “W
</bodyText>
<listItem confidence="0.9105695">
-9 R” (Gutian County Procuratorate) and
an ORG name: “&amp;� ” (Anti-malfeasance Bu-
reau).
2. Name abbreviation tagging and translation.
Some organization abbreviations are also dif-
ficult to extract because our name taggers have
</listItem>
<page confidence="0.982874">
610
</page>
<figure confidence="0.992096">
5.5
5.0
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
-0.5
0~10 10~20 20~30 30~40 &gt;40
#name tokens/#all tokens(%)
</figure>
<figureCaption confidence="0.9962615">
Figure 3: Word alignment gains according to the percentage
of name words in each sentence.
</figureCaption>
<bodyText confidence="0.9990868">
not incorporated any coreference resolution tech-
niques. For example, without knowing that “FAW”
refers to “First Automotive Works” in “FAW has
also utilized the capital market to directly fi-
nance, and now owns three domestic listed compa-
nies”, our system mistakenly labeled it as a GPE.
The same challenge exists in name alignment and
translation (for example, “ F�* (Min Ge)” refer-
s to “ +QQF�k*1r �kYr: ” (Revolutionary
Committee of the Chinese Kuomintang).
</bodyText>
<listItem confidence="0.781569">
3. Cross-lingual information transfer
</listItem>
<bodyText confidence="0.998960769230769">
English monolingual features normally gener-
ate higher confidence than Chinese features for
ORG names. On the other hand, some good prop-
agated Chinese features were not able to correct
English results. For example, in the following sen-
tence pair: “V,9+N,ZD VnNAAWE
1i_k)AM... (in accordance with the tripartite a-
greement reached by China, Laos and the UNHCR
on)...”, even though the tagger can successfully la-
bel “IK&apos;nQAF�X/UNHCR” as an organization
because it is a common Chinese name, English
features based on previous GPE contexts still in-
correctly predicted “UNHCR” as a GPE name.
</bodyText>
<sectionHeader confidence="0.999857" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.97417025">
Two types of humble strategies were previously
attempted to build name translation components
which operate in tandem and loosely integrate into
conventional statistical MT systems:
</bodyText>
<listItem confidence="0.791538">
1. Pre-processing: identify names in the source
</listItem>
<bodyText confidence="0.956128875">
texts and propose name translations to the
MT system; the name translation results can
be simply but aggressively transferred from
the source to the target side using word align-
ment, or added into phrase table in order to
enable the LM to decide which translations to
choose when encountering the names in the
texts (Ji et al., 2009). Heuristic rules or su-
pervised models can be developed to create
“do-not-translate” list (Babych and Hartley,
2003) or learn “when-to-transliterate” (Her-
mjakob et al., 2008).
2. Post-processing: in a cross-lingual informa-
tion retrieval or question answering frame-
work, online query names can be utilized
to obtain translation and post-edit MT out-
put (Parton et al., 2009; Ma and McKeown,
2009; Parton and McKeown, 2010; Parton et
al., 2012).
It is challenging to decide when to use name
translation results. The simple transfer method en-
sures all name translations appear in the MT out-
put, but it heavily relies on word alignment and
does not take into account word re-ordering or
the words found in a name’s context; therefore it
could mistakenly break some context phrase struc-
tures due to name translation or alignment errors.
The LM selection method often assigns an inap-
propriate weight to the additional name transla-
tion table because it is constructed independent-
ly from translation of context words; therefore af-
ter weighted voting most correct name translations
are not used in the final translation output. Our
experimental results 2 confirmed this weakness.
More importantly, in these approaches the MT
model was still mostly treated as a “black-box”
because neither the translation model nor the LM
was updated or adapted specifically for names.
Recently the wider idea of incorporating seman-
tics into MT has received increased interests. Most
of them designed some certain semantic represen-
tations, such as predicate-argument structure or
semantic role labeling (Wu and Fung, 2009; Liu
and Gildea, 2009; Meyer et al., 2011; Bojar and
Wu, 2012), word sense disambiguation (Carpu-
at and Wu, 2007b; Carpuat and Wu, 2007a) and
graph-structured grammar representation (Jones et
al., 2012). Lo et al. (2012) proposed a semantic
role driven MT metric. However, none of these
work declaratively exploited results from informa-
tion extraction for MT.
Some statistical MT systems (e.g. (Zens et al.,
2005), (Aswani and Gaizauskas, 2005)) have at-
tempted to use text normalization to improve word
alignment for dates, numbers and job titles. But
little reported work has shown the impact of joint
</bodyText>
<table confidence="0.9795675">
F-Measure Gains in Overall Word Alignment (%)
Baseline Giza++
Joint Name Tagging
Ground-truth Name Tagging (Upper-bound)
</table>
<page confidence="0.99796">
611
</page>
<bodyText confidence="0.999696555555556">
name tagging on overall word alignment.
Most of the previous name translation work
combined supervised transliteration approaches
with LM based re-scoring (Knight and Graehl,
1998; Al-Onaizan and Knight, 2002; Huang et
al., 2004). Some recent research used compara-
ble corpora to mine name translation pairs (Feng
et al., 2004; Kutsumi et al., 2004; Udupa et al.,
2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999;
Shao and Ng, 2004; Lu and Zhao, 2006; Hassan
et al., 2007). However, most of these approaches
required large amount of seeds, suffered from In-
formation Extraction errors, and relied on phonet-
ic similarity, context co-occurrence and documen-
t similarity for re-scoring. In contrast, our name
pair mining approach described in this paper does
not require any machine translation or translitera-
tion features.
</bodyText>
<sectionHeader confidence="0.997465" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999986434782609">
We developed a name-aware MT framework
which tightly integrates name tagging and name
translation into training and decoding of MT. Ex-
periments on Chinese-English translation demon-
strated the effectiveness of our approach over a
high-quality MT baseline in both overall transla-
tion and name translation, especially for formal
genres. We also proposed a new name-aware eval-
uation metric. In the future we intend to improve
the framework by training a discriminative model
to automatically assign weights to combine name
translation and baseline translation with additional
features including name confidence values, name
types and global validation evidence, as well as
conducting LM adaptation through bilingual top-
ic modeling and clustering based on name anno-
tations. We also plan to jointly optimize MT and
name tagging by propagating multiple word seg-
mentation and name annotation hypotheses in lat-
tice structure to statistical MT and conduct lattice-
based decoding (Dyer et al., 2008). Furthermore,
we are interested in extending this framework to
translate other out-of-vocabulary terms.
</bodyText>
<sectionHeader confidence="0.959024" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.99991665">
This work was supported by the U.S. Army Re-
search Laboratory under Cooperative Agreement
No. W911NF- 09-2-0053 (NS-CTA), the U.S. NS-
F CAREER Award under Grant IIS-0953149, the
U.S. NSF EAGER Award under Grant No. IIS-
1144111, the U.S. DARPA FA8750-13-2-0041 -
Deep Exploration and Filtering of Text (DEFT)
Program and CUNY Junior Faculty Award. The
views and conclusions contained in this documen-
t are those of the authors and should not be in-
terpreted as representing the official policies, ei-
ther expressed or implied, of the U.S. Govern-
ment. The U.S. Government is authorized to re-
produce and distribute reprints for Governmen-
t purposes notwithstanding any copyright notation
here on. We express our gratitude to Bing Zhao
who provided the test sets and references that were
used for Broad Operational Language Translation
(BOLT) evaluation and thanks to Taylor Cassidy
for constructive comments.
</bodyText>
<sectionHeader confidence="0.998348" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999569742857143">
Y. Al-Onaizan and K. Knight. 2002. Translating
Named Entities Using Monolingual and Bilingual
Resources. In Proceeding ACL’02, pages 400–408.
N. Aswani and R. Gaizauskas. 2005. A Hybrid Ap-
proach to Align Sentences and Words in English-
Hindi Parallel Corpora. In Proceeding ACL’05
Workshop on Building and Using Parallel Texts,
pages 57–64.
Bogdan Babych and Anthony Hartley. 2003. Im-
proving Machine Translation Quality with Automat-
ic Named Entity Recognition. In Proceeding EAMT
’03 workshop on MT and other Language Technol-
ogy Tools, Improving MT through other Language
Technology Tools: Resources and Tools for Building
MT, pages 1–8.
O. Bojar and D. Wu. 2012. Towards a Predicate-
Argument evaluation for MT. In Proceeding of the
Sixth Workshop on Syntax, Semantics and Structure
in Statistical Translation, pages 30–38, July.
Marine Carpuat and Dekai Wu. 2007a. How Phrase
Sense Disambiguation outperforms Word Sense Dis-
ambiguation for Statistical Machine Translation. In
Proceeding TMI’07, pages 43–52.
Marine Carpuat and Dekai Wu. 2007b. Improving Sta-
tistical Machine Translation using Word Sense Dis-
ambiguation. In Proceeding EMNLP-CoNLL’07,
pages 61–72.
Taylor Cassidy, Heng Ji, Hongbo Deng, Jing Zheng,
and Jiawei Han. 2012. Analysis and Refinement of
Cross-lingual Entity Linking. In Proceeding CLE-
F’12, pages 1–12.
Stanley F. Chen and Joshua Goodman. 1996. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Proceeding of ACL’96, pages
310–318.
</reference>
<page confidence="0.988581">
612
</page>
<reference confidence="0.999853653846154">
David Chiang. 2005. A Hierarchical Phrase-based
Model for Statistical Machine Translation. In Pro-
ceeding ACL’05, pages 263–270.
F. Dayne and K. Shahram. 2007. A Sequence Align-
ment Model Based on the Averaged Perceptron. In
Proceeding EMNLP-CoNLL’07, pages 238–247.
C. Dyer, S. Muresan, and P. Resnik. 2008. Generaliz-
ing Word Lattice Translation. In Proceeding ACL-
HLT’08, pages 1012–1020.
D. Feng, Y. Lv, and M. Zhou. 2004. A New Approach
for English-Chinese Named Entity Alignment. In
Proceeding PACLIC’04, pages 372–379.
R. Florian, H. Jing, N. Kambhatla, and I. Zitouni.
2006. Factorizing Complex Models: A Case S-
tudy in Mention Detection. In Proceeding COLING-
ACL’06, pages 473–480.
P. Fung and L. Y. Yee. 1998. An IR Approach for
Translating New Words from Nonparallel and Com-
parable Texts. In Proceeding COLING-ACL’98,
pages 414–420.
D. Hakkani-Tur, H. Ji, and R. Grishman. 2007. Us-
ing Information Extraction to Improve Cross-lingual
Document Retrieval. In Proceeding RANLP Work-
shop on Multi-source, Multilingual Information Ex-
traction and Summarization, pages 17–23.
A. Hassan, H. Fahmy, and H. Hassan. 2007. Im-
proving Named Entity Translation by Exploiting
Comparable and Parallel Corpora. In Proceeding
RANLP’07, pages 1–6.
U. Hermjakob, K. Knight, and H. Daume III. 2008.
Name Translation in Statistical Machine Transla-
tion: Learning When to Transliterate. In Proceeding
ACL’08, pages 389–397.
F. Huang, S. Vogel, and A. Waibel. 2004. Im-
proving Named Entity Translation Combining Pho-
netic and Semantic Similarities. In Proceeding
HLT/NAACL’04, pages 281–288.
H. Ji and R. Grishman. 2006. Analysis and Repair
of Name Tagger Errors. In Proceeding COLING-
ACL’06, pages 420–427.
H. Ji, R. Grishman, D. Freitag, M. Blume, J. Wang,
S. Khadivi, R. Zens, and H. Ney. 2009. Name
Extraction and Translation for Distillation. Hand-
book of Natural Language Processing and Machine
Translation: DARPA Global Autonomous Language
Exploitation.
H. Ji. 2009. Mining Name Translations from Com-
parable Corpora by Creating Bilingual Information
Networks. In Proceeding ACL-IJCNLP’09 work-
shop on Building and Using Comparable Corpora,
pages 34–37.
B. Jones, J. Andreas, D. Bauer, K. M. Hermann, and
K. Knight. 2012. Semantics-Based Machine Trans-
lation with Hyperedge Replacement Grammars. In
Proceeding COLING’12, pages 1359–1376.
K. Knight and J. Graehl. 1998. Machine Translit-
eration. In Computational Linguistics, volume 24,
pages 599–612, Cambridge, MA, USA, December.
MIT Press.
P. Koehn, F. Josef Och, and D. Marcu. 2003. Statis-
tical Phrase-Based Translation. In Proceeding HLT-
NAACL’03, pages 127–133.
T. Kutsumi, T. Yoshimi, K. Kotani, and I. Sata. 2004.
Integrated Use of Internal and External Evidence in
The Alignment of Multi-Word Named Entities. In
Proceeding PACLIC’04, pages 187–196.
X. Li, S. Strassel, S. Grimes, S. Ismael, X. Ma, N. Ge,
A. Bies, N. Xue, and M. Maamouri. 2010. Parallel
Aligned Treebank Corpora at LDC: Methodology,
Annotation and Integration. In Workshop on Anno-
tation and Exploitation of Parallel Corpora (AEPC).
Q. Li, H. Li, H. Ji, W. Wang, J. Zheng, and F. Huang.
2012. Joint Bilingual Name Tagging for Parallel
Corpora. In Proceeding CIKM’12, pages 1727–
1731.
D. Liu and D. Gildea. 2009. Semantic Role Fea-
tures for Machine Translation. In Proceeding COL-
ING’09, pages 716–724.
C. Lo, A. K. Tumuluru, and D. Wu. 2012. Fully Au-
tomatic Semantic MT Evaluation. In Proceeding of
the Seventh Workshop on Statistical Machine Trans-
lation, pages 243–252.
M. Lu and J. Zhao. 2006. Multi-feature based
Chinese-English Named Entity Extraction from
Comparable Corpora. In Proceeding PACLIC’06,
pages 134–141.
W. Ma and K. McKeown. 2009. Where’s the Ver-
b Correcting Machine Translation During Question
Answering. In Proceeding ACL-IJCNLP’09, pages
333–336.
P. McNamee, J. Mayfield, D. Lawrie, D. W. Oard, and
D. Doermann. 2011. Cross-Language Entity Link-
ing. In Proceeding IJCNLP’11.
A. Meyer, M. Kosaka, S. Liao, and N. Xue. 2011. Im-
proving MT Word Alignment Using Aligned Multi-
Stage Parses. In Proceeding ACL-HLT 2011 Work-
shop on Syntax, Semantics and Structure in Statisti-
cal Translation, pages 88–97.
T. T. Nguyen, A. Moschitti, and G. Riccardi. 2010.
Kernel-based Reranking for Named-Entity Extrac-
tion. In Proceeding COLING’10, pages 901–909.
F. J. Och and H. Ney. 2003. A Systematic Comparison
of Various Statistical Alignment Models. Computa-
tional Linguistics, 29(1):19–51.
</reference>
<page confidence="0.988296">
613
</page>
<reference confidence="0.99981516923077">
F. J. Och. 2003. Minimum Error Rate Training in
Statistical Machine Translation. In Proceeding A-
CL’03, pages 160–167.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a Method for Automatic Evaluation of Ma-
chine Translation. In Proceeding ACL’02, pages
311–318.
K. Parton and K. McKeown. 2010. MT Error Detec-
tion for Cross-Lingual Question Answering. Pro-
ceeding COLING’10, pages 946–954.
K. Parton, K. R. McKeown, R. Coyne, M. T. Dia-
b, R. Grishman, D. Hakkani-Tur, M. Harper, H. Ji,
W. Y. Ma, A. Meyers, S. Stolbach, A. Sun, G. Tur,
W. Xu, and S. Yaman. 2009. Who, What, When,
Where, Why? Comparing Multiple Approaches to
the Cross-Lingual 5W Task. In Proceeding ACL-
IJCNLP’09, pages 423–431.
K. Parton, N. Habash, K. McKeown, G. Iglesias,
and A. de Gispert. 2012. Can Automatic Post-
Editing Make MT More Meaningful? In Proceeding
EAMT’12, pages 111–118.
R. Rapp. 1999. Automatic Identification of Word
Translations from Unrelated English and German
Corpora. In Proceeding ACL’99, pages 519–526.
L. Shao and H. T. Ng. 2004. Mining New Word Trans-
lations from Comparable Corpora. In Proceeding
COLING’04.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and
J. Makhoul. 2006. A Study of Translation Edit Rate
with Targeted Human Annotation. In Proceeding of
Association for Machine Translation in the Americ-
as, pages 223–231.
M. Snover, X. Li, W. Lin, Z. Chen, S. Tamang, M. Ge,
A. Lee, Q. Li, H. Li, S. Anzaroot, and H. Ji. 2011.
Cross-lingual Slot Filling from Comparable Corpo-
ra. In Proceeding ACL’11 Worshop on Building and
Using Comparable Corpora, pages 110–119.
D. Talbot and T. Brants. 2008. Randomized Language
Models via Perfect Hash Functions. In Proceeding
of ACL/HLT’08, pages 505–513.
R. Udupa, K. Saravanan, A. Kumaran, and J. Jagarla-
mudi. 2009. MINT: A Method for Effective and
Scalable Mining of Named Entity Transliterations
from Large Comparable Corpora. In Proceeding
EACL’09, pages 799–807.
A. Venkataraman, A. Stolcke, W. Wang, D. Vergyri,
V. R. R. Gadde, and J. Zheng. 2004. An Efficient
Repair Procedure For Quick Transcriptions. In Pro-
ceeding INTERSPEECH’04, pages 1961–1964.
D. Wu and P. Fung. 2009. Semantic Roles for SMT: A
Hybrid Two-Pass Model. In NAACL HLT’09, pages
13–16.
R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov,
J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH
Phrase-based Statistical Machine Translation Sys-
tem. In Proceeding IWSLT’05, pages 155–162.
J. Zheng, N. F. Ayan, W. Wang, and D. Burkett.
2009. Using Syntax in Large-Scale Audio Doc-
ument Translation. In Proceeding Interspeech’09,
pages 440–443.
J. Zheng. 2008. SRInterp: SRI’s Scalable Multipur-
pose SMT Engine. In Technical Report.
I. Zitouni and R. Florian. 2008. Mention Detec-
tion Crossing the Language Barrier. In Proceeding
EMNLP’08, pages 600–609.
</reference>
<page confidence="0.998157">
614
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.536166">
<title confidence="0.999873">Name-aware Machine Translation</title>
<author confidence="0.999933">Jing Heng Qi Wen</author>
<affiliation confidence="0.9958835">Science Department and Linguistics Department Technology &amp; Research Laboratory Queens College and Graduate Center, City University of New York SRI International</affiliation>
<address confidence="0.999496">New York, NY, USA 10016 Menlo Park, CA, USA 94025</address>
<email confidence="0.963114">hengjicuny,</email>
<abstract confidence="0.999717444444445">We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over</abstract>
<intro confidence="0.564898">high-quality MT</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>K Knight</author>
</authors>
<title>Translating Named Entities Using Monolingual and Bilingual Resources.</title>
<date>2002</date>
<booktitle>In Proceeding ACL’02,</booktitle>
<pages>400--408</pages>
<contexts>
<context position="31702" citStr="Al-Onaizan and Knight, 2002" startWordPosition="5186" endWordPosition="5189">loited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration fe</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Y. Al-Onaizan and K. Knight. 2002. Translating Named Entities Using Monolingual and Bilingual Resources. In Proceeding ACL’02, pages 400–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Aswani</author>
<author>R Gaizauskas</author>
</authors>
<title>A Hybrid Approach to Align Sentences and Words in EnglishHindi Parallel Corpora.</title>
<date>2005</date>
<booktitle>In Proceeding ACL’05 Workshop on Building and Using Parallel Texts,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="31210" citStr="Aswani and Gaizauskas, 2005" startWordPosition="5113" endWordPosition="5116">into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et </context>
</contexts>
<marker>Aswani, Gaizauskas, 2005</marker>
<rawString>N. Aswani and R. Gaizauskas. 2005. A Hybrid Approach to Align Sentences and Words in EnglishHindi Parallel Corpora. In Proceeding ACL’05 Workshop on Building and Using Parallel Texts, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bogdan Babych</author>
<author>Anthony Hartley</author>
</authors>
<title>Improving Machine Translation Quality with Automatic Named Entity Recognition.</title>
<date>2003</date>
<booktitle>In Proceeding EAMT ’03 workshop on MT and other Language Technology Tools, Improving MT through other Language Technology Tools: Resources and Tools for Building MT,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="29288" citStr="Babych and Hartley, 2003" startWordPosition="4809" endWordPosition="4812">ed to build name translation components which operate in tandem and loosely integrate into conventional statistical MT systems: 1. Pre-processing: identify names in the source texts and propose name translations to the MT system; the name translation results can be simply but aggressively transferred from the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it heavily relies on word alignment and does not take into account word re-ordering or the words found in a name’s contex</context>
</contexts>
<marker>Babych, Hartley, 2003</marker>
<rawString>Bogdan Babych and Anthony Hartley. 2003. Improving Machine Translation Quality with Automatic Named Entity Recognition. In Proceeding EAMT ’03 workshop on MT and other Language Technology Tools, Improving MT through other Language Technology Tools: Resources and Tools for Building MT, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bojar</author>
<author>D Wu</author>
</authors>
<title>Towards a PredicateArgument evaluation for MT.</title>
<date>2012</date>
<booktitle>In Proceeding of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>30--38</pages>
<contexts>
<context position="30829" citStr="Bojar and Wu, 2012" startWordPosition="5055" endWordPosition="5058">ng most correct name translations are not used in the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza+</context>
</contexts>
<marker>Bojar, Wu, 2012</marker>
<rawString>O. Bojar and D. Wu. 2012. Towards a PredicateArgument evaluation for MT. In Proceeding of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 30–38, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>How Phrase Sense Disambiguation outperforms Word Sense Disambiguation for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceeding TMI’07,</booktitle>
<pages>43--52</pages>
<contexts>
<context position="30878" citStr="Carpuat and Wu, 2007" startWordPosition="5062" endWordPosition="5066">n the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (U</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007a. How Phrase Sense Disambiguation outperforms Word Sense Disambiguation for Statistical Machine Translation. In Proceeding TMI’07, pages 43–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving Statistical Machine Translation using Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceeding EMNLP-CoNLL’07,</booktitle>
<pages>61--72</pages>
<contexts>
<context position="30878" citStr="Carpuat and Wu, 2007" startWordPosition="5062" endWordPosition="5066">n the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (U</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007b. Improving Statistical Machine Translation using Word Sense Disambiguation. In Proceeding EMNLP-CoNLL’07, pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Heng Ji</author>
<author>Hongbo Deng</author>
<author>Jing Zheng</author>
<author>Jiawei Han</author>
</authors>
<title>Analysis and Refinement of Cross-lingual Entity Linking.</title>
<date>2012</date>
<booktitle>In Proceeding CLEF’12,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="1424" citStr="Cassidy et al., 2012" startWordPosition="204" endWordPosition="208">t weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at htt</context>
</contexts>
<marker>Cassidy, Ji, Deng, Zheng, Han, 2012</marker>
<rawString>Taylor Cassidy, Heng Ji, Hongbo Deng, Jing Zheng, and Jiawei Han. 2012. Analysis and Refinement of Cross-lingual Entity Linking. In Proceeding CLEF’12, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling. Proceeding of ACL’96,</title>
<date>1996</date>
<pages>310--318</pages>
<contexts>
<context position="6224" citStr="Chen and Goodman, 1996" startWordPosition="972" endWordPosition="975">d in derivation. • Translation length: number of words in translation output. Our previous work showed that combining multiple LMs trained from different sources can lead to significant improvement. The LM used for decoding is a log-linear combination of four word n-gram LMs which are built on different English corpora (details described in section 5.1), with the LM weights optimized on a development set and determined by minimum error rate training (MERT), to estimate the probability of a word given the preceding words. All four LMs were trained using modified Kneser-Ney smoothing algorithm (Chen and Goodman, 1996) and converted into Bloom filter LMs (Talbot and Brants, 2008) supporting memory map. The scaling factors for all features are optimized by minimum error rate training algorithm to maximize BLEU score (Och, 2003). Given an input sentence in the source language, translation into the target language is cast as a search problem, where the goal is to find the highest-probability derivation that generates the source-side sentence, using the rules in our SCFG. The source-side derivation corresponds to a synchronous targetside derivation and the terminal yield of this targetside derivation is the out</context>
</contexts>
<marker>Chen, Goodman, 1996</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1996. An Empirical Study of Smoothing Techniques for Language Modeling. Proceeding of ACL’96, pages 310–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceeding ACL’05,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="4652" citStr="Chiang, 2005" startWordPosition="707" endWordPosition="708">ment and grammar extraction (Section 3.1). 2. Tightly integrate name tagging and translation into MT decoding via name-aware grammar (Section 3.2). 3. Optimize name translation and context translation simultaneously and conduct name translation driven decoding with language model (LM) based selection (Section 3.2). 4. Propose a new MT evaluation metric which can discriminate names and non-informative words (Section 4). 2 Baseline NIT As our baseline, we apply a high-performing Chinese-English MT system (Zheng, 2008; Zheng et al., 2009) based on hierarchical phrase-based translation framework (Chiang, 2005). It is based on a weighted synchronous context-free grammar (SCFG). All SCFG rules are associated with a set of features that are used to compute derivation probabilities. The features include: • Relative frequency in two directions P(-y|α) and P(α|-y), estimating the likelihoods of one side of the rule r: X →&lt; -y, α &gt; translating into the other side, where -y and α are strings of terminals and non-terminals in the source side and target side. Non-terminals in -y and α are in one-to-one correspondence. • Lexical weights in two directions: P,,,(-y|α) and P,,,(α|-y), estimating likelihoods of w</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A Hierarchical Phrase-based Model for Statistical Machine Translation. In Proceeding ACL’05, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Dayne</author>
<author>K Shahram</author>
</authors>
<title>A Sequence Alignment Model Based on the Averaged Perceptron.</title>
<date>2007</date>
<booktitle>In Proceeding EMNLP-CoNLL’07,</booktitle>
<pages>238--247</pages>
<contexts>
<context position="10860" citStr="Dayne and Shahram, 2007" startWordPosition="1736" endWordPosition="1739">om a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier based on Chinese last name list (446 name characters) and name structure parsing features to distinguish Chinese person names and foreign person names (Ji, 2009), so that pinyin conversion is applied for Chinese names while name transliteration is applied only for foreign names. This classifier works reasonably well in most cases (about 92% classification accuracy), except when a common Chinese last name appears as the first ch</context>
</contexts>
<marker>Dayne, Shahram, 2007</marker>
<rawString>F. Dayne and K. Shahram. 2007. A Sequence Alignment Model Based on the Averaged Perceptron. In Proceeding EMNLP-CoNLL’07, pages 238–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>S Muresan</author>
<author>P Resnik</author>
</authors>
<title>Generalizing Word Lattice Translation.</title>
<date>2008</date>
<booktitle>In Proceeding ACLHLT’08,</booktitle>
<pages>1012--1020</pages>
<contexts>
<context position="33327" citStr="Dyer et al., 2008" startWordPosition="5440" endWordPosition="5443">valuation metric. In the future we intend to improve the framework by training a discriminative model to automatically assign weights to combine name translation and baseline translation with additional features including name confidence values, name types and global validation evidence, as well as conducting LM adaptation through bilingual topic modeling and clustering based on name annotations. We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct latticebased decoding (Dyer et al., 2008). Furthermore, we are interested in extending this framework to translate other out-of-vocabulary terms. Acknowledgement This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement No. W911NF- 09-2-0053 (NS-CTA), the U.S. NSF CAREER Award under Grant IIS-0953149, the U.S. NSF EAGER Award under Grant No. IIS1144111, the U.S. DARPA FA8750-13-2-0041 - Deep Exploration and Filtering of Text (DEFT) Program and CUNY Junior Faculty Award. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the officia</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing Word Lattice Translation. In Proceeding ACLHLT’08, pages 1012–1020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Feng</author>
<author>Y Lv</author>
<author>M Zhou</author>
</authors>
<title>A New Approach for English-Chinese Named Entity Alignment.</title>
<date>2004</date>
<booktitle>In Proceeding PACLIC’04,</booktitle>
<pages>372--379</pages>
<contexts>
<context position="31819" citStr="Feng et al., 2004" startWordPosition="5206" endWordPosition="5209">s, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging an</context>
</contexts>
<marker>Feng, Lv, Zhou, 2004</marker>
<rawString>D. Feng, Y. Lv, and M. Zhou. 2004. A New Approach for English-Chinese Named Entity Alignment. In Proceeding PACLIC’04, pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
<author>H Jing</author>
<author>N Kambhatla</author>
<author>I Zitouni</author>
</authors>
<title>Factorizing Complex Models: A Case Study in Mention Detection.</title>
<date>2006</date>
<booktitle>In Proceeding COLINGACL’06,</booktitle>
<pages>473--480</pages>
<contexts>
<context position="10428" citStr="Florian et al., 2006" startWordPosition="1665" endWordPosition="1668">RXf �* *)1 1iA ��-&amp;quot;fEL �+J� . • China appeals to world for non involvement in Angola conflict. after name tagging it becomes • GPE &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier</context>
</contexts>
<marker>Florian, Jing, Kambhatla, Zitouni, 2006</marker>
<rawString>R. Florian, H. Jing, N. Kambhatla, and I. Zitouni. 2006. Factorizing Complex Models: A Case Study in Mention Detection. In Proceeding COLINGACL’06, pages 473–480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>L Y Yee</author>
</authors>
<title>An IR Approach for Translating New Words from Nonparallel and Comparable Texts.</title>
<date>1998</date>
<booktitle>In Proceeding COLING-ACL’98,</booktitle>
<pages>414--420</pages>
<contexts>
<context position="31891" citStr="Fung and Yee, 1998" startWordPosition="5220" endWordPosition="5223">nment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chin</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>P. Fung and L. Y. Yee. 1998. An IR Approach for Translating New Words from Nonparallel and Comparable Texts. In Proceeding COLING-ACL’98, pages 414–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hakkani-Tur</author>
<author>H Ji</author>
<author>R Grishman</author>
</authors>
<title>Using Information Extraction to Improve Cross-lingual Document Retrieval.</title>
<date>2007</date>
<booktitle>In Proceeding RANLP Workshop on Multi-source, Multilingual Information Extraction and Summarization,</booktitle>
<pages>17--23</pages>
<contexts>
<context position="1469" citStr="Hakkani-Tur et al., 2007" startWordPosition="211" endWordPosition="214"> their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical sta</context>
</contexts>
<marker>Hakkani-Tur, Ji, Grishman, 2007</marker>
<rawString>D. Hakkani-Tur, H. Ji, and R. Grishman. 2007. Using Information Extraction to Improve Cross-lingual Document Retrieval. In Proceeding RANLP Workshop on Multi-source, Multilingual Information Extraction and Summarization, pages 17–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hassan</author>
<author>H Fahmy</author>
<author>H Hassan</author>
</authors>
<title>Improving Named Entity Translation by Exploiting Comparable and Parallel Corpora.</title>
<date>2007</date>
<booktitle>In Proceeding RANLP’07,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="31963" citStr="Hassan et al., 2007" startWordPosition="5234" endWordPosition="5237">shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English translation demonstrated the effectiveness of our approach o</context>
</contexts>
<marker>Hassan, Fahmy, Hassan, 2007</marker>
<rawString>A. Hassan, H. Fahmy, and H. Hassan. 2007. Improving Named Entity Translation by Exploiting Comparable and Parallel Corpora. In Proceeding RANLP’07, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
<author>K Knight</author>
<author>H Daume</author>
</authors>
<title>Name Translation in Statistical Machine Translation: Learning When to Transliterate.</title>
<date>2008</date>
<booktitle>In Proceeding ACL’08,</booktitle>
<pages>389--397</pages>
<contexts>
<context position="18861" citStr="Hermjakob et al., 2008" startWordPosition="3087" endWordPosition="3090">n seven test sets from multiple genres and domains. We asked four annotators to annotate names in four reference translations of each sentence and an expert annotator to adjudicate results. The detailed statistics and name distribution of each test data set is shown in Table 1. The percentage of names occurred fewer than 5 times in training data are listed in the brackets in the last column of the table. 5.2 Overall Performance Besides the new name-aware MT metric, we also adopt two traditional metrics, TER to evaluate the overall translation performance and Named Entity Weak Accuracy (NEWA) (Hermjakob et al., 2008) to evaluate the name translation performance. TER measures the amount of edits required to change a system output into one of the reference translations. Specifically: # of edits TER = (10) average # of reference words Possible edits include insertion, substitution deletion and shifts of words. The NEWA metric is defined as follows. Using a manually assembled name variant table, we also support the matching of name variants (e.g., “World Health Organization” and “WHO”). Count # of correctly translated names NEWA = (11) Count # of names in references 608 Corpus Genre Sentence # Word # Token # </context>
<context position="29346" citStr="Hermjakob et al., 2008" startWordPosition="4816" endWordPosition="4820">dem and loosely integrate into conventional statistical MT systems: 1. Pre-processing: identify names in the source texts and propose name translations to the MT system; the name translation results can be simply but aggressively transferred from the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it heavily relies on word alignment and does not take into account word re-ordering or the words found in a name’s context; therefore it could mistakenly break some context phrase</context>
</contexts>
<marker>Hermjakob, Knight, Daume, 2008</marker>
<rawString>U. Hermjakob, K. Knight, and H. Daume III. 2008. Name Translation in Statistical Machine Translation: Learning When to Transliterate. In Proceeding ACL’08, pages 389–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>S Vogel</author>
<author>A Waibel</author>
</authors>
<title>Improving Named Entity Translation Combining Phonetic and Semantic Similarities.</title>
<date>2004</date>
<booktitle>In Proceeding HLT/NAACL’04,</booktitle>
<pages>281--288</pages>
<contexts>
<context position="31723" citStr="Huang et al., 2004" startWordPosition="5190" endWordPosition="5193">on extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions</context>
</contexts>
<marker>Huang, Vogel, Waibel, 2004</marker>
<rawString>F. Huang, S. Vogel, and A. Waibel. 2004. Improving Named Entity Translation Combining Phonetic and Semantic Similarities. In Proceeding HLT/NAACL’04, pages 281–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
<author>R Grishman</author>
</authors>
<title>Analysis and Repair of Name Tagger Errors.</title>
<date>2006</date>
<booktitle>In Proceeding COLINGACL’06,</booktitle>
<pages>420--427</pages>
<contexts>
<context position="10406" citStr="Ji and Grishman, 2006" startWordPosition="1660" endWordPosition="1664">g sentence pair: • rpW RXf �* *)1 1iA ��-&amp;quot;fEL �+J� . • China appeals to world for non involvement in Angola conflict. after name tagging it becomes • GPE &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a </context>
</contexts>
<marker>Ji, Grishman, 2006</marker>
<rawString>H. Ji and R. Grishman. 2006. Analysis and Repair of Name Tagger Errors. In Proceeding COLINGACL’06, pages 420–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
<author>R Grishman</author>
<author>D Freitag</author>
<author>M Blume</author>
<author>J Wang</author>
<author>S Khadivi</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Name Extraction and Translation for Distillation. Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation.</title>
<date>2009</date>
<contexts>
<context position="2151" citStr="Ji et al., 2009" startWordPosition="316" endWordPosition="319">n et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical statistical MT system can only translate 60% person names correctly (Ji et al., 2009). Incorrect segmentation and translation of names which often carry central meanings of a sentence can also yield incorrect translation of long contexts. Names have been largely neglected in the prior MT research due to the following reasons: • The current dominant automatic MT scoring metrics (such as Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002)) treat all words equally, but names have relative low frequency in text (about 6% in newswire and only 3% in web documents) and thus are vastly outnumbered by function words and common nouns, etc.. • Name translations pose a greater </context>
<context position="10553" citStr="Ji et al., 2009" startWordPosition="1687" endWordPosition="1690">E &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier based on Chinese last name list (446 name characters) and name structure parsing features to distinguish Chinese person name</context>
<context position="29172" citStr="Ji et al., 2009" startWordPosition="4792" endWordPosition="4795">ctly predicted “UNHCR” as a GPE name. 6 Related Work Two types of humble strategies were previously attempted to build name translation components which operate in tandem and loosely integrate into conventional statistical MT systems: 1. Pre-processing: identify names in the source texts and propose name translations to the MT system; the name translation results can be simply but aggressively transferred from the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it he</context>
</contexts>
<marker>Ji, Grishman, Freitag, Blume, Wang, Khadivi, Zens, Ney, 2009</marker>
<rawString>H. Ji, R. Grishman, D. Freitag, M. Blume, J. Wang, S. Khadivi, R. Zens, and H. Ney. 2009. Name Extraction and Translation for Distillation. Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
</authors>
<title>Mining Name Translations from Comparable Corpora by Creating Bilingual Information Networks.</title>
<date>2009</date>
<booktitle>In Proceeding ACL-IJCNLP’09 workshop on Building and Using Comparable Corpora,</booktitle>
<pages>34--37</pages>
<contexts>
<context position="11190" citStr="Ji, 2009" startWordPosition="1789" endWordPosition="1790"> target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier based on Chinese last name list (446 name characters) and name structure parsing features to distinguish Chinese person names and foreign person names (Ji, 2009), so that pinyin conversion is applied for Chinese names while name transliteration is applied only for foreign names. This classifier works reasonably well in most cases (about 92% classification accuracy), except when a common Chinese last name appears as the first character of a foreign 606 name, such as “*AV” which can be translated either as “Jolie” or “Zhu Li”. For those names with fewer than five instances in the training data, we use the name translation system to provide translations; for the rest of the names, we leave them to the baseline MT model to handle. The joint bilingual name</context>
<context position="31871" citStr="Ji, 2009" startWordPosition="5218" endWordPosition="5219"> word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT.</context>
</contexts>
<marker>Ji, 2009</marker>
<rawString>H. Ji. 2009. Mining Name Translations from Comparable Corpora by Creating Bilingual Information Networks. In Proceeding ACL-IJCNLP’09 workshop on Building and Using Comparable Corpora, pages 34–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Jones</author>
<author>J Andreas</author>
<author>D Bauer</author>
<author>K M Hermann</author>
<author>K Knight</author>
</authors>
<title>Semantics-Based Machine Translation with Hyperedge Replacement Grammars.</title>
<date>2012</date>
<booktitle>In Proceeding COLING’12,</booktitle>
<pages>1359--1376</pages>
<contexts>
<context position="30968" citStr="Jones et al., 2012" startWordPosition="5075" endWordPosition="5078">portantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translat</context>
</contexts>
<marker>Jones, Andreas, Bauer, Hermann, Knight, 2012</marker>
<rawString>B. Jones, J. Andreas, D. Bauer, K. M. Hermann, and K. Knight. 2012. Semantics-Based Machine Translation with Hyperedge Replacement Grammars. In Proceeding COLING’12, pages 1359–1376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine Transliteration.</title>
<date>1998</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>24</volume>
<pages>599--612</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA,</location>
<contexts>
<context position="31673" citStr="Knight and Graehl, 1998" startWordPosition="5182" endWordPosition="5185">se work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine tran</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine Transliteration. In Computational Linguistics, volume 24, pages 599–612, Cambridge, MA, USA, December. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F Josef Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceeding HLTNAACL’03,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="5349" citStr="Koehn et al., 2003" startWordPosition="825" endWordPosition="828">rules are associated with a set of features that are used to compute derivation probabilities. The features include: • Relative frequency in two directions P(-y|α) and P(α|-y), estimating the likelihoods of one side of the rule r: X →&lt; -y, α &gt; translating into the other side, where -y and α are strings of terminals and non-terminals in the source side and target side. Non-terminals in -y and α are in one-to-one correspondence. • Lexical weights in two directions: P,,,(-y|α) and P,,,(α|-y), estimating likelihoods of words in one side of the rule r: X →&lt; -y, α &gt; translating into the other side (Koehn et al., 2003). • Phrase penalty: a penalty exp(1) for a rule with no non-terminal being used in derivation. • Rule penalty: a penalty exp(1) for a rule with at least one non-terminal being used in derivation. • Glue rule penalty: a penalty exp(1) if a glue rule used in derivation. • Translation length: number of words in translation output. Our previous work showed that combining multiple LMs trained from different sources can lead to significant improvement. The LM used for decoding is a log-linear combination of four word n-gram LMs which are built on different English corpora (details described in secti</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. Josef Och, and D. Marcu. 2003. Statistical Phrase-Based Translation. In Proceeding HLTNAACL’03, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kutsumi</author>
<author>T Yoshimi</author>
<author>K Kotani</author>
<author>I Sata</author>
</authors>
<title>Integrated Use of Internal and External Evidence in The Alignment of Multi-Word Named Entities.</title>
<date>2004</date>
<booktitle>In Proceeding PACLIC’04,</booktitle>
<pages>187--196</pages>
<contexts>
<context position="31841" citStr="Kutsumi et al., 2004" startWordPosition="5210" endWordPosition="5213">mpted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation int</context>
</contexts>
<marker>Kutsumi, Yoshimi, Kotani, Sata, 2004</marker>
<rawString>T. Kutsumi, T. Yoshimi, K. Kotani, and I. Sata. 2004. Integrated Use of Internal and External Evidence in The Alignment of Multi-Word Named Entities. In Proceeding PACLIC’04, pages 187–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>S Strassel</author>
<author>S Grimes</author>
<author>S Ismael</author>
<author>X Ma</author>
<author>N Ge</author>
<author>A Bies</author>
<author>N Xue</author>
<author>M Maamouri</author>
</authors>
<title>Parallel Aligned Treebank Corpora at LDC: Methodology, Annotation and Integration.</title>
<date>2010</date>
<booktitle>In Workshop on Annotation and Exploitation of Parallel Corpora (AEPC).</booktitle>
<contexts>
<context position="25295" citStr="Li et al., 2010" startWordPosition="4164" endWordPosition="4167">at NAMT consistently achieved higher scores with both name-aware BLEU metric and human judgement. Furthermore, we calculated three Pearson product-moment correlation coefficients between human judgment scores and name-aware BLEU scores of these two MT systems. Give the sample size and the correlation coefficient value, the high significance value of 0.99 indicates that nameaware BLEU tracks human judgment well. 5.4 Word Alignment It is also important to investigate the impact of our NAMT approach on improving word alignment. We conducted the experiment on the ChineseEnglish Parallel Treebank (Li et al., 2010) with ground-truth word alignment. The detailed procedure following NAMT framework is as follows: (1) Ran the joint bilingual name tagger; (2) Replaced each name string with its name type (PER, ORG or GPE), and ran Giza++ on the replaced sentences; (3) Ran Giza++ on the words within each name pair. (4) Merged (2) and (3) to produce the final word alignment results. In order to compare with the upper-bound gains, we also measured the performance of applying ground-truth name tagging with the above procedures. The experiment results are shown in Table 3. For the words within names, our approach </context>
</contexts>
<marker>Li, Strassel, Grimes, Ismael, Ma, Ge, Bies, Xue, Maamouri, 2010</marker>
<rawString>X. Li, S. Strassel, S. Grimes, S. Ismael, X. Ma, N. Ge, A. Bies, N. Xue, and M. Maamouri. 2010. Parallel Aligned Treebank Corpora at LDC: Methodology, Annotation and Integration. In Workshop on Annotation and Exploitation of Parallel Corpora (AEPC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Li</author>
<author>H Li</author>
<author>H Ji</author>
<author>W Wang</author>
<author>J Zheng</author>
<author>F Huang</author>
</authors>
<title>Joint Bilingual Name Tagging for Parallel Corpora.</title>
<date>2012</date>
<booktitle>In Proceeding CIKM’12,</booktitle>
<pages>1727--1731</pages>
<contexts>
<context position="7599" citStr="Li et al., 2012" startWordPosition="1194" endWordPosition="1197">to the above baseline to construct a NAMT model. Figure 1 depicts the general procedure. 3.1 Training This basic training process of NAMT requires us to apply a bilingual name tagger to annotate parallel training corpora. Traditional name tagging approaches for single languages cannot address this requirement because they were all built on data and resources which are specific to each language without using any cross-lingual features. In addition, due to separate decoding processes the results on parallel data may not be consistent across languages. We developed a bilingual joint name tagger (Li et al., 2012) based on conditional random fields that incorporates both monolingual and cross-lingual features and conducts joint inference, so that name tagging from two languages can mutually enhance each other and therefore inconsistent results can be corrected simultaneously. This joint name tagger achieved 86.3% bilingual pair F-measure with manual alignment and 84.4% bilingual pair F-measure with automatic alignment as reported in (Li et al., 2012). Given a parallel sentence pair we first apply Giza++ (Och and Ney, 2003) to align words, and apply this join605 Figure 1: Architecture of Name-aware Mach</context>
<context position="10233" citStr="Li et al., 2012" startWordPosition="1630" endWordPosition="1633">ess this issue, we merged the name-replaced parallel data with the original parallel data and extract grammars from the combined corpus. For example, given the following sentence pair: • rpW RXf �* *)1 1iA ��-&amp;quot;fEL �+J� . • China appeals to world for non involvement in Angola conflict. after name tagging it becomes • GPE &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT mode</context>
</contexts>
<marker>Li, Li, Ji, Wang, Zheng, Huang, 2012</marker>
<rawString>Q. Li, H. Li, H. Ji, W. Wang, J. Zheng, and F. Huang. 2012. Joint Bilingual Name Tagging for Parallel Corpora. In Proceeding CIKM’12, pages 1727– 1731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Liu</author>
<author>D Gildea</author>
</authors>
<title>Semantic Role Features for Machine Translation.</title>
<date>2009</date>
<booktitle>In Proceeding COLING’09,</booktitle>
<pages>716--724</pages>
<contexts>
<context position="30788" citStr="Liu and Gildea, 2009" startWordPosition="5047" endWordPosition="5050">ntext words; therefore after weighted voting most correct name translations are not used in the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in </context>
</contexts>
<marker>Liu, Gildea, 2009</marker>
<rawString>D. Liu and D. Gildea. 2009. Semantic Role Features for Machine Translation. In Proceeding COLING’09, pages 716–724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lo</author>
<author>A K Tumuluru</author>
<author>D Wu</author>
</authors>
<title>Fully Automatic Semantic MT Evaluation.</title>
<date>2012</date>
<booktitle>In Proceeding of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>243--252</pages>
<contexts>
<context position="30986" citStr="Lo et al. (2012)" startWordPosition="5079" endWordPosition="5082">pproaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined </context>
</contexts>
<marker>Lo, Tumuluru, Wu, 2012</marker>
<rawString>C. Lo, A. K. Tumuluru, and D. Wu. 2012. Fully Automatic Semantic MT Evaluation. In Proceeding of the Seventh Workshop on Statistical Machine Translation, pages 243–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lu</author>
<author>J Zhao</author>
</authors>
<title>Multi-feature based Chinese-English Named Entity Extraction from Comparable Corpora.</title>
<date>2006</date>
<booktitle>In Proceeding PACLIC’06,</booktitle>
<pages>134--141</pages>
<contexts>
<context position="31941" citStr="Lu and Zhao, 2006" startWordPosition="5230" endWordPosition="5233"> reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English translation demonstrated the effective</context>
</contexts>
<marker>Lu, Zhao, 2006</marker>
<rawString>M. Lu and J. Zhao. 2006. Multi-feature based Chinese-English Named Entity Extraction from Comparable Corpora. In Proceeding PACLIC’06, pages 134–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ma</author>
<author>K McKeown</author>
</authors>
<title>Where’s the Verb Correcting Machine Translation During Question Answering.</title>
<date>2009</date>
<booktitle>In Proceeding ACL-IJCNLP’09,</booktitle>
<pages>333--336</pages>
<contexts>
<context position="29565" citStr="Ma and McKeown, 2009" startWordPosition="4852" endWordPosition="4855">ssively transferred from the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it heavily relies on word alignment and does not take into account word re-ordering or the words found in a name’s context; therefore it could mistakenly break some context phrase structures due to name translation or alignment errors. The LM selection method often assigns an inappropriate weight to the additional name translation table because it is constructed independently from translation of</context>
</contexts>
<marker>Ma, McKeown, 2009</marker>
<rawString>W. Ma and K. McKeown. 2009. Where’s the Verb Correcting Machine Translation During Question Answering. In Proceeding ACL-IJCNLP’09, pages 333–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P McNamee</author>
<author>J Mayfield</author>
<author>D Lawrie</author>
<author>D W Oard</author>
<author>D Doermann</author>
</authors>
<title>Cross-Language Entity Linking.</title>
<date>2011</date>
<booktitle>In Proceeding IJCNLP’11.</booktitle>
<contexts>
<context position="1401" citStr="McNamee et al., 2011" startWordPosition="200" endWordPosition="203"> by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for </context>
</contexts>
<marker>McNamee, Mayfield, Lawrie, Oard, Doermann, 2011</marker>
<rawString>P. McNamee, J. Mayfield, D. Lawrie, D. W. Oard, and D. Doermann. 2011. Cross-Language Entity Linking. In Proceeding IJCNLP’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyer</author>
<author>M Kosaka</author>
<author>S Liao</author>
<author>N Xue</author>
</authors>
<title>Improving MT Word Alignment Using Aligned MultiStage Parses.</title>
<date>2011</date>
<booktitle>In Proceeding ACL-HLT 2011 Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>88--97</pages>
<contexts>
<context position="30808" citStr="Meyer et al., 2011" startWordPosition="5051" endWordPosition="5054"> after weighted voting most correct name translations are not used in the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignme</context>
</contexts>
<marker>Meyer, Kosaka, Liao, Xue, 2011</marker>
<rawString>A. Meyer, M. Kosaka, S. Liao, and N. Xue. 2011. Improving MT Word Alignment Using Aligned MultiStage Parses. In Proceeding ACL-HLT 2011 Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 88–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T T Nguyen</author>
<author>A Moschitti</author>
<author>G Riccardi</author>
</authors>
<title>Kernel-based Reranking for Named-Entity Extraction.</title>
<date>2010</date>
<booktitle>In Proceeding COLING’10,</booktitle>
<pages>901--909</pages>
<contexts>
<context position="10477" citStr="Nguyen et al., 2010" startWordPosition="1674" endWordPosition="1677">world for non involvement in Angola conflict. after name tagging it becomes • GPE &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier based on Chinese last name list (446 name charac</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2010</marker>
<rawString>T. T. Nguyen, A. Moschitti, and G. Riccardi. 2010. Kernel-based Reranking for Named-Entity Extraction. In Proceeding COLING’10, pages 901–909.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="8118" citStr="Och and Ney, 2003" startWordPosition="1277" endWordPosition="1280">ay not be consistent across languages. We developed a bilingual joint name tagger (Li et al., 2012) based on conditional random fields that incorporates both monolingual and cross-lingual features and conducts joint inference, so that name tagging from two languages can mutually enhance each other and therefore inconsistent results can be corrected simultaneously. This joint name tagger achieved 86.3% bilingual pair F-measure with manual alignment and 84.4% bilingual pair F-measure with automatic alignment as reported in (Li et al., 2012). Given a parallel sentence pair we first apply Giza++ (Och and Ney, 2003) to align words, and apply this join605 Figure 1: Architecture of Name-aware Machine Translation System. t bilingual name tagger to extract three types of names: (Person (PER), Organization (ORG) and Geo-political entities (GPE)) from both the source side and the target side. We pair two entities from two languages, if they have the same entity type and are mapped together by word alignment. We ignore two kinds of names: multi-word names with conflicting boundaries in two languages and names only identified in one side of a parallel sentence. We built a NAMT system from such nametagged paralle</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceeding ACL’03,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="6436" citStr="Och, 2003" startWordPosition="1009" endWordPosition="1010">s a log-linear combination of four word n-gram LMs which are built on different English corpora (details described in section 5.1), with the LM weights optimized on a development set and determined by minimum error rate training (MERT), to estimate the probability of a word given the preceding words. All four LMs were trained using modified Kneser-Ney smoothing algorithm (Chen and Goodman, 1996) and converted into Bloom filter LMs (Talbot and Brants, 2008) supporting memory map. The scaling factors for all features are optimized by minimum error rate training algorithm to maximize BLEU score (Och, 2003). Given an input sentence in the source language, translation into the target language is cast as a search problem, where the goal is to find the highest-probability derivation that generates the source-side sentence, using the rules in our SCFG. The source-side derivation corresponds to a synchronous targetside derivation and the terminal yield of this targetside derivation is the output of the system. We employ our CKY-style chart decoder, named SRInterp, to solve the search problem. 3 Name-aware NIT We tightly integrate name processing into the above baseline to construct a NAMT model. Figu</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceeding ACL’03, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceeding ACL’02,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="2517" citStr="Papineni et al., 2002" startWordPosition="373" endWordPosition="376">mes. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical statistical MT system can only translate 60% person names correctly (Ji et al., 2009). Incorrect segmentation and translation of names which often carry central meanings of a sentence can also yield incorrect translation of long contexts. Names have been largely neglected in the prior MT research due to the following reasons: • The current dominant automatic MT scoring metrics (such as Bilingual Evaluation Understudy (BLEU) (Papineni et al., 2002)) treat all words equally, but names have relative low frequency in text (about 6% in newswire and only 3% in web documents) and thus are vastly outnumbered by function words and common nouns, etc.. • Name translations pose a greater complexity because the set of names is open and highly dynamic. It is also important to acknowledge that there are many fundamental differences between the translation of names and other tokens, depending on whether a name is rendered phonetically, semantically, or a mixture of both (Ji et al., 2009). • The artificial settings of assigning low weights to informati</context>
<context position="12903" citStr="Papineni et al., 2002" startWordPosition="2076" endWordPosition="2079">acted 9,963 unique name translation pairs were also used to create an additional name phrase table for NAMT. Manual evaluation on 2,000 name pairs showed the accuracy is 86%. The non-terminals in SCFG rules are rewritten to the extracted names during decoding, therefore allow unseen names in the test data to be translated. Finally, based on LMs, our decoder exploits the dynamically created phrase table from name translation, competing with originally extracted rules, to find the best translation for the input sentence. 4 Name-aware MT Evaluation Traditional MT evaluation metrics such as BLEU (Papineni et al., 2002) and Translation Edit Rate (TER) (Snover et al., 2006) assign the same weights to all tokens equally. For example, incorrect translations of “the” and “Bush” will receive the same penalty. However, for crosslingual information processing applications, we should acknowledge that certain informationally critical words are more important than other common words. In order to properly evaluate the translation quality of NAMT methods, we propose to modify the BLEU metric so that they can dynamically assign more weights to names during evaluation. BLEU considers the correspondence between a system tr</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceeding ACL’02, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Parton</author>
<author>K McKeown</author>
</authors>
<title>MT Error Detection for Cross-Lingual Question Answering. Proceeding COLING’10,</title>
<date>2010</date>
<pages>946--954</pages>
<contexts>
<context position="1576" citStr="Parton and McKeown, 2010" startWordPosition="228" endWordPosition="231">veness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical statistical MT system can only translate 60% person names correctly (Ji et al., 2009). Incorrect segmentation </context>
<context position="29591" citStr="Parton and McKeown, 2010" startWordPosition="4856" endWordPosition="4859">om the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it heavily relies on word alignment and does not take into account word re-ordering or the words found in a name’s context; therefore it could mistakenly break some context phrase structures due to name translation or alignment errors. The LM selection method often assigns an inappropriate weight to the additional name translation table because it is constructed independently from translation of context words; therefore </context>
</contexts>
<marker>Parton, McKeown, 2010</marker>
<rawString>K. Parton and K. McKeown. 2010. MT Error Detection for Cross-Lingual Question Answering. Proceeding COLING’10, pages 946–954.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Parton</author>
<author>K R McKeown</author>
<author>R Coyne</author>
<author>M T Diab</author>
<author>R Grishman</author>
<author>D Hakkani-Tur</author>
<author>M Harper</author>
<author>H Ji</author>
<author>W Y Ma</author>
<author>A Meyers</author>
<author>S Stolbach</author>
<author>A Sun</author>
<author>G Tur</author>
<author>W Xu</author>
<author>S Yaman</author>
</authors>
<title>Comparing Multiple Approaches to the Cross-Lingual 5W Task.</title>
<date>2009</date>
<booktitle>In Proceeding ACLIJCNLP’09,</booktitle>
<pages>423--431</pages>
<location>Who, What, When, Where, Why?</location>
<contexts>
<context position="1549" citStr="Parton et al., 2009" startWordPosition="224" endWordPosition="227">onstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical statistical MT system can only translate 60% person names correctly (Ji et al., 200</context>
<context position="29543" citStr="Parton et al., 2009" startWordPosition="4848" endWordPosition="4851">n be simply but aggressively transferred from the source to the target side using word alignment, or added into phrase table in order to enable the LM to decide which translations to choose when encountering the names in the texts (Ji et al., 2009). Heuristic rules or supervised models can be developed to create “do-not-translate” list (Babych and Hartley, 2003) or learn “when-to-transliterate” (Hermjakob et al., 2008). 2. Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al., 2009; Ma and McKeown, 2009; Parton and McKeown, 2010; Parton et al., 2012). It is challenging to decide when to use name translation results. The simple transfer method ensures all name translations appear in the MT output, but it heavily relies on word alignment and does not take into account word re-ordering or the words found in a name’s context; therefore it could mistakenly break some context phrase structures due to name translation or alignment errors. The LM selection method often assigns an inappropriate weight to the additional name translation table because it is constructed independent</context>
</contexts>
<marker>Parton, McKeown, Coyne, Diab, Grishman, Hakkani-Tur, Harper, Ji, Ma, Meyers, Stolbach, Sun, Tur, Xu, Yaman, 2009</marker>
<rawString>K. Parton, K. R. McKeown, R. Coyne, M. T. Diab, R. Grishman, D. Hakkani-Tur, M. Harper, H. Ji, W. Y. Ma, A. Meyers, S. Stolbach, A. Sun, G. Tur, W. Xu, and S. Yaman. 2009. Who, What, When, Where, Why? Comparing Multiple Approaches to the Cross-Lingual 5W Task. In Proceeding ACLIJCNLP’09, pages 423–431.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Parton</author>
<author>N Habash</author>
<author>K McKeown</author>
<author>G Iglesias</author>
<author>A de Gispert</author>
</authors>
<title>Can Automatic PostEditing Make MT More Meaningful?</title>
<date>2012</date>
<booktitle>In Proceeding EAMT’12,</booktitle>
<pages>111--118</pages>
<marker>Parton, Habash, McKeown, Iglesias, de Gispert, 2012</marker>
<rawString>K. Parton, N. Habash, K. McKeown, G. Iglesias, and A. de Gispert. 2012. Can Automatic PostEditing Make MT More Meaningful? In Proceeding EAMT’12, pages 111–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Automatic Identification of Word Translations from Unrelated English and German Corpora.</title>
<date>1999</date>
<booktitle>In Proceeding ACL’99,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="31903" citStr="Rapp, 1999" startWordPosition="5224" endWordPosition="5225">bers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English </context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>R. Rapp. 1999. Automatic Identification of Word Translations from Unrelated English and German Corpora. In Proceeding ACL’99, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shao</author>
<author>H T Ng</author>
</authors>
<title>Mining New Word Translations from Comparable Corpora.</title>
<date>2004</date>
<booktitle>In Proceeding COLING’04.</booktitle>
<contexts>
<context position="31922" citStr="Shao and Ng, 2004" startWordPosition="5226" endWordPosition="5229"> titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English translation demonst</context>
</contexts>
<marker>Shao, Ng, 2004</marker>
<rawString>L. Shao and H. T. Ng. 2004. Mining New Word Translations from Comparable Corpora. In Proceeding COLING’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciulla</author>
<author>J Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceeding of Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="12957" citStr="Snover et al., 2006" startWordPosition="2086" endWordPosition="2089"> to create an additional name phrase table for NAMT. Manual evaluation on 2,000 name pairs showed the accuracy is 86%. The non-terminals in SCFG rules are rewritten to the extracted names during decoding, therefore allow unseen names in the test data to be translated. Finally, based on LMs, our decoder exploits the dynamically created phrase table from name translation, competing with originally extracted rules, to find the best translation for the input sentence. 4 Name-aware MT Evaluation Traditional MT evaluation metrics such as BLEU (Papineni et al., 2002) and Translation Edit Rate (TER) (Snover et al., 2006) assign the same weights to all tokens equally. For example, incorrect translations of “the” and “Bush” will receive the same penalty. However, for crosslingual information processing applications, we should acknowledge that certain informationally critical words are more important than other common words. In order to properly evaluate the translation quality of NAMT methods, we propose to modify the BLEU metric so that they can dynamically assign more weights to names during evaluation. BLEU considers the correspondence between a system translation and a human translation: N BLEU = BP · exp (</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J. Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceeding of Association for Machine Translation in the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>X Li</author>
<author>W Lin</author>
<author>Z Chen</author>
<author>S Tamang</author>
<author>M Ge</author>
<author>A Lee</author>
<author>Q Li</author>
<author>H Li</author>
<author>S Anzaroot</author>
<author>H Ji</author>
</authors>
<title>Cross-lingual Slot Filling from Comparable Corpora.</title>
<date>2011</date>
<booktitle>In Proceeding ACL’11 Worshop on Building and Using Comparable Corpora,</booktitle>
<pages>110--119</pages>
<contexts>
<context position="1505" citStr="Snover et al., 2011" startWordPosition="217" endWordPosition="220">xperiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1. 1 Introduction A shrinking fraction of the world’s Web pages are written in English, therefore the ability to access pages across a range of languages is becoming increasingly important. This need can be addressed in part by cross-lingual information access tasks such as entity linking (McNamee et al., 2011; Cassidy et al., 2012), event extraction (Hakkani-Tur et al., 2007), slot filling (Snover et al., 2011) and question answering (Parton et al., 2009; Parton and McKeown, 2010). A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation (MT). Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. 1Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/NAMT.tgz A typical statistical MT system can only translat</context>
</contexts>
<marker>Snover, Li, Lin, Chen, Tamang, Ge, Lee, Li, Li, Anzaroot, Ji, 2011</marker>
<rawString>M. Snover, X. Li, W. Lin, Z. Chen, S. Tamang, M. Ge, A. Lee, Q. Li, H. Li, S. Anzaroot, and H. Ji. 2011. Cross-lingual Slot Filling from Comparable Corpora. In Proceeding ACL’11 Worshop on Building and Using Comparable Corpora, pages 110–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Talbot</author>
<author>T Brants</author>
</authors>
<title>Randomized Language Models via Perfect Hash Functions.</title>
<date>2008</date>
<booktitle>In Proceeding of ACL/HLT’08,</booktitle>
<pages>505--513</pages>
<contexts>
<context position="6286" citStr="Talbot and Brants, 2008" startWordPosition="982" endWordPosition="985">nslation output. Our previous work showed that combining multiple LMs trained from different sources can lead to significant improvement. The LM used for decoding is a log-linear combination of four word n-gram LMs which are built on different English corpora (details described in section 5.1), with the LM weights optimized on a development set and determined by minimum error rate training (MERT), to estimate the probability of a word given the preceding words. All four LMs were trained using modified Kneser-Ney smoothing algorithm (Chen and Goodman, 1996) and converted into Bloom filter LMs (Talbot and Brants, 2008) supporting memory map. The scaling factors for all features are optimized by minimum error rate training algorithm to maximize BLEU score (Och, 2003). Given an input sentence in the source language, translation into the target language is cast as a search problem, where the goal is to find the highest-probability derivation that generates the source-side sentence, using the rules in our SCFG. The source-side derivation corresponds to a synchronous targetside derivation and the terminal yield of this targetside derivation is the output of the system. We employ our CKY-style chart decoder, name</context>
</contexts>
<marker>Talbot, Brants, 2008</marker>
<rawString>D. Talbot and T. Brants. 2008. Randomized Language Models via Perfect Hash Functions. In Proceeding of ACL/HLT’08, pages 505–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Udupa</author>
<author>K Saravanan</author>
<author>A Kumaran</author>
<author>J Jagarlamudi</author>
</authors>
<title>MINT: A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora.</title>
<date>2009</date>
<booktitle>In Proceeding EACL’09,</booktitle>
<pages>799--807</pages>
<contexts>
<context position="31861" citStr="Udupa et al., 2009" startWordPosition="5214" endWordPosition="5217">alization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine name translation pairs (Feng et al., 2004; Kutsumi et al., 2004; Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Lu and Zhao, 2006; Hassan et al., 2007). However, most of these approaches required large amount of seeds, suffered from Information Extraction errors, and relied on phonetic similarity, context co-occurrence and document similarity for re-scoring. In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. 7 Conclusions and Future Work We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decod</context>
</contexts>
<marker>Udupa, Saravanan, Kumaran, Jagarlamudi, 2009</marker>
<rawString>R. Udupa, K. Saravanan, A. Kumaran, and J. Jagarlamudi. 2009. MINT: A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora. In Proceeding EACL’09, pages 799–807.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Venkataraman</author>
<author>A Stolcke</author>
<author>W Wang</author>
<author>D Vergyri</author>
<author>V R R Gadde</author>
<author>J Zheng</author>
</authors>
<title>An Efficient Repair Procedure For Quick Transcriptions.</title>
<date>2004</date>
<booktitle>In Proceeding INTERSPEECH’04,</booktitle>
<pages>1961--1964</pages>
<contexts>
<context position="18135" citStr="Venkataraman et al., 2004" startWordPosition="2966" endWordPosition="2969">olingual discussion forums data listed above. LM3 is a 4-gram LM trained on the web genre among the target side of all parallel text (i.e., web text from pre-BOLT parallel text and BOLT released discussion forum parallel text). LM4 is a 4-gram LM trained on the English broadcast news and conversation transcripts released under the DARPA GALE program. Note that for LM4 training data, some transcripts were quick transcripts and quick rich transcripts released by LDC, and some were generated by running flexible alignment of closed captions or speech recognition output from LDC on the audio data (Venkataraman et al., 2004). In order to demonstrate the effectiveness and generality of our approach, we evaluated our approach on seven test sets from multiple genres and domains. We asked four annotators to annotate names in four reference translations of each sentence and an expert annotator to adjudicate results. The detailed statistics and name distribution of each test data set is shown in Table 1. The percentage of names occurred fewer than 5 times in training data are listed in the brackets in the last column of the table. 5.2 Overall Performance Besides the new name-aware MT metric, we also adopt two tradition</context>
</contexts>
<marker>Venkataraman, Stolcke, Wang, Vergyri, Gadde, Zheng, 2004</marker>
<rawString>A. Venkataraman, A. Stolcke, W. Wang, D. Vergyri, V. R. R. Gadde, and J. Zheng. 2004. An Efficient Repair Procedure For Quick Transcriptions. In Proceeding INTERSPEECH’04, pages 1961–1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>P Fung</author>
</authors>
<title>Semantic Roles for SMT: A Hybrid Two-Pass Model.</title>
<date>2009</date>
<booktitle>In NAACL HLT’09,</booktitle>
<pages>13--16</pages>
<contexts>
<context position="30766" citStr="Wu and Fung, 2009" startWordPosition="5043" endWordPosition="5046">m translation of context words; therefore after weighted voting most correct name translations are not used in the final translation output. Our experimental results 2 confirmed this weakness. More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. Recently the wider idea of incorporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joi</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>D. Wu and P. Fung. 2009. Semantic Roles for SMT: A Hybrid Two-Pass Model. In NAACL HLT’09, pages 13–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>O Bender</author>
<author>S Hasan</author>
<author>S Khadivi</author>
<author>E Matusov</author>
<author>J Xu</author>
<author>Y Zhang</author>
<author>H Ney</author>
</authors>
<title>The RWTH Phrase-based Statistical Machine Translation System. In</title>
<date>2005</date>
<booktitle>Proceeding IWSLT’05,</booktitle>
<pages>155--162</pages>
<contexts>
<context position="31179" citStr="Zens et al., 2005" startWordPosition="5109" endWordPosition="5112">orporating semantics into MT has received increased interests. Most of them designed some certain semantic representations, such as predicate-argument structure or semantic role labeling (Wu and Fung, 2009; Liu and Gildea, 2009; Meyer et al., 2011; Bojar and Wu, 2012), word sense disambiguation (Carpuat and Wu, 2007b; Carpuat and Wu, 2007a) and graph-structured grammar representation (Jones et al., 2012). Lo et al. (2012) proposed a semantic role driven MT metric. However, none of these work declaratively exploited results from information extraction for MT. Some statistical MT systems (e.g. (Zens et al., 2005), (Aswani and Gaizauskas, 2005)) have attempted to use text normalization to improve word alignment for dates, numbers and job titles. But little reported work has shown the impact of joint F-Measure Gains in Overall Word Alignment (%) Baseline Giza++ Joint Name Tagging Ground-truth Name Tagging (Upper-bound) 611 name tagging on overall word alignment. Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al., 2004). Some recent research used comparable corpora to mine n</context>
</contexts>
<marker>Zens, Bender, Hasan, Khadivi, Matusov, Xu, Zhang, Ney, 2005</marker>
<rawString>R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov, J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH Phrase-based Statistical Machine Translation System. In Proceeding IWSLT’05, pages 155–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zheng</author>
<author>N F Ayan</author>
<author>W Wang</author>
<author>D Burkett</author>
</authors>
<title>Using Syntax in Large-Scale Audio Document Translation.</title>
<date>2009</date>
<booktitle>In Proceeding Interspeech’09,</booktitle>
<pages>440--443</pages>
<contexts>
<context position="4580" citStr="Zheng et al., 2009" startWordPosition="697" endWordPosition="700"> Linguistics names in parallel corpora, updating word segmentation, word alignment and grammar extraction (Section 3.1). 2. Tightly integrate name tagging and translation into MT decoding via name-aware grammar (Section 3.2). 3. Optimize name translation and context translation simultaneously and conduct name translation driven decoding with language model (LM) based selection (Section 3.2). 4. Propose a new MT evaluation metric which can discriminate names and non-informative words (Section 4). 2 Baseline NIT As our baseline, we apply a high-performing Chinese-English MT system (Zheng, 2008; Zheng et al., 2009) based on hierarchical phrase-based translation framework (Chiang, 2005). It is based on a weighted synchronous context-free grammar (SCFG). All SCFG rules are associated with a set of features that are used to compute derivation probabilities. The features include: • Relative frequency in two directions P(-y|α) and P(α|-y), estimating the likelihoods of one side of the rule r: X →&lt; -y, α &gt; translating into the other side, where -y and α are strings of terminals and non-terminals in the source side and target side. Non-terminals in -y and α are in one-to-one correspondence. • Lexical weights i</context>
</contexts>
<marker>Zheng, Ayan, Wang, Burkett, 2009</marker>
<rawString>J. Zheng, N. F. Ayan, W. Wang, and D. Burkett. 2009. Using Syntax in Large-Scale Audio Document Translation. In Proceeding Interspeech’09, pages 440–443.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zheng</author>
</authors>
<title>SRInterp: SRI’s Scalable Multipurpose SMT Engine. In</title>
<date>2008</date>
<tech>Technical Report.</tech>
<contexts>
<context position="4559" citStr="Zheng, 2008" startWordPosition="695" endWordPosition="696">Computational Linguistics names in parallel corpora, updating word segmentation, word alignment and grammar extraction (Section 3.1). 2. Tightly integrate name tagging and translation into MT decoding via name-aware grammar (Section 3.2). 3. Optimize name translation and context translation simultaneously and conduct name translation driven decoding with language model (LM) based selection (Section 3.2). 4. Propose a new MT evaluation metric which can discriminate names and non-informative words (Section 4). 2 Baseline NIT As our baseline, we apply a high-performing Chinese-English MT system (Zheng, 2008; Zheng et al., 2009) based on hierarchical phrase-based translation framework (Chiang, 2005). It is based on a weighted synchronous context-free grammar (SCFG). All SCFG rules are associated with a set of features that are used to compute derivation probabilities. The features include: • Relative frequency in two directions P(-y|α) and P(α|-y), estimating the likelihoods of one side of the rule r: X →&lt; -y, α &gt; translating into the other side, where -y and α are strings of terminals and non-terminals in the source side and target side. Non-terminals in -y and α are in one-to-one correspondence</context>
</contexts>
<marker>Zheng, 2008</marker>
<rawString>J. Zheng. 2008. SRInterp: SRI’s Scalable Multipurpose SMT Engine. In Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zitouni</author>
<author>R Florian</author>
</authors>
<title>Mention Detection Crossing the Language Barrier.</title>
<date>2008</date>
<booktitle>In Proceeding EMNLP’08,</booktitle>
<pages>600--609</pages>
<contexts>
<context position="10455" citStr="Zitouni and Florian, 2008" startWordPosition="1669" endWordPosition="1673"> �+J� . • China appeals to world for non involvement in Angola conflict. after name tagging it becomes • GPE &amp;Xf, �F* *)j J A GPE �+J . • GPE appeals to world for non involvement in GPE conflict. Both sentence pairs are kept in the combined data to build the translation model. 3.2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al., 2012) from a source document. Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al., 2006; Zitouni and Florian, 2008; Nguyen et al., 2010). Then we apply a state-of-the-art name translation system (Ji et al., 2009) to translate names into the target language. The name translation system is composed of the following steps: (1) Dictionary matching based on 150,041 name translation pairs; (2) Statistical name transliteration based on a structured perceptron model and a character based MT model (Dayne and Shahram, 2007); (3) Context information extraction based re-ranking. In our NAMT framework, we add the following extensions to name translation. We developed a name origin classifier based on Chinese last name</context>
</contexts>
<marker>Zitouni, Florian, 2008</marker>
<rawString>I. Zitouni and R. Florian. 2008. Mention Detection Crossing the Language Barrier. In Proceeding EMNLP’08, pages 600–609.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>