<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004482">
<title confidence="0.997469">
ModelTalker Voice Recorder — An Interface System for Recording a
Corpus of Speech for Synthesis
</title>
<author confidence="0.967438">
Debra Yarrington, John Gray, H. Timothy Bunnell, Allegra Cornaglia,
Chris Pennington Jason Lilley, Kyoko Nagao,
James Polikoff,
</author>
<affiliation confidence="0.741893">
AgoraNet, Inc. Speech Research Laboratory
</affiliation>
<address confidence="0.515733333333333">
Newark, DE 19711 A.I. DuPont Hospital for Children
USA Wilmington, DE 19803, USA
{yarringt, gray, penningt} {bunnell, cornagli, lilley,
</address>
<email confidence="0.517438">
@agora—net.com nagao, polikoff}@asel.udel.edu
</email>
<sectionHeader confidence="0.990475" genericHeader="abstract">
1 Demonstration
</sectionHeader>
<subsectionHeader confidence="0.96916">
1.1 MT Voice Recorder Background
</subsectionHeader>
<bodyText confidence="0.999674607142857">
While most of us are familiar with the highly intel-
ligible but somewhat robotic sound of synthetic
speech, for the approximately 2 million people in
the United States with a limited ability to commu-
nicate vocally (Matas et al., 1985), these synthetic
voices are inadequate. The restricted number of
available voices lack the personalization they de-
sire. While intelligibility is a priority for these in-
dividuals, almost equally important is the
naturalness and individuality one associates with
one’s own voice. Individuals with difficulty speak-
ing can be any age, gender, and from any part of
the country, with regional dialects and idiosyncrat-
ic variations. Each individual deserves to speak
with a voice that is not only intelligible, but uni-
quely his or her own. For those with degenerative
diseases such as Amyotrophic Lateral Sclerosis
(ALS), knowing they will be losing the voice that
has become intricately associated with their identi-
ty is not only traumatic to the individual but to
family and friends as well.
A form of synthesis that incorporates the quali-
ties of individual voices is concatenative synthesis.
In this type of synthesis, units of recorded speech
are appended. By using recorded speech, many of
the voice qualities of the person recording the
speech remain in the resulting synthetic voice. Dif-
ferent synthesis systems append different sized
</bodyText>
<sectionHeader confidence="0.619439" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999981566666667">
We will demonstrate the ModelTalker Voice
Recorder (MT Voice Recorder) – an interface
system that lets individuals record and bank a
speech database for the creation of a synthetic
voice. The system guides users through an au-
tomatic calibration process that sets pitch,
amplitude, and silence. The system then
prompts users with both visual (text-based)
and auditory prompts. Each recording is
screened for pitch, amplitude and pronuncia-
tion and users are given immediate feedback
on the acceptability of each recording. Users
can then rerecord an unacceptable utterance.
Recordings are automatically labeled and
saved and a speech database is created from
these recordings. The system’s intention is to
make the process of recording a corpus of ut-
terances relatively easy for those inexpe-
rienced in linguistic analysis. Ultimately, the
recorded corpus and the resulting speech da-
tabase is used for concatenative synthetic
speech, thus allowing individuals at home or
in clinics to create a synthetic voice in their
own voice. The interface may prove useful
for other purposes as well. The system facili-
tates the recording and labeling of large cor-
pora of speech, making it useful for speech
and linguistic research, and it provides imme-
diate feedback on pronunciation, thus making
it useful as a clinical learning tool.
</bodyText>
<page confidence="0.930749">
28
</page>
<bodyText confidence="0.989282242424242">
Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 28–31,
Columbus, June 2008. c�2008 Association for Computational Linguistics
segments of speech. Appending larger the units of
speech results in smoother, more natural sounding
synthesis, but requires many hours of recording,
often by a trained professional. The recording
process is usually supervised, and the recordings
are often hand-polished. Because appending small-
er units requires less recording on the part of the
speaker, this is the approach the ModelTalker Syn-
thesizer has taken. However using smaller units
may result in noticeable auditory glitches at conca-
tenative junctures that are a result of variations (in
pitch, amplitude, pronunciation, etc.) between the
speech units being appended. Thus the speech rec-
orded must be more uniform in pitch and ampli-
tude. In addition, the units cannot be
mispronounced because each unit is crucial to the
resulting synthetic speech. In a smaller database
there may not be a second example of a specific
phoneme sequence.
MT Voice Recorder expects that the individuals
recording will be untrained and unsupervised, and
may lack strength and endurance because of the
presence of a degenerative disease. Thus the sys-
tem is user-friendly enough for untrained, unsu-
pervised individuals to record a corpus of speech.
The system provides the user with feedback on the
quality of each utterance they record in terms of
pronunciation accuracy, relative uniformity of
pitch, and relative uniformity of amplitude. Confe-
rence attendees will be able to experience this in-
terface system and test all its different features.
</bodyText>
<subsectionHeader confidence="0.918327">
1.2 Feature Demonstration
</subsectionHeader>
<bodyText confidence="0.999913">
At the conference, attendees will be able to try out
the different features of ModelTalker Voice Re-
corder. These features include automatic micro-
phone calibration, pitch, amplitude, and
pronunciation detection and feedback, and auto-
matic phoneme labeling of speech recordings.
</bodyText>
<subsubsectionHeader confidence="0.471495">
1.2.1 Microphone calibration
</subsubsectionHeader>
<bodyText confidence="0.999968090909091">
One important new feature of the MT Voice Re-
corder is the automatic microphone calibration
procedure. In InvTool, a predecessor software of
MT Voice Recorder, users had to set the micro-
phone’s amplitude. The system now calibrates the
signal to noise ratio automatically through a step-
by-step process (see Figure 1, below).
Using the automatic calibration procedure, the
optimal signal to noise ratio is set for the recording
session. These measurements are retained for fu-
ture recording sessions in cases in which an indi-
</bodyText>
<page confidence="0.99354">
29
</page>
<bodyText confidence="0.9998311">
vidual is unable to record the entire corpus in one
sitting.
Once the user has completed the automatic cali-
bration procedure, he will be able to start recording
a corpus of speech. The interface has been de-
signed with the assumption that individuals will be
recording without supervision. Thus the interface
incorporates a number of feedback mechanisms to
aid individuals in making a high quality corpus for
synthesis (see Figure 2, below).
</bodyText>
<subsectionHeader confidence="0.665043">
1.2.2 Recording Utterances
</subsectionHeader>
<bodyText confidence="0.9999618">
The corpus was carefully chosen so that all fre-
quently used phoneme combinations are included
at least once. Thus it is critical that users pro-
nounce prompted sentences in the manner in which
the system expects. Alterations in pronunciation as
small as saying /i/ versus /ə/ for “the,” for example,
can negatively affect the resulting synthetic voice.
To reduce the incidence of alternate pronunciation,
the user is prompted with both a text and an audito-
ry version of the utterance.
</bodyText>
<subsectionHeader confidence="0.778071">
1.2.3 Recording Feedback
</subsectionHeader>
<bodyText confidence="0.9994721">
Once an utterance has been recorded, the user rece-
ives feedback on the overall quality of the utter-
ance. Specifically, the user receives feedback on
the pitch, the overall amplitude, and the pronuncia-
tion of the recording.
Pitch: The user receives feedback on whether
the utterance’s average pitch is within range of the
user’s base pitch determined during the calibration
process. Collecting all recordings within a relative-
ly small pitch range minimizes concatenation costs
during the synthesis process. MT Voice Recorder
determines the average pitch of each utterance and
gives the user feedback on whether the pitch is
within an acceptable range. This feedback mechan-
ism also helps to eliminate cases in which the sys-
tem is unable to accurately track the pitch of an
utterance. In these cases, the utterance will be
marked unacceptable and the user should rerecord,
hopefully yielding an utterance with more accurate
pitch tracking.
</bodyText>
<figureCaption confidence="0.960518">
Figure 2: MT Voice Recorder User Interface
</figureCaption>
<page confidence="0.989351">
30
</page>
<bodyText confidence="0.973668826086956">
Amplitude: The user is also given feedback on
the overall amplitude of an utterance. If the ampli-
tude is either too low or too high, the user must
rerecord the utterance.
Pronunciation: Each recorded utterance is eva-
luated for pronunciation. Each utterance within the
corpus is associated with a string of phonemes
representing its transcription. When an utterance is
recorded, the phoneme string associated with the
utterance is force-aligned with the recorded
speech. If the alignment does not fall within an
acceptable range, the user is given feedback that
the recording’s pronunciation may not be accepta-
ble and the user is given the option of rerecording
the utterance.
1.2.4 Automatic Phoneme Labeling
During the process of pronunciation evaluation, an
associated phoneme transcription is aligned with
the utterance. This alignment is retained so that
each utterance is automatically labeled. Once the
entire corpus has been recorded, alignments are
automatically refined based on specific individual
voice characteristics.
</bodyText>
<subsubsectionHeader confidence="0.444615">
1.2.5 Other Features
</subsubsectionHeader>
<bodyText confidence="0.9989369375">
The MT Voice Recorder also allows users to add
utterances of their choice to the corpus of speech
for the synthetic voice. These utterances are those
the user wants to be synthesized clearly and will
automatically be included in their entirety in the
speech database. These utterances are also auto-
matically labeled before being stored.
In addition, for those with more speech and lin-
guistic experience, the system has a number of
other features that can be explored. For example,
the MT Voice Recorder also allows one to change
settings so that the phoneme string, peak ampli-
tude, RMS range, average F0, F0 range, and pro-
nunciation score can be viewed. Users may use this
information to more precisely adjust their utter-
ances.
</bodyText>
<subsectionHeader confidence="0.9574">
1.3 Synthetic Voice Demonstration
</subsectionHeader>
<bodyText confidence="0.999968375">
Those attending the demonstration will also be
able to listen to a sampling of synthetic voices
created using the ModelTalker system. While one
of the synthetic voices was created by a profes-
sional speaker and manually polished, all other
voices were created by untrained individuals, most
of whom have ALS, in an untrained setting, with
the recordings having no manual polishing.
</bodyText>
<sectionHeader confidence="0.987981" genericHeader="introduction">
2 Other Applications
</sectionHeader>
<bodyText confidence="0.999969181818182">
Although the MTVR was designed specifically to
record speech for the creation of a database that
will be used in speech synthesis, it can also be used
as a digital audio recording tool for speech re-
search. For example, the MT Voice Recorder of-
fers useful features for language documentation.
An immediate warning about a poor quality re-
cording will alert a researcher to rerecord the utter-
ance. MT Voice Recorder employs file formats
that are recommended for digital language docu-
mentation (e.g., XML, WAV, and TXT) (Bird &amp;
Simons, 2003). The recorded files are automatical-
ly stored with broad phonetic labels. The automatic
saving function will reduce the time of recordings
and the potential risk for miscataloging the files.
Currently, the automatic phonetic labeling feature
is only available for English, but it could be appli-
cable to different languages in the future.
For more information about the ModelTalker
System and to experience an interactive demo as
well as listen to sample synthetic voices,
visit http://www.modeltalker.com.
</bodyText>
<sectionHeader confidence="0.998226" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999683625">
This work was supported by STTR grants
R41/R42-DC006193 from NIH/NIDCD and from
Nemours Biomedical Research. We are especially
indebted to the many people with ALS, the AAC
specialists in clinics, and other interested individu-
als who have invested a great deal of time and ef-
fort into this project and have provided valuable
feedback.
</bodyText>
<sectionHeader confidence="0.999268" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999526142857143">
Bird, S. and Simons, G.F. (2003). Seven dimensions of
portability for language documentation and descrip-
tion. Language, 79(3): 557-582.
Matas, J., Mathy-Laikko, P., Beaukelman, D. and Le-
gresley. K. (1985). Identifying the nonspeaking
population: a demographic study, Augmentative &amp;
Alternative Communication, 1: 17-31.
</reference>
<page confidence="0.999913">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.021022">
<title confidence="0.999566">ModelTalker Voice Recorder — An Interface System for Recording a Corpus of Speech for Synthesis</title>
<author confidence="0.985111333333333">Debra Yarrington</author>
<author confidence="0.985111333333333">John Gray</author>
<author confidence="0.985111333333333">H Timothy Bunnell</author>
<author confidence="0.985111333333333">Allegra Cornaglia</author>
<author confidence="0.985111333333333">Chris Pennington Jason Lilley</author>
<author confidence="0.985111333333333">Kyoko Nagao</author>
<author confidence="0.985111333333333">James Polikoff</author>
<affiliation confidence="0.999671">AgoraNet, Inc. Speech Research Laboratory</affiliation>
<address confidence="0.8520115">Newark, DE 19711 A.I. DuPont Hospital for Children USA Wilmington, DE 19803, USA</address>
<email confidence="0.8083725">yarringt@asel.udel.edu</email>
<email confidence="0.8083725">gray@asel.udel.edu</email>
<email confidence="0.8083725">penningt}{bunnell@asel.udel.edu</email>
<email confidence="0.8083725">cornagli@asel.udel.edu</email>
<email confidence="0.8083725">lilley@asel.udel.edu</email>
<email confidence="0.8083725">@agora—net.comnagao@asel.udel.edu</email>
<email confidence="0.8083725">polikoff@asel.udel.edu</email>
<affiliation confidence="0.507564">1 Demonstration</affiliation>
<abstract confidence="0.99780942173913">1.1 MT Voice Recorder Background While most of us are familiar with the highly intelligible but somewhat robotic sound of synthetic speech, for the approximately 2 million people in the United States with a limited ability to communicate vocally (Matas et al., 1985), these synthetic voices are inadequate. The restricted number of available voices lack the personalization they desire. While intelligibility is a priority for these individuals, almost equally important is the naturalness and individuality one associates with one’s own voice. Individuals with difficulty speaking can be any age, gender, and from any part of the country, with regional dialects and idiosyncratic variations. Each individual deserves to speak with a voice that is not only intelligible, but uniquely his or her own. For those with degenerative diseases such as Amyotrophic Lateral Sclerosis (ALS), knowing they will be losing the voice that has become intricately associated with their identity is not only traumatic to the individual but to family and friends as well. A form of synthesis that incorporates the qualities of individual voices is concatenative synthesis. In this type of synthesis, units of recorded speech are appended. By using recorded speech, many of the voice qualities of the person recording the speech remain in the resulting synthetic voice. Different synthesis systems append different sized Abstract We will demonstrate the ModelTalker Voice Recorder (MT Voice Recorder) – an interface system that lets individuals record and bank a speech database for the creation of a synthetic voice. The system guides users through an automatic calibration process that sets pitch, amplitude, and silence. The system then prompts users with both visual (text-based) and auditory prompts. Each recording is screened for pitch, amplitude and pronunciation and users are given immediate feedback on the acceptability of each recording. Users can then rerecord an unacceptable utterance. Recordings are automatically labeled and saved and a speech database is created from these recordings. The system’s intention is to make the process of recording a corpus of utterances relatively easy for those inexperienced in linguistic analysis. Ultimately, the recorded corpus and the resulting speech database is used for concatenative synthetic speech, thus allowing individuals at home or in clinics to create a synthetic voice in their own voice. The interface may prove useful for other purposes as well. The system facilitates the recording and labeling of large corpora of speech, making it useful for speech and linguistic research, and it provides immediate feedback on pronunciation, thus making it useful as a clinical learning tool. 28 of the ACL-08: HLT Demo Session (Companion pages 28–31, June 2008. Association for Computational Linguistics segments of speech. Appending larger the units of speech results in smoother, more natural sounding synthesis, but requires many hours of recording, often by a trained professional. The recording process is usually supervised, and the recordings are often hand-polished. Because appending smaller units requires less recording on the part of the speaker, this is the approach the ModelTalker Synthesizer has taken. However using smaller units may result in noticeable auditory glitches at concatenative junctures that are a result of variations (in pitch, amplitude, pronunciation, etc.) between the speech units being appended. Thus the speech recorded must be more uniform in pitch and amplitude. In addition, the units cannot be mispronounced because each unit is crucial to the resulting synthetic speech. In a smaller database there may not be a second example of a specific phoneme sequence. MT Voice Recorder expects that the individuals recording will be untrained and unsupervised, and may lack strength and endurance because of the presence of a degenerative disease. Thus the system is user-friendly enough for untrained, unsupervised individuals to record a corpus of speech. The system provides the user with feedback on the quality of each utterance they record in terms of pronunciation accuracy, relative uniformity of pitch, and relative uniformity of amplitude. Conference attendees will be able to experience this interface system and test all its different features. 1.2 Feature Demonstration At the conference, attendees will be able to try out the different features of ModelTalker Voice Recorder. These features include automatic microphone calibration, pitch, amplitude, and pronunciation detection and feedback, and automatic phoneme labeling of speech recordings. 1.2.1 Microphone calibration One important new feature of the MT Voice Recorder is the automatic microphone calibration procedure. In InvTool, a predecessor software of MT Voice Recorder, users had to set the microphone’s amplitude. The system now calibrates the signal to noise ratio automatically through a stepby-step process (see Figure 1, below). Using the automatic calibration procedure, the optimal signal to noise ratio is set for the recording session. These measurements are retained for furecording sessions in cases in which an indi- 29 vidual is unable to record the entire corpus in one sitting. Once the user has completed the automatic calibration procedure, he will be able to start recording a corpus of speech. The interface has been designed with the assumption that individuals will be recording without supervision. Thus the interface incorporates a number of feedback mechanisms to aid individuals in making a high quality corpus for synthesis (see Figure 2, below). 1.2.2 Recording Utterances The corpus was carefully chosen so that all frequently used phoneme combinations are included at least once. Thus it is critical that users pronounce prompted sentences in the manner in which the system expects. Alterations in pronunciation as small as saying /i/ versus /ə/ for “the,” for example, can negatively affect the resulting synthetic voice. To reduce the incidence of alternate pronunciation, the user is prompted with both a text and an auditory version of the utterance. 1.2.3 Recording Feedback Once an utterance has been recorded, the user receives feedback on the overall quality of the utterance. Specifically, the user receives feedback on the pitch, the overall amplitude, and the pronunciation of the recording. user receives feedback on whether the utterance’s average pitch is within range of the user’s base pitch determined during the calibration process. Collecting all recordings within a relatively small pitch range minimizes concatenation costs during the synthesis process. MT Voice Recorder determines the average pitch of each utterance and gives the user feedback on whether the pitch is within an acceptable range. This feedback mechanism also helps to eliminate cases in which the system is unable to accurately track the pitch of an utterance. In these cases, the utterance will be marked unacceptable and the user should rerecord, hopefully yielding an utterance with more accurate pitch tracking. Figure 2: MT Voice Recorder User Interface 30 user is also given feedback on the overall amplitude of an utterance. If the amplitude is either too low or too high, the user must rerecord the utterance. recorded utterance is evaluated for pronunciation. Each utterance within the corpus is associated with a string of phonemes representing its transcription. When an utterance is recorded, the phoneme string associated with the utterance is force-aligned with the recorded speech. If the alignment does not fall within an acceptable range, the user is given feedback that the recording’s pronunciation may not be acceptable and the user is given the option of rerecording the utterance. 1.2.4 Automatic Phoneme Labeling During the process of pronunciation evaluation, an associated phoneme transcription is aligned with the utterance. This alignment is retained so that each utterance is automatically labeled. Once the entire corpus has been recorded, alignments are automatically refined based on specific individual voice characteristics. 1.2.5 Other Features The MT Voice Recorder also allows users to add utterances of their choice to the corpus of speech for the synthetic voice. These utterances are those the user wants to be synthesized clearly and will automatically be included in their entirety in the speech database. These utterances are also automatically labeled before being stored. In addition, for those with more speech and linguistic experience, the system has a number of other features that can be explored. For example, the MT Voice Recorder also allows one to change settings so that the phoneme string, peak amplitude, RMS range, average F0, F0 range, and pronunciation score can be viewed. Users may use this information to more precisely adjust their utterances. 1.3 Synthetic Voice Demonstration Those attending the demonstration will also be able to listen to a sampling of synthetic voices created using the ModelTalker system. While one of the synthetic voices was created by a professional speaker and manually polished, all other voices were created by untrained individuals, most of whom have ALS, in an untrained setting, with the recordings having no manual polishing. 2 Other Applications Although the MTVR was designed specifically to record speech for the creation of a database that will be used in speech synthesis, it can also be used as a digital audio recording tool for speech research. For example, the MT Voice Recorder offers useful features for language documentation. An immediate warning about a poor quality recording will alert a researcher to rerecord the utterance. MT Voice Recorder employs file formats that are recommended for digital language documentation (e.g., XML, WAV, and TXT) (Bird &amp; Simons, 2003). The recorded files are automatically stored with broad phonetic labels. The automatic saving function will reduce the time of recordings and the potential risk for miscataloging the files. Currently, the automatic phonetic labeling feature is only available for English, but it could be applicable to different languages in the future. For more information about the ModelTalker System and to experience an interactive demo as well as listen to sample synthetic voices, visithttp://www.modeltalker.com.</abstract>
<note confidence="0.699462666666667">Acknowledgments This work was supported by STTR grants R41/R42-DC006193 from NIH/NIDCD and from</note>
<abstract confidence="0.809164071428571">Nemours Biomedical Research. We are especially indebted to the many people with ALS, the AAC specialists in clinics, and other interested individuals who have invested a great deal of time and effort into this project and have provided valuable feedback. References Bird, S. and Simons, G.F. (2003). Seven dimensions of portability for language documentation and descrip- 557-582. Matas, J., Mathy-Laikko, P., Beaukelman, D. and Legresley. K. (1985). Identifying the nonspeaking a demographic study, &amp; 17-31.</abstract>
<intro confidence="0.860323">31</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>G F Simons</author>
</authors>
<title>Seven dimensions of portability for language documentation and description.</title>
<date>2003</date>
<journal>Language,</journal>
<volume>79</volume>
<issue>3</issue>
<pages>557--582</pages>
<contexts>
<context position="10402" citStr="Bird &amp; Simons, 2003" startWordPosition="1629" endWordPosition="1632">ined setting, with the recordings having no manual polishing. 2 Other Applications Although the MTVR was designed specifically to record speech for the creation of a database that will be used in speech synthesis, it can also be used as a digital audio recording tool for speech research. For example, the MT Voice Recorder offers useful features for language documentation. An immediate warning about a poor quality recording will alert a researcher to rerecord the utterance. MT Voice Recorder employs file formats that are recommended for digital language documentation (e.g., XML, WAV, and TXT) (Bird &amp; Simons, 2003). The recorded files are automatically stored with broad phonetic labels. The automatic saving function will reduce the time of recordings and the potential risk for miscataloging the files. Currently, the automatic phonetic labeling feature is only available for English, but it could be applicable to different languages in the future. For more information about the ModelTalker System and to experience an interactive demo as well as listen to sample synthetic voices, visit http://www.modeltalker.com. Acknowledgments This work was supported by STTR grants R41/R42-DC006193 from NIH/NIDCD and fro</context>
</contexts>
<marker>Bird, Simons, 2003</marker>
<rawString>Bird, S. and Simons, G.F. (2003). Seven dimensions of portability for language documentation and description. Language, 79(3): 557-582.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K</author>
</authors>
<title>Identifying the nonspeaking population: a demographic study,</title>
<date>1985</date>
<journal>Augmentative &amp; Alternative Communication,</journal>
<volume>1</volume>
<pages>17--31</pages>
<marker>K, 1985</marker>
<rawString>Matas, J., Mathy-Laikko, P., Beaukelman, D. and Legresley. K. (1985). Identifying the nonspeaking population: a demographic study, Augmentative &amp; Alternative Communication, 1: 17-31.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>