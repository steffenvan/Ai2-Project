<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000926">
<title confidence="0.996561">
Sentiment Vector Space Model for
Lyric-based Song Sentiment Classification
</title>
<author confidence="0.999369">
Yunqing Xia Linlin Wang
</author>
<affiliation confidence="0.883201333333333">
Center for Speech and language Tech. State Key Lab of Intelligent Tech. and Sys.
RIIT, Tsinghua University Dept. of CST, Tsinghua University
Beijing 100084, China Beijing 100084, China
</affiliation>
<email confidence="0.988825">
yqxia@tsinghua.edu.cn wangll07@mails.tsinghua.edu.cn
</email>
<author confidence="0.999393">
Kam-Fai Wong Mingxing Xu
</author>
<affiliation confidence="0.99138">
Dept. of SE&amp;EM Dept. of CST
The Chinese University of Hong Kong Tsinghua University
Shatin, Hong Kong Beijing 100084, China
</affiliation>
<email confidence="0.969505">
kfwong@se.cuhk.edu.hk xumx@tsinghua.edu.cn
</email>
<sectionHeader confidence="0.987174" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.771717666666667">
Lyric-based song sentiment classification
seeks to assign songs appropriate sentiment
labels such as light-hearted and heavy-hearted.
Four problems render vector space model
(VSM)-based text classification approach in-
effective: 1) Many words within song lyrics
actually contribute little to sentiment; 2)
Nouns and verbs used to express sentiment are
ambiguous; 3) Negations and modifiers
around the sentiment keywords make particu-
lar contributions to sentiment; 4) Song lyric is
usually very short. To address these problems,
the sentiment vector space model (s-VSM) is
proposed to represent song lyric document.
The preliminary experiments prove that the s-
VSM model outperforms the VSM model in
the lyric-based song sentiment classification
task.
</bodyText>
<sectionHeader confidence="0.999076" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99982012195122">
Song sentiment classification nowadays becomes a
hot research topic due largely to the increasing
demand of ubiquitous song access, especially via
mobile phone. In their music phone W910i, Sony
and Ericsson provide Sense Me component to catch
owner’s mood and play songs accordingly. Song
sentiment classification is the key technology for
song recommendation. Many research works have
been reported to achieve this goal using audio sig-
nal (Knees et al., 2007). But research efforts on
lyric-based song classification are very few.
Preliminary experiments show that VSM-based
text classification method (Joachims, 2002) is inef-
fective in song sentiment classification (see Sec-
tion 5) due to the following four reasons. Firstly,
the VSM model considers all content words within
song lyric as features in text classification. But in
fact many words in song lyric actually make little
contribution to sentiment expressing. Using all
content words as features, the VSM-based classifi-
cation methods perform poorly in song sentiment
classification. Secondly, observation on lyrics of
thousands of Chinese pop songs reveals that senti-
ment-related nouns and verbs usually carry multi-
ple senses. Unfortunately, the ambiguity is not
appropriately handled in the VSM model. Thirdly,
negations and modifiers are constantly found
around the sentiment words in song lyric to inverse,
to strengthen or to weaken the sentiments that the
sentences carry. But the VSM model is not capable
of reflecting these functions. Lastly, song lyric is
usually very short, namely 50 words on average in
length, rendering serious sparse data problem in
VSM-based classification.
To address the aforementioned problems of the
VSM model, the sentiment vector space model (s-
VSM) is proposed in this work. We adopt the s-
VSM model to extract sentiment features from
song lyrics and implement the SVM-light
(Joachims, 2002) classification algorithm to assign
sentiment labels to given songs.
</bodyText>
<page confidence="0.99761">
133
</page>
<affiliation confidence="0.27883">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133–136,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</affiliation>
<sectionHeader confidence="0.997835" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999990341463415">
Song sentiment classification has been investigated
since 1990s in audio signal processing community
and research works are mostly found relying on
audio signal to make a decision using machine
learning algorithms (Li and Ogihara, 2006; Lu et
al., 2006). Typically, the sentiment classes are de-
fined based on the Thayer’s arousal-valence emo-
tion plane (Thayer, 1989). Instead of assigning
songs one of the four typical sentiment labels, Lu
et al. (2006) propose the hierarchical framework to
perform song sentiment classification with two
steps. In the first step the energy level is detected
with intensity features and the stress level is de-
termined in the second step with timbre and
rhythm features. It is proved difficult to detect
stress level using audio as classification proof.
Song sentiment classification using lyric as
proof is recently investigated by Chen et al. (2006).
They adopt the hierarchical framework and make
use of song lyric to detect stress level in the second
step. In fact, many literatures have been produced
to address the sentiment analysis problem in natu-
ral language processing research. Three approaches
are dominating, i.e. knowledge-based approach
(Kim and Hovy, 2004), information retrieval-based
approach (Turney and Littman, 2003) and machine
learning approach (Pang et al., 2002), in which the
last approach is found very popular. Pang et al.
(2002) adopt the VSM model to represent product
reviews and apply text classification algorithms
such as Naïve Bayes, maximum entropy and sup-
port vector machines to predict sentiment polarity
of given product review.
Chen et al. (2006) also apply the VSM model in
lyric-based song sentiment classification. However,
our experiments show that song sentiment classifi-
cation with the VSM model delivers disappointing
quality (see Section 5). Error analysis reveals that
the VSM model is problematic in representing
song lyric. It is necessary to design a new lyric rep-
resentation model for song sentiment classification.
</bodyText>
<sectionHeader confidence="0.942423" genericHeader="method">
3 Sentiment Vector Space Model
</sectionHeader>
<bodyText confidence="0.990676333333333">
We propose the sentiment vector space model (s-
VSM) for song sentiment classification. Principles
of the s-VSM model are listed as follows.
</bodyText>
<listItem confidence="0.982998875">
(1) Only sentiment-related words are used to pro-
duce sentiment features for the s-VSM model.
(2) The sentiment words are appropriately disam-
biguated with the neighboring negations and
modifiers.
(3) Negations and modifiers are included in the s-
VSM model to reflect the functions of invers-
ing, strengthening and weakening.
</listItem>
<bodyText confidence="0.99513475">
Sentiment unit is found the appropriate element
complying with the above principles.
To be general, we first present the notation for
sentiment lexicon as follows.
</bodyText>
<equation confidence="0.995913111111111">
L C N M C c i
= { , , }; { } , 1, . . . ,
= = I
i
j
Mm l
= { }, 1, ... ,
= L
l
</equation>
<bodyText confidence="0.961107818181818">
in which L represents sentiment lexicon, C senti-
ment word set, N negation set and M modifier set.
These words can be automatically extracted from a
semantic dictionary and each sentiment word is
assigned a sentiment label, namely light-hearted or
heavy-hearted according to its lexical definition.
Given a piece of song lyric, denoted as follows,
W = { w h }, h = 1, . . . , H
in which W denotes a set of words that appear in
the song lyric, the semantic lexicon is in turn used
to locate sentiment units denoted as follows.
</bodyText>
<equation confidence="0.986913375">
U u
= =
{ } { ,
c n
v i v j
,
civ,E WnC; nj„E WnN; mlvE WnM
,
</equation>
<bodyText confidence="0.999988125">
Note that sentiment units are unambiguous sen-
timent expressions, each of which contains one
sentiment word and possibly one modifier and one
negation. Negations and modifiers are helpful to
determine the unique meaning of the sentiment
words within certain context window, e.g. 3 pre-
ceding words and 3 succeeding words in our case.
Then, the s-VSM model is presented as follows.
</bodyText>
<equation confidence="0.814255">
VS = ( f 1 ( U), f 2 ( U),..., f T (U)) .
</equation>
<bodyText confidence="0.999842888888889">
in which VS represents the sentiment vector for the
given song lyric and fi(U) sentiment features which
are usually certain statistics on sentiment units that
appear in lyric.
We classify the sentiment units according to oc-
currence of sentiment words, negations and modi-
fiers. If the sentiment word is mandatory for any
sentiment unit, eight kinds of sentiment units are
obtained. Let fPSW denote count of positive senti-
</bodyText>
<figure confidence="0.716231">
N
{ }, 1, . . . ,
n j J
=
,
,
,
ml
}
v
v
</figure>
<page confidence="0.995476">
134
</page>
<bodyText confidence="0.999785">
ment words (PSW), fNSW count of negative senti-
ment words (NSW), fNEG count of negations (NEG)
and fMOD count of modifiers (MOD). Eight senti-
ment features are defined in Table 1.
</bodyText>
<table confidence="0.996276">
fi Number of sentiment units satisfying ...
f1 fPSW &gt;0, fNSW =fNEG =fMOD =0
f2 fPSW =0, fNSW &gt;0, fNEG = fMOD =0
f3 fPSW &gt;0, fNSW =0, fNEG&gt;0, fMOD =0
f4 fPSW=0, fNSW &gt;0, fNEG &gt;0, fMOD =0
f5 fPSW &gt;0, fNSW =0, fNEG =0, fMOD &gt;0
f6 fPSW=0, fNSW &gt;0, fNEG =0, fMOD &gt;0
f7 fPSW &gt;0, fNSW =0, fNEG &gt;0, fMOD &gt;0
f8 fPSW =0, fNSW &gt;0, fNEG &gt;0, fMOD &gt;0
</table>
<tableCaption confidence="0.997236">
Table 1. Definition of sentiment features. Note that
</tableCaption>
<bodyText confidence="0.776397">
one sentiment unit contains only one sentiment
word. Thus it is not possible that fPSW and fNSW are
both bigger than zero.
Obviously, sparse data problem can be well ad-
dressed using statistics on sentiment units rather
than on individual words or sentiment units.
</bodyText>
<sectionHeader confidence="0.9924865" genericHeader="method">
4 Lyric-based Song Sentiment Classifica-
tion
</sectionHeader>
<bodyText confidence="0.999969071428571">
Song sentiment classification based on lyric can be
viewed as a text classification task thus can be
handled by some standard classification algorithms.
In this work, the SVM-light algorithm is imple-
mented to accomplish this task due to its excel-
lence in text classification.
Note that song sentiment classification differs
from the traditional text classification in feature
extraction. In our case, sentiment units are first
detected and the sentiment features are then gener-
ated based on sentiment units. As the sentiment
units carry unambiguous sentiments, it is deemed
that the s-VSM is model is promising to carry out
the song sentiment classification task effectively.
</bodyText>
<sectionHeader confidence="0.998123" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99998285">
To evaluate the s-VSM model, a song corpus, i.e.
5SONGS, is created manually. It covers 2,653 Chi-
nese pop songs, in which 1,632 are assigned label
of light-hearted (positive class) and 1,021 assigned
heavy-hearted (negative class). We randomly se-
lect 2,001 songs (around 75%) for training and the
rest for testing. We adopt the standard evaluation
criteria in text classification, namely precision (p),
recall (r), f-1 measure (f) and accuracy (a) (Yang
and Liu, 1999).
In our experiments, three approaches are imple-
mented in song sentiment classification, i.e. audio-
based (AB) approach, knowledge-based (KB) ap-
proach and machine learning (ML) approach, in
which the latter two approaches are also referred to
as text-based (TB) approach. The intentions are 1)
to compare AB approach against the two TB ap-
proaches, 2) to compare the ML approach against
the KB approach, and 3) to compare the VSM-
based ML approach against the s-VSM-based one.
</bodyText>
<subsectionHeader confidence="0.879874">
Audio-based (AB) Approach
</subsectionHeader>
<bodyText confidence="0.999945">
We extract 10 timbre features and 2 rhythm fea-
tures (Lu et al., 2006) from audio data of each song.
Thus each song is represented by a 12-dimension
vector. We run SVM-light algorithm to learn on the
training samples and classify test ones.
</bodyText>
<subsectionHeader confidence="0.834508">
Knowledge-based (KB) Approach
</subsectionHeader>
<bodyText confidence="0.999590857142857">
We make use of HowNet (Dong and dong,
2006), to detect sentiment words, to recognize the
neighboring negations and modifiers, and finally to
locate sentiment units within song lyric. Sentiment
(SM) of the sentiment unit (SU) is determined con-
sidering sentiment words (SW), negation (NEG)
and modifiers (MOD) using the following rule.
</bodyText>
<listItem confidence="0.9904775">
(1) SM(SU) = label(SW);
(2) SM(SU) = - SM(SU) iff SU contains NEG;
(3) SM(SU) = degree(MOD)*SM(SU) iff SU
contains MOD.
</listItem>
<bodyText confidence="0.999973833333333">
In the above rule, label(x) is the function to read
sentiment label(∈{1, -1}) of given word in the
sentiment lexicon and degree(x) to read its modifi-
cation degree(∈{1/2, 2}). As the sentiment labels
are integer numbers, the following formula is
adopted to obtain label of the given song lyric.
</bodyText>
<equation confidence="0.672812">
label = sign(y, SM(SUi) )
</equation>
<subsectionHeader confidence="0.960306">
Machine Learning (ML) Approach
</subsectionHeader>
<bodyText confidence="0.999616">
The ML approach adopts text classification al-
gorithms to predict sentiment label of given song
lyric. The SVM-light algorithm is implemented
based on VSM model and s-VSM model, respec-
tively. For the VSM model, we apply (CHI) algo-
rithm (Yang and Pedersen, 1997) to select effective
sentiment word features. For the s-VSM model, we
adopt HowNet as the sentiment lexicon to create
sentiment vectors.
Experimental results are presented Table 2.
</bodyText>
<page confidence="0.995326">
135
</page>
<table confidence="0.999235">
p R f-1 a
Audio-based 0.504 0.701 0.586 0.504
Knowledge-based 0.726 0.584 0.647 0.714
VSM-based 0.587 1.000 0.740 0.587
s-VSM-based 0.783 0.750 0.766 0.732
</table>
<tableCaption confidence="0.999592">
Table 2. Experimental results
</tableCaption>
<bodyText confidence="0.984376523809524">
Table 2 shows that the text-based methods out-
perform the audio-based method. This justifies our
claim that lyric is better than audio in song senti-
ment detection. The second observation is that ma-
chine learning approach outperforms the
knowledge-based approach. The third observation
is that s-VSM-based method outperforms VSM-
based method on f-1 score. Besides, we surpris-
ingly find that VSM-based method assigns all test
samples light-hearted label thus recall reaches
100%. This makes results of VSM-based method
unreliable. We look into the model file created by
the SVM-light algorithm and find that 1,868 of
2,001 VSM training vectors are selected as support
vectors while 1,222 s-VSM support vectors are
selected. This indicates that the VSM model indeed
suffers the problems mentioned in Section 1 in
lyric-based song sentiment classification. As a
comparison, the s-VSM model produces more dis-
criminative support vectors for the SVM classifier
thus yields reliable predictions.
</bodyText>
<sectionHeader confidence="0.998737" genericHeader="conclusions">
6 Conclusions and Future Works
</sectionHeader>
<bodyText confidence="0.999969583333333">
The s-VSM model is presented in this paper as a
document representation model to address the
problems encountered in song sentiment classifica-
tion. This model considers sentiment units in fea-
ture definition and produces more discriminative
support vectors for song sentiment classification.
Some conclusions can be drawn from the prelimi-
nary experiments on song sentiment classification.
Firstly, text-based methods are more effective than
the audio-based method. Secondly, the machine
learning approach outperforms the knowledge-
based approach. Thirdly, s-VSM model is more
reliable and more accurate than the VSM model.
We are thus encouraged to carry out more research
to further refine the s-VSM model in sentiment
classification. In the future, we will incorporate
some linguistic rules to improve performance of
sentiment unit detection. Meanwhile, sentiment
features in the s-VSM model are currently equally
weighted. We will adopt some estimation tech-
niques to assess their contributions for the s-VSM
model. Finally, we will also explore how the s-
VSM model improves quality of polarity classifi-
cation in opinion mining.
</bodyText>
<sectionHeader confidence="0.967495" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.99681475">
Research work in this paper is partially supported
by NSFC (No. 60703051) and Tsinghua University
under the Basic Research Foundation (No.
JC2007049).
</bodyText>
<sectionHeader confidence="0.998959" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999845189189189">
R.H. Chen, Z.L. Xu, Z.X. Zhang and F.Z. Luo. Content
Based Music Emotion Analysis and Recognition.
Proc. of 2006 International Workshop on Computer
Music and Audio Technology, pp.68-75. 2006.
Z. Dong and Q. Dong. HowNet and the Computation of
Meaning. World Scientific Publishing. 2006.
T. Joachims. Learning to Classify Text Using Support
Vector Machines, Methods, Theory, and Algorithms.
Kluwer (2002).
S.-M. Kim and E. Hovy. Determining the Sentiment of
Opinions. Proc. COLING’04, pp. 1367-1373. 2004.
P. Knees, T. Pohle, M. Schedl and G. Widmer. A Music
Search Engine Built upon Audio-based and Web-
based Similarity Measures. Proc. of SIGIR&apos;07, pp.47-
454. 2007
T. Li and M. Ogihara. Content-based music similarity
search and emotion detection. Proc. IEEE Int. Conf.
Acoustic, Speech, and Signal Processing, pp. 17–21.
2006.
L. Lu, D. Liu and H. Zhang. Automatic mood detection
and tracking of music audio signals. IEEE Transac-
tions on Audio, Speech &amp; Language Processing
14(1): 5-18 (2006).
B. Pang, L. Lee and S. Vaithyanathan. Thumbs up? Sen-
timent Classification using Machine Learning Tech-
niques. Proc. of EMNLP-02, pp.79-86. 2002.
R. E. Thayer, The Biopsychology of Mood and Arousal,
New York, Oxford University Press. 1989.
P. D. Turney and M. L. Littman. Measuring praise and
criticism: Inference of semantic orientation from as-
sociation. ACM Trans. on Information Systems,
21(4):315–346. 2003.
Y. Yang and X. Liu. A Re-Examination of Text Catego-
rization Methods. Proc. of SIGIR’99, pp. 42-49. 1999.
Y. Yang and J. O. Pedersen. A comparative study on
feature selection in text categorization. Proc.
ICML’97, pp.412-420. 1997.
</reference>
<page confidence="0.9988">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.516244">
<title confidence="0.9972955">Sentiment Vector Space Model for Lyric-based Song Sentiment Classification</title>
<author confidence="0.996484">Yunqing Xia Linlin Wang</author>
<affiliation confidence="0.9979015">Center for Speech and language Tech. State Key Lab of Intelligent Tech. and Sys. RIIT, Tsinghua University Dept. of CST, Tsinghua University</affiliation>
<address confidence="0.998242">Beijing 100084, China Beijing 100084, China</address>
<email confidence="0.643316">yqxia@tsinghua.edu.cnwangll07@mails.tsinghua.edu.cn</email>
<author confidence="0.992366">Kam-Fai Wong Mingxing Xu</author>
<affiliation confidence="0.9999495">Dept. of SE&amp;EM Dept. of CST The Chinese University of Hong Kong Tsinghua University</affiliation>
<address confidence="0.998434">Shatin, Hong Kong Beijing 100084, China</address>
<email confidence="0.884226">kfwong@se.cuhk.edu.hkxumx@tsinghua.edu.cn</email>
<abstract confidence="0.995881052631579">Lyric-based song sentiment classification seeks to assign songs appropriate sentiment such as Four problems render vector space model (VSM)-based text classification approach ineffective: 1) Many words within song lyrics actually contribute little to sentiment; 2) Nouns and verbs used to express sentiment are ambiguous; 3) Negations and modifiers around the sentiment keywords make particular contributions to sentiment; 4) Song lyric is usually very short. To address these problems, the sentiment vector space model (s-VSM) is proposed to represent song lyric document. The preliminary experiments prove that the s- VSM model outperforms the VSM model in the lyric-based song sentiment classification task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Chen</author>
<author>Z L Xu</author>
<author>Z X Zhang</author>
<author>F Z Luo</author>
</authors>
<title>Content Based Music Emotion Analysis and Recognition.</title>
<date>2006</date>
<booktitle>Proc. of 2006 International Workshop on Computer Music and Audio Technology,</booktitle>
<pages>68--75</pages>
<contexts>
<context position="4319" citStr="Chen et al. (2006)" startWordPosition="636" endWordPosition="639">the sentiment classes are defined based on the Thayer’s arousal-valence emotion plane (Thayer, 1989). Instead of assigning songs one of the four typical sentiment labels, Lu et al. (2006) propose the hierarchical framework to perform song sentiment classification with two steps. In the first step the energy level is detected with intensity features and the stress level is determined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently investigated by Chen et al. (2006). They adopt the hierarchical framework and make use of song lyric to detect stress level in the second step. In fact, many literatures have been produced to address the sentiment analysis problem in natural language processing research. Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular. Pang et al. (2002) adopt the VSM model to represent product reviews and apply text classification algorithms suc</context>
</contexts>
<marker>Chen, Xu, Zhang, Luo, 2006</marker>
<rawString>R.H. Chen, Z.L. Xu, Z.X. Zhang and F.Z. Luo. Content Based Music Emotion Analysis and Recognition. Proc. of 2006 International Workshop on Computer Music and Audio Technology, pp.68-75. 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Dong</author>
<author>Q Dong</author>
</authors>
<title>HowNet and the Computation of Meaning. World Scientific Publishing.</title>
<date>2006</date>
<marker>Dong, Dong, 2006</marker>
<rawString>Z. Dong and Q. Dong. HowNet and the Computation of Meaning. World Scientific Publishing. 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Learning to Classify Text Using Support Vector Machines, Methods, Theory, and Algorithms.</title>
<date>2002</date>
<publisher>Kluwer</publisher>
<contexts>
<context position="1921" citStr="Joachims, 2002" startWordPosition="268" endWordPosition="269"> sentiment classification nowadays becomes a hot research topic due largely to the increasing demand of ubiquitous song access, especially via mobile phone. In their music phone W910i, Sony and Ericsson provide Sense Me component to catch owner’s mood and play songs accordingly. Song sentiment classification is the key technology for song recommendation. Many research works have been reported to achieve this goal using audio signal (Knees et al., 2007). But research efforts on lyric-based song classification are very few. Preliminary experiments show that VSM-based text classification method (Joachims, 2002) is ineffective in song sentiment classification (see Section 5) due to the following four reasons. Firstly, the VSM model considers all content words within song lyric as features in text classification. But in fact many words in song lyric actually make little contribution to sentiment expressing. Using all content words as features, the VSM-based classification methods perform poorly in song sentiment classification. Secondly, observation on lyrics of thousands of Chinese pop songs reveals that sentiment-related nouns and verbs usually carry multiple senses. Unfortunately, the ambiguity is </context>
<context position="3189" citStr="Joachims, 2002" startWordPosition="466" endWordPosition="467">negations and modifiers are constantly found around the sentiment words in song lyric to inverse, to strengthen or to weaken the sentiments that the sentences carry. But the VSM model is not capable of reflecting these functions. Lastly, song lyric is usually very short, namely 50 words on average in length, rendering serious sparse data problem in VSM-based classification. To address the aforementioned problems of the VSM model, the sentiment vector space model (sVSM) is proposed in this work. We adopt the sVSM model to extract sentiment features from song lyrics and implement the SVM-light (Joachims, 2002) classification algorithm to assign sentiment labels to given songs. 133 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133–136, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 2 Related Works Song sentiment classification has been investigated since 1990s in audio signal processing community and research works are mostly found relying on audio signal to make a decision using machine learning algorithms (Li and Ogihara, 2006; Lu et al., 2006). Typically, the sentiment classes are defined based on the Thayer’s arousal-valence emotion plane (T</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>T. Joachims. Learning to Classify Text Using Support Vector Machines, Methods, Theory, and Algorithms. Kluwer (2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the Sentiment of Opinions.</title>
<date>2004</date>
<booktitle>Proc. COLING’04,</booktitle>
<pages>1367--1373</pages>
<contexts>
<context position="4640" citStr="Kim and Hovy, 2004" startWordPosition="685" endWordPosition="688">tected with intensity features and the stress level is determined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently investigated by Chen et al. (2006). They adopt the hierarchical framework and make use of song lyric to detect stress level in the second step. In fact, many literatures have been produced to address the sentiment analysis problem in natural language processing research. Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular. Pang et al. (2002) adopt the VSM model to represent product reviews and apply text classification algorithms such as Naïve Bayes, maximum entropy and support vector machines to predict sentiment polarity of given product review. Chen et al. (2006) also apply the VSM model in lyric-based song sentiment classification. However, our experiments show that song sentiment classification with the VSM model delivers disappointing quality</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S.-M. Kim and E. Hovy. Determining the Sentiment of Opinions. Proc. COLING’04, pp. 1367-1373. 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Knees</author>
<author>T Pohle</author>
<author>M Schedl</author>
<author>G Widmer</author>
</authors>
<title>A Music Search Engine Built upon Audio-based and Webbased Similarity Measures.</title>
<date>2007</date>
<booktitle>Proc. of SIGIR&apos;07,</booktitle>
<pages>47--454</pages>
<contexts>
<context position="1762" citStr="Knees et al., 2007" startWordPosition="246" endWordPosition="249">ocument. The preliminary experiments prove that the sVSM model outperforms the VSM model in the lyric-based song sentiment classification task. 1 Introduction Song sentiment classification nowadays becomes a hot research topic due largely to the increasing demand of ubiquitous song access, especially via mobile phone. In their music phone W910i, Sony and Ericsson provide Sense Me component to catch owner’s mood and play songs accordingly. Song sentiment classification is the key technology for song recommendation. Many research works have been reported to achieve this goal using audio signal (Knees et al., 2007). But research efforts on lyric-based song classification are very few. Preliminary experiments show that VSM-based text classification method (Joachims, 2002) is ineffective in song sentiment classification (see Section 5) due to the following four reasons. Firstly, the VSM model considers all content words within song lyric as features in text classification. But in fact many words in song lyric actually make little contribution to sentiment expressing. Using all content words as features, the VSM-based classification methods perform poorly in song sentiment classification. Secondly, observa</context>
</contexts>
<marker>Knees, Pohle, Schedl, Widmer, 2007</marker>
<rawString>P. Knees, T. Pohle, M. Schedl and G. Widmer. A Music Search Engine Built upon Audio-based and Webbased Similarity Measures. Proc. of SIGIR&apos;07, pp.47-454. 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Li</author>
<author>M Ogihara</author>
</authors>
<title>Content-based music similarity search and emotion detection.</title>
<date>2006</date>
<booktitle>Proc. IEEE Int. Conf. Acoustic, Speech, and Signal Processing,</booktitle>
<pages>17--21</pages>
<contexts>
<context position="3670" citStr="Li and Ogihara, 2006" startWordPosition="532" endWordPosition="535"> proposed in this work. We adopt the sVSM model to extract sentiment features from song lyrics and implement the SVM-light (Joachims, 2002) classification algorithm to assign sentiment labels to given songs. 133 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133–136, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 2 Related Works Song sentiment classification has been investigated since 1990s in audio signal processing community and research works are mostly found relying on audio signal to make a decision using machine learning algorithms (Li and Ogihara, 2006; Lu et al., 2006). Typically, the sentiment classes are defined based on the Thayer’s arousal-valence emotion plane (Thayer, 1989). Instead of assigning songs one of the four typical sentiment labels, Lu et al. (2006) propose the hierarchical framework to perform song sentiment classification with two steps. In the first step the energy level is detected with intensity features and the stress level is determined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as pro</context>
</contexts>
<marker>Li, Ogihara, 2006</marker>
<rawString>T. Li and M. Ogihara. Content-based music similarity search and emotion detection. Proc. IEEE Int. Conf. Acoustic, Speech, and Signal Processing, pp. 17–21. 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lu</author>
<author>D Liu</author>
<author>H Zhang</author>
</authors>
<title>Automatic mood detection and tracking of music audio signals.</title>
<date>2006</date>
<journal>IEEE Transactions on Audio, Speech &amp; Language Processing</journal>
<volume>14</volume>
<issue>1</issue>
<pages>5--18</pages>
<contexts>
<context position="3688" citStr="Lu et al., 2006" startWordPosition="536" endWordPosition="539">. We adopt the sVSM model to extract sentiment features from song lyrics and implement the SVM-light (Joachims, 2002) classification algorithm to assign sentiment labels to given songs. 133 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133–136, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 2 Related Works Song sentiment classification has been investigated since 1990s in audio signal processing community and research works are mostly found relying on audio signal to make a decision using machine learning algorithms (Li and Ogihara, 2006; Lu et al., 2006). Typically, the sentiment classes are defined based on the Thayer’s arousal-valence emotion plane (Thayer, 1989). Instead of assigning songs one of the four typical sentiment labels, Lu et al. (2006) propose the hierarchical framework to perform song sentiment classification with two steps. In the first step the energy level is detected with intensity features and the stress level is determined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently inv</context>
<context position="10247" citStr="Lu et al., 2006" startWordPosition="1665" endWordPosition="1668">asure (f) and accuracy (a) (Yang and Liu, 1999). In our experiments, three approaches are implemented in song sentiment classification, i.e. audiobased (AB) approach, knowledge-based (KB) approach and machine learning (ML) approach, in which the latter two approaches are also referred to as text-based (TB) approach. The intentions are 1) to compare AB approach against the two TB approaches, 2) to compare the ML approach against the KB approach, and 3) to compare the VSMbased ML approach against the s-VSM-based one. Audio-based (AB) Approach We extract 10 timbre features and 2 rhythm features (Lu et al., 2006) from audio data of each song. Thus each song is represented by a 12-dimension vector. We run SVM-light algorithm to learn on the training samples and classify test ones. Knowledge-based (KB) Approach We make use of HowNet (Dong and dong, 2006), to detect sentiment words, to recognize the neighboring negations and modifiers, and finally to locate sentiment units within song lyric. Sentiment (SM) of the sentiment unit (SU) is determined considering sentiment words (SW), negation (NEG) and modifiers (MOD) using the following rule. (1) SM(SU) = label(SW); (2) SM(SU) = - SM(SU) iff SU contains NEG</context>
</contexts>
<marker>Lu, Liu, Zhang, 2006</marker>
<rawString>L. Lu, D. Liu and H. Zhang. Automatic mood detection and tracking of music audio signals. IEEE Transactions on Audio, Speech &amp; Language Processing 14(1): 5-18 (2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>Proc. of EMNLP-02,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="4755" citStr="Pang et al., 2002" startWordPosition="700" endWordPosition="703">. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently investigated by Chen et al. (2006). They adopt the hierarchical framework and make use of song lyric to detect stress level in the second step. In fact, many literatures have been produced to address the sentiment analysis problem in natural language processing research. Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular. Pang et al. (2002) adopt the VSM model to represent product reviews and apply text classification algorithms such as Naïve Bayes, maximum entropy and support vector machines to predict sentiment polarity of given product review. Chen et al. (2006) also apply the VSM model in lyric-based song sentiment classification. However, our experiments show that song sentiment classification with the VSM model delivers disappointing quality (see Section 5). Error analysis reveals that the VSM model is problematic in representing song lyric. It is necess</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee and S. Vaithyanathan. Thumbs up? Sentiment Classification using Machine Learning Techniques. Proc. of EMNLP-02, pp.79-86. 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Thayer</author>
</authors>
<title>The Biopsychology of Mood and Arousal,</title>
<date>1989</date>
<publisher>University Press.</publisher>
<location>New York, Oxford</location>
<contexts>
<context position="3801" citStr="Thayer, 1989" startWordPosition="555" endWordPosition="556">) classification algorithm to assign sentiment labels to given songs. 133 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133–136, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 2 Related Works Song sentiment classification has been investigated since 1990s in audio signal processing community and research works are mostly found relying on audio signal to make a decision using machine learning algorithms (Li and Ogihara, 2006; Lu et al., 2006). Typically, the sentiment classes are defined based on the Thayer’s arousal-valence emotion plane (Thayer, 1989). Instead of assigning songs one of the four typical sentiment labels, Lu et al. (2006) propose the hierarchical framework to perform song sentiment classification with two steps. In the first step the energy level is detected with intensity features and the stress level is determined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently investigated by Chen et al. (2006). They adopt the hierarchical framework and make use of song lyric to detect stres</context>
</contexts>
<marker>Thayer, 1989</marker>
<rawString>R. E. Thayer, The Biopsychology of Mood and Arousal, New York, Oxford University Press. 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
<author>M L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Trans. on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="4705" citStr="Turney and Littman, 2003" startWordPosition="692" endWordPosition="695">rmined in the second step with timbre and rhythm features. It is proved difficult to detect stress level using audio as classification proof. Song sentiment classification using lyric as proof is recently investigated by Chen et al. (2006). They adopt the hierarchical framework and make use of song lyric to detect stress level in the second step. In fact, many literatures have been produced to address the sentiment analysis problem in natural language processing research. Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular. Pang et al. (2002) adopt the VSM model to represent product reviews and apply text classification algorithms such as Naïve Bayes, maximum entropy and support vector machines to predict sentiment polarity of given product review. Chen et al. (2006) also apply the VSM model in lyric-based song sentiment classification. However, our experiments show that song sentiment classification with the VSM model delivers disappointing quality (see Section 5). Error analysis reveals that the VSM model is pr</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>P. D. Turney and M. L. Littman. Measuring praise and criticism: Inference of semantic orientation from association. ACM Trans. on Information Systems, 21(4):315–346. 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>X Liu</author>
</authors>
<title>A Re-Examination of Text Categorization Methods.</title>
<date>1999</date>
<booktitle>Proc. of SIGIR’99,</booktitle>
<pages>42--49</pages>
<contexts>
<context position="9678" citStr="Yang and Liu, 1999" startWordPosition="1571" endWordPosition="1574">nambiguous sentiments, it is deemed that the s-VSM is model is promising to carry out the song sentiment classification task effectively. 5 Evaluation To evaluate the s-VSM model, a song corpus, i.e. 5SONGS, is created manually. It covers 2,653 Chinese pop songs, in which 1,632 are assigned label of light-hearted (positive class) and 1,021 assigned heavy-hearted (negative class). We randomly select 2,001 songs (around 75%) for training and the rest for testing. We adopt the standard evaluation criteria in text classification, namely precision (p), recall (r), f-1 measure (f) and accuracy (a) (Yang and Liu, 1999). In our experiments, three approaches are implemented in song sentiment classification, i.e. audiobased (AB) approach, knowledge-based (KB) approach and machine learning (ML) approach, in which the latter two approaches are also referred to as text-based (TB) approach. The intentions are 1) to compare AB approach against the two TB approaches, 2) to compare the ML approach against the KB approach, and 3) to compare the VSMbased ML approach against the s-VSM-based one. Audio-based (AB) Approach We extract 10 timbre features and 2 rhythm features (Lu et al., 2006) from audio data of each song. </context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Y. Yang and X. Liu. A Re-Examination of Text Categorization Methods. Proc. of SIGIR’99, pp. 42-49. 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>J O Pedersen</author>
</authors>
<title>A comparative study on feature selection in text categorization.</title>
<date>1997</date>
<booktitle>Proc. ICML’97,</booktitle>
<pages>412--420</pages>
<contexts>
<context position="11513" citStr="Yang and Pedersen, 1997" startWordPosition="1871" endWordPosition="1874">ontains MOD. In the above rule, label(x) is the function to read sentiment label(∈{1, -1}) of given word in the sentiment lexicon and degree(x) to read its modification degree(∈{1/2, 2}). As the sentiment labels are integer numbers, the following formula is adopted to obtain label of the given song lyric. label = sign(y, SM(SUi) ) Machine Learning (ML) Approach The ML approach adopts text classification algorithms to predict sentiment label of given song lyric. The SVM-light algorithm is implemented based on VSM model and s-VSM model, respectively. For the VSM model, we apply (CHI) algorithm (Yang and Pedersen, 1997) to select effective sentiment word features. For the s-VSM model, we adopt HowNet as the sentiment lexicon to create sentiment vectors. Experimental results are presented Table 2. 135 p R f-1 a Audio-based 0.504 0.701 0.586 0.504 Knowledge-based 0.726 0.584 0.647 0.714 VSM-based 0.587 1.000 0.740 0.587 s-VSM-based 0.783 0.750 0.766 0.732 Table 2. Experimental results Table 2 shows that the text-based methods outperform the audio-based method. This justifies our claim that lyric is better than audio in song sentiment detection. The second observation is that machine learning approach outperfor</context>
</contexts>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. Proc. ICML’97, pp.412-420. 1997.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>