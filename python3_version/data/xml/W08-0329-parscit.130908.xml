<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008750">
<title confidence="0.902959">
Incremental Hypothesis Alignment for Building Confusion Networks with
Application to Machine Translation System Combination
Antti-Veikko I. Rosti and Bing Zhang and Spyros Matsoukas and Richard Schwartz
</title>
<author confidence="0.618161">
BBN Technologies, 10 Moulton Street, Cambridge, MA 02138
</author>
<email confidence="0.978255">
arosti,bzhang,smatsouk,schwartz @bbn.com
</email>
<sectionHeader confidence="0.995357" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997073125">
Confusion network decoding has been the
most successful approach in combining out-
puts from multiple machine translation (MT)
systems in the recent DARPA GALE and
NIST Open MT evaluations. Due to the vary-
ing word order between outputs from differ-
ent MT systems, the hypothesis alignment
presents the biggest challenge in confusion
network decoding. This paper describes an
incremental alignment method to build confu-
sion networks based on the translation edit rate
(TER) algorithm. This new algorithm yields
significant BLEU score improvements over
other recent alignment methods on the GALE
test sets and was used in BBN’s submission to
the WMT08 shared translation task.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978205128205">
Confusion network decoding has been applied in
combining outputs from multiple machine transla-
tion systems. The earliest approach in (Bangalore
et al., 2001) used edit distance based multiple string
alignment (MSA) (Durbin et al., 1988) to build the
confusion networks. The recent approaches used
pair-wise alignment algorithms based on symmetric
alignments from a HMM alignment model (Matusov
et al., 2006) or edit distance alignments allowing
shifts (Rosti et al., 2007). The alignment method
described in this paper extends the latter by incre-
mentally aligning the hypotheses as in MSA but also
allowing shifts as in the TER alignment.
The confusion networks are built around a “skele-
ton” hypothesis. The skeleton hypothesis defines
the word order of the decoding output. Usually, the
1-best hypotheses from each system are considered
as possible skeletons. Using the pair-wise hypoth-
esis alignment, the confusion networks are built in
two steps. First, all hypotheses are aligned against
the skeleton independently. Second, the confusion
networks are created from the union of these align-
ments. The incremental hypothesis alignment algo-
rithm combines these two steps. All words from the
previously aligned hypotheses are available, even if
not present in the skeleton hypothesis, when align-
ing the following hypotheses. As in (Rosti et al.,
2007), confusion networks built around all skeletons
are joined into a lattice which is expanded and re-
scored with language models. System weights and
language model weights are tuned to optimize the
quality of the decoding output on a development set.
This paper is organized as follows. The incre-
mental TER alignment algorithm is described in
Section 2. Experimental evaluation comparing the
incremental and pair-wise alignment methods are
presented in Section 3 along with results on the
WMT08 Europarl test sets. Conclusions and future
work are presented in Section 4.
</bodyText>
<sectionHeader confidence="0.998766" genericHeader="method">
2 Incremental TER Alignment
</sectionHeader>
<bodyText confidence="0.999884375">
The incremental hypothesis alignment is based on
an extension of the TER algorithm (Snover et al.,
2006). The extension allows using a confusion net-
work as the reference. First, the algorithm finds the
minimum edit distance between the hypothesis and
the reference network by considering all word arcs
between two consecutive nodes in the reference net-
work as possible matches for a hypothesis word at
</bodyText>
<page confidence="0.986113">
183
</page>
<affiliation confidence="0.264569">
Proceedings of the Third Workshop on Statistical Machine Translation, pages 183–186,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</affiliation>
<equation confidence="0.901734666666667">
NULL (2) balloons (2) NULL (2) NULL (2) NULL (1) balloons (2)
I (3) like (3)
1 2 3 4 5 6
I (3) like (3)
1 2 3 4 5 6
big blue (1) blue (1) kites (1) big (1) blue (2) kites (1)
</equation>
<figureCaption confidence="0.993366">
Figure 1: Network after pair-wise TER alignment. Figure 2: Network after incremental TER alignment.
</figureCaption>
<bodyText confidence="0.999827534883721">
that position. Second, shifts of blocks of words that
have an exact match somewhere else in the network
are tried in order to find a new hypothesis word or-
der with a lower TER. Each shifted block is con-
sidered a single edit. These two steps are executed
iteratively as a greedy search. The final alignment
between the re-ordered hypothesis and the reference
network may include matches, substitutions, dele-
tions, and insertions.
The confusion networks are built by creating a
simple confusion network from the skeleton hypoth-
esis. If the skeleton hypothesis has words, the
initial network has arcs and nodes. Each
arc has a set of system specific confidence scores.
The score for the skeleton system is set to and
the confidences for other systems are set to zeros.
For each non-skeleton hypothesis, a TER alignment
against the current network is executed as described
above. Each match found will increase the system
specific word arc confidence by where
is the rank of the hypothesis in that system’s -best
list. Each substitution will generate a new word arc
at the corresponding position in the network. The
word arc confidence for the system is set to
and the confidences for other systems are set to ze-
ros. Each deletion will generate a new NULL word
arc unless one exists at the corresponding position
in the network. The NULL word arc confidences are
adjusted as in the case of a match or a substitution
depending on whether the NULL word arc exists or
not. Finally, each insertion will generate a new node
and two word arcs at the corresponding position in
the network. The first word arc will have the in-
serted word with the confidence set as in the case
of a substitution and the second word arc will have
a NULL word with confidences set by assuming all
previously aligned hypotheses and the skeleton gen-
erated the NULL word arc.
After all hypotheses have been added into the con-
fusion network, the system specific word arc confi-
dences are scaled to sum to one over all arcs between
each set of two consecutive nodes. Other scores for
the word arc are set as in (Rosti et al., 2007).
</bodyText>
<subsectionHeader confidence="0.999188">
2.1 Benefits over Pair-Wise TER Alignment
</subsectionHeader>
<bodyText confidence="0.9765474">
The incremental hypothesis alignment guarantees
that insertions between a hypothesis and the cur-
rent confusion network are always considered when
aligning the following hypotheses. This is not the
case in any pair-wise hypothesis alignment algo-
rithm. During the pair-wise hypothesis alignment,
an identical word in two hypotheses may be aligned
as an insertion or a substitution in a different posi-
tion with respect to the skeleton. This will result in
undesirable repetition and lower confidence for that
word in the final confusion network. Also, multiple
insertions are not handled implicitly.
For example, three hypotheses “I like balloons”,
“I like big blue balloons”, and “I like blue kites”
might be aligned by the pair-wise alignment, assum-
ing the first as the skeleton, as follows:
I like NULL balloons NULL
I like big blue balloons NULL
I like NULL balloons NULL
I like NULL blue kites
</bodyText>
<figureCaption confidence="0.726513333333333">
which results in the confusion network shown in
Figure 1. The number of hypotheses proposing each
word is shown in parentheses. The alignment be-
</figureCaption>
<bodyText confidence="0.97152825">
tween the skeleton and the second hypothesis has
two consecutive insertions “big blue” which are not
available for matching when the third hypothesis is
aligned against the skeleton. Therefore, the word
“blue” appears twice in the confusion network. If
many hypotheses have multiple insertions at the
same location with respect to the skeleton, they have
to be treated as phrases or a secondary alignment
process has to be applied.
Assuming the same hypotheses as above, the in-
cremental hypothesis alignment may yield the fol-
lowing alignment:
</bodyText>
<page confidence="0.985644">
184
</page>
<table confidence="0.999905857142857">
System TER BLEU MTR
worst 53.26 33.00 63.15
best 42.30 48.52 67.71
syscomb pw 39.85 52.00 68.73
syscomb giza 40.01 52.24 68.68
syscomb inc 39.25 52.73 68.97
oracle 21.68 64.14 78.18
</table>
<tableCaption confidence="0.995868">
Table 1: Results on the Arabic GALE Phase 2 system
combination tuning set with four reference translations.
</tableCaption>
<table confidence="0.999917571428571">
System TER BLEU MTR
worst 59.09 20.74 57.24
best 48.18 31.46 62.61
syscomb pw 46.31 33.02 63.18
syscomb giza 46.03 33.39 63.21
syscomb inc 45.45 33.90 63.45
oracle 27.53 49.10 71.81
</table>
<tableCaption confidence="0.982508">
Table 2: Results on the Arabic GALE Phase 2 evaluation
set with one reference translation.
</tableCaption>
<bodyText confidence="0.914229466666667">
I like NULL NULL balloons
I like big blue balloons
I like NULL blue kites
which results in the confusion network shown in
Figure 2. In this case the word “blue” is available
for matching when the third hypothesis is aligned.
It should be noted that the final confusion network
depends on the order in which the hypotheses are
added. The experiments so far have indicated that
different alignment order does not have a significant
influence on the final combination results as mea-
sured by the automatic evaluation metrics. Usually,
aligning the system outputs in the decreasing order
of their TER scores on the development set yields
the best scores.
</bodyText>
<subsectionHeader confidence="0.978538">
2.2 Confusion Network Oracle
</subsectionHeader>
<bodyText confidence="0.999986625">
The extended TER algorithm can also be used to
estimate an oracle TER in a confusion network by
aligning the reference translations against the con-
fusion network. The oracle hypotheses can be ex-
tracted by finding a path with the maximum number
of matches. These hypotheses give a lower bound
on the TER score for the hypotheses which can be
generated from the confusion networks.
</bodyText>
<sectionHeader confidence="0.997907" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999916944444445">
The quality of the final combination output depends
on many factors. Combining very similar outputs
does not yield as good gains as combining out-
puts from diverse systems. It is also important that
the development set used to tune the combination
weights is as similar to the evaluation set as possi-
ble. This development set should be different from
the one used to tune the individual systems to avoid
bias toward any system that may be over-tuned. Due
to the tight schedule for the WMT08, there was no
time to experiment with many configurations. As
more extensive experiments have been conducted in
the context of the DARPA GALE program, results
on the Arabic GALE Phase 2 evaluation setup are
first presented. The translation quality is measured
by three MT evaluation metrics: TER (Snover et al.,
2006), BLEU (Papineni et al., 2002), and METEOR
(Lavie and Agarwal, 2007).
</bodyText>
<subsectionHeader confidence="0.995443">
3.1 Results on Arabic GALE Outputs
</subsectionHeader>
<bodyText confidence="0.999972461538462">
For the Arabic GALE Phase 2 evaluation, nine sys-
tems were combined. Five systems were phrase-
based, two hierarchical, one syntax-based, and one
rule-based. All statistical systems were trained on
common parallel data, tuned on a common genre
specific development set, and a common English to-
kenization was used. The English bi-gram and 5-
gram language models used in the system combina-
tion were trained on about 7 billion words of English
text. Three iterations of bi-gram decoding weight
tuning were performed followed by one iteration of
5-gram re-scoring weight tuning. All weights were
tuned to minimize the sum of TER and 1-BLEU.
The final 1-best outputs were true-cased and deto-
kenized before scoring.
The results on the newswire system combination
development set and the GALE Phase 2 evaluation
set are shown in Tables 1 and 2. The first two
rows show the worst and best scores from the in-
dividual systems. The scores may be from different
systems as the best performing system in terms of
TER was not necessarily the best performing system
in terms of the other metrics. The following three
rows show the scores of three combination outputs
where the only difference was the hypothesis align-
ment method. The first, syscomb pw, corresponds
</bodyText>
<page confidence="0.995418">
185
</page>
<table confidence="0.995705">
BLEU
System de-en fr-en
worst 11.84 16.31
best 28.30 33.13
syscomb 29.05 33.63
</table>
<tableCaption confidence="0.9968945">
Table 3: NIST BLEU scores on the German-English (de-
en) and French-English (fr-en) Europarl test2008 set.
</tableCaption>
<bodyText confidence="0.999843875">
to the pair-wise TER alignment described in (Rosti
et al., 2007). The second, syscomb giza, cor-
responds to the pair-wise symmetric HMM align-
ments from GIZA++ described in (Matusov et al.,
2006). The third, syscomb inc, corresponds to
the incremental TER alignment presented in this pa-
per. Finally, oracle corresponds to an estimate of
the lower bound on the translation quality obtained
by extracting the TER oracle output from the con-
fusion networks generated by the incremental TER
alignment. It is unlikely that there exists a set of
weights that would yield the oracle output after de-
coding, though. The incremental TER alignment
yields significant improvements over all individual
systems and the combination outputs using the pair-
wise alignment methods.
</bodyText>
<subsectionHeader confidence="0.938463">
3.2 Results on WMT08 Europarl Outputs
</subsectionHeader>
<bodyText confidence="0.999768807692308">
On the WMT08 shared translation task, transla-
tions for two language pairs and two tasks were
provided for the system combination experiments.
Twelve systems participated in the German-English
and fourteen in the French-English translation tasks.
The translations of the Europarl test (test2008) were
provided as the development set outputs and the
translations of the News test (newstest2008) were
provided as the evaluation set outputs. An English
bi-gram, 4-gram, and true-caser language models
were trained by using all English text available for
the WMT08 shared task, including Europarl mono-
lingual and news commentary parallel training sets.
The outputs were tokenized and lower-cased before
combination, and the final combination output was
true-cased and detokenized.
The results on the Europarl test set for both lan-
guage pairs are shown in table 3. The first two rows
have the NIST BLEU scores of the worst and the
best individual systems. The last row, syscomb,
corresponds to the system combination using the in-
cremental TER alignment. The improvements in the
NIST BLEU scores are fairly modest which is prob-
ably due to low diversity of the system outputs. It is
also unlikely that these weights are optimal for the
out-of-domain News test set outputs.
</bodyText>
<sectionHeader confidence="0.999649" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999950166666667">
This paper describes a novel hypothesis alignment
algorithm for building confusion networks from
multiple machine translation system outputs. The al-
gorithm yields significant improvements on the Ara-
bic GALE evaluation set outputs and was used in
BBN’s submission to the WMT08 shared translation
task. The hypothesis alignment may benefit from
using stemming and synonymy in matching words.
Also, special handling of punctuation may improve
the alignment further. The future work will inves-
tigate the influence of better alignment to the final
combination outputs.
</bodyText>
<sectionHeader confidence="0.998203" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997713">
This work was supported by DARPA/IPTO Contract
No. HR0011-06-C-0022 under the GALE program.
</bodyText>
<sectionHeader confidence="0.999095" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999906958333333">
S. Bangalore, G. Bordel, and G. Riccardi. 2001. Com-
puting consensus translation from multiple machine
translation systems. In Proc. ASRU, pages 351–354.
R. Durbin, S.R. Eddy, A. Krogh, and G. Mitchison. 1988.
Biological Sequence Analysis: Probabilistic Models of
Proteins and Nucleic Acids. Cambridge Univ. Press.
A. Lavie and A. Agarwal. 2007. METEOR: An auto-
matic metric for MT evaluation with high levels of cor-
relation with human judgments. In Proc. ACL/WMT,
pages 228–231.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
consensus translation from multiple machine transla-
tion systems using enhanced hypotheses alignment. In
Proc. EACL, pages 33–40.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. In Proc. ACL, pages 311–318.
A.-V.I. Rosti, S. Matsoukas, and R. Schwartz. 2007.
Improved word-level system combination for machine
translation. In Proc. ACL 2007, pages 312–319.
M. Snover, B. Dorr, R. Schwartz, L. Micciula, and
J. Makhoul. 2006. A study of translation edit rate with
targeted human annotation. In Proc. AMTA, pages
223–231.
</reference>
<page confidence="0.998793">
186
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.911533">
<title confidence="0.9984335">Incremental Hypothesis Alignment for Building Confusion Networks Application to Machine Translation System Combination</title>
<author confidence="0.985612">I Rosti Zhang Matsoukas Schwartz</author>
<address confidence="0.962158">BBN Technologies, 10 Moulton Street, Cambridge, MA 02138</address>
<email confidence="0.994195">arosti,bzhang,smatsouk,schwartz@bbn.com</email>
<abstract confidence="0.998072">Confusion network decoding has been the most successful approach in combining outputs from multiple machine translation (MT) systems in the recent DARPA GALE and NIST Open MT evaluations. Due to the varying word order between outputs from different MT systems, the hypothesis alignment presents the biggest challenge in confusion network decoding. This paper describes an incremental alignment method to build confusion networks based on the translation edit rate (TER) algorithm. This new algorithm yields significant BLEU score improvements over other recent alignment methods on the GALE test sets and was used in BBN’s submission to the WMT08 shared translation task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Bordel</author>
<author>G Riccardi</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems.</title>
<date>2001</date>
<booktitle>In Proc. ASRU,</booktitle>
<pages>351--354</pages>
<contexts>
<context position="1154" citStr="Bangalore et al., 2001" startWordPosition="162" endWordPosition="165">ween outputs from different MT systems, the hypothesis alignment presents the biggest challenge in confusion network decoding. This paper describes an incremental alignment method to build confusion networks based on the translation edit rate (TER) algorithm. This new algorithm yields significant BLEU score improvements over other recent alignment methods on the GALE test sets and was used in BBN’s submission to the WMT08 shared translation task. 1 Introduction Confusion network decoding has been applied in combining outputs from multiple machine translation systems. The earliest approach in (Bangalore et al., 2001) used edit distance based multiple string alignment (MSA) (Durbin et al., 1988) to build the confusion networks. The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007). The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment. The confusion networks are built around a “skeleton” hypothesis. The skeleton hypothesis defines the word order of the</context>
</contexts>
<marker>Bangalore, Bordel, Riccardi, 2001</marker>
<rawString>S. Bangalore, G. Bordel, and G. Riccardi. 2001. Computing consensus translation from multiple machine translation systems. In Proc. ASRU, pages 351–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Durbin</author>
<author>S R Eddy</author>
<author>A Krogh</author>
<author>G Mitchison</author>
</authors>
<title>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.</title>
<date>1988</date>
<publisher>Cambridge Univ. Press.</publisher>
<contexts>
<context position="1233" citStr="Durbin et al., 1988" startWordPosition="174" endWordPosition="177">est challenge in confusion network decoding. This paper describes an incremental alignment method to build confusion networks based on the translation edit rate (TER) algorithm. This new algorithm yields significant BLEU score improvements over other recent alignment methods on the GALE test sets and was used in BBN’s submission to the WMT08 shared translation task. 1 Introduction Confusion network decoding has been applied in combining outputs from multiple machine translation systems. The earliest approach in (Bangalore et al., 2001) used edit distance based multiple string alignment (MSA) (Durbin et al., 1988) to build the confusion networks. The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007). The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment. The confusion networks are built around a “skeleton” hypothesis. The skeleton hypothesis defines the word order of the decoding output. Usually, the 1-best hypotheses from each system are considere</context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1988</marker>
<rawString>R. Durbin, S.R. Eddy, A. Krogh, and G. Mitchison. 1988. Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge Univ. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lavie</author>
<author>A Agarwal</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In Proc. ACL/WMT,</booktitle>
<pages>228--231</pages>
<contexts>
<context position="10038" citStr="Lavie and Agarwal, 2007" startWordPosition="1636" endWordPosition="1639">hts is as similar to the evaluation set as possible. This development set should be different from the one used to tune the individual systems to avoid bias toward any system that may be over-tuned. Due to the tight schedule for the WMT08, there was no time to experiment with many configurations. As more extensive experiments have been conducted in the context of the DARPA GALE program, results on the Arabic GALE Phase 2 evaluation setup are first presented. The translation quality is measured by three MT evaluation metrics: TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and METEOR (Lavie and Agarwal, 2007). 3.1 Results on Arabic GALE Outputs For the Arabic GALE Phase 2 evaluation, nine systems were combined. Five systems were phrasebased, two hierarchical, one syntax-based, and one rule-based. All statistical systems were trained on common parallel data, tuned on a common genre specific development set, and a common English tokenization was used. The English bi-gram and 5- gram language models used in the system combination were trained on about 7 billion words of English text. Three iterations of bi-gram decoding weight tuning were performed followed by one iteration of 5-gram re-scoring weigh</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>A. Lavie and A. Agarwal. 2007. METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments. In Proc. ACL/WMT, pages 228–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment.</title>
<date>2006</date>
<booktitle>In Proc. EACL,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="1404" citStr="Matusov et al., 2006" startWordPosition="199" endWordPosition="202">orithm. This new algorithm yields significant BLEU score improvements over other recent alignment methods on the GALE test sets and was used in BBN’s submission to the WMT08 shared translation task. 1 Introduction Confusion network decoding has been applied in combining outputs from multiple machine translation systems. The earliest approach in (Bangalore et al., 2001) used edit distance based multiple string alignment (MSA) (Durbin et al., 1988) to build the confusion networks. The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007). The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment. The confusion networks are built around a “skeleton” hypothesis. The skeleton hypothesis defines the word order of the decoding output. Usually, the 1-best hypotheses from each system are considered as possible skeletons. Using the pair-wise hypothesis alignment, the confusion networks are built in two steps. First, all hypotheses are aligned against the skeleton in</context>
<context position="11704" citStr="Matusov et al., 2006" startWordPosition="1911" endWordPosition="1914">t necessarily the best performing system in terms of the other metrics. The following three rows show the scores of three combination outputs where the only difference was the hypothesis alignment method. The first, syscomb pw, corresponds 185 BLEU System de-en fr-en worst 11.84 16.31 best 28.30 33.13 syscomb 29.05 33.63 Table 3: NIST BLEU scores on the German-English (deen) and French-English (fr-en) Europarl test2008 set. to the pair-wise TER alignment described in (Rosti et al., 2007). The second, syscomb giza, corresponds to the pair-wise symmetric HMM alignments from GIZA++ described in (Matusov et al., 2006). The third, syscomb inc, corresponds to the incremental TER alignment presented in this paper. Finally, oracle corresponds to an estimate of the lower bound on the translation quality obtained by extracting the TER oracle output from the confusion networks generated by the incremental TER alignment. It is unlikely that there exists a set of weights that would yield the oracle output after decoding, though. The incremental TER alignment yields significant improvements over all individual systems and the combination outputs using the pairwise alignment methods. 3.2 Results on WMT08 Europarl Out</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>E. Matusov, N. Ueffing, and H. Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. In Proc. EACL, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="10000" citStr="Papineni et al., 2002" startWordPosition="1630" endWordPosition="1633">et used to tune the combination weights is as similar to the evaluation set as possible. This development set should be different from the one used to tune the individual systems to avoid bias toward any system that may be over-tuned. Due to the tight schedule for the WMT08, there was no time to experiment with many configurations. As more extensive experiments have been conducted in the context of the DARPA GALE program, results on the Arabic GALE Phase 2 evaluation setup are first presented. The translation quality is measured by three MT evaluation metrics: TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and METEOR (Lavie and Agarwal, 2007). 3.1 Results on Arabic GALE Outputs For the Arabic GALE Phase 2 evaluation, nine systems were combined. Five systems were phrasebased, two hierarchical, one syntax-based, and one rule-based. All statistical systems were trained on common parallel data, tuned on a common genre specific development set, and a common English tokenization was used. The English bi-gram and 5- gram language models used in the system combination were trained on about 7 billion words of English text. Three iterations of bi-gram decoding weight tuning were performed followed by on</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. ACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-V I Rosti</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
</authors>
<title>Improved word-level system combination for machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL</booktitle>
<pages>312--319</pages>
<contexts>
<context position="1469" citStr="Rosti et al., 2007" startWordPosition="209" endWordPosition="212">ts over other recent alignment methods on the GALE test sets and was used in BBN’s submission to the WMT08 shared translation task. 1 Introduction Confusion network decoding has been applied in combining outputs from multiple machine translation systems. The earliest approach in (Bangalore et al., 2001) used edit distance based multiple string alignment (MSA) (Durbin et al., 1988) to build the confusion networks. The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007). The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment. The confusion networks are built around a “skeleton” hypothesis. The skeleton hypothesis defines the word order of the decoding output. Usually, the 1-best hypotheses from each system are considered as possible skeletons. Using the pair-wise hypothesis alignment, the confusion networks are built in two steps. First, all hypotheses are aligned against the skeleton independently. Second, the confusion networks are created from the </context>
<context position="5884" citStr="Rosti et al., 2007" startWordPosition="952" endWordPosition="955">each insertion will generate a new node and two word arcs at the corresponding position in the network. The first word arc will have the inserted word with the confidence set as in the case of a substitution and the second word arc will have a NULL word with confidences set by assuming all previously aligned hypotheses and the skeleton generated the NULL word arc. After all hypotheses have been added into the confusion network, the system specific word arc confidences are scaled to sum to one over all arcs between each set of two consecutive nodes. Other scores for the word arc are set as in (Rosti et al., 2007). 2.1 Benefits over Pair-Wise TER Alignment The incremental hypothesis alignment guarantees that insertions between a hypothesis and the current confusion network are always considered when aligning the following hypotheses. This is not the case in any pair-wise hypothesis alignment algorithm. During the pair-wise hypothesis alignment, an identical word in two hypotheses may be aligned as an insertion or a substitution in a different position with respect to the skeleton. This will result in undesirable repetition and lower confidence for that word in the final confusion network. Also, multipl</context>
<context position="11575" citStr="Rosti et al., 2007" startWordPosition="1890" endWordPosition="1893">ores from the individual systems. The scores may be from different systems as the best performing system in terms of TER was not necessarily the best performing system in terms of the other metrics. The following three rows show the scores of three combination outputs where the only difference was the hypothesis alignment method. The first, syscomb pw, corresponds 185 BLEU System de-en fr-en worst 11.84 16.31 best 28.30 33.13 syscomb 29.05 33.63 Table 3: NIST BLEU scores on the German-English (deen) and French-English (fr-en) Europarl test2008 set. to the pair-wise TER alignment described in (Rosti et al., 2007). The second, syscomb giza, corresponds to the pair-wise symmetric HMM alignments from GIZA++ described in (Matusov et al., 2006). The third, syscomb inc, corresponds to the incremental TER alignment presented in this paper. Finally, oracle corresponds to an estimate of the lower bound on the translation quality obtained by extracting the TER oracle output from the confusion networks generated by the incremental TER alignment. It is unlikely that there exists a set of weights that would yield the oracle output after decoding, though. The incremental TER alignment yields significant improvement</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>A.-V.I. Rosti, S. Matsoukas, and R. Schwartz. 2007. Improved word-level system combination for machine translation. In Proc. ACL 2007, pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciula</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proc. AMTA,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="3047" citStr="Snover et al., 2006" startWordPosition="455" endWordPosition="458">is expanded and rescored with language models. System weights and language model weights are tuned to optimize the quality of the decoding output on a development set. This paper is organized as follows. The incremental TER alignment algorithm is described in Section 2. Experimental evaluation comparing the incremental and pair-wise alignment methods are presented in Section 3 along with results on the WMT08 Europarl test sets. Conclusions and future work are presented in Section 4. 2 Incremental TER Alignment The incremental hypothesis alignment is based on an extension of the TER algorithm (Snover et al., 2006). The extension allows using a confusion network as the reference. First, the algorithm finds the minimum edit distance between the hypothesis and the reference network by considering all word arcs between two consecutive nodes in the reference network as possible matches for a hypothesis word at 183 Proceedings of the Third Workshop on Statistical Machine Translation, pages 183–186, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics NULL (2) balloons (2) NULL (2) NULL (2) NULL (1) balloons (2) I (3) like (3) 1 2 3 4 5 6 I (3) like (3) 1 2 3 4 5 6 big blue (1) blu</context>
<context position="9970" citStr="Snover et al., 2006" startWordPosition="1625" endWordPosition="1628">rtant that the development set used to tune the combination weights is as similar to the evaluation set as possible. This development set should be different from the one used to tune the individual systems to avoid bias toward any system that may be over-tuned. Due to the tight schedule for the WMT08, there was no time to experiment with many configurations. As more extensive experiments have been conducted in the context of the DARPA GALE program, results on the Arabic GALE Phase 2 evaluation setup are first presented. The translation quality is measured by three MT evaluation metrics: TER (Snover et al., 2006), BLEU (Papineni et al., 2002), and METEOR (Lavie and Agarwal, 2007). 3.1 Results on Arabic GALE Outputs For the Arabic GALE Phase 2 evaluation, nine systems were combined. Five systems were phrasebased, two hierarchical, one syntax-based, and one rule-based. All statistical systems were trained on common parallel data, tuned on a common genre specific development set, and a common English tokenization was used. The English bi-gram and 5- gram language models used in the system combination were trained on about 7 billion words of English text. Three iterations of bi-gram decoding weight tuning</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>M. Snover, B. Dorr, R. Schwartz, L. Micciula, and J. Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proc. AMTA, pages 223–231.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>