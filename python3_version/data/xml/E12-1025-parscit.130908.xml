<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000026">
<title confidence="0.956638">
Active learning for interactive machine translation
</title>
<author confidence="0.643623">
Jes´us Gonz´alez-Rubio and Daniel Ortiz-Martinez and Francisco Casacuberta
</author>
<affiliation confidence="0.318237">
D. de Sistemas Inform´aticos y Computaci´on
</affiliation>
<address confidence="0.209494">
U. Polit`ecnica de Val`encia
C. de Vera s/n, 46022 Valencia, Spain
</address>
<email confidence="0.989874">
{jegonzalez,dortiz,fcn}@dsic.upv.es
</email>
<sectionHeader confidence="0.996482" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999854333333333">
Translation needs have greatly increased
during the last years. In many situa-
tions, text to be translated constitutes an
unbounded stream of data that grows con-
tinually with time. An effective approach
to translate text documents is to follow
an interactive-predictive paradigm in which
both the system is guided by the user
and the user is assisted by the system to
generate error-free translations. Unfortu-
nately, when processing such unbounded
data streams even this approach requires an
overwhelming amount of manpower. Is in
this scenario where the use of active learn-
ing techniques is compelling. In this work,
we propose different active learning tech-
niques for interactive machine translation.
Results show that for a given translation
quality the use of active learning allows us
to greatly reduce the human effort required
to translate the sentences in the stream.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932916666667">
Translation needs have greatly increased during
the last years due to phenomena such as global-
ization and technologic development. For exam-
ple, the European Parliament1 translates its pro-
ceedings to 22 languages in a regular basis or
Project Syndicate2 that translates editorials into
different languages. In these and many other ex-
amples, data can be viewed as an incoming un-
bounded stream since it grows continually with
time (Levenberg et al., 2010). Manual translation
of such streams of data is extremely expensive
given the huge volume of translation required,
</bodyText>
<footnote confidence="0.9999245">
1http://www.europarl.europa.eu
2http://project-syndicate.org
</footnote>
<bodyText confidence="0.997571805555556">
therefore various automatic machine translation
methods have been proposed.
However, automatic statistical machine trans-
lation (SMT) systems are far from generating
error-free translations and their outputs usually
require human post-editing in order to achieve
high-quality translations. One way of taking ad-
vantage of SMT systems is to combine them
with the knowledge of a human translator in the
interactive-predictive machine translation (IMT)
framework (Foster et al., 1998; Langlais and La-
palme, 2002; Barrachina et al., 2009), which is
a particular case of the computer-assisted trans-
lation paradigm (Isabelle and Church, 1997). In
the IMT framework, a state-of-the-art SMT model
and a human translator collaborate to obtain high-
quality translations while minimizing required
human effort.
Unfortunately, the application of either post-
editing or IMT to data streams with massive data
volumes is still too expensive, simply because
manual supervision of all instances requires huge
amounts of manpower. For such massive data
streams the need of employing active learning
(AL) is compelling. AL techniques for IMT se-
lectively ask an oracle (e.g. a human transla-
tor) to supervise a small portion of the incoming
sentences. Sentences are selected so that SMT
models estimated from them translate new sen-
tences as accurately as possible. There are three
challenges when applying AL to unbounded data
streams (Zhu et al., 2010). These challenges can
be instantiated to IMT as follows:
1. The pool of candidate sentences is dynam-
ically changing, whereas existing AL algo-
rithms are dealing with static datasets only.
</bodyText>
<page confidence="0.980361">
245
</page>
<note confidence="0.9780845">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 245–254,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<listItem confidence="0.8598024">
2. Concepts such as optimum translation and
translation probability distribution are con-
tinually evolving whereas existing AL algo-
rithms only deal with constant concepts.
3. Data volume is unbounded which makes
</listItem>
<bodyText confidence="0.891897333333333">
impractical to batch-learn one single sys-
tem from all previously translated sentences.
Therefore, model training must be done in an
incremental fashion.
In this work, we present a proposal of AL for
IMT specifically designed to work with stream
data. In short, our proposal divides the data
stream into blocks where AL techniques for static
datasets are applied. Additionally, we implement
an incremental learning technique to efficiently
train the base SMT models as new data is avail-
able.
</bodyText>
<sectionHeader confidence="0.999754" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999974345454546">
A body of work has recently been proposed to ap-
ply AL techniques to SMT (Haffari et al., 2009;
Ambati et al., 2010; Bloodgood and Callison-
Burch, 2010). The aim of these works is to
build one single optimal SMT model from manu-
ally translated data extracted from static datasets.
None of them fit in the setting of data streams.
Some of the above described challenges of AL
from unbounded streams have been previously ad-
dressed in the MT literature. In order to deal with
the evolutionary nature of the problem, Nepveu et
al. (2004) propose an IMT system with dynamic
adaptation via cache-based model extensions for
language and translation models. Pursuing the
same goal for SMT, Levenberg et al., (2010)
study how to bound the space when processing
(potentially) unbounded streams of parallel data
and propose a method to incrementally retrain
SMT models. Another method to efficiently re-
train a SMT model with new data was presented
in (Ortiz-Martinez et al., 2010). In this work,
the authors describe an application of the online
learning paradigm to the IMT framework.
To the best of our knowledge, the only previ-
ous work on AL for IMT is (Gonz´alez-Rubio et
al., 2011). There, the authors present a naive ap-
plication of the AL paradigm for IMT that do not
take into account the dynamic change in proba-
bility distribution of the stream. Nevertheless, re-
sults show that even that simple AL framework
halves the required human effort to obtain a cer-
tain translation quality.
In this work, the AL framework presented
in (Gonz´alez-Rubio et al., 2011) is extended in
an effort to address all the above described chal-
lenges. In short, we propose an AL framework for
IMT that splits the data stream into blocks. This
approach allows us to have more context to model
the changing probability distribution of the stream
(challenge 2) and results in a more accurate sam-
pling of the changing pool of sentences (chal-
lenge 1). In contrast to the proposal described
in (Gonz´alez-Rubio et al., 2011), we define sen-
tence sampling strategies whose underlying mod-
els can be updated with the newly available data.
This way, the sentences to be supervised by the
user are chosen taking into account previously su-
pervised sentences. To efficiently retrain the un-
derlying SMT models of the IMT system (chal-
lenge 3), we follow the online learning technique
described in (Ortiz-Martinez et al., 2010). Finally,
we integrate all these elements to define an AL
framework for IMT with an objective of obtaining
an optimum balance between translation quality
and human user effort.
</bodyText>
<sectionHeader confidence="0.996157" genericHeader="method">
3 Interactive machine translation
</sectionHeader>
<bodyText confidence="0.9566006">
IMT can be seen as an evolution of the SMT
framework. Given a sentence f from a source
language to be translated into a sentence e of
a target language, the fundamental equation of
SMT (Brown et al., 1993) is defined as follows:
</bodyText>
<equation confidence="0.9853325">
e� = arg max Pr(e I f) (1)
e
</equation>
<bodyText confidence="0.9995685">
where Pr(e I f) is usually approximated by a log
linear translation model (Koehn et al., 2003). In
this case, the decision rule is given by the expres-
sion:
</bodyText>
<equation confidence="0.999759666666667">
e� = arg max
e � M
m=1 amhm(e, f) (2)
</equation>
<bodyText confidence="0.9998635">
where each hm(e, f) is a feature function repre-
senting a statistical model and am its weight.
In the IMT framework, a human translator is in-
troduced in the translation process to collaborate
with an SMT model. For a given source sentence,
the SMT model fully automatically generates an
initial translation. The human user checks this
translation, from left to right, correcting the first
</bodyText>
<page confidence="0.997354">
246
</page>
<bodyText confidence="0.580531">
source (f): Para ver la lista de recursos
desired translation (6): To view a listing of resources
</bodyText>
<figure confidence="0.98596725">
inter.-0 ep To view the resources list
es
inter.-1 ep To view
k
es
a
list of resources
inter.-2 ep To view a list
k i
es ng resources
inter.-3 ep To view a listing
k
es
o
f resources
accept ep To view a listing of resources
</figure>
<figureCaption confidence="0.917766666666667">
Figure 1: IMT session to translate a Spanish sentence
into English. The desired translation is the translation
the human user have in mind. At interaction-0, the sys-
</figureCaption>
<bodyText confidence="0.8718593125">
tem suggests a translation (es). At interaction-1, the
user moves the mouse to accept the first eight charac-
ters ”To view ” and presses the a key (k), then the
system suggests completing the sentence with ”list of
resources” (a new es). Interactions 2 and 3 are simi-
lar. In the final interaction, the user accepts the current
translation.
error. Then, the SMT model proposes a new ex-
tension taking the correct prefix, ep, into account.
These steps are repeated until the user accepts the
translation. Figure 1 illustrates a typical IMT ses-
sion. In the resulting decision rule, we have to
find an extension es for a given prefix ep. To do
this we reformulate equation (1) as follows, where
the term Prep  |f) has been dropped since it does
not depend on es:
</bodyText>
<equation confidence="0.98371225">
6s = arg max Prep, es  |f) (3)
es
� arg max p(es  |f, ep) (4)
es
</equation>
<bodyText confidence="0.9996528">
The search is restricted to those sentences e
which contain ep as prefix. Since e = ep es, we
can use the same log-linear SMT model, equa-
tion (2), whenever the search procedures are ad-
equately modified (Barrachina et al., 2009).
</bodyText>
<sectionHeader confidence="0.985367" genericHeader="method">
4 Active learning for IMT
</sectionHeader>
<bodyText confidence="0.994507537037037">
The aim of the IMT framework is to obtain high-
quality translations while minimizing the required
human effort. Despite the fact that IMT may
reduce the required effort with respect to post-
editing, it still requires the user to supervise all
the translations. To address this problem, we pro-
pose to use AL techniques to select only a small
number of sentences whose translations are worth
to be supervised by the human expert.
This approach implies a modification of the
user-machine interaction protocol. For a given
source sentence, the SMT model generates an ini-
tial translation. Then, if this initial translation is
classified as incorrect or “worth of supervision”,
we perform a conventional IMT procedure as in
Figure 1. If not, we directly return the initial au-
tomatic translation and no effort is required from
the user. At the end of the process, we use the new
sentence pair (f, e) available to refine the SMT
models used by the IMT system.
In this scenario, the user only checks a small
number of sentences, thus, final translations are
not error-free as in conventional IMT. However,
results in previous works (Gonz´alez-Rubio et al.,
2011) show that this approach yields important
reduction in human effort. Moreover, depending
on the definition of the sampling strategy, we can
modify the ratio of sentences that are interactively
translated to adapt our system to the requirements
of a specific translation task. For example, if the
main priority is to minimize human effort, our
system can be configured to translate all the sen-
tences without user intervention.
Algorithm 1 describes the basic algorithm to
implement AL for IMT. The algorithm receives as
input an initial SMT model, M, a sampling strat-
egy, S, a stream of source sentences, F, and the
block size, B. First, a block of B sentences, X,
is extracted from the data stream (line 3). From
this block, we sample those sentences, Y , that
are worth to be supervised by the human expert
(line 4). For each of the sentences in X, the cur-
rent SMT model generates an initial translation,
6, (line 6). If the sentence has been sampled as
worthy of supervision, f E Y , the user is required
to interactively translate it (lines 8–13) as exem-
plified in Figure 1. The source sentence f and its
human-supervised translation, e, are then used to
retrain the SMT model (line 14). Otherwise, we
directly output the automatic translation e� as our
final translation (line 17).
Most of the functions in the algorithm denote
different steps in the interaction between the hu-
man user and the machine:
</bodyText>
<listItem confidence="0.999534">
• translate(M, f): returns the most proba-
ble automatic translation of f given by M.
• validPrefix(e): returns the prefix of e
</listItem>
<page confidence="0.886807">
247
</page>
<listItem confidence="0.8067044">
Algorithm 1: Pseudo-code of the proposed
algorithm to implement AL for IMT from
unbounded data streams.
validated by the user as correct. This prefix
includes the correction k.
• genSuffix(M, f, ep): returns the suffix of
maximum probability that extends prefix ep.
• validTranslation(e): returns True if
the user considers the current translation to
be correct and False otherwise.
</listItem>
<bodyText confidence="0.999152615384615">
Apart from these, the two elements that define
the performance of our algorithm are the sampling
strategy S(X, M) and the retrain(M, (f, e))
function. On the one hand, the sampling strat-
egy decides which sentences should be supervised
by the user, which defines the human effort re-
quired by the algorithm. Section 5 describes our
implementation of the sentence sampling to deal
with the dynamic nature of data streams. On the
other hand, the retrain(·) function incremen-
tally trains the SMT model with each new training
pair (f, e). Section 6 describes the implementa-
tion of this function.
</bodyText>
<sectionHeader confidence="0.813468" genericHeader="method">
5 Sentence sampling strategies
</sectionHeader>
<bodyText confidence="0.9999873">
A good sentence sampling strategy must be able
to select those sentences that along with their cor-
rect translations improve most the performance of
the SMT model. To do that, the sampling strat-
egy have to correctly discriminate “informative”
sentences from those that are not. We can make
different approximations to measure the informa-
tiveness of a given sentence. In the following
sections, we describe the three different sampling
strategies tested in our experimentation.
</bodyText>
<subsectionHeader confidence="0.998041">
5.1 Random sampling
</subsectionHeader>
<bodyText confidence="0.999990739130435">
Arguably, the simplest sampling approach is ran-
dom sampling, where the sentences are randomly
selected to be interactively translated. Although
simple, it turns out that random sampling per-
form surprisingly well in practice. The success
of random sampling stem from the fact that in
data stream environments the translation proba-
bility distributions may vary significantly through
time. While general AL algorithms ask the user to
translate informative sentences, they may signifi-
cantly change probability distributions by favor-
ing certain translations, consequently, the previ-
ously human-translated sentences may no longer
reveal the genuine translation distribution in the
current point of the data stream (Zhu et al., 2007).
This problem is less severe for static data where
the candidate pool is fixed and AL algorithms are
able to survey all instances. Random sampling
avoids this problem by randomly selecting sen-
tences for human supervision. As a result, it al-
ways selects those sentences with the most similar
distribution to the current sentence distribution in
the data stream.
</bodyText>
<subsectionHeader confidence="0.999198">
5.2 n-gram coverage sampling
</subsectionHeader>
<bodyText confidence="0.999977666666667">
One technique to measure the informativeness
of a sentence is to directly measure the amount
of new information that it will add to the SMT
model. This sampling strategy considers that
sentences with rare n-grams are more informa-
tive. The intuition for this approach is that rare
n-grams need to be seen several times in order to
accurately estimate their probability.
To do that, we store the counts for each n-gram
present in the sentences used to train the SMT
model. We assume that an n-gram is accurately
represented when it appears A or more times in
</bodyText>
<figure confidence="0.98360888372093">
2
3
4
5
6
7
8
9
10
11
input : M (initial SMT model)
S (sampling strategy)
F (stream of source sentences)
B (block size)
auxiliar : X (block of sentences)
Y (sentences worth of supervision)
1 begin
repeat
X = getSentsFromStream (B,F);
Y = S(X,M);
foreach f E X do
e� = translate(M, f);
if f E Y then
e = e;
repeat
ep = validPrefix(e);
es = genSuffix(M, f, ep);
12
e=ep
es;
until validTranslation(e) ;
M = retrain(M, (f, e));
output(e);
13
14
15
16
else
output(e);
until True ;
17
18
19 end
</figure>
<page confidence="0.980224">
248
</page>
<bodyText confidence="0.998847">
the training samples. Therefore, the score for a
given sentence f is computed as:
</bodyText>
<equation confidence="0.991132333333333">
o�
C(f) = = |Nn A(f) |(5)
En=1 |Nn(f)|
</equation>
<bodyText confidence="0.990692214285714">
where Nn(f) is the set of n-grams of size n
in f, N&lt;A
n (f) is the set of n-grams of size n in
f that are inaccurately represented in the training
data and N is the maximum n-gram order. In
the experimentation, we assume N = 4 as the
maximum n-gram order and a value of 10 for the
threshold A. This sampling strategy works by se-
lecting a given percentage of the highest scoring
sentences.
We update the counts of the n-grams seen by
the SMT model with each new sentence pair.
Hence, the sampling strategy is always up-to-date
with the last training data.
</bodyText>
<subsectionHeader confidence="0.977311">
5.3 Dynamic confidence sampling
</subsectionHeader>
<bodyText confidence="0.99996865">
Another technique is to consider that the most in-
formative sentence is the one the current SMT
model translates worst. The intuition behind this
approach is that an SMT model can not generate
good translations unless it has enough informa-
tion to translate the sentence.
The usual approach to compute the quality of a
translation hypothesis is to compare it to a refer-
ence translation, but, in this case, it is not a valid
option since reference translations are not avail-
able. Hence, we use confidence estimation (Gan-
drabur and Foster, 2003; Blatz et al., 2004; Ueff-
ing and Ney, 2007) to estimate the probability of
correctness of the translations. Specifically, we
estimate the quality of a translation from the con-
fidence scores of their individual words.
The confidence score of a word ei of the trans-
lation e = e1 ... ei ... eI generated from the
source sentence f = f1 ... fj ... fJ is computed
as described in (Ueffing and Ney, 2005):
</bodyText>
<equation confidence="0.992225">
Cw(ei, f) = max p(ei|fj) (6)
0&lt;j&lt; |f |
</equation>
<bodyText confidence="0.999988571428571">
where p(ei|fj) is an IBM model 1 (Brown et al.,
1993) bilingual lexicon probability and f0 is the
empty source word. The confidence score for the
full translation e is computed as the ratio of its
words classified as correct by the word confidence
measure. Therefore, we define the confidence-
based informativeness score as:
</bodyText>
<equation confidence="0.893039">
C(e, f) = 1 _ |{ei  |Cw(ei,f) &gt; Tw} |(7)
|e|
</equation>
<bodyText confidence="0.99995225">
Finally, this sampling strategy works by select-
ing a given percentage of the highest scoring sen-
tences.
We dynamically update the confidence sampler
each time a new sentence pair is added to the SMT
model. The incremental version of the EM algo-
rithm (Neal and Hinton, 1999) is used to incre-
mentally train the IBM model 1.
</bodyText>
<sectionHeader confidence="0.7754" genericHeader="method">
6 Retraining of the SMT model
</sectionHeader>
<bodyText confidence="0.999920117647059">
To retrain the SMT model, we implement the
online learning techniques proposed in (Ortiz-
Mart´ınez et al., 2010). In that work, a state-
of-the-art log-linear model (Och and Ney, 2002)
and a set of techniques to incrementally train this
model were defined. The log-linear model is com-
posed of a set of feature functions governing dif-
ferent aspects of the translation process, includ-
ing a language model, a source sentence–length
model, inverse and direct translation models, a
target phrase–length model, a source phrase–
length model and a distortion model.
The incremental learning algorithm allows us
to process each new training sample in constant
time (i.e. the computational complexity of train-
ing a new sample does not depend on the num-
ber of previously seen training samples). To do
that, a set of sufficient statistics is maintained for
each feature function. If the estimation of the
feature function does not require the use of the
well-known expectation–maximization (EM) al-
gorithm (Dempster et al., 1977) (e.g. n-gram lan-
guage models), then it is generally easy to incre-
mentally extend the model given a new training
sample. By contrast, if the EM algorithm is re-
quired (e.g. word alignment models), the estima-
tion procedure has to be modified, since the con-
ventional EM algorithm is designed for its use in
batch learning scenarios. For such models, the in-
cremental version of the EM algorithm (Neal and
Hinton, 1999) is applied. A detailed description
of the update algorithm for each of the models in
the log-linear combination is presented in (Ortiz-
Martinez et al., 2010).
</bodyText>
<sectionHeader confidence="0.999318" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.9998265">
We carried out experiments to assess the perfor-
mance of the proposed AL implementation for
IMT. In each experiments, we started with an
initial SMT model that is incrementally updated
</bodyText>
<page confidence="0.9973">
249
</page>
<table confidence="0.998876">
corpus use sentences words
(Spa/Eng)
Europarl train 731K 15M/15M
devel. 2K 60K/58K
News test 51K 1.5M/1.2M
Commentary
</table>
<tableCaption confidence="0.857300666666667">
Table 1: Size of the Spanish–English corpora used in
the experiments. K and M stand for thousands and
millions of elements respectively.
</tableCaption>
<bodyText confidence="0.999962916666667">
with the sentences selected by the current sam-
pling strategy. Due to the unavailability of public
benchmark data streams, we selected a relatively
large corpus and treated it as a data stream for AL.
To simulate the interaction with the user, we used
the reference translations in the data stream cor-
pus as the translation the human user would like
to obtain. Since each experiment is carried out
under the same conditions, if one sampling strat-
egy outperforms its peers, then we can safely con-
clude that this is because the sentences selected to
be translated are more informative.
</bodyText>
<subsectionHeader confidence="0.999394">
7.1 Training corpus and data stream
</subsectionHeader>
<bodyText confidence="0.999961">
The training data comes from the Europarl corpus
as distributed for the shared task in the NAACL
2006 workshop on statistical machine transla-
tion (Koehn and Monz, 2006). We used this data
to estimate the initial log-linear model used by our
IMT system (see Section 6). The weights of the
different feature functions were tuned by means
of minimum error–rate training (Och, 2003) exe-
cuted on the Europarl development corpus. Once
the SMT model was trained, we use the News
Commentary corpus (Callison-Burch et al., 2007)
to simulate the data stream. The size of these cor-
pora is shown in Table 1. The reasons to choose
the News Commentary corpus to carry out our
experiments are threefold: first, its size is large
enough to simulate a data stream and test our
AL techniques in the long term; second, it is
out-of-domain data which allows us to simulate
a real-world situation that may occur in a trans-
lation company, and, finally, it consists in edito-
rials from eclectic domain: general politics, eco-
nomics and science, which effectively represents
the variations in the sentence distributions of the
simulated data stream.
</bodyText>
<subsectionHeader confidence="0.999346">
7.2 Assessment criteria
</subsectionHeader>
<bodyText confidence="0.999997515151515">
We want to measure both the quality of the gener-
ated translations and the human effort required to
obtain them.
We measure translation quality with the well-
known BLEU (Papineni et al., 2002) score.
To estimate human user effort, we simulate the
actions taken by a human user in its interaction
with the IMT system. The first translation hypoth-
esis for each given source sentence is compared
with a single reference translation and the longest
common character prefix (LCP) is obtained. The
first non-matching character is replaced by the
corresponding reference character and then a new
translation hypothesis is produced (see Figure 1).
This process is iterated until a full match with the
reference is obtained. Each computation of the
LCP would correspond to the user looking for the
next error and moving the pointer to the corre-
sponding position of the translation hypothesis.
Each character replacement, on the other hand,
would correspond to a keystroke of the user.
Bearing this in mind, we measure the user ef-
fort by means of the keystroke and mouse-action
ratio (KSMR) (Barrachina et al., 2009). This mea-
sure has been extensively used to report results in
the IMT literature. KSMR is calculated as the
number of keystrokes plus the number of mouse
movements divided by the total number of refer-
ence characters. From a user point of view the
two types of actions are different and require dif-
ferent types of effort (Macklovitch, 2006). In any
case, as an approximation, KSMR assumes that
both actions require a similar effort.
</bodyText>
<subsectionHeader confidence="0.996295">
7.3 Experimental results
</subsectionHeader>
<bodyText confidence="0.999916181818182">
In this section, we report results for three different
experiments. First, we studied the performance
of the sampling strategies when dealing with the
sampling bias problem. In the second experiment,
we carried out a typical AL experiment measur-
ing the performance of the sampling strategies as
a function of the percentage of the corpus used
to retrain the SMT model. Finally, we tested our
AL implementation for IMT in order to study the
tradeoff between required human effort and final
translation quality.
</bodyText>
<subsectionHeader confidence="0.735755">
7.3.1 Dealing with the sampling bias
</subsectionHeader>
<bodyText confidence="0.9952535">
In this experiment, we want to study the perfor-
mance of the different sampling strategies when
</bodyText>
<page confidence="0.987531">
250
</page>
<figure confidence="0.977188407407407">
22
21
20
BLEU
19
18
17
16
DCS NS RS
BLEU
DCS NS SCS RS
23
22
21
20
19
18
17
16
15
20
19
18
17
2 4 6 8
0 10 20 30 40 50
Block number
</figure>
<figureCaption confidence="0.979543">
Figure 2: Performance of the AL methods across dif-
ferent data blocks. Block size 500. Human supervision
10% of the corpus.
</figureCaption>
<figure confidence="0.948421">
0 5 10 15 20
Percentage (%) of the corpus in words
</figure>
<figureCaption confidence="0.995702666666667">
Figure 3: BLEU of the initial automatic translations
as a function of the percentage of the corpus used to
retrain the model.
</figureCaption>
<bodyText confidence="0.999811794871795">
dealing with the sampling bias problem. Fig-
ure 2 shows the evolution of the translation qual-
ity, in terms of BLEU, across different data blocks
for the three sampling strategies described in sec-
tion 5, namely, dynamic confidence sampling
(DCS), n-gram coverage sampling (NS) and ran-
dom sampling (RS). On the one hand, the x-axis
represents the data blocks number in their tempo-
ral order. On the other hand, the y-axis represents
the BLEU score when automatically translating a
block. Such translation is obtained by the SMT
model trained with translations supervised by the
user up to that point of the data stream. To fairly
compare the different methods, we fixed the per-
centage of words supervised by the human user
(10%). In addition to this, we used a block size of
500 sentences. Similar results were obtained for
other block sizes.
Results in Figure 2 indicate that the perfor-
mances for the data blocks fluctuate and fluctu-
ations are quite significant. This phenomenon is
due to the eclectic domain of the sentences in the
data stream. Additionally, the steady increase in
performance is caused by the increasing amount
of data used to retrain the SMT model.
Regarding the results for the different sam-
pling strategies, DCS consistently outperformed
RS and NS. This observation asserts that for con-
cept drifting data streams with constant changing
translation distributions, DCS can adaptively ask
the user to translate sentences to build a superior
SMT model. On the other hand, NS obtains worse
results that RS. This result can be explained by the
fact that NS is independent of the target language
and just looks into the source language, while
DCS takes into account both the source sentence
and its automatic translation. Similar phenomena
has been reported in a previous work on AL for
SMT (Haffari et al., 2009).
</bodyText>
<subsectionHeader confidence="0.96021">
7.3.2 AL performance
</subsectionHeader>
<bodyText confidence="0.999492423076923">
We carried out experiments to study the perfor-
mance of the different sampling strategies. To this
end, we compare the quality of the initial auto-
matic translations generated in our AL implemen-
tation for IMT (line 6 in Algorithm 1). Figure 3
shows the BLEU score of these initial translations
represented as a function of the percentage of the
corpus used to retrain the SMT model. The per-
centage of the corpus is measured in number of
running words.
In Figure 3, we present results for the three
sampling strategies described in section 5. Ad-
ditionally, we also compare our techniques with
the AL technique for IMT proposed in (Gonz´alez-
Rubio et al., 2011). Such technique is similar to
DCS but it does not update the IBM model 1 used
by the confidence sampler with the newly avail-
able human-translated sentences. This technique
is referred to as static confidence sampler (SCS).
Results in Figure 3 indicate that the perfor-
mance of the retrained SMT models increased as
more data was incorporated. Regarding the sam-
pling strategies, DCS improved the results ob-
tained by the other sampling strategies. NS ob-
tained by far the worst results, which confirms the
results shown in the previous experiment. Finally,
</bodyText>
<page confidence="0.991955">
251
</page>
<figure confidence="0.964587">
DCS SCS w/o AL
NS RS
55
50
75
70
65
60
16 18 20 22 24
BLEU
100
90
80
70
60
50
40
30
20
10
0 10 20 30 40 50 60 70
KSMR
</figure>
<figureCaption confidence="0.999876">
Figure 4: Quality of the data stream translation
</figureCaption>
<bodyText confidence="0.944032333333333">
(BLEU) as a function of the required human effort
(KSMR). w/o AL denotes a system with no retraining.
as it can be seen, SCS obtained slightly worst re-
sults than DCS showing the importance of dy-
namically adapting the underlying model used by
the sampling strategy.
</bodyText>
<subsectionHeader confidence="0.4728725">
7.3.3 Balancing human effort and
translation quality
</subsectionHeader>
<bodyText confidence="0.999835844444445">
Finally, we studied the balance between re-
quired human effort and final translation error.
This can be useful in a real-world scenario where
a translation company is hired to translate a
stream of sentences. Under these circumstances,
it would be important to be able to predict the ef-
fort required from the human translators to obtain
a certain translation quality.
The experiment simulate this situation using
our proposed IMT system with AL to translate
the stream of sentences. To have a broad view
of the behavior of our system, we repeated this
translation process multiple times requiring an in-
creasing human effort each time. Experiments
range from a fully-automatic translation system
with no need of human intervention to a system
where the human is required to supervise all the
sentences. Figure 4 presents results for SCS (see
section 7.3.2) and the sentence selection strate-
gies presented in section 5. In addition, we also
present results for a static system without AL (w/o
AL). This system is equal to SCS but it do not per-
form any SMT retraining.
Results in Figure 4 show a consistent reduction
in required user effort when using AL. For a given
human effort the use of AL methods allowed to
obtain twice the translation quality. Regarding the
different AL sampling strategies, DCS obtains the
better results but differences with other methods
are slight.
Varying the sentence classifier, we can achieve
a balance between final translation quality and re-
quired human effort. This feature allows us to
adapt the system to suit the requirements of the
particular translation task or to the available eco-
nomic or human resources. For example, if a
translation quality of 60 BLEU points is satisfac-
tory, then the human translators would need to
modify only a 20% of the characters of the au-
tomatically generated translations.
Finally, it should be noted that our IMT sys-
tems with AL are able to generate new suffixes
and retrain with new sentence pairs in tenths of a
second. Thus, it can be applied in real time sce-
narios.
</bodyText>
<sectionHeader confidence="0.988593" genericHeader="conclusions">
8 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999948290322581">
In this work, we have presented an AL frame-
work for IMT specially designed to process data
streams with massive volumes of data. Our pro-
posal splits the data stream in blocks of sentences
of a certain size and applies AL techniques indi-
vidually for each block. For this purpose, we im-
plemented different sampling strategies that mea-
sure the informativeness of a sentence according
to different criteria.
To evaluate the performance of our proposed
sampling strategies, we carried out experiments
comparing them with random sampling and the
only previously proposed AL technique for IMT
described in (Gonz´alez-Rubio et al., 2011). Ac-
cording to the results, one of the proposed sam-
pling strategies, specifically the dynamic con-
fidence sampling strategy, consistently outper-
formed all the other strategies.
The results in the experimentation show that the
use of AL techniques allows us to make a tradeoff
between required human effort and final transla-
tion quality. In other words, we can adapt our sys-
tem to meet the translation quality requirements
of the translation task or the available human re-
sources.
As future work, we plan to investigate on
more sophisticated sampling strategies such as
those based in information density or query-by-
committee. Additionally, we will conduct exper-
iments with real users to confirm the results ob-
tained by our user simulation.
</bodyText>
<page confidence="0.994455">
252
</page>
<sectionHeader confidence="0.996511" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999910888888889">
The research leading to these results has re-
ceived funding from the European Union Seventh
Framework Programme (FP7/2007-2013) under
grant agreement no 287576. Work also supported
by the EC (FEDER/FSE) and the Spanish MEC
under the MIPRCV Consolider Ingenio 2010 pro-
gram (CSD2007-00018) and iTrans2 (TIN2009-
14511) project and by the Generalitat Valenciana
under grant ALMPR (Prometeo/2009/01).
</bodyText>
<sectionHeader confidence="0.997785" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999836670103093">
Vamshi Ambati, Stephan Vogel, and Jaime Carbonell.
2010. Active learning and crowd-sourcing for ma-
chine translation. In Proc. of the conference on
International Language Resources and Evaluation,
pages 2169–2174.
Sergio Barrachina, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,
Antonio Lagarda, Hermann Ney, Jes´us Tom´as, En-
rique Vidal, and Juan-Miguel Vilar. 2009. Sta-
tistical approaches to computer-assisted translation.
Computational Linguistics, 35:3–28.
John Blatz, Erin Fitzgerald, George Foster, Simona
Gandrabur, Cyril Goutte, Alex Kulesza, Alberto
Sanchis, and Nicola Ueffing. 2004. Confidence es-
timation for machine translation. In Proc. of the in-
ternational conference on Computational Linguis-
tics, pages 315–321.
Michael Bloodgood and Chris Callison-Burch. 2010.
Bucking the trend: large-scale cost-focused active
learning for statistical machine translation. In Proc.
of the Association for Computational Linguistics,
pages 854–864.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
parameter estimation. Computational Linguistics,
19:263–311.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-) evaluation of machine translation. In Proc.
of the Workshop on Statistical Machine Translation,
pages 136–158.
Arthur Dempster, Nan Laird, and Donald Rubin.
1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statis-
tical Society., 39(1):1–38.
George Foster, Pierre Isabelle, and Pierre Plamon-
don. 1998. Target-text mediated interactive ma-
chine translation. Machine Translation, 12:175–
194.
Simona Gandrabur and George Foster. 2003. Confi-
dence estimation for text prediction. In Proc. of the
Conference on Computational Natural Language
Learning, pages 315–321.
Jes´us Gonz´alez-Rubio, Daniel Ortiz-Mart´ınez, and
Francisco casacuberta. 2011. An active learn-
ing scenario for interactive machine translation. In
Proc. of the 13thInternational Conference on Mul-
timodal Interaction. ACM.
Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.
2009. Active learning for statistical phrase-based
machine translation. In Proc. of the North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 415–423.
Pierre Isabelle and Kenneth Ward Church. 1997. Spe-
cial issue on new tools for human translators. Ma-
chine Translation, 12(1-2):1–2.
Philipp Koehn and Christof Monz. 2006. Man-
ual and automatic evaluation of machine transla-
tion between european languages. In Proc. of the
Workshop on Statistical Machine Translation, pages
102–121.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, pages 48–54.
Philippe Langlais and Guy Lapalme. 2002. Trans
Type: development-evaluation cycles to boost trans-
lator’s productivity. Machine Translation, 17:77–
98.
Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models for
statistical machine translation. In Proc. of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 394–402, Los Angeles,
California, June.
Elliott Macklovitch. 2006. TransType2: the last word.
In Proc. of the conference on International Lan-
guage Resources and Evaluation, pages 167–17.
Radford Neal and Geoffrey Hinton. 1999. A view of
the EM algorithm that justifies incremental, sparse,
and other variants. Learning in graphical models,
pages 355–368.
Laurent Nepveu, Guy Lapalme, Philippe Langlais, and
George Foster. 2004. Adaptive language and trans-
lation models for interactive machine translation. In
Proc, of EMNLP, pages 190–197, Barcelona, Spain,
July.
Franz Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statisti-
cal machine translation. In Proc. of the Association
for Computational Linguistics, pages 295–302.
Franz Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. of the Associa-
tion for Computational Linguistics, pages 160–167.
</reference>
<page confidence="0.981835">
253
</page>
<reference confidence="0.999659285714286">
Daniel Ortiz-Martfnez, Ismael Garcfa-Varea, and
Francisco Casacuberta. 2010. Online learning for
interactive statistical machine translation. In Proc.
of the North American Chapter of the Association
for Computational Linguistics, pages 546–554.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Proc.
of the Association for Computational Linguistics,
pages 311–318.
Nicola Ueffing and Hermann Ney. 2005. Applica-
tion of word-level confidence measures in interac-
tive statistical machine translation. In Proc. of the
European Association for Machine Translation con-
ference, pages 262–270.
Nicola Ueffing and Hermann Ney. 2007. Word-
level confidence estimation for machine translation.
Computational Linguistics, 33:9–40.
Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong
Shi. 2007. Active learning from data streams. In
Proc. of the 7th IEEE International Conference on
Data Mining, pages 757–762. IEEE Computer So-
ciety.
Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong
Shi. 2010. Active learning from stream data using
optimal weight classifier ensemble. Transactions
on Systems, Man and Cybernetics Part B, 40:1607–
1621, December.
</reference>
<page confidence="0.998637">
254
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.648532">
<title confidence="0.9013675">Active learning for interactive machine translation Gonz´alez-Rubio Ortiz-Martinez D. de Sistemas Inform´aticos y U. Polit`ecnica de</title>
<author confidence="0.859072">C de_Vera sn</author>
<author confidence="0.859072">Valencia</author>
<abstract confidence="0.998986">Translation needs have greatly increased during the last years. In many situations, text to be translated constitutes an unbounded stream of data that grows continually with time. An effective approach to translate text documents is to follow an interactive-predictive paradigm in which both the system is guided by the user and the user is assisted by the system to generate error-free translations. Unfortunately, when processing such unbounded data streams even this approach requires an overwhelming amount of manpower. Is in this scenario where the use of active learning techniques is compelling. In this work, we propose different active learning techniques for interactive machine translation. Results show that for a given translation quality the use of active learning allows us to greatly reduce the human effort required to translate the sentences in the stream.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Vamshi Ambati</author>
<author>Stephan Vogel</author>
<author>Jaime Carbonell</author>
</authors>
<title>Active learning and crowd-sourcing for machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of the conference on International Language Resources and Evaluation,</booktitle>
<pages>2169--2174</pages>
<contexts>
<context position="4462" citStr="Ambati et al., 2010" startWordPosition="671" endWordPosition="674">mpractical to batch-learn one single system from all previously translated sentences. Therefore, model training must be done in an incremental fashion. In this work, we present a proposal of AL for IMT specifically designed to work with stream data. In short, our proposal divides the data stream into blocks where AL techniques for static datasets are applied. Additionally, we implement an incremental learning technique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et al., (2010) study how </context>
</contexts>
<marker>Ambati, Vogel, Carbonell, 2010</marker>
<rawString>Vamshi Ambati, Stephan Vogel, and Jaime Carbonell. 2010. Active learning and crowd-sourcing for machine translation. In Proc. of the conference on International Language Resources and Evaluation, pages 2169–2174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Barrachina</author>
<author>Oliver Bender</author>
<author>Francisco Casacuberta</author>
<author>Jorge Civera</author>
<author>Elsa Cubel</author>
<author>Shahram Khadivi</author>
<author>Antonio Lagarda</author>
<author>Hermann Ney</author>
<author>Jes´us Tom´as</author>
<author>Enrique Vidal</author>
<author>Juan-Miguel Vilar</author>
</authors>
<title>Statistical approaches to computer-assisted translation.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<pages>35--3</pages>
<marker>Barrachina, Bender, Casacuberta, Civera, Cubel, Khadivi, Lagarda, Ney, Tom´as, Vidal, Vilar, 2009</marker>
<rawString>Sergio Barrachina, Oliver Bender, Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio Lagarda, Hermann Ney, Jes´us Tom´as, Enrique Vidal, and Juan-Miguel Vilar. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35:3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blatz</author>
<author>Erin Fitzgerald</author>
<author>George Foster</author>
<author>Simona Gandrabur</author>
<author>Cyril Goutte</author>
<author>Alex Kulesza</author>
<author>Alberto Sanchis</author>
<author>Nicola Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2004</date>
<booktitle>In Proc. of the international conference on Computational Linguistics,</booktitle>
<pages>315--321</pages>
<contexts>
<context position="16969" citStr="Blatz et al., 2004" startWordPosition="2824" endWordPosition="2827">h the last training data. 5.3 Dynamic confidence sampling Another technique is to consider that the most informative sentence is the one the current SMT model translates worst. The intuition behind this approach is that an SMT model can not generate good translations unless it has enough information to translate the sentence. The usual approach to compute the quality of a translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 ... ei ... eI generated from the source sentence f = f1 ... fj ... fJ is computed as described in (Ueffing and Ney, 2005): Cw(ei, f) = max p(ei|fj) (6) 0&lt;j&lt; |f | where p(ei|fj) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as </context>
</contexts>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kulesza, Sanchis, Ueffing, 2004</marker>
<rawString>John Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. 2004. Confidence estimation for machine translation. In Proc. of the international conference on Computational Linguistics, pages 315–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Bloodgood</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Bucking the trend: large-scale cost-focused active learning for statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of the Association for Computational Linguistics,</booktitle>
<pages>854--864</pages>
<marker>Bloodgood, Callison-Burch, 2010</marker>
<rawString>Michael Bloodgood and Chris Callison-Burch. 2010. Bucking the trend: large-scale cost-focused active learning for statistical machine translation. In Proc. of the Association for Computational Linguistics, pages 854–864.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="7146" citStr="Brown et al., 1993" startWordPosition="1123" endWordPosition="1126">ount previously supervised sentences. To efficiently retrain the underlying SMT models of the IMT system (challenge 3), we follow the online learning technique described in (Ortiz-Martinez et al., 2010). Finally, we integrate all these elements to define an AL framework for IMT with an objective of obtaining an optimum balance between translation quality and human user effort. 3 Interactive machine translation IMT can be seen as an evolution of the SMT framework. Given a sentence f from a source language to be translated into a sentence e of a target language, the fundamental equation of SMT (Brown et al., 1993) is defined as follows: e� = arg max Pr(e I f) (1) e where Pr(e I f) is usually approximated by a log linear translation model (Koehn et al., 2003). In this case, the decision rule is given by the expression: e� = arg max e � M m=1 amhm(e, f) (2) where each hm(e, f) is a feature function representing a statistical model and am its weight. In the IMT framework, a human translator is introduced in the translation process to collaborate with an SMT model. For a given source sentence, the SMT model fully automatically generates an initial translation. The human user checks this translation, from l</context>
<context position="17442" citStr="Brown et al., 1993" startWordPosition="2914" endWordPosition="2917">a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 ... ei ... eI generated from the source sentence f = f1 ... fj ... fJ is computed as described in (Ueffing and Ney, 2005): Cw(ei, f) = max p(ei|fj) (6) 0&lt;j&lt; |f | where p(ei|fj) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio of its words classified as correct by the word confidence measure. Therefore, we define the confidencebased informativeness score as: C(e, f) = 1 _ |{ei |Cw(ei,f) &gt; Tw} |(7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair is added to the SMT model. The incremental version of the EM algorithm (Neal and Hinton, 1999) is used to </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19:263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>(Meta-) evaluation of machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the Workshop on Statistical Machine Translation,</booktitle>
<pages>136--158</pages>
<contexts>
<context position="21291" citStr="Callison-Burch et al., 2007" startWordPosition="3555" endWordPosition="3558">is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain: general politics, economics and science, which effectively represents the variations in the sentence distributions of the simulated data str</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2007</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) evaluation of machine translation. In Proc. of the Workshop on Statistical Machine Translation, pages 136–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Dempster</author>
<author>Nan Laird</author>
<author>Donald Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society.,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="19123" citStr="Dempster et al., 1977" startWordPosition="3194" endWordPosition="3197">e model, a source sentence–length model, inverse and direct translation models, a target phrase–length model, a source phrase– length model and a distortion model. The incremental learning algorithm allows us to process each new training sample in constant time (i.e. the computational complexity of training a new sample does not depend on the number of previously seen training samples). To do that, a set of sufficient statistics is maintained for each feature function. If the estimation of the feature function does not require the use of the well-known expectation–maximization (EM) algorithm (Dempster et al., 1977) (e.g. n-gram language models), then it is generally easy to incrementally extend the model given a new training sample. By contrast, if the EM algorithm is required (e.g. word alignment models), the estimation procedure has to be modified, since the conventional EM algorithm is designed for its use in batch learning scenarios. For such models, the incremental version of the EM algorithm (Neal and Hinton, 1999) is applied. A detailed description of the update algorithm for each of the models in the log-linear combination is presented in (OrtizMartinez et al., 2010). 7 Experiments We carried ou</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur Dempster, Nan Laird, and Donald Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society., 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Pierre Isabelle</author>
<author>Pierre Plamondon</author>
</authors>
<title>Target-text mediated interactive machine translation.</title>
<date>1998</date>
<journal>Machine Translation,</journal>
<volume>12</volume>
<pages>194</pages>
<contexts>
<context position="2279" citStr="Foster et al., 1998" startWordPosition="327" endWordPosition="330">s of data is extremely expensive given the huge volume of translation required, 1http://www.europarl.europa.eu 2http://project-syndicate.org therefore various automatic machine translation methods have been proposed. However, automatic statistical machine translation (SMT) systems are far from generating error-free translations and their outputs usually require human post-editing in order to achieve high-quality translations. One way of taking advantage of SMT systems is to combine them with the knowledge of a human translator in the interactive-predictive machine translation (IMT) framework (Foster et al., 1998; Langlais and Lapalme, 2002; Barrachina et al., 2009), which is a particular case of the computer-assisted translation paradigm (Isabelle and Church, 1997). In the IMT framework, a state-of-the-art SMT model and a human translator collaborate to obtain highquality translations while minimizing required human effort. Unfortunately, the application of either postediting or IMT to data streams with massive data volumes is still too expensive, simply because manual supervision of all instances requires huge amounts of manpower. For such massive data streams the need of employing active learning (</context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1998</marker>
<rawString>George Foster, Pierre Isabelle, and Pierre Plamondon. 1998. Target-text mediated interactive machine translation. Machine Translation, 12:175– 194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simona Gandrabur</author>
<author>George Foster</author>
</authors>
<title>Confidence estimation for text prediction.</title>
<date>2003</date>
<booktitle>In Proc. of the Conference on Computational Natural Language Learning,</booktitle>
<pages>315--321</pages>
<contexts>
<context position="16949" citStr="Gandrabur and Foster, 2003" startWordPosition="2819" endWordPosition="2823">egy is always up-to-date with the last training data. 5.3 Dynamic confidence sampling Another technique is to consider that the most informative sentence is the one the current SMT model translates worst. The intuition behind this approach is that an SMT model can not generate good translations unless it has enough information to translate the sentence. The usual approach to compute the quality of a translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 ... ei ... eI generated from the source sentence f = f1 ... fj ... fJ is computed as described in (Ueffing and Ney, 2005): Cw(ei, f) = max p(ei|fj) (6) 0&lt;j&lt; |f | where p(ei|fj) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translati</context>
</contexts>
<marker>Gandrabur, Foster, 2003</marker>
<rawString>Simona Gandrabur and George Foster. 2003. Confidence estimation for text prediction. In Proc. of the Conference on Computational Natural Language Learning, pages 315–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gonz´alez-Rubio</author>
<author>Daniel Ortiz-Mart´ınez</author>
<author>Francisco casacuberta</author>
</authors>
<title>An active learning scenario for interactive machine translation.</title>
<date>2011</date>
<booktitle>In Proc. of the 13thInternational Conference on Multimodal Interaction.</booktitle>
<publisher>ACM.</publisher>
<marker>Gonz´alez-Rubio, Ortiz-Mart´ınez, casacuberta, 2011</marker>
<rawString>Jes´us Gonz´alez-Rubio, Daniel Ortiz-Mart´ınez, and Francisco casacuberta. 2011. An active learning scenario for interactive machine translation. In Proc. of the 13thInternational Conference on Multimodal Interaction. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gholamreza Haffari</author>
<author>Maxim Roy</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for statistical phrase-based machine translation.</title>
<date>2009</date>
<booktitle>In Proc. of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>415--423</pages>
<contexts>
<context position="4441" citStr="Haffari et al., 2009" startWordPosition="667" endWordPosition="670">nbounded which makes impractical to batch-learn one single system from all previously translated sentences. Therefore, model training must be done in an incremental fashion. In this work, we present a proposal of AL for IMT specifically designed to work with stream data. In short, our proposal divides the data stream into blocks where AL techniques for static datasets are applied. Additionally, we implement an incremental learning technique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et a</context>
<context position="26384" citStr="Haffari et al., 2009" startWordPosition="4425" endWordPosition="4428">t sampling strategies, DCS consistently outperformed RS and NS. This observation asserts that for concept drifting data streams with constant changing translation distributions, DCS can adaptively ask the user to translate sentences to build a superior SMT model. On the other hand, NS obtains worse results that RS. This result can be explained by the fact that NS is independent of the target language and just looks into the source language, while DCS takes into account both the source sentence and its automatic translation. Similar phenomena has been reported in a previous work on AL for SMT (Haffari et al., 2009). 7.3.2 AL performance We carried out experiments to study the performance of the different sampling strategies. To this end, we compare the quality of the initial automatic translations generated in our AL implementation for IMT (line 6 in Algorithm 1). Figure 3 shows the BLEU score of these initial translations represented as a function of the percentage of the corpus used to retrain the SMT model. The percentage of the corpus is measured in number of running words. In Figure 3, we present results for the three sampling strategies described in section 5. Additionally, we also compare our tec</context>
</contexts>
<marker>Haffari, Roy, Sarkar, 2009</marker>
<rawString>Gholamreza Haffari, Maxim Roy, and Anoop Sarkar. 2009. Active learning for statistical phrase-based machine translation. In Proc. of the North American Chapter of the Association for Computational Linguistics, pages 415–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
<author>Kenneth Ward Church</author>
</authors>
<title>Special issue on new tools for human translators.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<pages>12--1</pages>
<contexts>
<context position="2435" citStr="Isabelle and Church, 1997" startWordPosition="351" endWordPosition="354">e various automatic machine translation methods have been proposed. However, automatic statistical machine translation (SMT) systems are far from generating error-free translations and their outputs usually require human post-editing in order to achieve high-quality translations. One way of taking advantage of SMT systems is to combine them with the knowledge of a human translator in the interactive-predictive machine translation (IMT) framework (Foster et al., 1998; Langlais and Lapalme, 2002; Barrachina et al., 2009), which is a particular case of the computer-assisted translation paradigm (Isabelle and Church, 1997). In the IMT framework, a state-of-the-art SMT model and a human translator collaborate to obtain highquality translations while minimizing required human effort. Unfortunately, the application of either postediting or IMT to data streams with massive data volumes is still too expensive, simply because manual supervision of all instances requires huge amounts of manpower. For such massive data streams the need of employing active learning (AL) is compelling. AL techniques for IMT selectively ask an oracle (e.g. a human translator) to supervise a small portion of the incoming sentences. Sentenc</context>
</contexts>
<marker>Isabelle, Church, 1997</marker>
<rawString>Pierre Isabelle and Kenneth Ward Church. 1997. Special issue on new tools for human translators. Machine Translation, 12(1-2):1–2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Manual and automatic evaluation of machine translation between european languages.</title>
<date>2006</date>
<booktitle>In Proc. of the Workshop on Statistical Machine Translation,</booktitle>
<pages>102--121</pages>
<contexts>
<context position="20940" citStr="Koehn and Monz, 2006" startWordPosition="3497" endWordPosition="3500">eated it as a data stream for AL. To simulate the interaction with the user, we used the reference translations in the data stream corpus as the translation the human user would like to obtain. Since each experiment is carried out under the same conditions, if one sampling strategy outperforms its peers, then we can safely conclude that this is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techn</context>
</contexts>
<marker>Koehn, Monz, 2006</marker>
<rawString>Philipp Koehn and Christof Monz. 2006. Manual and automatic evaluation of machine translation between european languages. In Proc. of the Workshop on Statistical Machine Translation, pages 102–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -</booktitle>
<volume>1</volume>
<pages>48--54</pages>
<contexts>
<context position="7293" citStr="Koehn et al., 2003" startWordPosition="1153" endWordPosition="1156">ng technique described in (Ortiz-Martinez et al., 2010). Finally, we integrate all these elements to define an AL framework for IMT with an objective of obtaining an optimum balance between translation quality and human user effort. 3 Interactive machine translation IMT can be seen as an evolution of the SMT framework. Given a sentence f from a source language to be translated into a sentence e of a target language, the fundamental equation of SMT (Brown et al., 1993) is defined as follows: e� = arg max Pr(e I f) (1) e where Pr(e I f) is usually approximated by a log linear translation model (Koehn et al., 2003). In this case, the decision rule is given by the expression: e� = arg max e � M m=1 amhm(e, f) (2) where each hm(e, f) is a feature function representing a statistical model and am its weight. In the IMT framework, a human translator is introduced in the translation process to collaborate with an SMT model. For a given source sentence, the SMT model fully automatically generates an initial translation. The human user checks this translation, from left to right, correcting the first 246 source (f): Para ver la lista de recursos desired translation (6): To view a listing of resources inter.-0 e</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, pages 48–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>Guy Lapalme</author>
</authors>
<title>Trans Type: development-evaluation cycles to boost translator’s productivity.</title>
<date>2002</date>
<journal>Machine Translation,</journal>
<volume>17</volume>
<pages>98</pages>
<contexts>
<context position="2307" citStr="Langlais and Lapalme, 2002" startWordPosition="331" endWordPosition="335">y expensive given the huge volume of translation required, 1http://www.europarl.europa.eu 2http://project-syndicate.org therefore various automatic machine translation methods have been proposed. However, automatic statistical machine translation (SMT) systems are far from generating error-free translations and their outputs usually require human post-editing in order to achieve high-quality translations. One way of taking advantage of SMT systems is to combine them with the knowledge of a human translator in the interactive-predictive machine translation (IMT) framework (Foster et al., 1998; Langlais and Lapalme, 2002; Barrachina et al., 2009), which is a particular case of the computer-assisted translation paradigm (Isabelle and Church, 1997). In the IMT framework, a state-of-the-art SMT model and a human translator collaborate to obtain highquality translations while minimizing required human effort. Unfortunately, the application of either postediting or IMT to data streams with massive data volumes is still too expensive, simply because manual supervision of all instances requires huge amounts of manpower. For such massive data streams the need of employing active learning (AL) is compelling. AL techni</context>
</contexts>
<marker>Langlais, Lapalme, 2002</marker>
<rawString>Philippe Langlais and Guy Lapalme. 2002. Trans Type: development-evaluation cycles to boost translator’s productivity. Machine Translation, 17:77– 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abby Levenberg</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Stream-based translation models for statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>394--402</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="1625" citStr="Levenberg et al., 2010" startWordPosition="241" endWordPosition="244"> for a given translation quality the use of active learning allows us to greatly reduce the human effort required to translate the sentences in the stream. 1 Introduction Translation needs have greatly increased during the last years due to phenomena such as globalization and technologic development. For example, the European Parliament1 translates its proceedings to 22 languages in a regular basis or Project Syndicate2 that translates editorials into different languages. In these and many other examples, data can be viewed as an incoming unbounded stream since it grows continually with time (Levenberg et al., 2010). Manual translation of such streams of data is extremely expensive given the huge volume of translation required, 1http://www.europarl.europa.eu 2http://project-syndicate.org therefore various automatic machine translation methods have been proposed. However, automatic statistical machine translation (SMT) systems are far from generating error-free translations and their outputs usually require human post-editing in order to achieve high-quality translations. One way of taking advantage of SMT systems is to combine them with the knowledge of a human translator in the interactive-predictive ma</context>
<context position="5051" citStr="Levenberg et al., (2010)" startWordPosition="769" endWordPosition="772">i et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et al., (2010) study how to bound the space when processing (potentially) unbounded streams of parallel data and propose a method to incrementally retrain SMT models. Another method to efficiently retrain a SMT model with new data was presented in (Ortiz-Martinez et al., 2010). In this work, the authors describe an application of the online learning paradigm to the IMT framework. To the best of our knowledge, the only previous work on AL for IMT is (Gonz´alez-Rubio et al., 2011). There, the authors present a naive application of the AL paradigm for IMT that do not take into account the dynamic change in pro</context>
</contexts>
<marker>Levenberg, Callison-Burch, Osborne, 2010</marker>
<rawString>Abby Levenberg, Chris Callison-Burch, and Miles Osborne. 2010. Stream-based translation models for statistical machine translation. In Proc. of the North American Chapter of the Association for Computational Linguistics, pages 394–402, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elliott Macklovitch</author>
</authors>
<title>TransType2: the last word.</title>
<date>2006</date>
<booktitle>In Proc. of the conference on International Language Resources and Evaluation,</booktitle>
<pages>167--17</pages>
<contexts>
<context position="23363" citStr="Macklovitch, 2006" startWordPosition="3903" endWordPosition="3904">he corresponding position of the translation hypothesis. Each character replacement, on the other hand, would correspond to a keystroke of the user. Bearing this in mind, we measure the user effort by means of the keystroke and mouse-action ratio (KSMR) (Barrachina et al., 2009). This measure has been extensively used to report results in the IMT literature. KSMR is calculated as the number of keystrokes plus the number of mouse movements divided by the total number of reference characters. From a user point of view the two types of actions are different and require different types of effort (Macklovitch, 2006). In any case, as an approximation, KSMR assumes that both actions require a similar effort. 7.3 Experimental results In this section, we report results for three different experiments. First, we studied the performance of the sampling strategies when dealing with the sampling bias problem. In the second experiment, we carried out a typical AL experiment measuring the performance of the sampling strategies as a function of the percentage of the corpus used to retrain the SMT model. Finally, we tested our AL implementation for IMT in order to study the tradeoff between required human effort and</context>
</contexts>
<marker>Macklovitch, 2006</marker>
<rawString>Elliott Macklovitch. 2006. TransType2: the last word. In Proc. of the conference on International Language Resources and Evaluation, pages 167–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford Neal</author>
<author>Geoffrey Hinton</author>
</authors>
<title>A view of the EM algorithm that justifies incremental, sparse, and other variants. Learning in graphical models,</title>
<date>1999</date>
<pages>355--368</pages>
<contexts>
<context position="18030" citStr="Neal and Hinton, 1999" startWordPosition="3015" endWordPosition="3018">n IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio of its words classified as correct by the word confidence measure. Therefore, we define the confidencebased informativeness score as: C(e, f) = 1 _ |{ei |Cw(ei,f) &gt; Tw} |(7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair is added to the SMT model. The incremental version of the EM algorithm (Neal and Hinton, 1999) is used to incrementally train the IBM model 1. 6 Retraining of the SMT model To retrain the SMT model, we implement the online learning techniques proposed in (OrtizMart´ınez et al., 2010). In that work, a stateof-the-art log-linear model (Och and Ney, 2002) and a set of techniques to incrementally train this model were defined. The log-linear model is composed of a set of feature functions governing different aspects of the translation process, including a language model, a source sentence–length model, inverse and direct translation models, a target phrase–length model, a source phrase– le</context>
<context position="19537" citStr="Neal and Hinton, 1999" startWordPosition="3266" endWordPosition="3269">ficient statistics is maintained for each feature function. If the estimation of the feature function does not require the use of the well-known expectation–maximization (EM) algorithm (Dempster et al., 1977) (e.g. n-gram language models), then it is generally easy to incrementally extend the model given a new training sample. By contrast, if the EM algorithm is required (e.g. word alignment models), the estimation procedure has to be modified, since the conventional EM algorithm is designed for its use in batch learning scenarios. For such models, the incremental version of the EM algorithm (Neal and Hinton, 1999) is applied. A detailed description of the update algorithm for each of the models in the log-linear combination is presented in (OrtizMartinez et al., 2010). 7 Experiments We carried out experiments to assess the performance of the proposed AL implementation for IMT. In each experiments, we started with an initial SMT model that is incrementally updated 249 corpus use sentences words (Spa/Eng) Europarl train 731K 15M/15M devel. 2K 60K/58K News test 51K 1.5M/1.2M Commentary Table 1: Size of the Spanish–English corpora used in the experiments. K and M stand for thousands and millions of element</context>
</contexts>
<marker>Neal, Hinton, 1999</marker>
<rawString>Radford Neal and Geoffrey Hinton. 1999. A view of the EM algorithm that justifies incremental, sparse, and other variants. Learning in graphical models, pages 355–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent Nepveu</author>
<author>Guy Lapalme</author>
<author>Philippe Langlais</author>
<author>George Foster</author>
</authors>
<title>Adaptive language and translation models for interactive machine translation.</title>
<date>2004</date>
<booktitle>In Proc, of EMNLP,</booktitle>
<pages>190--197</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="4878" citStr="Nepveu et al. (2004)" startWordPosition="743" endWordPosition="746">chnique to efficiently train the base SMT models as new data is available. 2 Related work A body of work has recently been proposed to apply AL techniques to SMT (Haffari et al., 2009; Ambati et al., 2010; Bloodgood and CallisonBurch, 2010). The aim of these works is to build one single optimal SMT model from manually translated data extracted from static datasets. None of them fit in the setting of data streams. Some of the above described challenges of AL from unbounded streams have been previously addressed in the MT literature. In order to deal with the evolutionary nature of the problem, Nepveu et al. (2004) propose an IMT system with dynamic adaptation via cache-based model extensions for language and translation models. Pursuing the same goal for SMT, Levenberg et al., (2010) study how to bound the space when processing (potentially) unbounded streams of parallel data and propose a method to incrementally retrain SMT models. Another method to efficiently retrain a SMT model with new data was presented in (Ortiz-Martinez et al., 2010). In this work, the authors describe an application of the online learning paradigm to the IMT framework. To the best of our knowledge, the only previous work on AL</context>
</contexts>
<marker>Nepveu, Lapalme, Langlais, Foster, 2004</marker>
<rawString>Laurent Nepveu, Guy Lapalme, Philippe Langlais, and George Foster. 2004. Adaptive language and translation models for interactive machine translation. In Proc, of EMNLP, pages 190–197, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the Association for Computational Linguistics,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="18290" citStr="Och and Ney, 2002" startWordPosition="3061" endWordPosition="3064">onfidencebased informativeness score as: C(e, f) = 1 _ |{ei |Cw(ei,f) &gt; Tw} |(7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair is added to the SMT model. The incremental version of the EM algorithm (Neal and Hinton, 1999) is used to incrementally train the IBM model 1. 6 Retraining of the SMT model To retrain the SMT model, we implement the online learning techniques proposed in (OrtizMart´ınez et al., 2010). In that work, a stateof-the-art log-linear model (Och and Ney, 2002) and a set of techniques to incrementally train this model were defined. The log-linear model is composed of a set of feature functions governing different aspects of the translation process, including a language model, a source sentence–length model, inverse and direct translation models, a target phrase–length model, a source phrase– length model and a distortion model. The incremental learning algorithm allows us to process each new training sample in constant time (i.e. the computational complexity of training a new sample does not depend on the number of previously seen training samples).</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of the Association for Computational Linguistics, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="21150" citStr="Och, 2003" startWordPosition="3534" endWordPosition="3535">rried out under the same conditions, if one sampling strategy outperforms its peers, then we can safely conclude that this is because the sentences selected to be translated are more informative. 7.1 Training corpus and data stream The training data comes from the Europarl corpus as distributed for the shared task in the NAACL 2006 workshop on statistical machine translation (Koehn and Monz, 2006). We used this data to estimate the initial log-linear model used by our IMT system (see Section 6). The weights of the different feature functions were tuned by means of minimum error–rate training (Och, 2003) executed on the Europarl development corpus. Once the SMT model was trained, we use the News Commentary corpus (Callison-Burch et al., 2007) to simulate the data stream. The size of these corpora is shown in Table 1. The reasons to choose the News Commentary corpus to carry out our experiments are threefold: first, its size is large enough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain:</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz-Martfnez</author>
<author>Ismael Garcfa-Varea</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online learning for interactive statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>546--554</pages>
<marker>Ortiz-Martfnez, Garcfa-Varea, Casacuberta, 2010</marker>
<rawString>Daniel Ortiz-Martfnez, Ismael Garcfa-Varea, and Francisco Casacuberta. 2010. Online learning for interactive statistical machine translation. In Proc. of the North American Chapter of the Association for Computational Linguistics, pages 546–554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="22110" citStr="Papineni et al., 2002" startWordPosition="3693" endWordPosition="3696">ough to simulate a data stream and test our AL techniques in the long term; second, it is out-of-domain data which allows us to simulate a real-world situation that may occur in a translation company, and, finally, it consists in editorials from eclectic domain: general politics, economics and science, which effectively represents the variations in the sentence distributions of the simulated data stream. 7.2 Assessment criteria We want to measure both the quality of the generated translations and the human effort required to obtain them. We measure translation quality with the wellknown BLEU (Papineni et al., 2002) score. To estimate human user effort, we simulate the actions taken by a human user in its interaction with the IMT system. The first translation hypothesis for each given source sentence is compared with a single reference translation and the longest common character prefix (LCP) is obtained. The first non-matching character is replaced by the corresponding reference character and then a new translation hypothesis is produced (see Figure 1). This process is iterated until a full match with the reference is obtained. Each computation of the LCP would correspond to the user looking for the nex</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Application of word-level confidence measures in interactive statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. of the European Association for Machine Translation conference,</booktitle>
<pages>262--270</pages>
<contexts>
<context position="17348" citStr="Ueffing and Ney, 2005" startWordPosition="2894" endWordPosition="2897">translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 ... ei ... eI generated from the source sentence f = f1 ... fj ... fJ is computed as described in (Ueffing and Ney, 2005): Cw(ei, f) = max p(ei|fj) (6) 0&lt;j&lt; |f | where p(ei|fj) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio of its words classified as correct by the word confidence measure. Therefore, we define the confidencebased informativeness score as: C(e, f) = 1 _ |{ei |Cw(ei,f) &gt; Tw} |(7) |e| Finally, this sampling strategy works by selecting a given percentage of the highest scoring sentences. We dynamically update the confidence sampler each time a new sentence pair is added to </context>
</contexts>
<marker>Ueffing, Ney, 2005</marker>
<rawString>Nicola Ueffing and Hermann Ney. 2005. Application of word-level confidence measures in interactive statistical machine translation. In Proc. of the European Association for Machine Translation conference, pages 262–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Wordlevel confidence estimation for machine translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<pages>33--9</pages>
<contexts>
<context position="16993" citStr="Ueffing and Ney, 2007" startWordPosition="2828" endWordPosition="2832">data. 5.3 Dynamic confidence sampling Another technique is to consider that the most informative sentence is the one the current SMT model translates worst. The intuition behind this approach is that an SMT model can not generate good translations unless it has enough information to translate the sentence. The usual approach to compute the quality of a translation hypothesis is to compare it to a reference translation, but, in this case, it is not a valid option since reference translations are not available. Hence, we use confidence estimation (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007) to estimate the probability of correctness of the translations. Specifically, we estimate the quality of a translation from the confidence scores of their individual words. The confidence score of a word ei of the translation e = e1 ... ei ... eI generated from the source sentence f = f1 ... fj ... fJ is computed as described in (Ueffing and Ney, 2005): Cw(ei, f) = max p(ei|fj) (6) 0&lt;j&lt; |f | where p(ei|fj) is an IBM model 1 (Brown et al., 1993) bilingual lexicon probability and f0 is the empty source word. The confidence score for the full translation e is computed as the ratio of its words c</context>
</contexts>
<marker>Ueffing, Ney, 2007</marker>
<rawString>Nicola Ueffing and Hermann Ney. 2007. Wordlevel confidence estimation for machine translation. Computational Linguistics, 33:9–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xingquan Zhu</author>
<author>Peng Zhang</author>
<author>Xiaodong Lin</author>
<author>Yong Shi</author>
</authors>
<title>Active learning from data streams.</title>
<date>2007</date>
<booktitle>In Proc. of the 7th IEEE International Conference on Data Mining,</booktitle>
<pages>757--762</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="14260" citStr="Zhu et al., 2007" startWordPosition="2335" endWordPosition="2338">interactively translated. Although simple, it turns out that random sampling perform surprisingly well in practice. The success of random sampling stem from the fact that in data stream environments the translation probability distributions may vary significantly through time. While general AL algorithms ask the user to translate informative sentences, they may significantly change probability distributions by favoring certain translations, consequently, the previously human-translated sentences may no longer reveal the genuine translation distribution in the current point of the data stream (Zhu et al., 2007). This problem is less severe for static data where the candidate pool is fixed and AL algorithms are able to survey all instances. Random sampling avoids this problem by randomly selecting sentences for human supervision. As a result, it always selects those sentences with the most similar distribution to the current sentence distribution in the data stream. 5.2 n-gram coverage sampling One technique to measure the informativeness of a sentence is to directly measure the amount of new information that it will add to the SMT model. This sampling strategy considers that sentences with rare n-gr</context>
</contexts>
<marker>Zhu, Zhang, Lin, Shi, 2007</marker>
<rawString>Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong Shi. 2007. Active learning from data streams. In Proc. of the 7th IEEE International Conference on Data Mining, pages 757–762. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xingquan Zhu</author>
<author>Peng Zhang</author>
<author>Xiaodong Lin</author>
<author>Yong Shi</author>
</authors>
<title>Active learning from stream data using optimal weight classifier ensemble.</title>
<date>2010</date>
<journal>Transactions on Systems, Man and Cybernetics Part B,</journal>
<volume>40</volume>
<pages>1621</pages>
<contexts>
<context position="3229" citStr="Zhu et al., 2010" startWordPosition="476" endWordPosition="479"> the application of either postediting or IMT to data streams with massive data volumes is still too expensive, simply because manual supervision of all instances requires huge amounts of manpower. For such massive data streams the need of employing active learning (AL) is compelling. AL techniques for IMT selectively ask an oracle (e.g. a human translator) to supervise a small portion of the incoming sentences. Sentences are selected so that SMT models estimated from them translate new sentences as accurately as possible. There are three challenges when applying AL to unbounded data streams (Zhu et al., 2010). These challenges can be instantiated to IMT as follows: 1. The pool of candidate sentences is dynamically changing, whereas existing AL algorithms are dealing with static datasets only. 245 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 245–254, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics 2. Concepts such as optimum translation and translation probability distribution are continually evolving whereas existing AL algorithms only deal with constant concepts. 3. Data volume is unbounded</context>
</contexts>
<marker>Zhu, Zhang, Lin, Shi, 2010</marker>
<rawString>Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong Shi. 2010. Active learning from stream data using optimal weight classifier ensemble. Transactions on Systems, Man and Cybernetics Part B, 40:1607– 1621, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>