<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.069505">
<title confidence="0.92276">
Multilingual Video and Audio News Alerting
</title>
<author confidence="0.675461">
David D. Palmer, Patrick Bray, Marc
Reichman, Katherine Rhodes, Noah
White
</author>
<affiliation confidence="0.681338">
Virage Advanced Technology Group
</affiliation>
<address confidence="0.736364666666667">
300 Unicorn Park
Woburn, MA 01801
{dpalmer, pbray, mreichman,
</address>
<email confidence="0.962411">
krhodes, nwhite}@virage.com
</email>
<author confidence="0.937993">
Andrew Merlino, Francis Kubala
</author>
<affiliation confidence="0.607431">
BBN Technologies
</affiliation>
<address confidence="0.953698">
50 Moulton St.
Cambridge, MA 02138
</address>
<email confidence="0.995789">
{amerlino, fkubala}@bbn.com
</email>
<sectionHeader confidence="0.991353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998939857142857">
This paper describes a fully-automated real-
time broadcast news video and audio process-
ing system. The system combines speech rec-
ognition, machine translation, and cross-
lingual information retrieval components to
enable real-time alerting from live English
and Arabic news sources.
</bodyText>
<sectionHeader confidence="0.925167" genericHeader="categories and subject descriptors">
1 Real-time Video Alerting
</sectionHeader>
<bodyText confidence="0.9998025">
This paper describes the Enhanced Video Text and Au-
dio Processing (eViTAP) system, which provides fully-
automated real-time broadcast news video and audio
processing. The system combines state-of-the-art
automatic speech recognition and machine translation
components with cross-lingual information retrieval in
order to enable searching of multilingual video news
sources by a monolingual speaker. In addition to full
search capabilities, the system also enables real-time
alerting, such that a user can be notified as soon as a
word, phrase, or topic of interest appears in an English
or Arabic news broadcast.
The key component of the news processing is the
Virage VideoLogger video indexer software package
(Virage 2003). The VideoLogger processes an incom-
ing live satellite feed, encodes the video as a digital file,
and manages the video and audio processing compo-
nents. The individual components integrated into the
VideoLogger platform currently include the audio proc-
essing and machine translation systems described in
Section 2, as well as face ID, broadcaster logo ID, and
scene change analysis.
The video and audio processing components pro-
duce textual metadata that is time-stamped to enable
synchronization with the encoded video file. All data is
indexed and stored for retrieval by a cross-lingual in-
formation retrieval engine. Figure 1 shows the EViTAP
cross-lingual search and alerting interface, with real data
from the system. The list of relevant video clips match-
ing an alerting profile or a user search is shown on the
left, with broadcast source and time, most-frequent
named entities, and a relevancy score. Note that the
English query “bin laden” resulted in the display of
relevant stories in both English and Arabic. The center
of the screen contains the video playback window, with
clip navigation and keyframe storyboard. The right of
the interface contains the transcripts from the ASR and
MT engines; video playback is synchronized with the
transcripts such that words are highlighted as they are
spoken in the video.
</bodyText>
<sectionHeader confidence="0.949712" genericHeader="general terms">
2 Real-time Spoken Language Processing
</sectionHeader>
<bodyText confidence="0.999536818181818">
The real-time audio processing in the eViTAP system is
performed by the BBN AudioIndexer system, described
in detail in (Makhoul et al. 2000). The AudioIndexer
system provides a wide range of real-time audio proc-
essing components, including automatic speech recogni-
tion, speaker segmentation and identification, topic
classification, and named entity detection. All audio
processing is carried out on a high-end PC (dual 2.6
GHz Xeon CPU, 2 GB RAM). The real-time speech
recognition system produces a word error rate of
roughly 20-30% for English and Arabic news sources.
</bodyText>
<figureCaption confidence="0.66869">
Figure 1: Multilingual alerting and search interface, with alert list, synchronized video playback, Arabic speech
recognition output, Arabic-to-English machine translation output.
</figureCaption>
<bodyText confidence="0.998304125">
The Arabic words produced by the speech
recognition system, including all ASR errors, are
processed by an Arabic-to-English machine translation
system that also operates in real time (on a separate
high-end PC). The eViTAP system currently processes
Arabic sources using statistical machine translation
systems from IBM (Al-Onaizan 2003) and Language
Weaver (Benjamin et al. 2003).
</bodyText>
<sectionHeader confidence="0.996918" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.879457">
This work was partially supported by the Defense
Advanced Research Projects Agency and monitored by
SPAWAR under contract NBCHD030007.
</bodyText>
<sectionHeader confidence="0.998186" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987672">
Y. Al-Onaizan, R. Florian, M. Franz, H. Hassan, Y. S. Lee, S.
McCarley, K. Papineni, S. Roukos, J. Sorensen, C. Till-
mann, T. Ward, F. Xia, “TIPS: A Translingual Information
Processing System,” In Proceedings of HLT-NAACL 2003
Demonstrations, Edmonton, 2003.
B. Benjamin, L. Gerber, K. Knight, D. Marcu, “Language
Weaver: The Next Generation of Machine Translation,” In
Proceedings of MT Summit IX, New Orleans, Louisiana,
September 23-27, 2003.
J. Makhoul, F. Kubala, T. Leek, D. Liu, L. Nguyen, R.
Schwartz, and A. Srivastava, “Speech and Language Tech-
nologies for Audio Indexing and retrieval,” In Proceedings
of the IEEE, vol. 88, no. 8, pp. 1338-1353, 2000.
Virage VideoLogger Factsheet (2003)
http://www.virage.com/files/products/VL_DS_lores.pdf
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.030552">
<title confidence="0.999956">Multilingual Video and Audio News Alerting</title>
<author confidence="0.998892">David D Palmer</author>
<author confidence="0.998892">Patrick Bray</author>
<author confidence="0.998892">Marc</author>
<affiliation confidence="0.863284">Reichman, Katherine Rhodes, Noah White Virage Advanced Technology</affiliation>
<address confidence="0.9966915">300 Unicorn Park Woburn, MA 01801</address>
<email confidence="0.976352">dpalmer@virage.com</email>
<email confidence="0.976352">pbray@virage.com</email>
<email confidence="0.976352">mreichman@virage.com</email>
<email confidence="0.976352">krhodes@virage.com</email>
<email confidence="0.976352">nwhite@virage.com</email>
<author confidence="0.999854">Andrew Merlino</author>
<author confidence="0.999854">Francis Kubala</author>
<affiliation confidence="0.942636">BBN</affiliation>
<address confidence="0.978746">50 Moulton Cambridge, MA</address>
<email confidence="0.998918">amerlino@bbn.com</email>
<email confidence="0.998918">fkubala@bbn.com</email>
<abstract confidence="0.999448579710145">This paper describes a fully-automated realtime broadcast news video and audio processing system. The system combines speech recognition, machine translation, and crosslingual information retrieval components to enable real-time alerting from live English and Arabic news sources. 1 Real-time Video Alerting This paper describes the Enhanced Video Text and Audio Processing (eViTAP) system, which provides fullyautomated real-time broadcast news video and audio processing. The system combines automatic speech recognition and machine translation components with cross-lingual information retrieval in order to enable searching of multilingual video news sources by a monolingual speaker. In addition to full search capabilities, the system also enables real-time alerting, such that a user can be notified as soon as a word, phrase, or topic of interest appears in an English or Arabic news broadcast. The key component of the news processing is the Virage VideoLogger video indexer software package (Virage 2003). The VideoLogger processes an incoming live satellite feed, encodes the video as a digital file, and manages the video and audio processing components. The individual components integrated into the VideoLogger platform currently include the audio processing and machine translation systems described in Section 2, as well as face ID, broadcaster logo ID, and scene change analysis. The video and audio processing components produce textual metadata that is time-stamped to enable synchronization with the encoded video file. All data is indexed and stored for retrieval by a cross-lingual information retrieval engine. Figure 1 shows the EViTAP cross-lingual search and alerting interface, with real data from the system. The list of relevant video clips matching an alerting profile or a user search is shown on the left, with broadcast source and time, most-frequent named entities, and a relevancy score. Note that the English query “bin laden” resulted in the display of relevant stories in both English and Arabic. The center of the screen contains the video playback window, with clip navigation and keyframe storyboard. The right of the interface contains the transcripts from the ASR and MT engines; video playback is synchronized with the transcripts such that words are highlighted as they are spoken in the video. 2 Real-time Spoken Language Processing The real-time audio processing in the eViTAP system is performed by the BBN AudioIndexer system, described detail in (Makhoul al. The AudioIndexer system provides a wide range of real-time audio processing components, including automatic speech recognition, speaker segmentation and identification, topic classification, and named entity detection. All audio processing is carried out on a high-end PC (dual 2.6 GHz Xeon CPU, 2 GB RAM). The real-time speech recognition system produces a word error rate of roughly 20-30% for English and Arabic news sources. Figure 1: Multilingual alerting and search interface, with alert list, synchronized video playback, Arabic speech recognition output, Arabic-to-English machine translation output. The Arabic words produced by the speech recognition system, including all ASR errors, are processed by an Arabic-to-English machine translation system that also operates in real time (on a separate high-end PC). The eViTAP system currently processes Arabic sources using statistical machine translation</abstract>
<note confidence="0.819310125">systems from IBM (Al-Onaizan 2003) and Language (Benjamin al. Acknowledgements This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract NBCHD030007. References Y. Al-Onaizan, R. Florian, M. Franz, H. Hassan, Y. S. Lee, S.</note>
<author confidence="0.747919">K Papineni McCarley</author>
<author confidence="0.747919">S Roukos</author>
<author confidence="0.747919">J Sorensen</author>
<author confidence="0.747919">C Till-</author>
<keyword confidence="0.385622">mann, T. Ward, F. Xia, “TIPS: A Translingual Information</keyword>
<note confidence="0.872272272727273">System,” In of HLT-NAACL 2003 Edmonton, 2003. B. Benjamin, L. Gerber, K. Knight, D. Marcu, “Language Weaver: The Next Generation of Machine Translation,” In of MT Summit New Orleans, Louisiana, September 23-27, 2003. J. Makhoul, F. Kubala, T. Leek, D. Liu, L. Nguyen, R. Schwartz, and A. Srivastava, “Speech and Language Techfor Audio Indexing and retrieval,” In the vol. 88, no. 8, pp. 1338-1353, 2000. Virage VideoLogger Factsheet (2003)</note>
<web confidence="0.869392">http://www.virage.com/files/products/VL_DS_lores.pdf</web>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>R Florian</author>
<author>M Franz</author>
<author>H Hassan</author>
<author>Y S Lee</author>
<author>S McCarley</author>
<author>K Papineni</author>
<author>S Roukos</author>
<author>J Sorensen</author>
<author>C Tillmann</author>
<author>T Ward</author>
<author>F Xia</author>
</authors>
<title>TIPS: A Translingual Information Processing System,”</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<location>Demonstrations, Edmonton,</location>
<marker>Al-Onaizan, Florian, Franz, Hassan, Lee, McCarley, Papineni, Roukos, Sorensen, Tillmann, Ward, Xia, 2003</marker>
<rawString>Y. Al-Onaizan, R. Florian, M. Franz, H. Hassan, Y. S. Lee, S. McCarley, K. Papineni, S. Roukos, J. Sorensen, C. Tillmann, T. Ward, F. Xia, “TIPS: A Translingual Information Processing System,” In Proceedings of HLT-NAACL 2003 Demonstrations, Edmonton, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Benjamin</author>
<author>L Gerber</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Language Weaver: The Next Generation of Machine Translation,”</title>
<date>2003</date>
<booktitle>In Proceedings of MT Summit IX,</booktitle>
<location>New Orleans, Louisiana,</location>
<marker>Benjamin, Gerber, Knight, Marcu, 2003</marker>
<rawString>B. Benjamin, L. Gerber, K. Knight, D. Marcu, “Language Weaver: The Next Generation of Machine Translation,” In Proceedings of MT Summit IX, New Orleans, Louisiana, September 23-27, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Makhoul</author>
<author>F Kubala</author>
<author>T Leek</author>
<author>D Liu</author>
<author>L Nguyen</author>
<author>R Schwartz</author>
<author>A Srivastava</author>
</authors>
<title>Speech and Language Technologies for Audio Indexing and retrieval,”</title>
<date>2000</date>
<booktitle>In Proceedings of the IEEE,</booktitle>
<volume>88</volume>
<pages>1338--1353</pages>
<contexts>
<context position="2898" citStr="Makhoul et al. 2000" startWordPosition="433" endWordPosition="436">and a relevancy score. Note that the English query “bin laden” resulted in the display of relevant stories in both English and Arabic. The center of the screen contains the video playback window, with clip navigation and keyframe storyboard. The right of the interface contains the transcripts from the ASR and MT engines; video playback is synchronized with the transcripts such that words are highlighted as they are spoken in the video. 2 Real-time Spoken Language Processing The real-time audio processing in the eViTAP system is performed by the BBN AudioIndexer system, described in detail in (Makhoul et al. 2000). The AudioIndexer system provides a wide range of real-time audio processing components, including automatic speech recognition, speaker segmentation and identification, topic classification, and named entity detection. All audio processing is carried out on a high-end PC (dual 2.6 GHz Xeon CPU, 2 GB RAM). The real-time speech recognition system produces a word error rate of roughly 20-30% for English and Arabic news sources. Figure 1: Multilingual alerting and search interface, with alert list, synchronized video playback, Arabic speech recognition output, Arabic-to-English machine translati</context>
</contexts>
<marker>Makhoul, Kubala, Leek, Liu, Nguyen, Schwartz, Srivastava, 2000</marker>
<rawString>J. Makhoul, F. Kubala, T. Leek, D. Liu, L. Nguyen, R. Schwartz, and A. Srivastava, “Speech and Language Technologies for Audio Indexing and retrieval,” In Proceedings of the IEEE, vol. 88, no. 8, pp. 1338-1353, 2000.</rawString>
</citation>
<citation valid="false">
<date>2003</date>
<institution>Virage VideoLogger Factsheet</institution>
<marker>2003</marker>
<rawString>Virage VideoLogger Factsheet (2003)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>