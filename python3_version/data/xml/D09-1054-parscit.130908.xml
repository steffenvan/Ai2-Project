<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99487">
A Structural Support Vector Method for Extracting Contexts and
Answers of Questions from Online Forums
</title>
<author confidence="0.998462">
Wen-Yun Yang t* Yunbo Cao tt Chin-Yew Lin t
</author>
<affiliation confidence="0.988971666666667">
t Department of Computer Science and Engineering
Shanghai Jiao Tong University, Shanghai, China
t Microsoft Research Asia, Beijing, China
</affiliation>
<email confidence="0.983617">
wenyun.yang@gmail.com {yunbo.cao; cyl}@microsoft.com
</email>
<sectionHeader confidence="0.984298" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989">
This paper addresses the issue of extract-
ing contexts and answers of questions
from post discussion of online forums.
We propose a novel and unified model by
customizing the structural Support Vector
Machine method. Our customization has
several attractive properties: (1) it gives a
comprehensive graphical representation of
thread discussion. (2) It designs special
inference algorithms instead of general-
purpose ones. (3) It can be readily ex-
tended to different task preferences by
varying loss functions. Experimental re-
sults on a real data set show that our meth-
ods are both promising and flexible.
</bodyText>
<sectionHeader confidence="0.992535" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999357421052631">
Recently, extracting questions, contexts and an-
swers from post discussions of online forums in-
curs increasing academic attention (Cong et al.,
2008; Ding et al., 2008). The extracted knowl-
edge can be used either to enrich the knowledge
base of community question answering (QA) ser-
vices such as Yahoo! Answers or to augment the
knowledge base of chatbot (Huang et al., 2007).
Figure 1 gives an example of a forum thread
with questions, contexts and answers annotated.
This thread contains three posts and ten sentences,
among which three questions are discussed. The
three questions are proposed in three sentences,
S3, S5 and S6. The context sentences S1 and
S2 provide contextual information for question
sentence S3. Similarly, the context sentence S4
provides contextual information for question sen-
tence S5 and S6. There are three question-context-
answer triples in this example, (S3) − (S1, S2) −
</bodyText>
<note confidence="0.582035333333333">
(S8, S9), (S5) − (S4) − (S10) and (S6) − (S4) −
* This work was done while the first author visited Mi-
crosoft Research Asia.
</note>
<bodyText confidence="0.9247946">
Post1: &lt;context id=1&gt; S1: Hi I am looking for
a pet friendly hotel in Hong Kong because all of
my family is going therefor vacation. S2: my fam-
ily has 2 sons and a dog. &lt;/context&gt; &lt;question
id=1&gt; S3: Is there any recommended hotel near
Sheung Wan or Tsing Sha Tsui? &lt;/question&gt;
&lt;context id=2, 3&gt; S4: We also plan to go shopping
in Causeway Bay. &lt;/context&gt; &lt;question id=2&gt;
S5: What’s the traffic situation around those com-
mercial areas? &lt;/question&gt; &lt;question id=3&gt; S6:
Is it necessary to take a taxi? &lt;/question&gt; S7: Any
information would be appreciated.
Post2: &lt;answer id=1&gt; S8: The Comfort Lodge
near Kowloon Park allows pet as I know, and usu-
ally fits well within normal budgets. S9: It is also
conveniently located, nearby the Kowloon railway
station and subway. &lt;/answer&gt;
Post3: &lt;answer id=2, 3&gt; S10: It’s very crowd in
those areas, so I recommend MTR in Causeway Bay
because it is cheap to take you around. &lt;/answer&gt;
</bodyText>
<figureCaption confidence="0.7261335">
Figure 1: An example thread with three posts and
ten sentences
</figureCaption>
<bodyText confidence="0.998536058823529">
(S10). As shown in the example, a forum question
usually requires contextual information to com-
plement its expression. For example, the ques-
tion sentence S3 would be of incomplete meaning
without the contexts S1 and S2, since the impor-
tant keyword pet friendly would be lost.
The problem of extracting questions, contexts,
and answers can be solved in two steps: (1) iden-
tify questions and then (2) extract contexts and an-
swers for them. Since identifying questions from
forum discussions is already well solved in (Cong
et al., 2008), in this paper, we are focused on step
(2) while assuming questions already identified.
Previously, Ding et al. (2008) employ general-
purpose graphical models without any customiza-
tions to the specific extraction problem (step 2).
In this paper, we improve the existing models in
</bodyText>
<note confidence="0.833381666666667">
514
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 514–523,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999717640000001">
three aspects: graphical representation, inference
algorithm and loss function.
Graphical representation. We propose a more
comprehensive and unified graphical representa-
tion to model the thread for relational learning.
Our graphical representation has two advantages
over previous work (Ding et al., 2008): unifying
sentence relations and incorporating question in-
teractions.
Three types of relation should be considered for
context and answer extraction: (a) relations be-
tween successive sentences (e.g., context sentence
S2 occurs immediately before question sentence
S3); (b) relations between context sentences and
answer sentences (e.g., context S4 presents the
phrase Causeway Bay linking to answer which is
absent from question S6); and (c) relations be-
tween multiple labels for one sentence (e.g., one
question sentence is unlikely to be the answer to
another question although one sentence can serve
as contexts for more than one questions). Our pro-
posed graphical representation improves the mod-
eling of the three types of sentence relation (Sec-
tion 2.2).
Certain interactions exist among questions. For
example, question sentences S5 and S6 interact by
sharing context sentence S4. Our proposed graphi-
cal representation can naturally model the interac-
tions. Previous work (Ding et al., 2008) performs
the extraction of contexts and answers in multiple
passes of the thread (with each pass corresponding
to one question), which cannot address the interac-
tions well. In comparison, our model performs the
extraction in one pass of the thread.
Inference algorithm. Inference is usually a
time-consuming process for structured prediction.
We design special inference algorithms, instead of
general-purpose inference algorithms used in pre-
vious works (Cong et al., 2008; Ding et al., 2008),
by taking advantage of special properties of our
task. Specifically, we utilize two special properties
of thread structure to reduce the inference (time)
cost. First, context sentences and question sen-
tences usually occur in the same post while answer
sentences can only occur in the following posts.
With this properties, we can greatly reduce context
(or answer) candidate sets of a question, which
results in a significant decrease in inference cost
(Section 3). Second, context candidate set is usu-
ally much smaller than the number of sentences
in a thread. This property enables our proposal to
have an exact and efficient inference (Section 4.1).
Moreover, an approximate inference algorithm is
also given (Section 4.2).
Loss function. In practice, different applica-
tion settings usually imply different requirements
for system performance. For example, we expect
a higher recall for the purpose of archiving ques-
tions but a higher precision for the purpose of re-
trieving questions. A flexible framework should
be able to cope with various requirements. We
employ structural Support Vector Machine (SVM)
model that could naturally incorporate different
loss functions (Section 5).
We use a real data set to evaluate our approach
to extracting contexts and answers of questions.
The experimental results show both the effective-
ness and the flexibility of our approach.
In the next section, we formalize the problem
of context and answer extraction and introduce the
structural model. In Sections 3, 4 and 5 we give
the details of customizing structural model for our
task. In Section 6, we evaluate our methods. In
Section 7, we discuss the related work. Finally,
we conclude this paper in Section 8.
</bodyText>
<sectionHeader confidence="0.864588" genericHeader="introduction">
2 Problem Statement
</sectionHeader>
<bodyText confidence="0.9999835">
We first introduce our notations in Section 2.1 and
then in Section 2.2 introduce how we model the
problem of extracting contexts and answers for
questions with a novel form of graphical represen-
tation. In Section 2.3 we introduce the structured
model based on the new representation.
</bodyText>
<subsectionHeader confidence="0.956445">
2.1 Notations
</subsectionHeader>
<bodyText confidence="0.999958294117647">
Assuming that a given thread contains p posts
{p1, ... , pp}, which are authored by a set of
users {u1, ... , up}. The p posts can be further
segmented into n sentences x = {x1, ... , xn}.
Among the n sentences, m question sentences q =
{xq�, ... , xq„} have been identified. Our task is
to identify the context sentences and the answer
sentences for those m question sentences. More
formally, we use four types of label {C, A, Q, P}
to stand for context, answer, question and plain la-
bels. Then, our task is to predict an m × n label
matrix y = (yij)1&lt;i&lt;m,1&lt;j&lt;n, except m elements
{y1,qj, ... , ym,q„} which correspond to (known)
question labels. The element yij in label matrix y
represents the role that the jth sentence plays for
the ith question. We denote the ith row and jth
column of the label matrix y by yi. and y.j.
</bodyText>
<figure confidence="0.7634695">
515
(d) Label group model
</figure>
<figureCaption confidence="0.999031">
Figure 2: Structured models
</figureCaption>
<equation confidence="0.997961611111111">
{C, P}
Y1 Y2 Y3 Y4 Y5 Y6 Y7
{C, P } {C, P } {Q} {P } {A, P } {A, P }
Y1 Y2 Y3 Y4 Y5 Y6 Y7
{C, P} {C, P} {C, P} {Q} {P} {A, P} {A, P}
X1 X2 X3 X4 X5 X6 X7
X1 X2 X3 X4 X5 X6 X7
(a) Skip-chain model
ym1 ym2 ym3 ym4 ymn
y11 y12 y13 y14 y1n
y21 y22 y23 y24 y2n
(c) 2D model
(b) Complete skip-chain model
y11 y12 y13 y14 y1n
y21 y22 y23
y24
y2n
ym1 ym2 ym3 ym4 ymn
</equation>
<subsectionHeader confidence="0.99683">
2.2 Graphical Representation
</subsectionHeader>
<bodyText confidence="0.997654176470588">
Recently, Ding et al. (2008) use skip-chain and
2D Conditional Random Fields (CRFs) (Lafferty
et al., 2001) to perform the relational learning for
context and answer extraction. The skip-chain
CRFs (Sutton and McCallum, 2004; Galley, 2006)
model the long distance dependency between con-
text and answer sentences and the 2D CRFs (Zhu
et al., 2005) model the dependency between con-
tiguous questions. The graphical representation
of those two models are shown in Figures 2(a)
and 2(c), respectively. Those two CRFs are both
extensions of the linear chain CRFs for the sake
of powerful relational learning. However, di-
rectly using the skip-chain and 2D CRFs with-
out any customization has obvious disadvantages:
(a) the skip-chain model does not model the de-
pendency between answer sentence and multiple
context sentences; and (b) the 2D model does not
model the dependency between non-contiguous
questions.
To better model the problem of extracting con-
texts and answers of questions, we propose two
more comprehensive models, complete skip-chain
model and label group model to improve the ca-
pability of the two previous models. These two
models are shown in Figures 2(b) and 2(d).
In Figures 2(a) and 2(b), each label node is an-
notated with its allowed labels and the labels C, A,
Q and P stand for context, answer, question and
plain sentence labels, respectively. Note that the
complete skip-chain model completely links each
two context and answer candidates and the label
group model combines the labels of one sentence
into one label group.
</bodyText>
<subsectionHeader confidence="0.985564">
2.3 Structured Model
</subsectionHeader>
<bodyText confidence="0.999964">
Following the standard machine learning setup,
we denote the input and output spaces by X and
Y, then formulate our task as learning a hypoth-
esis function h : X —* Y to predict a y when
given x. In this setup, x represents a thread of n
sentences and m identified questions. y represents
the m x n label matrix to be predicted.
Given a set of training examples, S =
{(x(i), y(i)) E X x Y : i = 1, ... , N}, we
restrict ourselves to the supervised learning sce-
nario. We focus on hypothesis functions that
take the form h(x; w) = arg maxYEY F(x, y; w)
with discriminant function F : X x Y—* R
where F(x, y; w) = wTjp(x, y). As will be
introduced in Section 4, we employ structural
SVMs (Joachims et al., 2009) to find the optimal
parameters w. The structural SVMs have sev-
eral competitive properties as CRFs. First, it fol-
lows from the maximum margin strategy, which
has been shown with competitive or even better
</bodyText>
<page confidence="0.608574">
516
</page>
<bodyText confidence="0.9999328">
performance (Tsochantaridis et al., 2005; Nguyen
and Guo, 2007). Second, it allows flexible choices
of loss functions to users. Moreover, in general,
it has theoretically proved convergence in polyno-
mial time (Joachims et al., 2009).
To use structural SVMs in relational learning,
one needs to customize three steps according to
specific tasks. The three steps are (a) definition of
joint feature mapping for encoding relations, (b)
algorithm of finding the most violated constraint
(inference) for efficient trainings and (c) definition
of loss function for flexible uses.
In the following Sections 3, 4 and 5, we describe
the customizations of the three steps for our con-
text and answer extraction task, respectively.
</bodyText>
<sectionHeader confidence="0.963549" genericHeader="method">
3 Encoding Relations
</sectionHeader>
<bodyText confidence="0.999967">
We use a joint feature mapping to model the rela-
tions between sentences in a thread. For context
and answer extraction, the joint feature mapping
can be defined as follows,
</bodyText>
<equation confidence="0.99112375">
2 3
X&apos;n(x, y)
IF(x, y) = 4&apos;Ph(x, y) 5 ,
IFv(x, y)
</equation>
<bodyText confidence="0.999509636363637">
where the sub-mappings IFn(x, y), &apos;Ph(x, y), and
IFv(x, y) encode three types of feature mappings,
node features, edge features and label group fea-
tures. The node features provide the basic infor-
mation for the output labels. The edge features
consist of the sequential edge features and skip-
chain edge features for successive label dependen-
cies. The label group features encode the relations
within each label group.
Before giving the detail definitions of the sub-
mappings, we first introduce the context and an-
swer candidate sets, which will be used for the
definitions and inferences. Each row of the label
matrix y corresponds to one question. Assuming
that the ith row yi. corresponds to the question
with sentence index qi, we thus have two candi-
date sets of contexts and answers for this question
denoted by C and A, respectively. We denote the
post indices and the author indices for the n sen-
tences as p = (p1, ... , pn) and u = (u1, ... , un).
Then, we can formally define the two candidate
sets for the yi. as
</bodyText>
<equation confidence="0.95669375">
(
pcj = pqi , cj =6 qi
¯¯¯¯¯
C = cj � {z } � {z }
In Question Post Not Question Sentence
( )
pad &gt; pqa Uaj =6 uqi
A = aj 1. {z } .
</equation>
<bodyText confidence="0.572350666666667">
the relations between sentence an
d label pairs, we
define it as follows,
</bodyText>
<equation confidence="0.8266215">
&apos;Fn(x,y) =
,
</equation>
<bodyText confidence="0.874574833333333">
where
equal to one if yij = C, otherwise
zero. The
and
are similarly de-
fined. Thus, for example, writing out
</bodyText>
<equation confidence="0.939383">
yij)
for yij =Cone gets,
On
,/&apos; /
A(yij)=[λC(yij),λA(yij),λP(yij)]T
λC(yij)
λA(yij)
λP(yij)
ψn(xj,
φqi(xj) 1 ← context
4&apos;n(Xi,yij) = I @ 0
A
quential edges an
</equation>
<bodyText confidence="0.706568333333333">
d skip-chain edges, respectively.
Their formal definitions are given as follows,
),
After Question Post Not by the Same User
Xm
i=1
n
j=1
where �hn(x, y) and &apos;Ph
</bodyText>
<equation confidence="0.8218944">
, y) denote the two
,
)
[
q&apos;hc(x
)
¸,
c
x
x
y
=
,
,y
&apos;Phn(x,y) =
</equation>
<bodyText confidence="0.670805125">
In the following, we describe formally about the
definitions of the three feature sub-mappings.
The node feature mapping XFn(x, y) encodes
yij),
ψn(xj,
where
is a feature mapping for a given
sentence and a label. It can be formally defined as
</bodyText>
<figure confidence="0.961142024390244">
foll
ψn(xj,yij)
ows,
A(yij)
(1)
where
a tensor product,
and
A(yij) denote two vectors.
ψn(xj,yij)=
⊗ φqi(xj),
⊗ denotes
φqi(xj)
φqi(xj) contains ba-
sic information for output label. A(yij) is a 0/1
vector defined as
an
←
swer .
plain
Note that the node feature mapping does not in-
corporate the relations between sentences.
The edge feature mapping
y) is used
to incorporate two types of relation, the relation
between successive sentences and the relation be-
tween context and answer sentences. It can
0←
&apos;Ph(x,
be de-
fined as follows,
41h
types of feature mappings corresponding to se-
n−1X
j=1
yij,
ψhn(xj,xj+1,
yi,j+1),
Xm
i=1
517
</figure>
<table confidence="0.99478285">
Descriptions Dimensions
Oqi(xj) (32 dimensions) in IFn(x, y)
The cosine, WordNet and KL-divergence similarities with the question xqi 3
The cosine, WordNet and KL-divergence similarities with the questions other than xqi 3
The cosine, WordNet and KL-divergence similarities with previous and next sentences 6
Is this sentence xj exactly xqi or one of the questions in {xq,, ... , xqm}? 2
Is this sentence xj in the three beginning sentences? 3
The relative position of this sentence xj to questions 4
Is this sentence xj share the same author with the question sentence xqi? 1
Is this sentence xj in the same post with question sentences? 2
Is this sentence xj in the same paragraph with question sentences? 2
The presence of greeting (e.g., “hi”) and acknowledgement words in this sentence xj 2
The length of this sentence xj 1
The number of nouns, verbs and pronouns in this sentence xj, respectively 3
&apos;Ph(x, y) (704 dimensions)
For &apos;Phn(x, y), the above 32 dimension features w.r.t. 4 x 4 = 16 transition patterns 512
For XFhc(x, y), 12 types of pairwise or merged similarities w.r.t. 16 transition patterns 192
IFv(x, y) (32 dimensions)
The transition patterns for any two non-contiguous labels in a label group 16
The transition patterns for any two contiguous labels in a label group 16
</table>
<tableCaption confidence="0.999574">
Table 1: Feature descriptions and demisions
</tableCaption>
<equation confidence="0.615341642857143">
&apos;Phc(x, y) =
1. v �
Complete Edges
Em
i=1
E
kEA
E
jEC
0hc(xj, xk, yij, yik),
4&apos;hn(xj, xj+1, yij, yi,j+1)
= A(yij, yi,j+1) ® 0hn(xj, xj+1, yij, yi,j+1),
0hc(xj, xk, yij, yik)
= A(yij, yik) ®40hc(xj, xk, yij, yik)
</equation>
<bodyText confidence="0.999937375">
where A(yij, yik) is a 16-dimensional vector. It in-
dicates all 4x4 pairwise transition patterns of four
types of labels, the context, answer, question and
plain. Note that apart from previous work (Ding
et al., 2008) we use complete skip-chain (context-
answer) edges in&apos;Phc(x, y).
The label group feature mapping IFv(x, y) is
defined as follows,
</bodyText>
<equation confidence="0.982897666666667">
n
IFv(x, y) = E 0v(xj, y.j),
j=1
</equation>
<bodyText confidence="0.9999505">
where 0v(xj, y.j) encodes each label group pat-
tern into a vector.
The detail descriptions and vector dimensions
of the used features are listed in Table 1.
</bodyText>
<sectionHeader confidence="0.865803" genericHeader="method">
4 Structural SVMs and Inference
</sectionHeader>
<bodyText confidence="0.994043166666667">
Given a training set S = {(x(i), y(i)) E X x
Y : i = 1, ... , N}, we use the structural
SVMs (Taskar et al., 2003; Tsochantaridis et
al., 2005; Joachims et al., 2009) formulation, as
shown in Optimization Problem 1 (OP1), to learn
a weight vector w.
</bodyText>
<equation confidence="0.9385785">
OP 1 (1-Slack Structural SVM)
211wI12 + �
1N �
s.t. b(¯y(1), ... , ¯y(N)) E Yn,
</equation>
<bodyText confidence="0.999821444444444">
where � is a slack variable, &apos;F(x, y) is the joint
feature mapping and 0(y, ¯y) is the loss func-
tion that measures the loss caused by the dif-
ference between y and ¯y. Though OP1 is al-
ready a quadratic optimization problem, directly
using off-the-shelf quadratic optimization solver
will fail, due to the large number of constraints.
Instead, a cutting plane algorithm is used to ef-
ficiently solve this problem. For the details of the
</bodyText>
<figure confidence="0.998016823529412">
1 T EN [4/(x(i), y(i)) − 4/(x(i), ¯y(i))l
N w i=1
A(y(i), ¯y(i)) − �,
1
� N
EN
i=1
min
W,ξ&gt;0
518
(C, P) (C, P) (C, P) (Q) (P) (A, P) (A, P)
[PPP) [CCC)
[Q) [P) [A, P) [A, P) [Q) [P) [A, P) [A, P)
....
(PPP, PPC, PCP, PCC, CPP, CPC, CCP, CCC)
(Q) (P) (A, P) (A, P)
(a) Original graph (b) Transformed graph (c) Decomposed graph
</figure>
<figureCaption confidence="0.79843">
Figure 3: The equivalent transform of graphs
Algorithm 1 Exact Inference Algorithm
</figureCaption>
<listItem confidence="0.995779222222222">
1: Input: (Ci, Ai) for each qi, w, x, y
2: for iE{1,...,m}do
3: for Cs C Ci do
4: [R(Cs), ¯yi.(Cs)] — Viterbi(w, x; Cs)
5: end for
6: C∗s = arg maxCs⊆C, R(Cs)
7: ¯y∗i. = ¯yi.(C∗s)
8: end for
9: return ¯y∗
</listItem>
<bodyText confidence="0.937442733333333">
structural SVMs, please refer to (Tsochantaridis et
al., 2005; Joachims et al., 2009).
The most essential and time-consuming step in
structural SVMs is finding the most violated con-
straint, which is equivalent to solve
arg max wTq&apos;(x(i), y) + A(y(i), y). (2)
y∈Y
Without the ability to efficiently find the most vio-
lated constraint, the cutting plane algorithm is not
tractable.
In the next sub-sections, we introduce the al-
gorithms for finding the most violated constraint,
also called loss-augmented inference. The algo-
rithms are essential for the success of customizing
structural SVMs to our problem.
</bodyText>
<subsectionHeader confidence="0.986447">
4.1 Exact Inference
</subsectionHeader>
<bodyText confidence="0.999977428571429">
The exact inference algorithm is designed for a
simplified model with two sub-mappings IF,,, and
&apos;Ph, except IF,,.
One naive approach to finding the most violated
constraint for the simplified model is to enumer-
ate all the 2|C|+|A |cases for each row of the label
matrix. However, it would be intractable for large
candidate sets.
An important property is that the context can-
didate set is usually much smaller than the whole
number of sentences in a thread. This property en-
ables us to design efficient and exact inference al-
gorithm by transforming from the original graph
representation in Figure 2 to the graphs in Fig-
ure 3. This graph transform merges all the nodes
in the context candidate set C to one node with 2|C|
possible labels.
We design an exact inference algorithm in Algo-
rithm 1 based on the graph in Figure 3(c). The al-
gorithm can be summarized in three steps: (1) enu-
merate all the 2|C |possible labels1 for the merged
node (line 3). (2) For each given label of the
merged node, perform the Viterbi algorithm (Ra-
biner, 1989) on the decomposed graph (line 4) and
store the Viterbi algorithm outputs in R and ˆyi..
(3) From the 2|C |Viterbi algorithm outputs, select
the one with highest score as the output (lines 6
and 7).
The use of the Viterbi algorithm is assured by
the fact that there exists certain equivalence be-
tween the decomposed graph (Figure 3(c)) and a
linear chain. By fixing the the label of the merged
node, we could remove the dashed edges in the
decomposed graph and regard the rest graph as a
linear chain, which results in the Viterbi decoding.
</bodyText>
<subsectionHeader confidence="0.989492">
4.2 Approximate Inference
</subsectionHeader>
<bodyText confidence="0.999937466666667">
The exact inference cannot handle the complete
model with three sub-mappings, IF,,,, &apos;Ph, and
IF,,, since the label group defeats the graph trans-
form in Figure 3. Thus, we design two ap-
proximate algorithms by employing undergener-
ating and overgenerating approaches (Finley and
Joachims, 2008).
First, we develop an undergenerating local
greedy search algorithm shown in Algorithm 2. In
the algorithm, there are two loops, inner and outer
loops. The outer loop terminates when no labels
change (steps 3-11). The inner loop enumerates
the whole label matrix and greedily determines
each label (step 7) by maximizing the Equation
(2). Since the whole algorithm terminates only if
</bodyText>
<figure confidence="0.3830964">
1Since the merged node is from context candidate set C,
enumerating its label is equivalent to enumerating subsets Cs
of the candidate set C
519
Algorithm 2 Greedy Inference Algorithm
</figure>
<listItem confidence="0.6741945">
1: Input: w, x, y
2: initialize solution: y� ← y0
</listItem>
<table confidence="0.941131111111111">
repeat
y0 ← y�
for i ∈ {1,...,m} do
for j ∈ {1, ... , n} do
yj ← arg maxydj wTjp(x, �y)
+4(y, �y)
yij ← �y∗ij
end for
end for
</table>
<listItem confidence="0.682583666666667">
11: until y� = y0
12: �y∗ ← y�
13: return y∗
</listItem>
<bodyText confidence="0.886418">
the label matrix does not change during the last
outer loop. This indicates that at least a local opti-
mal solution is obtained.
Second, an overgenerating method can be
designed by using linear programming relax-
ation (Finley and Joachims, 2008). To save the
space, we skip the details of this algorithm here.
</bodyText>
<sectionHeader confidence="0.961597" genericHeader="method">
5 Loss Functions
</sectionHeader>
<bodyText confidence="0.999083428571429">
Structural SVMs allow users to customize the loss
function 4 : Y × Y → R according to different
system requirements. In this section, we introduce
the loss functions used in our work.
Basic loss function. The simplest way to quan-
tify the prediction quality is counting the number
of wrongly predicted labels. Formally,
</bodyText>
<equation confidence="0.894537">
I[yij =6 yij], (3)
</equation>
<bodyText confidence="0.999872888888889">
where I[.] is an indicative function that equals to
one if the condition holds and zero otherwise.
Recall-vs-precision loss function. In practice,
we may place different emphasis on recall and pre-
cision according to application settings. We could
include this preference into the model by defining
the following loss function,
This function penalizes the wrong prediction de-
creasing recall and that decreasing precision with
</bodyText>
<table confidence="0.979986875">
Items in the data set #items
Thread 515
Post 2,035
Sentence 8,500
question annotation 1,407
context annotation 1,962
answer annotation 4,652
plain annotation 18,198
</table>
<tableCaption confidence="0.999392">
Table 2: The data statistics
</tableCaption>
<bodyText confidence="0.99951125">
two weights cr and cp respectively. Specifically,
we denote the loss function with cp/cr = 2 and
that with cr/cp = 2 by 4p p and 4rp, respectively.
Various types of loss function can be defined in
a similar fashion. To save the space, we skip the
definitions of other loss functions and only use the
above two types of loss functions to show the flex-
ibility of our approach.
</bodyText>
<sectionHeader confidence="0.999037" genericHeader="method">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999548">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999964269230769">
Corpus. We made use of the same data set as
introduced in (Cong et al., 2008; Ding et al.,
2008). Specifically, the data set includes about
591 threads from the forum TripAdvisor2. Each
sentence in the threads is tagged with the labels
‘question’, ‘context’, ‘answer’, or ‘plain’ by two
annotators. We removed 76 threads that have no
question sentences or more than 40 sentences and
6 questions. The remaining 515 forum threads
form our data set.
Table 2 gives the statistics on the data set. On
average, each thread contains 3.95 posts and 2.73
questions, and each question has 1.39 context sen-
tences and 3.31 answer sentences. Note that the
number of annotations is much larger than the
number of sentences because one sentence can be
annotated with multiple labels.
Experimental Details. In all the experiments,
we made use of linear models for the sake of com-
putational efficiency. As a preprocessing step, we
normalized the value of each feature value into
the interval [0, 1] and then followed the heuristic
used in SVM-light (Joachims, 1998) to set C to
1/||x||&apos;, where ||x ||is the average length of input
samples (in our case, sentences). The tolerance pa-
rameter 2 was set to 0.1 (the value also used in (Cai
</bodyText>
<footnote confidence="0.5453135">
2TripAdvisor (http://www.tripadvisor.com/
ForumHome) is one of the most popular travel forums
</footnote>
<equation confidence="0.968112181818182">
Em
i=1
4b(y, �y) =
n
E
j=1
4p(y, �y) = Em n I[yij =6 P, yij = P] · cr
i=1 E
j=1
+I[yij = P, yij =6 P] · cp. (4)
520
</equation>
<bodyText confidence="0.999751714285714">
and Hofmann, 2004)) in all the runs of the experi-
ments.
Evaluation. We calculated the standard preci-
sion (P), recall (R) and F1-score (F1) for both tasks
(context extraction and answer extraction). All the
experimental results were obtained through 5-fold
cross validation.
</bodyText>
<subsectionHeader confidence="0.985456">
6.2 Baseline Methods
</subsectionHeader>
<bodyText confidence="0.999462333333333">
We employed binary SVMs (B-SVM), multiclass
SVMs (M-SVM), and C4.5 (Quinlan, 1993) as our
baseline methods:
B-SVM. We trained two binary SVMs for con-
text extraction (context vs. non-context) and an-
swer extraction (answer vs. non-answer), respec-
tively. We used the feature mapping Oea(xj) de-
fined in Equation (1) while training the binary
SVM models.
M-SVM. We extended the binary SVMs by
training multiclass SVMs for three category labels
(context, answer, plain).
C4.5. This decision tree algorithm solved the
same classification problem as binary SVMs and
made use of the same set of features.
</bodyText>
<subsectionHeader confidence="0.9999255">
6.3 Modeling Sentence Relations and
Question Interactions
</subsectionHeader>
<bodyText confidence="0.96954968">
We demonstrate in Table 3 that our approach can
make use of the three types of relation among sen-
tences well to boost the performance.
In Table 3, S-SVM represents the structural
SVMs only using the node features IF,,,(x, y). The
suffixes H, C, and V denote the models using
horizontal sequential edges, complete skip-chain
edges and vertical label groups, respectively. The
suffixes C* and V* denote the models using in-
complete skip-chain edges and vertical sequential
edges proposed in (Ding et al., 2008), as shown
in Figures 2(a) and 2(c). All the structural SVMs
were trained using basic loss function Ob in Equa-
tion (3). From Table 3, we can observe the follow-
ing advantages of our approaches.
Overall improvement. Our structural approach
steadily improves the extraction as more types of
relation (corresponding to more types of edge) are
included. The best results obtained by using the
three types of relation together improve the base-
line methods binary SVMs by about 6% and 20%
in terms of F1 values for context extraction and
answer extraction, respectively.
The usefulness of relations. The relations
encoded by horizontal sequential edges and la-
</bodyText>
<table confidence="0.999919142857143">
Method Ab P (%) R (%) F1 (%)
Context Extraction
C4.5 − 74.2 68.7 71.2
B-SVM − 78.3 72.2 74.9
M-SVM − 68.0 77.6 72.1
S-SVM 8.86 75.6 71.7 73.4
S-SVM-H 8.60 77.5 75.5 76.3
S-SVM-HC* 8.65 77.9 74.1 75.8
S-SVM-HC 8.62 77.5 75.2 76.2
S-SVM-HCV* 8.08 79.5 79.6 79.5
S-SVM-HCV 7.98 79.7 80.2 79.9
Answer Extraction
C4.5 − 61.3 45.2 51.8
B-SVM − 69.7 42.0 51.8
M-SVM − 63.2 51.5 55.8
S-SVM 8.86 67.0 48.0 55.6
S-SVM-H 8.60 66.9 49.7 56.7
S-SVM-HC* 8.65 66.5 49.4 56.4
S-SVM-HC 8.62 65.7 51.5 57.4
S-SVM-HCV* 8.08 65.5 58.7 61.7
S-SVM-HCV 7.98 65.1 61.2 63.0
</table>
<tableCaption confidence="0.999927">
Table 3: The effectiveness of our approach
</tableCaption>
<bodyText confidence="0.9930142">
bel groups are useful for both context extraction
and answer extraction. The relation encoded by
complete skip-chain edges is useful for answer
extraction. The complete skip-chain edges not
only avoid preprocessing but also boost the per-
formance when compared with the preprocessed
skip-chain edges. The label groups improve the
vertical sequential edges.
Interactions among questions. The interac-
tions encoded by label groups are especially use-
ful. We conducted significance tests (sign test) on
the experimental results. The test result shows that
S-SVM-HCV outperforms all the other methods
without vertical edges statistically significantly (p-
value &lt; 0.01). Our proposed graphical represen-
tation in Figure 2(d) eases us to model the complex
interactions. In comparison, the 2D model in Fig-
ure 2(c) used in previous work (Ding et al., 2008)
can only model the interaction between adjacent
questions.
</bodyText>
<subsectionHeader confidence="0.995055">
6.4 Loss Function Results
</subsectionHeader>
<bodyText confidence="0.9994094">
We report in Table 4 the comparison between
structural SVMs using different loss functions.
Note that OP prefers precision and OP prefers re-
call. From Table 4, we can observe that the ex-
perimental results also exhibit this kind of system
</bodyText>
<table confidence="0.932347454545455">
521
0.9
Method P (%) R (%) F1 (%)
Context Extraction
S-SVM-HCV-Ab 79.7 80.2 79.9
S-SVM-HCV-App 82.0 70.3 75.6
S-SVM-HCV-Arp 75.7 84.2 79.7
Answer Extraction
S-SVM-HCV-Ab 65.1 61.2 63.0
S-SVM-HCV-App 71.8 52.2 60.2
S-SVM-HCV-Arp 61.8 66.1 63.7
</table>
<tableCaption confidence="0.999924">
Table 4: The use of different loss functions
</tableCaption>
<figure confidence="0.962869375">
1
Context
Answer
0.8
0.7
0.6
−1.5 −1 −0.5 0 0.5 1 1.5
Log loss ratio
1
0.8
0.6
0.4
−1.5 −1 −0.5 0 0.5 1 1.5
Context
Answer
Log loss ratio
</figure>
<bodyText confidence="0.999824285714286">
preference. Moreover, we further demonstrate the
capability of the loss function Ap in Figure 4. The
curves are achieved by varying the ratio between
two parameters cp/cr in Equation (4). The curves
confirm our intuition: when log(cp/cr) becomes
larger, the precisions increase but the recalls de-
crease and vice versa.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="method">
7 Related work
</sectionHeader>
<bodyText confidence="0.999960666666667">
Previous work on extracting questions, answers
and contexts is most related with our work. Cong
et al. (2008) proposed a supervised approach for
question detection and an unsupervised approach
for answer detection without considering contexts.
Ding et al. (2008) used CRFs to detect contexts
and answers of questions from forum threads.
Some researches on summarizing discussion
threads and emails are related to our work, too.
Zhou and Hovy (2005) segmented internet re-
lay chat, clustered segments into sub-topics, and
identified responding segments of the first seg-
ment in each sub-topic by assuming the first seg-
ment to be focus. In (Nenkova and Bagga, 2003;
Wan and McKeown, 2004; Rambow et al., 2004),
email summaries were organized by extracting
overview sentences as discussion issues. The
work (Shrestha and McKeown, 2004) used RIP-
PER as a classifier to detect interrogative questions
and their answers then used the resulting question
and answer pairs as summaries. We also note the
existing work on extracting knowledge from dis-
cussion threads. Huang et al. (2007) used SVMs
to extract input-reply pairs from forums for chat-
bot knowledge. Feng et al. (2006) implemented
a discussion-bot which used cosine similarity to
match students’ query with reply posts from an an-
notated corpus of archived threaded discussions.
Moreover, extensive researches have been done
within the area of question answering (Burger et
</bodyText>
<figureCaption confidence="0.949187">
Figure 4: Balancing between precision and recall
</figureCaption>
<bodyText confidence="0.9639308">
al., 2006; Jeon et al., 2005; Harabagiu and Hickl,
2006; Cui et al., 2005; Dang et al., 2006). They
mainly focused on using sophisticated linguistic
analysis to construct answer from a large docu-
ment collection.
</bodyText>
<sectionHeader confidence="0.945274" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99999448">
We have proposed a new form of graphical rep-
resentation for modeling the problem of extract-
ing contexts and answers of questions from online
forums and then customized structural SVM ap-
proach to solve it.
The proposed graphical representation is able
to naturally express three types of relation among
sentences: relation between successive sentences,
relation between context sentences and answer
sentences, and relation between multiple labels for
one sentence. The representation also enables us
to address interactions among questions. We also
developed the inference algorithms for the struc-
tural SVM model by exploiting the special struc-
ture of thread discussions.
Experimental results on a real data set show that
our approach significantly improves the baseline
methods by effectively utilizing various types of
relation among sentences.
Our future work includes: (a) to summa-
rize threads and represent the forum threads in
question-context-answer triple, which will change
the organization of online forums; and (b) to en-
hance QA services (e.g., Yahoo! Answers) by the
contents extracted from online forums.
</bodyText>
<sectionHeader confidence="0.959982" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.81176475">
The authors would like to thank the anonymous re-
viewers for their comments to improve this paper.
ell,
522
</bodyText>
<sectionHeader confidence="0.983643" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999891971428571">
John Burger, Claire Cardie, Vinay Chaudhri, Robert
Gaizauskas, Sanda Harabagiu, David Israel, Chris-
tian Jacquemin, Chin-Yew Lin, Steve Maiorano,
George Miller, Dan Moldovan, Bill Ogden, John
Prager, Ellen Riloff, Amit Singhal, Rohini Shrihari,
Tomek Strzalkowski, Ellen Voorhees, and Ralph
Weishedel. 2006. Issues, tasks and program struc-
tures to roadmap research in question and answering
(qna). ARAD: Advanced Research and Development
Activity (US).
Lijuan Cai and Thomas Hofmann. 2004. Hierarchi-
cal document categorization with support vector ma-
chines. In Proceedings of CIKM, pages 78–87.
Gao Cong, Long Wang, Chin-Yew Lin, and Young-In
Song. 2008. Finding question-answer pairs from
online forums. In Proceedings of SIGIR, pages 467–
474.
Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-
Seng Chua. 2005. Question answering passage re-
trieval using dependency relations. In Proceedings
of SIGIR, pages 400–407.
Hoa Dang, Jimmy Lin, and Diane Kelly. 2006.
Overview of the trec 2006 question answering track.
In Proceedings of TREC, pages 99–116.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan
Zhu. 2008. Using conditional random field to ex-
tract contexts and answers of questions from online
forums. In Proceedings of ACL, pages 710–718.
Donghui Feng, Erin Shaw, Jihie Kim, and Eduard H.
Hovy. 2006. An intelligent discussion-bot for an-
swering student queries in threaded discussions. In
Proceedings of IUI, pages 171–177.
Thomas Finley and Thorsten Joachims. 2008. Training
structural SVMs when exact inference is intractable.
In Proceedings of ICML, pages 304–311.
Michel Galley. 2006. A skip-chain conditional random
field for ranking meeting utterances by importance.
In Proceedings of the 2006 Conference on Empiri-
cal Methods in Natural Language Processing, pages
364–372.
Sanda M. Harabagiu and Andrew Hickl. 2006. Meth-
ods for using textual entailment in open-domain
question answering. In Proceedings of ACL, pages
905–912.
Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Ex-
tracting chatbot knowledge from online discussion
forums. In Proceedings of IJCAI, pages 423–428.
Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005.
Finding similar questions in large question and an-
swer archives. In Proceedings of CIKM, pages 84–
90.
Thorsten Joachims, Thomas Finley, and Chun-Nam Yu.
2009. Cutting-plane training of structural SVMs.
Machine Learning.
Thorsten Joachims. 1998. Text categorization with
support vector machines: Learning with many rele-
vant features. In Proceedings of ECML, pages 137–
142.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of ICML, pages 282–
289.
Ani Nenkova and Amit Bagga. 2003. Facilitating
email thread access by extractive summary genera-
tion. In Proceedings of RANLP, pages 287–296.
Nam Nguyen and Yunsong Guo. 2007. Comparisons
of sequence labeling algorithms and extensions. In
Proceedings of ICML, pages 681–688.
John Quinlan. 1993. C4.5: programs for machine
learning. Morgan Kaufmann Publisher Incorpora-
tion.
Lawrence Rabiner. 1989. A tutorial on hidden markov
models and selected applications in speech recogni-
tion. In Proceedings of IEEE, pages 257–286.
Owen Rambow, Lokesh Shrestha, John Chen, and
Chirsty Lauridsen. 2004. Summarizing email
threads. In Proceedings of HLT-NAACL, pages 105–
108.
Lokesh Shrestha and Kathleen McKeown. 2004. De-
tection of question-answer pairs in email conversa-
tions. In Proceedings of COLING, pages 889–895.
Charles Sutton and Andrew McCallum. 2004. Collec-
tive segmentation and labeling of distant entities in
information extraction. Technical Report 04-49.
Benjamin Taskar, Carlos Guestrin, and Daphne Koller.
2003. Max-margin markov networks. In Advances
in Neural Information Processing Systems 16. MIT
Press.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas
Hofmann, and Yasemin Altun. 2005. Large margin
methods for structured and interdependent output
variables. Journal of Machine Learning Research,
6:1453–1484.
Stephen Wan and Kathy McKeown. 2004. Generating
overview summaries of ongoing email thread discus-
sions. In Proceedings of COLING, pages 549–555.
Liang Zhou and Eduard Hovy. 2005. Digesting vir-
tual ”geek” culture: The summarization of technical
internet relay chats. In Proceedings of ACL, pages
298–305.
Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and
Wei-Ying Ma. 2005. 2d conditional random fields
for web information extraction. In Proceedings of
ICML, pages 1044–1051.
</reference>
<page confidence="0.959279">
523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925858">
<title confidence="0.999053">A Structural Support Vector Method for Extracting Contexts Answers of Questions from Online Forums</title>
<author confidence="0.999893">Yang Cao Lin</author>
<affiliation confidence="0.9859535">of Computer Science and Shanghai Jiao Tong University, Shanghai,</affiliation>
<address confidence="0.990011">Research Asia, Beijing, China</address>
<abstract confidence="0.9975398125">This paper addresses the issue of extracting contexts and answers of questions from post discussion of online forums. We propose a novel and unified model by customizing the structural Support Vector Machine method. Our customization has several attractive properties: (1) it gives a comprehensive graphical representation of thread discussion. (2) It designs special inference algorithms instead of generalpurpose ones. (3) It can be readily extended to different task preferences by varying loss functions. Experimental results on a real data set show that our methods are both promising and flexible.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>John Burger</author>
<author>Claire Cardie</author>
<author>Vinay Chaudhri</author>
<author>Robert Gaizauskas</author>
<author>Sanda Harabagiu</author>
<author>David Israel</author>
<author>Christian Jacquemin</author>
<author>Chin-Yew Lin</author>
<author>Steve Maiorano</author>
<author>George Miller</author>
<author>Dan Moldovan</author>
<author>Bill Ogden</author>
<author>John Prager</author>
</authors>
<title>Ellen Riloff, Amit Singhal, Rohini Shrihari,</title>
<date>2006</date>
<location>Tomek Strzalkowski, Ellen Voorhees, and</location>
<marker>Burger, Cardie, Chaudhri, Gaizauskas, Harabagiu, Israel, Jacquemin, Lin, Maiorano, Miller, Moldovan, Ogden, Prager, 2006</marker>
<rawString>John Burger, Claire Cardie, Vinay Chaudhri, Robert Gaizauskas, Sanda Harabagiu, David Israel, Christian Jacquemin, Chin-Yew Lin, Steve Maiorano, George Miller, Dan Moldovan, Bill Ogden, John Prager, Ellen Riloff, Amit Singhal, Rohini Shrihari, Tomek Strzalkowski, Ellen Voorhees, and Ralph Weishedel. 2006. Issues, tasks and program structures to roadmap research in question and answering (qna). ARAD: Advanced Research and Development Activity (US).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijuan Cai</author>
<author>Thomas Hofmann</author>
</authors>
<title>Hierarchical document categorization with support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>78--87</pages>
<marker>Cai, Hofmann, 2004</marker>
<rawString>Lijuan Cai and Thomas Hofmann. 2004. Hierarchical document categorization with support vector machines. In Proceedings of CIKM, pages 78–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gao Cong</author>
<author>Long Wang</author>
<author>Chin-Yew Lin</author>
<author>Young-In Song</author>
</authors>
<title>Finding question-answer pairs from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>467--474</pages>
<contexts>
<context position="1113" citStr="Cong et al., 2008" startWordPosition="161" endWordPosition="164">model by customizing the structural Support Vector Machine method. Our customization has several attractive properties: (1) it gives a comprehensive graphical representation of thread discussion. (2) It designs special inference algorithms instead of generalpurpose ones. (3) It can be readily extended to different task preferences by varying loss functions. Experimental results on a real data set show that our methods are both promising and flexible. 1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008). The extracted knowledge can be used either to enrich the knowledge base of community question answering (QA) services such as Yahoo! Answers or to augment the knowledge base of chatbot (Huang et al., 2007). Figure 1 gives an example of a forum thread with questions, contexts and answers annotated. This thread contains three posts and ten sentences, among which three questions are discussed. The three questions are proposed in three sentences, S3, S5 and S6. The context sentences S1 and S2 provide contextual information for question sentence S3. Similarly, the context sent</context>
<context position="3512" citStr="Cong et al., 2008" startWordPosition="570" endWordPosition="573">ou around. &lt;/answer&gt; Figure 1: An example thread with three posts and ten sentences (S10). As shown in the example, a forum question usually requires contextual information to complement its expression. For example, the question sentence S3 would be of incomplete meaning without the contexts S1 and S2, since the important keyword pet friendly would be lost. The problem of extracting questions, contexts, and answers can be solved in two steps: (1) identify questions and then (2) extract contexts and answers for them. Since identifying questions from forum discussions is already well solved in (Cong et al., 2008), in this paper, we are focused on step (2) while assuming questions already identified. Previously, Ding et al. (2008) employ generalpurpose graphical models without any customizations to the specific extraction problem (step 2). In this paper, we improve the existing models in 514 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 514–523, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP three aspects: graphical representation, inference algorithm and loss function. Graphical representation. We propose a more comprehensive and unified graphical repr</context>
<context position="5724" citStr="Cong et al., 2008" startWordPosition="898" endWordPosition="901">ct by sharing context sentence S4. Our proposed graphical representation can naturally model the interactions. Previous work (Ding et al., 2008) performs the extraction of contexts and answers in multiple passes of the thread (with each pass corresponding to one question), which cannot address the interactions well. In comparison, our model performs the extraction in one pass of the thread. Inference algorithm. Inference is usually a time-consuming process for structured prediction. We design special inference algorithms, instead of general-purpose inference algorithms used in previous works (Cong et al., 2008; Ding et al., 2008), by taking advantage of special properties of our task. Specifically, we utilize two special properties of thread structure to reduce the inference (time) cost. First, context sentences and question sentences usually occur in the same post while answer sentences can only occur in the following posts. With this properties, we can greatly reduce context (or answer) candidate sets of a question, which results in a significant decrease in inference cost (Section 3). Second, context candidate set is usually much smaller than the number of sentences in a thread. This property en</context>
<context position="23667" citStr="Cong et al., 2008" startWordPosition="4063" endWordPosition="4066"> question annotation 1,407 context annotation 1,962 answer annotation 4,652 plain annotation 18,198 Table 2: The data statistics two weights cr and cp respectively. Specifically, we denote the loss function with cp/cr = 2 and that with cr/cp = 2 by 4p p and 4rp, respectively. Various types of loss function can be defined in a similar fashion. To save the space, we skip the definitions of other loss functions and only use the above two types of loss functions to show the flexibility of our approach. 6 Experiments 6.1 Experimental Setup Corpus. We made use of the same data set as introduced in (Cong et al., 2008; Ding et al., 2008). Specifically, the data set includes about 591 threads from the forum TripAdvisor2. Each sentence in the threads is tagged with the labels ‘question’, ‘context’, ‘answer’, or ‘plain’ by two annotators. We removed 76 threads that have no question sentences or more than 40 sentences and 6 questions. The remaining 515 forum threads form our data set. Table 2 gives the statistics on the data set. On average, each thread contains 3.95 posts and 2.73 questions, and each question has 1.39 context sentences and 3.31 answer sentences. Note that the number of annotations is much lar</context>
<context position="29756" citStr="Cong et al. (2008)" startWordPosition="5075" endWordPosition="5078"> The use of different loss functions 1 Context Answer 0.8 0.7 0.6 −1.5 −1 −0.5 0 0.5 1 1.5 Log loss ratio 1 0.8 0.6 0.4 −1.5 −1 −0.5 0 0.5 1 1.5 Context Answer Log loss ratio preference. Moreover, we further demonstrate the capability of the loss function Ap in Figure 4. The curves are achieved by varying the ratio between two parameters cp/cr in Equation (4). The curves confirm our intuition: when log(cp/cr) becomes larger, the precisions increase but the recalls decrease and vice versa. 7 Related work Previous work on extracting questions, answers and contexts is most related with our work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), em</context>
</contexts>
<marker>Cong, Wang, Lin, Song, 2008</marker>
<rawString>Gao Cong, Long Wang, Chin-Yew Lin, and Young-In Song. 2008. Finding question-answer pairs from online forums. In Proceedings of SIGIR, pages 467– 474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Renxu Sun</author>
<author>Keya Li</author>
<author>Min-Yen Kan</author>
<author>TatSeng Chua</author>
</authors>
<title>Question answering passage retrieval using dependency relations.</title>
<date>2005</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>400--407</pages>
<contexts>
<context position="31191" citStr="Cui et al., 2005" startWordPosition="5300" endWordPosition="5303">ulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document collection. 8 Conclusion and Future Work We have proposed a new form of graphical representation for modeling the problem of extracting contexts and answers of questions from online forums and then customized structural SVM approach to solve it. The proposed graphical representation is able to naturally express three types of relation among sentences: relation between successive sentences, relation between context sentences and answer sentences, and relation between mu</context>
</contexts>
<marker>Cui, Sun, Li, Kan, Chua, 2005</marker>
<rawString>Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and TatSeng Chua. 2005. Question answering passage retrieval using dependency relations. In Proceedings of SIGIR, pages 400–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Dang</author>
<author>Jimmy Lin</author>
<author>Diane Kelly</author>
</authors>
<title>Overview of the trec</title>
<date>2006</date>
<booktitle>In Proceedings of TREC,</booktitle>
<pages>99--116</pages>
<contexts>
<context position="31211" citStr="Dang et al., 2006" startWordPosition="5304" endWordPosition="5307">d answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document collection. 8 Conclusion and Future Work We have proposed a new form of graphical representation for modeling the problem of extracting contexts and answers of questions from online forums and then customized structural SVM approach to solve it. The proposed graphical representation is able to naturally express three types of relation among sentences: relation between successive sentences, relation between context sentences and answer sentences, and relation between multiple labels for on</context>
</contexts>
<marker>Dang, Lin, Kelly, 2006</marker>
<rawString>Hoa Dang, Jimmy Lin, and Diane Kelly. 2006. Overview of the trec 2006 question answering track. In Proceedings of TREC, pages 99–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin-Yew Lin</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Using conditional random field to extract contexts and answers of questions from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>710--718</pages>
<contexts>
<context position="1133" citStr="Ding et al., 2008" startWordPosition="165" endWordPosition="168">g the structural Support Vector Machine method. Our customization has several attractive properties: (1) it gives a comprehensive graphical representation of thread discussion. (2) It designs special inference algorithms instead of generalpurpose ones. (3) It can be readily extended to different task preferences by varying loss functions. Experimental results on a real data set show that our methods are both promising and flexible. 1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008). The extracted knowledge can be used either to enrich the knowledge base of community question answering (QA) services such as Yahoo! Answers or to augment the knowledge base of chatbot (Huang et al., 2007). Figure 1 gives an example of a forum thread with questions, contexts and answers annotated. This thread contains three posts and ten sentences, among which three questions are discussed. The three questions are proposed in three sentences, S3, S5 and S6. The context sentences S1 and S2 provide contextual information for question sentence S3. Similarly, the context sentence S4 provides con</context>
<context position="3631" citStr="Ding et al. (2008)" startWordPosition="589" endWordPosition="592">orum question usually requires contextual information to complement its expression. For example, the question sentence S3 would be of incomplete meaning without the contexts S1 and S2, since the important keyword pet friendly would be lost. The problem of extracting questions, contexts, and answers can be solved in two steps: (1) identify questions and then (2) extract contexts and answers for them. Since identifying questions from forum discussions is already well solved in (Cong et al., 2008), in this paper, we are focused on step (2) while assuming questions already identified. Previously, Ding et al. (2008) employ generalpurpose graphical models without any customizations to the specific extraction problem (step 2). In this paper, we improve the existing models in 514 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 514–523, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP three aspects: graphical representation, inference algorithm and loss function. Graphical representation. We propose a more comprehensive and unified graphical representation to model the thread for relational learning. Our graphical representation has two advantages over previous w</context>
<context position="5251" citStr="Ding et al., 2008" startWordPosition="828" endWordPosition="831">ay linking to answer which is absent from question S6); and (c) relations between multiple labels for one sentence (e.g., one question sentence is unlikely to be the answer to another question although one sentence can serve as contexts for more than one questions). Our proposed graphical representation improves the modeling of the three types of sentence relation (Section 2.2). Certain interactions exist among questions. For example, question sentences S5 and S6 interact by sharing context sentence S4. Our proposed graphical representation can naturally model the interactions. Previous work (Ding et al., 2008) performs the extraction of contexts and answers in multiple passes of the thread (with each pass corresponding to one question), which cannot address the interactions well. In comparison, our model performs the extraction in one pass of the thread. Inference algorithm. Inference is usually a time-consuming process for structured prediction. We design special inference algorithms, instead of general-purpose inference algorithms used in previous works (Cong et al., 2008; Ding et al., 2008), by taking advantage of special properties of our task. Specifically, we utilize two special properties of</context>
<context position="9068" citStr="Ding et al. (2008)" startWordPosition="1498" endWordPosition="1501"> y represents the role that the jth sentence plays for the ith question. We denote the ith row and jth column of the label matrix y by yi. and y.j. 515 (d) Label group model Figure 2: Structured models {C, P} Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P } {C, P } {Q} {P } {A, P } {A, P } Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P} {C, P} {C, P} {Q} {P} {A, P} {A, P} X1 X2 X3 X4 X5 X6 X7 X1 X2 X3 X4 X5 X6 X7 (a) Skip-chain model ym1 ym2 ym3 ym4 ymn y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n (c) 2D model (b) Complete skip-chain model y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n ym1 ym2 ym3 ym4 ymn 2.2 Graphical Representation Recently, Ding et al. (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al., 2001) to perform the relational learning for context and answer extraction. The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions. The graphical representation of those two models are shown in Figures 2(a) and 2(c), respectively. Those two CRFs are both extensions of the linear chain CRFs for the sake of powerful relational learning. However, directly using t</context>
<context position="16854" citStr="Ding et al., 2008" startWordPosition="2860" endWordPosition="2863">ansition patterns for any two non-contiguous labels in a label group 16 The transition patterns for any two contiguous labels in a label group 16 Table 1: Feature descriptions and demisions &apos;Phc(x, y) = 1. v � Complete Edges Em i=1 E kEA E jEC 0hc(xj, xk, yij, yik), 4&apos;hn(xj, xj+1, yij, yi,j+1) = A(yij, yi,j+1) ® 0hn(xj, xj+1, yij, yi,j+1), 0hc(xj, xk, yij, yik) = A(yij, yik) ®40hc(xj, xk, yij, yik) where A(yij, yik) is a 16-dimensional vector. It indicates all 4x4 pairwise transition patterns of four types of labels, the context, answer, question and plain. Note that apart from previous work (Ding et al., 2008) we use complete skip-chain (contextanswer) edges in&apos;Phc(x, y). The label group feature mapping IFv(x, y) is defined as follows, n IFv(x, y) = E 0v(xj, y.j), j=1 where 0v(xj, y.j) encodes each label group pattern into a vector. The detail descriptions and vector dimensions of the used features are listed in Table 1. 4 Structural SVMs and Inference Given a training set S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we use the structural SVMs (Taskar et al., 2003; Tsochantaridis et al., 2005; Joachims et al., 2009) formulation, as shown in Optimization Problem 1 (OP1), to learn a weight vector w. </context>
<context position="23687" citStr="Ding et al., 2008" startWordPosition="4067" endWordPosition="4070">n 1,407 context annotation 1,962 answer annotation 4,652 plain annotation 18,198 Table 2: The data statistics two weights cr and cp respectively. Specifically, we denote the loss function with cp/cr = 2 and that with cr/cp = 2 by 4p p and 4rp, respectively. Various types of loss function can be defined in a similar fashion. To save the space, we skip the definitions of other loss functions and only use the above two types of loss functions to show the flexibility of our approach. 6 Experiments 6.1 Experimental Setup Corpus. We made use of the same data set as introduced in (Cong et al., 2008; Ding et al., 2008). Specifically, the data set includes about 591 threads from the forum TripAdvisor2. Each sentence in the threads is tagged with the labels ‘question’, ‘context’, ‘answer’, or ‘plain’ by two annotators. We removed 76 threads that have no question sentences or more than 40 sentences and 6 questions. The remaining 515 forum threads form our data set. Table 2 gives the statistics on the data set. On average, each thread contains 3.95 posts and 2.73 questions, and each question has 1.39 context sentences and 3.31 answer sentences. Note that the number of annotations is much larger than the number </context>
<context position="26475" citStr="Ding et al., 2008" startWordPosition="4531" endWordPosition="4534">inary SVMs and made use of the same set of features. 6.3 Modeling Sentence Relations and Question Interactions We demonstrate in Table 3 that our approach can make use of the three types of relation among sentences well to boost the performance. In Table 3, S-SVM represents the structural SVMs only using the node features IF,,,(x, y). The suffixes H, C, and V denote the models using horizontal sequential edges, complete skip-chain edges and vertical label groups, respectively. The suffixes C* and V* denote the models using incomplete skip-chain edges and vertical sequential edges proposed in (Ding et al., 2008), as shown in Figures 2(a) and 2(c). All the structural SVMs were trained using basic loss function Ob in Equation (3). From Table 3, we can observe the following advantages of our approaches. Overall improvement. Our structural approach steadily improves the extraction as more types of relation (corresponding to more types of edge) are included. The best results obtained by using the three types of relation together improve the baseline methods binary SVMs by about 6% and 20% in terms of F1 values for context extraction and answer extraction, respectively. The usefulness of relations. The rel</context>
<context position="28563" citStr="Ding et al., 2008" startWordPosition="4874" endWordPosition="4877">oost the performance when compared with the preprocessed skip-chain edges. The label groups improve the vertical sequential edges. Interactions among questions. The interactions encoded by label groups are especially useful. We conducted significance tests (sign test) on the experimental results. The test result shows that S-SVM-HCV outperforms all the other methods without vertical edges statistically significantly (pvalue &lt; 0.01). Our proposed graphical representation in Figure 2(d) eases us to model the complex interactions. In comparison, the 2D model in Figure 2(c) used in previous work (Ding et al., 2008) can only model the interaction between adjacent questions. 6.4 Loss Function Results We report in Table 4 the comparison between structural SVMs using different loss functions. Note that OP prefers precision and OP prefers recall. From Table 4, we can observe that the experimental results also exhibit this kind of system 521 0.9 Method P (%) R (%) F1 (%) Context Extraction S-SVM-HCV-Ab 79.7 80.2 79.9 S-SVM-HCV-App 82.0 70.3 75.6 S-SVM-HCV-Arp 75.7 84.2 79.7 Answer Extraction S-SVM-HCV-Ab 65.1 61.2 63.0 S-SVM-HCV-App 71.8 52.2 60.2 S-SVM-HCV-Arp 61.8 66.1 63.7 Table 4: The use of different los</context>
<context position="29909" citStr="Ding et al. (2008)" startWordPosition="5096" endWordPosition="5099">Answer Log loss ratio preference. Moreover, we further demonstrate the capability of the loss function Ap in Figure 4. The curves are achieved by varying the ratio between two parameters cp/cr in Equation (4). The curves confirm our intuition: when log(cp/cr) becomes larger, the precisions increase but the recalls decrease and vice versa. 7 Related work Previous work on extracting questions, answers and contexts is most related with our work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to </context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu. 2008. Using conditional random field to extract contexts and answers of questions from online forums. In Proceedings of ACL, pages 710–718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donghui Feng</author>
<author>Erin Shaw</author>
<author>Jihie Kim</author>
<author>Eduard H Hovy</author>
</authors>
<title>An intelligent discussion-bot for answering student queries in threaded discussions.</title>
<date>2006</date>
<booktitle>In Proceedings of IUI,</booktitle>
<pages>171--177</pages>
<contexts>
<context position="30814" citStr="Feng et al. (2006)" startWordPosition="5242" endWordPosition="5245">s of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document collection. 8 Conclusion and Future Work We have proposed a new form of graphical representation</context>
</contexts>
<marker>Feng, Shaw, Kim, Hovy, 2006</marker>
<rawString>Donghui Feng, Erin Shaw, Jihie Kim, and Eduard H. Hovy. 2006. An intelligent discussion-bot for answering student queries in threaded discussions. In Proceedings of IUI, pages 171–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Finley</author>
<author>Thorsten Joachims</author>
</authors>
<title>Training structural SVMs when exact inference is intractable.</title>
<date>2008</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="21107" citStr="Finley and Joachims, 2008" startWordPosition="3620" endWordPosition="3623">s assured by the fact that there exists certain equivalence between the decomposed graph (Figure 3(c)) and a linear chain. By fixing the the label of the merged node, we could remove the dashed edges in the decomposed graph and regard the rest graph as a linear chain, which results in the Viterbi decoding. 4.2 Approximate Inference The exact inference cannot handle the complete model with three sub-mappings, IF,,,, &apos;Ph, and IF,,, since the label group defeats the graph transform in Figure 3. Thus, we design two approximate algorithms by employing undergenerating and overgenerating approaches (Finley and Joachims, 2008). First, we develop an undergenerating local greedy search algorithm shown in Algorithm 2. In the algorithm, there are two loops, inner and outer loops. The outer loop terminates when no labels change (steps 3-11). The inner loop enumerates the whole label matrix and greedily determines each label (step 7) by maximizing the Equation (2). Since the whole algorithm terminates only if 1Since the merged node is from context candidate set C, enumerating its label is equivalent to enumerating subsets Cs of the candidate set C 519 Algorithm 2 Greedy Inference Algorithm 1: Input: w, x, y 2: initialize</context>
</contexts>
<marker>Finley, Joachims, 2008</marker>
<rawString>Thomas Finley and Thorsten Joachims. 2008. Training structural SVMs when exact inference is intractable. In Proceedings of ICML, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
</authors>
<title>A skip-chain conditional random field for ranking meeting utterances by importance.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>364--372</pages>
<contexts>
<context position="9279" citStr="Galley, 2006" startWordPosition="1531" endWordPosition="1532">3 Y4 Y5 Y6 Y7 {C, P } {C, P } {Q} {P } {A, P } {A, P } Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P} {C, P} {C, P} {Q} {P} {A, P} {A, P} X1 X2 X3 X4 X5 X6 X7 X1 X2 X3 X4 X5 X6 X7 (a) Skip-chain model ym1 ym2 ym3 ym4 ymn y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n (c) 2D model (b) Complete skip-chain model y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n ym1 ym2 ym3 ym4 ymn 2.2 Graphical Representation Recently, Ding et al. (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al., 2001) to perform the relational learning for context and answer extraction. The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions. The graphical representation of those two models are shown in Figures 2(a) and 2(c), respectively. Those two CRFs are both extensions of the linear chain CRFs for the sake of powerful relational learning. However, directly using the skip-chain and 2D CRFs without any customization has obvious disadvantages: (a) the skip-chain model does not model the dependency between answer sentence and multiple context sentences; and (b) the 2D model </context>
</contexts>
<marker>Galley, 2006</marker>
<rawString>Michel Galley. 2006. A skip-chain conditional random field for ranking meeting utterances by importance. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 364–372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Andrew Hickl</author>
</authors>
<title>Methods for using textual entailment in open-domain question answering.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>905--912</pages>
<contexts>
<context position="31173" citStr="Harabagiu and Hickl, 2006" startWordPosition="5296" endWordPosition="5299">r answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document collection. 8 Conclusion and Future Work We have proposed a new form of graphical representation for modeling the problem of extracting contexts and answers of questions from online forums and then customized structural SVM approach to solve it. The proposed graphical representation is able to naturally express three types of relation among sentences: relation between successive sentences, relation between context sentences and answer sentences, and r</context>
</contexts>
<marker>Harabagiu, Hickl, 2006</marker>
<rawString>Sanda M. Harabagiu and Andrew Hickl. 2006. Methods for using textual entailment in open-domain question answering. In Proceedings of ACL, pages 905–912.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jizhou Huang</author>
<author>Ming Zhou</author>
<author>Dan Yang</author>
</authors>
<title>Extracting chatbot knowledge from online discussion forums.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>423--428</pages>
<contexts>
<context position="1340" citStr="Huang et al., 2007" startWordPosition="201" endWordPosition="204">nce algorithms instead of generalpurpose ones. (3) It can be readily extended to different task preferences by varying loss functions. Experimental results on a real data set show that our methods are both promising and flexible. 1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008). The extracted knowledge can be used either to enrich the knowledge base of community question answering (QA) services such as Yahoo! Answers or to augment the knowledge base of chatbot (Huang et al., 2007). Figure 1 gives an example of a forum thread with questions, contexts and answers annotated. This thread contains three posts and ten sentences, among which three questions are discussed. The three questions are proposed in three sentences, S3, S5 and S6. The context sentences S1 and S2 provide contextual information for question sentence S3. Similarly, the context sentence S4 provides contextual information for question sentence S5 and S6. There are three question-contextanswer triples in this example, (S3) − (S1, S2) − (S8, S9), (S5) − (S4) − (S10) and (S6) − (S4) − * This work was done whi</context>
<context position="30721" citStr="Huang et al. (2007)" startWordPosition="5226" endWordPosition="5229">ted internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document col</context>
</contexts>
<marker>Huang, Zhou, Yang, 2007</marker>
<rawString>Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Extracting chatbot knowledge from online discussion forums. In Proceedings of IJCAI, pages 423–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
<author>Joon Ho Lee</author>
</authors>
<title>Finding similar questions in large question and answer archives.</title>
<date>2005</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>84--90</pages>
<contexts>
<context position="31146" citStr="Jeon et al., 2005" startWordPosition="5292" endWordPosition="5295"> questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4: Balancing between precision and recall al., 2006; Jeon et al., 2005; Harabagiu and Hickl, 2006; Cui et al., 2005; Dang et al., 2006). They mainly focused on using sophisticated linguistic analysis to construct answer from a large document collection. 8 Conclusion and Future Work We have proposed a new form of graphical representation for modeling the problem of extracting contexts and answers of questions from online forums and then customized structural SVM approach to solve it. The proposed graphical representation is able to naturally express three types of relation among sentences: relation between successive sentences, relation between context sentences </context>
</contexts>
<marker>Jeon, Croft, Lee, 2005</marker>
<rawString>Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005. Finding similar questions in large question and answer archives. In Proceedings of CIKM, pages 84– 90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
<author>Thomas Finley</author>
<author>Chun-Nam Yu</author>
</authors>
<title>Cutting-plane training of structural SVMs.</title>
<date>2009</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="11310" citStr="Joachims et al., 2009" startWordPosition="1887" endWordPosition="1890">by X and Y, then formulate our task as learning a hypothesis function h : X —* Y to predict a y when given x. In this setup, x represents a thread of n sentences and m identified questions. y represents the m x n label matrix to be predicted. Given a set of training examples, S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we restrict ourselves to the supervised learning scenario. We focus on hypothesis functions that take the form h(x; w) = arg maxYEY F(x, y; w) with discriminant function F : X x Y—* R where F(x, y; w) = wTjp(x, y). As will be introduced in Section 4, we employ structural SVMs (Joachims et al., 2009) to find the optimal parameters w. The structural SVMs have several competitive properties as CRFs. First, it follows from the maximum margin strategy, which has been shown with competitive or even better 516 performance (Tsochantaridis et al., 2005; Nguyen and Guo, 2007). Second, it allows flexible choices of loss functions to users. Moreover, in general, it has theoretically proved convergence in polynomial time (Joachims et al., 2009). To use structural SVMs in relational learning, one needs to customize three steps according to specific tasks. The three steps are (a) definition of joint fe</context>
<context position="17370" citStr="Joachims et al., 2009" startWordPosition="2956" endWordPosition="2959">of labels, the context, answer, question and plain. Note that apart from previous work (Ding et al., 2008) we use complete skip-chain (contextanswer) edges in&apos;Phc(x, y). The label group feature mapping IFv(x, y) is defined as follows, n IFv(x, y) = E 0v(xj, y.j), j=1 where 0v(xj, y.j) encodes each label group pattern into a vector. The detail descriptions and vector dimensions of the used features are listed in Table 1. 4 Structural SVMs and Inference Given a training set S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we use the structural SVMs (Taskar et al., 2003; Tsochantaridis et al., 2005; Joachims et al., 2009) formulation, as shown in Optimization Problem 1 (OP1), to learn a weight vector w. OP 1 (1-Slack Structural SVM) 211wI12 + � 1N � s.t. b(¯y(1), ... , ¯y(N)) E Yn, where � is a slack variable, &apos;F(x, y) is the joint feature mapping and 0(y, ¯y) is the loss function that measures the loss caused by the difference between y and ¯y. Though OP1 is already a quadratic optimization problem, directly using off-the-shelf quadratic optimization solver will fail, due to the large number of constraints. Instead, a cutting plane algorithm is used to efficiently solve this problem. For the details of the 1 </context>
<context position="18667" citStr="Joachims et al., 2009" startWordPosition="3206" endWordPosition="3209">N i=1 min W,ξ&gt;0 518 (C, P) (C, P) (C, P) (Q) (P) (A, P) (A, P) [PPP) [CCC) [Q) [P) [A, P) [A, P) [Q) [P) [A, P) [A, P) .... (PPP, PPC, PCP, PCC, CPP, CPC, CCP, CCC) (Q) (P) (A, P) (A, P) (a) Original graph (b) Transformed graph (c) Decomposed graph Figure 3: The equivalent transform of graphs Algorithm 1 Exact Inference Algorithm 1: Input: (Ci, Ai) for each qi, w, x, y 2: for iE{1,...,m}do 3: for Cs C Ci do 4: [R(Cs), ¯yi.(Cs)] — Viterbi(w, x; Cs) 5: end for 6: C∗s = arg maxCs⊆C, R(Cs) 7: ¯y∗i. = ¯yi.(C∗s) 8: end for 9: return ¯y∗ structural SVMs, please refer to (Tsochantaridis et al., 2005; Joachims et al., 2009). The most essential and time-consuming step in structural SVMs is finding the most violated constraint, which is equivalent to solve arg max wTq&apos;(x(i), y) + A(y(i), y). (2) y∈Y Without the ability to efficiently find the most violated constraint, the cutting plane algorithm is not tractable. In the next sub-sections, we introduce the algorithms for finding the most violated constraint, also called loss-augmented inference. The algorithms are essential for the success of customizing structural SVMs to our problem. 4.1 Exact Inference The exact inference algorithm is designed for a simplified m</context>
</contexts>
<marker>Joachims, Finley, Yu, 2009</marker>
<rawString>Thorsten Joachims, Thomas Finley, and Chun-Nam Yu. 2009. Cutting-plane training of structural SVMs. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of ECML,</booktitle>
<pages>137--142</pages>
<contexts>
<context position="24639" citStr="Joachims, 1998" startWordPosition="4225" endWordPosition="4226">our data set. Table 2 gives the statistics on the data set. On average, each thread contains 3.95 posts and 2.73 questions, and each question has 1.39 context sentences and 3.31 answer sentences. Note that the number of annotations is much larger than the number of sentences because one sentence can be annotated with multiple labels. Experimental Details. In all the experiments, we made use of linear models for the sake of computational efficiency. As a preprocessing step, we normalized the value of each feature value into the interval [0, 1] and then followed the heuristic used in SVM-light (Joachims, 1998) to set C to 1/||x||&apos;, where ||x ||is the average length of input samples (in our case, sentences). The tolerance parameter 2 was set to 0.1 (the value also used in (Cai 2TripAdvisor (http://www.tripadvisor.com/ ForumHome) is one of the most popular travel forums Em i=1 4b(y, �y) = n E j=1 4p(y, �y) = Em n I[yij =6 P, yij = P] · cr i=1 E j=1 +I[yij = P, yij =6 P] · cp. (4) 520 and Hofmann, 2004)) in all the runs of the experiments. Evaluation. We calculated the standard precision (P), recall (R) and F1-score (F1) for both tasks (context extraction and answer extraction). All the experimental r</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of ECML, pages 137– 142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="9147" citStr="Lafferty et al., 2001" startWordPosition="1510" endWordPosition="1513"> denote the ith row and jth column of the label matrix y by yi. and y.j. 515 (d) Label group model Figure 2: Structured models {C, P} Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P } {C, P } {Q} {P } {A, P } {A, P } Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P} {C, P} {C, P} {Q} {P} {A, P} {A, P} X1 X2 X3 X4 X5 X6 X7 X1 X2 X3 X4 X5 X6 X7 (a) Skip-chain model ym1 ym2 ym3 ym4 ymn y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n (c) 2D model (b) Complete skip-chain model y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n ym1 ym2 ym3 ym4 ymn 2.2 Graphical Representation Recently, Ding et al. (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al., 2001) to perform the relational learning for context and answer extraction. The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions. The graphical representation of those two models are shown in Figures 2(a) and 2(c), respectively. Those two CRFs are both extensions of the linear chain CRFs for the sake of powerful relational learning. However, directly using the skip-chain and 2D CRFs without any customization has obvious disadvantages: </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML, pages 282– 289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
<author>Amit Bagga</author>
</authors>
<title>Facilitating email thread access by extractive summary generation.</title>
<date>2003</date>
<booktitle>In Proceedings of RANLP,</booktitle>
<pages>287--296</pages>
<contexts>
<context position="30307" citStr="Nenkova and Bagga, 2003" startWordPosition="5161" endWordPosition="5164">, answers and contexts is most related with our work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with repl</context>
</contexts>
<marker>Nenkova, Bagga, 2003</marker>
<rawString>Ani Nenkova and Amit Bagga. 2003. Facilitating email thread access by extractive summary generation. In Proceedings of RANLP, pages 287–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nam Nguyen</author>
<author>Yunsong Guo</author>
</authors>
<title>Comparisons of sequence labeling algorithms and extensions.</title>
<date>2007</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>681--688</pages>
<contexts>
<context position="11582" citStr="Nguyen and Guo, 2007" startWordPosition="1931" endWordPosition="1934">es, S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we restrict ourselves to the supervised learning scenario. We focus on hypothesis functions that take the form h(x; w) = arg maxYEY F(x, y; w) with discriminant function F : X x Y—* R where F(x, y; w) = wTjp(x, y). As will be introduced in Section 4, we employ structural SVMs (Joachims et al., 2009) to find the optimal parameters w. The structural SVMs have several competitive properties as CRFs. First, it follows from the maximum margin strategy, which has been shown with competitive or even better 516 performance (Tsochantaridis et al., 2005; Nguyen and Guo, 2007). Second, it allows flexible choices of loss functions to users. Moreover, in general, it has theoretically proved convergence in polynomial time (Joachims et al., 2009). To use structural SVMs in relational learning, one needs to customize three steps according to specific tasks. The three steps are (a) definition of joint feature mapping for encoding relations, (b) algorithm of finding the most violated constraint (inference) for efficient trainings and (c) definition of loss function for flexible uses. In the following Sections 3, 4 and 5, we describe the customizations of the three steps f</context>
</contexts>
<marker>Nguyen, Guo, 2007</marker>
<rawString>Nam Nguyen and Yunsong Guo. 2007. Comparisons of sequence labeling algorithms and extensions. In Proceedings of ICML, pages 681–688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Quinlan</author>
</authors>
<title>C4.5: programs for machine learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publisher Incorporation.</publisher>
<contexts>
<context position="25396" citStr="Quinlan, 1993" startWordPosition="4360" endWordPosition="4361">he value also used in (Cai 2TripAdvisor (http://www.tripadvisor.com/ ForumHome) is one of the most popular travel forums Em i=1 4b(y, �y) = n E j=1 4p(y, �y) = Em n I[yij =6 P, yij = P] · cr i=1 E j=1 +I[yij = P, yij =6 P] · cp. (4) 520 and Hofmann, 2004)) in all the runs of the experiments. Evaluation. We calculated the standard precision (P), recall (R) and F1-score (F1) for both tasks (context extraction and answer extraction). All the experimental results were obtained through 5-fold cross validation. 6.2 Baseline Methods We employed binary SVMs (B-SVM), multiclass SVMs (M-SVM), and C4.5 (Quinlan, 1993) as our baseline methods: B-SVM. We trained two binary SVMs for context extraction (context vs. non-context) and answer extraction (answer vs. non-answer), respectively. We used the feature mapping Oea(xj) defined in Equation (1) while training the binary SVM models. M-SVM. We extended the binary SVMs by training multiclass SVMs for three category labels (context, answer, plain). C4.5. This decision tree algorithm solved the same classification problem as binary SVMs and made use of the same set of features. 6.3 Modeling Sentence Relations and Question Interactions We demonstrate in Table 3 th</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>John Quinlan. 1993. C4.5: programs for machine learning. Morgan Kaufmann Publisher Incorporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>In Proceedings of IEEE,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="20248" citStr="Rabiner, 1989" startWordPosition="3476" endWordPosition="3478">umber of sentences in a thread. This property enables us to design efficient and exact inference algorithm by transforming from the original graph representation in Figure 2 to the graphs in Figure 3. This graph transform merges all the nodes in the context candidate set C to one node with 2|C| possible labels. We design an exact inference algorithm in Algorithm 1 based on the graph in Figure 3(c). The algorithm can be summarized in three steps: (1) enumerate all the 2|C |possible labels1 for the merged node (line 3). (2) For each given label of the merged node, perform the Viterbi algorithm (Rabiner, 1989) on the decomposed graph (line 4) and store the Viterbi algorithm outputs in R and ˆyi.. (3) From the 2|C |Viterbi algorithm outputs, select the one with highest score as the output (lines 6 and 7). The use of the Viterbi algorithm is assured by the fact that there exists certain equivalence between the decomposed graph (Figure 3(c)) and a linear chain. By fixing the the label of the merged node, we could remove the dashed edges in the decomposed graph and regard the rest graph as a linear chain, which results in the Viterbi decoding. 4.2 Approximate Inference The exact inference cannot handle</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>Lawrence Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings of IEEE, pages 257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Lokesh Shrestha</author>
<author>John Chen</author>
<author>Chirsty Lauridsen</author>
</authors>
<title>Summarizing email threads.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>105--108</pages>
<contexts>
<context position="30352" citStr="Rambow et al., 2004" startWordPosition="5169" endWordPosition="5172">work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived </context>
</contexts>
<marker>Rambow, Shrestha, Chen, Lauridsen, 2004</marker>
<rawString>Owen Rambow, Lokesh Shrestha, John Chen, and Chirsty Lauridsen. 2004. Summarizing email threads. In Proceedings of HLT-NAACL, pages 105– 108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lokesh Shrestha</author>
<author>Kathleen McKeown</author>
</authors>
<title>Detection of question-answer pairs in email conversations.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>889--895</pages>
<contexts>
<context position="30477" citStr="Shrestha and McKeown, 2004" startWordPosition="5186" endWordPosition="5189"> detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotated corpus of archived threaded discussions. Moreover, extensive researches have been done within the area of question answering (Burger et Figure 4</context>
</contexts>
<marker>Shrestha, McKeown, 2004</marker>
<rawString>Lokesh Shrestha and Kathleen McKeown. 2004. Detection of question-answer pairs in email conversations. In Proceedings of COLING, pages 889–895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction.</title>
<date>2004</date>
<tech>Technical Report 04-49.</tech>
<contexts>
<context position="9264" citStr="Sutton and McCallum, 2004" startWordPosition="1527" endWordPosition="1530">tured models {C, P} Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P } {C, P } {Q} {P } {A, P } {A, P } Y1 Y2 Y3 Y4 Y5 Y6 Y7 {C, P} {C, P} {C, P} {Q} {P} {A, P} {A, P} X1 X2 X3 X4 X5 X6 X7 X1 X2 X3 X4 X5 X6 X7 (a) Skip-chain model ym1 ym2 ym3 ym4 ymn y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n (c) 2D model (b) Complete skip-chain model y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n ym1 ym2 ym3 ym4 ymn 2.2 Graphical Representation Recently, Ding et al. (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al., 2001) to perform the relational learning for context and answer extraction. The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions. The graphical representation of those two models are shown in Figures 2(a) and 2(c), respectively. Those two CRFs are both extensions of the linear chain CRFs for the sake of powerful relational learning. However, directly using the skip-chain and 2D CRFs without any customization has obvious disadvantages: (a) the skip-chain model does not model the dependency between answer sentence and multiple context sentences; and (b</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>Charles Sutton and Andrew McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. Technical Report 04-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Taskar</author>
<author>Carlos Guestrin</author>
<author>Daphne Koller</author>
</authors>
<title>Max-margin markov networks.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems 16.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="17317" citStr="Taskar et al., 2003" startWordPosition="2948" endWordPosition="2951">ll 4x4 pairwise transition patterns of four types of labels, the context, answer, question and plain. Note that apart from previous work (Ding et al., 2008) we use complete skip-chain (contextanswer) edges in&apos;Phc(x, y). The label group feature mapping IFv(x, y) is defined as follows, n IFv(x, y) = E 0v(xj, y.j), j=1 where 0v(xj, y.j) encodes each label group pattern into a vector. The detail descriptions and vector dimensions of the used features are listed in Table 1. 4 Structural SVMs and Inference Given a training set S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we use the structural SVMs (Taskar et al., 2003; Tsochantaridis et al., 2005; Joachims et al., 2009) formulation, as shown in Optimization Problem 1 (OP1), to learn a weight vector w. OP 1 (1-Slack Structural SVM) 211wI12 + � 1N � s.t. b(¯y(1), ... , ¯y(N)) E Yn, where � is a slack variable, &apos;F(x, y) is the joint feature mapping and 0(y, ¯y) is the loss function that measures the loss caused by the difference between y and ¯y. Though OP1 is already a quadratic optimization problem, directly using off-the-shelf quadratic optimization solver will fail, due to the large number of constraints. Instead, a cutting plane algorithm is used to effi</context>
</contexts>
<marker>Taskar, Guestrin, Koller, 2003</marker>
<rawString>Benjamin Taskar, Carlos Guestrin, and Daphne Koller. 2003. Max-margin markov networks. In Advances in Neural Information Processing Systems 16. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thorsten Joachims</author>
<author>Thomas Hofmann</author>
<author>Yasemin Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>6--1453</pages>
<contexts>
<context position="11559" citStr="Tsochantaridis et al., 2005" startWordPosition="1927" endWordPosition="1930">iven a set of training examples, S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we restrict ourselves to the supervised learning scenario. We focus on hypothesis functions that take the form h(x; w) = arg maxYEY F(x, y; w) with discriminant function F : X x Y—* R where F(x, y; w) = wTjp(x, y). As will be introduced in Section 4, we employ structural SVMs (Joachims et al., 2009) to find the optimal parameters w. The structural SVMs have several competitive properties as CRFs. First, it follows from the maximum margin strategy, which has been shown with competitive or even better 516 performance (Tsochantaridis et al., 2005; Nguyen and Guo, 2007). Second, it allows flexible choices of loss functions to users. Moreover, in general, it has theoretically proved convergence in polynomial time (Joachims et al., 2009). To use structural SVMs in relational learning, one needs to customize three steps according to specific tasks. The three steps are (a) definition of joint feature mapping for encoding relations, (b) algorithm of finding the most violated constraint (inference) for efficient trainings and (c) definition of loss function for flexible uses. In the following Sections 3, 4 and 5, we describe the customizatio</context>
<context position="17346" citStr="Tsochantaridis et al., 2005" startWordPosition="2952" endWordPosition="2955">ition patterns of four types of labels, the context, answer, question and plain. Note that apart from previous work (Ding et al., 2008) we use complete skip-chain (contextanswer) edges in&apos;Phc(x, y). The label group feature mapping IFv(x, y) is defined as follows, n IFv(x, y) = E 0v(xj, y.j), j=1 where 0v(xj, y.j) encodes each label group pattern into a vector. The detail descriptions and vector dimensions of the used features are listed in Table 1. 4 Structural SVMs and Inference Given a training set S = {(x(i), y(i)) E X x Y : i = 1, ... , N}, we use the structural SVMs (Taskar et al., 2003; Tsochantaridis et al., 2005; Joachims et al., 2009) formulation, as shown in Optimization Problem 1 (OP1), to learn a weight vector w. OP 1 (1-Slack Structural SVM) 211wI12 + � 1N � s.t. b(¯y(1), ... , ¯y(N)) E Yn, where � is a slack variable, &apos;F(x, y) is the joint feature mapping and 0(y, ¯y) is the loss function that measures the loss caused by the difference between y and ¯y. Though OP1 is already a quadratic optimization problem, directly using off-the-shelf quadratic optimization solver will fail, due to the large number of constraints. Instead, a cutting plane algorithm is used to efficiently solve this problem. F</context>
<context position="18643" citStr="Tsochantaridis et al., 2005" startWordPosition="3202" endWordPosition="3205">1 A(y(i), ¯y(i)) − �, 1 � N EN i=1 min W,ξ&gt;0 518 (C, P) (C, P) (C, P) (Q) (P) (A, P) (A, P) [PPP) [CCC) [Q) [P) [A, P) [A, P) [Q) [P) [A, P) [A, P) .... (PPP, PPC, PCP, PCC, CPP, CPC, CCP, CCC) (Q) (P) (A, P) (A, P) (a) Original graph (b) Transformed graph (c) Decomposed graph Figure 3: The equivalent transform of graphs Algorithm 1 Exact Inference Algorithm 1: Input: (Ci, Ai) for each qi, w, x, y 2: for iE{1,...,m}do 3: for Cs C Ci do 4: [R(Cs), ¯yi.(Cs)] — Viterbi(w, x; Cs) 5: end for 6: C∗s = arg maxCs⊆C, R(Cs) 7: ¯y∗i. = ¯yi.(C∗s) 8: end for 9: return ¯y∗ structural SVMs, please refer to (Tsochantaridis et al., 2005; Joachims et al., 2009). The most essential and time-consuming step in structural SVMs is finding the most violated constraint, which is equivalent to solve arg max wTq&apos;(x(i), y) + A(y(i), y). (2) y∈Y Without the ability to efficiently find the most violated constraint, the cutting plane algorithm is not tractable. In the next sub-sections, we introduce the algorithms for finding the most violated constraint, also called loss-augmented inference. The algorithms are essential for the success of customizing structural SVMs to our problem. 4.1 Exact Inference The exact inference algorithm is des</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. 2005. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wan</author>
<author>Kathy McKeown</author>
</authors>
<title>Generating overview summaries of ongoing email thread discussions.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>549--555</pages>
<contexts>
<context position="30330" citStr="Wan and McKeown, 2004" startWordPosition="5165" endWordPosition="5168"> most related with our work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion threads. Huang et al. (2007) used SVMs to extract input-reply pairs from forums for chatbot knowledge. Feng et al. (2006) implemented a discussion-bot which used cosine similarity to match students’ query with reply posts from an annotat</context>
</contexts>
<marker>Wan, McKeown, 2004</marker>
<rawString>Stephen Wan and Kathy McKeown. 2004. Generating overview summaries of ongoing email thread discussions. In Proceedings of COLING, pages 549–555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Eduard Hovy</author>
</authors>
<title>Digesting virtual ”geek” culture: The summarization of technical internet relay chats.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>298--305</pages>
<contexts>
<context position="30095" citStr="Zhou and Hovy (2005)" startWordPosition="5126" endWordPosition="5129">rs cp/cr in Equation (4). The curves confirm our intuition: when log(cp/cr) becomes larger, the precisions increase but the recalls decrease and vice versa. 7 Related work Previous work on extracting questions, answers and contexts is most related with our work. Cong et al. (2008) proposed a supervised approach for question detection and an unsupervised approach for answer detection without considering contexts. Ding et al. (2008) used CRFs to detect contexts and answers of questions from forum threads. Some researches on summarizing discussion threads and emails are related to our work, too. Zhou and Hovy (2005) segmented internet relay chat, clustered segments into sub-topics, and identified responding segments of the first segment in each sub-topic by assuming the first segment to be focus. In (Nenkova and Bagga, 2003; Wan and McKeown, 2004; Rambow et al., 2004), email summaries were organized by extracting overview sentences as discussion issues. The work (Shrestha and McKeown, 2004) used RIPPER as a classifier to detect interrogative questions and their answers then used the resulting question and answer pairs as summaries. We also note the existing work on extracting knowledge from discussion th</context>
</contexts>
<marker>Zhou, Hovy, 2005</marker>
<rawString>Liang Zhou and Eduard Hovy. 2005. Digesting virtual ”geek” culture: The summarization of technical internet relay chats. In Proceedings of ACL, pages 298–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Zaiqing Nie</author>
<author>Ji-Rong Wen</author>
<author>Bo Zhang</author>
<author>Wei-Ying Ma</author>
</authors>
<title>2d conditional random fields for web information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>1044--1051</pages>
<contexts>
<context position="9386" citStr="Zhu et al., 2005" startWordPosition="1548" endWordPosition="1551">} {A, P} {A, P} X1 X2 X3 X4 X5 X6 X7 X1 X2 X3 X4 X5 X6 X7 (a) Skip-chain model ym1 ym2 ym3 ym4 ymn y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n (c) 2D model (b) Complete skip-chain model y11 y12 y13 y14 y1n y21 y22 y23 y24 y2n ym1 ym2 ym3 ym4 ymn 2.2 Graphical Representation Recently, Ding et al. (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al., 2001) to perform the relational learning for context and answer extraction. The skip-chain CRFs (Sutton and McCallum, 2004; Galley, 2006) model the long distance dependency between context and answer sentences and the 2D CRFs (Zhu et al., 2005) model the dependency between contiguous questions. The graphical representation of those two models are shown in Figures 2(a) and 2(c), respectively. Those two CRFs are both extensions of the linear chain CRFs for the sake of powerful relational learning. However, directly using the skip-chain and 2D CRFs without any customization has obvious disadvantages: (a) the skip-chain model does not model the dependency between answer sentence and multiple context sentences; and (b) the 2D model does not model the dependency between non-contiguous questions. To better model the problem of extracting c</context>
</contexts>
<marker>Zhu, Nie, Wen, Zhang, Ma, 2005</marker>
<rawString>Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and Wei-Ying Ma. 2005. 2d conditional random fields for web information extraction. In Proceedings of ICML, pages 1044–1051.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>