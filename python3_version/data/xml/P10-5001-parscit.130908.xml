<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.644271">
<title confidence="0.991304">
Wide-coverage NLP with Linguistically Expressive Grammars
</title>
<author confidence="0.974022">
Julia Hockenmaier Yusuke Miyao
</author>
<affiliation confidence="0.994109">
Department of Computer Science, National Institute of Informatics
University of Illinois yusuke@nii.ac.jp
</affiliation>
<email confidence="0.973695">
juliahmr@illinois.edu
</email>
<author confidence="0.864312">
Josef van Genabith
</author>
<affiliation confidence="0.989905">
Centre for Next Generation Localisation,
School of Computing,
Dublin City University
</affiliation>
<email confidence="0.994326">
josef@computing.dcu.ie
</email>
<sectionHeader confidence="0.99958" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998185">
In recent years, there has been a lot of research
on wide-coverage statistical natural language
processing with linguistically expressive gram-
mars such as Combinatory Categorial Grammars
(CCG), Head-driven Phrase-Structure Grammars
(HPSG), Lexical-Functional Grammars (LFG)
and Tree-Adjoining Grammars (TAG). But al-
though many young researchers in natural lan-
guage processing are very well trained in machine
learning and statistical methods, they often lack
the necessary background to understand the lin-
guistic motivation behind these formalisms. Fur-
thermore, in many linguistics departments, syntax
is still taught from a purely Chomskian perspec-
tive. Additionally, research on these formalisms
often takes place within tightly-knit, formalism-
specific subcommunities. It is therefore often dif-
ficult for outsiders as well as experts to grasp the
commonalities of and differences between these
formalisms.
</bodyText>
<sectionHeader confidence="0.955867" genericHeader="categories and subject descriptors">
2 Content Overview
</sectionHeader>
<bodyText confidence="0.9998939">
This tutorial overviews basic ideas of TAG/
CCG/LFG/HPSG, and provides attendees with a
comparison of these formalisms from a linguis-
tic and computational point of view. We start
from stating the motivation behind using these ex-
pressive grammar formalisms for NLP, contrast-
ing them with shallow formalisms like context-
free grammars. We introduce a common set of
examples illustrating various linguistic construc-
tions that elude context-free grammars, and reuse
them when introducing each formalism: bounded
and unbounded non-local dependencies that arise
through extraction and coordination, scrambling,
mappings to meaning representations, etc. In the
second half of the tutorial, we explain two key
technologies for wide-coverage NLP with these
grammar formalisms: grammar acquisition and
parsing models. Finally, we show NLP applica-
tions where these expressive grammar formalisms
provide additional benefits.
</bodyText>
<sectionHeader confidence="0.971773" genericHeader="general terms">
3 Tutorial Outline
</sectionHeader>
<listItem confidence="0.9915117">
1. Introduction: Why expressive grammars
2. Introduction to TAG
3. Introduction to CCG
4. Introduction to LFG
5. Introduction to HPSG
6. Inducing expressive grammars from corpora
7. Wide-coverage parsing with expressive
grammars
8. Applications
9. Summary
</listItem>
<sectionHeader confidence="0.997587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9946786875">
Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan
Riezler, Josef van Genabith and Andy Way. 2008.
Wide-Coverage Deep Statistical Parsing using Au-
tomatic Dependency Structure Annotation. Compu-
tational Linguistics, 34(1). pp.81-124, MIT Press.
Yusuke Miyao and Jun’ichi Tsujii. 2008. Feature For-
est Models for Probabilistic HPSG Parsing. Compu-
tational Linguistics, 34(1). pp.35-80, MIT Press.
Julia Hockenmaier and Mark Steedman. 2007. CCG-
bank: A Corpus of CCG Derivations and Depen-
dency Structures Extracted from the Penn Treebank.
Computational Linguistics, 33(3). pp.355-396, MIT
Press.
1
Tutorial Abstracts of ACL 2010, page 1,
Uppsala, Sweden, 11 July 2010. c�2010 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.511037">
<title confidence="0.999827">Wide-coverage NLP with Linguistically Expressive Grammars</title>
<author confidence="0.999894">Julia Hockenmaier Yusuke Miyao</author>
<affiliation confidence="0.999928">Department of Computer Science, National Institute of Informatics yusuke@nii.ac.jp University of Illinois</affiliation>
<email confidence="0.999392">juliahmr@illinois.edu</email>
<author confidence="0.997489">Josef van_Genabith</author>
<affiliation confidence="0.996438333333333">Centre for Next Generation Localisation, School of Computing, Dublin City University</affiliation>
<intro confidence="0.516826">josef@computing.dcu.ie</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Stefan Riezler</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Wide-Coverage Deep Statistical Parsing using Automatic Dependency Structure Annotation.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<pages>81--124</pages>
<publisher>MIT Press.</publisher>
<marker>Cahill, Burke, O’Donovan, Riezler, van Genabith, Way, 2008</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan Riezler, Josef van Genabith and Andy Way. 2008. Wide-Coverage Deep Statistical Parsing using Automatic Dependency Structure Annotation. Computational Linguistics, 34(1). pp.81-124, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Feature Forest Models for Probabilistic HPSG Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<pages>35--80</pages>
<publisher>MIT Press.</publisher>
<marker>Miyao, Tsujii, 2008</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2008. Feature Forest Models for Probabilistic HPSG Parsing. Computational Linguistics, 34(1). pp.35-80, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<booktitle>Tutorial Abstracts of ACL 2010,</booktitle>
<volume>33</volume>
<issue>3</issue>
<pages>355--396</pages>
<publisher>MIT Press.</publisher>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank. Computational Linguistics, 33(3). pp.355-396, MIT Press. Tutorial Abstracts of ACL 2010, page 1,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sweden Uppsala</author>
</authors>
<date>2010</date>
<booktitle>c�2010 Association for Computational Linguistics</booktitle>
<volume>11</volume>
<marker>Uppsala, 2010</marker>
<rawString>Uppsala, Sweden, 11 July 2010. c�2010 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>