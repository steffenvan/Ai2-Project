<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000135">
<title confidence="0.956619">
Inducing Word Senses to Improve Web Search Result Clustering
</title>
<note confidence="0.501208">
Roberto Navigli and Giuseppe Crisafulli
Dipartimento di Informatica
Sapienza Universit`a di Roma
</note>
<email confidence="0.994465">
navigli@di.uniroma1.it, crisafulli.giu@gmail.com
</email>
<sectionHeader confidence="0.995578" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996944">
In this paper, we present a novel approach to
Web search result clustering based on the au-
tomatic discovery of word senses from raw
text, a task referred to as Word Sense Induc-
tion (WSI). We first acquire the senses (i.e.,
meanings) of a query by means of a graph-
based clustering algorithm that exploits cycles
(triangles and squares) in the co-occurrence
graph of the query. Then we cluster the search
results based on their semantic similarity to
the induced word senses. Our experiments,
conducted on datasets of ambiguous queries,
show that our approach improves search result
clustering in terms of both clustering quality
and degree of diversification.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999794731707317">
Over recent years increasingly huge amounts of
text have been made available on the Web. Popular
search engines such as Yahoo! and Google usually
do a good job at retrieving a small number of rel-
evant results from such an enormous collection of
Web pages (i.e. retrieving with high precision, low
recall). However, current search engines are still fac-
ing the lexical ambiguity issue (Furnas et al., 1987)
– i.e. the linguistic property owing to which any
particular word may convey different meanings. In
a recent study (Sanderson, 2008) – conducted us-
ing WordNet (Miller et al., 1990) and Wikipedia as
sources of ambiguous words – it was reported that
around 3% of Web queries and 23% of the most
frequent queries are ambiguous. Examples include:
“buy B-52” (a cocktail? a bomber? a DJ worksta-
tion? tickets for a band?), “Alexander Smith quotes”
(the novelist? the poet?), “beagle search” (dogs? the
Linux search tool? the landing spacecraft?).
Ambiguity is often the consequence of the low
number of query words entered on average by Web
users (Kamvar and Baluja, 2006). While average
query length is increasing – it is now estimated at
around 3 words per query1 – many search engines
such as Google have already started to tackle the
query ambiguity issue by reranking and diversify-
ing their results, so as to prevent Web pages that are
similar to each other from ranking too high on the
list.
In the past few years, Web clustering engines
(Carpineto et al., 2009) have been proposed as a
solution to the lexical ambiguity issue in Web In-
formation Retrieval. These systems group search re-
sults, by providing a cluster for each specific aspect
(i.e., meaning) of the input query. Users can then se-
lect the cluster(s) and the pages therein that best an-
swer their information needs. However, many Web
clustering engines group search results on the ba-
sis of their lexical similarity. For instance, consider
the following snippets returned for the beagle search
query:
</bodyText>
<listItem confidence="0.999455666666667">
1. Beagle is a search tool that ransacks your...
2. ...the beagle disappearing in search of game...
3. Beagle indexes your files and searches...
</listItem>
<bodyText confidence="0.974346">
While snippets 1 and 3 both concern the Linux
search tool, they do not have any content word in
</bodyText>
<footnote confidence="0.9740295">
1http://www.hitwise.com/us/press-center/
press-releases/google-searches-apr-09
</footnote>
<page confidence="0.948516">
116
</page>
<note confidence="0.818306">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 116–126,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999935692307692">
common except our query words. As a result, they
will most likely be assigned to two different clusters.
In this paper we present a novel approach to Web
search result clustering which is based on the auto-
matic discovery of word senses from raw text – a
task referred to as Word Sense Induction (WSI). At
the core of our approach is a graph-based algorithm
that exploits cycles in the co-occurrence graph of
the input query to detect the query’s meanings. Our
experiments on two datasets of ambiguous queries
show that our WSI approach boosts search result
clustering in terms of both clustering quality and de-
gree of diversification.
</bodyText>
<sectionHeader confidence="0.999811" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9990895625">
Web directories. A first, historical solution to
query ambiguity is that of Web directories, that
is taxonomies providing categories to which Web
pages are manually assigned (e.g., the Open Direc-
tory Project – http://dmoz.org). Given a query,
search results are organized by category. This ap-
proach has three main weaknesses: first, it is static,
thus it needs manual updates to cover new pages;
second, it covers only a small portion of the Web;
third, it classifies Web pages based on coarse cate-
gories. This latter feature of Web directories makes
it difficult to distinguish between instances of the
same kind (e.g., pages about artists with the same
surname classified as Arts:Music:Bands and
Artists). While methods for the automatic clas-
sification of Web documents have been proposed
(e.g., (Liu et al., 2005b; Xue et al., 2008)) and some
problems have been effectively tackled (Bennett and
Nguyen, 2009), these approaches are usually super-
vised and still suffer from relying on a predefined
taxonomy of categories.
Semantic Information Retrieval (SIR). A dif-
ferent direction consists of associating explicit se-
mantics (i.e., word senses or concepts) with queries
and documents, that is, performing Word Sense Dis-
ambiguation (WSD, see Navigli (2009)). SIR is per-
formed by indexing and/or searching concepts rather
than terms, thus potentially coping with two linguis-
tic phenomena: expressing a single meaning with
different words (synonymy) and using the same word
to express various different meanings (polysemy).
Over the years, different methods for SIR have been
proposed (Krovetz and Croft, 1992; Voorhees, 1993;
Mandala et al., 1998; Gonzalo et al., 1999; Kim et
al., 2004; Liu et al., 2005a, inter alia). However, con-
trasting results have been reported on the benefits of
these techniques: it has been shown that WSD has
to be very accurate to benefit Information Retrieval
(Sanderson, 1994) – a result that was later debated
(Gonzalo et al., 1999; Stokoe et al., 2003). Also,
it has been reported that WSD has to be very pre-
cise on minority senses and uncommon terms, rather
than on frequent words (Krovetz and Croft, 1992;
Sanderson, 2000).
SIR relies on the existence of a reference dictio-
nary to perform WSD (typically, WordNet) and thus
suffers from its static nature and its inherent paucity
of most proper nouns. This latter problem is partic-
ularly important for Web searches, as users tend to
retrieve more information about named entities (e.g.,
singers, artists, cities) than concepts (e.g., abstract
information about singers or artists).
Search Result Clustering. A more popular ap-
proach to query ambiguity is that of search result
clustering. Typically, given a query, the system starts
from a flat list of text snippets returned from one or
more commonly-available search engines and clus-
ters them on the basis of some notion of textual simi-
larity. At the root of the clustering approach lies van
Rijsbergen’s (1979) cluster hypothesis: “closely as-
sociated documents tend to be relevant to the same
requests”, whereas documents concerning different
meanings of the input query are expected to belong
to different clusters.
Approaches to search result clustering can be
classified as data-centric or description-centric
(Carpineto et al., 2009). The former focus more on
the problem of data clustering than on presenting the
results to the user. A pioneering example is Scat-
ter/Gather (Cutting et al., 1992), which divides the
dataset into a small number of clusters and, after the
selection of a group, performs clustering again and
proceeds iteratively. Developments of this approach
have been proposed which improve on cluster qual-
ity and retrieval performance (Ke et al., 2009). Other
data-centric approaches use agglomerative hierar-
chical clustering (e.g., LASSI (Yoelle Maarek and
Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005)
or exploit link information (Zhang et al., 2008).
Description-centric approaches are, instead, more
</bodyText>
<page confidence="0.99659">
117
</page>
<bodyText confidence="0.999456576923077">
focused on the description to produce for each
cluster of search results. Among the most popular
and successful approaches are those based on suf-
fix trees (Zamir et al., 1997; Zamir and Etzioni,
1998), including later developments (Crabtree et al.,
2005; Bernardini et al., 2009). Other methods in
the literature are based on formal concept analy-
sis (Carpineto and Romano, 2004), singular value
decomposition (Osinski and Weiss, 2005), spectral
clustering (Cheng et al., 2005), spectral geometry
(Liu et al., 2008), link analysis (Gelgi et al., 2007),
and graph connectivity measures (Di Giacomo et al.,
2007). Search result clustering has also been viewed
as a supervised salient phrase ranking task (Zeng et
al., 2004).
Diversification. Another recent research topic
dealing with the query ambiguity issue is diversifi-
cation, which aims to rerank top search results based
on criteria that maximize their diversity. One of the
first examples of diversification algorithms is based
on the use of similarity functions to measure the
diversity among documents and between document
and query (Carbonell and Goldstein, 1998). Other
techniques use conditional probabilities to deter-
mine which document is most different from higher-
ranking ones (Chen and Karger, 2006) or use affinity
ranking (Zhang et al., 2005), based on topic variance
and coverage. More recently, an algorithm called Es-
sential Pages (Swaminathan et al., 2009) has been
proposed to reduce information redundancy and re-
turn Web pages that maximize coverage with respect
to the input query.
Word Sense Induction (WSI). In contrast to the
above approaches, we perform WSI to dynamically
acquire an inventory of senses of the input query.
Instead of performing clustering on the basis of the
surface similarity of Web snippets, we use our in-
duced word senses to group snippets. Very little
work on this topic exists: vector-based WSI was suc-
cessfully shown to improve bag-of-words ad-hoc In-
formation Retrieval (Sch¨utze and Pedersen, 1995)
and preliminary studies (Udani et al., 2005; Chen
et al., 2008) have provided interesting insights into
the use of WSI for Web search result clustering.
A more recent attempt at automatically identify-
ing query meanings is based on the use of hidden
topics (Nguyen et al., 2009). However, in this ap-
proach topics – estimated from a universal dataset –
are query-independent and thus their number needs
to be established beforehand. In contrast, we aim
to cluster snippets based on a dynamic and finer-
grained notion of sense.
</bodyText>
<sectionHeader confidence="0.992334" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.951958">
Web search result clustering is usually performed in
three main steps:
</bodyText>
<listItem confidence="0.996779555555556">
1. Given a query q, a search engine (e.g., Yahoo!) is
used to retrieve a list of results R = (ri, ... , r.);
2. A clustering C = (Co, Ci, ... , Cm) of the results
in R is obtained by means of a clustering algo-
rithm;
3. The clusters in C are optionally labeled with an
appropriate algorithm (e.g., see Zamir and Etzioni
(1998) and Carmel et al. (2009)) for visualization
purposes.
</listItem>
<bodyText confidence="0.927103333333333">
Our key idea is to improve step 2 by means of a
Word Sense Induction algorithm: given a query q,
we first dynamically induce, from a text corpus, the
set of word senses of q (Section 3.1); next, we clus-
ter the Web results on the basis of the word senses
previously induced (Section 3.2).
</bodyText>
<subsectionHeader confidence="0.999622">
3.1 Word Sense Induction
</subsectionHeader>
<bodyText confidence="0.9997662">
Word Sense Induction algorithms are unsupervised
techniques aimed at automatically identifying the
set of senses denoted by a word. These methods in-
duce word senses from text by clustering word oc-
currences based on the idea that a given word –
used in a specific sense – tends to co-occur with the
same neighbouring words (Harris, 1954). Several
approaches to WSI have been proposed in the litera-
ture (see Navigli (2009) for a survey), ranging from
clustering based on context vectors (e.g., Sch¨utze
(1998)) to word clustering (e.g., Lin (1998)) and
co-occurrence graphs (e.g., Widdows and Dorow
(2002)).
Successful approaches such as HyperLex
(V´eronis, 2004) – a graph algorithm based on the
identification of hubs in co-occurrence graphs –
have to cope with a high number of parameters to
be tuned (Agirre et al., 2006). To deal with this
issue we propose two variants of a simple, yet
effective, graph-based algorithm for WSI, that we
</bodyText>
<page confidence="0.992847">
118
</page>
<bodyText confidence="0.994044">
describe hereafter. The algorithm consists of two
steps: graph construction and identification of word
senses.
</bodyText>
<subsectionHeader confidence="0.826812">
3.1.1 Graph construction
</subsectionHeader>
<bodyText confidence="0.999994466666667">
Given a target query q, we build a co-occurrence
graph GQ = (V, E) such that V is a set of context
words related to q and E is the set of undirected
edges, each denoting a co-occurrence between pairs
of words in V . To determine the set of co-occurring
words V , we use the Google Web1T corpus (Brants
and Franz, 2006), a large collection of n-grams (n =
1, ... , 5) – i.e., windows of n consecutive tokens –
occurring in one terabyte of Web documents. First,
for each content word w we collect the total num-
ber c(w) of its occurrences and the number of times
c(w, w0) that w and w0 occur together in any 5-gram
(we include inflected forms in the count); second,
we use the Dice coefficient to determine the strength
of co-occurrence between w and w0:
</bodyText>
<equation confidence="0.9916395">
2c(w, w0)
Dice(w, w0) = c(w) + c(w0). (1)
</equation>
<bodyText confidence="0.999581166666667">
The rationale behind Dice is that dividing by the
sum of total counts of the two words drastically de-
creases the ranking of words that tend to co-occur
frequently with many other words (e.g., new, old,
nice, etc.).
The graph GQ = (V, E) is built as follows:
</bodyText>
<listItem confidence="0.996314875">
• Our initial vertex set V (0) contains all the con-
tent words from the snippet results of query q
(excluding stopwords); then, we add to V (0) the
highest-ranking words co-occurring with q in the
Web1T corpus, i.e., those words w for which
Dice(q, w) &gt; δ (the threshold δ is established ex-
perimentally, see Section 4.1). We set V := V (0)
and E := O.
• For each word w E V (0), we select the high-
est ranking words co-occurring with w in Web1T,
that is those words w0 for which Dice(w, w0) &gt;
δ. We add each of these words to V (note that
some w0 might already be in V (0)) and the
corresponding edge {w, w0} to E with weight
Dice(w, w0). Finally, we remove disconnected
vertices.
</listItem>
<subsectionHeader confidence="0.980706">
3.1.2 Identification of word senses
</subsectionHeader>
<bodyText confidence="0.979559111111111">
The main idea behind our approach is that edges
in the co-occurrence graph participating in cycles
are likely to connect vertices (i.e., words) belonging
to the same meaning component. Specifically, we fo-
cus on cycles of length 3 and 4, called respectively
triangles and squares in graph theory.
For each edge e, we calculate the ratio of triangles
in which e participates:
# triangles e participates in
</bodyText>
<equation confidence="0.96408">
Tri(e) = (2)
</equation>
<bodyText confidence="0.941037333333333">
# triangles e could participate in
where the numerator is the number of cycles of
length 3 in which e = {w, w0} participates, and the
denominator is the total number of neighbours of w
and w0. Similarly, we define a measure Sqr(e) of
the ratio of squares (i.e., cycles of length 4) an edge
e participates in to the number of possible squares e
could potentially participate in:
# squares e participates in
</bodyText>
<equation confidence="0.976926">
Sqr(e) = (3)
</equation>
<bodyText confidence="0.982845857142857">
# squares e could participate in
where the numerator is the number of squares con-
taining e and the denominator is the number of pos-
sible distinct pairs of neighbours of w and w0. If no
triangle (or square) exists for e, the value of the cor-
responding function is set to 0.
In order to disconnect the graph and determine
the meaning components, we remove all the edges
whose Tri (or Sqr) value is below a threshold σ. The
resulting connected components represent the word
senses induced for the query q. Notice that the num-
ber of senses is dynamically chosen based on the co-
occurrence graph and the algorithm’s thresholds.
Our triangular measure is the edge counterpart
of the clustering coefficient (or curvature) for ver-
tices, previously used to perform WSI (Widdows
and Dorow, 2002). However, it is our hunch that
measuring the ratio of squares an edge participates
in provides a stronger clue of how important that
edge is within a meaning component. In Section 4,
we will corroborate this idea with our experiments.
</bodyText>
<subsectionHeader confidence="0.986516">
3.1.3 An example
</subsectionHeader>
<bodyText confidence="0.9993225">
As an example, let q = beagle. Two steps are per-
formed:
</bodyText>
<page confidence="0.990872">
119
</page>
<listItem confidence="0.986532210526316">
1. Graph construction. We build the co-occurrence
graph Gbeagle = (V, E), an excerpt of which is
shown in Figure 1(a).
2. Identification of word senses. We calculate the
Sqr values of each edge in the graph. The edges
e whose Sqr(e) &lt; Q are removed (we assume
Q = 0.25). For instance, Sqr({ dog, breed }) = 1�,
as the edge participates in the square dog – breed
– puppy – canine – dog, but it could also have
participated in the potential square dog – breed
– puppy – search – dog. In fact, the other neigh-
bours of dog are canine, puppy and search, and
the other neighbour of breed is puppy, thus the
square can only be closed by connecting puppy
to either canine or search. In our example, the
only edges whose Sqr is below Q are: { dog,
puppy }, { dog, search } and { linux, mission }
(they participate in no square). We remove these
edges and select the resulting connected compo-
</listItem>
<bodyText confidence="0.831244777777778">
nents as the senses of the query beagle (shown in
Figure 1(b)). Note that, if we selected triangles
as our pruning measure, we should also remove
the following edges { search, index }, { index,
linux }, { linux, system } and { system, search }.
In fact, these edges do not participate in any tri-
angle (while they do participate in a square). As a
result, we would miss the computer science sense
of the query.
</bodyText>
<subsectionHeader confidence="0.99992">
3.2 Clustering of Web results
</subsectionHeader>
<bodyText confidence="0.965947357142857">
Given our query q, we submit it to a search engine,
which returns a list of relevant search results R =
(r1, ... , rr,,). We process each result ri by consid-
ering the corresponding text snippet and transform-
ing it to a bag of words bi (we apply tokenization,
stopwords and target word removal, and lemmatiza-
tion2). For instance, given the snippet:
“the beagle is a breed of medium-sized dog”,
we produce the following bag of words:
{ breed, medium, size, dog }.
As a result of the above processing, we obtain a
list of bags of words B = (b1, ... , b,,,). Now, our
aim is to cluster our Web results R, i.e., the corre-
sponding bags of words B. To this end, rather than
</bodyText>
<footnote confidence="0.874443">
2We use the WordNet lemmatizer.
</footnote>
<figureCaption confidence="0.998434666666667">
Figure 1: The beagle example: (a) graph construction,
“weak” edges (according to Sqr) drawn in bold, (b) the
word senses induced after edge removal.
</figureCaption>
<bodyText confidence="0.995652375">
considering the interrelationships between them (as
is done in traditional search result clustering), we
intersect each bag of words bi E B with the sense
clusters {S1, ... , Sm} acquired as a result of our
Word Sense Induction algorithm (cf. Section 3.1).
The sense cluster with the largest intersection with
bi is selected as the most likely meaning of ri. For-
mally:
</bodyText>
<figure confidence="0.5008605">
|bi ∩ Sj |if max |bi ∩ Sj |&gt; 0
j
0 else
(4)
</figure>
<bodyText confidence="0.982166857142857">
where 0 denotes that no sense is assigned to result ri,
as the intersection is empty for all senses Sj. Oth-
erwise the function returns the index of the sense
having the largest overlap with bi – the bag of words
associated with the search result ri. As a result of
sense assignment for each ri E R, we obtain a clus-
tering C = (C0, C1, ... , Cm) such that:
</bodyText>
<equation confidence="0.863523">
Cj = {ri E R : Sense(ri) = j}, (5)
</equation>
<bodyText confidence="0.9570948">
that is, Cj contains the search results classified with
the j-th sense of query q (C0 includes unassigned
results). Finally, we sort the clusters in our clus-
tering C based on their “quality”. For each cluster
Cj E C \ {C0}, we determine its similarity with
</bodyText>
<figure confidence="0.999147777777778">
canine
canine
puppy
puppy
breed
breed
dog
dog
search
search
index
index
system
system
linux
linux
mission
mission
spacecraft
spacecraft
lander
mars
lander
mars
Sense(ri) _
argmax
j��,...,m
</figure>
<page confidence="0.878528">
120
</page>
<bodyText confidence="0.7940355">
the corresponding meaning Sj by calculating the fol-
lowing formula:
</bodyText>
<equation confidence="0.949324">
avgsim(Cj,Sj) =
</equation>
<bodyText confidence="0.9998632">
The formula determines the average similarity be-
tween the search results in cluster Cj and the corre-
sponding sense cluster Sj. The similarity between a
search result ri and Sj is determined as the normal-
ized overlap between its bag of words bi and Sj:
</bodyText>
<equation confidence="0.9980105">
sim(ri,Sj) = sim(bi,Sj) = |bi ∩ Sj|
|bi |.(7)
</equation>
<bodyText confidence="0.999154285714286">
Finally, we rank the elements ri within each clus-
ter Cj by their similarity sim(ri, Sj). We note that
the ranking and optimality of clusters can be im-
proved with more sophisticated techniques (Crab-
tree et al., 2005; Kurland, 2008; Kurland and
Domshlak, 2008; Lee et al., 2008, inter alia). How-
ever, this is outside the scope of this paper.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996026">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.982114315789474">
Test Sets. We conducted our experiments on two
datasets:
• AMBIENT (AMBIguous ENTries), a recently
released dataset which contains 44 ambiguous
queries3. The sense inventory for the mean-
ings (i.e., subtopics)4 of queries is given by
Wikipedia disambiguation pages. For instance,
given the beagle query, its disambiguation page
in Wikipedia provides the meanings of dog, Mars
lander, computer search service, beer brand, etc.
The top 100 Web results of each query returned
by the Yahoo! search engine were tagged with
the most appropriate query senses according to
Wikipedia (amounting to 4400 sense-annotated
search results). To our knowledge, this is cur-
rently the largest dataset of ambiguous queries
available on-line. Other datasets, such as those
from the TREC competitions, are not focused on
distiguishing the subtopics of a query.
</bodyText>
<footnote confidence="0.986802666666667">
3http://credo.fub.it/ambient
4In the following, we use the terms subtopic and word sense
interchangeably.
</footnote>
<table confidence="0.998452">
dataset queries queries by length avg.
polys.
1 2 3 4
AMBIENT 44 35 6 3 0 17.9
MORESQUE 114 0 47 36 31 6.7
</table>
<tableCaption confidence="0.9997">
Table 1: Statistics on the datasets of ambiguous queries.
</tableCaption>
<listItem confidence="0.8505932">
• MORESQUE (MORE Sense-tagged QUEry re-
sults), a new dataset of 114 ambiguous queries
which we developed as a complement to AMBI-
ENT following the guidelines provided by its au-
thors. In fact, our aim was to study the behaviour
of Web search algorithms on queries of differ-
ent lengths, ranging from 1 to 4 words. How-
ever, the AMBIENT dataset is composed mostly
of single-word queries. MORESQUE provides
dozens of queries of length 2, 3 and 4, together
</listItem>
<bodyText confidence="0.992035896551724">
with the 100 top results from Yahoo! for each
query annotated as in the AMBIENT dataset
(overall, we tagged 11,400 snippets). We decided
to carry on using Yahoo! mainly for homogeneity
reasons.
We report the statistics on the composition of the
two datasets in Table 1. Given that the snippets could
possibly be annotated with more than one Wikipedia
subtopic, we also determined the average number
of subtopics per snippet. This amounted to 1.01 for
AMBIENT and 1.04 for MORESQUE for snippets
with at least one subtopic annotation (51% and 53%
of the respective datasets). We can thus conclude
that multiple subtopic annotations are infrequent.
Parameters. Our graph-based algorithms have
two parameters: the Dice threshold δ for graph
construction (Section 3.1.1) and the threshold σ
for edge removal (Section 3.1.2). The best pa-
rameters, used throughout our experiments, were
(δ = 0.00033, σ = 0.45) with triangles and (δ =
0.00033, σ = 0.33) with squares. The parameter
values were obtained as a result of tuning on a small
in-house development dataset. The dataset was built
by automatically identifying monosemous words
and creating pseudowords following the scheme
proposed by Sch¨utze (1998).
Systems. We compared Triangles and Squares
against the best systems reported by Bernardini et
al. (2009, cf. Section 2):
</bodyText>
<equation confidence="0.9728828">
E
rzEC; si
. (6)
|Cj|
m(ri, Sj)
</equation>
<page confidence="0.985797">
121
</page>
<listItem confidence="0.988178">
• Lingo (Osinski and Weiss, 2005): a Web clus-
tering engine implemented in the Carrot2 open-
source framework5 that clusters the most frequent
phrases extracted using suffix arrays.
• Suffix Tree Clustering (STC) (Zamir and Et-
zioni, 1998): the original Web search clustering
approach based on suffix trees.
• KeySRC (Bernardini et al., 2009): a state-of-the-
art Web clustering engine built on top of STC with
part-of-speech pruning and dynamic selection of
the cut-off level of the clustering dendrogram.
• Essential Pages (EP) (Swaminathan et al., 2009):
a recent diversification algorithm that selects fun-
damental pages which maximize the amount of
information covered for a given query.
• Yahoo!: the original search results returned by
the Yahoo! search engine.
</listItem>
<bodyText confidence="0.999782">
The first three of the above are Web search result
clustering approaches, whereas the last two produce
lists of possibly diversified results (cf. Section 2).
</bodyText>
<subsectionHeader confidence="0.983316">
4.2 Experiment 1: Clustering Quality
</subsectionHeader>
<bodyText confidence="0.999788166666667">
Measure. While assessing the quality of cluster-
ing is a notably hard problem, given a gold standard
!g we can calculate the Rand index (RI) of a cluster-
ing C, a common quality measure in the literature,
determined as follows (Rand, 1971; Manning et al.,
2008):
</bodyText>
<equation confidence="0.9977565">
�(w,w�)∈W×W,w6=w�δ(w, w0)
RI(C) = |{(w, w0) � W � W : w =� w0} |(8)
</equation>
<bodyText confidence="0.999859">
where W is the union set of all the words in C and
δ(w, w0) = 1 if any two words w and w0 are in the
same cluster both in C and in the gold standard !9 or
they are in two different clusters in both C and !g,
otherwise δ(w, w0) = 0. In other words, we calcu-
late the percentage of word pairs that are in the same
configuration in both C and !g. For the gold standard
!g we use the clustering induced by the sense annota-
tions provided in our datasets for each snippet (i.e.,
each cluster contains the snippets manually associ-
ated with a particular Wikipedia subtopic). Similarly
to what was done in Section 3.2, untagged results are
grouped together in a special cluster of !g.
</bodyText>
<footnote confidence="0.988571">
5http://project.carrot2.org
</footnote>
<table confidence="0.999258166666667">
System AMBIENT MORESQUE All
Squares 72.59 65.41 67.28
Triangles 66.13 64.47 64.93
Lingo 62.75 52.68 55.49
STC 61.48 51.52 54.29
KeySRC 66.49 55.82 58.78
</table>
<tableCaption confidence="0.999848">
Table 2: Results by Rand index (percentages).
</tableCaption>
<bodyText confidence="0.999462444444445">
Results. The results of all systems on the AM-
BIENT and MORESQUE datasets according to
the average Rand index are shown in Table 26.
In accordance with previous results in the litera-
ture, KeySRC performed generally better than the
other search result clustering systems, especially
on smaller queries. Our Word Sense Induction sys-
tems, Squares and Triangles, outperformed all other
systems by a large margin, thus showing a higher
clustering quality (with the exception of KeySRC
performing better than Triangles on AMBIENT).
Interestingly, all clustering systems perform more
poorly on longer queries (i.e., on the MORESQUE
dataset), however our WSI systems, and especially
Triangles, are more robust across query lengths.
Compared to Triangles, the Squares algorithm per-
forms better, confirming our hunch that Squares is a
more solid graph pattern.
</bodyText>
<subsectionHeader confidence="0.99741">
4.3 Experiment 2: Diversification
</subsectionHeader>
<bodyText confidence="0.999647857142857">
Measure. Search result clustering can also be used
to diversify the top results returned by a search en-
gine. Thus, for each query q, one natural way of
measuring a system’s performance is to calculate the
subtopic recall-at-K (Zhai et al., 2003) given by the
number of different subtopics retrieved for q in the
top K results returned:
</bodyText>
<equation confidence="0.997279666666667">
UK i subtopics(ri)|
S-recall@K = i= (9)
M
</equation>
<bodyText confidence="0.999936">
where subtopics(ri) is the set of subtopics manually
assigned to the search result ri and M is the number
of subtopics for query q (note that in our experiments
M is the number of subtopics occurring in the 100
results retrieved for q, so S-recall@100 = 1). How-
ever, this measure is only suitable for systems re-
turning ranked lists (such as Yahoo! and EP). Given
</bodyText>
<footnote confidence="0.981926">
6For reference systems we used the implementations of
Bernardini et al. (2009) and Osinski and Weiss (2005).
</footnote>
<page confidence="0.986172">
122
</page>
<table confidence="0.999810333333333">
System K=3 K=5 K=10 K=15 K=20
Squares 51.9 63.4 75.8 83.3 87.4
Triangles 50.8 62.4 75.2 82.7 86.6
Yahoo! 49.2 60.0 72.9 78.5 82.7
EP 40.6 53.2 68.6 77.2 83.3
KeySRC 44.3 55.8 72.0 79.1 83.2
</table>
<tableCaption confidence="0.999928">
Table 3: S-recall@K on all queries (percentages).
</tableCaption>
<bodyText confidence="0.999899789473684">
a clustering C = (Co, Ci, ... , Cm), we flatten it to a
list as follows: we add to the initially empty list the
first element of each cluster Cj (j = 1, ... , m); then
we iterate the process by selecting the second ele-
ment of each cluster Cj such that |Cj |&gt; 2, and so
on. The remaining elements returned by the search
engine, but not included in any cluster of C \ {Co},
are appended to the bottom of the list in their orig-
inal order. Note that the elements are selected from
each cluster according to their internal ranking (e.g.,
for our algorithms we use Formula 7 introduced in
Section 3.2).
Results. For the sake of clarity and to save space,
we selected the best systems from our previous ex-
periment, namely Squares, Triangles and KeySRC,
and compared their output with the original snippet
list returned by Yahoo! and the output of the EP di-
versification algorithm (cf. Section 4.1).
The S-recall@K (with K = 3, 5,10,15, 20) cal-
culated on AMBIENT+MORESQUE is reported
in Table 3. Squares and Triangles show the high-
est degree of diversification, with a subtopic recall
greater than all other systems, and with Squares con-
sistently performing better than Triangles. It is inter-
esting to observe that KeySRC performs worse than
Yahoo! with low values of K and generally better
with higher values of K.
Given that the two datasets complement each
other in terms of query lengths (with AMBIENT
having queries of length G 2 and MORESQUE
with many queries of length &gt; 3), we studied the S-
recall@K trend for the two datasets. The results are
shown in Figures 2 and 3. While KeySRC does not
show large differences in the presence of short and
long ambiguous queries, our graph-based algorithms
do. For instance, as soon as K = 3 the Squares al-
gorithm obtains S-recall values of 37% and 57.5%
on AMBIENT and MORESQUE, respectively. The
</bodyText>
<figure confidence="0.99776875">
10 20 30 40 50 60 70 80 90 100
number of results K
10 20 30 40 50 60 70 80 90 100
number of results K
</figure>
<figureCaption confidence="0.999984">
Figure 3: S-recall@K on MORESQUE.
</figureCaption>
<bodyText confidence="0.999753">
difference decreases as K increases, but is still sig-
nificant when K = 10. We hypothesize that, because
they are less ambiguous, longer queries are easier
to diversify with the aid of WSI. However, we note
that, even with low values of K, Squares and Tri-
angles obtain higher S-recall than the other systems
(with KeySRC competing on AMBIENT when K G
15). Finally, we observe that – with low values of K
– the Squares algorithm performs significantly better
than Triangles on shorter queries, and only slightly
better on longer ones.
</bodyText>
<sectionHeader confidence="0.998709" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999858666666667">
Results. Our results show that our graph-based al-
gorithms are able to consistently produce clusters of
better quality than all other systems tested in our
experiments. The results on S-recall@K show that
our approach can also be used effectively as a diver-
sification technique, performing better than a very
</bodyText>
<figure confidence="0.981006875">
Squares
Triangles
Yahoo!
EP
Keysrc
Figure 2: Results by S-recall@K on AMBIENT.
S-recall-at-K
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
1
Squares
Triangles
Yahoo!
EP
Keysrc
S-recall-at-K 1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
</figure>
<page confidence="0.997279">
123
</page>
<bodyText confidence="0.999974138888889">
recent proposal such as Essential Pages. The lat-
ter outperforms Yahoo! and KeySRC when K &gt;
30 on AMBIENT, whereas on MORESQUE it per-
forms generally worse until higher values of K are
reached. If we analyze the entire dataset of 158
queries by length, EP works best after examining at
least 20 results on 1- and 2-word ambiguous queries,
whereas on longer queries a larger number of docu-
ments (&gt; 30) needs to be analyzed before surpassing
Yahoo! performance.
The above considerations might not seem intu-
itive at first glance, as the average polysemy of
longer queries is lower (17.9 on AMBIENT vs. 6.7
on MORESQUE according to our gold standard).
However, we note that while the kind of ambigu-
ity of 1-word queries is generally coarser (e.g., bea-
gle as dog vs. lander vs. search tool), with longer
queries we often encounter much finer sense distinc-
tions (e.g., Across the Universe as song by The Bea-
tles vs. a 2007 film based on the song vs. a Star Trek
novel vs. a rock album by Trip Shakespeare, etc.).
Word Sense Induction is able to deal better with this
latter kind of ambiguity as discriminative words be-
come part of the meanings acquired.
Performance issues. Inducing word senses from
the query graph comes at a higher computational
cost than other non-semantic clustering techniques.
Indeed, the most time-consuming phase of our ap-
proach is the construction of the query graph, which
requires intensive querying of our database of co-
occurrences calculated from the Web1T corpus.
While graphs can be precomputed or cached, previ-
ously unseen queries will still require the construc-
tion of new graphs. Instead, triangles and squares, as
well as the resulting connected components, can be
calculated on the fly.
</bodyText>
<sectionHeader confidence="0.996556" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9993738125">
In this paper we have presented a novel approach
to Web search result clustering. Our key idea is to
induce senses for the target query automatically by
means of a graph-based algorithm focused on the
notion of cycles. The results of a Web search engine
are then mapped to the query senses and clustered
accordingly.
The paper provides three novel contributions.
First, we show that WSI boosts the quality of search
result clustering and improves the diversification of
the snippets returned as a flat list. We provide a clear
indication on the usefulness of a loose notion of
sense to cope with ambiguous queries. This is in
contrast to research on Semantic Information Re-
trieval, which has obtained contradictory and often
inconclusive results. The main advantage of WSI
lies in its dynamic production of word senses that
cover both concepts (e.g., beagle as a breed of dog)
and instances (e.g., beagle as a specific instance of
a space lander). In contrast, static dictionaries such
as WordNet – typically used in Word Sense Dis-
ambiguation – by their very nature encode mainly
concepts. Second, we propose two simple, yet ef-
fective, graph algorithms to induce the senses of
our queries. The best performing approach is based
on squares (cycles of length 4), a novel graph pat-
tern in WSI. Third, we contribute a new dataset of
114 ambiguous queries and 11,400 sense-annotated
snippets which complements an existing dataset of
ambiguous queries7. Given the lack of ambiguous
query datasets available (Sanderson, 2008), we hope
our new dataset will be useful in future compara-
tive experiments. Finally, we note that our approach
needed very little tuning. Moreover, its requirement
of a Web corpus of n-grams is not a stringent one, as
such corpora are available for several languages and
can be produced for any language of interest.
As regards future work, we intend to combine
our clustering algorithm with a cluster labeling al-
gorithm. We also aim to implement a number of
Word Sense Induction algorithms and compare them
in the same evaluation framework with more Web
search and Web clustering engines. Finally, it should
be possible to use precisely the same approach pre-
sented in this paper for document clustering, by
grouping the contexts in which the target query oc-
curs – and we will also experiment on this in the
future.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999796">
We thank Google for providing the Web1T corpus
for research purposes. We also thank Massimiliano
D’Amico for producing the output of KeySRC and
EP, and Stanislaw Osinski and Dawid Weiss for their
</bodyText>
<footnote confidence="0.9987145">
7The MORESQUE dataset is available at the following
URL: http://lcl.uniroma1.it/moresque
</footnote>
<page confidence="0.99648">
124
</page>
<bodyText confidence="0.991659">
help with Lingo and STC. Additional thanks go to
Jim McManus, Senja Pollak and the anonymous re-
viewers for their useful comments.
</bodyText>
<sectionHeader confidence="0.989243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999840969072165">
Eneko Agirre, David Martinez, Oier L´opez de Lacalle,
and Aitor Soroa. 2006. Evaluating and optimizing
the parameters of an unsupervised graph-based WSD
algorithm. In Proc. of TextGraphs ’06, pages 89–96,
New York, USA.
Paul N. Bennett and Nam Nguyen. 2009. Refined ex-
perts: improving classification in large taxonomies. In
Proc. of SIGIR ’09, pages 11–18, Boston, MA, USA.
Andrea Bernardini, Claudio Carpineto, and Massimil-
iano D’Amico. 2009. Full-subtopic retrieval with
keyphrase-based search results clustering. In Proc. of
WI ’09, pages 206–213, Milan, Italy.
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram,
ver. 1, ldc2006t13. In LDC, PA, USA.
Jaime Carbonell and Jade Goldstein. 1998. The use of
mmr, diversity-based reranking for reordering docu-
ments and producing summaries. In Proc. of SIGIR
’98, pages 335–336, Melbourne, Australia.
David Carmel, Haggai Roitman, and Naama Zwerdling.
2009. Enhancing cluster labeling using Wikipedia. In
Proc. of SIGIR ’09, pages 139–146, MA, USA.
Claudio Carpineto and Giovanni Romano. 2004. Ex-
ploiting the potential of concept lattices for informa-
tion retrieval with CREDO. Journal of Universal
Computer Science, 10(8):985–1013.
Claudio Carpineto, Stanislaw Osi´nski, Giovanni Ro-
mano, and Dawid Weiss. 2009. A survey of web clus-
tering engines. ACM Computing Surveys, 41(3):1–38.
Harr Chen and David R. Karger. 2006. Less is more:
probabilistic models for retrieving fewer relevant doc-
uments. In Proc. of SIGIR ’06, pages 429–436, Seat-
tle, WA, USA.
Jiyang Chen, Osmar R. Za¨ıane, and Randy Goebel. 2008.
An unsupervised approach to cluster web search re-
sults based on word sense communities. In Proc. of
WI-IAT 2008, pages 725–729, Sydney, Australia.
David Cheng, Santosh Vempala, Ravi Kannan, and Grant
Wang. 2005. A divide-and-merge methodology for
clustering. In Proc. of PODS ’05, pages 196–205,
New York, NY, USA.
Daniel Crabtree, Xiaoying Gao, and Peter Andreae.
2005. Improving web clustering by cluster selec-
tion. In Proc. of WI ’05, pages 172–178, Compi`egne,
France.
Douglass R. Cutting, David R. Karger, Jan O. Pedersen,
and John W. Tukey. 1992. Scatter/gather: A cluster-
based approach to browsing large document collec-
tions. In Proc. of SIGIR ’92, pages 318–329, Copen-
hagen, Denmark.
Emilio Di Giacomo, Walter Didimo, Luca Grilli, and
Giuseppe Liotta. 2007. Graph visualization tech-
niques for web clustering engines. IEEE Transactions
on Visualization and Computer Graphics, 13(2):294–
304.
George W. Furnas, Thomas K. Landauer, Louis Gomez,
and Susan Dumais. 1987. The vocabulary problem
in human-system communication. Communications of
the ACM, 30(11):964–971.
Fatih Gelgi, Hasan Davulcu, and Srinivas Vadrevu. 2007.
Term ranking for clustering web search results. In
Proc. of WebDB ’07, Beijing, China.
Julio Gonzalo, Anselmo Penas, and Felisa Verdejo. 1999.
Lexical ambiguity and Information Retrieval revisited.
In Proc. of EMNLP/VLC 1999, pages 195–202, Col-
lege Park, MD, USA.
Zellig Harris. 1954. Distributional structure. Word,
10:146–162.
Maryam Kamvar and Shumeet Baluja. 2006. A large
scale study of wireless search behavior: Google mo-
bile search. In Proc. of CHI ’06, pages 701–709, New
York, NY, USA.
Weimao Ke, Cassidy R. Sugimoto, and Javed Mostafa.
2009. Dynamicity vs. effectiveness: studying online
clustering for scatter/gather. In Proc. of SIGIR ’09,
pages 19–26, MA, USA.
Sang-Bum Kim, Hee-Cheol Seo, and Hae-Chang Rim.
2004. Information Retrieval using word senses: root
sense tagging approach. In Proc. of SIGIR ’04, pages
258–265, Sheffield, UK.
Robert Krovetz and William B. Croft. 1992. Lexical am-
biguity and Information Retrieval. ACM Transactions
on Information Systems, 10(2):115–141.
Oren Kurland and Carmel Domshlak. 2008. A rank-
aggregation approach to searching for optimal query-
specific clusters. In Proc. of SIGIR ’08, pages 547–
554, Singapore.
Oren Kurland. 2008. The opposite of smoothing: a lan-
guage model approach to ranking query-specific doc-
ument clusters. In Proc. of SIGIR ’08, pages 171–178,
Singapore.
Kyung Soon Lee, W. Bruce Croft, and James Allan.
2008. A cluster-based resampling method for pseudo-
relevance feedback. In Proc. of SIGIR ’08, pages 235–
242, Singapore.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In Proc. of the 171h COLING, pages
768–774, Montreal, Canada.
</reference>
<page confidence="0.981361">
125
</page>
<reference confidence="0.999872142857143">
Shuang Liu, Clement Yu, and Weiyi Meng. 2005a. Word
Sense Disambiguation in queries. In Proc. of CIKM
’05, pages 525–532, Bremen, Germany.
Tie-Yan Liu, Yiming Yang, Hao Wan, Hua-Jun Zeng,
Zheng Chen, and Wei-Ying Ma. 2005b. Support vec-
tor machines classification with a very large-scale tax-
onomy. SIGKDD Explor. Newsl., 7(1):36–43.
Ying Liu, Wenyuan Li, Yongjing Lin, and Liping Jing.
2008. Spectral geometry for simultaneously clustering
and ranking query search results. In Proc. of SIGIR
’08, pages 539–546, Singapore.
Rila Mandala, Takenobu Tokunaga, and Hozumi Tanaka.
1998. The use of WordNet in Information Retrieval.
In Proc. of the COLING-ACL workshop on Usage of
Wordnet in Natural Language Processing, pages 31–
37, Montreal, Canada.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Sch¨utze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, New York, NY,
USA.
George A. Miller, Richard T. Beckwith, Christiane D.
Fellbaum, Derek Gross, and Katherine Miller. 1990.
WordNet: an online lexical database. International
Journal of Lexicography, 3(4):235–244.
Roberto Navigli. 2009. Word Sense Disambiguation: a
survey. ACM Computing Surveys, 41(2):1–69.
Chi Lang Ngo and Hung Son Nguyen. 2005. A method
of web search result clustering based on rough sets. In
Proc. of WI ’05, pages 673–679, Compi`egne, France.
Cam-Tu Nguyen, Xuan-Hieu Phan, Susumu Horiguchi,
Thu-Trang Nguyen, and Quang-Thuy Ha. 2009.
Web search clustering and labeling with hidden top-
ics. ACM Transactions on Asian Language Informa-
tion Processing, 8(3):1–40.
Stanislaw Osinski and Dawid Weiss. 2005. A concept-
driven algorithm for clustering search results. IEEE
Intelligent Systems, 20(3):48–54.
William M. Rand. 1971. Objective criteria for the eval-
uation of clustering methods. Journal of the American
Statistical Association, 66(336):846–850.
Mark Sanderson. 1994. Word Sense Disambiguation
and Information Retrieval. In Proc. of SIGIR ’94,
pages 142–151, Dublin, Ireland.
Mark Sanderson. 2000. Retrieving with good sense. In-
formation Retrieval, 2(1):49–69.
Mark Sanderson. 2008. Ambiguous queries: test collec-
tions need more sense. In Proc. of SIGIR ’08, pages
499–506, Singapore.
Hinrich Sch¨utze and Jan Pedersen. 1995. Information
Retrieval based on word senses. In Proceedings of
SDAIR’95, pages 161–175, Las Vegas, Nevada, USA.
Hinrich Sch¨utze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97–124.
Christopher Stokoe, Michael J. Oakes, and John I. Tait.
2003. Word Sense Disambiguation in Information Re-
trieval revisited. In Proc. of SIGIR ’03, pages 159–
166, Canada.
Ashwin Swaminathan, Cherian V. Mathew, and Darko
Kirovski. 2009. Essential pages. In Proc. of WI ’09,
pages 173–182, Milan, Italy.
Goldee Udani, Shachi Dave, Anthony Davis, and Tim
Sibley. 2005. Noun sense induction using web search
results. In Proc. of SIGIR ’05, pages 657–658, Sal-
vador, Brazil.
Cornelis Joost van Rijsbergen. 1979. Information Re-
trieval. Butterworths, second edition.
Jean V´eronis. 2004. HyperLex: lexical cartography
for Information Retrieval. Computer Speech and Lan-
guage, 18(3):223–252.
Ellen M. Voorhees. 1993. Using WordNet to disam-
biguate word senses for text retrieval. In Proc. of SI-
GIR ’93, pages 171–180, Pittsburgh, PA, USA.
Dominic Widdows and Beate Dorow. 2002. A graph
model for unsupervised lexical acquisition. In Proc.
of the 191h COLING, pages 1–7, Taipei, Taiwan.
Gui-Rong Xue, Dikan Xing, Qiang Yang, and Yong Yu.
2008. Deep classification in large-scale text hierar-
chies. In Proc. of SIGIR ’08, pages 619–626, Singa-
pore.
Israel Ben-Shaul Yoelle Maarek, Ron Fagin and Dan Pel-
leg. 2000. Ephemeral document clustering for web
applications. IBM Research Report RJ 10186.
Oren Zamir and Oren Etzioni. 1998. Web document
clustering: a feasibility demonstration. In Proc. of SI-
GIR ’98, pages 46–54, Melbourne, Australia.
Oren Zamir, Oren Etzioni, Omid Madani, and Richard M.
Karp. 1997. Fast and intuitive clustering of web docu-
ments. In Proc. of KDD ’97, pages 287–290, Newport
Beach, California.
Hua-Jun Zeng, Qi-Cai He, Zheng Chen, Wei-Ying Ma,
and Jinwen Ma. 2004. Learning to cluster web
search results. In Proc. of SIGIR ’04, pages 210–217,
Sheffield, UK.
ChengXiang Zhai, William W. Cohen, and John Lafferty.
2003. Beyond independent relevance: Methods and
evaluation metrics for subtopic retrieval. In Proc. of
SIGIR ’03, pages 10–17, Toronto, Canada.
Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Weiguo
Fan, Zheng Chen, and Wei-Ying Ma. 2005. Improv-
ing web search results using affinity graph. In Proc. of
SIGIR ’05, pages 504–511, Salvador, Brazil.
Xiaodan Zhang, Xiaohua Hu, and Xiaohua Zhou. 2008.
A comparative evaluation of different link types on en-
hancing document clustering. In Proc. of SIGIR ’08,
pages 555–562, Singapore.
</reference>
<page confidence="0.998529">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.680240">
<title confidence="0.963015">Inducing Word Senses to Improve Web Search Result Clustering Navigli</title>
<author confidence="0.8308555">Dipartimento di_Sapienza Universit`a di</author>
<email confidence="0.973746">navigli@di.uniroma1.it,crisafulli.giu@gmail.com</email>
<abstract confidence="0.9995151875">In this paper, we present a novel approach to Web search result clustering based on the automatic discovery of word senses from raw text, a task referred to as Word Sense Induction (WSI). We first acquire the senses (i.e., meanings) of a query by means of a graphbased clustering algorithm that exploits cycles (triangles and squares) in the co-occurrence graph of the query. Then we cluster the search results based on their semantic similarity to the induced word senses. Our experiments, conducted on datasets of ambiguous queries, show that our approach improves search result clustering in terms of both clustering quality and degree of diversification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>David Martinez</author>
<author>Oier L´opez de Lacalle</author>
<author>Aitor Soroa</author>
</authors>
<title>Evaluating and optimizing the parameters of an unsupervised graph-based WSD algorithm.</title>
<date>2006</date>
<booktitle>In Proc. of TextGraphs ’06,</booktitle>
<pages>89--96</pages>
<location>New York, USA.</location>
<marker>Agirre, Martinez, de Lacalle, Soroa, 2006</marker>
<rawString>Eneko Agirre, David Martinez, Oier L´opez de Lacalle, and Aitor Soroa. 2006. Evaluating and optimizing the parameters of an unsupervised graph-based WSD algorithm. In Proc. of TextGraphs ’06, pages 89–96, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul N Bennett</author>
<author>Nam Nguyen</author>
</authors>
<title>Refined experts: improving classification in large taxonomies.</title>
<date>2009</date>
<booktitle>In Proc. of SIGIR ’09,</booktitle>
<pages>11--18</pages>
<location>Boston, MA, USA.</location>
<contexts>
<context position="4938" citStr="Bennett and Nguyen, 2009" startWordPosition="791" endWordPosition="794">his approach has three main weaknesses: first, it is static, thus it needs manual updates to cover new pages; second, it covers only a small portion of the Web; third, it classifies Web pages based on coarse categories. This latter feature of Web directories makes it difficult to distinguish between instances of the same kind (e.g., pages about artists with the same surname classified as Arts:Music:Bands and Artists). While methods for the automatic classification of Web documents have been proposed (e.g., (Liu et al., 2005b; Xue et al., 2008)) and some problems have been effectively tackled (Bennett and Nguyen, 2009), these approaches are usually supervised and still suffer from relying on a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (</context>
</contexts>
<marker>Bennett, Nguyen, 2009</marker>
<rawString>Paul N. Bennett and Nam Nguyen. 2009. Refined experts: improving classification in large taxonomies. In Proc. of SIGIR ’09, pages 11–18, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Bernardini</author>
<author>Claudio Carpineto</author>
<author>Massimiliano D’Amico</author>
</authors>
<title>Full-subtopic retrieval with keyphrase-based search results clustering.</title>
<date>2009</date>
<booktitle>In Proc. of WI ’09,</booktitle>
<pages>206--213</pages>
<location>Milan, Italy.</location>
<marker>Bernardini, Carpineto, D’Amico, 2009</marker>
<rawString>Andrea Bernardini, Claudio Carpineto, and Massimiliano D’Amico. 2009. Full-subtopic retrieval with keyphrase-based search results clustering. In Proc. of WI ’09, pages 206–213, Milan, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<journal>Web</journal>
<booktitle>In LDC,</booktitle>
<volume>1</volume>
<pages>2006--13</pages>
<location>PA, USA.</location>
<contexts>
<context position="12692" citStr="Brants and Franz, 2006" startWordPosition="2053" endWordPosition="2056"> of parameters to be tuned (Agirre et al., 2006). To deal with this issue we propose two variants of a simple, yet effective, graph-based algorithm for WSI, that we 118 describe hereafter. The algorithm consists of two steps: graph construction and identification of word senses. 3.1.1 Graph construction Given a target query q, we build a co-occurrence graph GQ = (V, E) such that V is a set of context words related to q and E is the set of undirected edges, each denoting a co-occurrence between pairs of words in V . To determine the set of co-occurring words V , we use the Google Web1T corpus (Brants and Franz, 2006), a large collection of n-grams (n = 1, ... , 5) – i.e., windows of n consecutive tokens – occurring in one terabyte of Web documents. First, for each content word w we collect the total number c(w) of its occurrences and the number of times c(w, w0) that w and w0 occur together in any 5-gram (we include inflected forms in the count); second, we use the Dice coefficient to determine the strength of co-occurrence between w and w0: 2c(w, w0) Dice(w, w0) = c(w) + c(w0). (1) The rationale behind Dice is that dividing by the sum of total counts of the two words drastically decreases the ranking of </context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram, ver. 1, ldc2006t13. In LDC, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of mmr, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proc. of SIGIR ’98,</booktitle>
<pages>335--336</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="9115" citStr="Carbonell and Goldstein, 1998" startWordPosition="1441" endWordPosition="1444">metry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditional probabilities to determine which document is most different from higherranking ones (Chen and Karger, 2006) or use affinity ranking (Zhang et al., 2005), based on topic variance and coverage. More recently, an algorithm called Essential Pages (Swaminathan et al., 2009) has been proposed to reduce information redundancy and return Web pages that maximize coverage with respect to the input query. Word Sense Induction (WSI). In contrast to the above approaches, we perform WSI to dynamically acquire an inventory of senses of the input query. Instead of performing</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proc. of SIGIR ’98, pages 335–336, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Carmel</author>
<author>Haggai Roitman</author>
<author>Naama Zwerdling</author>
</authors>
<title>Enhancing cluster labeling using Wikipedia.</title>
<date>2009</date>
<booktitle>In Proc. of SIGIR ’09,</booktitle>
<pages>139--146</pages>
<location>MA, USA.</location>
<contexts>
<context position="10951" citStr="Carmel et al. (2009)" startWordPosition="1753" endWordPosition="1756">rsal dataset – are query-independent and thus their number needs to be established beforehand. In contrast, we aim to cluster snippets based on a dynamic and finergrained notion of sense. 3 Approach Web search result clustering is usually performed in three main steps: 1. Given a query q, a search engine (e.g., Yahoo!) is used to retrieve a list of results R = (ri, ... , r.); 2. A clustering C = (Co, Ci, ... , Cm) of the results in R is obtained by means of a clustering algorithm; 3. The clusters in C are optionally labeled with an appropriate algorithm (e.g., see Zamir and Etzioni (1998) and Carmel et al. (2009)) for visualization purposes. Our key idea is to improve step 2 by means of a Word Sense Induction algorithm: given a query q, we first dynamically induce, from a text corpus, the set of word senses of q (Section 3.1); next, we cluster the Web results on the basis of the word senses previously induced (Section 3.2). 3.1 Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a given word – used in a spe</context>
</contexts>
<marker>Carmel, Roitman, Zwerdling, 2009</marker>
<rawString>David Carmel, Haggai Roitman, and Naama Zwerdling. 2009. Enhancing cluster labeling using Wikipedia. In Proc. of SIGIR ’09, pages 139–146, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Carpineto</author>
<author>Giovanni Romano</author>
</authors>
<title>Exploiting the potential of concept lattices for information retrieval with CREDO.</title>
<date>2004</date>
<journal>Journal of Universal Computer Science,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="8373" citStr="Carpineto and Romano, 2004" startWordPosition="1330" endWordPosition="1333">a-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is ba</context>
</contexts>
<marker>Carpineto, Romano, 2004</marker>
<rawString>Claudio Carpineto and Giovanni Romano. 2004. Exploiting the potential of concept lattices for information retrieval with CREDO. Journal of Universal Computer Science, 10(8):985–1013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Carpineto</author>
<author>Stanislaw Osi´nski</author>
<author>Giovanni Romano</author>
<author>Dawid Weiss</author>
</authors>
<title>A survey of web clustering engines.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>3</issue>
<marker>Carpineto, Osi´nski, Romano, Weiss, 2009</marker>
<rawString>Claudio Carpineto, Stanislaw Osi´nski, Giovanni Romano, and Dawid Weiss. 2009. A survey of web clustering engines. ACM Computing Surveys, 41(3):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harr Chen</author>
<author>David R Karger</author>
</authors>
<title>Less is more: probabilistic models for retrieving fewer relevant documents.</title>
<date>2006</date>
<booktitle>In Proc. of SIGIR ’06,</booktitle>
<pages>429--436</pages>
<location>Seattle, WA, USA.</location>
<contexts>
<context position="9257" citStr="Chen and Karger, 2006" startWordPosition="1462" endWordPosition="1465">also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditional probabilities to determine which document is most different from higherranking ones (Chen and Karger, 2006) or use affinity ranking (Zhang et al., 2005), based on topic variance and coverage. More recently, an algorithm called Essential Pages (Swaminathan et al., 2009) has been proposed to reduce information redundancy and return Web pages that maximize coverage with respect to the input query. Word Sense Induction (WSI). In contrast to the above approaches, we perform WSI to dynamically acquire an inventory of senses of the input query. Instead of performing clustering on the basis of the surface similarity of Web snippets, we use our induced word senses to group snippets. Very little work on this</context>
</contexts>
<marker>Chen, Karger, 2006</marker>
<rawString>Harr Chen and David R. Karger. 2006. Less is more: probabilistic models for retrieving fewer relevant documents. In Proc. of SIGIR ’06, pages 429–436, Seattle, WA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiyang Chen</author>
<author>Osmar R Za¨ıane</author>
<author>Randy Goebel</author>
</authors>
<title>An unsupervised approach to cluster web search results based on word sense communities.</title>
<date>2008</date>
<booktitle>In Proc. of WI-IAT</booktitle>
<pages>725--729</pages>
<location>Sydney, Australia.</location>
<marker>Chen, Za¨ıane, Goebel, 2008</marker>
<rawString>Jiyang Chen, Osmar R. Za¨ıane, and Randy Goebel. 2008. An unsupervised approach to cluster web search results based on word sense communities. In Proc. of WI-IAT 2008, pages 725–729, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Cheng</author>
<author>Santosh Vempala</author>
<author>Ravi Kannan</author>
<author>Grant Wang</author>
</authors>
<title>A divide-and-merge methodology for clustering.</title>
<date>2005</date>
<booktitle>In Proc. of PODS ’05,</booktitle>
<pages>196--205</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="8471" citStr="Cheng et al., 2005" startWordPosition="1343" endWordPosition="1346">0)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between docume</context>
</contexts>
<marker>Cheng, Vempala, Kannan, Wang, 2005</marker>
<rawString>David Cheng, Santosh Vempala, Ravi Kannan, and Grant Wang. 2005. A divide-and-merge methodology for clustering. In Proc. of PODS ’05, pages 196–205, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Crabtree</author>
<author>Xiaoying Gao</author>
<author>Peter Andreae</author>
</authors>
<title>Improving web clustering by cluster selection.</title>
<date>2005</date>
<booktitle>In Proc. of WI ’05,</booktitle>
<pages>172--178</pages>
<location>Compi`egne, France.</location>
<contexts>
<context position="8248" citStr="Crabtree et al., 2005" startWordPosition="1310" endWordPosition="1313">his approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top </context>
<context position="20093" citStr="Crabtree et al., 2005" startWordPosition="3416" endWordPosition="3420">i) _ argmax j��,...,m 120 the corresponding meaning Sj by calculating the following formula: avgsim(Cj,Sj) = The formula determines the average similarity between the search results in cluster Cj and the corresponding sense cluster Sj. The similarity between a search result ri and Sj is determined as the normalized overlap between its bag of words bi and Sj: sim(ri,Sj) = sim(bi,Sj) = |bi ∩ Sj| |bi |.(7) Finally, we rank the elements ri within each cluster Cj by their similarity sim(ri, Sj). We note that the ranking and optimality of clusters can be improved with more sophisticated techniques (Crabtree et al., 2005; Kurland, 2008; Kurland and Domshlak, 2008; Lee et al., 2008, inter alia). However, this is outside the scope of this paper. 4 Experiments 4.1 Experimental Setup Test Sets. We conducted our experiments on two datasets: • AMBIENT (AMBIguous ENTries), a recently released dataset which contains 44 ambiguous queries3. The sense inventory for the meanings (i.e., subtopics)4 of queries is given by Wikipedia disambiguation pages. For instance, given the beagle query, its disambiguation page in Wikipedia provides the meanings of dog, Mars lander, computer search service, beer brand, etc. The top 100 </context>
</contexts>
<marker>Crabtree, Gao, Andreae, 2005</marker>
<rawString>Daniel Crabtree, Xiaoying Gao, and Peter Andreae. 2005. Improving web clustering by cluster selection. In Proc. of WI ’05, pages 172–178, Compi`egne, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglass R Cutting</author>
<author>David R Karger</author>
<author>Jan O Pedersen</author>
<author>John W Tukey</author>
</authors>
<title>Scatter/gather: A clusterbased approach to browsing large document collections.</title>
<date>1992</date>
<booktitle>In Proc. of SIGIR ’92,</booktitle>
<pages>318--329</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="7461" citStr="Cutting et al., 1992" startWordPosition="1191" endWordPosition="1194">lusters them on the basis of some notion of textual similarity. At the root of the clustering approach lies van Rijsbergen’s (1979) cluster hypothesis: “closely associated documents tend to be relevant to the same requests”, whereas documents concerning different meanings of the input query are expected to belong to different clusters. Approaches to search result clustering can be classified as data-centric or description-centric (Carpineto et al., 2009). The former focus more on the problem of data clustering than on presenting the results to the user. A pioneering example is Scatter/Gather (Cutting et al., 1992), which divides the dataset into a small number of clusters and, after the selection of a group, performs clustering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search r</context>
</contexts>
<marker>Cutting, Karger, Pedersen, Tukey, 1992</marker>
<rawString>Douglass R. Cutting, David R. Karger, Jan O. Pedersen, and John W. Tukey. 1992. Scatter/gather: A clusterbased approach to browsing large document collections. In Proc. of SIGIR ’92, pages 318–329, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emilio Di Giacomo</author>
<author>Walter Didimo</author>
<author>Luca Grilli</author>
<author>Giuseppe Liotta</author>
</authors>
<title>Graph visualization techniques for web clustering engines.</title>
<date>2007</date>
<journal>IEEE Transactions on Visualization and Computer Graphics,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>304</pages>
<marker>Di Giacomo, Didimo, Grilli, Liotta, 2007</marker>
<rawString>Emilio Di Giacomo, Walter Didimo, Luca Grilli, and Giuseppe Liotta. 2007. Graph visualization techniques for web clustering engines. IEEE Transactions on Visualization and Computer Graphics, 13(2):294– 304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George W Furnas</author>
<author>Thomas K Landauer</author>
<author>Louis Gomez</author>
<author>Susan Dumais</author>
</authors>
<title>The vocabulary problem in human-system communication.</title>
<date>1987</date>
<journal>Communications of the ACM,</journal>
<volume>30</volume>
<issue>11</issue>
<contexts>
<context position="1294" citStr="Furnas et al., 1987" startWordPosition="198" endWordPosition="201">ed word senses. Our experiments, conducted on datasets of ambiguous queries, show that our approach improves search result clustering in terms of both clustering quality and degree of diversification. 1 Introduction Over recent years increasingly huge amounts of text have been made available on the Web. Popular search engines such as Yahoo! and Google usually do a good job at retrieving a small number of relevant results from such an enormous collection of Web pages (i.e. retrieving with high precision, low recall). However, current search engines are still facing the lexical ambiguity issue (Furnas et al., 1987) – i.e. the linguistic property owing to which any particular word may convey different meanings. In a recent study (Sanderson, 2008) – conducted using WordNet (Miller et al., 1990) and Wikipedia as sources of ambiguous words – it was reported that around 3% of Web queries and 23% of the most frequent queries are ambiguous. Examples include: “buy B-52” (a cocktail? a bomber? a DJ workstation? tickets for a band?), “Alexander Smith quotes” (the novelist? the poet?), “beagle search” (dogs? the Linux search tool? the landing spacecraft?). Ambiguity is often the consequence of the low number of qu</context>
</contexts>
<marker>Furnas, Landauer, Gomez, Dumais, 1987</marker>
<rawString>George W. Furnas, Thomas K. Landauer, Louis Gomez, and Susan Dumais. 1987. The vocabulary problem in human-system communication. Communications of the ACM, 30(11):964–971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fatih Gelgi</author>
<author>Hasan Davulcu</author>
<author>Srinivas Vadrevu</author>
</authors>
<title>Term ranking for clustering web search results.</title>
<date>2007</date>
<booktitle>In Proc. of WebDB ’07,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="8545" citStr="Gelgi et al., 2007" startWordPosition="1355" endWordPosition="1358">et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditi</context>
</contexts>
<marker>Gelgi, Davulcu, Vadrevu, 2007</marker>
<rawString>Fatih Gelgi, Hasan Davulcu, and Srinivas Vadrevu. 2007. Term ranking for clustering web search results. In Proc. of WebDB ’07, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Gonzalo</author>
<author>Anselmo Penas</author>
<author>Felisa Verdejo</author>
</authors>
<title>Lexical ambiguity and Information Retrieval revisited.</title>
<date>1999</date>
<booktitle>In Proc. of EMNLP/VLC</booktitle>
<pages>195--202</pages>
<location>College Park, MD, USA.</location>
<contexts>
<context position="5694" citStr="Gonzalo et al., 1999" startWordPosition="905" endWordPosition="908">rieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet) and thus suffers fro</context>
</contexts>
<marker>Gonzalo, Penas, Verdejo, 1999</marker>
<rawString>Julio Gonzalo, Anselmo Penas, and Felisa Verdejo. 1999. Lexical ambiguity and Information Retrieval revisited. In Proc. of EMNLP/VLC 1999, pages 195–202, College Park, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<booktitle>Distributional structure. Word,</booktitle>
<pages>10--146</pages>
<contexts>
<context position="11630" citStr="Harris, 1954" startWordPosition="1874" endWordPosition="1875"> means of a Word Sense Induction algorithm: given a query q, we first dynamically induce, from a text corpus, the set of word senses of q (Section 3.1); next, we cluster the Web results on the basis of the word senses previously induced (Section 3.2). 3.1 Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a given word – used in a specific sense – tends to co-occur with the same neighbouring words (Harris, 1954). Several approaches to WSI have been proposed in the literature (see Navigli (2009) for a survey), ranging from clustering based on context vectors (e.g., Sch¨utze (1998)) to word clustering (e.g., Lin (1998)) and co-occurrence graphs (e.g., Widdows and Dorow (2002)). Successful approaches such as HyperLex (V´eronis, 2004) – a graph algorithm based on the identification of hubs in co-occurrence graphs – have to cope with a high number of parameters to be tuned (Agirre et al., 2006). To deal with this issue we propose two variants of a simple, yet effective, graph-based algorithm for WSI, that</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. Word, 10:146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryam Kamvar</author>
<author>Shumeet Baluja</author>
</authors>
<title>A large scale study of wireless search behavior: Google mobile search.</title>
<date>2006</date>
<booktitle>In Proc. of CHI ’06,</booktitle>
<pages>701--709</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="1961" citStr="Kamvar and Baluja, 2006" startWordPosition="309" endWordPosition="312">ich any particular word may convey different meanings. In a recent study (Sanderson, 2008) – conducted using WordNet (Miller et al., 1990) and Wikipedia as sources of ambiguous words – it was reported that around 3% of Web queries and 23% of the most frequent queries are ambiguous. Examples include: “buy B-52” (a cocktail? a bomber? a DJ workstation? tickets for a band?), “Alexander Smith quotes” (the novelist? the poet?), “beagle search” (dogs? the Linux search tool? the landing spacecraft?). Ambiguity is often the consequence of the low number of query words entered on average by Web users (Kamvar and Baluja, 2006). While average query length is increasing – it is now estimated at around 3 words per query1 – many search engines such as Google have already started to tackle the query ambiguity issue by reranking and diversifying their results, so as to prevent Web pages that are similar to each other from ranking too high on the list. In the past few years, Web clustering engines (Carpineto et al., 2009) have been proposed as a solution to the lexical ambiguity issue in Web Information Retrieval. These systems group search results, by providing a cluster for each specific aspect (i.e., meaning) of the in</context>
</contexts>
<marker>Kamvar, Baluja, 2006</marker>
<rawString>Maryam Kamvar and Shumeet Baluja. 2006. A large scale study of wireless search behavior: Google mobile search. In Proc. of CHI ’06, pages 701–709, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weimao Ke</author>
<author>Cassidy R Sugimoto</author>
<author>Javed Mostafa</author>
</authors>
<title>Dynamicity vs. effectiveness: studying online clustering for scatter/gather.</title>
<date>2009</date>
<booktitle>In Proc. of SIGIR ’09,</booktitle>
<pages>pages</pages>
<location>MA, USA.</location>
<contexts>
<context position="7735" citStr="Ke et al., 2009" startWordPosition="1234" endWordPosition="1237"> input query are expected to belong to different clusters. Approaches to search result clustering can be classified as data-centric or description-centric (Carpineto et al., 2009). The former focus more on the problem of data clustering than on presenting the results to the user. A pioneering example is Scatter/Gather (Cutting et al., 1992), which divides the dataset into a small number of clusters and, after the selection of a group, performs clustering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept</context>
</contexts>
<marker>Ke, Sugimoto, Mostafa, 2009</marker>
<rawString>Weimao Ke, Cassidy R. Sugimoto, and Javed Mostafa. 2009. Dynamicity vs. effectiveness: studying online clustering for scatter/gather. In Proc. of SIGIR ’09, pages 19–26, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sang-Bum Kim</author>
<author>Hee-Cheol Seo</author>
<author>Hae-Chang Rim</author>
</authors>
<title>Information Retrieval using word senses: root sense tagging approach.</title>
<date>2004</date>
<booktitle>In Proc. of SIGIR ’04,</booktitle>
<pages>258--265</pages>
<location>Sheffield, UK.</location>
<contexts>
<context position="5712" citStr="Kim et al., 2004" startWordPosition="909" endWordPosition="912">ent direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet) and thus suffers from its static natur</context>
</contexts>
<marker>Kim, Seo, Rim, 2004</marker>
<rawString>Sang-Bum Kim, Hee-Cheol Seo, and Hae-Chang Rim. 2004. Information Retrieval using word senses: root sense tagging approach. In Proc. of SIGIR ’04, pages 258–265, Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Krovetz</author>
<author>William B Croft</author>
</authors>
<title>Lexical ambiguity and Information Retrieval.</title>
<date>1992</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="5634" citStr="Krovetz and Croft, 1992" startWordPosition="895" endWordPosition="898">n a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference diction</context>
</contexts>
<marker>Krovetz, Croft, 1992</marker>
<rawString>Robert Krovetz and William B. Croft. 1992. Lexical ambiguity and Information Retrieval. ACM Transactions on Information Systems, 10(2):115–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Carmel Domshlak</author>
</authors>
<title>A rankaggregation approach to searching for optimal queryspecific clusters.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>547--554</pages>
<contexts>
<context position="20136" citStr="Kurland and Domshlak, 2008" startWordPosition="3423" endWordPosition="3426">nding meaning Sj by calculating the following formula: avgsim(Cj,Sj) = The formula determines the average similarity between the search results in cluster Cj and the corresponding sense cluster Sj. The similarity between a search result ri and Sj is determined as the normalized overlap between its bag of words bi and Sj: sim(ri,Sj) = sim(bi,Sj) = |bi ∩ Sj| |bi |.(7) Finally, we rank the elements ri within each cluster Cj by their similarity sim(ri, Sj). We note that the ranking and optimality of clusters can be improved with more sophisticated techniques (Crabtree et al., 2005; Kurland, 2008; Kurland and Domshlak, 2008; Lee et al., 2008, inter alia). However, this is outside the scope of this paper. 4 Experiments 4.1 Experimental Setup Test Sets. We conducted our experiments on two datasets: • AMBIENT (AMBIguous ENTries), a recently released dataset which contains 44 ambiguous queries3. The sense inventory for the meanings (i.e., subtopics)4 of queries is given by Wikipedia disambiguation pages. For instance, given the beagle query, its disambiguation page in Wikipedia provides the meanings of dog, Mars lander, computer search service, beer brand, etc. The top 100 Web results of each query returned by the Y</context>
</contexts>
<marker>Kurland, Domshlak, 2008</marker>
<rawString>Oren Kurland and Carmel Domshlak. 2008. A rankaggregation approach to searching for optimal queryspecific clusters. In Proc. of SIGIR ’08, pages 547– 554, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
</authors>
<title>The opposite of smoothing: a language model approach to ranking query-specific document clusters.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>171--178</pages>
<contexts>
<context position="20108" citStr="Kurland, 2008" startWordPosition="3421" endWordPosition="3422">20 the corresponding meaning Sj by calculating the following formula: avgsim(Cj,Sj) = The formula determines the average similarity between the search results in cluster Cj and the corresponding sense cluster Sj. The similarity between a search result ri and Sj is determined as the normalized overlap between its bag of words bi and Sj: sim(ri,Sj) = sim(bi,Sj) = |bi ∩ Sj| |bi |.(7) Finally, we rank the elements ri within each cluster Cj by their similarity sim(ri, Sj). We note that the ranking and optimality of clusters can be improved with more sophisticated techniques (Crabtree et al., 2005; Kurland, 2008; Kurland and Domshlak, 2008; Lee et al., 2008, inter alia). However, this is outside the scope of this paper. 4 Experiments 4.1 Experimental Setup Test Sets. We conducted our experiments on two datasets: • AMBIENT (AMBIguous ENTries), a recently released dataset which contains 44 ambiguous queries3. The sense inventory for the meanings (i.e., subtopics)4 of queries is given by Wikipedia disambiguation pages. For instance, given the beagle query, its disambiguation page in Wikipedia provides the meanings of dog, Mars lander, computer search service, beer brand, etc. The top 100 Web results of </context>
</contexts>
<marker>Kurland, 2008</marker>
<rawString>Oren Kurland. 2008. The opposite of smoothing: a language model approach to ranking query-specific document clusters. In Proc. of SIGIR ’08, pages 171–178, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyung Soon Lee</author>
<author>W Bruce Croft</author>
<author>James Allan</author>
</authors>
<title>A cluster-based resampling method for pseudorelevance feedback.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>235--242</pages>
<contexts>
<context position="20154" citStr="Lee et al., 2008" startWordPosition="3427" endWordPosition="3430">ing the following formula: avgsim(Cj,Sj) = The formula determines the average similarity between the search results in cluster Cj and the corresponding sense cluster Sj. The similarity between a search result ri and Sj is determined as the normalized overlap between its bag of words bi and Sj: sim(ri,Sj) = sim(bi,Sj) = |bi ∩ Sj| |bi |.(7) Finally, we rank the elements ri within each cluster Cj by their similarity sim(ri, Sj). We note that the ranking and optimality of clusters can be improved with more sophisticated techniques (Crabtree et al., 2005; Kurland, 2008; Kurland and Domshlak, 2008; Lee et al., 2008, inter alia). However, this is outside the scope of this paper. 4 Experiments 4.1 Experimental Setup Test Sets. We conducted our experiments on two datasets: • AMBIENT (AMBIguous ENTries), a recently released dataset which contains 44 ambiguous queries3. The sense inventory for the meanings (i.e., subtopics)4 of queries is given by Wikipedia disambiguation pages. For instance, given the beagle query, its disambiguation page in Wikipedia provides the meanings of dog, Mars lander, computer search service, beer brand, etc. The top 100 Web results of each query returned by the Yahoo! search engin</context>
</contexts>
<marker>Lee, Croft, Allan, 2008</marker>
<rawString>Kyung Soon Lee, W. Bruce Croft, and James Allan. 2008. A cluster-based resampling method for pseudorelevance feedback. In Proc. of SIGIR ’08, pages 235– 242, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. of the 171h COLING,</booktitle>
<pages>768--774</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="11839" citStr="Lin (1998)" startWordPosition="1907" endWordPosition="1908">enses previously induced (Section 3.2). 3.1 Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a given word – used in a specific sense – tends to co-occur with the same neighbouring words (Harris, 1954). Several approaches to WSI have been proposed in the literature (see Navigli (2009) for a survey), ranging from clustering based on context vectors (e.g., Sch¨utze (1998)) to word clustering (e.g., Lin (1998)) and co-occurrence graphs (e.g., Widdows and Dorow (2002)). Successful approaches such as HyperLex (V´eronis, 2004) – a graph algorithm based on the identification of hubs in co-occurrence graphs – have to cope with a high number of parameters to be tuned (Agirre et al., 2006). To deal with this issue we propose two variants of a simple, yet effective, graph-based algorithm for WSI, that we 118 describe hereafter. The algorithm consists of two steps: graph construction and identification of word senses. 3.1.1 Graph construction Given a target query q, we build a co-occurrence graph GQ = (V, E</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. of the 171h COLING, pages 768–774, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuang Liu</author>
<author>Clement Yu</author>
<author>Weiyi Meng</author>
</authors>
<title>Word Sense Disambiguation in queries.</title>
<date>2005</date>
<booktitle>In Proc. of CIKM ’05,</booktitle>
<pages>525--532</pages>
<location>Bremen, Germany.</location>
<contexts>
<context position="4842" citStr="Liu et al., 2005" startWordPosition="776" endWordPosition="779"> Project – http://dmoz.org). Given a query, search results are organized by category. This approach has three main weaknesses: first, it is static, thus it needs manual updates to cover new pages; second, it covers only a small portion of the Web; third, it classifies Web pages based on coarse categories. This latter feature of Web directories makes it difficult to distinguish between instances of the same kind (e.g., pages about artists with the same surname classified as Arts:Music:Bands and Artists). While methods for the automatic classification of Web documents have been proposed (e.g., (Liu et al., 2005b; Xue et al., 2008)) and some problems have been effectively tackled (Bennett and Nguyen, 2009), these approaches are usually supervised and still suffer from relying on a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning</context>
</contexts>
<marker>Liu, Yu, Meng, 2005</marker>
<rawString>Shuang Liu, Clement Yu, and Weiyi Meng. 2005a. Word Sense Disambiguation in queries. In Proc. of CIKM ’05, pages 525–532, Bremen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tie-Yan Liu</author>
<author>Yiming Yang</author>
<author>Hao Wan</author>
<author>Hua-Jun Zeng</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
</authors>
<title>Support vector machines classification with a very large-scale taxonomy.</title>
<date>2005</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="4842" citStr="Liu et al., 2005" startWordPosition="776" endWordPosition="779"> Project – http://dmoz.org). Given a query, search results are organized by category. This approach has three main weaknesses: first, it is static, thus it needs manual updates to cover new pages; second, it covers only a small portion of the Web; third, it classifies Web pages based on coarse categories. This latter feature of Web directories makes it difficult to distinguish between instances of the same kind (e.g., pages about artists with the same surname classified as Arts:Music:Bands and Artists). While methods for the automatic classification of Web documents have been proposed (e.g., (Liu et al., 2005b; Xue et al., 2008)) and some problems have been effectively tackled (Bennett and Nguyen, 2009), these approaches are usually supervised and still suffer from relying on a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning</context>
</contexts>
<marker>Liu, Yang, Wan, Zeng, Chen, Ma, 2005</marker>
<rawString>Tie-Yan Liu, Yiming Yang, Hao Wan, Hua-Jun Zeng, Zheng Chen, and Wei-Ying Ma. 2005b. Support vector machines classification with a very large-scale taxonomy. SIGKDD Explor. Newsl., 7(1):36–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Liu</author>
<author>Wenyuan Li</author>
<author>Yongjing Lin</author>
<author>Liping Jing</author>
</authors>
<title>Spectral geometry for simultaneously clustering and ranking query search results.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>539--546</pages>
<contexts>
<context position="8509" citStr="Liu et al., 2008" startWordPosition="1349" endWordPosition="1352">r exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein,</context>
</contexts>
<marker>Liu, Li, Lin, Jing, 2008</marker>
<rawString>Ying Liu, Wenyuan Li, Yongjing Lin, and Liping Jing. 2008. Spectral geometry for simultaneously clustering and ranking query search results. In Proc. of SIGIR ’08, pages 539–546, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rila Mandala</author>
<author>Takenobu Tokunaga</author>
<author>Hozumi Tanaka</author>
</authors>
<title>The use of WordNet in Information Retrieval.</title>
<date>1998</date>
<booktitle>In Proc. of the COLING-ACL workshop on Usage of Wordnet in Natural Language Processing,</booktitle>
<pages>31--37</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="5672" citStr="Mandala et al., 1998" startWordPosition="901" endWordPosition="904">mantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet</context>
</contexts>
<marker>Mandala, Tokunaga, Tanaka, 1998</marker>
<rawString>Rila Mandala, Takenobu Tokunaga, and Hozumi Tanaka. 1998. The use of WordNet in Information Retrieval. In Proc. of the COLING-ACL workshop on Usage of Wordnet in Natural Language Processing, pages 31– 37, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard T Beckwith</author>
<author>Christiane D Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>WordNet: an online lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="1475" citStr="Miller et al., 1990" startWordPosition="228" endWordPosition="231">of diversification. 1 Introduction Over recent years increasingly huge amounts of text have been made available on the Web. Popular search engines such as Yahoo! and Google usually do a good job at retrieving a small number of relevant results from such an enormous collection of Web pages (i.e. retrieving with high precision, low recall). However, current search engines are still facing the lexical ambiguity issue (Furnas et al., 1987) – i.e. the linguistic property owing to which any particular word may convey different meanings. In a recent study (Sanderson, 2008) – conducted using WordNet (Miller et al., 1990) and Wikipedia as sources of ambiguous words – it was reported that around 3% of Web queries and 23% of the most frequent queries are ambiguous. Examples include: “buy B-52” (a cocktail? a bomber? a DJ workstation? tickets for a band?), “Alexander Smith quotes” (the novelist? the poet?), “beagle search” (dogs? the Linux search tool? the landing spacecraft?). Ambiguity is often the consequence of the low number of query words entered on average by Web users (Kamvar and Baluja, 2006). While average query length is increasing – it is now estimated at around 3 words per query1 – many search engine</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard T. Beckwith, Christiane D. Fellbaum, Derek Gross, and Katherine Miller. 1990. WordNet: an online lexical database. International Journal of Lexicography, 3(4):235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: a survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="5283" citStr="Navigli (2009)" startWordPosition="844" endWordPosition="845">ith the same surname classified as Arts:Music:Bands and Artists). While methods for the automatic classification of Web documents have been proposed (e.g., (Liu et al., 2005b; Xue et al., 2008)) and some problems have been effectively tackled (Bennett and Nguyen, 2009), these approaches are usually supervised and still suffer from relying on a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate t</context>
<context position="11714" citStr="Navigli (2009)" startWordPosition="1888" endWordPosition="1889">nduce, from a text corpus, the set of word senses of q (Section 3.1); next, we cluster the Web results on the basis of the word senses previously induced (Section 3.2). 3.1 Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a given word – used in a specific sense – tends to co-occur with the same neighbouring words (Harris, 1954). Several approaches to WSI have been proposed in the literature (see Navigli (2009) for a survey), ranging from clustering based on context vectors (e.g., Sch¨utze (1998)) to word clustering (e.g., Lin (1998)) and co-occurrence graphs (e.g., Widdows and Dorow (2002)). Successful approaches such as HyperLex (V´eronis, 2004) – a graph algorithm based on the identification of hubs in co-occurrence graphs – have to cope with a high number of parameters to be tuned (Agirre et al., 2006). To deal with this issue we propose two variants of a simple, yet effective, graph-based algorithm for WSI, that we 118 describe hereafter. The algorithm consists of two steps: graph construction </context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: a survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi Lang Ngo</author>
<author>Hung Son Nguyen</author>
</authors>
<title>A method of web search result clustering based on rough sets.</title>
<date>2005</date>
<booktitle>In Proc. of WI ’05,</booktitle>
<pages>673--679</pages>
<location>Compi`egne, France.</location>
<contexts>
<context position="7890" citStr="Ngo and Nguyen, 2005" startWordPosition="1255" endWordPosition="1258">tric (Carpineto et al., 2009). The former focus more on the problem of data clustering than on presenting the results to the user. A pioneering example is Scatter/Gather (Cutting et al., 1992), which divides the dataset into a small number of clusters and, after the selection of a group, performs clustering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry</context>
</contexts>
<marker>Ngo, Nguyen, 2005</marker>
<rawString>Chi Lang Ngo and Hung Son Nguyen. 2005. A method of web search result clustering based on rough sets. In Proc. of WI ’05, pages 673–679, Compi`egne, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cam-Tu Nguyen</author>
<author>Xuan-Hieu Phan</author>
<author>Susumu Horiguchi</author>
<author>Thu-Trang Nguyen</author>
<author>Quang-Thuy Ha</author>
</authors>
<title>Web search clustering and labeling with hidden topics.</title>
<date>2009</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="10272" citStr="Nguyen et al., 2009" startWordPosition="1628" endWordPosition="1631">n inventory of senses of the input query. Instead of performing clustering on the basis of the surface similarity of Web snippets, we use our induced word senses to group snippets. Very little work on this topic exists: vector-based WSI was successfully shown to improve bag-of-words ad-hoc Information Retrieval (Sch¨utze and Pedersen, 1995) and preliminary studies (Udani et al., 2005; Chen et al., 2008) have provided interesting insights into the use of WSI for Web search result clustering. A more recent attempt at automatically identifying query meanings is based on the use of hidden topics (Nguyen et al., 2009). However, in this approach topics – estimated from a universal dataset – are query-independent and thus their number needs to be established beforehand. In contrast, we aim to cluster snippets based on a dynamic and finergrained notion of sense. 3 Approach Web search result clustering is usually performed in three main steps: 1. Given a query q, a search engine (e.g., Yahoo!) is used to retrieve a list of results R = (ri, ... , r.); 2. A clustering C = (Co, Ci, ... , Cm) of the results in R is obtained by means of a clustering algorithm; 3. The clusters in C are optionally labeled with an app</context>
</contexts>
<marker>Nguyen, Phan, Horiguchi, Nguyen, Ha, 2009</marker>
<rawString>Cam-Tu Nguyen, Xuan-Hieu Phan, Susumu Horiguchi, Thu-Trang Nguyen, and Quang-Thuy Ha. 2009. Web search clustering and labeling with hidden topics. ACM Transactions on Asian Language Information Processing, 8(3):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanislaw Osinski</author>
<author>Dawid Weiss</author>
</authors>
<title>A conceptdriven algorithm for clustering search results.</title>
<date>2005</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="8429" citStr="Osinski and Weiss, 2005" startWordPosition="1337" endWordPosition="1340">ing (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the di</context>
<context position="23206" citStr="Osinski and Weiss, 2005" startWordPosition="3923" endWordPosition="3926">nd the threshold σ for edge removal (Section 3.1.2). The best parameters, used throughout our experiments, were (δ = 0.00033, σ = 0.45) with triangles and (δ = 0.00033, σ = 0.33) with squares. The parameter values were obtained as a result of tuning on a small in-house development dataset. The dataset was built by automatically identifying monosemous words and creating pseudowords following the scheme proposed by Sch¨utze (1998). Systems. We compared Triangles and Squares against the best systems reported by Bernardini et al. (2009, cf. Section 2): E rzEC; si . (6) |Cj| m(ri, Sj) 121 • Lingo (Osinski and Weiss, 2005): a Web clustering engine implemented in the Carrot2 opensource framework5 that clusters the most frequent phrases extracted using suffix arrays. • Suffix Tree Clustering (STC) (Zamir and Etzioni, 1998): the original Web search clustering approach based on suffix trees. • KeySRC (Bernardini et al., 2009): a state-of-theart Web clustering engine built on top of STC with part-of-speech pruning and dynamic selection of the cut-off level of the clustering dendrogram. • Essential Pages (EP) (Swaminathan et al., 2009): a recent diversification algorithm that selects fundamental pages which maximize </context>
<context position="27093" citStr="Osinski and Weiss (2005)" startWordPosition="4574" endWordPosition="4577">K (Zhai et al., 2003) given by the number of different subtopics retrieved for q in the top K results returned: UK i subtopics(ri)| S-recall@K = i= (9) M where subtopics(ri) is the set of subtopics manually assigned to the search result ri and M is the number of subtopics for query q (note that in our experiments M is the number of subtopics occurring in the 100 results retrieved for q, so S-recall@100 = 1). However, this measure is only suitable for systems returning ranked lists (such as Yahoo! and EP). Given 6For reference systems we used the implementations of Bernardini et al. (2009) and Osinski and Weiss (2005). 122 System K=3 K=5 K=10 K=15 K=20 Squares 51.9 63.4 75.8 83.3 87.4 Triangles 50.8 62.4 75.2 82.7 86.6 Yahoo! 49.2 60.0 72.9 78.5 82.7 EP 40.6 53.2 68.6 77.2 83.3 KeySRC 44.3 55.8 72.0 79.1 83.2 Table 3: S-recall@K on all queries (percentages). a clustering C = (Co, Ci, ... , Cm), we flatten it to a list as follows: we add to the initially empty list the first element of each cluster Cj (j = 1, ... , m); then we iterate the process by selecting the second element of each cluster Cj such that |Cj |&gt; 2, and so on. The remaining elements returned by the search engine, but not included in any clu</context>
</contexts>
<marker>Osinski, Weiss, 2005</marker>
<rawString>Stanislaw Osinski and Dawid Weiss. 2005. A conceptdriven algorithm for clustering search results. IEEE Intelligent Systems, 20(3):48–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Rand</author>
</authors>
<title>Objective criteria for the evaluation of clustering methods.</title>
<date>1971</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>66</volume>
<issue>336</issue>
<contexts>
<context position="24366" citStr="Rand, 1971" startWordPosition="4110" endWordPosition="4111">thm that selects fundamental pages which maximize the amount of information covered for a given query. • Yahoo!: the original search results returned by the Yahoo! search engine. The first three of the above are Web search result clustering approaches, whereas the last two produce lists of possibly diversified results (cf. Section 2). 4.2 Experiment 1: Clustering Quality Measure. While assessing the quality of clustering is a notably hard problem, given a gold standard !g we can calculate the Rand index (RI) of a clustering C, a common quality measure in the literature, determined as follows (Rand, 1971; Manning et al., 2008): �(w,w�)∈W×W,w6=w�δ(w, w0) RI(C) = |{(w, w0) � W � W : w =� w0} |(8) where W is the union set of all the words in C and δ(w, w0) = 1 if any two words w and w0 are in the same cluster both in C and in the gold standard !9 or they are in two different clusters in both C and !g, otherwise δ(w, w0) = 0. In other words, we calculate the percentage of word pairs that are in the same configuration in both C and !g. For the gold standard !g we use the clustering induced by the sense annotations provided in our datasets for each snippet (i.e., each cluster contains the snippets </context>
</contexts>
<marker>Rand, 1971</marker>
<rawString>William M. Rand. 1971. Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association, 66(336):846–850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>Word Sense Disambiguation and Information Retrieval.</title>
<date>1994</date>
<booktitle>In Proc. of SIGIR ’94,</booktitle>
<pages>142--151</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="5932" citStr="Sanderson, 1994" startWordPosition="947" endWordPosition="948">nd/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet) and thus suffers from its static nature and its inherent paucity of most proper nouns. This latter problem is particularly important for Web searches, as users tend to retrieve more information about named entities (e.g., singers, artists, cities) than conce</context>
</contexts>
<marker>Sanderson, 1994</marker>
<rawString>Mark Sanderson. 1994. Word Sense Disambiguation and Information Retrieval. In Proc. of SIGIR ’94, pages 142–151, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>Retrieving with good sense.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="6182" citStr="Sanderson, 2000" startWordPosition="992" endWordPosition="993">ifferent methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet) and thus suffers from its static nature and its inherent paucity of most proper nouns. This latter problem is particularly important for Web searches, as users tend to retrieve more information about named entities (e.g., singers, artists, cities) than concepts (e.g., abstract information about singers or artists). Search Result Clustering. A more popular approach to query ambiguity is that of search result clustering. Typically, given a query, the system starts from a flat list of text snippets returne</context>
</contexts>
<marker>Sanderson, 2000</marker>
<rawString>Mark Sanderson. 2000. Retrieving with good sense. Information Retrieval, 2(1):49–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>Ambiguous queries: test collections need more sense.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>499--506</pages>
<contexts>
<context position="1427" citStr="Sanderson, 2008" startWordPosition="221" endWordPosition="222">terms of both clustering quality and degree of diversification. 1 Introduction Over recent years increasingly huge amounts of text have been made available on the Web. Popular search engines such as Yahoo! and Google usually do a good job at retrieving a small number of relevant results from such an enormous collection of Web pages (i.e. retrieving with high precision, low recall). However, current search engines are still facing the lexical ambiguity issue (Furnas et al., 1987) – i.e. the linguistic property owing to which any particular word may convey different meanings. In a recent study (Sanderson, 2008) – conducted using WordNet (Miller et al., 1990) and Wikipedia as sources of ambiguous words – it was reported that around 3% of Web queries and 23% of the most frequent queries are ambiguous. Examples include: “buy B-52” (a cocktail? a bomber? a DJ workstation? tickets for a band?), “Alexander Smith quotes” (the novelist? the poet?), “beagle search” (dogs? the Linux search tool? the landing spacecraft?). Ambiguity is often the consequence of the low number of query words entered on average by Web users (Kamvar and Baluja, 2006). While average query length is increasing – it is now estimated a</context>
<context position="33632" citStr="Sanderson, 2008" startWordPosition="5710" endWordPosition="5711">le as a specific instance of a space lander). In contrast, static dictionaries such as WordNet – typically used in Word Sense Disambiguation – by their very nature encode mainly concepts. Second, we propose two simple, yet effective, graph algorithms to induce the senses of our queries. The best performing approach is based on squares (cycles of length 4), a novel graph pattern in WSI. Third, we contribute a new dataset of 114 ambiguous queries and 11,400 sense-annotated snippets which complements an existing dataset of ambiguous queries7. Given the lack of ambiguous query datasets available (Sanderson, 2008), we hope our new dataset will be useful in future comparative experiments. Finally, we note that our approach needed very little tuning. Moreover, its requirement of a Web corpus of n-grams is not a stringent one, as such corpora are available for several languages and can be produced for any language of interest. As regards future work, we intend to combine our clustering algorithm with a cluster labeling algorithm. We also aim to implement a number of Word Sense Induction algorithms and compare them in the same evaluation framework with more Web search and Web clustering engines. Finally, i</context>
</contexts>
<marker>Sanderson, 2008</marker>
<rawString>Mark Sanderson. 2008. Ambiguous queries: test collections need more sense. In Proc. of SIGIR ’08, pages 499–506, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
<author>Jan Pedersen</author>
</authors>
<title>Information Retrieval based on word senses.</title>
<date>1995</date>
<booktitle>In Proceedings of SDAIR’95,</booktitle>
<pages>161--175</pages>
<location>Las Vegas, Nevada, USA.</location>
<marker>Sch¨utze, Pedersen, 1995</marker>
<rawString>Hinrich Sch¨utze and Jan Pedersen. 1995. Information Retrieval based on word senses. In Proceedings of SDAIR’95, pages 161–175, Las Vegas, Nevada, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Stokoe</author>
<author>Michael J Oakes</author>
<author>John I Tait</author>
</authors>
<title>Word Sense Disambiguation in Information Retrieval revisited.</title>
<date>2003</date>
<booktitle>In Proc. of SIGIR ’03,</booktitle>
<pages>159--166</pages>
<contexts>
<context position="6010" citStr="Stokoe et al., 2003" startWordPosition="960" endWordPosition="963">wo linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform WSD (typically, WordNet) and thus suffers from its static nature and its inherent paucity of most proper nouns. This latter problem is particularly important for Web searches, as users tend to retrieve more information about named entities (e.g., singers, artists, cities) than concepts (e.g., abstract information about singers or artists). Search Result Clust</context>
</contexts>
<marker>Stokoe, Oakes, Tait, 2003</marker>
<rawString>Christopher Stokoe, Michael J. Oakes, and John I. Tait. 2003. Word Sense Disambiguation in Information Retrieval revisited. In Proc. of SIGIR ’03, pages 159– 166, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashwin Swaminathan</author>
<author>Cherian V Mathew</author>
<author>Darko Kirovski</author>
</authors>
<title>Essential pages.</title>
<date>2009</date>
<booktitle>In Proc. of WI ’09,</booktitle>
<pages>173--182</pages>
<location>Milan, Italy.</location>
<contexts>
<context position="9419" citStr="Swaminathan et al., 2009" startWordPosition="1488" endWordPosition="1491">ty issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditional probabilities to determine which document is most different from higherranking ones (Chen and Karger, 2006) or use affinity ranking (Zhang et al., 2005), based on topic variance and coverage. More recently, an algorithm called Essential Pages (Swaminathan et al., 2009) has been proposed to reduce information redundancy and return Web pages that maximize coverage with respect to the input query. Word Sense Induction (WSI). In contrast to the above approaches, we perform WSI to dynamically acquire an inventory of senses of the input query. Instead of performing clustering on the basis of the surface similarity of Web snippets, we use our induced word senses to group snippets. Very little work on this topic exists: vector-based WSI was successfully shown to improve bag-of-words ad-hoc Information Retrieval (Sch¨utze and Pedersen, 1995) and preliminary studies </context>
<context position="23723" citStr="Swaminathan et al., 2009" startWordPosition="4004" endWordPosition="4007">rnardini et al. (2009, cf. Section 2): E rzEC; si . (6) |Cj| m(ri, Sj) 121 • Lingo (Osinski and Weiss, 2005): a Web clustering engine implemented in the Carrot2 opensource framework5 that clusters the most frequent phrases extracted using suffix arrays. • Suffix Tree Clustering (STC) (Zamir and Etzioni, 1998): the original Web search clustering approach based on suffix trees. • KeySRC (Bernardini et al., 2009): a state-of-theart Web clustering engine built on top of STC with part-of-speech pruning and dynamic selection of the cut-off level of the clustering dendrogram. • Essential Pages (EP) (Swaminathan et al., 2009): a recent diversification algorithm that selects fundamental pages which maximize the amount of information covered for a given query. • Yahoo!: the original search results returned by the Yahoo! search engine. The first three of the above are Web search result clustering approaches, whereas the last two produce lists of possibly diversified results (cf. Section 2). 4.2 Experiment 1: Clustering Quality Measure. While assessing the quality of clustering is a notably hard problem, given a gold standard !g we can calculate the Rand index (RI) of a clustering C, a common quality measure in the li</context>
</contexts>
<marker>Swaminathan, Mathew, Kirovski, 2009</marker>
<rawString>Ashwin Swaminathan, Cherian V. Mathew, and Darko Kirovski. 2009. Essential pages. In Proc. of WI ’09, pages 173–182, Milan, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goldee Udani</author>
<author>Shachi Dave</author>
<author>Anthony Davis</author>
<author>Tim Sibley</author>
</authors>
<title>Noun sense induction using web search results.</title>
<date>2005</date>
<booktitle>In Proc. of SIGIR ’05,</booktitle>
<pages>657--658</pages>
<location>Salvador, Brazil.</location>
<contexts>
<context position="10038" citStr="Udani et al., 2005" startWordPosition="1588" endWordPosition="1591">has been proposed to reduce information redundancy and return Web pages that maximize coverage with respect to the input query. Word Sense Induction (WSI). In contrast to the above approaches, we perform WSI to dynamically acquire an inventory of senses of the input query. Instead of performing clustering on the basis of the surface similarity of Web snippets, we use our induced word senses to group snippets. Very little work on this topic exists: vector-based WSI was successfully shown to improve bag-of-words ad-hoc Information Retrieval (Sch¨utze and Pedersen, 1995) and preliminary studies (Udani et al., 2005; Chen et al., 2008) have provided interesting insights into the use of WSI for Web search result clustering. A more recent attempt at automatically identifying query meanings is based on the use of hidden topics (Nguyen et al., 2009). However, in this approach topics – estimated from a universal dataset – are query-independent and thus their number needs to be established beforehand. In contrast, we aim to cluster snippets based on a dynamic and finergrained notion of sense. 3 Approach Web search result clustering is usually performed in three main steps: 1. Given a query q, a search engine (</context>
</contexts>
<marker>Udani, Dave, Davis, Sibley, 2005</marker>
<rawString>Goldee Udani, Shachi Dave, Anthony Davis, and Tim Sibley. 2005. Noun sense induction using web search results. In Proc. of SIGIR ’05, pages 657–658, Salvador, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelis Joost van Rijsbergen</author>
</authors>
<date>1979</date>
<note>Information Retrieval. Butterworths, second edition.</note>
<marker>van Rijsbergen, 1979</marker>
<rawString>Cornelis Joost van Rijsbergen. 1979. Information Retrieval. Butterworths, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean V´eronis</author>
</authors>
<title>HyperLex: lexical cartography for Information Retrieval.</title>
<date>2004</date>
<journal>Computer Speech and Language,</journal>
<volume>18</volume>
<issue>3</issue>
<marker>V´eronis, 2004</marker>
<rawString>Jean V´eronis. 2004. HyperLex: lexical cartography for Information Retrieval. Computer Speech and Language, 18(3):223–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Using WordNet to disambiguate word senses for text retrieval.</title>
<date>1993</date>
<booktitle>In Proc. of SIGIR ’93,</booktitle>
<pages>171--180</pages>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="5650" citStr="Voorhees, 1993" startWordPosition="899" endWordPosition="900">f categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different words (synonymy) and using the same word to express various different meanings (polysemy). Over the years, different methods for SIR have been proposed (Krovetz and Croft, 1992; Voorhees, 1993; Mandala et al., 1998; Gonzalo et al., 1999; Kim et al., 2004; Liu et al., 2005a, inter alia). However, contrasting results have been reported on the benefits of these techniques: it has been shown that WSD has to be very accurate to benefit Information Retrieval (Sanderson, 1994) – a result that was later debated (Gonzalo et al., 1999; Stokoe et al., 2003). Also, it has been reported that WSD has to be very precise on minority senses and uncommon terms, rather than on frequent words (Krovetz and Croft, 1992; Sanderson, 2000). SIR relies on the existence of a reference dictionary to perform W</context>
</contexts>
<marker>Voorhees, 1993</marker>
<rawString>Ellen M. Voorhees. 1993. Using WordNet to disambiguate word senses for text retrieval. In Proc. of SIGIR ’93, pages 171–180, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A graph model for unsupervised lexical acquisition.</title>
<date>2002</date>
<booktitle>In Proc. of the 191h COLING,</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="11897" citStr="Widdows and Dorow (2002)" startWordPosition="1913" endWordPosition="1916">Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a given word – used in a specific sense – tends to co-occur with the same neighbouring words (Harris, 1954). Several approaches to WSI have been proposed in the literature (see Navigli (2009) for a survey), ranging from clustering based on context vectors (e.g., Sch¨utze (1998)) to word clustering (e.g., Lin (1998)) and co-occurrence graphs (e.g., Widdows and Dorow (2002)). Successful approaches such as HyperLex (V´eronis, 2004) – a graph algorithm based on the identification of hubs in co-occurrence graphs – have to cope with a high number of parameters to be tuned (Agirre et al., 2006). To deal with this issue we propose two variants of a simple, yet effective, graph-based algorithm for WSI, that we 118 describe hereafter. The algorithm consists of two steps: graph construction and identification of word senses. 3.1.1 Graph construction Given a target query q, we build a co-occurrence graph GQ = (V, E) such that V is a set of context words related to q and E</context>
<context position="15761" citStr="Widdows and Dorow, 2002" startWordPosition="2614" endWordPosition="2617">bours of w and w0. If no triangle (or square) exists for e, the value of the corresponding function is set to 0. In order to disconnect the graph and determine the meaning components, we remove all the edges whose Tri (or Sqr) value is below a threshold σ. The resulting connected components represent the word senses induced for the query q. Notice that the number of senses is dynamically chosen based on the cooccurrence graph and the algorithm’s thresholds. Our triangular measure is the edge counterpart of the clustering coefficient (or curvature) for vertices, previously used to perform WSI (Widdows and Dorow, 2002). However, it is our hunch that measuring the ratio of squares an edge participates in provides a stronger clue of how important that edge is within a meaning component. In Section 4, we will corroborate this idea with our experiments. 3.1.3 An example As an example, let q = beagle. Two steps are performed: 119 1. Graph construction. We build the co-occurrence graph Gbeagle = (V, E), an excerpt of which is shown in Figure 1(a). 2. Identification of word senses. We calculate the Sqr values of each edge in the graph. The edges e whose Sqr(e) &lt; Q are removed (we assume Q = 0.25). For instance, Sq</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows and Beate Dorow. 2002. A graph model for unsupervised lexical acquisition. In Proc. of the 191h COLING, pages 1–7, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gui-Rong Xue</author>
<author>Dikan Xing</author>
<author>Qiang Yang</author>
<author>Yong Yu</author>
</authors>
<title>Deep classification in large-scale text hierarchies.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>619--626</pages>
<contexts>
<context position="4862" citStr="Xue et al., 2008" startWordPosition="780" endWordPosition="783">moz.org). Given a query, search results are organized by category. This approach has three main weaknesses: first, it is static, thus it needs manual updates to cover new pages; second, it covers only a small portion of the Web; third, it classifies Web pages based on coarse categories. This latter feature of Web directories makes it difficult to distinguish between instances of the same kind (e.g., pages about artists with the same surname classified as Arts:Music:Bands and Artists). While methods for the automatic classification of Web documents have been proposed (e.g., (Liu et al., 2005b; Xue et al., 2008)) and some problems have been effectively tackled (Bennett and Nguyen, 2009), these approaches are usually supervised and still suffer from relying on a predefined taxonomy of categories. Semantic Information Retrieval (SIR). A different direction consists of associating explicit semantics (i.e., word senses or concepts) with queries and documents, that is, performing Word Sense Disambiguation (WSD, see Navigli (2009)). SIR is performed by indexing and/or searching concepts rather than terms, thus potentially coping with two linguistic phenomena: expressing a single meaning with different word</context>
</contexts>
<marker>Xue, Xing, Yang, Yu, 2008</marker>
<rawString>Gui-Rong Xue, Dikan Xing, Qiang Yang, and Yong Yu. 2008. Deep classification in large-scale text hierarchies. In Proc. of SIGIR ’08, pages 619–626, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Israel Ben-Shaul Yoelle Maarek</author>
<author>Ron Fagin</author>
<author>Dan Pelleg</author>
</authors>
<title>Ephemeral document clustering for web applications.</title>
<date>2000</date>
<journal>IBM Research Report RJ</journal>
<pages>10186</pages>
<marker>Maarek, Fagin, Pelleg, 2000</marker>
<rawString>Israel Ben-Shaul Yoelle Maarek, Ron Fagin and Dan Pelleg. 2000. Ephemeral document clustering for web applications. IBM Research Report RJ 10186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Zamir</author>
<author>Oren Etzioni</author>
</authors>
<title>Web document clustering: a feasibility demonstration.</title>
<date>1998</date>
<booktitle>In Proc. of SIGIR ’98,</booktitle>
<pages>46--54</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="8195" citStr="Zamir and Etzioni, 1998" startWordPosition="1303" endWordPosition="1306">tering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguit</context>
<context position="10926" citStr="Zamir and Etzioni (1998)" startWordPosition="1748" endWordPosition="1751">pics – estimated from a universal dataset – are query-independent and thus their number needs to be established beforehand. In contrast, we aim to cluster snippets based on a dynamic and finergrained notion of sense. 3 Approach Web search result clustering is usually performed in three main steps: 1. Given a query q, a search engine (e.g., Yahoo!) is used to retrieve a list of results R = (ri, ... , r.); 2. A clustering C = (Co, Ci, ... , Cm) of the results in R is obtained by means of a clustering algorithm; 3. The clusters in C are optionally labeled with an appropriate algorithm (e.g., see Zamir and Etzioni (1998) and Carmel et al. (2009)) for visualization purposes. Our key idea is to improve step 2 by means of a Word Sense Induction algorithm: given a query q, we first dynamically induce, from a text corpus, the set of word senses of q (Section 3.1); next, we cluster the Web results on the basis of the word senses previously induced (Section 3.2). 3.1 Word Sense Induction Word Sense Induction algorithms are unsupervised techniques aimed at automatically identifying the set of senses denoted by a word. These methods induce word senses from text by clustering word occurrences based on the idea that a g</context>
<context position="23408" citStr="Zamir and Etzioni, 1998" startWordPosition="3954" endWordPosition="3958">eter values were obtained as a result of tuning on a small in-house development dataset. The dataset was built by automatically identifying monosemous words and creating pseudowords following the scheme proposed by Sch¨utze (1998). Systems. We compared Triangles and Squares against the best systems reported by Bernardini et al. (2009, cf. Section 2): E rzEC; si . (6) |Cj| m(ri, Sj) 121 • Lingo (Osinski and Weiss, 2005): a Web clustering engine implemented in the Carrot2 opensource framework5 that clusters the most frequent phrases extracted using suffix arrays. • Suffix Tree Clustering (STC) (Zamir and Etzioni, 1998): the original Web search clustering approach based on suffix trees. • KeySRC (Bernardini et al., 2009): a state-of-theart Web clustering engine built on top of STC with part-of-speech pruning and dynamic selection of the cut-off level of the clustering dendrogram. • Essential Pages (EP) (Swaminathan et al., 2009): a recent diversification algorithm that selects fundamental pages which maximize the amount of information covered for a given query. • Yahoo!: the original search results returned by the Yahoo! search engine. The first three of the above are Web search result clustering approaches,</context>
</contexts>
<marker>Zamir, Etzioni, 1998</marker>
<rawString>Oren Zamir and Oren Etzioni. 1998. Web document clustering: a feasibility demonstration. In Proc. of SIGIR ’98, pages 46–54, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Zamir</author>
<author>Oren Etzioni</author>
<author>Omid Madani</author>
<author>Richard M Karp</author>
</authors>
<title>Fast and intuitive clustering of web documents.</title>
<date>1997</date>
<booktitle>In Proc. of KDD ’97,</booktitle>
<pages>287--290</pages>
<location>Newport Beach, California.</location>
<contexts>
<context position="8169" citStr="Zamir et al., 1997" startWordPosition="1299" endWordPosition="1302">group, performs clustering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic deali</context>
</contexts>
<marker>Zamir, Etzioni, Madani, Karp, 1997</marker>
<rawString>Oren Zamir, Oren Etzioni, Omid Madani, and Richard M. Karp. 1997. Fast and intuitive clustering of web documents. In Proc. of KDD ’97, pages 287–290, Newport Beach, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Jun Zeng</author>
<author>Qi-Cai He</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
<author>Jinwen Ma</author>
</authors>
<title>Learning to cluster web search results.</title>
<date>2004</date>
<booktitle>In Proc. of SIGIR ’04,</booktitle>
<pages>210--217</pages>
<location>Sheffield, UK.</location>
<contexts>
<context position="8715" citStr="Zeng et al., 2004" startWordPosition="1382" endWordPosition="1385">uccessful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al., 2007), and graph connectivity measures (Di Giacomo et al., 2007). Search result clustering has also been viewed as a supervised salient phrase ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditional probabilities to determine which document is most different from higherranking ones (Chen and Karger, 2006) or use affinity ranking (Zhang et al., 2005), based on to</context>
</contexts>
<marker>Zeng, He, Chen, Ma, Ma, 2004</marker>
<rawString>Hua-Jun Zeng, Qi-Cai He, Zheng Chen, Wei-Ying Ma, and Jinwen Ma. 2004. Learning to cluster web search results. In Proc. of SIGIR ’04, pages 210–217, Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>William W Cohen</author>
<author>John Lafferty</author>
</authors>
<title>Beyond independent relevance: Methods and evaluation metrics for subtopic retrieval.</title>
<date>2003</date>
<booktitle>In Proc. of SIGIR ’03,</booktitle>
<pages>10--17</pages>
<location>Toronto, Canada.</location>
<contexts>
<context position="26490" citStr="Zhai et al., 2003" startWordPosition="4467" endWordPosition="4470"> on AMBIENT). Interestingly, all clustering systems perform more poorly on longer queries (i.e., on the MORESQUE dataset), however our WSI systems, and especially Triangles, are more robust across query lengths. Compared to Triangles, the Squares algorithm performs better, confirming our hunch that Squares is a more solid graph pattern. 4.3 Experiment 2: Diversification Measure. Search result clustering can also be used to diversify the top results returned by a search engine. Thus, for each query q, one natural way of measuring a system’s performance is to calculate the subtopic recall-at-K (Zhai et al., 2003) given by the number of different subtopics retrieved for q in the top K results returned: UK i subtopics(ri)| S-recall@K = i= (9) M where subtopics(ri) is the set of subtopics manually assigned to the search result ri and M is the number of subtopics for query q (note that in our experiments M is the number of subtopics occurring in the 100 results retrieved for q, so S-recall@100 = 1). However, this measure is only suitable for systems returning ranked lists (such as Yahoo! and EP). Given 6For reference systems we used the implementations of Bernardini et al. (2009) and Osinski and Weiss (20</context>
</contexts>
<marker>Zhai, Cohen, Lafferty, 2003</marker>
<rawString>ChengXiang Zhai, William W. Cohen, and John Lafferty. 2003. Beyond independent relevance: Methods and evaluation metrics for subtopic retrieval. In Proc. of SIGIR ’03, pages 10–17, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benyu Zhang</author>
<author>Hua Li</author>
<author>Yi Liu</author>
<author>Lei Ji</author>
<author>Wensi Xi</author>
<author>Weiguo Fan</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
</authors>
<title>Improving web search results using affinity graph.</title>
<date>2005</date>
<booktitle>In Proc. of SIGIR ’05,</booktitle>
<pages>504--511</pages>
<location>Salvador, Brazil.</location>
<contexts>
<context position="9302" citStr="Zhang et al., 2005" startWordPosition="1470" endWordPosition="1473">ranking task (Zeng et al., 2004). Diversification. Another recent research topic dealing with the query ambiguity issue is diversification, which aims to rerank top search results based on criteria that maximize their diversity. One of the first examples of diversification algorithms is based on the use of similarity functions to measure the diversity among documents and between document and query (Carbonell and Goldstein, 1998). Other techniques use conditional probabilities to determine which document is most different from higherranking ones (Chen and Karger, 2006) or use affinity ranking (Zhang et al., 2005), based on topic variance and coverage. More recently, an algorithm called Essential Pages (Swaminathan et al., 2009) has been proposed to reduce information redundancy and return Web pages that maximize coverage with respect to the input query. Word Sense Induction (WSI). In contrast to the above approaches, we perform WSI to dynamically acquire an inventory of senses of the input query. Instead of performing clustering on the basis of the surface similarity of Web snippets, we use our induced word senses to group snippets. Very little work on this topic exists: vector-based WSI was successfu</context>
</contexts>
<marker>Zhang, Li, Liu, Ji, Xi, Fan, Chen, Ma, 2005</marker>
<rawString>Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Weiguo Fan, Zheng Chen, and Wei-Ying Ma. 2005. Improving web search results using affinity graph. In Proc. of SIGIR ’05, pages 504–511, Salvador, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodan Zhang</author>
<author>Xiaohua Hu</author>
<author>Xiaohua Zhou</author>
</authors>
<title>A comparative evaluation of different link types on enhancing document clustering.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR ’08,</booktitle>
<pages>555--562</pages>
<contexts>
<context position="7939" citStr="Zhang et al., 2008" startWordPosition="1263" endWordPosition="1266">e on the problem of data clustering than on presenting the results to the user. A pioneering example is Scatter/Gather (Cutting et al., 1992), which divides the dataset into a small number of clusters and, after the selection of a group, performs clustering again and proceeds iteratively. Developments of this approach have been proposed which improve on cluster quality and retrieval performance (Ke et al., 2009). Other data-centric approaches use agglomerative hierarchical clustering (e.g., LASSI (Yoelle Maarek and Pelleg, 2000)), rough sets (Ngo and Nguyen, 2005) or exploit link information (Zhang et al., 2008). Description-centric approaches are, instead, more 117 focused on the description to produce for each cluster of search results. Among the most popular and successful approaches are those based on suffix trees (Zamir et al., 1997; Zamir and Etzioni, 1998), including later developments (Crabtree et al., 2005; Bernardini et al., 2009). Other methods in the literature are based on formal concept analysis (Carpineto and Romano, 2004), singular value decomposition (Osinski and Weiss, 2005), spectral clustering (Cheng et al., 2005), spectral geometry (Liu et al., 2008), link analysis (Gelgi et al.,</context>
</contexts>
<marker>Zhang, Hu, Zhou, 2008</marker>
<rawString>Xiaodan Zhang, Xiaohua Hu, and Xiaohua Zhou. 2008. A comparative evaluation of different link types on enhancing document clustering. In Proc. of SIGIR ’08, pages 555–562, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>