<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011662">
<note confidence="0.449457">
Book Review Language as a Cognitive Process
</note>
<title confidence="0.569765">
Book Review
</title>
<subsectionHeader confidence="0.891774">
The Textbook Problem: Winograd&apos;s Language
as a Cognitive Process
</subsectionHeader>
<bodyText confidence="0.999709085106383">
Winograd&apos;s three ambitious goals for Language as a
Cognitive Process. Volume 1. Syntax (henceforth LCP1)
were to provide (1) a textbook for beginning graduate
students, (2) a practical guide for builders of natural
language systems, and (3) a reference source for linguis-
tics and computer science. These three goals are not
easily reconciled within a single book, even one to be
expanded to two volumes. With its comprehensive
coverage of the literature and its evenhanded treatment
of a variety of formalisms, LCP1 is most successful as a
reference volume. It is less successful as a practical guide
for system builders who need programming examples
because, despite numerous helpful suggestions, Winograd
chose to present algorithms in his own special description
language (DL), thus requiring students to translate these
descriptions into some programming language in order to
implement them. As a textbook, however, I believe LCP1
founders.
A reasonable textbook should present (i) material
ordered in a sequence that leads the student naturally
through subject matter that reflects (ii) the author&apos;s
clearly expressed point of view and (iii) a coherent
rationale for the selective coverage of the particular field.
Chapters 2, 3, and 5 satisfy requirement (i) by marching
steadily from the simpler to the more complex, from tran-
sition networks through context-free grammars and pars-
ing to recursive transition networks, and finally ATNs.
Chapter 1 satisfies the second of these ideals with a pres-
entation of the &amp;quot;computational paradigm&amp;quot;. Winograd&apos;s
comparison of this with the &amp;quot;generative paradigm&amp;quot; offers
the student a valuable perspective on the kinds of claims
(modularity, communicative goals, knowledge represen-
tation, and the like) that computational models make
about language comprehension.
The central problems lie with item (iii). In nearly
every case where clarity and brevity would dictate that a
detail be omitted or an alternative ignored, Winograd
instead includes the additional material required for the
nearly exhaustive coverage of a reference book. Two
examples will illustrate. In Section 3.1 three approaches
to assigning constituent structure (head and modifier,
immediate constituent, and slot and filler) are treated
equally even though the head and modifier method is not
referred to elsewhere in LCP1. In Section 3.4 the
samples of context-free non-deterministic recognition
procedures include top-down backtracking, top-down
parallel and bottom-up parallel algorithms with bottom-
up backtracking left as an exercise. Because of such
comprehensive coverage, using LCP1 as a textbook is a
bit like adopting The Handbook of Artificial Intelligence
for an Al course or assigning Knuth&apos;s three-volume work
The Art of Computer Programming for a course in algo-
rithms.
Moreover, Winograd makes little attempt to distin-
guish required (or more important) from optional (or less
important) information. That it is possible and useful to
make such distinctions is illustrated by the organization
of John Sowa&apos;s new Al text (Sowa 1983). Introductory
material is presented in the first section of each chapter
and the first page or two of subsequent sections so that
when the material advances beyond one&apos;s level of interest
a reader may skip to the next section without losing
continuity.
As a linguist trained in generative grammar, I found
Chapter 4, &amp;quot;Transformational Grammar&amp;quot;, among the
least satisfactory. Chomsky&apos;s linguistic theory has
contributed much to our understanding of language as a
cognitive process but little to the field of natural language
processing or to the emergence of the computational
paradigm. Given Winograd&apos;s computational stance, the
rationale is weak for devoting an entire chapter plus an
appendix (&amp;quot;Current Directions in Transformation
Grammar&amp;quot;) to major developments in generative linguis-
tics from Syntactic Structures to trace theory. Linguistics
students have far better sources to learn about the work
of Chomsky and other generativists, and computer scien-
tists, by and large, are indifferent. If the goals of LCP1
were less global, this material could have been greatly
reduced without ill effect.
The purpose of Chapter 6 is not at all clear. Entitled
&amp;quot;Feature and Function Grammars&amp;quot;, the chapter contains
an amorphous collection of grammatical formalisms
whose common theme appears to be their emphasis on
functional considerations. Most attention is given to
Halliday&apos;s systematic grammar even though this approach
has not figured importantly in computational work or
contributed major insights to the cognitive perspective on
language. Curiously, Winograd only mentions in passing
the strong influence that systemic grammar had on
SHRDLU&apos;s procedural semantics. Along with case gram-
mar, brief descriptions of several newer approaches —
lexical-functional grammar, generalized phrase structure
grammar, and definite clause grammar — are tossed in
almost as afterthoughts.
</bodyText>
<page confidence="0.826639">
148 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.307589">
Book Review Language as a Cognitive Process
</note>
<bodyText confidence="0.99985362264151">
The first six chapters of LCP1 exemplify a recent trend
in Al textbooks toward covering the inventory of princi-
ples, algorithms, and data structures that comprise the
basic knowledge of the field (e.g., Rich 1983 and
Winston 1984) rather than describing existing systems
(e.g., Winston 1977 and Tennant 1981). Though admi-
rable in many respects, this more theoretical orientation
fails at times to provide the necessary links between the
abstractions being taught and real world examples in a
field whose most significant achievements lie in the
success of its implemented systems. To counter this
potential problem, Chapter 7, &amp;quot;Computer Systems for
Natural Language Parsing&amp;quot;, contains summaries of over
fifty projects.
The main difficulty with LCP1 is that language as a
cognitive process, by Winograd&apos;s own definition, is a
concept too broad to fit within the confines of one book.
In his March 1982 Preface Winograd wrote that this first
of what was to become a two-volume text had its origins
nearly ten years earlier in notes for a one-term course
that he gradually expanded over the years into enough
material for three terms. The division into separate
volumes on syntax and semantics, whatever its pedagog-
ical usefulness, is artificial, as Winograd himself recog-
nizes, and belies, in practice if not in spirit, the necessary
interaction between the two in natural language process-
ing systems.
According to this preface, Winograd&apos;s views of
language and cognition changed significantly while work-
ing on LCP1. None of his newer ideas are incorporated
in this text, however, despite the fact that he presented
his more recent thinking as early as 1979 at the La Jolla
Conference on Cognitive Science (Winograd 1980).
Indeed, at La Jolla Winograd proposed a fundamental
shift away from a focus on language as cognitive process-
ing to a focus on language as that part of &amp;quot;the domain of
human action and interaction&amp;quot;, that is reflected in human
discourse and advocated speech acts as the basis for a
theory of &amp;quot;language interaction&amp;quot;.
For a typical one-term introductory graduate level
course there is a real need for a text that covers both
syntax and semantics in a single volume. Volume 1 was
useful as a text for only about 65% of my course. When
students selected topics for term projects, almost all
chose to investigate natural language systems or to
explore issues in semantics.
Volume 2 will surely rival its predecessor in impor-
tance if the treatment of semantics and other aspects of
meaning equals the coverage of syntax in Volume 1.
Nonetheless, whatever its enduring value as a reference
work, its everyday usefulness as a textbook is highly
questionable, Nirenburg (1983) to the contrary notwith-
standing.
</bodyText>
<reference confidence="0.71216875">
Virginia Teller
Computer Science Department
Hunter College, CUNY
New York, NY 10021
</reference>
<sectionHeader confidence="0.830325" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.98269704">
Barr, A.; Feigenbaum, E.; and Cohen, P. 1981-2 The Handbook of Arti-
ficial Intelligence. William Kaufmann, Los Altos, California.
Grishman, R. In preparation An Introduction to Computational Linguis-
tics.
Knuth, D. 1973-1981 The Art of Computer Programming. Three
Volumes. Addison-Wesley, Reading, Massachusetts.
Nirenburg, S. 1983 Review of Language as a Cognitive Process. Volume
I. Syntax by T. Winograd. American Journal of Computational
Linguistics 9(1): 25-29.
Rich, E. 1983 Artificial Intelligence. McGraw-Hill, New York, New
York.
Sowa, J. 1983 Conceptual Structures. Information Processing in Mind
and Machine. Addison-Wesley, Reading, Massachusetts.
Tennant, H. 1981 Natural Language Processing. Petrocelli, Princeton,
New Jersey.
Winston, P. 1977 Artificial Intelligence. First Edition. Addison-Wesley,
Reading, Massachusetts.
Winston, P. 1984 Artificial Intelligence. Second Edition. Addison-Wes-
ley, Reading, Massachusetts.
Winograd, T. 1980 What Does It Mean to Understand Language?
Cognitive Science 4: 209-241. Also in Norman, D., Ed., Perspectives in
Cognitive Science. Ablex, Norwood, New Jersey: 231-263.
Winograd, T. 1983 Language as a Cognitive Process. Volume I.
Syntax. Addison-Wesley, Reading, Massachuetts.
Computational Linguistics Volume 10, Number 2, April-June 1984 149
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.141424">
<title confidence="0.827547">Book Review Language as a Cognitive Process Book Review The Textbook Problem: Winograd&apos;s Language</title>
<abstract confidence="0.993143326666666">as a Cognitive Process three ambitious goals for as a Process. Volume 1. Syntax LCP1) were to provide (1) a textbook for beginning graduate students, (2) a practical guide for builders of natural language systems, and (3) a reference source for linguistics and computer science. These three goals are not easily reconciled within a single book, even one to be expanded to two volumes. With its comprehensive coverage of the literature and its evenhanded treatment of a variety of formalisms, LCP1 is most successful as a reference volume. It is less successful as a practical guide for system builders who need programming examples because, despite numerous helpful suggestions, Winograd chose to present algorithms in his own special description language (DL), thus requiring students to translate these descriptions into some programming language in order to implement them. As a textbook, however, I believe LCP1 founders. A reasonable textbook should present (i) material ordered in a sequence that leads the student naturally through subject matter that reflects (ii) the author&apos;s clearly expressed point of view and (iii) a coherent rationale for the selective coverage of the particular field. Chapters 2, 3, and 5 satisfy requirement (i) by marching steadily from the simpler to the more complex, from transition networks through context-free grammars and parsing to recursive transition networks, and finally ATNs. Chapter 1 satisfies the second of these ideals with a presentation of the &amp;quot;computational paradigm&amp;quot;. Winograd&apos;s comparison of this with the &amp;quot;generative paradigm&amp;quot; offers the student a valuable perspective on the kinds of claims (modularity, communicative goals, knowledge representation, and the like) that computational models make about language comprehension. The central problems lie with item (iii). In nearly every case where clarity and brevity would dictate that a detail be omitted or an alternative ignored, Winograd instead includes the additional material required for the nearly exhaustive coverage of a reference book. Two examples will illustrate. In Section 3.1 three approaches to assigning constituent structure (head and modifier, immediate constituent, and slot and filler) are treated equally even though the head and modifier method is not referred to elsewhere in LCP1. In Section 3.4 the samples of context-free non-deterministic recognition procedures include top-down backtracking, top-down parallel and bottom-up parallel algorithms with bottomup backtracking left as an exercise. Because of such coverage, using a textbook is a like adopting Handbook of Artificial Intelligence for an Al course or assigning Knuth&apos;s three-volume work Art of Computer Programming a course in algorithms. Moreover, Winograd makes little attempt to distinguish required (or more important) from optional (or less important) information. That it is possible and useful to make such distinctions is illustrated by the organization of John Sowa&apos;s new Al text (Sowa 1983). Introductory material is presented in the first section of each chapter and the first page or two of subsequent sections so that when the material advances beyond one&apos;s level of interest a reader may skip to the next section without losing continuity. As a linguist trained in generative grammar, I found Chapter 4, &amp;quot;Transformational Grammar&amp;quot;, among the least satisfactory. Chomsky&apos;s linguistic theory contributed much to our understanding of language as a cognitive process but little to the field of natural language processing or to the emergence of the computational paradigm. Given Winograd&apos;s computational stance, the rationale is weak for devoting an entire chapter plus an appendix (&amp;quot;Current Directions in Transformation Grammar&amp;quot;) to major developments in generative linguisfrom Structures trace theory. Linguistics students have far better sources to learn about the work of Chomsky and other generativists, and computer scienby and large, are indifferent. If the goals of were less global, this material could have been greatly reduced without ill effect. The purpose of Chapter 6 is not at all clear. Entitled &amp;quot;Feature and Function Grammars&amp;quot;, the chapter contains an amorphous collection of grammatical formalisms whose common theme appears to be their emphasis on functional considerations. Most attention is given to Halliday&apos;s systematic grammar even though this approach has not figured importantly in computational work or contributed major insights to the cognitive perspective on language. Curiously, Winograd only mentions in passing the strong influence that systemic grammar had on SHRDLU&apos;s procedural semantics. Along with case grammar, brief descriptions of several newer approaches — lexical-functional grammar, generalized phrase structure grammar, and definite clause grammar — are tossed in almost as afterthoughts. Linguistics Volume 10, Number 2, April-June 1984 Book Review Language as a Cognitive Process The first six chapters of LCP1 exemplify a recent trend in Al textbooks toward covering the inventory of principles, algorithms, and data structures that comprise the basic knowledge of the field (e.g., Rich 1983 and Winston 1984) rather than describing existing systems (e.g., Winston 1977 and Tennant 1981). Though admirable in many respects, this more theoretical orientation fails at times to provide the necessary links between the abstractions being taught and real world examples in a field whose most significant achievements lie in the success of its implemented systems. To counter this potential problem, Chapter 7, &amp;quot;Computer Systems for Natural Language Parsing&amp;quot;, contains summaries of over fifty projects. The main difficulty with LCP1 is that language as a cognitive process, by Winograd&apos;s own definition, is a concept too broad to fit within the confines of one book. In his March 1982 Preface Winograd wrote that this first of what was to become a two-volume text had its origins nearly ten years earlier in notes for a one-term course that he gradually expanded over the years into enough material for three terms. The division into separate volumes on syntax and semantics, whatever its pedagogical usefulness, is artificial, as Winograd himself recognizes, and belies, in practice if not in spirit, the necessary interaction between the two in natural language processing systems. According to this preface, Winograd&apos;s views of language and cognition changed significantly while workon of his newer ideas are incorporated in this text, however, despite the fact that he presented his more recent thinking as early as 1979 at the La Jolla Conference on Cognitive Science (Winograd 1980). Indeed, at La Jolla Winograd proposed a fundamental shift away from a focus on language as cognitive processing to a focus on language as that part of &amp;quot;the domain of human action and interaction&amp;quot;, that is reflected in human discourse and advocated speech acts as the basis for a theory of &amp;quot;language interaction&amp;quot;. For a typical one-term introductory graduate level course there is a real need for a text that covers both syntax and semantics in a single volume. Volume 1 was useful as a text for only about 65% of my course. When students selected topics for term projects, almost all chose to investigate natural language systems or to explore issues in semantics. Volume 2 will surely rival its predecessor in importance if the treatment of semantics and other aspects of meaning equals the coverage of syntax in Volume 1. Nonetheless, whatever its enduring value as a reference work, its everyday usefulness as a textbook is highly questionable, Nirenburg (1983) to the contrary notwithstanding.</abstract>
<author confidence="0.984">Virginia Teller</author>
<affiliation confidence="0.999064">Computer Science Department</affiliation>
<address confidence="0.8264205">Hunter College, CUNY New York, NY 10021</address>
<note confidence="0.846915666666667">References A.; Feigenbaum, E.; and Cohen, P. 1981-2 Handbook of Arti- Intelligence. Kaufmann, Los Altos, California.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<pages>10021</pages>
<institution>Virginia Teller Computer Science Department Hunter College, CUNY</institution>
<location>New York, NY</location>
<marker></marker>
<rawString>Virginia Teller Computer Science Department Hunter College, CUNY New York, NY 10021</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Barr</author>
<author>E Feigenbaum</author>
<author>P Cohen</author>
</authors>
<title>The Handbook of Artificial Intelligence.</title>
<date>1981</date>
<booktitle>In preparation An Introduction to Computational Linguistics.</booktitle>
<publisher>William Kaufmann,</publisher>
<location>Los Altos, California. Grishman, R.</location>
<marker>Barr, Feigenbaum, Cohen, 1981</marker>
<rawString>Barr, A.; Feigenbaum, E.; and Cohen, P. 1981-2 The Handbook of Artificial Intelligence. William Kaufmann, Los Altos, California. Grishman, R. In preparation An Introduction to Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Knuth</author>
</authors>
<title>The Art of Computer Programming. Three Volumes.</title>
<date>1973</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<marker>Knuth, 1973</marker>
<rawString>Knuth, D. 1973-1981 The Art of Computer Programming. Three Volumes. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nirenburg</author>
</authors>
<title>Review of Language as a Cognitive Process. Volume I. Syntax by T.</title>
<date>1983</date>
<journal>Winograd. American Journal of Computational Linguistics</journal>
<volume>9</volume>
<issue>1</issue>
<pages>25--29</pages>
<marker>Nirenburg, 1983</marker>
<rawString>Nirenburg, S. 1983 Review of Language as a Cognitive Process. Volume I. Syntax by T. Winograd. American Journal of Computational Linguistics 9(1): 25-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rich</author>
</authors>
<title>Artificial Intelligence.</title>
<date>1983</date>
<publisher>McGraw-Hill,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="5377" citStr="Rich 1983" startWordPosition="807" endWordPosition="808">strong influence that systemic grammar had on SHRDLU&apos;s procedural semantics. Along with case grammar, brief descriptions of several newer approaches — lexical-functional grammar, generalized phrase structure grammar, and definite clause grammar — are tossed in almost as afterthoughts. 148 Computational Linguistics Volume 10, Number 2, April-June 1984 Book Review Language as a Cognitive Process The first six chapters of LCP1 exemplify a recent trend in Al textbooks toward covering the inventory of principles, algorithms, and data structures that comprise the basic knowledge of the field (e.g., Rich 1983 and Winston 1984) rather than describing existing systems (e.g., Winston 1977 and Tennant 1981). Though admirable in many respects, this more theoretical orientation fails at times to provide the necessary links between the abstractions being taught and real world examples in a field whose most significant achievements lie in the success of its implemented systems. To counter this potential problem, Chapter 7, &amp;quot;Computer Systems for Natural Language Parsing&amp;quot;, contains summaries of over fifty projects. The main difficulty with LCP1 is that language as a cognitive process, by Winograd&apos;s own defi</context>
</contexts>
<marker>Rich, 1983</marker>
<rawString>Rich, E. 1983 Artificial Intelligence. McGraw-Hill, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sowa</author>
</authors>
<title>Conceptual Structures.</title>
<date>1983</date>
<booktitle>Information Processing in Mind and Machine.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="3175" citStr="Sowa 1983" startWordPosition="478" endWordPosition="479">ing, top-down parallel and bottom-up parallel algorithms with bottomup backtracking left as an exercise. Because of such comprehensive coverage, using LCP1 as a textbook is a bit like adopting The Handbook of Artificial Intelligence for an Al course or assigning Knuth&apos;s three-volume work The Art of Computer Programming for a course in algorithms. Moreover, Winograd makes little attempt to distinguish required (or more important) from optional (or less important) information. That it is possible and useful to make such distinctions is illustrated by the organization of John Sowa&apos;s new Al text (Sowa 1983). Introductory material is presented in the first section of each chapter and the first page or two of subsequent sections so that when the material advances beyond one&apos;s level of interest a reader may skip to the next section without losing continuity. As a linguist trained in generative grammar, I found Chapter 4, &amp;quot;Transformational Grammar&amp;quot;, among the least satisfactory. Chomsky&apos;s linguistic theory has contributed much to our understanding of language as a cognitive process but little to the field of natural language processing or to the emergence of the computational paradigm. Given Winogra</context>
</contexts>
<marker>Sowa, 1983</marker>
<rawString>Sowa, J. 1983 Conceptual Structures. Information Processing in Mind and Machine. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tennant</author>
</authors>
<title>Natural Language Processing.</title>
<date>1981</date>
<location>Petrocelli, Princeton, New Jersey.</location>
<contexts>
<context position="5473" citStr="Tennant 1981" startWordPosition="821" endWordPosition="822"> grammar, brief descriptions of several newer approaches — lexical-functional grammar, generalized phrase structure grammar, and definite clause grammar — are tossed in almost as afterthoughts. 148 Computational Linguistics Volume 10, Number 2, April-June 1984 Book Review Language as a Cognitive Process The first six chapters of LCP1 exemplify a recent trend in Al textbooks toward covering the inventory of principles, algorithms, and data structures that comprise the basic knowledge of the field (e.g., Rich 1983 and Winston 1984) rather than describing existing systems (e.g., Winston 1977 and Tennant 1981). Though admirable in many respects, this more theoretical orientation fails at times to provide the necessary links between the abstractions being taught and real world examples in a field whose most significant achievements lie in the success of its implemented systems. To counter this potential problem, Chapter 7, &amp;quot;Computer Systems for Natural Language Parsing&amp;quot;, contains summaries of over fifty projects. The main difficulty with LCP1 is that language as a cognitive process, by Winograd&apos;s own definition, is a concept too broad to fit within the confines of one book. In his March 1982 Preface</context>
</contexts>
<marker>Tennant, 1981</marker>
<rawString>Tennant, H. 1981 Natural Language Processing. Petrocelli, Princeton, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Winston</author>
</authors>
<title>Artificial Intelligence. First Edition.</title>
<date>1977</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="5455" citStr="Winston 1977" startWordPosition="818" endWordPosition="819">. Along with case grammar, brief descriptions of several newer approaches — lexical-functional grammar, generalized phrase structure grammar, and definite clause grammar — are tossed in almost as afterthoughts. 148 Computational Linguistics Volume 10, Number 2, April-June 1984 Book Review Language as a Cognitive Process The first six chapters of LCP1 exemplify a recent trend in Al textbooks toward covering the inventory of principles, algorithms, and data structures that comprise the basic knowledge of the field (e.g., Rich 1983 and Winston 1984) rather than describing existing systems (e.g., Winston 1977 and Tennant 1981). Though admirable in many respects, this more theoretical orientation fails at times to provide the necessary links between the abstractions being taught and real world examples in a field whose most significant achievements lie in the success of its implemented systems. To counter this potential problem, Chapter 7, &amp;quot;Computer Systems for Natural Language Parsing&amp;quot;, contains summaries of over fifty projects. The main difficulty with LCP1 is that language as a cognitive process, by Winograd&apos;s own definition, is a concept too broad to fit within the confines of one book. In his </context>
</contexts>
<marker>Winston, 1977</marker>
<rawString>Winston, P. 1977 Artificial Intelligence. First Edition. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Winston</author>
</authors>
<title>Artificial Intelligence. Second Edition.</title>
<date>1984</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="5395" citStr="Winston 1984" startWordPosition="810" endWordPosition="811">ce that systemic grammar had on SHRDLU&apos;s procedural semantics. Along with case grammar, brief descriptions of several newer approaches — lexical-functional grammar, generalized phrase structure grammar, and definite clause grammar — are tossed in almost as afterthoughts. 148 Computational Linguistics Volume 10, Number 2, April-June 1984 Book Review Language as a Cognitive Process The first six chapters of LCP1 exemplify a recent trend in Al textbooks toward covering the inventory of principles, algorithms, and data structures that comprise the basic knowledge of the field (e.g., Rich 1983 and Winston 1984) rather than describing existing systems (e.g., Winston 1977 and Tennant 1981). Though admirable in many respects, this more theoretical orientation fails at times to provide the necessary links between the abstractions being taught and real world examples in a field whose most significant achievements lie in the success of its implemented systems. To counter this potential problem, Chapter 7, &amp;quot;Computer Systems for Natural Language Parsing&amp;quot;, contains summaries of over fifty projects. The main difficulty with LCP1 is that language as a cognitive process, by Winograd&apos;s own definition, is a conce</context>
</contexts>
<marker>Winston, 1984</marker>
<rawString>Winston, P. 1984 Artificial Intelligence. Second Edition. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>What Does It Mean to Understand Language?</title>
<date>1980</date>
<journal>Cognitive Science</journal>
<booktitle>Perspectives in Cognitive Science. Ablex,</booktitle>
<volume>4</volume>
<pages>209--241</pages>
<location>Norwood, New Jersey:</location>
<note>Also in</note>
<contexts>
<context position="6884" citStr="Winograd 1980" startWordPosition="1048" endWordPosition="1049"> material for three terms. The division into separate volumes on syntax and semantics, whatever its pedagogical usefulness, is artificial, as Winograd himself recognizes, and belies, in practice if not in spirit, the necessary interaction between the two in natural language processing systems. According to this preface, Winograd&apos;s views of language and cognition changed significantly while working on LCP1. None of his newer ideas are incorporated in this text, however, despite the fact that he presented his more recent thinking as early as 1979 at the La Jolla Conference on Cognitive Science (Winograd 1980). Indeed, at La Jolla Winograd proposed a fundamental shift away from a focus on language as cognitive processing to a focus on language as that part of &amp;quot;the domain of human action and interaction&amp;quot;, that is reflected in human discourse and advocated speech acts as the basis for a theory of &amp;quot;language interaction&amp;quot;. For a typical one-term introductory graduate level course there is a real need for a text that covers both syntax and semantics in a single volume. Volume 1 was useful as a text for only about 65% of my course. When students selected topics for term projects, almost all chose to inves</context>
</contexts>
<marker>Winograd, 1980</marker>
<rawString>Winograd, T. 1980 What Does It Mean to Understand Language? Cognitive Science 4: 209-241. Also in Norman, D., Ed., Perspectives in Cognitive Science. Ablex, Norwood, New Jersey: 231-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Language as a Cognitive Process. Volume I. Syntax.</title>
<date>1983</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachuetts.</location>
<marker>Winograd, 1983</marker>
<rawString>Winograd, T. 1983 Language as a Cognitive Process. Volume I. Syntax. Addison-Wesley, Reading, Massachuetts.</rawString>
</citation>
<citation valid="false">
<date>1984</date>
<volume>10</volume>
<pages>149</pages>
<institution>Computational Linguistics</institution>
<marker>1984</marker>
<rawString>Computational Linguistics Volume 10, Number 2, April-June 1984 149</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>