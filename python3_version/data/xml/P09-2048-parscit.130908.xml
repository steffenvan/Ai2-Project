<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005593">
<title confidence="0.991194">
Learning Semantic Categories from Clickthrough Logs
</title>
<author confidence="0.99188">
Mamoru Komachi
</author>
<affiliation confidence="0.998122">
Nara Institute of Science and Technology (NAIST)
</affiliation>
<address confidence="0.656206">
8916-5 Takayama, Ikoma, Nara 630-0192, Japan
</address>
<email confidence="0.985343">
mamoru-k@is.naist.jp
</email>
<author confidence="0.801565">
Shimpei Makimoto and Kei Uchiumi and Manabu Sassano
</author>
<affiliation confidence="0.821301">
Yahoo Japan Corporation
</affiliation>
<address confidence="0.861394">
Midtown Tower, 9-7-1 Akasaka, Minato-ku, Tokyo 107-6211, Japan
</address>
<email confidence="0.962516">
{smakimot,kuchiumi,msassano}@yahoo-corp.jp
</email>
<sectionHeader confidence="0.99383" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999948">
As the web grows larger, knowledge ac-
quisition from the web has gained in-
creasing attention. In this paper, we pro-
pose using web search clickthrough logs
to learn semantic categories. Experimen-
tal results show that the proposed method
greatly outperforms previous work using
only web search query logs.
</bodyText>
<sectionHeader confidence="0.998413" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997535592592593">
Compared to other text resources, search queries
more directly reflect search users’ interests (Sil-
verstein et al., 1998). Web search logs are get-
ting a lot more attention lately as a source of in-
formation for applications such as targeted adver-
tisement and query suggestion.
However, it may not be appropriate to use
queries themselves because query strings are often
too heterogeneous or inspecific to characterize the
interests of the user population. Although it is not
clear that query logs are the best source of learning
semantic categories, all the previous studies using
web search logs rely on web search query logs.
Therefore, we propose to use web search
clickthrough logs to learn semantic categories.
Joachims (2002) developed a method that utilizes
clickthrough logs for training ranking of search
engines. A search clickthrough is a link which
search users click when they see the result of
their search. The intentions of two distinct search
queries are likely to be similar, if not identical,
when they have the same clickthrough. Search
clickthrough logs are thus potentially useful for
learnin semantic categories. Clickthrough logs
have the additional advantage that they are avail-
able in abundance and can be stored at very low
cost.1 Our proposed method employs search click-
</bodyText>
<footnote confidence="0.530055">
1As for data availability, MSN Search query logs
(RFP 2006 dataset) were provided to WSCD09: Work-
</footnote>
<bodyText confidence="0.999669571428571">
through logs to improve semantic category acqui-
sition in both precision and recall.
We cast semantic category acquisition from
search logs as the task of learning labeled in-
stances from few labeled seeds. To our knowledge
this is the first study that exploits search click-
through logs for semantic category learning.2
</bodyText>
<sectionHeader confidence="0.999785" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999562769230769">
There are many techniques that have been devel-
oped to help elicit knowledge from query logs.
These algorithms use contextual patterns to extract
a category or a relation in order to learn a target in-
stance which belongs to the category (e.g. cat in
animal class) or a pair of words in specific relation
(e.g. headquarter to a company). In this work,
we focus on extracting named entities of the same
class to learn semantic categories.
Pas¸ca and Durme (2007) were the first to dis-
cover the importance of search query logs in nat-
ural language processing applications. They fo-
cused on learning attributes of named entities, and
thus their objective is different from ours. An-
other line of new research is to combine various re-
sources such as web documents with search query
logs (Pas¸ca and Durme, 2008; Talukdar et al.,
2008). We differ from this work in that we use
search clickthrough logs rather than search query
logs.
Komachi and Suzuki (2008) proposed a boot-
strapping algorithm called Tchai, dedicated to the
task of semantic category acquisition from search
query logs. It achieves state-of-the-art perfor-
mance for this task, but it only uses web search
query logs.
</bodyText>
<footnote confidence="0.997450166666667">
shop on Web Search Click Data 2009 participants. http://
research.microsoft.com/en-US/um/people/nickcr/WSCD09/
2After the submission of this paper, we found that (Xu et
al., 2009) also applies search clickthrough logs to this task.
This work independently confirms the effectiveness of click-
through logs to this task using different sources.
</footnote>
<page confidence="0.935031">
189
</page>
<note confidence="0.9801275">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 189–192,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<figureCaption confidence="0.996548">
Figure 1: Labels of seeds are propagated to unla-
beled nodes.
</figureCaption>
<sectionHeader confidence="0.995073" genericHeader="method">
3 Quetchup3 Algorithm
</sectionHeader>
<bodyText confidence="0.99946825">
In this section, we describe an algorithm for
learning semantic categories from search logs us-
ing label propagation. We name the algorithm
Quetchup.
</bodyText>
<subsectionHeader confidence="0.999103">
3.1 Semi-supervised Learning by Laplacian
Label Propagation
</subsectionHeader>
<bodyText confidence="0.99985396">
Graph-based semi-supervised methods such as la-
bel propagation are known to achieve high perfor-
mance with only a few seeds and have the advan-
tage of scalability.
Figure 1 illustrates the process of label propa-
gation using a seed term “singapore” to learn the
Travel domain.
This is a bipartite graph whose left-hand side
nodes are terms and right-hand side nodes are
patterns. The strength of lines indicates related-
ness between each node. The darker a node, the
more likely it belongs to the Travel domain. Start-
ing from “singapore,” the pattern “♯ airlines” 4 is
strongly related to “singapore,” and thus the label
of “singapore” will be propagated to the pattern.
On the other hand, the pattern “♯ map” is a neu-
tral pattern which co-occurs with terms other than
the Travel domain such as “google” and “yahoo.”
Since the term “china” shares two patterns, “♯ air-
lines” and “♯ map,” with “singapore,” the label of
the seed term “singapore” propagates to “china.”
“China” will then be classified in the Travel do-
main. In this way, label propagation gradually
propagates the label of seed instances to neigh-
bouring nodes, and optimal labels are given as the
</bodyText>
<footnote confidence="0.9817285">
3Query Term Chunk Processor
4♯ is the place into which a query fits.
</footnote>
<figure confidence="0.948628">
Input:
Seed instance vector F(0)
Instance similarity matrix A
Output:
Instance score vector F(t)
1: Construct the normalized Laplacian matrix L = I −
D−1/2AD−1/2
2: Iterate F(t + 1) = α(−L)F(t) + (1 − α)F(0) until
convergence
</figure>
<figureCaption confidence="0.999355">
Figure 2: Laplacian label propagation algorithm
</figureCaption>
<bodyText confidence="0.984128789473684">
labels at which the label propagation process has
converged.
Figure 2 describes label propagation based on
the regularized Laplacian. Let a sample xi be xi E
X, F(0) be a score vector of x comprised of a
label set yi E Y, and F(t) be a score vector of
x after step t. Instance-instance similarity matrix
A is defined as A = WT W where W is a row-
normalized instance-pattern matrix. The (i, j)-th
element of Wij contains the normalized frequency
of co-occurrence of instance xi and pattern pj. D
is a diagonal degree matrix of N where the (i, i)th
element of D is given as Dii = Ej Nij.
This algorithm in Figure 2 is similar to (Zhou
et al., 2004) except for the method of construct-
ing A and the use of graph Laplacian. Zhou et al.
proposed a heuristic to set Aii = 0 to avoid self-
reinforcement5 because Gaussian kernel was used
to create A. The Laplacian label propagation does
not need such a heuristic because the graph Lapla-
cian automatically reduces self-reinforcement by
assigning negative weights to self-loops.
In the task of learning one category, scores of la-
beled (seed) instances are set to 1 whereas scores
of unlabeled instances are set to 0. The output is
a score vector which holds relatedness to seed in-
stances in descending order. In the task of learning
two categories, scores of seed instances are set to
either 1 or −1, respectively, and the final label of
instance xi will be determined by the sign of out-
put score vector yi.
Label propagation has a parameter α E (0, 1]
that controls how much the labels of seeds are em-
phasized. As α approaches 0 it puts more weight
on labeled instances, while as α increases it em-
ploys both labeled and unlabeled data.
There exists a closed-form solution for Lapla-
cian label propagation:
</bodyText>
<footnote confidence="0.987756">
5Avoiding self-reinforcement is important because it
causes semantic drift, a phenomenon where frequent in-
stances and patterns unrelated to seed instances infect seman-
tic category acquisition as iteration proceeds.
</footnote>
<page confidence="0.970384">
190
</page>
<table confidence="0.993130777777778">
Category Seed
Travel jal (Japan Airlines), ana (All Nippon
Airways), jr (Japan Railways), U &apos; 3;
/v (jalan: online travel guide site), his
(H.I.S.Co.,Ltd.: travel agency)
Finance�`6Wis (Mizuho Bank), �#(7sZWis
(Sumitomo Mitsui Banking Corporation),
jcb,f-tWis (Shinsei Bank), ����
(Nomura Securities)
</table>
<tableCaption confidence="0.999449">
Table 1: Seed terms for each category
</tableCaption>
<equation confidence="0.943049">
F* _ Et0=0(α(−L))tF(0) _ (I + αL)−1F(0)
</equation>
<bodyText confidence="0.9997932">
However, the matrix inversion leads to O(n3)
complexity, which is far from realistic in a real-
world configuration. Nonetheless, it can be ap-
proximated by fixing the number of steps for label
propagation.
</bodyText>
<sectionHeader confidence="0.983198" genericHeader="method">
4 Experiments with Web Search Logs
</sectionHeader>
<bodyText confidence="0.9999595">
We will describe experimental result comparing
a previous method Tchai to the proposed method
Quetchup with clickthrough logs (Quetchupclick)
and with query logs (Quetchup
</bodyText>
<subsectionHeader confidence="0.984928">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.997393666666667">
Search logs We used Japanese search logs col-
lected in August 2008 from Yahoo! JAPAN Web
Search. We thresholded both search query and
clickthrough logs and retained the top 1 million
distinct queries. Search logs are accompanied by
their frequencies within the logs.
Construction of an instance-pattern matrix
We used clicked links as clickthrough patterns.
Links clicked less than 200 times were removed.
After that, links which had only one co-occurring
query were pruned. 6 On the other hand, we used
two term queries as contextual patterns. For in-
stance, if one has the term “singapore” and the
query “singapore airlines,” the contextual pattern
“♯ airlines” will be created. Query patterns appear-
ing less than 100 times were discarded.
The (i, j)-th element of a row-normalized
instance-pattern matrix W is given by
</bodyText>
<equation confidence="0.4864085">
Wij _ xi,pj
Ek xi,pk .
</equation>
<bodyText confidence="0.985368769230769">
Target categories We used two categories,
Travel and Finance, to compare proposed methods
with (Komachi and Suzuki, 2008).
6Pruning facilitates the computation time and reduces the
size of instance-pattern matrix drastically.
When a query was a variant of a term or con-
tains spelling mistakes, we estimated original form
and manually assigned a semantic category. We
allowed a query to have more than two categories.
When a query had more than two terms, we as-
signed a semantic category to the whole query tak-
ing each term into account.7
System We used the same seeds presented in Ta-
ble 1 for both Tchai and Quetchup. We used the
same parameter for Tchai described in (Komachi
and Suzuki, 2008), and collected 100 instances by
iterating 10 times and extracting 10 instances per
iteration. The number of iteration of Quetchup is
set to 10. The parameter α is set to 0.0001.
Evaluation It is difficult in general to define re-
call for the task of semantic category acquisition
since the true set of instances is not known. Thus,
we evaluated all systems using precision at k and
relative recall (Pantel and Ravichandran, 2004).8
Relative recall is the coverage of a system given
another system as baseline.
</bodyText>
<subsectionHeader confidence="0.984038">
4.2 Experimental Result
4.2.1 Effectiveness of Clickthrough Logs
</subsectionHeader>
<bodyText confidence="0.897186392857143">
Figures 3 to 6 plot precision and relative recall
for three systems to show effectiveness of search
clickthrough logs in improvement of precision and
relative recall. Relative recall of Quetchupclick and
Tchai were calculated against Quetchupquery.
Quetchupclick gave the best precision among
three systems, and did not degenerate going down
through the list. In addition, it was demonstrated
that Quetchupclick gives high recall. This result
shows that search clickthrough logs effectively im-
prove both precision and recall for the task of se-
mantic category acquisition.
On the other hand, Quetchupquery degraded in
precision as its rank increased. Manual check of
the extracted queries revealed that the most promi-
nent queries were Pornographic queries, followed
by Food, Job and Housing, which frequently ap-
pear in web search logs. Other co-occurrence met-
rics such as pointwise mutual information would
be explored in the future to suppress the effect of
frequent queries.
In addition, Quetchupclick constantly out-
performed Tchai in both the Travel and Fi-
7Since web search query logs contain many spelling mis-
takes, we experimented in a realistic configuration.
8Typically, precision at k is the most important measure
since the top k highest scored terms are evaluated by hand.
query).
</bodyText>
<page confidence="0.939542">
191
</page>
<figure confidence="0.994076">
10 20 30 40 50 60 70 80 90 100
Rank
</figure>
<figureCaption confidence="0.998741">
Figure 3: Precision of Travel domain
</figureCaption>
<figure confidence="0.9965935">
10 20 30 40 50 60 70 80 90 100
Rank
</figure>
<figureCaption confidence="0.979815">
Figure 5: Relative recall of Travel domain
</figureCaption>
<figure confidence="0.9971925">
10 20 30 40 50 60 70 80 90 100
Rank
</figure>
<figureCaption confidence="0.999524">
Figure 4: Precision of Finance domain
</figureCaption>
<figure confidence="0.9976745">
10 20 30 40 50 60 70 80 90 100
Rank
</figure>
<figureCaption confidence="0.979998">
Figure 6: Relative recall of Finance domain
</figureCaption>
<figure confidence="0.999622027777778">
Quetchup (click)
Quetchup (query)
Tchai
Relative recall
10
4
2
8
6
0
Quetchup (click)
Tchai
Quetchup (click)
Quetchup (query)
Tchai
Relative recall
10
4
2
8
6
0
Quetchup (click)
Tchai
Precision 1
0.8
0.6
0.4
0.2
0
Precision 1
0.8
0.6
0.4
0.2
0
</figure>
<bodyText confidence="0.996923416666667">
nance domains in precision and outperfomed
QuetchupqueTy in relative recall. The differences
between the two domains of query-based systems
seem to lie in the size of correct instances. The Fi-
nance domain is a closed set which has only a few
effective query patterns, whereas Travel domain is
an open set which has many query patterns that
match correct instances. Quetchupclick has an ad-
ditional advantage that it is stable across over the
ranked list, because the variance of the number of
clicked links is small thanks to the nature of the
ranking algorithm of search engines.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999948666666667">
We have proposed a method called Quetchup
to learn semantic categories from search click-
through logs using Laplacian label propagation.
The proposed method greatly outperforms previ-
ous method, taking the advantage of search click-
through logs.
</bodyText>
<sectionHeader confidence="0.997641" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.94303575">
The first author is partly supported by the grant-in-
aid JSPS Fellowship for Young Researchers. We
thank the anonymous reviewers for helpful com-
ments and suggestions.
</bodyText>
<sectionHeader confidence="0.998746" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999887296296296">
T. Joachims. 2002. Optimizing Search Engines Using Click-
through Data. KDD, pages 133–142.
M. Komachi and H. Suzuki. 2008. Minimally Supervised
Learning of Semantic Knowledge from Query Logs. IJC-
NLP, pages 358–365.
M. Pas¸ca and B. V. Durme. 2007. What You Seek is What
You Get: Extraction of Class Attributes from Query Logs.
IJCAI-07, pages 2832–2837.
M. Pas¸ca and B. V. Durme. 2008. Weakly-Supervised Ac-
quisition of Open-Domain Classes and Class Attributes
from Web Documents and Query Logs. ACL-2008, pages
19–27.
P. Pantel and D. Ravichandran. 2004. Automatically Label-
ing Semantic Classes. HLT/NAACL-04, pages 321–328.
C. Silverstein, M. Henzinger, H. Marais, and M. Moricz.
1998. Analysis of a Very Large AltaVista Query Log. Dig-
ital SRC Technical Note 1998-014.
P. P. Talukdar, J. Reisinger, M. Pas¸ca, D. Ravichandran,
R. Bhagat, and F. Pereira. 2008. Weakly-Supervised Ac-
quisition of Labeled Class Instances using Graph Random
Walks. EMNLP-2008, pages 581–589.
G. Xu, S. Yang, and H. Li. 2009. Named Entity Mining
from Click-Through Log Using Weakly Supervised Latent
Dirichlet Allocation. KDD. to appear.
D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch¨okopf.
2004. Learning with Local and Global Consistency.
NIPS, 16:321–328.
</reference>
<page confidence="0.998194">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.537414">
<title confidence="0.999958">Learning Semantic Categories from Clickthrough Logs</title>
<author confidence="0.99306">Mamoru Komachi</author>
<affiliation confidence="0.999836">Nara Institute of Science and Technology (NAIST)</affiliation>
<address confidence="0.998314">8916-5 Takayama, Ikoma, Nara 630-0192, Japan</address>
<email confidence="0.975032">mamoru-k@is.naist.jp</email>
<author confidence="0.946969">Makimoto Uchiumi Sassano</author>
<affiliation confidence="0.961232">Yahoo Japan Corporation</affiliation>
<address confidence="0.585404">Midtown Tower, 9-7-1 Akasaka, Minato-ku, Tokyo 107-6211, Japan</address>
<abstract confidence="0.999565666666666">As the web grows larger, knowledge acquisition from the web has gained increasing attention. In this paper, we propose using web search clickthrough logs to learn semantic categories. Experimental results show that the proposed method greatly outperforms previous work using only web search query logs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Optimizing Search Engines Using Clickthrough Data.</title>
<date>2002</date>
<pages>133--142</pages>
<publisher>KDD,</publisher>
<contexts>
<context position="1421" citStr="Joachims (2002)" startWordPosition="209" endWordPosition="210"> 1998). Web search logs are getting a lot more attention lately as a source of information for applications such as targeted advertisement and query suggestion. However, it may not be appropriate to use queries themselves because query strings are often too heterogeneous or inspecific to characterize the interests of the user population. Although it is not clear that query logs are the best source of learning semantic categories, all the previous studies using web search logs rely on web search query logs. Therefore, we propose to use web search clickthrough logs to learn semantic categories. Joachims (2002) developed a method that utilizes clickthrough logs for training ranking of search engines. A search clickthrough is a link which search users click when they see the result of their search. The intentions of two distinct search queries are likely to be similar, if not identical, when they have the same clickthrough. Search clickthrough logs are thus potentially useful for learnin semantic categories. Clickthrough logs have the additional advantage that they are available in abundance and can be stored at very low cost.1 Our proposed method employs search click1As for data availability, MSN Se</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>T. Joachims. 2002. Optimizing Search Engines Using Clickthrough Data. KDD, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Komachi</author>
<author>H Suzuki</author>
</authors>
<title>Minimally Supervised Learning of Semantic Knowledge from Query Logs. IJCNLP,</title>
<date>2008</date>
<pages>358--365</pages>
<contexts>
<context position="3366" citStr="Komachi and Suzuki (2008)" startWordPosition="531" endWordPosition="534"> a company). In this work, we focus on extracting named entities of the same class to learn semantic categories. Pas¸ca and Durme (2007) were the first to discover the importance of search query logs in natural language processing applications. They focused on learning attributes of named entities, and thus their objective is different from ours. Another line of new research is to combine various resources such as web documents with search query logs (Pas¸ca and Durme, 2008; Talukdar et al., 2008). We differ from this work in that we use search clickthrough logs rather than search query logs. Komachi and Suzuki (2008) proposed a bootstrapping algorithm called Tchai, dedicated to the task of semantic category acquisition from search query logs. It achieves state-of-the-art performance for this task, but it only uses web search query logs. shop on Web Search Click Data 2009 participants. http:// research.microsoft.com/en-US/um/people/nickcr/WSCD09/ 2After the submission of this paper, we found that (Xu et al., 2009) also applies search clickthrough logs to this task. This work independently confirms the effectiveness of clickthrough logs to this task using different sources. 189 Proceedings of the ACL-IJCNLP</context>
<context position="9600" citStr="Komachi and Suzuki, 2008" startWordPosition="1555" endWordPosition="1558">through patterns. Links clicked less than 200 times were removed. After that, links which had only one co-occurring query were pruned. 6 On the other hand, we used two term queries as contextual patterns. For instance, if one has the term “singapore” and the query “singapore airlines,” the contextual pattern “♯ airlines” will be created. Query patterns appearing less than 100 times were discarded. The (i, j)-th element of a row-normalized instance-pattern matrix W is given by Wij _ xi,pj Ek xi,pk . Target categories We used two categories, Travel and Finance, to compare proposed methods with (Komachi and Suzuki, 2008). 6Pruning facilitates the computation time and reduces the size of instance-pattern matrix drastically. When a query was a variant of a term or contains spelling mistakes, we estimated original form and manually assigned a semantic category. We allowed a query to have more than two categories. When a query had more than two terms, we assigned a semantic category to the whole query taking each term into account.7 System We used the same seeds presented in Table 1 for both Tchai and Quetchup. We used the same parameter for Tchai described in (Komachi and Suzuki, 2008), and collected 100 instanc</context>
</contexts>
<marker>Komachi, Suzuki, 2008</marker>
<rawString>M. Komachi and H. Suzuki. 2008. Minimally Supervised Learning of Semantic Knowledge from Query Logs. IJCNLP, pages 358–365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>B V Durme</author>
</authors>
<title>What You Seek is What You Get: Extraction of Class Attributes from Query Logs.</title>
<date>2007</date>
<booktitle>IJCAI-07,</booktitle>
<pages>2832--2837</pages>
<marker>Pas¸ca, Durme, 2007</marker>
<rawString>M. Pas¸ca and B. V. Durme. 2007. What You Seek is What You Get: Extraction of Class Attributes from Query Logs. IJCAI-07, pages 2832–2837.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>B V Durme</author>
</authors>
<title>Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs.</title>
<date>2008</date>
<booktitle>ACL-2008,</booktitle>
<pages>pages</pages>
<marker>Pas¸ca, Durme, 2008</marker>
<rawString>M. Pas¸ca and B. V. Durme. 2008. Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs. ACL-2008, pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
</authors>
<title>Automatically Labeling Semantic Classes.</title>
<date>2004</date>
<booktitle>HLT/NAACL-04,</booktitle>
<pages>321--328</pages>
<contexts>
<context position="10602" citStr="Pantel and Ravichandran, 2004" startWordPosition="1728" endWordPosition="1731"> whole query taking each term into account.7 System We used the same seeds presented in Table 1 for both Tchai and Quetchup. We used the same parameter for Tchai described in (Komachi and Suzuki, 2008), and collected 100 instances by iterating 10 times and extracting 10 instances per iteration. The number of iteration of Quetchup is set to 10. The parameter α is set to 0.0001. Evaluation It is difficult in general to define recall for the task of semantic category acquisition since the true set of instances is not known. Thus, we evaluated all systems using precision at k and relative recall (Pantel and Ravichandran, 2004).8 Relative recall is the coverage of a system given another system as baseline. 4.2 Experimental Result 4.2.1 Effectiveness of Clickthrough Logs Figures 3 to 6 plot precision and relative recall for three systems to show effectiveness of search clickthrough logs in improvement of precision and relative recall. Relative recall of Quetchupclick and Tchai were calculated against Quetchupquery. Quetchupclick gave the best precision among three systems, and did not degenerate going down through the list. In addition, it was demonstrated that Quetchupclick gives high recall. This result shows that </context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>P. Pantel and D. Ravichandran. 2004. Automatically Labeling Semantic Classes. HLT/NAACL-04, pages 321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Silverstein</author>
<author>M Henzinger</author>
<author>H Marais</author>
<author>M Moricz</author>
</authors>
<title>Analysis of a Very Large AltaVista Query Log.</title>
<date>1998</date>
<booktitle>Digital SRC Technical Note</booktitle>
<contexts>
<context position="812" citStr="Silverstein et al., 1998" startWordPosition="107" endWordPosition="111">ei Makimoto and Kei Uchiumi and Manabu Sassano Yahoo Japan Corporation Midtown Tower, 9-7-1 Akasaka, Minato-ku, Tokyo 107-6211, Japan {smakimot,kuchiumi,msassano}@yahoo-corp.jp Abstract As the web grows larger, knowledge acquisition from the web has gained increasing attention. In this paper, we propose using web search clickthrough logs to learn semantic categories. Experimental results show that the proposed method greatly outperforms previous work using only web search query logs. 1 Introduction Compared to other text resources, search queries more directly reflect search users’ interests (Silverstein et al., 1998). Web search logs are getting a lot more attention lately as a source of information for applications such as targeted advertisement and query suggestion. However, it may not be appropriate to use queries themselves because query strings are often too heterogeneous or inspecific to characterize the interests of the user population. Although it is not clear that query logs are the best source of learning semantic categories, all the previous studies using web search logs rely on web search query logs. Therefore, we propose to use web search clickthrough logs to learn semantic categories. Joachi</context>
</contexts>
<marker>Silverstein, Henzinger, Marais, Moricz, 1998</marker>
<rawString>C. Silverstein, M. Henzinger, H. Marais, and M. Moricz. 1998. Analysis of a Very Large AltaVista Query Log. Digital SRC Technical Note 1998-014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P Talukdar</author>
<author>J Reisinger</author>
<author>M Pas¸ca</author>
<author>D Ravichandran</author>
<author>R Bhagat</author>
<author>F Pereira</author>
</authors>
<title>Weakly-Supervised Acquisition of Labeled Class Instances using Graph Random Walks.</title>
<date>2008</date>
<booktitle>EMNLP-2008,</booktitle>
<pages>581--589</pages>
<marker>Talukdar, Reisinger, Pas¸ca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>P. P. Talukdar, J. Reisinger, M. Pas¸ca, D. Ravichandran, R. Bhagat, and F. Pereira. 2008. Weakly-Supervised Acquisition of Labeled Class Instances using Graph Random Walks. EMNLP-2008, pages 581–589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Xu</author>
<author>S Yang</author>
<author>H Li</author>
</authors>
<title>Named Entity Mining from Click-Through Log Using Weakly Supervised Latent Dirichlet Allocation.</title>
<date>2009</date>
<publisher>KDD.</publisher>
<note>to appear.</note>
<contexts>
<context position="3770" citStr="Xu et al., 2009" startWordPosition="589" endWordPosition="592">h as web documents with search query logs (Pas¸ca and Durme, 2008; Talukdar et al., 2008). We differ from this work in that we use search clickthrough logs rather than search query logs. Komachi and Suzuki (2008) proposed a bootstrapping algorithm called Tchai, dedicated to the task of semantic category acquisition from search query logs. It achieves state-of-the-art performance for this task, but it only uses web search query logs. shop on Web Search Click Data 2009 participants. http:// research.microsoft.com/en-US/um/people/nickcr/WSCD09/ 2After the submission of this paper, we found that (Xu et al., 2009) also applies search clickthrough logs to this task. This work independently confirms the effectiveness of clickthrough logs to this task using different sources. 189 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 189–192, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Figure 1: Labels of seeds are propagated to unlabeled nodes. 3 Quetchup3 Algorithm In this section, we describe an algorithm for learning semantic categories from search logs using label propagation. We name the algorithm Quetchup. 3.1 Semi-supervised Learning by Laplacian Label Propagation Graph-based</context>
</contexts>
<marker>Xu, Yang, Li, 2009</marker>
<rawString>G. Xu, S. Yang, and H. Li. 2009. Named Entity Mining from Click-Through Log Using Weakly Supervised Latent Dirichlet Allocation. KDD. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zhou</author>
<author>O Bousquet</author>
<author>T N Lal</author>
<author>J Weston</author>
<author>B Sch¨okopf</author>
</authors>
<date>2004</date>
<booktitle>Learning with Local and Global Consistency. NIPS,</booktitle>
<pages>16--321</pages>
<marker>Zhou, Bousquet, Lal, Weston, Sch¨okopf, 2004</marker>
<rawString>D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch¨okopf. 2004. Learning with Local and Global Consistency. NIPS, 16:321–328.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>