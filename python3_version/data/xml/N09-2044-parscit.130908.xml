<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.064351">
<title confidence="0.995547">
Classifying Factored Genres with Part-of-Speech Histograms
</title>
<author confidence="0.999589">
S. Feldman, M. Marin, J. Medero, and M. Ostendorf
</author>
<affiliation confidence="0.9989495">
Dept. of Electrical Engineering
University of Washington, Seattle, Washington 98195
</affiliation>
<email confidence="0.999401">
{sergeyf,amarin,jmedero,ostendor}@u.washington.edu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998904692307692">
This work addresses the problem of genre
classification of text and speech transcripts,
with the goal of handling genres not seen in
training. Two frameworks employing differ-
ent statistics on word/POS histograms with a
PCA transform are examined: a single model
for each genre and a factored representation
of genre. The impact of the two frameworks
on the classification of training-matched and
new genres is discussed. Results show that the
factored models allow for a finer-grained rep-
resentation of genre and can more accurately
characterize genres not seen in training.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964846153846">
With increasing quantities of text and transcribed
speech available online, the ability to categorize
documents based on characteristics beyond topic be-
comes ever more important. In particular, the genre
of a document – whether it is a news report or an
editorial, a speech transcript or a weblog – may be
relevant for many human tasks. For example, one
might want to find “speeches on ethanol” or “we-
blog entries on Fannie Mae, sorted by most formal
first.” Genre classification is also of growing im-
portance for human language technologies, such as
speech recognition, parsing, and translation, because
of the potentially large differences in language as-
sociated with genre. Researchers find that genre-
dependent models lead to improved performance on
these tasks, e.g. (Wang, 2008). Since text harvested
from the web is increasingly used to address prob-
lems due to sparse training data, genre classifica-
tion can be useful for sampling such text sources to
obtain a better match to the target domain for of-
fline language model training. Prior work on genre-
dependent web text filtering for language modeling
relied on standard search engine methods, design-
ing queries based on frequent n-grams in the do-
main, e.g. (Bulyko et al., 2007). However, as the
variety of genres online has grown, this method has
become less reliable. This work addresses explicit
genre classification, with the assumption that genre
representation in the training data is incomplete.
In prior work on genre classification, an impor-
tant question has been the definition of “genre.”
For many studies, genre has been associated with
categories of text, such as research article, novel,
news report, editorial, advertisement, etc. In par-
ticular, several studies use classes identified in the
Brown corpus or the British National Corpus. Spo-
ken genres, including conversation, interview, de-
bate, and planned speech are considered in (Santini,
2004). Examples of spoken and written genres, rep-
resented in several corpora available from the Lin-
guistics Data Consortium, are explored in (Feldman
et al., 2009). Yet another study focuses on internet-
specific document types, including different types of
home pages (personal, public, commercial), bulletin
boards, and link lists (Lim et al., 2004). A limita-
tion of all of this work is that only a small, fixed set
of different genres are explored, with performance
assessed on matched data. In this paper, we assess
classification results of texts that come from new
genres, as well as those matching the training set.
In addressing new genres, we have two main
contributions: new features and factored coding.
</bodyText>
<page confidence="0.986626">
173
</page>
<note confidence="0.3585595">
Proceedings of NAACL HLT 2009: Short Papers, pages 173–176,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999790357142857">
The standard features for genre classification mod-
els include words, part-of-speech (POS) tags, and
punctuation (Kessler et al., 1997; Stamatatos et
al., 2000; Lee and Myaeng, 2002; Biber, 1993),
but constituent-based syntactic categories have also
been explored (Karlgren and Cutting, 1994). (Feld-
man et al., 2009) used mixed word and POS his-
togram mean and variance as features for genre clas-
sification. In this work, we augment those his-
togram statistics with higher-order ones, as well as
add new word features aimed at capturing online
genres. Further, we propose a factored genre model,
and demonstrate its effect on genre classification of
out-of-domain documents.
</bodyText>
<sectionHeader confidence="0.996516" genericHeader="introduction">
2 Methods
</sectionHeader>
<subsectionHeader confidence="0.86849">
2.1 Corpora
</subsectionHeader>
<bodyText confidence="0.99999944">
To train our algorithm, we use eight different gen-
res: broadcast news (bn, 671 docs), broadcast con-
versations (bc, 698 docs), meetings (mt, 493 docs),
newswire (nw, 471 docs), conversational telephone
speech (sb, 890 docs), weblogs (wl, 543 docs), Ama-
zon reviews of books, videogames and films (az
train, 218 docs), and chat data (chat, 187 docs). To
test our algorithm, we add six additional genres:
Amazon reviews of appliances (az test, 27 docs),
Wikipedia entries (wiki, 254 docs), Wikipedia dis-
cussion entries (wiki talk, 1792 docs), European Par-
liament transcripts (europarl, 1423 docs), a web col-
lection obtained from Google searches for common
conversational n-grams (web, 18540 docs), and tran-
scribed McCain and Obama speeches (speeches, 20
docs). With the exception of the chat data, Ama-
zon reviews, and a subset of the Europarl transcripts,
the training corpora are from standard published
datasets. The reviews, chat, Wikipedia, and web
data were all collected from websites and cleaned
locally. The documents average 600-1000 words in
length, except for smaller corpora like Amazon re-
views, whose documents average about 200 words.
For training factored models, we assume that all the
documents within a corpus share the same class.
</bodyText>
<subsectionHeader confidence="0.989849">
2.2 Features and Classifier
</subsectionHeader>
<bodyText confidence="0.999540896551724">
The features used in (Feldman et al., 2009) were de-
rived from a union of POS tags and a set of hand-
picked, informative words. A similar approach is
used here, including a collapsed version of the Tree-
bank POS tag set (Marcus et al., 1993), with addi-
tions for specific words (e.g. personal pronouns and
filled pause markers), compound punctuation (e.g.
multiple exclamation marks), and a general emoti-
con tag, resulting in a total of 41 tags. Histograms
are computed for a sliding window of length w = 5
over the tag sequence, and then statistics of each
histogram bin are extracted. In the previous work,
mean and standard deviation were extracted from the
histogram bins. To this, we add skewness and kurto-
sis, which we will show are necessary for increased
differentiation of unseen genres. For feature reduc-
tion, we used Principal Components Analysis and
retained all PC dimensions with variance above 1%
of the maximum PC variance.
Different approaches have been explored for com-
putational modeling, including naive Bayes, linear
discriminant modeling, and neural networks (San-
tini, 2004; Kessler et al., 1997; Stamatatos et al.,
2000; Lee and Myaeng, 2002). Since (Feldman et
al., 2009) found that quadratic discriminant analysis
(QDA) outperforms naive Bayes, we use it here with
full covariance matrices estimated by maximum
likelihood, and trained on the reduced-dimension
POS histogram features.
</bodyText>
<subsectionHeader confidence="0.983889">
2.3 Factors
</subsectionHeader>
<bodyText confidence="0.999673333333333">
Linguistic research has tended to look at attributes
of language rather than defining genre in terms of
task domains. Since the number of task domains ap-
pears to be growing with new uses of the internet, we
conjecture that an attribute approach is more practi-
cal for web-based text. We introduce the notion of a
factored model for genre. The genre of each docu-
ment can encoded as a vector of factors. Given data
limits, the set of factors explored so far are:
</bodyText>
<listItem confidence="0.99996375">
• number of speakers/authors (1,2,3+),
• level of formality (low, medium, high),
• intended audience (personal, broadcast), and
• intent (inform, persuade).
</listItem>
<bodyText confidence="0.987737">
Assuming factor independence, we train four sepa-
rate QDA classifiers, one per factor. Using factors
increases the richness of the space represented by
the training set, in that it is possible to identify gen-
res with factor combinations not seen in training.
</bodyText>
<page confidence="0.996994">
174
</page>
<sectionHeader confidence="0.998157" genericHeader="related work">
3 Experiments and Discussion
</sectionHeader>
<subsectionHeader confidence="0.984794">
3.1 Within-Domain Validation
</subsectionHeader>
<bodyText confidence="0.999972642857143">
As a preliminary step, and to ensure that the addition
of skewness and kurtosis, as well as extra syntactic
features, does not significantly impact the within-
domain classification accuracy, we performed ex-
periments with both the features in (Feldman et al.,
2009) and our expanded features. For this, we split
the training data 75/25 into training/test sets, and re-
peated the random split 50 times. We ran the experi-
ments for both the original genre classification prob-
lem and the individual factors. We found that the ad-
dition of new moments and features decreased per-
formance by less than 1% on average. We hypoth-
esize that this small deterioration in performance is
likely due to overtuning to the original training set.
</bodyText>
<subsectionHeader confidence="0.997561">
3.2 New Features with Unseen Genres
</subsectionHeader>
<bodyText confidence="0.999980465116279">
To assess the use of our new features (added punctu-
ation and emoticons) and the higher-order moments,
we classified the web data with different processing
configurations. In addition to the eight training gen-
res, we introduced an “undetermined” genre or class
for documents with a uniform posterior probability
across all genres, which occurs when there is a large
mismatch to all training genres. The distribution of
labels is shown in Figure 1. While we do not have
hand-labeled categories for this data, we thought it
highly unlikely that the vast majority is bn, as pre-
dicted by the models using only mean and variance
moments.
To validate our hypothesis that the spread of la-
bels was more appropriate for the data, we randomly
selected 100 documents and hand-labeled these us-
ing the eight classes plus “undetermined.” The unde-
termined class was used for new genres (play scripts,
lectures, newsgroups, congressional records). We
found that it was difficult to annotate the data, since
many samples had characteristics of more than one
genre; this finding motivates the factor representa-
tion. The main difference between the various fea-
ture extraction configurations was in the detection
of the undetermined cases. For the subset of un-
determined documents that we labeled (34), none
were detected using only 2 moments, but 35-40%
were detected with the higher-order moments. Of
the false detections, roughly 25-30% were associ-
ated with documents with characteristics of multiple
classes. The effect of adding more detailed punctua-
tion and emoticons to the tag set was not significant.
It should be noted that the web collection was
based on queries designed to extract BC-style text,
yet only 3 of 100 hand-labeled samples were in that
category, none of which were accurately classified.
Roughly 16 of the 100 documents are labeled as very
informal and another 55 include some informal text
or are moderately informal. This finding, combined
with the observation that many documents reflect a
mix of genres, suggests that a factored representa-
tion of genre (with formality as one “factor”) may
be more useful than explicit modeling of genres.
</bodyText>
<figureCaption confidence="0.999509">
Figure 1: Fraction of web data classified as each genre.
</figureCaption>
<subsectionHeader confidence="0.997546">
3.3 Unseen Genre Factor Results
</subsectionHeader>
<bodyText confidence="0.981680263157895">
We trained a set of models for each factor and ob-
tained posterior estimates for unseen classes. Figure
2 shows the class of out-of-domain documents for
the formality factor, using 3 categories of formal-
ity: low (conversational, unprofessional), medium
(casual but coherent), high (formal). We have not
hand-labeled individual documents in all of these
sets, but the resulting class proportions match our
intuition for these genres. The Wikipedia data is
labeled as highly formal, and most web data is la-
beled as medium. Examining the 100 hand-labeled
web documents, we find that adding the higher-order
moments improves classifier accuracy from 23% to
55%. The effect of the added tag set features was
once again not significant.
Figure 3 shows the class of out-of-domain doc-
uments for the factor indicating number of speak-
ers/authors. This factor appears difficult to detect.
2, old4, old 2, new 4, new
</bodyText>
<figure confidence="0.957485">
number of moments, old/new features
1
0.8
0.6
0.4
0.2
0
bc bn mt nw sb wl az chat undetermined
</figure>
<page confidence="0.99589">
175
</page>
<bodyText confidence="0.999921375">
We hypothesize that there is an unaccounted-for de-
pendence on audience. When there is a listener,
speakers may use the term “you,” as in conversa-
tions and internet chat. An interesting observation
is that the ten Obama speeches all appear to exhibit
this behavior. McCain speeches, on the other hand,
display some variation, and about a third are (cor-
rectly) characterized as single speaker.
</bodyText>
<figureCaption confidence="0.9995745">
Figure 2: Test corpora classification, formality.
Figure 3: Test corpora classification, number of speakers.
</figureCaption>
<bodyText confidence="0.999907166666667">
The audience factor results are very skewed to-
wards broadcast data, but this matches our intuition,
and the scarcity of data meant for private consump-
tion, so they are not included. However, further
study is needed, since 3-dimensional projections of
the training data suggest a Gaussian mixture (or
other more complex model) may fit better.
The intent factor results are also mixed. The
classifier labels most of the Wikipedia, europarl,
web, and speeches data as “report,” and most re-
views as “persuade.” While the “report” category fits
Wikipedia, it is not clear that europarl should also be
classified as “report,” since parliamentary proceed-
ings are notoriously argumentative. With this factor,
the noise inherent in using genre-level labels is sig-
nificant. It is not always clear what is reportage and
what is persuasion, and we expect some genres (e.g.
reviews) to be a mixture of both.
</bodyText>
<sectionHeader confidence="0.998922" genericHeader="conclusions">
4 Summary
</sectionHeader>
<bodyText confidence="0.999975444444444">
We have introduced new features that are more ro-
bust for handling domains unseen in training, and
presented a factored genre framework that allows for
a finer-grained representation of genre. Many open
questions remain, including which other factors can
or cannot be captured by our current feature set and
classifier, and whether noisy label learning methods
could address the problem of uncertainty in the la-
bels for particular features and genres.
</bodyText>
<sectionHeader confidence="0.99941" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998522896551724">
D. Biber. 1993. Using register-diversified corpora for
general language studies. Computational Linguistics,
19(2):219–242.
I. Bulyko et al. 2007. Web resources for language model-
ing in conversational speech recognition. ACM Trans.
on Speech and Language Processing, 5(1):1–25.
S. Feldman et al. 2009. Part-of-speech histograms for
genre classification of text. Proc. ICASSP.
W. Wang. 2008. Weakly supervised training for parsing
mandarin broadcast transcripts. Proc. Interspeech.
J. Karlgren and D. Cutting. 1994. Recognizing text gen-
res with simple metrics using discriminant analysis.
Proc. Computational Linguistics, pages 1071–1075.
B. Kessler, G. Numberg, and H. Sch¨utze. 1997. Auto-
matic detection of text genre. ACL-35, pages 32–38.
Y.-B. Lee and S. H. Myaeng. 2002. Text genre classifi-
cation with genre-revealing and subject-revealing fea-
tures. ACM SIGIR, pages 145–150.
C. S. Lim, K. J. Lee, and G. C. Kim. 2004. Automatic
genre detection of web documents. IJCNLP.
M. P. Marcus et al. 1993. Building a large annotated
corpus of English: the Penn Treebank. Computational
Linguistics, 19(2):313–330.
M. Santini. 2004. A shallow approach to syntactic fea-
ture extraction for genre classification. CLUK 7: UK
special-interest group for computational linguistics.
E. Stamatatos, N. Fakotakis, and G. Kokkinakis. 2000.
Text genre detection using common word frequencies.
Proc. Computational Linguistics, pages 808–814.
</reference>
<figure confidence="0.9953078125">
low medium high undetermined
az test wiki wiki talk europarl web speeches
1
0.8
0.6
0.4
0.2
0
1 2 3+ undetermined
az test wiki wiki talk europarl web speeches
1
0.8
0.6
0.4
0.2
0
</figure>
<page confidence="0.969793">
176
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.953618">
<title confidence="0.999647">Classifying Factored Genres with Part-of-Speech Histograms</title>
<author confidence="0.977124">S Feldman</author>
<author confidence="0.977124">M Marin</author>
<author confidence="0.977124">J Medero</author>
<author confidence="0.977124">M</author>
<affiliation confidence="0.990964">Dept. of Electrical University of Washington, Seattle, Washington</affiliation>
<abstract confidence="0.99949">This work addresses the problem of genre classification of text and speech transcripts, with the goal of handling genres not seen in training. Two frameworks employing different statistics on word/POS histograms with a PCA transform are examined: a single model for each genre and a factored representation of genre. The impact of the two frameworks on the classification of training-matched and new genres is discussed. Results show that the factored models allow for a finer-grained representation of genre and can more accurately characterize genres not seen in training.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Biber</author>
</authors>
<title>Using register-diversified corpora for general language studies.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="3807" citStr="Biber, 1993" startWordPosition="584" endWordPosition="585">e explored, with performance assessed on matched data. In this paper, we assess classification results of texts that come from new genres, as well as those matching the training set. In addressing new genres, we have two main contributions: new features and factored coding. 173 Proceedings of NAACL HLT 2009: Short Papers, pages 173–176, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994). (Feldman et al., 2009) used mixed word and POS histogram mean and variance as features for genre classification. In this work, we augment those histogram statistics with higher-order ones, as well as add new word features aimed at capturing online genres. Further, we propose a factored genre model, and demonstrate its effect on genre classification of out-of-domain documents. 2 Methods 2.1 Corpora To train our algorithm, we use eight different genres: broadcast news (bn, 671 docs), broadcast conv</context>
</contexts>
<marker>Biber, 1993</marker>
<rawString>D. Biber. 1993. Using register-diversified corpora for general language studies. Computational Linguistics, 19(2):219–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Bulyko</author>
</authors>
<title>Web resources for language modeling in conversational speech recognition.</title>
<date>2007</date>
<journal>ACM Trans. on Speech and Language Processing,</journal>
<volume>5</volume>
<issue>1</issue>
<marker>Bulyko, 2007</marker>
<rawString>I. Bulyko et al. 2007. Web resources for language modeling in conversational speech recognition. ACM Trans. on Speech and Language Processing, 5(1):1–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Feldman</author>
</authors>
<title>Part-of-speech histograms for genre classification of text.</title>
<date>2009</date>
<booktitle>Proc. ICASSP.</booktitle>
<marker>Feldman, 2009</marker>
<rawString>S. Feldman et al. 2009. Part-of-speech histograms for genre classification of text. Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
</authors>
<title>Weakly supervised training for parsing mandarin broadcast transcripts.</title>
<date>2008</date>
<booktitle>Proc. Interspeech.</booktitle>
<contexts>
<context position="1626" citStr="Wang, 2008" startWordPosition="242" endWordPosition="243">rtant. In particular, the genre of a document – whether it is a news report or an editorial, a speech transcript or a weblog – may be relevant for many human tasks. For example, one might want to find “speeches on ethanol” or “weblog entries on Fannie Mae, sorted by most formal first.” Genre classification is also of growing importance for human language technologies, such as speech recognition, parsing, and translation, because of the potentially large differences in language associated with genre. Researchers find that genredependent models lead to improved performance on these tasks, e.g. (Wang, 2008). Since text harvested from the web is increasingly used to address problems due to sparse training data, genre classification can be useful for sampling such text sources to obtain a better match to the target domain for offline language model training. Prior work on genredependent web text filtering for language modeling relied on standard search engine methods, designing queries based on frequent n-grams in the domain, e.g. (Bulyko et al., 2007). However, as the variety of genres online has grown, this method has become less reliable. This work addresses explicit genre classification, with </context>
</contexts>
<marker>Wang, 2008</marker>
<rawString>W. Wang. 2008. Weakly supervised training for parsing mandarin broadcast transcripts. Proc. Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Karlgren</author>
<author>D Cutting</author>
</authors>
<title>Recognizing text genres with simple metrics using discriminant analysis.</title>
<date>1994</date>
<booktitle>Proc. Computational Linguistics,</booktitle>
<pages>1071--1075</pages>
<contexts>
<context position="3904" citStr="Karlgren and Cutting, 1994" startWordPosition="594" endWordPosition="597">assification results of texts that come from new genres, as well as those matching the training set. In addressing new genres, we have two main contributions: new features and factored coding. 173 Proceedings of NAACL HLT 2009: Short Papers, pages 173–176, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994). (Feldman et al., 2009) used mixed word and POS histogram mean and variance as features for genre classification. In this work, we augment those histogram statistics with higher-order ones, as well as add new word features aimed at capturing online genres. Further, we propose a factored genre model, and demonstrate its effect on genre classification of out-of-domain documents. 2 Methods 2.1 Corpora To train our algorithm, we use eight different genres: broadcast news (bn, 671 docs), broadcast conversations (bc, 698 docs), meetings (mt, 493 docs), newswire (nw, 471 docs), conversational teleph</context>
</contexts>
<marker>Karlgren, Cutting, 1994</marker>
<rawString>J. Karlgren and D. Cutting. 1994. Recognizing text genres with simple metrics using discriminant analysis. Proc. Computational Linguistics, pages 1071–1075.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kessler</author>
<author>G Numberg</author>
<author>H Sch¨utze</author>
</authors>
<title>Automatic detection of text genre.</title>
<date>1997</date>
<booktitle>ACL-35,</booktitle>
<pages>32--38</pages>
<marker>Kessler, Numberg, Sch¨utze, 1997</marker>
<rawString>B. Kessler, G. Numberg, and H. Sch¨utze. 1997. Automatic detection of text genre. ACL-35, pages 32–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-B Lee</author>
<author>S H Myaeng</author>
</authors>
<title>Text genre classification with genre-revealing and subject-revealing features.</title>
<date>2002</date>
<journal>ACM SIGIR,</journal>
<pages>145--150</pages>
<contexts>
<context position="3793" citStr="Lee and Myaeng, 2002" startWordPosition="580" endWordPosition="583">of different genres are explored, with performance assessed on matched data. In this paper, we assess classification results of texts that come from new genres, as well as those matching the training set. In addressing new genres, we have two main contributions: new features and factored coding. 173 Proceedings of NAACL HLT 2009: Short Papers, pages 173–176, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994). (Feldman et al., 2009) used mixed word and POS histogram mean and variance as features for genre classification. In this work, we augment those histogram statistics with higher-order ones, as well as add new word features aimed at capturing online genres. Further, we propose a factored genre model, and demonstrate its effect on genre classification of out-of-domain documents. 2 Methods 2.1 Corpora To train our algorithm, we use eight different genres: broadcast news (bn, 671 docs), </context>
<context position="6742" citStr="Lee and Myaeng, 2002" startWordPosition="1054" endWordPosition="1057">stics of each histogram bin are extracted. In the previous work, mean and standard deviation were extracted from the histogram bins. To this, we add skewness and kurtosis, which we will show are necessary for increased differentiation of unseen genres. For feature reduction, we used Principal Components Analysis and retained all PC dimensions with variance above 1% of the maximum PC variance. Different approaches have been explored for computational modeling, including naive Bayes, linear discriminant modeling, and neural networks (Santini, 2004; Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002). Since (Feldman et al., 2009) found that quadratic discriminant analysis (QDA) outperforms naive Bayes, we use it here with full covariance matrices estimated by maximum likelihood, and trained on the reduced-dimension POS histogram features. 2.3 Factors Linguistic research has tended to look at attributes of language rather than defining genre in terms of task domains. Since the number of task domains appears to be growing with new uses of the internet, we conjecture that an attribute approach is more practical for web-based text. We introduce the notion of a factored model for genre. The ge</context>
</contexts>
<marker>Lee, Myaeng, 2002</marker>
<rawString>Y.-B. Lee and S. H. Myaeng. 2002. Text genre classification with genre-revealing and subject-revealing features. ACM SIGIR, pages 145–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C S Lim</author>
<author>K J Lee</author>
<author>G C Kim</author>
</authors>
<title>Automatic genre detection of web documents.</title>
<date>2004</date>
<publisher>IJCNLP.</publisher>
<contexts>
<context position="3106" citStr="Lim et al., 2004" startWordPosition="472" endWordPosition="475">icle, novel, news report, editorial, advertisement, etc. In particular, several studies use classes identified in the Brown corpus or the British National Corpus. Spoken genres, including conversation, interview, debate, and planned speech are considered in (Santini, 2004). Examples of spoken and written genres, represented in several corpora available from the Linguistics Data Consortium, are explored in (Feldman et al., 2009). Yet another study focuses on internetspecific document types, including different types of home pages (personal, public, commercial), bulletin boards, and link lists (Lim et al., 2004). A limitation of all of this work is that only a small, fixed set of different genres are explored, with performance assessed on matched data. In this paper, we assess classification results of texts that come from new genres, as well as those matching the training set. In addressing new genres, we have two main contributions: new features and factored coding. 173 Proceedings of NAACL HLT 2009: Short Papers, pages 173–176, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The standard features for genre classification models include words, part-of-speech (POS) tag</context>
</contexts>
<marker>Lim, Lee, Kim, 2004</marker>
<rawString>C. S. Lim, K. J. Lee, and G. C. Kim. 2004. Automatic genre detection of web documents. IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<marker>Marcus, 1993</marker>
<rawString>M. P. Marcus et al. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Santini</author>
</authors>
<title>A shallow approach to syntactic feature extraction for genre classification. CLUK 7: UK special-interest group for computational linguistics.</title>
<date>2004</date>
<contexts>
<context position="2762" citStr="Santini, 2004" startWordPosition="422" endWordPosition="423">become less reliable. This work addresses explicit genre classification, with the assumption that genre representation in the training data is incomplete. In prior work on genre classification, an important question has been the definition of “genre.” For many studies, genre has been associated with categories of text, such as research article, novel, news report, editorial, advertisement, etc. In particular, several studies use classes identified in the Brown corpus or the British National Corpus. Spoken genres, including conversation, interview, debate, and planned speech are considered in (Santini, 2004). Examples of spoken and written genres, represented in several corpora available from the Linguistics Data Consortium, are explored in (Feldman et al., 2009). Yet another study focuses on internetspecific document types, including different types of home pages (personal, public, commercial), bulletin boards, and link lists (Lim et al., 2004). A limitation of all of this work is that only a small, fixed set of different genres are explored, with performance assessed on matched data. In this paper, we assess classification results of texts that come from new genres, as well as those matching th</context>
<context position="6672" citStr="Santini, 2004" startWordPosition="1043" endWordPosition="1045">g window of length w = 5 over the tag sequence, and then statistics of each histogram bin are extracted. In the previous work, mean and standard deviation were extracted from the histogram bins. To this, we add skewness and kurtosis, which we will show are necessary for increased differentiation of unseen genres. For feature reduction, we used Principal Components Analysis and retained all PC dimensions with variance above 1% of the maximum PC variance. Different approaches have been explored for computational modeling, including naive Bayes, linear discriminant modeling, and neural networks (Santini, 2004; Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002). Since (Feldman et al., 2009) found that quadratic discriminant analysis (QDA) outperforms naive Bayes, we use it here with full covariance matrices estimated by maximum likelihood, and trained on the reduced-dimension POS histogram features. 2.3 Factors Linguistic research has tended to look at attributes of language rather than defining genre in terms of task domains. Since the number of task domains appears to be growing with new uses of the internet, we conjecture that an attribute approach is more practical for web-bas</context>
</contexts>
<marker>Santini, 2004</marker>
<rawString>M. Santini. 2004. A shallow approach to syntactic feature extraction for genre classification. CLUK 7: UK special-interest group for computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Stamatatos</author>
<author>N Fakotakis</author>
<author>G Kokkinakis</author>
</authors>
<title>Text genre detection using common word frequencies.</title>
<date>2000</date>
<booktitle>Proc. Computational Linguistics,</booktitle>
<pages>808--814</pages>
<contexts>
<context position="3771" citStr="Stamatatos et al., 2000" startWordPosition="576" endWordPosition="579"> only a small, fixed set of different genres are explored, with performance assessed on matched data. In this paper, we assess classification results of texts that come from new genres, as well as those matching the training set. In addressing new genres, we have two main contributions: new features and factored coding. 173 Proceedings of NAACL HLT 2009: Short Papers, pages 173–176, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994). (Feldman et al., 2009) used mixed word and POS histogram mean and variance as features for genre classification. In this work, we augment those histogram statistics with higher-order ones, as well as add new word features aimed at capturing online genres. Further, we propose a factored genre model, and demonstrate its effect on genre classification of out-of-domain documents. 2 Methods 2.1 Corpora To train our algorithm, we use eight different genres: broadcast</context>
<context position="6719" citStr="Stamatatos et al., 2000" startWordPosition="1050" endWordPosition="1053"> sequence, and then statistics of each histogram bin are extracted. In the previous work, mean and standard deviation were extracted from the histogram bins. To this, we add skewness and kurtosis, which we will show are necessary for increased differentiation of unseen genres. For feature reduction, we used Principal Components Analysis and retained all PC dimensions with variance above 1% of the maximum PC variance. Different approaches have been explored for computational modeling, including naive Bayes, linear discriminant modeling, and neural networks (Santini, 2004; Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002). Since (Feldman et al., 2009) found that quadratic discriminant analysis (QDA) outperforms naive Bayes, we use it here with full covariance matrices estimated by maximum likelihood, and trained on the reduced-dimension POS histogram features. 2.3 Factors Linguistic research has tended to look at attributes of language rather than defining genre in terms of task domains. Since the number of task domains appears to be growing with new uses of the internet, we conjecture that an attribute approach is more practical for web-based text. We introduce the notion of a factored </context>
</contexts>
<marker>Stamatatos, Fakotakis, Kokkinakis, 2000</marker>
<rawString>E. Stamatatos, N. Fakotakis, and G. Kokkinakis. 2000. Text genre detection using common word frequencies. Proc. Computational Linguistics, pages 808–814.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>