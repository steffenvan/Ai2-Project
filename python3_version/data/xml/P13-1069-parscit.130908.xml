<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.972931">
Learning to lemmatise Polish noun phrases
</title>
<author confidence="0.996313">
Adam Radziszewslii
</author>
<affiliation confidence="0.617513">
Institute of Informatics, Wrocław University of Technology
Wybrzeie Wyspia´nskiego 27
Wrocław, Poland
</affiliation>
<email confidence="0.992731">
adam.radziszewski@pwr.wroc.pl
</email>
<sectionHeader confidence="0.993715" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939583333333">
We present a novel approach to noun
phrase lemmatisation where the main
phase is cast as a tagging problem. The
idea draws on the observation that the
lemmatisation of almost all Polish noun
phrases may be decomposed into trans-
formation of singular words (tokens) that
make up each phrase. We perform eval-
uation, which shows results similar to
those obtained earlier by a rule-based sys-
tem, while our approach allows to separate
chunking from lemmatisation.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999792714285714">
Lemmatisation of word forms is the task of find-
ing base forms (lemmas) for each token in running
text. Typically, it is performed along POS tagging
and is considered crucial for many NLP applica-
tions. Similar task may be defined for whole noun
phrases (Degórski, 2011). By lemmatisation of
noun phrases (NPs) we will understand assigning
each NP a grammatically correct NP correspond-
ing to the same phrase that could stand as a dic-
tionary entry.
The task of NP lemmatisation is rarely con-
sidered, although it carries great practical value.
For instance, any keyword extraction system that
works for a morphologically rich language must
deal with lemmatisation of NPs. This is because
keywords are often longer phrases (Turney, 2000),
while the user would be confused to see inflected
forms as system output. Similar situation happens
when attempting at terminology extraction from
domain corpora: it is usually assumed that do-
main terms are subclass of NPs (Marciniak and
Mykowiecka, 2013).
In (1) we give an example Polish noun phrase
(‘the main city of the municipality’). Through-
out the paper we assume the usage of the tagset
of the National Corpus of Polish (Przepiórkowski,
2009), henceforth called NCP in short. The or-
thographic form (1a) appears in instrumental case,
singular. Phrase lemma is given as (1b). Lem-
matisation of this phrase consists in reverting case
value of the main noun (miasto) as well as its
adjective modifier (głdwne) to nominative (nom).
Each form in the example is in singular number
(sg), miasto has neuter gender (n), gmina is fem-
inine (f).
</bodyText>
<figure confidence="0.663263333333333">
(1) a. głdwnym miastem gminy
main city municipality
inst:sg:n inst:sg:n gen:sg:f
b. głdwne miasto gminy
main city municipality
nom:sg:n nom:sg:n gen:sg:f
</figure>
<bodyText confidence="0.999775913043478">
According to the lemmatisation principles ac-
companying the NCP tagset, adjectives are lem-
matised as masculine forms (głdwny), hence it is
not sufficient to take word-level lemma nor the or-
thographic form to obtain phrase lemmatisation.
Degórski (2011) discuses some similar cases. He
also notes that this is not an easy task and lemma
of a whole NP is rarely a concatenation of lem-
mas of phrase components. It is worth stressing
that even the task of word-level lemmatisation is
non-trivial for inflectional languages due to a large
number of inflected forms and even larger num-
ber of syncretisms. According to Przepiórkowski
(2007), “a typical Polish adjective may have 11
textually different forms (... ) but as many as 70
different tags (2 numbers × 7 cases × 5 genders)”,
which indicates the scale of the problem. What is
more, several syntactic phenomena typical for Pol-
ish complicate NP lemmatisation further. E.g., ad-
jectives may both precede and follow nouns they
modify; many English prepositional phrases are
realised in Polish using oblique case without any
proposition (e.g., there is no standard Polish coun-
</bodyText>
<page confidence="0.968238">
701
</page>
<note confidence="0.9140545">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 701–709,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.994905">
terpart for the preposition of as genitive case is
used for this purpose).
In this paper we present a novel approach to
noun phrase lemmatisation where the main phase
is cast as a tagging problem and tackled using a
method devised for such problems, namely Con-
ditional Random Fields (CRF).
</bodyText>
<sectionHeader confidence="0.998825" genericHeader="introduction">
2 Related works
</sectionHeader>
<bodyText confidence="0.999492028571429">
NP lemmatisation received very little attention.
This situation may be attributed to prevalence of
works targeted at English, where the problem is
next to trivial due to weak inflection in the lan-
guage.
The only work that contains a complete de-
scription and evaluation of an approach to this
task we were able to find is the work of Degór-
ski (2011). The approach consists in incorpor-
ating phrase lemmatisation rules into a shallow
grammar developed for Polish. This is implemen-
ted by extending the Spejd shallow parsing frame-
work (Buczy´nski and Przepiórkowski, 2009) with
a rule action that is able to generate phrase lem-
mas. Degórski assumes that lemma of each NP
may be obtained by concatenating each token’s
orthographic form, lemma or ‘half-lemmatised’
form (e.g. grammatical case normalised to nom-
inative, while leaving feminine gender). The other
assumption is to neglect letter case: all phrases are
converted to lower case and this is not penalised
during evaluation. For development and evalu-
ation, two subsets of NCP were chosen and manu-
ally annotated with NP lemmas: development set
(112 phrases) and evaluation set (224 phrases).
Degórski notes that the selection was not entirely
random: two types of NPs were deliberately omit-
ted, namely foreign names and “a few groups for
which the proper lemmatisation seemed very un-
clear”. The final evaluation was performed in two
ways. First, it is shown that the output of the en-
tire system intersects only with 58.5% of the test
set. The high error rate is attributed to problems
with identifying NP boundaries correctly (29.5%
of test set was not recognised correctly with re-
spect to phrase boundaries). The other experiment
was to limit the evaluation to those NPs whose
boundaries were recognised correctly by the gram-
mar (70.5%). This resulted in 82.9% success rate.
The task of phrase lemmatisation bears a close
resemblance to a more popular task, namely lem-
matisation of named entities. Depending on the
type of named entities considered, those two may
be solved using similar or significantly different
methodologies. One approach, which is especially
suitable for person names, assumes that nominat-
ive forms may be found in the same source as the
inflected forms. Hence, the main challenge is to
define a similarity metric between named entities
(Piskorski et al., 2009; Koco´n and Piasecki, 2012),
which can be used to match different mentions of
the same names. Other named entity types may be
realised as arbitrary noun phrases. This calls for
more robust lemmatisation strategies.
Piskorski (2005) handles the problem of lem-
matisation of Polish named entities of various
types by combining specialised gazetteers with
lemmatisation rules added to a hand-written gram-
mar. As he notes, organisation names are often
built of noun phrases, hence it is important to un-
derstand their internal structure. Another interest-
ing observation is that such organisation names are
often structurally ambiguous, which is exempli-
fied with the phrase (2a), being a string of items
in genitive case (‘of the main library of the Higher
School of Economics’). Such cases are easier to
solve when having access to a collocation diction-
ary — it may be inferred that there are two colloc-
ations here: Biblioteka Główna and Wy˙zsza Szkoła
Handlowa.
</bodyText>
<figure confidence="0.853245909090909">
(2) a. Biblioteki Głównej Wy˙zszej
library main higher
gen:sg:f gen:sg:f gen:sg:f
Szkoły Handlowej
school commercial
gen:sg:f gen:sg:f
b. Biblioteka Główna Wy˙zszej
library main higher
nom:sg:f nom:sg:f gen:sg:f
Szkoły Handlowej
school commercial
</figure>
<subsectionHeader confidence="0.419123">
gen:sg:f gen:sg:f
</subsectionHeader>
<bodyText confidence="0.9918264">
While the paper reports detailed figures on
named entity recognition performance, the qual-
ity of lemmatisation is assessed only for all entity
types collectively: “79.6 of the detected NEs were
lemmatised correctly” (Piskorski, 2005).
</bodyText>
<sectionHeader confidence="0.9373065" genericHeader="method">
3 Phrase lemmatisation as a tagging
problem
</sectionHeader>
<bodyText confidence="0.997027">
The idea presented here is directly inspired by De-
górski’s observations. First, we will also assume
</bodyText>
<page confidence="0.996041">
702
</page>
<bodyText confidence="0.999763421052632">
that lemma of any NP may be obtained by concat-
enating simple transformations of word forms that
make up the phrase. As we will show in Sec. 4,
this assumption is virtually always satisfied. We
will argue that there is a small finite set of inflec-
tional transformations that are sufficient to lem-
matise nearly every Polish NP.
Consider example (1) again. Correct lemmat-
isation of the phrase may be obtained by apply-
ing a series of simple inflectional transformations
to each of its words. The first two words need to
be turned into nominative forms, the last one is
already lemmatised. This is depicted in (3a). To
show the real setting, this time we give full NCP
tags and word-level lemmas assigned as a result of
tagging. In the NCP tagset, the first part of each
tag denotes grammatical class (adj stands for ad-
jective, subst for noun). Adjectives are also spe-
cified for degree (pos — positive degree).
</bodyText>
<equation confidence="0.8189712">
(3) a. głównym
główny
adj:sg:inst:n:pos
miastem gminy
miasto gmina
subst:sg:inst:n subst:sg:gen:f
b. główne miasto
adj:sg:nom:n:pos subst:sg:nom:n
cas=nom cas=nom
gminy
</equation>
<bodyText confidence="0.993643340909091">
subst:sg:gen:f
=
Example (3b) consists of three rows: the lem-
matised phrase, the desired tags (tags that would
be attached to tokens of the lemmatised phrase)
and the transformations needed to obtain lemma
from orthographic forms. The notation cas=nom
means that to obtain the desired form (e.g. główne)
you need to find an entry in a morphological dic-
tionary that bears the same word-level lemma as
the inflected form (główny) and a tag that res-
ults from taking the tag of the inflected form
(adj:sg:inst:n:pos) and setting the value
of the tagset attribute cas (grammatical case) to
the value nom (nominative). The transformation
labelled = means that the inflected form is already
equal to the desired part of the lemma, hence no
transformation is needed.
A tagset note is in order. In the NCP tag-
set each tag may be decomposed into grammat-
ical class and attribute values, where the choice
of applicable attributes depends on the grammat-
ical class. For instance, nouns are specified for
number, gender and case. This assumption is im-
portant for our approach to be able to use simple
tag transformations in the form replace the value
of attribute A with the new value V (A=V). This is
not a serious limitation, since the same assumption
holds for most tagsets developed for inflectional
languages, e.g., the whole MULTEXT-East fam-
ily (Erjavec, 2012), Czech tagset (Jakubíˇcek et al.,
2011).
Our idea is simple: by expressing phrase lem-
matisation in terms of word-level transformations
we can reduce the task to tagging problem and
apply well known Machine Learning techniques
that have been devised for solving such problems
(e.g. CRF). An important advantage is that this al-
lows to rely not only on the information contained
within the phrase to be lemmatised, but also on
tokens belonging to its local neighbourhood.
Assuming that we have already trained a statist-
ical model, we need to perform the following steps
to obtain lemmatisation of a new text:
</bodyText>
<listItem confidence="0.996571142857143">
1. POS tagging,
2. NP chunking,
3. tagging with transformations by applying the
trained model,
4. application of transformations to obtain NP
lemmas (using a morphological dictionary to
generate forms).
</listItem>
<bodyText confidence="0.999860222222222">
To train the statistical model, we need training
data labelled with such transformations. Probably
the most reliable way to obtain such data would
be to let annotators manually encode a training
corpus with such transformations. However, the
task would be extremely tedious and the annotat-
ors would probably have to undergo special train-
ing (to be able to think in terms of transforma-
tions). We decided for a simpler solution. The
annotators were given a simpler task of assigning
each NP instance a lemma and a heuristic proced-
ure was used to induce transformations by match-
ing the manually annotated lemmas to phrases’ or-
thographic forms using a morphological diction-
ary. The details of this procedure are given in the
next section.
We decided to perform the experiments using
the data from Polish Corpus of Wrocław Univer-
</bodyText>
<page confidence="0.992385">
703
</page>
<bodyText confidence="0.99982128125">
sity of Technology1 (Broda et al., 2012). The
corpus (abbreviated to KPWr from now on) con-
tains manual shallow syntactic annotation which
includes NP chunks and their syntactic heads. The
main motivation to use this corpus was its very
permissive licence (Creative Commons Attribu-
tion), which will not constrain any further use of
the tools developed. What is more, it allowed us
to release the data annotated manually with phrase
lemmas and under the same licence2.
One of the assumptions of KPWr annotation is
that actual noun phrases and prepositional phrases
are labelled collectively as NP chunks. To ob-
tain real noun phrases, phrase-initial prepositions
must be stripped off3. For practical reasons we de-
cided to include automatic recognition of phrase-
initial prepositions into our model: we introduced
a special transformation for such cases (labelled
p), having the interpretation that the token belongs
to a phrase-initial preposition and should be dis-
carded when generating phrase lemma. Preposi-
tions are usually contained in single tokens. There
are some cases of multi-word units which we treat
as prepositions (secondary prepositions), e.g. ze
wzgl˛edu na (with respect to). This solution allows
to use our lemmatiser directly against chunker out-
put to obtain NP lemmas from both NPs and PPs.
For instance, the phrase o przenoszeniu bakterii
droga˛ płciowa˛ (about sexual transmission of bac-
teria) should be lemmatised to przenoszenie bak-
terii droga˛ płciowa˛ (sexual transmission of bac-
teria).
</bodyText>
<sectionHeader confidence="0.833229" genericHeader="method">
4 Preparation of training data
</sectionHeader>
<bodyText confidence="0.999930888888889">
First, simple lemmatisation guidelines were de-
veloped. The default strategy is to normalise the
case to nominative and the number to singular. If
the phrase was in fact prepositional, phrase-initial
preposition should be removed first. If changing
the number would alter semantics of the phrase,
it should be left plural (e.g., warunki ‘conditions’
as in terms and conditions). Some additional ex-
ceptions concern pronouns, fixed expressions and
</bodyText>
<footnote confidence="0.9991068">
1We used version 1.1 downloaded from http://www.
nlp.pwr.wroc.pl/kpwr.
2The whole dataset described in this paper is avail-
able at http://nlp.pwr.wroc.pl/en/static/
kpwr-lemma.
3Note that if we decided to use the data from NCP, we
would still have to face this issue. Although an explicit dis-
tinctions is made between NPs and PPs, NPs are not annot-
ated as separate chunks when belonging to a PP chunk (an
assumption which is typical for shallow parsing).
</footnote>
<bodyText confidence="0.9998741">
proper names. They were introduced to obtain
lemmas that are practically most useful.
A subset of documents from KPWr corpus was
drawn randomly. Each NP/PP belonging to this
subset was annotated manually. Contrary to (De-
górski, 2011), we made no exclusions, so the ob-
tained set contains some foreign names and a num-
ber of cases which were hard to lemmatise manu-
ally. Among the latter there was one group we
found particularly interesting. It consisted of items
following the following pattern: NP in plural mod-
ified by another NP or PP in plural. For many
cases it was hard to decide if both parts were to
be reverted to singular, only the main one or per-
haps both of them should be left in plural. We
present two such cases in (4a) and (4b). For in-
stance, (4b) could be lemmatised as opis tytułu z
Wikipedii (description of a Wikipedia title), but it
was not obvious if it was better than leaving the
whole phrase as is.
</bodyText>
<listItem confidence="0.686285">
(4) a. obawy ze strony autorów
</listItem>
<bodyText confidence="0.958195851851852">
‘concerns on the part of the authors’
b. opisy tytułów z Wikipedii
‘descriptions of the Wikipedia titles’
Altogether, the annotated documents contain
1669 phrases. We used the same implementa-
tion of the 2+1 model which was used to annotate
morphosyntax in NCP (Przepiórkowski and Sz-
ałkiewicz, 2012): two annotators performed the
task independently, after which their decisions
were compared and the discrepancies were high-
lighted. The annotators were given a chance to
rethink their decisions concerning the highlighted
phrases. Both annotators were only told which
phrases were lemmatised differently by the other
party but they didn’t know the other decision. The
purpose of this stage was to correct obvious mis-
takes. Their output was finally compared, result-
ing in 94% phrases labelled identically (90% be-
fore reconsidering decisions). The remaining dis-
crepancies were decided by a superannotator. The
whole set was divided randomly into the develop-
ment set (1105 NPs) and evaluation set (564 NPs).
The development set was enhanced with word-
level transformations that were induced automat-
ically in the following manner. The procedure as-
sumes the usage of a morphological dictionary ex-
tracted from Morfeusz SGJP analyser4 (Woli´nski,
</bodyText>
<footnote confidence="0.832792">
4morfeusz-SGJP-src-20110416 package
</footnote>
<page confidence="0.994764">
704
</page>
<bodyText confidence="0.999969367346939">
2006). The dictionary is stored as a set of (ortho-
graphic form, word-level lemma, tag). The pro-
cedure starts with tokenisation of the manually as-
signed lemma. Next, a heuristic identification of
phrase-initial preposition is performed. The as-
sumption is that, having cut the preposition, all the
remaining tokens of the original inflected phrase
must be matched 1:1 to corresponding tokens from
the human-assigned lemma. If any match problem
did occur, an error was reported and such a case
was examined manually. The only problems en-
countered were due to proper names unknown to
the dictionary and misspelled phrases (altogether
about 10 cases). Those cases were dealt with
manually. Also, all the extracted phrase-initial
prepositions were examined and no controversy
was found.
The input and output to the matching procedure
is illustrated in Fig. 1. The core matching hap-
pens at token level. The task is to find a suit-
able transformation for the given inflected form
from the original phrase, its tag and word-level
lemma, but also given the desired form being part
of human-assigned lemma. If the inflected form
is identical to the desired human-assigned lemma,
the ‘=’ transformation is returned without any tag
analysis. For other cases the morphological dic-
tionary is required. For instance, the inflected
form tej tagged as adj:sg:loc:f:pos should
be matched to the human-assigned form ta (the
row label H lem). The first subtask is to find
all entries in the morphological dictionary with
the orthographic form equal to human-assigned
lemma (ta), the word-level lemma equal to the
lemma assigned by the tagger (ten) and having a
tag with the same grammatical class as the tag-
ger has it (adj; we deliberately disallow trans-
formations changing the grammatical class). The
result is a set of entries with the given lemma
and orthographic form, but with different tags at-
tached. For the example considered, two tags
may be obtained: adj:sg:nom:f:pos and
adj:sg:voc:f:pos (the former is in nomin-
ative case, the latter — in vocative). Each of the
obtained tags is compared to the tag attached to
the inflected forms (adj:sg:loc:f:pos) and
this way candidate transformations are generated
(cas=nom and cas=voc here). The transform-
ations are heuristically ranked. Most importantly,
</bodyText>
<footnote confidence="0.537301666666667">
obtained from http://sgjp.pl/morfeusz/
dopobrania.html. The package is available under
2-clause BSD licence.
</footnote>
<bodyText confidence="0.998896">
cas=nom is always preferred, then nmb=sg (en-
forcing singular number), then transforming the
gender to different values, preferably to masculine
inanimate (gnd=m3). The lowest possible ranking
is given to a transformation enforcing case value
other than nominative.
</bodyText>
<table confidence="0.995196666666667">
Original: przy tej drodze
T tags: prep: adj: subst:
T lem: loc sg:loc:f:pos sg:loc:f
przy ten droga
H lem: ta droga
Transf.: p cas=nom cas=nom
</table>
<figureCaption confidence="0.998365">
Figure 1: Matching of an NP and its lemma. The
</figureCaption>
<bodyText confidence="0.935405166666667">
first row shows the original inflected form. The
next three present tagger output: tags (split into
two rows) and lemmas. H lem stands for the lemma
assigned by a human. Last row presents the trans-
formations induced.
We are fully aware of limitations of this ap-
proach. This ranking was inspired only by intu-
ition obtained from the lemmatisation guidelines
and the transformations selected this way may be
wrong in a number of cases. While many trans-
formations may lead to obtaining the same lemma
for a given form, many of them will still be ac-
cidental. Different syncretisms may apply to dif-
ferent lexemes, which can negatively impact the
ability of the model to generalise from one phrase
to other. On the other hand, manual inspection of
some fragments suggest that the transformations
inferred are rarely unjustified.
The frequencies of all transformations induced
from the development set are given in Tab. 1.
Note that the first five most frequent transforma-
tion make up 98.7% of all cases. These findings
support our hypothesis that a small finite set of
transformations is sufficient to express lemmatisa-
tion of nearly every Polish NP.
We have also tested an alternative variant of
the matching procedure that included additional
transformation ‘lem’ with the meaning take the
word-level lemma assigned by the tagger as the
correct lemmatisation. This transformation could
be induced after an unsuccessful attempt to induce
the ‘=’ transformation (i.e., if the correct human-
assigned lemmatisation was not identical to ortho-
graphic form). This resulted in replacing a number
of tag-level transformations (mostly cas=nom)
with the simple ‘lem’. The advantage of this vari-
</bodyText>
<page confidence="0.939299">
705
</page>
<equation confidence="0.646120421052632">
=2444 72%
cas=nom 434 13%
p 292 9%
nmb=sg 97 3%
cas=nom,nmb=sg 76 2%
gnd=m3 9
cas=nom,gnd=m3,nmb=sg 7
gnd=m3,nmb=sg 6
acn,cas=nom 5
acm=rec,cas=nom 3
cas=gen 3
cas=nom,gnd=m3 3
cas=nom,gnd=m1 2
gnd=f,nmb=sg 2
cas=nom,gnd=f 1
cas=nom,gnd=f,nmb=sg 1
cas=nom,nmb=pl 1
cas=nom,nmb=sg,gnd=m3 1
Total 3387 100%
</equation>
<tableCaption confidence="0.980476">
Table 1: Frequencies of transformations.
</tableCaption>
<bodyText confidence="0.99926375">
ant is that application of this transformation does
not require resorting to the dictionary. The disad-
vantage is that it is likely to worsen the general-
ising power of the model.
</bodyText>
<sectionHeader confidence="0.799581" genericHeader="method">
5 CRF and features
</sectionHeader>
<bodyText confidence="0.9806105">
The choice of CRF for sequence labelling was
mainly influenced by its successful application to
chunking of Polish (Radziszewski and Pawlaczek,
2012). The work describes a feature set pro-
posed for this task, which includes word forms in a
local window, values of grammatical class, gender,
number and case, tests for agreement on number,
gender and case, as well as simple tests for letter
case.
We took this feature set as a starting point. Then
we performed some experiments with feature gen-
eration and selection. For this purpose the devel-
opment set was split into training and testing part.
The most obvious, yet most successful change was
to introduce features returning the chunk tag as-
signed to a token. As KPWr also contains inform-
ation on the location of chunks’ syntactic heads
and this information is also output by the chunker,
we could also use this in our features. Another
improvement resulted from completely removing
tests for grammatical gender and limiting the em-
ployed tests for number to the current token.
The final feature set includes the following
items:
</bodyText>
<listItem confidence="0.997483913043478">
• the word forms (turned lower-case) of tokens
occupying a local window (−2, ... , +2),
• word form bigrams: (−1, 0) and (0, 1),
• chunk tags (IOB2 tags concatenated with
Boolean value denoting whether the syntactic
head is placed at the position), for a local
window (−1, 0, +1)
• chunk tags (IOB2 tags only) for positions −2
and +2, and two chunk tag bigrams: (−1, 0)
and (0, 1),
• grammatical class of tokens in the window
(−2,...,+2),
• grammatical class for the focus token (0) con-
catenated with the last character of the word-
form,
• values of grammatical case for tokens
(−2,−1,+1,+2),
• grammatical class of the focus token concat-
enated with its gender value,
• 2-letter prefix of the word form (lower-
cased),
• tests for agreements and letter case as in
(Radziszewski and Pawlaczek, 2012).
</listItem>
<sectionHeader confidence="0.991519" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999803578947368">
The performed evaluation assumed training of the
CRF on the whole development set annotated with
the induced transformations and then applying the
trained model to tag the evaluation part with trans-
formations. Transformations were then applied
and the obtained phrase lemmas were compared
to the reference annotation. This procedure in-
cludes the influence of deficiencies of the morpho-
logical dictionary. The version of KPWr used here
was tagged automatically using the WCRFT tag-
ger (Radziszewski, 2013), hence tagging errors are
also included.
Degórski (2011) reports separate figures for the
performance of the entire system (chunker + NP
lemmatiser) on the whole test set and performance
of the entire system limiting the test set only to
those phrases that the system is able to chunk cor-
rectly (i.e., to output correct phrase boundaries).
Such a choice is reasonable given that his system
</bodyText>
<page confidence="0.996004">
706
</page>
<bodyText confidence="0.999884538461539">
is based on rules that intermingle chunking with
lemmatisation. We cannot expect the system to
lemmatise correctly those groups which it is un-
able to capture. Our approach assumes two-stage
operation, where the chunker stage is partially in-
dependent from the lemmatisation. This is why we
decided to report performance of the whole sys-
tem on the whole test set, but also, performance
of the lemmatisation module alone on the whole
test set. This seems more appropriate, since the
chunker may be improved or completely replaced
independently, while discarding the phrases that
are too hard to parse is likely to bias the evalu-
ation of the lemmatisation stage (what is hard to
chunk is probably also hard to lemmatise).
For the setting where chunker was used, we
used the CRF-based chunker mentioned in the
previous section (Radziszewski and Pawlaczek,
2012). The chunker has been trained on the en-
tire KPWr except for the documents that belong to
the evaluation set.
Degórski (2011) uses concatenation of word-
level base forms assigned by the tagger as a
baseline. Observation of the development set sug-
gests that returning the original inflected NPs may
be a better baseline. We tested both variants. As
detection of phrase-initial prepositions is a part of
our task formulation, we had to implement it in
the baseline algorithms as well. Otherwise, the
comparison would be unfair. We decided to imple-
ment both baseline algorithms using the same CRF
model but trained on fabricated data. The training
data for the ‘take-orthographic-form’ baseline was
obtained by leaving the ‘remove-phrase-initial-
preposition’ (‘p’) transformation and replacing all
others with ‘=’. Similarly, for the ‘take-lemma’
baseline, other transformations were substituted
with ‘lem’.
The results of the full evaluation are presen-
ted in Tab. 2. The first conclusion is that the
figures are disappointingly low, but comparable
with the 58.5% success rate reported in (Degórski,
2011). The other observation is that the proposed
solution significantly outperforms both baseline,
out of which the ‘take-orthographic-form’ (orth
baseline) performs slightly better. Also, it turns
out that the variation of the matching proced-
ure using the ‘lem’ transformation (row labelled
CRF lem) performs slightly worse than the proced-
ure without this transformation (row CRF nolem).
This supports the suspicion that relying on word-
level lemmas may reduce the ability to generalise.
</bodyText>
<table confidence="0.9992058">
Algorithm Prec. Recall F
CRF nolem 55.1% 56.9% 56.0%
CRF lem 53.7% 55.5% 54.6%
orth baseline 38.6% 39.9% 39.2%
lem baseline 36.2% 37.4% 36.8%
</table>
<tableCaption confidence="0.9529555">
Table 2: Performance of NP lemmatisation includ-
ing chunking errors.
</tableCaption>
<bodyText confidence="0.992735357142857">
Results corresponding to performance of the
lemmatisation module alone are reported in Tab. 3.
The test has been performed using chunk bound-
aries and locations of syntactic heads taken from
the reference corpus. In this settings recall and
precision have the same interpretation, hence we
simply refer to the value as accuracy (percentage
of chunks that were lemmatised correctly). The
figures are considerably higher than those repor-
ted in Tab. 2, which shows the huge impact of
chunking errors. It is worth noting that the best
accuracy achieved is only slightly lower than that
achieved by Degórski (82.9%), while our task is
harder. As mentioned above, in Degórski’s setting,
the phrases that are too hard to parse are excluded
from the test set. Those phrases are also likely to
be hard cases for lemmatisation. The other import-
ant difference stems from phrase definitions used
in both corpora; NPs in NCP are generally shorter
than the chunks allowed in KPWr. Most notably,
KPWr allows the inclusion of PP modifiers within
NP chunks (Broda et al., 2012). It seems likely
that the proposed algorithm would performed bet-
ter when trained on data from NCP which assumes
simpler NP definition. Note that the complex NP
definition in KPWr also explains the huge gap
between results of lemmatisation alone and lem-
matisation including chunking errors.
</bodyText>
<table confidence="0.9969884">
Algorithm Correct lemmas Accuracy
CRF nolem 455 / 564 80.7%
CRF lem 444 / 564 78.7%
orth baseline 314 / 564 55.7%
lem baseline 290 / 564 51.4%
</table>
<tableCaption confidence="0.999899">
Table 3: Performance of NP lemmatisation alone.
</tableCaption>
<bodyText confidence="0.9999656">
We also checked the extent to which the entries
unknown to the morphological dictionary could
lower the performance of lemmatisation. It turned
out that only 8 words couldn’t be transformed
during evaluation due to lack of the entries that
</bodyText>
<page confidence="0.989246">
707
</page>
<bodyText confidence="0.99997555">
were sought in the morphological dictionary, out
of which 5 were anyway handled correctly in the
end by using the simple heuristic to output the ‘=’
transformation when everything else fails.
A rudimentary analysis of lemmatiser output in-
dicates that the most common error is the assign-
ment of the orthographic form as phrase lemma
where something else was expected. This seems
to concern mostly many NPs that are left in plural,
even simple ones (e.g. audycje telewizyjne ‘TV
programmes’), but there are also some cases of
personal pronouns left in oblique case (was ‘you-
pl-accusative/genitive’). It seems that a part of
these cases come from tagging errors (even if the
correct transformation is obtained, the results of its
application depend on the tag and lemma attached
to the inflected form by the tagger). Not surpris-
ingly, proper names are hard cases for the model
(e.g. Pod Napi˛eciem was lemmatised to napi˛ecie,
which would be correct weren’t it a title).
</bodyText>
<sectionHeader confidence="0.988952" genericHeader="conclusions">
7 Conclusions and further work
</sectionHeader>
<bodyText confidence="0.999970363636364">
We presented a novel approach to lemmatisation
of Polish noun phrases. The main advantage
of this solution is that it allows to separate the
lemmatisation phrase from the chunking phrase.
Degórski’s rule-based approach (Degórski, 2011)
was also built on top of an existing parser but, as he
notes, to improve the lemmatisation accuracy, the
grammar underlying the parser should actually be
rewritten with lemmatisation in mind. The other
advantage of the approach presented here is that
it is able to learn from a corpus containing manu-
ally assigned phrase lemmas. Extending existing
chunk-annotated corpora with phrase lemmas cor-
responds to a relatively simple annotation task.
The performance figures obtained by our al-
gorithm are comparable with that of Degórski’s
grammar, while the conditions under which our
system was evaluated were arguably less favour-
able. To enable a better comparison it would
be desirable to evaluate our approach against the
phrases from NCP.
The main disadvantage of the approach lies in
the data preparation stage. It requires some semi-
manual work to obtain labelling with transform-
ations, which is language- and tagset-dependent.
A very interesting alternative has been suggested
by an anonymous reviewer: instead of considering
tag-level transformations that require an exhaust-
ive morphological dictionary, it would be simpler
to rely entirely on string-to-string transformations
that map inflected forms to their expected coun-
terparts. Such transformations may be expressed
in terms of simple edit scripts, which has already
been successfully applied to word-level lemmat-
isation of Polish and other languages (Chrupała
et al., 2008). This way, the training data labelled
with transformations could be obtained automatic-
ally. What is more, application of such transform-
ations also does not depend on the dictionary. It is
not obvious how this would affect the performance
of the module and, hence, needs to be evaluated.
We plan this as our further work.
Also, it would be worthwhile to evaluate the
presented solution for other Slavic languages.
</bodyText>
<sectionHeader confidence="0.998563" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996595">
This work was financed by Innovative Economy
Programme project POIG.01.01.02-14-013/09.
</bodyText>
<sectionHeader confidence="0.998916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999837032258065">
Robert Bembenik, Łukasz Skonieczny, Henryk
Rybi´nski, Marzena Kryszkiewicz, and Marek
Niezgódka, editors. 2013. Intelligent Tools for
Building a Scientific Information Platform, volume
467 of Studies in Computational Intelligence.
Springer Berlin Heidelberg.
Bartosz Broda, Michał Marci´nczuk, Marek Mazi-
arz, Adam Radziszewski, and Adam Wardy´nski.
2012. KPWr: Towards a free corpus of Pol-
ish. In Nicoletta Calzolari, Khalid Choukri, Thierry
Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard,
Joseph Mariani, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of LREC’12, Istanbul, Turkey.
ELRA.
Aleksander Buczy´nski and Adam Przepiórkowski.
2009. Human language technology. challenges
of the information society. chapter Spejd: A
Shallow Processing and Morphological Disambigu-
ation Tool, pages 131–141. Springer-Verlag, Berlin,
Heidelberg.
Grzegorz Chrupała, Georgiana Dinu, and Josef van
Genabith. 2008. Learning morphology with Mor-
fette. In Nicoletta Calzolari, Khalid Choukri,
Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios
Piperidis, and Daniel Tapias, editors, Proceedings
of the Sixth International Conference on Language
Resources and Evaluation (LREC’08), Marrakech,
Morocco, may. European Language Resources As-
sociation (ELRA).
Łukasz Degórski. 2011. Towards the lemmatisation
of Polish nominal syntactic groups using a shallow
</reference>
<page confidence="0.975655">
708
</page>
<reference confidence="0.9999568">
grammar. In Pascal Bouvry, Mieczysław A. Kłopo-
tek, Franck Leprevost, Małgorzata Marciniak, Ag-
nieszka Mykowiecka, and Henryk Rybi´nski, editors,
Security and Intelligent Information Systems: Inter-
national Joint Conference, SIIS 2011, Warsaw, Po-
land, June 13-14, 2011, Revised Selected Papers,
volume 7053 of Lecture Notes in Computer Science,
pages 370–378. Springer-Verlag.
Tomaž Erjavec. 2012. MULTEXT-East: morphosyn-
tactic resources for Central and Eastern European
languages. Language Resources and Evaluation,
46(1):131–142.
Milo&amp;quot;s Jakubíˇcek, Vojtˇech Kováˇr, and Pavel Šmerk.
2011. Czech morphological tagset revisited. In
Proceedings of Recent Advances in Slavonic Natural
Language Processing, pages 29–42, Brno.
Jan Koco´n and Maciej Piasecki. 2012. Heterogeneous
named entity similarity function. In Petr Sojka, Ale&amp;quot;s
Horák, Ivan Kopeˇcek, and Karel Pala, editors, Text,
Speech and Dialogue, volume 7499 of Lecture Notes
in Computer Science, pages 223–231. Springer Ber-
lin Heidelberg.
Małgorzata Marciniak and Agnieszka Mykowiecka.
2013. Terminology extraction from domain texts in
Polish. In Bembenik et al. (Bembenik et al., 2013),
pages 171–185.
Jakub Piskorski, Karol Wieloch, and Marcin Sydow.
2009. On knowledge-poor methods for person name
matching and lemmatization for highly inflectional
languages. Information Retrieval, 12(3):275–299.
Jakub Piskorski. 2005. Named-entity recognition for
Polish with SProUT. In Leonard Bolc, Zbigniew
Michalewicz, and Toyoaki Nishida, editors, Intelli-
gent Media Technology for Communicative Intelli-
gence, volume 3490 of Lecture Notes in Computer
Science, pages 122–133. Springer Berlin Heidel-
berg.
Adam Przepiórkowski. 2007. Slavic information ex-
traction and partial parsing. In Proceedings of the
Workshop on Balto-Slavonic Natural Language Pro-
cessing, pages 1–10, Praga, Czechy, June. Associ-
ation for Computational Linguistics.
Adam Przepiórkowski. 2009. A comparison of
two morphosyntactic tagsets of Polish. In Violetta
Koseska-Toszewa, Ludmila Dimitrova, and Roman
Roszko, editors, Representing Semantics in Digital
Lexicography: Proceedings of MONDILEX Fourth
Open Workshop, pages 138–144, Warszawa.
Adam Przepiórkowski and Łukasz Szałkiewicz.
2012. Anotacja morfoskładniowa. In Adam
Przepiórkowski, Mirosław Ba´nko, Rafał L. Górski,
and Barbara Lewandowska-Tomaszczyk, editors,
Narodowy Korpus J˛ezyka Polskiego. Wydawnictwo
Naukowe PWN, Warsaw.
Adam Radziszewski and Adam Pawlaczek. 2012.
Large-scale experiments with NP chunking of Pol-
ish. In Proceedings of the 15th International Con-
ference on Text, Speech and Dialogue, Brno, Czech
Republic. Springer Verlag.
Adam Radziszewski. 2013. A tiered CRF tagger for
Polish. In Bembenik et al. (Bembenik et al., 2013),
pages 215–230.
Peter Turney. 2000. Learning algorithms for keyphrase
extraction. Information Retrieval, 2:303–336.
Marcin Woli´nski. 2006. Morfeusz — a practical
tool for the morphological analysis of Polish. In
Mieczysław A. Kłopotek, Sławomir T. Wierzcho´n,
and Krzysztof Trojanowski, editors, Proceedings of
IIPWM’06, pages 511–520, Ustro´n, Poland, June
19–22. Springer-Verlag, Berlin.
</reference>
<page confidence="0.99867">
709
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.808509">
<title confidence="0.999298">Learning to lemmatise Polish noun phrases</title>
<author confidence="0.989058">Adam</author>
<affiliation confidence="0.9910335">Institute of Informatics, Wrocław University of Wybrzeie Wyspia´nskiego</affiliation>
<address confidence="0.854451">Wrocław,</address>
<email confidence="0.994168">adam.radziszewski@pwr.wroc.pl</email>
<abstract confidence="0.998231846153846">We present a novel approach to noun phrase lemmatisation where the main phase is cast as a tagging problem. The idea draws on the observation that the lemmatisation of almost all Polish noun phrases may be decomposed into transformation of singular words (tokens) that make up each phrase. We perform evaluation, which shows results similar to those obtained earlier by a rule-based system, while our approach allows to separate chunking from lemmatisation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert Bembenik</author>
</authors>
<title>Łukasz Skonieczny, Henryk Rybi´nski, Marzena Kryszkiewicz,</title>
<date>2013</date>
<booktitle>of Studies in Computational Intelligence.</booktitle>
<volume>467</volume>
<editor>and Marek Niezgódka, editors.</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Bembenik, 2013</marker>
<rawString>Robert Bembenik, Łukasz Skonieczny, Henryk Rybi´nski, Marzena Kryszkiewicz, and Marek Niezgódka, editors. 2013. Intelligent Tools for Building a Scientific Information Platform, volume 467 of Studies in Computational Intelligence. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bartosz Broda</author>
<author>Michał Marci´nczuk</author>
<author>Marek Maziarz</author>
<author>Adam Radziszewski</author>
<author>Adam Wardy´nski</author>
</authors>
<title>KPWr: Towards a free corpus of Polish.</title>
<date>2012</date>
<booktitle>Proceedings of LREC’12,</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey.</location>
<marker>Broda, Marci´nczuk, Maziarz, Radziszewski, Wardy´nski, 2012</marker>
<rawString>Bartosz Broda, Michał Marci´nczuk, Marek Maziarz, Adam Radziszewski, and Adam Wardy´nski. 2012. KPWr: Towards a free corpus of Polish. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of LREC’12, Istanbul, Turkey. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aleksander Buczy´nski</author>
<author>Adam Przepiórkowski</author>
</authors>
<title>Human language technology. challenges of the information society. chapter Spejd: A Shallow Processing and Morphological Disambiguation Tool,</title>
<date>2009</date>
<pages>131--141</pages>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Buczy´nski, Przepiórkowski, 2009</marker>
<rawString>Aleksander Buczy´nski and Adam Przepiórkowski. 2009. Human language technology. challenges of the information society. chapter Spejd: A Shallow Processing and Morphological Disambiguation Tool, pages 131–141. Springer-Verlag, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
<author>Georgiana Dinu</author>
<author>Josef van Genabith</author>
</authors>
<title>Learning morphology with Morfette.</title>
<date>2008</date>
<booktitle>Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08),</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, and Daniel Tapias, editors,</editor>
<location>Marrakech, Morocco,</location>
<marker>Chrupała, Dinu, van Genabith, 2008</marker>
<rawString>Grzegorz Chrupała, Georgiana Dinu, and Josef van Genabith. 2008. Learning morphology with Morfette. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, and Daniel Tapias, editors, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Łukasz Degórski</author>
</authors>
<title>Towards the lemmatisation of Polish nominal syntactic groups using a shallow grammar.</title>
<date>2011</date>
<booktitle>Security and Intelligent Information Systems: International Joint Conference, SIIS 2011,</booktitle>
<volume>7053</volume>
<pages>370--378</pages>
<editor>In Pascal Bouvry, Mieczysław A. Kłopotek, Franck Leprevost, Małgorzata Marciniak, Agnieszka Mykowiecka, and Henryk Rybi´nski, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<location>Warsaw, Poland,</location>
<contexts>
<context position="943" citStr="Degórski, 2011" startWordPosition="143" endWordPosition="144">the observation that the lemmatisation of almost all Polish noun phrases may be decomposed into transformation of singular words (tokens) that make up each phrase. We perform evaluation, which shows results similar to those obtained earlier by a rule-based system, while our approach allows to separate chunking from lemmatisation. 1 Introduction Lemmatisation of word forms is the task of finding base forms (lemmas) for each token in running text. Typically, it is performed along POS tagging and is considered crucial for many NLP applications. Similar task may be defined for whole noun phrases (Degórski, 2011). By lemmatisation of noun phrases (NPs) we will understand assigning each NP a grammatically correct NP corresponding to the same phrase that could stand as a dictionary entry. The task of NP lemmatisation is rarely considered, although it carries great practical value. For instance, any keyword extraction system that works for a morphologically rich language must deal with lemmatisation of NPs. This is because keywords are often longer phrases (Turney, 2000), while the user would be confused to see inflected forms as system output. Similar situation happens when attempting at terminology ext</context>
<context position="2655" citStr="Degórski (2011)" startWordPosition="416" endWordPosition="417">ng case value of the main noun (miasto) as well as its adjective modifier (głdwne) to nominative (nom). Each form in the example is in singular number (sg), miasto has neuter gender (n), gmina is feminine (f). (1) a. głdwnym miastem gminy main city municipality inst:sg:n inst:sg:n gen:sg:f b. głdwne miasto gminy main city municipality nom:sg:n nom:sg:n gen:sg:f According to the lemmatisation principles accompanying the NCP tagset, adjectives are lemmatised as masculine forms (głdwny), hence it is not sufficient to take word-level lemma nor the orthographic form to obtain phrase lemmatisation. Degórski (2011) discuses some similar cases. He also notes that this is not an easy task and lemma of a whole NP is rarely a concatenation of lemmas of phrase components. It is worth stressing that even the task of word-level lemmatisation is non-trivial for inflectional languages due to a large number of inflected forms and even larger number of syncretisms. According to Przepiórkowski (2007), “a typical Polish adjective may have 11 textually different forms (... ) but as many as 70 different tags (2 numbers × 7 cases × 5 genders)”, which indicates the scale of the problem. What is more, several syntactic p</context>
<context position="4369" citStr="Degórski (2011)" startWordPosition="700" endWordPosition="702">ive case is used for this purpose). In this paper we present a novel approach to noun phrase lemmatisation where the main phase is cast as a tagging problem and tackled using a method devised for such problems, namely Conditional Random Fields (CRF). 2 Related works NP lemmatisation received very little attention. This situation may be attributed to prevalence of works targeted at English, where the problem is next to trivial due to weak inflection in the language. The only work that contains a complete description and evaluation of an approach to this task we were able to find is the work of Degórski (2011). The approach consists in incorporating phrase lemmatisation rules into a shallow grammar developed for Polish. This is implemented by extending the Spejd shallow parsing framework (Buczy´nski and Przepiórkowski, 2009) with a rule action that is able to generate phrase lemmas. Degórski assumes that lemma of each NP may be obtained by concatenating each token’s orthographic form, lemma or ‘half-lemmatised’ form (e.g. grammatical case normalised to nominative, while leaving feminine gender). The other assumption is to neglect letter case: all phrases are converted to lower case and this is not </context>
<context position="14696" citStr="Degórski, 2011" startWordPosition="2356" endWordPosition="2358">The whole dataset described in this paper is available at http://nlp.pwr.wroc.pl/en/static/ kpwr-lemma. 3Note that if we decided to use the data from NCP, we would still have to face this issue. Although an explicit distinctions is made between NPs and PPs, NPs are not annotated as separate chunks when belonging to a PP chunk (an assumption which is typical for shallow parsing). proper names. They were introduced to obtain lemmas that are practically most useful. A subset of documents from KPWr corpus was drawn randomly. Each NP/PP belonging to this subset was annotated manually. Contrary to (Degórski, 2011), we made no exclusions, so the obtained set contains some foreign names and a number of cases which were hard to lemmatise manually. Among the latter there was one group we found particularly interesting. It consisted of items following the following pattern: NP in plural modified by another NP or PP in plural. For many cases it was hard to decide if both parts were to be reverted to singular, only the main one or perhaps both of them should be left in plural. We present two such cases in (4a) and (4b). For instance, (4b) could be lemmatised as opis tytułu z Wikipedii (description of a Wikipe</context>
<context position="24215" citStr="Degórski (2011)" startWordPosition="3897" endWordPosition="3898">as in (Radziszewski and Pawlaczek, 2012). 6 Evaluation The performed evaluation assumed training of the CRF on the whole development set annotated with the induced transformations and then applying the trained model to tag the evaluation part with transformations. Transformations were then applied and the obtained phrase lemmas were compared to the reference annotation. This procedure includes the influence of deficiencies of the morphological dictionary. The version of KPWr used here was tagged automatically using the WCRFT tagger (Radziszewski, 2013), hence tagging errors are also included. Degórski (2011) reports separate figures for the performance of the entire system (chunker + NP lemmatiser) on the whole test set and performance of the entire system limiting the test set only to those phrases that the system is able to chunk correctly (i.e., to output correct phrase boundaries). Such a choice is reasonable given that his system 706 is based on rules that intermingle chunking with lemmatisation. We cannot expect the system to lemmatise correctly those groups which it is unable to capture. Our approach assumes two-stage operation, where the chunker stage is partially independent from the lem</context>
<context position="25534" citStr="Degórski (2011)" startWordPosition="4117" endWordPosition="4118">also, performance of the lemmatisation module alone on the whole test set. This seems more appropriate, since the chunker may be improved or completely replaced independently, while discarding the phrases that are too hard to parse is likely to bias the evaluation of the lemmatisation stage (what is hard to chunk is probably also hard to lemmatise). For the setting where chunker was used, we used the CRF-based chunker mentioned in the previous section (Radziszewski and Pawlaczek, 2012). The chunker has been trained on the entire KPWr except for the documents that belong to the evaluation set. Degórski (2011) uses concatenation of wordlevel base forms assigned by the tagger as a baseline. Observation of the development set suggests that returning the original inflected NPs may be a better baseline. We tested both variants. As detection of phrase-initial prepositions is a part of our task formulation, we had to implement it in the baseline algorithms as well. Otherwise, the comparison would be unfair. We decided to implement both baseline algorithms using the same CRF model but trained on fabricated data. The training data for the ‘take-orthographic-form’ baseline was obtained by leaving the ‘remov</context>
<context position="30222" citStr="Degórski, 2011" startWordPosition="4867" endWordPosition="4868">of these cases come from tagging errors (even if the correct transformation is obtained, the results of its application depend on the tag and lemma attached to the inflected form by the tagger). Not surprisingly, proper names are hard cases for the model (e.g. Pod Napi˛eciem was lemmatised to napi˛ecie, which would be correct weren’t it a title). 7 Conclusions and further work We presented a novel approach to lemmatisation of Polish noun phrases. The main advantage of this solution is that it allows to separate the lemmatisation phrase from the chunking phrase. Degórski’s rule-based approach (Degórski, 2011) was also built on top of an existing parser but, as he notes, to improve the lemmatisation accuracy, the grammar underlying the parser should actually be rewritten with lemmatisation in mind. The other advantage of the approach presented here is that it is able to learn from a corpus containing manually assigned phrase lemmas. Extending existing chunk-annotated corpora with phrase lemmas corresponds to a relatively simple annotation task. The performance figures obtained by our algorithm are comparable with that of Degórski’s grammar, while the conditions under which our system was evaluated </context>
</contexts>
<marker>Degórski, 2011</marker>
<rawString>Łukasz Degórski. 2011. Towards the lemmatisation of Polish nominal syntactic groups using a shallow grammar. In Pascal Bouvry, Mieczysław A. Kłopotek, Franck Leprevost, Małgorzata Marciniak, Agnieszka Mykowiecka, and Henryk Rybi´nski, editors, Security and Intelligent Information Systems: International Joint Conference, SIIS 2011, Warsaw, Poland, June 13-14, 2011, Revised Selected Papers, volume 7053 of Lecture Notes in Computer Science, pages 370–378. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaž Erjavec</author>
</authors>
<title>MULTEXT-East: morphosyntactic resources for Central and Eastern European languages. Language Resources and Evaluation,</title>
<date>2012</date>
<pages>46--1</pages>
<contexts>
<context position="10387" citStr="Erjavec, 2012" startWordPosition="1672" endWordPosition="1673">sformation is needed. A tagset note is in order. In the NCP tagset each tag may be decomposed into grammatical class and attribute values, where the choice of applicable attributes depends on the grammatical class. For instance, nouns are specified for number, gender and case. This assumption is important for our approach to be able to use simple tag transformations in the form replace the value of attribute A with the new value V (A=V). This is not a serious limitation, since the same assumption holds for most tagsets developed for inflectional languages, e.g., the whole MULTEXT-East family (Erjavec, 2012), Czech tagset (Jakubíˇcek et al., 2011). Our idea is simple: by expressing phrase lemmatisation in terms of word-level transformations we can reduce the task to tagging problem and apply well known Machine Learning techniques that have been devised for solving such problems (e.g. CRF). An important advantage is that this allows to rely not only on the information contained within the phrase to be lemmatised, but also on tokens belonging to its local neighbourhood. Assuming that we have already trained a statistical model, we need to perform the following steps to obtain lemmatisation of a new</context>
</contexts>
<marker>Erjavec, 2012</marker>
<rawString>Tomaž Erjavec. 2012. MULTEXT-East: morphosyntactic resources for Central and Eastern European languages. Language Resources and Evaluation, 46(1):131–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milos Jakubíˇcek</author>
<author>Vojtˇech Kováˇr</author>
<author>Pavel Šmerk</author>
</authors>
<title>Czech morphological tagset revisited.</title>
<date>2011</date>
<booktitle>In Proceedings of Recent Advances in Slavonic Natural Language Processing,</booktitle>
<pages>29--42</pages>
<location>Brno.</location>
<marker>Jakubíˇcek, Kováˇr, Šmerk, 2011</marker>
<rawString>Milo&amp;quot;s Jakubíˇcek, Vojtˇech Kováˇr, and Pavel Šmerk. 2011. Czech morphological tagset revisited. In Proceedings of Recent Advances in Slavonic Natural Language Processing, pages 29–42, Brno.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Koco´n</author>
<author>Maciej Piasecki</author>
</authors>
<title>Heterogeneous named entity similarity function.</title>
<date>2012</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>7499</volume>
<pages>223--231</pages>
<editor>In Petr Sojka, Ale&amp;quot;s Horák, Ivan Kopeˇcek, and Karel Pala, editors, Text, Speech and Dialogue,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Koco´n, Piasecki, 2012</marker>
<rawString>Jan Koco´n and Maciej Piasecki. 2012. Heterogeneous named entity similarity function. In Petr Sojka, Ale&amp;quot;s Horák, Ivan Kopeˇcek, and Karel Pala, editors, Text, Speech and Dialogue, volume 7499 of Lecture Notes in Computer Science, pages 223–231. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Małgorzata Marciniak</author>
<author>Agnieszka Mykowiecka</author>
</authors>
<title>Terminology extraction from domain texts in Polish.</title>
<date>2013</date>
<booktitle>In Bembenik et al. (Bembenik</booktitle>
<pages>171--185</pages>
<contexts>
<context position="1664" citStr="Marciniak and Mykowiecka, 2013" startWordPosition="255" endWordPosition="258">lly correct NP corresponding to the same phrase that could stand as a dictionary entry. The task of NP lemmatisation is rarely considered, although it carries great practical value. For instance, any keyword extraction system that works for a morphologically rich language must deal with lemmatisation of NPs. This is because keywords are often longer phrases (Turney, 2000), while the user would be confused to see inflected forms as system output. Similar situation happens when attempting at terminology extraction from domain corpora: it is usually assumed that domain terms are subclass of NPs (Marciniak and Mykowiecka, 2013). In (1) we give an example Polish noun phrase (‘the main city of the municipality’). Throughout the paper we assume the usage of the tagset of the National Corpus of Polish (Przepiórkowski, 2009), henceforth called NCP in short. The orthographic form (1a) appears in instrumental case, singular. Phrase lemma is given as (1b). Lemmatisation of this phrase consists in reverting case value of the main noun (miasto) as well as its adjective modifier (głdwne) to nominative (nom). Each form in the example is in singular number (sg), miasto has neuter gender (n), gmina is feminine (f). (1) a. głdwnym</context>
</contexts>
<marker>Marciniak, Mykowiecka, 2013</marker>
<rawString>Małgorzata Marciniak and Agnieszka Mykowiecka. 2013. Terminology extraction from domain texts in Polish. In Bembenik et al. (Bembenik et al., 2013), pages 171–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakub Piskorski</author>
<author>Karol Wieloch</author>
<author>Marcin Sydow</author>
</authors>
<title>On knowledge-poor methods for person name matching and lemmatization for highly inflectional languages.</title>
<date>2009</date>
<journal>Information Retrieval,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="6355" citStr="Piskorski et al., 2009" startWordPosition="1019" endWordPosition="1022"> those NPs whose boundaries were recognised correctly by the grammar (70.5%). This resulted in 82.9% success rate. The task of phrase lemmatisation bears a close resemblance to a more popular task, namely lemmatisation of named entities. Depending on the type of named entities considered, those two may be solved using similar or significantly different methodologies. One approach, which is especially suitable for person names, assumes that nominative forms may be found in the same source as the inflected forms. Hence, the main challenge is to define a similarity metric between named entities (Piskorski et al., 2009; Koco´n and Piasecki, 2012), which can be used to match different mentions of the same names. Other named entity types may be realised as arbitrary noun phrases. This calls for more robust lemmatisation strategies. Piskorski (2005) handles the problem of lemmatisation of Polish named entities of various types by combining specialised gazetteers with lemmatisation rules added to a hand-written grammar. As he notes, organisation names are often built of noun phrases, hence it is important to understand their internal structure. Another interesting observation is that such organisation names are</context>
</contexts>
<marker>Piskorski, Wieloch, Sydow, 2009</marker>
<rawString>Jakub Piskorski, Karol Wieloch, and Marcin Sydow. 2009. On knowledge-poor methods for person name matching and lemmatization for highly inflectional languages. Information Retrieval, 12(3):275–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakub Piskorski</author>
</authors>
<title>Named-entity recognition for Polish with SProUT.</title>
<date>2005</date>
<booktitle>Intelligent Media Technology for Communicative Intelligence,</booktitle>
<volume>3490</volume>
<pages>122--133</pages>
<editor>In Leonard Bolc, Zbigniew Michalewicz, and Toyoaki Nishida, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="6587" citStr="Piskorski (2005)" startWordPosition="1057" endWordPosition="1058">Depending on the type of named entities considered, those two may be solved using similar or significantly different methodologies. One approach, which is especially suitable for person names, assumes that nominative forms may be found in the same source as the inflected forms. Hence, the main challenge is to define a similarity metric between named entities (Piskorski et al., 2009; Koco´n and Piasecki, 2012), which can be used to match different mentions of the same names. Other named entity types may be realised as arbitrary noun phrases. This calls for more robust lemmatisation strategies. Piskorski (2005) handles the problem of lemmatisation of Polish named entities of various types by combining specialised gazetteers with lemmatisation rules added to a hand-written grammar. As he notes, organisation names are often built of noun phrases, hence it is important to understand their internal structure. Another interesting observation is that such organisation names are often structurally ambiguous, which is exemplified with the phrase (2a), being a string of items in genitive case (‘of the main library of the Higher School of Economics’). Such cases are easier to solve when having access to a col</context>
<context position="7811" citStr="Piskorski, 2005" startWordPosition="1242" endWordPosition="1243"> dictionary — it may be inferred that there are two collocations here: Biblioteka Główna and Wy˙zsza Szkoła Handlowa. (2) a. Biblioteki Głównej Wy˙zszej library main higher gen:sg:f gen:sg:f gen:sg:f Szkoły Handlowej school commercial gen:sg:f gen:sg:f b. Biblioteka Główna Wy˙zszej library main higher nom:sg:f nom:sg:f gen:sg:f Szkoły Handlowej school commercial gen:sg:f gen:sg:f While the paper reports detailed figures on named entity recognition performance, the quality of lemmatisation is assessed only for all entity types collectively: “79.6 of the detected NEs were lemmatised correctly” (Piskorski, 2005). 3 Phrase lemmatisation as a tagging problem The idea presented here is directly inspired by Degórski’s observations. First, we will also assume 702 that lemma of any NP may be obtained by concatenating simple transformations of word forms that make up the phrase. As we will show in Sec. 4, this assumption is virtually always satisfied. We will argue that there is a small finite set of inflectional transformations that are sufficient to lemmatise nearly every Polish NP. Consider example (1) again. Correct lemmatisation of the phrase may be obtained by applying a series of simple inflectional </context>
</contexts>
<marker>Piskorski, 2005</marker>
<rawString>Jakub Piskorski. 2005. Named-entity recognition for Polish with SProUT. In Leonard Bolc, Zbigniew Michalewicz, and Toyoaki Nishida, editors, Intelligent Media Technology for Communicative Intelligence, volume 3490 of Lecture Notes in Computer Science, pages 122–133. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Przepiórkowski</author>
</authors>
<title>Slavic information extraction and partial parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Praga, Czechy,</location>
<contexts>
<context position="3036" citStr="Przepiórkowski (2007)" startWordPosition="481" endWordPosition="482">o the lemmatisation principles accompanying the NCP tagset, adjectives are lemmatised as masculine forms (głdwny), hence it is not sufficient to take word-level lemma nor the orthographic form to obtain phrase lemmatisation. Degórski (2011) discuses some similar cases. He also notes that this is not an easy task and lemma of a whole NP is rarely a concatenation of lemmas of phrase components. It is worth stressing that even the task of word-level lemmatisation is non-trivial for inflectional languages due to a large number of inflected forms and even larger number of syncretisms. According to Przepiórkowski (2007), “a typical Polish adjective may have 11 textually different forms (... ) but as many as 70 different tags (2 numbers × 7 cases × 5 genders)”, which indicates the scale of the problem. What is more, several syntactic phenomena typical for Polish complicate NP lemmatisation further. E.g., adjectives may both precede and follow nouns they modify; many English prepositional phrases are realised in Polish using oblique case without any proposition (e.g., there is no standard Polish coun701 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 701–709, Sofi</context>
</contexts>
<marker>Przepiórkowski, 2007</marker>
<rawString>Adam Przepiórkowski. 2007. Slavic information extraction and partial parsing. In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing, pages 1–10, Praga, Czechy, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Przepiórkowski</author>
</authors>
<title>A comparison of two morphosyntactic tagsets of Polish.</title>
<date>2009</date>
<booktitle>Representing Semantics in Digital Lexicography: Proceedings of MONDILEX Fourth Open Workshop,</booktitle>
<pages>138--144</pages>
<editor>In Violetta Koseska-Toszewa, Ludmila Dimitrova, and Roman Roszko, editors,</editor>
<location>Warszawa.</location>
<contexts>
<context position="1860" citStr="Przepiórkowski, 2009" startWordPosition="291" endWordPosition="292">d extraction system that works for a morphologically rich language must deal with lemmatisation of NPs. This is because keywords are often longer phrases (Turney, 2000), while the user would be confused to see inflected forms as system output. Similar situation happens when attempting at terminology extraction from domain corpora: it is usually assumed that domain terms are subclass of NPs (Marciniak and Mykowiecka, 2013). In (1) we give an example Polish noun phrase (‘the main city of the municipality’). Throughout the paper we assume the usage of the tagset of the National Corpus of Polish (Przepiórkowski, 2009), henceforth called NCP in short. The orthographic form (1a) appears in instrumental case, singular. Phrase lemma is given as (1b). Lemmatisation of this phrase consists in reverting case value of the main noun (miasto) as well as its adjective modifier (głdwne) to nominative (nom). Each form in the example is in singular number (sg), miasto has neuter gender (n), gmina is feminine (f). (1) a. głdwnym miastem gminy main city municipality inst:sg:n inst:sg:n gen:sg:f b. głdwne miasto gminy main city municipality nom:sg:n nom:sg:n gen:sg:f According to the lemmatisation principles accompanying t</context>
<context position="4588" citStr="Przepiórkowski, 2009" startWordPosition="733" endWordPosition="734">mely Conditional Random Fields (CRF). 2 Related works NP lemmatisation received very little attention. This situation may be attributed to prevalence of works targeted at English, where the problem is next to trivial due to weak inflection in the language. The only work that contains a complete description and evaluation of an approach to this task we were able to find is the work of Degórski (2011). The approach consists in incorporating phrase lemmatisation rules into a shallow grammar developed for Polish. This is implemented by extending the Spejd shallow parsing framework (Buczy´nski and Przepiórkowski, 2009) with a rule action that is able to generate phrase lemmas. Degórski assumes that lemma of each NP may be obtained by concatenating each token’s orthographic form, lemma or ‘half-lemmatised’ form (e.g. grammatical case normalised to nominative, while leaving feminine gender). The other assumption is to neglect letter case: all phrases are converted to lower case and this is not penalised during evaluation. For development and evaluation, two subsets of NCP were chosen and manually annotated with NP lemmas: development set (112 phrases) and evaluation set (224 phrases). Degórski notes that the </context>
</contexts>
<marker>Przepiórkowski, 2009</marker>
<rawString>Adam Przepiórkowski. 2009. A comparison of two morphosyntactic tagsets of Polish. In Violetta Koseska-Toszewa, Ludmila Dimitrova, and Roman Roszko, editors, Representing Semantics in Digital Lexicography: Proceedings of MONDILEX Fourth Open Workshop, pages 138–144, Warszawa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Przepiórkowski</author>
<author>Łukasz Szałkiewicz</author>
</authors>
<title>Anotacja morfoskładniowa.</title>
<date>2012</date>
<booktitle>Narodowy Korpus J˛ezyka Polskiego. Wydawnictwo Naukowe PWN,</booktitle>
<editor>In Adam Przepiórkowski, Mirosław Ba´nko, Rafał L. Górski, and Barbara Lewandowska-Tomaszczyk, editors,</editor>
<location>Warsaw.</location>
<contexts>
<context position="15714" citStr="Przepiórkowski and Szałkiewicz, 2012" startWordPosition="2538" endWordPosition="2542">ted to singular, only the main one or perhaps both of them should be left in plural. We present two such cases in (4a) and (4b). For instance, (4b) could be lemmatised as opis tytułu z Wikipedii (description of a Wikipedia title), but it was not obvious if it was better than leaving the whole phrase as is. (4) a. obawy ze strony autorów ‘concerns on the part of the authors’ b. opisy tytułów z Wikipedii ‘descriptions of the Wikipedia titles’ Altogether, the annotated documents contain 1669 phrases. We used the same implementation of the 2+1 model which was used to annotate morphosyntax in NCP (Przepiórkowski and Szałkiewicz, 2012): two annotators performed the task independently, after which their decisions were compared and the discrepancies were highlighted. The annotators were given a chance to rethink their decisions concerning the highlighted phrases. Both annotators were only told which phrases were lemmatised differently by the other party but they didn’t know the other decision. The purpose of this stage was to correct obvious mistakes. Their output was finally compared, resulting in 94% phrases labelled identically (90% before reconsidering decisions). The remaining discrepancies were decided by a superannotat</context>
</contexts>
<marker>Przepiórkowski, Szałkiewicz, 2012</marker>
<rawString>Adam Przepiórkowski and Łukasz Szałkiewicz. 2012. Anotacja morfoskładniowa. In Adam Przepiórkowski, Mirosław Ba´nko, Rafał L. Górski, and Barbara Lewandowska-Tomaszczyk, editors, Narodowy Korpus J˛ezyka Polskiego. Wydawnictwo Naukowe PWN, Warsaw.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Radziszewski</author>
<author>Adam Pawlaczek</author>
</authors>
<title>Large-scale experiments with NP chunking of Polish.</title>
<date>2012</date>
<booktitle>In Proceedings of the 15th International Conference on Text, Speech and Dialogue,</booktitle>
<publisher>Springer Verlag.</publisher>
<location>Brno, Czech Republic.</location>
<contexts>
<context position="21914" citStr="Radziszewski and Pawlaczek, 2012" startWordPosition="3510" endWordPosition="3513">=sg 76 2% gnd=m3 9 cas=nom,gnd=m3,nmb=sg 7 gnd=m3,nmb=sg 6 acn,cas=nom 5 acm=rec,cas=nom 3 cas=gen 3 cas=nom,gnd=m3 3 cas=nom,gnd=m1 2 gnd=f,nmb=sg 2 cas=nom,gnd=f 1 cas=nom,gnd=f,nmb=sg 1 cas=nom,nmb=pl 1 cas=nom,nmb=sg,gnd=m3 1 Total 3387 100% Table 1: Frequencies of transformations. ant is that application of this transformation does not require resorting to the dictionary. The disadvantage is that it is likely to worsen the generalising power of the model. 5 CRF and features The choice of CRF for sequence labelling was mainly influenced by its successful application to chunking of Polish (Radziszewski and Pawlaczek, 2012). The work describes a feature set proposed for this task, which includes word forms in a local window, values of grammatical class, gender, number and case, tests for agreement on number, gender and case, as well as simple tests for letter case. We took this feature set as a starting point. Then we performed some experiments with feature generation and selection. For this purpose the development set was split into training and testing part. The most obvious, yet most successful change was to introduce features returning the chunk tag assigned to a token. As KPWr also contains information on t</context>
<context position="23640" citStr="Radziszewski and Pawlaczek, 2012" startWordPosition="3809" endWordPosition="3812">ted with Boolean value denoting whether the syntactic head is placed at the position), for a local window (−1, 0, +1) • chunk tags (IOB2 tags only) for positions −2 and +2, and two chunk tag bigrams: (−1, 0) and (0, 1), • grammatical class of tokens in the window (−2,...,+2), • grammatical class for the focus token (0) concatenated with the last character of the wordform, • values of grammatical case for tokens (−2,−1,+1,+2), • grammatical class of the focus token concatenated with its gender value, • 2-letter prefix of the word form (lowercased), • tests for agreements and letter case as in (Radziszewski and Pawlaczek, 2012). 6 Evaluation The performed evaluation assumed training of the CRF on the whole development set annotated with the induced transformations and then applying the trained model to tag the evaluation part with transformations. Transformations were then applied and the obtained phrase lemmas were compared to the reference annotation. This procedure includes the influence of deficiencies of the morphological dictionary. The version of KPWr used here was tagged automatically using the WCRFT tagger (Radziszewski, 2013), hence tagging errors are also included. Degórski (2011) reports separate figures</context>
<context position="25409" citStr="Radziszewski and Pawlaczek, 2012" startWordPosition="4093" endWordPosition="4096">e is partially independent from the lemmatisation. This is why we decided to report performance of the whole system on the whole test set, but also, performance of the lemmatisation module alone on the whole test set. This seems more appropriate, since the chunker may be improved or completely replaced independently, while discarding the phrases that are too hard to parse is likely to bias the evaluation of the lemmatisation stage (what is hard to chunk is probably also hard to lemmatise). For the setting where chunker was used, we used the CRF-based chunker mentioned in the previous section (Radziszewski and Pawlaczek, 2012). The chunker has been trained on the entire KPWr except for the documents that belong to the evaluation set. Degórski (2011) uses concatenation of wordlevel base forms assigned by the tagger as a baseline. Observation of the development set suggests that returning the original inflected NPs may be a better baseline. We tested both variants. As detection of phrase-initial prepositions is a part of our task formulation, we had to implement it in the baseline algorithms as well. Otherwise, the comparison would be unfair. We decided to implement both baseline algorithms using the same CRF model b</context>
</contexts>
<marker>Radziszewski, Pawlaczek, 2012</marker>
<rawString>Adam Radziszewski and Adam Pawlaczek. 2012. Large-scale experiments with NP chunking of Polish. In Proceedings of the 15th International Conference on Text, Speech and Dialogue, Brno, Czech Republic. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Radziszewski</author>
</authors>
<title>A tiered CRF tagger for Polish. In Bembenik et al. (Bembenik et al.,</title>
<date>2013</date>
<pages>215--230</pages>
<contexts>
<context position="24158" citStr="Radziszewski, 2013" startWordPosition="3889" endWordPosition="3890">rd form (lowercased), • tests for agreements and letter case as in (Radziszewski and Pawlaczek, 2012). 6 Evaluation The performed evaluation assumed training of the CRF on the whole development set annotated with the induced transformations and then applying the trained model to tag the evaluation part with transformations. Transformations were then applied and the obtained phrase lemmas were compared to the reference annotation. This procedure includes the influence of deficiencies of the morphological dictionary. The version of KPWr used here was tagged automatically using the WCRFT tagger (Radziszewski, 2013), hence tagging errors are also included. Degórski (2011) reports separate figures for the performance of the entire system (chunker + NP lemmatiser) on the whole test set and performance of the entire system limiting the test set only to those phrases that the system is able to chunk correctly (i.e., to output correct phrase boundaries). Such a choice is reasonable given that his system 706 is based on rules that intermingle chunking with lemmatisation. We cannot expect the system to lemmatise correctly those groups which it is unable to capture. Our approach assumes two-stage operation, wher</context>
</contexts>
<marker>Radziszewski, 2013</marker>
<rawString>Adam Radziszewski. 2013. A tiered CRF tagger for Polish. In Bembenik et al. (Bembenik et al., 2013), pages 215–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Learning algorithms for keyphrase extraction. Information Retrieval,</title>
<date>2000</date>
<pages>2--303</pages>
<contexts>
<context position="1407" citStr="Turney, 2000" startWordPosition="217" endWordPosition="218"> performed along POS tagging and is considered crucial for many NLP applications. Similar task may be defined for whole noun phrases (Degórski, 2011). By lemmatisation of noun phrases (NPs) we will understand assigning each NP a grammatically correct NP corresponding to the same phrase that could stand as a dictionary entry. The task of NP lemmatisation is rarely considered, although it carries great practical value. For instance, any keyword extraction system that works for a morphologically rich language must deal with lemmatisation of NPs. This is because keywords are often longer phrases (Turney, 2000), while the user would be confused to see inflected forms as system output. Similar situation happens when attempting at terminology extraction from domain corpora: it is usually assumed that domain terms are subclass of NPs (Marciniak and Mykowiecka, 2013). In (1) we give an example Polish noun phrase (‘the main city of the municipality’). Throughout the paper we assume the usage of the tagset of the National Corpus of Polish (Przepiórkowski, 2009), henceforth called NCP in short. The orthographic form (1a) appears in instrumental case, singular. Phrase lemma is given as (1b). Lemmatisation o</context>
</contexts>
<marker>Turney, 2000</marker>
<rawString>Peter Turney. 2000. Learning algorithms for keyphrase extraction. Information Retrieval, 2:303–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Woli´nski</author>
</authors>
<title>Morfeusz — a practical tool for the morphological analysis of Polish.</title>
<date>2006</date>
<booktitle>Proceedings of IIPWM’06,</booktitle>
<pages>511--520</pages>
<editor>In Mieczysław A. Kłopotek, Sławomir T. Wierzcho´n, and Krzysztof Trojanowski, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Ustro´n, Poland,</location>
<marker>Woli´nski, 2006</marker>
<rawString>Marcin Woli´nski. 2006. Morfeusz — a practical tool for the morphological analysis of Polish. In Mieczysław A. Kłopotek, Sławomir T. Wierzcho´n, and Krzysztof Trojanowski, editors, Proceedings of IIPWM’06, pages 511–520, Ustro´n, Poland, June 19–22. Springer-Verlag, Berlin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>