<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.227406">
<title confidence="0.9985595">
Museli: A Multi-Source Evidence Integration Approach to Topic Seg-
mentation of Spontaneous Dialogue
</title>
<author confidence="0.99505">
Jaime Arguello Carolyn Rosé
</author>
<affiliation confidence="0.995423">
Language Technologies Institute Language Technologies Institute
Carnegie Mellon University Carnegie Mellon University
</affiliation>
<address confidence="0.514526">
Pittsburgh, PA 15213 Pittsburgh, PA 15213
</address>
<email confidence="0.998421">
jarguell@andrew.cmu.edu cprose@cs.cmu.edu
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999686777777778">
We introduce a novel topic segmentation
approach that combines evidence of topic
shifts from lexical cohesion with linguistic
evidence such as syntactically distinct fea-
tures of segment initial contributions. Our
evaluation demonstrates that this hybrid
approach outperforms state-of-the-art algo-
rithms even when applied to loosely struc-
tured, spontaneous dialogue.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999910777777778">
Use of topic-based models of dialogue has
played a role in information retrieval (Oard et al.,
2004), information extraction (Baufaden, 2001),
and summarization (Zechner, 2001). However,
previous work on automatic topic segmentation has
focused primarily on segmentation of expository
text. We present Museli, a novel topic segmenta-
tion approach for dialogue that integrates evidence
of topic shifts from lexical cohesion with linguistic
indicators such as syntactically distinct features of
segment initial contributions.
Our evaluation demonstrates that approaches de-
signed for text do not generalize well to dialogue.
We demonstrate a significant advantage of Museli
over competing approaches. We then discuss why
models based entirely on lexical cohesion fail on
dialogue and how our algorithm compensates with
other topic shift indicators.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.998159209302326">
Existing topic segmentation approaches can be
loosely classified into two types: (1) lexical cohe-
sion models, and (2) content-oriented models. The
underlying assumption in lexical cohesion models
is that a shift in term distribution signals a shift in
topic (Halliday and Hassan, 1976). The best known
algorithm based on this idea is TextTiling (Hearst,
1997). In TextTiling, a sliding window is passed
over the vector-space representation of the text. At
each position, the cosine correlation between the
upper and lower region of the sliding window is
compared with that of the peak cosine correlation
values to the left and right of the window. A seg-
ment boundary is predicted when the magnitude of
the difference exceeds a threshold.
One drawback to relying on term co-occurrence
to signal topic continuity is that synonyms or re-
lated terms are treated as thematically-unrelated.
One solution to this problem is using a dimension-
ality reduction technique such as Latent Semantic
Analysis (LSA) (Landauer and Dumais, 1997).
Two such algorithms for segmentation are de-
scribed in (Foltz, 1998) and (Olney and Cai, 2005).
Both TextTiling and Foltz’s approach measure
coherence as a function of the repetition of the-
matically-related terms. TextTiling looks for co-
occurrences of terms or term-stems and Foltz uses
LSA to measure semantic relatedness between
terms. Olney and Cai’s orthonormal basis ap-
proach also uses LSA, but allows a richer represen-
tation of discourse coherence, which is that coher-
ence is a function of how much new information a
discourse unit (e.g. a dialogue contribution) adds
(informativity) and how relevant it is to the local
context (relevance) (Olney and Cai, 2005).
Content-oriented models, such as (Barzilay and
Lee, 2004), rely on the re-occurrence of patterns of
topics over multiple realizations of thematically
similar discourses, such as a series of newspaper
articles about similar events. Their approach util-
izes a hidden Markov model where states corre-
spond to topics, and state transition probabilities
correspond to topic shifts. To obtain the desired
</bodyText>
<page confidence="0.955214">
9
</page>
<note confidence="0.864742">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 9–12,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999963272727273">
number of topics (states), text spans of uniform
length (individual contributions, in our case) are
clustered. Then, state emission probabilities are
induced using smoothed cluster-specific language
models. Transition probabilities are induced by
considering the proportion of documents in which
a contribution assigned to the source cluster (state)
immediately precedes a contribution assigned to
the target cluster (state). Using an EM-like Viterbi
approach, each contribution is reassigned to the
state most likely to have generated it.
</bodyText>
<sectionHeader confidence="0.880781" genericHeader="method">
3 Overview of Museli Approach
</sectionHeader>
<bodyText confidence="0.999993">
We will demonstrate that lexical cohesion alone
does not adequately mark topic boundaries in dia-
logue. Nevertheless, it can provide one meaning-
ful source of evidence towards segmenting dia-
logue. In our hybrid Museli approach, we com-
bined lexical cohesion with features that have the
potential to capture something about the linguistic
style that marks shifts in topic: word-unigrams,
word-bigrams, and POS-bigrams for the current
and previous contributions; the inclusion of at least
one non-stopword term (contribution of content);
time difference between contributions; contribution
length; and the agent role of the previous and cur-
rent contribution.
We cast the segmentation problem as a binary
classification problem where each contribution is
classified as NEW_TOPIC if the contribution in-
troduces a new topic and SAME_TOPIC other-
wise. We found that using a Naïve Bayes classifier
(John &amp; Langley, 1995) with an attribute selection
wrapper using the chi-square test for ranking at-
tributes performed better than other state-of-the-art
machine learning algorithms, perhaps because of
the evidence integration oriented nature of the
problem. We conducted our evaluation using 10-
fold cross-validation, being careful not to include
instances from the same dialogue in both the train-
ing and test sets on any fold so that the results we
report would not be biased by idiosyncratic com-
municative patterns associated with individual
conversational participants picked up by the
trained model.
Using the complete set of features enumerated
above, we perform feature selection on the training
data for each fold of the cross-validation sepa-
rately, training a model with the top 1000 features,
and applying that trained model to the test data.
Examples of high ranking features confirm our
intuition that contributions that begin new topic
segments are syntactically marked. For example,
many typical selected word bigrams were indica-
tive of imperatives, such as lets-do, do-the, ok-lets,
ok-try, lets-see, etc. Others included time oriented
discourse markers such as now, then, next, etc.
To capitalize on differences in conversational
behavior between participants assigned to different
roles in the conversation (i.e., student and tutor in
our evaluation corpora), we learn separate models
for each role in the conversation1. This decision is
based on the observation that participants with dif-
ferent agent-roles introduce topics with a different
frequency, introduce different types of topics, and
may introduce topics in a different style that dis-
plays their status in the conversation. For instance,
a tutor may introduce new topics with a contribu-
tion that ends with an imperative. A student may
introduce new topics with a contribution that ends
with a wh-question.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999907375">
In this section we evaluate Museli in comparison
to the best performing state-of-the-art approaches,
demonstrating that our hybrid Museli approach
out-performs all of these approaches on two differ-
ent dialogue corpora by a statistically significant
margin (p &lt; .01), in one case reducing the prob-
ability of error as measured by Beeferman&apos;s Pk to
only 10% (Beeferman et al., 1999).
</bodyText>
<subsectionHeader confidence="0.954643">
4.1 Experimental Corpora
</subsectionHeader>
<bodyText confidence="0.9999905">
We used two different dialogue corpora for our
evaluation. The first corpus, which we refer to as the
Olney &amp; Cai corpus, is a set of dialogues selected ran-
domly from the same corpus Olney and Cai selected
their corpus from (Olney and Cai, 2005). The second
corpus is a locally collected corpus of thermodynamics
tutoring dialogues, which we refer to as the Thermo
corpus. This corpus is particularly appropriate for ad-
dressing the research question of how to automatically
segment dialogue for two reasons: First, the explora-
tory task that students and tutors engaged in together is
more loosely structured than many task oriented do-
mains typically investigated in the dialogue commu-
nity, such as flight reservation or meeting scheduling.
Second, because the tutor and student play asymmetric
roles in the interaction, this corpus allows us to explore
</bodyText>
<footnote confidence="0.88969">
1 Dissimilar agent-roles occur in other domains as well (e.g.
Travel Agent and Customer)
</footnote>
<page confidence="0.996633">
10
</page>
<bodyText confidence="0.9934151875">
how conversational role affects how speakers mark
topic shifts.
Table 1 presents statistics describing characteris-
tics of these two corpora. Similar to (Passonneau
and Litman, 1993), we adopt a flat model of topic-
segmentation for our gold standard based on dis-
course segment purpose, where a shift in topic cor-
responds to a shift in purpose that is acknowledged
and acted upon by both conversational agents. We
evaluated inter-coder reliability over 10% of the
Thermo corpus mentioned above. 3 annotators
were given a 10 page coding manual with explana-
tion of our informal definition of shared discourse
segment purpose as well as examples of segmented
dialogues. Pairwise inter-coder agreement was
above 0.7 kappa for all pairs of annotators.
</bodyText>
<table confidence="0.9956601">
Olney &amp; Cai Thermo
Corpus Corpus
# Dialogues 42 22
Contributions/ 195.40 217.90
Dialogue
Contributions/ 24.00 13.31
Topic
Topics/Dialogue 8.14 16.36
Words/ 28.63 5.12
Contribution
</table>
<tableCaption confidence="0.99962">
Table 1: Evaluation Corpora Statistics
</tableCaption>
<subsectionHeader confidence="0.96349">
4.2 Baseline Approaches
</subsectionHeader>
<bodyText confidence="0.999969382978723">
We evaluate Museli against the following algo-
rithms: (1) Olney and Cai (Ortho), (2) Barzilay and
Lee (B&amp;L), (3) TextTiling (TT), and (4) Foltz.
As opposed to the other baseline algorithms,
(Olney and Cai, 2005) applied their orthonormal
basis approach specifically to dialogue, and prior
to this work, report the highest numbers for topic
segmentation of dialogue. Barzilay and Lee’s ap-
proach is the state of the art in modeling topic
shifts in monologue text. Our application of B&amp;L
to dialogue attempts to harness any existing and
recognizable redundancy in topic-flow across our
dialogues for the purpose of topic segmentation.
We chose TextTiling for its seminal contribution
to monologue segmentation. TextTiling and Foltz
consider lexical cohesion as their only evidence of
topic shifts. Applying these approaches to dialogue
segmentation sheds light on how term distribution
in dialogue differs from that of expository mono-
logue text (e.g. news articles).
The Foltz and Ortho approaches require a
trained LSA space, which we prepared as de-
scribed in (Olney and Cai, 2005). Any parameter
tuning for approaches other than our hybrid ap-
proach was computed over the entire test set, giv-
ing competing algorithms the maximum advantage.
In addition to these approaches, we include
segmentation results from three degenerate ap-
proaches: (1) classifying all contributions as
NEW_TOPIC (ALL), (2) classifying no contribu-
tions as NEW_TOPIC (NONE), and (3) classifying
contributions as NEW_TOPIC at uniform intervals
(EVEN), corresponding to the average reference
topic length (see Table 1).
As a means for comparison, we adopt two evalua-
tion metrics: Pk and f-measure. An extensive argu-
ment of Pk’s robustness (if k is set to 1/2 the average
reference topic length) is present in (Beeferman, et al.
1999). Pk measures the probability of misclassifying
two contributions a distance of k contributions apart,
where the classification question is are the two con-
tributions part of the same topic segment or not?
Lower Pk values are preferred over higher ones. It
equally captures the effect of false-negatives and
false-positives and it favors near misses. F-measure
punishes false positives equally, regardless of the
distance to the reference boundary.
</bodyText>
<subsectionHeader confidence="0.929118">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.9614992">
Results for all approaches are displayed in Table
2. Note that lower values of Pk are preferred over
higher ones. The opposite is true of F-measure. In
both corpora, Museli performed significantly better
than all other approaches (p &lt; .01).
</bodyText>
<table confidence="0.9992683">
Olney &amp; Cai Corpus Thermo Corpus
Pk F Pk F
NONE 0.4897 -- 0.4900 --
ALL 0.5180 -- 0.5100 --
EVEN 0.5117 -- 0.5132 --
TT 0.6240 0.1475 0.5353 0.1614
B&amp;L 0.6351 0.1747 0.5086 0.1512
Foltz 0.3270 0.3492 0.5058 0.1180
Ortho 0.2754 0.6012 0.4898 0.2111
Museli 0.1051 0.8013 0.4043 0.3693
</table>
<tableCaption confidence="0.999663">
Table 2: Results on both corpora
</tableCaption>
<subsectionHeader confidence="0.978651">
4.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.998481142857143">
Results for all approaches are better on the Ol-
ney and Cai corpus than the Thermo corpus. The
Thermo corpus differs profoundly from the Olney
and Cai corpus in ways that very likely influenced
the performance. For instance, in the Thermo cor-
pus each dialogue contribution is an average of 5
words long, whereas in the Olney and Cai corpus
</bodyText>
<page confidence="0.998191">
11
</page>
<bodyText confidence="0.999976485714286">
each dialogue contribution contains an average of
28 words. Thus, the vector space representation of
the dialogue contributions is much more sparse in
the Thermo corpus, which makes shifts in lexical
coherence less reliable as topic shift indicators.
In terms of Pk, TextTiling (TT) performed worse
than the degenerate algorithms. TextTiling meas-
ures the term-overlap between adjacent regions in
the discourse. However, dialogue contributions are
often terse or even contentless. This produces
many islands of contribution-sequences for which
the local lexical cohesion is zero. TextTiling
wrongfully classifies all of these as starts of new
topics. A heuristic improvement to prevent
TextTiling from placing topic boundaries at every
point along a sequence of contributions failed to
produce a statistically significant improvement.
The Foltz and the orthonormal basis approaches
rely on LSA to provide strategic semantic gener-
alizations. Following (Olney and Cai, 2005), we
built our LSA space using dialogue contributions
as the atomic text unit. However, in corpora such
as the Thermo corpus, this may not be effective
because of the brevity of contributions.
Barzilay and Lee’s algorithm (B&amp;L) did not
generalize well to either dialogue corpus. One rea-
son could be that such probabilistic methods re-
quire that reference topics have significantly dif-
ferent language models, which was not true in ei-
ther of our evaluation corpora. We also noticed a
number of instances in the dialogue corpora where
participants referred to information from previous
topic segments, which consequently may have
blurred the distinction between the language mod-
els assigned to different topics.
</bodyText>
<sectionHeader confidence="0.995567" genericHeader="conclusions">
5 Current Directions
</sectionHeader>
<bodyText confidence="0.999276263157895">
In this paper we address the problem of auto-
matic topic segmentation of spontaneous dialogue.
We demonstrated with an empirical evaluation that
state-of-the-art approaches fail on spontaneous dia-
logue because word-distribution patterns alone are
insufficient evidence of topic shifts in dialogue.
We have presented a supervised learning algorithm
for topic segmentation of dialogue that combines
linguistic features signaling a contribution’s func-
tion with lexical cohesion. Our evaluation on two
distinct dialogue corpora shows a significant im-
provement over the state of the art approaches.
The disadvantage of our approach is that it re-
quires hand-labeled training data. We are currently
exploring ways of bootstrapping a model from a
small amount of hand labeled data in combination
with lexical cohesion (tuned for high precision and
consequently low recall) and some reliable dis-
course markers.
</bodyText>
<sectionHeader confidence="0.998647" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996768">
This work was funded by Office of Naval Re-
search, Cognitive and Neural Science Division,
grant number N00014-05-1-0043.
</bodyText>
<sectionHeader confidence="0.999313" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999908923076923">
Regina Barzilay and Lillian Lee (2004). Catching the
drift: Probabilistic Content Models, with Applications
to Generation and Summarization. In Proceedings of
HLT-NAACL 2004.
Doug Beeferman, Adam Berger, John D. Lafferty
(1999). Statistical Models for Text Segmentation.
Machine Learning 34 (1-3): 177-210.
Narjès Boufaden, Guy Lapalme, Yoshua Bengio (2001).
Topic Segmentation: A first stage to Dialog-based In-
formation Extraction. In Proceedings of NLPRS 2001.
P.W. Foltz, W. Kintsch, and Thomas Landauer (1998).
The measurement of textual cohesion with latent se-
mantic analysis. Discourse Processes, 25, 285-307.
M. A. K. Halliday and Ruqaiya Hasan (1976). Cohesion
in English. London: Longman.
Marti Hearst. 1997. TextTiling: Segmenting Text into
Multi-Paragragh Subtopic Passages. Computational
Linguistics, 23(1), 33 – 64.
George John &amp; Pat Langley (1995). Estimating Con-
tinuous Distributions in Bayesian Classifiers. In Pro-
ceedings of UAI 2005.
Thomas Landauer, &amp; Susan Dumais (1997). A Solution
to Plato’s Problem: The Latent Semantic Analysis of
Acquisition, Induction, and Representation of Knowl-
edge. Psychological Review, 104, 221-240.
Douglas Oard, Bhuvana Ramabhadran, and Samuel
Gustman (2004). Building an Information Retrieval
Test Collection for Spontaneous Conversational
Speech. In Proceedings of SIGIR 2004.
Andrew Olney and Zhiqiang Cai (2005). An Orthonor-
mal Basis for Topic Segmentation of Tutorial Dia-
logue. In Proceedings of HLT-EMNLP 2005.
Rebecca Passonneau and Diane Litman (1993). Inten-
tion-Based Segmentation: Human Reliability and
Correlation with Linguistic Cues. In Proceedings
ACL 2003.
Klaus Zechner (2001). Automatic Generation of Con-
cise Summaries of Spoken Dialogues in Unrestricted
Domains. In Proceedings of SIGIR 2001.
</reference>
<page confidence="0.998462">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.919213">
<title confidence="0.997035">A Multi-Source Evidence Integration Approach to Topic mentation of Spontaneous Dialogue</title>
<author confidence="0.985995">Arguello Rosé</author>
<affiliation confidence="0.9968135">Language Technologies Institute Language Technologies Institute Carnegie Mellon University Carnegie Mellon University</affiliation>
<address confidence="0.999857">Pittsburgh, PA 15213 Pittsburgh, PA 15213</address>
<email confidence="0.99782">jarguell@andrew.cmu.educprose@cs.cmu.edu</email>
<abstract confidence="0.9940721">We introduce a novel topic segmentation approach that combines evidence of topic shifts from lexical cohesion with linguistic evidence such as syntactically distinct features of segment initial contributions. Our evaluation demonstrates that this hybrid approach outperforms state-of-the-art algorithms even when applied to loosely structured, spontaneous dialogue.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic Content Models, with Applications to Generation and Summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<contexts>
<context position="3332" citStr="Barzilay and Lee, 2004" startWordPosition="485" endWordPosition="488">xtTiling and Foltz’s approach measure coherence as a function of the repetition of thematically-related terms. TextTiling looks for cooccurrences of terms or term-stems and Foltz uses LSA to measure semantic relatedness between terms. Olney and Cai’s orthonormal basis approach also uses LSA, but allows a richer representation of discourse coherence, which is that coherence is a function of how much new information a discourse unit (e.g. a dialogue contribution) adds (informativity) and how relevant it is to the local context (relevance) (Olney and Cai, 2005). Content-oriented models, such as (Barzilay and Lee, 2004), rely on the re-occurrence of patterns of topics over multiple realizations of thematically similar discourses, such as a series of newspaper articles about similar events. Their approach utilizes a hidden Markov model where states correspond to topics, and state transition probabilities correspond to topic shifts. To obtain the desired 9 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 9–12, New York, June 2006. c�2006 Association for Computational Linguistics number of topics (states), text spans of uniform length (individual contributi</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee (2004). Catching the drift: Probabilistic Content Models, with Applications to Generation and Summarization. In Proceedings of HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John D Lafferty</author>
</authors>
<title>Statistical Models for Text Segmentation.</title>
<date>1999</date>
<journal>Machine Learning</journal>
<volume>34</volume>
<pages>1--3</pages>
<contexts>
<context position="7586" citStr="Beeferman et al., 1999" startWordPosition="1125" endWordPosition="1128"> that displays their status in the conversation. For instance, a tutor may introduce new topics with a contribution that ends with an imperative. A student may introduce new topics with a contribution that ends with a wh-question. 4 Evaluation In this section we evaluate Museli in comparison to the best performing state-of-the-art approaches, demonstrating that our hybrid Museli approach out-performs all of these approaches on two different dialogue corpora by a statistically significant margin (p &lt; .01), in one case reducing the probability of error as measured by Beeferman&apos;s Pk to only 10% (Beeferman et al., 1999). 4.1 Experimental Corpora We used two different dialogue corpora for our evaluation. The first corpus, which we refer to as the Olney &amp; Cai corpus, is a set of dialogues selected randomly from the same corpus Olney and Cai selected their corpus from (Olney and Cai, 2005). The second corpus is a locally collected corpus of thermodynamics tutoring dialogues, which we refer to as the Thermo corpus. This corpus is particularly appropriate for addressing the research question of how to automatically segment dialogue for two reasons: First, the exploratory task that students and tutors engaged in t</context>
<context position="11345" citStr="Beeferman, et al. 1999" startWordPosition="1715" endWordPosition="1718">est set, giving competing algorithms the maximum advantage. In addition to these approaches, we include segmentation results from three degenerate approaches: (1) classifying all contributions as NEW_TOPIC (ALL), (2) classifying no contributions as NEW_TOPIC (NONE), and (3) classifying contributions as NEW_TOPIC at uniform intervals (EVEN), corresponding to the average reference topic length (see Table 1). As a means for comparison, we adopt two evaluation metrics: Pk and f-measure. An extensive argument of Pk’s robustness (if k is set to 1/2 the average reference topic length) is present in (Beeferman, et al. 1999). Pk measures the probability of misclassifying two contributions a distance of k contributions apart, where the classification question is are the two contributions part of the same topic segment or not? Lower Pk values are preferred over higher ones. It equally captures the effect of false-negatives and false-positives and it favors near misses. F-measure punishes false positives equally, regardless of the distance to the reference boundary. 4.3 Results Results for all approaches are displayed in Table 2. Note that lower values of Pk are preferred over higher ones. The opposite is true of F-</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Doug Beeferman, Adam Berger, John D. Lafferty (1999). Statistical Models for Text Segmentation. Machine Learning 34 (1-3): 177-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Narjès Boufaden</author>
<author>Guy Lapalme</author>
</authors>
<title>Yoshua Bengio</title>
<date>2001</date>
<booktitle>In Proceedings of NLPRS</booktitle>
<marker>Boufaden, Lapalme, 2001</marker>
<rawString>Narjès Boufaden, Guy Lapalme, Yoshua Bengio (2001). Topic Segmentation: A first stage to Dialog-based Information Extraction. In Proceedings of NLPRS 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Foltz</author>
<author>W Kintsch</author>
<author>Thomas Landauer</author>
</authors>
<title>The measurement of textual cohesion with latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>285--307</pages>
<marker>Foltz, Kintsch, Landauer, 1998</marker>
<rawString>P.W. Foltz, W. Kintsch, and Thomas Landauer (1998). The measurement of textual cohesion with latent semantic analysis. Discourse Processes, 25, 285-307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K</author>
</authors>
<title>Halliday and Ruqaiya Hasan</title>
<date>1976</date>
<booktitle>Cohesion in English.</booktitle>
<publisher>Longman.</publisher>
<location>London:</location>
<marker>K, 1976</marker>
<rawString>M. A. K. Halliday and Ruqaiya Hasan (1976). Cohesion in English. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>TextTiling: Segmenting Text into Multi-Paragragh Subtopic Passages.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<pages>33--64</pages>
<contexts>
<context position="1939" citStr="Hearst, 1997" startWordPosition="265" endWordPosition="266"> to dialogue. We demonstrate a significant advantage of Museli over competing approaches. We then discuss why models based entirely on lexical cohesion fail on dialogue and how our algorithm compensates with other topic shift indicators. 2 Previous Work Existing topic segmentation approaches can be loosely classified into two types: (1) lexical cohesion models, and (2) content-oriented models. The underlying assumption in lexical cohesion models is that a shift in term distribution signals a shift in topic (Halliday and Hassan, 1976). The best known algorithm based on this idea is TextTiling (Hearst, 1997). In TextTiling, a sliding window is passed over the vector-space representation of the text. At each position, the cosine correlation between the upper and lower region of the sliding window is compared with that of the peak cosine correlation values to the left and right of the window. A segment boundary is predicted when the magnitude of the difference exceeds a threshold. One drawback to relying on term co-occurrence to signal topic continuity is that synonyms or related terms are treated as thematically-unrelated. One solution to this problem is using a dimensionality reduction technique </context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Marti Hearst. 1997. TextTiling: Segmenting Text into Multi-Paragragh Subtopic Passages. Computational Linguistics, 23(1), 33 – 64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George John</author>
<author>Pat Langley</author>
</authors>
<title>Estimating Continuous Distributions in Bayesian Classifiers.</title>
<date>1995</date>
<booktitle>In Proceedings of UAI</booktitle>
<contexts>
<context position="5333" citStr="John &amp; Langley, 1995" startWordPosition="780" endWordPosition="783">tial to capture something about the linguistic style that marks shifts in topic: word-unigrams, word-bigrams, and POS-bigrams for the current and previous contributions; the inclusion of at least one non-stopword term (contribution of content); time difference between contributions; contribution length; and the agent role of the previous and current contribution. We cast the segmentation problem as a binary classification problem where each contribution is classified as NEW_TOPIC if the contribution introduces a new topic and SAME_TOPIC otherwise. We found that using a Naïve Bayes classifier (John &amp; Langley, 1995) with an attribute selection wrapper using the chi-square test for ranking attributes performed better than other state-of-the-art machine learning algorithms, perhaps because of the evidence integration oriented nature of the problem. We conducted our evaluation using 10- fold cross-validation, being careful not to include instances from the same dialogue in both the training and test sets on any fold so that the results we report would not be biased by idiosyncratic communicative patterns associated with individual conversational participants picked up by the trained model. Using the complet</context>
</contexts>
<marker>John, Langley, 1995</marker>
<rawString>George John &amp; Pat Langley (1995). Estimating Continuous Distributions in Bayesian Classifiers. In Proceedings of UAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>Susan Dumais</author>
</authors>
<title>A Solution to Plato’s Problem: The Latent Semantic Analysis of Acquisition, Induction, and Representation of Knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<pages>221--240</pages>
<contexts>
<context position="2605" citStr="Landauer and Dumais, 1997" startWordPosition="370" endWordPosition="373">sed over the vector-space representation of the text. At each position, the cosine correlation between the upper and lower region of the sliding window is compared with that of the peak cosine correlation values to the left and right of the window. A segment boundary is predicted when the magnitude of the difference exceeds a threshold. One drawback to relying on term co-occurrence to signal topic continuity is that synonyms or related terms are treated as thematically-unrelated. One solution to this problem is using a dimensionality reduction technique such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997). Two such algorithms for segmentation are described in (Foltz, 1998) and (Olney and Cai, 2005). Both TextTiling and Foltz’s approach measure coherence as a function of the repetition of thematically-related terms. TextTiling looks for cooccurrences of terms or term-stems and Foltz uses LSA to measure semantic relatedness between terms. Olney and Cai’s orthonormal basis approach also uses LSA, but allows a richer representation of discourse coherence, which is that coherence is a function of how much new information a discourse unit (e.g. a dialogue contribution) adds (informativity) and how r</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas Landauer, &amp; Susan Dumais (1997). A Solution to Plato’s Problem: The Latent Semantic Analysis of Acquisition, Induction, and Representation of Knowledge. Psychological Review, 104, 221-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Oard</author>
<author>Bhuvana Ramabhadran</author>
<author>Samuel Gustman</author>
</authors>
<title>Building an Information Retrieval Test Collection for Spontaneous Conversational Speech.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGIR</booktitle>
<contexts>
<context position="819" citStr="Oard et al., 2004" startWordPosition="102" endWordPosition="105">ellon University Carnegie Mellon University Pittsburgh, PA 15213 Pittsburgh, PA 15213 jarguell@andrew.cmu.edu cprose@cs.cmu.edu Abstract We introduce a novel topic segmentation approach that combines evidence of topic shifts from lexical cohesion with linguistic evidence such as syntactically distinct features of segment initial contributions. Our evaluation demonstrates that this hybrid approach outperforms state-of-the-art algorithms even when applied to loosely structured, spontaneous dialogue. 1 Introduction Use of topic-based models of dialogue has played a role in information retrieval (Oard et al., 2004), information extraction (Baufaden, 2001), and summarization (Zechner, 2001). However, previous work on automatic topic segmentation has focused primarily on segmentation of expository text. We present Museli, a novel topic segmentation approach for dialogue that integrates evidence of topic shifts from lexical cohesion with linguistic indicators such as syntactically distinct features of segment initial contributions. Our evaluation demonstrates that approaches designed for text do not generalize well to dialogue. We demonstrate a significant advantage of Museli over competing approaches. We </context>
</contexts>
<marker>Oard, Ramabhadran, Gustman, 2004</marker>
<rawString>Douglas Oard, Bhuvana Ramabhadran, and Samuel Gustman (2004). Building an Information Retrieval Test Collection for Spontaneous Conversational Speech. In Proceedings of SIGIR 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Olney</author>
<author>Zhiqiang Cai</author>
</authors>
<title>An Orthonormal Basis for Topic Segmentation of Tutorial Dialogue.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP</booktitle>
<contexts>
<context position="2700" citStr="Olney and Cai, 2005" startWordPosition="386" endWordPosition="389">n the upper and lower region of the sliding window is compared with that of the peak cosine correlation values to the left and right of the window. A segment boundary is predicted when the magnitude of the difference exceeds a threshold. One drawback to relying on term co-occurrence to signal topic continuity is that synonyms or related terms are treated as thematically-unrelated. One solution to this problem is using a dimensionality reduction technique such as Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997). Two such algorithms for segmentation are described in (Foltz, 1998) and (Olney and Cai, 2005). Both TextTiling and Foltz’s approach measure coherence as a function of the repetition of thematically-related terms. TextTiling looks for cooccurrences of terms or term-stems and Foltz uses LSA to measure semantic relatedness between terms. Olney and Cai’s orthonormal basis approach also uses LSA, but allows a richer representation of discourse coherence, which is that coherence is a function of how much new information a discourse unit (e.g. a dialogue contribution) adds (informativity) and how relevant it is to the local context (relevance) (Olney and Cai, 2005). Content-oriented models, </context>
<context position="7858" citStr="Olney and Cai, 2005" startWordPosition="1173" endWordPosition="1176">eli in comparison to the best performing state-of-the-art approaches, demonstrating that our hybrid Museli approach out-performs all of these approaches on two different dialogue corpora by a statistically significant margin (p &lt; .01), in one case reducing the probability of error as measured by Beeferman&apos;s Pk to only 10% (Beeferman et al., 1999). 4.1 Experimental Corpora We used two different dialogue corpora for our evaluation. The first corpus, which we refer to as the Olney &amp; Cai corpus, is a set of dialogues selected randomly from the same corpus Olney and Cai selected their corpus from (Olney and Cai, 2005). The second corpus is a locally collected corpus of thermodynamics tutoring dialogues, which we refer to as the Thermo corpus. This corpus is particularly appropriate for addressing the research question of how to automatically segment dialogue for two reasons: First, the exploratory task that students and tutors engaged in together is more loosely structured than many task oriented domains typically investigated in the dialogue community, such as flight reservation or meeting scheduling. Second, because the tutor and student play asymmetric roles in the interaction, this corpus allows us to </context>
<context position="9755" citStr="Olney and Cai, 2005" startWordPosition="1468" endWordPosition="1471">nition of shared discourse segment purpose as well as examples of segmented dialogues. Pairwise inter-coder agreement was above 0.7 kappa for all pairs of annotators. Olney &amp; Cai Thermo Corpus Corpus # Dialogues 42 22 Contributions/ 195.40 217.90 Dialogue Contributions/ 24.00 13.31 Topic Topics/Dialogue 8.14 16.36 Words/ 28.63 5.12 Contribution Table 1: Evaluation Corpora Statistics 4.2 Baseline Approaches We evaluate Museli against the following algorithms: (1) Olney and Cai (Ortho), (2) Barzilay and Lee (B&amp;L), (3) TextTiling (TT), and (4) Foltz. As opposed to the other baseline algorithms, (Olney and Cai, 2005) applied their orthonormal basis approach specifically to dialogue, and prior to this work, report the highest numbers for topic segmentation of dialogue. Barzilay and Lee’s approach is the state of the art in modeling topic shifts in monologue text. Our application of B&amp;L to dialogue attempts to harness any existing and recognizable redundancy in topic-flow across our dialogues for the purpose of topic segmentation. We chose TextTiling for its seminal contribution to monologue segmentation. TextTiling and Foltz consider lexical cohesion as their only evidence of topic shifts. Applying these a</context>
<context position="13694" citStr="Olney and Cai, 2005" startWordPosition="2085" endWordPosition="2088">the term-overlap between adjacent regions in the discourse. However, dialogue contributions are often terse or even contentless. This produces many islands of contribution-sequences for which the local lexical cohesion is zero. TextTiling wrongfully classifies all of these as starts of new topics. A heuristic improvement to prevent TextTiling from placing topic boundaries at every point along a sequence of contributions failed to produce a statistically significant improvement. The Foltz and the orthonormal basis approaches rely on LSA to provide strategic semantic generalizations. Following (Olney and Cai, 2005), we built our LSA space using dialogue contributions as the atomic text unit. However, in corpora such as the Thermo corpus, this may not be effective because of the brevity of contributions. Barzilay and Lee’s algorithm (B&amp;L) did not generalize well to either dialogue corpus. One reason could be that such probabilistic methods require that reference topics have significantly different language models, which was not true in either of our evaluation corpora. We also noticed a number of instances in the dialogue corpora where participants referred to information from previous topic segments, wh</context>
</contexts>
<marker>Olney, Cai, 2005</marker>
<rawString>Andrew Olney and Zhiqiang Cai (2005). An Orthonormal Basis for Topic Segmentation of Tutorial Dialogue. In Proceedings of HLT-EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Passonneau</author>
<author>Diane Litman</author>
</authors>
<title>Intention-Based Segmentation: Human Reliability and Correlation with Linguistic Cues.</title>
<date>1993</date>
<booktitle>In Proceedings ACL</booktitle>
<contexts>
<context position="8739" citStr="Passonneau and Litman, 1993" startWordPosition="1308" endWordPosition="1311"> reasons: First, the exploratory task that students and tutors engaged in together is more loosely structured than many task oriented domains typically investigated in the dialogue community, such as flight reservation or meeting scheduling. Second, because the tutor and student play asymmetric roles in the interaction, this corpus allows us to explore 1 Dissimilar agent-roles occur in other domains as well (e.g. Travel Agent and Customer) 10 how conversational role affects how speakers mark topic shifts. Table 1 presents statistics describing characteristics of these two corpora. Similar to (Passonneau and Litman, 1993), we adopt a flat model of topicsegmentation for our gold standard based on discourse segment purpose, where a shift in topic corresponds to a shift in purpose that is acknowledged and acted upon by both conversational agents. We evaluated inter-coder reliability over 10% of the Thermo corpus mentioned above. 3 annotators were given a 10 page coding manual with explanation of our informal definition of shared discourse segment purpose as well as examples of segmented dialogues. Pairwise inter-coder agreement was above 0.7 kappa for all pairs of annotators. Olney &amp; Cai Thermo Corpus Corpus # Di</context>
</contexts>
<marker>Passonneau, Litman, 1993</marker>
<rawString>Rebecca Passonneau and Diane Litman (1993). Intention-Based Segmentation: Human Reliability and Correlation with Linguistic Cues. In Proceedings ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Zechner</author>
</authors>
<title>Automatic Generation of Concise Summaries of Spoken Dialogues in Unrestricted Domains.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR</booktitle>
<contexts>
<context position="895" citStr="Zechner, 2001" startWordPosition="112" endWordPosition="113">15213 jarguell@andrew.cmu.edu cprose@cs.cmu.edu Abstract We introduce a novel topic segmentation approach that combines evidence of topic shifts from lexical cohesion with linguistic evidence such as syntactically distinct features of segment initial contributions. Our evaluation demonstrates that this hybrid approach outperforms state-of-the-art algorithms even when applied to loosely structured, spontaneous dialogue. 1 Introduction Use of topic-based models of dialogue has played a role in information retrieval (Oard et al., 2004), information extraction (Baufaden, 2001), and summarization (Zechner, 2001). However, previous work on automatic topic segmentation has focused primarily on segmentation of expository text. We present Museli, a novel topic segmentation approach for dialogue that integrates evidence of topic shifts from lexical cohesion with linguistic indicators such as syntactically distinct features of segment initial contributions. Our evaluation demonstrates that approaches designed for text do not generalize well to dialogue. We demonstrate a significant advantage of Museli over competing approaches. We then discuss why models based entirely on lexical cohesion fail on dialogue </context>
</contexts>
<marker>Zechner, 2001</marker>
<rawString>Klaus Zechner (2001). Automatic Generation of Concise Summaries of Spoken Dialogues in Unrestricted Domains. In Proceedings of SIGIR 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>