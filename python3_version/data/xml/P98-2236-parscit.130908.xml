<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000734">
<title confidence="0.997895">
Automatic Construction of Frame Representations
for Spontaneous Speech in Unrestricted Domains
</title>
<author confidence="0.994271">
Klaus Zechner
</author>
<affiliation confidence="0.985934">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.705363">
5000 Forbes Avenue
Pittsburgh, PA 15213, USA
</address>
<email confidence="0.9663">
zechnerOcs.cmu.edu
</email>
<sectionHeader confidence="0.991835" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999850066666667">
This paper presents a system which automatically
generates shallow semantic frame structures for con-
versational speech in unrestricted domains.
We argue that such shallow semantic representations
can indeed be generated with a minimum amount of
linguistic knowledge engineering and without having
to explicitly construct a semantic knowledge base.
The system is designed to be robust to deal with the
problems of speech dysfluencies, ungrammaticalities,
and imperfect speech recognition.
Initial results on speech transcripts are promising
in that correct mappings could be identified in 21%
of the clauses of a test set (resp. 44% of this test
set where ungrammatical or verb-less clauses were
removed).
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999915333333333">
In syntactic and semantic analysis of spontaneous
speech, little research has been done with regard
to dealing with language in unrestricted domains.
There are several reasons why so far an in-depth
analysis of this type of language data has been con-
sidered prohibitively hard:
</bodyText>
<listItem confidence="0.951372181818182">
• inherent properties of spontaneous speech, such
as dysfluencies and ungrammaticalities (Lavie,
1996)
• word accuracy being far from perfect (e.g., on a
typical corpus such as SWITCHBOARD (SWBD)
(Godfrey et al., 1992), current state-of-the-art
recognizers have word error rates in the range
of 30-40% (Finke et al., 1997))
• if the domain is unrestricted, manual construc-
tion of a semantic knowledge base with reason-
able coverage is very labor intensive
</listItem>
<bodyText confidence="0.999310153846154">
In this paper we propose to combine methods of
partial parsing (&amp;quot;chunking&amp;quot;) with the mapping of
the verb arguments onto subcategorization frames
that can be extracted automatically, in this case,
from WordNet (Miller et al., 1993). As prelimi-
nary results indicate, this yields a way of generating
shallow semantic representations efficiently and with
minimal manual effort.
Eventually, these semantic structures can serve as
(additional) input to a variety of different tasks in
NLP, such as text or dialogue summarization, in-
formation gisting, information retrieval, or shallow
machine translation.
</bodyText>
<sectionHeader confidence="0.914126" genericHeader="introduction">
2 Shallow Semantic Structures
</sectionHeader>
<bodyText confidence="0.9442985">
The two main representations we are building on are
the following:
</bodyText>
<listItem confidence="0.9965318">
• chunks: these correspond mostly to basic (i.e.,
non-attached) phrasal constituents
• frames: these are built from the parsed chunks
according to subcategorization constraints ex-
tracted from the WordNet lexicon
</listItem>
<bodyText confidence="0.999943555555556">
The chunks are defined in a similar way as in (Ab-
ney, 1996), namely as &amp;quot;non-recursive phrasal units&amp;quot;;
they roughly correspond to the standard linguistic
notion of constituents, except that there are no at-
tachments made (e.g., a PP to a NP) and that a ver-
bal chunk does not include any of its arguments but
just consists of the verbal complex (auxiliary/main
verb), including possibly inserted adverbs and/or
negation particles.
All frames are being generated on the basis of
&amp;quot;short clauses&amp;quot; which we define as minimal clausal
units that contain at least one subject and an in-
flected verbal form.&apos; 2
To produce the list of all possible subcategoriza-
tion frames, we first extracted all verbal tokens from
the tagged SWITCHBOARD corpus and then retrieved
the frames from WordNet. Table 1 provides a sum-
mary of this pre-calculation.
</bodyText>
<footnote confidence="0.998207857142857">
1This means in effect that relative clauses will get mapped
separately. They will, however, have to be &amp;quot;linked&amp;quot; to the
phrase they modify.
2We are also considering to take even shorter units as basis
for the mapping that would, e.g., include non-inflected clausal
complements. The most convenient solution has yet to be
determined.
</footnote>
<page confidence="0.973572">
1448
</page>
<table confidence="0.9996025">
Verbal tokens 4428
Different lemmata 2464
Senses in all lemmata 8523
Avg. senses per lemma 3.46
Total number of frames 15467
Avg. frames per sense 1.81
</table>
<tableCaption confidence="0.987933">
Table 1: WordNet: verbal lemmata, senses,
and frames
</tableCaption>
<sectionHeader confidence="0.984412" genericHeader="method">
3 Resources and System
Components
</sectionHeader>
<bodyText confidence="0.998882">
We use the following resources to build our system:
</bodyText>
<listItem confidence="0.977062458333333">
• the SWITCHBOARD (SWBD) corpus (Godfrey
et al., 1992) for speech data, transcripts, and
annotations at various levels (e.g., for segment
boundaries or parts of speech)
• the JANUS speech recognizer (Waibel et al.,
1996) to provide us with input hypotheses
• a part of speech (POS) tagger, derived from
(Brill, 1994), adapted to and retrained for the
SWITCHBOARD corpus
• a preprocessing pipe which cleans up speech
dysfluencies (e.g., repetitions, hesitations) and
contains a segmentation module to split .the
speech recognizer turns into short clauses
• a chart parser (Ward, 1991) with a POS based
grammar to generate the chunks3 (phrasal con-
stituents)
• WordNet 1.5 (Miller et al., 1993) for the extrac-
tion of subcategorization (subcat) frames for all
senses of a verb (including semantic features,
such as &amp;quot;animacy&amp;quot;)
• a mapper which tries to find the &amp;quot;best match&amp;quot;
between the chunks found within a short clause
and the subcat frames for the main verb in that
clause
</listItem>
<bodyText confidence="0.999529222222222">
The major blocks of the system architecture are
depicted in Figure 1.
We want to stress here that except for the devel-
opment of the small POS grammar and the frame-
mapper, the other components and resources were
already present or quite simple to implement. There
has also been significant work on (semi-)automatic
induction of subcategorization frames (Manning,
1993; Briscoe and Carroll, 1997), such that even
</bodyText>
<footnote confidence="0.396185">
3More details about the chunk parser can be found in
(Zechner, 1997).
</footnote>
<figure confidence="0.945617444444445">
input Iterance
speech recognizer
hypothesis
POS tagger
preprocessing pipe
chunk parser
chunk sequence
semantic mapper
frame representation
</figure>
<figureCaption confidence="0.999991">
Figure 1: Global system architecture
</figureCaption>
<bodyText confidence="0.999923666666667">
without the important knowledge source from Word-
Net, a similar system could be built for other lan-
guages as well. Also, the Euro-WordNet project
(Vossen et al., 1997) is currently underway in build-
ing WordNet resources for other European lan-
guages.
</bodyText>
<sectionHeader confidence="0.985799" genericHeader="method">
4 Preliminary Experiments
</sectionHeader>
<bodyText confidence="0.999990384615385">
We performed some initial experiments using the
SWBD transcripts as input to the system. These
were POS tagged, preprocessed, segmented into
short clauses, parsed in chunks using a POS
based grammar, and finally, for each short clause,
the frame-mapper matched all potential arguments
of the verb against all possible subcategorization
frames listed in the lemmata file we had precom-
puted from WordNet (see section 2).
In total we had over 600000 short clauses, con-
taining approximately 1.7 million chunks. Only 18
different chunk patterns accounted for about half
of these short clauses. Table 2 shows these chunk
</bodyText>
<page confidence="0.947058">
1449
</page>
<table confidence="0.99978545">
main verb frequency chunk sequence
present?
no 83353 — (noises/hesit.)
no 36731 aff
no 33182 conj
yes 29749 np vb
yes 19176 np vb np
no 13834 np
no 13623 conj np
yes 12220 conj np vb
yes 11038 conj np vb np
yes 7649 np vb adjp
yes 7092 np vb pp
yes 5552 np vbneg
no 5044 advp
yes 4926 np vb np pp
no 4079 pp
yes 3999 conj np vb pp
yes 3998 conj np vb adjp
yes 3996 np vb advp
</table>
<tableCaption confidence="0.985272">
Table 2: Most frequent chunk sequences in
short clauses
</tableCaption>
<bodyText confidence="0.962529840909091">
patterns and their frequencies.4 Most of these con-
tain main verbs and hence can be sensibly used
in a mapping procedure but some of them (e.g.,
aff, , conj, advp) do not. These are typically back-
channellings, adverbial comments, and colloquial
forms (e.g., &amp;quot;yeah&amp;quot;, &amp;quot;and...&amp;quot;, &amp;quot;oh really&amp;quot;). They can
be easily dealt with a preprocessing module that as-
signs them to one of these categories and does not
send them to the mapper.
Another interesting observation we make here is
that within these most common chunk patterns,
there is only one pattern (np vb np pp) which could
lead to a potential PP-attachment ambiguity. We
conjecture that this is most probably due to the na-
ture of conversational speech which, unlike for writ-
ten (and more formal) language, does not make too
frequent use of complex noun phrases that have one
or multiple prepositional phrases attached to them.
We selected 98 short clauses randomly from the
output to perform a first error analysis.
The results are summarized in Table 3. In over
21% of the clauses, the mapper finds at least one
mapping that is correct. Another 23.5% of the
clauses do not contain any chunks that are worth
to be mapped in the first place (noises, hesitations),
4 Chunk abbreviations: conj=conjunction, aff=affirmative,
np=noun phrase, vb=verbal chunk, vbneg=negated ver-
bal chunk, adjp=adjectival phrase, advp=adverbial phrase,
pp=prepositional phrase.
so these could be filtered out and dealt with entirely
before the mapping process takes place, as we men-
tioned earlier. 28.6% of the clauses are in some sense
incomplete, mostly they are lacking a main verb
which is the crucial element to get the mapping pro-
cedure started. We regard these as &amp;quot;hard&amp;quot; residues,
including well-known linguistic problems such as el-
lipsis, in addition to some spoken language ungram-
maticalities. The last two categories (26.6% com-
bined) in the table are due to the incompleteness and
inaccuracies of the system components themselves.
To illustrate the process of mapping, we shall
present an example here, starting from the
POS-tagged utterance up to the semantic frame
representation:5 6
</bodyText>
<figure confidence="0.690575785714286">
short clause, annotated with POS:
i/PRP will/AUX talk/VB
to/PREP you/PRPA again/RB
LEMMA/token (of main verb):
talk/talk
parsed chunks:
-np-vb-pp-advp
parsed sequence to map:
-NP-VBZ-PP
WordNet frames:
:1 -INAN -VBZ:1 -ANIM -VBZ:1-INAN-IS -VBG-PP
:1 -ANIM -VBZ -PP:1 -ANIM -VBZ -TO -ANIM
:2 -ANIM -VBZ:2 -ANIM -VBZ -PP
:3 -ANIM -VBZ:3 -ANIM -VBZ -INAN
</figure>
<sectionHeader confidence="0.5961975" genericHeader="method">
:4 -ANIM -VBZ
:6 -ANIM -VBZ
:6 -ANIM -VBZ:6 -INAN -VBZ -TO -AND!
:6 -ANIM -VBZ-ON -INAN
</sectionHeader>
<tableCaption confidence="0.8818355625">
Potential mappings (found by mapper):
map. 1: 1-NP-VBZ (1-INAN-VBZ)
map. 2: 1-NP-VBZ (1-ANIM-VBZ)
map. 3: 1-NP-VBZ-PP (1-ANIM-VBZ-PP)
map. 4: 1-NP-VBZ-PP (1-ANIM-VBZ-TO-ANIM)
(...)
Frame representation (for mapping 4):
[agent/an] (i/PRP)
5POS abbreviations: PRP=personal pro-
noun, AUX=auxiliary verb, VB=main verb (non-inflected),
PREP=preposition, PRPA=personal pronoun in accusative,
RB=adverb.
6Frame abbreviations:
INAN=inanimate NP, ANIM=animate NP, VBZ=inflected
main verb, IS=is, VBG=gerund, PP=prepositional phrase,
TO=to (prep.), ON=on (prep.).
</tableCaption>
<page confidence="0.774282">
1450
</page>
<table confidence="0.973579">
classification occ. (%) Comment
correct 21 (21.4%) at least one reasonable mapping is found
non-mappable 23 (23.5%) clause consists of noises/hesitations only
ungrammatical 28 (28.6%) e.g., incomplete phrase, no verb
preprocessing 13 (13.3%) problem is caused by errors in POS tagger/segmenter/parser
mapper 13 (13.3%) problem due to incompleteness of mapper
</table>
<tableCaption confidence="0.999763">
Table 3: Summary of classification results for mapper output
</tableCaption>
<figure confidence="0.8958674">
[pred] ( [vb_t ([aux) (will/AUX)
[head] (talk/VB))
[pp_obj] ([prep) (to/PREP)
[theme/an] (you/PRPA)))
Dliodin (again/RB)
</figure>
<bodyText confidence="0.992343545454546">
Since chunks like advp or conj are not part of the
WordNet frames, we remove these from the parsed
chunk sequence, before a mapping attempt is being
made.7
In our example, WordNet yields 14 frames for 6
senses of the main verb talk. The mapper already
finds a &amp;quot;perfect match&amp;quot;&apos; for the first, i.e., the most
frequent sense of the verb (mapping 4 can be es-
timated to be more accurate than mapping 3 since
also the preposition matches to the input string).
This will be also the default sense to choose, unless
there is a word sense disambiguating module avail-
able that strongly favors a less frequent sense.
Since WordNet 1.5 does not provide detailed
semantic frame information but only general
subcategorization with extensions such as &amp;quot;ani-
mate/inanimate&amp;quot;, we plan to extend this infor-
mation by processing machine-readable dictionaries
which provide a richer set of semantic role informa-
tion of verbal heads.1°
It is interesting to see that even at this early stage
of our project the results of this shallow analysis are
quite encouraging. If we remove those clauses from
the test set which either should not or cannot be
mapped in the first place (because they are either
not containing any structure (&amp;quot;non-mappable&amp;quot;) or
are ungrammatical), the remainder of 47 clauses al-
ready has a success-rate of 44.7%. Improvements of
the system components before the mapping stage as
well as to the mapper itself will further increase the
mapping performance.
These chunks can be easily added to the mapper&apos;s output
again, as shown in the example.
</bodyText>
<footnote confidence="0.801312833333333">
8 Partial matches, such as mappings 1 and 2 in this exam-
ple, are allowed but disfavored to perfect matches.
91n WordNet 1.5, the first sense is also supposed to be the
most frequent one.
10The &amp;quot;agent&amp;quot; and &amp;quot;theme&amp;quot; assignments are currently just
defaults for these types of subcat frames.
</footnote>
<sectionHeader confidence="0.996121" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999990952380952">
It is obvious from our evaluation, that most core
components, specifically the mapper need to be im-
proved and refined. As for the mapper, there are
issues of constituent coordination, split verbs, infini-
tival complements, that need to be addressed and
properly handled. Also, the &amp;quot;linkage&amp;quot; between main
and relative clauses has to be performed such that
this information is maintained and not lost due to
the segmentation into short clauses.
Experiments with speech recognizer output in-
stead of transcripts will show in how far we still get
reasonable frame representations when we are faced
with erroneous input in the first place. Specifically,
since the mapper relies on the identification of the
&amp;quot;head verb&amp;quot;, it will be crucial that at least those
words are correctly recognized and tagged most of
the time.
To further enhance our representation, we could
use speech act tags, generated by an automatic
speech act classifier (Finke et al., 1998) and attach
these to the short clauses.&amp;quot;
</bodyText>
<sectionHeader confidence="0.999104" genericHeader="conclusions">
6 Summary
</sectionHeader>
<bodyText confidence="0.998625842105263">
We have presented a system which is able to build
shallow semantic representations for spontaneous
speech in unrestricted domains, without the neces-
sity of extensive knowledge engineering.
Initial experiments demonstrate that this ap-
proach is feasible in principle. However, more work
to improve the major components is needed to reach
a more reliable and valid output.
The potentials of this approach for NLP applica-
tions that use speech as their input are obvious: se-
mantic representations can enhance almost all tasks
that so far have either been restricted to narrow do-
mains or were mainly using word-level representa-
tions, such as text summarization, information re-
trieval, or shallow machine translation.
11Sometimes, the speech acts will span more than one short
clause but as long as the turn-boundaries are fixed for both
our system and the speech act classifier, the re-combination
of short clauses can be done straightforwardly.
</bodyText>
<page confidence="0.990363">
1451
</page>
<sectionHeader confidence="0.998102" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99959875">
The author wants to thank Marsal Gayalda, Mirella
Lapata, and the three anonymous reviewers for valu-
able comments on this paper.
This work was funded in part by grants of the
Verbmobil project of the Federal Republic of Ger-
many, ATR — Interpreting Telecommunications Re-
search Laboratories of Japan, and the US Depart-
ment of Defense.
</bodyText>
<sectionHeader confidence="0.998413" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995772125">
Steven Abney. 1996. Partial parsing via finite-state
cascades. In Workshop on Robust Parsing, 8th
European Summer School in Logic, Language and
Information, Prague, Czech Republic, pages 8-15.
Eric Brill. 1994. Some advances in transformation-
based part of speech tagging. In Proceeedings of
AAAI-94.
Ted Briscoe and John Carroll. 1997. Automatic
extraction of subcategorization from corpora. In
Proceedings of the 5th ANLP Conference, Wash-
ington DC, pages 24-29.
Michael Finke, Jürgen Fritsch, Petra Geutner, Klaus
Ries and Torsten Zeppenfeld. 1997. The Janus-
RTk SWITCHBOARD/CALLHOME 1997 Evaluation
System. In Proceedings of LVCSR Hub5-e Work-
shop, May 13-15, Baltimore, Maryland.
Michael Finke, Maria Lapata, Alon Lavie, Lori
Levin, Laura Mayfield Tomokiyo, Thomas Polzin,
Klaus Ries, Alex Waibel and Klaus Zechner. 1998.
CLARITY: Inferring Discourse Structure from
Speech. In Proceedings of the AAAI 98 Spring
Symposium: Applying Machine Learning to Dis-
course Processing, Stanford, CA, pages 25-32
J. J. Godfrey, E. C. Holliman, and J. McDaniel.
1992. SWITCHBOARD: telephone speech corpus
for research and development. In Proceedings of
the ICASSP-92, volume 1, pages 517-520.
Alon Lavie. 1996. GLR*: A Robust Grammar-
Focused Parser for Spontaneously Spoken Lan-
guage. Ph.D. thesis, Carnegie Mellon University,
Pittsburgh, PA.
Christopher D. Manning. 1993. Automatic acquisi-
tion of a large subcategorization dictionary from
corpora. In Proceeedings of the 31th Annual Meet-
ing of the ACL, pages 235-242.
George A. Miller, Richard Beckwith, Christiane
Fellbaum, Derek Gross, and Katherine Miller.
1993. Five papers on WordNet. Technical report,
Princeton University, CSL, revised version, Au-
gust.
Piek Vossen, Pedro Diez-Orzas, and Wim Peters.
1997. The Multilingual Design of EuroWordNet.
In Proceedings of the ACL/EACL-97 workshop
Automatic Information Extraction and Building
of Lexical Semantic Resources for NLP Applica-
tions, Madrid, July 12th, 1997
Alex Waibel, Michael Finke, Donna Gates, Marsal
Gayalcla., Thomas Kemp, Alon Lavie, Lori Levin,
Martin Maier, Laura Mayfield, Arthur McNair,
Ivica Rogina, Kaori Shima, Tilo Sloboda, Monika
Woszczyna, Torsten Zeppenfeld, and Puming
Zhan. 1996. JANUS-II - advances in speech recog-
nition. In Proceedings of the ICASSP-96.
Wayne Ward. 1991. Understanding spontaneous
speech: The PHOENIX system. In Proceedings
of ICASSP-91, pages 365-367.
Klaus Zechner. 1997. Building chunk level rep-
resentations for spontaneous speech in unre-
stricted domains: The CHUNKY system and
its application to reranking Nbest lists of a
speech recognizer. M.S. Project Report, CMU,
Department of Philosophy. Available from
http://www.contrib.andrew.cmu.edu/-zechner/
publications. html
</reference>
<page confidence="0.994383">
1452
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886569">
<title confidence="0.9998035">Automatic Construction of Frame Representations for Spontaneous Speech in Unrestricted Domains</title>
<author confidence="0.999775">Klaus Zechner</author>
<affiliation confidence="0.9970185">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.997958">5000 Forbes Avenue Pittsburgh, PA 15213, USA</address>
<email confidence="0.999789">zechnerOcs.cmu.edu</email>
<abstract confidence="0.9934856875">This paper presents a system which automatically generates shallow semantic frame structures for conversational speech in unrestricted domains. We argue that such shallow semantic representations can indeed be generated with a minimum amount of linguistic knowledge engineering and without having to explicitly construct a semantic knowledge base. The system is designed to be robust to deal with the problems of speech dysfluencies, ungrammaticalities, and imperfect speech recognition. Initial results on speech transcripts are promising in that correct mappings could be identified in 21% of the clauses of a test set (resp. 44% of this test set where ungrammatical or verb-less clauses were removed).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1996</date>
<booktitle>In Workshop on Robust Parsing, 8th European Summer School in Logic, Language and Information,</booktitle>
<pages>8--15</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2662" citStr="Abney, 1996" startWordPosition="392" endWordPosition="394">al manual effort. Eventually, these semantic structures can serve as (additional) input to a variety of different tasks in NLP, such as text or dialogue summarization, information gisting, information retrieval, or shallow machine translation. 2 Shallow Semantic Structures The two main representations we are building on are the following: • chunks: these correspond mostly to basic (i.e., non-attached) phrasal constituents • frames: these are built from the parsed chunks according to subcategorization constraints extracted from the WordNet lexicon The chunks are defined in a similar way as in (Abney, 1996), namely as &amp;quot;non-recursive phrasal units&amp;quot;; they roughly correspond to the standard linguistic notion of constituents, except that there are no attachments made (e.g., a PP to a NP) and that a verbal chunk does not include any of its arguments but just consists of the verbal complex (auxiliary/main verb), including possibly inserted adverbs and/or negation particles. All frames are being generated on the basis of &amp;quot;short clauses&amp;quot; which we define as minimal clausal units that contain at least one subject and an inflected verbal form.&apos; 2 To produce the list of all possible subcategorization frames</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Steven Abney. 1996. Partial parsing via finite-state cascades. In Workshop on Robust Parsing, 8th European Summer School in Logic, Language and Information, Prague, Czech Republic, pages 8-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some advances in transformationbased part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceeedings of AAAI-94.</booktitle>
<contexts>
<context position="4376" citStr="Brill, 1994" startWordPosition="673" endWordPosition="674">1448 Verbal tokens 4428 Different lemmata 2464 Senses in all lemmata 8523 Avg. senses per lemma 3.46 Total number of frames 15467 Avg. frames per sense 1.81 Table 1: WordNet: verbal lemmata, senses, and frames 3 Resources and System Components We use the following resources to build our system: • the SWITCHBOARD (SWBD) corpus (Godfrey et al., 1992) for speech data, transcripts, and annotations at various levels (e.g., for segment boundaries or parts of speech) • the JANUS speech recognizer (Waibel et al., 1996) to provide us with input hypotheses • a part of speech (POS) tagger, derived from (Brill, 1994), adapted to and retrained for the SWITCHBOARD corpus • a preprocessing pipe which cleans up speech dysfluencies (e.g., repetitions, hesitations) and contains a segmentation module to split .the speech recognizer turns into short clauses • a chart parser (Ward, 1991) with a POS based grammar to generate the chunks3 (phrasal constituents) • WordNet 1.5 (Miller et al., 1993) for the extraction of subcategorization (subcat) frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;) • a mapper which tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Eric Brill. 1994. Some advances in transformationbased part of speech tagging. In Proceeedings of AAAI-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th ANLP Conference,</booktitle>
<pages>24--29</pages>
<location>Washington DC,</location>
<contexts>
<context position="5426" citStr="Briscoe and Carroll, 1997" startWordPosition="842" endWordPosition="845"> frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;) • a mapper which tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause and the subcat frames for the main verb in that clause The major blocks of the system architecture are depicted in Figure 1. We want to stress here that except for the development of the small POS grammar and the framemapper, the other components and resources were already present or quite simple to implement. There has also been significant work on (semi-)automatic induction of subcategorization frames (Manning, 1993; Briscoe and Carroll, 1997), such that even 3More details about the chunk parser can be found in (Zechner, 1997). input Iterance speech recognizer hypothesis POS tagger preprocessing pipe chunk parser chunk sequence semantic mapper frame representation Figure 1: Global system architecture without the important knowledge source from WordNet, a similar system could be built for other languages as well. Also, the Euro-WordNet project (Vossen et al., 1997) is currently underway in building WordNet resources for other European languages. 4 Preliminary Experiments We performed some initial experiments using the SWBD transcrip</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Ted Briscoe and John Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of the 5th ANLP Conference, Washington DC, pages 24-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Finke</author>
<author>Jürgen Fritsch</author>
<author>Petra Geutner</author>
<author>Klaus Ries</author>
<author>Torsten Zeppenfeld</author>
</authors>
<title>Evaluation System. In</title>
<date>1997</date>
<booktitle>The JanusRTk SWITCHBOARD/CALLHOME</booktitle>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="1561" citStr="Finke et al., 1997" startWordPosition="223" endWordPosition="226">d). 1 Introduction In syntactic and semantic analysis of spontaneous speech, little research has been done with regard to dealing with language in unrestricted domains. There are several reasons why so far an in-depth analysis of this type of language data has been considered prohibitively hard: • inherent properties of spontaneous speech, such as dysfluencies and ungrammaticalities (Lavie, 1996) • word accuracy being far from perfect (e.g., on a typical corpus such as SWITCHBOARD (SWBD) (Godfrey et al., 1992), current state-of-the-art recognizers have word error rates in the range of 30-40% (Finke et al., 1997)) • if the domain is unrestricted, manual construction of a semantic knowledge base with reasonable coverage is very labor intensive In this paper we propose to combine methods of partial parsing (&amp;quot;chunking&amp;quot;) with the mapping of the verb arguments onto subcategorization frames that can be extracted automatically, in this case, from WordNet (Miller et al., 1993). As preliminary results indicate, this yields a way of generating shallow semantic representations efficiently and with minimal manual effort. Eventually, these semantic structures can serve as (additional) input to a variety of differe</context>
</contexts>
<marker>Finke, Fritsch, Geutner, Ries, Zeppenfeld, 1997</marker>
<rawString>Michael Finke, Jürgen Fritsch, Petra Geutner, Klaus Ries and Torsten Zeppenfeld. 1997. The JanusRTk SWITCHBOARD/CALLHOME 1997 Evaluation System. In Proceedings of LVCSR Hub5-e Workshop, May 13-15, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Finke</author>
<author>Maria Lapata</author>
<author>Alon Lavie</author>
<author>Lori Levin</author>
<author>Laura Mayfield Tomokiyo</author>
<author>Thomas Polzin</author>
<author>Klaus Ries</author>
<author>Alex Waibel</author>
<author>Klaus Zechner</author>
</authors>
<title>CLARITY: Inferring Discourse Structure from Speech.</title>
<date>1998</date>
<booktitle>In Proceedings of the AAAI 98 Spring Symposium: Applying Machine Learning to Discourse Processing,</booktitle>
<pages>25--32</pages>
<location>Stanford, CA,</location>
<contexts>
<context position="13463" citStr="Finke et al., 1998" startWordPosition="2131" endWordPosition="2134"> be performed such that this information is maintained and not lost due to the segmentation into short clauses. Experiments with speech recognizer output instead of transcripts will show in how far we still get reasonable frame representations when we are faced with erroneous input in the first place. Specifically, since the mapper relies on the identification of the &amp;quot;head verb&amp;quot;, it will be crucial that at least those words are correctly recognized and tagged most of the time. To further enhance our representation, we could use speech act tags, generated by an automatic speech act classifier (Finke et al., 1998) and attach these to the short clauses.&amp;quot; 6 Summary We have presented a system which is able to build shallow semantic representations for spontaneous speech in unrestricted domains, without the necessity of extensive knowledge engineering. Initial experiments demonstrate that this approach is feasible in principle. However, more work to improve the major components is needed to reach a more reliable and valid output. The potentials of this approach for NLP applications that use speech as their input are obvious: semantic representations can enhance almost all tasks that so far have either been</context>
</contexts>
<marker>Finke, Lapata, Lavie, Levin, Tomokiyo, Polzin, Ries, Waibel, Zechner, 1998</marker>
<rawString>Michael Finke, Maria Lapata, Alon Lavie, Lori Levin, Laura Mayfield Tomokiyo, Thomas Polzin, Klaus Ries, Alex Waibel and Klaus Zechner. 1998. CLARITY: Inferring Discourse Structure from Speech. In Proceedings of the AAAI 98 Spring Symposium: Applying Machine Learning to Discourse Processing, Stanford, CA, pages 25-32</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Godfrey</author>
<author>E C Holliman</author>
<author>J McDaniel</author>
</authors>
<title>SWITCHBOARD: telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>In Proceedings of the ICASSP-92,</booktitle>
<volume>1</volume>
<pages>517--520</pages>
<contexts>
<context position="1457" citStr="Godfrey et al., 1992" startWordPosition="207" endWordPosition="210">the clauses of a test set (resp. 44% of this test set where ungrammatical or verb-less clauses were removed). 1 Introduction In syntactic and semantic analysis of spontaneous speech, little research has been done with regard to dealing with language in unrestricted domains. There are several reasons why so far an in-depth analysis of this type of language data has been considered prohibitively hard: • inherent properties of spontaneous speech, such as dysfluencies and ungrammaticalities (Lavie, 1996) • word accuracy being far from perfect (e.g., on a typical corpus such as SWITCHBOARD (SWBD) (Godfrey et al., 1992), current state-of-the-art recognizers have word error rates in the range of 30-40% (Finke et al., 1997)) • if the domain is unrestricted, manual construction of a semantic knowledge base with reasonable coverage is very labor intensive In this paper we propose to combine methods of partial parsing (&amp;quot;chunking&amp;quot;) with the mapping of the verb arguments onto subcategorization frames that can be extracted automatically, in this case, from WordNet (Miller et al., 1993). As preliminary results indicate, this yields a way of generating shallow semantic representations efficiently and with minimal manu</context>
<context position="4114" citStr="Godfrey et al., 1992" startWordPosition="628" endWordPosition="631">eparately. They will, however, have to be &amp;quot;linked&amp;quot; to the phrase they modify. 2We are also considering to take even shorter units as basis for the mapping that would, e.g., include non-inflected clausal complements. The most convenient solution has yet to be determined. 1448 Verbal tokens 4428 Different lemmata 2464 Senses in all lemmata 8523 Avg. senses per lemma 3.46 Total number of frames 15467 Avg. frames per sense 1.81 Table 1: WordNet: verbal lemmata, senses, and frames 3 Resources and System Components We use the following resources to build our system: • the SWITCHBOARD (SWBD) corpus (Godfrey et al., 1992) for speech data, transcripts, and annotations at various levels (e.g., for segment boundaries or parts of speech) • the JANUS speech recognizer (Waibel et al., 1996) to provide us with input hypotheses • a part of speech (POS) tagger, derived from (Brill, 1994), adapted to and retrained for the SWITCHBOARD corpus • a preprocessing pipe which cleans up speech dysfluencies (e.g., repetitions, hesitations) and contains a segmentation module to split .the speech recognizer turns into short clauses • a chart parser (Ward, 1991) with a POS based grammar to generate the chunks3 (phrasal constituents</context>
</contexts>
<marker>Godfrey, Holliman, McDaniel, 1992</marker>
<rawString>J. J. Godfrey, E. C. Holliman, and J. McDaniel. 1992. SWITCHBOARD: telephone speech corpus for research and development. In Proceedings of the ICASSP-92, volume 1, pages 517-520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
</authors>
<title>GLR*: A Robust GrammarFocused Parser for Spontaneously Spoken Language.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="1341" citStr="Lavie, 1996" startWordPosition="189" endWordPosition="190">Initial results on speech transcripts are promising in that correct mappings could be identified in 21% of the clauses of a test set (resp. 44% of this test set where ungrammatical or verb-less clauses were removed). 1 Introduction In syntactic and semantic analysis of spontaneous speech, little research has been done with regard to dealing with language in unrestricted domains. There are several reasons why so far an in-depth analysis of this type of language data has been considered prohibitively hard: • inherent properties of spontaneous speech, such as dysfluencies and ungrammaticalities (Lavie, 1996) • word accuracy being far from perfect (e.g., on a typical corpus such as SWITCHBOARD (SWBD) (Godfrey et al., 1992), current state-of-the-art recognizers have word error rates in the range of 30-40% (Finke et al., 1997)) • if the domain is unrestricted, manual construction of a semantic knowledge base with reasonable coverage is very labor intensive In this paper we propose to combine methods of partial parsing (&amp;quot;chunking&amp;quot;) with the mapping of the verb arguments onto subcategorization frames that can be extracted automatically, in this case, from WordNet (Miller et al., 1993). As preliminary </context>
</contexts>
<marker>Lavie, 1996</marker>
<rawString>Alon Lavie. 1996. GLR*: A Robust GrammarFocused Parser for Spontaneously Spoken Language. Ph.D. thesis, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
</authors>
<title>Automatic acquisition of a large subcategorization dictionary from corpora.</title>
<date>1993</date>
<booktitle>In Proceeedings of the 31th Annual Meeting of the ACL,</booktitle>
<pages>235--242</pages>
<contexts>
<context position="5398" citStr="Manning, 1993" startWordPosition="840" endWordPosition="841">zation (subcat) frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;) • a mapper which tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause and the subcat frames for the main verb in that clause The major blocks of the system architecture are depicted in Figure 1. We want to stress here that except for the development of the small POS grammar and the framemapper, the other components and resources were already present or quite simple to implement. There has also been significant work on (semi-)automatic induction of subcategorization frames (Manning, 1993; Briscoe and Carroll, 1997), such that even 3More details about the chunk parser can be found in (Zechner, 1997). input Iterance speech recognizer hypothesis POS tagger preprocessing pipe chunk parser chunk sequence semantic mapper frame representation Figure 1: Global system architecture without the important knowledge source from WordNet, a similar system could be built for other languages as well. Also, the Euro-WordNet project (Vossen et al., 1997) is currently underway in building WordNet resources for other European languages. 4 Preliminary Experiments We performed some initial experime</context>
</contexts>
<marker>Manning, 1993</marker>
<rawString>Christopher D. Manning. 1993. Automatic acquisition of a large subcategorization dictionary from corpora. In Proceeedings of the 31th Annual Meeting of the ACL, pages 235-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>Five papers on WordNet.</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>Princeton University,</institution>
<note>CSL, revised version,</note>
<contexts>
<context position="1924" citStr="Miller et al., 1993" startWordPosition="281" endWordPosition="284"> and ungrammaticalities (Lavie, 1996) • word accuracy being far from perfect (e.g., on a typical corpus such as SWITCHBOARD (SWBD) (Godfrey et al., 1992), current state-of-the-art recognizers have word error rates in the range of 30-40% (Finke et al., 1997)) • if the domain is unrestricted, manual construction of a semantic knowledge base with reasonable coverage is very labor intensive In this paper we propose to combine methods of partial parsing (&amp;quot;chunking&amp;quot;) with the mapping of the verb arguments onto subcategorization frames that can be extracted automatically, in this case, from WordNet (Miller et al., 1993). As preliminary results indicate, this yields a way of generating shallow semantic representations efficiently and with minimal manual effort. Eventually, these semantic structures can serve as (additional) input to a variety of different tasks in NLP, such as text or dialogue summarization, information gisting, information retrieval, or shallow machine translation. 2 Shallow Semantic Structures The two main representations we are building on are the following: • chunks: these correspond mostly to basic (i.e., non-attached) phrasal constituents • frames: these are built from the parsed chunks</context>
<context position="4751" citStr="Miller et al., 1993" startWordPosition="730" endWordPosition="733"> transcripts, and annotations at various levels (e.g., for segment boundaries or parts of speech) • the JANUS speech recognizer (Waibel et al., 1996) to provide us with input hypotheses • a part of speech (POS) tagger, derived from (Brill, 1994), adapted to and retrained for the SWITCHBOARD corpus • a preprocessing pipe which cleans up speech dysfluencies (e.g., repetitions, hesitations) and contains a segmentation module to split .the speech recognizer turns into short clauses • a chart parser (Ward, 1991) with a POS based grammar to generate the chunks3 (phrasal constituents) • WordNet 1.5 (Miller et al., 1993) for the extraction of subcategorization (subcat) frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;) • a mapper which tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause and the subcat frames for the main verb in that clause The major blocks of the system architecture are depicted in Figure 1. We want to stress here that except for the development of the small POS grammar and the framemapper, the other components and resources were already present or quite simple to implement. There has also been significant work on (semi-)automatic induc</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1993</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. 1993. Five papers on WordNet. Technical report, Princeton University, CSL, revised version, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
<author>Pedro Diez-Orzas</author>
<author>Wim Peters</author>
</authors>
<title>The Multilingual Design of EuroWordNet.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL/EACL-97 workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="5855" citStr="Vossen et al., 1997" startWordPosition="907" endWordPosition="910">es were already present or quite simple to implement. There has also been significant work on (semi-)automatic induction of subcategorization frames (Manning, 1993; Briscoe and Carroll, 1997), such that even 3More details about the chunk parser can be found in (Zechner, 1997). input Iterance speech recognizer hypothesis POS tagger preprocessing pipe chunk parser chunk sequence semantic mapper frame representation Figure 1: Global system architecture without the important knowledge source from WordNet, a similar system could be built for other languages as well. Also, the Euro-WordNet project (Vossen et al., 1997) is currently underway in building WordNet resources for other European languages. 4 Preliminary Experiments We performed some initial experiments using the SWBD transcripts as input to the system. These were POS tagged, preprocessed, segmented into short clauses, parsed in chunks using a POS based grammar, and finally, for each short clause, the frame-mapper matched all potential arguments of the verb against all possible subcategorization frames listed in the lemmata file we had precomputed from WordNet (see section 2). In total we had over 600000 short clauses, containing approximately 1.7 </context>
</contexts>
<marker>Vossen, Diez-Orzas, Peters, 1997</marker>
<rawString>Piek Vossen, Pedro Diez-Orzas, and Wim Peters. 1997. The Multilingual Design of EuroWordNet. In Proceedings of the ACL/EACL-97 workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, Madrid, July 12th, 1997</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Waibel</author>
<author>Michael Finke</author>
<author>Donna Gates</author>
<author>Marsal Gayalcla</author>
<author>Thomas Kemp</author>
</authors>
<title>Alon Lavie,</title>
<date>1996</date>
<booktitle>In Proceedings of the ICASSP-96.</booktitle>
<institution>McNair, Ivica Rogina, Kaori Shima, Tilo Sloboda, Monika Woszczyna, Torsten Zeppenfeld, and</institution>
<location>Lori Levin, Martin Maier, Laura Mayfield, Arthur</location>
<contexts>
<context position="4280" citStr="Waibel et al., 1996" startWordPosition="654" endWordPosition="657">e.g., include non-inflected clausal complements. The most convenient solution has yet to be determined. 1448 Verbal tokens 4428 Different lemmata 2464 Senses in all lemmata 8523 Avg. senses per lemma 3.46 Total number of frames 15467 Avg. frames per sense 1.81 Table 1: WordNet: verbal lemmata, senses, and frames 3 Resources and System Components We use the following resources to build our system: • the SWITCHBOARD (SWBD) corpus (Godfrey et al., 1992) for speech data, transcripts, and annotations at various levels (e.g., for segment boundaries or parts of speech) • the JANUS speech recognizer (Waibel et al., 1996) to provide us with input hypotheses • a part of speech (POS) tagger, derived from (Brill, 1994), adapted to and retrained for the SWITCHBOARD corpus • a preprocessing pipe which cleans up speech dysfluencies (e.g., repetitions, hesitations) and contains a segmentation module to split .the speech recognizer turns into short clauses • a chart parser (Ward, 1991) with a POS based grammar to generate the chunks3 (phrasal constituents) • WordNet 1.5 (Miller et al., 1993) for the extraction of subcategorization (subcat) frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;</context>
</contexts>
<marker>Waibel, Finke, Gates, Gayalcla, Kemp, 1996</marker>
<rawString>Alex Waibel, Michael Finke, Donna Gates, Marsal Gayalcla., Thomas Kemp, Alon Lavie, Lori Levin, Martin Maier, Laura Mayfield, Arthur McNair, Ivica Rogina, Kaori Shima, Tilo Sloboda, Monika Woszczyna, Torsten Zeppenfeld, and Puming Zhan. 1996. JANUS-II - advances in speech recognition. In Proceedings of the ICASSP-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Ward</author>
</authors>
<title>Understanding spontaneous speech: The PHOENIX system.</title>
<date>1991</date>
<booktitle>In Proceedings of ICASSP-91,</booktitle>
<pages>365--367</pages>
<contexts>
<context position="4643" citStr="Ward, 1991" startWordPosition="713" endWordPosition="714">ources to build our system: • the SWITCHBOARD (SWBD) corpus (Godfrey et al., 1992) for speech data, transcripts, and annotations at various levels (e.g., for segment boundaries or parts of speech) • the JANUS speech recognizer (Waibel et al., 1996) to provide us with input hypotheses • a part of speech (POS) tagger, derived from (Brill, 1994), adapted to and retrained for the SWITCHBOARD corpus • a preprocessing pipe which cleans up speech dysfluencies (e.g., repetitions, hesitations) and contains a segmentation module to split .the speech recognizer turns into short clauses • a chart parser (Ward, 1991) with a POS based grammar to generate the chunks3 (phrasal constituents) • WordNet 1.5 (Miller et al., 1993) for the extraction of subcategorization (subcat) frames for all senses of a verb (including semantic features, such as &amp;quot;animacy&amp;quot;) • a mapper which tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause and the subcat frames for the main verb in that clause The major blocks of the system architecture are depicted in Figure 1. We want to stress here that except for the development of the small POS grammar and the framemapper, the other components and resources were </context>
</contexts>
<marker>Ward, 1991</marker>
<rawString>Wayne Ward. 1991. Understanding spontaneous speech: The PHOENIX system. In Proceedings of ICASSP-91, pages 365-367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Zechner</author>
</authors>
<title>Building chunk level representations for spontaneous speech in unrestricted domains: The CHUNKY system and its application to reranking Nbest lists of a speech recognizer.</title>
<date>1997</date>
<tech>M.S. Project Report, CMU,</tech>
<institution>Department of Philosophy.</institution>
<note>Available from http://www.contrib.andrew.cmu.edu/-zechner/ publications. html</note>
<contexts>
<context position="5511" citStr="Zechner, 1997" startWordPosition="859" endWordPosition="860">h tries to find the &amp;quot;best match&amp;quot; between the chunks found within a short clause and the subcat frames for the main verb in that clause The major blocks of the system architecture are depicted in Figure 1. We want to stress here that except for the development of the small POS grammar and the framemapper, the other components and resources were already present or quite simple to implement. There has also been significant work on (semi-)automatic induction of subcategorization frames (Manning, 1993; Briscoe and Carroll, 1997), such that even 3More details about the chunk parser can be found in (Zechner, 1997). input Iterance speech recognizer hypothesis POS tagger preprocessing pipe chunk parser chunk sequence semantic mapper frame representation Figure 1: Global system architecture without the important knowledge source from WordNet, a similar system could be built for other languages as well. Also, the Euro-WordNet project (Vossen et al., 1997) is currently underway in building WordNet resources for other European languages. 4 Preliminary Experiments We performed some initial experiments using the SWBD transcripts as input to the system. These were POS tagged, preprocessed, segmented into short </context>
</contexts>
<marker>Zechner, 1997</marker>
<rawString>Klaus Zechner. 1997. Building chunk level representations for spontaneous speech in unrestricted domains: The CHUNKY system and its application to reranking Nbest lists of a speech recognizer. M.S. Project Report, CMU, Department of Philosophy. Available from http://www.contrib.andrew.cmu.edu/-zechner/ publications. html</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>