<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039861">
<title confidence="0.995584">
Improving Phrase-Based Translation with Prototypes of Short Phrases
</title>
<author confidence="0.999697">
Frank Liberato†, Behrang Mohit$, Rebecca Hwa†$
</author>
<affiliation confidence="0.998416">
†Department of Computer Science $Intelligent Systems Program
University of Pittsburgh
</affiliation>
<email confidence="0.998696">
{frank,behrang,hwa@cs.pitt.edu}
</email>
<sectionHeader confidence="0.998598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999842818181818">
We investigate methods of generating addi-
tional bilingual phrase pairs for a phrase-
based decoder by translating short sequences
of source text. Because our translation task
is more constrained, we can use a model that
employs more linguistically rich features than
a traditional decoder. We have implemented
an example of this approach. Experimental re-
sults suggest that the phrase pairs produced by
our method are useful to the decoder, and lead
to improved sentence translations.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927633333333">
Recently, there have been a number of successful
attempts at improving phrase-based statistical ma-
chine translation by exploiting linguistic knowledge
such as morphology, part-of-speech tags, and syn-
tax. Many translation models use such knowledge
before decoding (Xia and McCord, 2004) and dur-
ing decoding (Birch et al., 2007; Gimpel and Smith,
2009; Koehn and Hoang, 2007; Chiang et al., 2009),
but they are limited to simpler features for practi-
cal reasons, often restricted to conditioning left-to-
right on the target sentence. Traditionally, n-best
rerankers (Shen et al., 2004) have applied expen-
sive analysis after the translation process, on both
the source and target side, though they suffer from
being limited to whatever is on the n-best list (Hasan
et al., 2007).
We argue that it can be desirable to pre-translate
parts of the source text before sentence-level decod-
ing begins, using a richer model that would typically
be out of reach during sentence-level decoding. In
this paper, we describe a particular method of gen-
erating additional bilingual phrase pairs for a new
source text, using what we call phrase prototypes,
which are are learned from bilingual training data.
Our goal is to generate improved translations of rel-
atively short phrase pairs to provide the SMT de-
coder with better phrasal choices. We validate the
idea through experiments on Arabic-English trans-
lation. Our method produces a 1.3 BLEU score in-
crease (3.3% relative) on a test set.
</bodyText>
<sectionHeader confidence="0.98831" genericHeader="introduction">
2 Approach
</sectionHeader>
<bodyText confidence="0.9998625">
Re-ranking tends to use expensive features of the en-
tire source and target sentences, s and t, and align-
ments, a, to produce a score for the translation. We
will call this scoring function 0(s, t, a). While 0(·)
might capture quite a bit of linguistic information, it
can be problematic to use this function for decoding
directly. This is due to both the expense of com-
puting it, and the difficulty in using it to guide the
decoder’s search. For example, a choice of 0(·) that
relies on a top-down parser is difficult to integrate
into a left-to-right decoder (Charniak et al., 2003).
Our idea is to use an expensive scoring function
to guide the search for potential translations for part
of a source sentence, S, even if translating all of it
isn’t feasible. We can then provide these transla-
tions to the decoder, along with their scores, to in-
corporate them as it builds the complete translation
of S. This differs from approaches such as (Och and
Ney, 2004) because we generate new phrase pairs in
isolation, rather than incorporating everything into
the sentence-level decoder. The baseline system is
the Moses phrase-based translation system (Koehn
</bodyText>
<page confidence="0.979974">
301
</page>
<subsubsectionHeader confidence="0.566894">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 301–304,
</subsubsectionHeader>
<subsectionHeader confidence="0.261387">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.940236">
et al., 2007).
</bodyText>
<subsectionHeader confidence="0.997278">
2.1 Description of Our Scoring Function
</subsectionHeader>
<bodyText confidence="0.999937121212121">
For this work, we consider a scoring function based
on part-of-speech (POS) tags, OPOS(·). It oper-
ates in two steps: it converts the source and target
phrases, plus alignments, into what we call a phrase
prototype, then assigns a score to it based on how
common that prototype was during training.
Each phrase pair prototype is a tuple containing
the source prototype, target prototype, and align-
ment prototype, respectively. The source and tar-
get prototypes are a mix of surface word forms and
POS tags, such as the Arabic string (NN Al JJ),
or the English string (NN NN). For example, the
source and target prototypes above might be used in
the phrase prototype (NN0 Al JJ1 , NN1 NN0),
with the alignment prototype specified implicitly via
subscripts for brevity. For simplicity, the alignment
prototype is restricted to allow a source or target
word/tag to be unaligned, plus 1:1 alignments be-
tween them. We do not consider 1:many, many:1, or
many:many alignments in this work.
For any input (s, t, a), it is possible to con-
struct potentially many phrase prototypes from it by
choosing different subsets of the source and target
words to represent as POS tags. In the above ex-
ample, the Arabic determiner Al could be converted
into an unaligned POS tag, making the source pro-
totype (NN DT JJ). For this work, we convert all
aligned words into POS tags. As a practical con-
cern, we insist that unaligned words are always kept
as their surface form.
OPOS(s, t, a) assign a score based on the proba-
bility of the resulting prototypes; more likely proto-
types should yield higher scores. We choose:
</bodyText>
<equation confidence="0.768743">
OPOS(s, t, a) = p(5P, AP|TP) · p(TP, AP|5P)
</equation>
<bodyText confidence="0.999940642857143">
where 5P is the source prototype constructed from
s, t, a. Similarly, TP and AP are the target and
alignment prototypes, respectively.
To compute OPOS(·), we must build a model for
each of p(5P, AP|TP) and p(TP, AP|5P). To do
this, we start with a corpus of aligned, POS-tagged
bilingual text. We then find phrases that are consis-
tent with (Koehn et al., 2003). As we extract these
phrase pairs, we convert each into a phrase proto-
type by replacing surface forms with POS tags for
all aligned words in the prototype.
After we have processed the bilingual training
text, we have collected a set of phrase prototypes
and a count of how often each was observed.
</bodyText>
<subsectionHeader confidence="0.998887">
2.2 Generating New Phrases
</subsectionHeader>
<bodyText confidence="0.99998115">
To generate phrases, we scan through the source text
to be translated, finding any span of source words
that matches the source prototype of at least one
phrase prototype. For each such phrase, and for each
phrase prototype which it matches, we generate all
target phrases which also match the target and align-
ment prototypes.
To do this, we use a word-to-word dictionary to
generate all target phrases which honor the align-
ments required by the alignment prototype. For each
source word which is aligned to a POS tag in the tar-
get prototype, we substitute all single-word transla-
tions in our dictionary1.
For each target phrase that we generate, we must
ensure that it matches the target prototype. We give
each phrase to a POS tagger, and check the resulting
tags against any tags in the target prototype. If there
are no mismatches, then the phrase pair is retained
for the phrase table, else it is discarded. In the latter
case, OPOS(·) would assign this pair a score of zero.
</bodyText>
<subsectionHeader confidence="0.998977">
2.3 Computing Phrase Weights
</subsectionHeader>
<bodyText confidence="0.915663888888889">
In the Moses phrase table, each entry has four pa-
rameters: two lexical weights, and the two condi-
tional phrase probabilities p(s|t) and p(t|s). While
the lexical weights can be computed using the stan-
dard method (Koehn et al., 2003), estimating the
conditional phrase probabilities is not straightfor-
ward for our approach because they are not ob-
served in bilingual training data. Instead, we esti-
mate the maximum conditional phrase probabilities
that would be assigned by the sentence-level decoder
for this phrase pair, as if it had generated the tar-
get string from the source string using the baseline
phrase table2. To do this efficiently, we use some
1Since we required that all unaligned target words are kept
as surface forms in the target prototype, this is sufficient. If we
did not insist this, then we might be faced with the unenviable
task of choosing a target languange noun, without further guid-
ance from the source text.
</bodyText>
<footnote confidence="0.8011305">
2If we use these probabilities for our generated phrase pair’s
probability estimates, then the sentence-level decoder would see
</footnote>
<page confidence="0.995057">
302
</page>
<bodyText confidence="0.999849">
simplifying assumptions: we do not restrict how of-
ten a source word is used during the translation, and
we ignore distortion / reordering costs. These admit
a simple dynamic programming solution.
We must also include the score from OPOS(·), to
give the decoder some idea of our confidence in the
generated phrase pair. We include the phrase pair’s
score as an additional weight in the phrase table.
</bodyText>
<sectionHeader confidence="0.998543" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999079259259259">
The Linguistic Data Consortium Arabic-English
corpus23 is used to train the baseline MT system
(34K sentences, about one million words), and to
learn phrase prototypes. The LDC multi-translation
Arabic-English corpus (NIST2003)4 is used for tun-
ing and testing; the tuning set consists of the first
500 sentences, and the test set consists of the next
500 sentences. The language model is a 4-gram
model built from the English side of the parallel cor-
pus, plus the English side of the wmt07 German-
English and French-English news commentary data.
The baseline translation system is Moses (Koehn
et al., 2007), with the msd-bidirectional-fe
reordering model. Evaluation is done using the
BLEU (Papineni et al., 2001) metric with four ref-
erences. All text is lowercased before evaluation;
recasing is not used. We use the Stanford Arabic
POS Tagging system, based on (Toutanova et al.,
2003)5. The word-to-word dictionary that is used in
the phrase generation step of our method is extracted
from the highest-scoring translations for each source
word in the baseline phrase table. For some closed-
class words, we use a small, manually constructed
dictionary to reduce the noise in the phrase table that
exists for very common words. We use this in place
of a stand-alone dictionary to reduce the need for
additional resources.
</bodyText>
<sectionHeader confidence="0.99982" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.992975333333333">
To see the effect on the BLEU score of the result-
ing sentence-level translation, we vary the amount
of bilingual data used to build the phrase prototypes.
(approximately) no difference between building the generated
phrase using the baseline phrase table, or using our generated
phrase pair directly.
</bodyText>
<footnote confidence="0.999634333333333">
3Catalogue numbers LDC2004T17 and LDC2004T18
4Catalogue number: LDC2003T18
5It is available at http://nlp.stanford.edu/software/tagger.shtml
</footnote>
<figure confidence="0.9883695">
0.42
0.41
0.4
0.39
0.38
0.37
0.36
0
</figure>
<figureCaption confidence="0.97905575">
Figure 1: Bilingual training size vs. BLEU score (mid-
dle line, left axis) and phrase table composition (top line,
right axis) on Arabic Development Set. The baseline
BLEU score (bottom line) is included for comparison.
</figureCaption>
<bodyText confidence="0.999847285714286">
As we increase the amount of training data, we ex-
pect that the phrase prototype extraction algorithm
will observe more phrase prototypes. This will cause
it to generate more phrase pairs, introducing both
more noise and more good phrases into the phrase
table. Because quite a few phrase prototypes are
built in any case, we require that each is seen at
least three times before we use it to generate phrases.
Phrase prototypes seen fewer times than this are dis-
carded before phrase generation begins. Varying this
minimum support parameter does not affect the re-
sults noticeably.
The results on the tuning set are seen in Figure 1.
The BLEU score on the tuning set generally im-
proves as the amount of bilingual training data is in-
creased, even as the percentage of generated phrases
approaches 100%. Manual inspection of the phrase
pairs reveals that many are badly formed; this sug-
gests that the language model is doing its job in fil-
tering out disfluent phrases.
Using the first 5,000 bilingual training sentences
to train our model, we compare our method to the
baseline moses system. Each system was tuned via
MERT (Och, 2003) before running it on the test set.
The tuned baseline system scores 38.45. Including
our generated phrases improves this by 1.3 points to
39.75. This is a slightly smaller gain than exists in
the tuning set experiment, due in part that we did not
</bodyText>
<page confidence="0.998441">
303
</page>
<bodyText confidence="0.853645">
run MERT for experiment shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.997707" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99874">
As one might expect, generated phrases both
help and hurt individual translations. A sentence
that can be translated starting with the phrase
“korea added that the syrian prime
minister” is translated by the baseline system as
“korean I foreign minister I added I
that I the syrian”. While “the syrian
foreign minister” is an unambiguous source
phrase, the baseline phrase table does not include it;
the language and reordering models must stitch the
translation together. Ours method generates “the
syrian foreign minister” directly.
Generated phrases are not always correct. For
example, a generated phrase causes our system to
choose “europe role”, while the baseline sys-
tem picks “the role of I europe”. While
the same prototype is used (correctly) for reordering
Arabic “NNp JJ1” constructs into English as “NN1
NNp” in many instances, it fails in this case. The lan-
guage model shares the blame, since it does not pre-
fer the correct phrase over the shorter one. In con-
trast, a 5-gram language model based on the LDC
Web IT 5-gram counts6 prefers the correct phrase.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999916333333333">
We have shown that translating short spans of source
text, and providing the results to a phrase-based
SMT decoder can improve sentence-level machine
translation. Further, it permits us to use linguisti-
cally informed features to guide the generation of
new phrase pairs.
</bodyText>
<sectionHeader confidence="0.99669" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.933493333333333">
This work is supported by U.S. National Science Foun-
dation Grant IIS-0745914. We thank the anonymous re-
viewers for their suggestions.
</bodyText>
<sectionHeader confidence="0.999224" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998393655172414">
A. Birch, M. Osborne, and P. Koehn. 2007. CCG su-
pertags in factored statistical machine translation. In
Proc. of the Second Workshop on SMT.
6Catalogue number LDC2006T13.
E. Charniak, K. Knight, and K. Yamada. 2003. Syntax-
based language models for statistical machine transla-
tion. In Proceedings of MT Summit IX.
D. Chiang, K. Knight, and W. Wang. 2009. 11,001 new
features for statistical machine translation. In NAACL
’09: Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Assoc. for Computational Linguistics.
K. Gimpel and N.A. Smith. 2009. Feature-rich transla-
tion by quasi-synchronous lattice parsing. In Proc. of
EMNLP.
S. Hasan, R. Zens, and H. Ney. 2007. Are very large n-
best lists useful for SMT? Proc. NAACL, Short paper,
pages 57–60.
P. Koehn and H. Hoang. 2007. Factored translation
models. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 868–876.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statisti-
cal phrase-based translation. In Proceedings of the
2003 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology-Volume 1, page 54.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al. 2007. Moses: Open
source toolkit for statistical machine translation. In
Annual meeting-Association for Computational Lin-
guistics, volume 45, page 2.
F. J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Computa-
tional Linguistics, 30(4):417–449.
F.J. Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proc. of the 41st Annual
Meeting on Assoc. for Computational Linguistics.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2001.
Bleu: a method for automatic evaluation of machine
translation. In Proc. of the 40th Annual Meeting of
Association for Computational Linguistics.
L. Shen, A. Sarkar, and F.J. Och. 2004. Discrimina-
tive reranking for machine translation. In Proceedings
of the Joint HLT and NAACL Conference (HLT 04),
pages 177–184.
K. Toutanova, D. Klein, C. D. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In NAACL ’03: Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology.
F. Xia and M. McCord. 2004. Improving a statistical mt
system with automatically learned rewrite patterns. In
COLING ’04: Proceedings of the 20th international
conference on Computational Linguistics.
</reference>
<page confidence="0.99933">
304
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966371">
<title confidence="0.999814">Improving Phrase-Based Translation with Prototypes of Short Phrases</title>
<author confidence="0.979994">Behrang Rebecca</author>
<affiliation confidence="0.995403">of Computer Science Systems University of</affiliation>
<abstract confidence="0.999189916666667">We investigate methods of generating additional bilingual phrase pairs for a phrasebased decoder by translating short sequences of source text. Because our translation task is more constrained, we can use a model that employs more linguistically rich features than a traditional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>CCG supertags in factored statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the Second Workshop on SMT. 6Catalogue number LDC2006T13.</booktitle>
<contexts>
<context position="1064" citStr="Birch et al., 2007" startWordPosition="147" endWordPosition="150"> a model that employs more linguistically rich features than a traditional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typ</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>A. Birch, M. Osborne, and P. Koehn. 2007. CCG supertags in factored statistical machine translation. In Proc. of the Second Workshop on SMT. 6Catalogue number LDC2006T13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>K Knight</author>
<author>K Yamada</author>
</authors>
<title>Syntaxbased language models for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of MT Summit IX.</booktitle>
<contexts>
<context position="2805" citStr="Charniak et al., 2003" startWordPosition="441" endWordPosition="444">3% relative) on a test set. 2 Approach Re-ranking tends to use expensive features of the entire source and target sentences, s and t, and alignments, a, to produce a score for the translation. We will call this scoring function 0(s, t, a). While 0(·) might capture quite a bit of linguistic information, it can be problematic to use this function for decoding directly. This is due to both the expense of computing it, and the difficulty in using it to guide the decoder’s search. For example, a choice of 0(·) that relies on a top-down parser is difficult to integrate into a left-to-right decoder (Charniak et al., 2003). Our idea is to use an expensive scoring function to guide the search for potential translations for part of a source sentence, S, even if translating all of it isn’t feasible. We can then provide these translations to the decoder, along with their scores, to incorporate them as it builds the complete translation of S. This differs from approaches such as (Och and Ney, 2004) because we generate new phrase pairs in isolation, rather than incorporating everything into the sentence-level decoder. The baseline system is the Moses phrase-based translation system (Koehn 301 Human Language Technolog</context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>E. Charniak, K. Knight, and K. Yamada. 2003. Syntaxbased language models for statistical machine translation. In Proceedings of MT Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
<author>K Knight</author>
<author>W Wang</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In NAACL ’09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Assoc. for Computational Linguistics.</booktitle>
<contexts>
<context position="1133" citStr="Chiang et al., 2009" startWordPosition="159" endWordPosition="162">itional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typically be out of reach during sentence-level decoding. In this paper,</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>D. Chiang, K. Knight, and W. Wang. 2009. 11,001 new features for statistical machine translation. In NAACL ’09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Assoc. for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpel</author>
<author>N A Smith</author>
</authors>
<title>Feature-rich translation by quasi-synchronous lattice parsing.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1088" citStr="Gimpel and Smith, 2009" startWordPosition="151" endWordPosition="154">s more linguistically rich features than a traditional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typically be out of reach d</context>
</contexts>
<marker>Gimpel, Smith, 2009</marker>
<rawString>K. Gimpel and N.A. Smith. 2009. Feature-rich translation by quasi-synchronous lattice parsing. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hasan</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Are very large nbest lists useful for SMT?</title>
<date>2007</date>
<booktitle>Proc. NAACL, Short paper,</booktitle>
<pages>57--60</pages>
<contexts>
<context position="1512" citStr="Hasan et al., 2007" startWordPosition="220" endWordPosition="223">h as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typically be out of reach during sentence-level decoding. In this paper, we describe a particular method of generating additional bilingual phrase pairs for a new source text, using what we call phrase prototypes, which are are learned from bilingual training data. Our goal is to generate improved translations of relatively short phrase pairs to provide the SMT decoder with better phrasal choices. We validate the idea through experiments on Arabic</context>
</contexts>
<marker>Hasan, Zens, Ney, 2007</marker>
<rawString>S. Hasan, R. Zens, and H. Ney. 2007. Are very large nbest lists useful for SMT? Proc. NAACL, Short paper, pages 57–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<contexts>
<context position="1111" citStr="Koehn and Hoang, 2007" startWordPosition="155" endWordPosition="158">ch features than a traditional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typically be out of reach during sentence-level de</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>P. Koehn and H. Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1,</booktitle>
<pages>54</pages>
<contexts>
<context position="5633" citStr="Koehn et al., 2003" startWordPosition="920" endWordPosition="923">we insist that unaligned words are always kept as their surface form. OPOS(s, t, a) assign a score based on the probability of the resulting prototypes; more likely prototypes should yield higher scores. We choose: OPOS(s, t, a) = p(5P, AP|TP) · p(TP, AP|5P) where 5P is the source prototype constructed from s, t, a. Similarly, TP and AP are the target and alignment prototypes, respectively. To compute OPOS(·), we must build a model for each of p(5P, AP|TP) and p(TP, AP|5P). To do this, we start with a corpus of aligned, POS-tagged bilingual text. We then find phrases that are consistent with (Koehn et al., 2003). As we extract these phrase pairs, we convert each into a phrase prototype by replacing surface forms with POS tags for all aligned words in the prototype. After we have processed the bilingual training text, we have collected a set of phrase prototypes and a count of how often each was observed. 2.2 Generating New Phrases To generate phrases, we scan through the source text to be translated, finding any span of source words that matches the source prototype of at least one phrase prototype. For each such phrase, and for each phrase prototype which it matches, we generate all target phrases w</context>
<context position="7201" citStr="Koehn et al., 2003" startWordPosition="1192" endWordPosition="1195">hrase that we generate, we must ensure that it matches the target prototype. We give each phrase to a POS tagger, and check the resulting tags against any tags in the target prototype. If there are no mismatches, then the phrase pair is retained for the phrase table, else it is discarded. In the latter case, OPOS(·) would assign this pair a score of zero. 2.3 Computing Phrase Weights In the Moses phrase table, each entry has four parameters: two lexical weights, and the two conditional phrase probabilities p(s|t) and p(t|s). While the lexical weights can be computed using the standard method (Koehn et al., 2003), estimating the conditional phrase probabilities is not straightforward for our approach because they are not observed in bilingual training data. Instead, we estimate the maximum conditional phrase probabilities that would be assigned by the sentence-level decoder for this phrase pair, as if it had generated the target string from the source string using the baseline phrase table2. To do this efficiently, we use some 1Since we required that all unaligned target words are kept as surface forms in the target prototype, this is sufficient. If we did not insist this, then we might be faced with </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, page 54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Annual meeting-Association for Computational Linguistics,</booktitle>
<volume>45</volume>
<pages>2</pages>
<contexts>
<context position="9063" citStr="Koehn et al., 2007" startWordPosition="1496" endWordPosition="1499">mental Setup The Linguistic Data Consortium Arabic-English corpus23 is used to train the baseline MT system (34K sentences, about one million words), and to learn phrase prototypes. The LDC multi-translation Arabic-English corpus (NIST2003)4 is used for tuning and testing; the tuning set consists of the first 500 sentences, and the test set consists of the next 500 sentences. The language model is a 4-gram model built from the English side of the parallel corpus, plus the English side of the wmt07 GermanEnglish and French-English news commentary data. The baseline translation system is Moses (Koehn et al., 2007), with the msd-bidirectional-fe reordering model. Evaluation is done using the BLEU (Papineni et al., 2001) metric with four references. All text is lowercased before evaluation; recasing is not used. We use the Stanford Arabic POS Tagging system, based on (Toutanova et al., 2003)5. The word-to-word dictionary that is used in the phrase generation step of our method is extracted from the highest-scoring translations for each source word in the baseline phrase table. For some closedclass words, we use a small, manually constructed dictionary to reduce the noise in the phrase table that exists f</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Annual meeting-Association for Computational Linguistics, volume 45, page 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="3183" citStr="Och and Ney, 2004" startWordPosition="508" endWordPosition="511">to both the expense of computing it, and the difficulty in using it to guide the decoder’s search. For example, a choice of 0(·) that relies on a top-down parser is difficult to integrate into a left-to-right decoder (Charniak et al., 2003). Our idea is to use an expensive scoring function to guide the search for potential translations for part of a source sentence, S, even if translating all of it isn’t feasible. We can then provide these translations to the decoder, along with their scores, to incorporate them as it builds the complete translation of S. This differs from approaches such as (Och and Ney, 2004) because we generate new phrase pairs in isolation, rather than incorporating everything into the sentence-level decoder. The baseline system is the Moses phrase-based translation system (Koehn 301 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 301–304, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics et al., 2007). 2.1 Description of Our Scoring Function For this work, we consider a scoring function based on part-of-speech (POS) tags, OPOS(·). It operates in two steps: it converts the source and targe</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>F. J. Och and H. Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 41st Annual Meeting on Assoc. for Computational Linguistics.</booktitle>
<contexts>
<context position="11621" citStr="Och, 2003" startWordPosition="1912" endWordPosition="1913">m support parameter does not affect the results noticeably. The results on the tuning set are seen in Figure 1. The BLEU score on the tuning set generally improves as the amount of bilingual training data is increased, even as the percentage of generated phrases approaches 100%. Manual inspection of the phrase pairs reveals that many are badly formed; this suggests that the language model is doing its job in filtering out disfluent phrases. Using the first 5,000 bilingual training sentences to train our model, we compare our method to the baseline moses system. Each system was tuned via MERT (Och, 2003) before running it on the test set. The tuned baseline system scores 38.45. Including our generated phrases improves this by 1.3 points to 39.75. This is a slightly smaller gain than exists in the tuning set experiment, due in part that we did not 303 run MERT for experiment shown in Figure 1. 5 Discussion As one might expect, generated phrases both help and hurt individual translations. A sentence that can be translated starting with the phrase “korea added that the syrian prime minister” is translated by the baseline system as “korean I foreign minister I added I that I the syrian”. While “t</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F.J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of the 41st Annual Meeting on Assoc. for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In Proc. of the 40th Annual Meeting of Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9170" citStr="Papineni et al., 2001" startWordPosition="1511" endWordPosition="1514">tem (34K sentences, about one million words), and to learn phrase prototypes. The LDC multi-translation Arabic-English corpus (NIST2003)4 is used for tuning and testing; the tuning set consists of the first 500 sentences, and the test set consists of the next 500 sentences. The language model is a 4-gram model built from the English side of the parallel corpus, plus the English side of the wmt07 GermanEnglish and French-English news commentary data. The baseline translation system is Moses (Koehn et al., 2007), with the msd-bidirectional-fe reordering model. Evaluation is done using the BLEU (Papineni et al., 2001) metric with four references. All text is lowercased before evaluation; recasing is not used. We use the Stanford Arabic POS Tagging system, based on (Toutanova et al., 2003)5. The word-to-word dictionary that is used in the phrase generation step of our method is extracted from the highest-scoring translations for each source word in the baseline phrase table. For some closedclass words, we use a small, manually constructed dictionary to reduce the noise in the phrase table that exists for very common words. We use this in place of a stand-alone dictionary to reduce the need for additional re</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. In Proc. of the 40th Annual Meeting of Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>A Sarkar</author>
<author>F J Och</author>
</authors>
<title>Discriminative reranking for machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Joint HLT and NAACL Conference (HLT 04),</booktitle>
<pages>177--184</pages>
<contexts>
<context position="1320" citStr="Shen et al., 2004" startWordPosition="187" endWordPosition="190">entence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding begins, using a richer model that would typically be out of reach during sentence-level decoding. In this paper, we describe a particular method of generating additional bilingual phrase pairs for a new source text, using what we call phrase prototypes, which are are learned from bilingual training</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>L. Shen, A. Sarkar, and F.J. Och. 2004. Discriminative reranking for machine translation. In Proceedings of the Joint HLT and NAACL Conference (HLT 04), pages 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C D Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology.</booktitle>
<contexts>
<context position="9344" citStr="Toutanova et al., 2003" startWordPosition="1540" endWordPosition="1543"> tuning set consists of the first 500 sentences, and the test set consists of the next 500 sentences. The language model is a 4-gram model built from the English side of the parallel corpus, plus the English side of the wmt07 GermanEnglish and French-English news commentary data. The baseline translation system is Moses (Koehn et al., 2007), with the msd-bidirectional-fe reordering model. Evaluation is done using the BLEU (Papineni et al., 2001) metric with four references. All text is lowercased before evaluation; recasing is not used. We use the Stanford Arabic POS Tagging system, based on (Toutanova et al., 2003)5. The word-to-word dictionary that is used in the phrase generation step of our method is extracted from the highest-scoring translations for each source word in the baseline phrase table. For some closedclass words, we use a small, manually constructed dictionary to reduce the noise in the phrase table that exists for very common words. We use this in place of a stand-alone dictionary to reduce the need for additional resources. 4 Experiments To see the effect on the BLEU score of the resulting sentence-level translation, we vary the amount of bilingual data used to build the phrase prototyp</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C. D. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>M McCord</author>
</authors>
<title>Improving a statistical mt system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1024" citStr="Xia and McCord, 2004" startWordPosition="139" endWordPosition="142">lation task is more constrained, we can use a model that employs more linguistically rich features than a traditional decoder. We have implemented an example of this approach. Experimental results suggest that the phrase pairs produced by our method are useful to the decoder, and lead to improved sentence translations. 1 Introduction Recently, there have been a number of successful attempts at improving phrase-based statistical machine translation by exploiting linguistic knowledge such as morphology, part-of-speech tags, and syntax. Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-toright on the target sentence. Traditionally, n-best rerankers (Shen et al., 2004) have applied expensive analysis after the translation process, on both the source and target side, though they suffer from being limited to whatever is on the n-best list (Hasan et al., 2007). We argue that it can be desirable to pre-translate parts of the source text before sentence-level decoding beg</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>F. Xia and M. McCord. 2004. Improving a statistical mt system with automatically learned rewrite patterns. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>