<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003133">
<title confidence="0.991505">
Hybrid Approach to User Intention Modeling for Dialog Simulation
</title>
<author confidence="0.997797">
Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Gary Geunbae Lee
</author>
<affiliation confidence="0.999924">
Department of Computer Science and Engineering
Pohang University of Science and Technology(POSTECH)
</affiliation>
<email confidence="0.984338">
{hugman, lcj80, getta, gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.997271" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999990263157895">
This paper proposes a novel user intention si-
mulation method which is a data-driven ap-
proach but able to integrate diverse user dis-
course knowledge together to simulate various
type of users. In Markov logic framework, lo-
gistic regression based data-driven user inten-
tion modeling is introduced, and human dialog
knowledge are designed into two layers such
as domain and discourse knowledge, then it is
integrated with the data-driven model in gen-
eration time. Cooperative, corrective and self-
directing discourse knowledge are designed
and integrated to mimic such type of users.
Experiments were carried out to investigate
the patterns of simulated users, and it turned
out that our approach was successful to gener-
ate user intention patterns which are not only
unseen in the training corpus and but also per-
sonalized in the designed direction.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999844153846154">
User simulation techniques are widely used for learn-
ing optimal dialog strategies in a statistical dialog
management framework and for automated evaluation
of spoken dialog systems. User simulation can be
layered into the user intention level and user surface
(utterance) level. This paper proposes a novel inten-
tion level user simulation technique.
In recent years, a data-driven user intention model-
ing is widely used since it is domain- and language
independent. However, the problem of data-driven
user intention simulation is the limitation of user pat-
terns. Usually, the response patterns from data-driven
simulated user tend to be limited to the training data.
Therefore, it is not easy to simulate unseen user inten-
tion patterns, which is quite important to evaluate or
learn optimal dialog policies. Another problem is poor
user type controllability in a data-driven method.
Sometimes, developers need to switch testers between
various type of users such as cooperative, uncoopera-
tive or novice user and so on to expose their dialog
system to various users.
For this, we introduce a novel data-driven user in-
tention simulation method which is powered by hu-
man dialog knowledge in Markov logic formulation
(Richardson and Domingos, 2006) to add diversity
and controllability to data-driven intention simulation.
</bodyText>
<sectionHeader confidence="0.999919" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999946545454546">
Data-driven intention modeling approach uses statis-
tical methods to generate the user intention given dis-
course information (history). The advantage of this
approach lies in its simplicity and in that it is domain-
and language independency. N-gram based approach-
es (Eckert et al., 1997, Levin et al., 2000) and other
approaches (Scheffler and Young, 2001, Pietquin and
Dutoit, 2006, Schatzmann et al., 2007) are introduced.
There has been some work on combining rules with
statistical models especially for system side dialog
management (Heeman, 2007, Henderson et al., 2008).
However, little prior research has tried to use both
knowledge and data-driven methods together in a sin-
gle framework especially for user intention simulation.
In this research, we introduce a novel data-driven
user intention modeling technique which can be di-
versified or personalized by integrating human dis-
course knowledge which is represented in first-order
logic in a single framework. In the framework, di-
verse type of user knowledge can be easily designed
and selectively integrated into data-driven user inten-
tion simulation.
</bodyText>
<sectionHeader confidence="0.958421" genericHeader="method">
3 Overall architecture
</sectionHeader>
<bodyText confidence="0.999903">
The overall architecture of our user simulator is
shown in Fig. 1. The user intention simulator accepts
the discourse circumstances with system intention as
input and generates the next user intention. The user
utterance simulator constructs a corresponding user
sentence to express the given user intention. The si-
mulated user sentence is fed to the automatic speech
recognition (ASR) channel simulator, which then adds
noises to the utterance. The noisy utterance is passed
to a dialog system which consists of spoken language
understanding (SLU) and dialog management (DM)
modules. In this research, the user utterance simulator
and ASR channel simulator are developed using the
method of (Jung et al., 2009).
</bodyText>
<page confidence="0.995573">
17
</page>
<note confidence="0.958073">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 17–20,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<figureCaption confidence="0.912153">
Fig. 1 Overall architecture of dialog simulation
</figureCaption>
<sectionHeader confidence="0.975264" genericHeader="method">
4 Markov logic
</sectionHeader>
<bodyText confidence="0.998791608695652">
Markov logic is a probabilistic extension of finite
first-order logic (Richardson and Domingos, 2006). A
Markov Logic Network (MLN) combines first-order
logic and probabilistic graphical models in a single
representation.
An MLN can be viewed as a template for construct-
ing Markov networks. From the above definition, the
probability distribution over possible worlds x speci-
fied by the ground Markov network is given by
where F is the number of formulas in the MLN and
ni(x) is the number of true groundings of Fi in x. As
formula weights increase, an MLN increasingly re-
sembles a purely logical KB, becoming equivalent to
one in the limit of all infinite weights. General algo-
rithms for inference and learning in Markov logic are
discussed in (Richardson and Domingos, 2006).
Since Markov logic is a first-order knowledge base
with a weight attached to each formula, it provides a
theoretically fine framework integrating a statistically
learned model with logically designed and inducted
human knowledge. So the framework can be used for
building up a hybrid user modeling with the advan-
tages of knowledge-based and data-driven models.
</bodyText>
<sectionHeader confidence="0.965618" genericHeader="method">
5 User intention modeling in Markov
logic
</sectionHeader>
<bodyText confidence="0.994020826086956">
The task of user intention simulation is to generate
subsequent user intentions given current discourse
circumstances. Therefore, user intention simulation
can be formulated in the probabilistic form
P(userIntention  |context).
In this research, we define the user intention state
userIntention = [dialog_act, main_goal, compo-
nent_slot], where dialog_act is a domain-independent
label of an utterance at the level of illocutionary force
(e.g. statement, request, wh_question) and main_goal
is the domain-specific user goal of an utterance (e.g.
give_something, tell_purpose). Component slots
represent domain-specific named-entities in the utter-
ance. For example, in the user intention state for the
utterance “I want to go to city hall” (Fig. 2), the com-
bination of each slot of semantic frame represents the
user intention symbol. In this example, the state sym-
bol is `request+search_loc+[loc_name]&apos;. Dialogs on
car navigation deal with support for the information
and selection of the desired destination.
The first-order language-based predicates which
are related with discourse context information and
with generating the next user intention are as follows:
</bodyText>
<listItem confidence="0.974624230769231">
• User intention simulation related predicates
GenerateUserIntention(context,userIntention)
• Discourse context related predicates
hasIntention(context, userIntention)
hasDialogAct(context, dialogAct)
hasMainGoal(context, mainGoal)
hasEntity(context, entity)
isFilledComponent(context,entity)
updatedEntity(contetx, entity)
hasNumDBResult(context, numDBResult)
hasSystemAct(context, systemAct)
hasSystemActAttr(context, sytemActAttr)
isSubTask(context, subTask)
</listItem>
<bodyText confidence="0.9924395">
For example, after the following fragment of dialog
for the car navigation domain,
</bodyText>
<equation confidence="0.943745">
User(01) : Where are Chinese restaurants?
// dialog_act=wh_question
// main_goal=search_loc
// named_entity[loc_keyword]=Chinese_restaurant
Sys(01) : There are Buchunsung and Idongbanjum in
Daeidong.
// system_act=inform
// targetactionattribute=name,address
</equation>
<bodyText confidence="0.995928272727273">
the discourse context which is passed to the user si-
mulator is illustrated in Fig. 3.
Notice that the context information is composed of
semantic frame (SF), discourse history (DH) and pre-
vious system intention (SI). `isFilledComponent&apos;
predicate indicates which component slots are filled
during the discourse. `updatedEntity&apos; predicate is
true if the corresponding named entity is newly up-
dated. `hasSystemAct&apos; and `hasSystemActAttr&apos;
predicate represent previous system intention and
mentioned attributes.
</bodyText>
<figure confidence="0.932718">
I want to go to city hall.
request
search_loc
component.[loc_name] cityhall
</figure>
<figureCaption confidence="0.9486305">
Fig. 2 Semantic frame for user intention simulation on
car navigation domain.
</figureCaption>
<equation confidence="0.985390916666667">
hasIntention(“ct_01”, “request+search_loc+loc_name”)
SF hasDialogAct(“ct_01”,”wh_question”)
hasMainGoal(“ct_01”, “search_loc”)
hasEntity(“ct_01”, “loc_keyword”)
isFilledComponent(“ct_01”, “loc_keyword)
!isFilledComponent(“ct_01”, “loc_address)
DH !isFilledComponent(“ct_01”, “loc_name”)
!isFilledComponent(“ct_01”, “route_type”)
updatedEntity(“ct_01”, “loc_keyword”)
hasNumDBResult(“ct_01”, “many”)
SI hasSystemAct(“ct_01”, “inform”)
hasSystemActAttr(“ct_01”, “address,name”)
</equation>
<figureCaption confidence="0.975672">
Fig. 3 Example of discourse context in car navigation domain.
SF=Semantic Frame, DH=Discourse History, SI=System Inten-
tion.
</figureCaption>
<bodyText confidence="0.493346333333333">
raw user utterance
dialog_act
main_goal
</bodyText>
<page confidence="0.966936">
18
</page>
<subsectionHeader confidence="0.984867">
5.1 Data-driven user intention modeling in
Markov logic
</subsectionHeader>
<bodyText confidence="0.9997532">
The formulas are defined between the predicates
which are related with discourse context information
and corresponding user intention. The formulas for
user intention modeling based on logistic regression
are as follows:
</bodyText>
<table confidence="0.520299076923077">
bct, pui, ui hasIntention(ct, pui)1
=&gt; GenerateUserIntention(ct, ui)
bct, da, ui hasDialogAct(ct, da) =&gt; GenerateUserIntention(ct,ui)
bct, mg, ui hasMainGoal(ct, mg) =&gt; GenerateUserIntention(ct,ui)
bct, en, ui hasEntity(ct, en) =&gt;GenerateUserIntention(ct,ui)
bct, en, ui isFilledComponent(ct,en)
_&gt; GenerateUserIntention(ct,ui)
bct, en, ui updatedEntity(ct, en) =&gt; GenerateUserIntention(ct,ui)
bct, dbr, ui hasNumDBResult(ct, dbr)
=&gt; GenerateUserIntention(ct, ui)
bct, sa, ui hasSystemAct(ct, sa) =&gt;GenerateUserIntention(ct, ui)
bct, attr, ui hasSystemActAttr(ct, attr)
=&gt; GenerateUserIntention(ct, ui)
</table>
<bodyText confidence="0.99900725">
The weights of each formula are estimated from
the data which contains the evidence (context) and
corresponding user intention of next turn (userInten-
tion).
</bodyText>
<subsectionHeader confidence="0.998149">
5.2 User knowledge
</subsectionHeader>
<bodyText confidence="0.999865888888889">
In this research, the user knowledge, which is used for
deciding user intention given discourse context, is
layered into two levels: domain knowledge and dis-
course knowledge. Domain- specific and dependent
knowledge is described in domain knowledge. Dis-
course knowledge is more general and abstracted
knowledge. It uses the domain knowledge as base
knowledge. The subtask which is one of domain
knowledge are defined as follows
</bodyText>
<listItem confidence="0.971703">
• Subtask related predicates
</listItem>
<equation confidence="0.989578">
subTaskHasIntention(subTask,userIntetion)
moveTo(subtask, subTask)
isCompletedSubTask (context, subTask)
isSubtask(context,subTask)
</equation>
<bodyText confidence="0.996382125">
`isSubTask&apos; implies which subtask corresponds
to the current context. `subTaskHasIntention&apos;
describes which subtask has which user intention.
`moveTo&apos; predicate implies the connection from sub-
task to subtask node.
Cooperative, corrective and self-directing discourse
knowledge is represented in Markov logic to mimic
following users.
</bodyText>
<listItem confidence="0.996086">
• Cooperative User: A user who is cooperative with a
system by answering what the system asked.
• Corrective User: A user who try to correct the mis-
behavior of system by jumping to or repeating spe-
cific subtask.
• Self-directing User: A user who tries to say what
he/she want to without considering system&apos;s sugges-
tion.
</listItem>
<bodyText confidence="0.8441701875">
Examples of discourse knowledge description for
three types of user are shown in Fig. 4.
1 ct: context, ui: user intention, pui: previous user intention, da:
dialog act, mg: main goal, en: entity, dbr:DB result, sa: system
action, attr: target attribute of system action
Both the formulas from data-driven model and
formulas from discourse knowledge are used for con-
structing MLN in generation time.
In inference, the discourse context related predi-
cates are given to MLN as true, then probabilities of
predicate ‘GenerateUserIntention’ over candi-
date user intention are calculated. One of example
evidence predicates was shown in Fig. 3. All of the
predicates of Fig. 3 are given to MLN as true. From
the network, the probability of P(userIntention  |con-
text) is calculated.
</bodyText>
<figure confidence="0.530811590909091">
Cooperative Knoweldge
// If system asks to specify an address explicitly, coop-
erative users would specify the address by jumping to
the address setting subtask.
V ct, st isSubTask(ct, st) ^
hasSytemAct(ct, “specify”) ^
hasSystemActAttr(ct, “address”)
=&gt; moveTo(st, “AddressSetting”)
Corrective Knowledge
// If the current subtask fails, corrective users would
repeat current subtask.
V ct, st isSubTask(ct, st)^
--i isCompletedSubTask(ct, st) ^
subTaskHasIntention(st, ui)
_&gt; GenerateUserIntention(ct,ui)
Self-directing Knowledge
// Self-directing users do not make an utterance which
is not relevant with the next subtask in their knowledge.
V ct, st isSubTask(ct, st) ^
--i moveTo(st, nt) ^
subTaskHasIntention(nt, ui)
=&gt; GenerateUserIntention(ct, ui)
</figure>
<figureCaption confidence="0.9872575">
Fig. 4 Example of cooperative, corrective and self-
directing discourse knowledge.
</figureCaption>
<figure confidence="0.8821118">
A B C D E F G H
Statistical model (S) O O O O O O O O
Cooperative(CPR) O O O O
Corrective(COR) O O O O
Self-directing(SFD) O O O O
</figure>
<figureCaption confidence="0.889754">
Fig. 5 Eight different users (A to H) according to the
combination of knowledge.
</figureCaption>
<sectionHeader confidence="0.998092" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999955882352941">
137 dialog examples from a real user and a dialog
system in the car navigation domain were used to
train the data-driven user intention simulator. The
SLU and DM are built in the same way of (Jung et al.,
2009). After the training, simulations collected 1000
dialog samples at each word error rate (WER) setting
(WER=0 to 40%). The simulator model can be varied
according to the combination of knowledge. We can
generate eight different simulated users from A to H
as Fig. 5.
The overall trend of simulated dialogs are ex-
amined by defining an average score function similar
to the reward score commonly used in reinforcement
learning-based dialog systems for measuring both a
cost and task success. We give 20 points for the suc-
cessful dialog state and penalize 1 point for each ac-
tion performed by the user to penalize longer dialogs.
</bodyText>
<page confidence="0.998172">
19
</page>
<bodyText confidence="0.999837710526316">
Fig. 6 shows that simulated user C which has cor-
rective knowledge with statistical model show signifi-
cantly different trend over the most of word error rate
settings. For the cooperative user (B), the difference is
not as large and not statistically significant. It can be
analyzed that the cooperative user behaviors are rela-
tively common patterns in human-machine dialog
corpus. So, these behaviors can be already learned in
statistical model (A).
Using more than two type of knowledge together
shows interesting result. Using cooperative know-
ledge with corrective knowledge together (E) shows
much different result than using each knowledge
alone (B and C). In the case of using self-directing
knowledge with cooperative knowledge (F), the aver-
age scores are partially increased against base line
scores. However, using corrective knowledge with
self-directing knowledge does not show different re-
sult. It can be thought that the corrective knowledge
and self-directing knowledge are working as contra-
dictory policy in deciding user intention. Three dis-
course knowledge combined user shows very interest-
ing result. H shows much higher improvement over
all simulated users, and the differences are significant
results at p &lt; 0.001.
To verify the proposed user simulation method can
simulate the unseen events, the unseen rates of units
were calculated. Fig. 7 shows the unseen unit rates of
intention sequence. The unseen rate of n-gram varies
according to the simulated user. Notice that simulated
user C, E and H generates higher unseen n-gram pat-
terns over all word error settings. These users com-
monly have corrective knowledge, and the patterns
seem to not be present in the corpus. But the unseen
patterns do not mean poor intention simulation. High-
er task completion rate of C, E and H imply that these
users actually generate corrective user response to
make a successful conversation.
</bodyText>
<sectionHeader confidence="0.998451" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999972461538461">
This paper presented a novel user intention simulation
method which is a data-driven approach but able to
integrate diverse user discourse knowledge together to
simulate various type of user. A logistic regression
model is used for the statistical user intention model
in Markov logic. Human dialog knowledge is sepa-
rated into domain and discourse knowledge, and co-
operative, corrective and self-directing discourse
knowledge are designed to mimic such type user. The
experiment results show that the proposed user inten-
tion simulation framework actually generates natural
and diverse user intention patterns what the developer
intended.
</bodyText>
<sectionHeader confidence="0.998007" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.959362833333333">
This research was supported by the MKE (Ministry of
Knowledge Economy), Korea, under the
ITRC(Information Technology Research Center) sup-
port program supervised by the IITA(Institute for In-
formation Technology Advancement) (IITA-2009-
C1090-0902-0045).
</bodyText>
<table confidence="0.995904944444444">
R(%) 0 10 20 30 40
model
A:S (base line) 14.22 9.13 5.55 1.33 -1.16
(0.00) (0.00) (0.00) (0.00) (0.00)
B:S+CPR 14.39 9.78 5.38 2.321 -1.00
(0.17) (0.65) (-0.17) (0.99) (0.16)
C:S+COR 14.611 10.91♠ 7.28♠ 2.62$ -0.81
(0.40) (1.78) (1.74) (1.30) (0.35)
D:S+SFD 15.70♠ 10.10$ 5.51 1.89 -0.96♠
(1.48) (0.97) (-0.04) (0.56) (0.20)
E:S+CPR+COR 14.75$ 10.93♠ 6.88$ 2.94♠ -1.061
(0.53) (1.79) (1.33) (1.61) (0.11)
F:S+CPR+SFD 15.75♠ 10.16$ 5.80 1.88 -0.03$
(1.54) (1.02) (0.26) (0.56) (1.13)
G:S+COR+SFD 14.39 9.18 5.04 1.63 -1.52
(0.17) (0.05) (-0.50) (0.31) (-0.36)
H:S+CPR+COR+SFD 15.70♠ 12.19♠ 9.20♠ 5.12♠ 1.32♠
(1.48) (3.05) (3.65) (3.80) (2.48)
</table>
<figureCaption confidence="0.92329075">
Fig. 6 Average scores of user intention models over used discourse
knowledge. The relative improvements against statistical models
are described between parentheses. Bold cells indicate the im-
provements are higher than 1.0.
</figureCaption>
<figure confidence="0.689683333333333">
1 : significantly different from the base line, p = 0.05,
$ : significantly different from the base line, p = 0.01,
� :significantly different from the base line, p &lt; 0.001
</figure>
<figureCaption confidence="0.9818245">
Fig. 7 Unseen user intention sequence rate and task com-
pletion rate over simulated users at word error rate of 10.
</figureCaption>
<sectionHeader confidence="0.996757" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999316142857143">
Eckert, W., Levin, E. and Pieraccini, R. 1997. User model-
ing for spoken dialogue system evaluation. Automatic
Speech Recognition and Understanding:80-87.
Heeman, P. 2007. Combining reinforcement learning with
information-state update rules. NAACL.
Henderson, J., Lemon, O. and Georgila, K. 2008. Hybrid
reinforcement/supervised learning of dialogue policies
from fixed data sets. Comput. Linguist., 34(4):487-511.
Jung, S., Lee, C., Kim, K. and Lee, G.G. 2009. Data-driven
user simulation for automated evaluation of spoken dialog
systems. Computer Speech &amp; Lan-
guage.doi:10.1016/j.csl.2009.03.002.
Levin, E., Pieraccini, R. and Eckert, W. 2000. A stochastic
model of human-machine interaction for learning dialog-
strategies. IEEE Transactions on Speech and Audio
Processing, 8(1):11-23.
Pietquin, O. and Dutoit, T. 2006. A Probabilistic Frame-
work for Dialog Simulation and Optimal Strategy Learn-
ing. IEEE Transactions on Audio, Speech and Language
Processing, 14(2):589-599.
Richardson, M. and Domingos, P. 2006. Markov logic net-
works. Machine Learning, 62(1):107-136.
Schatzmann, J., Thomson, B. and Young, S. 2007. Statistic-
al User Simulation with a Hidden Agenda. SIGDial.
Scheffler, K. and Young, S. 2001. Corpus-based dialogue
simulation for automatic strategy learning and evaluation.
NAACL Workshop on Adaptation in Dialogue Sys-
tems:64-70.
</reference>
<page confidence="0.994812">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.595956">
<title confidence="0.999805">Hybrid Approach to User Intention Modeling for Dialog Simulation</title>
<author confidence="0.998775">Sangkeun Jung</author>
<author confidence="0.998775">Cheongjae Lee</author>
<author confidence="0.998775">Kyungduk Kim</author>
<author confidence="0.998775">Gary Geunbae Lee</author>
<affiliation confidence="0.9698605">Department of Computer Science and Engineering Pohang University of Science and Technology(POSTECH)</affiliation>
<email confidence="0.686763">hugman@postech.ac.kr</email>
<email confidence="0.686763">lcj80@postech.ac.kr</email>
<email confidence="0.686763">getta@postech.ac.kr</email>
<email confidence="0.686763">gblee@postech.ac.kr</email>
<abstract confidence="0.99704005">This paper proposes a novel user intention simulation method which is a data-driven approach but able to integrate diverse user discourse knowledge together to simulate various type of users. In Markov logic framework, logistic regression based data-driven user intention modeling is introduced, and human dialog knowledge are designed into two layers such as domain and discourse knowledge, then it is integrated with the data-driven model in generation time. Cooperative, corrective and selfdirecting discourse knowledge are designed and integrated to mimic such type of users. Experiments were carried out to investigate the patterns of simulated users, and it turned out that our approach was successful to generate user intention patterns which are not only unseen in the training corpus and but also personalized in the designed direction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W Eckert</author>
<author>E Levin</author>
<author>R Pieraccini</author>
</authors>
<title>User modeling for spoken dialogue system evaluation. Automatic Speech Recognition and Understanding:80-87.</title>
<date>1997</date>
<contexts>
<context position="2759" citStr="Eckert et al., 1997" startWordPosition="418" endWordPosition="421">ice user and so on to expose their dialog system to various users. For this, we introduce a novel data-driven user intention simulation method which is powered by human dialog knowledge in Markov logic formulation (Richardson and Domingos, 2006) to add diversity and controllability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human d</context>
</contexts>
<marker>Eckert, Levin, Pieraccini, 1997</marker>
<rawString>Eckert, W., Levin, E. and Pieraccini, R. 1997. User modeling for spoken dialogue system evaluation. Automatic Speech Recognition and Understanding:80-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Heeman</author>
</authors>
<title>Combining reinforcement learning with information-state update rules.</title>
<date>2007</date>
<publisher>NAACL.</publisher>
<contexts>
<context position="3024" citStr="Heeman, 2007" startWordPosition="460" endWordPosition="461">ollability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user knowledge can be easily designed and selectively integrated into data-driven user intention simulation. 3 Overall architecture The overall arc</context>
</contexts>
<marker>Heeman, 2007</marker>
<rawString>Heeman, P. 2007. Combining reinforcement learning with information-state update rules. NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Henderson</author>
<author>O Lemon</author>
<author>K Georgila</author>
</authors>
<title>Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<pages>34--4</pages>
<contexts>
<context position="3049" citStr="Henderson et al., 2008" startWordPosition="462" endWordPosition="465">data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user knowledge can be easily designed and selectively integrated into data-driven user intention simulation. 3 Overall architecture The overall architecture of our user sim</context>
</contexts>
<marker>Henderson, Lemon, Georgila, 2008</marker>
<rawString>Henderson, J., Lemon, O. and Georgila, K. 2008. Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets. Comput. Linguist., 34(4):487-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jung</author>
<author>C Lee</author>
<author>K Kim</author>
<author>G G Lee</author>
</authors>
<title>Data-driven user simulation for automated evaluation of spoken dialog systems.</title>
<date>2009</date>
<journal>Computer Speech &amp; Language.doi:10.1016/j.csl.2009.03.002.</journal>
<contexts>
<context position="4320" citStr="Jung et al., 2009" startWordPosition="656" endWordPosition="659">or accepts the discourse circumstances with system intention as input and generates the next user intention. The user utterance simulator constructs a corresponding user sentence to express the given user intention. The simulated user sentence is fed to the automatic speech recognition (ASR) channel simulator, which then adds noises to the utterance. The noisy utterance is passed to a dialog system which consists of spoken language understanding (SLU) and dialog management (DM) modules. In this research, the user utterance simulator and ASR channel simulator are developed using the method of (Jung et al., 2009). 17 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 17–20, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Fig. 1 Overall architecture of dialog simulation 4 Markov logic Markov logic is a probabilistic extension of finite first-order logic (Richardson and Domingos, 2006). A Markov Logic Network (MLN) combines first-order logic and probabilistic graphical models in a single representation. An MLN can be viewed as a template for constructing Markov networks. From the above definition, the probability distribution over possible worlds x specified by the ground Markov ne</context>
<context position="13315" citStr="Jung et al., 2009" startWordPosition="1885" endWordPosition="1888">sSubTask(ct, st) ^ --i moveTo(st, nt) ^ subTaskHasIntention(nt, ui) =&gt; GenerateUserIntention(ct, ui) Fig. 4 Example of cooperative, corrective and selfdirecting discourse knowledge. A B C D E F G H Statistical model (S) O O O O O O O O Cooperative(CPR) O O O O Corrective(COR) O O O O Self-directing(SFD) O O O O Fig. 5 Eight different users (A to H) according to the combination of knowledge. 6 Experiments 137 dialog examples from a real user and a dialog system in the car navigation domain were used to train the data-driven user intention simulator. The SLU and DM are built in the same way of (Jung et al., 2009). After the training, simulations collected 1000 dialog samples at each word error rate (WER) setting (WER=0 to 40%). The simulator model can be varied according to the combination of knowledge. We can generate eight different simulated users from A to H as Fig. 5. The overall trend of simulated dialogs are examined by defining an average score function similar to the reward score commonly used in reinforcement learning-based dialog systems for measuring both a cost and task success. We give 20 points for the successful dialog state and penalize 1 point for each action performed by the user to</context>
</contexts>
<marker>Jung, Lee, Kim, Lee, 2009</marker>
<rawString>Jung, S., Lee, C., Kim, K. and Lee, G.G. 2009. Data-driven user simulation for automated evaluation of spoken dialog systems. Computer Speech &amp; Language.doi:10.1016/j.csl.2009.03.002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Levin</author>
<author>R Pieraccini</author>
<author>W Eckert</author>
</authors>
<title>A stochastic model of human-machine interaction for learning dialogstrategies.</title>
<date>2000</date>
<booktitle>IEEE Transactions on Speech and Audio Processing,</booktitle>
<pages>8--1</pages>
<contexts>
<context position="2780" citStr="Levin et al., 2000" startWordPosition="422" endWordPosition="425"> expose their dialog system to various users. For this, we introduce a novel data-driven user intention simulation method which is powered by human dialog knowledge in Markov logic formulation (Richardson and Domingos, 2006) to add diversity and controllability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge wh</context>
</contexts>
<marker>Levin, Pieraccini, Eckert, 2000</marker>
<rawString>Levin, E., Pieraccini, R. and Eckert, W. 2000. A stochastic model of human-machine interaction for learning dialogstrategies. IEEE Transactions on Speech and Audio Processing, 8(1):11-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Pietquin</author>
<author>T Dutoit</author>
</authors>
<title>A Probabilistic Framework for Dialog Simulation and Optimal Strategy Learning.</title>
<date>2006</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing,</journal>
<pages>14--2</pages>
<contexts>
<context position="2855" citStr="Pietquin and Dutoit, 2006" startWordPosition="433" endWordPosition="436">a novel data-driven user intention simulation method which is powered by human dialog knowledge in Markov logic formulation (Richardson and Domingos, 2006) to add diversity and controllability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the frame</context>
</contexts>
<marker>Pietquin, Dutoit, 2006</marker>
<rawString>Pietquin, O. and Dutoit, T. 2006. A Probabilistic Framework for Dialog Simulation and Optimal Strategy Learning. IEEE Transactions on Audio, Speech and Language Processing, 14(2):589-599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Richardson</author>
<author>P Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine Learning,</booktitle>
<pages>62--1</pages>
<contexts>
<context position="2385" citStr="Richardson and Domingos, 2006" startWordPosition="362" endWordPosition="365">ulated user tend to be limited to the training data. Therefore, it is not easy to simulate unseen user intention patterns, which is quite important to evaluate or learn optimal dialog policies. Another problem is poor user type controllability in a data-driven method. Sometimes, developers need to switch testers between various type of users such as cooperative, uncooperative or novice user and so on to expose their dialog system to various users. For this, we introduce a novel data-driven user intention simulation method which is powered by human dialog knowledge in Markov logic formulation (Richardson and Domingos, 2006) to add diversity and controllability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for syst</context>
<context position="4618" citStr="Richardson and Domingos, 2006" startWordPosition="700" endWordPosition="703"> (ASR) channel simulator, which then adds noises to the utterance. The noisy utterance is passed to a dialog system which consists of spoken language understanding (SLU) and dialog management (DM) modules. In this research, the user utterance simulator and ASR channel simulator are developed using the method of (Jung et al., 2009). 17 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 17–20, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Fig. 1 Overall architecture of dialog simulation 4 Markov logic Markov logic is a probabilistic extension of finite first-order logic (Richardson and Domingos, 2006). A Markov Logic Network (MLN) combines first-order logic and probabilistic graphical models in a single representation. An MLN can be viewed as a template for constructing Markov networks. From the above definition, the probability distribution over possible worlds x specified by the ground Markov network is given by where F is the number of formulas in the MLN and ni(x) is the number of true groundings of Fi in x. As formula weights increase, an MLN increasingly resembles a purely logical KB, becoming equivalent to one in the limit of all infinite weights. General algorithms for inference an</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Richardson, M. and Domingos, P. 2006. Markov logic networks. Machine Learning, 62(1):107-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>S Young</author>
</authors>
<title>Statistical User Simulation with a Hidden Agenda.</title>
<date>2007</date>
<booktitle>NAACL Workshop on Adaptation in Dialogue Systems:64-70.</booktitle>
<contexts>
<context position="2881" citStr="Schatzmann et al., 2007" startWordPosition="437" endWordPosition="440">tention simulation method which is powered by human dialog knowledge in Markov logic formulation (Richardson and Domingos, 2006) to add diversity and controllability to data-driven intention simulation. 2 Related work Data-driven intention modeling approach uses statistical methods to generate the user intention given discourse information (history). The advantage of this approach lies in its simplicity and in that it is domainand language independency. N-gram based approaches (Eckert et al., 1997, Levin et al., 2000) and other approaches (Scheffler and Young, 2001, Pietquin and Dutoit, 2006, Schatzmann et al., 2007) are introduced. There has been some work on combining rules with statistical models especially for system side dialog management (Heeman, 2007, Henderson et al., 2008). However, little prior research has tried to use both knowledge and data-driven methods together in a single framework especially for user intention simulation. In this research, we introduce a novel data-driven user intention modeling technique which can be diversified or personalized by integrating human discourse knowledge which is represented in first-order logic in a single framework. In the framework, diverse type of user</context>
</contexts>
<marker>Schatzmann, Thomson, Young, 2007</marker>
<rawString>Schatzmann, J., Thomson, B. and Young, S. 2007. Statistical User Simulation with a Hidden Agenda. SIGDial. Scheffler, K. and Young, S. 2001. Corpus-based dialogue simulation for automatic strategy learning and evaluation. NAACL Workshop on Adaptation in Dialogue Systems:64-70.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>