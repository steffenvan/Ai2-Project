<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012904">
<title confidence="0.974493">
UWB: Machine Learning Approach to Aspect-Based Sentiment Analysis
</title>
<author confidence="0.584614">
Tom´aˇs Brychcin
</author>
<affiliation confidence="0.8702325">
NTIS – New Technologies
for the Information Society,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.9574565">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.996893">
brychcin@kiv.zcu.cz
</email>
<author confidence="0.892998">
Michal Konkol
</author>
<affiliation confidence="0.93264125">
NTIS – New Technologies
for the Information Society,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.9577715">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.997473">
konkol@kiv.zcu.cz
</email>
<author confidence="0.988436">
Josef Steinberger
</author>
<affiliation confidence="0.992092">
Department of Computer
Science and Engineering,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.9553725">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.995298">
jstein@kiv.zcu.cz
</email>
<sectionHeader confidence="0.993738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922705882353">
This paper describes our system partici-
pating in the aspect-based sentiment anal-
ysis task of Semeval 2014. The goal
was to identify the aspects of given tar-
get entities and the sentiment expressed to-
wards each aspect. We firstly introduce
a system based on supervised machine
learning, which is strictly constrained and
uses the training data as the only source
of information. This system is then ex-
tended by unsupervised methods for latent
semantics discovery (LDA and semantic
spaces) as well as the approach based on
sentiment vocabularies. The evaluation
was done on two domains, restaurants and
laptops. We show that our approach leads
to very promising results.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943875">
The majority of current sentiment analysis ap-
proaches tries to detect the overall polarity of a
sentence (or a document) regardless of the target
entities (e.g. restaurants) and their aspects (e.g.
food, price). By contrast, the ABSA (aspect based
sentiment analysis) task is concerned with identi-
fying the aspects of given target entities and esti-
mating the sentiment polarity for each mentioned
aspect.
The aspect scenario can be decomposed into
two tasks: aspect extraction and aspect sentiment
classification (Liu, 2012).
The task of aspect extraction is to recognize
aspects of the entity and more generally can be
seen as an information extraction task. The ba-
sic approach is finding frequent nouns and noun
</bodyText>
<footnote confidence="0.9621548">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence de-
tails: http://creativecommons.org/licenses/
by/4.0/
</footnote>
<figureCaption confidence="0.885894636363636">
phrases (Liu et al., 2005; Blair-Goldensohn et
al., 2008; Moghaddam and Ester, 2010; Long et
al., 2010). Aspect extraction can be also seen as
a special case of the general information extrac-
tion problem. The most dominant methods are
based on sequential learning (e.g. HMM – Hidden
Markov Models (Rabiner, 2010) or CRF – Condi-
tional Random Fields (Lafferty et al., 2001)). An-
other group of methods use topic models (Mei et
al., 2007; Titov and McDonald, 2008; Blei et al.,
2003).
</figureCaption>
<bodyText confidence="0.999427909090909">
Aspect sentiment classification determines
whether the opinions on different aspects are
positive, negative, or neutral. While lexicon-based
approaches use a list of aspect-related sentiment
phrases as the core resource (Ding et al., 2008; Hu
and Liu, 2004), the key issue for learning methods
is to determine the scope of each sentiment
expression, i.e., whether it covers the aspect in
the sentence (Jiang et al., 2011; Boiy and Moens,
2009).
The most of the research in aspect-level senti-
ment analysis has been done in English, however,
there were some attempts to tackle the aspect-level
task in other languages (e.g. in Czech (Steinberger
et al., 2014)).
The rest of the article is organized as follows.
In Section 2, we summarize the ABSA shared task
(Pontiki et al., 2014). Then, we give a description
of our participating system (Section 3). In Section
4, we discuss our results in the task. We partic-
ipated with both the constrained and the uncon-
strained variants of the system.
</bodyText>
<sectionHeader confidence="0.972166" genericHeader="method">
2 The ABSA task
</sectionHeader>
<bodyText confidence="0.987800166666667">
Datasets consisting of customer reviews with
human-authored annotations identifying the men-
tioned aspects of the target entities and the senti-
ment polarity of each aspect were provided. The
experiments were run in two domains: restaurant
and laptop reviews.
</bodyText>
<page confidence="0.96454">
817
</page>
<note confidence="0.729639">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 817–822,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999707533333333">
Each team could submit two versions of sys-
tems – constrained and unconstrained. The con-
strained system uses only the training data and
other resources (such as lexicons) for training. The
unconstrained system can use additional data.
We use another definition of these types, which
is not against the rules. Our constrained systems
are based purely on ABSA training data, with-
out any external knowledge such as dictionaries or
rules. Our unconstrained systems use additional
dictionaries, rule-based extensions and unlabeled
data. From our point of view, hand-crafted dictio-
naries and rules are external knowledge and thus it
is the same as adding external data.
The task consists of the four subtasks.
</bodyText>
<subsectionHeader confidence="0.992319">
2.1 Subtask 1: Aspect term extraction
</subsectionHeader>
<bodyText confidence="0.995849833333333">
Given a set of sentences with pre-identified enti-
ties (restaurants or laptops), the task is to identify
the aspect terms present in the sentence and return
a list containing all the distinct aspect terms.
I liked the service and the staff, but not the food.
— {service, staff, food}
</bodyText>
<subsectionHeader confidence="0.999073">
2.2 Subtask 2: Aspect term polarity
</subsectionHeader>
<bodyText confidence="0.993998">
For a given set of aspect terms within a sentence,
the task is to determine the polarity of each aspect
term: positive, negative, neutral or conflict (i.e.,
both positive and negative).
I hated their fajitas, but their salads were great.
— {fajitas: negative, salads: positive}
</bodyText>
<subsectionHeader confidence="0.998925">
2.3 Subtask 3: Aspect category detection
</subsectionHeader>
<bodyText confidence="0.998911363636364">
Given a predefined set of aspect categories, the
task is to identify the aspect categories discussed
in a given sentence. Aspect categories are typi-
cally coarser than the aspect terms of Subtask 1,
and they do not necessarily occur as terms in the
given sentence.
For example, the following categories were de-
fined for the restaurants’ domain: food, service,
price, ambience and anecdotes/miscellaneous.
The restaurant was expensive, but the menu was
great. — {price, food}
</bodyText>
<subsectionHeader confidence="0.997495">
2.4 Subtask 4: Aspect category polarity
</subsectionHeader>
<bodyText confidence="0.9958714">
Given a set of pre-identified aspect categories, the
task is to determine the polarity (positive, nega-
tive, neutral or conflict) of each aspect category.
The restaurant was expensive, but the menu was
great. — {price: negative, food: positive}
</bodyText>
<sectionHeader confidence="0.954231" genericHeader="method">
3 System description
</sectionHeader>
<bodyText confidence="0.999287875">
We use machine learning approach to all subtasks.
For aspect term extraction we use CRF. For the
other three tasks we use the Maximum Entropy
classifier. We use the Brainy (Konkol, 2014) im-
plementation of these algorithms.
During the data preprocessing, we use simple
word tokenizer based on regular expressions. All
tokens are lowercased for tasks 2 and 4.
We will firstly describe all the features used in
this paper because the tasks share some of them.
These features are then referenced in the descrip-
tions of individual subtasks.
Words (W) – Word occurrence on a given posi-
tion in the context window.
Bag of Words (BoW) – Occurrence of a word in
a sentence (or context window).
Bigrams (B) – Bigram occurrence on a given po-
sition in the context window.
Bag of Bigrams (BoB) – Occurrence of a bigram
in a sentence (or context window).
Tf-idf – Term frequency–inverse document fre-
quency for all tokens in the sentence.
Learned Dictionary (LD) – Dictionary of terms
based on training data.
</bodyText>
<subsectionHeader confidence="0.678508">
Suffixes (S) – Suffix of a word (2-4 characters).
</subsectionHeader>
<bodyText confidence="0.9534235">
Sentiment Dictionary (SD) – Dictionary created
using semi-automatic triangulation method
(Steinberger et al., 2012). The score is nor-
malized.
Senti Wordnet (SW) – See (Baccianella et al.,
2010).
LDA – See Section 3.1.
Word Clusters (WC) – See Section 3.2. Cluster
occurrence on a given position in the context
window.
Bag of Clusters (BoC) – Same as word clusters,
but without information about position.
</bodyText>
<page confidence="0.988761">
818
</page>
<bodyText confidence="0.9999878125">
We use two features that are not in common
use in similar tasks – Latent Dirichlet Allocation
and word clusters based on semantic spaces. Both
these features use large amount of unlabeled data
to discover latent semantics. We downloaded the
restaurant reviews from http://opentable.
com. This corpus consists of 409,665 reviews
(documents) with about 27 million words. The
opentable corpus is used as the training data for
these features. Unfortunately, we did not find any
large corpus for laptop domain, thus presented un-
supervised features are used in restaurant domain
only.
We devote the following two subsections to de-
scribe these features. Then we introduce our ap-
proach to the individual tasks.
</bodyText>
<subsectionHeader confidence="0.99775">
3.1 Latent Dirichlet Allocation
</subsectionHeader>
<bodyText confidence="0.999963142857143">
The Latent Dirichlet Allocation (LDA) (Blei et al.,
2003) is a topic model that is assumed to provide
useful information for particular subtasks. We use
LDA implementation from the MALLET (McCal-
lum, 2002) software package. For each experi-
ment we always train the 400 topics LDA (no sig-
nificant difference was observed between different
numbers of topics) with 1,000 iterations of Gibbs
sampling. The hyperparameters of Dirichlet dis-
tributions were initially set to α = 50/K, where
K is the number of topics and Q = 0.1. This set-
ting is recommended by (Griffiths and Steyvers,
2004). The topic probabilities are directly used as
new features to the classifier.
</bodyText>
<subsectionHeader confidence="0.999438">
3.2 Word clusters
</subsectionHeader>
<bodyText confidence="0.9996920625">
We use same approach as presented in (Brychcin
and Konopik, 2014), where word clusters derived
from semantic spaces improved language model-
ing. As recommended by these authors, we use
COALS (Correlated Occurrence Analogue to Lex-
ical Semantics) (Rohde et al., 2004) and HAL
(Hyperspace Analogue to Language) (Lund and
Burgess, 1996) for representing the word mean-
ing and the Repeated Bisection algorithm for clus-
tering. Similar approach has been already used
for sentiment analysis in (Habernal and Brychcin,
2013) and (Brychcin and Habernal, 2013).
The parameters of semantic spaces are set as
follows. For both semantic spaces we use a four-
word context window (in both directions). HAL
uses a matrix consisting of 50,000 columns, which
keeps the largest amount of information. COALS
uses a matrix with only 14,000 columns (as rec-
ommended by the authors of the algorithm). The
SVD reduction was not used in our experiments.
Implementation of the HAL, COALS algo-
rithms is available in an open source package S-
Space (Jurgens and Stevens, 2010). For cluster-
ing, we use the implementation from the CLUTO
software package (Karypis, 2003). As a measure
of the similarity between two words, we use the
cosine similarity of word vectors.
For both semantic spaces the word vectors are
clustered into four different depths: 100, 500,
1,000, and 5,000 clusters (i.e. eight different clus-
ter sets). The occurrences of particular clusters
represent additional features to the classifiers.
</bodyText>
<subsectionHeader confidence="0.999085">
3.3 Aspect term extraction
</subsectionHeader>
<bodyText confidence="0.9999494">
Our approach for aspect term extraction is based
on Conditional Random Fields (CRF). The choice
was based on similarity with the named entity
recognition task, where CRF are regarded as the
current state of the art (Konkol and Konopik,
2013). We use the BIO model for representing as-
pect terms (Ramshaw and Marcus, 1999).
The constrained feature set consists of: W, BoW,
B, LD, S. It is extended by WC for the uncon-
strained case.
</bodyText>
<subsectionHeader confidence="0.992683">
3.4 Aspect term polarity
</subsectionHeader>
<bodyText confidence="0.999997733333333">
During the detection of the aspect term polarities,
the words affecting the sentiment of the aspect
term are assumed to be close in most of cases.
Thus we use a context window of 10 words in both
directions around the target aspect term. We as-
sume the further the word or bigram is from the
target aspect term, the lower impact it has on the
polarity label. To model this assumption we use
a weight for each word and bigram feature taken
from the Gaussian distribution according to the
distance from the aspect term. The mean is set
to 0 and the variance is optimized on training data.
As a feature set for the constrained approach we
use only BoW, BoB and for the unconstrained ap-
proach we use BoC, SD, SW above that.
</bodyText>
<subsectionHeader confidence="0.987237">
3.5 Aspect category detection
</subsectionHeader>
<bodyText confidence="0.999825142857143">
Aspect category detection is based on a set of bi-
nary Maximum Entropy classifiers, one for each
class. The final decision is simply assembled from
decisions of individual classifiers.
For this task we use BoW, Tf-Idf for the con-
strained approach and add LDA, BoC for uncon-
strained approach.
</bodyText>
<page confidence="0.998164">
819
</page>
<table confidence="0.9997345625">
Team Const. Rank P[%] R[%] F1[%] Rank ACC[%]
Best – 1. 85.35 82.71 84.01 1. 80.95
UWB U 7. 82.70 76.28 79.36 4. 77.69
UWB C 12. 83.28 70.28 76.23 12. 72.13
Average – 14-15. 76.74 67.26 70.78 18. 69.15
Semeval Baseline – – – – 47.15 64.28
Best – 1. 84.80 66.51 74.55 1. 70.49
UWB U – – – – 4. 66.67
UWB C 14. 77.33 49.54 60.39 10. 62.54
Average – 14. 68.97 50.45 56.20 16. 59.01
Semeval Baseline – – – – 35.64 51.07
Best – 1. 91.04 86.24 87.58 1. 82.92
UWB U 4. 84.36 78.93 81.55 8. 72.78
UWB C 5. 85.09 77.37 81.04 9. 72.78
Average – 11. 76.00 72.26 73.79 12-13. 69.51
Semeval Baseline – – – – 63.89 – 65.66
</table>
<tableCaption confidence="0.6267745">
Table 1: Comparison of our constrained (C) and unconstrained (U) system with Semeval baseline, best
and average results. P, R, and F1 denote the precision, recall and F-measure, respectively, used for
measuring aspect term and category detection. ACC denotes the accuracy, used for measuring aspect
term and category sentiment polarity detection.
</tableCaption>
<figure confidence="0.9959468">
Restaurants
Aspect terms
Laptops
Aspect
categories
</figure>
<subsectionHeader confidence="0.964893">
3.6 Aspect category polarity
</subsectionHeader>
<bodyText confidence="0.9999212">
For this task we always take the whole sentence
into account. We cannot take a limited window
as we do not know where exactly the category is
mentioned in the sentence. Moreover, it can be at
several positions. To distinguish between differ-
ent categories we again use standalone Maximum
Entropy classifier for each category.
The constrained feature set consists of: BoW,
BoB, Tf-Idf. It is extended by BoC, LDA, SD, SW
for the unconstrained case.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.9999436">
The ABSA task was a competition between re-
search teams from around the world. There were
21 to 32 submitted systems for individual tasks.
We have submitted both constrained (no ex-
ternal knowledge, dictionaries or rules) and un-
constrained systems for all tasks, except uncon-
strained system for aspect term extraction in the
laptops domain.
Table 1 shows results of our systems (UWB)
and compares them with the best and average sys-
tems as well as with the Semeval baseline. The
average system is not any particular system. It is
represented by average rank and metrics (metrics
are averaged separately).
Our systems performed quite well. In all
tasks, we outperform the Semeval baseline sys-
tem. Moreover, we are always above average (F-
measure and accuracy) in all tasks. We were three
times in the fourth place and our unconstrained
systems were always in top ten.
Table 2 presents the 10-fold cross-validation re-
sults on restaurant training data. We can clearly
see, that any of our extension (LDA, clusters, sen-
timent vocabularies) brings at least some improve-
ment.
</bodyText>
<sectionHeader confidence="0.993859" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999916928571429">
This paper covers our participation in the ABSA
task of Semeval 2014. The ABSA task consists
of 4 subtasks. For each subtask we propose both
constrained (no external knowledge) and uncon-
strained approach. The constrained versions of
our system are based purely on machine learning
techniques. The unconstrained versions extend the
constrained feature set by LDA, semantic spaces
and sentiment dictionaries.
The proposed approaches achieved very good
results. The constrained versions were always
above average, often by a large margin. The un-
constrained versions were ranked among the best
systems.
</bodyText>
<page confidence="0.990349">
820
</page>
<table confidence="0.972857130434783">
P[%] R[%] Fl[%]
Constrained 68.72 82.14 74.83
Constrained + WC 76.77 82.51 79.53
(a) Aspect term extraction
P[%] R[%] Fl[%]
Constrained 74.56 80.69 77.51
Constrained + LDA 75.96 81.94 78.84
Constrained + BoC 77.01 81.42 79.16
All 77.28 81.62 79.39
(c) Aspect category extraction
ACC[%]
Constrained 65.91
Constrained+BoC 70.05
Constrained+SD+SW 68.13
All 71.02
(b) Aspect term polarity
ACC[%]
Constrained 66.69
Constrained+LDA 67.85
Constrained+BoC 68.61
Constrained+SD+SW 69.28
All 70.20
(d) Aspect category polarity
</table>
<tableCaption confidence="0.971857">
Table 2: 10 fold cross-validation results on the restaurants training data for individual features. P, R,
</tableCaption>
<bodyText confidence="0.794009">
and Fi denote the precision, recall and F-measure, respectively, used for measuring aspect term and
category detection. ACC denotes the accuracy, used for measuring aspect term and category sentiment
polarity detection.
</bodyText>
<sectionHeader confidence="0.97114" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998742875">
This work was supported by grant no. SGS-
2013-029 Advanced computing and information
systems, by the European Regional Development
Fund (ERDF) and by project “NTIS - New Tech-
nologies for Information Society”, European Cen-
tre of Excellence, CZ.1.05/1.1.00/02.0090, and by
project MediaGist, EU’s FP7 People Programme
(Marie Curie Actions), no. 630786.
</bodyText>
<sectionHeader confidence="0.992123" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997788442307692">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining.
In Nicoletta Calzolari (Conference Chair), Khalid
Choukri, Bente Maegaard, Joseph Mariani, Jan
Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh Interna-
tional Conference on Language Resources and Eval-
uation (LREC’10), Valletta, Malta, may. European
Language Resources Association (ELRA).
Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDon-
ald, Tyler Neylon, George Reis, and Jeff Reynar.
2008. Building a sentiment summarizer for lo-
cal service reviews. In Proceedings of WWW-2008
workshop on NLP in the Information Explosion Era.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Erik Boiy and Marie-Francine Moens. 2009. A
machine learning approach to sentiment analysis
in multilingual web texts. Information retrieval,
12(5):526–558.
Tom´aˇs Brychcfn and Ivan Habernal. 2013. Un-
supervised improving of sentiment analysis using
global target context. In Proceedings of the In-
ternational Conference Recent Advances in Natu-
ral Language Processing RANLP 2013, pages 122–
128, Hissar, Bulgaria, September. INCOMA Ltd.
Shoumen, BULGARIA.
Tom´aˇs Brychcfn and Miloslav Konopfk. 2014. Seman-
tic spaces for improving language modeling. Com-
puter Speech &amp; Language, 28(1):192 – 209.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In Proceedings of the Conference on Web Search and
Web Data Mining.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences of the United States of Amer-
ica, 101(Suppl 1):5228–5235, April.
Ivan Habernal and Tom´aˇs Brychcfn. 2013. Semantic
spaces for sentiment analysis. In Text, Speech and
Dialogue, volume 8082 of Lecture Notes in Com-
puter Science, pages 482–489, Berlin Heidelberg.
Springer.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
</reference>
<page confidence="0.991495">
821
</page>
<reference confidence="0.998637790697674">
timent classification. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics.
David Jurgens and Keith Stevens. 2010. The s-space
package: An open source package for word space
models. In In Proceedings of the ACL 2010 System
Demonstrations.
George Karypis. 2003. Cluto - a clustering toolkit.
Michal Konkol and Miloslav Konopfk. 2013. Crf-
based czech named entity recognizer and consolida-
tion of czech ner research. In Ivan Habernal and
V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dia-
logue, volume 8082 of Lecture Notes in Computer
Science, pages 153–160. Springer Berlin Heidel-
berg.
Michal Konkol. 2014. Brainy: A machine learn-
ing library. In Leszek Rutkowski, Marcin Ko-
rytkowski, Rafa Scherer, Ryszard Tadeusiewicz,
Lotfi A. Zadeh, and Jacek M. Zurada, editors, Artifi-
cial Intelligence and Soft Computing, volume 8468
of Lecture Notes in Computer Science. Springer
Berlin Heidelberg.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of International Con-
ference on Machine Learning.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: Analyzing and comparing opin-
ions on the web. In Proceedings of International
Conference on World Wide Web.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool Publishers.
Chong Long, Jie Zhang, and Xiaoyan Zhu. 2010. A
review selection approach for accurate feature rating
estimation. In Proceedings of Coling 2010: Poster
Volume.
Kevin Lund and Curt Burgess. 1996. Producing
high-dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods Instru-
ments and Computers, 28(2):203–208.
Andrew Kachites McCallum. 2002. Mallet: A ma-
chine learning for language toolkit.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of International Conference on World
Wide Web.
Samaneh Moghaddam and Martin Ester. 2010. Opin-
ion digger: an unsupervised opinion miner from
unstructured product reviews. In Proceeding of
the ACM conference on Information and knowledge
management.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect based sentiment analysis. In Proceedings of
the International Workshop on Semantic Evaluation
(SemEval 2014), Dublin, Ireland.
Lawrence Rabiner. 2010. A tutorial on hidden markov
models and selected applications in speech recogni-
tion. In Proceedings of the IEEE, pages 257–286.
Lance A Ramshaw and Mitchell P Marcus. 1999. Text
chunking using transformation-based learning. In
Natural language processing using very large cor-
pora, pages 157–176. Springer.
Douglas L. T. Rohde, Laura M. Gonnerman, and
David C. Plaut. 2004. An improved method for
deriving word meaning from lexical co-occurrence.
Cognitive Psychology, 7:573–605.
Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,
Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova,
Ralf Steinberger, Hristo Tanev, Silvia Vzquez, and
Vanni Zavarella. 2012. Creating sentiment dictio-
naries via triangulation. Decision Support Systems,
53(4):689 – 694.
Josef Steinberger, Tom´a&amp;quot;s Brychcfn, and Michal
Konkol. 2014. Aspect-level sentiment analysis
in czech. In Proceedings of the 5th Workshop on
Computational Approaches to Subjectivity, Senti-
ment and Social Media Analysis, Baltimore, USA,
June. Association for Computational Linguistics.
Ivan Titov and Ryan McDonald. 2008. Modeling on-
line reviews with multi-grain topic models. In Pro-
ceedings of International Conference on World Wide
Web.
</reference>
<page confidence="0.997995">
822
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001122">
<title confidence="0.89189775">UWB: Machine Learning Approach to Aspect-Based Sentiment Analysis Tom´aˇs NTIS – New for the Information</title>
<affiliation confidence="0.92895">Faculty of Applied University of West</affiliation>
<address confidence="0.371202">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.761762">brychcin@kiv.zcu.cz</email>
<author confidence="0.82297">Michal</author>
<affiliation confidence="0.66588725">NTIS – New for the Information Faculty of Applied University of West</affiliation>
<address confidence="0.3844515">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.806269">konkol@kiv.zcu.cz</email>
<author confidence="0.970261">Josef</author>
<affiliation confidence="0.998832">Department of Science and Faculty of Applied University of West</affiliation>
<address confidence="0.4429745">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.91401">jstein@kiv.zcu.cz</email>
<abstract confidence="0.999657611111111">This paper describes our system participating in the aspect-based sentiment analysis task of Semeval 2014. The goal was to identify the aspects of given target entities and the sentiment expressed towards each aspect. We firstly introduce a system based on supervised machine learning, which is strictly constrained and uses the training data as the only source of information. This system is then extended by unsupervised methods for latent semantics discovery (LDA and semantic spaces) as well as the approach based on sentiment vocabularies. The evaluation was done on two domains, restaurants and laptops. We show that our approach leads to very promising results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors,</editor>
<location>Valletta, Malta,</location>
<contexts>
<context position="7529" citStr="Baccianella et al., 2010" startWordPosition="1191" endWordPosition="1194">of Words (BoW) – Occurrence of a word in a sentence (or context window). Bigrams (B) – Bigram occurrence on a given position in the context window. Bag of Bigrams (BoB) – Occurrence of a bigram in a sentence (or context window). Tf-idf – Term frequency–inverse document frequency for all tokens in the sentence. Learned Dictionary (LD) – Dictionary of terms based on training data. Suffixes (S) – Suffix of a word (2-4 characters). Sentiment Dictionary (SD) – Dictionary created using semi-automatic triangulation method (Steinberger et al., 2012). The score is normalized. Senti Wordnet (SW) – See (Baccianella et al., 2010). LDA – See Section 3.1. Word Clusters (WC) – See Section 3.2. Cluster occurrence on a given position in the context window. Bag of Clusters (BoC) – Same as word clusters, but without information about position. 818 We use two features that are not in common use in similar tasks – Latent Dirichlet Allocation and word clusters based on semantic spaces. Both these features use large amount of unlabeled data to discover latent semantics. We downloaded the restaurant reviews from http://opentable. com. This corpus consists of 409,665 reviews (documents) with about 27 million words. The opentable c</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
<author>Tyler Neylon</author>
<author>George Reis</author>
<author>Jeff Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</booktitle>
<contexts>
<context position="2307" citStr="Blair-Goldensohn et al., 2008" startWordPosition="342" endWordPosition="345"> the sentiment polarity for each mentioned aspect. The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). The task of aspect extraction is to recognize aspects of the entity and more generally can be seen as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-re</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, Reynar, 2008</marker>
<rawString>Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George Reis, and Jeff Reynar. 2008. Building a sentiment summarizer for local service reviews. In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="2730" citStr="Blei et al., 2003" startWordPosition="415" endWordPosition="418">al Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task i</context>
<context position="8537" citStr="Blei et al., 2003" startWordPosition="1353" endWordPosition="1356"> of unlabeled data to discover latent semantics. We downloaded the restaurant reviews from http://opentable. com. This corpus consists of 409,665 reviews (documents) with about 27 million words. The opentable corpus is used as the training data for these features. Unfortunately, we did not find any large corpus for laptop domain, thus presented unsupervised features are used in restaurant domain only. We devote the following two subsections to describe these features. Then we introduce our approach to the individual tasks. 3.1 Latent Dirichlet Allocation The Latent Dirichlet Allocation (LDA) (Blei et al., 2003) is a topic model that is assumed to provide useful information for particular subtasks. We use LDA implementation from the MALLET (McCallum, 2002) software package. For each experiment we always train the 400 topics LDA (no significant difference was observed between different numbers of topics) with 1,000 iterations of Gibbs sampling. The hyperparameters of Dirichlet distributions were initially set to α = 50/K, where K is the number of topics and Q = 0.1. This setting is recommended by (Griffiths and Steyvers, 2004). The topic probabilities are directly used as new features to the classifie</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Boiy</author>
<author>Marie-Francine Moens</author>
</authors>
<title>A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval,</title>
<date>2009</date>
<pages>12--5</pages>
<contexts>
<context position="3175" citStr="Boiy and Moens, 2009" startWordPosition="484" endWordPosition="487">er, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (Section 3). In Section 4, we discuss our results in the task. We participated with both the constrained and the unconstrained variants of the system. 2 The ABSA task Datasets consisting of customer reviews</context>
</contexts>
<marker>Boiy, Moens, 2009</marker>
<rawString>Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval, 12(5):526–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Brychcfn</author>
<author>Ivan Habernal</author>
</authors>
<title>Unsupervised improving of sentiment analysis using global target context.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013,</booktitle>
<pages>122--128</pages>
<publisher>INCOMA Ltd. Shoumen, BULGARIA.</publisher>
<location>Hissar, Bulgaria,</location>
<marker>Brychcfn, Habernal, 2013</marker>
<rawString>Tom´aˇs Brychcfn and Ivan Habernal. 2013. Unsupervised improving of sentiment analysis using global target context. In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013, pages 122– 128, Hissar, Bulgaria, September. INCOMA Ltd. Shoumen, BULGARIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Brychcfn</author>
<author>Miloslav Konopfk</author>
</authors>
<title>Semantic spaces for improving language modeling.</title>
<date>2014</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>209</pages>
<marker>Brychcfn, Konopfk, 2014</marker>
<rawString>Tom´aˇs Brychcfn and Miloslav Konopfk. 2014. Semantic spaces for improving language modeling. Computer Speech &amp; Language, 28(1):192 – 209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Web Search and Web Data Mining.</booktitle>
<contexts>
<context position="2970" citStr="Ding et al., 2008" startWordPosition="448" endWordPosition="451">). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the Conference on Web Search and Web Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America, 101(Suppl 1):5228–5235,</booktitle>
<contexts>
<context position="9061" citStr="Griffiths and Steyvers, 2004" startWordPosition="1441" endWordPosition="1444">dividual tasks. 3.1 Latent Dirichlet Allocation The Latent Dirichlet Allocation (LDA) (Blei et al., 2003) is a topic model that is assumed to provide useful information for particular subtasks. We use LDA implementation from the MALLET (McCallum, 2002) software package. For each experiment we always train the 400 topics LDA (no significant difference was observed between different numbers of topics) with 1,000 iterations of Gibbs sampling. The hyperparameters of Dirichlet distributions were initially set to α = 50/K, where K is the number of topics and Q = 0.1. This setting is recommended by (Griffiths and Steyvers, 2004). The topic probabilities are directly used as new features to the classifier. 3.2 Word clusters We use same approach as presented in (Brychcin and Konopik, 2014), where word clusters derived from semantic spaces improved language modeling. As recommended by these authors, we use COALS (Correlated Occurrence Analogue to Lexical Semantics) (Rohde et al., 2004) and HAL (Hyperspace Analogue to Language) (Lund and Burgess, 1996) for representing the word meaning and the Repeated Bisection algorithm for clustering. Similar approach has been already used for sentiment analysis in (Habernal and Brych</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences of the United States of America, 101(Suppl 1):5228–5235, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Habernal</author>
<author>Tom´aˇs Brychcfn</author>
</authors>
<title>Semantic spaces for sentiment analysis.</title>
<date>2013</date>
<booktitle>In Text, Speech and Dialogue,</booktitle>
<volume>8082</volume>
<pages>482--489</pages>
<publisher>Springer.</publisher>
<location>Berlin Heidelberg.</location>
<marker>Habernal, Brychcfn, 2013</marker>
<rawString>Ivan Habernal and Tom´aˇs Brychcfn. 2013. Semantic spaces for sentiment analysis. In Text, Speech and Dialogue, volume 8082 of Lecture Notes in Computer Science, pages 482–489, Berlin Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2989" citStr="Hu and Liu, 2004" startWordPosition="452" endWordPosition="455">n can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (Section 3). In Sect</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3152" citStr="Jiang et al., 2011" startWordPosition="480" endWordPosition="483">Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (Section 3). In Section 4, we discuss our results in the task. We participated with both the constrained and the unconstrained variants of the system. 2 The ABSA task Datasets consist</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Jurgens</author>
<author>Keith Stevens</author>
</authors>
<title>The s-space package: An open source package for word space models. In</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations.</booktitle>
<contexts>
<context position="10199" citStr="Jurgens and Stevens, 2010" startWordPosition="1624" endWordPosition="1627">ng. Similar approach has been already used for sentiment analysis in (Habernal and Brychcin, 2013) and (Brychcin and Habernal, 2013). The parameters of semantic spaces are set as follows. For both semantic spaces we use a fourword context window (in both directions). HAL uses a matrix consisting of 50,000 columns, which keeps the largest amount of information. COALS uses a matrix with only 14,000 columns (as recommended by the authors of the algorithm). The SVD reduction was not used in our experiments. Implementation of the HAL, COALS algorithms is available in an open source package SSpace (Jurgens and Stevens, 2010). For clustering, we use the implementation from the CLUTO software package (Karypis, 2003). As a measure of the similarity between two words, we use the cosine similarity of word vectors. For both semantic spaces the word vectors are clustered into four different depths: 100, 500, 1,000, and 5,000 clusters (i.e. eight different cluster sets). The occurrences of particular clusters represent additional features to the classifiers. 3.3 Aspect term extraction Our approach for aspect term extraction is based on Conditional Random Fields (CRF). The choice was based on similarity with the named ent</context>
</contexts>
<marker>Jurgens, Stevens, 2010</marker>
<rawString>David Jurgens and Keith Stevens. 2010. The s-space package: An open source package for word space models. In In Proceedings of the ACL 2010 System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Karypis</author>
</authors>
<title>Cluto - a clustering toolkit.</title>
<date>2003</date>
<contexts>
<context position="10290" citStr="Karypis, 2003" startWordPosition="1640" endWordPosition="1641">(Brychcin and Habernal, 2013). The parameters of semantic spaces are set as follows. For both semantic spaces we use a fourword context window (in both directions). HAL uses a matrix consisting of 50,000 columns, which keeps the largest amount of information. COALS uses a matrix with only 14,000 columns (as recommended by the authors of the algorithm). The SVD reduction was not used in our experiments. Implementation of the HAL, COALS algorithms is available in an open source package SSpace (Jurgens and Stevens, 2010). For clustering, we use the implementation from the CLUTO software package (Karypis, 2003). As a measure of the similarity between two words, we use the cosine similarity of word vectors. For both semantic spaces the word vectors are clustered into four different depths: 100, 500, 1,000, and 5,000 clusters (i.e. eight different cluster sets). The occurrences of particular clusters represent additional features to the classifiers. 3.3 Aspect term extraction Our approach for aspect term extraction is based on Conditional Random Fields (CRF). The choice was based on similarity with the named entity recognition task, where CRF are regarded as the current state of the art (Konkol and Ko</context>
</contexts>
<marker>Karypis, 2003</marker>
<rawString>George Karypis. 2003. Cluto - a clustering toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Konkol</author>
<author>Miloslav Konopfk</author>
</authors>
<title>Crfbased czech named entity recognizer and consolidation of czech ner research.</title>
<date>2013</date>
<booktitle>In Ivan Habernal and V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dialogue,</booktitle>
<volume>8082</volume>
<pages>153--160</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Konkol, Konopfk, 2013</marker>
<rawString>Michal Konkol and Miloslav Konopfk. 2013. Crfbased czech named entity recognizer and consolidation of czech ner research. In Ivan Habernal and V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dialogue, volume 8082 of Lecture Notes in Computer Science, pages 153–160. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Konkol</author>
</authors>
<title>Brainy: A machine learning library.</title>
<date>2014</date>
<booktitle>Artificial Intelligence and Soft Computing,</booktitle>
<volume>8468</volume>
<editor>In Leszek Rutkowski, Marcin Korytkowski, Rafa Scherer, Ryszard Tadeusiewicz, Lotfi A. Zadeh, and Jacek M. Zurada, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="6479" citStr="Konkol, 2014" startWordPosition="1017" endWordPosition="1018">rvice, price, ambience and anecdotes/miscellaneous. The restaurant was expensive, but the menu was great. — {price, food} 2.4 Subtask 4: Aspect category polarity Given a set of pre-identified aspect categories, the task is to determine the polarity (positive, negative, neutral or conflict) of each aspect category. The restaurant was expensive, but the menu was great. — {price: negative, food: positive} 3 System description We use machine learning approach to all subtasks. For aspect term extraction we use CRF. For the other three tasks we use the Maximum Entropy classifier. We use the Brainy (Konkol, 2014) implementation of these algorithms. During the data preprocessing, we use simple word tokenizer based on regular expressions. All tokens are lowercased for tasks 2 and 4. We will firstly describe all the features used in this paper because the tasks share some of them. These features are then referenced in the descriptions of individual subtasks. Words (W) – Word occurrence on a given position in the context window. Bag of Words (BoW) – Occurrence of a word in a sentence (or context window). Bigrams (B) – Bigram occurrence on a given position in the context window. Bag of Bigrams (BoB) – Occu</context>
</contexts>
<marker>Konkol, 2014</marker>
<rawString>Michal Konkol. 2014. Brainy: A machine learning library. In Leszek Rutkowski, Marcin Korytkowski, Rafa Scherer, Ryszard Tadeusiewicz, Lotfi A. Zadeh, and Jacek M. Zurada, editors, Artificial Intelligence and Soft Computing, volume 8468 of Lecture Notes in Computer Science. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proceedings of International Conference on Machine Learning.</booktitle>
<contexts>
<context position="2622" citStr="Lafferty et al., 2001" startWordPosition="395" endWordPosition="398">ch is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sent</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: Analyzing and comparing opinions on the web. In</title>
<date>2005</date>
<booktitle>Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="2276" citStr="Liu et al., 2005" startWordPosition="338" endWordPosition="341">ies and estimating the sentiment polarity for each mentioned aspect. The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). The task of aspect extraction is to recognize aspects of the entity and more generally can be seen as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based app</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and comparing opinions on the web. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1848" citStr="Liu, 2012" startWordPosition="273" endWordPosition="274">nd laptops. We show that our approach leads to very promising results. 1 Introduction The majority of current sentiment analysis approaches tries to detect the overall polarity of a sentence (or a document) regardless of the target entities (e.g. restaurants) and their aspects (e.g. food, price). By contrast, the ABSA (aspect based sentiment analysis) task is concerned with identifying the aspects of given target entities and estimating the sentiment polarity for each mentioned aspect. The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). The task of aspect extraction is to recognize aspects of the entity and more generally can be seen as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction p</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Long</author>
<author>Jie Zhang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>A review selection approach for accurate feature rating estimation.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling 2010: Poster Volume.</booktitle>
<contexts>
<context position="2354" citStr="Long et al., 2010" startWordPosition="350" endWordPosition="353">ect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). The task of aspect extraction is to recognize aspects of the entity and more generally can be seen as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (D</context>
</contexts>
<marker>Long, Zhang, Zhu, 2010</marker>
<rawString>Chong Long, Jie Zhang, and Xiaoyan Zhu. 2010. A review selection approach for accurate feature rating estimation. In Proceedings of Coling 2010: Poster Volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Lund</author>
<author>Curt Burgess</author>
</authors>
<title>Producing high-dimensional semantic spaces from lexical cooccurrence.</title>
<date>1996</date>
<journal>Behavior Research Methods Instruments and Computers,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="9489" citStr="Lund and Burgess, 1996" startWordPosition="1507" endWordPosition="1510">sampling. The hyperparameters of Dirichlet distributions were initially set to α = 50/K, where K is the number of topics and Q = 0.1. This setting is recommended by (Griffiths and Steyvers, 2004). The topic probabilities are directly used as new features to the classifier. 3.2 Word clusters We use same approach as presented in (Brychcin and Konopik, 2014), where word clusters derived from semantic spaces improved language modeling. As recommended by these authors, we use COALS (Correlated Occurrence Analogue to Lexical Semantics) (Rohde et al., 2004) and HAL (Hyperspace Analogue to Language) (Lund and Burgess, 1996) for representing the word meaning and the Repeated Bisection algorithm for clustering. Similar approach has been already used for sentiment analysis in (Habernal and Brychcin, 2013) and (Brychcin and Habernal, 2013). The parameters of semantic spaces are set as follows. For both semantic spaces we use a fourword context window (in both directions). HAL uses a matrix consisting of 50,000 columns, which keeps the largest amount of information. COALS uses a matrix with only 14,000 columns (as recommended by the authors of the algorithm). The SVD reduction was not used in our experiments. Impleme</context>
</contexts>
<marker>Lund, Burgess, 1996</marker>
<rawString>Kevin Lund and Curt Burgess. 1996. Producing high-dimensional semantic spaces from lexical cooccurrence. Behavior Research Methods Instruments and Computers, 28(2):203–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<contexts>
<context position="8684" citStr="McCallum, 2002" startWordPosition="1378" endWordPosition="1380">ews (documents) with about 27 million words. The opentable corpus is used as the training data for these features. Unfortunately, we did not find any large corpus for laptop domain, thus presented unsupervised features are used in restaurant domain only. We devote the following two subsections to describe these features. Then we introduce our approach to the individual tasks. 3.1 Latent Dirichlet Allocation The Latent Dirichlet Allocation (LDA) (Blei et al., 2003) is a topic model that is assumed to provide useful information for particular subtasks. We use LDA implementation from the MALLET (McCallum, 2002) software package. For each experiment we always train the 400 topics LDA (no significant difference was observed between different numbers of topics) with 1,000 iterations of Gibbs sampling. The hyperparameters of Dirichlet distributions were initially set to α = 50/K, where K is the number of topics and Q = 0.1. This setting is recommended by (Griffiths and Steyvers, 2004). The topic probabilities are directly used as new features to the classifier. 3.2 Word clusters We use same approach as presented in (Brychcin and Konopik, 2014), where word clusters derived from semantic spaces improved l</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="2684" citStr="Mei et al., 2007" startWordPosition="407" endWordPosition="410">Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were s</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>Opinion digger: an unsupervised opinion miner from unstructured product reviews.</title>
<date>2010</date>
<booktitle>In Proceeding of the ACM conference on Information and knowledge management.</booktitle>
<contexts>
<context position="2334" citStr="Moghaddam and Ester, 2010" startWordPosition="346" endWordPosition="349">h mentioned aspect. The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). The task of aspect extraction is to recognize aspects of the entity and more generally can be seen as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as </context>
</contexts>
<marker>Moghaddam, Ester, 2010</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2010. Opinion digger: an unsupervised opinion miner from unstructured product reviews. In Proceeding of the ACM conference on Information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Harris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Semeval-2014 task 4: Aspect based sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="3511" citStr="Pontiki et al., 2014" startWordPosition="541" endWordPosition="544">list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (Section 3). In Section 4, we discuss our results in the task. We participated with both the constrained and the unconstrained variants of the system. 2 The ABSA task Datasets consisting of customer reviews with human-authored annotations identifying the mentioned aspects of the target entities and the sentiment polarity of each aspect were provided. The experiments were run in two domains: restaurant and laptop reviews. 817 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 817–822, Dublin, Irela</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. Semeval-2014 task 4: Aspect based sentiment analysis. In Proceedings of the International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>2010</date>
<booktitle>In Proceedings of the IEEE,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="2563" citStr="Rabiner, 2010" startWordPosition="386" endWordPosition="387">as an information extraction task. The basic approach is finding frequent nouns and noun This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and </context>
</contexts>
<marker>Rabiner, 2010</marker>
<rawString>Lawrence Rabiner. 2010. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings of the IEEE, pages 257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning. In Natural language processing using very large corpora,</title>
<date>1999</date>
<pages>157--176</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="10981" citStr="Ramshaw and Marcus, 1999" startWordPosition="1749" endWordPosition="1752">ine similarity of word vectors. For both semantic spaces the word vectors are clustered into four different depths: 100, 500, 1,000, and 5,000 clusters (i.e. eight different cluster sets). The occurrences of particular clusters represent additional features to the classifiers. 3.3 Aspect term extraction Our approach for aspect term extraction is based on Conditional Random Fields (CRF). The choice was based on similarity with the named entity recognition task, where CRF are regarded as the current state of the art (Konkol and Konopik, 2013). We use the BIO model for representing aspect terms (Ramshaw and Marcus, 1999). The constrained feature set consists of: W, BoW, B, LD, S. It is extended by WC for the unconstrained case. 3.4 Aspect term polarity During the detection of the aspect term polarities, the words affecting the sentiment of the aspect term are assumed to be close in most of cases. Thus we use a context window of 10 words in both directions around the target aspect term. We assume the further the word or bigram is from the target aspect term, the lower impact it has on the polarity label. To model this assumption we use a weight for each word and bigram feature taken from the Gaussian distribut</context>
</contexts>
<marker>Ramshaw, Marcus, 1999</marker>
<rawString>Lance A Ramshaw and Mitchell P Marcus. 1999. Text chunking using transformation-based learning. In Natural language processing using very large corpora, pages 157–176. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas L T Rohde</author>
<author>Laura M Gonnerman</author>
<author>David C Plaut</author>
</authors>
<title>An improved method for deriving word meaning from lexical co-occurrence. Cognitive Psychology,</title>
<date>2004</date>
<pages>7--573</pages>
<contexts>
<context position="9422" citStr="Rohde et al., 2004" startWordPosition="1497" endWordPosition="1500">en different numbers of topics) with 1,000 iterations of Gibbs sampling. The hyperparameters of Dirichlet distributions were initially set to α = 50/K, where K is the number of topics and Q = 0.1. This setting is recommended by (Griffiths and Steyvers, 2004). The topic probabilities are directly used as new features to the classifier. 3.2 Word clusters We use same approach as presented in (Brychcin and Konopik, 2014), where word clusters derived from semantic spaces improved language modeling. As recommended by these authors, we use COALS (Correlated Occurrence Analogue to Lexical Semantics) (Rohde et al., 2004) and HAL (Hyperspace Analogue to Language) (Lund and Burgess, 1996) for representing the word meaning and the Repeated Bisection algorithm for clustering. Similar approach has been already used for sentiment analysis in (Habernal and Brychcin, 2013) and (Brychcin and Habernal, 2013). The parameters of semantic spaces are set as follows. For both semantic spaces we use a fourword context window (in both directions). HAL uses a matrix consisting of 50,000 columns, which keeps the largest amount of information. COALS uses a matrix with only 14,000 columns (as recommended by the authors of the alg</context>
</contexts>
<marker>Rohde, Gonnerman, Plaut, 2004</marker>
<rawString>Douglas L. T. Rohde, Laura M. Gonnerman, and David C. Plaut. 2004. An improved method for deriving word meaning from lexical co-occurrence. Cognitive Psychology, 7:573–605.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Steinberger</author>
<author>Mohamed Ebrahim</author>
<author>Maud Ehrmann</author>
</authors>
<title>Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova, Ralf Steinberger, Hristo Tanev, Silvia Vzquez, and Vanni Zavarella.</title>
<date>2012</date>
<volume>53</volume>
<issue>4</issue>
<pages>694</pages>
<contexts>
<context position="7451" citStr="Steinberger et al., 2012" startWordPosition="1177" endWordPosition="1180">s. Words (W) – Word occurrence on a given position in the context window. Bag of Words (BoW) – Occurrence of a word in a sentence (or context window). Bigrams (B) – Bigram occurrence on a given position in the context window. Bag of Bigrams (BoB) – Occurrence of a bigram in a sentence (or context window). Tf-idf – Term frequency–inverse document frequency for all tokens in the sentence. Learned Dictionary (LD) – Dictionary of terms based on training data. Suffixes (S) – Suffix of a word (2-4 characters). Sentiment Dictionary (SD) – Dictionary created using semi-automatic triangulation method (Steinberger et al., 2012). The score is normalized. Senti Wordnet (SW) – See (Baccianella et al., 2010). LDA – See Section 3.1. Word Clusters (WC) – See Section 3.2. Cluster occurrence on a given position in the context window. Bag of Clusters (BoC) – Same as word clusters, but without information about position. 818 We use two features that are not in common use in similar tasks – Latent Dirichlet Allocation and word clusters based on semantic spaces. Both these features use large amount of unlabeled data to discover latent semantics. We downloaded the restaurant reviews from http://opentable. com. This corpus consis</context>
</contexts>
<marker>Steinberger, Ebrahim, Ehrmann, 2012</marker>
<rawString>Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann, Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova, Ralf Steinberger, Hristo Tanev, Silvia Vzquez, and Vanni Zavarella. 2012. Creating sentiment dictionaries via triangulation. Decision Support Systems, 53(4):689 – 694.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Steinberger</author>
<author>Tom´as Brychcfn</author>
<author>Michal Konkol</author>
</authors>
<title>Aspect-level sentiment analysis in czech.</title>
<date>2014</date>
<booktitle>In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, USA,</location>
<contexts>
<context position="3389" citStr="Steinberger et al., 2014" startWordPosition="519" endWordPosition="522">determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the aspect-level task in other languages (e.g. in Czech (Steinberger et al., 2014)). The rest of the article is organized as follows. In Section 2, we summarize the ABSA shared task (Pontiki et al., 2014). Then, we give a description of our participating system (Section 3). In Section 4, we discuss our results in the task. We participated with both the constrained and the unconstrained variants of the system. 2 The ABSA task Datasets consisting of customer reviews with human-authored annotations identifying the mentioned aspects of the target entities and the sentiment polarity of each aspect were provided. The experiments were run in two domains: restaurant and laptop revi</context>
</contexts>
<marker>Steinberger, Brychcfn, Konkol, 2014</marker>
<rawString>Josef Steinberger, Tom´a&amp;quot;s Brychcfn, and Michal Konkol. 2014. Aspect-level sentiment analysis in czech. In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Baltimore, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="2710" citStr="Titov and McDonald, 2008" startWordPosition="411" endWordPosition="414">ttribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ phrases (Liu et al., 2005; Blair-Goldensohn et al., 2008; Moghaddam and Ester, 2010; Long et al., 2010). Aspect extraction can be also seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning (e.g. HMM – Hidden Markov Models (Rabiner, 2010) or CRF – Conditional Random Fields (Lafferty et al., 2001)). Another group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). Aspect sentiment classification determines whether the opinions on different aspects are positive, negative, or neutral. While lexicon-based approaches use a list of aspect-related sentiment phrases as the core resource (Ding et al., 2008; Hu and Liu, 2004), the key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect in the sentence (Jiang et al., 2011; Boiy and Moens, 2009). The most of the research in aspect-level sentiment analysis has been done in English, however, there were some attempts to tackle the</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>