<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009632">
<title confidence="0.907727">
The Life and Death of Discourse Entities: Identifying Singleton Mentions
</title>
<author confidence="0.805277">
Marta Recasens
</author>
<affiliation confidence="0.8341225">
Linguistics Department
Stanford University
</affiliation>
<address confidence="0.917773">
Stanford, CA 94305
</address>
<email confidence="0.996955">
recasens@google.com
</email>
<author confidence="0.420777">
Marie-Catherine de Marneffe
</author>
<affiliation confidence="0.656516">
Linguistics Department
The Ohio State University
</affiliation>
<address confidence="0.921344">
Columbus, OH 43210
</address>
<email confidence="0.999112">
mcdm@ling.osu.edu
</email>
<author confidence="0.921328">
Christopher Potts
</author>
<affiliation confidence="0.8879845">
Linguistics Department
Stanford University
</affiliation>
<address confidence="0.924125">
Stanford, CA 94305
</address>
<email confidence="0.999298">
cgpotts@stanford.edu
</email>
<sectionHeader confidence="0.995647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999693">
A discourse typically involves numerous en-
tities, but few are mentioned more than once.
Distinguishing discourse entities that die out
after just one mention (singletons) from those
that lead longer lives (coreferent) would ben-
efit NLP applications such as coreference res-
olution, protagonist identification, topic mod-
eling, and discourse coherence. We build a lo-
gistic regression model for predicting the sin-
gleton/coreferent distinction, drawing on lin-
guistic insights about how discourse entity
lifespans are affected by syntactic and seman-
tic features. The model is effective in its own
right (78% accuracy), and incorporating it into
a state-of-the-art coreference resolution sys-
tem yields a significant improvement.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999486135135135">
Not all discourse entities are created equal. Some
lead long lives and appear in a variety of discourse
contexts (coreferent), whereas others never escape
their birthplaces, dying out after just one mention
(singletons). The ability to make this distinction
based on properties of the NPs used to identify these
referents (mentions) would benefit not only corefer-
ence resolution, but also topic analysis, textual en-
tailment, and discourse coherence.
The existing literature provides numerous gen-
eralizations relevant to answering the question of
whether a given discourse entity will be singleton
or coreferent. These involve the internal syntax and
morphology of the target NP (Prince, 1981a; Prince,
1981b; Wang et al., 2006), the grammatical function
and discourse role of that NP (Chafe, 1976; Hobbs,
1979; Walker et al., 1997; Beaver, 2004), and the in-
teraction of all of those features with semantic oper-
ators like negation, modals, and attitude predicates
(Karttunen, 1973; Karttunen, 1976; Kamp, 1981;
Heim, 1982; Heim, 1992; Roberts, 1990; Groe-
nendijk and Stokhof, 1991; Bittner, 2001).
The first step in our analysis is to bring these
insights together into a single logistic regression
model — the lifespan model — and assess their
predictive power on real data. We show that the
features generally behave as the existing literature
leads us to expect, and that the model itself is highly
effective at predicting whether a given mention is
singleton or coreferent. We then provide an initial
assessment of the engineering value of making the
singleton/coreferent distinction by incorporating our
lifespan model into the Stanford coreference resolu-
tion system (Lee et al., 2011). This addition results
in a significant improvement on the CoNLL-2012
Shared Task data, across the MUC, B3, CEAF, and
CoNLL scoring algorithms.
</bodyText>
<sectionHeader confidence="0.988533" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.9996204">
All the data used throughout the paper come from
the CoNLL-2012 Shared Task (Pradhan et al.,
2012), which included the 1.6M English words from
OntoNotes v5.0 (Hovy et al., 2006) that have been
annotated with different layers of annotation (coref-
erence, parse trees, etc.). We used the training, de-
velopment (dev), and test splits as defined in the
shared task (Table 1). Since the OntoNotes corefer-
ence annotations do not contain singleton mentions,
we automatically marked as singletons all the NPs
</bodyText>
<page confidence="0.986713">
627
</page>
<table confidence="0.938736714285714">
Proceedings of NAACL-HLT 2013, pages 627–633,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
Dataset Docs Tokens MENTIONS
Coreferent Singletons
Training 2,802 1.3M 152,828 192,248
Dev 343 160K 18,815 24,170
Test 348 170K 19,392 24,921
</table>
<tableCaption confidence="0.9982165">
Table 1: CoNLL-2012 Shared Task data statistics. We
added singletons (NPs not annotated as coreferent).
</tableCaption>
<bodyText confidence="0.952102">
not annotated as coreferent. Thus, our singletons in-
clude non-referential NPs but not verbal mentions.
</bodyText>
<sectionHeader confidence="0.932694" genericHeader="method">
3 Predicting lifespans
</sectionHeader>
<bodyText confidence="0.999986428571429">
Our lifespan model makes a binary distinction be-
tween discourse referents that are not part of a coref-
erence chain (singletons) and items that are part of
one (coreferent). The distribution of lifespans in our
data (Figure 1) suggests that this is a natural divi-
sion. The propensity of singletons also highlights
the relevance of detecting singletons for a coref-
erence system. We fit a binary logistic regression
model in R (R Core Team, 2012) on the training
data, coding singletons as “0” and coreferent men-
tions as “1”. Throughout the following tables of co-
efficient estimates, positive values favor coreferents
and negative ones favor singletons. We turn now to
describing and motivating the features of this model.
</bodyText>
<equation confidence="0.8721">
0 5K 15K 25K
Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20
</equation>
<figureCaption confidence="0.977178">
Figure 1: Distribution of lifespans in the dev set. Single-
tons account for 56% of the data.
</figureCaption>
<bodyText confidence="0.999623567567568">
Internal morphosyntax of the mention Table 2
summarizes the features from our model that con-
cern the internal morphology and syntactic structure
of the mention. Many are common in coreference
systems (Recasens and Hovy, 2009), but our model
highlights their influence on lifespans. The picture
is expected on the taxonomy of given and new de-
fined by Prince (1981b) and assumed throughout dy-
namic semantics (Kamp, 1981; Heim, 1982): pro-
nouns depend on anaphoric connections to previous
mentions for disambiguation and thus are very likely
to be coreferent. This is corroborated by the pos-
itive coefficient estimate for ‘Type = pronoun’ in
Table 2. Few quantified phrases easily participate
in discourse anaphora (Partee, 1987; Wang et al.,
2006), accounting for the association between quan-
tifiers and singletons (negative coefficient estimate
for ‘Quantifier = quantified’ in Table 2). The one
surprise is the negative coefficient for indefinites. In
theories stretching back to Karttunen (1976), indef-
inites function primarily to establish new discourse
entities, and should be able to participate in coref-
erence chains, but here the association with such
chains is negative. However, interactions explain
this fact (see Table 4 and our discussion of it).
The person, number, and animacy values suggest
that singular animates are excellent coreferent NPs,
a previous finding of Centering Theory (Grosz et al.,
1995; Walker et al., 1998) and of cross-linguistic
work on obviative case-marking (Aissen, 1997).
Our model also includes named-entity features for
all of the eighteen OntoNotes entity-types (omitted
from Table 2 for space and clarity reasons). As a
rule, they behave like ‘Type = proper noun’ in asso-
ciating with coreferents. The exceptions are ORDI-
NAL, PERCENT, and QUANTITY, which seem intu-
itively unlikely to participate in coreference chains.
</bodyText>
<table confidence="0.998778076923077">
Estimate P-value
Type =pronoun 1.21 &lt; 0.001
Type = proper noun 1.88 &lt; 0.001
Animacy = inanimate −1.36 &lt; 0.001
Animacy = unknown −0.38 &lt; 0.001
Person = 1 1.05 &lt; 0.001
Person = 2 0.13 &lt; 0.001
Person = 3 1.62 &lt; 0.001
Number = singular 0.61 &lt; 0.001
Number = unknown 0.17 &lt; 0.001
Quantifier = indefinite −1.49 &lt; 0.001
Quantifier = quantified −1.23 &lt; 0.001
Number of modifiers −0.39 &lt; 0.001
</table>
<tableCaption confidence="0.998055">
Table 2: Internal morphosyntactic features.
</tableCaption>
<bodyText confidence="0.998341">
Grammatical role of the mention Synthesizing
much work in Centering Theory and information
structuring, we conclude that coreferent mentions
are likely to appear as core verbal arguments and
will favor sentence-initial (topic-tracking) positions
(Ward and Birner, 2004). The coefficient estimates
</bodyText>
<page confidence="0.995615">
628
</page>
<table confidence="0.999467454545454">
Estimate P-value
Sentence Position = end −0.22 &lt; 0.001
Sentence Position = first 0.04 0.07
Sentence Position = last −0.31 &lt; 0.001
Sentence Position = middle −0.11 &lt; 0.001
Relation = noun argument 0.56 &lt; 0.001
Relation = other −0.67 &lt; 0.001
Relation = root −0.61 &lt; 0.001
Relation = subject 0.65 &lt; 0.001
Relation = verb argument 0.32 &lt; 0.001
In coordination −0.48 &lt; 0.001
</table>
<tableCaption confidence="0.999339">
Table 3: Grammatical role features.
</tableCaption>
<bodyText confidence="0.999581150943396">
in Table 3 corroborate these conclusions. To de-
fine the ‘Relation’ and ‘In coordination’ features, we
used the Stanford dependencies (de Marneffe et al.,
2006) on the gold constituents.
Semantic environment of the mention Table 4
highlights the complex interactions between dis-
course anaphora and semantic operators. These
interactions have been a focus of logical seman-
tics since Karttunen (1976), whose guiding obser-
vation is semantic: an indefinite interpreted inside
the scope of a negation, modal, or attitude predicate
is generally unavailable for anaphoric reference out-
side of the scope of that operator, as in Kim didn’t
understand [an exam question]. #Iti was too hard.
Of course, such discourses cohere if the indefinite
is interpreted as taking wide scope (‘there is a ques-
tion Kim didn’t understand’). Such readings are of-
ten disfavored, but they become more salient when
modifiers like certain are included (Schwarzschild,
2002) or when the determiner is sensitive to the po-
larity or intensionality of its environment (Baker,
1970; Ladusaw, 1980; van der Wouden, 1997; Is-
rael, 1996; Israel, 2001; Giannakidou, 1999). Sub-
sequent research identified many other factors that
further extend or restrict the anaphoric potential of
an indefinite (Roberts, 1996).
We do not have direct access to semantic scope,
but we expect syntactic scope to correlate strongly
with semantic scope, so we used dependency rep-
resentations to define features capturing syntactic
scope for negation, modal auxiliaries, and a broad
range of attitude predicates. These features tend to
bias in favor of singletons because they so radically
restrict the possibilities for intersentential anaphora.
Interacting these features with those for the inter-
nal syntax of mentions is also informative. Since
proper names and pronouns are not scope-taking,
they are largely unaffected by the environment fea-
tures, whereas indefinites emerge as even more re-
stricted, just as Karttunen and others would predict.
Attitude predicates seem initially anomalous,
though. They share the relevant semantic proper-
ties with negation and modals, and yet they seem
to facilitate coreference. Here, the findings of de
Marneffe et al. (2012) seem informative. Those au-
thors find that, in texts of the sort we are studying,
attitude predicates are used predominantly to mark
the source of information that is effectively asserted
despite being embedded (Rooryck, 2001; Simons,
2007). That is, though X said p does not semanti-
cally entail p, it is often interpreted as a commitment
to p, which correspondingly elevates mentions in p
to main-clause status (Harris and Potts, 2009).
</bodyText>
<table confidence="0.999720384615385">
Estimate P-value
Presence of negation −0.18 &lt; 0.001
Presence of modality −0.22 &lt; 0.001
Under an attitude verb 0.03 0.01
AttitudeVerb * (Type = pronoun) 0.29 &lt; 0.001
AttitudeVerb * (Type = proper noun) 0.14 &lt; 0.001
Modal * (Type = pronoun) 0.12 0.04
Modal * (Type = proper noun) 0.35 &lt; 0.001
Negation * (Type = pronoun) 1.07 &lt; 0.001
Negation * (Type = proper noun) 0.30 &lt; 0.001
Negation * (Quantifier = indefinite) −0.37 &lt; 0.001
Negation * (Quantifier = quantified) −0.36 0.23
Negation * (Number of modifiers) 0.11 &lt; 0.001
</table>
<tableCaption confidence="0.99995">
Table 4: Semantic environment features and interactions.
</tableCaption>
<bodyText confidence="0.978353142857143">
Results The model successfully learns to tease
singletons and coreferent mentions apart. Table 5
summarizes its performance on the dev set. The
STANDARD model uses 0.5 as the decision bound-
ary, with 78% accuracy. The CONFIDENT model
predicts singleton if Pr &lt; .2 and coreferent if Pr &gt; .8,
which increases precision (P) at a cost to recall (R).
</bodyText>
<table confidence="0.9796305">
STANDARD CONFIDENT
Prediction R P F1 R P F1
Singleton 82.3 79.2 80.7 50.5 89.6 64.6
Coreferent 72.2 76.1 74.1 41.3 86.8 55.9
</table>
<tableCaption confidence="0.999565">
Table 5: Recall, precision, and F1 for the lifespan model.
</tableCaption>
<page confidence="0.914371">
629
</page>
<table confidence="0.9999365">
MUC B3 CEAF-03 CEAF-04 CoNLL
System R P F1 R P F1 R / P / F1 R P F1 F1
Baseline 66.64* 64.72 65.67 68.05* 71.58 69.77* 58.31 45.49 47.55* 46.50 60.65
w/Lifespan 66.08 67.33* 66.70* 66.40 73.14* 69.61 58.83* 47.77* 46.38 47.07* 61.13*
</table>
<tableCaption confidence="0.9957735">
Table 6: Performance on the test set according to the official CoNLL-2012 scorer. Scores are on automatically pre-
dicted mentions. Stars indicate a statistically significant difference (paired Mann-Whitney U-test, p &lt; 0.05).
</tableCaption>
<table confidence="0.99981125">
B3 CEAF-03 CoNLL
System R P F1 R P F1 F1
Baseline 58.53* 71.58 64.40 63.71* 58.31 60.89 58.86
w/ Lifespan 58.14 73.14* 64.78* 63.38 58.83* 61.02 59.52*
</table>
<tableCaption confidence="0.995315">
Table 7: B3, CEAF-03 and CoNLL measures on the test set according to a modified CoNLL-2012 scorer that follows
Cai and Strube (2010). Scores are on automatically predicted mentions.
</tableCaption>
<sectionHeader confidence="0.861776" genericHeader="method">
4 Application to coreference resolution
</sectionHeader>
<bodyText confidence="0.999981532258064">
To assess the usefulness of the lifespan model in an
NLP application, we incorporate it into the Stanford
coreference resolution system (Lee et al., 2011),
which we take as our baseline. This was the highest-
scoring system in the CoNLL-2011 Shared Task,
and was also part of the highest-scoring system in
the CoNLL-2012 Shared Task (Fernandes et al.,
2012). It is a rule-based system that includes a to-
tal of ten rules (or “sieves”) for entity coreference,
such as exact string match and pronominal resolu-
tion. The sieves are applied from highest to lowest
precision, each rule adding coreference links.
Incorporating the lifespan model The lifespan
model can improve coreference resolution in two
different ways: (i) mentions classified as singletons
should not be considered as either antecedents or
coreferent, and (ii) mentions classified as coreferent
should be linked with another mention(s). By suc-
cessfully predicting singletons (i), we can enhance
the system’s precision; by successfully predicting
coreferent mentions (ii), we can improve the sys-
tem’s recall. Here we focus on (i) and use the lifes-
pan model for detecting singletons. This decision
is motivated by two factors. First, given the large
number of singletons (Figure 1), we are more likely
to see a gain in performance from discarding sin-
gletons. Second, the multi-sieve nature of the Stan-
ford coreference system does not make it straightfor-
ward to decide which antecedent a mention should
be linked to even if we know that it is coreferent.
We leave the incorporation of coreferent predictions
for future work.
To integrate the singleton model into the Stanford
coreference system, we let a sieve consider whether
a pair of mentions is coreferent only if neither of
the two mentions are classified as singletons by our
CONFIDENT model. Experiments on the dev set
showed that the model often made wrong predic-
tions for NEs. We do not trust the model for NE
mentions. Performance on coreference (on the dev
set) was higher with the CONFIDENT model than
with the STANDARD model.
Results and discussion To evaluate the corefer-
ence system with and without the lifespan model, we
used the English dev and test sets from the CoNLL-
2012 Shared Task, presented in Section 2. Although
the CoNLL shared task evaluated systems on only
multi-mention (i.e., non-singleton) entities, by stop-
ping singletons from being linked to multi-mention
entities, we expected the lifespan model to increase
the system’s precision. Our evaluation uses five
of the measures given by the CoNLL-2012 scorer:
MUC (Vilain et al., 1995), B3 (Bagga and Baldwin,
1998), CEAF-03 and CEAF-04 (Luo, 2005), and the
CoNLL official score (Denis and Baldridge, 2009).
We do not include BLANC (Recasens and Hovy,
2011) because it assumes gold mentions and so is
not suited for the scenario considered in this paper,
which uses automatically predicted mentions.
Table 6 summarizes the test set performance. All
the scores are on automatically predicted mentions.
We use gold POS, parse trees, and NEs. The base-
</bodyText>
<page confidence="0.994723">
630
</page>
<bodyText confidence="0.999925722222222">
line is the Stanford system, and ‘w/Lifespan’ is the
same system extended with our lifespan model to
discard singletons, as explained above.
As expected, the lifespan model increases preci-
sion but decreases recall. Overall, however, we ob-
tain a significant improvement of 0.5–1 points in the
F1 score of MUC, CEAF-03, CEAF-04 and CoNLL.
The drop in B3 traces to a bug in the CoNLL scorer’s
implementation of Cai and Strube (2010)’s algo-
rithm for aligning gold and automatically predicted
mentions, which affects the computation of B3 and
CEAF-03.1 Table 7 presents the results after mod-
ifying the CoNLL-2012 scorer to compute B3 and
CEAF-03 according to Cai and Strube (2010).2 We
do see an improvement in the precision and F1
scores of B3, and the overall CoNLL score remains
significant. The CEAF-03 F1 score is no longer sig-
nificant, but is still in the expected direction.
</bodyText>
<sectionHeader confidence="0.993861" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.921274238095238">
We built a model to predict the lifespan of discourse
referents, teasing apart singletons from coreferent
mentions. The model validates existing linguistic
insights and performs well in its own right. This
alone has ramifications for tracking topics, identify-
ing protagonists, and modeling coreference and dis-
course coherence. We applied the lifespan model to
coreference resolution, showing how to incorporate
it effectively into a state-of-the-art rule-based coref-
erence system. We expect similar improvements
with machine-learning-based coreference systems,
where incorporating all the power of the lifespan
model would be easier.
Our lifespan model has been integrated into the
latest version of the Stanford coreference resolution
system.3
1At present, if the system links two mentions that do not
exist in the gold standard, the scorer adds two singletons to the
gold standard. This results in a higher B3 F1 score (when it
should be lower) because recall increases instead of staying the
same (precision goes up).
</bodyText>
<footnote confidence="0.8930872">
2In the modified scorer, twinless predicted mentions are
added to the gold standard to compute precision but not to com-
pute recall.
3http://nlp.stanford.edu/software/
dcoref.shtml
</footnote>
<sectionHeader confidence="0.978658" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999684625">
We thank Emili Sapena for modifying the CoNLL-
2012 scorer to follow Cai and Strube (2010).
This research was supported in part by ONR
grant No. N00014-10-1-0109 and ARO grant
No. W911NF-07-1-0216. The first author was sup-
ported by a Beatriu de Pin´os postdoctoral schol-
arship (2010 BP-A 00149) from Generalitat de
Catalunya.
</bodyText>
<sectionHeader confidence="0.950024" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.966893675">
Judith Aissen. 1997. On the syntax of obviation. Lan-
guage, 73(4):705–750.
Amit Bagga and Breck Baldwin. 1998. Algorithms
for scoring coreference chains. In Proceedings of
the LREC 1998 Workshop on Linguistic Coreference,
pages 563–566.
C. L. Baker. 1970. Double negatives. Linguistic Inquiry,
1(2):169–186.
David Beaver. 2004. The optimization of discourse
anaphora. Linguistics and Philosophy, 27(1):3–56.
Maria Bittner. 2001. Surface composition as bridging.
Journal of Semantics, 18(2):127–177.
Jie Cai and Michael Strube. 2010. Evaluation metrics
for end-to-end coreference resolution systems. In Pro-
ceedings of SIGDIAL 2010, pages 28–36.
Wallace L. Chafe. 1976. Givenness, Contrastiveness,
Definiteness, Subjects, Topics, and Point of View. In
Charles N. Li, editor, Subject and Topic, pages 25–55.
Academic Press, New York.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC 2006.
Marie-Catherine de Marneffe, Christopher D. Manning,
and Christopher Potts. 2012. Did it happen?
The pragmatic complexity of veridicality assessment.
Computational Linguistics, 38(2):301–333.
Pascal Denis and Jason Baldridge. 2009. Global joint
models for coreference resolution and named entity
classification. Procesamiento del Lenguaje Natural,
42:87–96.
Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u.
2012. Latent structure perceptron with feature induc-
tion for unrestricted coreference resolution. In Pro-
ceedings of CoNLL-2012: Shared Task, pages 41–48.
Anastasia Giannakidou. 1999. Affective dependencies.
Linguistics and Philosophy, 22(4):367–421.
Jeroen Groenendijk and Martin Stokhof. 1991. Dynamic
predicate logic. Linguistics and Philosophy, 14(1):39–
100.
</reference>
<page confidence="0.990672">
631
</page>
<reference confidence="0.999623523364486">
Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
1995. Centering: A framework for modeling the lo-
cal coherence of discourse. Computational Linguis-
tics, 21(2):203–225.
Jesse A. Harris and Christopher Potts. 2009.
Perspective-shifting with appositives and expressives.
Linguistics and Philosophy, 32(6):523–552.
Irene Heim. 1982. The Semantics of Definite and Indefi-
nite Noun Phrases. Ph.D. thesis, UMass Amherst.
Irene Heim. 1992. Presupposition projection and the
semantics of attitude verbs. Journal of Semantics,
9(2):183–221.
Jerry R. Hobbs. 1979. Coherence and coreference. Cog-
nitive Science, 3(1):67–90.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. OntoNotes:
The 90% solution. In Proceedings of HLT-
NAACL 2006, pages 57–60.
Michael Israel. 1996. Polarity sensitivity as lexical se-
mantics. Linguistics and Philosophy, 19(6):619–666.
Michael Israel. 2001. Minimizers, maximizers, and the
rhetoric of scalar reasoning. Journal of Semantics,
18(4):297–331.
Hans Kamp. 1981. A theory of truth and discourse
representation. In Jeroen Groenendijk, Theo M. V.
Janssen, and Martin Stockhof, editors, Formal Meth-
ods in the Study of Language, pages 277–322. Mathe-
matical Centre, Amsterdam.
Lauri Karttunen. 1973. Presuppositions and compound
sentences. Linguistic Inquiry, 4(2):169–193.
Lauri Karttunen. 1976. Discourse referents. In James D.
McCawley, editor, Syntax and Semantics, volume 7:
Notes from the Linguistic Underground, pages 363–
385. Academic Press, New York.
William A. Ladusaw. 1980. On the notion ‘affective’
in the analysis of negative polarity items. Journal of
Linguistic Research, 1(1):1–16.
Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael
Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011.
Stanford’s multi-pass sieve coreference resolution sys-
tem at the CoNLL-2011 Shared Task. In Proceedings
of CoNLL-2011: Shared Task, pages 28–34.
Xiaoqiang Luo. 2005. On coreference resolution perfor-
mance metrics. In Proceedings of HLT-EMNLP 2005,
pages 25–32.
Barbara H. Partee. 1987. Noun phrase interpretation
and type-shifting principles. In Jeroen Groenendijk,
Dick de Jong, and Martin Stokhof, editors, Studies in
Discourse Representation Theory and the Theory of
Generalized Quantifiers, pages 115–143. Foris Publi-
cations, Dordrecht.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-
2012 Shared Task: Modeling multilingual unrestricted
coreference in OntoNotes. In Proceedings of EMNLP
and CoNLL-2012: Shared Task, pages 1–40.
Ellen Prince. 1981a. On the inferencing of indefi-
nite ‘this’ NPs. In Bonnie Lynn Webber, Ivan Sag,
and Aravind Joshi, editors, Elements of Discourse Un-
derstanding, pages 231–250. Cambridge University
Press, Cambridge.
Ellen F. Prince. 1981b. Toward a taxonomy of given–
new information. In Peter Cole, editor, Radical Prag-
matics, pages 223–255. Academic Press, New York.
R Core Team, 2012. R: A Language and Environment
for Statistical Computing. R Foundation for Statistical
Computing, Vienna, Austria.
Marta Recasens and Eduard Hovy. 2009. A deeper
look into features for coreference resolution. In Sobha
Lalitha Devi, Ant´onio Branco, and Ruslan Mitkov, ed-
itors, Anaphora Processing and Applications, volume
5847 of Lecture Notes in Computer Science, pages 29–
42. Springer.
Marta Recasens and Eduard Hovy. 2011. BLANC: Im-
plementing the Rand index for coreference evaluation.
Natural Language Engineering, 17(4):485–510.
Craige Roberts. 1990. Modal Subordination, Anaphora,
and Distributivity. Garland, New York.
Craige Roberts. 1996. Anaphora in intensional contexts.
In Shalom Lappin, editor, The Handbook of Contem-
porary Semantic Theory, pages 215–246. Blackwell
Publishers, Oxford.
Johan Rooryck. 2001. Evidentiality, Part II. Glot Inter-
national, 5(5):161–168.
Roger Schwarzschild. 2002. Singleton indefinites. Jour-
nal of Semantics, 19(3):289–314.
Mandy Simons. 2007. Observations on embedding
verbs, evidentiality, and presupposition. Lingua,
117(6):1034–1056.
Ton van der Wouden. 1997. Negative Contexts: Col-
location, Polarity and Multiple Negation. Routledge,
London and New York.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceedings
of MUC-6, pages 45–52.
Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince,
editors. 1997. Centering in Discourse. Oxford Uni-
versity Press.
Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince.
1998. Centering in naturally-occurring discourse: An
overview. In Marilyn A. Walker, Aravind K. Joshi,
and Ellen F. Prince, editors, Centering Theory in Dis-
course, pages 1–28, Oxford. Clarendon Press.
Linton Wang, Eric McCready, and Nicholas Asher. 2006.
Information dependency in quantificational subordina-
tion. In Klaus von Heusinger and Ken Turner, editors,
</reference>
<page confidence="0.974111">
632
</page>
<reference confidence="0.999277333333333">
Where Semantics Meets Pragmatics, pages 267–304.
Elsevier Science, Amsterdam.
Gregory Ward and Betty Birner. 2004. Information
structure and non-canonical syntax. In Laurence R.
Horn and Gregory Ward, editors, The Handbook of
Pragmatics, pages 153–174. Blackwell, Oxford.
</reference>
<page confidence="0.999146">
633
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.056254">
<title confidence="0.996478">The Life and Death of Discourse Entities: Identifying Singleton Mentions</title>
<author confidence="0.984096">Marta</author>
<affiliation confidence="0.674446">Linguistics Stanford</affiliation>
<address confidence="0.909744">Stanford, CA</address>
<email confidence="0.998838">recasens@google.com</email>
<author confidence="0.806556">Marie-Catherine de</author>
<affiliation confidence="0.679768">Linguistics The Ohio State</affiliation>
<address confidence="0.930292">Columbus, OH</address>
<email confidence="0.998403">mcdm@ling.osu.edu</email>
<author confidence="0.746766">Christopher</author>
<affiliation confidence="0.5795305">Linguistics Stanford</affiliation>
<address confidence="0.729484">Stanford, CA</address>
<email confidence="0.983483">cgpotts@stanford.edu</email>
<abstract confidence="0.998126411764706">A discourse typically involves numerous entities, but few are mentioned more than once. Distinguishing discourse entities that die out after just one mention (singletons) from those that lead longer lives (coreferent) would benefit NLP applications such as coreference resolution, protagonist identification, topic modeling, and discourse coherence. We build a logistic regression model for predicting the singleton/coreferent distinction, drawing on linguistic insights about how discourse entity lifespans are affected by syntactic and semantic features. The model is effective in its own right (78% accuracy), and incorporating it into a state-of-the-art coreference resolution system yields a significant improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Judith Aissen</author>
</authors>
<title>On the syntax of obviation.</title>
<date>1997</date>
<journal>Language,</journal>
<volume>73</volume>
<issue>4</issue>
<contexts>
<context position="6347" citStr="Aissen, 1997" startWordPosition="966" endWordPosition="967">surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animates are excellent coreferent NPs, a previous finding of Centering Theory (Grosz et al., 1995; Walker et al., 1998) and of cross-linguistic work on obviative case-marking (Aissen, 1997). Our model also includes named-entity features for all of the eighteen OntoNotes entity-types (omitted from Table 2 for space and clarity reasons). As a rule, they behave like ‘Type = proper noun’ in associating with coreferents. The exceptions are ORDINAL, PERCENT, and QUANTITY, which seem intuitively unlikely to participate in coreference chains. Estimate P-value Type =pronoun 1.21 &lt; 0.001 Type = proper noun 1.88 &lt; 0.001 Animacy = inanimate −1.36 &lt; 0.001 Animacy = unknown −0.38 &lt; 0.001 Person = 1 1.05 &lt; 0.001 Person = 2 0.13 &lt; 0.001 Person = 3 1.62 &lt; 0.001 Number = singular 0.61 &lt; 0.001 Num</context>
</contexts>
<marker>Aissen, 1997</marker>
<rawString>Judith Aissen. 1997. On the syntax of obviation. Language, 73(4):705–750.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proceedings of the LREC 1998 Workshop on Linguistic Coreference,</booktitle>
<pages>563--566</pages>
<contexts>
<context position="15022" citStr="Bagga and Baldwin, 1998" startWordPosition="2373" endWordPosition="2376">t) was higher with the CONFIDENT model than with the STANDARD model. Results and discussion To evaluate the coreference system with and without the lifespan model, we used the English dev and test sets from the CoNLL2012 Shared Task, presented in Section 2. Although the CoNLL shared task evaluated systems on only multi-mention (i.e., non-singleton) entities, by stopping singletons from being linked to multi-mention entities, we expected the lifespan model to increase the system’s precision. Our evaluation uses five of the measures given by the CoNLL-2012 scorer: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF-03 and CEAF-04 (Luo, 2005), and the CoNLL official score (Denis and Baldridge, 2009). We do not include BLANC (Recasens and Hovy, 2011) because it assumes gold mentions and so is not suited for the scenario considered in this paper, which uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained above. As expected, the lifes</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the LREC 1998 Workshop on Linguistic Coreference, pages 563–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Baker</author>
</authors>
<title>Double negatives.</title>
<date>1970</date>
<journal>Linguistic Inquiry,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="8879" citStr="Baker, 1970" startWordPosition="1375" endWordPosition="1376">tic: an indefinite interpreted inside the scope of a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the poss</context>
</contexts>
<marker>Baker, 1970</marker>
<rawString>C. L. Baker. 1970. Double negatives. Linguistic Inquiry, 1(2):169–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Beaver</author>
</authors>
<title>The optimization of discourse anaphora.</title>
<date>2004</date>
<journal>Linguistics and Philosophy,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="1976" citStr="Beaver, 2004" startWordPosition="278" endWordPosition="279"> to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given menti</context>
</contexts>
<marker>Beaver, 2004</marker>
<rawString>David Beaver. 2004. The optimization of discourse anaphora. Linguistics and Philosophy, 27(1):3–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Bittner</author>
</authors>
<title>Surface composition as bridging.</title>
<date>2001</date>
<journal>Journal of Semantics,</journal>
<volume>18</volume>
<issue>2</issue>
<contexts>
<context position="2225" citStr="Bittner, 2001" startWordPosition="316" endWordPosition="317">es numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford coreference resolution system (Lee et al., 2011). This</context>
</contexts>
<marker>Bittner, 2001</marker>
<rawString>Maria Bittner. 2001. Surface composition as bridging. Journal of Semantics, 18(2):127–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>Michael Strube</author>
</authors>
<title>Evaluation metrics for end-to-end coreference resolution systems.</title>
<date>2010</date>
<booktitle>In Proceedings of SIGDIAL</booktitle>
<pages>28--36</pages>
<contexts>
<context position="12329" citStr="Cai and Strube (2010)" startWordPosition="1940" endWordPosition="1943">.31 45.49 47.55* 46.50 60.65 w/Lifespan 66.08 67.33* 66.70* 66.40 73.14* 69.61 58.83* 47.77* 46.38 47.07* 61.13* Table 6: Performance on the test set according to the official CoNLL-2012 scorer. Scores are on automatically predicted mentions. Stars indicate a statistically significant difference (paired Mann-Whitney U-test, p &lt; 0.05). B3 CEAF-03 CoNLL System R P F1 R P F1 F1 Baseline 58.53* 71.58 64.40 63.71* 58.31 60.89 58.86 w/ Lifespan 58.14 73.14* 64.78* 63.38 58.83* 61.02 59.52* Table 7: B3, CEAF-03 and CoNLL measures on the test set according to a modified CoNLL-2012 scorer that follows Cai and Strube (2010). Scores are on automatically predicted mentions. 4 Application to coreference resolution To assess the usefulness of the lifespan model in an NLP application, we incorporate it into the Stanford coreference resolution system (Lee et al., 2011), which we take as our baseline. This was the highestscoring system in the CoNLL-2011 Shared Task, and was also part of the highest-scoring system in the CoNLL-2012 Shared Task (Fernandes et al., 2012). It is a rule-based system that includes a total of ten rules (or “sieves”) for entity coreference, such as exact string match and pronominal resolution. </context>
<context position="15888" citStr="Cai and Strube (2010)" startWordPosition="2516" endWordPosition="2519"> uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained above. As expected, the lifespan model increases precision but decreases recall. Overall, however, we obtain a significant improvement of 0.5–1 points in the F1 score of MUC, CEAF-03, CEAF-04 and CoNLL. The drop in B3 traces to a bug in the CoNLL scorer’s implementation of Cai and Strube (2010)’s algorithm for aligning gold and automatically predicted mentions, which affects the computation of B3 and CEAF-03.1 Table 7 presents the results after modifying the CoNLL-2012 scorer to compute B3 and CEAF-03 according to Cai and Strube (2010).2 We do see an improvement in the precision and F1 scores of B3, and the overall CoNLL score remains significant. The CEAF-03 F1 score is no longer significant, but is still in the expected direction. 5 Conclusion We built a model to predict the lifespan of discourse referents, teasing apart singletons from coreferent mentions. The model validates exi</context>
</contexts>
<marker>Cai, Strube, 2010</marker>
<rawString>Jie Cai and Michael Strube. 2010. Evaluation metrics for end-to-end coreference resolution systems. In Proceedings of SIGDIAL 2010, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wallace L Chafe</author>
</authors>
<date>1976</date>
<booktitle>Subject and Topic,</booktitle>
<pages>25--55</pages>
<editor>Givenness, Contrastiveness, Definiteness, Subjects, Topics, and Point of View. In Charles N. Li, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1927" citStr="Chafe, 1976" startWordPosition="270" endWordPosition="271">fter just one mention (singletons). The ability to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is hig</context>
</contexts>
<marker>Chafe, 1976</marker>
<rawString>Wallace L. Chafe. 1976. Givenness, Contrastiveness, Definiteness, Subjects, Topics, and Point of View. In Charles N. Li, editor, Subject and Topic, pages 25–55. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
<author>Christopher Potts</author>
</authors>
<title>Did it happen? The pragmatic complexity of veridicality assessment.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>2</issue>
<marker>de Marneffe, Manning, Potts, 2012</marker>
<rawString>Marie-Catherine de Marneffe, Christopher D. Manning, and Christopher Potts. 2012. Did it happen? The pragmatic complexity of veridicality assessment. Computational Linguistics, 38(2):301–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Global joint models for coreference resolution and named entity classification.</title>
<date>2009</date>
<booktitle>Procesamiento del Lenguaje Natural,</booktitle>
<pages>42--87</pages>
<contexts>
<context position="15113" citStr="Denis and Baldridge, 2009" startWordPosition="2387" endWordPosition="2390">on To evaluate the coreference system with and without the lifespan model, we used the English dev and test sets from the CoNLL2012 Shared Task, presented in Section 2. Although the CoNLL shared task evaluated systems on only multi-mention (i.e., non-singleton) entities, by stopping singletons from being linked to multi-mention entities, we expected the lifespan model to increase the system’s precision. Our evaluation uses five of the measures given by the CoNLL-2012 scorer: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF-03 and CEAF-04 (Luo, 2005), and the CoNLL official score (Denis and Baldridge, 2009). We do not include BLANC (Recasens and Hovy, 2011) because it assumes gold mentions and so is not suited for the scenario considered in this paper, which uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained above. As expected, the lifespan model increases precision but decreases recall. Overall, however, we obtain a significa</context>
</contexts>
<marker>Denis, Baldridge, 2009</marker>
<rawString>Pascal Denis and Jason Baldridge. 2009. Global joint models for coreference resolution and named entity classification. Procesamiento del Lenguaje Natural, 42:87–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo Fernandes</author>
<author>C´ıcero dos Santos</author>
<author>Ruy Milidi´u</author>
</authors>
<title>Latent structure perceptron with feature induction for unrestricted coreference resolution.</title>
<date>2012</date>
<booktitle>In Proceedings of CoNLL-2012: Shared Task,</booktitle>
<pages>41--48</pages>
<marker>Fernandes, Santos, Milidi´u, 2012</marker>
<rawString>Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u. 2012. Latent structure perceptron with feature induction for unrestricted coreference resolution. In Proceedings of CoNLL-2012: Shared Task, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anastasia Giannakidou</author>
</authors>
<title>Affective dependencies.</title>
<date>1999</date>
<journal>Linguistics and Philosophy,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="8964" citStr="Giannakidou, 1999" startWordPosition="1388" endWordPosition="1389">ude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the possibilities for intersentential anaphora. Interacting these features with those for the</context>
</contexts>
<marker>Giannakidou, 1999</marker>
<rawString>Anastasia Giannakidou. 1999. Affective dependencies. Linguistics and Philosophy, 22(4):367–421.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Groenendijk</author>
<author>Martin Stokhof</author>
</authors>
<title>Dynamic predicate logic.</title>
<date>1991</date>
<journal>Linguistics and Philosophy,</journal>
<volume>14</volume>
<issue>1</issue>
<pages>100</pages>
<contexts>
<context position="2209" citStr="Groenendijk and Stokhof, 1991" startWordPosition="311" endWordPosition="315"> The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford coreference resolution system (Lee et </context>
</contexts>
<marker>Groenendijk, Stokhof, 1991</marker>
<rawString>Jeroen Groenendijk and Martin Stokhof. 1991. Dynamic predicate logic. Linguistics and Philosophy, 14(1):39– 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="6255" citStr="Grosz et al., 1995" startWordPosition="951" endWordPosition="954">and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animates are excellent coreferent NPs, a previous finding of Centering Theory (Grosz et al., 1995; Walker et al., 1998) and of cross-linguistic work on obviative case-marking (Aissen, 1997). Our model also includes named-entity features for all of the eighteen OntoNotes entity-types (omitted from Table 2 for space and clarity reasons). As a rule, they behave like ‘Type = proper noun’ in associating with coreferents. The exceptions are ORDINAL, PERCENT, and QUANTITY, which seem intuitively unlikely to participate in coreference chains. Estimate P-value Type =pronoun 1.21 &lt; 0.001 Type = proper noun 1.88 &lt; 0.001 Animacy = inanimate −1.36 &lt; 0.001 Animacy = unknown −0.38 &lt; 0.001 Person = 1 1.0</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesse A Harris</author>
<author>Christopher Potts</author>
</authors>
<title>Perspective-shifting with appositives and expressives.</title>
<date>2009</date>
<journal>Linguistics and Philosophy,</journal>
<volume>32</volume>
<issue>6</issue>
<contexts>
<context position="10473" citStr="Harris and Potts, 2009" startWordPosition="1619" endWordPosition="1622">ially anomalous, though. They share the relevant semantic properties with negation and modals, and yet they seem to facilitate coreference. Here, the findings of de Marneffe et al. (2012) seem informative. Those authors find that, in texts of the sort we are studying, attitude predicates are used predominantly to mark the source of information that is effectively asserted despite being embedded (Rooryck, 2001; Simons, 2007). That is, though X said p does not semantically entail p, it is often interpreted as a commitment to p, which correspondingly elevates mentions in p to main-clause status (Harris and Potts, 2009). Estimate P-value Presence of negation −0.18 &lt; 0.001 Presence of modality −0.22 &lt; 0.001 Under an attitude verb 0.03 0.01 AttitudeVerb * (Type = pronoun) 0.29 &lt; 0.001 AttitudeVerb * (Type = proper noun) 0.14 &lt; 0.001 Modal * (Type = pronoun) 0.12 0.04 Modal * (Type = proper noun) 0.35 &lt; 0.001 Negation * (Type = pronoun) 1.07 &lt; 0.001 Negation * (Type = proper noun) 0.30 &lt; 0.001 Negation * (Quantifier = indefinite) −0.37 &lt; 0.001 Negation * (Quantifier = quantified) −0.36 0.23 Negation * (Number of modifiers) 0.11 &lt; 0.001 Table 4: Semantic environment features and interactions. Results The model s</context>
</contexts>
<marker>Harris, Potts, 2009</marker>
<rawString>Jesse A. Harris and Christopher Potts. 2009. Perspective-shifting with appositives and expressives. Linguistics and Philosophy, 32(6):523–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Heim</author>
</authors>
<title>The Semantics of Definite and Indefinite Noun Phrases.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>UMass Amherst.</institution>
<contexts>
<context position="2151" citStr="Heim, 1982" startWordPosition="305" endWordPosition="306">al entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan mode</context>
<context position="5270" citStr="Heim, 1982" startWordPosition="804" endWordPosition="805">tivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to</context>
</contexts>
<marker>Heim, 1982</marker>
<rawString>Irene Heim. 1982. The Semantics of Definite and Indefinite Noun Phrases. Ph.D. thesis, UMass Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Heim</author>
</authors>
<title>Presupposition projection and the semantics of attitude verbs.</title>
<date>1992</date>
<journal>Journal of Semantics,</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="2163" citStr="Heim, 1992" startWordPosition="307" endWordPosition="308">t, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the S</context>
</contexts>
<marker>Heim, 1992</marker>
<rawString>Irene Heim. 1992. Presupposition projection and the semantics of attitude verbs. Journal of Semantics, 9(2):183–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Coherence and coreference.</title>
<date>1979</date>
<journal>Cognitive Science,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1940" citStr="Hobbs, 1979" startWordPosition="272" endWordPosition="273"> mention (singletons). The ability to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective</context>
</contexts>
<marker>Hobbs, 1979</marker>
<rawString>Jerry R. Hobbs. 1979. Coherence and coreference. Cognitive Science, 3(1):67–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: The 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of HLTNAACL</booktitle>
<pages>57--60</pages>
<contexts>
<context position="3148" citStr="Hovy et al., 2006" startWordPosition="463" endWordPosition="466"> effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford coreference resolution system (Lee et al., 2011). This addition results in a significant improvement on the CoNLL-2012 Shared Task data, across the MUC, B3, CEAF, and CoNLL scoring algorithms. 2 Data All the data used throughout the paper come from the CoNLL-2012 Shared Task (Pradhan et al., 2012), which included the 1.6M English words from OntoNotes v5.0 (Hovy et al., 2006) that have been annotated with different layers of annotation (coreference, parse trees, etc.). We used the training, development (dev), and test splits as defined in the shared task (Table 1). Since the OntoNotes coreference annotations do not contain singleton mentions, we automatically marked as singletons all the NPs 627 Proceedings of NAACL-HLT 2013, pages 627–633, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics Dataset Docs Tokens MENTIONS Coreferent Singletons Training 2,802 1.3M 152,828 192,248 Dev 343 160K 18,815 24,170 Test 348 170K 19,392 24,921 Ta</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% solution. In Proceedings of HLTNAACL 2006, pages 57–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Israel</author>
</authors>
<title>Polarity sensitivity as lexical semantics. Linguistics and Philosophy,</title>
<date>1996</date>
<contexts>
<context position="8930" citStr="Israel, 1996" startWordPosition="1383" endWordPosition="1385"> a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the possibilities for intersentential anaphora. Interacting</context>
</contexts>
<marker>Israel, 1996</marker>
<rawString>Michael Israel. 1996. Polarity sensitivity as lexical semantics. Linguistics and Philosophy, 19(6):619–666.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Israel</author>
</authors>
<title>Minimizers, maximizers, and the rhetoric of scalar reasoning.</title>
<date>2001</date>
<journal>Journal of Semantics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="8944" citStr="Israel, 2001" startWordPosition="1386" endWordPosition="1387">odal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the possibilities for intersentential anaphora. Interacting these feature</context>
</contexts>
<marker>Israel, 2001</marker>
<rawString>Michael Israel. 2001. Minimizers, maximizers, and the rhetoric of scalar reasoning. Journal of Semantics, 18(4):297–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
</authors>
<title>A theory of truth and discourse representation.</title>
<date>1981</date>
<booktitle>Formal Methods in the Study of Language,</booktitle>
<pages>277--322</pages>
<editor>In Jeroen Groenendijk, Theo M. V. Janssen, and Martin Stockhof, editors,</editor>
<publisher>Mathematical</publisher>
<location>Centre, Amsterdam.</location>
<contexts>
<context position="2139" citStr="Kamp, 1981" startWordPosition="303" endWordPosition="304">lysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our l</context>
<context position="5257" citStr="Kamp, 1981" startWordPosition="802" endWordPosition="803">ibing and motivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function</context>
</contexts>
<marker>Kamp, 1981</marker>
<rawString>Hans Kamp. 1981. A theory of truth and discourse representation. In Jeroen Groenendijk, Theo M. V. Janssen, and Martin Stockhof, editors, Formal Methods in the Study of Language, pages 277–322. Mathematical Centre, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Presuppositions and compound sentences.</title>
<date>1973</date>
<journal>Linguistic Inquiry,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="2110" citStr="Karttunen, 1973" startWordPosition="299" endWordPosition="300">nce resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent disti</context>
</contexts>
<marker>Karttunen, 1973</marker>
<rawString>Lauri Karttunen. 1973. Presuppositions and compound sentences. Linguistic Inquiry, 4(2):169–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Discourse referents.</title>
<date>1976</date>
<booktitle>Syntax and Semantics, volume 7: Notes from the Linguistic Underground,</booktitle>
<pages>363--385</pages>
<editor>In James D. McCawley, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="2127" citStr="Karttunen, 1976" startWordPosition="301" endWordPosition="302">ut also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorpo</context>
<context position="5835" citStr="Karttunen (1976)" startWordPosition="888" endWordPosition="889">roughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animates are excellent coreferent NPs, a previous finding of Centering Theory (Grosz et al., 1995; Walker et al., 1998) and of cross-linguistic work on obviative case-marking (Aissen, 1997). Our model also includes named-entity features for all of the eighteen OntoNotes entity</context>
<context position="8232" citStr="Karttunen (1976)" startWordPosition="1272" endWordPosition="1273">argument 0.56 &lt; 0.001 Relation = other −0.67 &lt; 0.001 Relation = root −0.61 &lt; 0.001 Relation = subject 0.65 &lt; 0.001 Relation = verb argument 0.32 &lt; 0.001 In coordination −0.48 &lt; 0.001 Table 3: Grammatical role features. in Table 3 corroborate these conclusions. To define the ‘Relation’ and ‘In coordination’ features, we used the Stanford dependencies (de Marneffe et al., 2006) on the gold constituents. Semantic environment of the mention Table 4 highlights the complex interactions between discourse anaphora and semantic operators. These interactions have been a focus of logical semantics since Karttunen (1976), whose guiding observation is semantic: an indefinite interpreted inside the scope of a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or</context>
</contexts>
<marker>Karttunen, 1976</marker>
<rawString>Lauri Karttunen. 1976. Discourse referents. In James D. McCawley, editor, Syntax and Semantics, volume 7: Notes from the Linguistic Underground, pages 363– 385. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Ladusaw</author>
</authors>
<title>On the notion ‘affective’ in the analysis of negative polarity items.</title>
<date>1980</date>
<journal>Journal of Linguistic Research,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="8894" citStr="Ladusaw, 1980" startWordPosition="1377" endWordPosition="1378">inite interpreted inside the scope of a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the possibilities for i</context>
</contexts>
<marker>Ladusaw, 1980</marker>
<rawString>William A. Ladusaw. 1980. On the notion ‘affective’ in the analysis of negative polarity items. Journal of Linguistic Research, 1(1):1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 Shared Task.</title>
<date>2011</date>
<booktitle>In Proceedings of CoNLL-2011: Shared Task,</booktitle>
<pages>28--34</pages>
<contexts>
<context position="2819" citStr="Lee et al., 2011" startWordPosition="409" endWordPosition="412">f, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford coreference resolution system (Lee et al., 2011). This addition results in a significant improvement on the CoNLL-2012 Shared Task data, across the MUC, B3, CEAF, and CoNLL scoring algorithms. 2 Data All the data used throughout the paper come from the CoNLL-2012 Shared Task (Pradhan et al., 2012), which included the 1.6M English words from OntoNotes v5.0 (Hovy et al., 2006) that have been annotated with different layers of annotation (coreference, parse trees, etc.). We used the training, development (dev), and test splits as defined in the shared task (Table 1). Since the OntoNotes coreference annotations do not contain singleton mentions</context>
<context position="12573" citStr="Lee et al., 2011" startWordPosition="1976" endWordPosition="1979"> indicate a statistically significant difference (paired Mann-Whitney U-test, p &lt; 0.05). B3 CEAF-03 CoNLL System R P F1 R P F1 F1 Baseline 58.53* 71.58 64.40 63.71* 58.31 60.89 58.86 w/ Lifespan 58.14 73.14* 64.78* 63.38 58.83* 61.02 59.52* Table 7: B3, CEAF-03 and CoNLL measures on the test set according to a modified CoNLL-2012 scorer that follows Cai and Strube (2010). Scores are on automatically predicted mentions. 4 Application to coreference resolution To assess the usefulness of the lifespan model in an NLP application, we incorporate it into the Stanford coreference resolution system (Lee et al., 2011), which we take as our baseline. This was the highestscoring system in the CoNLL-2011 Shared Task, and was also part of the highest-scoring system in the CoNLL-2012 Shared Task (Fernandes et al., 2012). It is a rule-based system that includes a total of ten rules (or “sieves”) for entity coreference, such as exact string match and pronominal resolution. The sieves are applied from highest to lowest precision, each rule adding coreference links. Incorporating the lifespan model The lifespan model can improve coreference resolution in two different ways: (i) mentions classified as singletons sho</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 Shared Task. In Proceedings of CoNLL-2011: Shared Task, pages 28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP</booktitle>
<pages>25--32</pages>
<contexts>
<context position="15055" citStr="Luo, 2005" startWordPosition="2380" endWordPosition="2381">h the STANDARD model. Results and discussion To evaluate the coreference system with and without the lifespan model, we used the English dev and test sets from the CoNLL2012 Shared Task, presented in Section 2. Although the CoNLL shared task evaluated systems on only multi-mention (i.e., non-singleton) entities, by stopping singletons from being linked to multi-mention entities, we expected the lifespan model to increase the system’s precision. Our evaluation uses five of the measures given by the CoNLL-2012 scorer: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF-03 and CEAF-04 (Luo, 2005), and the CoNLL official score (Denis and Baldridge, 2009). We do not include BLANC (Recasens and Hovy, 2011) because it assumes gold mentions and so is not suited for the scenario considered in this paper, which uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained above. As expected, the lifespan model increases precision but</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proceedings of HLT-EMNLP 2005, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara H Partee</author>
</authors>
<title>Noun phrase interpretation and type-shifting principles.</title>
<date>1987</date>
<booktitle>Studies in Discourse Representation Theory and the Theory of Generalized Quantifiers,</booktitle>
<pages>115--143</pages>
<editor>In Jeroen Groenendijk, Dick de Jong, and Martin Stokhof, editors,</editor>
<publisher>Foris Publications,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="5564" citStr="Partee, 1987" startWordPosition="849" endWordPosition="850">rphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animat</context>
</contexts>
<marker>Partee, 1987</marker>
<rawString>Barbara H. Partee. 1987. Noun phrase interpretation and type-shifting principles. In Jeroen Groenendijk, Dick de Jong, and Martin Stokhof, editors, Studies in Discourse Representation Theory and the Theory of Generalized Quantifiers, pages 115–143. Foris Publications, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>CoNLL2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP and CoNLL-2012: Shared Task,</booktitle>
<pages>1--40</pages>
<contexts>
<context position="3069" citStr="Pradhan et al., 2012" startWordPosition="450" endWordPosition="453">as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford coreference resolution system (Lee et al., 2011). This addition results in a significant improvement on the CoNLL-2012 Shared Task data, across the MUC, B3, CEAF, and CoNLL scoring algorithms. 2 Data All the data used throughout the paper come from the CoNLL-2012 Shared Task (Pradhan et al., 2012), which included the 1.6M English words from OntoNotes v5.0 (Hovy et al., 2006) that have been annotated with different layers of annotation (coreference, parse trees, etc.). We used the training, development (dev), and test splits as defined in the shared task (Table 1). Since the OntoNotes coreference annotations do not contain singleton mentions, we automatically marked as singletons all the NPs 627 Proceedings of NAACL-HLT 2013, pages 627–633, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics Dataset Docs Tokens MENTIONS Coreferent Singletons Training 2,802</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. CoNLL2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes. In Proceedings of EMNLP and CoNLL-2012: Shared Task, pages 1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Prince</author>
</authors>
<title>On the inferencing of indefinite ‘this’ NPs.</title>
<date>1981</date>
<booktitle>Elements of Discourse Understanding,</booktitle>
<pages>231--250</pages>
<editor>In Bonnie Lynn Webber, Ivan Sag, and Aravind Joshi, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="1822" citStr="Prince, 1981" startWordPosition="253" endWordPosition="254">n a variety of discourse contexts (coreferent), whereas others never escape their birthplaces, dying out after just one mention (singletons). The ability to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the </context>
<context position="5202" citStr="Prince (1981" startWordPosition="794" endWordPosition="795"> and negative ones favor singletons. We turn now to describing and motivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories st</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Ellen Prince. 1981a. On the inferencing of indefinite ‘this’ NPs. In Bonnie Lynn Webber, Ivan Sag, and Aravind Joshi, editors, Elements of Discourse Understanding, pages 231–250. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Toward a taxonomy of given– new information.</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>223--255</pages>
<editor>In Peter Cole, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1822" citStr="Prince, 1981" startWordPosition="253" endWordPosition="254">n a variety of discourse contexts (coreferent), whereas others never escape their birthplaces, dying out after just one mention (singletons). The ability to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the </context>
<context position="5202" citStr="Prince (1981" startWordPosition="794" endWordPosition="795"> and negative ones favor singletons. We turn now to describing and motivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories st</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Ellen F. Prince. 1981b. Toward a taxonomy of given– new information. In Peter Cole, editor, Radical Pragmatics, pages 223–255. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Core Team</author>
</authors>
<title>R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing,</title>
<date>2012</date>
<location>Vienna, Austria.</location>
<contexts>
<context position="4419" citStr="Team, 2012" startWordPosition="662" endWordPosition="663">letons (NPs not annotated as coreferent). not annotated as coreferent. Thus, our singletons include non-referential NPs but not verbal mentions. 3 Predicting lifespans Our lifespan model makes a binary distinction between discourse referents that are not part of a coreference chain (singletons) and items that are part of one (coreferent). The distribution of lifespans in our data (Figure 1) suggests that this is a natural division. The propensity of singletons also highlights the relevance of detecting singletons for a coreference system. We fit a binary logistic regression model in R (R Core Team, 2012) on the training data, coding singletons as “0” and coreferent mentions as “1”. Throughout the following tables of coefficient estimates, positive values favor coreferents and negative ones favor singletons. We turn now to describing and motivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in</context>
</contexts>
<marker>Team, 2012</marker>
<rawString>R Core Team, 2012. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Eduard Hovy</author>
</authors>
<title>A deeper look into features for coreference resolution.</title>
<date>2009</date>
<booktitle>Anaphora Processing and Applications,</booktitle>
<volume>5847</volume>
<pages>29--42</pages>
<editor>In Sobha Lalitha Devi, Ant´onio Branco, and Ruslan Mitkov, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="5065" citStr="Recasens and Hovy, 2009" startWordPosition="768" endWordPosition="771"> coding singletons as “0” and coreferent mentions as “1”. Throughout the following tables of coefficient estimates, positive values favor coreferents and negative ones favor singletons. We turn now to describing and motivating the features of this model. 0 5K 15K 25K Singleton 2 3 4 5 6-10 11-15 16-20 &gt;20 Figure 1: Distribution of lifespans in the dev set. Singletons account for 56% of the data. Internal morphosyntax of the mention Table 2 summarizes the features from our model that concern the internal morphology and syntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coe</context>
</contexts>
<marker>Recasens, Hovy, 2009</marker>
<rawString>Marta Recasens and Eduard Hovy. 2009. A deeper look into features for coreference resolution. In Sobha Lalitha Devi, Ant´onio Branco, and Ruslan Mitkov, editors, Anaphora Processing and Applications, volume 5847 of Lecture Notes in Computer Science, pages 29– 42. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Eduard Hovy</author>
</authors>
<title>BLANC: Implementing the Rand index for coreference evaluation.</title>
<date>2011</date>
<journal>Natural Language Engineering,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="15164" citStr="Recasens and Hovy, 2011" startWordPosition="2396" endWordPosition="2399">t the lifespan model, we used the English dev and test sets from the CoNLL2012 Shared Task, presented in Section 2. Although the CoNLL shared task evaluated systems on only multi-mention (i.e., non-singleton) entities, by stopping singletons from being linked to multi-mention entities, we expected the lifespan model to increase the system’s precision. Our evaluation uses five of the measures given by the CoNLL-2012 scorer: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF-03 and CEAF-04 (Luo, 2005), and the CoNLL official score (Denis and Baldridge, 2009). We do not include BLANC (Recasens and Hovy, 2011) because it assumes gold mentions and so is not suited for the scenario considered in this paper, which uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained above. As expected, the lifespan model increases precision but decreases recall. Overall, however, we obtain a significant improvement of 0.5–1 points in the F1 score of M</context>
</contexts>
<marker>Recasens, Hovy, 2011</marker>
<rawString>Marta Recasens and Eduard Hovy. 2011. BLANC: Implementing the Rand index for coreference evaluation. Natural Language Engineering, 17(4):485–510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craige Roberts</author>
</authors>
<title>Modal Subordination, Anaphora, and Distributivity.</title>
<date>1990</date>
<publisher>Garland,</publisher>
<location>New York.</location>
<contexts>
<context position="2178" citStr="Roberts, 1990" startWordPosition="309" endWordPosition="310">urse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the existing literature leads us to expect, and that the model itself is highly effective at predicting whether a given mention is singleton or coreferent. We then provide an initial assessment of the engineering value of making the singleton/coreferent distinction by incorporating our lifespan model into the Stanford corefer</context>
</contexts>
<marker>Roberts, 1990</marker>
<rawString>Craige Roberts. 1990. Modal Subordination, Anaphora, and Distributivity. Garland, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craige Roberts</author>
</authors>
<title>Anaphora in intensional contexts.</title>
<date>1996</date>
<booktitle>The Handbook of Contemporary Semantic Theory,</booktitle>
<pages>215--246</pages>
<editor>In Shalom Lappin, editor,</editor>
<publisher>Blackwell Publishers,</publisher>
<location>Oxford.</location>
<contexts>
<context position="9104" citStr="Roberts, 1996" startWordPosition="1408" endWordPosition="1409">ion]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates. These features tend to bias in favor of singletons because they so radically restrict the possibilities for intersentential anaphora. Interacting these features with those for the internal syntax of mentions is also informative. Since proper names and pronouns are not scope-taking, they are largely unaffected by the e</context>
</contexts>
<marker>Roberts, 1996</marker>
<rawString>Craige Roberts. 1996. Anaphora in intensional contexts. In Shalom Lappin, editor, The Handbook of Contemporary Semantic Theory, pages 215–246. Blackwell Publishers, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Rooryck</author>
</authors>
<title>Evidentiality, Part II.</title>
<date>2001</date>
<journal>Glot International,</journal>
<volume>5</volume>
<issue>5</issue>
<contexts>
<context position="10262" citStr="Rooryck, 2001" startWordPosition="1585" endWordPosition="1586"> not scope-taking, they are largely unaffected by the environment features, whereas indefinites emerge as even more restricted, just as Karttunen and others would predict. Attitude predicates seem initially anomalous, though. They share the relevant semantic properties with negation and modals, and yet they seem to facilitate coreference. Here, the findings of de Marneffe et al. (2012) seem informative. Those authors find that, in texts of the sort we are studying, attitude predicates are used predominantly to mark the source of information that is effectively asserted despite being embedded (Rooryck, 2001; Simons, 2007). That is, though X said p does not semantically entail p, it is often interpreted as a commitment to p, which correspondingly elevates mentions in p to main-clause status (Harris and Potts, 2009). Estimate P-value Presence of negation −0.18 &lt; 0.001 Presence of modality −0.22 &lt; 0.001 Under an attitude verb 0.03 0.01 AttitudeVerb * (Type = pronoun) 0.29 &lt; 0.001 AttitudeVerb * (Type = proper noun) 0.14 &lt; 0.001 Modal * (Type = pronoun) 0.12 0.04 Modal * (Type = proper noun) 0.35 &lt; 0.001 Negation * (Type = pronoun) 1.07 &lt; 0.001 Negation * (Type = proper noun) 0.30 &lt; 0.001 Negation *</context>
</contexts>
<marker>Rooryck, 2001</marker>
<rawString>Johan Rooryck. 2001. Evidentiality, Part II. Glot International, 5(5):161–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schwarzschild</author>
</authors>
<title>Singleton indefinites.</title>
<date>2002</date>
<journal>Journal of Semantics,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="8777" citStr="Schwarzschild, 2002" startWordPosition="1358" endWordPosition="1359"> interactions have been a focus of logical semantics since Karttunen (1976), whose guiding observation is semantic: an indefinite interpreted inside the scope of a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the scope of that operator, as in Kim didn’t understand [an exam question]. #Iti was too hard. Of course, such discourses cohere if the indefinite is interpreted as taking wide scope (‘there is a question Kim didn’t understand’). Such readings are often disfavored, but they become more salient when modifiers like certain are included (Schwarzschild, 2002) or when the determiner is sensitive to the polarity or intensionality of its environment (Baker, 1970; Ladusaw, 1980; van der Wouden, 1997; Israel, 1996; Israel, 2001; Giannakidou, 1999). Subsequent research identified many other factors that further extend or restrict the anaphoric potential of an indefinite (Roberts, 1996). We do not have direct access to semantic scope, but we expect syntactic scope to correlate strongly with semantic scope, so we used dependency representations to define features capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude pred</context>
</contexts>
<marker>Schwarzschild, 2002</marker>
<rawString>Roger Schwarzschild. 2002. Singleton indefinites. Journal of Semantics, 19(3):289–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mandy Simons</author>
</authors>
<title>Observations on embedding verbs, evidentiality, and presupposition.</title>
<date>2007</date>
<journal>Lingua,</journal>
<volume>117</volume>
<issue>6</issue>
<contexts>
<context position="10277" citStr="Simons, 2007" startWordPosition="1587" endWordPosition="1588">ng, they are largely unaffected by the environment features, whereas indefinites emerge as even more restricted, just as Karttunen and others would predict. Attitude predicates seem initially anomalous, though. They share the relevant semantic properties with negation and modals, and yet they seem to facilitate coreference. Here, the findings of de Marneffe et al. (2012) seem informative. Those authors find that, in texts of the sort we are studying, attitude predicates are used predominantly to mark the source of information that is effectively asserted despite being embedded (Rooryck, 2001; Simons, 2007). That is, though X said p does not semantically entail p, it is often interpreted as a commitment to p, which correspondingly elevates mentions in p to main-clause status (Harris and Potts, 2009). Estimate P-value Presence of negation −0.18 &lt; 0.001 Presence of modality −0.22 &lt; 0.001 Under an attitude verb 0.03 0.01 AttitudeVerb * (Type = pronoun) 0.29 &lt; 0.001 AttitudeVerb * (Type = proper noun) 0.14 &lt; 0.001 Modal * (Type = pronoun) 0.12 0.04 Modal * (Type = proper noun) 0.35 &lt; 0.001 Negation * (Type = pronoun) 1.07 &lt; 0.001 Negation * (Type = proper noun) 0.30 &lt; 0.001 Negation * (Quantifier = </context>
</contexts>
<marker>Simons, 2007</marker>
<rawString>Mandy Simons. 2007. Observations on embedding verbs, evidentiality, and presupposition. Lingua, 117(6):1034–1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ton van der Wouden</author>
</authors>
<title>Negative Contexts: Collocation, Polarity and Multiple Negation. Routledge, London and</title>
<date>1997</date>
<location>New York.</location>
<marker>van der Wouden, 1997</marker>
<rawString>Ton van der Wouden. 1997. Negative Contexts: Collocation, Polarity and Multiple Negation. Routledge, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A modeltheoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of MUC-6,</booktitle>
<pages>45--52</pages>
<contexts>
<context position="14992" citStr="Vilain et al., 1995" startWordPosition="2368" endWordPosition="2371">coreference (on the dev set) was higher with the CONFIDENT model than with the STANDARD model. Results and discussion To evaluate the coreference system with and without the lifespan model, we used the English dev and test sets from the CoNLL2012 Shared Task, presented in Section 2. Although the CoNLL shared task evaluated systems on only multi-mention (i.e., non-singleton) entities, by stopping singletons from being linked to multi-mention entities, we expected the lifespan model to increase the system’s precision. Our evaluation uses five of the measures given by the CoNLL-2012 scorer: MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), CEAF-03 and CEAF-04 (Luo, 2005), and the CoNLL official score (Denis and Baldridge, 2009). We do not include BLANC (Recasens and Hovy, 2011) because it assumes gold mentions and so is not suited for the scenario considered in this paper, which uses automatically predicted mentions. Table 6 summarizes the test set performance. All the scores are on automatically predicted mentions. We use gold POS, parse trees, and NEs. The base630 line is the Stanford system, and ‘w/Lifespan’ is the same system extended with our lifespan model to discard singletons, as explained</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme. In Proceedings of MUC-6, pages 45–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Aravind K Joshi</author>
</authors>
<date>1997</date>
<booktitle>Centering in Discourse.</booktitle>
<editor>and Ellen F. Prince, editors.</editor>
<publisher>Oxford University Press.</publisher>
<marker>Walker, Joshi, 1997</marker>
<rawString>Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors. 1997. Centering in Discourse. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Aravind K Joshi</author>
<author>Ellen F Prince</author>
</authors>
<title>Centering in naturally-occurring discourse: An overview.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>1--28</pages>
<editor>In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors,</editor>
<publisher>Clarendon Press.</publisher>
<location>Oxford.</location>
<contexts>
<context position="6277" citStr="Walker et al., 1998" startWordPosition="955" endWordPosition="958">tive coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animates are excellent coreferent NPs, a previous finding of Centering Theory (Grosz et al., 1995; Walker et al., 1998) and of cross-linguistic work on obviative case-marking (Aissen, 1997). Our model also includes named-entity features for all of the eighteen OntoNotes entity-types (omitted from Table 2 for space and clarity reasons). As a rule, they behave like ‘Type = proper noun’ in associating with coreferents. The exceptions are ORDINAL, PERCENT, and QUANTITY, which seem intuitively unlikely to participate in coreference chains. Estimate P-value Type =pronoun 1.21 &lt; 0.001 Type = proper noun 1.88 &lt; 0.001 Animacy = inanimate −1.36 &lt; 0.001 Animacy = unknown −0.38 &lt; 0.001 Person = 1 1.05 &lt; 0.001 Person = 2 0</context>
</contexts>
<marker>Walker, Joshi, Prince, 1998</marker>
<rawString>Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince. 1998. Centering in naturally-occurring discourse: An overview. In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors, Centering Theory in Discourse, pages 1–28, Oxford. Clarendon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linton Wang</author>
<author>Eric McCready</author>
<author>Nicholas Asher</author>
</authors>
<title>Information dependency in quantificational subordination.</title>
<date>2006</date>
<booktitle>In Klaus von Heusinger and</booktitle>
<pages>267--304</pages>
<editor>Ken Turner, editors,</editor>
<publisher>Elsevier Science,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="1858" citStr="Wang et al., 2006" startWordPosition="257" endWordPosition="260">xts (coreferent), whereas others never escape their birthplaces, dying out after just one mention (singletons). The ability to make this distinction based on properties of the NPs used to identify these referents (mentions) would benefit not only coreference resolution, but also topic analysis, textual entailment, and discourse coherence. The existing literature provides numerous generalizations relevant to answering the question of whether a given discourse entity will be singleton or coreferent. These involve the internal syntax and morphology of the target NP (Prince, 1981a; Prince, 1981b; Wang et al., 2006), the grammatical function and discourse role of that NP (Chafe, 1976; Hobbs, 1979; Walker et al., 1997; Beaver, 2004), and the interaction of all of those features with semantic operators like negation, modals, and attitude predicates (Karttunen, 1973; Karttunen, 1976; Kamp, 1981; Heim, 1982; Heim, 1992; Roberts, 1990; Groenendijk and Stokhof, 1991; Bittner, 2001). The first step in our analysis is to bring these insights together into a single logistic regression model — the lifespan model — and assess their predictive power on real data. We show that the features generally behave as the exi</context>
<context position="5584" citStr="Wang et al., 2006" startWordPosition="851" endWordPosition="854">yntactic structure of the mention. Many are common in coreference systems (Recasens and Hovy, 2009), but our model highlights their influence on lifespans. The picture is expected on the taxonomy of given and new defined by Prince (1981b) and assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric connections to previous mentions for disambiguation and thus are very likely to be coreferent. This is corroborated by the positive coefficient estimate for ‘Type = pronoun’ in Table 2. Few quantified phrases easily participate in discourse anaphora (Partee, 1987; Wang et al., 2006), accounting for the association between quantifiers and singletons (negative coefficient estimate for ‘Quantifier = quantified’ in Table 2). The one surprise is the negative coefficient for indefinites. In theories stretching back to Karttunen (1976), indefinites function primarily to establish new discourse entities, and should be able to participate in coreference chains, but here the association with such chains is negative. However, interactions explain this fact (see Table 4 and our discussion of it). The person, number, and animacy values suggest that singular animates are excellent cor</context>
</contexts>
<marker>Wang, McCready, Asher, 2006</marker>
<rawString>Linton Wang, Eric McCready, and Nicholas Asher. 2006. Information dependency in quantificational subordination. In Klaus von Heusinger and Ken Turner, editors, Where Semantics Meets Pragmatics, pages 267–304. Elsevier Science, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Ward</author>
<author>Betty Birner</author>
</authors>
<title>Information structure and non-canonical syntax.</title>
<date>2004</date>
<booktitle>The Handbook of Pragmatics,</booktitle>
<pages>153--174</pages>
<editor>In Laurence R. Horn and Gregory Ward, editors,</editor>
<publisher>Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="7397" citStr="Ward and Birner, 2004" startWordPosition="1135" endWordPosition="1138">Animacy = inanimate −1.36 &lt; 0.001 Animacy = unknown −0.38 &lt; 0.001 Person = 1 1.05 &lt; 0.001 Person = 2 0.13 &lt; 0.001 Person = 3 1.62 &lt; 0.001 Number = singular 0.61 &lt; 0.001 Number = unknown 0.17 &lt; 0.001 Quantifier = indefinite −1.49 &lt; 0.001 Quantifier = quantified −1.23 &lt; 0.001 Number of modifiers −0.39 &lt; 0.001 Table 2: Internal morphosyntactic features. Grammatical role of the mention Synthesizing much work in Centering Theory and information structuring, we conclude that coreferent mentions are likely to appear as core verbal arguments and will favor sentence-initial (topic-tracking) positions (Ward and Birner, 2004). The coefficient estimates 628 Estimate P-value Sentence Position = end −0.22 &lt; 0.001 Sentence Position = first 0.04 0.07 Sentence Position = last −0.31 &lt; 0.001 Sentence Position = middle −0.11 &lt; 0.001 Relation = noun argument 0.56 &lt; 0.001 Relation = other −0.67 &lt; 0.001 Relation = root −0.61 &lt; 0.001 Relation = subject 0.65 &lt; 0.001 Relation = verb argument 0.32 &lt; 0.001 In coordination −0.48 &lt; 0.001 Table 3: Grammatical role features. in Table 3 corroborate these conclusions. To define the ‘Relation’ and ‘In coordination’ features, we used the Stanford dependencies (de Marneffe et al., 2006) on</context>
</contexts>
<marker>Ward, Birner, 2004</marker>
<rawString>Gregory Ward and Betty Birner. 2004. Information structure and non-canonical syntax. In Laurence R. Horn and Gregory Ward, editors, The Handbook of Pragmatics, pages 153–174. Blackwell, Oxford.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>