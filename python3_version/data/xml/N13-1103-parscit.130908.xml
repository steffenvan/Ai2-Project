<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.998921">
Using Semantic Unification to Generate
Regular Expressions from Natural Language
</title>
<author confidence="0.996428">
Nate Kushman Regina Barzilay
</author>
<affiliation confidence="0.997886">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.997409">
{nkushman, regina}@csail.mit.edu
</email>
<sectionHeader confidence="0.993775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999244888888889">
We consider the problem of translating natu-
ral language text queries into regular expres-
sions which represent their meaning. The mis-
match in the level of abstraction between the
natural language representation and the regu-
lar expression representation make this a novel
and challenging problem. However, a given
regular expression can be written in many se-
mantically equivalent forms, and we exploit
this flexibility to facilitate translation by find-
ing a form which more directly corresponds to
the natural language. We evaluate our tech-
nique on a set of natural language queries
and their associated regular expressions which
we gathered from Amazon Mechanical Turk.
Our model substantially outperforms a state-
of-the-art semantic parsing baseline, yielding
a 29% absolute improvement in accuracy.1
</bodyText>
<sectionHeader confidence="0.998959" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999583">
Regular expressions (regexps) have proven them-
selves to be an extremely powerful and versatile for-
malism that has made its way into everything from
spreadsheets to databases. However, despite their
usefulness and wide availability, they are still con-
sidered a dark art that even many programmers do
not fully understand (Friedl, 2006). Thus, the ability
to automatically generate regular expressions from
natural language would be useful in many contexts.
Our goal is to learn to generate regexps from nat-
ural language, using a training set of natural lan-
guage and regular expression pairs such as the one
in Figure 1. We do not assume that the data includes
an alignment between fragments of the natural lan-
guage and fragments of the regular expression. In-
</bodyText>
<footnote confidence="0.9923095">
1The dataset used in this work is available at
http://groups.csail.mit.edu/rbg/code/regexp/
</footnote>
<table confidence="0.7004215">
Text Description Regular Expression
three letter word starting with ’X’ \bX[A-Za-z]{2}\b
</table>
<figureCaption confidence="0.9842505">
Figure 1: An example text description and its associated
regular expression.3
</figureCaption>
<bodyText confidence="0.999908931034483">
ducing such an alignment during learning is partic-
ularly challenging because oftentimes even humans
are unable to perform a fragment-by-fragment align-
ment.
We can think of this task as an instance of
grounded semantic parsing, similar to the work
done in the domain of database queries (Kate and
Mooney, 2006; Zettlemoyer and Collins, 2005;
Kwiatkowski et al., 2010). However, the current
success in semantic parsing relies on two impor-
tant properties of the data. First, while the past
work did not assume the alignment was given, they
did assume that finding a fine grained fragment-
by-fragment alignment was possible. Secondly,
the semantic domains considered in the past were
strongly typed. This typing provides constraints
which significantly reduce the space of possible
parses, thereby greatly reducing the ambiguity.
However, in many interesting domains these two
properties may not hold. In our domain, the align-
ment between the natural language and the regu-
lar expressions often happens at the level of the
whole phrase, making fragment-by-fragment align-
ment impossible. For example, in Figure 1 no frag-
ment of the regexp maps clearly to the phrase “three
letter”. Instead, the regexp explicitly represents the
fact that there is only two characters after X, which is
not stated explicitly by the text description and must
be inferred. Furthermore, regular expressions have
</bodyText>
<footnote confidence="0.93540875">
3Our regular expression syntax supports Perl regular expres-
sion shorthand which utilizes \b to represent a break (i.e. a
space or the start or end of the line). Our regular expression
syntax also supports intersection (&amp;) and complement(˜).
</footnote>
<page confidence="0.952201">
826
</page>
<note confidence="0.512334">
Proceedings of NAACL-HLT 2013, pages 826–836,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<figure confidence="0.903462">
([A-Za-z]{3})&amp;(\b[A-Za-z]+\b)&amp;(X.*)
three letter [A-Za-z]{3}
word \b[A-Za-z]+\b
starting with ’X’ X.*
</figure>
<figureCaption confidence="0.9937565">
Figure 2: (a) shows a regexp which is semantically
equivalent to that in Figure 1, yet admits a fragment-by-
fragment mapping to the natural language. (b) shows this
mapping.
</figureCaption>
<bodyText confidence="0.998625972222223">
relatively few type constraints.
The key idea of our work is to utilize semantic
unification in the logical domain to disambiguate the
meaning of the natural language. Semantic unifi-
cation utilizes an inference engine to determine the
semantic equality of two syntactically divergent ex-
pressions. This is a departure from past work on se-
mantic parsing which has largely focused on the syn-
tactic interface between the natural language and the
logical form, and on example-based semantic equal-
ity, neither of which utilize the inference power in-
herent in many symbolic domains.
To see how we can take advantage of semantic
unification, consider the regular expression in Fig-
ure 2(a). This regular expression is semantically
equivalent to the regular expression in Figure 1. Fur-
thermore, it admits a fragment-by-fragment map-
ping as can be seen in Figure 2(b). In contrast, as
we noted earlier, the regexp in Figure 1 does not ad-
mit such a mapping. In fact, learning can be quite
difficult if our training data contains only the regexp
in Figure 1. We can, nonetheless, use the regexp in
Figure 2 as a stepping-stone for learning if we can
use semantic inference to determine the equivalence
between the two regular expressions. More gener-
ally, whenever the regexp in the training data does
not factorize in a way that facilitates a direct map-
ping to the natural language description, we must
find a regexp which does factorize and be able to
compute its equivalence to the regexp we see in the
training data. We compute this equivalence by con-
verting each regexp to a minimal deterministic finite
automaton (DFA) and leveraging the fact that mini-
mal DFAs are guaranteed to be the same for seman-
tically equivalent regexps (Hopcroft et al., 1979).
We handle the additional ambiguity stemming
from the weak typing in our domain through the use
of a more effective parsing algorithm. The state of
the art semantic parsers (Kwiatkowski et al., 2011;
Liang et al., 2011) utilize a pruned chart parsing
algorithm which fails to represent many of the top
parses and is prohibitively slow in the face of weak
typing. In contrast, we use an n-best parser which
always represents the most likely parses, and can be
made very efficient through the use of the parsing
algorithm from Jimenez and Marzal (2000).
Our approach works by inducing a combinatory
categorial grammar (CCG) (Steedman, 2001). This
grammar consists of a lexicon which pairs words
or phrases with regular expression functions. The
learning process initializes the lexicon by pairing
each sentence in the training data with the full reg-
ular expression associated with it. These lexical en-
tries are iteratively refined by considering all possi-
ble ways to split the regular expression and all pos-
sible ways to split the phrase. At each iteration we
find the n-best parses with the current lexicon, and
find the subset of these parses which are correct us-
ing DFA equivalence. We update the weights of a
log-linear model based on these parses and the cal-
culated DFA equivalence.
We evaluate our technique using a dataset of sen-
tence/regular expression pairs which we generated
using Amazon Mechanical Turk (Turk, 2013). We
find that our model generates the correct regexp
for 66% of sentences, while the state-of-the-art se-
mantic parsing technique from Kwiatkowski et al.
(2010) generates correct regexps for only 37% of
sentences. The results confirm our hypothesis that
leveraging the inference capabilities of the seman-
tic domain can help disambiguate natural language
meaning.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.994429923076923">
Generating Regular Expressions Past work has
looked at generating regular expressions from nat-
ural language using rule based techniques (Ranta,
1998), and also at automatically generating regular
expressions from examples (Angluin, 1987). To the
best of our knowledge, however, our work is the first
to use training data to learn to automatically gener-
ate regular expressions from natural language.
Language Grounding There is a large body of re-
search mapping natural language to some form of
meaning representation (Kate and Mooney, 2006;
Kate et al., 2005; Raymond and Mooney, 2006;
Thompson and Mooney, 2003; Wong and Mooney,
</bodyText>
<page confidence="0.995364">
827
</page>
<bodyText confidence="0.999810953488372">
2006; Wong and Mooney, 2007; Zelle and Mooney,
1996; Branavan et al., 2009; Mihalcea et al., 2006;
Poon and Domingos, 2009). In some of the consid-
ered domains the issue of semantic equivalence does
not arise because of the way the data is generated.
The most directly related work in these domains, is
that by Kwiatkowski et al. (2010 and 2011) which is
an extension of earlier work on CCG-based semantic
parsing by Zettlemoyer and Collins (2005). Similar
to our work, Kwiatkowski et al. utilize unification to
find possible ways to decompose the logical form.
However, they perform only syntactic unification.
Syntactic unification determines equality using only
variable substitutions and does not take advantage of
the inference capabilities available in many semantic
domains. Thus, syntactic unification is unable to de-
termine the equivalence of two logical expressions
which use different lexical items, such as “.*” and
“.*.*”. In contrast, our DFA based technique can
determine the equivalence of such expressions. It
does this by leveraging the equational inference ca-
pabilities of the regular expression domain, making
it a form of semantic unification. Thus, the contribu-
tion of our work is to show that using semantic uni-
fication to find a deeper level of equivalence helps to
disambiguate language meanings.
In many other domains of interest, determining
semantic equivalence is important to the learning
process. Previous work on such domains has fo-
cused on either heuristic or example-driven mea-
sures of semantic equivalence. For example, Artzi
and Zettlemoyer (2011) estimate semantic equiva-
lence using a heuristic loss function. Other past
work has executed the logical form on an example
world or in a situated context and then compared the
outputs. This provides a very weak form of semantic
equivalence valid only in that world/context (Clarke
et al., 2010; Liang et al., 2009; Liang et al., 2011;
Chen and Mooney, 2011; Artzi and Zettlemoyer,
2013). In contrast, our work uses an exact, theoret-
ically sound measure of semantic equivalence that
determines whether two logical representations are
equivalent in any context, i.e. on any input string.
</bodyText>
<sectionHeader confidence="0.999447" genericHeader="method">
3 Background
</sectionHeader>
<subsectionHeader confidence="0.999971">
3.1 Finding Regexp Equivalence Using DFAs
</subsectionHeader>
<bodyText confidence="0.646105142857143">
Regular expressions can be equivalently represented
as minimal DFAs, which are guaranteed to be equal
function sig. regexp function signature regexp
cons(R,R,...) ab rep*(R) a*
and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5}
or(R,R,...) a|b repmin(I,R) a13,}
not(R) ˜(a) repexact(I,R) a13}
</bodyText>
<figureCaption confidence="0.9649915">
Figure 3: This shows the signatures of all functions in our
lambda calculus along with their regexp syntax.
</figureCaption>
<bodyText confidence="0.999838230769231">
for the same regular language (Hopcroft et al.,
1979). The DFA representation of a regular expres-
sion may be exponentially larger than the the orig-
inal regular expression. However, past work has
shown that most regular expressions do not exhibit
this exponential behavior (Tabakov and Vardi, 2005;
Moreira and Reis, 2012), and the conversion pro-
cess is renowned for its good performance in prac-
tice (Moreira and Reis, 2012). Hence, we compare
the equivalence of two regular expressions by con-
verting them to minimal DFAs and comparing the
DFAs. We do this using a modified version of Møller
(2010).4
</bodyText>
<subsectionHeader confidence="0.999291">
3.2 Lambda Calculus Representation
</subsectionHeader>
<bodyText confidence="0.999993666666667">
To take advantage of the inherent structure of reg-
ular expressions, we deterministically convert them
from a flat string representation into simply typed
lambda calculus expressions. The full set of func-
tions available in our lambda calculus can be seen
in Figure 3. As can be seen from the figures, our
lambda calculus is very weakly typed. It has only
two primitive types, integer (I) and regexp (R), with
most arguments being of type R.
</bodyText>
<subsectionHeader confidence="0.999043">
3.3 Parsing
</subsectionHeader>
<bodyText confidence="0.979580533333333">
Our parsing model is based on a Combinatory Cate-
gorial Grammar. In CCG parsing most of the gram-
mar complexity is contained in the lexicon, A, while
the parser itself contains only a few simple rewrite
rules called combinators.
Lexicon The lexicon, A, consists of a set of lexical
entries that couple natural language with a lambda
calculus expression. Our lexical entries contain
words or phrases, each of which is associated with
a function from the lambda calculus we described
in §3.2. For example:
4We set a timeout on this process to catch any cases where
the resulting DFA might be prohibitively large. We use a one
second timeout in our experiments, which results in timeouts
on less than 0.25% of the regular expressions.
</bodyText>
<page confidence="0.971669">
828
</page>
<figure confidence="0.9994684">
with R ’bob’ —– ’joe’
bob after —–
R
joe
R/R R\R/R
fix(.*x.*) -ry.(x.*y)
————————–(f)
(f)
R
.*joe.*bob.*
</figure>
<figureCaption confidence="0.984141">
Figure 4: This shows an example parse.
</figureCaption>
<equation confidence="0.680323285714286">
R\R
Ay.joe.*y
————————————(b)
R
joe.*bob
( after, R\R/R:Axy.(x.*y) )
( at least, R/I/R:Axy.((x){y,}) )
</equation>
<bodyText confidence="0.999911866666667">
Note that the lambda expressions contain type infor-
mation indicating the number of arguments and the
type of those arguments as described in §3.2. How-
ever, this information is augmented with a (/) or a
(\) for each argument indicating whether that argu-
ment comes from the left or the right, in sentence
order. Thus R\R/R can be read as a function which
first takes an argument of type R on the right then
takes another argument of type R on the left, and
returns an expression of type R.
Combinators Parses are built by combining lexical
entries through the use of a set of combinators. Our
parser uses only the two most basic combinators,
forward function application and backward function
application.5 These combinators work as follows:
</bodyText>
<equation confidence="0.8374465">
R/R:f R:g R:f(g) (forward)
R:f R\R:g R:g(f) (backward)
</equation>
<bodyText confidence="0.9999972">
The forward combinator applies a function to an ar-
gument on its right when the type of the argument
matches the type of the function’s first argument.
The backward combinator works analogously. Fig-
ure 4 shows an example parse.
</bodyText>
<sectionHeader confidence="0.996149" genericHeader="method">
4 Parsing Model
</sectionHeader>
<bodyText confidence="0.978446">
For a given lexicon, A, and sentence, w, there will in
general be many valid parse trees, t E T (w; A). We
assign probabilities to these parses using a standard
log-linear parsing model with parameters 0:
Et, eθ φ(t&apos;,~w)
Our training data, however, includes only the cor-
rect regular expression, r, and not the correct parse,
5Technically, this choice of combinators makes our model
just a Categorial Grammar instead of a CCG.
t. The training objective used by the past work in
such circumstances, is to maximize the probability
of the correct regular expression by marginalizing
over all parses which generate that exact regular ex-
pression. Such an objective is limited, however, be-
cause it does not allow parses that generate seman-
tically correct regexps which are not syntactically
equivalent to r, such as those in Figure 2. The main
departure of our work is to use an objective which al-
lows such parses through the use of the DFA-EQUAL
procedure. DFA-EQUAL uses the process described
in §3.1 to determine whether parse t evaluates to a
regexp which is semantically equivalent to r, lead-
ing to the following objective:
</bodyText>
<equation confidence="0.9967135">
�O = log � p(tJ~wi; θ, A) (1)
i t|DFA-EQUAL(t,ri)
</equation>
<bodyText confidence="0.9999398">
At testing time, for efficiency reasons, we calcu-
late only the top parse. Specifically, if r = eval(t)
is the regexp which results from evaluating parse t,
then we generate t* = arg maxtET(w) At|w; 0, A),
and return r* = eval(t*).
</bodyText>
<sectionHeader confidence="0.983612" genericHeader="method">
5 Learning
</sectionHeader>
<bodyText confidence="0.99997208">
Our learning algorithm starts by generating a single
lexical entry for each training sample which pairs
the full sentence, wi, with the associated regular ex-
pression, ri. Formally, we initialize the lexicon as
A = {(wi, R : ri) |i = 1... n}. We then run an iter-
ative process where in each iteration we update both
A and 0 for each training sample. Our initial A will
perfectly parse the training data. However it won’t
generalize at all to the test data since the lexical en-
tries contain only full sentences. Hence, in each
iteration we refine the lexicon by splitting existing
lexical entries to generate more granular lexical en-
tries which will generalize better. The candidates for
splitting are all lexical entries used by parses which
generate the correct regular expression, ri, for the
current training sample. We consider all possible
ways to factorize each lexical entry, and we add to
A a new lexical entry for each possible factorization,
as discussed in §5.2. Finally, we update 0 by per-
forming a single stochastic gradient ascent update
step for each training sample, as discussed in §5.1.
See Algorithm 1 for details.
This learning approach follows the structure
of the previous work on CCG based seman-
tic parsers (Zettlemoyer and Collins, 2005;
</bodyText>
<equation confidence="0.9853095">
eθ-φ(t,~w)
p(tJ~w; θ, A) =
</equation>
<page confidence="0.948992">
829
</page>
<bodyText confidence="0.407893333333333">
Inputs: Training set of sentence regular expression pairs.
I(4Li, ri) Ii = 1 ... n}
Functions:
</bodyText>
<listItem confidence="0.916711105263158">
• N-BEST(4L; B, A) n-best parse trees for L4 using the
algorithm from §5.1
• DFA-EQUAL(t, r) calculates the equality of the regexp
from parse t and regexp r using the algorithm from §3.1
• SPLIT-LEX(T) splits all lexical entries used by any
parse tree in set T, using the process described in §5.2
Initialization: A = I(4Li, R : ri) Ii = 1 ... n}
Fork= 1 ... K, i = 1 ... n
Update Lexicon: A
• T = N-BEST(4Li; B, A)
• C = Itlt E T ∧ DFA-EQUAL(t, ri)l
• A = A u SPLIT-LEX(C)
Update Parameters: B
• T = N-BEST(4Li; B, A)
• C = Itlt E T ∧ DFA-EQUAL(t, ri)l
• O = Ep(t|t∈C)10(t, 4L)] − Ep(t|t∈T)10(t, 4L)]
• B=B+caO
Output: The lexicon and the parameters, (A, B)
Algorithm 1: The full learning algorithm.
</listItem>
<bodyText confidence="0.998655363636364">
Kwiatkowski et al., 2010). However, our domain
has distinct properties that led to three important
departures from this past work.
First, we use the DFA based semantic unifica-
tion process described in §3.1 to determine the set
of correct parses when performing parameter up-
dates. This is in contrast to the syntactic unification
technique, used by Kwiatkowski et al. (2010), and
the example based unification used by other seman-
tic parsers, e.g. Artzi and Zettlemoyer (2011). Us-
ing semantic unification allows us to handle training
data which does not admit a fragment-by-fragment
mapping between the natural language and the reg-
ular expression, such as the example in Figure 2.
Second, our parser is based on the efficient n-best
parsing algorithm of Jimenez and Marzal (2000) in-
stead of the pruned chart parsing algorithm used
by the past work (Zettlemoyer and Collins, 2005;
Kwiatkowski et al., 2010). As we show in §8.2, this
results in a parser which more effectively represents
the most likely parses. This allows our parser to bet-
ter handle the large number of potential parses that
exist in our domain due to the weak typing.
Third, we consider splitting lexical entries used in
any correct parse, while the past work (Zettlemoyer
and Collins, 2005; Kwiatkowski et al., 2010) con-
siders splitting only those used in the best parse. We
must utilize a less constrictive splitting policy since
our domain does not admit the feature weight ini-
tialization technique used in the domains of the past
work. We discuss this in §5.2.1. In the remainder
of this section we discuss the process for learning 0
and for generating the lexicon, A.
</bodyText>
<subsectionHeader confidence="0.996073">
5.1 Estimating Theta
</subsectionHeader>
<bodyText confidence="0.9999318">
To estimate 0 we will use stochastic gradient ascent,
updating the parameters based on one training exam-
ple at a time. Hence, we can differentiate the objec-
tive from equation 1 to get the gradient of parameter
0j for training example i, as follows:
</bodyText>
<equation confidence="0.97772">
�Ep(t|DFA-EQUAL(t,ri),·) %(t, i i)] − Ep(t|·) %(t, i i)]
(2)
</equation>
<bodyText confidence="0.999759121212121">
This gives us the standard log-linear gradient, which
requires calculating expected feature counts. We de-
fine the features in our model over individual parse
productions, admitting the use of dynamic program-
ming to efficiently calculate the unconditioned ex-
pected counts. However, when we condition on gen-
erating the correct regular expression, as in the first
term in (2), the calculation no longer factorizes, ren-
dering exact algorithms computationally infeasible.
To handle this, we use an approximate gradient
calculation based on the n-best parses. Our n-best
parser uses an efficient algorithm developed orig-
inally by (Jimenez and Marzal, 2000), and subse-
quently improved by (Huang and Chiang, 2005).
This algorithm utilizes the fact that the first best
parse, t1, makes the optimal choice at each deci-
sion point, and the 2nd best parse, t2 must make the
same optimal choice at every decision point, except
for one. To execute on this intuition, the algorithm
first calculates t1 by generating an unpruned CKY-
style parse forest which includes a priority queue
of possible subparses for each constituent. The set
of possible 2nd best parses T are those that choose
the 2nd best subparse for exactly one constituent of
t1 but are otherwise identical to t1. The algorithm
chooses t2 = arg maxtET p(t). More generally,
T is maintained as a priority queue of possible nth
best parses. At each iteration, i, the algorithm sets
ti = arg maxtET p(t) and augments T by all parses
which both differ from ti at exactly one constituent
ci and choose the next best possible subparse for ci.
We use the n-best parses to calculate an approxi-
mate version of the gradient. Specifically, Ti is the
</bodyText>
<figure confidence="0.911807421052632">
aOi
aej
830
Original Tree
cons
cons
b o b rep*
rep*
.
. .
Parent Tree Child Tree
cons
rep* x rep* b o b
.
set of n-best parses for training sample i, and Ci in-
cludes all parses t in Ti such that DFA-EQUAL(t, ri).
We calculate the approximate gradient as:
A = Ep(t|tEC;;6,n)[�(t, wi)] − Ep(t|tET;;6,n)[O(t, A)]
(3)
</figure>
<bodyText confidence="0.999934648648649">
In contrast to our n-best technique, the past
work has calculated equation (2) using a beam
search approximation of the full inside-outside algo-
rithm (Zettlemoyer and Collins, 2005; Kwiatkowski
et al., 2010; Liang et al., 2011). Specifically, since
the conditional probability of t given r does not fac-
torize, a standard chart parser would need to main-
tain the full logical form (i.e. regular expression)
for each subparse, and there may be an exponential
number of such subparses at each chart cell. Thus,
they approximate this full computation using beam
search, maintaining only the m-best logical forms at
each chart cell.
Qualitatively, our n-best approximation always
represents the most likely parses in the approxima-
tion, but the number of represented parses scales
only linearly with n. In contrast, the number of
parses represented by the beam search algorithm
of the past work can potentially scale exponentially
with the beam size, m, due to its use of dynamic pro-
gramming. However, since the beam search prunes
myopically at each chart cell, it often prunes out
the highest probability parses. In fact, we find that
the single most likely parse is pruned out almost
20% of the time. Furthermore, our results in §8
show that the beam search’s inability to represent
the likely parses significantly impacts the overall
performance. It is also important to note that the
runtime of the n-best algorithm scales much better.
Specifically, as n increases, the n-best runtime in-
creases as O(n|w |log(|w||P |+ n), where P is the
set of possible parse productions. In contrast, as
m is increased, the beam search runtime scales as
O(|w|5m2), where the |w|5 factor comes from our
use of headwords, as discussed in §6. In practice,
we find that even with n set to 10, 000 and m set to
200, our algorithm still runs almost 20 times faster.
</bodyText>
<subsectionHeader confidence="0.998914">
5.2 Lexical Entry Splitting
</subsectionHeader>
<bodyText confidence="0.99966525">
Each lexical entry consists of a sequence of n
words aligned to a typed regular expression func-
tion, (w0q, T : r). Our splitting algorithm considers
all possible ways to split a lexical entry into two new
</bodyText>
<figure confidence="0.983198">
(a) (b) (c)
</figure>
<figureCaption confidence="0.999247">
Figure 5: The tree in (a) represents the lambda expression
from the lexical entry (with bob, R:.*bob.*). One pos-
sible split of this lexical entry generates the parent lexical
entry (with, R/R:Ax.(.*x.*)) and the child lexical en-
try, (bob, R:bob), whose lambda expressions are repre-
sented by (b) and (c), respectively.
</figureCaption>
<bodyText confidence="0.999688947368421">
lexical entries such that they can be recombined via
function application to obtain the original lexical en-
try. This process is analogous to the syntactic unifi-
cation process done by Kwiatkowski et al. (2010).
We first consider all possible ways to split the
lambda expression r. The splitting process is most
easily explained using a tree representation for r, as
shown in Figure 5(a). This tree format is simply a
convenient visual representation of a lambda calcu-
lus function, with each node representing one of the
function type constants from Figure 3. Each split,
s E 5(r), generates a child expression sc and a par-
ent expression sp such that r = sp(sc). For each
node, n, in r besides the root node, we generate a
split where sc is the subtree rooted at node n. For
such splits, sp is the lambda expression r with the
sub-expression sc replaced with a bound variable,
say x. In addition to these simple splits, we also con-
sider a set of more complicated splits at each node
whose associated function type constant can take
any number of arguments, i.e. or, and, or cons. If
C(n) are the children of node n, then we generate a
split for each possible subset, {V |V C C(n)}. Note
that for cons nodes V must be contiguous. In §6 we
discuss additional restrictions placed on the splitting
process to avoid generating an exponential number
of splits. For the split with subset V , the child tree,
sc, is a version of the tree rooted at node n pruned
to contain only the children in V . Additionally, the
parent tree, sp, is generated from r by replacing all
the children in V with a single bound variable, say
x. Figure 5 shows an example of such a split. We
only consider splits in which sc does not have any
bound variables, so its type, Tc, is always either R
or I. The type of sp is then type of the original ex-
pression, T augmented by an additional argument of
the child type, i.e. either TITc or T\Tc.
Each split s generates two pairs of lexical entries,
</bodyText>
<page confidence="0.995846">
831
</page>
<bodyText confidence="0.9941975">
one for forward application, and one for backward
application. The set of suchairs of pairs is:
</bodyText>
<equation confidence="0.986334333333333">
{( (w0:j, T/Tc : sp),�wj:l, Tc : sc)),
((w0:j, Tc : sc) , (wj:l, T\Tc : sp�)|
(0 &lt; j &lt; l) n (s E S(r))}
</equation>
<subsectionHeader confidence="0.881994">
5.2.1 Adding New Lexical Entries
</subsectionHeader>
<bodyText confidence="0.999976578947368">
Our model splits all lexical entries used in parses
which generate correct regular expressions, i.e.
those in Ci, and adds all of the generated lexical
entries to A. In contrast, the previous work (Zettle-
moyer and Collins, 2005; Kwiatkowski et al., 2010)
has a very conservative process for adding new lex-
ical entries. This process relies on a good initial-
ization of the feature weights associated with a new
lexical entry. They perform this initialization using
a Giza++ alignment of the words in the training sen-
tences with the names of functions in the associated
lambda calculus expression. Such an initialization
is ineffective in our domain since it has very few
primitive functions and most of the training exam-
ples use more than half of these functions. Instead,
we add new lexical entries more aggressively, and
rely on the n-best parser to effectively ignore any
lexicon entries which do not generate high probabil-
ity parses.
</bodyText>
<sectionHeader confidence="0.994742" genericHeader="method">
6 Applying the Model
</sectionHeader>
<bodyText confidence="0.996293692307693">
Features To allow inclusion of head words in our
features, our chart cells are indexed by start word,
end word, and head word. Thus for each parse pro-
duction we have a set of features that combine the
head word and CCG type, of the two children and
the newly generated parent. Additionally, for each
lexical entry (wi, R : ri) E A, we have four types of
features: (1) a feature for (wi, R : ri), (2) a feature
for wi, (3) a feature for R : ri, and (4) a set of fea-
tures indicating whether wi contains a string literal
and whether the leaves of ri contain any exact char-
acter matches (rather than character range matches).
Initialization In addition to the sentence level ini-
tialization discussed in §5 we also initialize the lex-
icon, A, with two other sets of lexical entries. The
first set is all of the quoted string literals in the natu-
ral language phrases from the training set. Thus for
the phrase, “lines with ’bob’ twice” we would add
the lexical entry ( ’bob’, R:bob ). We also add lex-
ical entries for both numeric and word representa-
tions of numbers, such as ( 1, R:1) and ( one, R:1).
We add these last two types of lexical entries be-
cause learning them from the data is almost impos-
sible due to data sparsity. Lastly, for every individual
word in our training set vocabulary, we add an iden-
tity lexical entry whose lambda expression is just a
function which takes one argument and returns that
argument. This allows our parser to learn to skip
semantically unimportant words in the natural lan-
guage description, and ensures that it generates at
least one parse for every example in the dataset. At
test time we also add both identity lexical entries for
every word in the test set vocabulary as well as lex-
ical entries for every quoted string literal seen in the
test queries. Note that the addition of these lexical
entries requires only access to the test queries and
does not make use of the regular expressions (i.e.
labels) in the test data in any way.
Parameters We initialize the weight of all lexical
entry features except the identity features to a default
value of 1 and initialize all other features to a default
weight of 0. We regularize our log-linear model us-
ing the L2-norm and a A value of 0.001. We use a
learning rate of α = 1.0, set n = 10, 000 in our n-
best parser, and run each experiment with 5 random
restarts and K = 50 iterations. We report results
using the pocket algorithm technique originated by
Gallant (1990).
Constraints on Lexical Entry Splitting To prevent
the generation of an exponential number of splits,
we constrain the lexical entry splitting process as
follows:
</bodyText>
<listItem confidence="0.9049946">
• We only consider splits at nodes which are at most
a depth of 2 from the root of the original tree.
• We limit lambda expressions to 2 arguments.
• In unordered node splits (and and or) the result-
ing child can contain at most 4 of the arguments.
</listItem>
<bodyText confidence="0.99795775">
These restrictions ensure the number of splits is
at most an M-degree polynomial of the regexp size.
The unification process used by Kwiatowski et al.
(2010) bounded the number of splits similarly.
</bodyText>
<sectionHeader confidence="0.992937" genericHeader="method">
7 Experimental Setup
</sectionHeader>
<bodyText confidence="0.50551525">
Dataset Our dataset consists of 824 natural language
and regular expression pairs gathered using Amazon
Mechanical Turk (Turk, 2013) and oDesk (oDesk,
2013).6 On Mechanical Turk we asked workers to
</bodyText>
<footnote confidence="0.998631">
6This is similar to the size of the datasets used by past work.
</footnote>
<page confidence="0.994846">
832
</page>
<bodyText confidence="0.999822181818182">
generate their own original natural language queries
to capture a subset of the lines in a file (similar to
UNIX grep). In order to compare to example based
techniques we also ask the Mechanical Turk work-
ers to generate 5 positive and 5 negative examples
for each query. On oDesk we hired a set of pro-
grammers to generate regular expressions for each
of these natural language queries. We split our data
into 3 sets of 275 queries each and tested using 3-
fold cross validation. We tuned our parameters sep-
arately on each development set but ended up with
the same values in each case.
Evaluation Metrics We evaluate by comparing the
generated regular expression for each sentence with
the correct regular expression using our DFA equiv-
alence technique. As discussed in §3.1 this met-
ric is exact, indicating whether the generated regu-
lar expression is semantically equivalent to the cor-
rect regular expression. Additionally, as discussed
in §6, our identity lexical entries ensure we generate
a valid parse for every sentence, so we report only
accuracy instead of precision and recall.
Baselines We compared against six different base-
lines. The UBL baseline uses the published code
from Kwiatkowski et al. (2010) after configuring
it to handle the lambda calculus format of our reg-
ular expressions.7 The other baselines are ablated
and/or modified versions of our model. The Beam-
Parse baselines replace the N-BEST procedure from
Algorithm 1 with the beam search algorithm used
for parsing by past CCG parsers (Zettlemoyer and
Collins, 2005; Kwiatkowski et al., 2010).8 The
StringUnify baseline replaces the DFA-EQUAL proce-
dure from Algorithm 1 with exact regular expres-
sion string equality. The HeuristicUnify baselines
strengthen this by replacing DFA-EQUAL with a smart
heuristic form of semantic unification. Our heuristic
unification procedure first flattens the regexp trees
by merging all children into the parent node if they
are both of the same type and of type or, and, or
cons. It then sorts all children of the and and or
operators. Finally, it converts both regexps back to
a flat string and compares these strings for equiva-
lence. This process should more effective than any
</bodyText>
<footnote confidence="0.99672525">
7This was done in consultation with the original authors.
8we set the beam size to 200, which is equivalent to the past
work. With this setting, the slow runtime of this algorithm al-
lowed us to run only two random restarts.
</footnote>
<table confidence="0.999648875">
Model Percent Correct
UBL 36.5%
BeamParse-HeuristicUnify 9.4%
BeamParse-HeuristicUnify-TopParse 22.1%
NBestParse-StringUnify 31.1%
NBestParse-ExampleUnify 52.3%
NBestParse-HeuristicUnify 56.8%
Our Full Model 65.5%
</table>
<tableCaption confidence="0.999924">
Table 1: Accuracy of our model and the baselines.
</tableCaption>
<bodyText confidence="0.999968307692308">
form of syntactic unification and any simpler heuris-
tics. The ExampleUnify baseline represents the per-
formance of the example based semantic unification
techniques. It replaces DFA-EQUAL with a procedure
that evaluates the regexp on all the positive and neg-
ative examples associated with the given query and
returns true if all 10 are correctly classified. Finally,
BeamParse-HeuristicUnify-TopParse uses the same
algorithm as that for BeamParse-HeuristicUnify ex-
cept that it only generates lexical entries from the
top parse instead of all parses. This more closely
resembles the conservative lexical entry splitting al-
gorithm used by Kwiatkowski et al.
</bodyText>
<sectionHeader confidence="0.99959" genericHeader="evaluation">
8 Results
</sectionHeader>
<bodyText confidence="0.999975894736842">
Our model outperforms all of the baselines, as
shown in Table 1. The first three baselines –
UBL, BeamParse-HeuristicUnify, and BeamParse-
HeuristicUnify-TopParse– represent the algorithm
used by Kwiatkowski et al. Our model outperforms
the best of these by over 30% in absolute terms and
180% in relative terms.
The improvement in performance of our model
over the NBestParse-StringUnify, NBestParse-
ExampleUnify and NBestParse-HeuristicUnify
baselines highlights the importance of our DFA
based semantic unification technique. Specifi-
cally, our model outperforms exact string based
unification by over 30%, example based semantic
unification by over 13% and our smart heuristic
unification procedure by 9%. These improvements
confirm that leveraging exact semantic unification
during the learning process helps to disambiguate
language meanings.
</bodyText>
<subsectionHeader confidence="0.998469">
8.1 Effect of Additional Training Data
</subsectionHeader>
<bodyText confidence="0.999956666666667">
Table 2 shows the change in performance as we in-
crease the amount of training data. We see that our
model provides particularly large gains when there
</bodyText>
<page confidence="0.996363">
833
</page>
<table confidence="0.9989086">
%age of Data 15% 30% 50% 75%
NBestParse- 12.4% 26.4% 39.0% 45.4%
HeuristicUnify
Our Model 29.0% 50.3% 58.7% 65.2%
Relative Gain 2.34x 1.91x 1.51x 1.43x
</table>
<figureCaption confidence="0.9964896">
Figure 6: This graph compares the set of parses repre-
sented by the n-best algorithm used in our model to the
set of parses represented by the beam search algorithm
used by the past work. Note that our n-best algorithm
represents 100% of the top 10000 parses.
</figureCaption>
<bodyText confidence="0.999935777777778">
is a small amount of training data. These gains de-
crease as the amount of training data increases be-
cause the additional data allows the baseline to learn
new lexical entries for every special case. This re-
duces the need for the fine grained lexicon decom-
position which is enabled by our DFA based unifica-
tion. For example, our DFA based model will learn
separate lexical entries for “line”, “word”, “starting
with”, and “ending with”. The baseline instead will
just learn separate lexical entries for every possible
combination such as “line starting with”, “word end-
ing with”, etc. Our model’s ability to decompose,
however, allows it to provide equivalent accuracy to
even the best baseline with less than half the amount
of training data. Furthermore, we would expect this
gain to be even larger for domains with more com-
plex mappings and a larger number of different com-
binations.
</bodyText>
<subsectionHeader confidence="0.992701">
8.2 Beam Search vs. N-Best
</subsectionHeader>
<bodyText confidence="0.9999876">
A critical step in the training process is calculating
the expected feature counts over all parses that gen-
erate the correct regular expression. In §4 we dis-
cussed the trade-off between approximating this cal-
culation using the n-best parses, as our model does,
verses the beam search model used by the past work.
The effect of this trade-off can be seen clearly in Fig-
ure 6. The n-best parser always represents the n-best
parses, which is set to 10,000 in our experiments. In
contrast, on the first iteration, the beam search algo-
rithm fails to represent the top parse almost 20% of
the time and represents less than 15% of the 10,000
most likely parses. Even after 10 iterations it still
only represents 70% of the top parses and fails to
represent the top parse almost 10% of the time. This
difference in representation ability is what provides
the more than 30% difference in accuracy between
the BeamParse-HeuristicUnify version of our model
and the NBestParse-HeuristicUnify version of our
model.
</bodyText>
<sectionHeader confidence="0.991617" genericHeader="conclusions">
9 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999986826086957">
In this paper, we present a technique for learning
a probabilistic CCG which can parse a natural lan-
guage text search into the regular expression that
performs that search. The key idea behind our ap-
proach is to use a DFA based form of semantic uni-
fication to disambiguate the meaning of the natural
language descriptions. Experiments on a dataset of
natural language regular expression pairs show that
our model significantly outperforms baselines based
on a state-of-the-art model.
We performed our work on the domain of reg-
ular expressions, for which semantic unification is
tractable. In more general domains, semantic uni-
fication is undecidable. Nevertheless, we believe
our work motivates the use of semantic inference
techniques for language grounding in more general
domains, potentially through the use of some form
of approximation or by restricting those domains in
some way. For example, SAT and SMT solvers have
seen significant success in performing semantic in-
ference for program induction and hardware veri-
fication despite the computational intractability of
these problems in the general case.
</bodyText>
<sectionHeader confidence="0.993412" genericHeader="acknowledgments">
10 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999901222222222">
The authors acknowledge the support of Battelle
Memorial Institute (PO#300662) and NSF (grant
IIS-0835652). We thank Luke Zettlemoyer, Tom
Kwiatkowski, Yoav Artzi, Mirella Lapata, the MIT
NLP group, and the ACL reviewers for their sugges-
tions and comments. Any opinions, findings, con-
clusions, or recommendations expressed in this pa-
per are those of the authors, and do not necessarily
reflect the views of the funding organizations.
</bodyText>
<figure confidence="0.971035083333333">
Table 2: Results for varying amounts of training data.
1stIter
10th Iter
60
40
20
0
1 2000 4000 6000 8000 10000
# of Top Parses
% Represented
100
80
</figure>
<page confidence="0.994202">
834
</page>
<sectionHeader confidence="0.989515" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999646509615385">
Dana Angluin. 1987. Learning regular sets from queries
and counterexamples. Information and computation,
75(2):87–106.
Yoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping
semantic parsers from conversations. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 421–432. Association for
Computational Linguistics.
Yoav Artzi and Luke Zettlemoyer. 2013. Weakly su-
pervised learning of semantic parsers for mapping in-
structions to actions. Transactions of the Association
for Computational Linguistics.
S.R.K Branavan, Harr Chen, Luke Zettlemoyer, and
Regina Barzilay. 2009. Reinforcement learning for
mapping instructions to actions. In Proceedings of
ACL, pages 82–90.
David L Chen and Raymond J Mooney. 2011. Learn-
ing to interpret natural language navigation instruc-
tions from observations. In Proceedings of the 25th
AAAI Conference on Artificial Intelligence (AAAI-
2011), pages 859–865.
J. Clarke, D. Goldwasser, M.W. Chang, and D. Roth.
2010. Driving semantic parsing from the world’s re-
sponse. In Proceedings of the Fourteenth Conference
on Computational Natural Language Learning, pages
18–27. Association for Computational Linguistics.
Jeffrey Friedl. 2006. Mastering Regular Expressions.
OReilly.
Steven I Gallant. 1990. Perceptron-based learning al-
gorithms. Neural Networks, IEEE Transactions on,
1(2):179–191.
J.E. Hopcroft, R. Motwani, and J.D. Ullman. 1979. In-
troduction to automata theory, languages, and compu-
tation, volume 2. Addison-wesley Reading, MA.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proceedings of the Ninth International
Workshop on Parsing Technology, pages 53–64. As-
sociation for Computational Linguistics.
Victor M. Jimenez and Andres Marzal. 2000. Com-
putation of the n best parse trees for weighted and
stochastic context-free grammars. Advances in Pat-
tern Recognition, pages 183–192.
R.J. Kate and R.J. Mooney. 2006. Using string-kernels
for learning semantic parsers. In ASSOCIATION FOR
COMPUTATIONAL LINGUISTICS, volume 44, page
913.
R.J. Kate, Y.W. Wong, and R.J. Mooney. 2005. Learning
to transform natural to formal languages. In Proceed-
ings of the National Conference on Artificial Intelli-
gence, volume 20, page 1062. Menlo Park, CA; Cam-
bridge, MA; London; AAAI Press; MIT Press; 1999.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater,
and Mark Steedman. 2010. Inducing probabilistic ccg
grammars from logical form with higher-order unifica-
tion. In Proceedings of EMNLP.
T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, and
M. Steedman. 2011. Lexical generalization in ccg
grammar induction for semantic parsing. In Proceed-
ings of the Conference on Empirical Methods in Natu-
ral Language Processing, pages 1512–1523. Associa-
tion for Computational Linguistics.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less supervi-
sion. In Proceedings of ACL, pages 91–99.
P. Liang, M.I. Jordan, and D. Klein. 2011. Learning
dependency-based compositional semantics. Compu-
tational Linguistics, pages 1–94.
R. Mihalcea, H. Liu, and H. Lieberman. 2006. Nlp (natu-
ral language processing) for nlp (natural language pro-
gramming). Computational Linguistics and Intelligent
Text Processing, pages 319–330.
Anders Møller. 2010. dk.brics.automaton – finite-
state automata and regular expressions for Java.
http://www.brics.dk/automaton/.
N. Moreira and R. Reis. 2012. Implementation and ap-
plication of automata.
oDesk. 2013. http://odesk.com/.
H. Poon and P. Domingos. 2009. Unsupervised seman-
tic parsing. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Process-
ing: Volume 1-Volume 1, pages 1–10. Association for
Computational Linguistics.
Aarne Ranta. 1998. A multilingual natural-language
interface to regular expressions. In Proceedings of
the International Workshop on Finite State Methods in
Natural Language Processing, pages 79–90. Associa-
tion for Computational Linguistics.
R.G. Raymond and J. Mooney. 2006. Discriminative
reranking for semantic parsing. In Proceedings of
the COLING/ACL on Main conference poster sessions,
pages 263–270. Association for Computational Lin-
guistics.
M. Steedman. 2001. The syntactic process. MIT press.
D. Tabakov and M. Vardi. 2005. Experimental evalua-
tion of classical automata constructions. In Logic for
Programming, Artificial Intelligence, and Reasoning,
pages 396–411. Springer.
C.A. Thompson and R.J. Mooney. 2003. Acquiring
word-meaning mappings for natural language inter-
faces. Journal of Artificial Intelligence Research,
18(1):1–44.
Mechanical Turk. 2013. http://mturk.com/.
Y.W. Wong and R.J. Mooney. 2006. Learning for se-
mantic parsing with statistical machine translation. In
</reference>
<page confidence="0.985901">
835
</page>
<reference confidence="0.999249066666666">
Proceedings of the main conference on Human Lan-
guage Technology Conference of the North American
Chapter of the Association of Computational Linguis-
tics, pages 439–446. Association for Computational
Linguistics.
Y.W. Wong and R. Mooney. 2007. Learning syn-
chronous grammars for semantic parsing with lambda
calculus. In ANNUAL MEETING-ASSOCIATION
FOR COMPUTATIONAL LINGUISTICS, volume 45,
page 960.
J.M. Zelle and R.J. Mooney. 1996. Learning to parse
database queries using inductive logic programming.
In Proceedings of the National Conference on Artifi-
cial Intelligence, pages 1050–1055.
L.S. Zettlemoyer and M. Collins. 2005. Learning to
map sentences to logical form: Structured classifica-
tion with probabilistic categorial grammars.
L.S. Zettlemoyer and M. Collins. 2007. Online learning
of relaxed ccg grammars for parsing to logical form.
In In Proceedings of the 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL-2007. Citeseer.
L.S. Zettlemoyer and M. Collins. 2009. Learning
context-dependent mappings from sentences to logi-
cal form. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of theAFNLP: Volume 2-Volume 2, pages 976–
984. Association for Computational Linguistics.
</reference>
<page confidence="0.998853">
836
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.462791">
<title confidence="0.9997635">Using Semantic Unification to Regular Expressions from Natural Language</title>
<author confidence="0.999313">Nate Kushman Regina</author>
<affiliation confidence="0.9715315">Computer Science and Artificial Intelligence Massachusetts Institute of</affiliation>
<abstract confidence="0.972780157894737">We consider the problem of translating natural language text queries into regular expressions which represent their meaning. The mismatch in the level of abstraction between the natural language representation and the regular expression representation make this a novel and challenging problem. However, a given regular expression can be written in many semantically equivalent forms, and we exploit this flexibility to facilitate translation by finding a form which more directly corresponds to the natural language. We evaluate our technique on a set of natural language queries and their associated regular expressions which we gathered from Amazon Mechanical Turk. Our model substantially outperforms a stateof-the-art semantic parsing baseline, yielding 29% absolute improvement in</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dana Angluin</author>
</authors>
<title>Learning regular sets from queries and counterexamples.</title>
<date>1987</date>
<booktitle>Information and computation,</booktitle>
<pages>75--2</pages>
<contexts>
<context position="7892" citStr="Angluin, 1987" startWordPosition="1233" endWordPosition="1234"> We find that our model generates the correct regexp for 66% of sentences, while the state-of-the-art semantic parsing technique from Kwiatkowski et al. (2010) generates correct regexps for only 37% of sentences. The results confirm our hypothesis that leveraging the inference capabilities of the semantic domain can help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not ar</context>
</contexts>
<marker>Angluin, 1987</marker>
<rawString>Dana Angluin. 1987. Learning regular sets from queries and counterexamples. Information and computation, 75(2):87–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Bootstrapping semantic parsers from conversations.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>421--432</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9870" citStr="Artzi and Zettlemoyer (2011)" startWordPosition="1545" endWordPosition="1548">A based technique can determine the equivalence of such expressions. It does this by leveraging the equational inference capabilities of the regular expression domain, making it a form of semantic unification. Thus, the contribution of our work is to show that using semantic unification to find a deeper level of equivalence helps to disambiguate language meanings. In many other domains of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background </context>
<context position="17992" citStr="Artzi and Zettlemoyer (2011)" startWordPosition="2920" endWordPosition="2923">, ri)l • O = Ep(t|t∈C)10(t, 4L)] − Ep(t|t∈T)10(t, 4L)] • B=B+caO Output: The lexicon and the parameters, (A, B) Algorithm 1: The full learning algorithm. Kwiatkowski et al., 2010). However, our domain has distinct properties that led to three important departures from this past work. First, we use the DFA based semantic unification process described in §3.1 to determine the set of correct parses when performing parameter updates. This is in contrast to the syntactic unification technique, used by Kwiatkowski et al. (2010), and the example based unification used by other semantic parsers, e.g. Artzi and Zettlemoyer (2011). Using semantic unification allows us to handle training data which does not admit a fragment-by-fragment mapping between the natural language and the regular expression, such as the example in Figure 2. Second, our parser is based on the efficient n-best parsing algorithm of Jimenez and Marzal (2000) instead of the pruned chart parsing algorithm used by the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). As we show in §8.2, this results in a parser which more effectively represents the most likely parses. This allows our parser to better handle the large number of potent</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping semantic parsers from conversations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 421–432. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics.</title>
<date>2013</date>
<contexts>
<context position="10257" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="1610" endWordPosition="1613">s of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) repexact(I,R) a13} Figure 3: This shows the signatures of all functions i</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2013. Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Luke Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reinforcement learning for mapping instructions to actions.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>82--90</pages>
<contexts>
<context position="8362" citStr="Branavan et al., 2009" startWordPosition="1310" endWordPosition="1313">from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unification determines equality using only variable s</context>
</contexts>
<marker>Branavan, Chen, Zettlemoyer, Barzilay, 2009</marker>
<rawString>S.R.K Branavan, Harr Chen, Luke Zettlemoyer, and Regina Barzilay. 2009. Reinforcement learning for mapping instructions to actions. In Proceedings of ACL, pages 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI2011),</booktitle>
<pages>859--865</pages>
<contexts>
<context position="10227" citStr="Chen and Mooney, 2011" startWordPosition="1606" endWordPosition="1609">s. In many other domains of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) repexact(I,R) a13} Figure 3: This shows the</context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>David L Chen and Raymond J Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI2011), pages 859–865.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>D Goldwasser</author>
<author>M W Chang</author>
<author>D Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>18--27</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10164" citStr="Clarke et al., 2010" startWordPosition="1594" endWordPosition="1597">r level of equivalence helps to disambiguate language meanings. In many other domains of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>J. Clarke, D. Goldwasser, M.W. Chang, and D. Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 18–27. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Friedl</author>
</authors>
<title>Mastering Regular Expressions.</title>
<date>2006</date>
<location>OReilly.</location>
<contexts>
<context position="1395" citStr="Friedl, 2006" startWordPosition="200" endWordPosition="201">chnique on a set of natural language queries and their associated regular expressions which we gathered from Amazon Mechanical Turk. Our model substantially outperforms a stateof-the-art semantic parsing baseline, yielding a 29% absolute improvement in accuracy.1 1 Introduction Regular expressions (regexps) have proven themselves to be an extremely powerful and versatile formalism that has made its way into everything from spreadsheets to databases. However, despite their usefulness and wide availability, they are still considered a dark art that even many programmers do not fully understand (Friedl, 2006). Thus, the ability to automatically generate regular expressions from natural language would be useful in many contexts. Our goal is to learn to generate regexps from natural language, using a training set of natural language and regular expression pairs such as the one in Figure 1. We do not assume that the data includes an alignment between fragments of the natural language and fragments of the regular expression. In1The dataset used in this work is available at http://groups.csail.mit.edu/rbg/code/regexp/ Text Description Regular Expression three letter word starting with ’X’ \bX[A-Za-z]{2</context>
</contexts>
<marker>Friedl, 2006</marker>
<rawString>Jeffrey Friedl. 2006. Mastering Regular Expressions. OReilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven I Gallant</author>
</authors>
<title>Perceptron-based learning algorithms.</title>
<date>1990</date>
<journal>Neural Networks, IEEE Transactions on,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="29499" citStr="Gallant (1990)" startWordPosition="4942" endWordPosition="4943">requires only access to the test queries and does not make use of the regular expressions (i.e. labels) in the test data in any way. Parameters We initialize the weight of all lexical entry features except the identity features to a default value of 1 and initialize all other features to a default weight of 0. We regularize our log-linear model using the L2-norm and a A value of 0.001. We use a learning rate of α = 1.0, set n = 10, 000 in our nbest parser, and run each experiment with 5 random restarts and K = 50 iterations. We report results using the pocket algorithm technique originated by Gallant (1990). Constraints on Lexical Entry Splitting To prevent the generation of an exponential number of splits, we constrain the lexical entry splitting process as follows: • We only consider splits at nodes which are at most a depth of 2 from the root of the original tree. • We limit lambda expressions to 2 arguments. • In unordered node splits (and and or) the resulting child can contain at most 4 of the arguments. These restrictions ensure the number of splits is at most an M-degree polynomial of the regexp size. The unification process used by Kwiatowski et al. (2010) bounded the number of splits s</context>
</contexts>
<marker>Gallant, 1990</marker>
<rawString>Steven I Gallant. 1990. Perceptron-based learning algorithms. Neural Networks, IEEE Transactions on, 1(2):179–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hopcroft</author>
<author>R Motwani</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to automata theory, languages, and computation, volume 2.</title>
<date>1979</date>
<publisher>Addison-wesley</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="5851" citStr="Hopcroft et al., 1979" startWordPosition="906" endWordPosition="909">arning if we can use semantic inference to determine the equivalence between the two regular expressions. More generally, whenever the regexp in the training data does not factorize in a way that facilitates a direct mapping to the natural language description, we must find a regexp which does factorize and be able to compute its equivalence to the regexp we see in the training data. We compute this equivalence by converting each regexp to a minimal deterministic finite automaton (DFA) and leveraging the fact that minimal DFAs are guaranteed to be the same for semantically equivalent regexps (Hopcroft et al., 1979). We handle the additional ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm. The state of the art semantic parsers (Kwiatkowski et al., 2011; Liang et al., 2011) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing. In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from Jimenez and Marzal (2000). Our approach works by inducing a combinatory ca</context>
<context position="10964" citStr="Hopcroft et al., 1979" startWordPosition="1712" endWordPosition="1715">lence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) repexact(I,R) a13} Figure 3: This shows the signatures of all functions in our lambda calculus along with their regexp syntax. for the same regular language (Hopcroft et al., 1979). The DFA representation of a regular expression may be exponentially larger than the the original regular expression. However, past work has shown that most regular expressions do not exhibit this exponential behavior (Tabakov and Vardi, 2005; Moreira and Reis, 2012), and the conversion process is renowned for its good performance in practice (Moreira and Reis, 2012). Hence, we compare the equivalence of two regular expressions by converting them to minimal DFAs and comparing the DFAs. We do this using a modified version of Møller (2010).4 3.2 Lambda Calculus Representation To take advantage </context>
</contexts>
<marker>Hopcroft, Motwani, Ullman, 1979</marker>
<rawString>J.E. Hopcroft, R. Motwani, and J.D. Ullman. 1979. Introduction to automata theory, languages, and computation, volume 2. Addison-wesley Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Better k-best parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth International Workshop on Parsing Technology,</booktitle>
<pages>53--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="20193" citStr="Huang and Chiang, 2005" startWordPosition="3281" endWordPosition="3284">d feature counts. We define the features in our model over individual parse productions, admitting the use of dynamic programming to efficiently calculate the unconditioned expected counts. However, when we condition on generating the correct regular expression, as in the first term in (2), the calculation no longer factorizes, rendering exact algorithms computationally infeasible. To handle this, we use an approximate gradient calculation based on the n-best parses. Our n-best parser uses an efficient algorithm developed originally by (Jimenez and Marzal, 2000), and subsequently improved by (Huang and Chiang, 2005). This algorithm utilizes the fact that the first best parse, t1, makes the optimal choice at each decision point, and the 2nd best parse, t2 must make the same optimal choice at every decision point, except for one. To execute on this intuition, the algorithm first calculates t1 by generating an unpruned CKYstyle parse forest which includes a priority queue of possible subparses for each constituent. The set of possible 2nd best parses T are those that choose the 2nd best subparse for exactly one constituent of t1 but are otherwise identical to t1. The algorithm chooses t2 = arg maxtET p(t). </context>
</contexts>
<marker>Huang, Chiang, 2005</marker>
<rawString>Liang Huang and David Chiang. 2005. Better k-best parsing. In Proceedings of the Ninth International Workshop on Parsing Technology, pages 53–64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor M Jimenez</author>
<author>Andres Marzal</author>
</authors>
<title>Computation of the n best parse trees for weighted and stochastic context-free grammars.</title>
<date>2000</date>
<booktitle>Advances in Pattern Recognition,</booktitle>
<pages>183--192</pages>
<contexts>
<context position="6402" citStr="Jimenez and Marzal (2000)" startWordPosition="1000" endWordPosition="1003">to be the same for semantically equivalent regexps (Hopcroft et al., 1979). We handle the additional ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm. The state of the art semantic parsers (Kwiatkowski et al., 2011; Liang et al., 2011) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing. In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from Jimenez and Marzal (2000). Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 2001). This grammar consists of a lexicon which pairs words or phrases with regular expression functions. The learning process initializes the lexicon by pairing each sentence in the training data with the full regular expression associated with it. These lexical entries are iteratively refined by considering all possible ways to split the regular expression and all possible ways to split the phrase. At each iteration we find the n-best parses with the current lexicon, and find the subset of these parses which a</context>
<context position="18295" citStr="Jimenez and Marzal (2000)" startWordPosition="2969" endWordPosition="2972"> based semantic unification process described in §3.1 to determine the set of correct parses when performing parameter updates. This is in contrast to the syntactic unification technique, used by Kwiatkowski et al. (2010), and the example based unification used by other semantic parsers, e.g. Artzi and Zettlemoyer (2011). Using semantic unification allows us to handle training data which does not admit a fragment-by-fragment mapping between the natural language and the regular expression, such as the example in Figure 2. Second, our parser is based on the efficient n-best parsing algorithm of Jimenez and Marzal (2000) instead of the pruned chart parsing algorithm used by the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). As we show in §8.2, this results in a parser which more effectively represents the most likely parses. This allows our parser to better handle the large number of potential parses that exist in our domain due to the weak typing. Third, we consider splitting lexical entries used in any correct parse, while the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) considers splitting only those used in the best parse. We must utilize a less constrictive sp</context>
<context position="20138" citStr="Jimenez and Marzal, 2000" startWordPosition="3272" endWordPosition="3275">d log-linear gradient, which requires calculating expected feature counts. We define the features in our model over individual parse productions, admitting the use of dynamic programming to efficiently calculate the unconditioned expected counts. However, when we condition on generating the correct regular expression, as in the first term in (2), the calculation no longer factorizes, rendering exact algorithms computationally infeasible. To handle this, we use an approximate gradient calculation based on the n-best parses. Our n-best parser uses an efficient algorithm developed originally by (Jimenez and Marzal, 2000), and subsequently improved by (Huang and Chiang, 2005). This algorithm utilizes the fact that the first best parse, t1, makes the optimal choice at each decision point, and the 2nd best parse, t2 must make the same optimal choice at every decision point, except for one. To execute on this intuition, the algorithm first calculates t1 by generating an unpruned CKYstyle parse forest which includes a priority queue of possible subparses for each constituent. The set of possible 2nd best parses T are those that choose the 2nd best subparse for exactly one constituent of t1 but are otherwise identi</context>
</contexts>
<marker>Jimenez, Marzal, 2000</marker>
<rawString>Victor M. Jimenez and Andres Marzal. 2000. Computation of the n best parse trees for weighted and stochastic context-free grammars. Advances in Pattern Recognition, pages 183–192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>R J Mooney</author>
</authors>
<title>Using string-kernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,</booktitle>
<volume>44</volume>
<pages>913</pages>
<contexts>
<context position="2385" citStr="Kate and Mooney, 2006" startWordPosition="352" endWordPosition="355">l language and fragments of the regular expression. In1The dataset used in this work is available at http://groups.csail.mit.edu/rbg/code/regexp/ Text Description Regular Expression three letter word starting with ’X’ \bX[A-Za-z]{2}\b Figure 1: An example text description and its associated regular expression.3 ducing such an alignment during learning is particularly challenging because oftentimes even humans are unable to perform a fragment-by-fragment alignment. We can think of this task as an instance of grounded semantic parsing, similar to the work done in the domain of database queries (Kate and Mooney, 2006; Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). However, the current success in semantic parsing relies on two important properties of the data. First, while the past work did not assume the alignment was given, they did assume that finding a fine grained fragmentby-fragment alignment was possible. Secondly, the semantic domains considered in the past were strongly typed. This typing provides constraints which significantly reduce the space of possible parses, thereby greatly reducing the ambiguity. However, in many interesting domains these two properties may not hold. In our doma</context>
<context position="8193" citStr="Kate and Mooney, 2006" startWordPosition="1281" endWordPosition="1284">the semantic domain can help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unificati</context>
</contexts>
<marker>Kate, Mooney, 2006</marker>
<rawString>R.J. Kate and R.J. Mooney. 2006. Using string-kernels for learning semantic parsers. In ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, volume 44, page 913.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning to transform natural to formal languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<volume>20</volume>
<pages>1062</pages>
<publisher>AAAI Press; MIT Press;</publisher>
<location>Menlo Park, CA; Cambridge, MA; London;</location>
<contexts>
<context position="8212" citStr="Kate et al., 2005" startWordPosition="1285" endWordPosition="1288"> help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible</context>
</contexts>
<marker>Kate, Wong, Mooney, 2005</marker>
<rawString>R.J. Kate, Y.W. Wong, and R.J. Mooney. 2005. Learning to transform natural to formal languages. In Proceedings of the National Conference on Artificial Intelligence, volume 20, page 1062. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic ccg grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2443" citStr="Kwiatkowski et al., 2010" startWordPosition="360" endWordPosition="363">1The dataset used in this work is available at http://groups.csail.mit.edu/rbg/code/regexp/ Text Description Regular Expression three letter word starting with ’X’ \bX[A-Za-z]{2}\b Figure 1: An example text description and its associated regular expression.3 ducing such an alignment during learning is particularly challenging because oftentimes even humans are unable to perform a fragment-by-fragment alignment. We can think of this task as an instance of grounded semantic parsing, similar to the work done in the domain of database queries (Kate and Mooney, 2006; Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). However, the current success in semantic parsing relies on two important properties of the data. First, while the past work did not assume the alignment was given, they did assume that finding a fine grained fragmentby-fragment alignment was possible. Secondly, the semantic domains considered in the past were strongly typed. This typing provides constraints which significantly reduce the space of possible parses, thereby greatly reducing the ambiguity. However, in many interesting domains these two properties may not hold. In our domain, the alignment between the natural language and the reg</context>
<context position="7437" citStr="Kwiatkowski et al. (2010)" startWordPosition="1167" endWordPosition="1170">s to split the regular expression and all possible ways to split the phrase. At each iteration we find the n-best parses with the current lexicon, and find the subset of these parses which are correct using DFA equivalence. We update the weights of a log-linear model based on these parses and the calculated DFA equivalence. We evaluate our technique using a dataset of sentence/regular expression pairs which we generated using Amazon Mechanical Turk (Turk, 2013). We find that our model generates the correct regexp for 66% of sentences, while the state-of-the-art semantic parsing technique from Kwiatkowski et al. (2010) generates correct regexps for only 37% of sentences. The results confirm our hypothesis that leveraging the inference capabilities of the semantic domain can help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from n</context>
<context position="17543" citStr="Kwiatkowski et al., 2010" startWordPosition="2848" endWordPosition="2851">es the equality of the regexp from parse t and regexp r using the algorithm from §3.1 • SPLIT-LEX(T) splits all lexical entries used by any parse tree in set T, using the process described in §5.2 Initialization: A = I(4Li, R : ri) Ii = 1 ... n} Fork= 1 ... K, i = 1 ... n Update Lexicon: A • T = N-BEST(4Li; B, A) • C = Itlt E T ∧ DFA-EQUAL(t, ri)l • A = A u SPLIT-LEX(C) Update Parameters: B • T = N-BEST(4Li; B, A) • C = Itlt E T ∧ DFA-EQUAL(t, ri)l • O = Ep(t|t∈C)10(t, 4L)] − Ep(t|t∈T)10(t, 4L)] • B=B+caO Output: The lexicon and the parameters, (A, B) Algorithm 1: The full learning algorithm. Kwiatkowski et al., 2010). However, our domain has distinct properties that led to three important departures from this past work. First, we use the DFA based semantic unification process described in §3.1 to determine the set of correct parses when performing parameter updates. This is in contrast to the syntactic unification technique, used by Kwiatkowski et al. (2010), and the example based unification used by other semantic parsers, e.g. Artzi and Zettlemoyer (2011). Using semantic unification allows us to handle training data which does not admit a fragment-by-fragment mapping between the natural language and the</context>
<context position="18801" citStr="Kwiatkowski et al., 2010" startWordPosition="3055" endWordPosition="3058">example in Figure 2. Second, our parser is based on the efficient n-best parsing algorithm of Jimenez and Marzal (2000) instead of the pruned chart parsing algorithm used by the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). As we show in §8.2, this results in a parser which more effectively represents the most likely parses. This allows our parser to better handle the large number of potential parses that exist in our domain due to the weak typing. Third, we consider splitting lexical entries used in any correct parse, while the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) considers splitting only those used in the best parse. We must utilize a less constrictive splitting policy since our domain does not admit the feature weight initialization technique used in the domains of the past work. We discuss this in §5.2.1. In the remainder of this section we discuss the process for learning 0 and for generating the lexicon, A. 5.1 Estimating Theta To estimate 0 we will use stochastic gradient ascent, updating the parameters based on one training example at a time. Hence, we can differentiate the objective from equation 1 to get the gradient of parameter 0j for traini</context>
<context position="21694" citStr="Kwiatkowski et al., 2010" startWordPosition="3548" endWordPosition="3551">. We use the n-best parses to calculate an approximate version of the gradient. Specifically, Ti is the aOi aej 830 Original Tree cons cons b o b rep* rep* . . . Parent Tree Child Tree cons rep* x rep* b o b . set of n-best parses for training sample i, and Ci includes all parses t in Ti such that DFA-EQUAL(t, ri). We calculate the approximate gradient as: A = Ep(t|tEC;;6,n)[�(t, wi)] − Ep(t|tET;;6,n)[O(t, A)] (3) In contrast to our n-best technique, the past work has calculated equation (2) using a beam search approximation of the full inside-outside algorithm (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010; Liang et al., 2011). Specifically, since the conditional probability of t given r does not factorize, a standard chart parser would need to maintain the full logical form (i.e. regular expression) for each subparse, and there may be an exponential number of such subparses at each chart cell. Thus, they approximate this full computation using beam search, maintaining only the m-best logical forms at each chart cell. Qualitatively, our n-best approximation always represents the most likely parses in the approximation, but the number of represented parses scales only linearly with n. In contras</context>
<context position="24100" citStr="Kwiatkowski et al. (2010)" startWordPosition="3953" endWordPosition="3956"> splitting algorithm considers all possible ways to split a lexical entry into two new (a) (b) (c) Figure 5: The tree in (a) represents the lambda expression from the lexical entry (with bob, R:.*bob.*). One possible split of this lexical entry generates the parent lexical entry (with, R/R:Ax.(.*x.*)) and the child lexical entry, (bob, R:bob), whose lambda expressions are represented by (b) and (c), respectively. lexical entries such that they can be recombined via function application to obtain the original lexical entry. This process is analogous to the syntactic unification process done by Kwiatkowski et al. (2010). We first consider all possible ways to split the lambda expression r. The splitting process is most easily explained using a tree representation for r, as shown in Figure 5(a). This tree format is simply a convenient visual representation of a lambda calculus function, with each node representing one of the function type constants from Figure 3. Each split, s E 5(r), generates a child expression sc and a parent expression sp such that r = sp(sc). For each node, n, in r besides the root node, we generate a split where sc is the subtree rooted at node n. For such splits, sp is the lambda expre</context>
<context position="26346" citStr="Kwiatkowski et al., 2010" startWordPosition="4370" endWordPosition="4373">augmented by an additional argument of the child type, i.e. either TITc or T\Tc. Each split s generates two pairs of lexical entries, 831 one for forward application, and one for backward application. The set of suchairs of pairs is: {( (w0:j, T/Tc : sp),�wj:l, Tc : sc)), ((w0:j, Tc : sc) , (wj:l, T\Tc : sp�)| (0 &lt; j &lt; l) n (s E S(r))} 5.2.1 Adding New Lexical Entries Our model splits all lexical entries used in parses which generate correct regular expressions, i.e. those in Ci, and adds all of the generated lexical entries to A. In contrast, the previous work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) has a very conservative process for adding new lexical entries. This process relies on a good initialization of the feature weights associated with a new lexical entry. They perform this initialization using a Giza++ alignment of the words in the training sentences with the names of functions in the associated lambda calculus expression. Such an initialization is ineffective in our domain since it has very few primitive functions and most of the training examples use more than half of these functions. Instead, we add new lexical entries more aggressively, and rely on the n-best parser to effe</context>
<context position="31609" citStr="Kwiatkowski et al. (2010)" startWordPosition="5296" endWordPosition="5299">aluation Metrics We evaluate by comparing the generated regular expression for each sentence with the correct regular expression using our DFA equivalence technique. As discussed in §3.1 this metric is exact, indicating whether the generated regular expression is semantically equivalent to the correct regular expression. Additionally, as discussed in §6, our identity lexical entries ensure we generate a valid parse for every sentence, so we report only accuracy instead of precision and recall. Baselines We compared against six different baselines. The UBL baseline uses the published code from Kwiatkowski et al. (2010) after configuring it to handle the lambda calculus format of our regular expressions.7 The other baselines are ablated and/or modified versions of our model. The BeamParse baselines replace the N-BEST procedure from Algorithm 1 with the beam search algorithm used for parsing by past CCG parsers (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010).8 The StringUnify baseline replaces the DFA-EQUAL procedure from Algorithm 1 with exact regular expression string equality. The HeuristicUnify baselines strengthen this by replacing DFA-EQUAL with a smart heuristic form of semantic unification. </context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic ccg grammars from logical form with higher-order unification. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L Zettlemoyer</author>
<author>S Goldwater</author>
<author>M Steedman</author>
</authors>
<title>Lexical generalization in ccg grammar induction for semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1512--1523</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6050" citStr="Kwiatkowski et al., 2011" startWordPosition="939" endWordPosition="942">acilitates a direct mapping to the natural language description, we must find a regexp which does factorize and be able to compute its equivalence to the regexp we see in the training data. We compute this equivalence by converting each regexp to a minimal deterministic finite automaton (DFA) and leveraging the fact that minimal DFAs are guaranteed to be the same for semantically equivalent regexps (Hopcroft et al., 1979). We handle the additional ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm. The state of the art semantic parsers (Kwiatkowski et al., 2011; Liang et al., 2011) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing. In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from Jimenez and Marzal (2000). Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 2001). This grammar consists of a lexicon which pairs words or phrases with regular expression functions. The learning process initializes the lexicon by pairing eac</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2011</marker>
<rawString>T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, and M. Steedman. 2011. Lexical generalization in ccg grammar induction for semantic parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1512–1523. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>91--99</pages>
<contexts>
<context position="10184" citStr="Liang et al., 2009" startWordPosition="1598" endWordPosition="1601">e helps to disambiguate language meanings. In many other domains of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) </context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of ACL, pages 91–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning dependency-based compositional semantics. Computational Linguistics,</title>
<date>2011</date>
<pages>1--94</pages>
<contexts>
<context position="6071" citStr="Liang et al., 2011" startWordPosition="943" endWordPosition="946">g to the natural language description, we must find a regexp which does factorize and be able to compute its equivalence to the regexp we see in the training data. We compute this equivalence by converting each regexp to a minimal deterministic finite automaton (DFA) and leveraging the fact that minimal DFAs are guaranteed to be the same for semantically equivalent regexps (Hopcroft et al., 1979). We handle the additional ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm. The state of the art semantic parsers (Kwiatkowski et al., 2011; Liang et al., 2011) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing. In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from Jimenez and Marzal (2000). Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 2001). This grammar consists of a lexicon which pairs words or phrases with regular expression functions. The learning process initializes the lexicon by pairing each sentence in the tra</context>
<context position="10204" citStr="Liang et al., 2011" startWordPosition="1602" endWordPosition="1605">ate language meanings. In many other domains of interest, determining semantic equivalence is important to the learning process. Previous work on such domains has focused on either heuristic or example-driven measures of semantic equivalence. For example, Artzi and Zettlemoyer (2011) estimate semantic equivalence using a heuristic loss function. Other past work has executed the logical form on an example world or in a situated context and then compared the outputs. This provides a very weak form of semantic equivalence valid only in that world/context (Clarke et al., 2010; Liang et al., 2009; Liang et al., 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013). In contrast, our work uses an exact, theoretically sound measure of semantic equivalence that determines whether two logical representations are equivalent in any context, i.e. on any input string. 3 Background 3.1 Finding Regexp Equivalence Using DFAs Regular expressions can be equivalently represented as minimal DFAs, which are guaranteed to be equal function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) repexact(I,R) a13} F</context>
<context position="21715" citStr="Liang et al., 2011" startWordPosition="3552" endWordPosition="3555"> to calculate an approximate version of the gradient. Specifically, Ti is the aOi aej 830 Original Tree cons cons b o b rep* rep* . . . Parent Tree Child Tree cons rep* x rep* b o b . set of n-best parses for training sample i, and Ci includes all parses t in Ti such that DFA-EQUAL(t, ri). We calculate the approximate gradient as: A = Ep(t|tEC;;6,n)[�(t, wi)] − Ep(t|tET;;6,n)[O(t, A)] (3) In contrast to our n-best technique, the past work has calculated equation (2) using a beam search approximation of the full inside-outside algorithm (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010; Liang et al., 2011). Specifically, since the conditional probability of t given r does not factorize, a standard chart parser would need to maintain the full logical form (i.e. regular expression) for each subparse, and there may be an exponential number of such subparses at each chart cell. Thus, they approximate this full computation using beam search, maintaining only the m-best logical forms at each chart cell. Qualitatively, our n-best approximation always represents the most likely parses in the approximation, but the number of represented parses scales only linearly with n. In contrast, the number of pars</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>P. Liang, M.I. Jordan, and D. Klein. 2011. Learning dependency-based compositional semantics. Computational Linguistics, pages 1–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>H Liu</author>
<author>H Lieberman</author>
</authors>
<title>Nlp (natural language processing) for nlp (natural language programming).</title>
<date>2006</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>319--330</pages>
<contexts>
<context position="8385" citStr="Mihalcea et al., 2006" startWordPosition="1314" endWordPosition="1317">sing rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unification determines equality using only variable substitutions and does n</context>
</contexts>
<marker>Mihalcea, Liu, Lieberman, 2006</marker>
<rawString>R. Mihalcea, H. Liu, and H. Lieberman. 2006. Nlp (natural language processing) for nlp (natural language programming). Computational Linguistics and Intelligent Text Processing, pages 319–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Møller</author>
</authors>
<title>dk.brics.automaton – finitestate automata and regular expressions for Java.</title>
<date>2010</date>
<note>http://www.brics.dk/automaton/.</note>
<contexts>
<context position="11508" citStr="Møller (2010)" startWordPosition="1804" endWordPosition="1805"> regexp syntax. for the same regular language (Hopcroft et al., 1979). The DFA representation of a regular expression may be exponentially larger than the the original regular expression. However, past work has shown that most regular expressions do not exhibit this exponential behavior (Tabakov and Vardi, 2005; Moreira and Reis, 2012), and the conversion process is renowned for its good performance in practice (Moreira and Reis, 2012). Hence, we compare the equivalence of two regular expressions by converting them to minimal DFAs and comparing the DFAs. We do this using a modified version of Møller (2010).4 3.2 Lambda Calculus Representation To take advantage of the inherent structure of regular expressions, we deterministically convert them from a flat string representation into simply typed lambda calculus expressions. The full set of functions available in our lambda calculus can be seen in Figure 3. As can be seen from the figures, our lambda calculus is very weakly typed. It has only two primitive types, integer (I) and regexp (R), with most arguments being of type R. 3.3 Parsing Our parsing model is based on a Combinatory Categorial Grammar. In CCG parsing most of the grammar complexity </context>
</contexts>
<marker>Møller, 2010</marker>
<rawString>Anders Møller. 2010. dk.brics.automaton – finitestate automata and regular expressions for Java. http://www.brics.dk/automaton/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Moreira</author>
<author>R Reis</author>
</authors>
<title>Implementation and application of automata. oDesk.</title>
<date>2012</date>
<note>http://odesk.com/.</note>
<contexts>
<context position="11232" citStr="Moreira and Reis, 2012" startWordPosition="1754" endWordPosition="1757">qual function sig. regexp function signature regexp cons(R,R,...) ab rep*(R) a* and(R,R,...) [a-b]&amp;[b-c] repminmax(I,I,R) a13,5} or(R,R,...) a|b repmin(I,R) a13,} not(R) ˜(a) repexact(I,R) a13} Figure 3: This shows the signatures of all functions in our lambda calculus along with their regexp syntax. for the same regular language (Hopcroft et al., 1979). The DFA representation of a regular expression may be exponentially larger than the the original regular expression. However, past work has shown that most regular expressions do not exhibit this exponential behavior (Tabakov and Vardi, 2005; Moreira and Reis, 2012), and the conversion process is renowned for its good performance in practice (Moreira and Reis, 2012). Hence, we compare the equivalence of two regular expressions by converting them to minimal DFAs and comparing the DFAs. We do this using a modified version of Møller (2010).4 3.2 Lambda Calculus Representation To take advantage of the inherent structure of regular expressions, we deterministically convert them from a flat string representation into simply typed lambda calculus expressions. The full set of functions available in our lambda calculus can be seen in Figure 3. As can be seen from</context>
</contexts>
<marker>Moreira, Reis, 2012</marker>
<rawString>N. Moreira and R. Reis. 2012. Implementation and application of automata. oDesk. 2013. http://odesk.com/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
<author>P Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8411" citStr="Poon and Domingos, 2009" startWordPosition="1318" endWordPosition="1321">ues (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unification determines equality using only variable substitutions and does not take advantage of the i</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>H. Poon and P. Domingos. 2009. Unsupervised semantic parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>A multilingual natural-language interface to regular expressions.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop on Finite State Methods in Natural Language Processing,</booktitle>
<pages>79--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7804" citStr="Ranta, 1998" startWordPosition="1222" endWordPosition="1223">regular expression pairs which we generated using Amazon Mechanical Turk (Turk, 2013). We find that our model generates the correct regexp for 66% of sentences, while the state-of-the-art semantic parsing technique from Kwiatkowski et al. (2010) generates correct regexps for only 37% of sentences. The results confirm our hypothesis that leveraging the inference capabilities of the semantic domain can help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos</context>
</contexts>
<marker>Ranta, 1998</marker>
<rawString>Aarne Ranta. 1998. A multilingual natural-language interface to regular expressions. In Proceedings of the International Workshop on Finite State Methods in Natural Language Processing, pages 79–90. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R G Raymond</author>
<author>J Mooney</author>
</authors>
<title>Discriminative reranking for semantic parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8238" citStr="Raymond and Mooney, 2006" startWordPosition="1289" endWordPosition="1292">natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the log</context>
</contexts>
<marker>Raymond, Mooney, 2006</marker>
<rawString>R.G. Raymond and J. Mooney. 2006. Discriminative reranking for semantic parsing. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 263–270. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>The syntactic process.</title>
<date>2001</date>
<booktitle>In Logic for Programming, Artificial Intelligence, and Reasoning,</booktitle>
<pages>396--411</pages>
<publisher>MIT</publisher>
<contexts>
<context position="6490" citStr="Steedman, 2001" startWordPosition="1014" endWordPosition="1015">al ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm. The state of the art semantic parsers (Kwiatkowski et al., 2011; Liang et al., 2011) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing. In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from Jimenez and Marzal (2000). Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 2001). This grammar consists of a lexicon which pairs words or phrases with regular expression functions. The learning process initializes the lexicon by pairing each sentence in the training data with the full regular expression associated with it. These lexical entries are iteratively refined by considering all possible ways to split the regular expression and all possible ways to split the phrase. At each iteration we find the n-best parses with the current lexicon, and find the subset of these parses which are correct using DFA equivalence. We update the weights of a log-linear model based on t</context>
</contexts>
<marker>Steedman, 2001</marker>
<rawString>M. Steedman. 2001. The syntactic process. MIT press. D. Tabakov and M. Vardi. 2005. Experimental evaluation of classical automata constructions. In Logic for Programming, Artificial Intelligence, and Reasoning, pages 396–411. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C A Thompson</author>
<author>R J Mooney</author>
</authors>
<title>Acquiring word-meaning mappings for natural language interfaces.</title>
<date>2003</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="8265" citStr="Thompson and Mooney, 2003" startWordPosition="1293" endWordPosition="1296">2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they pe</context>
</contexts>
<marker>Thompson, Mooney, 2003</marker>
<rawString>C.A. Thompson and R.J. Mooney. 2003. Acquiring word-meaning mappings for natural language interfaces. Journal of Artificial Intelligence Research, 18(1):1–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mechanical Turk</author>
</authors>
<title>Learning for semantic parsing with statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>439--446</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7277" citStr="Turk, 2013" startWordPosition="1144" endWordPosition="1145">e training data with the full regular expression associated with it. These lexical entries are iteratively refined by considering all possible ways to split the regular expression and all possible ways to split the phrase. At each iteration we find the n-best parses with the current lexicon, and find the subset of these parses which are correct using DFA equivalence. We update the weights of a log-linear model based on these parses and the calculated DFA equivalence. We evaluate our technique using a dataset of sentence/regular expression pairs which we generated using Amazon Mechanical Turk (Turk, 2013). We find that our model generates the correct regexp for 66% of sentences, while the state-of-the-art semantic parsing technique from Kwiatkowski et al. (2010) generates correct regexps for only 37% of sentences. The results confirm our hypothesis that leveraging the inference capabilities of the semantic domain can help disambiguate natural language meaning. 2 Related Work Generating Regular Expressions Past work has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples </context>
<context position="30262" citStr="Turk, 2013" startWordPosition="5070" endWordPosition="5071">as follows: • We only consider splits at nodes which are at most a depth of 2 from the root of the original tree. • We limit lambda expressions to 2 arguments. • In unordered node splits (and and or) the resulting child can contain at most 4 of the arguments. These restrictions ensure the number of splits is at most an M-degree polynomial of the regexp size. The unification process used by Kwiatowski et al. (2010) bounded the number of splits similarly. 7 Experimental Setup Dataset Our dataset consists of 824 natural language and regular expression pairs gathered using Amazon Mechanical Turk (Turk, 2013) and oDesk (oDesk, 2013).6 On Mechanical Turk we asked workers to 6This is similar to the size of the datasets used by past work. 832 generate their own original natural language queries to capture a subset of the lines in a file (similar to UNIX grep). In order to compare to example based techniques we also ask the Mechanical Turk workers to generate 5 positive and 5 negative examples for each query. On oDesk we hired a set of programmers to generate regular expressions for each of these natural language queries. We split our data into 3 sets of 275 queries each and tested using 3- fold cross</context>
</contexts>
<marker>Turk, 2013</marker>
<rawString>Mechanical Turk. 2013. http://mturk.com/. Y.W. Wong and R.J. Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 439–446. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Wong</author>
<author>R Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,</booktitle>
<volume>45</volume>
<pages>960</pages>
<contexts>
<context position="8315" citStr="Wong and Mooney, 2007" startWordPosition="1302" endWordPosition="1305">k has looked at generating regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unific</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Y.W. Wong and R. Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, volume 45, page 960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Zelle</author>
<author>R J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>1050--1055</pages>
<contexts>
<context position="8339" citStr="Zelle and Mooney, 1996" startWordPosition="1306" endWordPosition="1309">ing regular expressions from natural language using rule based techniques (Ranta, 1998), and also at automatically generating regular expressions from examples (Angluin, 1987). To the best of our knowledge, however, our work is the first to use training data to learn to automatically generate regular expressions from natural language. Language Grounding There is a large body of research mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unification determines equalit</context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>J.M. Zelle and R.J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the National Conference on Artificial Intelligence, pages 1050–1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<contexts>
<context position="2416" citStr="Zettlemoyer and Collins, 2005" startWordPosition="356" endWordPosition="359">s of the regular expression. In1The dataset used in this work is available at http://groups.csail.mit.edu/rbg/code/regexp/ Text Description Regular Expression three letter word starting with ’X’ \bX[A-Za-z]{2}\b Figure 1: An example text description and its associated regular expression.3 ducing such an alignment during learning is particularly challenging because oftentimes even humans are unable to perform a fragment-by-fragment alignment. We can think of this task as an instance of grounded semantic parsing, similar to the work done in the domain of database queries (Kate and Mooney, 2006; Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). However, the current success in semantic parsing relies on two important properties of the data. First, while the past work did not assume the alignment was given, they did assume that finding a fine grained fragmentby-fragment alignment was possible. Secondly, the semantic domains considered in the past were strongly typed. This typing provides constraints which significantly reduce the space of possible parses, thereby greatly reducing the ambiguity. However, in many interesting domains these two properties may not hold. In our domain, the alignment between the n</context>
<context position="8734" citStr="Zettlemoyer and Collins (2005)" startWordPosition="1374" endWordPosition="1377">ch mapping natural language to some form of meaning representation (Kate and Mooney, 2006; Kate et al., 2005; Raymond and Mooney, 2006; Thompson and Mooney, 2003; Wong and Mooney, 827 2006; Wong and Mooney, 2007; Zelle and Mooney, 1996; Branavan et al., 2009; Mihalcea et al., 2006; Poon and Domingos, 2009). In some of the considered domains the issue of semantic equivalence does not arise because of the way the data is generated. The most directly related work in these domains, is that by Kwiatkowski et al. (2010 and 2011) which is an extension of earlier work on CCG-based semantic parsing by Zettlemoyer and Collins (2005). Similar to our work, Kwiatkowski et al. utilize unification to find possible ways to decompose the logical form. However, they perform only syntactic unification. Syntactic unification determines equality using only variable substitutions and does not take advantage of the inference capabilities available in many semantic domains. Thus, syntactic unification is unable to determine the equivalence of two logical expressions which use different lexical items, such as “.*” and “.*.*”. In contrast, our DFA based technique can determine the equivalence of such expressions. It does this by leverag</context>
<context position="16689" citStr="Zettlemoyer and Collins, 2005" startWordPosition="2681" endWordPosition="2684">ntries which will generalize better. The candidates for splitting are all lexical entries used by parses which generate the correct regular expression, ri, for the current training sample. We consider all possible ways to factorize each lexical entry, and we add to A a new lexical entry for each possible factorization, as discussed in §5.2. Finally, we update 0 by performing a single stochastic gradient ascent update step for each training sample, as discussed in §5.1. See Algorithm 1 for details. This learning approach follows the structure of the previous work on CCG based semantic parsers (Zettlemoyer and Collins, 2005; eθ-φ(t,~w) p(tJ~w; θ, A) = 829 Inputs: Training set of sentence regular expression pairs. I(4Li, ri) Ii = 1 ... n} Functions: • N-BEST(4L; B, A) n-best parse trees for L4 using the algorithm from §5.1 • DFA-EQUAL(t, r) calculates the equality of the regexp from parse t and regexp r using the algorithm from §3.1 • SPLIT-LEX(T) splits all lexical entries used by any parse tree in set T, using the process described in §5.2 Initialization: A = I(4Li, R : ri) Ii = 1 ... n} Fork= 1 ... K, i = 1 ... n Update Lexicon: A • T = N-BEST(4Li; B, A) • C = Itlt E T ∧ DFA-EQUAL(t, ri)l • A = A u SPLIT-LEX(C</context>
<context position="18394" citStr="Zettlemoyer and Collins, 2005" startWordPosition="2986" endWordPosition="2989">en performing parameter updates. This is in contrast to the syntactic unification technique, used by Kwiatkowski et al. (2010), and the example based unification used by other semantic parsers, e.g. Artzi and Zettlemoyer (2011). Using semantic unification allows us to handle training data which does not admit a fragment-by-fragment mapping between the natural language and the regular expression, such as the example in Figure 2. Second, our parser is based on the efficient n-best parsing algorithm of Jimenez and Marzal (2000) instead of the pruned chart parsing algorithm used by the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010). As we show in §8.2, this results in a parser which more effectively represents the most likely parses. This allows our parser to better handle the large number of potential parses that exist in our domain due to the weak typing. Third, we consider splitting lexical entries used in any correct parse, while the past work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) considers splitting only those used in the best parse. We must utilize a less constrictive splitting policy since our domain does not admit the feature weight initialization technique used in </context>
<context position="21668" citStr="Zettlemoyer and Collins, 2005" startWordPosition="3544" endWordPosition="3547">t best possible subparse for ci. We use the n-best parses to calculate an approximate version of the gradient. Specifically, Ti is the aOi aej 830 Original Tree cons cons b o b rep* rep* . . . Parent Tree Child Tree cons rep* x rep* b o b . set of n-best parses for training sample i, and Ci includes all parses t in Ti such that DFA-EQUAL(t, ri). We calculate the approximate gradient as: A = Ep(t|tEC;;6,n)[�(t, wi)] − Ep(t|tET;;6,n)[O(t, A)] (3) In contrast to our n-best technique, the past work has calculated equation (2) using a beam search approximation of the full inside-outside algorithm (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010; Liang et al., 2011). Specifically, since the conditional probability of t given r does not factorize, a standard chart parser would need to maintain the full logical form (i.e. regular expression) for each subparse, and there may be an exponential number of such subparses at each chart cell. Thus, they approximate this full computation using beam search, maintaining only the m-best logical forms at each chart cell. Qualitatively, our n-best approximation always represents the most likely parses in the approximation, but the number of represented parses scales only l</context>
<context position="26319" citStr="Zettlemoyer and Collins, 2005" startWordPosition="4365" endWordPosition="4369"> of the original expression, T augmented by an additional argument of the child type, i.e. either TITc or T\Tc. Each split s generates two pairs of lexical entries, 831 one for forward application, and one for backward application. The set of suchairs of pairs is: {( (w0:j, T/Tc : sp),�wj:l, Tc : sc)), ((w0:j, Tc : sc) , (wj:l, T\Tc : sp�)| (0 &lt; j &lt; l) n (s E S(r))} 5.2.1 Adding New Lexical Entries Our model splits all lexical entries used in parses which generate correct regular expressions, i.e. those in Ci, and adds all of the generated lexical entries to A. In contrast, the previous work (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) has a very conservative process for adding new lexical entries. This process relies on a good initialization of the feature weights associated with a new lexical entry. They perform this initialization using a Giza++ alignment of the words in the training sentences with the names of functions in the associated lambda calculus expression. Such an initialization is ineffective in our domain since it has very few primitive functions and most of the training examples use more than half of these functions. Instead, we add new lexical entries more aggressively, and rely o</context>
<context position="31936" citStr="Zettlemoyer and Collins, 2005" startWordPosition="5348" endWordPosition="5351">Additionally, as discussed in §6, our identity lexical entries ensure we generate a valid parse for every sentence, so we report only accuracy instead of precision and recall. Baselines We compared against six different baselines. The UBL baseline uses the published code from Kwiatkowski et al. (2010) after configuring it to handle the lambda calculus format of our regular expressions.7 The other baselines are ablated and/or modified versions of our model. The BeamParse baselines replace the N-BEST procedure from Algorithm 1 with the beam search algorithm used for parsing by past CCG parsers (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010).8 The StringUnify baseline replaces the DFA-EQUAL procedure from Algorithm 1 with exact regular expression string equality. The HeuristicUnify baselines strengthen this by replacing DFA-EQUAL with a smart heuristic form of semantic unification. Our heuristic unification procedure first flattens the regexp trees by merging all children into the parent node if they are both of the same type and of type or, and, or cons. It then sorts all children of the and and or operators. Finally, it converts both regexps back to a flat string and compares these strings for equival</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Online learning of relaxed ccg grammars for parsing to logical form. In</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL-2007. Citeseer.</booktitle>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2007. Online learning of relaxed ccg grammars for parsing to logical form. In In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL-2007. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning context-dependent mappings from sentences to logical form.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of theAFNLP: Volume</booktitle>
<volume>2</volume>
<pages>976--984</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Zettlemoyer, Collins, 2009</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of theAFNLP: Volume 2-Volume 2, pages 976– 984. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>