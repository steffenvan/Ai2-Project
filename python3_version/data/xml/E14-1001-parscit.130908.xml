<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.596674">
Improving Word Alignment Using Linguistic Code Switching Data
</title>
<author confidence="0.573031">
Fei Huang∗ and Alexander Yates
</author>
<affiliation confidence="0.5891305">
Temple University
Computer and Information Sciences
</affiliation>
<address confidence="0.6663025">
324 Wachman Hall
Philadelphia, PA 19122
</address>
<email confidence="0.999483">
{fei.huang,yates}@temple.edu
</email>
<sectionHeader confidence="0.994755" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998791807692308">
Linguist Code Switching (LCS) is a
situation where two or more languages
show up in the context of a single
conversation. For example, in English-
Chinese code switching, there might
be a sentence like “V, in15ft �rP r �q
`meeting (We will have a meeting in 15
minutes)”. Traditional machine translation
(MT) systems treat LCS data as noise,
or just as regular sentences. However, if
LCS data is processed intelligently, it can
provide a useful signal for training word
alignment and MT models. Moreover,
LCS data is from non-news sources which
can enhance the diversity of training data
for MT. In this paper, we first extract
constraints from this code switching data
and then incorporate them into a word
alignment model training procedure. We
also show that by using the code switching
data, we can jointly train a word alignment
model and a language model using co-
training. Our techniques for incorporating
LCS data improve by 2.64 in BLEU score
over a baseline MT system trained using
only standard sentence-aligned corpora.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.982032134615385">
Many language users are competent in multiple
languages, and they often use elements of multiple
languages in conversations with other speakers
with competence in the same set of languages.
For example, native Mandarin speakers who
also speak English might use English words in
a Chinese sentence, like “Irl, 0 MR A -Al` f p7 W&apos;
MsolutionU4 ?(Do you know the solution to
this problem ?)”. This phenomenon of mixing
∗*The author is working at Raytheon BBN Technologies
now
languages within a single utterance is known as
Linguistic Code Switching (LCS). Examples of
these utterances are common in communities of
speakers with a shared competency in multiple
languages, such as Web forums for Chinese
emigr´es to the United States. For example, more
than 50% of the sentences we collected from a
Web forum (MITBBS.com) contains both Chinese
and English.
Traditional word alignment models take a
sentence-level aligned corpus as input and gener-
ate word-level alignments for each pair of parallel
sentences. Automatically-gathered LCS data
typically contains no sentence-level alignments,
but it still has some advantages for training
word alignment models and machine translation
(MT) systems which are worth exploring. First,
because it contains multiple languages in the same
sentence and still has a valid meaning, it will tell
the relationship between the words from different
languages to some extent. Second, most LCS
data is formed during people’s daily conversation,
and thus it contains a diversity of topics that
people care about, such as home furnishings,
cars, entertainment, etc, that may not show up in
standard parallel corpora. Moreover, LCS data is
easily accessible from Web communities, such as
MITBBS.com, Sina Weibo, Twitter, etc.
However, like most unedited natural language
text on the Web, LCS data contains symbols like
emotions, grammar and spelling mistakes, slang
and strongly idiomatic usage, and a variety of
other phenomena that are difficult to handle. LCS
data with different language pairs may also need
special handling. For instance, Sinha and Thakur
(2005) focus on words in mixed English and
Hindi texts where a single word contains elements
from both languages; they propose techniques
for translating such words into both pure English
and pure Hindi. Our study focuses on Chinese-
English LCS, where this is rarely a problem,
</bodyText>
<page confidence="0.82227">
1
</page>
<note confidence="0.9931615">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1–9,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999586055555556">
but for other language pairs, Sinha and Thakur’s
techniques may be required as preprocessing
steps. Primarily, though, LCS data requires
special-purpose algorithms to use it for word
alignment, since it contains no explicit alignment
labels.
In this paper, we investigate two approaches to
using LCS data for machine translation. The first
approach focuses exclusively on word alignment,
and uses patterns extracted from LCS data to guide
the EM training procedure for word alignment
over a standard sentence-aligned parallel corpus.
We focus on two types of patterns in the LCS
data: first, English words are almost never correct
translations for any Chinese word in the same
LCS utterance. Second, for sentences that are
mostly Chinese but with some English words, if
we propose substitutes for the English words using
a Chinese language model, those substitutes are
often good translations of the English words. We
incorporate these patterns into EM training via
the posterior regularization framework (Ganchev
et al., 2010).
Our second approach treats the alignment and
language model as two different and comple-
mentary views of the data. We apply the co-
training paradigm for semi-supervised learning
to incorporate the LCS data into the training
procedures for the alignment model and the
language model. From the translation table of
the alignment model, the training procedure finds
candidate translations of the English words in
the LCS data, and uses those to supplement the
language model training data. From the language
model, the training procedure identifies Chinese
words that complete the Chinese sentence with
high probability, and it uses the English word
paired with these completion words as additional
training points for translation probabilities. These
models are trained repeatedly until they converge
to similar predictions on the LCS data. In
combination with a larger phrase-based MT
system (Koehn et al., 2003), these two training
procedures yield an MT system that achieves a
BLEU score of 31.79 on an English-to-Chinese
translation task, an improvement of 2.64 in BLEU
score over a baseline MT system trained on only
our parallel corpora.
The rest of this paper is organized as follows.
The next section presents related work. Section 3
gives an overview of word alignment. Sections 4
and 5 detail our two algorithms. Section 6 presents
our experiments and discusses results, and Section
7 concludes and discusses future work.
</bodyText>
<sectionHeader confidence="0.999437" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999863543478261">
There has been a lot of research on LCS from
the theoretical and socio-linguistic communities
(Nilep, 2006; De Fina, 2007). Computational
research on LCS has studied how to identify
the boundaries of an individual language within
LCS data, or how to predict when an utterance
will switch to another language (Chan et al.,
2004; Solorio and Liu, 2008). Manandise and
Gdaniec (2011) analyzed the effect on machine
translation quality of LCS of Spanish-English and
showed that LCS degrades the performance of
the syntactic parser. Sinha and Thakur (2005)
translate mixed Hindi and English (Hinglish)
to pure Hindi and pure English by using two
morphological analyzers from both Hindi and
English. The difficulty in their problem is
that Hindi and English are often mixed into a
single word which uses only the English alphabet;
approaches based only on the character set cannot
tell these words apart from English words. Our
current study is for a language pair (English-
Chinese) where the words are easy to tell apart,
but for MT using code-switching data for other
language pairs (such as Hindi-English), we can
leverage some of the techniques from their work
to separate the tokens into source and target.
Like our proposed methods, other researchers
have used co-training before for MT (Callison-
Burch and Osborne, 2003). They use target
strings in multiple languages as different views on
translation. However, in our work, we treat the
alignment model and language model as different
views of LCS data.
In addition to co-training, various other semi-
supervised approaches for MT and word align-
ment have been proposed, but these have relied on
sentence alignments among multiple languages,
rather than LCS data. Kay (2000) proposes using
multiple target documents as a way of informing
subsequent machine translations. Kumar et al.
(2007) described a technique for word alignment
in a multi-parallel sentence-aligned corpus and
showed that this technique can be used to obtain
higher quality bilingual word alignments. Other
work like (Eisele, 2006) took the issue one step
further that they used bilingual translation systems
</bodyText>
<page confidence="0.988285">
2
</page>
<bodyText confidence="0.999867526315789">
which share one or more common pivot languages
to build systems which non-parallel corpus is used.
Unlike the data in these techniques, LCS data
requires no manual alignment effort and is freely
available in large quantities.
Another line of research has attempted to
improve word alignment models by incorporating
manually-labeled word alignments in addition to
sentence alignments. Callison-Burch et al. (2004)
tried to give a higher weight on manually labeled
data compared to the automatic alignments. Fraser
and Marcu (2006) used a log-linear model with
features from IBM models. They alternated the
traditional Expectation Maximization algorithm
which is applied on a large parallel corpus with
a discriminative step aimed at increasing word-
alignment quality on a small, manually word-
aligned corpus. Ambati et al.(2010) tried to man-
ually correct the alignments which are informative
during the unsupervised training and applied them
to an active learning model. However, labeled
word alignment data is expensive to produce. Our
approach is complementary, in that we use mixed
data that has no word alignments, but still able to
learn constraints on word alignments.
Our techniques make use of posterior regular-
ization (PR) framework (Ganchev et al., 2010),
which has previously been used for MT (Graca
et al., 2008), but with very different constraints
on EM training and different goals. (Graca et
al., 2008) use PR to enforce the constraint that
one word should not translate to many words, and
that if a word s translates to a word t in one MT
system, then a model for translation in the reverse
direction should translate t to s. Both of these
constraints apply to sentence-aligned training data
directly, and complement the constraints that we
extract from LCS data.
</bodyText>
<sectionHeader confidence="0.987203" genericHeader="method">
3 Statistical Word Alignment
</sectionHeader>
<bodyText confidence="0.990060875">
Statistical word alignment (Brown et al., 1994) is
the task identifying which words are translations
of each other in a bilingual sentence corpus. It
is primarily used for machine translation. The
input to an alignment system is a sentence-level
aligned bilingual corpus, which consists of pairs
of sentences in two languages. One language
is denoted as the target language, and the other
language as the source language.
We now introduce the baseline model for word
alignment and how we can incorporate the LCS
data to improve the model. IBM Model 1
(Brown et al., 1994) and the HMM alignment
model (Vogel et al., 1996) are cascaded to
form the baseline model for alignment. These
two models have a similar formulation L =
P(t, a|s) = P(a) Hj P(tj|saj) with a different
distortion probability P(a). s and t denote the
source and target sentences. a is the alignment,
and aj is the index of the source language word
that generates the target language word at position
j. The HMM model assumes the alignments have
a first-order Markov dependency, so that P(a) =
H
</bodyText>
<listItem confidence="0.3024205">
j P(aj|aj − aj−1). IBM Model 1 ignores the
word position and uses a uniform distribution, so
</listItem>
<equation confidence="0.970833">
P(a) = Hj P(aj) where P(aj) = 1
</equation>
<bodyText confidence="0.960976222222222">
|t|, where |t|
is the length of t.
Expectation Maximization (Dempster et al.,
1977) is typically used to train the alignment
model. It tries to maximize the marginal
likelihood of the sentence-level aligned pairs.
For the HMM alignment model, the forward-
backward algorithm can be used the optimize the
posterior probability of the hidden alignment a.
</bodyText>
<sectionHeader confidence="0.771666" genericHeader="method">
4 Learning Constraints for Word
Alignments from LCS Data
</sectionHeader>
<bodyText confidence="0.999971375">
We observed that most LCS sentences are
predominantly in one language, which we call
the majority language, with just a small number
of words from another language, which we
call the minority language. The grammar of
each sentence appears to mirror the structure
of the majority language. Speakers appear to
be substituting primarily content words from the
minority language, especially nouns and verbs,
without changing the structure of the majority
language. In this section, we explain two types
of constraints we extract from the LCS data
that can be helpful for guiding the training of a
word alignment model, and we describe how we
incorporate those constraints into a full training
procedure.
</bodyText>
<subsectionHeader confidence="0.998878">
4.1 Preventing bad alignments
</subsectionHeader>
<bodyText confidence="0.999968142857143">
After inspecting sentences in our LCS data, we
found that the words from the target language
occurring in the sentence are highly likely not to
be the translation of the remaining source word.
Figure 1 shows an example LCS sentence where
the speaker has replaced the Chinese word “:I!*”
with the corresponding English word “request”.
</bodyText>
<page confidence="0.969169">
3
</page>
<figure confidence="0.991995666666667">
LCS sentence:
Chinese Translation:
English Translation:
KA request 40%ok 3%Y-
P�A 9�* 40%ok 3%Y-
People request to change the Constitution
</figure>
<figureCaption confidence="0.985334">
Figure 1: The upper sentence is the original LCS sentence. The bottom ones are its translation in pure Chinese and English.
Underlined words are the original words in the LCS sentence.
</figureCaption>
<bodyText confidence="0.987761681818182">
In most LCS utterances, the minority language
replaces or substitutes for words in the majority
language, and thus it does not serve as a translation
of any majority-language words in the sentence.
If we can enforce that a word alignment model
avoids pairing words that appear in the same
LCS sentence, we can significantly narrow down
the possible choices of the translation candidates
during word alignment training.
Formally, let tLCS be the set of target (Chinese)
words and sLCS be the source (English) words in
the same sentence of the LCS data. According to
our observation, each sLCS
j in sLCS should not
be aligned with any word tLCS
i in tLCS. We call
every target-source word pair (tLCS
i , sLCS
j ) from
LCS data a blocked alignment. For a set of word
alignments WA = {(sw, tw)I produced by a word
alignment model, define
</bodyText>
<equation confidence="0.9007415">
1: OBA = 1[(sw, tw) E BA] (1)
(sw,tw)∈WA
</equation>
<bodyText confidence="0.9968835">
where BA is the set of blocked alignments
extracted from the LCS data. We want to minimize
OBA. Figure 2 shows a graphical illustration of this
constraint.
</bodyText>
<figureCaption confidence="0.998329">
Figure 2: Illustration of the blocked alignment constraint.
</figureCaption>
<bodyText confidence="0.968772318181818">
4.2 Encouraging alignments with substitutes
proposed by a language model
Another perspective of using the LCS data is
that if we can find some target word set tsimilar
from the target language which shares similar
contexts as the source word sLCS
data, then we can encourage sLCS
j to be aligned
j in the LCS
with the each word tsimilar in tsimilar. Figure
m
3 shows example phrases (“F� A 31 A 6,4 &amp;” ,
“ F�A:I!*6,4&amp;”, “F�A4fEf6,4&amp;” etc) that
appear in a Chinese language model and which
share the same left context and right context as
the word “request.” Our second objective is to
encourage minority language words like “request”
to align with possible substitutes from the majority
language’s language model. If we see any of
“31A, :1!*, 4fiM” in the parallel corpus, we
should encourage the word “request” to be aligned
with them. We call this target-source word pair
</bodyText>
<equation confidence="0.862664833333333">
(tsimilar
j ) an encouraged alignment. Formally, we define
m , sLCS
1:
OEA = |C |1[(sw, tw) E EA] (2)
(sw,tw)∈WA
</equation>
<bodyText confidence="0.9980924">
where |C |is the size of the parallel corpus and EA
is the encouraged alignment set. We define this
expression in such a way that if the optimization
procedure minimizes it, it will increase the number
of encouraged alignments.
</bodyText>
<figureCaption confidence="0.9900905">
Figure 3: Illustration of the encouraged alignment
constraint. The dotted rectangle shows the candidate
translations of the English word from the tri-gram output
from the language model
</figureCaption>
<bodyText confidence="0.854045333333333">
Algorithm 1 shows the algorithm of calculating
tsimilar. (tLCS
l , sLCS
j , tLCS
r ) is a (target, source,
target)word tuple contained in the LCS data. l
and r denote the left and right target words to the
source word. We use the language model output
from the target language. For each pair of contexts
tl and tr for the source word, we find the exact
match of this pair in the ngram. Then we extract
the middle word as the candidates for tsimilar.
Here, we only use 3 grams in our experiments, but
it is possible to extend this to 5grams, which might
lead to further improvements. The EA constraint
</bodyText>
<figure confidence="0.998450333333333">
V�A
(People)
SOA
(change)
3M
(constitution)
request
Trigrams
iZA #@M(refuse) Wk
iZA MiA(suggest) Wk
iZA Oftequest) Wk
iZA
(People)
Wk
(change)
3M
(constitution)
request
</figure>
<page confidence="0.77007">
4
</page>
<listItem confidence="0.899308666666667">
Algorithm 1: finding tsimilar
1: Input: sLCS,tLCS, language model LM
2: Set tsimilar={}
3: Extract the 3 grams (tl, tm, tr) E gram3 from
LM
4: set S = {}
5: For j from 1 to size(gram3)
if (tjl , tjr) E S
add tjm into C j j
</listItem>
<figure confidence="0.9805276">
tl ,tr
else
put (tjl , tjr) into S
set Ctj l ,tj r = {}
6: Extract tuple (tLCS
l , sLCS
j , tLCS
r )
if KCS,
tLCS) E S
add Ct LCS/ l ,tLCS
r into tsimilar
7: Output: tsimilar
民众 request 修改 宪法
(People request to change the constitution)
</figure>
<figureCaption confidence="0.9405485">
Figure 4: The framework of co-training in word alignment.
AM represents alignment model and LM represents language
model. Green italic words are the encouraged translation and
red italic words are the discouraged translation.
</figureCaption>
<equation confidence="0.991691833333333">
民众 要求 修改 (0.06)
民众 慰留 修改 (0.002)
民众 委托 修改 (0.01)
民众 请求 修改 (0.04)
民众 要求 修改 宪法 (0.025)
民众 慰留 修改 宪法 (0.05)
</equation>
<figure confidence="0.959899724137931">
Update mixed data
民众 委托 修改 宪法 (0.009)
......
LM
Chinese
Monolingual
data
Translation Table
request 要求
0.025
......
Request 慰留
0.05
request 委托
0.009
......
Translation Table
......
request 要求
0.06
request 请求
0.04
Request 慰留
0.0002
request 委托
0.01
Update Translation Table
......
AM
</figure>
<bodyText confidence="0.999564615384615">
is similar to a bilingual dictionary. However, in the
bilingual dictionary, each source word might have
several target translations (senses), so it might be
ambiguous. The candidate translations used in
EA are from language model (3 grams in this
paper, but it can be extended to 5 grams), which
will always match the contexts. Additionally,
the bilingual dictionary contains the standard
English/Chinese word pairs. But the LCS data
is generated from people&apos;s daily conversation; it
reflects usage in a variety of domains, including
colloquial and figurative usages that may not
appear in a dictionary.
</bodyText>
<subsectionHeader confidence="0.99967">
4.3 Constrained parameter estimation
</subsectionHeader>
<bodyText confidence="0.999606555555556">
We incorporate φBA and φEA into the EM
training procedure for the alignment model using
posterior regularization (PR) (Ganchev et al.,
2010). Formally, let x be the sentence pairs s and
t. During the E step, instead of using the posterior
p(a|x) to calculate the expected counts, the PR
framework tries to find a distribution q(a) which
is close to p(a|x), but which also minimizes the
properties φ(a, x):
</bodyText>
<equation confidence="0.99497">
min [KL(q(a)||p(a|x, θ)) + σ||ξ||] (3)
q,ξ
s.t. Ea,.,q[φ(a,x)] ≤ ξ (4)
</equation>
<bodyText confidence="0.9980212">
where KL is the Kullback-Leibler divergence, σ
is a free parameter indicating how important the
constraints are compared with the marginal log
likelihood and ξ is a small violation allowed in
the optimization. To impose multiple constraints,
</bodyText>
<equation confidence="0.899887">
V/
A = (ξtAξ), where A
</equation>
<bodyText confidence="0.9598805">
is a diagonal matrix whose diagonal entries Aii
are free parameters that provide weights on the
different constraints. Since we only have two
constraints here from LCS data, A = ( 1 0 )
</bodyText>
<equation confidence="0.740759">
0 α
</equation>
<bodyText confidence="0.999779">
where α controls the relative importance of the
two constraints.
To make the optimization task in the E-step
more tractable, PR transforms it to a dual problem:
</bodyText>
<equation confidence="0.536309">
p(a|x, θ) exp{−λ·φ(a, x)}
</equation>
<bodyText confidence="0.9999665">
where 11·11. is the dual norm of 11·11A. The gradient
of this dual objective is −Eq[φ(a, x)]. A projected
subgradient descent algorithm is used to perform
the optimization.
</bodyText>
<sectionHeader confidence="0.829619" genericHeader="method">
5 Co-training using the LCS data
</sectionHeader>
<bodyText confidence="0.999983846153846">
The above approaches alter the translation and
distortion probabilities in the alignment model.
However, they leave the language model un-
changed. We next investigate a technique that
uses LCS data to re-estimate parameters for the
language model as well as the alignment model
simultaneously. Co-training (Blum and Mitchell,
1998) is a semi-supervised learning technique
that requires two different views of the data. It
assumes that each example can be described using
two different feature sets which are conditionally
independent. Also, each feature set of the data
should be sufficient to make accurate prediction.
</bodyText>
<figure confidence="0.95307">
we define a norm ||ξ||
max �− log
λ?0,llλll∗&lt;_σ a
</figure>
<page confidence="0.958193">
5
</page>
<bodyText confidence="0.999979736842105">
The schema fits perfectly into our problem. We
can treat the alignment model and the language
model as two different views of the LCS data.
We use the same example “F�Arequest &apos;(IX&amp;
�fM” to show how co-training works, shown in
Figure 4. From the translation table generated
by the alignment model, we can get a set of
candidate translations of “request”, such as “‘:I!
*”,“�*”,etc. We can find the candidate with the
highest probability as the translation. Similarly,
from the language model, we can extract all the
ngrams containing “ F�A” and “&apos;(IX&amp;” as the left
and right words and pick the words in the middle
such as “ 31A, :1!*, 40-OT” etc as the candidate
translations. We can then use the candidate
with the highest probability as the translation
for “request”. Thus both models can predict
translations for the English (minority language) in
this example. Each model’s predictions can be
used as supplemental training data for the other
model.
Algorithm 2 shows the co-training algorithm for
word alignment. At each iteration, a language
model and an alignment model are trained. The
language model is trained on a Chinese-only
corpus plus a corpus of probabilistic LCS sen-
tences where the source words are replaced with
target candidates from the alignment model. The
alignment model is retrained using a translation
table which is updated according to the output
word pairs from the language model output and the
LCS data. In order to take the sentence probability
into consideration, we modify the language model
training procedure: when it counts the number of
times each ngram appears, instead of adding 1,
it adds the probability from the translation model
for ngrams in the LCS data that contain predicted
translations.
</bodyText>
<sectionHeader confidence="0.987125" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.99281">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.970553166666667">
We evaluated our LCS-driven training algorithms
on an English-to-Chinese translation task. We
use Moses (Koehn et al., 2003), a phrase-
based translation system that learns from bilingual
sentence-aligned corpora as the MT system. We
supplement the baseline word alignment model in
Moses with our LCS data, constrained training
procedure, and co-training algorithm as well as
IBM 3 model. Because IBM 3 model is a
fertility based model which might also alleviate
Algorithm 2: Co-training for word alignment and
language modeling
</bodyText>
<listItem confidence="0.98781575">
1: Input: parallel data Xp, LCS data XLCS,
language model training data Xl
2: Initialize translation table tb for IBM1 model
3: For iteration from 1 to MAX
</listItem>
<figure confidence="0.320515916666667">
tb +— Train-IBM(Xp)
tb� +— Train-HMM(Xp|tb)
4: For each sentence xi in XLCS:
For each source word sj in xi:
1) find the translation tj of sj with
with probability pj from tb�
X2) replace sj with tj and update
sentence’s probability ps = ps * pj
new
l +— Xl U xi
5: LM +— Train-LM(Xnew
l )
</figure>
<listItem confidence="0.979793857142857">
6: Extract the tri-gram gram3 from LM
7: For each sentence xi in XLCS:
run Algorithm 1: finding tsimilar
8: update tb� using (tm, sj) where
tm E tsimilar and sj E xi
9: End For
10: Output: word alignment for Xp and LM
</listItem>
<bodyText confidence="0.999620846153846">
some of the problems caused by LCS data. To
clarify, we use IBM1 model and HMM models in
succession for the baseline. We trained the IBM1
model first and used the resulting parameters
as the initial parameter values to train HMM
model. Parameters for the final MT system
are tuned with Minimum Error Rate Training
(MERT) (Och, 2003). The tuning set for MERT
is the NIST MT06 data set, which includes 1664
sentences. We test the system on NIST MT02
(878 sentences). To evaluate the word alignment
results, we manually aligned 250 sentences from
NIST MT02 data set. For simplicity, we only
have two types of labels for evaluating word
alignments: either two words are aligned together
or not. (Previous evaluation metrics also consider
a third label for ”possible” alignments.) Out of
the word-aligned data, we use 100 sentences as a
development set and the rest as our testing set.
Our MT training corpus contains 2,636,692
sentence pairs from two parallel corpora: Hong
Kong News (LDC2004T08) and Chinese English
News Magazine Parallel Text (LDC2005T10). We
use the Stanford Chinese segmenter to segment
the Chinese data. We use a ngram model
package called SRILM (Stolcke, 2002) to train
</bodyText>
<page confidence="0.99856">
6
</page>
<bodyText confidence="0.999976642857143">
the language model. Because our modified
ngram counts contain factions, we used Witten-
Bell smoothing(Witten and Bell, 1991) which
supports fractional counts. The 3-gram language
model is trained on the Xinhua section of the
Chinese Gigaword corpus (LDC2003T09) as well
as the Chinese side of the parallel corpora. We
also removed the sentences in MT02 from the
Gigaword corpus if there is any to avoid the biases.
We gather the LCS data from “MITBBS.com,”
a popular forum for Chinese people living in
the United States. This forum is separated by
discussion topic, and includes topics such as
“Travel”, “News”, and “Living style”. We extract
data from 29 different topics. To clean up the
LCS data, we get rid of HTML mark-up, and we
remove patterns that are commonly repeated in
forums, like “Re:” (for “reply” posts) and “[ff
&apos;c]” (for “repost”). We change all English letters
written in Chinese font into English font. We stem
the English words in both the parallel training data
and the LCS data. After the cleaning step, we have
245,470 sentences in the LCS data. 120,922 of
them actually contain both Chinese and English in
the same sentence. 101,302 of them contain only
Chinese, and we add these into the language model
training data. We discard the sentences that only
contain English.
</bodyText>
<subsectionHeader confidence="0.999705">
6.2 Word Alignment Results
</subsectionHeader>
<bodyText confidence="0.999870714285714">
In order to incorporate the two constraints during
the Posterior Regularization, we need to tune the
parameters σ which controls the weights between
the constraints and the marginal likelihood and
α which controls the relative importance between
two constraints on development data. We varied
σ from 0.1 to 1000 and varied α over the
set {0.01, 0.1,1,10,100}. After testing the
25 different combinations of σ and α on the
development data, we find that the setting with
σ = 100 and α = 0.1 achieves the best
performance. During PR training, we trained the
model 20 iterations for the dual optimization and
5 iterations for the modified EM.
Table 1 shows the word alignment results. We
can see that incorporating the LCS data into
our alignment model improves the performance.
Our best co-training+PR+ system outperforms
the baseline by 8 points. Figure 5 shows an
example of how BA is extracted from LCS data
can help the word alignment performance. The
</bodyText>
<table confidence="0.99881825">
System F1
Baseline 0.68
IBM 3 0.70
PR+BA 0.71
PR+EA 0.70
PR+ 0.73
co-training 0.74
co-training+PR+ 0.76
</table>
<tableCaption confidence="0.999955">
Table 1: Word alignment results (PR+ means PR+BA+EA).
</tableCaption>
<bodyText confidence="0.999954611111111">
upper figure shows that alignment by the baseline
system. We can see that the word “badminton”
is aligned incorrectly with word “&gt;�A(Taufik)”
. However, in the LCS data, we see that “ &gt;�
A(Taufik)” and “badminton” appear in the same
sentence “&gt;VAMbadminton�kW9_T(Taufik
plays badminton so well)” and by adding the
blocked constraint into the alignment model, it
correctly learns that “ &gt;�A(Taufik)” should be
aligned with something else, and it finds “Taufik”
at end. Table 2 shows some of the translations
of “badminton” before and after incorporating the
LCS data. We can see that it contains some wrong
translations like “�F; -#-(pingpong room)”,“&gt;
� A(Taufik)”etc using baseline model. After
using the LCS data as constraints and the co-
training framework, these wrong alignments are
eliminated and the translation “,I� f*(another
way of expressing badminton)” get a higher
probability. We found that IBM 3 model can
also correct this specific case. However, our
co-training+PR+ system still outperforms it by 6
points.
Figure 6 shows an example of how EA is
extracted from LCS data can help the word
alignment. The solid lines show the alignment
by the baseline model and we can see that
the word “compiled” is not aligned with any
Chinese word. After using the LCS data and the
language model, we find that “ ftompile)”
shows up in the same context “Ö(book) jh�
*(up)”as “compile” along with “ ]T(staple)”
and “�T(staple)”, therefore “(compile, m)” will
be an encouraged alignment. After adding the EA
constraint, the model learns that “compile” should
be aligned with “ W.
</bodyText>
<subsectionHeader confidence="0.994654">
6.3 Phrase-based machine translation
</subsectionHeader>
<bodyText confidence="0.9924045">
In this section, we investigated whether improved
alignments can improve MT performance. We
</bodyText>
<page confidence="0.996213">
7
</page>
<figure confidence="0.871239333333333">
Vld k7:fng -V* kt PNSA M fl�� W17$il
Indonesia badminton experts think Taufik’s ranking favorable
Vld k7:fng -V* kt PNSA M fl�� W17$il
Indonesia badminton experts think Taufik’s ranking favorable
Baseline:
PR+BA:
</figure>
<figureCaption confidence="0.956392">
Figure 5: After incorporating the BA constraint from the LCS data, the word “Taufik(N*A)” is aligned correctly.
</figureCaption>
<table confidence="0.999566375">
Baseline PR+co-training
Translation Probability Translation Probability
f¥(badminton) 0.500 f¥(badminton) 0.500
A-E�-¥(pingpong)-&apos;#-(room) 0.500 ¥(two of the three characters in badminton) 0.430
4T(play)f(feather) 0.250 Wplay)f(feather) 0.326
f¥(shuttlecock)5;:(head) 0.125 f¥(shuttlecock),�!,-(head) 0.105
... ... ... ...
NVA(Taufik) 0.005 Ga ¥û(racket) 0.002
</table>
<tableCaption confidence="0.996345">
Table 2: Translation tables of “badminton” before and after incorporation of LCS data.
</tableCaption>
<figure confidence="0.269538">
经 评审 后 的 获奖 作品 则 集纳
Winning entries after the review will be compiled
</figure>
<figureCaption confidence="0.3225165">
Table 3: Machine translation results. All entries marked
with an asterisk are better than the baseline with 95%
statistical significance computed using paired bootstrap
resampling (Koehn, 2004).
</figureCaption>
<figure confidence="0.981439857142857">
如何 把 书 compile 起来?
(How to compile the book ?)
Trigrams
书(book) 集纳(compile) 起来(up)
书(book) 装订(staple) 起来(up)
书(book) 订(staple) 起来
()
...
System BLEU score
Baseline 29.15
IBM 3 30.24
PR+ 31.59*
co-training 31.04*
co-training+PR+ 31.79*
</figure>
<figureCaption confidence="0.9910675">
Figure 6: After incorporating the EA constraint from the
LCS data, the word “compiled(�-l)” is aligned correctly.
</figureCaption>
<bodyText confidence="0.999965">
use different word alignment models’ outputs as
the first step for Moses and keep the rest of
Moses system the same. We incorporate Moses’s
eight standard features as well as the lexicalized
reordering model. We also use the grow-diag-final
</bodyText>
<equation confidence="0.405353">
Otb 16 13
</equation>
<bodyText confidence="0.995490428571429">
and alignment symmetrization heuristic.
Table 3 shows the machine translation results.
We can see that 3 techniques we proposed for word
alignment all improve the machine translation
result over the baseline system as well as the
IBM 3 model. However, although co-training
has a bigger improvement on the word alignment
compared with PR+, it actually has a lower
BLEU score. This phenomenon shows that the
improvement in the word alignment does not
necessarily lead to the improvement on machine
translation. After combining the co-training
and the PR+ together, co-training+PR+ improved
slightly over PR+ for MT.
</bodyText>
<sectionHeader confidence="0.992206" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999815">
In this paper, we explored two different ways to
use LCS data in a MT system: 1) PR framework
to incorporate with Blocked Alignment and
Encouraged Alignment constraints. 2) A semi-
supervised co-training procedure. Both techniques
improve the performance of word alignment and
MT over the baseline. Our techniques are
currently limited to sentences where the LCS data
contains very short (usually one word) phrases
from a minority language. An important line of
investigation for generalizing these approaches is
to consider techniques that cover longer phrases in
the minority language; this can help add more of
the LCS data into training.
</bodyText>
<sectionHeader confidence="0.998398" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.632811">
This work was supported in part by NSF awards
1065397 and 1218692.
</bodyText>
<page confidence="0.997849">
8
</page>
<sectionHeader confidence="0.993837" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998987578313253">
S.and Carbonell J. Ambati, V.and Vogel. 2010.
Active semi-supervised learning for improving word
alignment. In In Proceedings of the Active Learning
for NLP Workshop, NAACL.
Avrim Blum and Tom Mitchell. 1998. Combining
labeled and unlabeled data with co-training. In
Annual Conference on Computational Learning
Theaory.
P. F. Brown, S. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1994. The mathematics of statistical
machine translation: Parameter estimation. Compu-
tational Linguistics, 19(2):263–311.
Chris Callison-Burch and Miles Osborne. 2003. Co-
training for statistical machine translation. In In
Proceedings of the 6th Annual CLUK Research
Colloquium.
Chris Callison-Burch, David Talbot, and Miles Os-
borne. 2004. Statistical machine translation with
word- and sentence-aligned parallel corpora. In In
Proceedings of ACL.
J. Y. C. Chan, P. C. Ching, and H. M. LEE, T.and Meng.
2004. Detection of language boundary in code-
switching utterances by bi-phone probabilities. In
In Proceedings of the International Symposium on
Chinese Spoken Language Processing.
A De Fina. 2007. Code-switching and the construction
of ethnic identity in a community of practice. In
Language in Society, volume 36.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum likelihood from incomplete data via the
em algorithm. In Royal Statistical Society, Ser,
volume 39.
Andreas Eisele. 2006. Parallel corpora and
phrase-based statistical machine translation for new
language pairs via multiple intermediaries. In
International Conference on Language Resources
and Evaluation.
Alex Fraser and Daniel Marcu. 2006. Semi-supervised
training for statistical word alignment. In In
Proceedings of ACL.
Kuzman Ganchev, J. Graca, Jennifer Gillenwater, and
Ben Taskar. 2010. Posterior regularization for
structured latent variable models. In Journal of
Machine Learning Research, volume 11.
J. Graca, K. Ganchev, and B. Taskar. 2008.
Expectation maximization and posterior constraints.
In NIPS.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
NAACL-HLT.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In In Proceedings of
EMNLP.
Shankar Kumar, Franz Josef Och, and Wolfgang
Macherey. 2007. Improving word alignment with
bridge languages. In EMNLP.
Esme Manandise and Claudia Gdaniec. 2011. Mor-
phology to the rescue redux: Resolving borrowings
and code-mixing in machine translation. In SFCM.
C. Nilep. 2006. Code switching in sociocultural
linguistics. In Colorado Research in Linguistics,
volume 19.
Franz Josef Och. 2003. Minimum error rate training
for statistical machine translation. In ACL.
R.M.K. Sinha and A. Thakur. 2005. Machine
translation of bi-lingual hindi-english (hinglish)
text. In In Proceedings of the 10th Conference on
Machine Translation.
T. Solorio and Y. Liu. 2008. Learning to predict
code-switching points. In In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing (EMNLP).
A. Stolcke. 2002. An extensible language modeling
toolkit. In Proc. Intl. Conf. on Spoken Language
Processing, volume 2, pages 901–904.
S. Vogel, H. Ney, and C. Tillmann. 1996. Hmm-
based word alignment in statistical translation. In
In Proc.COLING.
Ian H. Witten and Timothy C. Bell. 1991. The zero-
frequency problem: Estimating the probabil- ities of
novel events in adaptive text compression. In IEEE
Transactions on Information Theory, volume 4,
pages 1085–1094.
</reference>
<page confidence="0.997035">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.833304">
<title confidence="0.999111">Improving Word Alignment Using Linguistic Code Switching Data</title>
<author confidence="0.908224">Temple</author>
<affiliation confidence="0.945911">Computer and Information</affiliation>
<address confidence="0.9594105">324 Wachman Philadelphia, PA</address>
<abstract confidence="0.999756222222222">Linguist Code Switching (LCS) is a situation where two or more languages show up in the context of a single conversation. For example, in English- Chinese code switching, there might a sentence like �rP (We will have a meeting in 15 minutes)”. Traditional machine translation (MT) systems treat LCS data as noise, or just as regular sentences. However, if LCS data is processed intelligently, it can provide a useful signal for training word alignment and MT models. Moreover, LCS data is from non-news sources which can enhance the diversity of training data for MT. In this paper, we first extract constraints from this code switching data and then incorporate them into a word alignment model training procedure. We also show that by using the code switching data, we can jointly train a word alignment model and a language model using cotraining. Our techniques for incorporating LCS data improve by 2.64 in BLEU score over a baseline MT system trained using only standard sentence-aligned corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S and Carbonell J Ambati</author>
<author>V and Vogel</author>
</authors>
<title>Active semi-supervised learning for improving word alignment. In</title>
<date>2010</date>
<booktitle>In Proceedings of the Active Learning for NLP Workshop,</booktitle>
<location>NAACL.</location>
<marker>Ambati, Vogel, 2010</marker>
<rawString>S.and Carbonell J. Ambati, V.and Vogel. 2010. Active semi-supervised learning for improving word alignment. In In Proceedings of the Active Learning for NLP Workshop, NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In Annual Conference on Computational Learning Theaory.</booktitle>
<contexts>
<context position="19857" citStr="Blum and Mitchell, 1998" startWordPosition="3249" endWordPosition="3252">he E-step more tractable, PR transforms it to a dual problem: p(a|x, θ) exp{−λ·φ(a, x)} where 11·11. is the dual norm of 11·11A. The gradient of this dual objective is −Eq[φ(a, x)]. A projected subgradient descent algorithm is used to perform the optimization. 5 Co-training using the LCS data The above approaches alter the translation and distortion probabilities in the alignment model. However, they leave the language model unchanged. We next investigate a technique that uses LCS data to re-estimate parameters for the language model as well as the alignment model simultaneously. Co-training (Blum and Mitchell, 1998) is a semi-supervised learning technique that requires two different views of the data. It assumes that each example can be described using two different feature sets which are conditionally independent. Also, each feature set of the data should be sufficient to make accurate prediction. we define a norm ||ξ|| max �− log λ?0,llλll∗&lt;_σ a 5 The schema fits perfectly into our problem. We can treat the alignment model and the language model as two different views of the LCS data. We use the same example “F�Arequest &apos;(IX&amp; �fM” to show how co-training works, shown in Figure 4. From the translation t</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In Annual Conference on Computational Learning Theaory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="10292" citStr="Brown et al., 1994" startWordPosition="1613" endWordPosition="1616">ork (Ganchev et al., 2010), which has previously been used for MT (Graca et al., 2008), but with very different constraints on EM training and different goals. (Graca et al., 2008) use PR to enforce the constraint that one word should not translate to many words, and that if a word s translates to a word t in one MT system, then a model for translation in the reverse direction should translate t to s. Both of these constraints apply to sentence-aligned training data directly, and complement the constraints that we extract from LCS data. 3 Statistical Word Alignment Statistical word alignment (Brown et al., 1994) is the task identifying which words are translations of each other in a bilingual sentence corpus. It is primarily used for machine translation. The input to an alignment system is a sentence-level aligned bilingual corpus, which consists of pairs of sentences in two languages. One language is denoted as the target language, and the other language as the source language. We now introduce the baseline model for word alignment and how we can incorporate the LCS data to improve the model. IBM Model 1 (Brown et al., 1994) and the HMM alignment model (Vogel et al., 1996) are cascaded to form the b</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1994</marker>
<rawString>P. F. Brown, S. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1994. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Cotraining for statistical machine translation. In</title>
<date>2003</date>
<booktitle>In Proceedings of the 6th Annual CLUK Research Colloquium.</booktitle>
<marker>Callison-Burch, Osborne, 2003</marker>
<rawString>Chris Callison-Burch and Miles Osborne. 2003. Cotraining for statistical machine translation. In In Proceedings of the 6th Annual CLUK Research Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora. In</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8850" citStr="Callison-Burch et al. (2004)" startWordPosition="1380" endWordPosition="1383">ned corpus and showed that this technique can be used to obtain higher quality bilingual word alignments. Other work like (Eisele, 2006) took the issue one step further that they used bilingual translation systems 2 which share one or more common pivot languages to build systems which non-parallel corpus is used. Unlike the data in these techniques, LCS data requires no manual alignment effort and is freely available in large quantities. Another line of research has attempted to improve word alignment models by incorporating manually-labeled word alignments in addition to sentence alignments. Callison-Burch et al. (2004) tried to give a higher weight on manually labeled data compared to the automatic alignments. Fraser and Marcu (2006) used a log-linear model with features from IBM models. They alternated the traditional Expectation Maximization algorithm which is applied on a large parallel corpus with a discriminative step aimed at increasing wordalignment quality on a small, manually wordaligned corpus. Ambati et al.(2010) tried to manually correct the alignments which are informative during the unsupervised training and applied them to an active learning model. However, labeled word alignment data is expe</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Y C Chan</author>
<author>P C Ching</author>
<author>H M LEE</author>
<author>T and Meng</author>
</authors>
<title>Detection of language boundary in codeswitching utterances by bi-phone probabilities. In</title>
<date>2004</date>
<booktitle>In Proceedings of the International Symposium on Chinese Spoken Language Processing.</booktitle>
<contexts>
<context position="6636" citStr="Chan et al., 2004" startWordPosition="1034" endWordPosition="1037">this paper is organized as follows. The next section presents related work. Section 3 gives an overview of word alignment. Sections 4 and 5 detail our two algorithms. Section 6 presents our experiments and discusses results, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and socio-linguistic communities (Nilep, 2006; De Fina, 2007). Computational research on LCS has studied how to identify the boundaries of an individual language within LCS data, or how to predict when an utterance will switch to another language (Chan et al., 2004; Solorio and Liu, 2008). Manandise and Gdaniec (2011) analyzed the effect on machine translation quality of LCS of Spanish-English and showed that LCS degrades the performance of the syntactic parser. Sinha and Thakur (2005) translate mixed Hindi and English (Hinglish) to pure Hindi and pure English by using two morphological analyzers from both Hindi and English. The difficulty in their problem is that Hindi and English are often mixed into a single word which uses only the English alphabet; approaches based only on the character set cannot tell these words apart from English words. Our curr</context>
</contexts>
<marker>Chan, Ching, LEE, Meng, 2004</marker>
<rawString>J. Y. C. Chan, P. C. Ching, and H. M. LEE, T.and Meng. 2004. Detection of language boundary in codeswitching utterances by bi-phone probabilities. In In Proceedings of the International Symposium on Chinese Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A De Fina</author>
</authors>
<title>Code-switching and the construction of ethnic identity in a community of practice.</title>
<date>2007</date>
<booktitle>In Language in Society,</booktitle>
<volume>36</volume>
<marker>De Fina, 2007</marker>
<rawString>A De Fina. 2007. Code-switching and the construction of ethnic identity in a community of practice. In Language in Society, volume 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>In Royal Statistical Society, Ser,</journal>
<volume>39</volume>
<contexts>
<context position="11516" citStr="Dempster et al., 1977" startWordPosition="1827" endWordPosition="1830">eline model for alignment. These two models have a similar formulation L = P(t, a|s) = P(a) Hj P(tj|saj) with a different distortion probability P(a). s and t denote the source and target sentences. a is the alignment, and aj is the index of the source language word that generates the target language word at position j. The HMM model assumes the alignments have a first-order Markov dependency, so that P(a) = H j P(aj|aj − aj−1). IBM Model 1 ignores the word position and uses a uniform distribution, so P(a) = Hj P(aj) where P(aj) = 1 |t|, where |t| is the length of t. Expectation Maximization (Dempster et al., 1977) is typically used to train the alignment model. It tries to maximize the marginal likelihood of the sentence-level aligned pairs. For the HMM alignment model, the forwardbackward algorithm can be used the optimize the posterior probability of the hidden alignment a. 4 Learning Constraints for Word Alignments from LCS Data We observed that most LCS sentences are predominantly in one language, which we call the majority language, with just a small number of words from another language, which we call the minority language. The grammar of each sentence appears to mirror the structure of the major</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. In Royal Statistical Society, Ser, volume 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Eisele</author>
</authors>
<title>Parallel corpora and phrase-based statistical machine translation for new language pairs via multiple intermediaries.</title>
<date>2006</date>
<booktitle>In International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="8358" citStr="Eisele, 2006" startWordPosition="1308" endWordPosition="1309">e alignment model and language model as different views of LCS data. In addition to co-training, various other semisupervised approaches for MT and word alignment have been proposed, but these have relied on sentence alignments among multiple languages, rather than LCS data. Kay (2000) proposes using multiple target documents as a way of informing subsequent machine translations. Kumar et al. (2007) described a technique for word alignment in a multi-parallel sentence-aligned corpus and showed that this technique can be used to obtain higher quality bilingual word alignments. Other work like (Eisele, 2006) took the issue one step further that they used bilingual translation systems 2 which share one or more common pivot languages to build systems which non-parallel corpus is used. Unlike the data in these techniques, LCS data requires no manual alignment effort and is freely available in large quantities. Another line of research has attempted to improve word alignment models by incorporating manually-labeled word alignments in addition to sentence alignments. Callison-Burch et al. (2004) tried to give a higher weight on manually labeled data compared to the automatic alignments. Fraser and Mar</context>
</contexts>
<marker>Eisele, 2006</marker>
<rawString>Andreas Eisele. 2006. Parallel corpora and phrase-based statistical machine translation for new language pairs via multiple intermediaries. In International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semi-supervised training for statistical word alignment. In</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8967" citStr="Fraser and Marcu (2006)" startWordPosition="1399" endWordPosition="1402">(Eisele, 2006) took the issue one step further that they used bilingual translation systems 2 which share one or more common pivot languages to build systems which non-parallel corpus is used. Unlike the data in these techniques, LCS data requires no manual alignment effort and is freely available in large quantities. Another line of research has attempted to improve word alignment models by incorporating manually-labeled word alignments in addition to sentence alignments. Callison-Burch et al. (2004) tried to give a higher weight on manually labeled data compared to the automatic alignments. Fraser and Marcu (2006) used a log-linear model with features from IBM models. They alternated the traditional Expectation Maximization algorithm which is applied on a large parallel corpus with a discriminative step aimed at increasing wordalignment quality on a small, manually wordaligned corpus. Ambati et al.(2010) tried to manually correct the alignments which are informative during the unsupervised training and applied them to an active learning model. However, labeled word alignment data is expensive to produce. Our approach is complementary, in that we use mixed data that has no word alignments, but still abl</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alex Fraser and Daniel Marcu. 2006. Semi-supervised training for statistical word alignment. In In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>J Graca</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>In Journal of Machine Learning Research,</journal>
<volume>11</volume>
<contexts>
<context position="4865" citStr="Ganchev et al., 2010" startWordPosition="752" endWordPosition="755">extracted from LCS data to guide the EM training procedure for word alignment over a standard sentence-aligned parallel corpus. We focus on two types of patterns in the LCS data: first, English words are almost never correct translations for any Chinese word in the same LCS utterance. Second, for sentences that are mostly Chinese but with some English words, if we propose substitutes for the English words using a Chinese language model, those substitutes are often good translations of the English words. We incorporate these patterns into EM training via the posterior regularization framework (Ganchev et al., 2010). Our second approach treats the alignment and language model as two different and complementary views of the data. We apply the cotraining paradigm for semi-supervised learning to incorporate the LCS data into the training procedures for the alignment model and the language model. From the translation table of the alignment model, the training procedure finds candidate translations of the English words in the LCS data, and uses those to supplement the language model training data. From the language model, the training procedure identifies Chinese words that complete the Chinese sentence with </context>
<context position="9699" citStr="Ganchev et al., 2010" startWordPosition="1512" endWordPosition="1515">n algorithm which is applied on a large parallel corpus with a discriminative step aimed at increasing wordalignment quality on a small, manually wordaligned corpus. Ambati et al.(2010) tried to manually correct the alignments which are informative during the unsupervised training and applied them to an active learning model. However, labeled word alignment data is expensive to produce. Our approach is complementary, in that we use mixed data that has no word alignments, but still able to learn constraints on word alignments. Our techniques make use of posterior regularization (PR) framework (Ganchev et al., 2010), which has previously been used for MT (Graca et al., 2008), but with very different constraints on EM training and different goals. (Graca et al., 2008) use PR to enforce the constraint that one word should not translate to many words, and that if a word s translates to a word t in one MT system, then a model for translation in the reverse direction should translate t to s. Both of these constraints apply to sentence-aligned training data directly, and complement the constraints that we extract from LCS data. 3 Statistical Word Alignment Statistical word alignment (Brown et al., 1994) is the</context>
<context position="18342" citStr="Ganchev et al., 2010" startWordPosition="2997" endWordPosition="3000">iguous. The candidate translations used in EA are from language model (3 grams in this paper, but it can be extended to 5 grams), which will always match the contexts. Additionally, the bilingual dictionary contains the standard English/Chinese word pairs. But the LCS data is generated from people&apos;s daily conversation; it reflects usage in a variety of domains, including colloquial and figurative usages that may not appear in a dictionary. 4.3 Constrained parameter estimation We incorporate φBA and φEA into the EM training procedure for the alignment model using posterior regularization (PR) (Ganchev et al., 2010). Formally, let x be the sentence pairs s and t. During the E step, instead of using the posterior p(a|x) to calculate the expected counts, the PR framework tries to find a distribution q(a) which is close to p(a|x), but which also minimizes the properties φ(a, x): min [KL(q(a)||p(a|x, θ)) + σ||ξ||] (3) q,ξ s.t. Ea,.,q[φ(a,x)] ≤ ξ (4) where KL is the Kullback-Leibler divergence, σ is a free parameter indicating how important the constraints are compared with the marginal log likelihood and ξ is a small violation allowed in the optimization. To impose multiple constraints, V/ A = (ξtAξ), where </context>
</contexts>
<marker>Ganchev, Graca, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, J. Graca, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. In Journal of Machine Learning Research, volume 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Graca</author>
<author>K Ganchev</author>
<author>B Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2008</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="9759" citStr="Graca et al., 2008" startWordPosition="1523" endWordPosition="1526"> discriminative step aimed at increasing wordalignment quality on a small, manually wordaligned corpus. Ambati et al.(2010) tried to manually correct the alignments which are informative during the unsupervised training and applied them to an active learning model. However, labeled word alignment data is expensive to produce. Our approach is complementary, in that we use mixed data that has no word alignments, but still able to learn constraints on word alignments. Our techniques make use of posterior regularization (PR) framework (Ganchev et al., 2010), which has previously been used for MT (Graca et al., 2008), but with very different constraints on EM training and different goals. (Graca et al., 2008) use PR to enforce the constraint that one word should not translate to many words, and that if a word s translates to a word t in one MT system, then a model for translation in the reverse direction should translate t to s. Both of these constraints apply to sentence-aligned training data directly, and complement the constraints that we extract from LCS data. 3 Statistical Word Alignment Statistical word alignment (Brown et al., 1994) is the task identifying which words are translations of each other</context>
</contexts>
<marker>Graca, Ganchev, Taskar, 2008</marker>
<rawString>J. Graca, K. Ganchev, and B. Taskar. 2008. Expectation maximization and posterior constraints. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="5776" citStr="Koehn et al., 2003" startWordPosition="892" endWordPosition="895">translation table of the alignment model, the training procedure finds candidate translations of the English words in the LCS data, and uses those to supplement the language model training data. From the language model, the training procedure identifies Chinese words that complete the Chinese sentence with high probability, and it uses the English word paired with these completion words as additional training points for translation probabilities. These models are trained repeatedly until they converge to similar predictions on the LCS data. In combination with a larger phrase-based MT system (Koehn et al., 2003), these two training procedures yield an MT system that achieves a BLEU score of 31.79 on an English-to-Chinese translation task, an improvement of 2.64 in BLEU score over a baseline MT system trained on only our parallel corpora. The rest of this paper is organized as follows. The next section presents related work. Section 3 gives an overview of word alignment. Sections 4 and 5 detail our two algorithms. Section 6 presents our experiments and discusses results, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and s</context>
<context position="22107" citStr="Koehn et al., 2003" startWordPosition="3615" endWordPosition="3618">del is retrained using a translation table which is updated according to the output word pairs from the language model output and the LCS data. In order to take the sentence probability into consideration, we modify the language model training procedure: when it counts the number of times each ngram appears, instead of adding 1, it adds the probability from the translation model for ngrams in the LCS data that contain predicted translations. 6 Experiments and Results 6.1 Experimental Setup We evaluated our LCS-driven training algorithms on an English-to-Chinese translation task. We use Moses (Koehn et al., 2003), a phrasebased translation system that learns from bilingual sentence-aligned corpora as the MT system. We supplement the baseline word alignment model in Moses with our LCS data, constrained training procedure, and co-training algorithm as well as IBM 3 model. Because IBM 3 model is a fertility based model which might also alleviate Algorithm 2: Co-training for word alignment and language modeling 1: Input: parallel data Xp, LCS data XLCS, language model training data Xl 2: Initialize translation table tb for IBM1 model 3: For iteration from 1 to MAX tb +— Train-IBM(Xp) tb� +— Train-HMM(Xp|t</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation. In</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="29551" citStr="Koehn, 2004" startWordPosition="4831" endWordPosition="4832">) 0.500 A-E�-¥(pingpong)-&apos;#-(room) 0.500 ¥(two of the three characters in badminton) 0.430 4T(play)f(feather) 0.250 Wplay)f(feather) 0.326 f¥(shuttlecock)5;:(head) 0.125 f¥(shuttlecock),�!,-(head) 0.105 ... ... ... ... NVA(Taufik) 0.005 Ga ¥û(racket) 0.002 Table 2: Translation tables of “badminton” before and after incorporation of LCS data. 经 评审 后 的 获奖 作品 则 集纳 Winning entries after the review will be compiled Table 3: Machine translation results. All entries marked with an asterisk are better than the baseline with 95% statistical significance computed using paired bootstrap resampling (Koehn, 2004). 如何 把 书 compile 起来? (How to compile the book ?) Trigrams 书(book) 集纳(compile) 起来(up) 书(book) 装订(staple) 起来(up) 书(book) 订(staple) 起来 () ... System BLEU score Baseline 29.15 IBM 3 30.24 PR+ 31.59* co-training 31.04* co-training+PR+ 31.79* Figure 6: After incorporating the EA constraint from the LCS data, the word “compiled(�-l)” is aligned correctly. use different word alignment models’ outputs as the first step for Moses and keep the rest of Moses system the same. We incorporate Moses’s eight standard features as well as the lexicalized reordering model. We also use the grow-diag-final Otb 16 1</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>Franz Josef Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Improving word alignment with bridge languages.</title>
<date>2007</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="8147" citStr="Kumar et al. (2007)" startWordPosition="1275" endWordPosition="1278">osed methods, other researchers have used co-training before for MT (CallisonBurch and Osborne, 2003). They use target strings in multiple languages as different views on translation. However, in our work, we treat the alignment model and language model as different views of LCS data. In addition to co-training, various other semisupervised approaches for MT and word alignment have been proposed, but these have relied on sentence alignments among multiple languages, rather than LCS data. Kay (2000) proposes using multiple target documents as a way of informing subsequent machine translations. Kumar et al. (2007) described a technique for word alignment in a multi-parallel sentence-aligned corpus and showed that this technique can be used to obtain higher quality bilingual word alignments. Other work like (Eisele, 2006) took the issue one step further that they used bilingual translation systems 2 which share one or more common pivot languages to build systems which non-parallel corpus is used. Unlike the data in these techniques, LCS data requires no manual alignment effort and is freely available in large quantities. Another line of research has attempted to improve word alignment models by incorpor</context>
</contexts>
<marker>Kumar, Och, Macherey, 2007</marker>
<rawString>Shankar Kumar, Franz Josef Och, and Wolfgang Macherey. 2007. Improving word alignment with bridge languages. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esme Manandise</author>
<author>Claudia Gdaniec</author>
</authors>
<title>Morphology to the rescue redux: Resolving borrowings and code-mixing in machine translation.</title>
<date>2011</date>
<booktitle>In SFCM.</booktitle>
<contexts>
<context position="6690" citStr="Manandise and Gdaniec (2011)" startWordPosition="1042" endWordPosition="1045">t section presents related work. Section 3 gives an overview of word alignment. Sections 4 and 5 detail our two algorithms. Section 6 presents our experiments and discusses results, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and socio-linguistic communities (Nilep, 2006; De Fina, 2007). Computational research on LCS has studied how to identify the boundaries of an individual language within LCS data, or how to predict when an utterance will switch to another language (Chan et al., 2004; Solorio and Liu, 2008). Manandise and Gdaniec (2011) analyzed the effect on machine translation quality of LCS of Spanish-English and showed that LCS degrades the performance of the syntactic parser. Sinha and Thakur (2005) translate mixed Hindi and English (Hinglish) to pure Hindi and pure English by using two morphological analyzers from both Hindi and English. The difficulty in their problem is that Hindi and English are often mixed into a single word which uses only the English alphabet; approaches based only on the character set cannot tell these words apart from English words. Our current study is for a language pair (EnglishChinese) wher</context>
</contexts>
<marker>Manandise, Gdaniec, 2011</marker>
<rawString>Esme Manandise and Claudia Gdaniec. 2011. Morphology to the rescue redux: Resolving borrowings and code-mixing in machine translation. In SFCM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nilep</author>
</authors>
<title>Code switching in sociocultural linguistics.</title>
<date>2006</date>
<booktitle>In Colorado Research in Linguistics,</booktitle>
<volume>19</volume>
<contexts>
<context position="6416" citStr="Nilep, 2006" startWordPosition="999" endWordPosition="1000">es yield an MT system that achieves a BLEU score of 31.79 on an English-to-Chinese translation task, an improvement of 2.64 in BLEU score over a baseline MT system trained on only our parallel corpora. The rest of this paper is organized as follows. The next section presents related work. Section 3 gives an overview of word alignment. Sections 4 and 5 detail our two algorithms. Section 6 presents our experiments and discusses results, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and socio-linguistic communities (Nilep, 2006; De Fina, 2007). Computational research on LCS has studied how to identify the boundaries of an individual language within LCS data, or how to predict when an utterance will switch to another language (Chan et al., 2004; Solorio and Liu, 2008). Manandise and Gdaniec (2011) analyzed the effect on machine translation quality of LCS of Spanish-English and showed that LCS degrades the performance of the syntactic parser. Sinha and Thakur (2005) translate mixed Hindi and English (Hinglish) to pure Hindi and pure English by using two morphological analyzers from both Hindi and English. The difficul</context>
</contexts>
<marker>Nilep, 2006</marker>
<rawString>C. Nilep. 2006. Code switching in sociocultural linguistics. In Colorado Research in Linguistics, volume 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="23505" citStr="Och, 2003" startWordPosition="3868" endWordPosition="3869">ty ps = ps * pj new l +— Xl U xi 5: LM +— Train-LM(Xnew l ) 6: Extract the tri-gram gram3 from LM 7: For each sentence xi in XLCS: run Algorithm 1: finding tsimilar 8: update tb� using (tm, sj) where tm E tsimilar and sj E xi 9: End For 10: Output: word alignment for Xp and LM some of the problems caused by LCS data. To clarify, we use IBM1 model and HMM models in succession for the baseline. We trained the IBM1 model first and used the resulting parameters as the initial parameter values to train HMM model. Parameters for the final MT system are tuned with Minimum Error Rate Training (MERT) (Och, 2003). The tuning set for MERT is the NIST MT06 data set, which includes 1664 sentences. We test the system on NIST MT02 (878 sentences). To evaluate the word alignment results, we manually aligned 250 sentences from NIST MT02 data set. For simplicity, we only have two types of labels for evaluating word alignments: either two words are aligned together or not. (Previous evaluation metrics also consider a third label for ”possible” alignments.) Out of the word-aligned data, we use 100 sentences as a development set and the rest as our testing set. Our MT training corpus contains 2,636,692 sentence </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M K Sinha</author>
<author>A Thakur</author>
</authors>
<title>Machine translation of bi-lingual hindi-english (hinglish) text. In</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Conference on Machine Translation.</booktitle>
<contexts>
<context position="3358" citStr="Sinha and Thakur (2005)" startWordPosition="521" endWordPosition="524">on, and thus it contains a diversity of topics that people care about, such as home furnishings, cars, entertainment, etc, that may not show up in standard parallel corpora. Moreover, LCS data is easily accessible from Web communities, such as MITBBS.com, Sina Weibo, Twitter, etc. However, like most unedited natural language text on the Web, LCS data contains symbols like emotions, grammar and spelling mistakes, slang and strongly idiomatic usage, and a variety of other phenomena that are difficult to handle. LCS data with different language pairs may also need special handling. For instance, Sinha and Thakur (2005) focus on words in mixed English and Hindi texts where a single word contains elements from both languages; they propose techniques for translating such words into both pure English and pure Hindi. Our study focuses on ChineseEnglish LCS, where this is rarely a problem, 1 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1–9, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics but for other language pairs, Sinha and Thakur’s techniques may be required as preprocessing steps. Primarily, though, L</context>
<context position="6861" citStr="Sinha and Thakur (2005)" startWordPosition="1068" endWordPosition="1071">ults, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and socio-linguistic communities (Nilep, 2006; De Fina, 2007). Computational research on LCS has studied how to identify the boundaries of an individual language within LCS data, or how to predict when an utterance will switch to another language (Chan et al., 2004; Solorio and Liu, 2008). Manandise and Gdaniec (2011) analyzed the effect on machine translation quality of LCS of Spanish-English and showed that LCS degrades the performance of the syntactic parser. Sinha and Thakur (2005) translate mixed Hindi and English (Hinglish) to pure Hindi and pure English by using two morphological analyzers from both Hindi and English. The difficulty in their problem is that Hindi and English are often mixed into a single word which uses only the English alphabet; approaches based only on the character set cannot tell these words apart from English words. Our current study is for a language pair (EnglishChinese) where the words are easy to tell apart, but for MT using code-switching data for other language pairs (such as Hindi-English), we can leverage some of the techniques from thei</context>
</contexts>
<marker>Sinha, Thakur, 2005</marker>
<rawString>R.M.K. Sinha and A. Thakur. 2005. Machine translation of bi-lingual hindi-english (hinglish) text. In In Proceedings of the 10th Conference on Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Solorio</author>
<author>Y Liu</author>
</authors>
<title>Learning to predict code-switching points. In</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="6660" citStr="Solorio and Liu, 2008" startWordPosition="1038" endWordPosition="1041">ized as follows. The next section presents related work. Section 3 gives an overview of word alignment. Sections 4 and 5 detail our two algorithms. Section 6 presents our experiments and discusses results, and Section 7 concludes and discusses future work. 2 Related Work There has been a lot of research on LCS from the theoretical and socio-linguistic communities (Nilep, 2006; De Fina, 2007). Computational research on LCS has studied how to identify the boundaries of an individual language within LCS data, or how to predict when an utterance will switch to another language (Chan et al., 2004; Solorio and Liu, 2008). Manandise and Gdaniec (2011) analyzed the effect on machine translation quality of LCS of Spanish-English and showed that LCS degrades the performance of the syntactic parser. Sinha and Thakur (2005) translate mixed Hindi and English (Hinglish) to pure Hindi and pure English by using two morphological analyzers from both Hindi and English. The difficulty in their problem is that Hindi and English are often mixed into a single word which uses only the English alphabet; approaches based only on the character set cannot tell these words apart from English words. Our current study is for a langu</context>
</contexts>
<marker>Solorio, Liu, 2008</marker>
<rawString>T. Solorio and Y. Liu. 2008. Learning to predict code-switching points. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>An extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. Intl. Conf. on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="24352" citStr="Stolcke, 2002" startWordPosition="4005" endWordPosition="4006">or simplicity, we only have two types of labels for evaluating word alignments: either two words are aligned together or not. (Previous evaluation metrics also consider a third label for ”possible” alignments.) Out of the word-aligned data, we use 100 sentences as a development set and the rest as our testing set. Our MT training corpus contains 2,636,692 sentence pairs from two parallel corpora: Hong Kong News (LDC2004T08) and Chinese English News Magazine Parallel Text (LDC2005T10). We use the Stanford Chinese segmenter to segment the Chinese data. We use a ngram model package called SRILM (Stolcke, 2002) to train 6 the language model. Because our modified ngram counts contain factions, we used WittenBell smoothing(Witten and Bell, 1991) which supports fractional counts. The 3-gram language model is trained on the Xinhua section of the Chinese Gigaword corpus (LDC2003T09) as well as the Chinese side of the parallel corpora. We also removed the sentences in MT02 from the Gigaword corpus if there is any to avoid the biases. We gather the LCS data from “MITBBS.com,” a popular forum for Chinese people living in the United States. This forum is separated by discussion topic, and includes topics suc</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. An extensible language modeling toolkit. In Proc. Intl. Conf. on Spoken Language Processing, volume 2, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>Hmmbased word alignment in statistical translation. In</title>
<date>1996</date>
<booktitle>In Proc.COLING.</booktitle>
<contexts>
<context position="10865" citStr="Vogel et al., 1996" startWordPosition="1710" endWordPosition="1713">tatistical word alignment (Brown et al., 1994) is the task identifying which words are translations of each other in a bilingual sentence corpus. It is primarily used for machine translation. The input to an alignment system is a sentence-level aligned bilingual corpus, which consists of pairs of sentences in two languages. One language is denoted as the target language, and the other language as the source language. We now introduce the baseline model for word alignment and how we can incorporate the LCS data to improve the model. IBM Model 1 (Brown et al., 1994) and the HMM alignment model (Vogel et al., 1996) are cascaded to form the baseline model for alignment. These two models have a similar formulation L = P(t, a|s) = P(a) Hj P(tj|saj) with a different distortion probability P(a). s and t denote the source and target sentences. a is the alignment, and aj is the index of the source language word that generates the target language word at position j. The HMM model assumes the alignments have a first-order Markov dependency, so that P(a) = H j P(aj|aj − aj−1). IBM Model 1 ignores the word position and uses a uniform distribution, so P(a) = Hj P(aj) where P(aj) = 1 |t|, where |t| is the length of </context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. Hmmbased word alignment in statistical translation. In In Proc.COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Timothy C Bell</author>
</authors>
<title>The zerofrequency problem: Estimating the probabil- ities of novel events in adaptive text compression.</title>
<date>1991</date>
<booktitle>In IEEE Transactions on Information Theory,</booktitle>
<volume>4</volume>
<pages>1085--1094</pages>
<contexts>
<context position="24487" citStr="Witten and Bell, 1991" startWordPosition="4024" endWordPosition="4027">Previous evaluation metrics also consider a third label for ”possible” alignments.) Out of the word-aligned data, we use 100 sentences as a development set and the rest as our testing set. Our MT training corpus contains 2,636,692 sentence pairs from two parallel corpora: Hong Kong News (LDC2004T08) and Chinese English News Magazine Parallel Text (LDC2005T10). We use the Stanford Chinese segmenter to segment the Chinese data. We use a ngram model package called SRILM (Stolcke, 2002) to train 6 the language model. Because our modified ngram counts contain factions, we used WittenBell smoothing(Witten and Bell, 1991) which supports fractional counts. The 3-gram language model is trained on the Xinhua section of the Chinese Gigaword corpus (LDC2003T09) as well as the Chinese side of the parallel corpora. We also removed the sentences in MT02 from the Gigaword corpus if there is any to avoid the biases. We gather the LCS data from “MITBBS.com,” a popular forum for Chinese people living in the United States. This forum is separated by discussion topic, and includes topics such as “Travel”, “News”, and “Living style”. We extract data from 29 different topics. To clean up the LCS data, we get rid of HTML mark-</context>
</contexts>
<marker>Witten, Bell, 1991</marker>
<rawString>Ian H. Witten and Timothy C. Bell. 1991. The zerofrequency problem: Estimating the probabil- ities of novel events in adaptive text compression. In IEEE Transactions on Information Theory, volume 4, pages 1085–1094.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>