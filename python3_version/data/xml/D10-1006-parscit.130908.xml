<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.743365">
Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid
</title>
<author confidence="0.897425">
Wayne Xin Zhao†, Jing Jiang$, Hongfei Yan†, Xiaoming Li††School of Electronics Engineering and Computer Science, Peking University, China
</author>
<affiliation confidence="0.982919">
$School of Information Systems, Singapore Management University, Singapore
</affiliation>
<email confidence="0.995755">
{zhaoxin,yhf}@net.pku.edu.cn, jingjiang@smu.edu.cn, lxm@pku.edu.cn
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990156875">
Discovering and summarizing opinions from
online reviews is an important and challeng-
ing task. A commonly-adopted framework
generates structured review summaries with
aspects and opinions. Recently topic mod-
els have been used to identify meaningful re-
view aspects, but existing topic models do
not identify aspect-specific opinion words. In
this paper, we propose a MaxEnt-LDA hy-
brid model to jointly discover both aspects
and aspect-specific opinion words. We show
that with a relatively small amount of train-
ing data, our model can effectively identify as-
pect and opinion words simultaneously. We
also demonstrate the domain adaptability of
our model.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999865">
With the dramatic growth of opinionated user-
generated content, consumers often turn to online
product reviews to seek advice while companies see
reviews as a valuable source of consumer feedback.
How to automatically understand, extract and sum-
marize the opinions expressed in online reviews has
therefore become an important research topic and
gained much attention in recent years (Pang and Lee,
2008). A wide spectrum of tasks have been studied
under review mining, ranging from coarse-grained
document-level polarity classification (Pang et al.,
2002) to fine-grained extraction of opinion expres-
sions and their targets (Wu et al., 2009). In partic-
ular, a general framework of summarizing reviews
of a certain product is to first identify different as-
pects (a.k.a. features) of the given product and then
extract specific opinion expressions for each aspect.
For example, aspects of a restaurant may include
food, staff, ambience and price, and opinion expres-
sions for staff may include friendly, rude, etc. Be-
cause of the practicality of this structured summary
format, it has been adopted in several previous stud-
ies (Hu and Liu, 2004; Popescu and Etzioni, 2005;
Brody and Elhadad, 2010) as well as some commer-
cial systems, e.g. the “scorecard” feature at Bing
shopping1.
Different approaches have been proposed to iden-
tify aspect words and phrases from reviews. Previ-
ous methods using frequent itemset mining (Hu and
Liu, 2004) or supervised learning (Jin and Ho, 2009;
Jin et al., 2009; Wu et al., 2009) have the limitation
that they do not group semantically related aspect
expressions together. Supervised learning also suf-
fers from its heavy dependence on training data. In
contrast, unsupervised, knowledge-lean topic mod-
eling approach has been shown to be effective in au-
tomatically identifying aspects and their representa-
tive words (Titov and McDonald, 2008; Brody and
Elhadad, 2010). For example, words such as waiter,
waitress, staff and service are grouped into one as-
pect.
We follow this promising direction and extend ex-
isting topic models to jointly identify both aspect
and opinion words, especially aspect-specific opin-
ion words. Current topic models for opinion mining,
which we will review in detail in Section 2, still lack
this ability. But separating aspect and opinion words
can be very useful. Aspect-specific opinion words
can be used to construct a domain-dependent senti-
</bodyText>
<footnote confidence="0.976082">
1http://www.bing.com/shopping
</footnote>
<page confidence="0.958675">
56
</page>
<note confidence="0.8181895">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 56–65,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999967586206897">
ment lexicon and applied to tasks such as sentiment
classification. They can also provide more informa-
tive descriptions of the product or service being re-
viewed. For example, using more specific opinion
words such as cozy and romantic to describe the am-
bience aspect in a review summary is more meaning-
ful than using generic words such as nice and great.
To the best of our knowledge, Brody and Elhadad
(2010) are the first to study aspect-specific opinion
words, but their opinion word detection is performed
outside of topic modeling, and they only consider
adjectives as possible opinion words.
In this paper, we propose a new topic modeling
approach that can automatically separate aspect and
opinion words. A novelty of this model is the inte-
gration of a discriminative maximum entropy (Max-
Ent) component with the standard generative com-
ponent. The MaxEnt component allows us to lever-
age arbitrary features such as POS tags to help sepa-
rate aspect and opinion words. Because the supervi-
sion relies mostly on non-lexical features, although
our model is no longer fully unsupervised, the num-
ber of training sentences needed is relatively small.
Moreover, training data can also come from a differ-
ent domain and yet still remain effective, making our
model highly domain adaptive. Empirical evaluation
on large review data sets shows that our model can
effectively identify both aspects and aspect-specific
opinion words with a small amount of training data.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999710127659574">
Pioneered by the work of Hu and Liu (2004), review
summarization has been an important research topic.
There are usually two major tasks involved, namely,
aspect or feature identification and opinion extrac-
tion. Hu and Liu (2004) applied frequent itemset
mining to identify product features without supervi-
sion, and considered adjectives collocated with fea-
ture words as opinion words. Jin and Ho (2009),
Jin et al. (2009) and Wu et al. (2009) used super-
vised learning that requires hand-labeled training
sentences to identify both aspects and opinions. A
common limitation of these methods is that they do
not group semantically related aspect expressions to-
gether. Furthermore, supervised learning usually re-
quires a large amount of training data in order to per-
form well and is not easily domain adaptable.
Topic modeling provides an unsupervised and
knowledge-lean approach to opinion mining. Titov
and McDonald (2008) show that global topic models
such as LDA (Blei et al., 2003) may not be suitable
for detecting rateable aspects. They propose multi-
grain topic models for discovering local rateable as-
pects. However, they do not explicitly separate as-
pect and opinion words. Lin and He (2009) propose
a joint topic-sentiment model, but topic words and
sentiment words are still not explicitly separated.
Mei et al. (2007) propose to separate topic and sen-
timent words using a positive sentiment model and
a negative sentiment model, but both models cap-
ture general opinion words only. In contrast, we
model aspect-specific opinion words as well as gen-
eral opinion words.
Recently Brody and Elhadad (2010) propose to
detect aspect-specific opinion words in an unsuper-
vised manner. They take a two-step approach by first
detecting aspect words using topic models and then
identifying aspect-specific opinion words using po-
larity propagation. They only consider adjectives as
opinion words, which may potentially miss opinion
words with other POS tags. We try to jointly capture
both aspect and opinion words within topic models,
and we allow non-adjective opinion words.
Another line of related work is about how to in-
corporate useful features into topic models (Zhu and
Xing, 2010; Mimno and McCallum, 2008). Our
MaxEnt-LDA hybrid bears similarity to these recent
models but ours is designed for opinion mining.
</bodyText>
<sectionHeader confidence="0.985988" genericHeader="method">
3 Model Description
</sectionHeader>
<bodyText confidence="0.999668857142857">
Our model is an extension of LDA (Blei et al., 2003)
but captures both aspect words and opinion words.
To model the aspect words, we use a modified ver-
sion of the multi-grain topic models from (Titov and
McDonald, 2008). Our model is simpler and yet still
produces meaningful aspects. Specifically, we as-
sume that there are T aspects in a given collection of
reviews from the same domain, and each review doc-
ument contains a mixture of aspects. We further as-
sume that each sentence (instead of each word as in
standard LDA) is assigned to a single aspect, which
is often true based on our observation.
To understand how we model the opinion words,
let us first look at two example review sentences
</bodyText>
<page confidence="0.997298">
57
</page>
<bodyText confidence="0.996292117647059">
from the restaurant domain:
The food was tasty.
The waiter was quite friendly.
We can see that there is a strong association of
tasty with food and similarly offriendly with waiter.
While both tasty and friendly are specific to the
restaurant domain, they are each associated with
only a single aspect, namely food and staff, respec-
tively. Besides these aspect-specific opinion words,
we also see general opinion words such as great
in the sentence “The food was great!” These gen-
eral opinion words are shared across aspects, as op-
posed to aspect-specific opinion words which are
used most commonly with their corresponding as-
pects. We therefore introduce a general opinion
model and T aspect-specific opinion models to cap-
ture these different opinion words.
</bodyText>
<subsectionHeader confidence="0.797058">
3.1 Generative Process
</subsectionHeader>
<bodyText confidence="0.989933620689655">
We now describe the generative process of the
model. First, we draw several multinomial word dis-
tributions from a symmetric Dirichlet prior with pa-
rameter β: a background model φB, a general aspect
model φA,9, a general opinion model φO,9, T as-
pect models {φA,t}t1 and T aspect-specific opin-
ion models {φO,t}t_1. All these are multinomial
distributions over the vocabulary, which we assume
has V words. Then for each review document d, we
draw a topic distribution θd∼Dir(α) as in standard
LDA. For each sentence s in document d, we draw
an aspect assignment zd,s∼Multi(θd).
Now for each word in sentence s of document d,
we have several choices: The word may describe the
specific aspect (e.g. waiter for the staff aspect), or a
general aspect (e.g. restaurant), or an opinion either
specific to the aspect (e.g. friendly) or generic (e.g.
great), or a commonly used background word (e.g.
know). To distinguish between these choices, we in-
troduce two indicator variable, yd,s,n and ud,s,n, for
the nth word wd,s,n. We draw yd,s,n from a multi-
nomial distribution over {0, 1, 2}, parameterized by
πd,s,n. yd,s,n determines whether wd,s,n is a back-
ground word, aspect word or opinion word. We will
discuss how to set πd,s,n in Section 3.2. We draw
ud,s,n from a Bernoulli distribution over {0, 1} pa-
rameterized by p, which in turn is drawn from a sym-
metric Beta(γ). ud,s,n determines whether wd,s,n is
general or aspect-specific. We then draw wd,s,n as
</bodyText>
<figureCaption confidence="0.718354">
Figure 1: The plate notation of our model.
follows:
</figureCaption>
<equation confidence="0.9967852">
{ Multi(φ11) if yd,s,n = 0
Multi(φA,zd,.) if yd,s,n = 1,ud,s,n = 0
Multi(φA,g) if yd,s,n = 1, ud,s,n = 1
Multi(φO,zd,.) if yd,s,n = 2,ud,s,n = 0
Multi(φO,g) if yd,s,n = 2, ud,s,n = 1
</equation>
<bodyText confidence="0.515485">
Figure 1 shows our model using the plate notation.
</bodyText>
<subsectionHeader confidence="0.997783">
3.2 Setting π with a Maximum Entropy Model
</subsectionHeader>
<bodyText confidence="0.999991857142857">
A simple way to set πd,s,n is to draw it from a
symmetric Dirichlet prior. However, as suggested
in (Mei et al., 2007; Lin and He, 2009), fully un-
supervised topic models are unable to identify opin-
ion words well. An important observation we make
is that aspect words and opinion words usually play
different syntactic roles in a sentence. Aspect words
tend to be nouns while opinion words tend to be ad-
jectives. Their contexts in sentences can also be dif-
ferent. But we do not want to use strict rules to sepa-
rate aspect and opinion words because there are also
exceptions. E.g. verbs such as recommend can also
be opinion words.
In order to use information such as POS tags
to help discriminate between aspect and opinion
words, we propose a novel idea as follows: We set
πd,s,n using a maximum entropy (MaxEnt) model
applied to a feature vector xd,s,n associated with
wd,s,n. xd,s,n can encode any arbitrary features we
think may be discriminative, e.g. previous, current
and next POS tags. Formally, we have
</bodyText>
<equation confidence="0.997899333333333">
p(yd,s,n = l|xd,s,n) = πd,s,n
l = �2 ,
exp (λl · xd,s,n)
=p exp (λl, · xd,s,n)
wd,s,n ∼
.
</equation>
<page confidence="0.986436">
58
</page>
<bodyText confidence="0.999950909090909">
where {λl}i0 denote the MaxEnt model weights
and can be learned from a set of training sentences
with labeled background, aspect and opinion words.
This MaxEnt-LDA hybrid model is partially in-
spired by (Mimno and McCallum, 2008).
As for the features included in x, currently we
use two types of simple features: (1) lexical features
which include the previous, the current and the next
words {wZ_1, wZ, wZ+1}, and (2) POS tag features
which include the previous, the current and the next
POS tags {POSZ_1, POSZ, POSZ+1}.
</bodyText>
<subsectionHeader confidence="0.978713">
3.3 Inference
</subsectionHeader>
<bodyText confidence="0.999967384615384">
We use Gibbs sampling to perform model inference.
Due to the space limit, we leave out the derivation
details and only show the sampling formulas. Note
that the MaxEnt component is trained first indepen-
dently of the Gibbs sampling procedure, that is, in
Gibbs sampling, we assume that the λ parameters
are fixed.
We use w to denote all the words we observe in
the collection, x to denote all the feature vectors for
these words, and y, z and u to denote all the hidden
variables. First, given the assignment of all other
hidden variables, to sample a value for zd,s, we use
the following formula:
</bodyText>
<equation confidence="0.9978961">
P(zd,s = t|z¬(d,s), y, u, w, x) ∝
´ 3
Ã Γ 3 ´ !
cA,t cA,t
(·) + V β YV Γ (v) + nA,t
(v) + β
× 3 ´ · 3 ´
cA,t
Γ (·) + nA,t cA,t
(·) + V β v=1 Γ (v) + β
3 ´
Ã Γ 3 ´ !
cO,t cO,t
(·) + V β YV Γ (v) + nO,t
(v) + β
×
3 ´ · 3 ´ .
cO,t cO,t
Γ (·) + nO,t
(·) + V β v=1 Γ (v) + β
</equation>
<bodyText confidence="0.803112318181818">
Here cd(t) is the number of sentences assigned to as-
pect t in document d, and cd (·) is the number of sen-
tences in document d. cA,t
(v) is the number of times
word v is assigned as an aspect word to aspect t,
and cO,t
(v) is the number of times word v is assigned
as an opinion word to aspect t. cA,t (·)is the total num-
ber of times any word is assigned as an aspect word
to aspect t, and cO,t
(·) is the total number of times any
word is assigned as an opinion word to aspect t. All
these counts represented by a c variable exclude sen-
tence s of document d. nA,t
(v) is the number of times
word v is assigned as an aspect word to aspect t in
sentence s of document d, and similarly, nO,t
(v) is the
number of times word v is assigned as an opinion
word to aspect t in sentence s of document d.
Then, to jointly sample values for yd,s,n and
ud,s,n, we have
</bodyText>
<equation confidence="0.999684125">
P(yd,s,n = 0|z, y¬(d,s,n), u¬(d,s,n), w, x)
B
c(wd,s,n) + β
cB (·) + V β ,
P(yd,s,n = l, ud,s,n = b|z, y¬(d,s,n), u¬(d,s,n), w, x)
exp(λl · xd,s,n)
∝ g(wd,s,n, zd,s, l, b),
Pl0 exp(λl0· xd s n)
</equation>
<bodyText confidence="0.982829">
where the function g(v, t,l, b) (1 ≤ v ≤ V,1 ≤ t ≤
T, l ∈ {1, 2}, b ∈ {0,1}) is defined as follows:
</bodyText>
<equation confidence="0.9951555">
c(1)+γ if l = 1, b = 1
c(·)+2γ
c(1)+γ if l = 2, b = 1.
c(·)+2γ
</equation>
<bodyText confidence="0.99989475">
Here the various c variables denote various counts
excluding the nth word in sentence s of document d.
Due to space limit, we do not give full explanation
here.
</bodyText>
<sectionHeader confidence="0.995603" genericHeader="method">
4 Experiment Setup
</sectionHeader>
<bodyText confidence="0.999893866666667">
To evaluate our MaxEnt-LDA hybrid model for
jointly modeling aspect and opinion words, we used
a restaurant review data set previously used in (Ganu
et al., 2009; Brody and Elhadad, 2010) and a ho-
tel review data set previously used in (Baccianella
et al., 2009). We removed stop words and used the
Stanford POS Tagger2 to tag the two data sets. Only
reviews that have no more than 50 sentences were
used. We also kept another version of the data which
includes the stop words for the purpose of extracting
the contextual features included in x. Some details
of the data sets are given in Table 1.
For our hybrid model, we ran 500 iterations of
Gibbs sampling. Following (Griffiths and Steyvers,
2004), we fixed the Dirichlet priors as follows: α =
</bodyText>
<footnote confidence="0.590767">
2http://nlp.stanford.edu/software/tagger.shtml
</footnote>
<equation confidence="0.748317285714286">
cd(t) + α
cd (·) + Tα
exp(λ0 · xd,s,n)
·
Pl0 exp(λl0 · xd,s,n)
∝
g(v, t, l, b) = ⎧ cA,t+β
</equation>
<figure confidence="0.982106421052632">
⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪ (v)
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ cA,t (·) +V β ·
cO,t
(v) +β
cO,t
(·) +V β ·
cA, g+β
(v)
cA,g
(·) +V β ·
cO,g
(v) +β
cO,g
(·) +Vβ ·
c(0)+γ if l = 1, b = 0
c(·)+2γ
c(0)+γ if l = 2, b = 0
c(·)+2γ
.
</figure>
<page confidence="0.980052">
59
</page>
<table confidence="0.998335">
data set restaurant hotel
#tokens 1,644,923 1,097,739
#docs 52,574 14,443
</table>
<tableCaption confidence="0.994788">
Table 1: Some statistics of the data sets.
</tableCaption>
<table confidence="0.9999245">
data set #sentences #tokens
restaurant 46 634
cell phone 125 4414
DVD player 180 3024
</table>
<tableCaption confidence="0.999557">
Table 2: Some statistics of the labeled training data.
</tableCaption>
<bodyText confidence="0.998926227272727">
50/T, Q = 0.1 and -y = 0.5. We also experimented
with other settings of these priors and did not notice
any major difference. For MaxEnt training, we tried
three labeled data sets: one that was taken from the
restaurant data set and manually annotated by us3,
and two from the annotated data set used in (Wu et
al., 2009). Note that the latter two were used for test-
ing domain adaptation in Section 6.3. Some details
of the training sets are shown in Table 2.
In our preliminary experiments, we also tried two
variations of our MaxEnt-LDA hybrid model. (1)
The first is a fully unsupervised model where we
used a uniform Dirichlet prior for 7r. We found
that this unsupervised model could not separate as-
pect and opinion words well. (2) The second is a
bootstrapping version of the MaxEnt-LDA model
where we used the predicted values of y as pseudo
labels and re-trained the MaxEnt model iteratively.
We found that this bootstrapping procedure did not
boost the overall performance much and even hurt
the performance a little in some cases. Due to the
space limit we do not report these experiments here.
</bodyText>
<sectionHeader confidence="0.999217" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999903857142857">
In this section we report the evaluation of our
model. We refer to our MaxEnt-LDA hybrid model
as ME-LDA. We also implemented a local version
of the standard LDA method where each sentence
is treated as a document. This is the model used
in (Brody and Elhadad, 2010) to identify aspects,
and we refer to this model as LocLDA.
</bodyText>
<table confidence="0.999742636363636">
Food Staff Order Taking Ambience
chocolate service wait room
dessert food waiter dining
cake staff wait tables
cream excellent order bar
ice friendly minutes place
desserts attentive seated decor
coffee extremely waitress scene
tea waiters reservation space
bread slow asked area
cheese outstanding told table
</table>
<tableCaption confidence="0.993091">
Table 4: Sample aspects of the restaurant domain using
LocLDA. Note that the words in bold are opinion words
which are mixed with aspect words.
</tableCaption>
<subsectionHeader confidence="0.964398">
5.1 Qualitative Evaluation
</subsectionHeader>
<bodyText confidence="0.999967176470588">
For each of the two data sets, we show four sample
aspects identified by ME-LDA in Table 3 and Ta-
ble 5. Because the hotel domain is somehow similar
to the restaurant domain, we used the labeled train-
ing data from the restaurant domain also for the hotel
data set. From the tables we can see that generally
aspect words are quite coherent and meaningful, and
opinion words correspond to aspects very well. For
comparison, we also applied LocLDA to the restau-
rant data set and present the aspects in Table 4. We
can see that ME-LDA and LocLDA give similar as-
pect words. The major difference between these two
models is that ME-LDA can sperate aspect words
and opinion words, which can be very useful. ME-
LDA is also able to separate general opinion words
from aspect-specific ones, giving more informative
opinion expressions for each aspect.
</bodyText>
<subsectionHeader confidence="0.999837">
5.2 Evaluation of Aspects Identification
</subsectionHeader>
<bodyText confidence="0.988389166666667">
We also quantitatively evaluated the quality of the
automatically identified aspects. Ganu et al. (2009)
provide a set of annotated sentences from the restau-
rant data set, in which each sentence has been as-
signed one or more labels from a gold standard label
set S = {Staff, Food, Ambience, Price, Anecdote,
Misc}. To evaluate the quality of our aspect iden-
tification, we chose from the gold standard labels
three major aspects, namely Staff, Food and Ambi-
ence. We did not choose the other aspects because
(1) Price is often mixed with other aspects such as
Food, and (2) Anecdote and Misc do not show clear
</bodyText>
<footnote confidence="0.886676">
3We randomly selected 46 sentences for manual annotation.
</footnote>
<page confidence="0.992409">
60
</page>
<table confidence="0.8549135">
Food Staff Order Taking Ambience General
Aspect Opinion Aspect Opinion Aspect Opinion Aspect Opinion Opinion
</table>
<bodyText confidence="0.7286514">
chocolate good service friendly table seated room small good
dessert best staff attentive minutes asked dining nice well
cake great food great wait told tables beautiful nice
cream delicious wait nice waiter waited bar romantic great
ice sweet waiter good reservation waiting place cozy better
desserts hot place excellent order long decor great small
coffee amazing waiters helpful time arrived scene open bad
tea fresh restaurant rude hour rude space warm worth
bread tasted waitress extremely manager sat area feel definitely
cheese excellent waitstaff slow people finally table comfortable special
</bodyText>
<tableCaption confidence="0.997009">
Table 3: Sample aspects and opinion words of the restaurant domain using ME-LDA.
</tableCaption>
<table confidence="0.780345166666667">
Service Room Condition Ambience Meal General
Aspect Opinion Aspect Opinion Aspect Opinion Aspect Opinion Opinion
staff helpful room shower room quiet breakfast good great
desk friendly bathroom small floor open coffee fresh good
hotel front bed clean hotel small fruit continental nice
english polite air comfortable noise noisy buffet included well
reception courteous tv hot street nice eggs hot excellent
help pleasant conditioning large view top pastries cold best
service asked water nice night lovely cheese nice small
concierge good rooms safe breakfast hear room great lovely
room excellent beds double room overlooking tea delicious better
restaurant rude bath well terrace beautiful cereal adequate fine
</table>
<tableCaption confidence="0.988319">
Table 5: Sample aspects and opinion words of the hotel domain using ME-LDA.
</tableCaption>
<bodyText confidence="0.99985825">
patterns in either word usage or writing styles, mak-
ing it even hard for humans to identify them. Brody
and Elhadad (2010) also only used these three as-
pects for quantitative evaluation. To avoid ambigu-
ity, we used only the single-labeled sentences for
evaluation. About 83% of the labeled sentences have
a single label, which confirms our observation that a
sentence usually belongs to a single aspect.
We first ran ME-LDA and LocLDA each to get
an inferred aspect set T . Following (Brody and El-
hadad, 2010), we set the number of aspects to 14
in both models. We then manually mapped each in-
ferred aspect to one of the six gold standard aspects,
i.e., we created a mapping function f(t) : T —* S.
For sentence s of document d, we first assign it to an
inferred aspect as follows:
</bodyText>
<equation confidence="0.498074">
log P(wd,s,n|t)-
</equation>
<bodyText confidence="0.983765">
We then assign the gold standard aspect f(t*) to this
</bodyText>
<table confidence="0.999019285714286">
Aspect Method Precision Recall F-1
Staff LocLDA 0.804 0.585 0.677
ME-LDA 0.779 0.540 0.638
Food LocLDA 0.898 0.648 0.753
ME-LDA 0.874 0.787 0.828
Ambience LocLDA 0.603 0.677 0.638
ME-LDA 0.773 0.558 0.648
</table>
<tableCaption confidence="0.999624">
Table 6: Results of aspects identification on restaurant.
</tableCaption>
<bodyText confidence="0.999867125">
sentence. We then calculated the F-1 score of the
three aspects: Staff, Food and Ambience. The re-
sults are shown in Table 6. Generally ME-LDA has
given competitive results compared with LocLDA.
For Food and Ambience ME-LDA outperformed Lo-
cLDA, while for Staff ME-LDA is a little worse
than LocLDA. Note that ME-LDA is not designed
to compete with LocLDA for aspect identification.
</bodyText>
<equation confidence="0.982581333333333">
t* = arg max
tET
Nd,.E
</equation>
<page confidence="0.8061725">
n=1
61
</page>
<subsectionHeader confidence="0.996013">
5.3 Evaluation of Opinion Identification
</subsectionHeader>
<bodyText confidence="0.992777088888889">
Since the major advantage of ME-LDA is its abil-
ity to separate aspect and opinion words, we further
quantitatively evaluated the quality of the aspect-
specific opinion words identified by ME-LDA.
Brody and Elhadad (2010) has constructed a gold
standard set of aspect-specific opinion words for the
restaurant data set. In this gold standard set, they
manually judged eight out of the 14 automatically
inferred aspects they had: J = {Ambiance, Staff,
Food-Main Dishes, Atmosphere-Physical, Food-
Baked Goods, Food-General, Drinks, Service}.
Each word is assigned a polarity score ranging from
-2.0 to 2.0 in each aspect. We used their gold stan-
dard words whose polarity scores are not equal to
zero. Because their gold standard only includes
adjectives, we also manually added more opinion
words into the gold standard set. To do so, we took
the top 20 opinion words returned by our method
and two baseline methods, pooled them together,
and manually judged them. We use precision at n
(P@n), a commonly used metric in information re-
trieval, for evaluation. Because top words are more
important in opinion models, we set n to 5, 10 and
20. For both ME-LDA and BL-1 below, we again
manually mapped each automatically inferred aspect
to one of the gold standard aspects.
Since LocLDA does not identify aspect-specific
opinion words, we consider the following two base-
line methods that can identify aspect-specific opin-
ion words:
BL-1: In this baseline, we start with all adjectives
as candidate opinion words, and use mutual infor-
mation (MI) to rank these candidates. Specifically,
given an aspect t, we rank the candidate words ac-
cording to the following scoring function:
p(w,v)log p(w,v)
p(w)p(v),
where Vt is the set of the top-100 frequent aspect
words from φA,t.
BL-2: In this baseline, we first use LocLDA to learn
a topic distribution for each sentence. We then as-
sign a sentence to the aspect with the largest proba-
bility and hence get sentence clusters. We manually
map these clusters to the eight gold standard aspects.
Finally, for each aspect we rank adjectives by their
</bodyText>
<table confidence="0.9994655">
Method P@5 P@10 P@20
ME-LDA 0.825*,O 0.700* 0.569*
BL-1 0.400 0.450 0.469
BL-2 0.725 0.650 0.563
</table>
<tableCaption confidence="0.990378">
Table 7: Average P@n of aspect-specific opinion words
</tableCaption>
<bodyText confidence="0.897670769230769">
on restaurant. * and o indicate that the improvement hy-
pothesis is accepted at confidence level 0.9 respectively
for BL-1 and BL-2.
frequencies in the aspect and treat these as aspect-
specific opinion words.
The basic results in terms of the average precision
at n over the eight aspects are shown in Table 7. We
can see that ME-LDA outperformed the two base-
lines consistently. Especially, for P@5, ME-LDA
gave more than 100% relative improvement over
BL-1. The absolute value of 0.825 for P@5 also
indicates that top opinion words discovered by our
model are indeed meaningful.
</bodyText>
<subsectionHeader confidence="0.9939445">
5.4 Evaluation of the Association between
Opinion Words and Aspects
</subsectionHeader>
<bodyText confidence="0.99990304">
The evaluation in the previous section shows that our
model returns good opinion words for each aspect.
It does not, however, directly judge how aspect-
specific those opinion words are. This is because the
gold standard created by (Brody and Elhadad, 2010)
also includes general opinion words. E.g. friendly
and good may both be judged to be opinion words
for the staff aspect, but the former is more specific
than the latter. We suspect that BL-2 has comparable
performance with ME-LDA for this reason. So we
further evaluated the association between opinion
words and aspects by directly looking at how easy
it is to infer the corresponding aspect by only look-
ing at an aspect-specific opinion word. We selected
four aspects for evaluation: Ambiance, Staff, Food-
Main Dishes and Atmosphere-Physical . We chose
these four aspects because they are quite different
from each other and thus manual judgments on these
four aspects can be more objective. For each aspect,
similar to the pooling strategy in IR, we pooled the
top 20 opinion words identified by BL-1, BL-2 and
ME-LDA. We then asked two human assessors to
assign an association score to each of these words
as follows: If the word is closely associated with an
aspect, a score of 2 is given; if it is marginally as-
</bodyText>
<equation confidence="0.9193815">
�ScoreBL-1(w, t) �
vEVt
</equation>
<page confidence="0.989963">
62
</page>
<table confidence="0.9998286">
Metrics Dataset BL-2 ME-LDA
nDCG@5 Restaurant 0.647 0.764
Hotel 0.782 0.820
nDCG@10 Restaurant 0.781 0.897
Hotel 0.722 0.789
</table>
<tableCaption confidence="0.9904826">
Table 8: Average nDCG performance of BL-2 and ME-
LDA. Because only four aspects were used for evaluation,
we did not perform statistical significance test. We found
that in all cases ME-LDA outperformed BL-2 for either
all aspects or three out of four aspects.
</tableCaption>
<bodyText confidence="0.999771888888889">
sociated with an aspect, a score of 1 is given; other-
wise, 0 is given. We calculated the Kappa statistics
of agreement, and we got a quite high Kappa value
of 0.8375 and 0.7875 respectively for the restaurant
data set and the hotel data set. Then for each word
in an aspect, we took the average of the scores of
the two assessors. We used an nDCG-like metric to
compare the performance of our model and of BL-2.
The metric is defined as follows:
</bodyText>
<equation confidence="0.876116">
nDCG@k(t, M) = iDCG@k(t) ,
</equation>
<bodyText confidence="0.99995">
where Mt,i is the ith aspect-specific opinion word
inferred by method M for aspect t, Score(Mt,i) is
the association score of this word, and iDCG@k(t)
is the score of the ideal DCG measure at k for as-
pect t, that is, the maximum DCG score assuming
an ideal ranking. We chose k = 5 and k = 10. The
average nDCG over the four aspects are presented
in Table 8. We can see that ME-LDA outperformed
BL-2 quite a lot for the restaurant data set, which
conforms to our hypothesis that ME-LDA generates
aspect-specific opinion words of stronger associa-
tion with aspects. For the hotel data set, ME-LDA
outperformed a little. This may be due to the fact
that we used the restaurant training data for the ho-
tel data set.
</bodyText>
<sectionHeader confidence="0.990137" genericHeader="method">
6 Further Analysis of MaxEnt
</sectionHeader>
<bodyText confidence="0.999302">
In this section, we perform some further evaluation
and analysis of the MaxEnt component in our model.
</bodyText>
<subsectionHeader confidence="0.998404">
6.1 Feature Selection
</subsectionHeader>
<bodyText confidence="0.999806">
Previous studies have shown that simple POS fea-
tures and lexical features can be very effective for
discovering aspect words and opinion words (Hu
</bodyText>
<table confidence="0.9984194">
Methods Average F-1
LocLDA 0.690
ME-LDA + A 0.631
ME-LDA + B 0.695
ME-LDA + C 0.705
</table>
<tableCaption confidence="0.9962525">
Table 9: Comparison of the average F-1 using different
feature sets for aspect identification on restaurant.
</tableCaption>
<bodyText confidence="0.9997971875">
and Liu, 2004; Jin et al., 2009; Wu et al., 2009;
Brody and Elhadad, 2010). for POS features, since
we observe that aspect words tend to be nouns while
opinion words tend to be adjectives but sometimes
also verbs or other part-of-speeches, we can expect
that POS features should be quite useful. As for lexi-
cal features, words from a sentiment lexicon can also
be helpful in discovering opinion words.
However, lexical features are more diverse so pre-
sumably we need more training data in order to de-
tect useful lexical features. Lexical features are also
more domain-dependent. On the other hand, we hy-
pothesize that POS features are more effective when
the amount of training data is small and/or the train-
ing data comes from a different domain. We there-
fore compare the following three sets of features:
</bodyText>
<listItem confidence="0.999960666666667">
• A: wi−1, wi, wi+1
• B: POSi−1, POSi, POSi+1
• C: A + B
</listItem>
<bodyText confidence="0.999969769230769">
We show the comparison of the performance in Ta-
ble 9 using the average F-1 score defined in Sec-
tion 5.2 for aspect identification, and in Table 10 us-
ing the average P@n measure defined in Section 5.3
for opinion identification. We can see that Set B
plays the most important part, which conforms to
our hypothesis that POS features are very important
in opinion mining. In addition, we can see that Set C
performs a bit better than Set B, which indicates that
some lexical features (e.g., general opinion words)
may also be helpful. Note that here the training data
is from the same domain as the test data, and there-
fore lexical features are likely to be useful.
</bodyText>
<subsectionHeader confidence="0.993525">
6.2 Examine the Size of Labeled Data
</subsectionHeader>
<bodyText confidence="0.99991975">
As we have seen, POS features play the major role
in discriminating between aspect and opinion words.
Because there are much fewer POS features than
word features, we expect that we do not need many
</bodyText>
<equation confidence="0.9742065">
Ek Score(Mt,i)
i=1 log,(i+1)
</equation>
<page confidence="0.999543">
63
</page>
<tableCaption confidence="0.9734835">
Table 10: Comparison of the average P@n using different
feature sets for opinion identification on restaurant.
</tableCaption>
<table confidence="0.999967105263158">
Methods P@5 P@10 P@20
BL-2 0.725 0.650 0.563
ME-LDA + A 0.150 0.200 0.231
ME-LDA + B 0.775 0.688 0.569
ME-LDA + C 0.825 0.700 0.569
Method Average F-1
restaurant + B 0.695
restaurant + C 0.705
cell phone + B 0.662
cell phone + C 0.629
DVD player + B 0.686
DVD player + C 0.635
Method F-1
LocalLDA 0.690
ME-LDA + 10 0.629
ME-LDA + 20 0.692
ME-LDA + 30 0.691
ME-LDA + 40 0.726
ME-LDA + 46 0.705
</table>
<tableCaption confidence="0.994823">
Table 11: Average F-1 with differen sizes of training data
on restaurant.
</tableCaption>
<bodyText confidence="0.999857083333333">
labeled sentences to learn the POS-based patterns.
We now examine the sensitivity of the performance
with respect to the amount of labeled data. We gen-
erated four smaller training data sets with 10, 20, 30
and 40 sentences each from the whole training data
set we have, which consists of 46 labeled sentences.
The results are shown in Table 11 and Table 12. We
can see that generally the performance stays above
BL when the number of training sentences is 20 or
more. This indicates that our model needs only a
relatively small number of high-quality training sen-
tences to achieve good results.
</bodyText>
<subsectionHeader confidence="0.990487">
6.3 Domain Adaption
</subsectionHeader>
<bodyText confidence="0.9995738">
Since we find that the MaxEnt supervision relies
more on POS features than lexical features, we also
hypothesize that if the training sentences come from
a different domain the performance can still remain
relatively high. To test this hypothesis, we tried two
</bodyText>
<table confidence="0.999760285714286">
Method P@5 P@10 P@20
BL-2 0.725 0.650 0.563
ME-LDA + 10 0.700 0.563 0.488
ME-LDA + 20 0.875 0.650 0.600
ME-LDA + 30 0.825 0.700 0.569
ME-LDA + 40 0.825 0.688 0.581
ME-LDA + 46 0.825 0.700 0.569
</table>
<tableCaption confidence="0.99544125">
Table 12: Average P@n of aspect-specific opinion words
with differen sizes of training data on restaurant.
Table 13: Average F-1 performance for domain adaption
on restaurant.
</tableCaption>
<table confidence="0.999938142857143">
Method P@5 P@10 P@20
restaurant + B 0.775 0.688 0.569
restaurant + C 0.825 0.700 0.569
cell phone + B 0.775 0.675 0.588
cell phone + C 0.750 0.688 0.594
DVD player + B 0.775 0.713 0.575
DVD player + C 0.825 0.663 0.588
</table>
<tableCaption confidence="0.993938">
Table 14: Average P@n of aspect-specific opinion words
for domain adaption on restaurant.
</tableCaption>
<bodyText confidence="0.999763">
quite different training data sets, one from the cell
phone domain and the other from the DVD player
domain, both used in (Wu et al., 2009).
We consider two feature sets defined in Sec-
tion 6.1 for domain adaption, namely B and C. The
results are shown in Table 13 and Table 14.
For aspect identification, using out-of-domain
training data performed worse than using in-domain
training data, but the absolute performance is still
decent. And interestingly, we can see that using B
is better than using C, indicating that lexical features
may hurt the performance in the cross-domain set-
ting. It suggests that lexical features are not easily
adaptable across domains for aspect identification.
For opinion identification, we can see that there
is no clear difference between using out-of-domain
training data and using in-domain training data,
which may indicate that our opinion identification
component is robust in domain adaption. Also, we
cannot easily tell whether B has advantage over C for
opinion identification. One possible reason may be
that those general opinion words are useful across
domains, so lexical features may still be useful for
domain adaption.
</bodyText>
<page confidence="0.999171">
64
</page>
<sectionHeader confidence="0.999734" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99999025">
In this paper, we presented a topic modeling ap-
proach that can jointly identify aspect and opinion
words, using a MaxEnt-LDA hybrid. We showed
that by incorporating a supervised, discriminative
maximum entropy model into an unsupervised, gen-
erative topic model, we could leverage syntactic fea-
tures to help separate aspect and opinion words.
We evaluated our model on two large review data
sets from the restaurant and the hotel domains. We
found that our model was competitive in identifying
meaningful aspects compared with previous mod-
els. Most importantly, our model was able to iden-
tify meaningful opinion words strongly associated
with different aspects. We also demonstrated that
the model could perform well with a relatively small
amount of training data or with training data from a
different domain.
Our model provides a principled way to jointly
model both aspects and opinions. One of the future
directions we plan to explore is to use this model
to help sentence-level extraction of specific opinions
and their targets, which previously was only tackled
in a fully supervised manner. Another direction is to
extend the model to support polarity classification.
</bodyText>
<sectionHeader confidence="0.99968" genericHeader="acknowledgments">
ACKNOWLEDGMENT
</sectionHeader>
<bodyText confidence="0.968028142857143">
The authors Xin Zhao, Hongfei Yan and Xiaom-
ing Li are partially supported by NSFC under the
grant No. 70903008 and 60933004, CNGI grant No.
2008-122, 863 Program No. 2009AA01Z143, and
the Open Fund of the State Key Laboratory of Soft-
ware Development Environment under Grant No.
SKLSDE-2010KF-03, Beihang University.
</bodyText>
<sectionHeader confidence="0.99866" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999823661538462">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2009. Multi-facet rating of product reviews. In
Proceedings of the 31st ECIR.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3.
Samuel Brody and Noemie Elhadad. 2010. An unsuper-
vised aspect-sentiment model for online reviews. In
Proceedings of Human Language Technologies: The
Annual Conference of the North American Chapter of
the Association for Computational Linguistics.
Gayatree Ganu, Noemie Elhadad, and Amelie Marian.
2009. Beyond the stars: Improving rating predictions
using review text content. In Proceedings of the 12th
International Workshop on the Web and Databases.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences of the United States of America.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the 10th
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining.
Wei Jin and Hung Hay Ho. 2009. A novel lexicalized
HMM-based learning framework for web opinion min-
ing. In Proceedings of the 26th International Confer-
ence on Machine Learning.
Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009.
OpinionMiner: A novel machine learning system for
web opinion mining and extraction. In Proceedings of
the 15th ACM SIGKDD.
Chenghua Lin and Yulan He. 2009. Joint senti-
ment/topic model for sentiment analysis. In Proceed-
ing of the Eighteenth ACM Conference on Information
and Knowledge Management.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and
ChengXiang Zhai. 2007. Topic sentiment mixture:
Modeling facets and opinions in weblogs. In Proceed-
ings of the 16th International Conference on World
Wide Web.
David Mimno and Andrew McCallum. 2008.
Topic models conditioned on arbitrary features with
dirichlet-multinomial regression. In Conference on
Uncertainty in Artificial Intelligence.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2).
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the
2002 Conference on Empirical Methods in Natural
Language Processing.
Ana-Maria Popescu and Oren Etzioni. 2005. Extracting
product features and opinions from reviews. In Pro-
ceedings of the HLT-EMNLP.
Ivan Titov and Ryan McDonald. 2008. Modeling online
reviews with multi-grain topic models. In Proceeding
of the 17th International Conference on World Wide
Web.
Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion mining.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing.
Jun Zhu and Eric P. Xing. 2010. Conditional topic ran-
dom fields. In Proceedings of the 27th International
Conference on Machine Learning.
</reference>
<page confidence="0.999615">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.328185">
<title confidence="0.554463">Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid</title>
<affiliation confidence="0.8904875">Xin Jing Hongfei Xiaoming of Electronics Engineering and Computer Science, Peking University, of Information Systems, Singapore Management University,</affiliation>
<email confidence="0.965356">jingjiang@smu.edu.cn,lxm@pku.edu.cn</email>
<abstract confidence="0.999837117647059">Discovering and summarizing opinions from online reviews is an important and challenging task. A commonly-adopted framework generates structured review summaries with aspects and opinions. Recently topic models have been used to identify meaningful review aspects, but existing topic models do not identify aspect-specific opinion words. In this paper, we propose a MaxEnt-LDA hybrid model to jointly discover both aspects and aspect-specific opinion words. We show that with a relatively small amount of training data, our model can effectively identify aspect and opinion words simultaneously. We also demonstrate the domain adaptability of our model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Multi-facet rating of product reviews.</title>
<date>2009</date>
<booktitle>In Proceedings of the 31st ECIR.</booktitle>
<contexts>
<context position="14888" citStr="Baccianella et al., 2009" startWordPosition="2539" endWordPosition="2542">Pl0 exp(λl0· xd s n) where the function g(v, t,l, b) (1 ≤ v ≤ V,1 ≤ t ≤ T, l ∈ {1, 2}, b ∈ {0,1}) is defined as follows: c(1)+γ if l = 1, b = 1 c(·)+2γ c(1)+γ if l = 2, b = 1. c(·)+2γ Here the various c variables denote various counts excluding the nth word in sentence s of document d. Due to space limit, we do not give full explanation here. 4 Experiment Setup To evaluate our MaxEnt-LDA hybrid model for jointly modeling aspect and opinion words, we used a restaurant review data set previously used in (Ganu et al., 2009; Brody and Elhadad, 2010) and a hotel review data set previously used in (Baccianella et al., 2009). We removed stop words and used the Stanford POS Tagger2 to tag the two data sets. Only reviews that have no more than 50 sentences were used. We also kept another version of the data which includes the stop words for the purpose of extracting the contextual features included in x. Some details of the data sets are given in Table 1. For our hybrid model, we ran 500 iterations of Gibbs sampling. Following (Griffiths and Steyvers, 2004), we fixed the Dirichlet priors as follows: α = 2http://nlp.stanford.edu/software/tagger.shtml cd(t) + α cd (·) + Tα exp(λ0 · xd,s,n) · Pl0 exp(λl0 · xd,s,n) ∝ g</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2009</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2009. Multi-facet rating of product reviews. In Proceedings of the 31st ECIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>3</volume>
<contexts>
<context position="6111" citStr="Blei et al., 2003" startWordPosition="938" endWordPosition="941">s as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rateable aspects. They propose multigrain topic models for discovering local rateable aspects. However, they do not explicitly separate aspect and opinion words. Lin and He (2009) propose a joint topic-sentiment model, but topic words and sentiment words are still not explicitly separated. Mei et al. (2007) propose to separate topic and sentiment words using a positive sentiment model and a negative sentiment model, but both models capture general opinion words only. In contrast, we model aspect-specific opinion words as well as general opinion words. Recentl</context>
<context position="7516" citStr="Blei et al., 2003" startWordPosition="1163" endWordPosition="1166">then identifying aspect-specific opinion words using polarity propagation. They only consider adjectives as opinion words, which may potentially miss opinion words with other POS tags. We try to jointly capture both aspect and opinion words within topic models, and we allow non-adjective opinion words. Another line of related work is about how to incorporate useful features into topic models (Zhu and Xing, 2010; Mimno and McCallum, 2008). Our MaxEnt-LDA hybrid bears similarity to these recent models but ours is designed for opinion mining. 3 Model Description Our model is an extension of LDA (Blei et al., 2003) but captures both aspect words and opinion words. To model the aspect words, we use a modified version of the multi-grain topic models from (Titov and McDonald, 2008). Our model is simpler and yet still produces meaningful aspects. Specifically, we assume that there are T aspects in a given collection of reviews from the same domain, and each review document contains a mixture of aspects. We further assume that each sentence (instead of each word as in standard LDA) is assigned to a single aspect, which is often true based on our observation. To understand how we model the opinion words, let </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2214" citStr="Brody and Elhadad, 2010" startWordPosition="323" endWordPosition="326">ed extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “scorecard” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling approach has been shown to be effective in automatical</context>
<context position="4060" citStr="Brody and Elhadad (2010)" startWordPosition="612" endWordPosition="615">bing.com/shopping 56 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 56–65, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics ment lexicon and applied to tasks such as sentiment classification. They can also provide more informative descriptions of the product or service being reviewed. For example, using more specific opinion words such as cozy and romantic to describe the ambience aspect in a review summary is more meaningful than using generic words such as nice and great. To the best of our knowledge, Brody and Elhadad (2010) are the first to study aspect-specific opinion words, but their opinion word detection is performed outside of topic modeling, and they only consider adjectives as possible opinion words. In this paper, we propose a new topic modeling approach that can automatically separate aspect and opinion words. A novelty of this model is the integration of a discriminative maximum entropy (MaxEnt) component with the standard generative component. The MaxEnt component allows us to leverage arbitrary features such as POS tags to help separate aspect and opinion words. Because the supervision relies mostly</context>
<context position="6737" citStr="Brody and Elhadad (2010)" startWordPosition="1039" endWordPosition="1042">ay not be suitable for detecting rateable aspects. They propose multigrain topic models for discovering local rateable aspects. However, they do not explicitly separate aspect and opinion words. Lin and He (2009) propose a joint topic-sentiment model, but topic words and sentiment words are still not explicitly separated. Mei et al. (2007) propose to separate topic and sentiment words using a positive sentiment model and a negative sentiment model, but both models capture general opinion words only. In contrast, we model aspect-specific opinion words as well as general opinion words. Recently Brody and Elhadad (2010) propose to detect aspect-specific opinion words in an unsupervised manner. They take a two-step approach by first detecting aspect words using topic models and then identifying aspect-specific opinion words using polarity propagation. They only consider adjectives as opinion words, which may potentially miss opinion words with other POS tags. We try to jointly capture both aspect and opinion words within topic models, and we allow non-adjective opinion words. Another line of related work is about how to incorporate useful features into topic models (Zhu and Xing, 2010; Mimno and McCallum, 200</context>
<context position="14814" citStr="Brody and Elhadad, 2010" startWordPosition="2525" endWordPosition="2528">z, y¬(d,s,n), u¬(d,s,n), w, x) exp(λl · xd,s,n) ∝ g(wd,s,n, zd,s, l, b), Pl0 exp(λl0· xd s n) where the function g(v, t,l, b) (1 ≤ v ≤ V,1 ≤ t ≤ T, l ∈ {1, 2}, b ∈ {0,1}) is defined as follows: c(1)+γ if l = 1, b = 1 c(·)+2γ c(1)+γ if l = 2, b = 1. c(·)+2γ Here the various c variables denote various counts excluding the nth word in sentence s of document d. Due to space limit, we do not give full explanation here. 4 Experiment Setup To evaluate our MaxEnt-LDA hybrid model for jointly modeling aspect and opinion words, we used a restaurant review data set previously used in (Ganu et al., 2009; Brody and Elhadad, 2010) and a hotel review data set previously used in (Baccianella et al., 2009). We removed stop words and used the Stanford POS Tagger2 to tag the two data sets. Only reviews that have no more than 50 sentences were used. We also kept another version of the data which includes the stop words for the purpose of extracting the contextual features included in x. Some details of the data sets are given in Table 1. For our hybrid model, we ran 500 iterations of Gibbs sampling. Following (Griffiths and Steyvers, 2004), we fixed the Dirichlet priors as follows: α = 2http://nlp.stanford.edu/software/tagge</context>
<context position="17346" citStr="Brody and Elhadad, 2010" startWordPosition="2988" endWordPosition="2991">apping version of the MaxEnt-LDA model where we used the predicted values of y as pseudo labels and re-trained the MaxEnt model iteratively. We found that this bootstrapping procedure did not boost the overall performance much and even hurt the performance a little in some cases. Due to the space limit we do not report these experiments here. 5 Evaluation In this section we report the evaluation of our model. We refer to our MaxEnt-LDA hybrid model as ME-LDA. We also implemented a local version of the standard LDA method where each sentence is treated as a document. This is the model used in (Brody and Elhadad, 2010) to identify aspects, and we refer to this model as LocLDA. Food Staff Order Taking Ambience chocolate service wait room dessert food waiter dining cake staff wait tables cream excellent order bar ice friendly minutes place desserts attentive seated decor coffee extremely waitress scene tea waiters reservation space bread slow asked area cheese outstanding told table Table 4: Sample aspects of the restaurant domain using LocLDA. Note that the words in bold are opinion words which are mixed with aspect words. 5.1 Qualitative Evaluation For each of the two data sets, we show four sample aspects </context>
<context position="21141" citStr="Brody and Elhadad (2010)" startWordPosition="3597" endWordPosition="3600">glish polite air comfortable noise noisy buffet included well reception courteous tv hot street nice eggs hot excellent help pleasant conditioning large view top pastries cold best service asked water nice night lovely cheese nice small concierge good rooms safe breakfast hear room great lovely room excellent beds double room overlooking tea delicious better restaurant rude bath well terrace beautiful cereal adequate fine Table 5: Sample aspects and opinion words of the hotel domain using ME-LDA. patterns in either word usage or writing styles, making it even hard for humans to identify them. Brody and Elhadad (2010) also only used these three aspects for quantitative evaluation. To avoid ambiguity, we used only the single-labeled sentences for evaluation. About 83% of the labeled sentences have a single label, which confirms our observation that a sentence usually belongs to a single aspect. We first ran ME-LDA and LocLDA each to get an inferred aspect set T . Following (Brody and Elhadad, 2010), we set the number of aspects to 14 in both models. We then manually mapped each inferred aspect to one of the six gold standard aspects, i.e., we created a mapping function f(t) : T —* S. For sentence s of docum</context>
<context position="22806" citStr="Brody and Elhadad (2010)" startWordPosition="3880" endWordPosition="3883">he three aspects: Staff, Food and Ambience. The results are shown in Table 6. Generally ME-LDA has given competitive results compared with LocLDA. For Food and Ambience ME-LDA outperformed LocLDA, while for Staff ME-LDA is a little worse than LocLDA. Note that ME-LDA is not designed to compete with LocLDA for aspect identification. t* = arg max tET Nd,.E n=1 61 5.3 Evaluation of Opinion Identification Since the major advantage of ME-LDA is its ability to separate aspect and opinion words, we further quantitatively evaluated the quality of the aspectspecific opinion words identified by ME-LDA. Brody and Elhadad (2010) has constructed a gold standard set of aspect-specific opinion words for the restaurant data set. In this gold standard set, they manually judged eight out of the 14 automatically inferred aspects they had: J = {Ambiance, Staff, Food-Main Dishes, Atmosphere-Physical, FoodBaked Goods, Food-General, Drinks, Service}. Each word is assigned a polarity score ranging from -2.0 to 2.0 in each aspect. We used their gold standard words whose polarity scores are not equal to zero. Because their gold standard only includes adjectives, we also manually added more opinion words into the gold standard set.</context>
<context position="25717" citStr="Brody and Elhadad, 2010" startWordPosition="4361" endWordPosition="4364">t aspects are shown in Table 7. We can see that ME-LDA outperformed the two baselines consistently. Especially, for P@5, ME-LDA gave more than 100% relative improvement over BL-1. The absolute value of 0.825 for P@5 also indicates that top opinion words discovered by our model are indeed meaningful. 5.4 Evaluation of the Association between Opinion Words and Aspects The evaluation in the previous section shows that our model returns good opinion words for each aspect. It does not, however, directly judge how aspectspecific those opinion words are. This is because the gold standard created by (Brody and Elhadad, 2010) also includes general opinion words. E.g. friendly and good may both be judged to be opinion words for the staff aspect, but the former is more specific than the latter. We suspect that BL-2 has comparable performance with ME-LDA for this reason. So we further evaluated the association between opinion words and aspects by directly looking at how easy it is to infer the corresponding aspect by only looking at an aspect-specific opinion word. We selected four aspects for evaluation: Ambiance, Staff, FoodMain Dishes and Atmosphere-Physical . We chose these four aspects because they are quite dif</context>
<context position="28898" citStr="Brody and Elhadad, 2010" startWordPosition="4920" endWordPosition="4923">ed the restaurant training data for the hotel data set. 6 Further Analysis of MaxEnt In this section, we perform some further evaluation and analysis of the MaxEnt component in our model. 6.1 Feature Selection Previous studies have shown that simple POS features and lexical features can be very effective for discovering aspect words and opinion words (Hu Methods Average F-1 LocLDA 0.690 ME-LDA + A 0.631 ME-LDA + B 0.695 ME-LDA + C 0.705 Table 9: Comparison of the average F-1 using different feature sets for aspect identification on restaurant. and Liu, 2004; Jin et al., 2009; Wu et al., 2009; Brody and Elhadad, 2010). for POS features, since we observe that aspect words tend to be nouns while opinion words tend to be adjectives but sometimes also verbs or other part-of-speeches, we can expect that POS features should be quite useful. As for lexical features, words from a sentiment lexicon can also be helpful in discovering opinion words. However, lexical features are more diverse so presumably we need more training data in order to detect useful lexical features. Lexical features are also more domain-dependent. On the other hand, we hypothesize that POS features are more effective when the amount of train</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>Noemie Elhadad</author>
<author>Amelie Marian</author>
</authors>
<title>Beyond the stars: Improving rating predictions using review text content.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th International Workshop on the Web and Databases.</booktitle>
<contexts>
<context position="14788" citStr="Ganu et al., 2009" startWordPosition="2521" endWordPosition="2524">,n = l, ud,s,n = b|z, y¬(d,s,n), u¬(d,s,n), w, x) exp(λl · xd,s,n) ∝ g(wd,s,n, zd,s, l, b), Pl0 exp(λl0· xd s n) where the function g(v, t,l, b) (1 ≤ v ≤ V,1 ≤ t ≤ T, l ∈ {1, 2}, b ∈ {0,1}) is defined as follows: c(1)+γ if l = 1, b = 1 c(·)+2γ c(1)+γ if l = 2, b = 1. c(·)+2γ Here the various c variables denote various counts excluding the nth word in sentence s of document d. Due to space limit, we do not give full explanation here. 4 Experiment Setup To evaluate our MaxEnt-LDA hybrid model for jointly modeling aspect and opinion words, we used a restaurant review data set previously used in (Ganu et al., 2009; Brody and Elhadad, 2010) and a hotel review data set previously used in (Baccianella et al., 2009). We removed stop words and used the Stanford POS Tagger2 to tag the two data sets. Only reviews that have no more than 50 sentences were used. We also kept another version of the data which includes the stop words for the purpose of extracting the contextual features included in x. Some details of the data sets are given in Table 1. For our hybrid model, we ran 500 iterations of Gibbs sampling. Following (Griffiths and Steyvers, 2004), we fixed the Dirichlet priors as follows: α = 2http://nlp.s</context>
<context position="18872" citStr="Ganu et al. (2009)" startWordPosition="3239" endWordPosition="3242">ords correspond to aspects very well. For comparison, we also applied LocLDA to the restaurant data set and present the aspects in Table 4. We can see that ME-LDA and LocLDA give similar aspect words. The major difference between these two models is that ME-LDA can sperate aspect words and opinion words, which can be very useful. MELDA is also able to separate general opinion words from aspect-specific ones, giving more informative opinion expressions for each aspect. 5.2 Evaluation of Aspects Identification We also quantitatively evaluated the quality of the automatically identified aspects. Ganu et al. (2009) provide a set of annotated sentences from the restaurant data set, in which each sentence has been assigned one or more labels from a gold standard label set S = {Staff, Food, Ambience, Price, Anecdote, Misc}. To evaluate the quality of our aspect identification, we chose from the gold standard labels three major aspects, namely Staff, Food and Ambience. We did not choose the other aspects because (1) Price is often mixed with other aspects such as Food, and (2) Anecdote and Misc do not show clear 3We randomly selected 46 sentences for manual annotation. 60 Food Staff Order Taking Ambience Ge</context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, Noemie Elhadad, and Amelie Marian. 2009. Beyond the stars: Improving rating predictions using review text content. In Proceedings of the 12th International Workshop on the Web and Databases.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America.</booktitle>
<contexts>
<context position="15327" citStr="Griffiths and Steyvers, 2004" startWordPosition="2617" endWordPosition="2620"> opinion words, we used a restaurant review data set previously used in (Ganu et al., 2009; Brody and Elhadad, 2010) and a hotel review data set previously used in (Baccianella et al., 2009). We removed stop words and used the Stanford POS Tagger2 to tag the two data sets. Only reviews that have no more than 50 sentences were used. We also kept another version of the data which includes the stop words for the purpose of extracting the contextual features included in x. Some details of the data sets are given in Table 1. For our hybrid model, we ran 500 iterations of Gibbs sampling. Following (Griffiths and Steyvers, 2004), we fixed the Dirichlet priors as follows: α = 2http://nlp.stanford.edu/software/tagger.shtml cd(t) + α cd (·) + Tα exp(λ0 · xd,s,n) · Pl0 exp(λl0 · xd,s,n) ∝ g(v, t, l, b) = ⎧ cA,t+β ⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪ (v) ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ cA,t (·) +V β · cO,t (v) +β cO,t (·) +V β · cA, g+β (v) cA,g (·) +V β · cO,g (v) +β cO,g (·) +Vβ · c(0)+γ if l = 1, b = 0 c(·)+2γ c(0)+γ if l = 2, b = 0 c(·)+2γ . 59 data set restaurant hotel #tokens 1,644,923 1,097,739 #docs 52,574 14,443 Table 1: Some statistics of the data sets. data set #sentences #tokens restaurant 46 634 cell phone 125 4414 DVD player 180 3024 Table 2: Some statis</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences of the United States of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="2161" citStr="Hu and Liu, 2004" startWordPosition="315" endWordPosition="318">ssification (Pang et al., 2002) to fine-grained extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “scorecard” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling a</context>
<context position="5169" citStr="Hu and Liu (2004)" startWordPosition="791" endWordPosition="794">y features such as POS tags to help separate aspect and opinion words. Because the supervision relies mostly on non-lexical features, although our model is no longer fully unsupervised, the number of training sentences needed is relatively small. Moreover, training data can also come from a different domain and yet still remain effective, making our model highly domain adaptive. Empirical evaluation on large review data sets shows that our model can effectively identify both aspects and aspect-specific opinion words with a small amount of training data. 2 Related Work Pioneered by the work of Hu and Liu (2004), review summarization has been an important research topic. There are usually two major tasks involved, namely, aspect or feature identification and opinion extraction. Hu and Liu (2004) applied frequent itemset mining to identify product features without supervision, and considered adjectives collocated with feature words as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspe</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
</authors>
<title>A novel lexicalized HMM-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="2496" citStr="Jin and Ho, 2009" startWordPosition="369" endWordPosition="372">ct. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “scorecard” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling approach has been shown to be effective in automatically identifying aspects and their representative words (Titov and McDonald, 2008; Brody and Elhadad, 2010). For example, words such as waiter, waitress, staff and service are grouped into one aspect. We follow this promising direction and extend existing topic models to jointly iden</context>
<context position="5530" citStr="Jin and Ho (2009)" startWordPosition="845" endWordPosition="848">hly domain adaptive. Empirical evaluation on large review data sets shows that our model can effectively identify both aspects and aspect-specific opinion words with a small amount of training data. 2 Related Work Pioneered by the work of Hu and Liu (2004), review summarization has been an important research topic. There are usually two major tasks involved, namely, aspect or feature identification and opinion extraction. Hu and Liu (2004) applied frequent itemset mining to identify product features without supervision, and considered adjectives collocated with feature words as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitabl</context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Wei Jin and Hung Hay Ho. 2009. A novel lexicalized HMM-based learning framework for web opinion mining. In Proceedings of the 26th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>OpinionMiner: A novel machine learning system for web opinion mining and extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD.</booktitle>
<contexts>
<context position="2514" citStr="Jin et al., 2009" startWordPosition="373" endWordPosition="376">spects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “scorecard” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling approach has been shown to be effective in automatically identifying aspects and their representative words (Titov and McDonald, 2008; Brody and Elhadad, 2010). For example, words such as waiter, waitress, staff and service are grouped into one aspect. We follow this promising direction and extend existing topic models to jointly identify both aspect a</context>
<context position="5549" citStr="Jin et al. (2009)" startWordPosition="849" endWordPosition="852">. Empirical evaluation on large review data sets shows that our model can effectively identify both aspects and aspect-specific opinion words with a small amount of training data. 2 Related Work Pioneered by the work of Hu and Liu (2004), review summarization has been an important research topic. There are usually two major tasks involved, namely, aspect or feature identification and opinion extraction. Hu and Liu (2004) applied frequent itemset mining to identify product features without supervision, and considered adjectives collocated with feature words as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rat</context>
<context position="28855" citStr="Jin et al., 2009" startWordPosition="4912" endWordPosition="4915">s may be due to the fact that we used the restaurant training data for the hotel data set. 6 Further Analysis of MaxEnt In this section, we perform some further evaluation and analysis of the MaxEnt component in our model. 6.1 Feature Selection Previous studies have shown that simple POS features and lexical features can be very effective for discovering aspect words and opinion words (Hu Methods Average F-1 LocLDA 0.690 ME-LDA + A 0.631 ME-LDA + B 0.695 ME-LDA + C 0.705 Table 9: Comparison of the average F-1 using different feature sets for aspect identification on restaurant. and Liu, 2004; Jin et al., 2009; Wu et al., 2009; Brody and Elhadad, 2010). for POS features, since we observe that aspect words tend to be nouns while opinion words tend to be adjectives but sometimes also verbs or other part-of-speeches, we can expect that POS features should be quite useful. As for lexical features, words from a sentiment lexicon can also be helpful in discovering opinion words. However, lexical features are more diverse so presumably we need more training data in order to detect useful lexical features. Lexical features are also more domain-dependent. On the other hand, we hypothesize that POS features </context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009. OpinionMiner: A novel machine learning system for web opinion mining and extraction. In Proceedings of the 15th ACM SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceeding of the Eighteenth ACM Conference on Information and Knowledge Management.</booktitle>
<contexts>
<context position="6325" citStr="Lin and He (2009)" startWordPosition="973" endWordPosition="976">e methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rateable aspects. They propose multigrain topic models for discovering local rateable aspects. However, they do not explicitly separate aspect and opinion words. Lin and He (2009) propose a joint topic-sentiment model, but topic words and sentiment words are still not explicitly separated. Mei et al. (2007) propose to separate topic and sentiment words using a positive sentiment model and a negative sentiment model, but both models capture general opinion words only. In contrast, we model aspect-specific opinion words as well as general opinion words. Recently Brody and Elhadad (2010) propose to detect aspect-specific opinion words in an unsupervised manner. They take a two-step approach by first detecting aspect words using topic models and then identifying aspect-spe</context>
<context position="10863" citStr="Lin and He, 2009" startWordPosition="1738" endWordPosition="1741">meterized by p, which in turn is drawn from a symmetric Beta(γ). ud,s,n determines whether wd,s,n is general or aspect-specific. We then draw wd,s,n as Figure 1: The plate notation of our model. follows: { Multi(φ11) if yd,s,n = 0 Multi(φA,zd,.) if yd,s,n = 1,ud,s,n = 0 Multi(φA,g) if yd,s,n = 1, ud,s,n = 1 Multi(φO,zd,.) if yd,s,n = 2,ud,s,n = 0 Multi(φO,g) if yd,s,n = 2, ud,s,n = 1 Figure 1 shows our model using the plate notation. 3.2 Setting π with a Maximum Entropy Model A simple way to set πd,s,n is to draw it from a symmetric Dirichlet prior. However, as suggested in (Mei et al., 2007; Lin and He, 2009), fully unsupervised topic models are unable to identify opinion words well. An important observation we make is that aspect words and opinion words usually play different syntactic roles in a sentence. Aspect words tend to be nouns while opinion words tend to be adjectives. Their contexts in sentences can also be different. But we do not want to use strict rules to separate aspect and opinion words because there are also exceptions. E.g. verbs such as recommend can also be opinion words. In order to use information such as POS tags to help discriminate between aspect and opinion words, we pro</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceeding of the Eighteenth ACM Conference on Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: Modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th International Conference on World Wide Web.</booktitle>
<contexts>
<context position="6454" citStr="Mei et al. (2007)" startWordPosition="993" endWordPosition="996">quires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rateable aspects. They propose multigrain topic models for discovering local rateable aspects. However, they do not explicitly separate aspect and opinion words. Lin and He (2009) propose a joint topic-sentiment model, but topic words and sentiment words are still not explicitly separated. Mei et al. (2007) propose to separate topic and sentiment words using a positive sentiment model and a negative sentiment model, but both models capture general opinion words only. In contrast, we model aspect-specific opinion words as well as general opinion words. Recently Brody and Elhadad (2010) propose to detect aspect-specific opinion words in an unsupervised manner. They take a two-step approach by first detecting aspect words using topic models and then identifying aspect-specific opinion words using polarity propagation. They only consider adjectives as opinion words, which may potentially miss opinio</context>
<context position="10844" citStr="Mei et al., 2007" startWordPosition="1734" endWordPosition="1737">n over {0, 1} parameterized by p, which in turn is drawn from a symmetric Beta(γ). ud,s,n determines whether wd,s,n is general or aspect-specific. We then draw wd,s,n as Figure 1: The plate notation of our model. follows: { Multi(φ11) if yd,s,n = 0 Multi(φA,zd,.) if yd,s,n = 1,ud,s,n = 0 Multi(φA,g) if yd,s,n = 1, ud,s,n = 1 Multi(φO,zd,.) if yd,s,n = 2,ud,s,n = 0 Multi(φO,g) if yd,s,n = 2, ud,s,n = 1 Figure 1 shows our model using the plate notation. 3.2 Setting π with a Maximum Entropy Model A simple way to set πd,s,n is to draw it from a symmetric Dirichlet prior. However, as suggested in (Mei et al., 2007; Lin and He, 2009), fully unsupervised topic models are unable to identify opinion words well. An important observation we make is that aspect words and opinion words usually play different syntactic roles in a sentence. Aspect words tend to be nouns while opinion words tend to be adjectives. Their contexts in sentences can also be different. But we do not want to use strict rules to separate aspect and opinion words because there are also exceptions. E.g. verbs such as recommend can also be opinion words. In order to use information such as POS tags to help discriminate between aspect and op</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: Modeling facets and opinions in weblogs. In Proceedings of the 16th International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Topic models conditioned on arbitrary features with dirichlet-multinomial regression.</title>
<date>2008</date>
<booktitle>In Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="7339" citStr="Mimno and McCallum, 2008" startWordPosition="1133" endWordPosition="1136">rody and Elhadad (2010) propose to detect aspect-specific opinion words in an unsupervised manner. They take a two-step approach by first detecting aspect words using topic models and then identifying aspect-specific opinion words using polarity propagation. They only consider adjectives as opinion words, which may potentially miss opinion words with other POS tags. We try to jointly capture both aspect and opinion words within topic models, and we allow non-adjective opinion words. Another line of related work is about how to incorporate useful features into topic models (Zhu and Xing, 2010; Mimno and McCallum, 2008). Our MaxEnt-LDA hybrid bears similarity to these recent models but ours is designed for opinion mining. 3 Model Description Our model is an extension of LDA (Blei et al., 2003) but captures both aspect words and opinion words. To model the aspect words, we use a modified version of the multi-grain topic models from (Titov and McDonald, 2008). Our model is simpler and yet still produces meaningful aspects. Specifically, we assume that there are T aspects in a given collection of reviews from the same domain, and each review document contains a mixture of aspects. We further assume that each se</context>
<context position="12059" citStr="Mimno and McCallum, 2008" startWordPosition="1947" endWordPosition="1950">ect and opinion words, we propose a novel idea as follows: We set πd,s,n using a maximum entropy (MaxEnt) model applied to a feature vector xd,s,n associated with wd,s,n. xd,s,n can encode any arbitrary features we think may be discriminative, e.g. previous, current and next POS tags. Formally, we have p(yd,s,n = l|xd,s,n) = πd,s,n l = �2 , exp (λl · xd,s,n) =p exp (λl, · xd,s,n) wd,s,n ∼ . 58 where {λl}i0 denote the MaxEnt model weights and can be learned from a set of training sentences with labeled background, aspect and opinion words. This MaxEnt-LDA hybrid model is partially inspired by (Mimno and McCallum, 2008). As for the features included in x, currently we use two types of simple features: (1) lexical features which include the previous, the current and the next words {wZ_1, wZ, wZ+1}, and (2) POS tag features which include the previous, the current and the next POS tags {POSZ_1, POSZ, POSZ+1}. 3.3 Inference We use Gibbs sampling to perform model inference. Due to the space limit, we leave out the derivation details and only show the sampling formulas. Note that the MaxEnt component is trained first independently of the Gibbs sampling procedure, that is, in Gibbs sampling, we assume that the λ pa</context>
</contexts>
<marker>Mimno, McCallum, 2008</marker>
<rawString>David Mimno and Andrew McCallum. 2008. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. In Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="1424" citStr="Pang and Lee, 2008" startWordPosition="198" endWordPosition="201">rds. We show that with a relatively small amount of training data, our model can effectively identify aspect and opinion words simultaneously. We also demonstrate the domain adaptability of our model. 1 Introduction With the dramatic growth of opinionated usergenerated content, consumers often turn to online product reviews to seek advice while companies see reviews as a valuable source of consumer feedback. How to automatically understand, extract and summarize the opinions expressed in online reviews has therefore become an important research topic and gained much attention in recent years (Pang and Lee, 2008). A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al., 2002) to fine-grained extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, ru</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1576" citStr="Pang et al., 2002" startWordPosition="219" endWordPosition="222">monstrate the domain adaptability of our model. 1 Introduction With the dramatic growth of opinionated usergenerated content, consumers often turn to online product reviews to seek advice while companies see reviews as a valuable source of consumer feedback. How to automatically understand, extract and summarize the opinions expressed in online reviews has therefore become an important research topic and gained much attention in recent years (Pang and Lee, 2008). A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al., 2002) to fine-grained extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and E</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the HLT-EMNLP.</booktitle>
<contexts>
<context position="2188" citStr="Popescu and Etzioni, 2005" startWordPosition="319" endWordPosition="322">et al., 2002) to fine-grained extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “scorecard” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling approach has been shown to b</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th International Conference on World Wide Web.</booktitle>
<contexts>
<context position="2893" citStr="Titov and McDonald, 2008" startWordPosition="430" endWordPosition="433">d” feature at Bing shopping1. Different approaches have been proposed to identify aspect words and phrases from reviews. Previous methods using frequent itemset mining (Hu and Liu, 2004) or supervised learning (Jin and Ho, 2009; Jin et al., 2009; Wu et al., 2009) have the limitation that they do not group semantically related aspect expressions together. Supervised learning also suffers from its heavy dependence on training data. In contrast, unsupervised, knowledge-lean topic modeling approach has been shown to be effective in automatically identifying aspects and their representative words (Titov and McDonald, 2008; Brody and Elhadad, 2010). For example, words such as waiter, waitress, staff and service are grouped into one aspect. We follow this promising direction and extend existing topic models to jointly identify both aspect and opinion words, especially aspect-specific opinion words. Current topic models for opinion mining, which we will review in detail in Section 2, still lack this ability. But separating aspect and opinion words can be very useful. Aspect-specific opinion words can be used to construct a domain-dependent senti1http://www.bing.com/shopping 56 Proceedings of the 2010 Conference o</context>
<context position="6049" citStr="Titov and McDonald (2008)" startWordPosition="926" endWordPosition="929">t supervision, and considered adjectives collocated with feature words as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rateable aspects. They propose multigrain topic models for discovering local rateable aspects. However, they do not explicitly separate aspect and opinion words. Lin and He (2009) propose a joint topic-sentiment model, but topic words and sentiment words are still not explicitly separated. Mei et al. (2007) propose to separate topic and sentiment words using a positive sentiment model and a negative sentiment model, but both models capture general opinion words only. In contrast, we model aspect-sp</context>
<context position="7683" citStr="Titov and McDonald, 2008" startWordPosition="1192" endWordPosition="1195">rds with other POS tags. We try to jointly capture both aspect and opinion words within topic models, and we allow non-adjective opinion words. Another line of related work is about how to incorporate useful features into topic models (Zhu and Xing, 2010; Mimno and McCallum, 2008). Our MaxEnt-LDA hybrid bears similarity to these recent models but ours is designed for opinion mining. 3 Model Description Our model is an extension of LDA (Blei et al., 2003) but captures both aspect words and opinion words. To model the aspect words, we use a modified version of the multi-grain topic models from (Titov and McDonald, 2008). Our model is simpler and yet still produces meaningful aspects. Specifically, we assume that there are T aspects in a given collection of reviews from the same domain, and each review document contains a mixture of aspects. We further assume that each sentence (instead of each word as in standard LDA) is assigned to a single aspect, which is often true based on our observation. To understand how we model the opinion words, let us first look at two example review sentences 57 from the restaurant domain: The food was tasty. The waiter was quite friendly. We can see that there is a strong assoc</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceeding of the 17th International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuangjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1662" citStr="Wu et al., 2009" startWordPosition="233" endWordPosition="236">of opinionated usergenerated content, consumers often turn to online product reviews to seek advice while companies see reviews as a valuable source of consumer feedback. How to automatically understand, extract and summarize the opinions expressed in online reviews has therefore become an important research topic and gained much attention in recent years (Pang and Lee, 2008). A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al., 2002) to fine-grained extraction of opinion expressions and their targets (Wu et al., 2009). In particular, a general framework of summarizing reviews of a certain product is to first identify different aspects (a.k.a. features) of the given product and then extract specific opinion expressions for each aspect. For example, aspects of a restaurant may include food, staff, ambience and price, and opinion expressions for staff may include friendly, rude, etc. Because of the practicality of this structured summary format, it has been adopted in several previous studies (Hu and Liu, 2004; Popescu and Etzioni, 2005; Brody and Elhadad, 2010) as well as some commercial systems, e.g. the “s</context>
<context position="5570" citStr="Wu et al. (2009)" startWordPosition="854" endWordPosition="857"> on large review data sets shows that our model can effectively identify both aspects and aspect-specific opinion words with a small amount of training data. 2 Related Work Pioneered by the work of Hu and Liu (2004), review summarization has been an important research topic. There are usually two major tasks involved, namely, aspect or feature identification and opinion extraction. Hu and Liu (2004) applied frequent itemset mining to identify product features without supervision, and considered adjectives collocated with feature words as opinion words. Jin and Ho (2009), Jin et al. (2009) and Wu et al. (2009) used supervised learning that requires hand-labeled training sentences to identify both aspects and opinions. A common limitation of these methods is that they do not group semantically related aspect expressions together. Furthermore, supervised learning usually requires a large amount of training data in order to perform well and is not easily domain adaptable. Topic modeling provides an unsupervised and knowledge-lean approach to opinion mining. Titov and McDonald (2008) show that global topic models such as LDA (Blei et al., 2003) may not be suitable for detecting rateable aspects. They p</context>
<context position="16283" citStr="Wu et al., 2009" startWordPosition="2803" endWordPosition="2806"> c(0)+γ if l = 2, b = 0 c(·)+2γ . 59 data set restaurant hotel #tokens 1,644,923 1,097,739 #docs 52,574 14,443 Table 1: Some statistics of the data sets. data set #sentences #tokens restaurant 46 634 cell phone 125 4414 DVD player 180 3024 Table 2: Some statistics of the labeled training data. 50/T, Q = 0.1 and -y = 0.5. We also experimented with other settings of these priors and did not notice any major difference. For MaxEnt training, we tried three labeled data sets: one that was taken from the restaurant data set and manually annotated by us3, and two from the annotated data set used in (Wu et al., 2009). Note that the latter two were used for testing domain adaptation in Section 6.3. Some details of the training sets are shown in Table 2. In our preliminary experiments, we also tried two variations of our MaxEnt-LDA hybrid model. (1) The first is a fully unsupervised model where we used a uniform Dirichlet prior for 7r. We found that this unsupervised model could not separate aspect and opinion words well. (2) The second is a bootstrapping version of the MaxEnt-LDA model where we used the predicted values of y as pseudo labels and re-trained the MaxEnt model iteratively. We found that this b</context>
<context position="28872" citStr="Wu et al., 2009" startWordPosition="4916" endWordPosition="4919">e fact that we used the restaurant training data for the hotel data set. 6 Further Analysis of MaxEnt In this section, we perform some further evaluation and analysis of the MaxEnt component in our model. 6.1 Feature Selection Previous studies have shown that simple POS features and lexical features can be very effective for discovering aspect words and opinion words (Hu Methods Average F-1 LocLDA 0.690 ME-LDA + A 0.631 ME-LDA + B 0.695 ME-LDA + C 0.705 Table 9: Comparison of the average F-1 using different feature sets for aspect identification on restaurant. and Liu, 2004; Jin et al., 2009; Wu et al., 2009; Brody and Elhadad, 2010). for POS features, since we observe that aspect words tend to be nouns while opinion words tend to be adjectives but sometimes also verbs or other part-of-speeches, we can expect that POS features should be quite useful. As for lexical features, words from a sentiment lexicon can also be helpful in discovering opinion words. However, lexical features are more diverse so presumably we need more training data in order to detect useful lexical features. Lexical features are also more domain-dependent. On the other hand, we hypothesize that POS features are more effectiv</context>
<context position="32892" citStr="Wu et al., 2009" startWordPosition="5630" endWordPosition="5633">: Average P@n of aspect-specific opinion words with differen sizes of training data on restaurant. Table 13: Average F-1 performance for domain adaption on restaurant. Method P@5 P@10 P@20 restaurant + B 0.775 0.688 0.569 restaurant + C 0.825 0.700 0.569 cell phone + B 0.775 0.675 0.588 cell phone + C 0.750 0.688 0.594 DVD player + B 0.775 0.713 0.575 DVD player + C 0.825 0.663 0.588 Table 14: Average P@n of aspect-specific opinion words for domain adaption on restaurant. quite different training data sets, one from the cell phone domain and the other from the DVD player domain, both used in (Wu et al., 2009). We consider two feature sets defined in Section 6.1 for domain adaption, namely B and C. The results are shown in Table 13 and Table 14. For aspect identification, using out-of-domain training data performed worse than using in-domain training data, but the absolute performance is still decent. And interestingly, we can see that using B is better than using C, indicating that lexical features may hurt the performance in the cross-domain setting. It suggests that lexical features are not easily adaptable across domains for aspect identification. For opinion identification, we can see that the</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Eric P Xing</author>
</authors>
<title>Conditional topic random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 27th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="7312" citStr="Zhu and Xing, 2010" startWordPosition="1129" endWordPosition="1132">on words. Recently Brody and Elhadad (2010) propose to detect aspect-specific opinion words in an unsupervised manner. They take a two-step approach by first detecting aspect words using topic models and then identifying aspect-specific opinion words using polarity propagation. They only consider adjectives as opinion words, which may potentially miss opinion words with other POS tags. We try to jointly capture both aspect and opinion words within topic models, and we allow non-adjective opinion words. Another line of related work is about how to incorporate useful features into topic models (Zhu and Xing, 2010; Mimno and McCallum, 2008). Our MaxEnt-LDA hybrid bears similarity to these recent models but ours is designed for opinion mining. 3 Model Description Our model is an extension of LDA (Blei et al., 2003) but captures both aspect words and opinion words. To model the aspect words, we use a modified version of the multi-grain topic models from (Titov and McDonald, 2008). Our model is simpler and yet still produces meaningful aspects. Specifically, we assume that there are T aspects in a given collection of reviews from the same domain, and each review document contains a mixture of aspects. We </context>
</contexts>
<marker>Zhu, Xing, 2010</marker>
<rawString>Jun Zhu and Eric P. Xing. 2010. Conditional topic random fields. In Proceedings of the 27th International Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>