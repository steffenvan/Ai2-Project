<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<note confidence="0.781249">
INTEGRATING SEMANTICS AND FLEXIBLE SYNTAX BY EXPLOITING
ISOMORPHISM BETWEEN GRAMMATICAL AND SEMANTICAL RELATIONS
Morena Danieli, Franco Ferrara, Roberto Gemello, Claudio Rullent
CSELT - Centro Studi e Laboratori Telecomunicazioni -
Via G.Reiss Romoli 274, 10148 Torino, ITALY
</note>
<sectionHeader confidence="0.98812" genericHeader="abstract">
. ABSTRACT
</sectionHeader>
<bodyText confidence="0.999897615384616">
This work concerns integration between syntax
and semantics. Syntactic and semantic activities
rely on separate bodies of knowledges. Integration
is obtained by exploiting the isomorphism between
grammatical relations (among immediate constitu-
ents) and conceptual relations, thanks to a limited
set of formal mapping rules. Syntactic analysis
does not construct all the explicit parse trees but
just a graph that represents all the plausible
grammatical relations among immediate constituents.
Such graph gives the semantic interpreter, based on
Conceptual Graphs formalism, the discriminative
power required to establish conceptual relations.
</bodyText>
<sectionHeader confidence="0.999697" genericHeader="keywords">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99995552">
In the field of automatic natural language
understanding, the problem of connecting syntax and
semantics has been faced in three different ways.
Some authors are persuaded that understanding
natural language requires no use of syntactic know-
ledge. They claim that semantic representation can
be built directly from the surface string, without
the help of almost any syntactic source (1).
Other authors proposed highly syntactic sys-
tems, starting from the idea that the represen-
tation of the syntactic structure is preliminary to
the understanding process (2).
While the work of this second group of resear-
chers was concerned mainly with the understanding
of individual sentences, the work of the partisans
of semantics was about the understanding of whole
texts.
This shifting of attention substained the idea
that syntax and semantics should be used in an
integrated way. Most researchers have thought that
semantics and syntax should be integrated with
respect to both the representation and the pro-
cessing (3); others have claimed that it is more
efficient to build a full-blooded syntactic repre-
sentation during the parsing process (4).
</bodyText>
<listItem confidence="0.998579833333333">
(1) See the system IPP [Schank 80].
(2) The LUNAR system [Woods 72] is a classical
example.
(3) An example is the Conceptual Analyzer [Birnbaum
81].
(4) See MOPTRANS [Lytinen 85].
</listItem>
<bodyText confidence="0.999871951219512">
Our approach shares some communalities with the
last position. We reckon that semantic and syntac-
tic processes should rely on separate knowledge
bodies. our effort is mainly focused on the reali-
zation of the integration by exploiting the iso-
morphism between syntactic structures and semantic
representations, rather than by making syntactic
and semantic processes interact, as it happens in
previous integrated parsers (5). The idea of iso-
morphism is not carried out through one-to-one cor-
respondence between syntactic rules and semantic
ones - as in Montague-inspired parsers (6), but by
mapping in a formal way grammatical and conceptual
relations. The use of grammatical relations as in-
termediate level between syntax and semantics was
also adopted in the KING KONG parser (7), but this
system is still more near to the position which
wants the representation of syntax and semantics as
well as their processes to interact, while our
choice is to maintain separate these different
sources of knowledge.
The subsequent paragraphs describe how this
hypothesis works in SHEILA (Syntax Helping
Expectations In Language Analysis), a prototype
developed at CSELT laboratories (Turin, Italy). The
aim of SHEILA is to analyze and to extract relevant
information from news (coming from the Italian news
agency &amp;quot;ANSA&amp;quot;). The system is initially being
applied to texts describing variations in the top-
management of commercial societies; it has been
fully implemented on a Symbolics Lisp machine.
SHEILA takes advantage both from the use of expec-
tations and from the combination of the results of
a non-conventional syntactic analysis with the
activity of a surface semantic analysis, based on
the formalism of conceptual graphs (8). In this
paper we describe just the principles which guide
the integration between syntax and semantics.
SHEILA correctly analyzes a set of thirty news,
generating for each of them a set of records for a
relational data base.
</bodyText>
<sectionHeader confidence="0.997712" genericHeader="introduction">
2. THE PROBLEM AND OUR PROPOSAL
</sectionHeader>
<bodyText confidence="0.994487333333333">
In text understanding systems syntax and seman-
tics have almost always been dealt with integra-
tion of their processing. Usually this kind of
</bodyText>
<listItem confidence="0.997206666666667">
(5) See PSLI3 [Frederking 85], FIDO [Lesmo 85] and
WEDNESDAY-2 [Stock 86].
(6) See ABSITY [Hirst 84].
(7) See [BAYER 85]
(8) See [Sowa 84] and also the fourth paragraph be-
low.
</listItem>
<page confidence="0.996714">
278
</page>
<bodyText confidence="0.978649269230769">
systems are semantic driven and they do only local
syntactic checks during analysis. Doing local syn-
tactic checks only involves little amount of syn-
tactic knowledge and that is misleading in solving
problems as anaphoric reference, prepositional
attachment, conjunction and so on.
In a different approach the integration has
been realized during the syntactic structure repre-
sentation construction: the syntactic parser makes
use of semantic information to handle structural
ambiguities.
The questioning done by the syntactic analyzer
to the semantic component aims to cut down the
number of parse trees, but very many rules are
required for this questioning, which has always
been the most domain-dependent part of natural
language understanding systems.
In designing SHEILA we chose another way of
integrating syntax with semantics. The basic schema
may look rather classic: the system produces a syn-
tactic analysis of the text, driven on the basis of
purely syntactic knowledge. The semantic analyzer
checks the syntactic output to see if the semantic
relations among words are supported by it.
But a classical syntax-first analysis is highly
inefficient. It cannot solve structural ambiguities
without the help of any semantic source and that
leads to an explosion of the number of syntactic
parse trees, some of them representing artificial
syntactic ambiguities. So there are two problems:
reducing the explosion of ambiguities and deter-
mining how semantic patterns for each word interact
with syntax.
Our proposal faces these problems through the
original combination of two key ideas, i.e.:
1) a flexible syntactic analysis, which is per-
formed by constructing not all the explicit
parse trees but just a graph, representing all
the plausible grammatical relations among imme-
diate constituents;
2) a formal way of interaction between syntax and
semantics exploiting the isomorphism between
syntactic structures (grammatical relations
among immediate constituents) and semantic ones
(conceptual relations).
Such flexible syntactic analysis gains a
discriminative power (sufficient for aiding seman-
tics in solving ambiguities) and avoids the explo-
sion in the parse trees number. Furthermore, the
mapping between grammatical and conceptual rela-
tions can be defined through a limited set of for-
mal rules.
</bodyText>
<sectionHeader confidence="0.976285" genericHeader="method">
3. THE SYNTACTIC ANALYSIS
</sectionHeader>
<bodyText confidence="0.999979774193548">
Our system has the goal of generating a seman-
tic structure that has to be consistent with the
syntactic form used to convey it in the text. The
aim of syntactic analysis is to support semantics.
A first activity performed by the syntactic
analyzer is the recognition of constituents of the
phrase structure of text. This is done by applying
a set of rewriting phrase structure rules for
Italian language. These rules utilize the output of
a previous morphological analysis that assigns to
words morphological and lexical features (gender,
number, lexical category and so on).
In this analysis phase the application of the
syntactic rules is limited to the recognition of
the basic constituents of the phrase structure of
the sentences. A basic constituent (BC, henceforth)
is a NP, a PP or a VP described at a minimal level
of complexity. At this level the grammar does not
include rules of the form &amp;quot;S --&gt; NP - VP&amp;quot; or
&amp;quot;NP --&gt; NP - PP&amp;quot;, but it does include all the rules
which describe the internal structures of BCs at
the lowest level of recursion.
Every BC has a head and may have one (or more)
modifier. The head of a BC is the characteristic
word, the word without which a group of words would
fail to be an instance of that particular BC. So
the head of a NP is a noun, that of a PP is a pre-
position, that of a VP is a verb, etc.(9). The head
of a BC carries on all the morphological, syntac-
tical and lexical features of the BC itself (10).
Let us consider the sentence
</bodyText>
<listItem confidence="0.9731405">
(1) &amp;quot;Arturo vide una commedia con Meryl Streep.&amp;quot;.
which may be interpreted both
(1.a) Arthur and Meryl Streep saw a play together
and
(1.b) Arthur saw Meryl Streep while she was working
in a play.
</listItem>
<bodyText confidence="0.796875142857143">
At this first level of analysis (1) is rewritten
as
(9) The case of PP constitutes a partial exception
to this principle. In fact while for syntax is
sufficient to know all the relevant informa-
tion concerning the preposition, semantics
also need to know the information con-
cerning the head of the NP which forms the PP.
(10) This definition of head encompasses all
constructions (endocentric and exocentric);
it is closer to the traditional notion of
governing categories than the definition given
by Bloomfield [Bloomfield 35] in terms of
distribution. See [Miller 85].
</bodyText>
<figure confidence="0.997037545454546">
ART
UNA COMMEDIA
PREP I
I N N
I
CON MERYL STREEP
NP VP
V
ARTURO VIDE
NP
/\
</figure>
<page confidence="0.810237">
279
</page>
<bodyText confidence="0.967965405405405">
while the second interpretation can be described
as:
NP
The output of this first step of syntactic analysis
is a structure that includes the syntactic ambi-
guities which will be properly treated at the
second level of analysis (11).
The second level of syntactic analysis has the
goal of solving the problems about prepositional
phrase attachment, noun phrase modification and
conjunction and that of establishing grammatical
relations among BCs (12). In the usual syntactic
approach this activity, performed among more
complex constituents, leads to the explosion of
structural ambiguities. In our case the problem of
handling ambiguity strongly arises: in fact the
syntactic analyzer has been designed in order to
treat a large variety of real texts which contain
words out of their preferred grammatical order or
which present elliptical constructions or, finally,
which present very complex grammatical constructs.
To reach such an adequacy we relax the grammar
constraints, but that may cause the generation of
artificial structural ambiguities (13). In order to
solve this problem, we see all the groups of BCs
having the same head as belonging to an equivalence
class of constituents. Let us consider an example
concerning this important point. In Italian the
phrase &amp;quot;Il sindaco Rossi di Torino&amp;quot; (&amp;quot;The major
Rossi of Turin&amp;quot;) may involve some structural ambi-
guity if it has to be parsed without the help of
semantic hints. In fact, this noun phrase can mean
both that Rossi is the major of Turin and that
Rossi is a major who comes from Turin. Performing a
classical analysis this ambiguity generates two
different structural descriptions. The first
interpretation can be described as:
</bodyText>
<sectionHeader confidence="0.731762" genericHeader="method">
NP
NP NP PP
</sectionHeader>
<bodyText confidence="0.409857">
AAA
</bodyText>
<sectionHeader confidence="0.907211" genericHeader="method">
IL SINDACO ROSSI DI TORINO
</sectionHeader>
<bodyText confidence="0.878690545454546">
(11) At this level we have not so many ambiguities
because the linguis-tic phenomena which
cause them are still not faced. In this phase
of analysis lexical ambiguity (involving
uncertainty about the lexical category of
a given word) only arises; this kind of
ambiguity is treated by taking into account
the syntagmatic relationships of the words
in question; the analyzer keeps different
interpretations for the ambiguity which can
not be solved without semantics.
</bodyText>
<listItem confidence="0.854103">
(12) Grammatical relations are primitive notions
such as subject, object, complement and so
on.
</listItem>
<bodyText confidence="0.8071072">
(13) The constraining power is provided setting up
a structural homology between syntactic and
semantic levels and performing the formal map-
ping between grammatical relations and concep-
tual relations.
</bodyText>
<sectionHeader confidence="0.930569" genericHeader="method">
NP NP PP
</sectionHeader>
<bodyText confidence="0.34447">
AAA
</bodyText>
<sectionHeader confidence="0.754627" genericHeader="method">
IL SINDACO ROSS! DI TORINO
</sectionHeader>
<bodyText confidence="0.997066333333333">
In our analysis we handle this problem starting
from the consideration that in both the interpreta-
tions the NP &amp;quot;Rossi&amp;quot; is the head of the resulting
structural unit. So the analyzer generates only one
representation for the new construction in this
way:
</bodyText>
<sectionHeader confidence="0.962308" genericHeader="method">
SPECIFICATION
</sectionHeader>
<bodyText confidence="0.887142588235294">
Now, let us consider this construction as being
part of a sentence:
(2) &amp;quot;Il sindaco Rossi di Torino parte per Roma.&amp;quot;
&amp;quot;The major Rossi of Turin is leaving for Rome.&amp;quot;
The ascription of grammatical relations among the
phrases of this sentence requires the recognition
of the NP &amp;quot;Il sindaco Rossi di Torino&amp;quot; as subject
of the sentence and the PP &amp;quot;per Roma&amp;quot; as modifier
of the VP. The detection of the subject relation
does not necessarily involve the problem of struc-
tural ambiguity because this is limited at the
relations between the two NPs and the first PP. So
the analyzer gives the following description of the
sentence:
SPECIFIC.
COMPLEM.
Np APP. Np&amp;quot;-SPECIF:spp VP PP
</bodyText>
<sectionHeader confidence="0.589945" genericHeader="method">
AAAA
</sectionHeader>
<bodyText confidence="0.9471376">
(ROSSI) DI TORINO PARTE PER ROMA
Thanks to this treatment of ambiguity, the syn-
tactic structure of this sentence can be described
by only one representation, while a classical syn-
tactic analysis would generate at least two repre-
</bodyText>
<figure confidence="0.988317714285714">
NP
NP
NP APPOSITIOIZ-4•NP SPECIFIC PP
AA
IL SINDACO (ROSSI) DI TORINO
SUBJECT
IL SINDACO
</figure>
<page confidence="0.990599">
280
</page>
<bodyText confidence="0.9998691">
sentations. Our single representation consists of a
graph of BCs connected by grammatical relations,
which are established unless syntactic knowledge
guarantees that no constituent in the two classes
can be connected by such relations. In this way the
processing is efficient almost as in the case of
complete parallelism between syntax and semantics
and, in addition, there is complete compatibility
with a parallel implementation.
Note that none of the possible interpretations
has been lost: all them are passed to the semantic
interpreter which operates the resolution of ambi-
guity taking into account both the connections bet-
ween the BCs pointed out by syntactic analysis and
the semantic plausibility of the proposed connec-
tions.
The resulting discriminative power of syntax is
still sufficient for helping semantics in
establishing the correct semantic relations among
concepts denoted by words.
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="method">
4. THE SEMANTIC ANALYSIS
</sectionHeader>
<bodyText confidence="0.999826804878049">
Our working hypothesis is that we can represent
the meaning of a text starting from the meanings of
words and from the syntactic structure of the text.
We represent the surface semantic structure by
conceptual graphs (14). A conceptual graph is an
oriented bipartite graph with two kinds of nodes:
concept nodes (representing entities) and concep-
tual relation nodes (representing semantic rela-
tions among concepts). A Type Hierarchy is defined
over concepts.
The semantic information is distributed on
words by means of canonical graphs, which describe
concepts connoted by the words of the domain in
terms of their semantic context; they represent the
implicit pattern of relationships necessary for a
semantically well-formed text. In each canonical
graph we can distinguish a head (the main concept
node of the canonical graph itself) and a semantic
context (see figure 1). The Type Hierarchy is a
taxonomy of domain concepts used to inherit seman-
tic contexts and guide graph joins.
The aim of surface semantic analysis is to
establish semantic relations among the head nodes
of canonical graphs connoted by the words of text.
First, the canonical graphs are activated (copied
in the working memory); then the activated graphs
are joined, superimposing context nodes on head
nodes according with the Type Hierarchy; so rela-
tions are established among head concepts.
When establishing a semantic relation, the
mapping with syntax allows the evaluation of its
syntactic soundness: the syntactic analysis output
(14) The theory of Conceptual Graphs is presented
by [Sowa, 1984]. This formalism is a generali-
zation of various previous approaches to the
representation of the semantic relations
holding among words such as frames, semantic
networks and conceptual dependency.
is checked to see if a grammatical relation sup-
ports the proposed semantic one. Otherwise the
semantic relation is not established.
</bodyText>
<sectionHeader confidence="0.998092" genericHeader="method">
5. INTEGRATING SYNTAX AND SEMANTICS
</sectionHeader>
<bodyText confidence="0.999836684210527">
During semantic analysis relations between con-
cept nodes are established only if they are sup-
ported by the result of syntactic analysis.
Given a semantic relation, it is necessary to
see if there is a corresponding grammatical rela-
tion. The correspondence between grammatical rela-
tions and semantic relations (mapping) is solved
through the notion of head which has been intro-
duced both in syntax (heads of BCs) and in seman-
tics (heads of canonical graphs).
The semantic relations and the grammatical
relations must relate to the same couple of lexical
items; in other words such lexical items must be
both the heads of the BCs (involved by the gram-
matical relation) and the heads of the conceptual
graphs (involved by the semantic relation).
A semantic relation SR between two head nodes
HNi and HNj, having as heads the words Wi and Wj,
can only be established if:
</bodyText>
<listItem confidence="0.874216666666667">
1) there is a grammatical relation GR between two
BCs, BCi and BCj, whose heads are Wi and Wj
respectively.
2) semantic relation SR is compatible with the
grammatical relation GR and with the set of
features Fi and Fj associated to BCi and BCj.
</listItem>
<bodyText confidence="0.999656666666667">
Conditions are verified through the application of
a mapping rule among a limited set. Each semantic
relation inside a semantic context of a canonical
conceptual graph is augmented with the indication
of a mapping rule.
A mapping rule is a list of plausible gram-
matical relations that can correspond to the seman-
tic relation.
In a mapping rule each grammatical relation can
be constrained by an activation condition that
relates to the morphologic and syntactic features
of the involved BC classes.
</bodyText>
<subsectionHeader confidence="0.997714">
5.1 An example
</subsectionHeader>
<listItem confidence="0.825665">
• Let us consider the example of the figure 2.
</listItem>
<bodyText confidence="0.999549615384616">
The join J1 of the head conceptual node HN1
with the context node CN2,1 of the head node HN2
causes a conceptual relation AGENT to be
established between concept nodes HN1 and HN2. Such
head concept nodes correspond to words W1 (&amp;quot;John&amp;quot;)
and W2 (&amp;quot;eats&amp;quot;) at the lexical level.
Such conceptual relation has an associated
mapping rule which requires a grammatical relation
of a certain kind (e.g. &amp;quot;subject&amp;quot;). Such gram-
matical relation must have been established by syn-
tactic analysis between two BCs having W1 and W2 as
their heads. As that is the case of figure 2, the
join J1 can be made.
</bodyText>
<page confidence="0.99008">
281
</page>
<bodyText confidence="0.999964866666667">
Differently, join J4 between HN3 and CN2,1 can
not be established as it would cause an AGENT rela-
tion between conceptual nodes HN2 (&amp;quot;eat&amp;quot;) and HN3
(&amp;quot;chicken&amp;quot;); such semantic relation is not sup-
ported by a suitable grammatical relation. In fact
there is a grammatical relation between BC2 and
BC3, but it is not the correct one because the
grammatical relation &amp;quot;object&amp;quot; can not correspond to
the semantic relation AGENT.
To give an idea of the mapping rules, the
MR-AGENT mapping rule is sketched. It is used to
map the conceptual relation AGENT on the gram-
matical relation &amp;quot;subject&amp;quot; if the analyzed sentence
is active or on the grammatical relation &amp;quot;agentive&amp;quot;
if the sentence is passive:
</bodyText>
<equation confidence="0.5261205">
MR-AGENT : subject if BC1 is ACTIVE and
BC1 and BC2 agree.
agentive if BC1 is PASSIVE and
8C2 is a &amp;quot;by-phrase&amp;quot;
</equation>
<sectionHeader confidence="0.99916" genericHeader="conclusions">
6. CONCLUSION
</sectionHeader>
<bodyText confidence="0.999992777777778">
The SHEILA system has been presented as an
attempt to solve the problem of integrating syntax
and semantics. The authors propose that syntactic
and semantic processes should rely on distinct
bodies of knowledge and that the interaction bet-
ween syntax and semantics should be obtained by
exploiting, in a formal way, the isomorphism bet-
ween syntactic and semantic structures. In order to
avoid the lack of efficiency characterizing a
syntax-first parser, the authors have designed a
flexible syntax which, without exploding the struc-
tural ambiguities, supplies semantic interpreter
with knowledge about syntactic connections between
the words occurring in the text. The isomorphism
between syntax and semantics is accounted into a
limited set of formal mapping rules and conditions.
Prepositional phrase attachment, apposition, deter-
mination of conjunction&apos;s scope and modification of
a NP through other NPs are dealt in a satisfactory
way both from a syntactical and from a semantical
point of view. Other complex linguistic phenomena
(as anaphora, quantification and ellipsis) requires
a more extensive use of heuristics. The future work
will concentrate on these specific aspects in order
to check the adequacy of the hypothesis of iso-
morphism between syntactic and semantic structures
to larger fragments of the Italian language.
</bodyText>
<sectionHeader confidence="0.998695" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.997625787878788">
[Bayer 85] Bayer, S., Joseph, L., Kalish, C.,
Grammatical Relations as The Basis for NL Parsing
and Text Understanding. Proc. 9th IJCAI, Los
Angeles, 1985, pp. 798-790.
[Birnbaum 81] Birnbaum, L. and Selfridge, M.,
Conceptual Analysis for Language. in Schank, R.C.
and Riesbeck, C.K., (eds), Inside Computers
Understanding. Lawrence Erlbaum Ass., 1981.
[Bloomfield 35] Bloomfield, Leonard, Language,
Allen &amp; Unwin, London 1935.
[Frederking 85] Frederking, R.E., Syntax and
Semantics in NL Parsers. Technical Report 133,
Carnegie-Mellon, Dept. of Computer Science, May
1985.
(Hirst 84] Hirst, G.J., Semantic Interpretation
Against Ambiguity. Brown University, Ph.D., 1984
[Lesmo 85] Lesmo, L. and Torasso, P. Weighted,
Interaction of Syntax and Semantics in NL Analysis.
Proc. 9th IJCAI, Los Angeles, 1985, 772-778.
[Lytinen 85] Lytinen, S.L., Integrating Syntax
and Semantics., Proc. Theoretical and
Methodological Issues in MT for NLs, Hamilton,
1985, 167-178.
[Miller 85] Miller, J., Semantics and Syntax,
Cambridge Univ. Press, Cambridge (U.K.), 1985.
[Stock 86] Stock, O., Dynamic Unification in
Lexically Based Parsing., Proc. 7th ECAI, Brighton,
1986, 212-221.
[Sowa 84] Sowa, J.F., Conceptual Structures.
Addison Wesley, 1984.
[Woods 72] Woods, W.A., An Experimental Parsing
System for Transition Network Grammars. Technical
Report 2362, Bolt Beranek and Newman Inc., 1972.
</reference>
<page confidence="0.987502">
282
</page>
<figure confidence="0.994068035714286">
EATS
JOHN
FORK
LEXICAL
LEVEL
CHICKEN
SURFACE
SEMANTIC
m LEVEL
A W1 A wz A 143 4W4
= = 2 = SYNTACTIC
m m m m LEVEL
› g OBJECT &gt;COMPLEMENT g or A
0 13
8C1 BC2 BC3 (WITH) IA (FORK)
SUBJECT
CONCEPTS
CANONICAL GRAPHS
TYPE HIERARCHY
EAT 41 ACTION
- - -
SEN. CONTEXT
EAT
HEAD
HE...... 1) JOHN 1) EATS COMPLEMENT 1) WITH A FORK
FORK FORK )41-C EAT FORK4 INANIM-OBJ 1) A CHICKEN
....... 2) A CHICKEN
SEM. CONTEXT WITH A FORK
</figure>
<figureCaption confidence="0.947291">
Fig.1 - The canonical graph of &amp;quot;eat&amp;quot; and that of
&amp;quot;fork&amp;quot;.
</figureCaption>
<bodyText confidence="0.991973615384615">
Fig.2 Mapping aspects for the sentence &amp;quot;John eats
a chicken with the fork&amp;quot;. The syntactic le-
vel represents the graph of EICs that con-
stitutes the two syntactic structures of
the sentence. At the semantic level dotted
arrows (4=4) stand for a join that is
supported by syntax. The double arrows
(C,==&gt;) instead represents a join that is
not supposed by syntax. In fact a mapping
rule requires that the semantic relation
&amp;quot;agent&amp;quot; must be supported by the grammati-
cal relation &amp;quot;subject&amp;quot; (in an active sen-
tence) and not by the &amp;quot;object&amp;quot; relation.
</bodyText>
<page confidence="0.998082">
283
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.798296">
<title confidence="0.9843715">INTEGRATING SEMANTICS AND FLEXIBLE SYNTAX BY EXPLOITING ISOMORPHISM BETWEEN GRAMMATICAL AND SEMANTICAL RELATIONS</title>
<author confidence="0.999106">Morena Danieli</author>
<author confidence="0.999106">Franco Ferrara</author>
<author confidence="0.999106">Roberto Gemello</author>
<author confidence="0.999106">Claudio Rullent</author>
<affiliation confidence="0.902023">CSELT - Centro Studi e Laboratori Telecomunicazioni -</affiliation>
<address confidence="0.92175">Via G.Reiss Romoli 274, 10148 Torino, ITALY</address>
<abstract confidence="0.991198785714286">This work concerns integration between syntax and semantics. Syntactic and semantic activities rely on separate bodies of knowledges. Integration is obtained by exploiting the isomorphism between grammatical relations (among immediate constituents) and conceptual relations, thanks to a limited set of formal mapping rules. Syntactic analysis does not construct all the explicit parse trees but just a graph that represents all the plausible grammatical relations among immediate constituents. Such graph gives the semantic interpreter, based on Conceptual Graphs formalism, the discriminative power required to establish conceptual relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bayer</author>
<author>L Joseph</author>
<author>C Kalish</author>
</authors>
<title>Grammatical Relations as The Basis for NL Parsing and Text Understanding.</title>
<date>1985</date>
<booktitle>Proc. 9th IJCAI,</booktitle>
<pages>798--790</pages>
<location>Los Angeles,</location>
<marker>[Bayer 85]</marker>
<rawString>Bayer, S., Joseph, L., Kalish, C., Grammatical Relations as The Basis for NL Parsing and Text Understanding. Proc. 9th IJCAI, Los Angeles, 1985, pp. 798-790.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Birnbaum</author>
<author>M Selfridge</author>
</authors>
<title>Conceptual Analysis for Language.</title>
<date>1981</date>
<booktitle>in Schank, R.C. and Riesbeck, C.K., (eds), Inside Computers Understanding. Lawrence Erlbaum Ass.,</booktitle>
<marker>[Birnbaum 81]</marker>
<rawString>Birnbaum, L. and Selfridge, M., Conceptual Analysis for Language. in Schank, R.C. and Riesbeck, C.K., (eds), Inside Computers Understanding. Lawrence Erlbaum Ass., 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Bloomfield</author>
</authors>
<title>Language, Allen &amp; Unwin,</title>
<date>1935</date>
<location>London</location>
<marker>[Bloomfield 35]</marker>
<rawString>Bloomfield, Leonard, Language, Allen &amp; Unwin, London 1935.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Frederking</author>
</authors>
<title>Syntax and Semantics in NL Parsers.</title>
<date>1985</date>
<journal>Hirst</journal>
<tech>Technical Report 133, Carnegie-Mellon,</tech>
<volume>84</volume>
<institution>Dept. of Computer Science,</institution>
<location>Ph.D.,</location>
<marker>[Frederking 85]</marker>
<rawString>Frederking, R.E., Syntax and Semantics in NL Parsers. Technical Report 133, Carnegie-Mellon, Dept. of Computer Science, May 1985. (Hirst 84] Hirst, G.J., Semantic Interpretation Against Ambiguity. Brown University, Ph.D., 1984</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lesmo</author>
<author>P Weighted Torasso</author>
</authors>
<title>Interaction of Syntax and Semantics in NL Analysis.</title>
<date>1985</date>
<booktitle>Proc. 9th IJCAI,</booktitle>
<pages>772--778</pages>
<location>Los Angeles,</location>
<marker>[Lesmo 85]</marker>
<rawString>Lesmo, L. and Torasso, P. Weighted, Interaction of Syntax and Semantics in NL Analysis. Proc. 9th IJCAI, Los Angeles, 1985, 772-778.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Lytinen</author>
</authors>
<title>Integrating Syntax and Semantics.,</title>
<date>1985</date>
<booktitle>Proc. Theoretical and Methodological Issues in MT for NLs,</booktitle>
<pages>167--178</pages>
<location>Hamilton,</location>
<marker>[Lytinen 85]</marker>
<rawString>Lytinen, S.L., Integrating Syntax and Semantics., Proc. Theoretical and Methodological Issues in MT for NLs, Hamilton, 1985, 167-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Miller</author>
</authors>
<title>Semantics and Syntax,</title>
<date>1985</date>
<publisher>Univ. Press,</publisher>
<location>Cambridge</location>
<marker>[Miller 85]</marker>
<rawString>Miller, J., Semantics and Syntax, Cambridge Univ. Press, Cambridge (U.K.), 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Stock</author>
</authors>
<title>Dynamic Unification in Lexically Based Parsing.,</title>
<date>1986</date>
<booktitle>Proc. 7th ECAI,</booktitle>
<pages>212--221</pages>
<location>Brighton,</location>
<marker>[Stock 86]</marker>
<rawString>Stock, O., Dynamic Unification in Lexically Based Parsing., Proc. 7th ECAI, Brighton, 1986, 212-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Sowa</author>
</authors>
<title>Conceptual Structures.</title>
<date>1984</date>
<publisher>Addison Wesley,</publisher>
<marker>[Sowa 84]</marker>
<rawString>Sowa, J.F., Conceptual Structures. Addison Wesley, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>An Experimental Parsing System for Transition Network Grammars.</title>
<date>1972</date>
<tech>Technical Report 2362,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<marker>[Woods 72]</marker>
<rawString>Woods, W.A., An Experimental Parsing System for Transition Network Grammars. Technical Report 2362, Bolt Beranek and Newman Inc., 1972.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>