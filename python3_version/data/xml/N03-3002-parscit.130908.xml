<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006275">
<note confidence="0.93307">
Proceedings of HLT-NAACL 2003
Student Research Workshop , pp. 7-12
Edmonton, May-June 2003
</note>
<title confidence="0.9971245">
The Importance of Prosodic Factors in Phoneme Modeling with
Applications to Speech Recognition
</title>
<author confidence="0.999285">
Sarah Borys
</author>
<affiliation confidence="0.9989225">
Department of Electrical and Computer Engineering
University of Illinois at Urbana-Champaign, Urbana, IL 61901
</affiliation>
<sectionHeader confidence="0.98809" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999858857142857">
This paper tests speech recognition using
prosody dependent allophone models. The
log likehoods of various prosodically
labeled phonemes are calculated using
Baum-Welsh re-estimation. These log
likehoods are then compared to log
likehoods of non-prosodically labeled
phonemes. Based on the comparison of
these log likehoods, it can be concluded that
modeling all prosodic information directly
in the vowel model leads to improvement in
the model. Consonants, on the other hand,
split naturally into three categories,
strengthened, lengthened and neutral.
</bodyText>
<sectionHeader confidence="0.998214" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.970903225">
Prosody is an important factor in how humans interpret
speech. The same word string can have different
meanings depending on the way it is said. Many
linguists have performed extensive studies of prosody
and of the effects of prosodic factors on spoken
language.
In his dissertation, Cho (2001) investigates
how phonetic features are conditioned by prosodic
factors by examining pre-boundary, post-boundary, and
accented syllables. Cho reports that boundary induced
articulatory strengthening occurs in phrase final vowel
positions and phrase initial consonant positions. Phrase
initial vowels are also more susceptible to coarticulation
than phrase final vowels. Cho also hypothesizes that
accented syllables are characterized primarily by
sonority expansion. An accented vowel is usually not
affected by coarticulation with a neighboring vowel.
Strengthening effects caused by boundaries and accents
cannot be considered the same and Cho discusses
several differences between boundary and accent
strengthening effects.
In a study performed by Edwards et al (1991),
the effect of final lengthening at prosodic boundaries
was examined by studying articulator movement
patterns. It was found that decreasing intragestural
stiffness slows down the syllable, affecting the tempo of
the spoken word, causing the syllable to be lengthened.
The changing of intergestural phrasing also affects the
syllable duration by decreasing the overlap of a vowel
gesture with a consonant gesture. This increases the
duration of accented syllables comparatively to
unaccented syllables and causes the accented syllable to
be strengthened.
De Jong (1994) investigated the supraglottal
correlates of linguistic prominence in English. De Jong
suggests that stress involves a localized shift toward
hyperarticulated speech. An increase in the duration in
the closure and in the aspiration of initial voiceless stops
was observed along with an increase in duration of
prevoicing in initial voiced stops in stressed syllables.
Fougeron and Keating (1997) report that on the
edges of prosodic phrase boundaries, final vowels and
initial consonants have less reduced lingual articulation.
The differences in articulation were manifested in the
linguopalatal contact of boundary consonants and
vowels. The linguopalatal contact of both consonants
and vowels relates directly to the type and size of phrase
boundary. Boundary type and size also appear to effect
the acoustic duration of post-boundary consonants.
Wightman et al (1992) report that there is
segmental lengthening in the rhyme of a syllable that
directly precedes a phrase boundary. Wightman
examines the effect of duration and pause on boundary
words and shows that speaking rate effects the
distribution of phoneme duration. The lengthening
effects of pre-boundary syllables can be used to
distinguish several different types of phrase boundaries.
These results show that prosody can cause
variations not just in pitch, but also in the articulation of
phonetic contrasts in different phonemes. These
variations can be modeled as a part of the phoneme
definition in an automatic speech recognition (ASR)
system. However, the question is whether or not
modeling prosodic factors with phonemes would lead to
improvements in the quality of the phoneme model and
thus lead to improvements in both the correctness and
accuracy in an ASR system.
Most modern speech recognizers function by
breaking words up into mathematical features. The
recognizer then determines the most likely occurring set
Consonants Vowels
b ch d aa ae
dh f g ah ao
hh jh k aw ax
l m n ay eh
p r s el er
sh t v ey ih
w y z iy ow
oy uh
uw
</bodyText>
<figureCaption confidence="0.845458333333333">
Figure 1. This figure contains a chart of the 38
different non-prosodically distinguished phonemes used
for experimentation.
</figureCaption>
<bodyText confidence="0.99996634375">
of phonemes by comparing these extracted features with
its own phoneme models. Phonemes are usually
modeled using hidden Markov Models (HMMs). Once
the recognizer has identified a set of the most likely
occurring phonemes, it then uses a dictionary to match a
word or group of words to that set.
Prosody can be incorporated into the phoneme
model by allowing two different HMMs to represent a
single phoneme. One HMM would need to represent
the prosody independent version of the phoneme while
the other would represent the phoneme in some prosodic
context. This could allow the recognizer to do things
such as distinguish between accented and unaccented
phonemes or distinguish between boundary and non-
boundary phonemes. Allowing the recognizer to make
such a distinction may reduce the confusability of
certain phoneme groups, which in turn could allow for
increased recognition rates.
The goal of this research is to not only
determine if the inclusion of prosody in the phoneme
model causes improvement in the model, but also to
determine which prosodic factors to model and the best
way to model them. This will be accomplished by first
splitting phonemes into different prosodically varying
groups and then by comparing the log probability of the
occurrence of each phoneme in those different groups.
Because prosody causes noticeable variations in speech,
a phoneme model that includes prosodic factors should
differ from models of the same phoneme that do not.
This difference will prove to be significant enough to
show that prosodic factors should be taken into account
for a more accurate phoneme model.
</bodyText>
<sectionHeader confidence="0.968109" genericHeader="method">
2. The Database
</sectionHeader>
<bodyText confidence="0.99509">
Boston University’s Radio News Corpus (1995) was
used for all experiments. The speakers from this corpus
that were analyzed were F1A, F2B, and M2B. The
usable data from these three speakers consisted of 259
</bodyText>
<equation confidence="0.488986666666667">
phn : phrase medial
phn! : phrase medial, accented
phnB4 : phrase final, unaccented
phnB4! : phrase final, accented
B4phn : phrase initial, unaccented
B4phn! : phrase initial, accented
</equation>
<figureCaption confidence="0.9857025">
Figure 2. The different prosodic labels. “Phn”
represents some generic phoneme.
</figureCaption>
<bodyText confidence="0.999546888888889">
wav files containing 18270 words. All the wav files
that were used were accompanied by two types of
prosodic transcription files, .brk and .ton files.
The corpus was labeled according to the ToBI
standard. Silverman et al (1992) explain the labeling
system in detail. It will not be described in this paper.
The .brk files specify a ToBI break index (0-4)
for every spoken word in the associated wav file. For
the experiments, the only boundary distinguished was
the intonational phrase boundary (ToBI index 4). All
other boundary types (indices 0-3) were grouped
together. There were 3855 intonational phrase
boundaries in the data set.
The .ton files label the times in which an
accented vowel occurs. The most abundant accent label
was H* which occurs in a ratio of about 10 H* for every
single L*. Other accent types do occur, but most
include H* in bitonal accent.
</bodyText>
<sectionHeader confidence="0.917532" genericHeader="method">
3. Prosodic Annotation
</sectionHeader>
<bodyText confidence="0.9998">
The set of 38 different phonemes, shown in figure 1,
were used in the experiments.
</bodyText>
<subsectionHeader confidence="0.998803">
3.1 Allophone Modeling
</subsectionHeader>
<bodyText confidence="0.998829">
Recognition experiments were preformed for four
different allophone sets:
</bodyText>
<listItem confidence="0.99988825">
• Tied
• Accent
• Boundary
• Untied
</listItem>
<bodyText confidence="0.999212333333333">
The Tied set contained no prosodically labeled
data.
The Accent set contained monophones that were
split into two groups, accented and unaccented.
Phonemes were not distinguished on the basis of phrase
position.
</bodyText>
<table confidence="0.998537">
Tied Accent Boundary Untied
Monophone All All All Cons. All
Group Cons. Cons. Cons.
After After After After
Vowel Vowel Vowel Vowel
Before Before Before Before
Vowel Vowel Vowel Vowel
Vowels Vowels Vowels Vowels
</table>
<figureCaption confidence="0.997206">
Figure 3. The sixteen experimental conditions
</figureCaption>
<bodyText confidence="0.996920888888889">
The Boundary set modeled monophones as phrase
initial, phrase medial, or phrase final. Accented
phonemes were not distinguished from unaccented
phonemes.
The Untied set distinguish phonemes by both
phrasal position and accentuation. A monophone in this
group could be labeled as phrase medial, phrase medial
accented, phrase initial, phrase initial accented, phrase
final or phrase final accented.
</bodyText>
<subsectionHeader confidence="0.993882">
3.2 Allophone Definitions
</subsectionHeader>
<bodyText confidence="0.990583647058824">
Figure 2 contains the six different labels used to
represent the allophones of a single imaginary phoneme
“phn.”
A phrase final phoneme was considered to be
any phoneme that occurred in the nucleus or coda of the
final syllable of a word directly preceding an
intonational phrase boundary. Phrase initial phonemes,
on the other hand, were considered to be any phoneme
in the onset or nucleus of the initial syllable of a word
that followed an intonational phrase boundary. Phase
medial phonemes were considered to be any other
phoneme.
An accented vowel was the lexically stressed
vowel in a word containing a transcribed pitch accent.
Because accented consonants are not clearly defined,
three different labeled sets of accented consonants were
developed:
</bodyText>
<listItem confidence="0.81845">
❑❑ All Consonants
❑❑ After Vowel
❑❑ Before Vowel
</listItem>
<bodyText confidence="0.995361">
All Consonants considered every consonant in a syllable
with an accented vowel to also be accented. After
Vowel considered as accented only the coda consonants.
Before Vowel recognized only the onset consonants of
the accented syllable as being accented. Accents were
considered to be limited to a single syllable.
Because there were three different groups of
accented consonants and because there is only one way
a vowel can be labeled as accented, vowels were
</bodyText>
<figure confidence="0.763960166666667">
beyond b iy y aa n d
beyond! b iy y aa! n! d!
beyondB4 b iy y aaB4 nB4 dB4
beyondB4! b iy y aaB4! nB4! dB4!
B4beyond B4b B4iy y aa n d
B4beyond! B4b B4iy y aa! n! d!
</figure>
<figureCaption confidence="0.9983108">
Figure 4. An example of each of the six word types
defined with Untied allophones for the After Vowel
experimental condition. Boundary allophones could
only be used to define three distinct word types, Accent
only two, and Tied only one.
</figureCaption>
<figure confidence="0.989295166666667">
0 370000 B4in
370000 760000 nineteen!
760000 1150000 seventy
1150000 1680000 sixB4
1680000 2310000 B4democratic!
2310000 2680000 governor
600000 1600000 w
1600000 2400000 aa!
2400000 2900000 n!
2900000 3800000 t
3800000 4900000 axB4
4900000 5300000 dB4
</figure>
<figureCaption confidence="0.94151075">
Figure 5a. An example Untied word level transcription
b. An example Untied phone level transcription for the
After Vowel accent condition. The transcribed word is
“wanted.”
</figureCaption>
<bodyText confidence="0.99771925">
separated into a fourth group of their own, entitled
Vowels. The four groups along with the four different
allophone models lead to the sixteen experimental
conditions illustrated in figure 3.
</bodyText>
<subsectionHeader confidence="0.994912">
3.3 Dictionaries and Transcription Types
</subsectionHeader>
<bodyText confidence="0.999713">
Each experimental condition required its own dictionary
and transcription. Just as each phoneme had six distinct
allophones, each word had six distinct types. A word
could be phrase initial, medial or final and accented or
unaccented. Each word type had its own definition.
An example dictionary is shown in figure 4.
Every experimental condition had both a word
level transcription and a phone level transcription.
Figure 5 shows an example of the two different levels of
transcription files.
</bodyText>
<sectionHeader confidence="0.989416" genericHeader="method">
4. Experiments
</sectionHeader>
<table confidence="0.999656733333333">
All Consonants After Vowel Before Vowel Vowels
Merge Separate Merge Separate Merge Separate Merge Separate
ch b dhB4 b B4d b aoB4 aa
dB4, B4b gB4 ch B4f B4b ax aaB4
B4d d jhB4 d B4g ch B4eh B4aa
dhB4 dh kB4 dB4 B4k d B4ey ae
B4dh f lB4 dh B4m dh B4ow aeB4
fB4 g mB4 f B4n f uh B4ae
B4f hh nB4 fB4 B4p g uhB4 ah
gB4 jh pB4 g B4s hh B4uh ahB4
B4g jhB4 pB4 jh B4w B4hh B4uw ao
jhB4 k sB4 k z jh aoB4
kB4 l sh l k aw
B4k m tB4 m l ay
lB4 n v n m ayB4
mB4 nB4 p n eh
B4m p r p ehB4
pB4 r rB4 r ey
B4p rB4 s B4r eyB4
sB4 B4r sh s ih
B4s s t sh ihB4
tB4 sh vB4 t B4ih
v t y B4t iy
B4w tB4 z v iyB4
z vB4 zB4 w B4iy
B4v y ow
w owB4
y oy
zB4 uw
uwB4
</table>
<tableCaption confidence="0.998906">
Table 1. The results of
</tableCaption>
<bodyText confidence="0.990929466666667">
experiments for the Accented
allophone sets. The &amp;quot;Merge&amp;quot;
column lists phonemes with
WA ≥ LL. The &amp;quot;Separate&amp;quot;
column indicates phonemes
where WA &lt; LL. Due to the
relatively small size of the
data set, several phonemes
are missing from the table.
Experiments were performed using the Hidden
Markov Toolkit (HTK), which is distributed by the
University of Cambridge (2002). Phonemes were
modeled using a three-state HMM with no emitting start
and end states. Each emitting state consisted of three
mixture Gaussians and no state skipping was allowed.
</bodyText>
<subsectionHeader confidence="0.967585">
4.1 Experimental Procedure
</subsectionHeader>
<bodyText confidence="0.990166">
The Radio News Corpus data was divided into 2 sets: a
training set and a test set. The test set was
approximately 10% of the size of the training set. The
experimental procedure was completed for sixteen
experimental conditions.
The experimental procedure can be divided
into two steps. In step one, the training data was used to
re-estimate the HMM definitions for each phoneme.
Re-estimation was performed with the HTK tool HRest,
which uses Baum-Welsh re-estimation described in
detail in the HTK book available from Cambridge
University (2002). HMM parameters were re-estimated
until either the log likehood converged or HRest had
performed 100 iterations of the re-estimation algorithm.
In the second step of the experiments, HRest
was used to perform a single iteration of the re-
estimation algorithm on the test data using the HMM
definitions that were updated from the re-estimation of
the training set. During re-estimation, the log likehoods
of each phoneme were output and saved for later
comparisons.
</bodyText>
<subsectionHeader confidence="0.997479">
4.2 Post Processing
</subsectionHeader>
<bodyText confidence="0.999009333333333">
Once all the log likehoods had been recorded, the
Untied allophone sets were used as a basis to determine
if the considered monophones were better modeled as
prosody independent or prosody dependent. To
determine the best modeling strategy for a particular
monophone, six different weighted averages (WA’s)
were calculated from the Untied log likehoods and
compared to the computed log likehoods of the
Boundary, Accent and Tied models.
</bodyText>
<table confidence="0.981453666666667">
Initial Medial Final
Accented 1 3
Unaccented 2
Initial Medial Final
Accented 1 2 3
Unaccented 4 5 6
</table>
<figureCaption confidence="0.5575495">
Figure 6a. The proposed modeling of consonants.
1 = Strengthened, 2 = Neutral, 3 = Lengthened
b. The proposed modeling of Vowels. Numbers 1-6
indicate six different distinguishable prosodic types
</figureCaption>
<bodyText confidence="0.999713">
The following three formulas were used to calculate the
WA’s of the Untied set for comparison with the
Boundary set computed value:
</bodyText>
<equation confidence="0.989394">
WAPM = LphnWphn + L phn!Wphn!
WAPI = LB4phnWB4phn + LB4phn!WB4phn!
WAPF = L phnB4WphnB4 + LphnB4!WphnB4!
</equation>
<bodyText confidence="0.986907066666667">
where PM, PI, and PF stand for phrase medial, initial
and final, respectively. Lx represents the computed log
likehood of the allophone label x in the Untied
allophone set, and Wx represents the frequency of that x.
Wx, where x is representative of any of the six
types of prosodically labeled monophones, is computed
by the following formula:
Wx = numx / TOTAL
where numx represents the number of examples of the
token x, and TOTAL is the sum of all the different
phoneme tokens being taken into account for the
computation of WA of some set of phonemes.
The two formulas used in calculating the WA’s
for comparison with the Accent allophone set are as
follows:
</bodyText>
<equation confidence="0.9035205">
WAU = LphnWphn + LB4phnWB4phn + LphnB4WphnB4
WAA = Lphn!Wphn! + LB4phn!WB4phn! + LphnB4!WphnB4!
</equation>
<bodyText confidence="0.9994772">
where WAU and WAA are the weighted averages of log
likehoods for the accented and unaccented tokens
respectively.
The WA compared to the Tied set was
computed as follows:
</bodyText>
<equation confidence="0.717495">
WAT = Lphn!Wphn! + LB4phn!WB4phn! + LphnB4!WphnB4! +
LphnWphn + LB4phnWB4phn + LphnB4WphnB4
</equation>
<bodyText confidence="0.996076714285714">
where WAT is the weighted average of all of the
phonemes in the Untied model.
The weighted averages were then compared to
the log likehoods using the following algorithm:
if (WA &lt; LL), then split using prosodic labels
if (WA ≥ LL), then do not split using prosodic labels
LL is the log likehood computed using HRest.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
5. Results
</sectionHeader>
<bodyText confidence="0.999951258064516">
For each prosodic variable (phrasal position or accent),
tables were constructed listing the preferred tying of
phonemes based on the log likehood results. Table 1,
for example, lists all phonemes that should be tied on
the basis of accent and those that should not. Similar
tables exist for phrasal position and for the combination
of both accent and phrasal position. Examples of
certain phonemes are not present due to the relatively
small size of the data set.
Experimental results varied greatly between
consonants and vowels. For consonants, there appeared
to be an improvement in the model when phonemes are
distinguished by phrasal position. Separation of
accented and unaccented phrase initial consonants
yielded no improvement to the model for most
consonants. This implies that phrase initial accented
and phrase initial unaccented phonemes should be
merged into a single token. Accented consonants are
also not benefited by positional information. Results
indicate that phrase initial, medial and final accented
phonemes can be merged together. Figure 6a illustrates
a proposed model for the prosodic labeling of
consonants based on these results.
For vowels, a model showed improvement
when the phoneme was separated into phrase initial,
medial and final tokens. Vowel phoneme models also
showed improvement when separated by accent. The
accent on a vowel appears to be important regardless of
phrasal position. These results suggest a six-way
distinction should be used when modeling vowels and
the proposed model is illustrated in figure 6b.
</bodyText>
<sectionHeader confidence="0.999448" genericHeader="conclusions">
6. Conclusion
</sectionHeader>
<bodyText confidence="0.990380083333333">
While the data used for these experiments was sparse
for certain phonemes, many of the phoneme models
tested showed improvement when prosody was
incorporated directly into the HMM definition.
Analysis of experimental results led to two different
proposals for the modeling of consonants and vowels.
Verifying that the proposed models are indeed an
improvement over standard phoneme modeling will be a
goal of future work.
Fougeron, P. &amp; Keating, P. 1997 “Articulatory
strengthening at edges of prosodic domains,” JASA
101(6), pp. 3728-3740.
</bodyText>
<sectionHeader confidence="0.996351" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997732333333333">
This work could not have been completed without the
help and guidance of Professor Mark Hasegawa-
Johnson and Professor Jennifer Cole.
</bodyText>
<sectionHeader confidence="0.989242" genericHeader="references">
7. References
</sectionHeader>
<reference confidence="0.997652956521739">
Cho, T. 2001 Effects of Prosody on Articulation in
English. Ph.D. dissertation, UCLA.
De Jong, Kenneth (1995) “The supraglottal articulation
of prominence in English: Linguistic stress as localized
hyperarticulation,” JASA, vol.97(1), pp. 491-504.
Edwards, Jan. Beckman, Mary, &amp; Fletcher, Janet. 1991
“The articulatory kinematics of final lengthening,”
JASA 89(1), pp. 369-382.
Ostendorf, M., Price, P.J., Shattuck-Hufnagel, S. 1995.
“The Boston University Radio News Corpus,” Boston
University Technical Report No ECS-95-001,
&lt;http://ssli.ee.Washington.edu/papers/radionews-
tech.ps&gt;.
Silverman, K., Beckman, M., Pitrelli, J., Ostendorf, M.
Wighnman, C. Price, P., Pierrehumbert, J., Hirschberg,
J., 1992, “ToBI, a standard for labeling English”
ICSLP, vol. 2, pp867-870
The University of Cambridge Engineering Department,
2002. “http://htk.eng.cam.ac.uk/”.
Wightman, C. W., Shattuck-Hufnagel, S., Ostendorf,
M., &amp; Price, P. J. 1992. “Segmental durations in the
vicinity of prosodic phrase boundaries,” J. Acoust. Soc.
Am., vol. 91, no. 3, pp 1707-17
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.756061">
<note confidence="0.967327666666667">Proceedings of HLT-NAACL 2003 Student Research Workshop , pp. 7-12 Edmonton, May-June 2003</note>
<title confidence="0.998907">The Importance of Prosodic Factors in Phoneme Modeling with Applications to Speech Recognition</title>
<author confidence="0.999897">Sarah Borys</author>
<affiliation confidence="0.999933">Department of Electrical and Computer Engineering</affiliation>
<address confidence="0.942453">University of Illinois at Urbana-Champaign, Urbana, IL 61901</address>
<abstract confidence="0.992455133333333">This paper tests speech recognition using prosody dependent allophone models. The log likehoods of various prosodically labeled phonemes are calculated using Baum-Welsh re-estimation. These likehoods are then compared to log likehoods of non-prosodically labeled phonemes. Based on the comparison of these log likehoods, it can be concluded that modeling all prosodic information directly in the vowel model leads to improvement in the model. Consonants, on the other hand, split naturally into three categories, strengthened, lengthened and neutral.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Cho</author>
</authors>
<date>2001</date>
<booktitle>Effects of Prosody on Articulation in English. Ph.D. dissertation, UCLA.</booktitle>
<contexts>
<context position="1183" citStr="Cho (2001)" startWordPosition="169" endWordPosition="170">lly labeled phonemes. Based on the comparison of these log likehoods, it can be concluded that modeling all prosodic information directly in the vowel model leads to improvement in the model. Consonants, on the other hand, split naturally into three categories, strengthened, lengthened and neutral. 1. Introduction Prosody is an important factor in how humans interpret speech. The same word string can have different meanings depending on the way it is said. Many linguists have performed extensive studies of prosody and of the effects of prosodic factors on spoken language. In his dissertation, Cho (2001) investigates how phonetic features are conditioned by prosodic factors by examining pre-boundary, post-boundary, and accented syllables. Cho reports that boundary induced articulatory strengthening occurs in phrase final vowel positions and phrase initial consonant positions. Phrase initial vowels are also more susceptible to coarticulation than phrase final vowels. Cho also hypothesizes that accented syllables are characterized primarily by sonority expansion. An accented vowel is usually not affected by coarticulation with a neighboring vowel. Strengthening effects caused by boundaries and </context>
</contexts>
<marker>Cho, 2001</marker>
<rawString>Cho, T. 2001 Effects of Prosody on Articulation in English. Ph.D. dissertation, UCLA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth De Jong</author>
</authors>
<title>The supraglottal articulation of prominence in English: Linguistic stress as localized hyperarticulation,”</title>
<date>1995</date>
<journal>JASA,</journal>
<volume>97</volume>
<issue>1</issue>
<pages>491--504</pages>
<marker>De Jong, 1995</marker>
<rawString>De Jong, Kenneth (1995) “The supraglottal articulation of prominence in English: Linguistic stress as localized hyperarticulation,” JASA, vol.97(1), pp. 491-504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Beckman</author>
<author>Janet Fletcher</author>
</authors>
<title>The articulatory kinematics of final lengthening,”</title>
<date>1991</date>
<journal>JASA</journal>
<volume>89</volume>
<issue>1</issue>
<pages>369--382</pages>
<marker>Beckman, Fletcher, 1991</marker>
<rawString>Edwards, Jan. Beckman, Mary, &amp; Fletcher, Janet. 1991 “The articulatory kinematics of final lengthening,” JASA 89(1), pp. 369-382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ostendorf</author>
<author>P J Price</author>
<author>S Shattuck-Hufnagel</author>
</authors>
<date>1995</date>
<tech>Technical Report No ECS-95-001,</tech>
<institution>The Boston University Radio News Corpus,” Boston University</institution>
<marker>Ostendorf, Price, Shattuck-Hufnagel, 1995</marker>
<rawString>Ostendorf, M., Price, P.J., Shattuck-Hufnagel, S. 1995. “The Boston University Radio News Corpus,” Boston University Technical Report No ECS-95-001, &lt;http://ssli.ee.Washington.edu/papers/radionewstech.ps&gt;.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Silverman</author>
<author>M Beckman</author>
<author>J Pitrelli</author>
<author>M Wighnman Ostendorf</author>
<author>C Price</author>
<author>P Pierrehumbert</author>
<author>J Hirschberg</author>
<author>J</author>
</authors>
<title>ToBI, a standard for labeling English”</title>
<date>1992</date>
<journal>ICSLP,</journal>
<volume>2</volume>
<pages>867--870</pages>
<contexts>
<context position="6988" citStr="Silverman et al (1992)" startWordPosition="1072" endWordPosition="1075"> speakers from this corpus that were analyzed were F1A, F2B, and M2B. The usable data from these three speakers consisted of 259 phn : phrase medial phn! : phrase medial, accented phnB4 : phrase final, unaccented phnB4! : phrase final, accented B4phn : phrase initial, unaccented B4phn! : phrase initial, accented Figure 2. The different prosodic labels. “Phn” represents some generic phoneme. wav files containing 18270 words. All the wav files that were used were accompanied by two types of prosodic transcription files, .brk and .ton files. The corpus was labeled according to the ToBI standard. Silverman et al (1992) explain the labeling system in detail. It will not be described in this paper. The .brk files specify a ToBI break index (0-4) for every spoken word in the associated wav file. For the experiments, the only boundary distinguished was the intonational phrase boundary (ToBI index 4). All other boundary types (indices 0-3) were grouped together. There were 3855 intonational phrase boundaries in the data set. The .ton files label the times in which an accented vowel occurs. The most abundant accent label was H* which occurs in a ratio of about 10 H* for every single L*. Other accent types do occu</context>
</contexts>
<marker>Silverman, Beckman, Pitrelli, Ostendorf, Price, Pierrehumbert, Hirschberg, J, 1992</marker>
<rawString>Silverman, K., Beckman, M., Pitrelli, J., Ostendorf, M. Wighnman, C. Price, P., Pierrehumbert, J., Hirschberg, J., 1992, “ToBI, a standard for labeling English” ICSLP, vol. 2, pp867-870</rawString>
</citation>
<citation valid="false">
<date>2002</date>
<institution>The University of Cambridge Engineering Department,</institution>
<note>http://htk.eng.cam.ac.uk/”.</note>
<contexts>
<context position="12637" citStr="(2002)" startWordPosition="2054" endWordPosition="2054">ay lB4 n v n m ayB4 mB4 nB4 p n eh B4m p r p ehB4 pB4 r rB4 r ey B4p rB4 s B4r eyB4 sB4 B4r sh s ih B4s s t sh ihB4 tB4 sh vB4 t B4ih v t y B4t iy B4w tB4 z v iyB4 z vB4 zB4 w B4iy B4v y ow w owB4 y oy zB4 uw uwB4 Table 1. The results of experiments for the Accented allophone sets. The &amp;quot;Merge&amp;quot; column lists phonemes with WA ≥ LL. The &amp;quot;Separate&amp;quot; column indicates phonemes where WA &lt; LL. Due to the relatively small size of the data set, several phonemes are missing from the table. Experiments were performed using the Hidden Markov Toolkit (HTK), which is distributed by the University of Cambridge (2002). Phonemes were modeled using a three-state HMM with no emitting start and end states. Each emitting state consisted of three mixture Gaussians and no state skipping was allowed. 4.1 Experimental Procedure The Radio News Corpus data was divided into 2 sets: a training set and a test set. The test set was approximately 10% of the size of the training set. The experimental procedure was completed for sixteen experimental conditions. The experimental procedure can be divided into two steps. In step one, the training data was used to re-estimate the HMM definitions for each phoneme. Re-estimation </context>
</contexts>
<marker>2002</marker>
<rawString>The University of Cambridge Engineering Department, 2002. “http://htk.eng.cam.ac.uk/”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Wightman</author>
<author>S Shattuck-Hufnagel</author>
<author>M Ostendorf</author>
<author>P J Price</author>
</authors>
<title>Segmental durations in the vicinity of prosodic phrase boundaries,”</title>
<date>1992</date>
<journal>J. Acoust. Soc. Am.,</journal>
<volume>91</volume>
<pages>1707--17</pages>
<contexts>
<context position="3395" citStr="Wightman et al (1992)" startWordPosition="482" endWordPosition="485">ss stops was observed along with an increase in duration of prevoicing in initial voiced stops in stressed syllables. Fougeron and Keating (1997) report that on the edges of prosodic phrase boundaries, final vowels and initial consonants have less reduced lingual articulation. The differences in articulation were manifested in the linguopalatal contact of boundary consonants and vowels. The linguopalatal contact of both consonants and vowels relates directly to the type and size of phrase boundary. Boundary type and size also appear to effect the acoustic duration of post-boundary consonants. Wightman et al (1992) report that there is segmental lengthening in the rhyme of a syllable that directly precedes a phrase boundary. Wightman examines the effect of duration and pause on boundary words and shows that speaking rate effects the distribution of phoneme duration. The lengthening effects of pre-boundary syllables can be used to distinguish several different types of phrase boundaries. These results show that prosody can cause variations not just in pitch, but also in the articulation of phonetic contrasts in different phonemes. These variations can be modeled as a part of the phoneme definition in an </context>
</contexts>
<marker>Wightman, Shattuck-Hufnagel, Ostendorf, Price, 1992</marker>
<rawString>Wightman, C. W., Shattuck-Hufnagel, S., Ostendorf, M., &amp; Price, P. J. 1992. “Segmental durations in the vicinity of prosodic phrase boundaries,” J. Acoust. Soc. Am., vol. 91, no. 3, pp 1707-17</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>