<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9972905">
What do We Know about Conversation Participants: Experiments on
Conversation Entailment
</title>
<author confidence="0.999822">
Chen Zhang Joyce Y. Chai
</author>
<affiliation confidence="0.9963315">
Department of Computer Science and Engineering
Michigan State University
</affiliation>
<address confidence="0.935527">
East Lansing, MI 48824, USA
</address>
<email confidence="0.998785">
{zhangch6, jchai}@cse.msu.edu
</email>
<sectionHeader confidence="0.993865" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999757388888889">
Given the increasing amount of conversa-
tion data, techniques to automatically ac-
quire information about conversation par-
ticipants have become more important.
Towards this goal, we investigate the prob-
lem of conversation entailment, a task
that determines whether a given conversa-
tion discourse entails a hypothesis about
the participants. This paper describes
the challenges related to conversation en-
tailment based on our collected data and
presents a probabilistic framework that in-
corporates conversation context in entail-
ment prediction. Our preliminary exper-
imental results have shown that conver-
sation context, in particular dialogue act,
plays an important role in conversation en-
tailment.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928321428571">
Conversation is a joint activity between its partic-
ipants (Clark, 1996). Their goals and their under-
standing of mutual beliefs of each other shape the
linguistic discourse of conversation. In turn, this
linguistic discourse provides tremendous informa-
tion about conversation participants. Given the
increasing amount of available conversation data
(e.g., conversation scripts such as meeting scripts,
court records, and online chatting), an important
question is what do we know about conversation
participants? The capability to automatically ac-
quire such information can benefit many appli-
cations, for example, development of social net-
works and discovery of social dynamics.
Related to this question, previous work has de-
veloped techniques to extract profiling informa-
tion about participants from conversation inter-
views (Jing et al., 2007) and to automatically iden-
tify dynamics between conversation participants
such as agreement/disagreement from multiparty
meeting scripts (Galley et al., 2004). We approach
this question from a different angle as a conversa-
tion entailment problem: given a conversation dis-
course D and a hypothesis H concerning its par-
ticipant, the goal is to identify whether D entails
H. For instance, in the following example, the first
hypothesis can be entailed from the dialogue seg-
ment while the second hypothesis cannot.
</bodyText>
<figure confidence="0.723327857142857">
Example 1:
Dialogue Segment:
A: And where about were you born?
B: Up in Person Country.
Hypothesis:
(1) B was born in Person Country.
(2) B lives in Person Country.
</figure>
<bodyText confidence="0.996077625">
Inspired by textual entailment (Dagan et al.,
2005; Bar-Haim et al., 2006; Giampiccolo et al.,
2007), conversation entailment provides an inter-
mediate step towards acquiring information about
conversation participants. What we should know
or would like to know about a participant can be
rather open. The type of information needed about
participants is also application-dependent and dif-
ficult to generalize. In conversation entailment, we
will not face this problem since hypotheses can be
used to express any type of information about a
participant one might be interested in. Although
hypotheses are currently given in our investiga-
tion, they can potentially be automatically gener-
ated based on information needs and/or theories
on cognitive status/mental models of conversation
participants. The capability to make correct entail-
ment judgements based on these hypotheses will
benefit many applications such as information ex-
traction, question answering, and summarization.
As a first step in our investigation, we collected
a corpus of conversation entailment data from
nineteen human annotators. Our data showed that
conversation entailment is more challenging than
</bodyText>
<note confidence="0.709924">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 206–215,
</note>
<affiliation confidence="0.662724">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.999022">
206
</page>
<bodyText confidence="0.999946625">
the textual entailment task due to unique charac-
teristics about conversation and conversational im-
plicature. To predict entailment, we developed a
probabilisitic framework that incorporates seman-
tic representation of conversation context. Our
preliminary experimental results have shown that
conversation context, in particular dialogue acts,
play an important role in conversation entailment.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999929444444444">
Recent work has applied different approaches
to acquire information about conversation par-
ticipants based on human-human conversation
scripts, for example, to extract profiling infor-
mation from conversation interviews (Jing et al.,
2007) and to identify agreement/disagreement
between participants from multiparty meeting
scripts (Galley et al., 2004). In human-machine
conversation, inference about conversation partic-
ipants has been studied as a part of user modeling.
For example, earlier work has investigated infer-
ence of user intention from utterances to control
clarification dialogue (Horvitz and Paek, 2001)
and recognition of user emotion and attitude from
utterances for intelligent tutoring systems (Litman
and Forbes-Riley, 2006). In contrast to previous
work, we propose a new angle to address informa-
tion acquisition about conversation participants,
namely, through conversation entailment.
This work is inspired by a large body of recent
work on textual entailment initiated by the PAS-
CAL RTE Challenge (Dagan et al., 2005; Bar-
Haim et al., 2006; Giampiccolo et al., 2007). Nev-
ertheless, conversation discourse is very different
from written monologue discourse. The conversa-
tion discourse is shaped by the goals of its partici-
pants and their mutual beliefs. The key distinctive
features include turn-taking between participants,
grounding between participants, and different lin-
guistic phenomena of utterances (e.g., utterances
in conversation tend to be shorter, with disfluency,
and sometimes incomplete or ungrammatical). It
is the goal of this paper to explore how techniques
developed for textual entailment can be extended
to address these unique behaviors in conversation
entailment.
</bodyText>
<sectionHeader confidence="0.99597" genericHeader="method">
3 Experimental Data
</sectionHeader>
<bodyText confidence="0.97657925">
The first step in our investigation is to collect en-
tailment data to help us better understand the prob-
lem and facilitate algorithm development and eval-
uation.
</bodyText>
<subsectionHeader confidence="0.998482">
3.1 Data Collection Procedure
</subsectionHeader>
<bodyText confidence="0.999296829787234">
We selected 50 dialogues from the Switchboard
corpus (Godfrey and Holliman, 1997). In each of
these dialogues, two participants discuss a topic
of interest (e.g., sports activities, corporate cul-
ture, etc.). To focus our work on the entailment
problem, we use the transcribed scripts of the di-
alogues in our experiments. We also make use of
available annotations such as syntactic structures,
disfluency markers, and dialogue acts.
We had 15 volunteer annotators read the se-
lected dialogues and create hypotheses about par-
ticipants. As a result, a total of 1096 entailment
examples were created. Each example consists of
a snippet from the dialogue (referred to as dia-
logue segment in the rest of this paper), a hypothe-
sis statement, and a truth value indicating whether
the hypothesis can be inferred from the snippet
given the whole history of that dialogue session.
During annotation, we asked the annotators to pro-
vide balanced examples for each dialogue. That is,
roughly half of the hypotheses are truly entailed
and half are not. Special attention was given to
negative entailment examples. Since any arbitrary
hypotheses that are completely irrelevant can be
negative examples, a special criteria is enforced
that any negative examples should have a major-
ity word overlap with the snippet. In addition, in-
spired by previous work (Jing et al., 2007; Galley
et al., 2004), we particularly asked annotators to
provide hypotheses that address the profiling in-
formation of the participants, their opinions and
desires, as well as the dynamic communicative re-
lations between participants.
A recent study shows that for many NLP an-
notation tasks, the reliability of a small number
of non-expert annotations is on par with that of
an expert annotator (Snow et al., 2008). It also
found that for tasks such as affection recogni-
tion, an average of four non-expert labels per item
are capable of emulating expert-level label qual-
ity. Based on this finding, in our study the en-
tailment judgement for each example was further
independently annotated by four annotators (who
were not the original contributors of the hypothe-
ses). As a result, on average each entailment ex-
ample (i.e., a pair of snippet and hypothesis) re-
ceived five judgements.
</bodyText>
<page confidence="0.998005">
207
</page>
<figureCaption confidence="0.94723">
Figure 1: Agreement histogram of entailment
judgements
</figureCaption>
<subsectionHeader confidence="0.999649">
3.2 Data and Examples
</subsectionHeader>
<bodyText confidence="0.999568888888889">
Figure 1 shows a histogram of the agreements of
collected judgements. It indicates that conversa-
tion entailment is in fact a quite difficult task even
for humans. Only 53% of all the examples (586
out of 1096) are agreed upon by all human annota-
tors. The disagreement between users sometimes
is caused by language ambiguity since conversa-
tion scripts are often short and without clear sen-
tence boundaries. For example,
</bodyText>
<equation confidence="0.5027285">
Example 2:
Dialogue Segment:
</equation>
<bodyText confidence="0.919101125">
A: Margaret Thatcher was prime minister, uh,
uh, in India, so many, uh, women are heads
of state.
Hypothesis:
A believes that Margaret Thatcher was prime
minister of India.
In the utterance of speaker A, the prepositional
phrase in India is ambiguous because it can either
be attached to the preceding sentence, which suffi-
ciently entails the hypothesis; or it can be attached
to the succeeding sentence, which leaves it unclear
which country A believes Margaret Thatcher was
prime minister of.
Difference in recognition and handling of con-
versational implicature is another issue that led to
disagreement among annotators. For example:
</bodyText>
<equation confidence="0.187639">
Example 3:
Dialogue Segment:
</equation>
<bodyText confidence="0.7705354">
A: Um, I had a friend who had fixed some, uh,
chili, buffalo chili and, about a week before
we went to see the movie.
Hypothesis:
A ate some buffalo chili.
</bodyText>
<figure confidence="0.586585875">
Example 4:
Dialogue Segment:
B: Um, I’ve visited the Wyoming area. I’m
not sure exactly where Dances with Wolves
was filmed.
Hypothesis:
B thinks Dances with Wolves was filmed in
Wyoming.
</figure>
<bodyText confidence="0.9999634375">
In the first example, a listener could assume
that A follows the maxim of relevance. Therefore,
a natural inference that makes “fixing of buffalo
chili” relevant is that A ate the buffalo chili. Sim-
ilarly, in the second example, the speaker A men-
tions a visit to Wyoming, which can be considered
relevant to the filming place of DANCES WITH
WOLVES. Some annotators recognized such rele-
vance and some did not.
Given the discrepencies between annotators, we
selected 875 examples which have at least 75%
agreement among the judgements in our current
investigation. We further selected one-third of this
data (291 examples) as our development data. The
experiments reported in Section 5 are based on this
development set.
</bodyText>
<subsectionHeader confidence="0.999966">
3.3 Types of Hypotheses
</subsectionHeader>
<bodyText confidence="0.99961176">
The hypotheses collected from our study can be
categorzied into the following four types:
Fact. Facts about the participants. This includes:
(1) profiling information about individual partici-
pants (e.g., occupation, birth place, etc.); (2) activ-
ities associated with individual participants (e.g.,
A bikes to work everyday); and (3) social rela-
tions between participants (e.g., A and B are co-
workers, A and B went to college together).
Belief. Participants’ beliefs and opinions about the
physical world. Any statement about the physical
world in fact is a belief of the speaker. Technically,
the state of the physical world that involves the
speaker him/herself is also a type of belief. How-
ever, here we assume a statement about oneself is
true and is considered as a fact.
Desire. Participants’ desire of certain actions or
outcomes (e.g., A wants to find a university job).
These desires represent the states of the world the
participant finds pleasant (although they could be
conflicting to each other).
Intent. Participants’ deliberated intent, in partic-
ular communicative intention which captures the
intent from one participant on the other partici-
pant such as whether A agrees/disagrees with B
</bodyText>
<page confidence="0.990111">
208
</page>
<bodyText confidence="0.998526722222222">
= P(d1 ... dm �= h1 ... hn|d1,..., dm, h1,...,hn)
= P(D I-- h1, ... , D I-- hn|D, h1, ... , hn)
on some issue, whether A intends to convince B
on something, etc.
Most of these types are motivated by the Belief-
Desire-Intention (BDI) model, which represents
key mental states and reflects the thoughts of
a conversation participant. Desire is different
from intention. The former arises subconsciously
and the latter arise from rational deliberation that
takes into consideration desires and beliefs (Allen,
1995). The fact type represents the facts about
a participant. Both thoughts and facts are criti-
cal to characterize a participant and thus impor-
tant to serve many other downstream applications.
The above four types account for 47.1%, 34.0%,
10.7%, and 8.2% of our development set respec-
tively.
</bodyText>
<sectionHeader confidence="0.99685" genericHeader="method">
4 A Probabilistic Framework
</sectionHeader>
<bodyText confidence="0.999914666666667">
Following previous work (Haghighi et al., 2005;
de Salvo Braz et al., 2005; MacCartney et al.,
2006), we approach conversation entailment using
a probabilistic framework. To predict whether a
hypothesis statement H can be inferred from a di-
alogue segment D, we estimate the probability
</bodyText>
<equation confidence="0.871757">
P(D [-- H|D, H)
</equation>
<bodyText confidence="0.999946615384615">
Suppose we have a representation of a dia-
logue segment D in m clauses d1, ... , dm and a
representation of the hypothesis H in n clauses
h1, ... , hn. Since a hypothesis is the conjunc-
tion of the decomposed clauses, whether it can be
inferred from a segment is equivalent to whether
all of its clauses can be inferred from the seg-
ment. We further simplify the problem by assum-
ing that whether a clause is entailed from a dia-
logue segment is conditionally independent from
other clauses. Note that this conditional indepen-
dence assumption is an over-simplification, but it
gets things started. Therefore:
</bodyText>
<equation confidence="0.996937428571429">
P(D I-- H|D, H)
n
= H P(D �= hj|D = d1 ... dm, hj)
j=1
n
= H P(d1 ... dm �= hj|d1,..., dm, hj) (1)
j=1
</equation>
<bodyText confidence="0.999805">
If this likelihood is above a certain threshold
(e.g., 0.5 in our experiments), then H is consid-
ered as a true entailment from D.
Given this framework, two important questions
are: (1) how to represent and automatically create
the clauses from each pair of dialogue segment and
hypothesis; and (2) how to estimate probabilities
as shown in Equation 1?
</bodyText>
<subsectionHeader confidence="0.996656">
4.1 Clause Representation
</subsectionHeader>
<bodyText confidence="0.997738386363636">
Our clause representation is inspired by previ-
ous work on textual entailment (Dagan et al.,
2005; Bar-Haim et al., 2006; Giampiccolo et al.,
2007). Clause representation has several advan-
tages. First, it can be acquired automatically from
a parse tree (e.g., dependency parser). Second,
it can be used to facilitate both logic-based rea-
soning as in (Tatu and Moldovan, 2005; Bos and
Markert, 2005; Raina et al., 2005) or probabilis-
tic reasoning as in (Haghighi et al., 2005; de
Salvo Braz et al., 2005; MacCartney et al., 2006).
The key difference between our work and previ-
ous work on textual entailment is the representa-
tion of conversation discourse, which has not been
considered in previous work but is important for
conversation entailment, as we will see later.
More specifically, a clause is made up by two
components: Term and Predicate.
Term: A term can be an entity or an event. An
entity refers to a person, a place, an organization,
or other real world entities. This follows the con-
cept of mention in the Automatic Content Extrac-
tion (ACE) evaluation (Doddington et al., 2004).
An event refers to an action or an activity. For
example, from the sentence “John married Eva in
1940” we can identify an event of marriage. Fol-
lowing the neo-Davidsonian representation (Par-
sons, 1990), all the events are reified as terms in
our representation.
Predicate: A predicate represents either a prop-
erty (i.e., unary) for a term or a relation (i.e., bi-
nary) between two terms. For example, an entity
company has a property of Russian as in the phrase
“a Russian company” (i.e., Russian(company)).
An event visit has a property of recently (i.e.,
recently(visit)) as in the phrase “visit Brazil re-
cently”. From the phrase “Prime Minister re-
cently visited Brazil”, there are binary relations:
Prime Minister is the subject of the event visit (i.e.,
subj(visit, Prime Minister)) and Brazil is the
object of the visit (i.e., obj(visit, Brazil)).
This representation is a direct conversion from
the dependency structure and can be used to rep-
resent the semantics of utterances in the dialogue
</bodyText>
<page confidence="0.993693">
209
</page>
<bodyText confidence="0.905187">
segments and the semantics of hypotheses. For ex-
ample,
</bodyText>
<figure confidence="0.627058">
Example 5:
Dialogue Segment:
B: Have you seen Sleeping with the Enemy?
A: No. I’ve heard that’s really great, though.
B: You have to go see that one.
Hypothesis:
B suggests A to watch Sleeping with the Enemy.
</figure>
<bodyText confidence="0.992936666666667">
Appendix A shows the dependency structure of
the dialogue utterances and the hypothesis from
Example 5. Appendix B shows the correspond-
ing clause representation of the dialogue segment
and the hypothesis. Note that in this represen-
tation, you and I are replaced with the respec-
tive participants. Since the clauses are generated
based on parse trees, most relational predicates are
syntactic-driven.
To facilitate conversation entailment, we fur-
ther augment the representation of a dialogue seg-
ment by incorporating conversation context. Ap-
pendix C shows the augmented representation for
Example 5. It represents the following additional
information:
</bodyText>
<listItem confidence="0.997581076923077">
• Utterance: A group of pseudo terms u1,
u2, ... are used to represent individual utter-
ances.
• Participant: A relational clause
speaker(·, ·) is used to represent the speaker
of this utterance, e.g., speaker(u1, B).
• Content: A relational clause content(·, ·) is
used to represent the content of an utterance
where the second term is the head of the ut-
terance as identified in the parsing structure.
e.g., content(u3, heard)
• Dialogue act: A relational clause act(·, ·)
is used to represent the dialogue act of the
</listItem>
<bodyText confidence="0.931923545454545">
speaker for a particular utterance. e.g.,
act(u2, no answer). A set of 42 dialogue
acts from the Switchboard annotation are
used here (Godfrey and Holliman, 1997).
• Utterance flow: A relational clause
follow(·, ·) is used to connect each pair of
adjacent utterances. e.g., follow(u2,u1).
We currently do not consider overlap in utter-
ances, but our representation can be modified
to handle this situation by introducing
additional predicates.
</bodyText>
<subsectionHeader confidence="0.967986">
4.2 Entailment Prediction
</subsectionHeader>
<bodyText confidence="0.9997008">
Given the clause representation for a conversation
segment and a hypothesis, the next step is to make
an entailment prediction (as in Equation 1) based
on two models: an Alignment Model and an Infer-
ence Model.
</bodyText>
<subsubsectionHeader confidence="0.4256">
4.2.1 Alignment Model
</subsubsectionHeader>
<bodyText confidence="0.99984709375">
The alignment model is to find alignments (or
matches) between terms in the clause representa-
tion for a hypothesis and those in the clause rep-
resentation for a conversation segment. We define
an alignment as a mapping function g between a
term x in the dialogue segment and a term y in the
hypothesis. g(x, y) = 1 if x and y are aligned;
otherwise g(x, y) = 0. Note that a verb can be
aligned to a noun as in g(sell, sale) = 1. It is also
possible that there are multiple terms from the seg-
ment mapped to one term in the hypothesis, or vice
versa.
For any two terms x and y, the problem of pre-
dicting the alignment function g(x, y) can be for-
mulated as a binary classification problem. We
used several features to train the classifier, which
include whether x and y are the same (or have the
same stem), whether one term is an acronym of the
other, and their WordNet and distributional simi-
larities (Lin, 1998).
Given an augmented representation with con-
versation context (as in Appendix C), we also
align event terms in the hypothesis (e.g., suggest
in Example 5) to (pseudo) utterance terms in the
dialogue segment. We call it a pseudo alignment.
This is currently done by a set of rules which asso-
ciate event terms in the hypotheses with dialogue
acts. For example, the event term suggest may be
aligned to an utterance with dialogue act of opin-
ion. Appendix D gives a correct alignment for Ex-
ample 5, in which g(u4, x1) = 1 is a pseudo align-
ment.
</bodyText>
<sectionHeader confidence="0.627702" genericHeader="method">
4.2.2 Inference Model
</sectionHeader>
<bodyText confidence="0.9996523">
As shown in Equation 1, to predict the infer-
ence of the entire hypothesis, we need to calculate
the probability that the dialogue segment entails
each clause from the hypothesis. More specifi-
cally, given a clause from the hypothesis hj, a set
of clauses from the dialogue segment d1, ... , dm,
and an alignment function g between them derived
by the method described in Section 4.2.1, we pre-
dict whether d1, ... , dm entails hj under the align-
ment g using two different classification models,
</bodyText>
<page confidence="0.995849">
210
</page>
<bodyText confidence="0.998050230769231">
depending on whether hj is a property or a rela-
tion (i.e. whether it takes one argument (hj(·)) or
two arguments (hj(·, ·))):
Given a property clause from the hypothe-
sis, hj(x), we look for all the property clauses
in the dialogue segment that describes the
same term as x, i.e. a clause set D&apos; =
{dz(x&apos;)|dz(x&apos;) ∈ D,g(x&apos;,x) = 1}. Then we pre-
dict whether hj(x) can be inferred from the
clauses in D&apos; by binary classification, using a set
of features similar to those used in the alignment
model.
Given a relational clause from the hypothe-
sis, hj(x, y), we look for the relation between
the counterparts of x and y in the dialogue seg-
ment. That is, we find the set of terms X&apos; =
{x&apos;|x&apos; ∈ D, g(x&apos;, x) = 1} and the set of terms
Y &apos; = {y&apos;|y&apos; ∈ D, g(y&apos;, y) = 1} and look for the
closest relation between these two sets of terms in
the dependency structure. If there is a path be-
tween any x&apos; ∈ X&apos; and any y&apos; ∈ Y &apos; in the de-
pendency structure with a length smaller than a
threshold AL, we predict that hj(x, y) can be in-
ferred. Note that our current handling of the re-
lational clauses is rather simplified. It only cap-
tures whether two terms from an hypothesis are
connected by any relation in the dialogue segment.
Appendix E shows the inference procedure of
the four hypothesis clauses in Example 5. For
each relational clause hj(x, y), the shortest path
between the corresponding X&apos; and Y &apos; has a length
of 3 or less, so each of these four clauses is en-
tailed from the dialogue segment. Based on Equa-
tion 1 we can conclude that the overall hypothesis
is entailed.
We trained the alignment model and the in-
ference model (e.g.,the threshold AL) based on
the development data provided by the PASCAL 3
challenges on textual entailment.
</bodyText>
<sectionHeader confidence="0.996296" genericHeader="method">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999613">
To understand unique behaviors of conversation
entailment, we focused our current experiments
on the development dataset (see Section 3.2).
We are particularly interested in how the tech-
niques for textual entailment can be improved for
conversation entailment. To do so, we applied
our entailment framework on the test data of the
PASCAL-3 RTE Challenge (Giampiccolo et al.,
2007). Among 800 testing examples, our ap-
proach achieved an accuracy of 60.6%. This re-
sult is on par with the performance of the me-
dian system of accuracy 61.8% (z-test, p=0.63) in
the PASCAL-3 RTE Challenge. Our current ap-
proach is very lean on the use of external knowl-
edge. Its competitive performance sets up a rea-
sonable baseline for our investigation on conversa-
tion entailment. This same system, modified to tai-
lor linguistic characteristics of conversation (e.g.,
removal of disfluency), was used as the baseline in
our experiments.
</bodyText>
<subsectionHeader confidence="0.995354">
5.1 Event Alignment
</subsectionHeader>
<bodyText confidence="0.999983179487179">
To understand the effect of conversation context
in the event alignment, we compared two configu-
rations of alignment model for events. The first
configuration is based on the clause representa-
tion of semantics of utterances (as shown in Ap-
pendix B). This is the same configuration as used
in textual entailment. The second configuration
is based on representation of both semantics from
utterances and conversation context (as shown in
Appendix C). We evaluate how well each config-
uration aligns the event terms based on the pair-
wise alignment decision: for any event term tH in
the hypothesis and any term tD in the dialogue,
whether the model can correctly predict that the
two terms should be aligned.
Figure 2(a) shows the comparison of F-measure
between the two models. Depending on the thresh-
old of alignment prediction, the precision and re-
call of the prediction vary. When the thresh-
old is lower, the models tend to give more align-
ments, resulting in lower precision and higher re-
call. When the threshold is higher, the models tend
to give fewer alignments, thus resulting in higher
precision but lower recall. When the threshold
is around 0.5, the alignment reaches its best F-
measure. Regardless of what threshold is cho-
sen, the model based on both utterance and con-
text consistently works better. Figure 2(b) shows
the breakdown based on the types of hypothesis (at
threshold 0.5). The model that incorporates con-
versation context consistently performs better for
all types. Its improvement is particularly signifi-
cant for the intent type of hypothesis.
These results are not surprising. Many event
terms in hypotheses (e.g., suggest, think, etc.) do
not have their counterparts directly expressed in
utterances in the dialogue discourse. Only through
the modeling of dialog acts, these terms can be
aligned to potential pseudo terms in the dialogue
</bodyText>
<page confidence="0.994948">
211
</page>
<table confidence="0.99907325">
System Acc Prec Recall F
Text 53.6% 71.6% 29.3% 41.6%
+Dialogue 58.4% 84.1% 32.3% 46.7%
+Context 67.7% 91.7% 47.0% 62.1%
</table>
<tableCaption confidence="0.690133">
Table 1: Experimental results on entailment pre-
diction
</tableCaption>
<bodyText confidence="0.993797620689655">
For each configuration we present two evalua-
tion metrics: an accuracy of the overall prediction
and a precision-recall measurement for the posi-
tive entailment examples. All the evaluations are
performed on our development data, which has
56.4% of positive examples and 43.6% of negative
examples.
The evaluations results are shown in Table 1.
The system learned from textual entailment per-
forms lower than the prediction based on the
majority class (56.4%). Incorporating syntactic
features of dialogues did better but the differ-
ence is not statistically significant. Incorporat-
ing conversation context, especially dialogue acts,
achieves significantly better performance (z-test,
p &lt; 0.005).
Table 2 shows the comparison of the three con-
figurations based on different types of hypothesis.
As expected, the basic system trained on textual
entailment is not capable for any intent type of
hypotheses. Modeling conversation context with
dialogue acts improves inference for all types of
hypothesis, with most significant improvement for
the belief, desire, and intent types of hypothesis.
segment. For the fact type hypotheses, the event
terms in the hypotheses generally have their coun-
terparts in the dialogue discourse. That explains
why the improvement for the fact type using con-
versation context is minimal.
</bodyText>
<figure confidence="0.990771333333333">
(a) Overall comparison on F-measure
(b) Comparison for different types of hypothesis
6 Conclusion
</figure>
<figureCaption confidence="0.997994">
Figure 2: Experimental results on event alignment
</figureCaption>
<subsectionHeader confidence="0.995173">
5.2 Entailment Prediction
</subsectionHeader>
<bodyText confidence="0.999994677419355">
Given correct alignments, we further evaluated
entailment prediction based on three configura-
tions of the inference model: (1) the same infer-
ence model learned from the textual entailment
data and tested on the PASCAL-3 RTE Challenge
(Text); (2) an improved model incorporating a
number of features relevant to dialogues (espe-
cially syntactic structure of utterances) based on
representations without conversation context as in
Appendix B (+Dialogue); (3) a further improved
model based on augmented representations of con-
versation context and using dialogue acts during
the prediction of entailment as in Appendix C
(+Context).
This paper describes our initial investigation on
conversation entailment to address information ac-
quisition about conversation participants. Since
there are so many variables involved in the pre-
diction, our experiments have been focused on a
set of development data where most of the features
are annotated. This allowed us to study the effect
of conversation context in both alignment and en-
tailment. Our future work will enhance the cur-
rent approach by training the models based on our
development data and evaluate them on the test-
ing data. Conversation entailment is an important
task. Although the current exercise is targeted to
process conversation scripts from human-human
conversation, it can potentially benefit human ma-
chine conversation by enabling automated agents
to gain better understanding of their conversation
</bodyText>
<page confidence="0.992434">
212
</page>
<table confidence="0.9998574">
Fact Belief Desire Intent
System Acc F Acc F Acc F Acc F
Text 58.4% 51.3% 52.5% 37.3% 51.6% 34.8% 33.3% 0
+Dialogue 68.6% 62.6% 53.5% 36.1% 48.4% 33.3% 33.3% 0
+Context 70.8% 64.9% 67.7% 62.8% 58.1% 47.8% 62.5% 60.9%
</table>
<tableCaption confidence="0.997994">
Table 2: Experimental results on entailment prediction for different types of hypotheses
</tableCaption>
<bodyText confidence="0.73762">
partners.
</bodyText>
<sectionHeader confidence="0.997371" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999813">
This work was partially supported by IIS-0347548
and IIS-0840538 from the National Science Foun-
dation. We thank the anonymous reviewers for
their valuable comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998948" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999062666666666">
James Allen. 1995. Natural language understanding.
The Benjamin/Cummings Publishing Company, Inc.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,
Danilo Giampiccolo, Bernardo Magnini, and Idan
Szpektor. 2006. The second pascal recognising
textual entailment challenge. In Proceedings of the
Second PASCAL Challenges Workshop on Recognis-
ing Textual Entailment, Venice, Italy.
Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of HLT-EMNLP, pages 628–635.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment
challenge. In PASCAL Challenges Workshop on
Recognising Textual Entailment.
Rodrigo de Salvo Braz, Roxana Girju, Vasin Pun-
yakanok, Dan Roth, and Mark Sammons. 2005. An
inference model for semantic entailment in natural
language. In Proceedings of AAAI.
G. Doddington, A. Mitchell, M. Przybocki, and
L. Ramshaw. 2004. The automatic content extrac-
tion (ace) programctasks, data, and evaluation. In
Proceedings of the 4th International Conference on
Language Resources and Evaluation (LREC).
Michel Galley, Kathleen McKeown, Julia Hirschberg,
and Elizabeth Shriberg. 2004. Identifying agree-
ment and disagreement in conversational speech:
Use of bayesian networks to model pragmatic de-
pendencies. In Proceedings ofACL, pages 669–676.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recogniz-
ing textual entailment challenge. In Proceedings of
the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing, pages 1–9.
John J. Godfrey and Edward Holliman. 1997.
Switchboard-1 Release 2. Linguistic Data Consor-
tium, Philadelphia.
Aria Haghighi, Andrew Ng, and Christopher Manning.
2005. Robust textual inference via graph matching.
In Proceedings of HLT-EMNLP, pages 387–394.
Eric Horvitz and Tim Paek. 2001. Harnessing mod-
els of users’ goals to mediate clarification dialog in
spoken language systems. In Proceedings of the 8th
International Conference on User Modeling, pages
3–13.
Hongyan Jing, Nanda Kambhatla, and Salim Roukos.
2007. Extracting social networks and biographical
facts from conversational speech transcripts. In Pro-
ceedings of ACL, pages 1040–1047.
Dekang Lin. 1998. An information-theoretic defini-
tion of similarity. In Proceedings of International
Conference on Machine Learning, pages 296–304.
Diane Litman and Katherine Forbes-Riley. 2006. Rec-
ognizing student emotions and attitudes on the basis
of utterances in spoken tutoring dialogues with both
human and computer tutors. Speech Communica-
tion, 48(5):559–590.
Bill MacCartney, Trond Grenager, Marie-Catherine
de Marneffe, Daniel Cer, and Christopher D. Man-
ning. 2006. Learning to recognize features of valid
textual entailments. In Proceedings of HLT-NAACL,
pages 41–48.
Terence Parsons. 1990. Events in the Semantics of En-
glish. A Study in Subatomic Semantics. MIT Press.
Rajat Raina, Andrew Y. Ng, and Christopher D. Man-
ning. 2005. Robust textual inference via learning
and abductive reasoning. In Proceedings of AAAI,
pages 1099–1105.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and
Andrew Ng. 2008. Cheap and fast – but is it good?
evaluating non-expert annotations for natural lan-
guage tasks. In Proceedings of EMNLP, pages 254–
263.
Marta Tatu and Dan Moldovan. 2005. A semantic ap-
proach to recognizing textual entailment. In Pro-
ceedings of HLT-EMNLP, pages 371–378.
</reference>
<page confidence="0.999656">
213
</page>
<sectionHeader confidence="0.86983" genericHeader="method">
APPENDIX
</sectionHeader>
<figure confidence="0.930732952380952">
A Dependency Structure of Dialogue Utterances and Hypothesis in Example 5
Dialogue Segment: Hypothesis:
B: Have you seen Sleeping with th
A: No. I&apos;ve heard that&apos;s really great though
B: You have to go see that one.
x1 A
A
A
x7
x4
x2
x8
x5
x9
x6
x10
x3
t
B Clause Representation of Dialogue Segment and Hypothesis for Example 5
Dialogue Segment:
Terms Clauses
</figure>
<bodyText confidence="0.744360166666667">
B: x1=have, x2=seen, subj(x2,A), obj(x2,x3), aux(x2,x1)
x3=Sleeping with the Enemy, A
x4=have heard, x5=that,
x6=is really great, A subj(x4,A), obj(x4,x6), subj(x6,x5), though(x4)
x7=have, x8=go, x9=see, x10=one, A subj(x7,A), obj(x7,x8), obj(x8,x9), obj(x9,x10)
x3=Sleeping with the Enemy, A, B
</bodyText>
<sectionHeader confidence="0.710419" genericHeader="method">
Hypothesis:
C Augmented Clause Representation of Dialogue Segment in Example 5
</sectionHeader>
<subsectionHeader confidence="0.765503">
Clauses
</subsectionHeader>
<bodyText confidence="0.981354928571429">
x1=suggests, x2=watch,
subj(x1,B), obj(x1,A), obj(x1,x2), obj(x2,x3)
ialogue Segment (with context representation):
:
u1, x1=have, x2=seen,
speaker(u1,B), content(u1,x2), act(u1,wh_question),
Terms subj(x2,A), obj(x2,x3), aux(x2,x1)
x3=Sleeping with the Enemy, A, B
: u2, u3, x4=have heard, x5=that, speaker(u2,A), content(u2,-), act(u2,no_answer),
x6=is really great, A speaker(u3,A), content(u3,x4), act(u3,statement),
subj(x4,A), obj(x4,x6), subj(x6,x5), though(x4)
: u4, x7=have, x8=go, x9=see, speaker(u4,B), content(u4,x7), act(u4,opinion),
x10=one, A, B subj(x7,A), obj(x7,x8), obj(x8,x9), obj(x9,x10)
follow(u2,u1), follow(u3,u2), follow(u4,u3)
</bodyText>
<page confidence="0.988615">
214
</page>
<figure confidence="0.993674259259259">
D The Alignment for Example 5
Dialogue Segment
A
B
x1=have
x2=seen
x3=Sleeping with the Enemy
x4=have heard
x5=that
x6=is really great
x7=have
x8=go
x9=see
x10=one
u1: act(u1,wh_question)
u2: act(u2,no_answer)
u3: act(u3,statement)
u4: act(u4,opinion)
A
B
x1=sug
x2=wat
x3=Sle
E The Prediction of Inference for the Hypothesis Clauses in Example 5
Hypothesis Clause
obj(x1,A)
obj(x1,x2)
</figure>
<table confidence="0.957405461538462">
Clause Type subj(x1,B) relation relation
relation
Terms in this Clause x1 x1 x1
B A x2
Aligned Terms in the B A x2, x9
Dialogue Segment u4 u4 u4
Shortest Path between the content(u4,x7),
Aligned Terms in the speaker(u4,B) content(u4,x7), obj(x7,x8), obj(x9,xlo)
Dependency Structure of 1 subj(x7,A) obj(x8,x9)
Dialogue Segment 2 3
Path Length
Hypothesis Clause yes yes yes
Entailed? yes
</table>
<page confidence="0.995077">
215
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.700986">
<title confidence="0.999015">What do We Know about Conversation Participants: Experiments Conversation Entailment</title>
<author confidence="0.999663">Chen Zhang Joyce Y</author>
<affiliation confidence="0.9705745">Department of Computer Science and Michigan State</affiliation>
<address confidence="0.977608">East Lansing, MI 48824,</address>
<abstract confidence="0.986976947368421">Given the increasing amount of conversation data, techniques to automatically acquire information about conversation participants have become more important. Towards this goal, we investigate the problem of conversation entailment, a task that determines whether a given conversation discourse entails a hypothesis about the participants. This paper describes the challenges related to conversation entailment based on our collected data and presents a probabilistic framework that incorporates conversation context in entailment prediction. Our preliminary experimental results have shown that conversation context, in particular dialogue act, plays an important role in conversation entailment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Natural language understanding.</title>
<date>1995</date>
<publisher>The Benjamin/Cummings Publishing Company, Inc.</publisher>
<contexts>
<context position="12448" citStr="Allen, 1995" startWordPosition="1914" endWordPosition="1915">e intent from one participant on the other participant such as whether A agrees/disagrees with B 208 = P(d1 ... dm �= h1 ... hn|d1,..., dm, h1,...,hn) = P(D I-- h1, ... , D I-- hn|D, h1, ... , hn) on some issue, whether A intends to convince B on something, etc. Most of these types are motivated by the BeliefDesire-Intention (BDI) model, which represents key mental states and reflects the thoughts of a conversation participant. Desire is different from intention. The former arises subconsciously and the latter arise from rational deliberation that takes into consideration desires and beliefs (Allen, 1995). The fact type represents the facts about a participant. Both thoughts and facts are critical to characterize a participant and thus important to serve many other downstream applications. The above four types account for 47.1%, 34.0%, 10.7%, and 8.2% of our development set respectively. 4 A Probabilistic Framework Following previous work (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006), we approach conversation entailment using a probabilistic framework. To predict whether a hypothesis statement H can be inferred from a dialogue segment D, we estimate the probabili</context>
</contexts>
<marker>Allen, 1995</marker>
<rawString>James Allen. 1995. Natural language understanding. The Benjamin/Cummings Publishing Company, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Lisa Ferro</author>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Idan Szpektor</author>
</authors>
<title>The second pascal recognising textual entailment challenge.</title>
<date>2006</date>
<booktitle>In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment,</booktitle>
<location>Venice, Italy.</location>
<contexts>
<context position="2557" citStr="Bar-Haim et al., 2006" startWordPosition="375" endWordPosition="378"> scripts (Galley et al., 2004). We approach this question from a different angle as a conversation entailment problem: given a conversation discourse D and a hypothesis H concerning its participant, the goal is to identify whether D entails H. For instance, in the following example, the first hypothesis can be entailed from the dialogue segment while the second hypothesis cannot. Example 1: Dialogue Segment: A: And where about were you born? B: Up in Person Country. Hypothesis: (1) B was born in Person Country. (2) B lives in Person Country. Inspired by textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007), conversation entailment provides an intermediate step towards acquiring information about conversation participants. What we should know or would like to know about a participant can be rather open. The type of information needed about participants is also application-dependent and difficult to generalize. In conversation entailment, we will not face this problem since hypotheses can be used to express any type of information about a participant one might be interested in. Although hypotheses are currently given in our investigation, they can potentially be automat</context>
<context position="14271" citStr="Bar-Haim et al., 2006" startWordPosition="2229" endWordPosition="2232"> started. Therefore: P(D I-- H|D, H) n = H P(D �= hj|D = d1 ... dm, hj) j=1 n = H P(d1 ... dm �= hj|d1,..., dm, hj) (1) j=1 If this likelihood is above a certain threshold (e.g., 0.5 in our experiments), then H is considered as a true entailment from D. Given this framework, two important questions are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important f</context>
</contexts>
<marker>Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, Szpektor, 2006</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor. 2006. The second pascal recognising textual entailment challenge. In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>628--635</pages>
<contexts>
<context position="14548" citStr="Bos and Markert, 2005" startWordPosition="2273" endWordPosition="2276">wo important questions are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the con</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proceedings of HLT-EMNLP, pages 628–635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1036" citStr="Clark, 1996" startWordPosition="145" endWordPosition="146">goal, we investigate the problem of conversation entailment, a task that determines whether a given conversation discourse entails a hypothesis about the participants. This paper describes the challenges related to conversation entailment based on our collected data and presents a probabilistic framework that incorporates conversation context in entailment prediction. Our preliminary experimental results have shown that conversation context, in particular dialogue act, plays an important role in conversation entailment. 1 Introduction Conversation is a joint activity between its participants (Clark, 1996). Their goals and their understanding of mutual beliefs of each other shape the linguistic discourse of conversation. In turn, this linguistic discourse provides tremendous information about conversation participants. Given the increasing amount of available conversation data (e.g., conversation scripts such as meeting scripts, court records, and online chatting), an important question is what do we know about conversation participants? The capability to automatically acquire such information can benefit many applications, for example, development of social networks and discovery of social dyn</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>In PASCAL Challenges Workshop on Recognising Textual Entailment.</booktitle>
<contexts>
<context position="2534" citStr="Dagan et al., 2005" startWordPosition="371" endWordPosition="374">m multiparty meeting scripts (Galley et al., 2004). We approach this question from a different angle as a conversation entailment problem: given a conversation discourse D and a hypothesis H concerning its participant, the goal is to identify whether D entails H. For instance, in the following example, the first hypothesis can be entailed from the dialogue segment while the second hypothesis cannot. Example 1: Dialogue Segment: A: And where about were you born? B: Up in Person Country. Hypothesis: (1) B was born in Person Country. (2) B lives in Person Country. Inspired by textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007), conversation entailment provides an intermediate step towards acquiring information about conversation participants. What we should know or would like to know about a participant can be rather open. The type of information needed about participants is also application-dependent and difficult to generalize. In conversation entailment, we will not face this problem since hypotheses can be used to express any type of information about a participant one might be interested in. Although hypotheses are currently given in our investigation, they can</context>
<context position="5330" citStr="Dagan et al., 2005" startWordPosition="768" endWordPosition="771">pants has been studied as a part of user modeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about conversation participants, namely, through conversation entailment. This work is inspired by a large body of recent work on textual entailment initiated by the PASCAL RTE Challenge (Dagan et al., 2005; BarHaim et al., 2006; Giampiccolo et al., 2007). Nevertheless, conversation discourse is very different from written monologue discourse. The conversation discourse is shaped by the goals of its participants and their mutual beliefs. The key distinctive features include turn-taking between participants, grounding between participants, and different linguistic phenomena of utterances (e.g., utterances in conversation tend to be shorter, with disfluency, and sometimes incomplete or ungrammatical). It is the goal of this paper to explore how techniques developed for textual entailment can be ex</context>
<context position="14248" citStr="Dagan et al., 2005" startWordPosition="2225" endWordPosition="2228">, but it gets things started. Therefore: P(D I-- H|D, H) n = H P(D �= hj|D = d1 ... dm, hj) j=1 n = H P(d1 ... dm �= hj|d1,..., dm, hj) (1) j=1 If this likelihood is above a certain threshold (e.g., 0.5 in our experiments), then H is considered as a true entailment from D. Given this framework, two important questions are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous </context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In PASCAL Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodrigo de Salvo Braz</author>
<author>Roxana Girju</author>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Mark Sammons</author>
</authors>
<title>An inference model for semantic entailment in natural language.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="12839" citStr="Braz et al., 2005" startWordPosition="1976" endWordPosition="1979">s the thoughts of a conversation participant. Desire is different from intention. The former arises subconsciously and the latter arise from rational deliberation that takes into consideration desires and beliefs (Allen, 1995). The fact type represents the facts about a participant. Both thoughts and facts are critical to characterize a participant and thus important to serve many other downstream applications. The above four types account for 47.1%, 34.0%, 10.7%, and 8.2% of our development set respectively. 4 A Probabilistic Framework Following previous work (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006), we approach conversation entailment using a probabilistic framework. To predict whether a hypothesis statement H can be inferred from a dialogue segment D, we estimate the probability P(D [-- H|D, H) Suppose we have a representation of a dialogue segment D in m clauses d1, ... , dm and a representation of the hypothesis H in n clauses h1, ... , hn. Since a hypothesis is the conjunction of the decomposed clauses, whether it can be inferred from a segment is equivalent to whether all of its clauses can be inferred from the segment. We further simplify the problem by a</context>
<context position="14653" citStr="Braz et al., 2005" startWordPosition="2293" endWordPosition="2296">gue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the concept of mention in the Automatic Content Extraction (ACE) evaluation (Doddington et al., 2004). An event </context>
</contexts>
<marker>Braz, Girju, Punyakanok, Roth, Sammons, 2005</marker>
<rawString>Rodrigo de Salvo Braz, Roxana Girju, Vasin Punyakanok, Dan Roth, and Mark Sammons. 2005. An inference model for semantic entailment in natural language. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
</authors>
<title>The automatic content extraction (ace) programctasks, data, and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="15242" citStr="Doddington et al., 2004" startWordPosition="2393" endWordPosition="2396">., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the concept of mention in the Automatic Content Extraction (ACE) evaluation (Doddington et al., 2004). An event refers to an action or an activity. For example, from the sentence “John married Eva in 1940” we can identify an event of marriage. Following the neo-Davidsonian representation (Parsons, 1990), all the events are reified as terms in our representation. Predicate: A predicate represents either a property (i.e., unary) for a term or a relation (i.e., binary) between two terms. For example, an entity company has a property of Russian as in the phrase “a Russian company” (i.e., Russian(company)). An event visit has a property of recently (i.e., recently(visit)) as in the phrase “visit B</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, and L. Ramshaw. 2004. The automatic content extraction (ace) programctasks, data, and evaluation. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen McKeown</author>
<author>Julia Hirschberg</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>669--676</pages>
<contexts>
<context position="1966" citStr="Galley et al., 2004" startWordPosition="274" endWordPosition="277">as meeting scripts, court records, and online chatting), an important question is what do we know about conversation participants? The capability to automatically acquire such information can benefit many applications, for example, development of social networks and discovery of social dynamics. Related to this question, previous work has developed techniques to extract profiling information about participants from conversation interviews (Jing et al., 2007) and to automatically identify dynamics between conversation participants such as agreement/disagreement from multiparty meeting scripts (Galley et al., 2004). We approach this question from a different angle as a conversation entailment problem: given a conversation discourse D and a hypothesis H concerning its participant, the goal is to identify whether D entails H. For instance, in the following example, the first hypothesis can be entailed from the dialogue segment while the second hypothesis cannot. Example 1: Dialogue Segment: A: And where about were you born? B: Up in Person Country. Hypothesis: (1) B was born in Person Country. (2) B lives in Person Country. Inspired by textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampic</context>
<context position="4643" citStr="Galley et al., 2004" startWordPosition="666" endWordPosition="669">oped a probabilisitic framework that incorporates semantic representation of conversation context. Our preliminary experimental results have shown that conversation context, in particular dialogue acts, play an important role in conversation entailment. 2 Related Work Recent work has applied different approaches to acquire information about conversation participants based on human-human conversation scripts, for example, to extract profiling information from conversation interviews (Jing et al., 2007) and to identify agreement/disagreement between participants from multiparty meeting scripts (Galley et al., 2004). In human-machine conversation, inference about conversation participants has been studied as a part of user modeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about conversation participants, namely, through conversation entailment. This work is inspired by a large body of rece</context>
<context position="7586" citStr="Galley et al., 2004" startWordPosition="1121" endWordPosition="1124">ating whether the hypothesis can be inferred from the snippet given the whole history of that dialogue session. During annotation, we asked the annotators to provide balanced examples for each dialogue. That is, roughly half of the hypotheses are truly entailed and half are not. Special attention was given to negative entailment examples. Since any arbitrary hypotheses that are completely irrelevant can be negative examples, a special criteria is enforced that any negative examples should have a majority word overlap with the snippet. In addition, inspired by previous work (Jing et al., 2007; Galley et al., 2004), we particularly asked annotators to provide hypotheses that address the profiling information of the participants, their opinions and desires, as well as the dynamic communicative relations between participants. A recent study shows that for many NLP annotation tasks, the reliability of a small number of non-expert annotations is on par with that of an expert annotator (Snow et al., 2008). It also found that for tasks such as affection recognition, an average of four non-expert labels per item are capable of emulating expert-level label quality. Based on this finding, in our study the entail</context>
</contexts>
<marker>Galley, McKeown, Hirschberg, Shriberg, 2004</marker>
<rawString>Michel Galley, Kathleen McKeown, Julia Hirschberg, and Elizabeth Shriberg. 2004. Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies. In Proceedings ofACL, pages 669–676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="2584" citStr="Giampiccolo et al., 2007" startWordPosition="379" endWordPosition="382">, 2004). We approach this question from a different angle as a conversation entailment problem: given a conversation discourse D and a hypothesis H concerning its participant, the goal is to identify whether D entails H. For instance, in the following example, the first hypothesis can be entailed from the dialogue segment while the second hypothesis cannot. Example 1: Dialogue Segment: A: And where about were you born? B: Up in Person Country. Hypothesis: (1) B was born in Person Country. (2) B lives in Person Country. Inspired by textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007), conversation entailment provides an intermediate step towards acquiring information about conversation participants. What we should know or would like to know about a participant can be rather open. The type of information needed about participants is also application-dependent and difficult to generalize. In conversation entailment, we will not face this problem since hypotheses can be used to express any type of information about a participant one might be interested in. Although hypotheses are currently given in our investigation, they can potentially be automatically generated based on i</context>
<context position="5379" citStr="Giampiccolo et al., 2007" startWordPosition="777" endWordPosition="780">odeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about conversation participants, namely, through conversation entailment. This work is inspired by a large body of recent work on textual entailment initiated by the PASCAL RTE Challenge (Dagan et al., 2005; BarHaim et al., 2006; Giampiccolo et al., 2007). Nevertheless, conversation discourse is very different from written monologue discourse. The conversation discourse is shaped by the goals of its participants and their mutual beliefs. The key distinctive features include turn-taking between participants, grounding between participants, and different linguistic phenomena of utterances (e.g., utterances in conversation tend to be shorter, with disfluency, and sometimes incomplete or ungrammatical). It is the goal of this paper to explore how techniques developed for textual entailment can be extended to address these unique behaviors in conve</context>
<context position="14298" citStr="Giampiccolo et al., 2007" startWordPosition="2233" endWordPosition="2236">D I-- H|D, H) n = H P(D �= hj|D = d1 ... dm, hj) j=1 n = H P(d1 ... dm �= hj|d1,..., dm, hj) (1) j=1 If this likelihood is above a certain threshold (e.g., 0.5 in our experiments), then H is considered as a true entailment from D. Given this framework, two important questions are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment,</context>
<context position="22479" citStr="Giampiccolo et al., 2007" startWordPosition="3652" endWordPosition="3655">can conclude that the overall hypothesis is entailed. We trained the alignment model and the inference model (e.g.,the threshold AL) based on the development data provided by the PASCAL 3 challenges on textual entailment. 5 Experimental Results To understand unique behaviors of conversation entailment, we focused our current experiments on the development dataset (see Section 3.2). We are particularly interested in how the techniques for textual entailment can be improved for conversation entailment. To do so, we applied our entailment framework on the test data of the PASCAL-3 RTE Challenge (Giampiccolo et al., 2007). Among 800 testing examples, our approach achieved an accuracy of 60.6%. This result is on par with the performance of the median system of accuracy 61.8% (z-test, p=0.63) in the PASCAL-3 RTE Challenge. Our current approach is very lean on the use of external knowledge. Its competitive performance sets up a reasonable baseline for our investigation on conversation entailment. This same system, modified to tailor linguistic characteristics of conversation (e.g., removal of disfluency), was used as the baseline in our experiments. 5.1 Event Alignment To understand the effect of conversation con</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John J Godfrey</author>
<author>Edward Holliman</author>
</authors>
<date>1997</date>
<booktitle>Switchboard-1 Release 2. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="6290" citStr="Godfrey and Holliman, 1997" startWordPosition="910" endWordPosition="913">ants, and different linguistic phenomena of utterances (e.g., utterances in conversation tend to be shorter, with disfluency, and sometimes incomplete or ungrammatical). It is the goal of this paper to explore how techniques developed for textual entailment can be extended to address these unique behaviors in conversation entailment. 3 Experimental Data The first step in our investigation is to collect entailment data to help us better understand the problem and facilitate algorithm development and evaluation. 3.1 Data Collection Procedure We selected 50 dialogues from the Switchboard corpus (Godfrey and Holliman, 1997). In each of these dialogues, two participants discuss a topic of interest (e.g., sports activities, corporate culture, etc.). To focus our work on the entailment problem, we use the transcribed scripts of the dialogues in our experiments. We also make use of available annotations such as syntactic structures, disfluency markers, and dialogue acts. We had 15 volunteer annotators read the selected dialogues and create hypotheses about participants. As a result, a total of 1096 entailment examples were created. Each example consists of a snippet from the dialogue (referred to as dialogue segment</context>
<context position="17840" citStr="Godfrey and Holliman, 1997" startWordPosition="2816" endWordPosition="2819">used to represent individual utterances. • Participant: A relational clause speaker(·, ·) is used to represent the speaker of this utterance, e.g., speaker(u1, B). • Content: A relational clause content(·, ·) is used to represent the content of an utterance where the second term is the head of the utterance as identified in the parsing structure. e.g., content(u3, heard) • Dialogue act: A relational clause act(·, ·) is used to represent the dialogue act of the speaker for a particular utterance. e.g., act(u2, no answer). A set of 42 dialogue acts from the Switchboard annotation are used here (Godfrey and Holliman, 1997). • Utterance flow: A relational clause follow(·, ·) is used to connect each pair of adjacent utterances. e.g., follow(u2,u1). We currently do not consider overlap in utterances, but our representation can be modified to handle this situation by introducing additional predicates. 4.2 Entailment Prediction Given the clause representation for a conversation segment and a hypothesis, the next step is to make an entailment prediction (as in Equation 1) based on two models: an Alignment Model and an Inference Model. 4.2.1 Alignment Model The alignment model is to find alignments (or matches) betwee</context>
</contexts>
<marker>Godfrey, Holliman, 1997</marker>
<rawString>John J. Godfrey and Edward Holliman. 1997. Switchboard-1 Release 2. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Andrew Ng</author>
<author>Christopher Manning</author>
</authors>
<title>Robust textual inference via graph matching.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>387--394</pages>
<contexts>
<context position="12811" citStr="Haghighi et al., 2005" startWordPosition="1970" endWordPosition="1973">ts key mental states and reflects the thoughts of a conversation participant. Desire is different from intention. The former arises subconsciously and the latter arise from rational deliberation that takes into consideration desires and beliefs (Allen, 1995). The fact type represents the facts about a participant. Both thoughts and facts are critical to characterize a participant and thus important to serve many other downstream applications. The above four types account for 47.1%, 34.0%, 10.7%, and 8.2% of our development set respectively. 4 A Probabilistic Framework Following previous work (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006), we approach conversation entailment using a probabilistic framework. To predict whether a hypothesis statement H can be inferred from a dialogue segment D, we estimate the probability P(D [-- H|D, H) Suppose we have a representation of a dialogue segment D in m clauses d1, ... , dm and a representation of the hypothesis H in n clauses h1, ... , hn. Since a hypothesis is the conjunction of the decomposed clauses, whether it can be inferred from a segment is equivalent to whether all of its clauses can be inferred from the segment. We furth</context>
<context position="14625" citStr="Haghighi et al., 2005" startWordPosition="2287" endWordPosition="2290"> clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the concept of mention in the Automatic Content Extraction (ACE) evaluation (Dodding</context>
</contexts>
<marker>Haghighi, Ng, Manning, 2005</marker>
<rawString>Aria Haghighi, Andrew Ng, and Christopher Manning. 2005. Robust textual inference via graph matching. In Proceedings of HLT-EMNLP, pages 387–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Horvitz</author>
<author>Tim Paek</author>
</authors>
<title>Harnessing models of users’ goals to mediate clarification dialog in spoken language systems.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th International Conference on User Modeling,</booktitle>
<pages>3--13</pages>
<contexts>
<context position="4908" citStr="Horvitz and Paek, 2001" startWordPosition="704" endWordPosition="707">d Work Recent work has applied different approaches to acquire information about conversation participants based on human-human conversation scripts, for example, to extract profiling information from conversation interviews (Jing et al., 2007) and to identify agreement/disagreement between participants from multiparty meeting scripts (Galley et al., 2004). In human-machine conversation, inference about conversation participants has been studied as a part of user modeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about conversation participants, namely, through conversation entailment. This work is inspired by a large body of recent work on textual entailment initiated by the PASCAL RTE Challenge (Dagan et al., 2005; BarHaim et al., 2006; Giampiccolo et al., 2007). Nevertheless, conversation discourse is very different from written monologue discourse. The conversation discourse is shaped b</context>
</contexts>
<marker>Horvitz, Paek, 2001</marker>
<rawString>Eric Horvitz and Tim Paek. 2001. Harnessing models of users’ goals to mediate clarification dialog in spoken language systems. In Proceedings of the 8th International Conference on User Modeling, pages 3–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Salim Roukos</author>
</authors>
<title>Extracting social networks and biographical facts from conversational speech transcripts.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1040--1047</pages>
<contexts>
<context position="1808" citStr="Jing et al., 2007" startWordPosition="254" endWordPosition="257">rovides tremendous information about conversation participants. Given the increasing amount of available conversation data (e.g., conversation scripts such as meeting scripts, court records, and online chatting), an important question is what do we know about conversation participants? The capability to automatically acquire such information can benefit many applications, for example, development of social networks and discovery of social dynamics. Related to this question, previous work has developed techniques to extract profiling information about participants from conversation interviews (Jing et al., 2007) and to automatically identify dynamics between conversation participants such as agreement/disagreement from multiparty meeting scripts (Galley et al., 2004). We approach this question from a different angle as a conversation entailment problem: given a conversation discourse D and a hypothesis H concerning its participant, the goal is to identify whether D entails H. For instance, in the following example, the first hypothesis can be entailed from the dialogue segment while the second hypothesis cannot. Example 1: Dialogue Segment: A: And where about were you born? B: Up in Person Country. H</context>
<context position="4529" citStr="Jing et al., 2007" startWordPosition="652" endWordPosition="655">due to unique characteristics about conversation and conversational implicature. To predict entailment, we developed a probabilisitic framework that incorporates semantic representation of conversation context. Our preliminary experimental results have shown that conversation context, in particular dialogue acts, play an important role in conversation entailment. 2 Related Work Recent work has applied different approaches to acquire information about conversation participants based on human-human conversation scripts, for example, to extract profiling information from conversation interviews (Jing et al., 2007) and to identify agreement/disagreement between participants from multiparty meeting scripts (Galley et al., 2004). In human-machine conversation, inference about conversation participants has been studied as a part of user modeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about</context>
<context position="7564" citStr="Jing et al., 2007" startWordPosition="1117" endWordPosition="1120">a truth value indicating whether the hypothesis can be inferred from the snippet given the whole history of that dialogue session. During annotation, we asked the annotators to provide balanced examples for each dialogue. That is, roughly half of the hypotheses are truly entailed and half are not. Special attention was given to negative entailment examples. Since any arbitrary hypotheses that are completely irrelevant can be negative examples, a special criteria is enforced that any negative examples should have a majority word overlap with the snippet. In addition, inspired by previous work (Jing et al., 2007; Galley et al., 2004), we particularly asked annotators to provide hypotheses that address the profiling information of the participants, their opinions and desires, as well as the dynamic communicative relations between participants. A recent study shows that for many NLP annotation tasks, the reliability of a small number of non-expert annotations is on par with that of an expert annotator (Snow et al., 2008). It also found that for tasks such as affection recognition, an average of four non-expert labels per item are capable of emulating expert-level label quality. Based on this finding, i</context>
</contexts>
<marker>Jing, Kambhatla, Roukos, 2007</marker>
<rawString>Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2007. Extracting social networks and biographical facts from conversational speech transcripts. In Proceedings of ACL, pages 1040–1047.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<contexts>
<context position="19289" citStr="Lin, 1998" startWordPosition="3076" endWordPosition="3077">. g(x, y) = 1 if x and y are aligned; otherwise g(x, y) = 0. Note that a verb can be aligned to a noun as in g(sell, sale) = 1. It is also possible that there are multiple terms from the segment mapped to one term in the hypothesis, or vice versa. For any two terms x and y, the problem of predicting the alignment function g(x, y) can be formulated as a binary classification problem. We used several features to train the classifier, which include whether x and y are the same (or have the same stem), whether one term is an acronym of the other, and their WordNet and distributional similarities (Lin, 1998). Given an augmented representation with conversation context (as in Appendix C), we also align event terms in the hypothesis (e.g., suggest in Example 5) to (pseudo) utterance terms in the dialogue segment. We call it a pseudo alignment. This is currently done by a set of rules which associate event terms in the hypotheses with dialogue acts. For example, the event term suggest may be aligned to an utterance with dialogue act of opinion. Appendix D gives a correct alignment for Example 5, in which g(u4, x1) = 1 is a pseudo alignment. 4.2.2 Inference Model As shown in Equation 1, to predict th</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. An information-theoretic definition of similarity. In Proceedings of International Conference on Machine Learning, pages 296–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane Litman</author>
<author>Katherine Forbes-Riley</author>
</authors>
<title>Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors.</title>
<date>2006</date>
<journal>Speech Communication,</journal>
<volume>48</volume>
<issue>5</issue>
<contexts>
<context position="5034" citStr="Litman and Forbes-Riley, 2006" startWordPosition="721" endWordPosition="724">an-human conversation scripts, for example, to extract profiling information from conversation interviews (Jing et al., 2007) and to identify agreement/disagreement between participants from multiparty meeting scripts (Galley et al., 2004). In human-machine conversation, inference about conversation participants has been studied as a part of user modeling. For example, earlier work has investigated inference of user intention from utterances to control clarification dialogue (Horvitz and Paek, 2001) and recognition of user emotion and attitude from utterances for intelligent tutoring systems (Litman and Forbes-Riley, 2006). In contrast to previous work, we propose a new angle to address information acquisition about conversation participants, namely, through conversation entailment. This work is inspired by a large body of recent work on textual entailment initiated by the PASCAL RTE Challenge (Dagan et al., 2005; BarHaim et al., 2006; Giampiccolo et al., 2007). Nevertheless, conversation discourse is very different from written monologue discourse. The conversation discourse is shaped by the goals of its participants and their mutual beliefs. The key distinctive features include turn-taking between participant</context>
</contexts>
<marker>Litman, Forbes-Riley, 2006</marker>
<rawString>Diane Litman and Katherine Forbes-Riley. 2006. Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors. Speech Communication, 48(5):559–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Trond Grenager</author>
<author>Marie-Catherine de Marneffe</author>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
</authors>
<title>Learning to recognize features of valid textual entailments.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>41--48</pages>
<marker>MacCartney, Grenager, de Marneffe, Cer, Manning, 2006</marker>
<rawString>Bill MacCartney, Trond Grenager, Marie-Catherine de Marneffe, Daniel Cer, and Christopher D. Manning. 2006. Learning to recognize features of valid textual entailments. In Proceedings of HLT-NAACL, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terence Parsons</author>
</authors>
<title>Events in the Semantics of English. A Study in Subatomic Semantics.</title>
<date>1990</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="15445" citStr="Parsons, 1990" startWordPosition="2428" endWordPosition="2430">ered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the concept of mention in the Automatic Content Extraction (ACE) evaluation (Doddington et al., 2004). An event refers to an action or an activity. For example, from the sentence “John married Eva in 1940” we can identify an event of marriage. Following the neo-Davidsonian representation (Parsons, 1990), all the events are reified as terms in our representation. Predicate: A predicate represents either a property (i.e., unary) for a term or a relation (i.e., binary) between two terms. For example, an entity company has a property of Russian as in the phrase “a Russian company” (i.e., Russian(company)). An event visit has a property of recently (i.e., recently(visit)) as in the phrase “visit Brazil recently”. From the phrase “Prime Minister recently visited Brazil”, there are binary relations: Prime Minister is the subject of the event visit (i.e., subj(visit, Prime Minister)) and Brazil is t</context>
</contexts>
<marker>Parsons, 1990</marker>
<rawString>Terence Parsons. 1990. Events in the Semantics of English. A Study in Subatomic Semantics. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajat Raina</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Robust textual inference via learning and abductive reasoning.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>1099--1105</pages>
<contexts>
<context position="14569" citStr="Raina et al., 2005" startWordPosition="2277" endWordPosition="2280">are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entities. This follows the concept of mention in th</context>
</contexts>
<marker>Raina, Ng, Manning, 2005</marker>
<rawString>Rajat Raina, Andrew Y. Ng, and Christopher D. Manning. 2005. Robust textual inference via learning and abductive reasoning. In Proceedings of AAAI, pages 1099–1105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Ng</author>
</authors>
<title>Cheap and fast – but is it good? evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>254--263</pages>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Ng. 2008. Cheap and fast – but is it good? evaluating non-expert annotations for natural language tasks. In Proceedings of EMNLP, pages 254– 263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Dan Moldovan</author>
</authors>
<title>A semantic approach to recognizing textual entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>371--378</pages>
<contexts>
<context position="14525" citStr="Tatu and Moldovan, 2005" startWordPosition="2269" endWordPosition="2272">. Given this framework, two important questions are: (1) how to represent and automatically create the clauses from each pair of dialogue segment and hypothesis; and (2) how to estimate probabilities as shown in Equation 1? 4.1 Clause Representation Our clause representation is inspired by previous work on textual entailment (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Clause representation has several advantages. First, it can be acquired automatically from a parse tree (e.g., dependency parser). Second, it can be used to facilitate both logic-based reasoning as in (Tatu and Moldovan, 2005; Bos and Markert, 2005; Raina et al., 2005) or probabilistic reasoning as in (Haghighi et al., 2005; de Salvo Braz et al., 2005; MacCartney et al., 2006). The key difference between our work and previous work on textual entailment is the representation of conversation discourse, which has not been considered in previous work but is important for conversation entailment, as we will see later. More specifically, a clause is made up by two components: Term and Predicate. Term: A term can be an entity or an event. An entity refers to a person, a place, an organization, or other real world entitie</context>
</contexts>
<marker>Tatu, Moldovan, 2005</marker>
<rawString>Marta Tatu and Dan Moldovan. 2005. A semantic approach to recognizing textual entailment. In Proceedings of HLT-EMNLP, pages 371–378.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>