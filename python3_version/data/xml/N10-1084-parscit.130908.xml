<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002104">
<title confidence="0.993918">
Linguistic Steganography Using Automatically Generated Paraphrases
</title>
<author confidence="0.997731">
Ching-Yun Chang Stephen Clark
</author>
<affiliation confidence="0.9791385">
University of Cambridge University of Cambridge
Computer Laboratory Computer Laboratory
</affiliation>
<email confidence="0.983512">
Ching-Yun.Chang@cl.cam.ac.uk Stephen.Clark@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993452" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999846375">
This paper describes a method for checking
the acceptability of paraphrases in context.
We use the Google n-gram data and a CCG
parser to certify the paraphrasing grammati-
cality and fluency. We collect a corpus of hu-
man judgements to evaluate our system. The
ultimate goal of our work is to integrate text
paraphrasing into a Linguistic Steganography
system, by using paraphrases to hide informa-
tion in a cover text. We propose automati-
cally generated paraphrases as a new and use-
ful source of transformations for Linguistic
Steganography, and show that our method for
checking paraphrases is effective at maintain-
ing a high level of imperceptibility, which is
crucial for effective steganography.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997744">
Steganography is concerned with hiding informa-
tion in some cover medium, by manipulating prop-
erties of the medium in such a way that the hidden
information is not easily detectable by an observer
(Fridrich, 2009). The covert communication is such
that the very act of communication is to be kept se-
cret from outside observers. A related area is Wa-
termarking, in which modifications are made to a
cover medium in order to identify it, for example for
the purposes of copyright. Here the changes may
be known to an observer, and the task is to make
the changes in such a way that the watermark cannot
easily be removed.
There is a large literature on image steganogra-
phy and watermarking, in which images are mod-
ified to encode a hidden message or watermark.
Image stegosystems exploit the redundancy in an
image representation together with limitations of
the human visual system. For example, a stan-
dard image stegosystem uses the least-significant-bit
(LSB) substitution technique. Since the difference
between 11111111 and 11111110 in the value for
red/green/blue intensity is likely to be undetectable
by the human eye, the LSB can be used to hide infor-
mation other than colour, without being perceptable
by a human observer.1
A key question for any steganography system is
the choice of cover medium. Given the ubiqui-
tous nature of natural languages and electronic text,
text is an obvious medium to consider. However,
the literature on Linguistic Steganography, in which
linguistic properties of a text are modified to hide
information, is small compared with other media
(Bergmair, 2007). The likely reason is that it is
easier to make changes to images and other non-
linguistic media which are undetectable by an ob-
server. Language has the property that even small
local changes to a text, e.g. replacing a word by a
word with similar meaning, may result in text which
is anomalous at the document level, or anomalous
with respect to the state of the world. Hence find-
ing linguistic transformations which can be applied
reliably and often is a challenging problem for Lin-
guistic Steganography.
In this paper we focus on steganography rather
than watermarking, since we are interested in the re-
quirement that any changes to a text be impercep-
tible to an observer. Figure 1 shows the Linguistic
Steganography framework. First, some secret mes-
sage, represented as a sequence of bits, is hidden in a
</bodyText>
<footnote confidence="0.995021666666667">
1The observer may also be a computer program, designed to
detect statistical anomalies in the image representation which
may indicate the presence of hidden information.
</footnote>
<page confidence="0.911847">
591
</page>
<note confidence="0.8514455">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 591–599,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999912">
Figure 1: The Linguistic Steganography framework
</figureCaption>
<bodyText confidence="0.999479066666667">
cover text using the embedding algorithm, resulting
in the stego text.2 Next, the stego text passes the hu-
man observer, who is happy for innocuous messages
to pass between the sender and receiver, but will ex-
amine the text for any suspicious looking content.
Once the stego text reaches the receiver, the hidden
message is recovered using the extracting algorithm.
There is a fundamental tradeoff in all steganogra-
phy systems, and one that is especially apparent in
the Linguistic Steganography framework: the trade-
off between imperceptibility and payload. Payload
is the number of bits that can be encoded per unit
of cover medium, for example per sentence in the
linguistic case. The tradeoff arises because any at-
tempt to hide additional information in the cover
text, through the application of more linguistic trans-
formations, is likely to increase the chances of rais-
ing the suspicions of the observer, by introducing
anomalies into the text.
The key elements of a Linguistic Steganography
system are the linguistic transformation and the em-
bedding method. In this paper we focus on the lin-
guistic transformation. Section 5 describes a pos-
sible embedding method for our framework, and
for readers unfamiliar with linguistic steganography
shows how linguistic transformations can be used to
embed hidden bits in text.
Section 2 describes some of the previous transfor-
mations used in Linguistic Steganography. Note that
we are concerned with transformations which are
</bodyText>
<footnote confidence="0.968826">
2The message may have been encrypted initially also, as in
the figure, but this is not important in this paper; the key point
is that the hidden message is a sequence of bits.
</footnote>
<bodyText confidence="0.999870060606061">
linguistic in nature, rather than dealing with superfi-
cial properties of the text, e.g. the amount of white
space between words (Por et al., 2008). Our pro-
posed method is based on the automatically acquired
paraphrase dictionary described in Callison-Burch
(2008), in which the application of paraphrases from
the dictionary encodes secret bits. One advantage
of the dictionary is that it has wide coverage, be-
ing automatically extracted; however, a disadvan-
tage is that it contains many paraphrases which are
either inappropriate, or only appropriate in certain
contexts. Since we require any changes to be im-
perceptible to a human observer, it is crucial to our
system that any uses of paraphrasing are grammati-
cal and retain the meaning of the original cover text.
In order to test the grammaticality and meaning
preserving nature of a paraphrase, we employ a sim-
ple technique based on checking whether the con-
texts containing the paraphrase are in the Google n-
gram corpus. This technique is based on the sim-
ple hypothesis that, if the paraphrase in context has
been used many times before on the web, then it is
an appropriate use. We test our n-gram-based sys-
tem against some human judgements of the gram-
maticality of paraphrases in context. We find that
using larger contexts leads to a high precision sys-
tem (100% when using 5-grams), but at the cost of
a reduced recall. This precision-recall tradeoff re-
flects the inherent tradeoff between imperceptibility
and payload in a Linguistic Steganography system.
We also experiment with a CCG parser (Clark and
Curran, 2007), requiring that the contexts surround-
ing the original phrase and paraphrase are assigned
</bodyText>
<page confidence="0.996234">
592
</page>
<bodyText confidence="0.999871555555556">
the same CCG lexical categories by the parser. This
method increases the precision of the Google n-gram
check with a slight loss in recall.
A contribution of this paper is to advertise the Lin-
guistic Steganography problem to the ACL commu-
nity. The requirement that any linguistic transfor-
mation maintain the grammaticality and meaning of
the cover text makes the problem a strong test for
existing NLP technology.
</bodyText>
<sectionHeader confidence="0.99864" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<subsectionHeader confidence="0.999269">
2.1 Synonym Substitution
</subsectionHeader>
<bodyText confidence="0.99998605882353">
The simplest and most straightforward subliminal
modification of text is to substitute selected words
with their synonyms. The first lexical substitu-
tion method was proposed by Chapman and Davida
(1997). Later works, such as Atallah et al. (2001a),
Bolshakov (2004), Taskiran et al. (2006) and Top-
kara et al. (2006b), further made use of part-of-
speech taggers and electronic dictionaries, such as
WordNet and VerbNet, to increase the robustness of
the method. Taskiran et al. (2006) attempt to use
context by prioritizing the alternatives using an n-
gram language model; that is, rather than randomly
choose an option from the synonym set, the system
relies on the language model to select the synonym.
Topkara et al. (2005) and Topkara et al. (2006b) re-
port an average embedding capacity of 0.67 bits per
sentence for the synonym substitution method.
</bodyText>
<subsectionHeader confidence="0.99931">
2.2 Syntactic Transformations
</subsectionHeader>
<bodyText confidence="0.999991434782609">
The second and the most widely used manipulations
for linguistic steganography are syntactic transfor-
mations. This method is based on the fact that a sen-
tence can be transformed into more than one seman-
tically equivalent syntactic structure, using trans-
formations such as passivization, topicalization and
clefting. The first syntactic transformation method is
presented by Atallah et al. (2001a). Later, Atallah et
al. (2001b) embedded information in the tree struc-
ture of the text by adjusting the structural proper-
ties of intermediate representations of sentences. In
other words, instead of performing lexical substitu-
tion directly to the text, the secret message is embed-
ded into syntactic parse trees of the sentences. Liu
et al. (2005), Meral et al. (2007), Murphy (2001),
Murphy and Vogel (2007) and Topkara et al. (2006a)
all belong to the syntactic transformation category.
After embedding the secret message, modified deep
structure forms are converted into the surface struc-
ture format via language generation tools. Atallah et
al. (2001b) and Topkara et al. (2006a) attained the
embedding capacity of 0.5 bits per sentence with the
syntactic transformation method.
</bodyText>
<subsectionHeader confidence="0.999614">
2.3 Semantic Transformations
</subsectionHeader>
<bodyText confidence="0.999989266666667">
The semantic transformation method is the most so-
phisticated approach for linguistic steganography,
and perhaps impractical given the current state-of-
the-art for NLP technology. It requires some sophis-
ticated tools and knowledge to model natural lan-
guage semantics. Atallah et al. (2002) used seman-
tic transformations and embed information in text-
meaning representation (TMR) trees of the text by
either pruning, grafting or substituting the tree struc-
ture with information available from ontological se-
mantic resources. Vybornova and Macq (2007)
aimed to embed information by exploiting the lin-
guistic phenomenon of presupposition, with the idea
that some presuppositional information can be re-
moved without changing the meaning of a sentence.
</bodyText>
<sectionHeader confidence="0.997056" genericHeader="method">
3 Data Resources
</sectionHeader>
<subsectionHeader confidence="0.99995">
3.1 Paraphrase Dictionary
</subsectionHeader>
<bodyText confidence="0.99096835">
The cover text used for our experiments consists of
newspaper sentences from Section 00 of the Penn
Treebank (Marcus et al., 1993). Hence we require
possible paraphrases for phrases that occur in Sec-
tion 00. The paraphrase dictionary that we use
was generated for us by Chris Callison-Burch, using
the technique described in Callison-Burch (2008),
which exploits a parallel corpus and methods devel-
oped for statistical machine translation.
Table 1 gives summary statistics of the paraphrase
dictionary and its coverage on Section 00 of the
Penn Treebank. The length of the extracted n-gram
phrases ranges from unigrams to five-grams. The
coverage figure gives the percentage of sentences
which have at least one phrase in the dictionary. The
coverage is important for us because it determines
the payload capacity of the embedding method de-
scribed in Section 5.
Table 2 lists some examples 5-gram phrases and
paraphrases from the dictionary. The format of the
</bodyText>
<page confidence="0.994025">
593
</page>
<table confidence="0.998117857142857">
N-gram Number of Coverage on
phrases section 00 (%)
Unigrams 5,856 99
Bigrams 13,473 96
Trigrams 6,574 65
Four-grams 1,604 40
Five-grams 295 10
</table>
<tableCaption confidence="0.88028975">
Table 1: Statistics for the paraphrase dictionary
Original phrase Paraphrases
Table 2: Example phrases and paraphrases from the dic-
tionary
</tableCaption>
<bodyText confidence="0.999973823529412">
dictionary is a mapping from phrases to sets of pos-
sible paraphrases. Each paraphrase also has a prob-
ability, based on a statistical machine translation
model, but we do not use that feature here. The ex-
amples show that, while some of the paraphrases are
of a high quality, some are not. For example, dif-
ferences is unlikely to be a suitable paraphrase for
a number of people in any context. Moreover, there
are some (phrase, paraphrase) pairs which are only
suitable in particular contexts. For example, year
end is an unsuitable paraphrase for the end of this
year in the sentence The chart compares the gold
price at the end of last year with the end of this year.
Barzilay and McKeown (2001) also note that the ap-
plicability of paraphrases is strongly influenced by
context. Section 4 describes our method for deter-
mining if a paraphrase is suitable in a given context.
</bodyText>
<subsectionHeader confidence="0.999853">
3.2 Google N-gram Data
</subsectionHeader>
<bodyText confidence="0.999943166666667">
The Google n-gram data was collected by Google
Research for statistical language modelling, and has
been used for many tasks such as lexical disam-
biguation (Bergsma et al., 2009), and contains En-
glish n-grams and their observed frequency counts,
for counts of at least 40. The striking feature of
</bodyText>
<figureCaption confidence="0.999199">
Figure 2: The web-based annotation system
</figureCaption>
<bodyText confidence="0.999944">
the n-gram corpus is the large number of n-grams
and the size of the counts, since the counts were ex-
tracted from over 1 trillion word tokens of English
text on publicly accessible Web pages collected in
January 2006. For example, the 5-gram phrase the
part that you were has a count of 103. The com-
pressed data is around 24 GB on disk.
</bodyText>
<subsectionHeader confidence="0.999192">
3.3 Paraphrase Judgement Corpus
</subsectionHeader>
<bodyText confidence="0.999682413793103">
The focus of the paper is to develop an automatic
system for checking the grammaticality and flu-
ency of paraphrases in context. In order to evaluate
the system, we collected some human judgements,
based on 70 sentences from Section 00 of the Penn
Treebank. For each sentence, we took every phrase
in the sentence which is in the dictionary, and for
each paraphrase of that phrase, replaced the phrase
with the paraphrase to create an instance. This pro-
cedure resulted in 500 cases of paraphrases in con-
text.
Each case was then evaluated by a human judge,
using a web-based annotation system that we devel-
oped. The judges were asked to judge each case on
two dimensions: a) whether the paraphrase is gram-
matical in context; and b) whether the paraphrase
retains the meaning of the original phrase given the
context. Figure 2 gives a screen shot of the annota-
tion system.
50 of the 500 cases were judged by two judges, in
order to obtain some indication of whether the gram-
maticality and meaning retention judgements are vi-
able; the rest were judged by one annotator. (The
500 instances were randomly distributed among 10
native speakers, each being given 55 instances to
judge.) For the meaning retention check, only 34 out
of the 50 cases received the same judgement. One
reason for the low agreement may be that, for 11 of
the 16 disagreement cases, we were asking annota-
</bodyText>
<figure confidence="0.799028888888889">
the end of this year
later this year
the end of the year
year end
a number of people
some of my colleagues
differences
the European peoples party
the PPE group
</figure>
<page confidence="0.992605">
594
</page>
<bodyText confidence="0.99996325">
tors to judge the meaning retention of paraphrases
which had been judged to be ungrammatical in con-
text, which may not be a meaningful task. For the
grammatical check, 42 out of the 50 cases received
the same judgement, a much higher level of agree-
ment.
Since the meaning retention judgements were un-
reliable, we used only the grammatical judgements
to evaluate our system. Hence we are interested
in evaluating whether our n-gram and parser-based
systems can determine if a paraphrase is grammat-
ical in context. Meaning retention is important for
the imperceptibility requirement, but grammatical-
ity is even more so, since ungrammatical sentences
will be easy for an observer to spot. However, we
recognise that only testing for grammaticality does
not fully test the imperceptibility properties of the
system, only part of it.
For the 8 cases which received different judge-
ments on grammaticality, the second author of this
paper made the definitive judgement, which resulted
in a test set of 308 paraphrases judged as grammat-
ical in context, and 192 paraphrases judged as un-
grammatical in context.
</bodyText>
<sectionHeader confidence="0.993098" genericHeader="method">
4 Proposed Method and Experiments
</sectionHeader>
<subsectionHeader confidence="0.998585">
4.1 Google N-gram Method
</subsectionHeader>
<bodyText confidence="0.999441833333333">
The main idea for testing the use of paraphrases is
to check if the various contextual n-grams appear
in the Google n-gram data, or were already in the
original sentence (before paraphrasing). Let us first
define some notation to be used in describing the
method. The leftmost and rightmost &lt;m&gt; words in
the phrase/paraphrase are represented as &lt;m&gt;INLeft
and &lt;m&gt;INRight, respectively. Words at the left and
right side of the substituted phrase are defined as
&lt;c&gt;OUTLeft and &lt;c&gt;OUTRight, where &lt;c&gt; is an
integer which indicates the number of words rep-
resented. Also, we define a context window pair
</bodyText>
<equation confidence="0.63830675">
W &lt;c&gt;
&lt;n&gt; = (WL&lt;c&gt;
&lt;n&gt;, WR&lt;c&gt;
&lt;n&gt;), where WL&lt;c&gt;
</equation>
<bodyText confidence="0.904458333333333">
&lt;n&gt; is
composed by &lt;c&gt;OUTLeft concatenated with &lt;n-
c&gt;INLeft, and WR&lt;c&gt;
&lt;n&gt; is composed by &lt;n-c&gt;INRight
concatenated with &lt;c&gt;OUTRight. Figure 3 gives an
example of the context window pairs W3 and W3 in
the sentence Soviets said that it is too early to say
whether that will happen where the phrase too early
to is being considered in context.
</bodyText>
<figure confidence="0.640005888888889">
INPUT: S, P, P&apos;, n, maxC
OUTPUT: the acceptability of paraphrase P&apos;
checked by (n, maxC)
FOR each context size C from 1 to maxC
GET a context window pair WnC
IF O(WnC) is zero THEN
OUTPUT paraphrase P&apos; fails
END FOR
OUTPUT paraphrase P&apos; passes
</figure>
<figureCaption confidence="0.998466">
Figure 4: Procedure for checking acceptability
</figureCaption>
<bodyText confidence="0.966452466666667">
We define a google-count function G(). This func-
tion takes a context window pair W&lt;c&gt;
&lt;n&gt; as input and
outputs a frequency count pair of W&lt;c&gt;
&lt;n&gt; recorded in
the Google n-gram data. If a context window cannot
be found in the Google n-gram data, the frequency
count of that window is zero. Also, we define a bi-
nary occurrence function O(). It is used to deter-
mine whether a context window pair can be passed
as acceptable. The input of this function is W&lt;c&gt;
&lt;n&gt;.
The function outputs one if either both WL&lt;c&gt;
&lt;n&gt; and
WR&lt;c&gt;
&lt;n&gt; already occurred in the original sentence
(before paraphrasing) or if the frequency counts out-
put by G(W &lt;c&gt;
&lt;n&gt;) are both greater than zero.
The two major components in our method are the
paraphrase dictionary and the Google n-gram data.
Once a phrase P in the cover sentence S is matched
with that in the paraphrase dictionary, we test the use
of its paraphrase P&apos; by the following method. This
method takes into account maximum C contextual
words at both sides of the target phrase, and uses
Google n-gram data as a check, where n = 2, 3, 4 or
5, and maxC = 1 to n − 1. Each pair of (n, maxC)
provides a separate check, by considering both left
and right contexts for these values.
</bodyText>
<figureCaption confidence="0.8809005">
Figure 4 describes the procedure for checking the
Figure 3: An example of the context window pair
</figureCaption>
<page confidence="0.993937">
595
</page>
<bodyText confidence="0.999943333333333">
acceptability of paraphrasing phrase P with P&apos; in
a given sentence 5, given the n-gram size and the
maximum considered context size maxC. For ex-
ample, we want to check the acceptability of the
paraphrase in context shown in Figure 3 by using
google tri-gram data (n = 3) and taking maximum
context size equal to two into consideration (maxC
= 2). The procedure starts from taking context size
C equal to one into account, namely checking the
occurrence of W31. If the paraphrase P&apos; passes the
current test, in the next iteration it will be tested by
taking one more context word into account, namely
W32. However, If the paraphrase P&apos; fails the current
(n, C) check the checking procedure will terminate
and report that the paraphrase fails. In contrast, if
the paraphrase passes all the (n, C) checks where
C = 1 to maxC, the procedure determines the para-
phrase as acceptable. What is happening is that an n-
gram window is effectively being shifted across the
paraphrase boundary to include different amounts of
context and paraphrase.
</bodyText>
<subsectionHeader confidence="0.995552">
4.2 Syntactic Filter
</subsectionHeader>
<bodyText confidence="0.999996222222223">
In order to improve the grammaticality checking, we
use a parser as an addition to the basic Google n-
gram method. We use the Clark and Curran (2007)
CCG parser to analyse the sentence before and af-
ter paraphrasing. Combinatory Categorial Grammar
(CCG) is a lexicalised grammar formalism, in which
CCG lexical categories — typically expressing sub-
categorisation information — are assigned to each
word in a sentence. The grammatical check works
by checking if the words in the sentence outside of
the phrase and paraphrase receive the same lexical
categories before and after paraphrasing. If there is
any change in lexical category assignment to these
words then the paraphrase is judged ungrammati-
cal. Hence the grammar check is at the word, rather
than derivation, level; however, CCG lexical cate-
gories contain a large amount of syntactic informa-
tion which this method is able to exploit.
</bodyText>
<subsectionHeader confidence="0.769729">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999262">
The test corpus described in Section 3.3 was split
into development and test data: 100 instances for
development and 400 for testing. The development
data was used for preliminary experiments. For the
test data, 246 of the examples (61.5%) had been
</bodyText>
<table confidence="0.999111">
Acc% P% R% F%
baseline 61.5 61.5 100.0 76.2
parser 68.3 67.4 93.9 78.4
</table>
<tableCaption confidence="0.99991">
Table 3: Grammar check using CCG parser
</tableCaption>
<bodyText confidence="0.999953048780488">
judged as grammatical, and 154 (38.5%) had been
judged as ungrammatical by the annotators.
The performance of the system is evaluated us-
ing accuracy, precision, recall and balanced F-
measure. Accuracy is the percentage of correct
judgements over all grammatical and ungrammati-
cal paraphrases. Precision is the percentage of para-
phrases judged grammatical by the system which are
judged grammatical by the human judges, and recall
is the percentage of paraphrases judged grammatical
by human judges which are also judged grammatical
by the system. Precision and recall are relevant in
our setting because high precision implies high im-
perceptibility, since grammatical phrases in context
are less likely to be viewed as suspicious by the ob-
server; whereas high recall maximises the payload
(given the dictionary), since high recall implies that
phrases are being paraphrased where possible (and
hence embedding as much information as possible).
An accuracy baseline is obtained by always re-
turning the majority class, in this case always judg-
ing the paraphrase grammatical, which gives an ac-
curacy of 61.5%. Table 3 gives the performance
when only the CCG parser is used for checking gram-
maticality. As far as steganography is concerned, the
precision is low, since over 30% of the paraphrases
used are ungrammatical, which is likely to raise the
suspicions of the observer.
Table 4 gives the results for the Google n-gram
method, for various n-gram and context sizes. As the
n-gram size increases — meaning that a larger part
of the context is used — the accuracy falls below
that of the baseline. However, from a steganogra-
phy aspect, accuracy is not useful, since the trade-
off between precision and recall is more relevant.
As expected, with larger n-grams checking the left
and right contexts, the precision increases, reaching
100% for the 5-grams. Hence, as far as grammati-
cality judgements are concerned, the imperceptibil-
ity requirement is completely satisified. However,
the large drop in recall means that the imperceptibil-
</bodyText>
<page confidence="0.995797">
596
</page>
<table confidence="0.999867875">
N- Context Accuracy Precision Recall F-measure
gram Size (%) (%) (%) (%)
2- 1 62.0 62.1 98.0 76.0
gram
3- 1 62.5 65.1 84.2 73.4
gram
2 67.3 72.9 74.4 73.6
4- 1 58.5 71.3 54.5 61.8
gram
2 53.2 84.7 29.3 43.5
3 51.8 89.6 24.4 38.3
5- 1 54.8 85.0 32.1 46.6
gram
2 43.5 95.5 8.5 15.7
3 41.0 100.0 4.1 7.8
4 41.0 100.0 4.1 7.8
</table>
<tableCaption confidence="0.999888">
Table 4: Performance of google n-gram method
</tableCaption>
<bodyText confidence="0.999910083333333">
ity is achieved at the cost of a reduced payload, since
many of the grammatical paraphrases that could be
used to embed information are being discarded.
Table 5 shows the results for the Google n-gram
method followed by the parser check; that is, if the
Google n-gram method judges the paraphrase to be
grammatical, then it is passed to the CCG parser for
an additional check. Adding the parser generally
increases the precision with a slight loss in recall.
Which settings are best to use in practice would de-
pend on how the steganography user wished to trade
off imperceptibility for payload.
</bodyText>
<sectionHeader confidence="0.916641" genericHeader="method">
5 Possible embedding method
</sectionHeader>
<bodyText confidence="0.999743333333333">
In this section, we propose a linguistic hiding
method which can be integrated with an automatic
paraphrasing system. It needs a large paraphrase
dictionary to determine modifiable phrases and pro-
vide available paraphrases. The embedding capacity
of the proposed linguistic stegosystem relies on the
number of paraphrasable sentences in the cover text.
If every sentence in the cover text is paraphrasable,
the system can have the maximum embedding ca-
pacity equal to 1 bit per sentence which is compara-
ble to other linguistic steganography methods using
syntactic transformations and synonym substitution.
</bodyText>
<table confidence="0.999782">
N- Context Accuracy Precision Recall F-measure
gram Size (%) (%) (%) (%)
2- 1 68.0 67.7 91.9 78.0
gram
3- 1 67.3 70.9 79.3 74.9
gram
2 69.5 77.7 70.7 74.0
4- 1 59.5 75.6 50.4 60.5
gram
2 53.8 88.6 28.5 43.1
3 52.0 92.2 24.0 38.1
5- 1 53.8 86.8 29.3 43.8
gram
2 43.3 95.2 8.1 15.0
3 41.0 100.0 4.1 7.8
4 41.0 100.0 4.1 7.8
</table>
<tableCaption confidence="0.9931675">
Table 5: Performance of google n-gram method with the
CCG parser filter
</tableCaption>
<subsectionHeader confidence="0.996706">
5.1 Data Embedding Procedure
</subsectionHeader>
<bodyText confidence="0.99995504">
First the sentences in a cover text T are identi-
fied using a sentence segmentation algorithm, giv-
ing N sentences s1, s2,... , sN. The paraphrasabil-
ity of each sentence is then checked using our au-
tomatic method. If a sentence contains at least one
paraphrasable phrase, we call the sentence a para-
phrasable sentence or a non-paraphrasable sen-
tence otherwise. Let D be the maximum number of
sentence boundaries between two subsequent para-
phrasable sentences in T. Thus, for every D sen-
tences within a cover text T, there will be at least
one paraphrasable sentence. Let every unit of D sen-
tences serve as one embedding unit in which a single
secret bit can be embedded. If we want to embed
0 in an embedding unit, we transform all the para-
phrasable sentences in this embedding unit to non-
paraphrasable sentences (assuming certain proper-
ties of the dictionary; see end of this section for dis-
cussion). If we want to embed 1, we leave the em-
bedding unit without any modifications.
Figure 5 demonstrates the embedding of the se-
cret bitstring 101 in a cover text containing nine sen-
tences t1, t2,... , t9 defined by a sentence segmenta-
tion algorithm. First, t1, t3, t4, t7 and t9 are de-
termined as paraphrasable sentences and thus D, the
</bodyText>
<page confidence="0.994636">
597
</page>
<figureCaption confidence="0.9990825">
Figure 5: Embedding secret bits in a cover text using sen-
tence segmentation method
</figureCaption>
<bodyText confidence="0.999987333333334">
size of an embedding unit, is 3. Next, we segment
the cover text into three embedding units u1, u2 and
u3, each of which contains three sentences. Since
we want to embed secret bits 101 in u1, u2 and u3 re-
spectively, the embedding unit u2 should contain no
paraphrasable sentence. That is, the paraphrasable
phrase in t4 should be replaced by its paraphrase.
Finally, the stego text is output and sent along with
the private key D to the other party. A private key is
known only to the parties that exchange messages.
In order for this method to work, we require cer-
tain properties of the paraphrase dictionary. For ex-
ample, it is crucial that, once a phrase has been para-
phrased, it does not produce another phrase that can
be paraphrased. This can be achieved by simply
requiring that any paraphrase ‘on the RHS’ of the
dictionary does not also appear as a phrase on the
LHS. In fact, this is not so unnatural for the Callison-
Burch dictionary, which consists of phrases mapped
to sets of paraphrases, many of which only appear
on one side.
</bodyText>
<subsectionHeader confidence="0.998478">
5.2 Data Extracting Procedure
</subsectionHeader>
<bodyText confidence="0.999930764705882">
For extracting the secret data, first, the stego text
V undergoes sentence segmentation, and N defined
sentences st1, st2,..., st are obtained. According
to the private key D, every D sentences are treated
as an information unit, and in each unit we check
the occurrence of paraphrasable sentences making
use of our paraphrasing method. If an information
unit contains at least one paraphrasable sentence,
this information unit implies the embedding of 1.
In contrast, if none of the sentences in the informa-
tion unit are paraphrasable, it implies the embedding
of 0. Hence, in order to recover the hidden mes-
sage, the receiver requires the sentence segmentation
algorithm, the paraphrase dictionary, the automatic
program determining grammaticality of paraphrases
in context, and the secret key D. The extraction pro-
cess essentially reverses the embedding method.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999986555555556">
The contributions of this paper are to develop an
automatic system for checking the grammaticality
and fluency of paraphrases in context, and the pro-
posal of using paraphrases as a suitable transfor-
mation for Linguistic Steganography. An advan-
tage of our proposed method is that it is somewhat
language and domain independent, requiring only a
paraphrase dictionary and a Google n-gram corpus,
both of which are likely to be available for a range
of languages in the future.
There are various practical issues in the applica-
tion of Linguistic Steganography systems that we
have chosen to ignore. For example, we have not
discussed the choice of cover text. If a newspaper ar-
ticle were chosen as the cover text, then any changes
could be easily found in practice by comparing the
stego text with the original article, which is likely
to be readily available. Another interesting ques-
tion that we have not addressed is whether some lan-
guages are better suited to Linguistic Steganography
than others, or whether some languages are better
suited to particular linguistic transformations than
others. Finally, we have only evaluated our gram-
matical checker and not the steganography system
itself (other than giving an indication of the likely
payload). How best to evaluate the imperceptibility
of such a system we leave to future work.
</bodyText>
<sectionHeader confidence="0.996455" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.7169362">
We would like to thank Chris Callison-Burch for pro-
viding the paraphrase dictionary, Katja Markert, Stephen
Pulman, Laura Rimell, and the anonymous reviewers for
useful comments. Ching-Yun Chang was funded by an
Oxford University Clarendon scholarship.
</bodyText>
<page confidence="0.997809">
598
</page>
<sectionHeader confidence="0.989168" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999888460784314">
Mikhail J. Atallah, Craig J. McDonough, Victor Raskin,
and Sergei Nirenburg. 2001a. Natural language pro-
cessing for information assurance and security: an
overview and implementations. In Proceedings of the
2000 workshop on New security paradigms, pages 51–
65, Ballycotton, County Cork, Ireland.
Mikhail J. Atallah, Victor Raskin, Michael C. Crogan,
Christian Hempelmann, Florian Kerschbaum, Dina
Mohamed, and Sanket Naik. 2001b. Natural lan-
guage watermarking: design, analysis, and a proof-
of-concept implementation. In Proceedings of the 4th
International Information Hiding Workshop, volume
2137, pages 185–199, Pittsburgh, Pennsylvania.
Mikhail J. Atallah, Victor Raskin, Christian F. Hempel-
mann, Mercan Karahan, Umut Topkara, Katrina E.
Triezenberg, and Radu Sion. 2002. Natural language
watermarking and tamperproofing. In Proceedings of
the 5th International Information Hiding Workshop,
pages 196–212, Noordwijkerhout, The Netherlands.
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of the 39th ACL, pages 50–57, Toulouse.
Richard Bergmair. 2007. A comprehensive bibliogra-
phy of linguistic steganography. In Proceedings of the
SPIE Conference on Security, Steganography, and Wa-
termarking of Multimedia Contents, volume 6505.
Shane Bergsma, Dekang Lin, and Randy Goebel. 2009.
Web-scale n-gram models for lexical disambiguation.
In Proceedings of the 21st International Joint Con-
ference on Artifical Intelligence, pages 1507–1512,
Pasadena, CA.
Igor A. Bolshakov. 2004. A method of linguistic
steganography based on coladdressally-verified syn-
onym. In Information Hiding: 6th International Work-
shop, volume 3200, pages 180–191, Toronto, Canada.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. In Pro-
ceedings of the EMNLP Conference, pages 196–205,
Honolulu, Hawaii.
Mark Chapman and George I. Davida. 1997. Hiding the
hidden: A software system for concealing ciphertext
as innocuous text. In Proceedings of the First Interna-
tional Conference on Information and Communication
Security, volume 1334, pages 335–345, Beijing.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG and
log-linear models. Comp. Ling., 33(4):493–552.
Jessica Fridrich. 2009. Steganography in Digital Media:
Principles, Algorithms, and Applications. Cambridge
University Press, first edition.
Yuling Liu, Xingming Sun, and Yong Wu. 2005. A nat-
ural language watermarking based on Chinese syntax.
In Advances in Natural Computation, volume 3612,
pages 958–961, Changsha, China.
Mitchell P. Marcus, Beatrice Santorini, and Mary A.
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English: the Penn Treebank. Computational
Linguistics, 19:313–330.
Hasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent
Sankur, A. Sumru Ozsoy, and Tunga Gungor. 2007.
Syntactic tools for text watermarking. In Proceed-
ings of the SPIE Conference on Security, Steganogra-
phy, and Watermarking of Multimedia Contents, vol-
ume 6505, San Jose, CA.
Brian Murphy and Carl Vogel. 2007. The syntax of con-
cealment: reliable methods for plain text information
hiding. In Proceedings of the SPIE Conference on Se-
curity, Steganography, and Watermarking of Multime-
dia Contents, volume 6505, San Jose, CA.
Brian Murphy. 2001. Syntactic information hiding in
plain text. Masters Thesis. Trinity College Dublin.
Lip Y. Por, Ang T. Fong, and B. Delina. 2008.
Whitesteg: a new scheme in information hiding using
text steganography. WSEAS Transactions on Comput-
ers, 7:735–745.
Cuneyt M. Taskiran, Mercan Topkara, and Edward J.
Delp. 2006. Attacks on linguistic steganography sys-
tems using text analysis. In Proceedings of the SPIE
Conference on Security, Steganography, and Water-
marking of Multimedia Contents, volume 6072, pages
97–105, San Jose, CA.
Mercan Topkara, Cuneyt M. Taskiran, and Edward J.
Delp. 2005. Natural language watermarking.
In Proceedings of the SPIE Conference on Secu-
rity, Steganography, and Watermarking of Multimedia
Contents, volume 5681, pages 441–452, San Jose, CA.
Mercan Topkara, Umut Topkara, and Mikhail J. Atallah.
2006a. Words are not enough: sentence level natural
language watermarking. In Proceedings of the ACM
Workshop on Content Protection and Security, pages
37–46, Santa Barbara, CA.
Umut Topkara, Mercan Topkara, and Mikhail J. Atal-
lah. 2006b. The hiding virtues of ambiguity: quan-
tifiably resilient watermarking of natural language text
through synonym substitutions. In Proceedings of the
8th Workshop on Multimedia and Security, pages 164–
174, Geneva, Switzerland.
M. Olga Vybornova and Benoit Macq. 2007. A
method of text watermarking using presuppositions.
In Proceedings of the SPIE Conference on Secu-
rity, Steganography, and Watermarking of Multimedia
Contents, volume 6505, San Jose, CA.
</reference>
<page confidence="0.99874">
599
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.335486">
<title confidence="0.999819">Linguistic Steganography Using Automatically Generated Paraphrases</title>
<author confidence="0.998407">Ching-Yun Chang Stephen Clark</author>
<affiliation confidence="0.710439333333333">University of Cambridge University of Cambridge Computer Laboratory Computer Ching-Yun.Chang@cl.cam.ac.uk Stephen.Clark@cl.cam.ac.uk</affiliation>
<abstract confidence="0.998990117647059">This paper describes a method for checking the acceptability of paraphrases in context. use the Google n-gram data and a parser to certify the paraphrasing grammaticality and fluency. We collect a corpus of human judgements to evaluate our system. The ultimate goal of our work is to integrate text paraphrasing into a Linguistic Steganography system, by using paraphrases to hide information in a cover text. We propose automatically generated paraphrases as a new and useful source of transformations for Linguistic Steganography, and show that our method for checking paraphrases is effective at maintaining a high level of imperceptibility, which is crucial for effective steganography.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Craig J McDonough</author>
<author>Victor Raskin</author>
<author>Sergei Nirenburg</author>
</authors>
<title>Natural language processing for information assurance and security: an overview and implementations.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2000 workshop on New security paradigms,</booktitle>
<pages>51--65</pages>
<location>Ballycotton, County Cork, Ireland.</location>
<contexts>
<context position="7805" citStr="Atallah et al. (2001" startWordPosition="1248" endWordPosition="1251">on of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution me</context>
<context position="9490" citStr="Atallah et al. (2001" startWordPosition="1513" endWordPosition="1516">mbedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al. (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the </context>
</contexts>
<marker>Atallah, McDonough, Raskin, Nirenburg, 2001</marker>
<rawString>Mikhail J. Atallah, Craig J. McDonough, Victor Raskin, and Sergei Nirenburg. 2001a. Natural language processing for information assurance and security: an overview and implementations. In Proceedings of the 2000 workshop on New security paradigms, pages 51– 65, Ballycotton, County Cork, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Victor Raskin</author>
<author>Michael C Crogan</author>
<author>Christian Hempelmann</author>
<author>Florian Kerschbaum</author>
<author>Dina Mohamed</author>
<author>Sanket Naik</author>
</authors>
<title>Natural language watermarking: design, analysis, and a proofof-concept implementation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 4th International Information Hiding Workshop,</booktitle>
<volume>2137</volume>
<pages>185--199</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="7805" citStr="Atallah et al. (2001" startWordPosition="1248" endWordPosition="1251">on of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution me</context>
<context position="9490" citStr="Atallah et al. (2001" startWordPosition="1513" endWordPosition="1516">mbedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al. (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the </context>
</contexts>
<marker>Atallah, Raskin, Crogan, Hempelmann, Kerschbaum, Mohamed, Naik, 2001</marker>
<rawString>Mikhail J. Atallah, Victor Raskin, Michael C. Crogan, Christian Hempelmann, Florian Kerschbaum, Dina Mohamed, and Sanket Naik. 2001b. Natural language watermarking: design, analysis, and a proofof-concept implementation. In Proceedings of the 4th International Information Hiding Workshop, volume 2137, pages 185–199, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Victor Raskin</author>
<author>Christian F Hempelmann</author>
<author>Mercan Karahan</author>
<author>Umut Topkara</author>
<author>Katrina E Triezenberg</author>
<author>Radu Sion</author>
</authors>
<title>Natural language watermarking and tamperproofing.</title>
<date>2002</date>
<booktitle>In Proceedings of the 5th International Information Hiding Workshop,</booktitle>
<pages>196--212</pages>
<location>Noordwijkerhout, The Netherlands.</location>
<contexts>
<context position="9935" citStr="Atallah et al. (2002)" startWordPosition="1577" endWordPosition="1580"> category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al. (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tree structure with information available from ontological semantic resources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn</context>
</contexts>
<marker>Atallah, Raskin, Hempelmann, Karahan, Topkara, Triezenberg, Sion, 2002</marker>
<rawString>Mikhail J. Atallah, Victor Raskin, Christian F. Hempelmann, Mercan Karahan, Umut Topkara, Katrina E. Triezenberg, and Radu Sion. 2002. Natural language watermarking and tamperproofing. In Proceedings of the 5th International Information Hiding Workshop, pages 196–212, Noordwijkerhout, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th ACL,</booktitle>
<pages>50--57</pages>
<location>Toulouse.</location>
<contexts>
<context position="12378" citStr="Barzilay and McKeown (2001)" startWordPosition="1973" endWordPosition="1976">. Each paraphrase also has a probability, based on a statistical machine translation model, but we do not use that feature here. The examples show that, while some of the paraphrases are of a high quality, some are not. For example, differences is unlikely to be a suitable paraphrase for a number of people in any context. Moreover, there are some (phrase, paraphrase) pairs which are only suitable in particular contexts. For example, year end is an unsuitable paraphrase for the end of this year in the sentence The chart compares the gold price at the end of last year with the end of this year. Barzilay and McKeown (2001) also note that the applicability of paraphrases is strongly influenced by context. Section 4 describes our method for determining if a paraphrase is suitable in a given context. 3.2 Google N-gram Data The Google n-gram data was collected by Google Research for statistical language modelling, and has been used for many tasks such as lexical disambiguation (Bergsma et al., 2009), and contains English n-grams and their observed frequency counts, for counts of at least 40. The striking feature of Figure 2: The web-based annotation system the n-gram corpus is the large number of n-grams and the si</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th ACL, pages 50–57, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Bergmair</author>
</authors>
<title>A comprehensive bibliography of linguistic steganography.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<contexts>
<context position="2556" citStr="Bergmair, 2007" startWordPosition="397" endWordPosition="398">que. Since the difference between 11111111 and 11111110 in the value for red/green/blue intensity is likely to be undetectable by the human eye, the LSB can be used to hide information other than colour, without being perceptable by a human observer.1 A key question for any steganography system is the choice of cover medium. Given the ubiquitous nature of natural languages and electronic text, text is an obvious medium to consider. However, the literature on Linguistic Steganography, in which linguistic properties of a text are modified to hide information, is small compared with other media (Bergmair, 2007). The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer. Language has the property that even small local changes to a text, e.g. replacing a word by a word with similar meaning, may result in text which is anomalous at the document level, or anomalous with respect to the state of the world. Hence finding linguistic transformations which can be applied reliably and often is a challenging problem for Linguistic Steganography. In this paper we focus on steganography rather than watermarking, since we are interested in </context>
</contexts>
<marker>Bergmair, 2007</marker>
<rawString>Richard Bergmair. 2007. A comprehensive bibliography of linguistic steganography. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Web-scale n-gram models for lexical disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st International Joint Conference on Artifical Intelligence,</booktitle>
<pages>1507--1512</pages>
<location>Pasadena, CA.</location>
<contexts>
<context position="12758" citStr="Bergsma et al., 2009" startWordPosition="2036" endWordPosition="2039">only suitable in particular contexts. For example, year end is an unsuitable paraphrase for the end of this year in the sentence The chart compares the gold price at the end of last year with the end of this year. Barzilay and McKeown (2001) also note that the applicability of paraphrases is strongly influenced by context. Section 4 describes our method for determining if a paraphrase is suitable in a given context. 3.2 Google N-gram Data The Google n-gram data was collected by Google Research for statistical language modelling, and has been used for many tasks such as lexical disambiguation (Bergsma et al., 2009), and contains English n-grams and their observed frequency counts, for counts of at least 40. The striking feature of Figure 2: The web-based annotation system the n-gram corpus is the large number of n-grams and the size of the counts, since the counts were extracted from over 1 trillion word tokens of English text on publicly accessible Web pages collected in January 2006. For example, the 5-gram phrase the part that you were has a count of 103. The compressed data is around 24 GB on disk. 3.3 Paraphrase Judgement Corpus The focus of the paper is to develop an automatic system for checking </context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2009</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2009. Web-scale n-gram models for lexical disambiguation. In Proceedings of the 21st International Joint Conference on Artifical Intelligence, pages 1507–1512, Pasadena, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Bolshakov</author>
</authors>
<title>A method of linguistic steganography based on coladdressally-verified synonym.</title>
<date>2004</date>
<booktitle>In Information Hiding: 6th International Workshop,</booktitle>
<volume>3200</volume>
<pages>180--191</pages>
<location>Toronto, Canada.</location>
<contexts>
<context position="7825" citStr="Bolshakov (2004)" startWordPosition="1252" endWordPosition="1253">check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic </context>
</contexts>
<marker>Bolshakov, 2004</marker>
<rawString>Igor A. Bolshakov. 2004. A method of linguistic steganography based on coladdressally-verified synonym. In Information Hiding: 6th International Workshop, volume 3200, pages 180–191, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the EMNLP Conference,</booktitle>
<pages>196--205</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="5697" citStr="Callison-Burch (2008)" startWordPosition="904" endWordPosition="905">ed to embed hidden bits in text. Section 2 describes some of the previous transformations used in Linguistic Steganography. Note that we are concerned with transformations which are 2The message may have been encrypted initially also, as in the figure, but this is not important in this paper; the key point is that the hidden message is a sequence of bits. linguistic in nature, rather than dealing with superficial properties of the text, e.g. the amount of white space between words (Por et al., 2008). Our proposed method is based on the automatically acquired paraphrase dictionary described in Callison-Burch (2008), in which the application of paraphrases from the dictionary encodes secret bits. One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts. Since we require any changes to be imperceptible to a human observer, it is crucial to our system that any uses of paraphrasing are grammatical and retain the meaning of the original cover text. In order to test the grammaticality and meaning preserving nature of a paraphrase, we employ a </context>
<context position="10782" citStr="Callison-Burch (2008)" startWordPosition="1708" endWordPosition="1709">ources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn Treebank (Marcus et al., 1993). Hence we require possible paraphrases for phrases that occur in Section 00. The paraphrase dictionary that we use was generated for us by Chris Callison-Burch, using the technique described in Callison-Burch (2008), which exploits a parallel corpus and methods developed for statistical machine translation. Table 1 gives summary statistics of the paraphrase dictionary and its coverage on Section 00 of the Penn Treebank. The length of the extracted n-gram phrases ranges from unigrams to five-grams. The coverage figure gives the percentage of sentences which have at least one phrase in the dictionary. The coverage is important for us because it determines the payload capacity of the embedding method described in Section 5. Table 2 lists some examples 5-gram phrases and paraphrases from the dictionary. The </context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of the EMNLP Conference, pages 196–205, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Chapman</author>
<author>George I Davida</author>
</authors>
<title>Hiding the hidden: A software system for concealing ciphertext as innocuous text.</title>
<date>1997</date>
<booktitle>In Proceedings of the First International Conference on Information and Communication Security,</booktitle>
<volume>1334</volume>
<pages>335--345</pages>
<location>Beijing.</location>
<contexts>
<context position="7762" citStr="Chapman and Davida (1997)" startWordPosition="1240" endWordPosition="1243">by the parser. This method increases the precision of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits p</context>
</contexts>
<marker>Chapman, Davida, 1997</marker>
<rawString>Mark Chapman and George I. Davida. 1997. Hiding the hidden: A software system for concealing ciphertext as innocuous text. In Proceedings of the First International Conference on Information and Communication Security, volume 1334, pages 335–345, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Comp. Ling.,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="7011" citStr="Clark and Curran, 2007" startWordPosition="1122" endWordPosition="1125">e Google ngram corpus. This technique is based on the simple hypothesis that, if the paraphrase in context has been used many times before on the web, then it is an appropriate use. We test our n-gram-based system against some human judgements of the grammaticality of paraphrases in context. We find that using larger contexts leads to a high precision system (100% when using 5-grams), but at the cost of a reduced recall. This precision-recall tradeoff reflects the inherent tradeoff between imperceptibility and payload in a Linguistic Steganography system. We also experiment with a CCG parser (Clark and Curran, 2007), requiring that the contexts surrounding the original phrase and paraphrase are assigned 592 the same CCG lexical categories by the parser. This method increases the precision of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal mo</context>
<context position="19780" citStr="Clark and Curran (2007)" startWordPosition="3263" endWordPosition="3266">o account, namely W32. However, If the paraphrase P&apos; fails the current (n, C) check the checking procedure will terminate and report that the paraphrase fails. In contrast, if the paraphrase passes all the (n, C) checks where C = 1 to maxC, the procedure determines the paraphrase as acceptable. What is happening is that an ngram window is effectively being shifted across the paraphrase boundary to include different amounts of context and paraphrase. 4.2 Syntactic Filter In order to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method. We use the Clark and Curran (2007) CCG parser to analyse the sentence before and after paraphrasing. Combinatory Categorial Grammar (CCG) is a lexicalised grammar formalism, in which CCG lexical categories — typically expressing subcategorisation information — are assigned to each word in a sentence. The grammatical check works by checking if the words in the sentence outside of the phrase and paraphrase receive the same lexical categories before and after paraphrasing. If there is any change in lexical category assignment to these words then the paraphrase is judged ungrammatical. Hence the grammar check is at the word, rathe</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Comp. Ling., 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Fridrich</author>
</authors>
<title>Steganography in Digital Media: Principles, Algorithms, and Applications.</title>
<date>2009</date>
<publisher>Cambridge University Press,</publisher>
<note>first edition.</note>
<contexts>
<context position="1175" citStr="Fridrich, 2009" startWordPosition="170" endWordPosition="171">phrasing into a Linguistic Steganography system, by using paraphrases to hide information in a cover text. We propose automatically generated paraphrases as a new and useful source of transformations for Linguistic Steganography, and show that our method for checking paraphrases is effective at maintaining a high level of imperceptibility, which is crucial for effective steganography. 1 Introduction Steganography is concerned with hiding information in some cover medium, by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer (Fridrich, 2009). The covert communication is such that the very act of communication is to be kept secret from outside observers. A related area is Watermarking, in which modifications are made to a cover medium in order to identify it, for example for the purposes of copyright. Here the changes may be known to an observer, and the task is to make the changes in such a way that the watermark cannot easily be removed. There is a large literature on image steganography and watermarking, in which images are modified to encode a hidden message or watermark. Image stegosystems exploit the redundancy in an image r</context>
</contexts>
<marker>Fridrich, 2009</marker>
<rawString>Jessica Fridrich. 2009. Steganography in Digital Media: Principles, Algorithms, and Applications. Cambridge University Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuling Liu</author>
<author>Xingming Sun</author>
<author>Yong Wu</author>
</authors>
<title>A natural language watermarking based on Chinese syntax.</title>
<date>2005</date>
<booktitle>In Advances in Natural Computation,</booktitle>
<volume>3612</volume>
<pages>958--961</pages>
<location>Changsha, China.</location>
<contexts>
<context position="9183" citStr="Liu et al. (2005)" startWordPosition="1466" endWordPosition="1469">based on the fact that a sentence can be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the c</context>
</contexts>
<marker>Liu, Sun, Wu, 2005</marker>
<rawString>Yuling Liu, Xingming Sun, and Yong Wu. 2005. A natural language watermarking based on Chinese syntax. In Advances in Natural Computation, volume 3612, pages 958–961, Changsha, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="10566" citStr="Marcus et al., 1993" startWordPosition="1673" endWordPosition="1676">tic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tree structure with information available from ontological semantic resources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn Treebank (Marcus et al., 1993). Hence we require possible paraphrases for phrases that occur in Section 00. The paraphrase dictionary that we use was generated for us by Chris Callison-Burch, using the technique described in Callison-Burch (2008), which exploits a parallel corpus and methods developed for statistical machine translation. Table 1 gives summary statistics of the paraphrase dictionary and its coverage on Section 00 of the Penn Treebank. The length of the extracted n-gram phrases ranges from unigrams to five-grams. The coverage figure gives the percentage of sentences which have at least one phrase in the dict</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary A. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasan M Meral</author>
<author>Emre Sevinc</author>
<author>Ersin Unkar</author>
<author>Bulent Sankur</author>
<author>A Sumru Ozsoy</author>
<author>Tunga Gungor</author>
</authors>
<title>Syntactic tools for text watermarking.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="9204" citStr="Meral et al. (2007)" startWordPosition="1470" endWordPosition="1473">hat a sentence can be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-ar</context>
</contexts>
<marker>Meral, Sevinc, Unkar, Sankur, Ozsoy, Gungor, 2007</marker>
<rawString>Hasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent Sankur, A. Sumru Ozsoy, and Tunga Gungor. 2007. Syntactic tools for text watermarking. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Murphy</author>
<author>Carl Vogel</author>
</authors>
<title>The syntax of concealment: reliable methods for plain text information hiding.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="9244" citStr="Murphy and Vogel (2007)" startWordPosition="1476" endWordPosition="1479">to more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some s</context>
</contexts>
<marker>Murphy, Vogel, 2007</marker>
<rawString>Brian Murphy and Carl Vogel. 2007. The syntax of concealment: reliable methods for plain text information hiding. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Murphy</author>
</authors>
<title>Syntactic information hiding in plain text. Masters Thesis. Trinity College Dublin.</title>
<date>2001</date>
<contexts>
<context position="9219" citStr="Murphy (2001)" startWordPosition="1474" endWordPosition="1475"> transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP techn</context>
</contexts>
<marker>Murphy, 2001</marker>
<rawString>Brian Murphy. 2001. Syntactic information hiding in plain text. Masters Thesis. Trinity College Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lip Y Por</author>
<author>Ang T Fong</author>
<author>B Delina</author>
</authors>
<title>Whitesteg: a new scheme in information hiding using text steganography.</title>
<date>2008</date>
<journal>WSEAS Transactions on Computers,</journal>
<pages>7--735</pages>
<contexts>
<context position="5580" citStr="Por et al., 2008" startWordPosition="886" endWordPosition="889">ramework, and for readers unfamiliar with linguistic steganography shows how linguistic transformations can be used to embed hidden bits in text. Section 2 describes some of the previous transformations used in Linguistic Steganography. Note that we are concerned with transformations which are 2The message may have been encrypted initially also, as in the figure, but this is not important in this paper; the key point is that the hidden message is a sequence of bits. linguistic in nature, rather than dealing with superficial properties of the text, e.g. the amount of white space between words (Por et al., 2008). Our proposed method is based on the automatically acquired paraphrase dictionary described in Callison-Burch (2008), in which the application of paraphrases from the dictionary encodes secret bits. One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts. Since we require any changes to be imperceptible to a human observer, it is crucial to our system that any uses of paraphrasing are grammatical and retain the meaning of the</context>
</contexts>
<marker>Por, Fong, Delina, 2008</marker>
<rawString>Lip Y. Por, Ang T. Fong, and B. Delina. 2008. Whitesteg: a new scheme in information hiding using text steganography. WSEAS Transactions on Computers, 7:735–745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cuneyt M Taskiran</author>
<author>Mercan Topkara</author>
<author>Edward J Delp</author>
</authors>
<title>Attacks on linguistic steganography systems using text analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>6072</volume>
<pages>97--105</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="7849" citStr="Taskiran et al. (2006)" startWordPosition="1254" endWordPosition="1257">t loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The seco</context>
</contexts>
<marker>Taskiran, Topkara, Delp, 2006</marker>
<rawString>Cuneyt M. Taskiran, Mercan Topkara, and Edward J. Delp. 2006. Attacks on linguistic steganography systems using text analysis. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6072, pages 97–105, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mercan Topkara</author>
<author>Cuneyt M Taskiran</author>
<author>Edward J Delp</author>
</authors>
<title>Natural language watermarking.</title>
<date>2005</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>5681</volume>
<pages>441--452</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="8283" citStr="Topkara et al. (2005)" startWordPosition="1327" endWordPosition="1330">with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The second and the most widely used manipulations for linguistic steganography are syntactic transformations. This method is based on the fact that a sentence can be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded infor</context>
</contexts>
<marker>Topkara, Taskiran, Delp, 2005</marker>
<rawString>Mercan Topkara, Cuneyt M. Taskiran, and Edward J. Delp. 2005. Natural language watermarking. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 5681, pages 441–452, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mercan Topkara</author>
<author>Umut Topkara</author>
<author>Mikhail J Atallah</author>
</authors>
<title>Words are not enough: sentence level natural language watermarking.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACM Workshop on Content Protection and Security,</booktitle>
<pages>37--46</pages>
<location>Santa Barbara, CA.</location>
<contexts>
<context position="7874" citStr="Topkara et al. (2006" startWordPosition="1259" endWordPosition="1263">ution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The second and the most widely us</context>
<context position="9269" citStr="Topkara et al. (2006" startWordPosition="1481" endWordPosition="1484">y equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and kn</context>
</contexts>
<marker>Topkara, Topkara, Atallah, 2006</marker>
<rawString>Mercan Topkara, Umut Topkara, and Mikhail J. Atallah. 2006a. Words are not enough: sentence level natural language watermarking. In Proceedings of the ACM Workshop on Content Protection and Security, pages 37–46, Santa Barbara, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Umut Topkara</author>
<author>Mercan Topkara</author>
<author>Mikhail J Atallah</author>
</authors>
<title>The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 8th Workshop on Multimedia and Security,</booktitle>
<pages>164--174</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="7874" citStr="Topkara et al. (2006" startWordPosition="1259" endWordPosition="1263">ution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al. (2001a), Bolshakov (2004), Taskiran et al. (2006) and Topkara et al. (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al. (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al. (2005) and Topkara et al. (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The second and the most widely us</context>
<context position="9269" citStr="Topkara et al. (2006" startWordPosition="1481" endWordPosition="1484">y equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al. (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al. (2005), Meral et al. (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al. (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al. (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and kn</context>
</contexts>
<marker>Topkara, Topkara, Atallah, 2006</marker>
<rawString>Umut Topkara, Mercan Topkara, and Mikhail J. Atallah. 2006b. The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions. In Proceedings of the 8th Workshop on Multimedia and Security, pages 164– 174, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Olga Vybornova</author>
<author>Benoit Macq</author>
</authors>
<title>A method of text watermarking using presuppositions.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="10194" citStr="Vybornova and Macq (2007)" startWordPosition="1615" endWordPosition="1618">entence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al. (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tree structure with information available from ontological semantic resources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn Treebank (Marcus et al., 1993). Hence we require possible paraphrases for phrases that occur in Section 00. The paraphrase dictionary that we use was generated for us by Chris Callison-Burch, using the technique described in Callison-Burch (2008), which expl</context>
</contexts>
<marker>Vybornova, Macq, 2007</marker>
<rawString>M. Olga Vybornova and Benoit Macq. 2007. A method of text watermarking using presuppositions. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>