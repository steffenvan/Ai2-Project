<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992157">
Mention Detection Crossing the Language Barrier
</title>
<author confidence="0.626599">
Imed Zitouni and Radu Florian
</author>
<affiliation confidence="0.550274">
IBM T.J. Watson Research Center
</affiliation>
<address confidence="0.841408">
1101 Kitchawan Rd, Yorktown Heights, NY 10598
</address>
<email confidence="0.996864">
{izitouni, raduf}@us.ibm.com
</email>
<sectionHeader confidence="0.997369" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999774107142857">
While significant effort has been put into an-
notating linguistic resources for several lan-
guages, there are still many left that have
only small amounts of such resources. This
paper investigates a method of propagat-
ing information (specifically mention detec-
tion information) into such low resource
languages from richer ones. Experiments
run on three language pairs (Arabic-English,
Chinese-English, and Spanish-English) show
that one can achieve relatively decent perfor-
mance by propagating information from a lan-
guage with richer resources such as English
into a foreign language alone (no resources
or models in the foreign language). Fur-
thermore, while examining the performance
using various degrees of linguistic informa-
tion in a statistical framework, results show
that propagated features from English help
improve the source-language system perfor-
mance even when used in conjunction with all
feature types built from the source language.
The experiments also show that using propa-
gated features in conjunction with lexically-
derived features only (as can be obtained di-
rectly from a mention annotated corpus) yields
similar performance to using feature types de-
rived from many linguistic resources.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991977511627907">
Information extraction is a crucial step toward un-
derstanding a text, as it identifies the important con-
ceptual objects and relations between them in a dis-
course. It includes classification, filtering, and se-
lection based on the language content of the source
data, i.e., based on the meaning conveyed by the
data. It is a crucial step for several applications,
such as summarization, information retrieval, data
mining, question answering, language understand-
ing, etc. This paper addresses an important and basic
task of information extraction: mention detection1:
the identification and classification of textual refer-
ences to objects/abstractions mentions, which can be
either named (e.g. John Smith), nominal (the presi-
dent) or pronominal (e.g. he, she). For instance, in
the sentence
President John Smith said he has no
comments.
there are three mentions: President, John Smith and
he. This is similar to the named entity recognition
(NER) task with the additional twist of also identi-
fying nominal and pronominal mentions.
A few languages have received a lot of attention
in terms of natural language resources that were cre-
ated – for instance, in English one has access to la-
beled part-of-speech data, word sense information,
parse tree structure, discourse, semantic role labeles,
named entity data, to name just a few (our apologies
if we missed your favorite resource). There are a few
other languages that also have annotated resources
(such as Arabic, Chinese, German, French, Spanish,
etc), but also a very large number of languages with
few resources. It would be very useful if one could
make use of the resources in the former languages
to help bootstrapping (or just the projection) of re-
source in any resource-challenged language.
Information transfer from a language to another
can be very useful when the “donor” language has
more resources than the receiving one. As resources
grow in quantity and quality in the receiving lan-
guage, it becomes less and less likely that there will
be a gain in performance by transfering information,
as there are several sources of noise involved in the
</bodyText>
<footnote confidence="0.984696">
1We adopt here the ACE (NIST, 2007) nomenclature
</footnote>
<page confidence="0.859633">
600
</page>
<note confidence="0.962659">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 600–609,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999885961538462">
process - such as the translation (machine generated
or not) and the inherent imperfection of the mention
detection in the donor language. To test this hypoth-
esis, we conducted experiments on systems build
with a varied amount of resources in the receiv-
ing language, starting with the case where there are
none2 (all information is transferred through transla-
tion alignment), and ending with the case where we
used all the resources we could gather for that lan-
guage. The experiments will show that the gain in
performance decreases with the amount of resources
used in the source language, but, still, even when all
resources were used, a statistically significant gain
was still observed.
Similarly to classical NLP tasks such as text
chunking (Ramshaw and Marcus, 1995) and named
entity recognition (Tjong Kim Sang, 2002), we for-
mulate mention detection as a sequence classifica-
tion problem, by assigning a label to each token in
the text, indicating whether it starts a specific men-
tion, is inside a specific mention, or is outside any
mentions. The classification is performed with a sta-
tistical approach, built around the maximum entropy
(MaxEnt) principle (Berger et al., 1996), that has the
advantage of combining arbitrary types of informa-
tion in making a classification decision.
</bodyText>
<sectionHeader confidence="0.998644" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99998075">
There are several investigations in literature that
explore using parallel corpora to transfer informa-
tion content from one language (most of the time
English) to another. The earliest investigations of
the subject have been performed, on word sense
disambiguation (Dagan et al., 1991; P.F.Brown et
al., 1991; Gale et al., 1992) (perhaps unsurpris-
ingly given its close connection to machine trans-
lation) – all propose and (lightly) evaluate methods
to use word sense information extracted from the
target language to help the sense resolution in the
source language and machine translation. (Dagan
and Itai, 1994) explicitly suggests performing word
sense disambiguation in the target language (English
in the article) with the goal of resolving ambiguity in
the source language (Hebrew), and show moderate
</bodyText>
<footnote confidence="0.942144333333333">
2While applying this method in the case where the source
language has absolutely no resources might be an interesting
test case, we don’t see it as being realistic. Resources are build
nowadays in a large variety of languages, and not making use
of them is rather foolish (a certain big bird and sand comes to
mind).
</footnote>
<bodyText confidence="0.999802212765958">
improvement on a small data set3. More recently,
(Diab and Resnik, 2001) presents a method for per-
forming word sense tagging in both the source and
target texts of parallel bilingual corpora with the En-
glish WordNet sense inventory, by using translation
correspondences.
On more general cross-language information
transfer, (Yarowsky et al., 2001) proposed and eval-
uated a method of propagating POS tagging, named
mention, base noun phrase, and morphological in-
formation from English into a foreign language,
which is very similar to the one presented in this
article (experiments were run on French, Chinese,
Czech, and Spanish – on human-generated transla-
tions). Their results show a significant improvement
in performance while building an automatic classi-
fier on the projected annotations over the same au-
tomatic classifier trained on a small amount of an-
notated data in the source language. (Riloff et al.,
2002) extends the ideas in (Yarowsky et al., 2001),
by showing how it can be used, in conjunction with
an automatically trained information extraction sys-
tem on the source language, to bootstrap the annota-
tion of resources in the target language. They show
that they can obtain 48 F-measure on a information
extraction task identifying locations, vehicles and
victims in plane crashes. (Hwa et al., 2002) proposes
a framework that enables the acquisition of syntactic
dependency trees for low-resource languages by im-
porting linguistic annotation from rich-resource lan-
guages (English). The authors run a large-scale ex-
periment in which Chinese dependency parses were
induced from English, and show that a parser trained
on the resulting trees outperformed simple baselines.
(Cabezas et al., 2001) investigates a similar method
of propagating syntactic treebank-like annotations
from English to Spanish.
Finally, a large body of research has been done
on cross-language information retrieval, where the
goal is to find information in one language (e.g. Chi-
nese newswire) corresponding to a query in a differ-
ent language (e.g. English) – although the list of rel-
evant papers is too long to be mentioned here (see,
for instance, (Grefenstette, 1998)).
The work presented here differs from the infor-
mation extraction investigations presented above in
two aspects:
</bodyText>
<listItem confidence="0.96643">
• it handles unrestricted text and a full set of
</listItem>
<footnote confidence="0.915985">
3Very small by “modern” standards - 137 examples. Prob-
ably because at the time the article was written, there were no
large publicly annotated databases, such as Semcor.
</footnote>
<page confidence="0.997823">
601
</page>
<bodyText confidence="0.9907775">
mention types (the ACE entity types) during the
information transfer
</bodyText>
<listItem confidence="0.998989571428571">
• it investigates whether using a resource-rich
language (English) can improve on the perfor-
mance obtained by using various degrees of ex-
istent resources in the source language (Arabic,
Chinese, Spanish)
• the information transfer is performed over ma-
chine generated translations and alignments.
</listItem>
<sectionHeader confidence="0.956293" genericHeader="method">
3 Mention Detection
</sectionHeader>
<bodyText confidence="0.969076647058824">
As mentioned in the introduction, the mention detec-
tion problem is formulated as a classification prob-
lem, by assigning to each token in the text a label,
indicating whether it starts a specific mention, is in-
side a specific mention, or is outside any mentions.
Good performance in many natural language pro-
cessing tasks has been shown to depend heavily on
integrating many sources of information (Florian et
al., 2004).4 Given this observation, we are interested
in algorithms that can easily integrate and make ef-
fective use of diverse input types. We select a ex-
ponential classifier, the Maximum Entropy (MaxEnt
henceforth) classifier that integrates arbitrary types
of information and makes a classification decision
by aggregating all information available for a given
classification. But the reader can replace it with her
favorite feature-based classifier throughout the pa-
per.
To help with the presentation, we introduce some
notations: let Y = {y1, ... , yn} be the set of pre-
dicted classes, X be the example space and F =
{0,1}m be a feature space. Each example x ∈ X
has associated a vector of m binary features f (x) =
(f1 (x) , ... , fm (x)). The goal of the training pro-
cess is to associate examples x ∈ X with either
a probability distribution over the labels from Y,
P (·|x)(if we are interested in soft classification) or
associate one label y ∈ Y (if we are interested in
hard classification).
The MaxEnt algorithm associates a set of weights
{αij}i=1...n
j=1...m with the features (fj)i, and computes
the probability distribution as f� (x,yi)
x 1 17b
</bodyText>
<equation confidence="0.977515">
P af
(yil ) = Z(x) � U ( )
j=1
</equation>
<footnote confidence="0.8630754">
4In
sifier method itself.
fact, the feature set used for classification has a much
larger impact on the performance of the resulting system than
the clas
</footnote>
<bodyText confidence="0.959576571428571">
where Z(x) is a normalization factor. The
data (Berger et al., 1996). In this paper, the Max-
Ent model is trained using the sequential condi-
tional generalized iterative scaling (SCGIS) tech-
nique (Goodman, 2002), and it uses a Gaussian
prior for regularization (Chen and Rosenfeld, 2000).
Now take
</bodyText>
<equation confidence="0.665868857142857">
=
... xN), a sequence of
contiguous tokens (i.e., a sentence or a document) in
the source lan
{αij}j=1...m
xN1
(x1,x2,
</equation>
<bodyText confidence="0.997616">
guage. The goal of mention detection
system is to find the most likely sequence of labels
yN1 = (y1, y2 . . . yN) that best matches the input xN1 .
In the mention detection case, each token xi in xN1
is tagged with a label yi as follows:5
</bodyText>
<listItem confidence="0.9985199">
• if
not part of any entity, yi = O (O for
any
• if it is part of an entity, itis composed of a sub-
tag specifying whether it starts a mention (B-)
or is inside a mention (I-), and asub-type cor-
responding to mention type (e.g. B-PERSON).
In ACE, there are seven possible types: person,
organization, location, facility, geopolitical en-
tity (GPE), weapon, an
</listItem>
<bodyText confidence="0.6837215">
it’s
“out-
side
mentions”)
d vehicle.
weights are estimated during the train-
ing phase to maximize the likelihood of the
To compute the best sequence yN1 , we use
</bodyText>
<equation confidence="0.9690946">
yJ
Y= arg max
yˆ
j
,
</equation>
<bodyText confidence="0.8718646">
kl has an exponential form of
where P (9j
x
the type (2). We also used the standard Markov as-
sumption that the probability P (yj
</bodyText>
<equation confidence="0.97822">
x
, y1
</equation>
<bodyText confidence="0.9398892">
11 only
depends on the previous k classifications. J This
model is similar to the MEMM model (McCallum
et al., 2000), but it does not separate the probability
into generation probabilities and transition probabil-
ities, and, crucially, has access to
observed
features (i.e. it can examine the entire
sequence,
though in practice it will only examine some small
</bodyText>
<equation confidence="0.969682071428571">
N1
−
|
|
N1
−
“future”
xN1
of it) – which is one way of eliminating label
602
yN1 = arg max
ˆyN
P
(�yN�
1|xN1
= arg max
P (9j
x
,
11
Y
|
N1
−
P (9j
part
mention encoding is the
encoding presented in
</equation>
<subsectionHeader confidence="0.525351">
(Tjong Kim Sang and Veenstra, 1999) and introduced by
</subsectionHeader>
<bodyText confidence="0.699976">
and Marcus, 1994) for base noun phras
</bodyText>
<equation confidence="0.924122666666667">
5The
IOB2
(Ramshaw
e chunking.
Z(x) = X Y
i j
αf�(x,yi)
ij
x
|
N1
�−k)
</equation>
<bodyText confidence="0.99678325">
bias observed by (Lafferty et al., 2001).6
The experiments are run on four languages, part
of the ACE-2007 evaluation (NIST, 2007): Arabic,
Chinese, English and Spanish.7 Systems across the
languages use a large range of features, including
lexical (words and morphs in a 3-word window, pre-
fixes and suffixes of length up to 4 characters, Word-
Net (Miller, 1995) for English), syntactic (POS tags,
text chunks), and the output of other information ex-
traction models. These features were described in
(Florian et al., 2004), and are not discussed here. In
this paper we focus on the examining the benefit of
cross-language mention propagation information in
improving mention detection systems.
Besides generic types of features, we also have
implemented language-specific features:
</bodyText>
<listItem confidence="0.993135071428571">
• In Arabic, blank-delimited words are com-
posed of zero or more prefixes, followed by a
stem and zero or more suffixes. Each prefix,
stem or suffix is a token; any contiguous se-
quence of tokens can represent a mention. Sim-
ilar to the approaches described in (Florian et
al., 2004) and (Zitouni et al., 2005), we decided
to “condition” the output of the system on the
segmented data: the text is segmented first into
tokens and classification is then performed on
tokens. The segmentation model is similar to
the one presented by (Lee et al., 2003) and ob-
tains an accuracy of 98%.
• In Chinese text, unlike in Indo-European lan-
guages, words neither are white-space delim-
ited nor do they have capitalization markers.
Instead of a word-based model, we build a
character-based one, since word segmentation
errors can lead to irrecoverable mention detec-
tion errors; Jing et al. (2003) also observes that
character-based models are better performing
than word-based ones. Word segmentation in-
formation is still useful and is integrated as an
additional feature stream.
• In English and in Spanish mention detection
systems are similar to those described in (Flo-
rian et al., 2004) where words are the tokens to
classify.
</listItem>
<footnote confidence="0.9973336">
6In fact their example of label bias can be trivially solved
by allowing the classifier to examine features for subsequent
words.
7The ACE data has the nice property of being consistent in
annotations across these languages.
</footnote>
<sectionHeader confidence="0.962703" genericHeader="method">
4 Cross-Language Mention Propagation
</sectionHeader>
<bodyText confidence="0.99824825">
The approach proposed in this article requires a
mention detection system build in a resource-rich
language, and a translation from the source lan-
guage to the resource-rich language, together with
word alignment. This assumption is realistic: while
truly parallel data (humanly created) might be in
short supply or harder to acquire, adapting statis-
tical machine translation (SMT) systems from one
language-pair to another is not as challenging as it
used to be (Al-Onaizan and Papineni, 2006). We
also find that there is a large number of parallel
corpora available these days which cover many lan-
guage pairs. For example, for the European Union’s
23 official languages we find 253 language pairs;
each document in one language might have to be
translated in all other 22 languages. This is in ad-
dition to parallel corpora one could get from books,
including religious texts such as the Bible, that are
translated to a large number of languages. On the
other hand, even though mention detection system
is important for many natural language processing
applications, we still find lack of mention-annotated
corpora in many languages. In the approach we pro-
pose below, the annotated corpus used to train the
mention detection classifier does not have to be part
of a parallel corpus.
To start the process, we first use a SMT system
to translate the source unit (document or sentence)
xN1 into the resource-rich language, yielding the se-
quence ξM 1 = (ξ1, ξ2,... ξM). Taking the sequence
of tokens ξM1 as input, the MaxEnt classifier assigns
a mention label to each token, building the label se-
quence ψM1 = (ψ1, ψ2 . . . ψM). Using the SMT-
produced word alignment between source text xN1
and translated text ξM 1 (Koehn, 2004),we propagate
the target labels ψM 1to the source language build-
ing the label sequence yN1 = (y1, y2 ... �yN).8 As
an example, if a sequence of tokens in the resource-
rich language ξiξi+1ξi+2 is aligned to xjxj+1 in the
source language and if ξiξi+1ξi+2 is tagged as a lo-
cation mention, then the sequence xjxj+1 can be la-
beled as a location mention: B-LOC, I-LOC. Hence,
each token xi in xN1 is tagged with a corresponding
propagated label yi in yN1 , yi = φ (i, A, ψM ), where
</bodyText>
<equation confidence="0.486118">
1
</equation>
<bodyText confidence="0.99676325">
A is the alignment between the source and resource-
rich languages. In cases when the alignment is 1-
to-1 the function becomes the identity, but one can
imagine different scenarios which can be used in
</bodyText>
<footnote confidence="0.9976025">
8Or by using Giza++ if your favorite engine does not give
you word alignment.
</footnote>
<page confidence="0.989899">
603
</page>
<table confidence="0.690254">
PER GPE PER GPE LOC GPE ORG
The Nepalese soldier was gunned down by former Haitian soldiers when patrullaba the central area of Haiti , reported minustah .
GPE PER GPE PER LOC GPE
</table>
<figureCaption confidence="0.98926625">
Figure 1: Word alignment for a Spanish sentence and its English machine-translation. The mention labels shown are
the gold-standard ones for Spanish and the automatically detected ones for English. If mentions were to be propagated
from English to Spanish, the last mention would be a miss, due to the fact that the English mention detection failed to
identify ’minustah’ as an organization.
</figureCaption>
<bodyText confidence="0.888852407407408">
El soldado nepalés fue baleado por ex soldados haitianos cuando patrullaba la zona central de Haiti , informó Minustah .
many-to-many alignment cases. The alignement we
use in this paper is 1-to-many (11...n}) from the
source language (eg., Arabic) to the resource-rich
language (e.g., English). Once we use SMT word
alignment to propagate label sequence 0M1 of �M1 to
the corresponding text xN1 in the target language, we
end up with a sequence of labels yN1 where for each
token xi in xN1 we attach its label yi in yN1 . Hence,
we label te entire span and if the strategy results in
two mentions where one contains the other, we elim-
inate the inner one.
Figure 1 displays the alignment between a Span-
ish sentence and its English automatic translation. It
also shows a good match between the gold-standard
tags in Spanish and the automatically extracted tags
in English.
There are three ways in which we propose using
these propagated labels:
1. Consider yN1 as the result of propagating the
detected mentions in the original text xN1 , basi-
cally selecting yN1 = yN1 . This situation corre-
sponds to a case where no resources (annotated
data) are available/needed on the source side,
where the propagated labels are the output of
the system.
2. Use the label sequence yN1 as an additional fea-
ture in the MaxEnt framework when predicting
P (yj JxN1 , yj_k), together with other features
built from resources available on the source
language. We will call this model CDP (Con-
text Dependent Propagation).
3. Starting with a large corpus (possibly including
the training data), translate it into the resource-
rich language and run mention detection. Then
select the word sequences in the source lan-
guage associated with the found mentions in
the translation and add them to a machine-
generated gazetteer !g9. This gazetteer !g is then
used to construct features for classification. We
will call this model CIP (Context Independent
Propagation).
From a runtime point of view, the CIP method has
the advantage that there is no need to perform ma-
chine translation, and it can incorporate data from a
very large amount of text. The CDP method, on the
other hand, has the advantage that features are com-
puted in context, and will not fire unless the corre-
sponding mentions were found in the translated ver-
sion (hence the name). Of course, the CDP method
can incorporate features generated in the dictionary
!g. The experimental section analyzes the impact of
each of these techniques on mention detection task
performance.
</bodyText>
<sectionHeader confidence="0.999525" genericHeader="method">
5 Resources
</sectionHeader>
<bodyText confidence="0.999903055555556">
Experiments are conducted on the ACE 2007 data
sets10, in four languages: Arabic, Chinese, English,
and Spanish. This data is selected from a variety
of sources (broadcast news, broadcast conversations,
newswire, web log, newswire, conversational tele-
phony) and is labeled with 7 types: person, organi-
zation, location, facility, GPE (geo-political entity),
vehicle and weapon. Besides mention level informa-
tion, also labeled are coreference between the men-
tions, relations, events, and time resolution.
Since the evaluation tests set are not publicly
available, we have split the publicly available train-
ing corpus into an 85%/15% data split. To facilitate
future comparisons with work presented here, and
to simulate a realistic scenario, the splits are created
based on article dates: the test data is selected as the
latest 15% of the data in chronological order, in each
of the covered genres. This way, the documents in
</bodyText>
<footnote confidence="0.994671666666667">
9This is in fact a way to automatically construct a source-
side mention dictionary.
10Same data as for ACE 2008.
</footnote>
<page confidence="0.998737">
604
</page>
<tableCaption confidence="0.983349">
Table 3: BLEU performance of the SMT systems on the
3 language pairs
Table 1: Datasets size (number of documents)
</tableCaption>
<table confidence="0.991034666666667">
Language Training Test
Arabic 323 56
Chinese 538 95
English 499 100
Spanish 467 52
Language Pair BLEU Score
Arabic-English 0.55
Chinese-English 0.32
Spanish-English 0.55
</table>
<bodyText confidence="0.993132333333334">
the training and test data sets do not overlap in time,
and the content of the test data is more recent than
the training data. Table 1 presents the number of
documents in the training/test datasets for each of
the four languages.
While performance on the ACE data is usually
evaluated using a special-purpose measure - the
ACE value metric (NIST, 2007), given that we are
interested in the mention detection task only, we
decided to use the more intuitive and popular (un-
weighted) F-measure, the harmonic mean of preci-
sion and recall.
</bodyText>
<sectionHeader confidence="0.999528" genericHeader="method">
6 Resource-Rich Languages
</sectionHeader>
<bodyText confidence="0.9985144">
From the set of four languages in ACE 2007, we
will unsurprisingly select English as the resource-
rich language. Table 2 shows the performance of
mention detection systems in all 4 languages one
can obtain by using all available resources in that
language, including lexical (words and morphs in a
3-word window, prefixes and suffixes of length up
to 4, WordNet (Miller, 1995) for English), syntac-
tic (POS tags, text chunks), and the output of other
information extraction models.
</bodyText>
<table confidence="0.9989">
N P R F
Arabic 3566 83.6 76.8 80.0
Chinese 4791 81.1 71.3 75.8
English 8170 84.6 80.8 82.7
Spanish 2487 79.1 73.5 76.2
</table>
<tableCaption confidence="0.9728884">
Table 2: Performance of Arabic, Chinese, English and
Spanish mention detection systems. Performance is pre-
sented in terms of Precision (P), Recall (R), and F-
measure (F). The column (N) displays the number of
mentions in the test set.
</tableCaption>
<bodyText confidence="0.991176375">
Results show that the English mention detection
system has a better performance when compared to
systems dealing with other languages such as Ara-
bic, Chinese and Spanish. These results are not un-
expected since the English model has access to a
larger training data and uses richer set of informa-
tion such as WordNet (Miller, 1995) and the output
of a larger set of information extraction models.
</bodyText>
<sectionHeader confidence="0.998685" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.999507457142857">
To show the effectiveness of cross-language mention
propagation information in improving mention de-
tection system performance in Arabic, Chinese and
Spanish, we use three SMT systems with very com-
petitive performance in terms of BLEU11 (Papineni
et al., 2002).
To give an idea of the SMT performance, Table 3
shows the performance of the translation systems on
the three language pairs, computed on standard test
sets. The Arabic to English SMT system is similar to
the one described in (Huang and Papineni, 2007); it
has 0.55 BLEU score on NIST 2003 Arabic-English
machine translation evaluation test set. The Chi-
nese to English SMT system has similar architecture
to the one described in (Al-Onaizan and Papineni,
2006). This system obtains a score of 0.32 cased
BLUE on NIST 2003 Arabic-English machine trans-
lation evaluation test set. The Spanish to English
SMT system is similar to the one described in (Lee et
al., 2006); it has a 0.55 BLEU score on the final text
edition of the European Parliament Plenary Speech
corpus in TC-STAR 2006 evaluation. As mentioned
earlier, these three SMT systems have very compet-
itive performance and are ranked among top 2 sys-
tems participating to NIST or TC-STAR evaluations.
Also, the English mention detection system used for
experiments has an F-measure of 82.7 and that has
very competitive results among systems participat-
ing in the ACE 2007 evaluation.
Experiments are conducted under several con-
ditions in order to investigate the effectiveness of
our approach in improving mention detection sys-
tem performance on languages with different levels
of resource availability (from simple to more com-
plex):
</bodyText>
<listItem confidence="0.7993535">
1. the system does not have access to any train-
ing data in the source language (no resources
</listItem>
<footnote confidence="0.971695">
11BLEU is an automatic measure for the translation quality
which makes good use of multiple reference translations.
</footnote>
<page confidence="0.998293">
605
</page>
<bodyText confidence="0.908044">
needed besides the MT system);
</bodyText>
<listItem confidence="0.9756444">
2. the system has access to only lexical informa-
tion (information that can be directly derived
exclusively from mention-labeled text);
3. the system has access to lexical and syntactic
(e.g., POS tags, text chunks) information (re-
quires mention-labeled text, and models to pre-
dict POS tags, etc);
4. the system that has access to lexical, syntactic,
and semantic information (requires even more
models and labeled data).
</listItem>
<bodyText confidence="0.999446666666667">
The rest of this section examines in detail these four
cases.
To measure whether the improvement in per-
formance of a particular system over another
one is statistically significant or not, we use
the stratified bootstrap re-sampling significance
test (Noreen, 1989). This approach was used in the
named entity recognition shared task of CoNNL-
2002 (http://www.cnts.ua.ac.be/conll2002/ner/,
2002). In the following tables, we add a dagger sign
† to results that are not statistically significant when
compared to the baseline results.
</bodyText>
<subsectionHeader confidence="0.953945">
7.1 No Source Language Training Data
</subsectionHeader>
<bodyText confidence="0.997139333333333">
In this first case, as described in Section 4, the men-
tion labels in the source language are obtained di-
rectly through the alignment from the mentions in
the translated text. This is a very simple scenario,
which can be implemented with ease, and, as we will
see, yields reasonable performance out-of-the-box.
</bodyText>
<table confidence="0.999045">
N P R F
Arabic 3566 52.7 49.6 51.1
Chinese 4791 66.4 52.2 58.5
Spanish 2487 63.4 63.6 63.5
</table>
<tableCaption confidence="0.746262">
Table 4: Performance of the cross-language propagation
from English mention detection system onto Arabic, Chi-
nese and Spanish texts. Performance is presented in terms
of Precision (P), Recall (R), and F-measure (F). The col-
umn (N) shows the number of mentions in the test set.
</tableCaption>
<bodyText confidence="0.999742347826087">
Experimental results presented in Table 4 show
the performance of applying this information trans-
fer approach. For each source language (Arabic,
Chinese, or Arabic), we show the performance of
propagating mentions from the English text. Even
though no training data to build a source language
mention classifier is available, we still can detect
mentions with reasonably high accuracy. We con-
sider the obtained accuracy as reasonably good be-
cause, as an example, the performance of a sys-
tem that attaches to every word its most frequent
label (unigram) is around 25% F-measure on Ara-
bic. Results in Table 4 also show that even though
the Chinese-to-English SMT system is lower in term
of BLEU than the Arbic-to-English SMT system
(0.32 vs. 0.55), performance of the cross-language
propagation from English mention detection system
onto Chinese is better than the performance of the
propagation from English mention detection system
onto Arabic. One reason for this is that we notice
that Chinese-to-English SMT system translates and
aligns ACE categories better than Arabic-to-English
SMT system.
</bodyText>
<subsectionHeader confidence="0.998452">
7.2 Lexical Resources
</subsectionHeader>
<bodyText confidence="0.999981692307692">
In this section, we consider the case when we have
available training data in the source language to be
able to train a statistical classifier. We also consider
that the classifier has access to lexical information
only. Our goal here is to study the effectiveness of
adding cross-language mention propagation infor-
mation to improve mention detection performance
on languages with limited resources.
Table 5 shows the performance of the 3 languages
with and without cross-language mention propaga-
tion information from English, with the 3 propa-
gation methods described in Section 4. One can
see that propagating mention propagation informa-
tion results in system performance increase12. When
systems use the CIP method, no improvement can
be observed on Arabic and Chinese, while a small
improvement of 0.5F point is obtained on Spanish
(74.5 vs. 75.0). In contrast, when systems use the
CDP method an improvement is obtained in recall
– which is to be expected, given the method – lead-
ing to systems with better performance in terms of
F-measure: 1.6F points improvement for Arabic,
1.5F points improvement for Chinese and almost 3F
points improvement for Spanish. The results for all
the CDP transfers and the CIP for Spanish are statis-
tically significant.
</bodyText>
<subsectionHeader confidence="0.998406">
7.3 Lexical and Syntactic Resources
</subsectionHeader>
<bodyText confidence="0.999844666666667">
We represent in Table 6 mention detection system
performance when syntactic resources are available
in the source language, in addition to lexical re-
</bodyText>
<footnote confidence="0.7800785">
12Only systems’ performance marked with † is not statisti-
cally significantly better.
</footnote>
<page confidence="0.993652">
606
</page>
<table confidence="0.9997644">
Baseline CIP CDP
N P R F P R F P R F
Arabic: 3566 81.8 71.7 76.4 82.2 71.3 76.41 82.6 73.9 78.0
Chinese: 4791 79.3 70.2 74.5 79.4 70.5 74.71 79.8 72.5 76.0
Spanish: 2478 79.1 70.4 74.5 79.7 70.8 75.0 80.4 74.6 77.4
</table>
<tableCaption confidence="0.865587">
Table 5: Performance of Arabic, Chinese and Spanish mention detection using lexical features (“Baseline” column).
</tableCaption>
<table confidence="0.984131142857143">
Columns “CIP” stands for systems that add cross-language context independent mention propagation information and
column “CDP” is for systems that add cross-language context dependent mention propagation information.
Baseline CIP CDP
N P R F P R F P R F
Arabic: 3566 82.2 72.6 77.1 82.7 72.9 77.5 83.2 74.5 78.6
Chinese: 4791 80.0 71.3 75.5 79.9 71.5 75.51 81.0 72.4 76.5
Spanish: 2487 79.1 71.2 74.9 79.9 71.9 75.7 80.7 74.6 77.5
</table>
<tableCaption confidence="0.995659">
Table 6: Performance of Arabic, Chinese and Spanish mention detection using lexical and syntactic features (POS
tags, chunk information, etc).
</tableCaption>
<bodyText confidence="0.9998885">
sources available in the previous Subsection. This
experiment is important because it tests the effec-
tiveness of the propagation approach in improving
performance on languages with a typical level of re-
sources.
Results show that even in this situation, the use
of cross language mention propagation informa-
tion still lead to considerable improvement: using
the CDP transfer method yields improvements from
1.1F in Chinese to 2.6F in Spanish. Similar to the
previous section, the use of CIP information did not
improve performance significantly on Arabic (77.5
vs. 77.1) and Chinese (75.5 vs. 75.5) systems, but
we notice an improvement in Spanish13.
</bodyText>
<subsectionHeader confidence="0.998467">
7.4 Lexical, Syntactic and Semantic Resources
</subsectionHeader>
<bodyText confidence="0.98445325">
This final section investigates whether the access
to cross-language mention propagation information
can still improve the performance of existing com-
petitive mention detection systems trained on lan-
guages with large resources. In this case, systems
have access to a full array of lexical, syntax, seman-
tic information, including the output from other in-
formation extraction models. Table 7 presents the
performance of mention detection systems on the
three languages, in the familiar 3 propagation meth-
ods: again, results show that better performance
is obtained when cross language mention informa-
tion is used. Under CIP, almost no change in terms
of performance is obtained for Arabic and Span-
13The dagger sign † marks the systems that are not statisti-
cally significantly better.
ish, though a slight improvement can be observed
for Chinese (76.9F vs. 75.8F). When CDP is used
the performance of mention detection systems is im-
proved by 0.9F for Arabic (80.9 vs. 80.0), 2.3F
for Chinese (78.1F vs. 75.8F) and 1.9F for Span-
ish (78.1 vs. 76.2F). Once again, the results prove
that the use of cross language mention propagation
information, especially through CDP, is effective in
improving the performance even in this case.
By comparing results across tables, one can note
that systems having access to only lexical and cross
language mention propagation information are as ef-
fective as systems having access to large set of in-
formation. For Chinese, we obtain a performance of
75.8F when the system has access to lexical, syntac-
tic and output of other information extraction mod-
els. On the other hand, the same system has a
slightly better performance of 76.0 when it has ac-
cess to lexical and cross language mention propa-
gation information. The same behavior is observed
for Spanish, we obtain a performance of 76.2F when
the system has access to lexical, syntactic and output
of other information extraction models; compared to
77.�F when lexical and cross language mention in-
formation are used. This is not true for Arabic where
having access to larger set of information led to bet-
ter performance when compared to systems having
access to lexical information and CDP information
(80.0F vs. 78.0). We attribute this difference to
the fact that in Arabic we use the output of larger
number of information extraction models, and con-
sequently a richer set of information.
</bodyText>
<page confidence="0.993649">
607
</page>
<table confidence="0.9997354">
Baseline CIP CDP
N P R F P R F P R F
Arabic: 3566 83.6 76.8 80.0 83.9 77.0 80.21 84.2 77.8 80.9
Chinese: 4791 81.1 71.3 75.8 81.4 73.0 76.9 81.7 74.8 78.1
Spanish: 2487 79.1 73.5 76.2 79.3 73.4 76.21 80.1 76.2 78.1
</table>
<tableCaption confidence="0.9704475">
Table 7: Performance of Arabic, Chinese and Spanish mention detection using lexical, syntactic and output of other
information extraction models: full-blown systems.
</tableCaption>
<bodyText confidence="0.999744277777778">
The other observation that is worth making is that
the improvement in performance has a decreasing
tendency as more resources are available. The per-
formance gain for CDP in Arabic goes from 1.6 to
1.5 to 0.9, and the one on Spanish goes from 2.9 to
2.6 to 1.9. The one on Chinese follows part of this
trend, as it goes from 1.4 to 1.1 to 2.3. While the
evidence here is not definitive, one can indeed note
the reduced effectiveness of the method as more re-
sources are available, which was indeed what we ex-
pected.
Results obtained by all these experiments help
answer an important question: when trying to im-
prove mention detection systems in a resource-poor
language, should we invest in building resources or
should we use propagation from a resource-rich lan-
guage to (at least) bootstrap the process? The answer
seems to be the latter.
</bodyText>
<sectionHeader confidence="0.99885" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999943026315789">
This paper presents a new approach to mention de-
tection in low, medium or high-resource languages,
which benefits from projecting the output from a
resource-rich language such as English. We show
that even when no training data is available in one
source language, we can still build a decently per-
forming baseline mention detection system by only
using resources from English. This approach re-
quires a mention detection system on a resource-
rich language and an SMT system that translate text
from the source to the resource-rich language, both
of which can be attained.
In cases when large resources are available in the
source language, our cross language mention propa-
gation technique is still able to further improve men-
tion detection system performance. Experiments
performed on the four languages of ACE 2007, with
English chosen as the resource-rich language, show
consistent and significant improvements across con-
ditions and levels of linguistic sophistication. The
experiments are conducted on clearly specified par-
titions of the ACE 2007 data set, so future compar-
isons against the presented work can be correctly
and accurately made. We also note that systems
that have access to lexical and cross language men-
tion propagation information are as accurate as those
that have access to lexical, syntactic and output of
other information extraction models in the source
language (but no cross-language resources). As fu-
ture work, we plan to extend this work to use semi-
supervised and unsupervised approaches that can
make use of cross-language information propaga-
tion.
We believe that it is important for the research
community to continue to invest in building better
resources in “source” languages, as it looks the most
promising approach. However, using a propagation
approach can definitely help bootstrap the process.
</bodyText>
<sectionHeader confidence="0.998398" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9908295">
This work was supported by DARPA/IPTO Contract
No. HR0011-06-2-0001 under the GALE program.
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995119095238095">
Yaser Al-Onaizan and Kishore Papineni. 2006. Dis-
tortion models for statistical machine translation. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 529–536, Sydney, Australia, July. Association
for Computational Linguistics.
A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A
maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):39–71.
C. Cabezas, B. Dorr, and P. Resnik. 2001. Spanish lan-
guage processing at university of maryland: Building
infrastructure for multilingual applications. In Pro-
ceedings of the 2nd International Workshop on Span-
ish Language Processing and Language Technologies.
Stanley Chen and Ronald Rosenfeld. 2000. A survey of
smoothing techniques for me models. IEEE Trans. on
Speech and Audio Processing.
I. Dagan and A. Itai. 1994. Word sense disambiguation
using a second language monolingual corpus. Compu-
tational Linguistics, 20(4):563–596.
</reference>
<page confidence="0.980193">
608
</page>
<reference confidence="0.999842276190476">
Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two
languages are more informative than one. In Meet-
ing of the Association for Computational Linguistics,
pages 130–137.
Mona Diab and Philip Resnik. 2001. An unsupervised
method for word sense tagging using parallel corpora.
In ACL ’02: Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, pages
255–262, Morristown, NJ, USA. Association for Com-
putational Linguistics.
R. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kamb-
hatla, X. Luo, N Nicolov, and S Roukos. 2004. A
statistical model for multilingual entity detection and
tracking. In Proceedings of the Human Language
Technology Conference of the North American Chap-
ter of the Association for Computational Linguistics:
HLT-NAACL 2004, pages 1–8.
W. Gale, K. Church, and D. Yarowsky. 1992. A method
for disambiguating word senses in a large corpus.
Computers and the Humanities, 26:415–439.
Joshua Goodman. 2002. Sequential conditional general-
ized iterative scaling. In Proceedings ofACL’02.
Gregory Grefenstette. 1998. Cross-Language Informa-
tion Retrieval, volume 079238122X. Kluwer Aca-
demic Publishers.
http://www.cnts.ua.ac.be/conll2002/ner/. 2002.
Fei Huang and Kishore Papineni. 2007. Hierarchi-
cal system combination for machine translation. In
Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 277–286.
Rebecca Hwa, Philip Resnik, and Amy Weinberg. 2002.
Breaking the resource bottleneck for multilingual pars-
ing. In Proceedings of the Workshop on Linguis-
tic Knowledge Acquisition and Representation: Boot-
strapping Annotated Language Data.
H. Jing, R. Florian, X. Luo, T. Zhang, and A. Itty-
cheriah. 2003. HowtogetaChineseName(Entity): Seg-
mentation and combination issues. In Proceedings of
EMNLP’03, pages 200–207.
Philipp Koehn. 2004. Pharaoh: a Beam Search De-
coder for Phrase-Based Statistical Machine Transla-
tion Models. In Proceedings ofAMTA’04, Washington
DC, September-October.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In ICML.
Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Has-
san. 2003. Language model based Arabic word seg-
mentation. In Proceedings of the ACL’03, pages 399–
406.
Young-Suk Lee, Yaser Al-Onaizan, Kishore Papineni,
and Salim Roukos. 2006. Ibm spoken language trans-
lation system. In TC-STAR Workshop on Speech-to-
Speech Translation, pages 13–18, Barcelona, Spain,
June.
Andrew McCallum, Dayne Freitag, and Fernando
Pereira. 2000. Maximum entropy markov models for
information extraction and segmentation. In ICML.
G. A. Miller. 1995. WordNet: A lexical database. Com-
munications of the ACM, 38(11).
NIST. 2007. The ACE evaluation plan.
www.nist.gov/speech/tests/ace/index.htm.
Eric W. Noreen. 1989. Computer-Intensive Methods for
Testing Hypotheses. John Wiley Sons.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311–318.
P.F.Brown, S.A.Della Pietra, V.J. Della Pietra, and
R.L.Mercer. 1991. Word-sense disambiguation using
statistical methods. In Proceedings ofACL’91.
L. Ramshaw and M. Marcus. 1994. Exploring the sta-
tistical derivation of transformational rule sequences
for part-of-speech tagging. In Proceedings of the ACL
Workshop on Combining Symbolic and Statistical Ap-
proaches to Language, pages 128–135.
L. Ramshaw and M. Marcus. 1995. Text chunking us-
ing transformation-based learning. In David Yarowsky
and Kenneth Church, editors, Proceedings of the Third
Workshop on Very Large Corpora, pages 82–94, Som-
erset, New Jersey. Association for Computational Lin-
guistics.
E. Riloff, C. Schafer, and D. Yarowsky. 2002. Inducing
information extraction systems for new languages via
cross-language projection. In Proceedings of Coling
2002, Taipei, Taiwan.
E. F. Tjong Kim Sang and J. Veenstra. 1999. Represent-
ing text chunks. In Proceedings ofEACL’99.
E. F. Tjong Kim Sang. 2002. Introduction to the conll-
2002 shared task: Language-independentnamed entity
recognition. In Proceedings of CoNLL-2002, pages
155–158.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings ofHLT
2001, San Diego, California, USA.
Imed Zitouni, Jeff Sorensen, Xiaoqiang Luo, and Radu
Florian. 2005. The impact of morphological stem-
ming on Arabic mention detection and coreference res-
olution. In Proceedings of the ACL Workshop on Com-
putational Approaches to Semitic Languages, pages
63–70, Ann Arbor, June.
</reference>
<page confidence="0.998833">
609
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.856536">
<title confidence="0.998559">Mention Detection Crossing the Language Barrier</title>
<author confidence="0.920158">Imed Zitouni</author>
<author confidence="0.920158">Radu</author>
<affiliation confidence="0.993876">IBM T.J. Watson Research</affiliation>
<address confidence="0.995933">1101 Kitchawan Rd, Yorktown Heights, NY</address>
<email confidence="0.998715">izitouni@us.ibm.com</email>
<email confidence="0.998715">raduf@us.ibm.com</email>
<abstract confidence="0.997830517241379">While significant effort has been put into annotating linguistic resources for several languages, there are still many left that have only small amounts of such resources. This paper investigates a method of propagating information (specifically mention detection information) into such low resource languages from richer ones. Experiments run on three language pairs (Arabic-English, Chinese-English, and Spanish-English) show that one can achieve relatively decent performance by propagating information from a language with richer resources such as English into a foreign language alone (no resources or models in the foreign language). Furthermore, while examining the performance using various degrees of linguistic information in a statistical framework, results show that propagated features from English help improve the source-language system performance even when used in conjunction with all feature types built from the source language. The experiments also show that using propagated features in conjunction with lexicallyderived features only (as can be obtained directly from a mention annotated corpus) yields similar performance to using feature types derived from many linguistic resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kishore Papineni</author>
</authors>
<title>Distortion models for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>529--536</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="15621" citStr="Al-Onaizan and Papineni, 2006" startWordPosition="2546" endWordPosition="2549">rds. 7The ACE data has the nice property of being consistent in annotations across these languages. 4 Cross-Language Mention Propagation The approach proposed in this article requires a mention detection system build in a resource-rich language, and a translation from the source language to the resource-rich language, together with word alignment. This assumption is realistic: while truly parallel data (humanly created) might be in short supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be (Al-Onaizan and Papineni, 2006). We also find that there is a large number of parallel corpora available these days which cover many language pairs. For example, for the European Union’s 23 official languages we find 253 language pairs; each document in one language might have to be translated in all other 22 languages. This is in addition to parallel corpora one could get from books, including religious texts such as the Bible, that are translated to a large number of languages. On the other hand, even though mention detection system is important for many natural language processing applications, we still find lack of ment</context>
<context position="24560" citStr="Al-Onaizan and Papineni, 2006" startWordPosition="4058" endWordPosition="4061">ntion detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11 (Papineni et al., 2002). To give an idea of the SMT performance, Table 3 shows the performance of the translation systems on the three language pairs, computed on standard test sets. The Arabic to English SMT system is similar to the one described in (Huang and Papineni, 2007); it has 0.55 BLEU score on NIST 2003 Arabic-English machine translation evaluation test set. The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006). This system obtains a score of 0.32 cased BLUE on NIST 2003 Arabic-English machine translation evaluation test set. The Spanish to English SMT system is similar to the one described in (Lee et al., 2006); it has a 0.55 BLEU score on the final text edition of the European Parliament Plenary Speech corpus in TC-STAR 2006 evaluation. As mentioned earlier, these three SMT systems have very competitive performance and are ranked among top 2 systems participating to NIST or TC-STAR evaluations. Also, the English mention detection system used for experiments has an F-measure of 82.7 and that has ve</context>
</contexts>
<marker>Al-Onaizan, Papineni, 2006</marker>
<rawString>Yaser Al-Onaizan and Kishore Papineni. 2006. Distortion models for statistical machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 529–536, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="4939" citStr="Berger et al., 1996" startWordPosition="765" endWordPosition="768">ed in the source language, but, still, even when all resources were used, a statistically significant gain was still observed. Similarly to classical NLP tasks such as text chunking (Ramshaw and Marcus, 1995) and named entity recognition (Tjong Kim Sang, 2002), we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been performed, on word sense disambiguation (Dagan et al., 1991; P.F.Brown et al., 1991; Gale et al., 1992) (perhaps unsurprisingly given its close connection to machine translation) – all propose and (lightly) evaluate methods to use word sense information</context>
<context position="10889" citStr="Berger et al., 1996" startWordPosition="1729" endWordPosition="1732">e examples x ∈ X with either a probability distribution over the labels from Y, P (·|x)(if we are interested in soft classification) or associate one label y ∈ Y (if we are interested in hard classification). The MaxEnt algorithm associates a set of weights {αij}i=1...n j=1...m with the features (fj)i, and computes the probability distribution as f� (x,yi) x 1 17b P af (yil ) = Z(x) � U ( ) j=1 4In sifier method itself. fact, the feature set used for classification has a much larger impact on the performance of the resulting system than the clas where Z(x) is a normalization factor. The data (Berger et al., 1996). In this paper, the MaxEnt model is trained using the sequential conditional generalized iterative scaling (SCGIS) technique (Goodman, 2002), and it uses a Gaussian prior for regularization (Chen and Rosenfeld, 2000). Now take = ... xN), a sequence of contiguous tokens (i.e., a sentence or a document) in the source lan {αij}j=1...m xN1 (x1,x2, guage. The goal of mention detection system is to find the most likely sequence of labels yN1 = (y1, y2 . . . yN) that best matches the input xN1 . In the mention detection case, each token xi in xN1 is tagged with a label yi as follows:5 • if not part </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cabezas</author>
<author>B Dorr</author>
<author>P Resnik</author>
</authors>
<title>Spanish language processing at university of maryland: Building infrastructure for multilingual applications.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd International Workshop on Spanish Language Processing and Language Technologies.</booktitle>
<contexts>
<context position="7894" citStr="Cabezas et al., 2001" startWordPosition="1229" endWordPosition="1232">uage, to bootstrap the annotation of resources in the target language. They show that they can obtain 48 F-measure on a information extraction task identifying locations, vehicles and victims in plane crashes. (Hwa et al., 2002) proposes a framework that enables the acquisition of syntactic dependency trees for low-resource languages by importing linguistic annotation from rich-resource languages (English). The authors run a large-scale experiment in which Chinese dependency parses were induced from English, and show that a parser trained on the resulting trees outperformed simple baselines. (Cabezas et al., 2001) investigates a similar method of propagating syntactic treebank-like annotations from English to Spanish. Finally, a large body of research has been done on cross-language information retrieval, where the goal is to find information in one language (e.g. Chinese newswire) corresponding to a query in a different language (e.g. English) – although the list of relevant papers is too long to be mentioned here (see, for instance, (Grefenstette, 1998)). The work presented here differs from the information extraction investigations presented above in two aspects: • it handles unrestricted text and a</context>
</contexts>
<marker>Cabezas, Dorr, Resnik, 2001</marker>
<rawString>C. Cabezas, B. Dorr, and P. Resnik. 2001. Spanish language processing at university of maryland: Building infrastructure for multilingual applications. In Proceedings of the 2nd International Workshop on Spanish Language Processing and Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Chen</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>A survey of smoothing techniques for me models.</title>
<date>2000</date>
<journal>IEEE Trans. on Speech and Audio Processing.</journal>
<contexts>
<context position="11106" citStr="Chen and Rosenfeld, 2000" startWordPosition="1763" endWordPosition="1766"> MaxEnt algorithm associates a set of weights {αij}i=1...n j=1...m with the features (fj)i, and computes the probability distribution as f� (x,yi) x 1 17b P af (yil ) = Z(x) � U ( ) j=1 4In sifier method itself. fact, the feature set used for classification has a much larger impact on the performance of the resulting system than the clas where Z(x) is a normalization factor. The data (Berger et al., 1996). In this paper, the MaxEnt model is trained using the sequential conditional generalized iterative scaling (SCGIS) technique (Goodman, 2002), and it uses a Gaussian prior for regularization (Chen and Rosenfeld, 2000). Now take = ... xN), a sequence of contiguous tokens (i.e., a sentence or a document) in the source lan {αij}j=1...m xN1 (x1,x2, guage. The goal of mention detection system is to find the most likely sequence of labels yN1 = (y1, y2 . . . yN) that best matches the input xN1 . In the mention detection case, each token xi in xN1 is tagged with a label yi as follows:5 • if not part of any entity, yi = O (O for any • if it is part of an entity, itis composed of a subtag specifying whether it starts a mention (B-) or is inside a mention (I-), and asub-type corresponding to mention type (e.g. B-PER</context>
</contexts>
<marker>Chen, Rosenfeld, 2000</marker>
<rawString>Stanley Chen and Ronald Rosenfeld. 2000. A survey of smoothing techniques for me models. IEEE Trans. on Speech and Audio Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>A Itai</author>
</authors>
<title>Word sense disambiguation using a second language monolingual corpus.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="5674" citStr="Dagan and Itai, 1994" startWordPosition="879" endWordPosition="882">us Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been performed, on word sense disambiguation (Dagan et al., 1991; P.F.Brown et al., 1991; Gale et al., 1992) (perhaps unsurprisingly given its close connection to machine translation) – all propose and (lightly) evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation. (Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew), and show moderate 2While applying this method in the case where the source language has absolutely no resources might be an interesting test case, we don’t see it as being realistic. Resources are build nowadays in a large variety of languages, and not making use of them is rather foolish (a certain big bird and sand comes to mind). improvement on a small data set3. More recently, (Diab and Resnik, 2001) presents a metho</context>
</contexts>
<marker>Dagan, Itai, 1994</marker>
<rawString>I. Dagan and A. Itai. 1994. Word sense disambiguation using a second language monolingual corpus. Computational Linguistics, 20(4):563–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
<author>Ulrike Schwall</author>
</authors>
<title>Two languages are more informative than one.</title>
<date>1991</date>
<booktitle>In Meeting of the Association for Computational Linguistics,</booktitle>
<pages>130--137</pages>
<contexts>
<context position="5345" citStr="Dagan et al., 1991" startWordPosition="827" endWordPosition="830">a specific mention, is inside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been performed, on word sense disambiguation (Dagan et al., 1991; P.F.Brown et al., 1991; Gale et al., 1992) (perhaps unsurprisingly given its close connection to machine translation) – all propose and (lightly) evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation. (Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew), and show moderate 2While applying this method in the case where the source language has absolut</context>
</contexts>
<marker>Dagan, Itai, Schwall, 1991</marker>
<rawString>Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two languages are more informative than one. In Meeting of the Association for Computational Linguistics, pages 130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Philip Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel corpora.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>255--262</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6257" citStr="Diab and Resnik, 2001" startWordPosition="975" endWordPosition="978">ine translation. (Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew), and show moderate 2While applying this method in the case where the source language has absolutely no resources might be an interesting test case, we don’t see it as being realistic. Resources are build nowadays in a large variety of languages, and not making use of them is rather foolish (a certain big bird and sand comes to mind). improvement on a small data set3. More recently, (Diab and Resnik, 2001) presents a method for performing word sense tagging in both the source and target texts of parallel bilingual corpora with the English WordNet sense inventory, by using translation correspondences. On more general cross-language information transfer, (Yarowsky et al., 2001) proposed and evaluated a method of propagating POS tagging, named mention, base noun phrase, and morphological information from English into a foreign language, which is very similar to the one presented in this article (experiments were run on French, Chinese, Czech, and Spanish – on human-generated translations). Their r</context>
</contexts>
<marker>Diab, Resnik, 2001</marker>
<rawString>Mona Diab and Philip Resnik. 2001. An unsupervised method for word sense tagging using parallel corpora. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 255–262, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
<author>H Hassan</author>
<author>A Ittycheriah</author>
<author>H Jing</author>
<author>N Kambhatla</author>
<author>X Luo</author>
<author>N Nicolov</author>
<author>S Roukos</author>
</authors>
<title>A statistical model for multilingual entity detection and tracking.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL</booktitle>
<pages>1--8</pages>
<contexts>
<context position="9485" citStr="Florian et al., 2004" startWordPosition="1482" endWordPosition="1485">g various degrees of existent resources in the source language (Arabic, Chinese, Spanish) • the information transfer is performed over machine generated translations and alignments. 3 Mention Detection As mentioned in the introduction, the mention detection problem is formulated as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. Good performance in many natural language processing tasks has been shown to depend heavily on integrating many sources of information (Florian et al., 2004).4 Given this observation, we are interested in algorithms that can easily integrate and make effective use of diverse input types. We select a exponential classifier, the Maximum Entropy (MaxEnt henceforth) classifier that integrates arbitrary types of information and makes a classification decision by aggregating all information available for a given classification. But the reader can replace it with her favorite feature-based classifier throughout the paper. To help with the presentation, we introduce some notations: let Y = {y1, ... , yn} be the set of predicted classes, X be the example s</context>
<context position="13392" citStr="Florian et al., 2004" startWordPosition="2190" endWordPosition="2193">s, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1 �−k) bias observed by (Lafferty et al., 2001).6 The experiments are run on four languages, part of the ACE-2007 evaluation (NIST, 2007): Arabic, Chinese, English and Spanish.7 Systems across the languages use a large range of features, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4 characters, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. These features were described in (Florian et al., 2004), and are not discussed here. In this paper we focus on the examining the benefit of cross-language mention propagation information in improving mention detection systems. Besides generic types of features, we also have implemented language-specific features: • In Arabic, blank-delimited words are composed of zero or more prefixes, followed by a stem and zero or more suffixes. Each prefix, stem or suffix is a token; any contiguous sequence of tokens can represent a mention. Similar to the approaches described in (Florian et al., 2004) and (Zitouni et al., 2005), we decided to “condition” the o</context>
<context position="14825" citStr="Florian et al., 2004" startWordPosition="2422" endWordPosition="2426">obtains an accuracy of 98%. • In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers. Instead of a word-based model, we build a character-based one, since word segmentation errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observes that character-based models are better performing than word-based ones. Word segmentation information is still useful and is integrated as an additional feature stream. • In English and in Spanish mention detection systems are similar to those described in (Florian et al., 2004) where words are the tokens to classify. 6In fact their example of label bias can be trivially solved by allowing the classifier to examine features for subsequent words. 7The ACE data has the nice property of being consistent in annotations across these languages. 4 Cross-Language Mention Propagation The approach proposed in this article requires a mention detection system build in a resource-rich language, and a translation from the source language to the resource-rich language, together with word alignment. This assumption is realistic: while truly parallel data (humanly created) might be i</context>
</contexts>
<marker>Florian, Hassan, Ittycheriah, Jing, Kambhatla, Luo, Nicolov, Roukos, 2004</marker>
<rawString>R. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kambhatla, X. Luo, N Nicolov, and S Roukos. 2004. A statistical model for multilingual entity detection and tracking. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and the Humanities,</title>
<date>1992</date>
<pages>26--415</pages>
<contexts>
<context position="5389" citStr="Gale et al., 1992" startWordPosition="835" endWordPosition="838">tion, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been performed, on word sense disambiguation (Dagan et al., 1991; P.F.Brown et al., 1991; Gale et al., 1992) (perhaps unsurprisingly given its close connection to machine translation) – all propose and (lightly) evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation. (Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew), and show moderate 2While applying this method in the case where the source language has absolutely no resources might be an interesting tes</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>W. Gale, K. Church, and D. Yarowsky. 1992. A method for disambiguating word senses in a large corpus. Computers and the Humanities, 26:415–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Sequential conditional generalized iterative scaling.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL’02.</booktitle>
<contexts>
<context position="11030" citStr="Goodman, 2002" startWordPosition="1753" endWordPosition="1754">ne label y ∈ Y (if we are interested in hard classification). The MaxEnt algorithm associates a set of weights {αij}i=1...n j=1...m with the features (fj)i, and computes the probability distribution as f� (x,yi) x 1 17b P af (yil ) = Z(x) � U ( ) j=1 4In sifier method itself. fact, the feature set used for classification has a much larger impact on the performance of the resulting system than the clas where Z(x) is a normalization factor. The data (Berger et al., 1996). In this paper, the MaxEnt model is trained using the sequential conditional generalized iterative scaling (SCGIS) technique (Goodman, 2002), and it uses a Gaussian prior for regularization (Chen and Rosenfeld, 2000). Now take = ... xN), a sequence of contiguous tokens (i.e., a sentence or a document) in the source lan {αij}j=1...m xN1 (x1,x2, guage. The goal of mention detection system is to find the most likely sequence of labels yN1 = (y1, y2 . . . yN) that best matches the input xN1 . In the mention detection case, each token xi in xN1 is tagged with a label yi as follows:5 • if not part of any entity, yi = O (O for any • if it is part of an entity, itis composed of a subtag specifying whether it starts a mention (B-) or is in</context>
</contexts>
<marker>Goodman, 2002</marker>
<rawString>Joshua Goodman. 2002. Sequential conditional generalized iterative scaling. In Proceedings ofACL’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Cross-Language Information Retrieval, volume 079238122X.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers.</publisher>
<location>http://www.cnts.ua.ac.be/conll2002/ner/.</location>
<contexts>
<context position="8344" citStr="Grefenstette, 1998" startWordPosition="1302" endWordPosition="1303">in which Chinese dependency parses were induced from English, and show that a parser trained on the resulting trees outperformed simple baselines. (Cabezas et al., 2001) investigates a similar method of propagating syntactic treebank-like annotations from English to Spanish. Finally, a large body of research has been done on cross-language information retrieval, where the goal is to find information in one language (e.g. Chinese newswire) corresponding to a query in a different language (e.g. English) – although the list of relevant papers is too long to be mentioned here (see, for instance, (Grefenstette, 1998)). The work presented here differs from the information extraction investigations presented above in two aspects: • it handles unrestricted text and a full set of 3Very small by “modern” standards - 137 examples. Probably because at the time the article was written, there were no large publicly annotated databases, such as Semcor. 601 mention types (the ACE entity types) during the information transfer • it investigates whether using a resource-rich language (English) can improve on the performance obtained by using various degrees of existent resources in the source language (Arabic, Chinese,</context>
</contexts>
<marker>Grefenstette, 1998</marker>
<rawString>Gregory Grefenstette. 1998. Cross-Language Information Retrieval, volume 079238122X. Kluwer Academic Publishers. http://www.cnts.ua.ac.be/conll2002/ner/. 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Kishore Papineni</author>
</authors>
<title>Hierarchical system combination for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>277--286</pages>
<contexts>
<context position="24352" citStr="Huang and Papineni, 2007" startWordPosition="4025" endWordPosition="4028">n such as WordNet (Miller, 1995) and the output of a larger set of information extraction models. 7 Experiments To show the effectiveness of cross-language mention propagation information in improving mention detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11 (Papineni et al., 2002). To give an idea of the SMT performance, Table 3 shows the performance of the translation systems on the three language pairs, computed on standard test sets. The Arabic to English SMT system is similar to the one described in (Huang and Papineni, 2007); it has 0.55 BLEU score on NIST 2003 Arabic-English machine translation evaluation test set. The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006). This system obtains a score of 0.32 cased BLUE on NIST 2003 Arabic-English machine translation evaluation test set. The Spanish to English SMT system is similar to the one described in (Lee et al., 2006); it has a 0.55 BLEU score on the final text edition of the European Parliament Plenary Speech corpus in TC-STAR 2006 evaluation. As mentioned earlier, these three SMT systems have very c</context>
</contexts>
<marker>Huang, Papineni, 2007</marker>
<rawString>Fei Huang and Kishore Papineni. 2007. Hierarchical system combination for machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 277–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
</authors>
<title>Breaking the resource bottleneck for multilingual parsing.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</booktitle>
<contexts>
<context position="7501" citStr="Hwa et al., 2002" startWordPosition="1172" endWordPosition="1175">mprovement in performance while building an automatic classifier on the projected annotations over the same automatic classifier trained on a small amount of annotated data in the source language. (Riloff et al., 2002) extends the ideas in (Yarowsky et al., 2001), by showing how it can be used, in conjunction with an automatically trained information extraction system on the source language, to bootstrap the annotation of resources in the target language. They show that they can obtain 48 F-measure on a information extraction task identifying locations, vehicles and victims in plane crashes. (Hwa et al., 2002) proposes a framework that enables the acquisition of syntactic dependency trees for low-resource languages by importing linguistic annotation from rich-resource languages (English). The authors run a large-scale experiment in which Chinese dependency parses were induced from English, and show that a parser trained on the resulting trees outperformed simple baselines. (Cabezas et al., 2001) investigates a similar method of propagating syntactic treebank-like annotations from English to Spanish. Finally, a large body of research has been done on cross-language information retrieval, where the g</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, 2002</marker>
<rawString>Rebecca Hwa, Philip Resnik, and Amy Weinberg. 2002. Breaking the resource bottleneck for multilingual parsing. In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jing</author>
<author>R Florian</author>
<author>X Luo</author>
<author>T Zhang</author>
<author>A Ittycheriah</author>
</authors>
<title>HowtogetaChineseName(Entity): Segmentation and combination issues.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP’03,</booktitle>
<pages>200--207</pages>
<contexts>
<context position="14531" citStr="Jing et al. (2003)" startWordPosition="2377" endWordPosition="2380">orian et al., 2004) and (Zitouni et al., 2005), we decided to “condition” the output of the system on the segmented data: the text is segmented first into tokens and classification is then performed on tokens. The segmentation model is similar to the one presented by (Lee et al., 2003) and obtains an accuracy of 98%. • In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers. Instead of a word-based model, we build a character-based one, since word segmentation errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observes that character-based models are better performing than word-based ones. Word segmentation information is still useful and is integrated as an additional feature stream. • In English and in Spanish mention detection systems are similar to those described in (Florian et al., 2004) where words are the tokens to classify. 6In fact their example of label bias can be trivially solved by allowing the classifier to examine features for subsequent words. 7The ACE data has the nice property of being consistent in annotations across these languages. 4 Cross-Language Mention Propagation The</context>
</contexts>
<marker>Jing, Florian, Luo, Zhang, Ittycheriah, 2003</marker>
<rawString>H. Jing, R. Florian, X. Luo, T. Zhang, and A. Ittycheriah. 2003. HowtogetaChineseName(Entity): Segmentation and combination issues. In Proceedings of EMNLP’03, pages 200–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models.</title>
<date>2004</date>
<booktitle>In Proceedings ofAMTA’04,</booktitle>
<location>Washington DC, September-October.</location>
<contexts>
<context position="16851" citStr="Koehn, 2004" startWordPosition="2762" endWordPosition="2763">ora in many languages. In the approach we propose below, the annotated corpus used to train the mention detection classifier does not have to be part of a parallel corpus. To start the process, we first use a SMT system to translate the source unit (document or sentence) xN1 into the resource-rich language, yielding the sequence ξM 1 = (ξ1, ξ2,... ξM). Taking the sequence of tokens ξM1 as input, the MaxEnt classifier assigns a mention label to each token, building the label sequence ψM1 = (ψ1, ψ2 . . . ψM). Using the SMTproduced word alignment between source text xN1 and translated text ξM 1 (Koehn, 2004),we propagate the target labels ψM 1to the source language building the label sequence yN1 = (y1, y2 ... �yN).8 As an example, if a sequence of tokens in the resourcerich language ξiξi+1ξi+2 is aligned to xjxj+1 in the source language and if ξiξi+1ξi+2 is tagged as a location mention, then the sequence xjxj+1 can be labeled as a location mention: B-LOC, I-LOC. Hence, each token xi in xN1 is tagged with a corresponding propagated label yi in yN1 , yi = φ (i, A, ψM ), where 1 A is the alignment between the source and resourcerich languages. In cases when the alignment is 1- to-1 the function bec</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. In Proceedings ofAMTA’04, Washington DC, September-October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="12911" citStr="Lafferty et al., 2001" startWordPosition="2113" endWordPosition="2116">te the probability into generation probabilities and transition probabilities, and, crucially, has access to observed features (i.e. it can examine the entire sequence, though in practice it will only examine some small N1 − | | N1 − “future” xN1 of it) – which is one way of eliminating label 602 yN1 = arg max ˆyN P (�yN� 1|xN1 = arg max P (9j x , 11 Y | N1 − P (9j part mention encoding is the encoding presented in (Tjong Kim Sang and Veenstra, 1999) and introduced by and Marcus, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1 �−k) bias observed by (Lafferty et al., 2001).6 The experiments are run on four languages, part of the ACE-2007 evaluation (NIST, 2007): Arabic, Chinese, English and Spanish.7 Systems across the languages use a large range of features, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4 characters, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. These features were described in (Florian et al., 2004), and are not discussed here. In this paper we focus on the examining the benefit of cross-language mention propagation</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-S Lee</author>
<author>K Papineni</author>
<author>S Roukos</author>
<author>O Emam</author>
<author>H Hassan</author>
</authors>
<title>Language model based Arabic word segmentation.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL’03,</booktitle>
<pages>399--406</pages>
<contexts>
<context position="14199" citStr="Lee et al., 2003" startWordPosition="2323" endWordPosition="2326">pes of features, we also have implemented language-specific features: • In Arabic, blank-delimited words are composed of zero or more prefixes, followed by a stem and zero or more suffixes. Each prefix, stem or suffix is a token; any contiguous sequence of tokens can represent a mention. Similar to the approaches described in (Florian et al., 2004) and (Zitouni et al., 2005), we decided to “condition” the output of the system on the segmented data: the text is segmented first into tokens and classification is then performed on tokens. The segmentation model is similar to the one presented by (Lee et al., 2003) and obtains an accuracy of 98%. • In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers. Instead of a word-based model, we build a character-based one, since word segmentation errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observes that character-based models are better performing than word-based ones. Word segmentation information is still useful and is integrated as an additional feature stream. • In English and in Spanish mention detection systems are similar to those described</context>
</contexts>
<marker>Lee, Papineni, Roukos, Emam, Hassan, 2003</marker>
<rawString>Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Hassan. 2003. Language model based Arabic word segmentation. In Proceedings of the ACL’03, pages 399– 406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Yaser Al-Onaizan</author>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
</authors>
<title>Ibm spoken language translation system.</title>
<date>2006</date>
<booktitle>In TC-STAR Workshop on Speech-toSpeech Translation,</booktitle>
<pages>13--18</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="24765" citStr="Lee et al., 2006" startWordPosition="4094" endWordPosition="4097">shows the performance of the translation systems on the three language pairs, computed on standard test sets. The Arabic to English SMT system is similar to the one described in (Huang and Papineni, 2007); it has 0.55 BLEU score on NIST 2003 Arabic-English machine translation evaluation test set. The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006). This system obtains a score of 0.32 cased BLUE on NIST 2003 Arabic-English machine translation evaluation test set. The Spanish to English SMT system is similar to the one described in (Lee et al., 2006); it has a 0.55 BLEU score on the final text edition of the European Parliament Plenary Speech corpus in TC-STAR 2006 evaluation. As mentioned earlier, these three SMT systems have very competitive performance and are ranked among top 2 systems participating to NIST or TC-STAR evaluations. Also, the English mention detection system used for experiments has an F-measure of 82.7 and that has very competitive results among systems participating in the ACE 2007 evaluation. Experiments are conducted under several conditions in order to investigate the effectiveness of our approach in improving ment</context>
</contexts>
<marker>Lee, Al-Onaizan, Papineni, Roukos, 2006</marker>
<rawString>Young-Suk Lee, Yaser Al-Onaizan, Kishore Papineni, and Salim Roukos. 2006. Ibm spoken language translation system. In TC-STAR Workshop on Speech-toSpeech Translation, pages 13–18, Barcelona, Spain, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Dayne Freitag</author>
<author>Fernando Pereira</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation.</title>
<date>2000</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="12265" citStr="McCallum et al., 2000" startWordPosition="1987" endWordPosition="1990">n (I-), and asub-type corresponding to mention type (e.g. B-PERSON). In ACE, there are seven possible types: person, organization, location, facility, geopolitical entity (GPE), weapon, an it’s “outside mentions”) d vehicle. weights are estimated during the training phase to maximize the likelihood of the To compute the best sequence yN1 , we use yJ Y= arg max yˆ j , kl has an exponential form of where P (9j x the type (2). We also used the standard Markov assumption that the probability P (yj x , y1 11 only depends on the previous k classifications. J This model is similar to the MEMM model (McCallum et al., 2000), but it does not separate the probability into generation probabilities and transition probabilities, and, crucially, has access to observed features (i.e. it can examine the entire sequence, though in practice it will only examine some small N1 − | | N1 − “future” xN1 of it) – which is one way of eliminating label 602 yN1 = arg max ˆyN P (�yN� 1|xN1 = arg max P (9j x , 11 Y | N1 − P (9j part mention encoding is the encoding presented in (Tjong Kim Sang and Veenstra, 1999) and introduced by and Marcus, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1</context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>Andrew McCallum, Dayne Freitag, and Fernando Pereira. 2000. Maximum entropy markov models for information extraction and segmentation. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: A lexical database.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="13232" citStr="Miller, 1995" startWordPosition="2167" endWordPosition="2168">= arg max P (9j x , 11 Y | N1 − P (9j part mention encoding is the encoding presented in (Tjong Kim Sang and Veenstra, 1999) and introduced by and Marcus, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1 �−k) bias observed by (Lafferty et al., 2001).6 The experiments are run on four languages, part of the ACE-2007 evaluation (NIST, 2007): Arabic, Chinese, English and Spanish.7 Systems across the languages use a large range of features, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4 characters, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. These features were described in (Florian et al., 2004), and are not discussed here. In this paper we focus on the examining the benefit of cross-language mention propagation information in improving mention detection systems. Besides generic types of features, we also have implemented language-specific features: • In Arabic, blank-delimited words are composed of zero or more prefixes, followed by a stem and zero or more suffixes. Each prefix, stem or suffix is a token; any contiguous seque</context>
<context position="22971" citStr="Miller, 1995" startWordPosition="3796" endWordPosition="3797">ACE value metric (NIST, 2007), given that we are interested in the mention detection task only, we decided to use the more intuitive and popular (unweighted) F-measure, the harmonic mean of precision and recall. 6 Resource-Rich Languages From the set of four languages in ACE 2007, we will unsurprisingly select English as the resourcerich language. Table 2 shows the performance of mention detection systems in all 4 languages one can obtain by using all available resources in that language, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. N P R F Arabic 3566 83.6 76.8 80.0 Chinese 4791 81.1 71.3 75.8 English 8170 84.6 80.8 82.7 Spanish 2487 79.1 73.5 76.2 Table 2: Performance of Arabic, Chinese, English and Spanish mention detection systems. Performance is presented in terms of Precision (P), Recall (R), and Fmeasure (F). The column (N) displays the number of mentions in the test set. Results show that the English mention detection system has a better performance when compared to systems dealing with other languages such as </context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>G. A. Miller. 1995. WordNet: A lexical database. Communications of the ACM, 38(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>The ACE evaluation plan.</title>
<date>2007</date>
<note>www.nist.gov/speech/tests/ace/index.htm.</note>
<contexts>
<context position="3562" citStr="NIST, 2007" startWordPosition="551" endWordPosition="552">of languages with few resources. It would be very useful if one could make use of the resources in the former languages to help bootstrapping (or just the projection) of resource in any resource-challenged language. Information transfer from a language to another can be very useful when the “donor” language has more resources than the receiving one. As resources grow in quantity and quality in the receiving language, it becomes less and less likely that there will be a gain in performance by transfering information, as there are several sources of noise involved in the 1We adopt here the ACE (NIST, 2007) nomenclature 600 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 600–609, Honolulu, October 2008.c�2008 Association for Computational Linguistics process - such as the translation (machine generated or not) and the inherent imperfection of the mention detection in the donor language. To test this hypothesis, we conducted experiments on systems build with a varied amount of resources in the receiving language, starting with the case where there are none2 (all information is transferred through translation alignment), and ending with the case where </context>
<context position="13001" citStr="NIST, 2007" startWordPosition="2129" endWordPosition="2130">cess to observed features (i.e. it can examine the entire sequence, though in practice it will only examine some small N1 − | | N1 − “future” xN1 of it) – which is one way of eliminating label 602 yN1 = arg max ˆyN P (�yN� 1|xN1 = arg max P (9j x , 11 Y | N1 − P (9j part mention encoding is the encoding presented in (Tjong Kim Sang and Veenstra, 1999) and introduced by and Marcus, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1 �−k) bias observed by (Lafferty et al., 2001).6 The experiments are run on four languages, part of the ACE-2007 evaluation (NIST, 2007): Arabic, Chinese, English and Spanish.7 Systems across the languages use a large range of features, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4 characters, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. These features were described in (Florian et al., 2004), and are not discussed here. In this paper we focus on the examining the benefit of cross-language mention propagation information in improving mention detection systems. Besides generic types of features, we</context>
<context position="22387" citStr="NIST, 2007" startWordPosition="3699" endWordPosition="3700">of the SMT systems on the 3 language pairs Table 1: Datasets size (number of documents) Language Training Test Arabic 323 56 Chinese 538 95 English 499 100 Spanish 467 52 Language Pair BLEU Score Arabic-English 0.55 Chinese-English 0.32 Spanish-English 0.55 the training and test data sets do not overlap in time, and the content of the test data is more recent than the training data. Table 1 presents the number of documents in the training/test datasets for each of the four languages. While performance on the ACE data is usually evaluated using a special-purpose measure - the ACE value metric (NIST, 2007), given that we are interested in the mention detection task only, we decided to use the more intuitive and popular (unweighted) F-measure, the harmonic mean of precision and recall. 6 Resource-Rich Languages From the set of four languages in ACE 2007, we will unsurprisingly select English as the resourcerich language. Table 2 shows the performance of mention detection systems in all 4 languages one can obtain by using all available resources in that language, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4, WordNet (Miller, 1995) for English), s</context>
</contexts>
<marker>NIST, 2007</marker>
<rawString>NIST. 2007. The ACE evaluation plan. www.nist.gov/speech/tests/ace/index.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric W Noreen</author>
</authors>
<title>Computer-Intensive Methods for Testing Hypotheses.</title>
<date>1989</date>
<publisher>John Wiley Sons.</publisher>
<contexts>
<context position="26419" citStr="Noreen, 1989" startWordPosition="4358" endWordPosition="4359">n be directly derived exclusively from mention-labeled text); 3. the system has access to lexical and syntactic (e.g., POS tags, text chunks) information (requires mention-labeled text, and models to predict POS tags, etc); 4. the system that has access to lexical, syntactic, and semantic information (requires even more models and labeled data). The rest of this section examines in detail these four cases. To measure whether the improvement in performance of a particular system over another one is statistically significant or not, we use the stratified bootstrap re-sampling significance test (Noreen, 1989). This approach was used in the named entity recognition shared task of CoNNL2002 (http://www.cnts.ua.ac.be/conll2002/ner/, 2002). In the following tables, we add a dagger sign † to results that are not statistically significant when compared to the baseline results. 7.1 No Source Language Training Data In this first case, as described in Section 4, the mention labels in the source language are obtained directly through the alignment from the mentions in the translated text. This is a very simple scenario, which can be implemented with ease, and, as we will see, yields reasonable performance o</context>
</contexts>
<marker>Noreen, 1989</marker>
<rawString>Eric W. Noreen. 1989. Computer-Intensive Methods for Testing Hypotheses. John Wiley Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="24098" citStr="Papineni et al., 2002" startWordPosition="3981" endWordPosition="3984"> system has a better performance when compared to systems dealing with other languages such as Arabic, Chinese and Spanish. These results are not unexpected since the English model has access to a larger training data and uses richer set of information such as WordNet (Miller, 1995) and the output of a larger set of information extraction models. 7 Experiments To show the effectiveness of cross-language mention propagation information in improving mention detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11 (Papineni et al., 2002). To give an idea of the SMT performance, Table 3 shows the performance of the translation systems on the three language pairs, computed on standard test sets. The Arabic to English SMT system is similar to the one described in (Huang and Papineni, 2007); it has 0.55 BLEU score on NIST 2003 Arabic-English machine translation evaluation test set. The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006). This system obtains a score of 0.32 cased BLUE on NIST 2003 Arabic-English machine translation evaluation test set. The Spanish to Engli</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Della Pietra P F Brown</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>Word-sense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>In Proceedings ofACL’91.</booktitle>
<contexts>
<context position="5369" citStr="Brown et al., 1991" startWordPosition="831" endWordPosition="834">nside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content from one language (most of the time English) to another. The earliest investigations of the subject have been performed, on word sense disambiguation (Dagan et al., 1991; P.F.Brown et al., 1991; Gale et al., 1992) (perhaps unsurprisingly given its close connection to machine translation) – all propose and (lightly) evaluate methods to use word sense information extracted from the target language to help the sense resolution in the source language and machine translation. (Dagan and Itai, 1994) explicitly suggests performing word sense disambiguation in the target language (English in the article) with the goal of resolving ambiguity in the source language (Hebrew), and show moderate 2While applying this method in the case where the source language has absolutely no resources might b</context>
</contexts>
<marker>Brown, Pietra, Mercer, 1991</marker>
<rawString>P.F.Brown, S.A.Della Pietra, V.J. Della Pietra, and R.L.Mercer. 1991. Word-sense disambiguation using statistical methods. In Proceedings ofACL’91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ramshaw</author>
<author>M Marcus</author>
</authors>
<title>Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language,</booktitle>
<pages>128--135</pages>
<marker>Ramshaw, Marcus, 1994</marker>
<rawString>L. Ramshaw and M. Marcus. 1994. Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging. In Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ramshaw</author>
<author>M Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<editor>In David Yarowsky and Kenneth Church, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Somerset, New Jersey.</location>
<contexts>
<context position="4527" citStr="Ramshaw and Marcus, 1995" startWordPosition="698" endWordPosition="701">this hypothesis, we conducted experiments on systems build with a varied amount of resources in the receiving language, starting with the case where there are none2 (all information is transferred through translation alignment), and ending with the case where we used all the resources we could gather for that language. The experiments will show that the gain in performance decreases with the amount of resources used in the source language, but, still, even when all resources were used, a statistically significant gain was still observed. Similarly to classical NLP tasks such as text chunking (Ramshaw and Marcus, 1995) and named entity recognition (Tjong Kim Sang, 2002), we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using </context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. Ramshaw and M. Marcus. 1995. Text chunking using transformation-based learning. In David Yarowsky and Kenneth Church, editors, Proceedings of the Third Workshop on Very Large Corpora, pages 82–94, Somerset, New Jersey. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>C Schafer</author>
<author>D Yarowsky</author>
</authors>
<title>Inducing information extraction systems for new languages via cross-language projection.</title>
<date>2002</date>
<booktitle>In Proceedings of Coling</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="7102" citStr="Riloff et al., 2002" startWordPosition="1107" endWordPosition="1110">uage information transfer, (Yarowsky et al., 2001) proposed and evaluated a method of propagating POS tagging, named mention, base noun phrase, and morphological information from English into a foreign language, which is very similar to the one presented in this article (experiments were run on French, Chinese, Czech, and Spanish – on human-generated translations). Their results show a significant improvement in performance while building an automatic classifier on the projected annotations over the same automatic classifier trained on a small amount of annotated data in the source language. (Riloff et al., 2002) extends the ideas in (Yarowsky et al., 2001), by showing how it can be used, in conjunction with an automatically trained information extraction system on the source language, to bootstrap the annotation of resources in the target language. They show that they can obtain 48 F-measure on a information extraction task identifying locations, vehicles and victims in plane crashes. (Hwa et al., 2002) proposes a framework that enables the acquisition of syntactic dependency trees for low-resource languages by importing linguistic annotation from rich-resource languages (English). The authors run a </context>
</contexts>
<marker>Riloff, Schafer, Yarowsky, 2002</marker>
<rawString>E. Riloff, C. Schafer, and D. Yarowsky. 2002. Inducing information extraction systems for new languages via cross-language projection. In Proceedings of Coling 2002, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Tjong Kim Sang</author>
<author>J Veenstra</author>
</authors>
<title>Representing text chunks.</title>
<date>1999</date>
<booktitle>In Proceedings ofEACL’99.</booktitle>
<contexts>
<context position="12743" citStr="Sang and Veenstra, 1999" startWordPosition="2079" endWordPosition="2082"> the probability P (yj x , y1 11 only depends on the previous k classifications. J This model is similar to the MEMM model (McCallum et al., 2000), but it does not separate the probability into generation probabilities and transition probabilities, and, crucially, has access to observed features (i.e. it can examine the entire sequence, though in practice it will only examine some small N1 − | | N1 − “future” xN1 of it) – which is one way of eliminating label 602 yN1 = arg max ˆyN P (�yN� 1|xN1 = arg max P (9j x , 11 Y | N1 − P (9j part mention encoding is the encoding presented in (Tjong Kim Sang and Veenstra, 1999) and introduced by and Marcus, 1994) for base noun phras 5The IOB2 (Ramshaw e chunking. Z(x) = X Y i j αf�(x,yi) ij x | N1 �−k) bias observed by (Lafferty et al., 2001).6 The experiments are run on four languages, part of the ACE-2007 evaluation (NIST, 2007): Arabic, Chinese, English and Spanish.7 Systems across the languages use a large range of features, including lexical (words and morphs in a 3-word window, prefixes and suffixes of length up to 4 characters, WordNet (Miller, 1995) for English), syntactic (POS tags, text chunks), and the output of other information extraction models. These </context>
</contexts>
<marker>Sang, Veenstra, 1999</marker>
<rawString>E. F. Tjong Kim Sang and J. Veenstra. 1999. Representing text chunks. In Proceedings ofEACL’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Tjong Kim Sang</author>
</authors>
<title>Introduction to the conll2002 shared task: Language-independentnamed entity recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL-2002,</booktitle>
<pages>155--158</pages>
<contexts>
<context position="4579" citStr="Sang, 2002" startWordPosition="708" endWordPosition="709">varied amount of resources in the receiving language, starting with the case where there are none2 (all information is transferred through translation alignment), and ending with the case where we used all the resources we could gather for that language. The experiments will show that the gain in performance decreases with the amount of resources used in the source language, but, still, even when all resources were used, a statistically significant gain was still observed. Similarly to classical NLP tasks such as text chunking (Ramshaw and Marcus, 1995) and named entity recognition (Tjong Kim Sang, 2002), we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision. 2 Previous Work There are several investigations in literature that explore using parallel corpora to transfer information content fro</context>
</contexts>
<marker>Sang, 2002</marker>
<rawString>E. F. Tjong Kim Sang. 2002. Introduction to the conll2002 shared task: Language-independentnamed entity recognition. In Proceedings of CoNLL-2002, pages 155–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings ofHLT 2001,</booktitle>
<location>San Diego, California, USA.</location>
<contexts>
<context position="6532" citStr="Yarowsky et al., 2001" startWordPosition="1016" endWordPosition="1019">ere the source language has absolutely no resources might be an interesting test case, we don’t see it as being realistic. Resources are build nowadays in a large variety of languages, and not making use of them is rather foolish (a certain big bird and sand comes to mind). improvement on a small data set3. More recently, (Diab and Resnik, 2001) presents a method for performing word sense tagging in both the source and target texts of parallel bilingual corpora with the English WordNet sense inventory, by using translation correspondences. On more general cross-language information transfer, (Yarowsky et al., 2001) proposed and evaluated a method of propagating POS tagging, named mention, base noun phrase, and morphological information from English into a foreign language, which is very similar to the one presented in this article (experiments were run on French, Chinese, Czech, and Spanish – on human-generated translations). Their results show a significant improvement in performance while building an automatic classifier on the projected annotations over the same automatic classifier trained on a small amount of annotated data in the source language. (Riloff et al., 2002) extends the ideas in (Yarowsk</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings ofHLT 2001, San Diego, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Jeff Sorensen</author>
<author>Xiaoqiang Luo</author>
<author>Radu Florian</author>
</authors>
<title>The impact of morphological stemming on Arabic mention detection and coreference resolution.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages,</booktitle>
<pages>63--70</pages>
<location>Ann Arbor,</location>
<contexts>
<context position="13959" citStr="Zitouni et al., 2005" startWordPosition="2282" endWordPosition="2285">hese features were described in (Florian et al., 2004), and are not discussed here. In this paper we focus on the examining the benefit of cross-language mention propagation information in improving mention detection systems. Besides generic types of features, we also have implemented language-specific features: • In Arabic, blank-delimited words are composed of zero or more prefixes, followed by a stem and zero or more suffixes. Each prefix, stem or suffix is a token; any contiguous sequence of tokens can represent a mention. Similar to the approaches described in (Florian et al., 2004) and (Zitouni et al., 2005), we decided to “condition” the output of the system on the segmented data: the text is segmented first into tokens and classification is then performed on tokens. The segmentation model is similar to the one presented by (Lee et al., 2003) and obtains an accuracy of 98%. • In Chinese text, unlike in Indo-European languages, words neither are white-space delimited nor do they have capitalization markers. Instead of a word-based model, we build a character-based one, since word segmentation errors can lead to irrecoverable mention detection errors; Jing et al. (2003) also observes that characte</context>
</contexts>
<marker>Zitouni, Sorensen, Luo, Florian, 2005</marker>
<rawString>Imed Zitouni, Jeff Sorensen, Xiaoqiang Luo, and Radu Florian. 2005. The impact of morphological stemming on Arabic mention detection and coreference resolution. In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 63–70, Ann Arbor, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>