<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005271">
<title confidence="0.995966">
Detecting Errors within a Corpus using Anomaly Detection
</title>
<author confidence="0.997082">
Eleazar Eskin
</author>
<affiliation confidence="0.998154">
Department of Computer Science
Columbia University
</affiliation>
<email confidence="0.993687">
eeskin@cs.columbia.edu
</email>
<sectionHeader confidence="0.993802" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99897175">
We present a method for automatically detect-
ing errors in a manually marked corpus us-
ing anomaly detection. Anomaly detection is
a method for determining which elements of a
large data set do not conform to the whole.
This method fits a probability distribution over
the data and applies a statistical test to detect
anomalous elements. In the corpus error detec-
tion problem, anomalous elements are typically
marking errors. We present the results of ap-
plying this method to the tagged portion of the
Penn Treebank corpus.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999853702702703">
Manually marking corpora is a time consuming
and expensive process. The process is subject to
human error by the experts doing the marking.
Unfortunately, many natural language process-
ing methods are sensitive to these errors. In
order to ensure accuracy in a corpus, typically
several experts pass over the corpus to ensure
consistency. For large corpora this can be a
tremendous expense.
In this paper, we propose a method for au-
tomatically detecting errors in a marked cor-
pus using an anomaly detection technique. This
technique detects anomalies or elements which
do not fit in with the rest of the corpus. When
applied to marked corpora, the anomalies tend
to be errors in the markings of the corpus.
To detect the anomalies, we first compute a
probability distribution over the entire corpus.
Then we apply a statistical test which identi-
fies which elements are anomalies. In this case
the anomalies are the elements with very low
likelihood. These elements are marked as errors
and are thrown out of the corpus. The model is
recomputed on the remaining elements. At con-
clusion, we are left with two data sets: one the
normal elements and the second the detected
anomalous elements.
We evaluate this method over the part of
speech tagged portion of the Penn Treebank cor-
pus (Marcus et al., 1993). In one experiment,
our method detected 1000 anomalies within a
data set of 1.25 million tagged elements. Human
judges evaluated the results of the application
of this method and verified that 69% of iden-
tified anomalies are in fact tagging errors. In
another experiment, our method detected 4000
anomalies of which 44% are tagging errors.
</bodyText>
<sectionHeader confidence="0.546981" genericHeader="related work">
1.1 Related Work
</sectionHeader>
<bodyText confidence="0.999969269230769">
The tagged portion of the Penn Treebank
has been extensively utilized for construction
and evaluation of taggers. This includes
transformation-based tagging (Brill, 1994; Brill
and Wu, 1998). Weischedel et al. (1993) applied
Markov Models to tagging. Abney et al. (1999)
applied boosting to part of speech tagging. Ad-
wait Ratnaparkhi (1996) estimates a probabil-
ity distribution for tagging using a maximum
entropy approach.
Regarding error detection in corpora, Rat-
naparkhi (1996) discusses inconsistencies in
the Penn Treebank and relates them to inter-
annotator differences in tagging style. Abney,
Schapire and Singer (1999) discuss how to use
boosting for cleaning data.
Much related work to the anomaly detection
problem stems from the field of statistics in
the study of outliers. This work examines de-
tecting and dealing with outliers in univariate
data, multivariate data, and structured data
where the probability distribution over the data
is given a priori. Statistics gives a set of discor-
dancy tests which can be applied to any given
element in the dataset to determine whether it
is an outlier. A survey of outliers in statistics is
</bodyText>
<page confidence="0.997115">
148
</page>
<bodyText confidence="0.999869294117647">
given in Barnett and Lewis (1994).
Anomaly detection is extensively used within
the field of computer security specifically in in-
trusion detection (Denning, 1987). Typically
anomaly detection methods are applied to de-
tect attacks by comparing the activity during an
attack to the activity under normal use (Lane
and Brodley, 1997; Warrender et al., 1999). The
method used in this paper is based on a method
for anomaly detection which detects anomalies
in noisy data (Eskin, 2000).
The sparse Markov transducer probability
modeling method is an extension of adaptive
mixtures of probabilistic transducers (Singer,
1997; Pereira and Singer, 1999). Naive Bayes
learning, which is used to estimate probabilities
in this paper, is described in (Mitchell, 1997).
</bodyText>
<sectionHeader confidence="0.97751" genericHeader="method">
2 Anomaly Detection
</sectionHeader>
<bodyText confidence="0.9999498">
More formally, anomaly detection is the process
of determining when an element of data is an
outlier. Given a set of training data without a
probability distribution, we want to construct
an automatic method for detecting anomalies.
We are interested in detecting anomalies for two
main reasons. One, we are interested in model-
ing the data and the anomalies can contaminate
the model. And two, the anomalies themselves
can be of interest as they may show rarely oc-
curring events. For the purposes of this work,
we are most interested in identifying mistagged
elements, i.e. the second case.
In order to motivate a method for detect-
ing anomalies, we must first make assumptions
about how the anomalies occur in the data. We
use a &amp;quot;mixture model&amp;quot; for explaining the pres-
ence of anomalies, one of several popular models
in statistics for explaining outliers (Barnett and
Lewis, 1994). In the mixture model, there are
two probability distributions which generate the
data. An element xi is either generated from the
majority distribution or with (small) probabil-
ity A from an alternate (anomalous) distribu-
tion. Our distribution for the data, D, is then:
</bodyText>
<equation confidence="0.938205">
D (1 — A)M + AA (1)
</equation>
<bodyText confidence="0.99994165">
where M is the majority distribution, and A
is the anomalous distribution. The mixture
framework for explaining anomalies is indepen-
dent of the properties of the distributions M
and A. In other words, no assumptions about
the nature of the probability distributions are
necessary. The specific probability distribu-
tions, M and A, are chosen based on prior
knowledge of the problem. Typically M is a
structured distribution which is estimated over
the data using a machine learning technique,
while A is a uniform (random) distribution rep-
resenting elements which do not fit into M.
In the corpus error detection problem, we are
assuming that for each tag in the corpus with
probability (1 — A) the human annotator markes
the corpus with the correct tag and with prob-
ability A the human annotator makes an error.
In the case of an error, we assume that the tag
is chosen at random.
</bodyText>
<subsectionHeader confidence="0.999676">
2.1 Detection of Anomalies
</subsectionHeader>
<bodyText confidence="0.99997455">
Detecting anomalies, in this framework, is
equivalent to determining which elements were
generated by the distribution A and which ele-
ments were generated by distribution M. Ele-
ments generated by A are anomalies, while ele-
ments generated by M are not. In our case, we
have probability distributions associated with
the distributions M and A, Pm and PA respec-
tively.
The algorithm partitions the data into two
sets, the normal elements M and the anomalies
A. For each element, we make a determination
of whether it is an anomaly and should be in-
cluded in A or a majority element in which it
should be included in M. We measure the like-
lihood of the distribution under both cases to
make this determination.
The likelihood, L, of distribution D with
probability function P over elements xi,...,xN
is defined as follows:
</bodyText>
<equation confidence="0.989406">
L(D) = PD(xi)
— A)IM II Pm(xi)) PA(Xj))
xiEM x1•EA
</equation>
<bodyText confidence="0.998906">
Since the product of small numbers is difficult
to compute, we instead compute the log likeli-
hood, LL. The log likelihood for our case is:
</bodyText>
<equation confidence="0.9911936">
LL(D) =I* log(1 — A) + E log(Pm(xi))
x,EM
+IAI log A + E log(PA (xi)) (3)
x EA
(2)
</equation>
<page confidence="0.981709">
149
</page>
<bodyText confidence="0.999846214285714">
In order to determine which elements are
anomalies, we use a general principal for deter-
mining outliers in multivariate data (Barnett,
1979). We measure how likely each element xi is
an outlier by comparing the difference between
the log likelihood of the distribution if the ele-
ment is removed from the majority distribution
and included in the anomalous distribution. If
this difference is sufficiently large, we declare
the element an anomaly.
Specifically what this difference should be de-
pends on the probability distributions and prior
knowledge of the problem such as the rate of the
anomalies, A.
</bodyText>
<sectionHeader confidence="0.997112" genericHeader="method">
3 Methodology
</sectionHeader>
<subsectionHeader confidence="0.870259">
3.1 Corpus
</subsectionHeader>
<bodyText confidence="0.9999604">
The corpus we use is the Penn Treebank tagged
corpus. The corpus contains approximately 1.25
million manually tagged words from Wall Street
Journal articles. For each word, a record is gen-
erated containing the following elements:
</bodyText>
<listItem confidence="0.990585">
1. The tag of the current word T.
2. The current word Wi.
3. The previous tag Ti_1.
4. The next tag
</listItem>
<bodyText confidence="0.97468">
Over records containing these 4 elements, we
compute our probability distributions.
</bodyText>
<subsectionHeader confidence="0.999186">
3.2 Probability Modeling Methods
</subsectionHeader>
<bodyText confidence="0.999982571428571">
The anomaly detection framework is indepen-
dent of specific probability distributions. Dif-
ferent probability distributions have different
properties. Since the anomaly detection frame-
work does not depend on a specific probability
distribution, we can choose the probability dis-
tribution to best model the data based on our
intuitions about the problem.
To illustrate this, we perform two sets of ex-
periments, each using a different probability dis-
tribution modeling method. The first set of
experiments uses sparse Markov transducers as
the probability modeling method, while the sec-
ond uses a simple naive Bayes method.
</bodyText>
<subsectionHeader confidence="0.996163">
3.3 Sparse Markov Transducers
</subsectionHeader>
<bodyText confidence="0.998621833333333">
Sparse Malloy transducers compute probabilis-
tic mappings over sparse data. A Markov trans-
ducer is defined to be a probability distribution
conditional on a finite set of inputs. A Markov
transducer of order L is the conditional proba-
bility distribution of the form:
</bodyText>
<equation confidence="0.999696">
P(YtiXtXt_iXt-2Xt-3...Xt- (L-1) ) (4)
</equation>
<bodyText confidence="0.989705822222222">
where Xk are random variables over the in-
put alphabet Eiu and Yk is a random variable
over the output alphabet Eout. This probability
distribution stochastically defines a mapping of
strings over the input alphabet into the output
alphabet. The mapping is conditional on the L
previous input symbols.
In the case of sparse data, the probability
distribution is conditioned on only some of the
inputs. We use sparse Markov transducers to
model these type of distributions. A sparse
Markov transducer is a conditional probability
of the form:
p(yt xti on2xt2...(Ank Xtk (5)
where 0 represents a wild card symbol and
ti= t - E zi .1n3 - (i - 1). The goal of the
sparse Markov transducer estimation algorithm
is to estimate a conditional probability of this
form based upon a set of inputs and their cor-
responding outputs. However, the task is com-
plicated due to the lack of knowledge a priori
of which inputs the probability distribution is
conditional on.
Intuitively, a fixed order Markov Chain of or-
der L is equivalent to a n-gram with n = L.
In a variable order Markov Chain, the value of
n changes depending on the context. For ex-
ample, some elements in the data may use a
bigram, while others may use a trigram. The
sparse Markov transducer uses a weighted sum
of n-grams for different values of n and these
weights depend on the context. In addition the
weighted sum is over not only n-grams, but also
n-grams with wild cards such as a trigram where
only the first and last element is conditioned on.
In this case we are looking at the input se-
quence of the current word, Wt, the previous
tag, Tt_1, and the next tag, Tt±i. The out-
put is the set of all possible tags. The models
that are in the weighted sum are the trigram,
WtTt_iTt+1; the bigrams WtTt_i, WtTt+i and
Tt_iTt+i; and the unigrams Wt, Tt_1 and Tt-Fi.
The specific weights of each model depends on
the context or the actual values of Wt, Tt_1, and
Tt+i .
</bodyText>
<page confidence="0.995374">
150
</page>
<bodyText confidence="0.999958444444445">
Sparse Markov transducers depend on a set of
prior probabilities that incorporate prior knowl-
edge about the importance of various elements
in the input sequence. These prior probabilities
are set based on the problem. For this problem,
we use the priors to encode the information that
the current word, Wt, is very important in de-
termining the part of speech.
Each model in the weighted sum uses a
pseudo-count predictor. This predictor com-
putes the probability of an output (tag) by the
number of times that a specific output was seen
in a given context. In order to avoid probabil-
ities of 0, we assume that we have seen each
output at least once in every context. In fact,
these predictors can be any probability distri-
bution which can also depend on what works
best for the task.
</bodyText>
<subsectionHeader confidence="0.930016">
3.4 Naive Bayes
</subsectionHeader>
<bodyText confidence="0.998934375">
The probability distribution for the tags was
also estimated using a straight forward naive
Bayes approach.
We are interested in the probability of a tag,
given the current word, the previous tag, and
the next tag, or the probability distribution
P(Tt I Wt, Tt_i, Tt+i) which using Bayes Rule is
equivalent to:
</bodyText>
<equation confidence="0.832762333333333">
=
P(Wi,Ti-1,71+1)21)*P(T2)
P(Wi, T2+1)
</equation>
<bodyText confidence="0.999827666666667">
If we make the Naive Bayes independence as-
sumption and we assume that the denominator
is constant for all values this reduces to:
</bodyText>
<equation confidence="0.999457666666667">
P(711147z, Ti+1) =
P(WitZ) * * P(Ti+ilTi) * P(Ti)
(7)
</equation>
<bodyText confidence="0.9998506">
where C is a normalization constant in order to
have the probabilities sum to 1. Each of the val-
ues on the right side of the equation can easily
be computed over the data estimating a proba-
bility distribution.
</bodyText>
<subsectionHeader confidence="0.613228">
3.5 Computing Probability
Distributions
</subsectionHeader>
<bodyText confidence="0.999982583333333">
Each probability distribution was trained over
each record giving a model over the entire data.
The probability model is then used to deter-
mine whether or not an element is an anomaly
by applying the test in equation (3). Typi-
cally this can be done in an efficient manner
because the approach does not require reesti-
mating the model over the entire data set. If an
element is designated as an anomaly, we remove
it from the set of normal elements and efficiently
reestimate the probability distribution to obtain
more anomalous elements.
</bodyText>
<sectionHeader confidence="0.976348" genericHeader="method">
4 Results/Evaluation
</sectionHeader>
<bodyText confidence="0.999955285714285">
The method was applied to the Penn Tree-
bank corpus and a set of anomalies were gen-
erated. These anomalies were evaluated by hu-
man judges to determine if they are in fact tag-
ging errors in the corpus. The human judges
were natural language processing researchers
(not the author) familiar with the Penn Tree-
bank markings.
In the experiments involving the sparse
Markov transducers, after applying the method,
7055 anomalies were detected. In the ex-
periments involving the naive Bayes learning
method, 6213 anomalies were detected.
Sample output from the system is shown in
figure 1. The error is shown in the context
marked with !!!. The likelihood of the tag is
also given which is extremely low for the errors.
The system also outputs a suggested tag and
its likelihood which is the tag with the highest
likelihood for that context. As we can see, these
errors are clearly annotation errors.
Since the anomalies detected from the two
probability modeling methods differed only
slightly, we performed human judge verification
of the errors over only the results of the sparse
Markov transducer experiments.
The anomalies were ordered based on their
likelihood. Using this ranking, the set of anoma-
lies were broken up into sets of 1000 records. We
examined the first 4000 elements by randomly
selecting 100 elements out of each 1000.
Human judges were presented with the sys-
tem output for four sets of 100 anomalies. The
judges were asked to choose among three op-
tions for each example:
</bodyText>
<listItem confidence="0.946816">
1. Corpus Error - The tag in the corpus sen-
tence is incorrect.
2. Unsure - The judge is unsure whether or
not the corpus tag is correct.
(6)
</listItem>
<page confidence="0.992989">
151
</page>
<table confidence="0.974379285714286">
Error 0.000035: Its/PRP$ fast-food/NN restaurants/NNS -/: including! VBG
Denny/NNP &apos;s/POS ,/, Hardee/NNP &apos;s/POS ,/, Quincy/NNP &apos;s/POS and/CC
El/NNP Pollo/NNP Loco/NNP (/( &amp;quot;/&amp;quot; !!!the/NN!!! only/JJ significant/JJ fast-food/NN
chain/NN to/TO specialize/VB in/IN char-broiled/JJ chicken/NN &amp;quot;/&amp;quot; )/) -/: are/VBP
stable/JJ ,/, recession-resist ant/ J J and/CC growing/VBG ./.
Suggested Tag: DT (0.998262)
Error 0.019231: Not/RB even/RB Jack/NNP Lemmon/NNP &apos;s/POS expert/JJ
doddering/JJ !!!makes/NNS!!! this/DT trip/NN worth/NN taking/VBG ./.
Suggested Tag: VBZ (0.724359)
Error 0.014286: It/PRP also/RB underscores/VBZ the/DT difficult/JJ task/NN
ahead/RB as/IN !!!Coors/NNS!!! attempts/VBZ to/TO purchase/VB Stroh/NNP Brew-
ery/NNP Co./NNP and/CC fight/VB off/RP increasingly/RB tough/JJ competition/NN
from/IN Anheuser-Busch/NNP Cos/NNP ./.
Suggested Tag: NNP (0.414286)
</table>
<figureCaption confidence="0.973073">
Figure 1: Sample output of anomalies in Penn Treebank corpus. The errors are marked with !!!.
</figureCaption>
<bodyText confidence="0.919328461538462">
3. System Error - The tag in the corpus sen-
tence is correct and the system incorrectly
marked it as an error.
The &amp;quot;unsure&amp;quot; choice was allowed because of the
inherent subtleties in differentiating between
types of tags such as &amp;quot;VB vs. VBP&amp;quot; or &amp;quot;VBD
vs. VBN&amp;quot;.
Over the 400 examples evaluated, 158 were
corpus errors, 202 were system errors and the
judges were unsure in 40 of the cases. The cor-
pus error rate was computed by throwing out
the unsure cases and computing:
Corpus error rate = (8)
</bodyText>
<sectionHeader confidence="0.5895505" genericHeader="method">
Corpus Errors
System Errors + Corpus Errors
</sectionHeader>
<bodyText confidence="0.999989684210526">
The total corpus error rate over the 400 manu-
ally checked examples was was 44%. As can be
seen, many of the anomalies are in fact errors
in the corpus.
For each error, we asked the human judge to
determine if the correct tag is the systems sug-
gested tag. Out of the total 158 corpus errors,
the systems correct tag would have corrected
the error in 145 cases.
Since the verified examples were random, we
can assume that 91% of corpus errors would be
automatically corrected if the system would re-
place the suspect tag with the suggested tag. Ig-
noring the &amp;quot;unsure&amp;quot; elements for the purposes
of this analysis, if we attempted to automati-
cally correct the first 1000 examples where the
error rate was 69%, this method would have led
to a reduction of the total number of errors in
the corpus by 245.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999946041666667">
This paper presents a fully automatic method
for detecting errors in corpora using anomaly
detection techniques. As shown, the anomalies
detected in the Penn Treebank corpus tend to
be tagging errors.
This method has some inherent limitations
because not all errors in the corpus would mani-
fest themselves as anomalies. In infrequent con-
texts or ambiguous situations, the method may
not have enough information to detect an error.
In addition, if there are inconsistencies between
annotators, the method would not detect the
errors because the errors would be manifested
over a significant portion of the corpus.
Although this paper presents a fully au-
tomatic method for error detection in cor-
pora, this method can also be used as a semi-
automatic method for correcting errors. The
method can guide an annotator to the elements
which are most likely errors. The method can
greatly reduce the number of elements that an
annotator needs to examine.
Future work in this area involves modeling
the corpora with other probability distributions.
</bodyText>
<page confidence="0.991508">
152
</page>
<table confidence="0.9992735">
Anomaly Rank Corpus Errors System Error Unsure Corpus Error Rate
1-1000 63 28 9 69%
1001-2000 36 54 10 40%
2001-3000 18 70 12 20%
3001-4000 41 50 9 45%
Totals 158 202 40 1 44%
</table>
<tableCaption confidence="0.999941">
Table 1: Results of error detection experiments on the tagged portion of the Penn Treebank
</tableCaption>
<bodyText confidence="0.9999511">
The method is very sensitive to the effective-
ness of the probability model in modeling the
normal elements. Extensions to the probabil-
ity distributions presented here such as adding
information about endings of words or using
more features could increase the accuracy of the
probability distribution and the overall perfor-
mance of the anomaly detection system. Other
future work involves applying this method to
other marked corpora.
</bodyText>
<sectionHeader confidence="0.99808" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996512524590164">
Steve Abney, Robert E. Schapire, and Yoram
Singer. 1999. Boosting applied to tag-
ging and PP attachment. In Proceedings of
the Joint SIGDAT Conference on Empiri-
cal Methods in Natural Language Processing
Conference and Very Large Corpora.
V. Barnett and T. Lewis. 1994. Outliers in Sta-
tistical Data. John Wiley and Sons.
V. Barnett. 1979. Some outlier tests for multi-
variate samples. South African Statist, 13:29-
52.
Eric Brill and Jun Wu. 1998. Classifier com-
bination for improved lexical disambiguation.
In Proceedings of COLING-ACL.
Eric Brill. 1994. Some advances in
transformation-based part of speech tagging.
In Proceedings of the Twelfth National
Conference on Artificial Intelligence, pages
722-727.
D.E. Denning. 1987. An intrusion detection
model. IEEE Transactions on Software En-
gineering, SE-13:222-232.
Eleazar Eskin. 2000. Anomaly detection over
noisy data using learned probability distribu-
tions. In Proceedings of the Seventeenth In-
ternational Conference on Machine Learning
(ICML-2000) (to appear).
T. Lane and C. E. Brodley. 1997. Sequence
matching and learning in anomaly detection
for computer security. In AAAI Workshop:
Al Approaches to Fraud Detection and Risk
Management, pages 43-49. AAAI Press.
Mitchell Marcus, Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building
a large annotated corpus of english: The
Penn Treebank. Computational Linguistics,
19(2):313-330.
Tom Mitchell. 1997. Machine Learning. Mc-
Graw Hill.
Fernando Pereira and Yoram Singer. 1999.
An efficient extension to mixture techniques
for prediction and decision trees. Machine
Learning, 36(3):183-199.
Adwait Ratnaparkhi. 1996. A maximum en-
tropy model part-of-speech tagger. In Pro-
ceedings of the Empirical Methods in Natural
Language Processing Conference.
Yoram Singer. 1997. Adaptive mixtures of
probalistic transducers. Neural Computation,
9(8):1711-1733.
Christina Warrender, Stephanie Forrest, and
Barak Pearlmutter. 1999. Detecting intru-
sions using system calls: alternative data
models. In 1999 IEEE Symposium on Secu-
rity and Privacy, pages 133-145. IEEE Com-
puter Society.
Ralph Weischedel, Marie Meteer, Richard
Schwartz, Lance Ramshaw, and Jeff Pal-
mucci. 1993. Coping with ambiguity and un-
known words through probabilistic models.
Computational Linguistics, 19(2):359-382.
</reference>
<page confidence="0.999231">
153
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.772662">
<title confidence="0.999973">Detecting Errors within a Corpus using Anomaly Detection</title>
<author confidence="0.998827">Eleazar Eskin</author>
<affiliation confidence="0.999965">Department of Computer Science Columbia University</affiliation>
<email confidence="0.999442">eeskin@cs.columbia.edu</email>
<abstract confidence="0.980805">present method for automatically detecting errors in a manually marked corpus using anomaly detection. Anomaly detection is a method for determining which elements of a large data set do not conform to the whole. This method fits a probability distribution over the data and applies a statistical test to detect anomalous elements. In the corpus error detection problem, anomalous elements are typically marking errors. We present the results of applying this method to the tagged portion of the Penn Treebank corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steve Abney</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Boosting applied to tagging and PP attachment.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing Conference and Very Large Corpora.</booktitle>
<contexts>
<context position="2621" citStr="Abney et al. (1999)" startWordPosition="421" endWordPosition="424">experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach. Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting and dealing with outliers in univariate data, multivari</context>
</contexts>
<marker>Abney, Schapire, Singer, 1999</marker>
<rawString>Steve Abney, Robert E. Schapire, and Yoram Singer. 1999. Boosting applied to tagging and PP attachment. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing Conference and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Barnett</author>
<author>T Lewis</author>
</authors>
<title>Outliers in Statistical Data.</title>
<date>1994</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="3534" citStr="Barnett and Lewis (1994)" startWordPosition="568" endWordPosition="571">tor differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting and dealing with outliers in univariate data, multivariate data, and structured data where the probability distribution over the data is given a priori. Statistics gives a set of discordancy tests which can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is 148 given in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and S</context>
<context position="5159" citStr="Barnett and Lewis, 1994" startWordPosition="828" endWordPosition="831">tecting anomalies for two main reasons. One, we are interested in modeling the data and the anomalies can contaminate the model. And two, the anomalies themselves can be of interest as they may show rarely occurring events. For the purposes of this work, we are most interested in identifying mistagged elements, i.e. the second case. In order to motivate a method for detecting anomalies, we must first make assumptions about how the anomalies occur in the data. We use a &amp;quot;mixture model&amp;quot; for explaining the presence of anomalies, one of several popular models in statistics for explaining outliers (Barnett and Lewis, 1994). In the mixture model, there are two probability distributions which generate the data. An element xi is either generated from the majority distribution or with (small) probability A from an alternate (anomalous) distribution. Our distribution for the data, D, is then: D (1 — A)M + AA (1) where M is the majority distribution, and A is the anomalous distribution. The mixture framework for explaining anomalies is independent of the properties of the distributions M and A. In other words, no assumptions about the nature of the probability distributions are necessary. The specific probability dis</context>
</contexts>
<marker>Barnett, Lewis, 1994</marker>
<rawString>V. Barnett and T. Lewis. 1994. Outliers in Statistical Data. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Barnett</author>
</authors>
<title>Some outlier tests for multivariate samples.</title>
<date>1979</date>
<journal>South African Statist,</journal>
<pages>13--29</pages>
<contexts>
<context position="7593" citStr="Barnett, 1979" startWordPosition="1253" endWordPosition="1254">sure the likelihood of the distribution under both cases to make this determination. The likelihood, L, of distribution D with probability function P over elements xi,...,xN is defined as follows: L(D) = PD(xi) — A)IM II Pm(xi)) PA(Xj)) xiEM x1•EA Since the product of small numbers is difficult to compute, we instead compute the log likelihood, LL. The log likelihood for our case is: LL(D) =I* log(1 — A) + E log(Pm(xi)) x,EM +IAI log A + E log(PA (xi)) (3) x EA (2) 149 In order to determine which elements are anomalies, we use a general principal for determining outliers in multivariate data (Barnett, 1979). We measure how likely each element xi is an outlier by comparing the difference between the log likelihood of the distribution if the element is removed from the majority distribution and included in the anomalous distribution. If this difference is sufficiently large, we declare the element an anomaly. Specifically what this difference should be depends on the probability distributions and prior knowledge of the problem such as the rate of the anomalies, A. 3 Methodology 3.1 Corpus The corpus we use is the Penn Treebank tagged corpus. The corpus contains approximately 1.25 million manually </context>
</contexts>
<marker>Barnett, 1979</marker>
<rawString>V. Barnett. 1979. Some outlier tests for multivariate samples. South African Statist, 13:29-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Jun Wu</author>
</authors>
<title>Classifier combination for improved lexical disambiguation.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL.</booktitle>
<contexts>
<context position="2541" citStr="Brill and Wu, 1998" startWordPosition="408" endWordPosition="411">speech tagged portion of the Penn Treebank corpus (Marcus et al., 1993). In one experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach. Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This</context>
</contexts>
<marker>Brill, Wu, 1998</marker>
<rawString>Eric Brill and Jun Wu. 1998. Classifier combination for improved lexical disambiguation. In Proceedings of COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some advances in transformation-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence,</booktitle>
<pages>722--727</pages>
<contexts>
<context position="2520" citStr="Brill, 1994" startWordPosition="406" endWordPosition="407"> the part of speech tagged portion of the Penn Treebank corpus (Marcus et al., 1993). In one experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach. Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the st</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Eric Brill. 1994. Some advances in transformation-based part of speech tagging. In Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 722-727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Denning</author>
</authors>
<title>An intrusion detection model.</title>
<date>1987</date>
<journal>IEEE Transactions on Software Engineering,</journal>
<pages>13--222</pages>
<contexts>
<context position="3663" citStr="Denning, 1987" startWordPosition="588" endWordPosition="589"> anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting and dealing with outliers in univariate data, multivariate data, and structured data where the probability distribution over the data is given a priori. Statistics gives a set of discordancy tests which can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is 148 given in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 An</context>
</contexts>
<marker>Denning, 1987</marker>
<rawString>D.E. Denning. 1987. An intrusion detection model. IEEE Transactions on Software Engineering, SE-13:222-232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleazar Eskin</author>
</authors>
<title>Anomaly detection over noisy data using learned probability distributions.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000)</booktitle>
<note>(to appear).</note>
<contexts>
<context position="3981" citStr="Eskin, 2000" startWordPosition="641" endWordPosition="642">can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is 148 given in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want to construct an automatic method for detecting anomalies. We are interested in detecting anomalies for two main reasons. One, w</context>
</contexts>
<marker>Eskin, 2000</marker>
<rawString>Eleazar Eskin. 2000. Anomaly detection over noisy data using learned probability distributions. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000) (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Lane</author>
<author>C E Brodley</author>
</authors>
<title>Sequence matching and learning in anomaly detection for computer security.</title>
<date>1997</date>
<booktitle>In AAAI Workshop: Al Approaches to Fraud Detection and Risk Management,</booktitle>
<pages>43--49</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="3830" citStr="Lane and Brodley, 1997" startWordPosition="613" endWordPosition="616">ta, multivariate data, and structured data where the probability distribution over the data is given a priori. Statistics gives a set of discordancy tests which can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is 148 given in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probabilit</context>
</contexts>
<marker>Lane, Brodley, 1997</marker>
<rawString>T. Lane and C. E. Brodley. 1997. Sequence matching and learning in anomaly detection for computer security. In AAAI Workshop: Al Approaches to Fraud Detection and Risk Management, pages 43-49. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<pages>19--2</pages>
<contexts>
<context position="1993" citStr="Marcus et al., 1993" startWordPosition="323" endWordPosition="326"> markings of the corpus. To detect the anomalies, we first compute a probability distribution over the entire corpus. Then we apply a statistical test which identifies which elements are anomalies. In this case the anomalies are the elements with very low likelihood. These elements are marked as errors and are thrown out of the corpus. The model is recomputed on the remaining elements. At conclusion, we are left with two data sets: one the normal elements and the second the detected anomalous elements. We evaluate this method over the part of speech tagged portion of the Penn Treebank corpus (Marcus et al., 1993). In one experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Mitchell</author>
</authors>
<date>1997</date>
<booktitle>Machine Learning.</booktitle>
<publisher>McGraw Hill.</publisher>
<contexts>
<context position="4257" citStr="Mitchell, 1997" startWordPosition="680" endWordPosition="681">ction (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want to construct an automatic method for detecting anomalies. We are interested in detecting anomalies for two main reasons. One, we are interested in modeling the data and the anomalies can contaminate the model. And two, the anomalies themselves can be of interest as they may show rarely occurring events. For the purposes of this work, we are most interested in identifying mistagged elements, i.e. the </context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Tom Mitchell. 1997. Machine Learning. McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yoram Singer</author>
</authors>
<title>An efficient extension to mixture techniques for prediction and decision trees.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>36--3</pages>
<contexts>
<context position="4146" citStr="Pereira and Singer, 1999" startWordPosition="661" endWordPosition="664"> Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want to construct an automatic method for detecting anomalies. We are interested in detecting anomalies for two main reasons. One, we are interested in modeling the data and the anomalies can contaminate the model. And two, the anomalies themselves can be of interest as they may show rarely occur</context>
</contexts>
<marker>Pereira, Singer, 1999</marker>
<rawString>Fernando Pereira and Yoram Singer. 1999. An efficient extension to mixture techniques for prediction and decision trees. Machine Learning, 36(3):183-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model part-of-speech tagger.</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference.</booktitle>
<contexts>
<context position="2691" citStr="Ratnaparkhi (1996)" startWordPosition="434" endWordPosition="435">5 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach. Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting and dealing with outliers in univariate data, multivariate data, and structured data where the probability distribution over </context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model part-of-speech tagger. In Proceedings of the Empirical Methods in Natural Language Processing Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoram Singer</author>
</authors>
<title>Adaptive mixtures of probalistic transducers.</title>
<date>1997</date>
<journal>Neural Computation,</journal>
<pages>9--8</pages>
<contexts>
<context position="4119" citStr="Singer, 1997" startWordPosition="659" endWordPosition="660">in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want to construct an automatic method for detecting anomalies. We are interested in detecting anomalies for two main reasons. One, we are interested in modeling the data and the anomalies can contaminate the model. And two, the anomalies themselves can be of interest as</context>
</contexts>
<marker>Singer, 1997</marker>
<rawString>Yoram Singer. 1997. Adaptive mixtures of probalistic transducers. Neural Computation, 9(8):1711-1733.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Warrender</author>
<author>Stephanie Forrest</author>
<author>Barak Pearlmutter</author>
</authors>
<title>Detecting intrusions using system calls: alternative data models.</title>
<date>1999</date>
<booktitle>In 1999 IEEE Symposium on Security and Privacy,</booktitle>
<pages>133--145</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="3855" citStr="Warrender et al., 1999" startWordPosition="617" endWordPosition="620">nd structured data where the probability distribution over the data is given a priori. Statistics gives a set of discordancy tests which can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is 148 given in Barnett and Lewis (1994). Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000). The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997). 2 Anomaly Detection More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want t</context>
</contexts>
<marker>Warrender, Forrest, Pearlmutter, 1999</marker>
<rawString>Christina Warrender, Stephanie Forrest, and Barak Pearlmutter. 1999. Detecting intrusions using system calls: alternative data models. In 1999 IEEE Symposium on Security and Privacy, pages 133-145. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Lance Ramshaw</author>
<author>Jeff Palmucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="2567" citStr="Weischedel et al. (1993)" startWordPosition="412" endWordPosition="415"> of the Penn Treebank corpus (Marcus et al., 1993). In one experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that 69% of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which 44% are tagging errors. 1.1 Related Work The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach. Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data. Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting a</context>
</contexts>
<marker>Weischedel, Meteer, Schwartz, Ramshaw, Palmucci, 1993</marker>
<rawString>Ralph Weischedel, Marie Meteer, Richard Schwartz, Lance Ramshaw, and Jeff Palmucci. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19(2):359-382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>