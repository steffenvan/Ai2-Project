<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026195">
<title confidence="0.999177">
A NLG-based Application for Walking Directions
</title>
<author confidence="0.985426">
Michael Roth and Anette Frank
</author>
<affiliation confidence="0.9892795">
Department of Computational Linguistics
Heidelberg University
</affiliation>
<address confidence="0.844281">
69120 Heidelberg, Germany
</address>
<email confidence="0.997116">
{mroth,frank}@cl.uni-heidelberg.de
</email>
<sectionHeader confidence="0.995606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999955142857143">
This work describes an online application
that uses Natural Language Generation
(NLG) methods to generate walking di-
rections in combination with dynamic 2D
visualisation. We make use of third party
resources, which provide for a given
query (geographic) routes and landmarks
along the way. We present a statistical
model that can be used for generating
natural language directions. This model
is trained on a corpus of walking direc-
tions annotated with POS, grammatical
information, frame-semantics and mark-
up for temporal structure.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999986358974359">
The purpose of route directions is to inform a
person, who is typically not familiar with his cur-
rent environment, of how to get to a designated
goal. Generating such directions poses difficul-
ties on various conceptual levels such as the
planning of the route, the selection of landmarks
along the way (i.e. easily recognizable buildings
or structures) and generating the actual instruc-
tions of how to navigate along the route using the
selected landmarks as reference points.
As pointed out by Tom &amp; Denis (2003), the
use of landmarks in route directions allows for
more effective way-finding than directions rely-
ing solely on street names and distance measures.
An experiment performed in Tom &amp; Denis’ work
also showed that people tend to use landmarks
rather than street names when producing route
directions themselves.
The application presented here is an early re-
search prototype that takes a data-driven genera-
tion approach, making use of annotated corpora
collected in a way-finding study. In contrast to
previously developed NLG systems in this area
(e.g. Dale et. al, 2002), one of our key features is
the integration of a number of online resources to
compute routes and to find salient landmarks.
The information acquired from these resources
can then be used to generate natural directions
that are both easier to memorise and easier to
follow than directions given by a classic route
planner or navigation system.
The remainder of this paper is structured as
follows: In Section 2 we introduce our system
and describe the resources and their integration
in the architecture. Section 3 describes our cor-
pus-based generation approach, with Section 4
outlining our integration of text generation and
visualisation. Finally, Section 5 gives a short
conclusion and discusses future work.
</bodyText>
<sectionHeader confidence="0.91355" genericHeader="method">
2 Combining Resources
</sectionHeader>
<bodyText confidence="0.999663285714286">
The route planner used in our system is provided
by the Google Maps API1. Given a route com-
puted in Google Maps, our system queries a
number of online resources to determine land-
marks that are adjacent to this route. At the time
of writing, these resources are: OpenStreetMaps2
for public transportation, the Wikipedia WikiPro-
ject Geographical coordinates3 for salient build-
ings, statues and other objects, Google AJAX
Search API4 for “yellow pages landmarks” such
as hotels and restaurants, and Wikimapia 5 for
squares and other prominent places.
All of the above mentioned resources can be
queried for landmarks either by a single GPS
</bodyText>
<footnote confidence="0.998999666666667">
1 http://code.google.com/apis/maps/
2 http://www.openstreetmap.org
3 http://en.wikipedia.org/wiki/Wikipedia:WikiProject
Geographical_coordinates
4 http://code.google.com/apis/ajaxsearch
5 http://www.wikimapia.org
</footnote>
<page confidence="0.997439">
37
</page>
<note confidence="0.9437455">
Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 37–40,
Suntec, Singapore, 3 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999375">
coordinate (using the LocalSearch method in
Google AJAX Search and web tools in Wikipe-
dia) or an area of GPS coordinates (using URL
based queries in Wikimapia and OpenStreet-
Maps). The following list describes the data for-
mats returned by the respective services and how
they were integrated:
</bodyText>
<listItem confidence="0.836218">
• Wikimapia and OpenStreetMaps – Both
resources return landmarks in the queried
</listItem>
<bodyText confidence="0.706931571428571">
area as an XML file that specifies GPS
coordinates and additional information.
The XML files are parsed using a Java-
Script implementation of a SAX parser.
The coordinates and names of landmarks
are then used to add objects within the
Google Maps API.
</bodyText>
<listItem confidence="0.9739109375">
• Wikipedia – In order to integrate land-
marks from Wikipedia, we make use of a
community created tool called search-a-
6place , which returns landmarks from
Wikipedia in a given radius of a GPS
coordinate. The results are returned in an
HTML table that is converted to an XML
file similar to the output of Wikimapia.
Both the query and the conversion are im-
plemented in a Yahoo! Pipe7 that can be
accessed in JavaScript via its URL.
• Google AJAX Search – The results re-
turned by the Google AJAX Search API
are JavaScript objects that can be directly
inserted in the visualisation using the
Google Maps API.
</listItem>
<sectionHeader confidence="0.866762" genericHeader="method">
3 Using Corpora for Generation
</sectionHeader>
<bodyText confidence="0.999931642857143">
A data-driven generation approach achieves a
number of advantages over traditional ap-
proaches for our scenario. First of all, corpus
data can be used to learn directly how certain
events are typically expressed in natural lan-
guage, thus avoiding the need of manually speci-
fying linguistic realisations. Secondly, variations
of discourse structures found in naturally given
directions can be learned and reproduced to
avoid monotonous descriptions in the generation
part. Last but not least, a corpus with good cov-
erage can help us determine the correct selection
restrictions on verbs and nouns occurring in di-
rections. The price to pay for these advantages is
</bodyText>
<footnote confidence="0.992216">
6 http://toolserver.org/~kolossos/wp-
world/umkreis.php
7 http://pipes.yahoo.com/pipes/pipe.info?_id=BBI0x8
G73RGbWzKnBR50VA
</footnote>
<bodyText confidence="0.999791166666667">
the cost of annotation; however we believe that
this is a reasonable trade-off, in view of the fact
that a small annotated corpus and reasonable
generalizations in data modelling will likely
yield enough information for the intended navi-
gation applications.
</bodyText>
<subsectionHeader confidence="0.995964">
3.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.99974775">
We currently use the data set from (Marciniak &amp;
Strube, 2005) to learn linguistic expressions for
our generation approach. The data is annotated
on the following levels:
</bodyText>
<listItem confidence="0.996130125">
• Token and POS level
• Grammatical level (including annotations
of main verbs, arguments and connectives)
• Frame-semantics level (including semantic
roles and frame annotations in the sense of
(Fillmore, 1977))
• Temporal level (including temporal rela-
tions between discourse units)
</listItem>
<subsectionHeader confidence="0.99772">
3.2 Our Generation Approach
</subsectionHeader>
<bodyText confidence="0.999758384615385">
At the time of writing, our system only makes
use of the first three annotation levels. The lexi-
cal selection is inspired by the work of Ratna-
parkhi (2000) with the overall process designed
as follows: given a certain situation on a route,
our generation component receives the respective
frame name and a list of semantic role filling
landmarks as input (cf. Section 4). The genera-
tion component then determines a list of poten-
tial lexical items to express this frame using the
relative frequencies of verbs annotated as evok-
ing the particular frame with the respective set of
semantic roles (examples in Table 1).
</bodyText>
<table confidence="0.997662285714286">
SELF_MOTION
PATH 17% walk, 13% follow, 10%
cross, 7% continue, 6% take, ...
GOAL 18% get, 18% enter, 9% con-
tinue, 7% head, 5% reach, ...
SOURCE 14% leave, 14% start, ...
DIRECTION 25% continue, 13% make,
13% walk, 6% go, 3% take, ...
DISTANCE 15% continue, 8% go, ...
PATH + GOAL 29% continue, 14% take, ...
DISTANCE + 100% walk
GOAL
DIRECTION + 23% continue, 23% walk,
PATH 8% take, 6% turn, 6% face, ...
</table>
<tableCaption confidence="0.997559">
Table 1: Probabilities of lexical items for the frame
SELF_MOTION and different frame elements
</tableCaption>
<page confidence="0.999115">
38
</page>
<bodyText confidence="0.9975168">
For frame-evoking elements and each associated
semantic role-filler in the situation, the gram-
matical knowledge learned from the annotation
level determines how these parts can be put to-
gether in order to generate a full sentence (cf.
</bodyText>
<tableCaption confidence="0.658698">
Table 2).
</tableCaption>
<table confidence="0.996629">
SELF_MOTION
walk + walk 4 walk + PP
[building PATH] PP 4 along + NPNP 4 the + building
get + get 4 get + to + NP
[building GOAL] NP 4 the + building
take + take 4 take + NP
[left DIRECTION] NP 4 a + left
</table>
<tableCaption confidence="0.997388">
Table 2: Examples of phrase structures for the frame
SELF_MOTION and different semantic role fillers
</tableCaption>
<sectionHeader confidence="0.865155" genericHeader="method">
4 Combining Text and Visualisation
</sectionHeader>
<bodyText confidence="0.9998305">
As mentioned in the previous section, our model
is able to compute single instructions at crucial
points of a route. At the time of writing the ac-
tual integration of this component consists of a
set of hardcoded rules that map route segments to
frames, and landmarks within the segment to role
fillers of the considered frame. The rules are
specified as follows:
</bodyText>
<listItem confidence="0.9954238">
• A turning point given by the Google Maps
API is mapped to the SELF_MOTION frame
with the actual direction as the semantic
role direction. If there is a landmark adja-
cent to the turning point, it is added to the
frame as the role filler of the role source.
• If a landmark is adjacent or within the
starting point of the route, it will be
mapped to the SELF_MOTION frame with
the landmark filling the semantic role
source.
• If a landmark is adjacent or within the
goal of a route, it will be mapped to the
SELF_MOTION frame with the landmark
filling the semantic role goal.
• If a landmark is adjacent to a route or a
route segment is within a landmark, the
respective segment will be mapped to the
SELF_MOTION frame with the landmark
filling the semantic role path.
</listItem>
<sectionHeader confidence="0.93918" genericHeader="method">
5 Conclusions and Outlook
</sectionHeader>
<bodyText confidence="0.999980307692308">
We have presented the technical details of an
early research prototype that uses NLG methods
to generate walking directions for routes com-
puted by an online route planner. We outlined
the advantages of a data-driven generation ap-
proach over traditional rule-based approaches
and implemented a first-version application,
which can be used as an initial prototype exten-
sible for further research and development.
Our next goal in developing this system is to
enhance the generation component with an inte-
grated model based on machine learning tech-
niques that will also account for discourse level
phenomena typically found in natural language
directions. We further intend to replace the cur-
rent hard-coded set of mapping rules with an
automatically induced mapping that aligns
physical routes and landmarks with the semantic
representations. The application is planned to be
used in web experiments to acquire further data
for alignment and to study specific effects in the
generation of walking instructions in a multimo-
dal setting.
The prototype system described above will be
made publicly available at the time of publica-
tion.
</bodyText>
<sectionHeader confidence="0.994727" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99970275">
This work is supported by the DFG-financed in-
novation fund FRONTIER as part of the Excel-
lence Initiative at Heidelberg University (ZUK
49/1).
</bodyText>
<sectionHeader confidence="0.998535" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.9916701">
Dale, R., Geldof, S., &amp; Prost, J.-P. (2002). Generating
more natural route descriptions. Proceedings of the
2002 Australasian Natural Language Processing
Workshop. Canberra, Australia.
Fillmore, C. (1977). The need for a frame semantics
in linguistics. Methods in Linguistics , 12, 2-29.
Marciniak, T., &amp; Strube, M. (2005). Using an
annotated corpus as a knowledge source for
language generation. Proceedings of the Workshop
on Using Corpora for Natural Language
Generation, (pp. 19-24). Birmingham, UK.
Ratnaparkhi, A. (2000). Trainable Methods for
Surface Natural Language Generation. Proceedings
of the 6th Applied Natural Language Processing
Conference. Seattle, WA, USA.
Tom, A., &amp; Denis, M. (2003). Referring to landmark
or street information in route directions: What
difference does it make? In W. Kuhn, M. Worboys,
&amp; S. Timpf (Eds.), Spatial Information Theory (pp.
384-397). Berlin: Springer.
</reference>
<page confidence="0.999468">
39
</page>
<figureCaption confidence="0.993915">
Figure 1: Visualised route from Rohrbacher Straße 6 to Hauptstrasse 22, Heidelberg. Left: GoogleMaps
directions; Right: GoogleMaps visualisation enriched with landmarks and directions generated by our system
(The directions were manually inserted here as they are actually presented step-by-step following the route)
</figureCaption>
<sectionHeader confidence="0.505848" genericHeader="method">
Script Outline
</sectionHeader>
<bodyText confidence="0.9999876">
Our demonstration is outlined as follows: At first
we will have a look at the textual outputs of
standard route planners and discuss at which
points the respective instructions could be im-
proved in order to be better understandable or
easier to follow. We will then give an overview
of different types of landmarks and argue how
their integration into route directions is a valu-
able step towards better and more natural instruc-
tions.
Following the motivation of our work, we will
present different online resources that provide
landmarks of various sorts. We will look at the
information provided by these resources, exam-
ine the respective input and output formats, and
state how the formats are integrated into a com-
mon data representation in order to access the
information within the presented application.
Next, we will give a brief overview of the cor-
pus in use and point out which kinds of annota-
tions were available to train the statistical gen-
eration component. We will discuss which other
annotation levels would be useful in this scenario
and which disadvantages we see in the current
corpus. Subsequently we outline our plans to
acquire further data by collecting directions for
routes computed via Google Maps, which would
allow an easier alignment between the instruc-
tions and routes.
Finally, we conclude the demonstration with a
presentation of our system in action. During the
presentation, the audience will be given the pos-
sibility to ask questions and propose routes for
which we show our system’s computation and
output (cf. Figure 1).
</bodyText>
<subsectionHeader confidence="0.805662">
System Requirements
</subsectionHeader>
<bodyText confidence="0.999974818181818">
The system is currently developed as a web-
based application that can be viewed with any
JavaScript supporting browser. A mid-end CPU
is required to view the dynamic route presenta-
tion given by the application. Depending on the
presentation mode, we can bring our own laptop
so that the only requirements to the local organ-
isers would be a stable internet connection (ac-
cess to the resources mentioned in the system
description is required) and presentation hard-
ware (projector or sufficiently large display).
</bodyText>
<page confidence="0.997851">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.947799">
<title confidence="0.999968">A NLG-based Application for Walking Directions</title>
<author confidence="0.999972">Michael Roth</author>
<author confidence="0.999972">Anette Frank</author>
<affiliation confidence="0.999605">Department of Computational Linguistics Heidelberg University</affiliation>
<address confidence="0.999975">69120 Heidelberg, Germany</address>
<email confidence="0.999374">mroth@cl.uni-heidelberg.de</email>
<email confidence="0.999374">frank@cl.uni-heidelberg.de</email>
<abstract confidence="0.996466933333333">This work describes an online application that uses Natural Language Generation (NLG) methods to generate walking directions in combination with dynamic 2D visualisation. We make use of third party resources, which provide for a given query (geographic) routes and landmarks along the way. We present a statistical model that can be used for generating natural language directions. This model is trained on a corpus of walking directions annotated with POS, grammatical information, frame-semantics and markup for temporal structure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>S Geldof</author>
<author>J-P Prost</author>
</authors>
<title>Generating more natural route descriptions.</title>
<date>2002</date>
<booktitle>Proceedings of the 2002 Australasian Natural Language Processing Workshop.</booktitle>
<location>Canberra, Australia.</location>
<marker>Dale, Geldof, Prost, 2002</marker>
<rawString>Dale, R., Geldof, S., &amp; Prost, J.-P. (2002). Generating more natural route descriptions. Proceedings of the 2002 Australasian Natural Language Processing Workshop. Canberra, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>The need for a frame semantics in linguistics.</title>
<date>1977</date>
<booktitle>Methods in Linguistics ,</booktitle>
<volume>12</volume>
<pages>2--29</pages>
<contexts>
<context position="6261" citStr="Fillmore, 1977" startWordPosition="958" endWordPosition="959">hat this is a reasonable trade-off, in view of the fact that a small annotated corpus and reasonable generalizations in data modelling will likely yield enough information for the intended navigation applications. 3.1 Data Collection We currently use the data set from (Marciniak &amp; Strube, 2005) to learn linguistic expressions for our generation approach. The data is annotated on the following levels: • Token and POS level • Grammatical level (including annotations of main verbs, arguments and connectives) • Frame-semantics level (including semantic roles and frame annotations in the sense of (Fillmore, 1977)) • Temporal level (including temporal relations between discourse units) 3.2 Our Generation Approach At the time of writing, our system only makes use of the first three annotation levels. The lexical selection is inspired by the work of Ratnaparkhi (2000) with the overall process designed as follows: given a certain situation on a route, our generation component receives the respective frame name and a list of semantic role filling landmarks as input (cf. Section 4). The generation component then determines a list of potential lexical items to express this frame using the relative frequencie</context>
</contexts>
<marker>Fillmore, 1977</marker>
<rawString>Fillmore, C. (1977). The need for a frame semantics in linguistics. Methods in Linguistics , 12, 2-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Marciniak</author>
<author>M Strube</author>
</authors>
<title>Using an annotated corpus as a knowledge source for language generation.</title>
<date>2005</date>
<booktitle>Proceedings of the Workshop on Using Corpora for Natural Language Generation,</booktitle>
<pages>(pp.</pages>
<location>Birmingham, UK.</location>
<contexts>
<context position="5941" citStr="Marciniak &amp; Strube, 2005" startWordPosition="909" endWordPosition="912">s with good coverage can help us determine the correct selection restrictions on verbs and nouns occurring in directions. The price to pay for these advantages is 6 http://toolserver.org/~kolossos/wpworld/umkreis.php 7 http://pipes.yahoo.com/pipes/pipe.info?_id=BBI0x8 G73RGbWzKnBR50VA the cost of annotation; however we believe that this is a reasonable trade-off, in view of the fact that a small annotated corpus and reasonable generalizations in data modelling will likely yield enough information for the intended navigation applications. 3.1 Data Collection We currently use the data set from (Marciniak &amp; Strube, 2005) to learn linguistic expressions for our generation approach. The data is annotated on the following levels: • Token and POS level • Grammatical level (including annotations of main verbs, arguments and connectives) • Frame-semantics level (including semantic roles and frame annotations in the sense of (Fillmore, 1977)) • Temporal level (including temporal relations between discourse units) 3.2 Our Generation Approach At the time of writing, our system only makes use of the first three annotation levels. The lexical selection is inspired by the work of Ratnaparkhi (2000) with the overall proce</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>Marciniak, T., &amp; Strube, M. (2005). Using an annotated corpus as a knowledge source for language generation. Proceedings of the Workshop on Using Corpora for Natural Language Generation, (pp. 19-24). Birmingham, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Trainable Methods for Surface Natural Language Generation.</title>
<date>2000</date>
<booktitle>Proceedings of the 6th Applied Natural Language Processing Conference.</booktitle>
<location>Seattle, WA, USA.</location>
<contexts>
<context position="6518" citStr="Ratnaparkhi (2000)" startWordPosition="1000" endWordPosition="1002"> data set from (Marciniak &amp; Strube, 2005) to learn linguistic expressions for our generation approach. The data is annotated on the following levels: • Token and POS level • Grammatical level (including annotations of main verbs, arguments and connectives) • Frame-semantics level (including semantic roles and frame annotations in the sense of (Fillmore, 1977)) • Temporal level (including temporal relations between discourse units) 3.2 Our Generation Approach At the time of writing, our system only makes use of the first three annotation levels. The lexical selection is inspired by the work of Ratnaparkhi (2000) with the overall process designed as follows: given a certain situation on a route, our generation component receives the respective frame name and a list of semantic role filling landmarks as input (cf. Section 4). The generation component then determines a list of potential lexical items to express this frame using the relative frequencies of verbs annotated as evoking the particular frame with the respective set of semantic roles (examples in Table 1). SELF_MOTION PATH 17% walk, 13% follow, 10% cross, 7% continue, 6% take, ... GOAL 18% get, 18% enter, 9% continue, 7% head, 5% reach, ... SO</context>
</contexts>
<marker>Ratnaparkhi, 2000</marker>
<rawString>Ratnaparkhi, A. (2000). Trainable Methods for Surface Natural Language Generation. Proceedings of the 6th Applied Natural Language Processing Conference. Seattle, WA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tom</author>
<author>M Denis</author>
</authors>
<title>Referring to landmark or street information in route directions: What difference does it make? In</title>
<date>2003</date>
<pages>384--397</pages>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<contexts>
<context position="1271" citStr="Tom &amp; Denis (2003)" startWordPosition="187" endWordPosition="190">ted with POS, grammatical information, frame-semantics and markup for temporal structure. 1 Introduction The purpose of route directions is to inform a person, who is typically not familiar with his current environment, of how to get to a designated goal. Generating such directions poses difficulties on various conceptual levels such as the planning of the route, the selection of landmarks along the way (i.e. easily recognizable buildings or structures) and generating the actual instructions of how to navigate along the route using the selected landmarks as reference points. As pointed out by Tom &amp; Denis (2003), the use of landmarks in route directions allows for more effective way-finding than directions relying solely on street names and distance measures. An experiment performed in Tom &amp; Denis’ work also showed that people tend to use landmarks rather than street names when producing route directions themselves. The application presented here is an early research prototype that takes a data-driven generation approach, making use of annotated corpora collected in a way-finding study. In contrast to previously developed NLG systems in this area (e.g. Dale et. al, 2002), one of our key features is t</context>
</contexts>
<marker>Tom, Denis, 2003</marker>
<rawString>Tom, A., &amp; Denis, M. (2003). Referring to landmark or street information in route directions: What difference does it make? In W. Kuhn, M. Worboys, &amp; S. Timpf (Eds.), Spatial Information Theory (pp. 384-397). Berlin: Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>