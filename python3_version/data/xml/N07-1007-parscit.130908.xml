<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001224">
<title confidence="0.979962">
Generating Case Markers in Machine Translation
</title>
<author confidence="0.979586">
Kristina Toutanova Hisami Suzuki
</author>
<affiliation confidence="0.889924">
Microsoft Research
One Microsoft Way, Redmond WA 98052 USA
</affiliation>
<email confidence="0.983352">
{hisamis,kristout}@microsoft.com
</email>
<sectionHeader confidence="0.993531" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999921294117647">
We study the use of rich syntax-based
statistical models for generating gram-
matical case for the purpose of machine
translation from a language which does
not indicate case explicitly (English) to a
language with a rich system of surface
case markers (Japanese). We propose an
extension of n-best re-ranking as a
method of integrating such models into a
statistical MT system and show that this
method substantially outperforms stan-
dard n-best re-ranking. Our best perform-
ing model achieves a statistically signifi-
cant improvement over the baseline MT
system according to the BLEU metric.
Human evaluation also confirms the re-
sults.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999828">
Generation of grammatical elements such as in-
flectional endings and case markers is an impor-
tant component technology for machine transla-
tion (MT). Statistical machine translation (SMT)
systems, however, have not yet successfully in-
corporated components that generate grammati-
cal elements in the target language. Most state-
of-the-art SMT systems treat grammatical ele-
ments in exactly the same way as content words,
and rely on general-purpose phrasal translations
and target language models to generate these ele-
ments (e.g., Och and Ney, 2002; Koehn et al.,
2003; Quirk et al., 2005; Chiang, 2005; Galley et
al., 2006). However, since these grammatical
elements in the target language often correspond
to long-range dependencies and/or do not have
any words corresponding in the source, they may
be difficult to model, and the output of an SMT
system is often ungrammatical.
For example, Figure 1 shows an output from
our baseline English-to-Japanese SMT system on
a sentence from a computer domain. The SMT
system, trained on this domain, produces a natu-
ral lexical translation for the English word patch
as correction program, and translates replace
</bodyText>
<page confidence="0.997407">
49
</page>
<bodyText confidence="0.999419333333333">
into passive voice, which is more appropriate in
Japanese.1 However, there is a problem in the
case marker assignment: the accusative marker
wo, which was output by the SMT system, is
completely inappropriate when the main verb is
passive. This type of mistake in case marker as-
signment is by no means isolated in our SMT
system: a manual analysis showed that 16 out of
100 translations had mistakes solely in the as-
signment of case markers. A better model of case
assignment could therefore improve the quality
of an SMT system significantly.
</bodyText>
<figure confidence="0.950166">
S: The patch replaces the .dll file.
O: .dll
shuusei puroguramu-wo .dll fairu-ga okikae-raremasu
correction program-ACC dll file-NOM replace-PASS
C: .dll
shuusei puroguramu-de .dll fairu-ga okikae-raremasu
correction program-with dll file-NOM replace-PASS
</figure>
<figureCaption confidence="0.999549">
Figure 1: Example of SMT (S: source; O: output of
MT; C: correct translation)
</figureCaption>
<bodyText confidence="0.999981318181818">
In this paper, we explore the use of a statisti-
cal model for case marker generation in English-
to-Japanese SMT. Though we focus on the gen-
eration of case markers in this paper, there are
many other surface grammatical phenomena that
can be modeled in a similar way, so any SMT
system dealing with morpho-syntactically diver-
gent language pairs may benefit from a similar
approach to modeling grammatical elements. Our
model uses a rich set of syntactic features of both
the source (English) and the target (Japanese)
sentences, using context which is broader than
that utilized by existing SMT systems. We show
that the use of such features results in very high
case assignment quality and also leads to a nota-
ble improvement in MT quality.
Previous work has discussed the building of
special-purpose classifiers which generate gram-
matical elements such as prepositions (Haji et al.
2002), determiners (Knight and Chander, 1994)
and case markers (Suzuki and Toutanova, 2006)
with an eye toward improving MT output. How-
</bodyText>
<footnote confidence="0.9202015">
1 There is a strong tendency to avoid transitive sentences
with an inanimate subject in Japanese.
</footnote>
<note confidence="0.8692525">
Proceedings of NAACL HLT 2007, pages 49–56,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999921190476191">
ever, these components have not actually been
integrated in an MT system. To our knowledge,
this is the first work to integrate a grammatical
element production model in an SMT system and
to evaluate its impact in the context of end-to-
end MT.
A common approach of integrating new mod-
els with a statistical MT system is to add them as
new feature functions which are used in decod-
ing or in models which re-rank n-best lists from
the MT system (Och et al., 2004). In this paper
we propose an extension of the n-best re-ranking
approach, where we expand n-best candidate lists
with multiple case assignment variations, and
define new feature functions on this expanded
candidate set. We show that expanding the n-best
lists significantly outperforms standard n-best re-
ranking. We also show that integrating our case
prediction model improves the quality of transla-
tion according to BLEU (Papineni et al., 2002)
and human evaluation.
</bodyText>
<sectionHeader confidence="0.97123" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999508">
In this section, we provide necessary background
of the current work.
</bodyText>
<subsectionHeader confidence="0.999579">
2.1 Task of case marker prediction
</subsectionHeader>
<bodyText confidence="0.958905777777778">
Our definition of the case marker prediction task
follows Suzuki and Toutanova (2006). That is,
we assume that we are given a source English
sentence, and its translation in Japanese which
does not include case markers. Our task is to pre-
dict all case markers in the Japanese sentence.
We determine the location of case marker in-
sertion using the notion of bunsetsu. A bunsetsu
consists of one content (head) word followed by
any number of function words. We can therefore
segment any sentence into a sequence of bun-
setsu by using a part-of-speech (POS) tagger.
Once a sentence is segmented into bunsetsu, it
is trivial to determine the location of case mark-
ers in a sentence: each bunsetsu can have at most
one case marker, and the position of the case
maker within a phrase is predictable, i.e., the
rightmost position before any punctuation marks.
The sentence in Figure 1 thus has the following
bunsetsu analysis (denoted by square brackets),
with the locations of potential case marker inser-
tion indicated by :
[&apos;correction&apos;&apos;program&apos;.dll
&apos;file&apos;&apos;replace-PASS&apos;
For each of these positions, our task is to predict
the case marker or to predict NONE, which means
that the phrase does not have a case marker.
</bodyText>
<table confidence="0.8484265">
case markers grammatical functions +wa
ga subject; object
wo object; path
no genitive; subject
ni dative object, location
kara source
to quotative, reciprocal, as
de location,instrument, cause
e goal, direction
made goal (up to, until)
yori source, comparison target
wa Topic
</table>
<tableCaption confidence="0.999949">
Table 1. Case markers to be predicted
</tableCaption>
<bodyText confidence="0.999903769230769">
The case markers we used for the prediction
task are the same as those defined in Suzuki and
Toutatnova (2006), and are summarized in Table
1: in addition to the case markers in a strict sense,
the topic marker wa is also included as well as
the combination of a case marker plus the topic
marker for the case markers with the column
+wa checked in the table. In total, there are 18
case markers to predict: ten simple case markers,
the topic marker wa, and seven case+wa combi-
nations. The case prediction task is therefore a
19-fold classification task: for each phrase, we
assign one of the 18 case markers or NONE.
</bodyText>
<subsectionHeader confidence="0.998844">
2.2 Treelet translation system
</subsectionHeader>
<bodyText confidence="0.999418052631579">
We constructed and evaluated our case predic-
tion model in the context of a treelet-based trans-
lation system, described in Quirk et al. (2005).2
In this approach, translation is guided by treelet
translation pairs, where a treelet is a connected
subgraph of a dependency tree.
A sentence is translated in the treelet system
as follows. The input sentence is first parsed into
a dependency structure, which is then partitioned
into treelets, assuming a uniform probability dis-
tribution over all partitions. Each source treelet is
then matched to a treelet translation pair, the col-
lection of which will form the target translation.
The target language treelets are then joined to
form a single tree, and the ordering of all the
nodes is determined, using the method described
in Quirk et al. (2005).
Translations are scored according to a linear
combination of feature functions:
</bodyText>
<equation confidence="0.887212">
(1)
j
</equation>
<footnote confidence="0.557332333333333">
2 Though this paper reports results in the context of a treelet
system, the model is also applicable to other syntax-based
or phrase-based SMT systems.
</footnote>
<equation confidence="0.9043655">
score t = ∑ λ f t
( ) j j ( )
</equation>
<page confidence="0.980426">
50
</page>
<figureCaption confidence="0.999914">
Figure 2. Aligned English-Japanese sentence pair
</figureCaption>
<bodyText confidence="0.999998657142857">
where j are the model parameters and fj(t) is the
value of the feature function j on the candidate t.
There are ten feature functions in the treelet sys-
tem, including log-probabilities according to in-
verted and direct channel models estimated by
relative frequency, lexical weighting channel
models following Vogel et al. (2003), a trigram
target language model, an order model, word
count, phrase count, average phrase size func-
tions, and whole-sentence IBM Model 1 log-
probabilities in both directions (Och et al. 2004).
The weights of these models are determined us-
ing the max-BLEU method described in Och
(2003). As we describe in Section 4, the case
prediction model is integrated into the system as
an additional feature function.
The treelet translation model is estimated us-
ing a parallel corpus. First, the corpus is word-
aligned using GIZA++ (Och and Ney, 2000);
then the source sentences are parsed into a de-
pendency structure, and the dependency is pro-
jected onto the target side following the heuris-
tics described in Quirk et al. (2005). Figure 2
shows an example of an aligned sentence pair: on
the source (English) side, POS tags and word
dependency structure are assigned (solid arcs);
the word alignments between English and Japa-
nese words are indicated by the dotted lines. On
the target (Japanese) side, projected word de-
pendencies (solid arcs) are available. Additional
annotations in Figure 2, namely the POS tags and
the bunsetsu dependency structure (bold arcs) on
the target side, are derived from the treelet sys-
tem to be used for building a case prediction
model, which we describe in Section 3.
</bodyText>
<subsectionHeader confidence="0.994492">
2.3 Data
</subsectionHeader>
<bodyText confidence="0.999938">
All experiments reported in this paper are run
using parallel data from a technical (computer)
domain. We used two main data sets: train-500K,
consisting of 500K sentence pairs which we used
for training the baseline treelet system as well as
the case prediction model, and a disjoint set of
three data sets, lambda-1K, dev-1K and test-2K,
which are used to integrate and evaluate the case
prediction model in an end-to-end MT scenario.
Some characteristics of these data sets are given
in Table 2. We will refer to this table as we de-
scribe our experiments in later sections.
</bodyText>
<table confidence="0.996090625">
data set # sent # of words
pairs (average sent length in words)
English Japanese
train-500K 500K 7,909,198 9,379,240
(15.81) (18.75)
lambda-1K 1,000 15,219(15.2) 20,660 (20.7)
dev-1K 1,000 15,397(15.4) 21,280 (21.3)
test-2K 2,000 30,198(15.1) 41,269 (20.6)
</table>
<tableCaption confidence="0.995786">
Table 2: Data set characteristics
</tableCaption>
<sectionHeader confidence="0.9739195" genericHeader="method">
3 Statistical Models for Case Prediction
in MT
</sectionHeader>
<subsectionHeader confidence="0.999641">
3.1 Case prediction model
</subsectionHeader>
<bodyText confidence="0.996251">
Our model of case marker prediction closely fol-
lows our previous work of case prediction in a
non-MT context (Suzuki and Toutanova, 2006).
The model is a multi-class log-linear (maximum
entropy) classifier using 19 classes (18 case
markers and NONE). It assigns a probability dis-
tribution over case marker assignments given a
source English sentence, all non-case marker
words of a candidate Japanese translation, and
additional annotation information. Let t denote a
Japanese translation, s a corresponding source
sentence, and A additional annotation informa-
tion such as alignment, dependency structure,
and POS tags (such as shown in Figure 2). Let
rest(t) denote the sequence of words in t exclud-
ing all case markers, and case(t) a case marking
assignment for all phrases in t. Our case marking
model estimates the probability of a case as-
signment given all other information:
Pcase (case (t)  |rest (t), s, A )
The probability of a complete case assignment is
a product over all phrases of the probability of
the case marker of the phrase given all context
features used by the model. Our model assumes
that the case markers in a sentence are independ-
ent of each other given the input features. This
independence assumption may seem strong, but
the results presented in our previous work (Su-
zuki and Toutanova, 2006) showed that a joint
model did not result in large improvements over
a local one in predicting case markers in a non-
MT context.
</bodyText>
<page confidence="0.990419">
51
</page>
<subsectionHeader confidence="0.999745">
3.2 Model features and feature selection
</subsectionHeader>
<bodyText confidence="0.999993094339623">
The features of our model are similar to the ones
described in Suzuki and Toutanova (2006). The
main difference is that in the current model we
applied a feature selection and induction algo-
rithm to determine the most useful features and
feature combinations. This is important for un-
derstanding what sources of information are im-
portant for predicting grammatical elements, but
are currently absent from SMT systems. We
used 490K sentence pairs for training the case
prediction model, which is a subset of the train-
500K set of Table 2. We divided the remaining
10K sentences for feature selection (5K-feat) and
for evaluating the case prediction models on ref-
erence translations (5K-test, discussed in Section
3.3). The paired data is annotated using the
treelet translation system: as shown in Figure 2,
we have source and target word dependency
structure, source language POS and word align-
ment directly from the aligned treelet structure.
Additionally, we used a POS tagger of Japanese
to assign POS to the target sentence as well as to
parse the sentence into bunsetsu (indicated by
brackets in Figure 2), using the method described
in Section 2.1. We then compute bunsetsu de-
pendency structure on the target side (indicated
by bold arcs in Figure 2) based on the word de-
pendency structure projected from English. We
apply this procedure to annotate a paired corpus
(in which case the Japanese sentence is a refer-
ence translation) as well as translations generated
by the SMT system (which may potentially be
ill-formed).
We derived a large set of possible features
from these annotations. The features are repre-
sented as feature templates, such as &amp;quot;Headword
POS=X&amp;quot;, which generate a set of binary features
corresponding to different instantiations of the
template, such as &amp;quot;Headword POS=NOUN&amp;quot;. We
applied an automatic feature selection and induc-
tion algorithm to the base set of templates.
The feature selection algorithm considers the
original templates as well as arbitrary (bigram
and trigram) conjunctions of these templates.
The algorithm performs forward stepwise feature
selection, choosing templates which result in the
highest increase in model accuracy on the 5K-
feat set mentioned above. The algorithm is simi-
lar to the one described in McCallum (2003).
The application of this feature selection pro-
cedure gave us 17 templates, some of which are
shown in Table 3, along with example instantia-
tions for the phrase headed by saabisu ‘service’
</bodyText>
<table confidence="0.992569625">
Features Example
Words in position –1 and +2 kono,moodo
Headword &amp; previous headword saabisu&amp;kono
Parent word kaishi
Aligned word service
Parent of word aligned to headword started
Next word POS NOUN
Next word &amp; next word POS seefu&amp;NN
Headword POS NOUN
Parent headword POS VN
Aligned to parent word POS &amp; next word VERB&amp;NN&amp;an
POS &amp; prev word POS d
Parent POS of word aligned to headword VERB
Aligned word POS &amp; headword POS &amp; NN&amp;NN&amp;ADN
prev word POS
POS of word aligned to headword NOUN
</table>
<tableCaption confidence="0.967733">
Table 3: Features for the case prediction model
</tableCaption>
<bodyText confidence="0.999984565217391">
from Figure 2. Conjunctions are indicated by &amp;.
Note that many features that refer to POS and
syntactic (parent) information are selected, on
both the target and source sides. We also note
that the context required by these features is
more extensive than what is usually available
during decoding in an SMT system due to a limit
imposed on the treelet or phrase size. For exam-
ple, our model uses word lemma and POS tags of
up to six words (previous word, next word, word
in position +2, head word, previous head word
and parent word), which covers more context
than the treelet system we used (the system im-
poses the treelet size limit of four words). This
means that the case model can make use of much
richer information from both the source and tar-
get than the baseline MT system. Furthermore,
our model makes better use of the context by
combining the contributions of multiple sources
of knowledge using a maximum entropy model,
rather than using the relative frequency estimates
with a very limited amount of smoothing, which
are used by most state-of-the art SMT systems.
</bodyText>
<subsectionHeader confidence="0.999059">
3.3 Performance on reference translations
</subsectionHeader>
<bodyText confidence="0.9999675">
Before discussing the integration of the case pre-
diction model with the MT system, we present an
evaluation of the model on the task of predicting
the case assignment of reference translations.
This performance constitutes an upper bound on
the model’s performance in MT, because in ref-
erence translations, the word choice and the word
order are perfect.
Table 4 summarizes the results of the refer-
ence experiments on the 5K-test set using two
metrics: accuracy, which denotes the percentage
of phrases for which the respective model
guessed the case marker correctly, and BLEU
score against the reference translation. For com-
</bodyText>
<page confidence="0.983619">
52
</page>
<table confidence="0.9998445">
Model ACC BLEU
Baseline (frequency) 58.9 40.0
Baseline (490K LM) 87.2 83.6
Log-linear model 94.9 93.0
</table>
<tableCaption confidence="0.978754333333333">
Table 4: Accuracy (%) and BLEU score for case
prediction when given correct context (reference
translations) on the 5K-test set
</tableCaption>
<bodyText confidence="0.999353956521739">
parison, we also include results from two base-
lines: a frequency-based baseline, which always
assigns the most likely class (NONE), and a lan-
guage model (LM) baseline, which is one of the
standard methods of generating grammatical
elements in MT. We trained a word-trigram LM
using the CMU toolkit (Clarkson and Rosenfeld,
1997) on the same 490K sentences which we
used for training the case prediction model.
Table 4 shows that our model performs sub-
stantially better than both baselines: the accuracy
of the frequency-based baseline is 59%, and an
LM-based model improves it to 87.2%. In con-
trast, our model achieves an accuracy of 95%,
which is a 60% error reduction over the LM
baseline. It is also interesting to note that as the
accuracy goes up, so does the BLEU score.
These results show that our best model can
very effectively predict case markers when the
input to the model is clean, i.e., when the input
has correct words in correct order. Next, we see
the impact of applying this model to improve MT
output.
</bodyText>
<sectionHeader confidence="0.9988765" genericHeader="method">
4 Integrating Case Prediction Models in
MT
</sectionHeader>
<bodyText confidence="0.999940791666667">
In the end-to-end MT scenario, we integrate our
case assignment model with the SMT system and
evaluate its contribution to the final MT output.
As a method of integration with the MT sys-
tem, we chose an n-best re-ranking approach,
where the baseline MT system is left unchanged
and additional models are integrated in the form
of feature functions via re-ranking of n-best lists
from the system. Such an approach has been
taken by Och et al. (2004) for integrating sophis-
ticated syntax-informed models in a phrase-
based SMT system. We also chose this approach
for ease of implementation: as discussed in Sec-
tion 3.2, the features we use in our case model
extend over long distance, and are not readily
available during decoding. Though a tighter inte-
gration with the decoding process is certainly
worth exploring in the future, we have taken an
approach here that allows fast experimentation.
Within the space of n-best re-ranking, we
have considered two variations: the standard n-
best re-ranking method, and our significantly
better performing extension. These are now dis-
cussed in turn.
</bodyText>
<subsectionHeader confidence="0.998601">
4.1 Method 1: Standard n-best re-ranking
</subsectionHeader>
<bodyText confidence="0.944688357142857">
This method is a straightforward application of
the n-best re-ranking approach described in Och
et al. (2004). As described in Section 2.2, our
baseline SMT system is a linear model which
weighs the values of ten feature functions. To
integrate a case prediction model, we simply add
it to the linear model as an 11th feature function,
whose value is the log-probability of the case
assignment of the candidate hypothesis t accord-
ing to our model. The weights of all feature func-
tions are then re-estimated using max-BLEU
training on the n-best list of the lambda-1K set in
Table 2. As we show in Section 5, this re-ranking
method did not result in good performance.
</bodyText>
<subsectionHeader confidence="0.7724185">
4.2 Method 2: Re-ranking of expanded
candidate lists
</subsectionHeader>
<bodyText confidence="0.999991903225807">
A drawback of the previous method is that in an
n-best list, there may not be sufficiently many
case assignment variations of existing hypothe-
ses. If this is the case, the model cannot be effec-
tive in choosing a hypothesis with a good case
assignment. We performed a simple experiment
to test this. We took the first (best) hypothesis t
from the MT system and generated the top 40
case variations t’ of t, according to the case as-
signment model. These variations differ from t
only in their case markers. We wanted to see
what fraction of these new hypotheses t’ oc-
curred in a 1000-best list of the MT system. In
the dev-1K set of Table 2, the fraction of new
case variations of the first hypothesis occurring
in the 1000-best list of hypotheses was 0.023.
This means that only less than one (2.3% of 40 =
0.92) case variant of the first hypothesis is ex-
pected to be found in the 1000-best list, indicat-
ing that even an n-best list for a reasonably large
n (such as 1000) does not contain enough candi-
dates varying in case marker assignment.
In order to allow more case marking candi-
dates to be considered, we propose the following
method to expand the candidate translation list:
for each translation t in the n-best list of the base-
line SMT system, we also consider case assign-
ment variations of t. For simplicity, we chose to
consider the top k case assignment variations of
each hypothesis according to our case model,3
for 1 k 40.4
</bodyText>
<footnote confidence="0.527109">
3 From a computational standpoint, it is non-trivial to con-
</footnote>
<page confidence="0.998989">
53
</page>
<bodyText confidence="0.979010631578947">
After we expand the translation candidate set,
we compute feature functions for all candidates
and train a linear model which chooses from this
larger set. While some features (e.g., word count
feature) are easy to recompute for a new candi-
date, other features (e.g., treelet phrase transla-
tion probability) are difficult to recompute. We
have chosen to recompute only four features of
the baseline model: the language model feature,
the word count feature, and the direct and reverse
whole-sentence IBM Model 1 features, assum-
ing that the values of the other baseline model
features for a casing variation t’ of t are the same
as their values for t. In addition, we added the
following four feature functions, specifically
meant to capture the extent to which the newly
generated case marking variations differ from the
original baseline system hypotheses they are de-
rived from:
</bodyText>
<listItem confidence="0.9336475">
• Generated: a binary feature with a value of 0
for original baseline system candidates, and a
value of 1 for newly generated candidates.
• Number NONEnon-NONE: the count of case
markers changed from NONE to non-NONE
with respect to an original translation candi-
date.
• Number non-NONENONE: the count of case
markers changed from non-NONE to NONE.
• Number non-NONEnon-NONE: the count of
case markers changed from non-NONE to an-
other non-NONE case marker.
</listItem>
<bodyText confidence="0.999939285714286">
Note that these newly defined features all have a
value of 0 for original baseline system candidates
(i.e., when k=0) and therefore would have no
effect in Method 1. Therefore, the only differ-
ence between our two methods of integration is
the presence or absence of case-expanded candi-
date translations.
</bodyText>
<sectionHeader confidence="0.989594" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.996239">
5.1 Data and settings
</subsectionHeader>
<bodyText confidence="0.930081090909091">
For our end-to-end MT experiments, we used
three datasets in Table 2 that are disjoint from
the train-500K data set. They consist of source
English sentences and their top 1000 candidate
translations produced by the baseline SMT sys-
sider all possible case assignment variations of a hypothesis:
even though the case assignment score for a sentence is
locally decomposable, there are still global dependencies in
the linear model from Equation (1) due to the reverse
whole-sentence IBM model 1 score used as a feature func-
tion.
</bodyText>
<footnote confidence="0.926015">
4 Our results indicate that additional case variations would
not be helpful.
</footnote>
<table confidence="0.991980294117647">
Models #MT #case BLEU Oracle
hypothe expan- BLEU
ses sions
Baseline 1 0 37.99 37.99
20 0 37.83 41.79
Method 1 100 0 38.02 42.79
1000 0 38.08 43.14
1 1 38.18 38.75
Method 2 1 10 38.42 40.51
1 20 38.54 41.15
1 40 38.41 41.74
20 10 38.91 45.32
20 20 38.72 45.94
Method 2 20 40 38.78 46.56
100 10 38.73 46.87
100 20 38.64 47.47
100 40 38.74 47.96
</table>
<tableCaption confidence="0.992961">
Table 5. Results of end-to-end experiments on the
dev-1K set
</tableCaption>
<bodyText confidence="0.9992142">
tem. These datasets are the lambda-1K set for
training the weights of the linear model from
Equation (1), the dev-1K set for model selection,
and the test-2K set for final testing including
human evaluation.
</bodyText>
<subsectionHeader confidence="0.91112">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999851375">
The results for the end-to-end experiments on the
dev-1K set are summarized in Table 5. The table
is divided into four sections. The first section
(row) shows the BLEU score of the baseline
SMT system, which is equivalent to the 1-best
re-ranking scenario with no case expansion. The
BLEU score for the baseline was 37.99. In the
table, we also show the oracle BLEU scores for
each model, which are computed by greedily se-
lecting the translation in the candidate list with
the highest BLEU score.5
The second section of Table 5 corresponds to
the results obtained by Method 1, i.e., the stan-
dard n-best re-ranking, for n = 20, 100, and 1000.
Even though the oracle scores improve as n is
increased, the actual performance improves only
slightly. These results show that the strategy of
only including the new information as features in
a standard n-best re-ranking scenario does not
lead to an improvement over the baseline.
In contrast, Method 2 obtains notable im-
provements over the baseline. Recall that we ex-
pand the n-best SMT candidates with their k-best
case marking variations in this method, and re-
</bodyText>
<footnote confidence="0.96519825">
5 A modified version of BLEU was used to compute sen-
tence-level BLEU in order to select the best hypothesis per
sentence. The table shows corpus-level BLEU on the result-
ing set of translations.
</footnote>
<page confidence="0.998666">
54
</page>
<bodyText confidence="0.999987692307692">
train the model parameters on the resulting can-
didate lists. For the values n=1 and k=1 (which
we refer to as 1best-1case), we observe a small
BLEU gain of .19 over the baseline. Even though
this is not a big improvement, it is still better
than the improvement of standard n-best re-
ranking with a 1000-best list. By considering
more case marker variations (k = 10, 20 and 40),
we are able to gain about a half BLEU point over
the baseline. The fact that using more case varia-
tions performs better than using only the best
case assignment candidate proposed by the case
model suggests that the proposed approach,
which integrates the case prediction model as a
feature function and retrains the weights of the
linear model, works better than using the case
prediction model as a post-processor of the MT
output.
The last section of the table explores combi-
nations of the values for n and k. Considering 20
best SMT candidates and their top 10 case varia-
tions gave the highest BLEU score on the dev-
1K set of 38.91, which is an 0.92 BLEU points
improvement over the baseline. Considering
more case variations (20 or 40), and more SMT
candidates (100) resulted in a similar but slightly
lower performance in BLEU. This is presumably
because the case model does affect the choice of
content words as well, but this influence is lim-
ited and can be best captured when using a small
number (n=20) of baseline system candidates.
Based on these results on the dev-1K set, we
chose the best model (i.e., 20-best-10case) and
evaluated it on the test-2K set against the base-
line. Using the pair-wise statistical test design
described in Collins et al. (2005), the BLEU im-
provement (35.53 vs. 36.29) was statistically
significant (p &lt; .01) according to the Wilcoxon
signed-rank test.
</bodyText>
<subsectionHeader confidence="0.997593">
5.3 Human evaluation
</subsectionHeader>
<bodyText confidence="0.974191785714286">
These results demonstrate that the proposed
model is effective at improving the translation
quality according to the BLEU score. In this sec-
tion, we report the results of human evaluation to
ensure that the improvements in BLEU lead to
better translations according to human evaluators.
We performed human evaluation on the
20best-10case (n=20, k=10) and 1best-40case
(n=1, k=40) models against the baseline using
our final test set, the test-2K data. The perform-
ance in BLEU of these models on the full test-2K
data was 35.53 for the baseline, 36.09 for the
1best-40case model, and 36.29 for the 20best-
10case model, respectively.
</bodyText>
<table confidence="0.998943">
Fluency Adequacy
Annotator #1 Annotator #1
S B E S B E
Anno- S 27 1 8 17 0 9
tator B 1 9 16 0 9 12
#2 E 7 4 27 9 8 36
</table>
<tableCaption confidence="0.994085333333333">
Table 6. Results of human evaluation comparing
20best-10case vs. baseline. S: proposed system is bet-
ter; B: baseline is better; E: of equal quality
</tableCaption>
<bodyText confidence="0.999976822222223">
In our human evaluation, two annotators were
asked to evaluate a random set of 100 sentences
for which the models being compared produced
different translations. The judges were asked to
compare two translations, the baseline output
from the original SMT system and the output
chosen by the system augmented with the case
marker generation component. Each judge was
asked to run two separate evaluations along dif-
ferent evaluation criteria. In the evaluation of
fluency, the judges were asked to decide which
translation is more readable/grammatical, ignor-
ing the reference translation. In the evaluation of
adequacy, they were asked to judge which trans-
lation more correctly reflects the meaning of the
reference translation. In either setting, they were
not given the source sentence.
Table 6 summarizes the results of the evalua-
tion of the 20best-10case model. The table shows
the results along two evaluation criteria sepa-
rately, fluency on the left and adequacy on the
right. The evaluation results of Annotator #1 are
shown in the columns, while those of Annotator
#2 are in the rows. Each grid in the table shows
the number of sentences the annotators classified
as the proposed system output better (S), the
baseline system better (B) or the translations are
of equal quality (E). Along the diagonal (in bold-
face) are the judgments that were agreed on by
the two annotators: both annotators judged the
output of the proposed system to be more fluent
in 27 translations, less fluent in 9 translations;
they judged that our system output was more
adequate in 17 translations and less adequate in 9
translations. Our system output was thus judged
better under both criteria, though according to a
sign test, the improvement is statistically signifi-
cant (p &lt; .01) in fluency, but not in adequacy.
One of the reasons for this inconclusive result
is that human evaluation may be very difficult
and can be unreliable when evaluating very dif-
ferent translation candidates, which happens of-
ten when comparing the results of models that
consider n-best candidates where n&gt;1, as is the
case with the 20best-10case model. In Table 6,
</bodyText>
<page confidence="0.993666">
55
</page>
<table confidence="0.999511166666667">
Fluency Adequacy
Annotator #1 Annotator #1
S B E S B E
Anno- S 42 0 9 30 1 9
tator B 1 0 7 0 9 7
#2 E 7 2 32 9 3 32
</table>
<tableCaption confidence="0.989077">
Table 7. Results of human evaluation comparing
1best-40case vs. baseline
</tableCaption>
<bodyText confidence="0.99958688">
we can see that the raw agreement rate between
the two annotators (i.e., number of agreed judg-
ments over all judgments) is only 63% (27+9+27
/100) in fluency and 62% (17+9+36/100) in ade-
quacy. We therefore performed an additional
human evaluation where translations being com-
pared differ only in case markers: the baseline vs.
the 1best-40case model output. The results are
shown in Table 7.
This evaluation has a higher rate of agreement,
74% for fluency and 71% for adequacy, indicat-
ing that comparing two translations that differ
only minimally (i.e., in case markers) is more
reliable. The improvements achieved by our
model are statistically significant in both fluency
and adequacy according to a sign test; in particu-
lar, it is remarkable that on 42 sentences, the
judges agreed that our system was better in flu-
ency, and there were no sentences on which the
judges agreed that our system caused degradation.
This means that the proposed system, when
choosing among candidates differing only in case
markers, can improve the quality of MT output
in an extremely precise manner, i.e. making im-
provements without causing degradations.
</bodyText>
<sectionHeader confidence="0.999578" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999994391304348">
We have described a method of using a case
marker generation model to improve the quality
of English-to-Japanese MT output. We have
shown that the use of such a model contributes to
improving MT output, both in BLEU and human
evaluation. We have also proposed an extension
of n-best re-ranking which significantly outper-
formed standard n-best re-ranking. This method
should be generally applicable to integrating
models which target specific phenomena in
translation, and for which an extremely large n-
best list would be needed to cover enough vari-
ants of the phenomena in question.
Our model improves the quality of generated
case markers in an extremely precise manner.
We believe this result is significant, as there are
many phenomena in the target language of MT
that may be improved by using special-purpose
models, including the generation of articles, aux-
iliaries, inflection and agreement. We plan to
extend and generalize the current approach to
cover these phenomena in morphologically com-
plex languages in general in the future.
</bodyText>
<sectionHeader confidence="0.996459" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999637224489796">
Clarkson, P.R. and R. Rosenfeld. 1997. Statistical
Language Modeling Using the CMU-Cambridge
Toolkit. In ESCA Eurospeech, pp. 2007-2010.
Collins, M., P. Koehn and I. Kuerová. 2005. Clause
Restructuring for Statistical Machine Translation.
In ACL, pp.531-540.
Chiang, D. 2005. A Hierarchical Phrase-based Model
for Statistical Machine Translation. In ACL.
Galley, M., J. Graehl, K. Knight, D. Marcu, S.
DeNeefe, W. Wang and I. Thayer. 2006. Scalable
Inference and Training of Context-Rich Syntactic
Translation Models. In ACL.
Koehn, P., F. J. Och and D. Marcu. 2003. Statistical
Phrase-based Translation. In HLT-NAACL.
Haji, J., M. mejrek, B. Dorr, Y. Ding, J. Eisner, D.
Gildea, T. Koo, K. Parton, G. Penn, D. Radev and
O. Rambow. 2002. Natural Language Generation
in the Context of Machine Translation. Technical
report, Center for Language and Speech Process-
ing, Johns Hopkins University 2002 Summer Work-
shop Final Report.
Knight, K. and I. Chander. 1994. Automatic Postedit-
ing of Documents. In AAAI.
McCallum, A. 2003. Efficiently inducing features of
conditional random fields. In UAI.
Och, F. J. 2003. Minimum Error-rate Training for
Statistical Machine Translation. In ACL.
Och, F. J. and H. Ney. 2000. Improved Statistical
Alignment Models. In ACL.
Och, F. J. and H. Ney. 2002. Discriminative Training
and Maximum Entropy Models for Statistical Ma-
chine Translation. In ACL 2002.
Och, F. J., D. Gildea, S. Khudanpur, A. Sarkar, K.
Yamada, A. Fraser, S. Kumar, L. Shen, D. Smith,
K. Eng, V. Jain, Z. Jin and D. Radev. 2004. A
Smorgasbord of Features for Statistical Machine
Translation. In NAACL.
Papineni, K., S. Roukos, T. Ward and W.J. Zhu. 2002.
BLEU: A Method for Automatic Evaluation of
Machine Translation. In ACL.
Quirk, C., A. Menezes and C. Cherry. 2005. Depend-
ency Tree Translation: Syntactically Informed
Phrasal SMT. In ACL.
Suzuki, H. and K. Toutanova. 2006. Learning to Pre-
dict Case Markers in Japanese. In ACL-COLING.
Vogel, S., Y. Zhang, F. Huang, A. Tribble, A.
Venugopal, B. Zhao and A. Waibel. 2003. The
CMU Statistical Machine Translation System. In
Proceedings of the MT Summit.
</reference>
<page confidence="0.998406">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854409">
<title confidence="0.999934">Generating Case Markers in Machine Translation</title>
<author confidence="0.996519">Kristina Toutanova Hisami</author>
<affiliation confidence="0.972064">Microsoft</affiliation>
<address confidence="0.999601">One Microsoft Way, Redmond WA 98052</address>
<email confidence="0.999656">hisamis@microsoft.com</email>
<email confidence="0.999656">kristout@microsoft.com</email>
<abstract confidence="0.992558222222222">We study the use of rich syntax-based statistical models for generating grammatical case for the purpose of machine translation from a language which does not indicate case explicitly (English) to a language with a rich system of surface case markers (Japanese). We propose an of re-ranking as a method of integrating such models into a statistical MT system and show that this method substantially outperforms stanre-ranking. Our best performing model achieves a statistically significant improvement over the baseline MT system according to the BLEU metric. Human evaluation also confirms the results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P R Clarkson</author>
<author>R Rosenfeld</author>
</authors>
<title>Statistical Language Modeling Using the CMU-Cambridge Toolkit.</title>
<date>1997</date>
<booktitle>In ESCA Eurospeech,</booktitle>
<pages>2007--2010</pages>
<contexts>
<context position="17797" citStr="Clarkson and Rosenfeld, 1997" startWordPosition="2914" endWordPosition="2917">correctly, and BLEU score against the reference translation. For com52 Model ACC BLEU Baseline (frequency) 58.9 40.0 Baseline (490K LM) 87.2 83.6 Log-linear model 94.9 93.0 Table 4: Accuracy (%) and BLEU score for case prediction when given correct context (reference translations) on the 5K-test set parison, we also include results from two baselines: a frequency-based baseline, which always assigns the most likely class (NONE), and a language model (LM) baseline, which is one of the standard methods of generating grammatical elements in MT. We trained a word-trigram LM using the CMU toolkit (Clarkson and Rosenfeld, 1997) on the same 490K sentences which we used for training the case prediction model. Table 4 shows that our model performs substantially better than both baselines: the accuracy of the frequency-based baseline is 59%, and an LM-based model improves it to 87.2%. In contrast, our model achieves an accuracy of 95%, which is a 60% error reduction over the LM baseline. It is also interesting to note that as the accuracy goes up, so does the BLEU score. These results show that our best model can very effectively predict case markers when the input to the model is clean, i.e., when the input has correct</context>
</contexts>
<marker>Clarkson, Rosenfeld, 1997</marker>
<rawString>Clarkson, P.R. and R. Rosenfeld. 1997. Statistical Language Modeling Using the CMU-Cambridge Toolkit. In ESCA Eurospeech, pp. 2007-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kuerová</author>
</authors>
<title>Clause Restructuring for Statistical Machine Translation. In</title>
<date>2005</date>
<booktitle>ACL,</booktitle>
<pages>531--540</pages>
<contexts>
<context position="27748" citStr="Collins et al. (2005)" startWordPosition="4635" endWordPosition="4638"> 0.92 BLEU points improvement over the baseline. Considering more case variations (20 or 40), and more SMT candidates (100) resulted in a similar but slightly lower performance in BLEU. This is presumably because the case model does affect the choice of content words as well, but this influence is limited and can be best captured when using a small number (n=20) of baseline system candidates. Based on these results on the dev-1K set, we chose the best model (i.e., 20-best-10case) and evaluated it on the test-2K set against the baseline. Using the pair-wise statistical test design described in Collins et al. (2005), the BLEU improvement (35.53 vs. 36.29) was statistically significant (p &lt; .01) according to the Wilcoxon signed-rank test. 5.3 Human evaluation These results demonstrate that the proposed model is effective at improving the translation quality according to the BLEU score. In this section, we report the results of human evaluation to ensure that the improvements in BLEU lead to better translations according to human evaluators. We performed human evaluation on the 20best-10case (n=20, k=10) and 1best-40case (n=1, k=40) models against the baseline using our final test set, the test-2K data. Th</context>
</contexts>
<marker>Collins, Koehn, Kuerová, 2005</marker>
<rawString>Collins, M., P. Koehn and I. Kuerová. 2005. Clause Restructuring for Statistical Machine Translation. In ACL, pp.531-540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>A Hierarchical Phrase-based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1425" citStr="Chiang, 2005" startWordPosition="213" endWordPosition="214"> 1 Introduction Generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (MT). Statistical machine translation (SMT) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language. Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g., Och and Ney, 2002; Koehn et al., 2003; Quirk et al., 2005; Chiang, 2005; Galley et al., 2006). However, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an SMT system is often ungrammatical. For example, Figure 1 shows an output from our baseline English-to-Japanese SMT system on a sentence from a computer domain. The SMT system, trained on this domain, produces a natural lexical translation for the English word patch as correction program, and translates replace 49 into passive voice, which is more appropr</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, D. 2005. A Hierarchical Phrase-based Model for Statistical Machine Translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>J Graehl</author>
<author>K Knight</author>
<author>D Marcu</author>
<author>S DeNeefe</author>
<author>W Wang</author>
<author>I Thayer</author>
</authors>
<title>Scalable Inference and Training of Context-Rich Syntactic Translation Models.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1447" citStr="Galley et al., 2006" startWordPosition="215" endWordPosition="218">n Generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (MT). Statistical machine translation (SMT) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language. Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g., Och and Ney, 2002; Koehn et al., 2003; Quirk et al., 2005; Chiang, 2005; Galley et al., 2006). However, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an SMT system is often ungrammatical. For example, Figure 1 shows an output from our baseline English-to-Japanese SMT system on a sentence from a computer domain. The SMT system, trained on this domain, produces a natural lexical translation for the English word patch as correction program, and translates replace 49 into passive voice, which is more appropriate in Japanese.1 How</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Galley, M., J. Graehl, K. Knight, D. Marcu, S. DeNeefe, W. Wang and I. Thayer. 2006. Scalable Inference and Training of Context-Rich Syntactic Translation Models. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical Phrase-based Translation.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="1391" citStr="Koehn et al., 2003" startWordPosition="205" endWordPosition="208">an evaluation also confirms the results. 1 Introduction Generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (MT). Statistical machine translation (SMT) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language. Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g., Och and Ney, 2002; Koehn et al., 2003; Quirk et al., 2005; Chiang, 2005; Galley et al., 2006). However, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an SMT system is often ungrammatical. For example, Figure 1 shows an output from our baseline English-to-Japanese SMT system on a sentence from a computer domain. The SMT system, trained on this domain, produces a natural lexical translation for the English word patch as correction program, and translates replace 49 into pa</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, P., F. J. Och and D. Marcu. 2003. Statistical Phrase-based Translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Haji</author>
<author>M mejrek</author>
<author>B Dorr</author>
<author>Y Ding</author>
<author>J Eisner</author>
<author>D Gildea</author>
<author>T Koo</author>
<author>K Parton</author>
<author>G Penn</author>
<author>D Radev</author>
<author>O Rambow</author>
</authors>
<title>Natural Language Generation in the Context of Machine Translation.</title>
<date>2002</date>
<tech>Technical report,</tech>
<institution>Center for Language and Speech Processing, Johns Hopkins University</institution>
<contexts>
<context position="3748" citStr="Haji et al. 2002" startWordPosition="585" endWordPosition="588">ny SMT system dealing with morpho-syntactically divergent language pairs may benefit from a similar approach to modeling grammatical elements. Our model uses a rich set of syntactic features of both the source (English) and the target (Japanese) sentences, using context which is broader than that utilized by existing SMT systems. We show that the use of such features results in very high case assignment quality and also leads to a notable improvement in MT quality. Previous work has discussed the building of special-purpose classifiers which generate grammatical elements such as prepositions (Haji et al. 2002), determiners (Knight and Chander, 1994) and case markers (Suzuki and Toutanova, 2006) with an eye toward improving MT output. How1 There is a strong tendency to avoid transitive sentences with an inanimate subject in Japanese. Proceedings of NAACL HLT 2007, pages 49–56, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ever, these components have not actually been integrated in an MT system. To our knowledge, this is the first work to integrate a grammatical element production model in an SMT system and to evaluate its impact in the context of end-toend MT. A common </context>
</contexts>
<marker>Haji, mejrek, Dorr, Ding, Eisner, Gildea, Koo, Parton, Penn, Radev, Rambow, 2002</marker>
<rawString>Haji, J., M. mejrek, B. Dorr, Y. Ding, J. Eisner, D. Gildea, T. Koo, K. Parton, G. Penn, D. Radev and O. Rambow. 2002. Natural Language Generation in the Context of Machine Translation. Technical report, Center for Language and Speech Processing, Johns Hopkins University 2002 Summer Workshop Final Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>I Chander</author>
</authors>
<title>Automatic Postediting of Documents. In</title>
<date>1994</date>
<publisher>AAAI.</publisher>
<contexts>
<context position="3788" citStr="Knight and Chander, 1994" startWordPosition="590" endWordPosition="593">o-syntactically divergent language pairs may benefit from a similar approach to modeling grammatical elements. Our model uses a rich set of syntactic features of both the source (English) and the target (Japanese) sentences, using context which is broader than that utilized by existing SMT systems. We show that the use of such features results in very high case assignment quality and also leads to a notable improvement in MT quality. Previous work has discussed the building of special-purpose classifiers which generate grammatical elements such as prepositions (Haji et al. 2002), determiners (Knight and Chander, 1994) and case markers (Suzuki and Toutanova, 2006) with an eye toward improving MT output. How1 There is a strong tendency to avoid transitive sentences with an inanimate subject in Japanese. Proceedings of NAACL HLT 2007, pages 49–56, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ever, these components have not actually been integrated in an MT system. To our knowledge, this is the first work to integrate a grammatical element production model in an SMT system and to evaluate its impact in the context of end-toend MT. A common approach of integrating new models with </context>
</contexts>
<marker>Knight, Chander, 1994</marker>
<rawString>Knight, K. and I. Chander. 1994. Automatic Postediting of Documents. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>Efficiently inducing features of conditional random fields.</title>
<date>2003</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="14764" citStr="McCallum (2003)" startWordPosition="2406" endWordPosition="2407"> &amp;quot;Headword POS=X&amp;quot;, which generate a set of binary features corresponding to different instantiations of the template, such as &amp;quot;Headword POS=NOUN&amp;quot;. We applied an automatic feature selection and induction algorithm to the base set of templates. The feature selection algorithm considers the original templates as well as arbitrary (bigram and trigram) conjunctions of these templates. The algorithm performs forward stepwise feature selection, choosing templates which result in the highest increase in model accuracy on the 5Kfeat set mentioned above. The algorithm is similar to the one described in McCallum (2003). The application of this feature selection procedure gave us 17 templates, some of which are shown in Table 3, along with example instantiations for the phrase headed by saabisu ‘service’ Features Example Words in position –1 and +2 kono,moodo Headword &amp; previous headword saabisu&amp;kono Parent word kaishi Aligned word service Parent of word aligned to headword started Next word POS NOUN Next word &amp; next word POS seefu&amp;NN Headword POS NOUN Parent headword POS VN Aligned to parent word POS &amp; next word VERB&amp;NN&amp;an POS &amp; prev word POS d Parent POS of word aligned to headword VERB Aligned word POS &amp; </context>
</contexts>
<marker>McCallum, 2003</marker>
<rawString>McCallum, A. 2003. Efficiently inducing features of conditional random fields. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum Error-rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9048" citStr="Och (2003)" startWordPosition="1471" endWordPosition="1472">e j are the model parameters and fj(t) is the value of the feature function j on the candidate t. There are ten feature functions in the treelet system, including log-probabilities according to inverted and direct channel models estimated by relative frequency, lexical weighting channel models following Vogel et al. (2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004). The weights of these models are determined using the max-BLEU method described in Och (2003). As we describe in Section 4, the case prediction model is integrated into the system as an additional feature function. The treelet translation model is estimated using a parallel corpus. First, the corpus is wordaligned using GIZA++ (Och and Ney, 2000); then the source sentences are parsed into a dependency structure, and the dependency is projected onto the target side following the heuristics described in Quirk et al. (2005). Figure 2 shows an example of an aligned sentence pair: on the source (English) side, POS tags and word dependency structure are assigned (solid arcs); the word align</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. 2003. Minimum Error-rate Training for Statistical Machine Translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9303" citStr="Och and Ney, 2000" startWordPosition="1512" endWordPosition="1515">ive frequency, lexical weighting channel models following Vogel et al. (2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004). The weights of these models are determined using the max-BLEU method described in Och (2003). As we describe in Section 4, the case prediction model is integrated into the system as an additional feature function. The treelet translation model is estimated using a parallel corpus. First, the corpus is wordaligned using GIZA++ (Och and Ney, 2000); then the source sentences are parsed into a dependency structure, and the dependency is projected onto the target side following the heuristics described in Quirk et al. (2005). Figure 2 shows an example of an aligned sentence pair: on the source (English) side, POS tags and word dependency structure are assigned (solid arcs); the word alignments between English and Japanese words are indicated by the dotted lines. On the target (Japanese) side, projected word dependencies (solid arcs) are available. Additional annotations in Figure 2, namely the POS tags and the bunsetsu dependency structur</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Och, F. J. and H. Ney. 2000. Improved Statistical Alignment Models. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative Training and Maximum Entropy Models for Statistical Machine Translation.</title>
<date>2002</date>
<booktitle>In ACL</booktitle>
<contexts>
<context position="1371" citStr="Och and Ney, 2002" startWordPosition="201" endWordPosition="204">he BLEU metric. Human evaluation also confirms the results. 1 Introduction Generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (MT). Statistical machine translation (SMT) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language. Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g., Och and Ney, 2002; Koehn et al., 2003; Quirk et al., 2005; Chiang, 2005; Galley et al., 2006). However, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an SMT system is often ungrammatical. For example, Figure 1 shows an output from our baseline English-to-Japanese SMT system on a sentence from a computer domain. The SMT system, trained on this domain, produces a natural lexical translation for the English word patch as correction program, and translate</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Och, F. J. and H. Ney. 2002. Discriminative Training and Maximum Entropy Models for Statistical Machine Translation. In ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>D Gildea</author>
<author>S Khudanpur</author>
<author>A Sarkar</author>
<author>K Yamada</author>
<author>A Fraser</author>
<author>S Kumar</author>
<author>L Shen</author>
<author>D Smith</author>
<author>K Eng</author>
<author>V Jain</author>
<author>Z Jin</author>
<author>D Radev</author>
</authors>
<title>A Smorgasbord of Features for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="4556" citStr="Och et al., 2004" startWordPosition="722" endWordPosition="725">th an inanimate subject in Japanese. Proceedings of NAACL HLT 2007, pages 49–56, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ever, these components have not actually been integrated in an MT system. To our knowledge, this is the first work to integrate a grammatical element production model in an SMT system and to evaluate its impact in the context of end-toend MT. A common approach of integrating new models with a statistical MT system is to add them as new feature functions which are used in decoding or in models which re-rank n-best lists from the MT system (Och et al., 2004). In this paper we propose an extension of the n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set. We show that expanding the n-best lists significantly outperforms standard n-best reranking. We also show that integrating our case prediction model improves the quality of translation according to BLEU (Papineni et al., 2002) and human evaluation. 2 Background In this section, we provide necessary background of the current work. 2.1 Task of case marker prediction Our definiti</context>
<context position="8954" citStr="Och et al. 2004" startWordPosition="1453" endWordPosition="1456"> SMT systems. score t = ∑ λ f t ( ) j j ( ) 50 Figure 2. Aligned English-Japanese sentence pair where j are the model parameters and fj(t) is the value of the feature function j on the candidate t. There are ten feature functions in the treelet system, including log-probabilities according to inverted and direct channel models estimated by relative frequency, lexical weighting channel models following Vogel et al. (2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004). The weights of these models are determined using the max-BLEU method described in Och (2003). As we describe in Section 4, the case prediction model is integrated into the system as an additional feature function. The treelet translation model is estimated using a parallel corpus. First, the corpus is wordaligned using GIZA++ (Och and Ney, 2000); then the source sentences are parsed into a dependency structure, and the dependency is projected onto the target side following the heuristics described in Quirk et al. (2005). Figure 2 shows an example of an aligned sentence pair: on the source (E</context>
<context position="18982" citStr="Och et al. (2004)" startWordPosition="3123" endWordPosition="3126">i.e., when the input has correct words in correct order. Next, we see the impact of applying this model to improve MT output. 4 Integrating Case Prediction Models in MT In the end-to-end MT scenario, we integrate our case assignment model with the SMT system and evaluate its contribution to the final MT output. As a method of integration with the MT system, we chose an n-best re-ranking approach, where the baseline MT system is left unchanged and additional models are integrated in the form of feature functions via re-ranking of n-best lists from the system. Such an approach has been taken by Och et al. (2004) for integrating sophisticated syntax-informed models in a phrasebased SMT system. We also chose this approach for ease of implementation: as discussed in Section 3.2, the features we use in our case model extend over long distance, and are not readily available during decoding. Though a tighter integration with the decoding process is certainly worth exploring in the future, we have taken an approach here that allows fast experimentation. Within the space of n-best re-ranking, we have considered two variations: the standard nbest re-ranking method, and our significantly better performing exte</context>
</contexts>
<marker>Och, Gildea, Khudanpur, Sarkar, Yamada, Fraser, Kumar, Shen, Smith, Eng, Jain, Jin, Radev, 2004</marker>
<rawString>Och, F. J., D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng, V. Jain, Z. Jin and D. Radev. 2004. A Smorgasbord of Features for Statistical Machine Translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>BLEU: A Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="5003" citStr="Papineni et al., 2002" startWordPosition="790" endWordPosition="793">s with a statistical MT system is to add them as new feature functions which are used in decoding or in models which re-rank n-best lists from the MT system (Och et al., 2004). In this paper we propose an extension of the n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set. We show that expanding the n-best lists significantly outperforms standard n-best reranking. We also show that integrating our case prediction model improves the quality of translation according to BLEU (Papineni et al., 2002) and human evaluation. 2 Background In this section, we provide necessary background of the current work. 2.1 Task of case marker prediction Our definition of the case marker prediction task follows Suzuki and Toutanova (2006). That is, we assume that we are given a source English sentence, and its translation in Japanese which does not include case markers. Our task is to predict all case markers in the Japanese sentence. We determine the location of case marker insertion using the notion of bunsetsu. A bunsetsu consists of one content (head) word followed by any number of function words. We </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., S. Roukos, T. Ward and W.J. Zhu. 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>A Menezes</author>
<author>C Cherry</author>
</authors>
<title>Dependency Tree Translation: Syntactically Informed Phrasal SMT.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1411" citStr="Quirk et al., 2005" startWordPosition="209" endWordPosition="212">onfirms the results. 1 Introduction Generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (MT). Statistical machine translation (SMT) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language. Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g., Och and Ney, 2002; Koehn et al., 2003; Quirk et al., 2005; Chiang, 2005; Galley et al., 2006). However, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an SMT system is often ungrammatical. For example, Figure 1 shows an output from our baseline English-to-Japanese SMT system on a sentence from a computer domain. The SMT system, trained on this domain, produces a natural lexical translation for the English word patch as correction program, and translates replace 49 into passive voice, which i</context>
<context position="7457" citStr="Quirk et al. (2005)" startWordPosition="1204" endWordPosition="1207">ers in a strict sense, the topic marker wa is also included as well as the combination of a case marker plus the topic marker for the case markers with the column +wa checked in the table. In total, there are 18 case markers to predict: ten simple case markers, the topic marker wa, and seven case+wa combinations. The case prediction task is therefore a 19-fold classification task: for each phrase, we assign one of the 18 case markers or NONE. 2.2 Treelet translation system We constructed and evaluated our case prediction model in the context of a treelet-based translation system, described in Quirk et al. (2005).2 In this approach, translation is guided by treelet translation pairs, where a treelet is a connected subgraph of a dependency tree. A sentence is translated in the treelet system as follows. The input sentence is first parsed into a dependency structure, which is then partitioned into treelets, assuming a uniform probability distribution over all partitions. Each source treelet is then matched to a treelet translation pair, the collection of which will form the target translation. The target language treelets are then joined to form a single tree, and the ordering of all the nodes is determ</context>
<context position="9481" citStr="Quirk et al. (2005)" startWordPosition="1543" endWordPosition="1546">ctions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004). The weights of these models are determined using the max-BLEU method described in Och (2003). As we describe in Section 4, the case prediction model is integrated into the system as an additional feature function. The treelet translation model is estimated using a parallel corpus. First, the corpus is wordaligned using GIZA++ (Och and Ney, 2000); then the source sentences are parsed into a dependency structure, and the dependency is projected onto the target side following the heuristics described in Quirk et al. (2005). Figure 2 shows an example of an aligned sentence pair: on the source (English) side, POS tags and word dependency structure are assigned (solid arcs); the word alignments between English and Japanese words are indicated by the dotted lines. On the target (Japanese) side, projected word dependencies (solid arcs) are available. Additional annotations in Figure 2, namely the POS tags and the bunsetsu dependency structure (bold arcs) on the target side, are derived from the treelet system to be used for building a case prediction model, which we describe in Section 3. 2.3 Data All experiments re</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Quirk, C., A. Menezes and C. Cherry. 2005. Dependency Tree Translation: Syntactically Informed Phrasal SMT. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suzuki</author>
<author>K Toutanova</author>
</authors>
<title>Learning to Predict Case Markers in Japanese.</title>
<date>2006</date>
<booktitle>In ACL-COLING.</booktitle>
<contexts>
<context position="3834" citStr="Suzuki and Toutanova, 2006" startWordPosition="597" endWordPosition="600"> benefit from a similar approach to modeling grammatical elements. Our model uses a rich set of syntactic features of both the source (English) and the target (Japanese) sentences, using context which is broader than that utilized by existing SMT systems. We show that the use of such features results in very high case assignment quality and also leads to a notable improvement in MT quality. Previous work has discussed the building of special-purpose classifiers which generate grammatical elements such as prepositions (Haji et al. 2002), determiners (Knight and Chander, 1994) and case markers (Suzuki and Toutanova, 2006) with an eye toward improving MT output. How1 There is a strong tendency to avoid transitive sentences with an inanimate subject in Japanese. Proceedings of NAACL HLT 2007, pages 49–56, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ever, these components have not actually been integrated in an MT system. To our knowledge, this is the first work to integrate a grammatical element production model in an SMT system and to evaluate its impact in the context of end-toend MT. A common approach of integrating new models with a statistical MT system is to add them as new </context>
<context position="5229" citStr="Suzuki and Toutanova (2006)" startWordPosition="825" endWordPosition="828"> n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set. We show that expanding the n-best lists significantly outperforms standard n-best reranking. We also show that integrating our case prediction model improves the quality of translation according to BLEU (Papineni et al., 2002) and human evaluation. 2 Background In this section, we provide necessary background of the current work. 2.1 Task of case marker prediction Our definition of the case marker prediction task follows Suzuki and Toutanova (2006). That is, we assume that we are given a source English sentence, and its translation in Japanese which does not include case markers. Our task is to predict all case markers in the Japanese sentence. We determine the location of case marker insertion using the notion of bunsetsu. A bunsetsu consists of one content (head) word followed by any number of function words. We can therefore segment any sentence into a sequence of bunsetsu by using a part-of-speech (POS) tagger. Once a sentence is segmented into bunsetsu, it is trivial to determine the location of case markers in a sentence: each bun</context>
<context position="11141" citStr="Suzuki and Toutanova, 2006" startWordPosition="1814" endWordPosition="1817">istics of these data sets are given in Table 2. We will refer to this table as we describe our experiments in later sections. data set # sent # of words pairs (average sent length in words) English Japanese train-500K 500K 7,909,198 9,379,240 (15.81) (18.75) lambda-1K 1,000 15,219(15.2) 20,660 (20.7) dev-1K 1,000 15,397(15.4) 21,280 (21.3) test-2K 2,000 30,198(15.1) 41,269 (20.6) Table 2: Data set characteristics 3 Statistical Models for Case Prediction in MT 3.1 Case prediction model Our model of case marker prediction closely follows our previous work of case prediction in a non-MT context (Suzuki and Toutanova, 2006). The model is a multi-class log-linear (maximum entropy) classifier using 19 classes (18 case markers and NONE). It assigns a probability distribution over case marker assignments given a source English sentence, all non-case marker words of a candidate Japanese translation, and additional annotation information. Let t denote a Japanese translation, s a corresponding source sentence, and A additional annotation information such as alignment, dependency structure, and POS tags (such as shown in Figure 2). Let rest(t) denote the sequence of words in t excluding all case markers, and case(t) a c</context>
<context position="12586" citStr="Suzuki and Toutanova (2006)" startWordPosition="2056" endWordPosition="2059">nment is a product over all phrases of the probability of the case marker of the phrase given all context features used by the model. Our model assumes that the case markers in a sentence are independent of each other given the input features. This independence assumption may seem strong, but the results presented in our previous work (Suzuki and Toutanova, 2006) showed that a joint model did not result in large improvements over a local one in predicting case markers in a nonMT context. 51 3.2 Model features and feature selection The features of our model are similar to the ones described in Suzuki and Toutanova (2006). The main difference is that in the current model we applied a feature selection and induction algorithm to determine the most useful features and feature combinations. This is important for understanding what sources of information are important for predicting grammatical elements, but are currently absent from SMT systems. We used 490K sentence pairs for training the case prediction model, which is a subset of the train500K set of Table 2. We divided the remaining 10K sentences for feature selection (5K-feat) and for evaluating the case prediction models on reference translations (5K-test, </context>
</contexts>
<marker>Suzuki, Toutanova, 2006</marker>
<rawString>Suzuki, H. and K. Toutanova. 2006. Learning to Predict Case Markers in Japanese. In ACL-COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>Y Zhang</author>
<author>F Huang</author>
<author>A Tribble</author>
<author>A Venugopal</author>
<author>B Zhao</author>
<author>A Waibel</author>
</authors>
<title>The CMU Statistical Machine Translation System.</title>
<date>2003</date>
<booktitle>In Proceedings of the MT Summit.</booktitle>
<contexts>
<context position="8762" citStr="Vogel et al. (2003)" startWordPosition="1422" endWordPosition="1425">ding to a linear combination of feature functions: (1) j 2 Though this paper reports results in the context of a treelet system, the model is also applicable to other syntax-based or phrase-based SMT systems. score t = ∑ λ f t ( ) j j ( ) 50 Figure 2. Aligned English-Japanese sentence pair where j are the model parameters and fj(t) is the value of the feature function j on the candidate t. There are ten feature functions in the treelet system, including log-probabilities according to inverted and direct channel models estimated by relative frequency, lexical weighting channel models following Vogel et al. (2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004). The weights of these models are determined using the max-BLEU method described in Och (2003). As we describe in Section 4, the case prediction model is integrated into the system as an additional feature function. The treelet translation model is estimated using a parallel corpus. First, the corpus is wordaligned using GIZA++ (Och and Ney, 2000); then the source sentences are parsed into a dependency st</context>
</contexts>
<marker>Vogel, Zhang, Huang, Tribble, Venugopal, Zhao, Waibel, 2003</marker>
<rawString>Vogel, S., Y. Zhang, F. Huang, A. Tribble, A. Venugopal, B. Zhao and A. Waibel. 2003. The CMU Statistical Machine Translation System. In Proceedings of the MT Summit.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>