<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013775">
<title confidence="0.915536">
Semi-supervised latent variable models for sentence-level sentiment analysis
</title>
<author confidence="0.77339">
Oscar T¨ackstr¨om Ryan McDonald
</author>
<affiliation confidence="0.504153">
SICS, Kista / Uppsala University, Uppsala Google, Inc., New York
</affiliation>
<email confidence="0.971799">
oscar@sics.se ryanmcd@google.com
</email>
<sectionHeader confidence="0.993216" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9977671875">
We derive two variants of a semi-supervised
model for fine-grained sentiment analysis.
Both models leverage abundant natural super-
vision in the form of review ratings, as well as
a small amount of manually crafted sentence
labels, to learn sentence-level sentiment clas-
sifiers. The proposed model is a fusion of a
fully supervised structured conditional model
and its partially supervised counterpart. This
allows for highly efficient estimation and infer-
ence algorithms with rich feature definitions.
We describe the two variants as well as their
component models and verify experimentally
that both variants give significantly improved
results for sentence-level sentiment analysis
compared to all baselines.
</bodyText>
<sectionHeader confidence="0.81131" genericHeader="categories and subject descriptors">
1 Sentence-level sentiment analysis
</sectionHeader>
<bodyText confidence="0.999949824561404">
In this paper, we demonstrate how combining
coarse-grained and fine-grained supervision bene-
fits sentence-level sentiment analysis – an important
task in the field of opinion classification and retrieval
(Pang and Lee, 2008). Typical supervised learning ap-
proaches to sentence-level sentiment analysis rely on
sentence-level supervision. While such fine-grained
supervision rarely exist naturally, and thus requires
labor intensive manual annotation effort (Wiebe et
al., 2005), coarse-grained supervision is naturally
abundant in the form of online review ratings. This
coarse-grained supervision is, of course, less infor-
mative compared to fine-grained supervision, how-
ever, by combining a small amount of sentence-level
supervision with a large amount of document-level
supervision, we are able to substantially improve on
the sentence-level classification task. Our work com-
bines two strands of research: models for sentiment
analysis that take document structure into account;
and models that use latent variables to learn unob-
served phenomena from that which can be observed.
Exploiting document structure for sentiment anal-
ysis has attracted research attention since the early
work of Pang and Lee (2004), who performed min-
imal cuts in a sentence graph to select subjective
sentences. McDonald et al. (2007) later showed that
jointly learning fine-grained (sentence) and coarse-
grained (document) sentiment improves predictions
at both levels. More recently, Yessenalina et al.
(2010) described how sentence-level latent variables
can be used to improve document-level prediction
and Nakagawa et al. (2010) used latent variables over
syntactic dependency trees to improve sentence-level
prediction, using only labeled sentences for training.
In a similar vein, Sauper et al. (2010) integrated gen-
erative content structure models with discriminative
models for multi-aspect sentiment summarization
and ranking. These approaches all rely on the avail-
ability of fine-grained annotations, but T¨ackstr¨om
and McDonald (2011) showed that latent variables
can be used to learn fine-grained sentiment using only
coarse-grained supervision. While this model was
shown to beat a set of natural baselines with quite a
wide margin, it has its shortcomings. Most notably,
due to the loose constraints provided by the coarse
supervision, it tends to only predict the two dominant
fine-grained sentiment categories well for each docu-
ment sentiment category, so that almost all sentences
in positive documents are deemed positive or neutral,
and vice versa for negative documents. As a way of
overcoming these shortcomings, we propose to fuse
a coarsely supervised model with a fully supervised
model.
Below, we describe two ways of achieving such
a combined model in the framework of structured
conditional latent variable models. Contrary to (gen-
erative) topic models (Mei et al., 2007; Titov and
</bodyText>
<page confidence="0.977975">
569
</page>
<note confidence="0.6153035">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 569–574,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<equation confidence="0.995964625">
a) yd
· · ·ys ys ys · · ·
i−1 i i+1
··· si−1 si si+1 ···
b) yd
··· ys ys ys ···
i−1 i i+1
··· si−1 si si+1 ···
</equation>
<figureCaption confidence="0.9746575">
Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable
model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are
always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the
sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences.
</figureCaption>
<bodyText confidence="0.994717739130435">
McDonald, 2008; Lin and He, 2009), structured con-
ditional models can handle rich and overlapping fea-
tures and allow for exact inference and simple gradi-
ent based estimation. The former models are largely
orthogonal to the one we propose in this work and
combining their merits might be fruitful. As shown
by Sauper et al. (2010), it is possible to fuse gener-
ative document structure models and task specific
structured conditional models. While we do model
document structure in terms of sentiment transitions,
we do not model topical structure. An interesting
avenue for future work would be to extend the model
of Sauper et al. (2010) to take coarse-grained task-
specific supervision into account, while modeling
fine-grained task-specific aspects with latent vari-
ables.
Note also that the proposed approach is orthogonal
to semi-supervised and unsupervised induction of
context independent (prior polarity) lexicons (Turney,
2002; Kim and Hovy, 2004; Esuli and Sebastiani,
2009; Rao and Ravichandran, 2009; Velikovich et al.,
2010). The output of such models could readily be
incorporated as features in the proposed model.
</bodyText>
<subsectionHeader confidence="0.992108">
1.1 Preliminaries
</subsectionHeader>
<bodyText confidence="0.9998194">
Let d be a document consisting of n sentences, s =
(si)ni=1, with a document–sentence-sequence pair de-
noted d = (d, s). Let yd = (yd, ys) denote random
variables1 – the document level sentiment, yd, and the
sequence of sentence level sentiment, ys = (ysi )ni=1.
</bodyText>
<footnote confidence="0.6659795">
1We are abusing notation throughout by using the same sym-
bols to refer to random variables and their particular assignments.
</footnote>
<bodyText confidence="0.9983205">
In what follows, we assume that we have access to
two training sets: a small set of fully labeled in-
stances, DF = {(dj,ydj)}mf
j=1, and a large set of
coarsely labeled instances DC = {(dj, yd j )}mf +m�
j=mf +1.
Furthermore, we assume that yd and all ysi take val-
ues in {POS, NEG, NEU}.
We focus on structured conditional models in the
exponential family, with the standard parametrization
</bodyText>
<equation confidence="0.9789625">
{ �
pθ(yd, ys�s) = exp (φ(yd, ys, s), θ) − Aθ(s) ,
</equation>
<bodyText confidence="0.999862">
where θ E Rn is a parameter vector, φ(·) E Rn is a
vector valued feature function that factors according
to the graph structure outlined in Figure 1, and Aθ
is the log-partition function. This class of models is
known as conditional random fields (CRFs) (Lafferty
et al., 2001), when all variables are observed, and as
hidden conditional random fields (HCRFs) (Quattoni
et al., 2007), when only a subset of the variables are
observed.
</bodyText>
<subsectionHeader confidence="0.990239">
1.2 The fully supervised fine-to-coarse model
</subsectionHeader>
<bodyText confidence="0.973939222222222">
McDonald et al. (2007) introduced a fully super-
vised model in which predictions of coarse-grained
(document) and fine-grained (sentence) sentiment are
learned and inferred jointly. They showed that learn-
ing both levels jointly improved performance at both
levels, compared to learning each level individually,
as well as to using a cascaded model in which the
predictions at one level are used as input to the other.
Figure 1a outlines the factor graph of the corre-
</bodyText>
<page confidence="0.965906">
570
</page>
<bodyText confidence="0.9999665">
sponding conditional random field.2 The parameters,
θF, of this model can be estimated from the set of
fully labeled data, DF, by maximizing the joint con-
ditional likelihood function
</bodyText>
<equation confidence="0.983173">
2
log pθ, (ydj,y�|sj) − kθ�2 F
</equation>
<bodyText confidence="0.9994035">
where σ2F is the variance of the Normal(0, σ2F) prior.
Note that LF is a concave function and consequently
its unique maximum can be found by gradient based
optimization techniques.
</bodyText>
<subsectionHeader confidence="0.986612">
1.3 Latent variables for coarse supervision
</subsectionHeader>
<bodyText confidence="0.999857619047619">
Recently, T¨ackstr¨om and McDonald (2011) showed
that fine-grained sentiment can be learned from
coarse-grained supervision alone. Specifically, they
used a HCRF model with the same structure as that
in Figure 1a, but with sentence labels treated as la-
tent variables. The factor graph corresponding to this
model is outlined in Figure 1b.
The fully supervised model might benefit from fac-
tors that directly connect the document variable, yd,
with the inputs s. However, as argued by T¨ackstr¨om
and McDonald (2011), when only document-level
supervision is available, the document variable, yd,
should be independent of the input, s, conditioned
on the latent variables, ys. This prohibits the model
from bypassing the latent variables, which is crucial,
since we seek to improve the sentence-level predic-
tions, rather than the document-level predictions.
The parameters, θC, of this model can be esti-
mated from the set of coarsely labeled data, DC, by
maximizing the marginalized conditional likelihood
function
</bodyText>
<equation confidence="0.990031666666667">
2
pθC(ydj, ys|sj)− k��2I
C
</equation>
<bodyText confidence="0.958194142857143">
where the marginalization is over all possible se-
quences of latent sentence label assignments ys.
Due to the introduction of latent variables, the
marginal likelihood function is non-concave and thus
there are no guarantees of global optimality, how-
ever, we can still use a gradient based optimization
technique to find a local maximum.
2Figure 1a differs slightly from the model employed by Mc-
Donald et al. (2007), where they had factors connecting the
document label yd with each input si as well.
2 Combining coarse and full supervision
The fully supervised and the partially supervised
models both have their merits. The former requires
an expensive and laborious process of manual an-
notation, while the latter can be used with readily
available document labels, such as review star rat-
ings. The latter, however, has its shortcomings in
that the coarse-grained sentiment signal is less infor-
mative compared to a fine-grained signal. Thus, in
order to get the best of both worlds, we would like to
combine the merits of both of these models.
</bodyText>
<subsectionHeader confidence="0.960521">
2.1 A cascaded model
</subsectionHeader>
<bodyText confidence="0.999648166666666">
A straightforward way of fusing the two models is
by means of a cascaded model in which the predic-
tions of the partially supervised model, trained by
maximizing LC(θC) are used to derive additional
features for the fully supervised model, trained by
maximizing LF(θF).
Although more complex representations are pos-
sible, we generate meta-features for each sentence
based solely on operations on the estimated distribu-
tions, pθC(yd, ysi |s). Specifically, we encode the fol-
lowing probability distributions as discrete features
by uniform bucketing, with bucket width 0.1: the
joint distribution, pθC(yd, ysi |s); the marginal docu-
ment distribution, pθC(yd|s); and the marginal sen-
tence distribution, pθC(ysi |s). We also encode the
argmax of these distributions, as well as the pair-
wise combinations of the derived features.
The upshot of this cascaded approach is that it is
very simple to implement and efficient to train. The
downside is that only the partially supervised model
influences the fully supervised model; there is no
reciprocal influence between the models. Given the
non-concavity of LC(θC), such influence could be
beneficial.
</bodyText>
<subsectionHeader confidence="0.993737">
2.2 Interpolating likelihood functions
</subsectionHeader>
<bodyText confidence="0.999997142857143">
A more flexible way of fusing the two models is to
interpolate their likelihood functions, thereby allow-
ing for both coarse and joint supervision of the same
model. Such a combination can be achieved by con-
straining the parameters so that θI = θF = θC and
taking the mean of the likelihood functions LF and
LC, appropriately weighted by a hyper-parameter λ.
</bodyText>
<equation confidence="0.936820875">
LF (θF) = �mf
j=1
LC(θC) = mf+mom �
� log
j=mf+1 Y8
571
The result is the interpolated likelihood function
LI(BI) = ALF(BI) + (1 − A)LC(BI) .
</equation>
<bodyText confidence="0.99990556">
A simple, yet efficient, way of optimizing this ob-
jective function is to use stochastic gradient ascent
with learning rate q. At each step we select a fully
labeled instance, (dj, ydj) E DF, with probability A
and a coarsely labeled instance, (dj, ydj) E DC, with
probability (1 − A). We then update the parameters,
BI, according to the gradients aLF and aLC, respec-
tively. In principle we could use different learning
rates qF and qC as well as different prior variances
Q2F and Q2C, but in what follows we set them equal.
Since we are interpolating conditional models, we
need at least partial observations of each instance.
Methods for blending discriminative and generative
models (Lasserre et al., 2006; Suzuki et al., 2007;
Agarwal and Daum´e, 2009; Sauper et al., 2010),
would enable incorporation of completely unlabeled
data as well. It is straightforward to extend the pro-
posed model along these lines, however, in practice
coarsely labeled sentiment data is so abundant on
the web (e.g., rated consumer reviews) that incorpo-
rating completely unlabeled data seems superfluous.
Furthermore, using conditional models with shared
parameters throughout allows for rich overlapping
features, while maintaining simple and efficient in-
ference and estimation.
</bodyText>
<sectionHeader confidence="0.999668" genericHeader="acknowledgments">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999642">
For the following experiments, we used the same data
set and a comparable experimental setup to that of
T¨ackstr¨om and McDonald (2011).3 We compare the
two proposed hybrid models (Cascaded and Interpo-
lated) to the fully supervised model of McDonald et
al. (2007) (FineToCoarse) as well as to the soft vari-
ant of the coarsely supervised model of T¨ackstr¨om
and McDonald (2011) (Coarse).
The learning rate was fixed to q = 0.001, while
we tuned the prior variances, Q2, and the number of
epochs for each model. When sampling according to
A during optimization of LI(BI), we cycle through
DF and DC deterministically, but shuffle these sets
between epochs. Due to time constraints, we fixed the
interpolation factor to A = 0.1, but tuning this could
</bodyText>
<footnote confidence="0.95366">
3The annotated test data can be downloaded from
http://www.sics.se/people/oscar/datasets.
</footnote>
<bodyText confidence="0.999904625">
potentially improve the results of the interpolated
model. For the same reason we allowed a maximum
of 30 epochs, for all models, while T¨ackstr¨om and
McDonald (2011) report a maximum of 75 epochs.
To assess the impact of fully labeled versus
coarsely labeled data, we took stratified samples with-
out replacement, of sizes 60, 120, and 240 reviews,
from the fully labeled folds and of sizes 15,000 and
143,580 reviews from the coarsely labeled data. On
average each review consists of ten sentences. We
performed 5-fold stratified cross-validation over the
labeled data, while using stratified samples for the
coarsely labeled data. Statistical significance was as-
sessed by a hierachical bootstrap of 95% confidence
intervals, using the technique described by Davison
and Hinkley (1997).
</bodyText>
<subsectionHeader confidence="0.976255">
3.1 Results and analysis
</subsectionHeader>
<bodyText confidence="0.999010620689655">
Table 1 lists sentence-level accuracy along with 95%
confidence interval for all tested models. We first
note that the interpolated model dominates all other
models in terms of accuracy. While the cascaded
model requires both large amounts of fully labeled
and coarsely labeled data, the interpolated model
is able to take advantage of both types of data on
its own and jointly. Still, by comparing the fully
supervised and the coarsely supervised models, the
superior impact of fully labeled over coarsely labeled
data is evident. As can be seen in Figure 2, when
all data is used, the cascaded model outperforms the
interpolated model for some recall values, and vice
versa, while both models dominate the supervised
approach for the full range of recall values.
As discussed earlier, and confirmed by Table 2,
the coarse-grained model only performs well on the
predominant sentence-level categories for each docu-
ment category. The supervised model handles nega-
tive and neutral sentences well, but performs poorly
on positive sentences even in positive documents.
The interpolated model, while still better at capturing
the predominant category, does a better job overall.
These results are with a maximum of 30 training
iterations. Preliminary experiments with a maximum
of 75 iterations indicate that all models gain from
more iterations; this seems to be especially true for
the supervised model and for the cascaded model
with less amount of course-grained data.
</bodyText>
<page confidence="0.990542">
572
</page>
<table confidence="0.979138166666667">
|DC |= 15,000 |DC |= 143,580
|DF |= 60 |DF |= 120 |DF |= 240 |DF |= 60 |DF  |= 120 |DF  |= 240
FineToCoarse 49.3 (-1.3, 1.4) 53.4 (-1.8, 1.7) 54.6 (-3.6, 3.8) 49.3 (-1.3, 1.4) 53.4 (-1.8, 1.7) 54.6 (-3.6, 3.8)
Coarse 49.6 (-1.5, 1.8) 49.6 (-1.5, 1.8) 49.6 (-1.5, 1.8) 53.5 (-1.2, 1.4) 53.5 (-1.2, 1.4) 53.5 (-1.2, 1.4)
Cascaded 39.7 (-6.8, 5.7) 45.4 (-3.1, 2.9) 42.6 (-6.5, 6.5) 55.6 (-2.9, 2.7) 55.0 (-3.2, 3.4) 56.8 (-3.8, 3.6)
Interpolated 54.3 (-1.4, 1.4) 55.0 (-1.7, 1.6) 57.5 (-4.1, 5.2) 56.0 (-2.4, 2.1) 54.5 (-2.9, 2.8) 59.1 (-2.8, 3.4)
</table>
<tableCaption confidence="0.9773445">
Table 1: Sentence level results for varying numbers of fully labeled (DF) and coarsely labeled (DC) reviews. Bold:
significantly better than the FineToCoarse model according to a hierarchical bootstrapped confidence interval, p &lt; 0.05.
</tableCaption>
<figure confidence="0.992259485714285">
POS sentences NEG sentences
Precision
100
90
80
60
40
30
70
50
20
10
0
Precision
100
90
80
60
40
30
70
50
20
10
0
FineToCoarse
Cascaded
Interpolated
FineToCoarse
Cascaded
Interpolated
0 10 20 30 40 50 60 70 80 90 100
Recall
0 10 20 30 40 50 60 70 80 90 100
Recall
</figure>
<sectionHeader confidence="0.885592" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999263634408602">
Arvind Agarwal and Hal Daum´e. 2009. Exponential
family hybrid semi-supervised learning. In Proceed-
ings of the International Jont conference on Artifical
Intelligence (IJCAI).
Anthony C. Davison and David V. Hinkley. 1997. Boot-
strap Methods and Their Applications. Cambridge Se-
ries in Statistical and Probabilistic Mathematics. Cam-
bridge University Press, Cambridge, UK.
Andrea Esuli and Fabrizio Sebastiani. 2009. SentiWord-
Net: A publicly available lexical resource for opinion
mining. In Proceedings of the Language Resource and
Evaluation Conference (LREC).
Soo-Min Kim and Eduard Hovy. 2004. Determining
the sentiment of opinions. In Proceedings of the In-
ternational Conference on Computational Linguistics
(COLING).
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In Pro-
ceedings of the International Conference on Machine
Learning (ICML).
Julia A. Lasserre, Christopher M. Bishop, and Thomas P.
Minka. 2006. Principled hybrids of generative and
discriminative models. In Proceedings of the IEEE
Computer Society Conference on Computer Vision and
Pattern Recognition (CVPR).
Chenghua Lin and Yulan He. 2009. Joint sentiment/topic
model for sentiment analysis. In Proceeding of the Con-
ference on Information and Knowledge Management
(CIKM).
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeff Reynar. 2007. Structured models for
fine-to-coarse sentiment analysis. In Proceedings of
the Annual Conference of the Association for Computa-
tional Linguistics (ACL).
Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. 2007.
Topic sentiment mixture: modeling facets and opin-
ions in weblogs. In Proceedings of the International
Conference on World Wide Web (WWW).
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency Tree-based Sentiment Classification
using CRFs with Hidden Variables. In Proceedings of
the North American Chapter of the Association for
Computational Linguistics (NAACL).
Bo Pang and Lillian Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In Proceedings of the Associ-
ation for Computational Linguistics (ACL).
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Now Publishers.
Ariadna Quattoni, Sybor Wang, Louis-Philippe Morency,
Michael Collins, and Trevor Darrell. 2007. Hidden
conditional random fields. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceedings
of the European Chapter of the Association for Compu-
tational Linguistics (EACL).
Christina Sauper, Aria Haghighi, and Regina Barzilay.
2010. Incorporating content structure into text analy-
sis applications. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Jun Suzuki, Akinori Fujino, and Hideki Isozaki. 2007.
Semi-supervised structured output learning based on
a hybrid generative and discriminative approach. In
Porceedings of the Conference on Emipirical Methods
in Natural Language Processing (EMNLP).
Oscar T¨ackstr¨om and Ryan McDonald. 2011. Discov-
ering fine-grained sentiment with latent variable struc-
tured prediction models. In Proceedings of the Euro-
pean Conference on Information Retrieval (ECIR).
Ivan Titov and Ryan McDonald. 2008. Modeling online
reviews with multi-grain topic models. In Proceedings
of the Annual World Wide Web Conference (WWW).
Peter Turney. 2002. Thumbs up or thumbs down? Senti-
ment orientation applied to unsupervised classification
of reviews. In Proceedings of the Annual Conference of
the Association for Computational Linguistics (ACL).
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-
nan, and Ryan McDonald. 2010. The viability of
web-derived polarity lexicons. In Proceedings of the
North American Chapter of the Association for Compu-
tational Linguistics (NAACL).
Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.
Annotating expressions of opinions and emotions in
language. In Language Resources and Evaluation
(LREC).
Ainur Yessenalina, Yisong Yue, and Claire Cardie. 2010.
Multi-level structured models for document-level senti-
ment classification. In Proceedings of the Conference
on Empirical Methods in Natural Language Processing
(EMNLP).
</reference>
<page confidence="0.998226">
574
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.170301">
<title confidence="0.998285">Semi-supervised latent variable models for sentence-level sentiment analysis</title>
<author confidence="0.757145">Oscar T¨ackstr¨om Ryan McDonald SICS</author>
<author confidence="0.757145">Kista Uppsala University</author>
<author confidence="0.757145">Uppsala Google</author>
<author confidence="0.757145">New York Inc</author>
<email confidence="0.992006">oscar@sics.seryanmcd@google.com</email>
<abstract confidence="0.994584353591161">We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis – an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but T¨ackstr¨om and McDonald (2011) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and 569 of the 49th Annual Meeting of the Association for Computational pages 569–574, Oregon, June 19-24, 2011. Association for Computational Linguistics · · · · ······ ··· ······ Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences observed. Note that there are no factors connecting the document node, with the input nodes, so that the variables, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries a document consisting of = with a document–sentence-sequence pair de- = Let = random – the document level sentiment, and the of sentence level sentiment, = are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. In what follows, we assume that we have access to two training sets: a small set of fully labeled inand a large set of labeled instances j we assume that and all take valin We focus on structured conditional models in the exponential family, with the standard parametrization { � = exp − is a parameter vector, is a vector valued feature function that factors according the graph structure outlined in Figure 1, and the function. This class of models is as conditional random fields (Lafferty et al., 2001), when all variables are observed, and as conditional random fields (Quattoni et al., 2007), when only a subset of the variables are observed. 1.2 The fully supervised fine-to-coarse model McDonald et al. (2007) introduced a fully supervised model in which predictions of coarse-grained (document) and fine-grained (sentence) sentiment are learned and inferred jointly. They showed that learning both levels jointly improved performance at both levels, compared to learning each level individually, as well as to using a cascaded model in which the predictions at one level are used as input to the other. 1a outlines the factor graph of the corre- 570 conditional random parameters, of this model can be estimated from the set of labeled data, by maximizing the joint conditional likelihood function 2 the variance of the that a concave function and consequently its unique maximum can be found by gradient based optimization techniques. 1.3 Latent variables for coarse supervision Recently, T¨ackstr¨om and McDonald (2011) showed that fine-grained sentiment can be learned from coarse-grained supervision alone. Specifically, they a with the same structure as that in Figure 1a, but with sentence labels treated as latent variables. The factor graph corresponding to this model is outlined in Figure 1b. The fully supervised model might benefit from facthat directly connect the document variable, the inputs However, as argued by T¨ackstr¨om and McDonald (2011), when only document-level is available, the document variable, be independent of the input, conditioned the latent variables, This prohibits the model from bypassing the latent variables, which is crucial, since we seek to improve the sentence-level predictions, rather than the document-level predictions. parameters, of this model can be estifrom the set of coarsely labeled data, by maximizing the marginalized conditional likelihood function 2 C where the marginalization is over all possible se-</abstract>
<intro confidence="0.591947">of latent sentence label assignments</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Arvind Agarwal</author>
<author>Hal Daum´e</author>
</authors>
<title>Exponential family hybrid semi-supervised learning.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Jont conference on Artifical Intelligence (IJCAI).</booktitle>
<marker>Agarwal, Daum´e, 2009</marker>
<rawString>Arvind Agarwal and Hal Daum´e. 2009. Exponential family hybrid semi-supervised learning. In Proceedings of the International Jont conference on Artifical Intelligence (IJCAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony C Davison</author>
<author>David V Hinkley</author>
</authors>
<title>Bootstrap Methods and Their Applications.</title>
<date>1997</date>
<booktitle>Cambridge Series in Statistical and Probabilistic Mathematics.</booktitle>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="14689" citStr="Davison and Hinkley (1997)" startWordPosition="2304" endWordPosition="2307">(2011) report a maximum of 75 epochs. To assess the impact of fully labeled versus coarsely labeled data, we took stratified samples without replacement, of sizes 60, 120, and 240 reviews, from the fully labeled folds and of sizes 15,000 and 143,580 reviews from the coarsely labeled data. On average each review consists of ten sentences. We performed 5-fold stratified cross-validation over the labeled data, while using stratified samples for the coarsely labeled data. Statistical significance was assessed by a hierachical bootstrap of 95% confidence intervals, using the technique described by Davison and Hinkley (1997). 3.1 Results and analysis Table 1 lists sentence-level accuracy along with 95% confidence interval for all tested models. We first note that the interpolated model dominates all other models in terms of accuracy. While the cascaded model requires both large amounts of fully labeled and coarsely labeled data, the interpolated model is able to take advantage of both types of data on its own and jointly. Still, by comparing the fully supervised and the coarsely supervised models, the superior impact of fully labeled over coarsely labeled data is evident. As can be seen in Figure 2, when all data</context>
</contexts>
<marker>Davison, Hinkley, 1997</marker>
<rawString>Anthony C. Davison and David V. Hinkley. 1997. Bootstrap Methods and Their Applications. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the Language Resource and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="5616" citStr="Esuli and Sebastiani, 2009" startWordPosition="833" endWordPosition="836">generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)ni=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 – the document level sentiment, yd, and the sequence of sentence level sentiment, ys = (ysi )ni=1. 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. In what follows, we assume that we have access t</context>
</contexts>
<marker>Esuli, Sebastiani, 2009</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2009. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceedings of the Language Resource and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="5588" citStr="Kim and Hovy, 2004" startWordPosition="829" endWordPosition="832">is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)ni=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 – the document level sentiment, yd, and the sequence of sentence level sentiment, ys = (ysi )ni=1. 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. In what follows, we </context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="6886" citStr="Lafferty et al., 2001" startWordPosition="1058" endWordPosition="1061">d instances, DF = {(dj,ydj)}mf j=1, and a large set of coarsely labeled instances DC = {(dj, yd j )}mf +m� j=mf +1. Furthermore, we assume that yd and all ysi take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization { � pθ(yd, ys�s) = exp (φ(yd, ys, s), θ) − Aθ(s) , where θ E Rn is a parameter vector, φ(·) E Rn is a vector valued feature function that factors according to the graph structure outlined in Figure 1, and Aθ is the log-partition function. This class of models is known as conditional random fields (CRFs) (Lafferty et al., 2001), when all variables are observed, and as hidden conditional random fields (HCRFs) (Quattoni et al., 2007), when only a subset of the variables are observed. 1.2 The fully supervised fine-to-coarse model McDonald et al. (2007) introduced a fully supervised model in which predictions of coarse-grained (document) and fine-grained (sentence) sentiment are learned and inferred jointly. They showed that learning both levels jointly improved performance at both levels, compared to learning each level individually, as well as to using a cascaded model in which the predictions at one level are used as</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia A Lasserre</author>
<author>Christopher M Bishop</author>
<author>Thomas P Minka</author>
</authors>
<title>Principled hybrids of generative and discriminative models.</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR).</booktitle>
<contexts>
<context position="12494" citStr="Lasserre et al., 2006" startWordPosition="1964" endWordPosition="1967">c gradient ascent with learning rate q. At each step we select a fully labeled instance, (dj, ydj) E DF, with probability A and a coarsely labeled instance, (dj, ydj) E DC, with probability (1 − A). We then update the parameters, BI, according to the gradients aLF and aLC, respectively. In principle we could use different learning rates qF and qC as well as different prior variances Q2F and Q2C, but in what follows we set them equal. Since we are interpolating conditional models, we need at least partial observations of each instance. Methods for blending discriminative and generative models (Lasserre et al., 2006; Suzuki et al., 2007; Agarwal and Daum´e, 2009; Sauper et al., 2010), would enable incorporation of completely unlabeled data as well. It is straightforward to extend the proposed model along these lines, however, in practice coarsely labeled sentiment data is so abundant on the web (e.g., rated consumer reviews) that incorporating completely unlabeled data seems superfluous. Furthermore, using conditional models with shared parameters throughout allows for rich overlapping features, while maintaining simple and efficient inference and estimation. 3 Experiments For the following experiments, </context>
</contexts>
<marker>Lasserre, Bishop, Minka, 2006</marker>
<rawString>Julia A. Lasserre, Christopher M. Bishop, and Thomas P. Minka. 2006. Principled hybrids of generative and discriminative models. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceeding of the Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="4670" citStr="Lin and He, 2009" startWordPosition="687" endWordPosition="690">tics a) yd · · ·ys ys ys · · · i−1 i i+1 ··· si−1 si si+1 ··· b) yd ··· ys ys ys ··· i−1 i i+1 ··· si−1 si si+1 ··· Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (20</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceeding of the Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeff Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="2277" citStr="McDonald et al. (2007)" startWordPosition="317" endWordPosition="320">small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking</context>
<context position="7112" citStr="McDonald et al. (2007)" startWordPosition="1093" endWordPosition="1096">models in the exponential family, with the standard parametrization { � pθ(yd, ys�s) = exp (φ(yd, ys, s), θ) − Aθ(s) , where θ E Rn is a parameter vector, φ(·) E Rn is a vector valued feature function that factors according to the graph structure outlined in Figure 1, and Aθ is the log-partition function. This class of models is known as conditional random fields (CRFs) (Lafferty et al., 2001), when all variables are observed, and as hidden conditional random fields (HCRFs) (Quattoni et al., 2007), when only a subset of the variables are observed. 1.2 The fully supervised fine-to-coarse model McDonald et al. (2007) introduced a fully supervised model in which predictions of coarse-grained (document) and fine-grained (sentence) sentiment are learned and inferred jointly. They showed that learning both levels jointly improved performance at both levels, compared to learning each level individually, as well as to using a cascaded model in which the predictions at one level are used as input to the other. Figure 1a outlines the factor graph of the corre570 sponding conditional random field.2 The parameters, θF, of this model can be estimated from the set of fully labeled data, DF, by maximizing the joint co</context>
<context position="9452" citStr="McDonald et al. (2007)" startWordPosition="1462" endWordPosition="1466">ment-level predictions. The parameters, θC, of this model can be estimated from the set of coarsely labeled data, DC, by maximizing the marginalized conditional likelihood function 2 pθC(ydj, ys|sj)− k��2I C where the marginalization is over all possible sequences of latent sentence label assignments ys. Due to the introduction of latent variables, the marginal likelihood function is non-concave and thus there are no guarantees of global optimality, however, we can still use a gradient based optimization technique to find a local maximum. 2Figure 1a differs slightly from the model employed by McDonald et al. (2007), where they had factors connecting the document label yd with each input si as well. 2 Combining coarse and full supervision The fully supervised and the partially supervised models both have their merits. The former requires an expensive and laborious process of manual annotation, while the latter can be used with readily available document labels, such as review star ratings. The latter, however, has its shortcomings in that the coarse-grained sentiment signal is less informative compared to a fine-grained signal. Thus, in order to get the best of both worlds, we would like to combine the m</context>
<context position="13326" citStr="McDonald et al. (2007)" startWordPosition="2089" endWordPosition="2092">ver, in practice coarsely labeled sentiment data is so abundant on the web (e.g., rated consumer reviews) that incorporating completely unlabeled data seems superfluous. Furthermore, using conditional models with shared parameters throughout allows for rich overlapping features, while maintaining simple and efficient inference and estimation. 3 Experiments For the following experiments, we used the same data set and a comparable experimental setup to that of T¨ackstr¨om and McDonald (2011).3 We compare the two proposed hybrid models (Cascaded and Interpolated) to the fully supervised model of McDonald et al. (2007) (FineToCoarse) as well as to the soft variant of the coarsely supervised model of T¨ackstr¨om and McDonald (2011) (Coarse). The learning rate was fixed to q = 0.001, while we tuned the prior variances, Q2, and the number of epochs for each model. When sampling according to A during optimization of LI(BI), we cycle through DF and DC deterministically, but shuffle these sets between epochs. Due to time constraints, we fixed the interpolation factor to A = 0.1, but tuning this could 3The annotated test data can be downloaded from http://www.sics.se/people/oscar/datasets. potentially improve the </context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeff Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
<author>C X Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on World Wide Web (WWW).</booktitle>
<contexts>
<context position="3841" citStr="Mei et al., 2007" startWordPosition="548" endWordPosition="551">ly, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and 569 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 569–574, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics a) yd · · ·ys ys ys · · · i−1 i i+1 ··· si−1 si si+1 ··· b) yd ··· ys ys ys ··· i−1 i i+1 ··· si−1 si si+1 ··· Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are </context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the International Conference on World Wide Web (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency Tree-based Sentiment Classification using CRFs with Hidden Variables.</title>
<date>2010</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="2575" citStr="Nakagawa et al. (2010)" startWordPosition="357" endWordPosition="360">ls that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but T¨ackstr¨om and McDonald (2011) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite </context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency Tree-based Sentiment Classification using CRFs with Hidden Variables. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="2174" citStr="Pang and Lee (2004)" startWordPosition="300" endWordPosition="303">ision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative c</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<publisher>Now Publishers.</publisher>
<contexts>
<context position="1187" citStr="Pang and Lee, 2008" startWordPosition="160" endWordPosition="163">l model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis – an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve o</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Now Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariadna Quattoni</author>
<author>Sybor Wang</author>
<author>Louis-Philippe Morency</author>
<author>Michael Collins</author>
<author>Trevor Darrell</author>
</authors>
<title>Hidden conditional random fields.</title>
<date>2007</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence.</journal>
<contexts>
<context position="6992" citStr="Quattoni et al., 2007" startWordPosition="1074" endWordPosition="1077"> j=mf +1. Furthermore, we assume that yd and all ysi take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization { � pθ(yd, ys�s) = exp (φ(yd, ys, s), θ) − Aθ(s) , where θ E Rn is a parameter vector, φ(·) E Rn is a vector valued feature function that factors according to the graph structure outlined in Figure 1, and Aθ is the log-partition function. This class of models is known as conditional random fields (CRFs) (Lafferty et al., 2001), when all variables are observed, and as hidden conditional random fields (HCRFs) (Quattoni et al., 2007), when only a subset of the variables are observed. 1.2 The fully supervised fine-to-coarse model McDonald et al. (2007) introduced a fully supervised model in which predictions of coarse-grained (document) and fine-grained (sentence) sentiment are learned and inferred jointly. They showed that learning both levels jointly improved performance at both levels, compared to learning each level individually, as well as to using a cascaded model in which the predictions at one level are used as input to the other. Figure 1a outlines the factor graph of the corre570 sponding conditional random field</context>
</contexts>
<marker>Quattoni, Wang, Morency, Collins, Darrell, 2007</marker>
<rawString>Ariadna Quattoni, Sybor Wang, Louis-Philippe Morency, Michael Collins, and Trevor Darrell. 2007. Hidden conditional random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semisupervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="5644" citStr="Rao and Ravichandran, 2009" startWordPosition="837" endWordPosition="840">e models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)ni=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 – the document level sentiment, yd, and the sequence of sentence level sentiment, ys = (ysi )ni=1. 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. In what follows, we assume that we have access to two training sets: a small</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Incorporating content structure into text analysis applications.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="2750" citStr="Sauper et al. (2010)" startWordPosition="382" endWordPosition="385"> since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but T¨ackstr¨om and McDonald (2011) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained s</context>
<context position="4965" citStr="Sauper et al. (2010)" startWordPosition="737" endWordPosition="740">on-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2</context>
<context position="12563" citStr="Sauper et al., 2010" startWordPosition="1976" endWordPosition="1979"> labeled instance, (dj, ydj) E DF, with probability A and a coarsely labeled instance, (dj, ydj) E DC, with probability (1 − A). We then update the parameters, BI, according to the gradients aLF and aLC, respectively. In principle we could use different learning rates qF and qC as well as different prior variances Q2F and Q2C, but in what follows we set them equal. Since we are interpolating conditional models, we need at least partial observations of each instance. Methods for blending discriminative and generative models (Lasserre et al., 2006; Suzuki et al., 2007; Agarwal and Daum´e, 2009; Sauper et al., 2010), would enable incorporation of completely unlabeled data as well. It is straightforward to extend the proposed model along these lines, however, in practice coarsely labeled sentiment data is so abundant on the web (e.g., rated consumer reviews) that incorporating completely unlabeled data seems superfluous. Furthermore, using conditional models with shared parameters throughout allows for rich overlapping features, while maintaining simple and efficient inference and estimation. 3 Experiments For the following experiments, we used the same data set and a comparable experimental setup to that</context>
</contexts>
<marker>Sauper, Haghighi, Barzilay, 2010</marker>
<rawString>Christina Sauper, Aria Haghighi, and Regina Barzilay. 2010. Incorporating content structure into text analysis applications. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Akinori Fujino</author>
<author>Hideki Isozaki</author>
</authors>
<title>Semi-supervised structured output learning based on a hybrid generative and discriminative approach.</title>
<date>2007</date>
<booktitle>In Porceedings of the Conference on Emipirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="12515" citStr="Suzuki et al., 2007" startWordPosition="1968" endWordPosition="1971">learning rate q. At each step we select a fully labeled instance, (dj, ydj) E DF, with probability A and a coarsely labeled instance, (dj, ydj) E DC, with probability (1 − A). We then update the parameters, BI, according to the gradients aLF and aLC, respectively. In principle we could use different learning rates qF and qC as well as different prior variances Q2F and Q2C, but in what follows we set them equal. Since we are interpolating conditional models, we need at least partial observations of each instance. Methods for blending discriminative and generative models (Lasserre et al., 2006; Suzuki et al., 2007; Agarwal and Daum´e, 2009; Sauper et al., 2010), would enable incorporation of completely unlabeled data as well. It is straightforward to extend the proposed model along these lines, however, in practice coarsely labeled sentiment data is so abundant on the web (e.g., rated consumer reviews) that incorporating completely unlabeled data seems superfluous. Furthermore, using conditional models with shared parameters throughout allows for rich overlapping features, while maintaining simple and efficient inference and estimation. 3 Experiments For the following experiments, we used the same data</context>
</contexts>
<marker>Suzuki, Fujino, Isozaki, 2007</marker>
<rawString>Jun Suzuki, Akinori Fujino, and Hideki Isozaki. 2007. Semi-supervised structured output learning based on a hybrid generative and discriminative approach. In Porceedings of the Conference on Emipirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
</authors>
<title>Discovering fine-grained sentiment with latent variable structured prediction models.</title>
<date>2011</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval (ECIR).</booktitle>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan McDonald. 2011. Discovering fine-grained sentiment with latent variable structured prediction models. In Proceedings of the European Conference on Information Retrieval (ECIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual World Wide Web Conference (WWW).</booktitle>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of the Annual World Wide Web Conference (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="5568" citStr="Turney, 2002" startWordPosition="827" endWordPosition="828">l. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)ni=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 – the document level sentiment, yd, and the sequence of sentence level sentiment, ys = (ysi )ni=1. 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. </context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews. In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="5670" citStr="Velikovich et al., 2010" startWordPosition="841" endWordPosition="844">tructured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)ni=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 – the document level sentiment, yd, and the sequence of sentence level sentiment, ys = (ysi )ni=1. 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. In what follows, we assume that we have access to two training sets: a small set of fully labeled inst</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of web-derived polarity lexicons. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language.</title>
<date>2005</date>
<booktitle>In Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="1440" citStr="Wiebe et al., 2005" startWordPosition="192" endWordPosition="195">ants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis – an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; and models that use latent variables to learn unobserved phenomena from that which can be obser</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. In Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Yisong Yue</author>
<author>Claire Cardie</author>
</authors>
<title>Multi-level structured models for document-level sentiment classification.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="2453" citStr="Yessenalina et al. (2010)" startWordPosition="340" endWordPosition="343"> Our work combines two strands of research: models for sentiment analysis that take document structure into account; and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but T¨ackstr¨om and McDonald (2011) showed that latent variables can be used to learn fine-grained </context>
</contexts>
<marker>Yessenalina, Yue, Cardie, 2010</marker>
<rawString>Ainur Yessenalina, Yisong Yue, and Claire Cardie. 2010. Multi-level structured models for document-level sentiment classification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>