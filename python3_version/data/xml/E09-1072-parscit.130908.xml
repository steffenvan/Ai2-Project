<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.982769">
Empirical evaluations of animacy annotation
</title>
<author confidence="0.995121">
Lilja Øvrelid
</author>
<affiliation confidence="0.9972695">
Department of Linguistics
University of Potsdam
</affiliation>
<address confidence="0.485788">
Germany
</address>
<email confidence="0.975812">
lilja@ling.uni-potsdam.de
</email>
<sectionHeader confidence="0.981506" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999545">
This article presents empirical evaluations
of aspects of annotation for the linguis-
tic property of animacy in Swedish, rang-
ing from manual human annotation, auto-
matic classification and, finally, an exter-
nal evaluation in the task of syntactic pars-
ing. We show that a treatment of animacy
as a lexical semantic property of noun
types enables generalization over distri-
butional properties of these nouns which
proves beneficial in automatic classifica-
tion and furthermore gives significant im-
provements in terms of parsing accuracy
for Swedish, compared to a state-of-the-
art baseline parser with gold standard ani-
macy information.
</bodyText>
<sectionHeader confidence="0.995155" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986222142857143">
The property of animacy influences linguistic phe-
nomena in a range of different languages, such
as case marking (Aissen, 2003) and argument re-
alization (Bresnan et al., 2005; de Swart et al.,
2008), and has been shown to constitute an im-
portant factor in the production and comprehen-
sion of syntactic structure (Branigan et al., 2008;
Weckerly and Kutas, 1999).1 In computational
linguistic work, animacy has been shown to pro-
vide important information in anaphora resolution
(Or˘asan and Evans, 2007), argument disambigua-
tion (Dell’Orletta et al., 2005) and syntactic pars-
ing in general (Øvrelid and Nivre, 2007).
The dimension of animacy roughly distin-
guishes between entities which are alive and en-
tities which are not, however, other distinctions
1Parts of the research reported in this paper has been sup-
ported by the Deutsche Forschungsgemeinschaft (DFG, Son-
derforschungsbereich 632, project D4).
are also relevant and the animacy dimension is of-
ten viewed as a continuum ranging from humans
to inanimate objects. Following Silverstein (1976)
several animacy hierarchies have been proposed in
typological studies, focusing on the linguistic cat-
egory of animacy, i.e., the distinctions which are
relevant for linguistic phenomena. An example of
an animacy hierarchy, taken from (Aissen, 2003),
is provided in (1):
</bodyText>
<listItem confidence="0.973865">
(1) Human &gt; Animate &gt; Inanimate
</listItem>
<bodyText confidence="0.999940777777778">
Clearly, non-human animates, like animals, are
not less animate than humans in a biological sense,
however, humans and animals show differing lin-
guistic behaviour.
Empirical studies of animacy require human an-
notation efforts, and, in particular, a well-defined
annotation task. However, annotation studies of
animacy differ distinctly in their treatment of ani-
macy as a type or token-level phenomenon, as well
as in terms of granularity of categories. The use
of the annotated data as a computational resource
furthermore poses requirements on the annotation
which do not necessarily agree with more theo-
retical considerations. Methods for the induction
of animacy information for use in practical appli-
cations require the resolution of issues of level of
representation, as well as granularity.
This article addresses these issues through em-
pirical and experimental evaluation. We present
an in-depth study of a manually annotated data
set which indicates that animacy may be treated
as a lexical semantic property at the type level.
We then evaluate this proposal through supervised
machine learning of animacy information and fo-
cus on an in-depth error analysis of the resulting
classifier, addressing issues of granularity of the
animacy dimension. Finally, the automatically an-
</bodyText>
<note confidence="0.9842215">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 630–638,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.832011">
630
</page>
<bodyText confidence="0.99978725">
notated data set is employed in order to train a syn-
tactic parser and we investigate the effect of the an-
imacy information and contrast the automatically
acquired features with gold standard ones.
The rest of the article is structured as follows. In
section 2, we briefly discuss annotation schemes
for animacy, the annotation strategies and cate-
gories proposed there. We go on to describe anno-
tation for the binary distinction of ‘human refer-
ence’ found in a Swedish dependency treebank in
section 3 and we perform an evaluation of the con-
sistency of the human annotation in terms of lin-
guistic level. In section 4, we present experiments
in lexical acquisition of animacy based on mor-
phosyntactic features extracted from a consider-
ably larger corpus. Section 5 presents experiments
with the acquired animacy information applied in
the data-driven dependency parsing of Swedish.
Finally, section 6 concludes the article and pro-
vides some suggestions for future research.
</bodyText>
<sectionHeader confidence="0.91066" genericHeader="method">
2 Animacy annotation
</sectionHeader>
<bodyText confidence="0.992484065217392">
Annotation for animacy is not a common compo-
nent of corpora or treebanks. However, following
from the theoretical interest in the property of an-
imacy, there have been some initiatives directed at
animacy annotation of corpus data.
Corpus studies of animacy (Yamamoto, 1999;
Dahl and Fraurud, 1996) have made use of an-
notated data, however they differ in the extent to
which the annotation has been explicitly formu-
lated as an annotation scheme. The annotation
study presented in Zaenen et. al. (2004) makes use
of a coding manual designed for a project study-
ing genitive modification (Garretson et al., 2004)
and presents an explicit annotation scheme for an-
imacy, illustrated by figure 1. The main class dis-
tinction for animacy is three-way, distinguishing
Human, Other animate and Inanimate, with sub-
classes under two of the main classes. The ‘Other
animate’ class further distinguishes Organizations
and Animals. Within the group of inanimates, fur-
ther distinctions are made between concrete and
non-concrete inanimate, as well as time and place
nominals.2
The annotation scheme described in Zaenen et.
al. (2004) annotates the markables according to
2The fact that the study focuses on genitival modification
has clearly influenced the categories distinguished, as these
are all distinctions which have been claimed to influence the
choice of genitive construction. For instance, temporal nouns
are frequent in genitive constructions, unlike the other inani-
mate nouns.
the animacy of their referent in the particular con-
text. Animacy is thus treated as a token level
property, however, has also been proposed as a
lexical semantic property of nouns (Yamamoto,
1999). The indirect encoding of animacy in lex-
ical resources, such as WordNet (Fellbaum, 1998)
can also be seen as treating animacy as a type-
level property. We may thus distinguish between a
purely type level annotation strategy and a purely
token level one. Type level properties hold for lex-
emes and are context-independent, i.e., indepen-
dent of the particular linguistic context, whereas
token-level properties are determined in context
and hold for referring expressions, rather than lex-
emes.
</bodyText>
<sectionHeader confidence="0.755218" genericHeader="method">
3 Human reference in Swedish
</sectionHeader>
<bodyText confidence="0.999912555555555">
Talbanken05 is a Swedish treebank which was
created in the 1970’s and which has recently
been converted to dependency format (Nivre et
al., 2006b) and made freely available. The writ-
ten sections of the treebank consist of profes-
sional prose and student essays and amount to
197,123 running tokens, spread over 11,431 sen-
tences. Figure 2 shows the labeled dependency
graph of example (2), taken from Talbanken05.
</bodyText>
<figure confidence="0.517831125">
(2) Samma erfarenhet giorde engelsm¨annen
same experience made englishmen-DEF
‘The same experience, the Englishmen had’
DT OO ROOT SS
_ Samma erfarenhet gjorde engelsmannen
_ PO NN VV NN
KP PT DD|HH
_ _
</figure>
<figureCaption confidence="0.7214475">
Figure 2: Dependency representation of example
(2) from Talbanken05.
</figureCaption>
<bodyText confidence="0.999924153846154">
In addition to information on part-of-speech, de-
pendency head and relation, and various mor-
phosyntactic properties such as definiteness, the
annotation expresses a distinction for nominal el-
ements between reference to human and non-
human. The annotation manual (Teleman, 1974)
states that a markable should be tagged as human
(HH) if it may be replaced by the interrogative pro-
noun vem ‘who’ and be referred to by the personal
pronouns han ‘he’ or hon ‘she’.
There are clear similarities between the anno-
tation for human reference found in Talbanken05
and the annotation scheme for animacy discussed
</bodyText>
<figure confidence="0.957483444444445">
631
HUM Other Inanimate
animate
ORG
TIME
PLACE
ANIM
CONC
NCONC
</figure>
<figureCaption confidence="0.999974">
Figure 1: Animacy classification scheme (Zaenen et al., 2004).
</figureCaption>
<bodyText confidence="0.9999779">
above. The human/non-human contrast forms the
central distinction in the animacy dimension and,
in this respect, the annotation schemes do not con-
flict. If we compare the annotation found in Tal-
banken05 with the annotation proposed in Zaenen
et. al. (2004), we find that the schemes differ pri-
marily in the granularity of classes distinguished.
The main source of variation in class distinctions
consists in the annotation of collective nouns, in-
cluding organizations, as well as animals.
</bodyText>
<subsectionHeader confidence="0.999943">
3.1 Level of annotation
</subsectionHeader>
<bodyText confidence="0.999948525">
We distinguished above between type and token
level annotation strategies, where a type level an-
notation strategy entails that an element consis-
tently be assigned to only one class. A token level
strategy, in contrast, does not impose this restric-
tion on the annotation and class assignment may
vary depending on the specific context. Garretson
et. al (2004) propose a token level annotation strat-
egy and state that “when coding for animacy [... ]
we are not considering the nominal per se (e.g., the
word ‘church’), but rather the entity that is the ref-
erent of that nominal (e.g. some particular thing in
the real world)”. This indicates that for all possible
markables, a referent should be determinable.
The brief instruction with respect to annotation
for human reference in the annotation manual for
Talbanken05 (Teleman, 1974, 223) gives leeway
for interpretation in the annotation and does not
clearly state that it should be based on token level
reference in context. It may thus be interesting
to examine the extent to which this manual an-
notation is consistent across lexemes or whether
we observe variation. We manually examine the
intersection of the two classes of noun lemmas
in the written sections of Talbanken, i.e., the set
of nouns which have been assigned both classes
by the annotators. It contains 82 noun lemmas,
which corresponds to only 1.1% of the total num-
ber of noun lemmas in the treebank (7554 lem-
mas all together). After a manual inspection of
the intersective elements along with their linguis-
tic contexts, we may group the nouns which were
assigned to both classes, into the following cate-
gories:that ‘HH’ is the tag for
Abstract nouns Nouns with underspecified or
vague type level properties with respect to ani-
macy, such as quantifying nouns, e.g. h¨alft ‘half’,
miljon ‘million’, as well as nouns which may be
employed with varying animacy, e.g. element ‘el-
ement’, part ‘party’, as in (3) and (4):
</bodyText>
<listItem confidence="0.983134833333333">
(3) ...ocks˚a den andra partenxx st˚ar utanf¨or
... also the other party-DEF stands outside
‘... also the other party is left outside’
(4) I ett f¨orh˚allande ¨ar aldrig b¨agge parter
in a relationship are never both parties
lika starka
</listItem>
<bodyText confidence="0.885487904761905">
same strong
‘In a relationship, both parties are never equally
strong’
We also find that nouns which denote abstract con-
cepts regarding humans show variable annotation,
e.g. individ ‘individual’, adressat ‘addressee’,
medlem ‘member’, kandidat ‘candidate’, repre-
sentant ‘representative’, auktoritet ‘authority’
Reference shifting contexts These are nouns
whose type level animacy is clear but which are
employed in a specific context which shifts their
reference. Examples include metonymic usage of
nouns, as in (5) and nouns occurring in derefer-
encing constructions, such as predicative construc-
tions (6), titles (7) and idioms (8):
(5) ... daghemmensxx otillr¨ackliga resurser
...kindergarten-DEF.GEN inadequate resources
‘... the kindergarten’s inadequate resources’
(6) ... f¨or att bli en bra soldat
...for to become a good soldier
‘... in order to become a good soldier’
</bodyText>
<listItem confidence="0.7384026">
(7) ... menar biskop Hellsten
...thinks bishop Hellsten
‘thinks bishop Hellsten’
(8) ta studenten
take student-DEF
</listItem>
<bodyText confidence="0.436466">
‘graduate from highschool (lit. take the student)’
</bodyText>
<page confidence="0.579606">
632
</page>
<bodyText confidence="0.999974636363636">
It is interesting to note that the main variation in
annotation stems precisely from difficulties in de-
termining reference, either due to bleak type level
properties such as for the abstract nouns, or due to
properties of the context, as in the reference shift-
ing constructions. The small amount of variation
in the human annotation for animacy clearly sup-
ports a type-level approach to animacy, however,
underline the influence of the linguistic context on
the conception of animacy, as noted in the litera-
ture (Zaenen et al., 2004; Rosenbach, 2008).
</bodyText>
<sectionHeader confidence="0.955012" genericHeader="method">
4 Lexical acquisition of animacy
</sectionHeader>
<bodyText confidence="0.999002564102564">
Even though knowledge about the animacy of a
noun clearly has some interesting implications, lit-
tle work has been done within the field of lexical
acquisition in order to automatically acquire ani-
macy information. Or˘asan and Evans (2007) make
use of hyponym-relations taken from the Word-
Net resource in order to classify animate referents.
However, such a method is clearly restricted to
languages for which large scale lexical resources,
such as the WordNet, are available. The task of
animacy classification bears some resemblance to
the task of named entity recognition (NER) which
usually makes reference to a ‘person’ class. How-
ever, whereas most NER systems make extensive
use of orthographic, morphological or contextual
clues (titles, suffixes) and gazetteers, animacy for
nouns is not signaled overtly in the same way.
Following a strategy in line with work on
verb classification (Merlo and Stevenson, 2001;
Stevenson and Joanis, 2003), we set out to clas-
sify common noun lemmas based on their mor-
phosyntactic distribution in a considerably larger
corpus. This is thus equivalent to treatment of
animacy as a lexical semantic property and the
classification strategy is based on generalization
of morphosyntactic behaviour of common nouns
over large quantities of data. Due to the small size
of the Talbanken05 treebank and the small amount
of variation, this strategy was pursued for the ac-
quisition of animacy information.
In the animacy classification of common nouns
we exploit well-documented correlations between
morphosyntactic realization and semantic proper-
ties of nouns. For instance, animate nouns tend to
be realized as agentive subjects, inanimate nouns
do not (Dahl and Fraurud, 1996). Animate nouns
make good ‘possessors’, whereas inanimate nouns
are more likely ‘possessees’ (Rosenbach, 2008).
Table 1 presents an overview of the animacy data
</bodyText>
<table confidence="0.98483425">
Class Types Tokens covered
Animate 644 6010
Inanimate 6910 34822
Total 7554 40832
</table>
<tableCaption confidence="0.997867">
Table 1: The animacy data set from Talbanken05;
</tableCaption>
<bodyText confidence="0.960399333333333">
number of noun lemmas (Types) and tokens in
each class.
for common nouns in Talbanken05. It is clear that
the data is highly skewed towards the non-human
class, which accounts for 91.5% of the type in-
stances. For classification we organize the data
into accumulated frequency bins, which include
all nouns with frequencies above a certain thresh-
old. We here approximate the class of ‘animate’
to ‘human’ and the class of ‘inanimate’ to ‘non-
human’. Intersective elements, see section 3.1, are
assigned to their majority class.3
</bodyText>
<sectionHeader confidence="0.502328" genericHeader="method">
4.1 Features for animacy classification
</sectionHeader>
<bodyText confidence="0.952540931034483">
We define a feature space, which makes use of
distributional data regarding the general syntactic
properties of a noun, as well as various morpho-
logical properties. It is clear that in order for a
syntactic environment to be relevant for animacy
classification it must be, at least potentially, nom-
inal. We define the nominal potential of a depen-
dency relation as the frequency with which it is
realized by a nominal element (noun or pronoun)
and determine empirically a threshold of .10. The
syntactic and morphological features in the feature
space are presented below:
Syntactic features A feature for each depen-
dency relation with nominal potential: (tran-
sitive) subject (SUBJ), object (OBJ), preposi-
tional complement (PA), root (ROOT)4, ap-
position (APP), conjunct (CC), determiner
(DET), predicative (PRD), complement of
comparative subjunction (UK). We also in-
clude a feature for the head of a genitive mod-
ifier, the so-called ‘possessee’, (GENHD).
Morphological features A feature for each mor-
phological distinction relevant for a noun
3When there is no majority class, i.e. in the case of ties,
the noun is removed from the data set. 12 lemmas were con-
sequently removed.
4Nominal elements may be assigned the root relation of
the dependency graph in sentence fragments which do not
contain a finite verb.
</bodyText>
<page confidence="0.847448">
633
</page>
<bodyText confidence="0.999375083333334">
in Swedish: gender (NEU/UTR), num-
ber (SIN/PLU), definiteness (DEF/IND), case
(NOM/GEN). Also, the part-of-speech tags
distinguish dates (DAT) and quantifying
nouns (SET), e.g. del, rad ‘part, row’, so
these are also included as features.
For extraction of distributional data for the set of
Swedish nouns we make use of the Swedish Pa-
role corpus of 21.5M tokens.5 To facilitate feature
extraction, we part-of-speech tag the corpus and
parse it with MaltParser6, which assigns a depen-
dency analysis.7
</bodyText>
<subsectionHeader confidence="0.921809">
4.2 Experimental methodology
</subsectionHeader>
<bodyText confidence="0.999911260869565">
For machine learning, we make use of the Tilburg
Memory-Based Learner (TiMBL) (Daelemans et
al., 2004).8 Memory-based learning is a super-
vised machine learning method characterized by
a lazy learning algorithm which postpones learn-
ing until classification time, using the k-nearest
neighbor algorithm for the classification of unseen
instances. For animacy classification, the TiMBL
parameters are optimized on a subset of the full
data set.9
For training and testing of the classifiers, we
make use of leave-one-out cross-validation. The
baseline represents assignment of the majority
class (inanimate) to all nouns in the data set. Due
to the skewed distribution of classes, as noted
above, the baseline accuracy is very high, usu-
ally around 90%.Clearly, however, the class-based
measures of precision and recall, as well as the
combined F-score measure are more informative
for these results. The baseline F-score for the ani-
mate class is thus 0, and a main goal is to improve
on the rate of true positives for animates, while
limiting the trade-off in terms of performance for
</bodyText>
<footnote confidence="0.99248">
5Parole is freely available at http://spraakbanken.gu.se
6http://www.maltparser.org
7For part-of-speech tagging, we employ the MaltTagger
</footnote>
<bodyText confidence="0.8383862">
– a HMM part-of-speech tagger for Swedish (Hall, 2003).
For parsing, we employ MaltParser (Nivre et al., 2006a),
a language-independent system for data-driven dependency
parsing , with the pretrained model for Swedish, which has
been trained on the tags output by the tagger.
</bodyText>
<tableCaption confidence="0.659437">
8http://ilk.uvt.nl/software.html
9For parameter optimization we employ the
paramsearch tool, supplied with TiMBL, see
http://ilk.uvt.nl/software.html. Paramsearch implements
a hill climbing search for the optimal settings on iteratively
larger parts of the supplied data. We performed parameter
</tableCaption>
<table confidence="0.965909818181818">
optimization on 20% of the total data set, where we balanced
the data with respect to frequency. The resulting settings are
k = 11, GainRatio feature weighting and Inverse Linear (IL)
class voting weights.
Bin Instances Baseline MBL SVM
&gt;1000 291 89.3 97.3 95.2
&gt;500 597 88.9 97.3 97.1
&gt;100 1668 90.5 96.8 96.9
&gt;50 2278 90.6 96.1 96.0
&gt;10 3786 90.8 95.4 95.1
&gt;0 5481 91.3 93.9 93.7
</table>
<tableCaption confidence="0.862414333333333">
Table 2: Accuracy for MBL and SVM classifiers
on Talbanken05 nouns in accumulated frequency
bins by Parole frequency.
</tableCaption>
<bodyText confidence="0.9986624">
the majority class of inanimates, which start out
with F-scores approaching 100. For calculation of
the statistical significance of differences in the per-
formance of classifiers tested on the same data set,
McNemar’s test (Dietterich, 1998) is employed.
</bodyText>
<subsectionHeader confidence="0.846011">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999977928571428">
Column four (MBL) in table 2 shows the accu-
racy obtained with all features in the general fea-
ture space. We observe a clear improvement on
all data sets (p&lt;.0001), compared to the respec-
tive baselines. As we recall, the data sets are suc-
cessively larger, hence it seems fair to conclude
that the size of the data set partially counteracts
the lower frequency of the test nouns. It is not
surprising, however, that a method based on dis-
tributional features suffers when the absolute fre-
quencies approach 1. We obtain results for ani-
macy classification, ranging from 97.3% accuracy
to 93.9% depending on the sparsity of the data.
With an absolute frequency threshold of 10, we
obtain an accuracy of 95.4%, which constitutes a
50% reduction of error rate.
Table 3 presents the experimental results rela-
tive to class. We find that classification of the inan-
imate class is quite stable throughout the experi-
ments, whereas the classification of the minority
class of animate nouns suffers from sparse data. It
is an important point, however, that it is largely re-
call for the animate class which goes down with
increased sparseness, whereas precision remains
quite stable. All of these properties are clearly ad-
vantageous in the application to realistic data sets,
where a more conservative classifier is to be pre-
ferred.
</bodyText>
<subsectionHeader confidence="0.995381">
4.4 Error analysis
</subsectionHeader>
<bodyText confidence="0.998557333333333">
The human reference annotation of the Tal-
banken05 nouns distinguishes only the classes cor-
responding to ‘human’ and ‘inanimate’ along the
</bodyText>
<page confidence="0.782003">
634
</page>
<table confidence="0.99981375">
Animate Inanimate
Precision Recall Fscore Precision Recall Fscore
&gt;1000 89.7 83.9 86.7 98.1 98.8 98.5
&gt;500 89.1 86.4 87.7 98.3 98.7 98.5
&gt;100 87.7 76.6 81.8 97.6 98.9 98.2
&gt;50 85.8 70.2 77.2 97.0 98.9 97.9
&gt;10 81.9 64.0 71.8 96.4 98.6 97.5
&gt;0 75.7 44.9 56.4 94.9 98.6 96.7
</table>
<tableCaption confidence="0.8491075">
Table 3: Precision, recall and F-scores for the two classes in MBL-experiments with a general feature
space.
</tableCaption>
<figure confidence="0.9693255">
&gt;10 nouns
(a) (b) ← classified as
222 125 (a) class animate
49 3390 (b) class inanimate
</figure>
<tableCaption confidence="0.887877">
Table 4: Confusion matrix for the MBL-classifier
</tableCaption>
<bodyText confidence="0.995417">
with a general feature space on the &gt;10 data set
on Talbanken05 nouns.
animacy dimension. An interesting question is
whether the errors show evidence of the gradi-
ence in categories discussed earlier and explic-
itly expressed in the annotation scheme by Zaenen
et.al. (2004) in figure 1. If so, we would expect
erroneously classified inanimate nouns to contain
nouns of intermediate animacy, such as animals
and organizations.
The error analysis examines the performance of
the MBL-classifier employing all features on the
&gt; 10 data set in order to abstract away from the
most serious effects of data sparseness. Table 4
shows a confusion matrix for the classification of
the nouns. If we examine the errors for the inan-
imate class we indeed find evidence of gradience
within this category. The errors contain a group
of nouns referring to animals and other living be-
ings (bacteria, algae), as listed in (9), as well as
one noun referring to an “intelligent machine”, in-
cluded in the intermediate animacy category in Za-
enen et al. (2004). Collective nouns with human
reference and organizations are also found among
the errors, listed in (11). We also find some nouns
among the errors with human denotation, listed in
(12). These are nouns which typically occur in
dereferencing contexts, such as titles, e.g. herr
‘mister’, biskop ‘bishop’ and which were anno-
tated as non-human referring by the human an-
notators.10 Finally, a group of abstract, human-
10In fact, both of these showed variable annotation in the
treebank and were assigned their majority class – inanimate
denoting nouns are also found among the errors, as
listed in (13). In summary, we find that nouns with
gradient animacy properties account for 53.1% of
the errors for the inanimate class.
</bodyText>
<listItem confidence="0.848762">
(9) Animals/living beings:
</listItem>
<bodyText confidence="0.597002">
alg ‘algae’, apa ‘monkey’, bakterie ‘bacteria’, bj¨orn
‘bear’, djur ‘animal’, f˚agel ‘bird’, fladderm¨oss ‘bat’,
myra ‘ant’, m˚as ‘seagull’, parasit ‘parasite’
</bodyText>
<listItem confidence="0.789478333333333">
(10) Intelligent machines:
robot ‘robot’
(11) Collective nouns, organizations:
</listItem>
<table confidence="0.508560333333333">
myndighet ‘authority’, nation ‘nation’, f¨oretagsledning
‘corporate-board’, personal ‘personell’, stiftelse
‘foundation’, idrottsklubb ‘sport-club’
(12) Human-denoting nouns:
biskop ‘bishop’, herr ‘mister’, nationalist
‘nationalist’, tolk ‘interpreter’
(13) Abstract, human nouns:
f¨orlorare ‘loser’, huvudpart ‘main-party’, konkurrent
‘competitor’, majoritet ‘majority’, v¨ard ‘host’
</table>
<bodyText confidence="0.999908444444444">
It is interesting to note that both the hu-
man and automatic annotation showed difficul-
ties in ascertaining class for a group of ab-
stract, human-denoting nouns, like individ ‘indi-
vidual’, motst˚andare ‘opponent’, kandidat ‘candi-
date’, representant ‘representative’. These were
all assigned to the animate majority class dur-
ing extraction, but were misclassified as inanimate
during classification.
</bodyText>
<subsectionHeader confidence="0.99498">
4.5 SVM classifiers
</subsectionHeader>
<bodyText confidence="0.997158615384615">
In order to evaluate whether the classification
method generalizes to a different machine learn-
ing algorithm, we design an identical set of experi-
ments to the ones presented above, but where clas-
sification is performed with Support Vector Ma-
chines (SVMs) instead of MBL. We use the LIB-
SVM package (Chang and Lin, 2001) with a RBF
kernel (C = 8.0, γ = 0.5).11
– in the extraction of training data.
11As in the MBL-experiment, parameter optimization, i.e.,
choice of kernel function, C and γ values, is performed on
20% of the total data set with the easy.py tool, supplied
with LIBSVM.
</bodyText>
<page confidence="0.884426">
635
</page>
<bodyText confidence="0.999977428571429">
As column 5 (SVM) in table 2 shows, the clas-
sification results are very similar to the results ob-
tained with MBL.12 We furthermore find a very
similar set of errors, and in particular, we find that
51.0 % of the errors for the inanimate class are
nouns with the gradient animacy properties pre-
sented in (9)-(13) above.
</bodyText>
<subsectionHeader confidence="0.486957">
5 Parsing with animacy information
</subsectionHeader>
<bodyText confidence="0.999975125">
As an external evaluation of our animacy classi-
fier, we apply the induced information to the task
of syntactic parsing. Seeing that we have a tree-
bank with gold standard syntactic information and
gold standard as well as induced animacy informa-
tion, it should be possible to study the direct effect
of the added animacy information in the assign-
ment of syntactic structure.
</bodyText>
<subsectionHeader confidence="0.984546">
5.1 Experimental methodology
</subsectionHeader>
<bodyText confidence="0.999939038461539">
We use the freely available MaltParser system,
which is a language-independent system for data-
driven dependency parsing (Nivre, 2006; Nivre et
al., 2006c). A set of parsers are trained on Tal-
banken05, both with and without additional an-
imacy information, the origin of which is either
the manual annotation described in section 3 or
the automatic animacy classifier described in sec-
tion 4.2- 4.4 (MBL). The common nouns in the
treebank are classified for animacy using leave-
one-out training and testing. This ensures that
the training and test instances are disjoint at all
times. Moreover, the fact that the distributional
data is taken from a separate data set ensures non-
circularity since we are not basing the classifica-
tion on gold standard parses.
All parsing experiments are performed using
10-fold cross-validation for training and testing on
the entire written part of Talbanken05. Overall
parsing accuracy will be reported using the stan-
dard metrics of labeled attachment score (LAS)
and unlabeled attachment score (UAS).13 Statis-
tical significance is checked using Dan Bikel’s
randomized parsing evaluation comparator.14 As
our baseline, we use the settings optimized for
Swedish in the CoNLL-X shared task (Buchholz
</bodyText>
<table confidence="0.703962545454545">
12The SVM-classifiers generally show slightly lower re-
sults, however, only performance on the &gt;1000 data set is
significantly lower (p&lt;.05).
13LAS and UAS report the percentage of tokens that are as-
signed the correct head with (labeled) or without (unlabeled)
the correct dependency label.
14http://www.cis.upenn.edu/∼dbikel/software.html
Gold standard Automatic
UAS LAS UAS LAS
Baseline 89.87 84.92 89.87 84.92
Anim 89.81 84.94 89.87 84.99
</table>
<tableCaption confidence="0.952489">
Table 5: Overall results in experiments with au-
</tableCaption>
<bodyText confidence="0.5604818">
tomatic features compared to gold standard fea-
tures, expressed as unlabeled and labeled attach-
ment scores.
and Marsi, 2006), where this parser was the best
performing parser for Swedish.
</bodyText>
<subsectionHeader confidence="0.926821">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999591567567568">
The addition of automatically assigned animacy
information for common nouns (Anim) causes a
small, but significant improvement in overall re-
sults (p&lt;.04) compared to the baseline, as well
as the corresponding gold standard experiment
(p&lt;.04). In the gold standard experiment, the re-
sults are not significantly better than the baseline
and the main, overall, improvement from the gold
standard animacy information reported in Øvrelid
and Nivre (2007) and Øvrelid (2008) stems largely
from the animacy annotation of pronouns.15 This
indicates that the animacy information for com-
mon nouns, which has been automatically ac-
quired from a considerably larger corpus, captures
distributional distinctions which are important for
the general effect of animacy and furthermore that
the differences from the gold standard annotation
prove beneficial for the results.
We see from Table 5, that the improvement in
overall parse results is mainly in terms of depen-
dency labeling, reflected in the LAS score. A
closer error analysis shows that the performance
of the two parsers employing gold and automatic
animacy information is very similar with respect
to dependency relations and we observe an im-
proved analysis for subjects, (direct and indirect)
objects and subject predicatives with only minor
variations. This in itself is remarkable, since the
covered set of animate instances is notably smaller
in the automatically annotated data set. We fur-
thermore find that the main difference between the
gold standard and automatic Anim-experiments
15Recall that the Talbanken05 treebank contains animacy
information for all nominal elements – pronouns, proper and
common nouns. When the totality of this information is
added the overall parse results are significantly improved
(p&lt;.0002) (Øvrelid and Nivre, 2007; Øvrelid, 2008).
</bodyText>
<page confidence="0.837795">
636
</page>
<bodyText confidence="0.999549878787879">
does not reside in the analysis of syntactic argu-
ments, but rather of non-arguments. One rela-
tion for which performance deteriorates with the
added information in the gold Anim-experiment
is the nominal postmodifier relation (ET) which
is employed for relative clauses and nominal PP-
attachment. With the automatically assigned fea-
ture, in contrast, we observe an improvement in
the performance for the ET relation, compared to
the gold standard experiment, from a F-score in
the latter of 76.14 to 76.40 in the former. Since
this is a quite common relation, with a frequency
of 5% in the treebank as a whole, the improvement
has a clear effect on the results.
The parser’s analysis of postnominal modifica-
tion is influenced by the differences in the added
animacy annotation for the nominal head, as well
as the internal dependent. If we examine the cor-
rected errors in the automatic experiment, com-
pared to the gold standard experiment, we find ele-
ments with differing annotation. Preferences with
respect to the animacy of prepositional comple-
ments vary. In (14), the automatic annotation of
the noun djur ‘animal’ as animate results in cor-
rect assignment of the ET relation to the prepo-
sition hos ‘among’, as well as correct nominal,
as opposed to verbal, attachment. This preposi-
tion is one of the few with a preference for an-
imate complements in the treebank. In contrast,
the example in (15) illustrates an error where the
automatic classification of barn ‘children’ as inan-
imate causes a correct analysis of the head prepo-
sition om ‘about’.16
</bodyText>
<figure confidence="0.9351665">
(14) ... samh¨allsbildningar hos olika djur
... societies among different animals
‘... social organizations among different animals’
(15) F¨or¨aldrar har v˚ardnaden om sina barn
</figure>
<bodyText confidence="0.987051666666667">
parents have custody-DEF of their children
‘Parents have the custody of their children’
A more thorough analysis of the different factors
involved in PP-attachment is a complex task which
is clearly beyond the scope of the present study.
We may note, however, that the distinctions in-
duced by the animacy classifier based purely on
linguistic evidence proves useful for the analysis
of both arguments and non-arguments.
16Recall that the classification is based purely on linguistic
evidence and in this respect children largely pattern with the
inanimate nouns. A child is probably more like a physical
object in the sense that it is something one possesses and oth-
erwise reacts to, rather than being an agent that acts upon its
surroundings.
</bodyText>
<sectionHeader confidence="0.998614" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999990918367347">
This article has dealt with an empirical evaluation
of animacy annotation in Swedish, where the main
focus has been on the use of such annotation for
computational purposes.
We have seen that human annotation for ani-
macy shows little variation at the type-level for
a binary animacy distinction. Following from
this observation, we have shown how a type-
level induction strategy based on morphosyntac-
tic distributional features enables automatic ani-
macy classification for noun lemmas which fur-
thermore generalizes to different machine learning
algorithms (MBL, SVM). We obtain results for an-
imacy classification, ranging from 97.3% accuracy
to 93.9% depending on the sparsity of the data.
With an absolute frequency threshold of 10, we
obtain an accuracy of 95.4%, which constitutes a
50% reduction of error rate. A detailed error anal-
ysis revealed some interesting results and we saw
that more than half of the errors performed by the
animacy classifier for the large class of inanimate
nouns actually included elements which have been
assigned an intermediate animacy status in theo-
retical work, such as animals and collective nouns.
The application of animacy annotation in the
task of syntactic parsing provided a test bed for
the applicability of the annotation, where we could
contrast the manually assigned classes with the
automatically acquired ones. The results showed
that the automatically acquired information gives
a slight, but significant improvement of overall
parse results where the gold standard annotation
does not, despite a considerably lower coverage.
This is a suprising result which highlights impor-
tant properties of the annotation. First of all, the
automatic annotation is completely consistent at
the type level. Second, the automatic animacy
classifier captures important distributional proper-
ties of the nouns, exemplified by the case of nom-
inal postmodifiers in PP-attachment. The auto-
matic annotation thus captures a purely linguistic
notion of animacy and abstracts over contextual
influence in particular instances.
Animacy has been shown to be an important
property in a range of languages, hence animacy
classification of other languages constitutes an in-
teresting line of work for the future, where empir-
ical evaluations may point to similarities and dif-
ferences in the linguistic expression of animacy.
</bodyText>
<page confidence="0.815906">
637
</page>
<sectionHeader confidence="0.99344" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999879620370371">
Judith Aissen. 2003. Differential Object Marking: Iconicity
vs. economy. Natural Language and Linguistic Theory,
21(3):435–483.
Holly P. Branigan, Martin J. Pickering, and Mikihiro Tanaka.
2008. Contributions of animacy to grammatical func-
tion assignment and word order production. Lingua,
118(2):172–189.
Joan Bresnan, Anna Cueni, Tatiana Nikitina, and Harald
Baayen. 2005. Predicting the dative alternation. In Gosse
Bouma, Irene Kraemer, and Joost Zwarts, editors, Cog-
nitive foundations of interpretation, pages 69–94. Royal
Netherlands Academy of Science, Amsterdam.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proceedings
of the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 149–164.
Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM: A
library for support vector machines. Software available at
http://www.csie.ntu.edu.tw/∼cjlin/libsvm.
Walter Daelemans, Jakub Zavrel, Ko Van der Sloot, and An-
tal Van den Bosch. 2004. TiMBL: Tilburg Memory Based
Learner, version 5.1, Reference Guide. Technical report,
ILK Technical Report Series 04-02.
¨Osten Dahl and Kari Fraurud. 1996. Animacy in gram-
mar and discourse. In Thorstein Fretheim and Jeanette K.
Gundel, editors, Reference and referent accessibility,
pages 47–65. John Benjamins, Amsterdam.
Peter de Swart, Monique Lamers, and Sander Lestrade. 2008.
Animacy, argument structure and argument encoding: In-
troduction to the special issue on animacy. Lingua,
118(2):131–140.
Felice Dell’Orletta, Alessandro Lenci, Simonetta Monte-
magni, and Vito Pirrelli. 2005. Climbing the path to
grammar: A maximum entropy model of subject/object
learning. In Proceedings of the 2nd Workshop on Psy-
chocomputational Models of Human Language Acquisi-
tion, pages 72–81.
Thomas G. Dietterich. 1998. Approximate statistical test for
comparing supervised classification learning algorithms.
Neural Computation, 10(7):1895–1923.
Christiane Fellbaum, editor. 1998. WordNet: an electronic
lexical database. MIT Press, Cambridge, MA.
Gregory Garretson, M. Catherine O’Connor, Barbora
Skarabela, and Marjorie Hogan, 2004. Optimal Typol-
ogy of Determiner Phrases Coding Manual. Boston
University, version 3.2 edition. Downloaded from
http://people.bu.edu/depot/coding manual.html on
02/15/2006.
Johan Hall. 2003. A probabilistic part-of-speech tagger
with suffix probabilities. Master’s thesis, V¨axj¨o Univer-
sity, Sweden.
Paola Merlo and Suzanne Stevenson. 2001. Automatic verb
classification based on statistical distributions of argument
structure. Computational Linguistics, 27(3):373–408.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a. Malt-
parser: A data-driven parser-generator for dependency
parsing. In Proceedings of the Fifth International Con-
ference on Language Resources and Evaluation (LREC),
pages 2216–2219.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006b. Tal-
banken05: A Swedish treebank with phrase structure and
dependency annotation. In Proceedings of the fifth Inter-
national Conference on Language Resources and Evalua-
tion (LREC), pages 1392–1395.
Joakim Nivre, Jens Nilsson, Johan Hall, G¨uls¸en Eryiˇgit, and
Svetoslav Marinov. 2006c. Labeled pseudo-projective
dependency parsing with Support Vector Machines. In
Proceedings of the Conference on Computational Natural
Language Learning (CoNLL).
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer, Dordrecht.
Constantin Or˘asan and Richard Evans. 2007. NP animacy
resolution for anaphora resolution. Journal of Artificial
Intelligence Research, 29:79–103.
Lilja Øvrelid and Joakim Nivre. 2007. When word order and
part-of-speech tags are not enough – Swedish dependency
parsing with rich linguistic features. In Proceedings of the
International Conference on Recent Advances in Natural
Language Processing (RANLP), pages 447–451.
Lilja Øvrelid. 2008. Linguistic features in data-driven
dependency parsing. In Proceedings of the Conference
on Computational Natural Language Learning (CoNLL
2008).
Anette Rosenbach. 2008. Animacy and grammatical vari-
ation - findings from English genitive variation. Lingua,
118(2):151–171.
Michael Silverstein. 1976. Hierarchy of features and erga-
tivity. In Robert M.W. Dixon, editor, Grammatical cat-
egories in Australian Languages, pages 112–171. Aus-
tralian Institute of Aboriginal Studies, Canberra.
Suzanne Stevenson and Eric Joanis. 2003. Semi-supervised
verb class discovery using noisy features. In Proceedings
of the Conference on Computational Natural Language
Learning (CoNLL), pages 71–78.
Ulf Teleman. 1974. Manual f¨or grammatisk beskrivning av
talad och skriven svenska. Studentlitteratur, Lund.
J. Weckerly and M. Kutas. 1999. An electrophysiological
analysis of animacy effects in the processing of object rel-
ative sentences. Psychophysiology, 36:559–570.
Mutsumi Yamamoto. 1999. Animacy and Reference: A cog-
nitive approach to corpus linguistics. John Benjamins,
Amsterdam.
Annie Zaenen, Jean Carletta, Gregory Garretson, Joan
Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina,
M. Catherine O’Connor, and Tom Wasow. 2004. Ani-
macy encoding in English: why and how. In Donna By-
ron and Bonnie Webber, editors, Proceedings of the ACL
Workshop on Discourse Annotation.
</reference>
<page confidence="0.922431">
638
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.894689">
<title confidence="0.998446">Empirical evaluations of animacy annotation</title>
<author confidence="0.997974">Lilja Øvrelid</author>
<affiliation confidence="0.999934">Department of Linguistics University of Potsdam</affiliation>
<address confidence="0.994401">Germany</address>
<email confidence="0.999615">lilja@ling.uni-potsdam.de</email>
<abstract confidence="0.994239588235294">This article presents empirical evaluations of aspects of annotation for the linguistic property of animacy in Swedish, ranging from manual human annotation, automatic classification and, finally, an external evaluation in the task of syntactic parsing. We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-theart baseline parser with gold standard animacy information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Judith Aissen</author>
</authors>
<title>Differential Object Marking: Iconicity vs.</title>
<date>2003</date>
<booktitle>economy. Natural Language and Linguistic Theory,</booktitle>
<pages>21--3</pages>
<contexts>
<context position="921" citStr="Aissen, 2003" startWordPosition="133" endWordPosition="134">utomatic classification and, finally, an external evaluation in the task of syntactic parsing. We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-theart baseline parser with gold standard animacy information. 1 Introduction The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, how</context>
</contexts>
<marker>Aissen, 2003</marker>
<rawString>Judith Aissen. 2003. Differential Object Marking: Iconicity vs. economy. Natural Language and Linguistic Theory, 21(3):435–483.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holly P Branigan</author>
<author>Martin J Pickering</author>
<author>Mikihiro Tanaka</author>
</authors>
<title>Contributions of animacy to grammatical function assignment and word order production.</title>
<date>2008</date>
<journal>Lingua,</journal>
<volume>118</volume>
<issue>2</issue>
<contexts>
<context position="1128" citStr="Branigan et al., 2008" startWordPosition="167" endWordPosition="170">over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-theart baseline parser with gold standard animacy information. 1 Introduction The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions 1Parts of the research reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Sonderforschungsbereich 632, project D4). are also relevant and the anim</context>
</contexts>
<marker>Branigan, Pickering, Tanaka, 2008</marker>
<rawString>Holly P. Branigan, Martin J. Pickering, and Mikihiro Tanaka. 2008. Contributions of animacy to grammatical function assignment and word order production. Lingua, 118(2):172–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
<author>Anna Cueni</author>
<author>Tatiana Nikitina</author>
<author>Harald Baayen</author>
</authors>
<title>Predicting the dative alternation.</title>
<date>2005</date>
<booktitle>Cognitive foundations of interpretation,</booktitle>
<pages>69--94</pages>
<editor>In Gosse Bouma, Irene Kraemer, and Joost Zwarts, editors,</editor>
<location>Amsterdam.</location>
<contexts>
<context position="968" citStr="Bresnan et al., 2005" startWordPosition="139" endWordPosition="142"> external evaluation in the task of syntactic parsing. We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-theart baseline parser with gold standard animacy information. 1 Introduction The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions 1Parts of the research</context>
</contexts>
<marker>Bresnan, Cueni, Nikitina, Baayen, 2005</marker>
<rawString>Joan Bresnan, Anna Cueni, Tatiana Nikitina, and Harald Baayen. 2005. Predicting the dative alternation. In Gosse Bouma, Irene Kraemer, and Joost Zwarts, editors, Cognitive foundations of interpretation, pages 69–94. Royal Netherlands Academy of Science, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</title>
<date>2001</date>
<contexts>
<context position="24626" citStr="Chang and Lin, 2001" startWordPosition="3850" endWordPosition="3853">r a group of abstract, human-denoting nouns, like individ ‘individual’, motst˚andare ‘opponent’, kandidat ‘candidate’, representant ‘representative’. These were all assigned to the animate majority class during extraction, but were misclassified as inanimate during classification. 4.5 SVM classifiers In order to evaluate whether the classification method generalizes to a different machine learning algorithm, we design an identical set of experiments to the ones presented above, but where classification is performed with Support Vector Machines (SVMs) instead of MBL. We use the LIBSVM package (Chang and Lin, 2001) with a RBF kernel (C = 8.0, γ = 0.5).11 – in the extraction of training data. 11As in the MBL-experiment, parameter optimization, i.e., choice of kernel function, C and γ values, is performed on 20% of the total data set with the easy.py tool, supplied with LIBSVM. 635 As column 5 (SVM) in table 2 shows, the classification results are very similar to the results obtained with MBL.12 We furthermore find a very similar set of errors, and in particular, we find that 51.0 % of the errors for the inanimate class are nouns with the gradient animacy properties presented in (9)-(13) above. 5 Parsing </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM: A library for support vector machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Ko Van der Sloot</author>
<author>Antal Van den Bosch</author>
</authors>
<title>TiMBL: Tilburg Memory Based Learner, version 5.1, Reference Guide.</title>
<date>2004</date>
<tech>Technical report, ILK Technical Report Series 04-02.</tech>
<marker>Daelemans, Zavrel, Van der Sloot, Van den Bosch, 2004</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Ko Van der Sloot, and Antal Van den Bosch. 2004. TiMBL: Tilburg Memory Based Learner, version 5.1, Reference Guide. Technical report, ILK Technical Report Series 04-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨Osten Dahl</author>
<author>Kari Fraurud</author>
</authors>
<title>Animacy in grammar and discourse.</title>
<date>1996</date>
<booktitle>Reference and referent accessibility,</booktitle>
<pages>47--65</pages>
<editor>In Thorstein Fretheim and Jeanette K. Gundel, editors,</editor>
<publisher>John Benjamins,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="4899" citStr="Dahl and Fraurud, 1996" startWordPosition="749" endWordPosition="752">nimacy based on morphosyntactic features extracted from a considerably larger corpus. Section 5 presents experiments with the acquired animacy information applied in the data-driven dependency parsing of Swedish. Finally, section 6 concludes the article and provides some suggestions for future research. 2 Animacy annotation Annotation for animacy is not a common component of corpora or treebanks. However, following from the theoretical interest in the property of animacy, there have been some initiatives directed at animacy annotation of corpus data. Corpus studies of animacy (Yamamoto, 1999; Dahl and Fraurud, 1996) have made use of annotated data, however they differ in the extent to which the annotation has been explicitly formulated as an annotation scheme. The annotation study presented in Zaenen et. al. (2004) makes use of a coding manual designed for a project studying genitive modification (Garretson et al., 2004) and presents an explicit annotation scheme for animacy, illustrated by figure 1. The main class distinction for animacy is three-way, distinguishing Human, Other animate and Inanimate, with subclasses under two of the main classes. The ‘Other animate’ class further distinguishes Organiza</context>
<context position="14228" citStr="Dahl and Fraurud, 1996" startWordPosition="2223" endWordPosition="2226">lent to treatment of animacy as a lexical semantic property and the classification strategy is based on generalization of morphosyntactic behaviour of common nouns over large quantities of data. Due to the small size of the Talbanken05 treebank and the small amount of variation, this strategy was pursued for the acquisition of animacy information. In the animacy classification of common nouns we exploit well-documented correlations between morphosyntactic realization and semantic properties of nouns. For instance, animate nouns tend to be realized as agentive subjects, inanimate nouns do not (Dahl and Fraurud, 1996). Animate nouns make good ‘possessors’, whereas inanimate nouns are more likely ‘possessees’ (Rosenbach, 2008). Table 1 presents an overview of the animacy data Class Types Tokens covered Animate 644 6010 Inanimate 6910 34822 Total 7554 40832 Table 1: The animacy data set from Talbanken05; number of noun lemmas (Types) and tokens in each class. for common nouns in Talbanken05. It is clear that the data is highly skewed towards the non-human class, which accounts for 91.5% of the type instances. For classification we organize the data into accumulated frequency bins, which include all nouns wit</context>
</contexts>
<marker>Dahl, Fraurud, 1996</marker>
<rawString>¨Osten Dahl and Kari Fraurud. 1996. Animacy in grammar and discourse. In Thorstein Fretheim and Jeanette K. Gundel, editors, Reference and referent accessibility, pages 47–65. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter de Swart</author>
<author>Monique Lamers</author>
<author>Sander Lestrade</author>
</authors>
<title>Animacy, argument structure and argument encoding: Introduction to the special issue on animacy.</title>
<date>2008</date>
<journal>Lingua,</journal>
<volume>118</volume>
<issue>2</issue>
<marker>de Swart, Lamers, Lestrade, 2008</marker>
<rawString>Peter de Swart, Monique Lamers, and Sander Lestrade. 2008. Animacy, argument structure and argument encoding: Introduction to the special issue on animacy. Lingua, 118(2):131–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Felice Dell’Orletta</author>
<author>Alessandro Lenci</author>
<author>Simonetta Montemagni</author>
<author>Vito Pirrelli</author>
</authors>
<title>Climbing the path to grammar: A maximum entropy model of subject/object learning.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd Workshop on Psychocomputational Models of Human Language Acquisition,</booktitle>
<pages>72--81</pages>
<marker>Dell’Orletta, Lenci, Montemagni, Pirrelli, 2005</marker>
<rawString>Felice Dell’Orletta, Alessandro Lenci, Simonetta Montemagni, and Vito Pirrelli. 2005. Climbing the path to grammar: A maximum entropy model of subject/object learning. In Proceedings of the 2nd Workshop on Psychocomputational Models of Human Language Acquisition, pages 72–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Approximate statistical test for comparing supervised classification learning algorithms.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<volume>10</volume>
<issue>7</issue>
<contexts>
<context position="19462" citStr="Dietterich, 1998" startWordPosition="3037" endWordPosition="3038"> k = 11, GainRatio feature weighting and Inverse Linear (IL) class voting weights. Bin Instances Baseline MBL SVM &gt;1000 291 89.3 97.3 95.2 &gt;500 597 88.9 97.3 97.1 &gt;100 1668 90.5 96.8 96.9 &gt;50 2278 90.6 96.1 96.0 &gt;10 3786 90.8 95.4 95.1 &gt;0 5481 91.3 93.9 93.7 Table 2: Accuracy for MBL and SVM classifiers on Talbanken05 nouns in accumulated frequency bins by Parole frequency. the majority class of inanimates, which start out with F-scores approaching 100. For calculation of the statistical significance of differences in the performance of classifiers tested on the same data set, McNemar’s test (Dietterich, 1998) is employed. 4.3 Results Column four (MBL) in table 2 shows the accuracy obtained with all features in the general feature space. We observe a clear improvement on all data sets (p&lt;.0001), compared to the respective baselines. As we recall, the data sets are successively larger, hence it seems fair to conclude that the size of the data set partially counteracts the lower frequency of the test nouns. It is not surprising, however, that a method based on distributional features suffers when the absolute frequencies approach 1. We obtain results for animacy classification, ranging from 97.3% acc</context>
</contexts>
<marker>Dietterich, 1998</marker>
<rawString>Thomas G. Dietterich. 1998. Approximate statistical test for comparing supervised classification learning algorithms. Neural Computation, 10(7):1895–1923.</rawString>
</citation>
<citation valid="true">
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: an electronic lexical database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Garretson</author>
<author>M Catherine O’Connor</author>
<author>Barbora Skarabela</author>
<author>Marjorie Hogan</author>
</authors>
<title>Optimal Typology of Determiner Phrases Coding Manual. Boston University, version 3.2 edition. Downloaded from http://people.bu.edu/depot/coding manual.html on 02/15/2006.</title>
<date>2004</date>
<marker>Garretson, O’Connor, Skarabela, Hogan, 2004</marker>
<rawString>Gregory Garretson, M. Catherine O’Connor, Barbora Skarabela, and Marjorie Hogan, 2004. Optimal Typology of Determiner Phrases Coding Manual. Boston University, version 3.2 edition. Downloaded from http://people.bu.edu/depot/coding manual.html on 02/15/2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Hall</author>
</authors>
<title>A probabilistic part-of-speech tagger with suffix probabilities. Master’s thesis,</title>
<date>2003</date>
<institution>V¨axj¨o University, Sweden.</institution>
<contexts>
<context position="18205" citStr="Hall, 2003" startWordPosition="2845" endWordPosition="2846">on of classes, as noted above, the baseline accuracy is very high, usually around 90%.Clearly, however, the class-based measures of precision and recall, as well as the combined F-score measure are more informative for these results. The baseline F-score for the animate class is thus 0, and a main goal is to improve on the rate of true positives for animates, while limiting the trade-off in terms of performance for 5Parole is freely available at http://spraakbanken.gu.se 6http://www.maltparser.org 7For part-of-speech tagging, we employ the MaltTagger – a HMM part-of-speech tagger for Swedish (Hall, 2003). For parsing, we employ MaltParser (Nivre et al., 2006a), a language-independent system for data-driven dependency parsing , with the pretrained model for Swedish, which has been trained on the tags output by the tagger. 8http://ilk.uvt.nl/software.html 9For parameter optimization we employ the paramsearch tool, supplied with TiMBL, see http://ilk.uvt.nl/software.html. Paramsearch implements a hill climbing search for the optimal settings on iteratively larger parts of the supplied data. We performed parameter optimization on 20% of the total data set, where we balanced the data with respect </context>
</contexts>
<marker>Hall, 2003</marker>
<rawString>Johan Hall. 2003. A probabilistic part-of-speech tagger with suffix probabilities. Master’s thesis, V¨axj¨o University, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="13436" citStr="Merlo and Stevenson, 2001" startWordPosition="2102" endWordPosition="2105">resource in order to classify animate referents. However, such a method is clearly restricted to languages for which large scale lexical resources, such as the WordNet, are available. The task of animacy classification bears some resemblance to the task of named entity recognition (NER) which usually makes reference to a ‘person’ class. However, whereas most NER systems make extensive use of orthographic, morphological or contextual clues (titles, suffixes) and gazetteers, animacy for nouns is not signaled overtly in the same way. Following a strategy in line with work on verb classification (Merlo and Stevenson, 2001; Stevenson and Joanis, 2003), we set out to classify common noun lemmas based on their morphosyntactic distribution in a considerably larger corpus. This is thus equivalent to treatment of animacy as a lexical semantic property and the classification strategy is based on generalization of morphosyntactic behaviour of common nouns over large quantities of data. Due to the small size of the Talbanken05 treebank and the small amount of variation, this strategy was pursued for the acquisition of animacy information. In the animacy classification of common nouns we exploit well-documented correlat</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>2216--2219</pages>
<contexts>
<context position="6936" citStr="Nivre et al., 2006" startWordPosition="1069" endWordPosition="1072">esources, such as WordNet (Fellbaum, 1998) can also be seen as treating animacy as a typelevel property. We may thus distinguish between a purely type level annotation strategy and a purely token level one. Type level properties hold for lexemes and are context-independent, i.e., independent of the particular linguistic context, whereas token-level properties are determined in context and hold for referring expressions, rather than lexemes. 3 Human reference in Swedish Talbanken05 is a Swedish treebank which was created in the 1970’s and which has recently been converted to dependency format (Nivre et al., 2006b) and made freely available. The written sections of the treebank consist of professional prose and student essays and amount to 197,123 running tokens, spread over 11,431 sentences. Figure 2 shows the labeled dependency graph of example (2), taken from Talbanken05. (2) Samma erfarenhet giorde engelsm¨annen same experience made englishmen-DEF ‘The same experience, the Englishmen had’ DT OO ROOT SS _ Samma erfarenhet gjorde engelsmannen _ PO NN VV NN KP PT DD|HH _ _ Figure 2: Dependency representation of example (2) from Talbanken05. In addition to information on part-of-speech, dependency hea</context>
<context position="18260" citStr="Nivre et al., 2006" startWordPosition="2852" endWordPosition="2855">racy is very high, usually around 90%.Clearly, however, the class-based measures of precision and recall, as well as the combined F-score measure are more informative for these results. The baseline F-score for the animate class is thus 0, and a main goal is to improve on the rate of true positives for animates, while limiting the trade-off in terms of performance for 5Parole is freely available at http://spraakbanken.gu.se 6http://www.maltparser.org 7For part-of-speech tagging, we employ the MaltTagger – a HMM part-of-speech tagger for Swedish (Hall, 2003). For parsing, we employ MaltParser (Nivre et al., 2006a), a language-independent system for data-driven dependency parsing , with the pretrained model for Swedish, which has been trained on the tags output by the tagger. 8http://ilk.uvt.nl/software.html 9For parameter optimization we employ the paramsearch tool, supplied with TiMBL, see http://ilk.uvt.nl/software.html. Paramsearch implements a hill climbing search for the optimal settings on iteratively larger parts of the supplied data. We performed parameter optimization on 20% of the total data set, where we balanced the data with respect to frequency. The resulting settings are k = 11, GainRa</context>
<context position="25806" citStr="Nivre et al., 2006" startWordPosition="4051" endWordPosition="4054">resented in (9)-(13) above. 5 Parsing with animacy information As an external evaluation of our animacy classifier, we apply the induced information to the task of syntactic parsing. Seeing that we have a treebank with gold standard syntactic information and gold standard as well as induced animacy information, it should be possible to study the direct effect of the added animacy information in the assignment of syntactic structure. 5.1 Experimental methodology We use the freely available MaltParser system, which is a language-independent system for datadriven dependency parsing (Nivre, 2006; Nivre et al., 2006c). A set of parsers are trained on Talbanken05, both with and without additional animacy information, the origin of which is either the manual annotation described in section 3 or the automatic animacy classifier described in section 4.2- 4.4 (MBL). The common nouns in the treebank are classified for animacy using leaveone-out training and testing. This ensures that the training and test instances are disjoint at all times. Moreover, the fact that the distributional data is taken from a separate data set ensures noncircularity since we are not basing the classification on gold standard parses</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a. Maltparser: A data-driven parser-generator for dependency parsing. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC), pages 2216–2219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
</authors>
<title>Talbanken05: A Swedish treebank with phrase structure and dependency annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1392--1395</pages>
<contexts>
<context position="6936" citStr="Nivre et al., 2006" startWordPosition="1069" endWordPosition="1072">esources, such as WordNet (Fellbaum, 1998) can also be seen as treating animacy as a typelevel property. We may thus distinguish between a purely type level annotation strategy and a purely token level one. Type level properties hold for lexemes and are context-independent, i.e., independent of the particular linguistic context, whereas token-level properties are determined in context and hold for referring expressions, rather than lexemes. 3 Human reference in Swedish Talbanken05 is a Swedish treebank which was created in the 1970’s and which has recently been converted to dependency format (Nivre et al., 2006b) and made freely available. The written sections of the treebank consist of professional prose and student essays and amount to 197,123 running tokens, spread over 11,431 sentences. Figure 2 shows the labeled dependency graph of example (2), taken from Talbanken05. (2) Samma erfarenhet giorde engelsm¨annen same experience made englishmen-DEF ‘The same experience, the Englishmen had’ DT OO ROOT SS _ Samma erfarenhet gjorde engelsmannen _ PO NN VV NN KP PT DD|HH _ _ Figure 2: Dependency representation of example (2) from Talbanken05. In addition to information on part-of-speech, dependency hea</context>
<context position="18260" citStr="Nivre et al., 2006" startWordPosition="2852" endWordPosition="2855">racy is very high, usually around 90%.Clearly, however, the class-based measures of precision and recall, as well as the combined F-score measure are more informative for these results. The baseline F-score for the animate class is thus 0, and a main goal is to improve on the rate of true positives for animates, while limiting the trade-off in terms of performance for 5Parole is freely available at http://spraakbanken.gu.se 6http://www.maltparser.org 7For part-of-speech tagging, we employ the MaltTagger – a HMM part-of-speech tagger for Swedish (Hall, 2003). For parsing, we employ MaltParser (Nivre et al., 2006a), a language-independent system for data-driven dependency parsing , with the pretrained model for Swedish, which has been trained on the tags output by the tagger. 8http://ilk.uvt.nl/software.html 9For parameter optimization we employ the paramsearch tool, supplied with TiMBL, see http://ilk.uvt.nl/software.html. Paramsearch implements a hill climbing search for the optimal settings on iteratively larger parts of the supplied data. We performed parameter optimization on 20% of the total data set, where we balanced the data with respect to frequency. The resulting settings are k = 11, GainRa</context>
<context position="25806" citStr="Nivre et al., 2006" startWordPosition="4051" endWordPosition="4054">resented in (9)-(13) above. 5 Parsing with animacy information As an external evaluation of our animacy classifier, we apply the induced information to the task of syntactic parsing. Seeing that we have a treebank with gold standard syntactic information and gold standard as well as induced animacy information, it should be possible to study the direct effect of the added animacy information in the assignment of syntactic structure. 5.1 Experimental methodology We use the freely available MaltParser system, which is a language-independent system for datadriven dependency parsing (Nivre, 2006; Nivre et al., 2006c). A set of parsers are trained on Talbanken05, both with and without additional animacy information, the origin of which is either the manual annotation described in section 3 or the automatic animacy classifier described in section 4.2- 4.4 (MBL). The common nouns in the treebank are classified for animacy using leaveone-out training and testing. This ensures that the training and test instances are disjoint at all times. Moreover, the fact that the distributional data is taken from a separate data set ensures noncircularity since we are not basing the classification on gold standard parses</context>
</contexts>
<marker>Nivre, Nilsson, Hall, 2006</marker>
<rawString>Joakim Nivre, Jens Nilsson, and Johan Hall. 2006b. Talbanken05: A Swedish treebank with phrase structure and dependency annotation. In Proceedings of the fifth International Conference on Language Resources and Evaluation (LREC), pages 1392–1395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
<author>G¨uls¸en Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudo-projective dependency parsing with Support Vector Machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL).</booktitle>
<marker>Nivre, Nilsson, Hall, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Jens Nilsson, Johan Hall, G¨uls¸en Eryiˇgit, and Svetoslav Marinov. 2006c. Labeled pseudo-projective dependency parsing with Support Vector Machines. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="25786" citStr="Nivre, 2006" startWordPosition="4049" endWordPosition="4050"> properties presented in (9)-(13) above. 5 Parsing with animacy information As an external evaluation of our animacy classifier, we apply the induced information to the task of syntactic parsing. Seeing that we have a treebank with gold standard syntactic information and gold standard as well as induced animacy information, it should be possible to study the direct effect of the added animacy information in the assignment of syntactic structure. 5.1 Experimental methodology We use the freely available MaltParser system, which is a language-independent system for datadriven dependency parsing (Nivre, 2006; Nivre et al., 2006c). A set of parsers are trained on Talbanken05, both with and without additional animacy information, the origin of which is either the manual annotation described in section 3 or the automatic animacy classifier described in section 4.2- 4.4 (MBL). The common nouns in the treebank are classified for animacy using leaveone-out training and testing. This ensures that the training and test instances are disjoint at all times. Moreover, the fact that the distributional data is taken from a separate data set ensures noncircularity since we are not basing the classification on </context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Or˘asan</author>
<author>Richard Evans</author>
</authors>
<title>NP animacy resolution for anaphora resolution.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>29--79</pages>
<marker>Or˘asan, Evans, 2007</marker>
<rawString>Constantin Or˘asan and Richard Evans. 2007. NP animacy resolution for anaphora resolution. Journal of Artificial Intelligence Research, 29:79–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lilja Øvrelid</author>
<author>Joakim Nivre</author>
</authors>
<title>When word order and part-of-speech tags are not enough – Swedish dependency parsing with rich linguistic features.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP),</booktitle>
<pages>447--451</pages>
<contexts>
<context position="1408" citStr="Øvrelid and Nivre, 2007" startWordPosition="208" endWordPosition="211">troduction The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions 1Parts of the research reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Sonderforschungsbereich 632, project D4). are also relevant and the animacy dimension is often viewed as a continuum ranging from humans to inanimate objects. Following Silverstein (1976) several animacy hierarchies have been proposed in typological studies, focusing on the linguistic category of animacy, i.e., the distinctions which are relevant for</context>
<context position="28018" citStr="Øvrelid and Nivre (2007)" startWordPosition="4387" endWordPosition="4390">d to gold standard features, expressed as unlabeled and labeled attachment scores. and Marsi, 2006), where this parser was the best performing parser for Swedish. 5.2 Results The addition of automatically assigned animacy information for common nouns (Anim) causes a small, but significant improvement in overall results (p&lt;.04) compared to the baseline, as well as the corresponding gold standard experiment (p&lt;.04). In the gold standard experiment, the results are not significantly better than the baseline and the main, overall, improvement from the gold standard animacy information reported in Øvrelid and Nivre (2007) and Øvrelid (2008) stems largely from the animacy annotation of pronouns.15 This indicates that the animacy information for common nouns, which has been automatically acquired from a considerably larger corpus, captures distributional distinctions which are important for the general effect of animacy and furthermore that the differences from the gold standard annotation prove beneficial for the results. We see from Table 5, that the improvement in overall parse results is mainly in terms of dependency labeling, reflected in the LAS score. A closer error analysis shows that the performance of </context>
<context position="29368" citStr="Øvrelid and Nivre, 2007" startWordPosition="4591" endWordPosition="4594">serve an improved analysis for subjects, (direct and indirect) objects and subject predicatives with only minor variations. This in itself is remarkable, since the covered set of animate instances is notably smaller in the automatically annotated data set. We furthermore find that the main difference between the gold standard and automatic Anim-experiments 15Recall that the Talbanken05 treebank contains animacy information for all nominal elements – pronouns, proper and common nouns. When the totality of this information is added the overall parse results are significantly improved (p&lt;.0002) (Øvrelid and Nivre, 2007; Øvrelid, 2008). 636 does not reside in the analysis of syntactic arguments, but rather of non-arguments. One relation for which performance deteriorates with the added information in the gold Anim-experiment is the nominal postmodifier relation (ET) which is employed for relative clauses and nominal PPattachment. With the automatically assigned feature, in contrast, we observe an improvement in the performance for the ET relation, compared to the gold standard experiment, from a F-score in the latter of 76.14 to 76.40 in the former. Since this is a quite common relation, with a frequency of </context>
</contexts>
<marker>Øvrelid, Nivre, 2007</marker>
<rawString>Lilja Øvrelid and Joakim Nivre. 2007. When word order and part-of-speech tags are not enough – Swedish dependency parsing with rich linguistic features. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP), pages 447–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lilja Øvrelid</author>
</authors>
<title>Linguistic features in data-driven dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL</booktitle>
<contexts>
<context position="28037" citStr="Øvrelid (2008)" startWordPosition="4392" endWordPosition="4393">expressed as unlabeled and labeled attachment scores. and Marsi, 2006), where this parser was the best performing parser for Swedish. 5.2 Results The addition of automatically assigned animacy information for common nouns (Anim) causes a small, but significant improvement in overall results (p&lt;.04) compared to the baseline, as well as the corresponding gold standard experiment (p&lt;.04). In the gold standard experiment, the results are not significantly better than the baseline and the main, overall, improvement from the gold standard animacy information reported in Øvrelid and Nivre (2007) and Øvrelid (2008) stems largely from the animacy annotation of pronouns.15 This indicates that the animacy information for common nouns, which has been automatically acquired from a considerably larger corpus, captures distributional distinctions which are important for the general effect of animacy and furthermore that the differences from the gold standard annotation prove beneficial for the results. We see from Table 5, that the improvement in overall parse results is mainly in terms of dependency labeling, reflected in the LAS score. A closer error analysis shows that the performance of the two parsers emp</context>
<context position="29384" citStr="Øvrelid, 2008" startWordPosition="4595" endWordPosition="4596">s for subjects, (direct and indirect) objects and subject predicatives with only minor variations. This in itself is remarkable, since the covered set of animate instances is notably smaller in the automatically annotated data set. We furthermore find that the main difference between the gold standard and automatic Anim-experiments 15Recall that the Talbanken05 treebank contains animacy information for all nominal elements – pronouns, proper and common nouns. When the totality of this information is added the overall parse results are significantly improved (p&lt;.0002) (Øvrelid and Nivre, 2007; Øvrelid, 2008). 636 does not reside in the analysis of syntactic arguments, but rather of non-arguments. One relation for which performance deteriorates with the added information in the gold Anim-experiment is the nominal postmodifier relation (ET) which is employed for relative clauses and nominal PPattachment. With the automatically assigned feature, in contrast, we observe an improvement in the performance for the ET relation, compared to the gold standard experiment, from a F-score in the latter of 76.14 to 76.40 in the former. Since this is a quite common relation, with a frequency of 5% in the treeba</context>
</contexts>
<marker>Øvrelid, 2008</marker>
<rawString>Lilja Øvrelid. 2008. Linguistic features in data-driven dependency parsing. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Rosenbach</author>
</authors>
<title>Animacy and grammatical variation - findings from English genitive variation.</title>
<date>2008</date>
<journal>Lingua,</journal>
<volume>118</volume>
<issue>2</issue>
<contexts>
<context position="12484" citStr="Rosenbach, 2008" startWordPosition="1956" endWordPosition="1957">tudent-DEF ‘graduate from highschool (lit. take the student)’ 632 It is interesting to note that the main variation in annotation stems precisely from difficulties in determining reference, either due to bleak type level properties such as for the abstract nouns, or due to properties of the context, as in the reference shifting constructions. The small amount of variation in the human annotation for animacy clearly supports a type-level approach to animacy, however, underline the influence of the linguistic context on the conception of animacy, as noted in the literature (Zaenen et al., 2004; Rosenbach, 2008). 4 Lexical acquisition of animacy Even though knowledge about the animacy of a noun clearly has some interesting implications, little work has been done within the field of lexical acquisition in order to automatically acquire animacy information. Or˘asan and Evans (2007) make use of hyponym-relations taken from the WordNet resource in order to classify animate referents. However, such a method is clearly restricted to languages for which large scale lexical resources, such as the WordNet, are available. The task of animacy classification bears some resemblance to the task of named entity rec</context>
<context position="14338" citStr="Rosenbach, 2008" startWordPosition="2239" endWordPosition="2240">n of morphosyntactic behaviour of common nouns over large quantities of data. Due to the small size of the Talbanken05 treebank and the small amount of variation, this strategy was pursued for the acquisition of animacy information. In the animacy classification of common nouns we exploit well-documented correlations between morphosyntactic realization and semantic properties of nouns. For instance, animate nouns tend to be realized as agentive subjects, inanimate nouns do not (Dahl and Fraurud, 1996). Animate nouns make good ‘possessors’, whereas inanimate nouns are more likely ‘possessees’ (Rosenbach, 2008). Table 1 presents an overview of the animacy data Class Types Tokens covered Animate 644 6010 Inanimate 6910 34822 Total 7554 40832 Table 1: The animacy data set from Talbanken05; number of noun lemmas (Types) and tokens in each class. for common nouns in Talbanken05. It is clear that the data is highly skewed towards the non-human class, which accounts for 91.5% of the type instances. For classification we organize the data into accumulated frequency bins, which include all nouns with frequencies above a certain threshold. We here approximate the class of ‘animate’ to ‘human’ and the class o</context>
</contexts>
<marker>Rosenbach, 2008</marker>
<rawString>Anette Rosenbach. 2008. Animacy and grammatical variation - findings from English genitive variation. Lingua, 118(2):151–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Silverstein</author>
</authors>
<title>Hierarchy of features and ergativity.</title>
<date>1976</date>
<booktitle>Grammatical categories in Australian Languages,</booktitle>
<pages>112--171</pages>
<editor>In Robert M.W. Dixon, editor,</editor>
<location>Canberra.</location>
<contexts>
<context position="1843" citStr="Silverstein (1976)" startWordPosition="276" endWordPosition="277"> important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions 1Parts of the research reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Sonderforschungsbereich 632, project D4). are also relevant and the animacy dimension is often viewed as a continuum ranging from humans to inanimate objects. Following Silverstein (1976) several animacy hierarchies have been proposed in typological studies, focusing on the linguistic category of animacy, i.e., the distinctions which are relevant for linguistic phenomena. An example of an animacy hierarchy, taken from (Aissen, 2003), is provided in (1): (1) Human &gt; Animate &gt; Inanimate Clearly, non-human animates, like animals, are not less animate than humans in a biological sense, however, humans and animals show differing linguistic behaviour. Empirical studies of animacy require human annotation efforts, and, in particular, a well-defined annotation task. However, annotatio</context>
</contexts>
<marker>Silverstein, 1976</marker>
<rawString>Michael Silverstein. 1976. Hierarchy of features and ergativity. In Robert M.W. Dixon, editor, Grammatical categories in Australian Languages, pages 112–171. Australian Institute of Aboriginal Studies, Canberra.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semi-supervised verb class discovery using noisy features.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>71--78</pages>
<contexts>
<context position="13465" citStr="Stevenson and Joanis, 2003" startWordPosition="2106" endWordPosition="2109">fy animate referents. However, such a method is clearly restricted to languages for which large scale lexical resources, such as the WordNet, are available. The task of animacy classification bears some resemblance to the task of named entity recognition (NER) which usually makes reference to a ‘person’ class. However, whereas most NER systems make extensive use of orthographic, morphological or contextual clues (titles, suffixes) and gazetteers, animacy for nouns is not signaled overtly in the same way. Following a strategy in line with work on verb classification (Merlo and Stevenson, 2001; Stevenson and Joanis, 2003), we set out to classify common noun lemmas based on their morphosyntactic distribution in a considerably larger corpus. This is thus equivalent to treatment of animacy as a lexical semantic property and the classification strategy is based on generalization of morphosyntactic behaviour of common nouns over large quantities of data. Due to the small size of the Talbanken05 treebank and the small amount of variation, this strategy was pursued for the acquisition of animacy information. In the animacy classification of common nouns we exploit well-documented correlations between morphosyntactic </context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Suzanne Stevenson and Eric Joanis. 2003. Semi-supervised verb class discovery using noisy features. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL), pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Teleman</author>
</authors>
<title>Manual f¨or grammatisk beskrivning av talad och skriven svenska.</title>
<date>1974</date>
<location>Studentlitteratur, Lund.</location>
<contexts>
<context position="7751" citStr="Teleman, 1974" startWordPosition="1197" endWordPosition="1198">e labeled dependency graph of example (2), taken from Talbanken05. (2) Samma erfarenhet giorde engelsm¨annen same experience made englishmen-DEF ‘The same experience, the Englishmen had’ DT OO ROOT SS _ Samma erfarenhet gjorde engelsmannen _ PO NN VV NN KP PT DD|HH _ _ Figure 2: Dependency representation of example (2) from Talbanken05. In addition to information on part-of-speech, dependency head and relation, and various morphosyntactic properties such as definiteness, the annotation expresses a distinction for nominal elements between reference to human and nonhuman. The annotation manual (Teleman, 1974) states that a markable should be tagged as human (HH) if it may be replaced by the interrogative pronoun vem ‘who’ and be referred to by the personal pronouns han ‘he’ or hon ‘she’. There are clear similarities between the annotation for human reference found in Talbanken05 and the annotation scheme for animacy discussed 631 HUM Other Inanimate animate ORG TIME PLACE ANIM CONC NCONC Figure 1: Animacy classification scheme (Zaenen et al., 2004). above. The human/non-human contrast forms the central distinction in the animacy dimension and, in this respect, the annotation schemes do not conflic</context>
<context position="9546" citStr="Teleman, 1974" startWordPosition="1490" endWordPosition="1491">does not impose this restriction on the annotation and class assignment may vary depending on the specific context. Garretson et. al (2004) propose a token level annotation strategy and state that “when coding for animacy [... ] we are not considering the nominal per se (e.g., the word ‘church’), but rather the entity that is the referent of that nominal (e.g. some particular thing in the real world)”. This indicates that for all possible markables, a referent should be determinable. The brief instruction with respect to annotation for human reference in the annotation manual for Talbanken05 (Teleman, 1974, 223) gives leeway for interpretation in the annotation and does not clearly state that it should be based on token level reference in context. It may thus be interesting to examine the extent to which this manual annotation is consistent across lexemes or whether we observe variation. We manually examine the intersection of the two classes of noun lemmas in the written sections of Talbanken, i.e., the set of nouns which have been assigned both classes by the annotators. It contains 82 noun lemmas, which corresponds to only 1.1% of the total number of noun lemmas in the treebank (7554 lemmas </context>
</contexts>
<marker>Teleman, 1974</marker>
<rawString>Ulf Teleman. 1974. Manual f¨or grammatisk beskrivning av talad och skriven svenska. Studentlitteratur, Lund.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weckerly</author>
<author>M Kutas</author>
</authors>
<title>An electrophysiological analysis of animacy effects in the processing of object relative sentences.</title>
<date>1999</date>
<tech>Psychophysiology,</tech>
<pages>36--559</pages>
<contexts>
<context position="1155" citStr="Weckerly and Kutas, 1999" startWordPosition="171" endWordPosition="174">perties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-theart baseline parser with gold standard animacy information. 1 Introduction The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Or˘asan and Evans, 2007), argument disambiguation (Dell’Orletta et al., 2005) and syntactic parsing in general (Øvrelid and Nivre, 2007). The dimension of animacy roughly distinguishes between entities which are alive and entities which are not, however, other distinctions 1Parts of the research reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Sonderforschungsbereich 632, project D4). are also relevant and the animacy dimension is often view</context>
</contexts>
<marker>Weckerly, Kutas, 1999</marker>
<rawString>J. Weckerly and M. Kutas. 1999. An electrophysiological analysis of animacy effects in the processing of object relative sentences. Psychophysiology, 36:559–570.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mutsumi Yamamoto</author>
</authors>
<title>Animacy and Reference: A cognitive approach to corpus linguistics. John Benjamins,</title>
<date>1999</date>
<location>Amsterdam.</location>
<contexts>
<context position="4874" citStr="Yamamoto, 1999" startWordPosition="747" endWordPosition="748">acquisition of animacy based on morphosyntactic features extracted from a considerably larger corpus. Section 5 presents experiments with the acquired animacy information applied in the data-driven dependency parsing of Swedish. Finally, section 6 concludes the article and provides some suggestions for future research. 2 Animacy annotation Annotation for animacy is not a common component of corpora or treebanks. However, following from the theoretical interest in the property of animacy, there have been some initiatives directed at animacy annotation of corpus data. Corpus studies of animacy (Yamamoto, 1999; Dahl and Fraurud, 1996) have made use of annotated data, however they differ in the extent to which the annotation has been explicitly formulated as an annotation scheme. The annotation study presented in Zaenen et. al. (2004) makes use of a coding manual designed for a project studying genitive modification (Garretson et al., 2004) and presents an explicit annotation scheme for animacy, illustrated by figure 1. The main class distinction for animacy is three-way, distinguishing Human, Other animate and Inanimate, with subclasses under two of the main classes. The ‘Other animate’ class furth</context>
<context position="6271" citStr="Yamamoto, 1999" startWordPosition="965" endWordPosition="966">als.2 The annotation scheme described in Zaenen et. al. (2004) annotates the markables according to 2The fact that the study focuses on genitival modification has clearly influenced the categories distinguished, as these are all distinctions which have been claimed to influence the choice of genitive construction. For instance, temporal nouns are frequent in genitive constructions, unlike the other inanimate nouns. the animacy of their referent in the particular context. Animacy is thus treated as a token level property, however, has also been proposed as a lexical semantic property of nouns (Yamamoto, 1999). The indirect encoding of animacy in lexical resources, such as WordNet (Fellbaum, 1998) can also be seen as treating animacy as a typelevel property. We may thus distinguish between a purely type level annotation strategy and a purely token level one. Type level properties hold for lexemes and are context-independent, i.e., independent of the particular linguistic context, whereas token-level properties are determined in context and hold for referring expressions, rather than lexemes. 3 Human reference in Swedish Talbanken05 is a Swedish treebank which was created in the 1970’s and which has</context>
</contexts>
<marker>Yamamoto, 1999</marker>
<rawString>Mutsumi Yamamoto. 1999. Animacy and Reference: A cognitive approach to corpus linguistics. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wasow</author>
</authors>
<title>Animacy encoding in English: why and how.</title>
<date>2004</date>
<booktitle>Proceedings of the ACL Workshop on Discourse Annotation.</booktitle>
<editor>Annie Zaenen, Jean Carletta, Gregory Garretson, Joan Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina, M. Catherine O’Connor, and Tom</editor>
<marker>Wasow, 2004</marker>
<rawString>Annie Zaenen, Jean Carletta, Gregory Garretson, Joan Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina, M. Catherine O’Connor, and Tom Wasow. 2004. Animacy encoding in English: why and how. In Donna Byron and Bonnie Webber, editors, Proceedings of the ACL Workshop on Discourse Annotation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>