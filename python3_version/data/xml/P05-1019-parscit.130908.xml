<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003430">
<title confidence="0.992391">
Modelling the substitutability of discourse connectives
</title>
<author confidence="0.996551">
Ben Hutchinson
</author>
<affiliation confidence="0.9988665">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.996789">
B.Hutchinson@sms.ed.ac.uk
</email>
<sectionHeader confidence="0.995626" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999799083333333">
Processing discourse connectives is im-
portant for tasks such as discourse parsing
and generation. For these tasks, it is use-
ful to know which connectives can signal
the same coherence relations. This paper
presents experiments into modelling the
substitutability of discourse connectives.
It shows that substitutability effects dis-
tributional similarity. A novel variance-
based function for comparing probability
distributions is found to assist in predict-
ing substitutability.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999950019607843">
Discourse coherence relations contribute to the
meaning of texts, by specifying the relationships be-
tween semantic objects such as events and propo-
sitions. They also assist in the interpretation of
anaphora, verb phrase ellipsis and lexical ambigu-
ities (Hobbs, 1985; Kehler, 2002; Asher and Las-
carides, 2003). Coherence relations can be implicit,
or they can be signalled explicitly through the use of
discourse connectives, e.g. because, even though.
For a machine to interpret a text, it is impor-
tant that it recognises coherence relations, and so as
explicit markers discourse connectives are of great
assistance (Marcu, 2000). When discourse con-
nectives are not present, the task is more difficult.
For such cases, unsupervised approaches have been
developed for predicting relations, by using sen-
tences containing discourse connectives as training
data (Marcu and Echihabi, 2002; Lapata and Las-
carides, 2004). However the nature of the relation-
ship between the coherence relations signalled by
discourse connectives and their empirical distribu-
tions has to date been poorly understood. In par-
ticular, one might wonder whether connectives with
similar meanings also have similar distributions.
Concerning natural language generation, texts are
easier for humans to understand if they are coher-
ently structured. Addressing this, a body of research
has considered the problems of generating appropri-
ate discourse connectives (for example (Moser and
Moore, 1995; Grote and Stede, 1998)). One such
problem involves choosing which connective to gen-
erate, as the mapping between connectives and re-
lations is not one-to-one, but rather many-to-many.
Siddharthan (2003) considers the task of paraphras-
ing a text while preserving its rhetorical relations.
Clauses conjoined by but, or and when are sepa-
rated to form distinct orthographic sentences, and
these conjunctions are replaced by the discourse ad-
verbials however, otherwise and then, respectively.
The idea underlying Siddharthan’s work is that
one connective can be substituted for another while
preserving the meaning of a text. Knott (1996)
studies the substitutability of discourse connectives,
and proposes that substitutability can motivate the-
ories of discourse coherence. Knott uses an empiri-
cal methodology to determine the substitutability of
pairs of connectives. However this methodology is
manually intensive, and Knott derives relationships
for only about 18% of pairs of connectives. It would
thus be useful if substitutability could be predicted
automatically.
</bodyText>
<page confidence="0.985403">
149
</page>
<note confidence="0.991621">
Proceedings of the 43rd Annual Meeting of the ACL, pages 149–156,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.999889666666667">
This paper proposes that substitutability can be
predicted through statistical analysis of the contexts
in which connectives appear. Similar methods have
been developed for predicting the similarity of nouns
and verbs on the basis of their distributional similar-
ity, and many distributional similarity functions have
been proposed for these tasks (Lee, 1999). However
substitutability is a more complex notion than simi-
larity, and we propose a novel variance-based func-
tion for assisting in this task.
This paper constitutes a first step towards predict-
ing substitutability of cnonectives automatically. We
demonstrate that the substitutability of connectives
has significant effects on both distributional similar-
ity and the new variance-based function. We then at-
tempt to predict substitutability of connectives using
a simplified task that factors out the prior likelihood
of being substitutable.
</bodyText>
<sectionHeader confidence="0.921035" genericHeader="introduction">
2 Relationships between connectives
</sectionHeader>
<bodyText confidence="0.993065">
Two types of relationships between connectives are
of interest: similarity and substitutability.
</bodyText>
<subsectionHeader confidence="0.980771">
2.1 Similarity
</subsectionHeader>
<bodyText confidence="0.999299826086956">
The concept of lexical similarity occupies an impor-
tant role in psychology, artificial intelligence, and
computational linguistics. For example, in psychol-
ogy, Miller and Charles (1991) report that psycholo-
gists ‘have largely abandoned “synonymy” in favour
of “semantic similarity”.’ In addition, work in au-
tomatic lexical acquisition is based on the proposi-
tion that distributional similarity correlates with se-
mantic similarity (Grefenstette, 1994; Curran and
Moens, 2002; Weeds and Weir, 2003).
Several studies have found subjects’ judge-
ments of semantic similarity to be robust. For
example, Miller and Charles (1991) elicit similar-
ity judgements for 30 pairs of nouns such as
cord–smile, and found a high correlation with
judgements of the same data obtained over 25
years previously (Rubenstein and Goodenough,
1965). Resnik (1999) repeated the experiment,
and calculated an inter-rater agreement of 0.90.
Resnik and Diab (2000) also performed a similar
experiment with pairs of verbs (e.g. bathe–kneel).
The level of inter-rater agreement was again signifi-
cant (r = 0.76).
</bodyText>
<listItem confidence="0.999741111111111">
1. Take an instance of a discourse connective
in a corpus. Imagine you are the writer
that produced this text, but that you need to
choose an alternative connective.
2. Remove the connective from the text, and
insert another connective in its place.
3. If the new connective achieves the same dis-
course goals as the original one, it is consid-
ered substitutable in this context.
</listItem>
<figureCaption confidence="0.997055">
Figure 1: Knott’s Test for Substitutability
</figureCaption>
<bodyText confidence="0.999973">
Given two words, it has been suggested that if
words have the similar meanings, then they can be
expected to have similar contextual distributions.
The studies listed above have also found evidence
that similarity ratings correlate positively with the
distributional similarity of the lexical items.
</bodyText>
<subsectionHeader confidence="0.997845">
2.2 Substitutability
</subsectionHeader>
<bodyText confidence="0.980141142857143">
The notion of substitutability has played an impor-
tant role in theories of lexical relations. A defini-
tion of synonymy attributed to Leibniz states that
two words are synonyms if one word can be used in
place of the other without affecting truth conditions.
Unlike similarity, the substitutability of dis-
course connectives has been previously studied.
Halliday and Hasan (1976) note that in certain con-
texts otherwise can be paraphrased by if not, as in
(1) It’s the way I like to go to work.
One person and one line of enquiry at a time.
Otherwise/if not, there’s a muddle.
They also suggest some other extended paraphrases
of otherwise, such as under other circumstances.
Knott (1996) systematises the study of the substi-
tutability of discourse connectives. His first step is
to propose a Test for Substitutability for connectives,
which is summarised in Figure 1. An application of
the Test is illustrated by (2). Here seeing as was
the connective originally used by the writer, how-
ever because can be used instead.
</bodyText>
<page confidence="0.981284">
150
</page>
<figure confidence="0.991823818181818">
w1
w2
w1
w2
w1
w2
w1
w2
(a) w1 and w2 are (b) w1 is a (c) w1 and w2 are (d) w1 and w2 are
SYNONYMS HYPONYM of w2 CONTINGENTLY EXCLUSIVE
SUBSTITUTABLE
</figure>
<figureCaption confidence="0.999753">
Figure 2: Venn diagrams representing relationships between distributions
</figureCaption>
<bodyText confidence="0.999725096774194">
Given examples (2)–(4) we can conclude that be-
cause and seeing as are CONTINGENTLY SUBSTI-
TUTABLE (henceforth “CONT. SUBS.”). However
this is the only relationship that can be established
using a finite number of linguistic examples. The
other relationships all involve generalisations over
all contexts, and so rely to some degree on the judge-
ment of the analyst. Examples of each relationship
given by Knott (1996) include: given that and see-
ing as are SYNONYMS, on the grounds that is a HY-
PONYM of because, and because and now that are
EXCLUSIVE.
Although substitutability is inherently a more
complex notion than similarity, distributional simi-
larity is expected to be of some use in predicting sub-
stitutability relationships. For example, if two dis-
course connectives are SYNONYMS then we would
expect them to have similar distributions. On the
other hand, if two connectives are EXCLUSIVE, then
we would expect them to have dissimilar distribu-
tions. However if the relationship between two con-
nectives is HYPONYMY or CONT. SUBS. then we
expect to have partial overlap between their distribu-
tions (consider Figure 2), and so distributional simi-
larity might not distinguish these relationships.
The Kullback-Leibler (KL) divergence function
is a distributional similarity function that is of par-
ticular relevance here since it can be described in-
formally in terms of substitutability. Given co-
occurrence distributions p and q, its mathematical
definition can be written as:
</bodyText>
<equation confidence="0.981448333333333">
� 1 1
D(p||q) = p(x)(log − log p(x)) (5)
X q(x)x)
</equation>
<listItem confidence="0.711428333333333">
(2) Seeing as/because we’ve got nothing but
circumstantial evidence, it’s going to be
difficult to get a conviction. (Knott, p. 177)
</listItem>
<bodyText confidence="0.998467666666667">
However the ability to substitute is sensitive to the
context. In other contexts, for example (3), the sub-
stitution of because for seeing as is not valid.
</bodyText>
<listItem confidence="0.961390125">
(3) It’s a fairly good piece of work, seeing
as/#because you have been under a lot of
pressure recently. (Knott, p. 177)
Similarly, there are contexts in which because can
be used, but seeing as cannot be substituted for it:
(4) That proposal is useful, because/#seeing as it
gives us a fallback position if the negotiations
collapse. (Knott, p. 177)
</listItem>
<bodyText confidence="0.999556333333333">
Knott’s next step is to generalise over all contexts
a connective appears in, and to define four substi-
tutability relationships that can hold between a pair
of connectives w1 and w2. These relationships are
illustrated graphically through the use of Venn dia-
grams in Figure 2, and defined below.
</bodyText>
<listItem confidence="0.949690222222222">
• w1 is a SYNONYM of w2 if w1 can always be
substituted for w2, and vice versa.
• w1 and w2 are EXCLUSIVE if neither can ever
be substituted for the other.
• w1 is a HYPONYM of w2 if w2 can always be
substituted for w1, but not vice versa.
• w1 and w2 are CONTINGENTLY SUBSTI-
TUTABLE if each can sometimes, but not al-
ways, be substituted for the other.
</listItem>
<page confidence="0.959704">
151
</page>
<figure confidence="0.984782916666667">
w1
w2
w2
w1
w1
w2
w1
w2
w1
w2
(a) w1 and w2 (b) w2 is a HY- (c) w1 is a HY- (d) w1 and w2 are (e) w1 and w2 are
are SYNONYMS PONYM of w1 PONYM of w2 CONT. SUBS. EXCLUSIVE
</figure>
<figureCaption confidence="0.999957">
Figure 3: Surprise in substituting w2 for w1 (darker shading indicates higher surprise)
</figureCaption>
<bodyText confidence="0.9968465">
The value log 1
p�x) has an informal interpretation as
a measure of how surprised an observer would be
to see event x, given prior likelihood expectations
defined by p. Thus, if p and q are the distributions of
words w1 and w2 then
</bodyText>
<equation confidence="0.997425">
D(p||q) = Ep(surprise in seeing w2
− surprise in seeing w1) (6)
</equation>
<bodyText confidence="0.9999732">
where Ep is the expectation function over the distri-
bution of w1 (i.e. p). That is, KL divergence mea-
sures how much more surprised we would be, on
average, to see word w2 rather than w1, where the
averaging is weighted by the distribution of w1.
</bodyText>
<sectionHeader confidence="0.972632" genericHeader="method">
3 A variance-based function for
distributional analysis
</sectionHeader>
<bodyText confidence="0.999958571428571">
A distributional similarity function provides only
a one-dimensional comparison of two distributions,
namely how similar they are. However we can ob-
tain an additional perspective by using a variance-
based function. We now introduce a new function V
by taking the variance of the surprise in seeing w2,
over the contexts in which w1 appears:
</bodyText>
<equation confidence="0.996800666666667">
V (p, q) = V ar(surprise in seeing w2)
1 1
= Ep((Ep(log q(x)) − log q(x))2) (7)
</equation>
<bodyText confidence="0.995462333333333">
Note that like KL divergence, V (p, q) is asymmetric.
We now consider how the substitutability of con-
nectives affects our expectations of the value of V .
If two connectives are SYNONYMS then each can
always be used in place of other. Thus we would
always expect a low level of surprise in seeing one
</bodyText>
<table confidence="0.998956833333333">
Relationship D(p||q) Function V (p, q) V (q, p)
of w1 to w2 D(q||p)
SYNONYM Low Low Low Low
HYPONYM Low Medium Low High
CONT. SUBS. Medium Medium High High
EXCLUSIVE High High Low Low
</table>
<tableCaption confidence="0.999422">
Table 1: Expectations for distributional functions
</tableCaption>
<bodyText confidence="0.99993252173913">
connective in place of the other, and this low level of
surprise is indicated via light shading in Figure 3a.
It follows that the variance in surprise is low. On the
other hand, if two connectives are EXCLUSIVE then
there would always be a high degree of surprise in
seeing one in place of the other. This is indicated
using dark shading in Figure 3e. Only one set is
shaded because we need only consider the contexts
in which w1 is appropriate. In this case, the vari-
ance in surprise is again low. The situation is more
interesting when we consider two connectives that
are CONT. SUBS.. In this case substitutability (and
hence surprise) is dependent on the context. This
is illustrated using light and dark shading in Fig-
ure 3d. As a result, the variance in surprise is high.
Finally, with HYPONYMY, the variance in surprise
depends on whether the original connective was the
HYPONYM or the HYPERNYM.
Table 1 summarises our expectations of the val-
ues of KL divergence and V , for the various sub-
stitutability relationships. (KL divergence, unlike
most similarity functions, is sensitive to the order of
arguments related by hyponymy (Lee, 1999).) The
</bodyText>
<page confidence="0.991094">
152
</page>
<bodyText confidence="0.697478333333333">
Something happened and something else happened.
Something happened or something else happened.
0 0 0 1 0 2 0 3 0 4 0 5
</bodyText>
<figureCaption confidence="0.953961">
Figure 4: Example experimental item
</figureCaption>
<table confidence="0.9997962">
Mean HYP CONT. SUBS. EXCL
SYNONYM 3.97 * * *
HYPONYM 3.43 * *
CONT. SUBS. 1.79 *
EXCLUSIVE 1.08
</table>
<tableCaption confidence="0.998599">
Table 2: Similarity by substitutability relationship
</tableCaption>
<bodyText confidence="0.9208945">
experiments described below test these expectations
using empirical data.
</bodyText>
<sectionHeader confidence="0.999552" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999972333333333">
We now describe our empirical experiments which
investigate the connections between a) subjects’ rat-
ings of the similarity of discourse connectives, b)
the substitutability of discourse connectives, and c)
KL divergence and the new function V applied to
the distributions of connectives. Our motivation is
to explore how distributional properties of words
might be used to predict substitutability. The ex-
periments are restricted to connectives which relate
clauses within a sentence. These include coordinat-
ing conjunctions (e.g. but) and a range of subordina-
tors including conjunctions (e.g. because) as well as
phrases introducing adverbial clauses (e.g. now that,
given that, for the reason that). Adverbial discourse
connectives are therefore not considered.
</bodyText>
<subsectionHeader confidence="0.99153">
4.1 Experiment 1: Subject ratings of similarity
</subsectionHeader>
<bodyText confidence="0.999972">
This experiment tests the hypotheses that 1) subjects
agree on the degree of similarity between pairs of
discourse connectives, and 2) similarity ratings cor-
relate with the degree of substitutability.
</bodyText>
<subsectionHeader confidence="0.553416">
4.1.1 Methodology
</subsectionHeader>
<bodyText confidence="0.9999898125">
We randomly selected 48 pairs of discourse con-
nectives such that there were 12 pairs standing in
each of the four substitutability relationships.To do
this, we used substitutability judgements made by
Knott (1996), supplemented with some judgements
of our own. Each experimental item consisted of
the two discourse connectives along with dummy
clauses, as illustrated in Figure 4. The format of the
experimental items was designed to indicate how a
phrase could be used as a discourse connective (e.g.
it may not be obvious to a subject that the phrase
the moment is a discourse connective), but without
providing complete semantics for the clauses, which
might bias the subjects’ ratings. Forty native speak-
ers of English participated in the experiment, which
was conducted remotely via the internet.
</bodyText>
<sectionHeader confidence="0.895537" genericHeader="method">
4.1.2 Results
</sectionHeader>
<bodyText confidence="0.999978">
Leave-one-out resampling was used to compare
each subject’s ratings are with the means of their
peers’ (Weiss and Kulikowski, 1991). The average
inter-subject correlation was 0.75 (Min = 0.49, Max
= 0.86, StdDev = 0.09), which is comparable to pre-
vious results on verb similarity ratings (Resnik and
Diab, 2000). The effect of substitutability on simi-
larity ratings can be seen in Table 2. Post-hoc Tukey
tests revealed all differences between means in Ta-
ble 2 to be significant.
The results demonstrate that subjects’ ratings of
connective similarity show significant agreement
and are robust enough for effects of substitutability
to be found.
</bodyText>
<subsectionHeader confidence="0.956019">
4.2 Experiment 2: Modelling similarity
</subsectionHeader>
<bodyText confidence="0.99993">
This experiment compares subjects’ ratings of sim-
ilarity with lexical co-occurrence data. It hypothe-
sises that similarity ratings correlate with distribu-
tional similarity, but that neither correlates with the
new variance in surprise function.
</bodyText>
<subsectionHeader confidence="0.60397">
4.2.1 Methodology
</subsectionHeader>
<bodyText confidence="0.999634666666667">
Sentences containing discourse connectives were
gathered from the British National Corpus and the
world wide web, with discourse connectives identi-
fied on the basis of their syntactic contexts (for de-
tails, see Hutchinson (2004b)). The mean number
of sentences per connective was about 32, 000, al-
though about 12% of these are estimated to be er-
rors. From these sentences, lexical co-occurrence
data were collected. Only co-occurrences with dis-
</bodyText>
<page confidence="0.995701">
153
</page>
<figure confidence="0.997547">
0 1 2 3 4 5
Similarity judgements
</figure>
<figureCaption confidence="0.999953">
Figure 5: Similarity versus distributional divergence
</figureCaption>
<bodyText confidence="0.99747575">
course adverbials and other structural discourse con-
nectives were stored, as these had previously been
found to be useful for predicting semantic features
of connectives (Hutchinson, 2004a).
</bodyText>
<sectionHeader confidence="0.855067" genericHeader="evaluation">
4.2.2 Results
</sectionHeader>
<bodyText confidence="0.999900173913044">
A skewed variant of the Kullback-Leibler diver-
gence function was used to compare co-occurrence
distributions (Lee, 1999, with α = 0.95). Spear-
man’s correlation coefficient for ranked data showed
a significant correlation (r = −0.51, p &lt; 0.001).
(The correlation is negative because KL divergence
is lower when distributions are more similar.) The
strength of this correlation is comparable with sim-
ilar results achieved for verbs (Resnik and Diab,
2000), but not as great as has been observed for
nouns (McDonald, 2000). Figure 5 plots the mean
similarity judgements against the distributional di-
vergence obtained using discourse markers, and also
indicates the substitutability relationship for each
item. (Two outliers can be observed in the upper left
corner; these were excluded from the calculations.)
The “variance in surprise” function introduced in
the previous section was applied to the same co-
occurrence data.1 These variances were compared
to distributional divergence and the subjects’ simi-
larity ratings, but in both cases Spearman’s correla-
tion coefficient was not significant.
In combination with the previous experiment,
</bodyText>
<footnote confidence="0.75518">
1In practice, the skewed variant V (p, 0.95q + 0.05p) was
used, in order to avoid problems arising when q(x) = 0.
</footnote>
<bodyText confidence="0.999973333333333">
these results demonstrate a three way correspon-
dence between the human ratings of the similar-
ity of a pair of connectives, their substitutabil-
ity relationship, and their distributional similarity.
Hutchinson (2005) presents further experiments on
modelling connective similarity, and discusses their
implications. This experiment also provides empiri-
cal evidence that the new variance in surprise func-
tion is not a measure of similarity.
</bodyText>
<subsectionHeader confidence="0.998992">
4.3 Experiment 3: Predicting substitutability
</subsectionHeader>
<bodyText confidence="0.999994066666667">
The previous experiments provide hope that sub-
stitutability of connectives might be predicted on
the basis of their empirical distributions. However
one complicating factor is that EXCLUSIVE is by far
the most likely relationship, holding between about
70% of pairs. Preliminary experiments showed
that the empirical evidence for other relationships
was not strong enough to overcome this prior bias.
We therefore attempted two pseudodisambiguation
tasks which eliminated the effects of prior likeli-
hoods. The first task involved distinguishing be-
tween the relationships whose connectives subjects
rated as most similar, namely SYNONYMY and HY-
PONYMY. Triples of connectives (p, q, q&apos;) were
collected such that SYNONYM(p, q) and either HY-
PONYM(p, q&apos;) or HYPONYM(q&apos;, p) (we were not at-
tempting to predict the order of HYPONYMY). The
task was then to decide automatically which of q and
q&apos; is the SYNONYM of p.
The second task was identical in nature to the first,
however here the relationship between p and q was
either SYNONYMY or HYPONYMY, while p and q&apos;
were either CONT. SUBS. or EXCLUSIVE. These
two sets of relationships are those corresponding to
high and low similarity, respectively. In combina-
tion, the two tasks are equivalent to predicting SYN-
ONYMY or HYPONYMY from the set of all four rela-
tionships, by first distinguishing the high similarity
relationships from the other two, and then making a
finer-grained distinction between the two.
</bodyText>
<subsectionHeader confidence="0.78869">
4.3.1 Methodology
</subsectionHeader>
<bodyText confidence="0.9999092">
Substitutability relationships between 49 struc-
tural discourse connectives were extracted from
Knott’s (1996) classification. In order to obtain more
evaluation data, we used Knott’s methodology to ob-
tain relationships between an additional 32 connec-
</bodyText>
<figure confidence="0.99702325">
best fit
SYNONYM
HYPONYM
CONT SUBS
EXCLUSIVE
2.5
2
1.5
1
0.5
0
Divergence of DM co-occurrences
</figure>
<page confidence="0.99736">
154
</page>
<table confidence="0.9997408">
max(D1, D2) max(V1, V2) (V1 − V2)2
SYN 0.627 4.44 3.29
HYP 0.720 5.16 8.02
CONT 1.057 4.85 7.81
EXCL 1.069 4.79 7.27
</table>
<tableCaption confidence="0.998728">
Table 3: Distributional analysis by substitutability
</tableCaption>
<bodyText confidence="0.999509466666667">
tives. This resulted in 46 triples (p, q, q&apos;) for the first
task, and 10,912 triples for the second task.
The co-occurrence data from the previous section
were re-used. These were used to calculate D(p||q)
and V (p, q). Both of these are asymmetric, so for
our purposes we took the maximum of applying
their arguments in both orders. Recall from Table 1
that when two connectives are in a HYPONYMY re-
lation we expect V to be sensitive to the order in
which the connectives are given as arguments. To
test this, we also calculated (V (p, q) − V (q, p))2,
i.e. the square of the difference of applying the argu-
ments to V in both orders. The average values are
summarised in Table 3, with D1 and D2 (and V1 and
V2) denoting different orderings of the arguments to
D (and V ), and max denoting the function which
selects the larger of two numbers.
These statistics show that our theoretically moti-
vated expectations are supported. In particular, (1)
SYNONYMOUS connectives have the least distribu-
tional divergence and EXCLUSIVE connectives the
most, (2) CONT. SUBS. and HYPONYMOUS connec-
tives have the greatest values for V , and (3) V shows
the greatest sensitivity to the order of its arguments
in the case of HYPONYMY.
The co-occurrence data were used to construct a
Gaussian classifier, by assuming the values for D
and V are generated by Gaussians.2 First, normal
functions were used to calculate the likelihood ratio
of p and q being in the two relationships:
</bodyText>
<equation confidence="0.8434418">
P(data|syn)
(8)
P(data|hyp)
= 1 n(max(D1, D2); µsyn,Qs yn) 9)
n(max(D1, D2); µhyp, Qhyp) (
</equation>
<footnote confidence="0.9155945">
2KL divergence is right skewed, so a log-normal model was
used to model D, whereas a normal model used for V .
</footnote>
<table confidence="0.980573">
Input to Gaussian SYN vs SYN/HYP vs
Model HYP EX/CONT
max(D1, D2) 50.0% 76.1%
max(V1, V2) 84.8% 60.6%
</table>
<tableCaption confidence="0.999797">
Table 4: Accuracy on pseudodisambiguation task
</tableCaption>
<bodyText confidence="0.99996125">
where n(x; µ, Q) is the normal function with mean
µ and standard deviation Q, and where µsyn, for ex-
ample, denotes the mean of the Gaussian model for
SYNONYMY. Next the likelihood ratio for p and
q was divided by that for p and q&apos;. If this value
was greater than 1, the model predicted p and q
were SYNONYMS, otherwise HYPONYMS. The same
technique was used for the second task.
</bodyText>
<sectionHeader confidence="0.94609" genericHeader="evaluation">
4.3.2 Results
</sectionHeader>
<bodyText confidence="0.999969217391304">
A leave-one-out cross validation procedure was
used. For each triple (p, q, q&apos;), the data concern-
ing the pairs p, q and p, q&apos; were held back, and the
remaining data used to construct the models. The
results are shown in Table 4. For comparison, a ran-
dom baseline classifier achieves 50% accuracy.
The results demonstrate the utility of the new
variance-based function V . The new variance-based
function V is better than KL divergence at dis-
tinguishing HYPONYMY from SYNONYMY (x2 =
11.13, df = 1, p &lt; 0.001), although it performs
worse on the coarser grained task. This is consis-
tent with the expectations of Table 1. The two clas-
sifiers were also combined by making a naive Bayes
assumption. This gave an accuracy of 76.1% on the
first task, which is significantly better than just us-
ing KL divergence (x2 = 5.65, df = 1, p &lt; 0.05),
and not significantly worse than using V . The com-
bination’s accuracy on the second task was 76.2%,
which is about the same as using KL divergence.
This shows that combining similarity- and variance-
based measures can be useful can improve overall
performance.
</bodyText>
<sectionHeader confidence="0.999633" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999653666666667">
The concepts of lexical similarity and substitutabil-
ity are of central importance to psychology, ar-
tificial intelligence and computational linguistics.
</bodyText>
<equation confidence="0.9949495">
P(syn|data) P(syn)
P(hyp|data) P(hyp) �
</equation>
<page confidence="0.99625">
155
</page>
<bodyText confidence="0.99999129032258">
To our knowledge this is the first modelling study
of how these concepts relate to lexical items in-
volved in discourse-level phenomena. We found a
three way correspondence between data sources of
quite distinct types: distributional similarity scores
obtained from lexical co-occurrence data, substi-
tutability judgements made by linguists, and the
similarity ratings of naive subjects.
The substitutability of lexical items is important
for applications such as text simplification, where it
can be desirable to paraphrase one discourse con-
nective using another. Ultimately we would like to
automatically predict substitutability for individual
tokens. However predicting whether one connective
can either a) always, b) sometimes or c) never be
substituted for another is a step towards this goal.
Our results demonstrate that these general substi-
tutability relationships have empirical correlates.
We have introduced a novel variance-based func-
tion of two distributions which complements distri-
butional similarity. We demonstrated the new func-
tion’s utility in helping to predict the substitutabil-
ity of connectives, and it can be expected to have
wider applicability to lexical acquisition tasks. In
particular, it is expected to be useful for learning
relationships which cannot be characterised purely
in terms of similarity, such as hyponymy. In future
work we will analyse further the empirical proper-
ties of the new function, and investigate its applica-
bility to learning relationships between other classes
of lexical items such as nouns.
</bodyText>
<sectionHeader confidence="0.994407" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9973776">
I would like to thank Mirella Lapata, Alex Las-
carides, Alistair Knott, and the anonymous ACL re-
viewers for their helpful comments. This research
was supported by EPSRC Grant GR/R40036/01 and
a University of Sydney Travelling Scholarship.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999784547945205">
Nicholas Asher and Alex Lascarides. 2003. Logics of Conver-
sation. Cambridge University Press.
James R. Curran and M. Moens. 2002. Improvements in auto-
matic thesaurus extraction. In Proceedings of the Workshop
on Unsupervised Lexical Acquisition, Philadelphia, USA.
Gregory Grefenstette. 1994. Explorations in Automatic The-
saurus Discovery. Kluwer Academic Publishers, Boston.
Brigitte Grote and Manfred Stede. 1998. Discourse marker
choice in sentence planning. In Eduard Hovy, editor, Pro-
ceedings of the Ninth International Workshop on Natural
Language Generation, pages 128–137, New Brunswick,
New Jersey. Association for Computational Linguistics.
M. Halliday and R. Hasan. 1976. Cohesion in English. Long-
man.
Jerry A Hobbs. 1985. On the coherence and structure of dis-
course. Technical Report CSLI-85-37, Center for the Study
of Language and Information, Stanford University.
Ben Hutchinson. 2004a. Acquiring the meaning of discourse
markers. In Proceedings of the 42nd Annual Meeting of
the Association for Computational Linguistics (ACL 2004),
pages 685–692.
Ben Hutchinson. 2004b. Mining the web for discourse mark-
ers. In Proceedings of the Fourth International Conference
on Language Resources and Evaluation (LREC 2004), pages
407–410, Lisbon, Portugal.
Ben Hutchinson. 2005. Modelling the similarity of discourse
connectives. To appear in Proceedings of the the 27th An-
nual Meeting of the Cognitive Science Society (CogSci2005).
Andrew Kehler. 2002. Coherence, Reference and the Theory of
Grammar. CSLI publications.
Alistair Knott. 1996. A data-driven methodology for motivat-
ing a set of coherence relations. Ph.D. thesis, University of
Edinburgh.
Mirella Lapata and Alex Lascarides. 2004. Inferring sentence-
internal temporal relations. In In Proceedings of the Human
Language Technology Conference and the North American
Chapter of the Association for Computational Linguistics
Annual Meeting, Boston, MA.
Lillian Lee. 1999. Measures of distributional similarity. In
Proceedings ofACL 1999.
Daniel Marcu and Abdessamad Echihabi. 2002. An unsuper-
vised approach to recognizing discourse relations. In Pro-
ceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL-2002), Philadelphia, PA.
Daniel Marcu. 2000. The Theory and Practice of Discourse
Parsing and Summarization. The MIT Press.
Scott McDonald. 2000. Environmental determinants of lexical
processing effort. Ph.D. thesis, University of Edinburgh.
George A. Miller and William G. Charles. 1991. Contextual
correlates of semantic similarity. Language and Cognitive
Processes, 6(1):1–28.
M. Moser and J. Moore. 1995. Using discourse analysis and
automatic text generation to study discourse cue usage. In
Proceedings of the AAAI 1995 Spring Symposium on Empir-
ical Methods in Discourse Interpretation and Generation.
Philip Resnik and Mona Diab. 2000. Measuring verb similarity.
In Proceedings of the Twenty Second Annual Meeting of the
Cognitive Science Society, Philadelphia, US, August.
Philip Resnik. 1999. Semantic similarity in a taxonomy: An
information-based measure and its application to problems
of ambiguity in natural language. Journal ofArtificialIntel-
ligence Research, 11:95–130.
H. Rubenstein and J. B. Goodenough. 1965. Contextual corre-
lates of synonymy. Computational Linguistics, 8:627–633.
Advaith Siddharthan. 2003. Preserving discourse structure
when simplifying text. In Proceedings of the 2003 European
Natural Language Generation Workshop.
Julie Weeds and David Weir. 2003. A general framework
for distributional similarity. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Processing
(EMNLP 2003), Sapporo, Japan, July.
Sholom M. Weiss and Casimir A. Kulikowski. 1991. Computer
systems that learn. Morgan Kaufmann, San Mateo, CA.
</reference>
<page confidence="0.998783">
156
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.949326">
<title confidence="0.999977">Modelling the substitutability of discourse connectives</title>
<author confidence="0.999828">Ben Hutchinson</author>
<affiliation confidence="0.9998515">School of Informatics University of Edinburgh</affiliation>
<email confidence="0.997064">B.Hutchinson@sms.ed.ac.uk</email>
<abstract confidence="0.996335769230769">Processing discourse connectives is important for tasks such as discourse parsing and generation. For these tasks, it is useful to know which connectives can signal the same coherence relations. This paper presents experiments into modelling the substitutability of discourse connectives. It shows that substitutability effects distributional similarity. A novel variancebased function for comparing probability distributions is found to assist in predicting substitutability.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="952" citStr="Asher and Lascarides, 2003" startWordPosition="127" endWordPosition="131"> coherence relations. This paper presents experiments into modelling the substitutability of discourse connectives. It shows that substitutability effects distributional similarity. A novel variancebased function for comparing probability distributions is found to assist in predicting substitutability. 1 Introduction Discourse coherence relations contribute to the meaning of texts, by specifying the relationships between semantic objects such as events and propositions. They also assist in the interpretation of anaphora, verb phrase ellipsis and lexical ambiguities (Hobbs, 1985; Kehler, 2002; Asher and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, </context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>M Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Unsupervised Lexical Acquisition,</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="4836" citStr="Curran and Moens, 2002" startWordPosition="692" endWordPosition="695"> 2 Relationships between connectives Two types of relationships between connectives are of interest: similarity and substitutability. 2.1 Similarity The concept of lexical similarity occupies an important role in psychology, artificial intelligence, and computational linguistics. For example, in psychology, Miller and Charles (1991) report that psychologists ‘have largely abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was again significant (r = </context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran and M. Moens. 2002. Improvements in automatic thesaurus extraction. In Proceedings of the Workshop on Unsupervised Lexical Acquisition, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Explorations in Automatic Thesaurus Discovery.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston.</location>
<contexts>
<context position="4812" citStr="Grefenstette, 1994" startWordPosition="690" endWordPosition="691">being substitutable. 2 Relationships between connectives Two types of relationships between connectives are of interest: similarity and substitutability. 2.1 Similarity The concept of lexical similarity occupies an important role in psychology, artificial intelligence, and computational linguistics. For example, in psychology, Miller and Charles (1991) report that psychologists ‘have largely abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was</context>
</contexts>
<marker>Grefenstette, 1994</marker>
<rawString>Gregory Grefenstette. 1994. Explorations in Automatic Thesaurus Discovery. Kluwer Academic Publishers, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
<author>Manfred Stede</author>
</authors>
<title>Discourse marker choice in sentence planning.</title>
<date>1998</date>
<booktitle>Proceedings of the Ninth International Workshop on Natural Language Generation,</booktitle>
<pages>128--137</pages>
<editor>In Eduard Hovy, editor,</editor>
<publisher>Association for</publisher>
<location>New Brunswick, New Jersey.</location>
<contexts>
<context position="2130" citStr="Grote and Stede, 1998" startWordPosition="304" endWordPosition="307"> and Echihabi, 2002; Lapata and Lascarides, 2004). However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language generation, texts are easier for humans to understand if they are coherently structured. Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example (Moser and Moore, 1995; Grote and Stede, 1998)). One such problem involves choosing which connective to generate, as the mapping between connectives and relations is not one-to-one, but rather many-to-many. Siddharthan (2003) considers the task of paraphrasing a text while preserving its rhetorical relations. Clauses conjoined by but, or and when are separated to form distinct orthographic sentences, and these conjunctions are replaced by the discourse adverbials however, otherwise and then, respectively. The idea underlying Siddharthan’s work is that one connective can be substituted for another while preserving the meaning of a text. Kn</context>
</contexts>
<marker>Grote, Stede, 1998</marker>
<rawString>Brigitte Grote and Manfred Stede. 1998. Discourse marker choice in sentence planning. In Eduard Hovy, editor, Proceedings of the Ninth International Workshop on Natural Language Generation, pages 128–137, New Brunswick, New Jersey. Association for Computational Linguistics. M. Halliday and R. Hasan. 1976. Cohesion in English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry A Hobbs</author>
</authors>
<title>On the coherence and structure of discourse.</title>
<date>1985</date>
<tech>Technical Report CSLI-85-37,</tech>
<institution>Center for the Study of Language and Information, Stanford University.</institution>
<contexts>
<context position="909" citStr="Hobbs, 1985" startWordPosition="123" endWordPosition="124">ectives can signal the same coherence relations. This paper presents experiments into modelling the substitutability of discourse connectives. It shows that substitutability effects distributional similarity. A novel variancebased function for comparing probability distributions is found to assist in predicting substitutability. 1 Introduction Discourse coherence relations contribute to the meaning of texts, by specifying the relationships between semantic objects such as events and propositions. They also assist in the interpretation of anaphora, verb phrase ellipsis and lexical ambiguities (Hobbs, 1985; Kehler, 2002; Asher and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu </context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry A Hobbs. 1985. On the coherence and structure of discourse. Technical Report CSLI-85-37, Center for the Study of Language and Information, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hutchinson</author>
</authors>
<title>Acquiring the meaning of discourse markers.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>685--692</pages>
<contexts>
<context position="16633" citStr="Hutchinson (2004" startWordPosition="2656" endWordPosition="2657">ignificant agreement and are robust enough for effects of substitutability to be found. 4.2 Experiment 2: Modelling similarity This experiment compares subjects’ ratings of similarity with lexical co-occurrence data. It hypothesises that similarity ratings correlate with distributional similarity, but that neither correlates with the new variance in surprise function. 4.2.1 Methodology Sentences containing discourse connectives were gathered from the British National Corpus and the world wide web, with discourse connectives identified on the basis of their syntactic contexts (for details, see Hutchinson (2004b)). The mean number of sentences per connective was about 32, 000, although about 12% of these are estimated to be errors. From these sentences, lexical co-occurrence data were collected. Only co-occurrences with dis153 0 1 2 3 4 5 Similarity judgements Figure 5: Similarity versus distributional divergence course adverbials and other structural discourse connectives were stored, as these had previously been found to be useful for predicting semantic features of connectives (Hutchinson, 2004a). 4.2.2 Results A skewed variant of the Kullback-Leibler divergence function was used to compare co-oc</context>
</contexts>
<marker>Hutchinson, 2004</marker>
<rawString>Ben Hutchinson. 2004a. Acquiring the meaning of discourse markers. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), pages 685–692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hutchinson</author>
</authors>
<title>Mining the web for discourse markers.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<pages>407--410</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="16633" citStr="Hutchinson (2004" startWordPosition="2656" endWordPosition="2657">ignificant agreement and are robust enough for effects of substitutability to be found. 4.2 Experiment 2: Modelling similarity This experiment compares subjects’ ratings of similarity with lexical co-occurrence data. It hypothesises that similarity ratings correlate with distributional similarity, but that neither correlates with the new variance in surprise function. 4.2.1 Methodology Sentences containing discourse connectives were gathered from the British National Corpus and the world wide web, with discourse connectives identified on the basis of their syntactic contexts (for details, see Hutchinson (2004b)). The mean number of sentences per connective was about 32, 000, although about 12% of these are estimated to be errors. From these sentences, lexical co-occurrence data were collected. Only co-occurrences with dis153 0 1 2 3 4 5 Similarity judgements Figure 5: Similarity versus distributional divergence course adverbials and other structural discourse connectives were stored, as these had previously been found to be useful for predicting semantic features of connectives (Hutchinson, 2004a). 4.2.2 Results A skewed variant of the Kullback-Leibler divergence function was used to compare co-oc</context>
</contexts>
<marker>Hutchinson, 2004</marker>
<rawString>Ben Hutchinson. 2004b. Mining the web for discourse markers. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), pages 407–410, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hutchinson</author>
</authors>
<title>Modelling the similarity of discourse connectives. To appear in</title>
<date>2005</date>
<booktitle>Proceedings of the the 27th Annual Meeting of the Cognitive Science Society (CogSci2005).</booktitle>
<contexts>
<context position="18613" citStr="Hutchinson (2005)" startWordPosition="2959" endWordPosition="2960">uced in the previous section was applied to the same cooccurrence data.1 These variances were compared to distributional divergence and the subjects’ similarity ratings, but in both cases Spearman’s correlation coefficient was not significant. In combination with the previous experiment, 1In practice, the skewed variant V (p, 0.95q + 0.05p) was used, in order to avoid problems arising when q(x) = 0. these results demonstrate a three way correspondence between the human ratings of the similarity of a pair of connectives, their substitutability relationship, and their distributional similarity. Hutchinson (2005) presents further experiments on modelling connective similarity, and discusses their implications. This experiment also provides empirical evidence that the new variance in surprise function is not a measure of similarity. 4.3 Experiment 3: Predicting substitutability The previous experiments provide hope that substitutability of connectives might be predicted on the basis of their empirical distributions. However one complicating factor is that EXCLUSIVE is by far the most likely relationship, holding between about 70% of pairs. Preliminary experiments showed that the empirical evidence for </context>
</contexts>
<marker>Hutchinson, 2005</marker>
<rawString>Ben Hutchinson. 2005. Modelling the similarity of discourse connectives. To appear in Proceedings of the the 27th Annual Meeting of the Cognitive Science Society (CogSci2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
</authors>
<title>Coherence, Reference and the Theory of Grammar.</title>
<date>2002</date>
<publisher>CSLI publications.</publisher>
<contexts>
<context position="923" citStr="Kehler, 2002" startWordPosition="125" endWordPosition="126">ignal the same coherence relations. This paper presents experiments into modelling the substitutability of discourse connectives. It shows that substitutability effects distributional similarity. A novel variancebased function for comparing probability distributions is found to assist in predicting substitutability. 1 Introduction Discourse coherence relations contribute to the meaning of texts, by specifying the relationships between semantic objects such as events and propositions. They also assist in the interpretation of anaphora, verb phrase ellipsis and lexical ambiguities (Hobbs, 1985; Kehler, 2002; Asher and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, </context>
</contexts>
<marker>Kehler, 2002</marker>
<rawString>Andrew Kehler. 2002. Coherence, Reference and the Theory of Grammar. CSLI publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
</authors>
<title>A data-driven methodology for motivating a set of coherence relations.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="2740" citStr="Knott (1996)" startWordPosition="398" endWordPosition="399">8)). One such problem involves choosing which connective to generate, as the mapping between connectives and relations is not one-to-one, but rather many-to-many. Siddharthan (2003) considers the task of paraphrasing a text while preserving its rhetorical relations. Clauses conjoined by but, or and when are separated to form distinct orthographic sentences, and these conjunctions are replaced by the discourse adverbials however, otherwise and then, respectively. The idea underlying Siddharthan’s work is that one connective can be substituted for another while preserving the meaning of a text. Knott (1996) studies the substitutability of discourse connectives, and proposes that substitutability can motivate theories of discourse coherence. Knott uses an empirical methodology to determine the substitutability of pairs of connectives. However this methodology is manually intensive, and Knott derives relationships for only about 18% of pairs of connectives. It would thus be useful if substitutability could be predicted automatically. 149 Proceedings of the 43rd Annual Meeting of the ACL, pages 149–156, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics This paper proposes that </context>
<context position="6872" citStr="Knott (1996)" startWordPosition="1023" endWordPosition="1024"> lexical relations. A definition of synonymy attributed to Leibniz states that two words are synonyms if one word can be used in place of the other without affecting truth conditions. Unlike similarity, the substitutability of discourse connectives has been previously studied. Halliday and Hasan (1976) note that in certain contexts otherwise can be paraphrased by if not, as in (1) It’s the way I like to go to work. One person and one line of enquiry at a time. Otherwise/if not, there’s a muddle. They also suggest some other extended paraphrases of otherwise, such as under other circumstances. Knott (1996) systematises the study of the substitutability of discourse connectives. His first step is to propose a Test for Substitutability for connectives, which is summarised in Figure 1. An application of the Test is illustrated by (2). Here seeing as was the connective originally used by the writer, however because can be used instead. 150 w1 w2 w1 w2 w1 w2 w1 w2 (a) w1 and w2 are (b) w1 is a (c) w1 and w2 are (d) w1 and w2 are SYNONYMS HYPONYM of w2 CONTINGENTLY EXCLUSIVE SUBSTITUTABLE Figure 2: Venn diagrams representing relationships between distributions Given examples (2)–(4) we can conclude t</context>
<context position="14856" citStr="Knott (1996)" startWordPosition="2383" endWordPosition="2384">g adverbial clauses (e.g. now that, given that, for the reason that). Adverbial discourse connectives are therefore not considered. 4.1 Experiment 1: Subject ratings of similarity This experiment tests the hypotheses that 1) subjects agree on the degree of similarity between pairs of discourse connectives, and 2) similarity ratings correlate with the degree of substitutability. 4.1.1 Methodology We randomly selected 48 pairs of discourse connectives such that there were 12 pairs standing in each of the four substitutability relationships.To do this, we used substitutability judgements made by Knott (1996), supplemented with some judgements of our own. Each experimental item consisted of the two discourse connectives along with dummy clauses, as illustrated in Figure 4. The format of the experimental items was designed to indicate how a phrase could be used as a discourse connective (e.g. it may not be obvious to a subject that the phrase the moment is a discourse connective), but without providing complete semantics for the clauses, which might bias the subjects’ ratings. Forty native speakers of English participated in the experiment, which was conducted remotely via the internet. 4.1.2 Resul</context>
</contexts>
<marker>Knott, 1996</marker>
<rawString>Alistair Knott. 1996. A data-driven methodology for motivating a set of coherence relations. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Inferring sentenceinternal temporal relations. In</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="1557" citStr="Lapata and Lascarides, 2004" startWordPosition="219" endWordPosition="223">r and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, 2004). However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language generation, texts are easier for humans to understand if they are coherently structured. Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example (Moser and Moore, 1995; Grote and Stede, 1998)). One such problem involve</context>
</contexts>
<marker>Lapata, Lascarides, 2004</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2004. Inferring sentenceinternal temporal relations. In In Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="3673" citStr="Lee, 1999" startWordPosition="531" endWordPosition="532">out 18% of pairs of connectives. It would thus be useful if substitutability could be predicted automatically. 149 Proceedings of the 43rd Annual Meeting of the ACL, pages 149–156, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics This paper proposes that substitutability can be predicted through statistical analysis of the contexts in which connectives appear. Similar methods have been developed for predicting the similarity of nouns and verbs on the basis of their distributional similarity, and many distributional similarity functions have been proposed for these tasks (Lee, 1999). However substitutability is a more complex notion than similarity, and we propose a novel variance-based function for assisting in this task. This paper constitutes a first step towards predicting substitutability of cnonectives automatically. We demonstrate that the substitutability of connectives has significant effects on both distributional similarity and the new variance-based function. We then attempt to predict substitutability of connectives using a simplified task that factors out the prior likelihood of being substitutable. 2 Relationships between connectives Two types of relations</context>
<context position="13209" citStr="Lee, 1999" startWordPosition="2132" endWordPosition="2133">n we consider two connectives that are CONT. SUBS.. In this case substitutability (and hence surprise) is dependent on the context. This is illustrated using light and dark shading in Figure 3d. As a result, the variance in surprise is high. Finally, with HYPONYMY, the variance in surprise depends on whether the original connective was the HYPONYM or the HYPERNYM. Table 1 summarises our expectations of the values of KL divergence and V , for the various substitutability relationships. (KL divergence, unlike most similarity functions, is sensitive to the order of arguments related by hyponymy (Lee, 1999).) The 152 Something happened and something else happened. Something happened or something else happened. 0 0 0 1 0 2 0 3 0 4 0 5 Figure 4: Example experimental item Mean HYP CONT. SUBS. EXCL SYNONYM 3.97 * * * HYPONYM 3.43 * * CONT. SUBS. 1.79 * EXCLUSIVE 1.08 Table 2: Similarity by substitutability relationship experiments described below test these expectations using empirical data. 4 Experiments We now describe our empirical experiments which investigate the connections between a) subjects’ ratings of the similarity of discourse connectives, b) the substitutability of discourse connectives</context>
<context position="17266" citStr="Lee, 1999" startWordPosition="2752" endWordPosition="2753">sentences per connective was about 32, 000, although about 12% of these are estimated to be errors. From these sentences, lexical co-occurrence data were collected. Only co-occurrences with dis153 0 1 2 3 4 5 Similarity judgements Figure 5: Similarity versus distributional divergence course adverbials and other structural discourse connectives were stored, as these had previously been found to be useful for predicting semantic features of connectives (Hutchinson, 2004a). 4.2.2 Results A skewed variant of the Kullback-Leibler divergence function was used to compare co-occurrence distributions (Lee, 1999, with α = 0.95). Spearman’s correlation coefficient for ranked data showed a significant correlation (r = −0.51, p &lt; 0.001). (The correlation is negative because KL divergence is lower when distributions are more similar.) The strength of this correlation is comparable with similar results achieved for verbs (Resnik and Diab, 2000), but not as great as has been observed for nouns (McDonald, 2000). Figure 5 plots the mean similarity judgements against the distributional divergence obtained using discourse markers, and also indicates the substitutability relationship for each item. (Two outlier</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In Proceedings ofACL 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Abdessamad Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1527" citStr="Marcu and Echihabi, 2002" startWordPosition="215" endWordPosition="218">, 1985; Kehler, 2002; Asher and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, 2004). However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language generation, texts are easier for humans to understand if they are coherently structured. Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example (Moser and Moore, 1995; Grote and Stede, 19</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Daniel Marcu and Abdessamad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="1273" citStr="Marcu, 2000" startWordPosition="180" endWordPosition="181">ce relations contribute to the meaning of texts, by specifying the relationships between semantic objects such as events and propositions. They also assist in the interpretation of anaphora, verb phrase ellipsis and lexical ambiguities (Hobbs, 1985; Kehler, 2002; Asher and Lascarides, 2003). Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though. For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance (Marcu, 2000). When discourse connectives are not present, the task is more difficult. For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, 2004). However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language gen</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott McDonald</author>
</authors>
<title>Environmental determinants of lexical processing effort.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="17666" citStr="McDonald, 2000" startWordPosition="2817" endWordPosition="2818">to be useful for predicting semantic features of connectives (Hutchinson, 2004a). 4.2.2 Results A skewed variant of the Kullback-Leibler divergence function was used to compare co-occurrence distributions (Lee, 1999, with α = 0.95). Spearman’s correlation coefficient for ranked data showed a significant correlation (r = −0.51, p &lt; 0.001). (The correlation is negative because KL divergence is lower when distributions are more similar.) The strength of this correlation is comparable with similar results achieved for verbs (Resnik and Diab, 2000), but not as great as has been observed for nouns (McDonald, 2000). Figure 5 plots the mean similarity judgements against the distributional divergence obtained using discourse markers, and also indicates the substitutability relationship for each item. (Two outliers can be observed in the upper left corner; these were excluded from the calculations.) The “variance in surprise” function introduced in the previous section was applied to the same cooccurrence data.1 These variances were compared to distributional divergence and the subjects’ similarity ratings, but in both cases Spearman’s correlation coefficient was not significant. In combination with the pr</context>
</contexts>
<marker>McDonald, 2000</marker>
<rawString>Scott McDonald. 2000. Environmental determinants of lexical processing effort. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>William G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="4548" citStr="Miller and Charles (1991)" startWordPosition="651" endWordPosition="654">emonstrate that the substitutability of connectives has significant effects on both distributional similarity and the new variance-based function. We then attempt to predict substitutability of connectives using a simplified task that factors out the prior likelihood of being substitutable. 2 Relationships between connectives Two types of relationships between connectives are of interest: similarity and substitutability. 2.1 Similarity The concept of lexical similarity occupies an important role in psychology, artificial intelligence, and computational linguistics. For example, in psychology, Miller and Charles (1991) report that psychologists ‘have largely abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previou</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>George A. Miller and William G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moser</author>
<author>J Moore</author>
</authors>
<title>Using discourse analysis and automatic text generation to study discourse cue usage.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI 1995 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</booktitle>
<contexts>
<context position="2106" citStr="Moser and Moore, 1995" startWordPosition="300" endWordPosition="303">as training data (Marcu and Echihabi, 2002; Lapata and Lascarides, 2004). However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language generation, texts are easier for humans to understand if they are coherently structured. Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example (Moser and Moore, 1995; Grote and Stede, 1998)). One such problem involves choosing which connective to generate, as the mapping between connectives and relations is not one-to-one, but rather many-to-many. Siddharthan (2003) considers the task of paraphrasing a text while preserving its rhetorical relations. Clauses conjoined by but, or and when are separated to form distinct orthographic sentences, and these conjunctions are replaced by the discourse adverbials however, otherwise and then, respectively. The idea underlying Siddharthan’s work is that one connective can be substituted for another while preserving t</context>
</contexts>
<marker>Moser, Moore, 1995</marker>
<rawString>M. Moser and J. Moore. 1995. Using discourse analysis and automatic text generation to study discourse cue usage. In Proceedings of the AAAI 1995 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Mona Diab</author>
</authors>
<title>Measuring verb similarity.</title>
<date>2000</date>
<booktitle>In Proceedings of the Twenty Second Annual Meeting of the Cognitive Science Society,</booktitle>
<location>Philadelphia, US,</location>
<contexts>
<context position="5297" citStr="Resnik and Diab (2000)" startWordPosition="763" endWordPosition="766">ic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was again significant (r = 0.76). 1. Take an instance of a discourse connective in a corpus. Imagine you are the writer that produced this text, but that you need to choose an alternative connective. 2. Remove the connective from the text, and insert another connective in its place. 3. If the new connective achieves the same discourse goals as the original one, it is considered substitutable in this context. Figure 1: Knott’s Test for Substitutability Given two words, it has been sug</context>
<context position="15770" citStr="Resnik and Diab, 2000" startWordPosition="2527" endWordPosition="2530">may not be obvious to a subject that the phrase the moment is a discourse connective), but without providing complete semantics for the clauses, which might bias the subjects’ ratings. Forty native speakers of English participated in the experiment, which was conducted remotely via the internet. 4.1.2 Results Leave-one-out resampling was used to compare each subject’s ratings are with the means of their peers’ (Weiss and Kulikowski, 1991). The average inter-subject correlation was 0.75 (Min = 0.49, Max = 0.86, StdDev = 0.09), which is comparable to previous results on verb similarity ratings (Resnik and Diab, 2000). The effect of substitutability on similarity ratings can be seen in Table 2. Post-hoc Tukey tests revealed all differences between means in Table 2 to be significant. The results demonstrate that subjects’ ratings of connective similarity show significant agreement and are robust enough for effects of substitutability to be found. 4.2 Experiment 2: Modelling similarity This experiment compares subjects’ ratings of similarity with lexical co-occurrence data. It hypothesises that similarity ratings correlate with distributional similarity, but that neither correlates with the new variance in s</context>
<context position="17600" citStr="Resnik and Diab, 2000" startWordPosition="2803" endWordPosition="2806">al discourse connectives were stored, as these had previously been found to be useful for predicting semantic features of connectives (Hutchinson, 2004a). 4.2.2 Results A skewed variant of the Kullback-Leibler divergence function was used to compare co-occurrence distributions (Lee, 1999, with α = 0.95). Spearman’s correlation coefficient for ranked data showed a significant correlation (r = −0.51, p &lt; 0.001). (The correlation is negative because KL divergence is lower when distributions are more similar.) The strength of this correlation is comparable with similar results achieved for verbs (Resnik and Diab, 2000), but not as great as has been observed for nouns (McDonald, 2000). Figure 5 plots the mean similarity judgements against the distributional divergence obtained using discourse markers, and also indicates the substitutability relationship for each item. (Two outliers can be observed in the upper left corner; these were excluded from the calculations.) The “variance in surprise” function introduced in the previous section was applied to the same cooccurrence data.1 These variances were compared to distributional divergence and the subjects’ similarity ratings, but in both cases Spearman’s corre</context>
</contexts>
<marker>Resnik, Diab, 2000</marker>
<rawString>Philip Resnik and Mona Diab. 2000. Measuring verb similarity. In Proceedings of the Twenty Second Annual Meeting of the Cognitive Science Society, Philadelphia, US, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal ofArtificialIntelligence Research,</journal>
<pages>11--95</pages>
<contexts>
<context position="5200" citStr="Resnik (1999)" startWordPosition="751" endWordPosition="752">y abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was again significant (r = 0.76). 1. Take an instance of a discourse connective in a corpus. Imagine you are the writer that produced this text, but that you need to choose an alternative connective. 2. Remove the connective from the text, and insert another connective in its place. 3. If the new connective achieves the same discourse goals as the original one, it is considered substituta</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal ofArtificialIntelligence Research, 11:95–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Computational Linguistics,</journal>
<pages>8--627</pages>
<contexts>
<context position="5185" citStr="Rubenstein and Goodenough, 1965" startWordPosition="747" endWordPosition="750">rt that psychologists ‘have largely abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was again significant (r = 0.76). 1. Take an instance of a discourse connective in a corpus. Imagine you are the writer that produced this text, but that you need to choose an alternative connective. 2. Remove the connective from the text, and insert another connective in its place. 3. If the new connective achieves the same discourse goals as the original one, it is consid</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>H. Rubenstein and J. B. Goodenough. 1965. Contextual correlates of synonymy. Computational Linguistics, 8:627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Preserving discourse structure when simplifying text.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 European Natural Language Generation Workshop.</booktitle>
<contexts>
<context position="2309" citStr="Siddharthan (2003)" startWordPosition="332" endWordPosition="333">butions has to date been poorly understood. In particular, one might wonder whether connectives with similar meanings also have similar distributions. Concerning natural language generation, texts are easier for humans to understand if they are coherently structured. Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example (Moser and Moore, 1995; Grote and Stede, 1998)). One such problem involves choosing which connective to generate, as the mapping between connectives and relations is not one-to-one, but rather many-to-many. Siddharthan (2003) considers the task of paraphrasing a text while preserving its rhetorical relations. Clauses conjoined by but, or and when are separated to form distinct orthographic sentences, and these conjunctions are replaced by the discourse adverbials however, otherwise and then, respectively. The idea underlying Siddharthan’s work is that one connective can be substituted for another while preserving the meaning of a text. Knott (1996) studies the substitutability of discourse connectives, and proposes that substitutability can motivate theories of discourse coherence. Knott uses an empirical methodol</context>
</contexts>
<marker>Siddharthan, 2003</marker>
<rawString>Advaith Siddharthan. 2003. Preserving discourse structure when simplifying text. In Proceedings of the 2003 European Natural Language Generation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2003),</booktitle>
<location>Sapporo, Japan,</location>
<contexts>
<context position="4859" citStr="Weeds and Weir, 2003" startWordPosition="696" endWordPosition="699"> connectives Two types of relationships between connectives are of interest: similarity and substitutability. 2.1 Similarity The concept of lexical similarity occupies an important role in psychology, artificial intelligence, and computational linguistics. For example, in psychology, Miller and Charles (1991) report that psychologists ‘have largely abandoned “synonymy” in favour of “semantic similarity”.’ In addition, work in automatic lexical acquisition is based on the proposition that distributional similarity correlates with semantic similarity (Grefenstette, 1994; Curran and Moens, 2002; Weeds and Weir, 2003). Several studies have found subjects’ judgements of semantic similarity to be robust. For example, Miller and Charles (1991) elicit similarity judgements for 30 pairs of nouns such as cord–smile, and found a high correlation with judgements of the same data obtained over 25 years previously (Rubenstein and Goodenough, 1965). Resnik (1999) repeated the experiment, and calculated an inter-rater agreement of 0.90. Resnik and Diab (2000) also performed a similar experiment with pairs of verbs (e.g. bathe–kneel). The level of inter-rater agreement was again significant (r = 0.76). 1. Take an insta</context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2003), Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sholom M Weiss</author>
<author>Casimir A Kulikowski</author>
</authors>
<title>Computer systems that learn.</title>
<date>1991</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="15590" citStr="Weiss and Kulikowski, 1991" startWordPosition="2497" endWordPosition="2500">ctives along with dummy clauses, as illustrated in Figure 4. The format of the experimental items was designed to indicate how a phrase could be used as a discourse connective (e.g. it may not be obvious to a subject that the phrase the moment is a discourse connective), but without providing complete semantics for the clauses, which might bias the subjects’ ratings. Forty native speakers of English participated in the experiment, which was conducted remotely via the internet. 4.1.2 Results Leave-one-out resampling was used to compare each subject’s ratings are with the means of their peers’ (Weiss and Kulikowski, 1991). The average inter-subject correlation was 0.75 (Min = 0.49, Max = 0.86, StdDev = 0.09), which is comparable to previous results on verb similarity ratings (Resnik and Diab, 2000). The effect of substitutability on similarity ratings can be seen in Table 2. Post-hoc Tukey tests revealed all differences between means in Table 2 to be significant. The results demonstrate that subjects’ ratings of connective similarity show significant agreement and are robust enough for effects of substitutability to be found. 4.2 Experiment 2: Modelling similarity This experiment compares subjects’ ratings of </context>
</contexts>
<marker>Weiss, Kulikowski, 1991</marker>
<rawString>Sholom M. Weiss and Casimir A. Kulikowski. 1991. Computer systems that learn. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>