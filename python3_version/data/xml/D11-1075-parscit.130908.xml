<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.917849">
Unsupervised Information Extraction with Distributional Prior Knowledge
</title>
<author confidence="0.995691">
Cane Wing-ki Leung1, Jing Jiang1, Kian Ming A. Chai2, Hai Leong Chieu2, Loo-Nin Teow2
</author>
<affiliation confidence="0.903682">
1School of Information Systems, Singapore Management University, Singapore
2DSO National Laboratories, Singapore
</affiliation>
<email confidence="0.995413">
icaneleung,jingjiangl@smu.edu.sg, ickianmin,chaileon,tlooninl@dso.org.sg
</email>
<sectionHeader confidence="0.994761" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999934071428572">
We address the task of automatic discovery of
information extraction template from a given
text collection. Our approach clusters candi-
date slot fillers to identify meaningful tem-
plate slots. We propose a generative model
that incorporates distributional prior knowl-
edge to help distribute candidates in a docu-
ment into appropriate slots. Empirical results
suggest that the proposed prior can bring sub-
stantial improvements to our task as compared
to a K-means baseline and a Gaussian mixture
model baseline. Specifically, the proposed
prior has shown to be effective when coupled
with discriminative features of the candidates.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944327272728">
Information extraction (IE) is the task of extract-
ing information from natural language texts to fill a
database record following a structure called a tem-
plate. Such templates are usually defined based
on the domain of interest. For example, the do-
main in the Sixth Message Understanding Confer-
ence (MUC-6, 1995) is management succession, and
the pre-defined template consists of the slots posi-
tion, the person leaving, the person joining, and the
organization.
Previous research on IE often requires the pre-
definition of templates. Template construction is
usually done manually by domain experts, and an-
notated documents are often created to facilitate su-
pervised learning approaches to IE. However, both
manual template construction and data annotation
are labor-intensive. More importantly, templates and
annotated data usually cannot be re-used in new do-
mains due to domain dependency. It is therefore nat-
ural to consider the problem of unsupervised tem-
plate induction and information extraction. This is
the topic of this paper.
There have been a few previous attempts to ad-
dress the unsupervised IE problem (Shinyama and
Sekine, 2006; Sekine, 2006; Rosenfeld and Feld-
man, 2006; Filatova et al., 2006). These approaches
have a commonality: they try to cluster candidate
slot fillers, which are often nouns and noun phrases,
into slots of the template to be constructed. How-
ever, most of them have neglected the following im-
portant observation: a single document or text seg-
ment tends to cover different slots rather than re-
dundantly fill the same slot. In other words, during
clustering, candidates within the same text segment
should be more likely to be distributed into different
clusters.
In this paper, we propose a generative model that
incorporates this distributional prior knowledge. We
define a prior distribution over the possible label
assignments in a document or a text segment such
that a more diversified label assignment is preferred.
This prior is based on the Poisson distribution. We
also compare a number of generative models for
generating slot fillers and find that the Gaussian mix-
ture model is the best. We then combine the Poisson-
based label assignment prior with the Gaussian mix-
ture model to perform slot clustering. We find that
compared with a K-means baseline and a Gaussian
mixture model baseline, our combined model with
the proposed label assignment prior substantially
performs better on two of the three data sets we use
for evaluation. We further analyze the results on the
third data set and find that the proposed prior will
have little effect if there are no good discriminative
features to begin with. In summary, we find that
</bodyText>
<page confidence="0.974257">
814
</page>
<note confidence="0.958457">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 814–824,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9732575">
our Poisson-based label assignment prior is effective
when coupled with good discriminative features.
</bodyText>
<sectionHeader confidence="0.999291" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999978819444445">
One common approach to unsupervised IE is based
on automatic IE pattern acquisition on a cluster of
similar documents. For instance, Sudo et al. (2003)
and Sekine (2006) proposed different methods for
automatic IE pattern acquisition for a given domain
based on frequent subtree discovery in dependency
parse trees. These methods leveraged heavily on the
entity types of candidates when assigning them to
template slots. As a consequence, potentially dif-
ferent semantic roles of candidates having the same
entity type could become indistinguishable (Sudo et
al., 2003; Sekine, 2006). This problem is alleviated
in our work by exploiting distributional prior knowl-
edge about template slots, which is shown effective
when coupled with discriminative features of can-
didates. Filatova et al. (2006) also considered fre-
quent subtrees in dependency parse trees, but their
goal was to build templates around verbs that are
statistically important in a given domain. Our work,
in contrast, is not constrained to verb-centric tem-
plates. We aim to identify salient slots in the given
domain by clustering.
Marx et al. (2002) proposed the cross-component
clustering algorithm for unsupervised IE. Their al-
gorithm assigned a candidate from a document to
a cluster based on the candidate’s feature similarity
with candidates from other documents only. In other
words, the algorithm did not consider a candidate’s
relationships with other candidates in the same doc-
ument. Our work is based on a different perspec-
tive: we model label assignments for all candidates
in the same document with a distributional prior that
prefers a document to cover more distinct slots. We
show empirically that this prior improves slot clus-
tering results greatly in some cases.
Also related to our work is open domain IE, which
aims to perform unsupervised relation extraction.
TEXTRUNNER (Banko et al., 2007), for example,
automatically extracts all possible relations between
pairs of noun phrases from a given corpus. The main
difference between open domain IE and our work
is that open domain IE does not aim to induce do-
main templates, whereas we focus on a single do-
main with the goal of inducing a template that de-
scribes salient information structure of that domain.
Furthermore, TEXTRUNNER and related studies on
unsupervised relation extraction often rely on highly
redundant information on the Web or in large cor-
pus (Hasegawa et al., 2004; Rosenfeld and Feldman,
2006; Yan et al., 2009), which is not assumed in our
study.
We propose a generative model with a distribu-
tional prior for the unsupervised IE task, where
slot fillers correspond to observations in the model,
and their labels correspond to hidden variables we
want to learn. In the machine learning literature,
researchers have explored the use of similar prior
knowledge in the form of constraints through model
expectation. For example, Grac¸a et al. (2007) pro-
posed to place constraints on the posterior proba-
bilities of hidden variables in a generative model,
while Druck et al. (2008) studied a similar problem
in a discriminative, semi-supervised setting. These
studies model constraints as features, and enforce
the constraints through expected feature values. In
contrast, we place constraints on label assignments
through a probabilistic prior on the distribution of
slots. The proposed prior is simple and easy to inter-
pret in a generative model. Nevertheless, it will be
interesting to explore how the proposed prior can be
implemented within the posterior constraint frame-
work.
</bodyText>
<sectionHeader confidence="0.972152" genericHeader="method">
3 Problem Overview
</sectionHeader>
<bodyText confidence="0.997444666666667">
In this section, we first formally define our unsuper-
vised IE problem. We then provide an overview of
our solution, which is based on a generative model.
</bodyText>
<subsectionHeader confidence="0.99904">
3.1 Problem Definition
</subsectionHeader>
<bodyText confidence="0.999895818181818">
We assume a collection of documents or short text
segments from a certain domain. These documents
or text segments describe different events or enti-
ties, but they are about the same topic or aspect of
the domain. Examples of such collections include
a collection of sentences describing the educational
background of famous scientists and a collection of
aviation incident reports. Our task is to automati-
cally discover an IE template from this collection.
The discovered template should contain a set of slots
that play different semantic roles in the domain.
</bodyText>
<page confidence="0.996997">
815
</page>
<figure confidence="0.647040642857143">
Input text:
Topic: Graduate Student Seminar Lunch
Dates: 13-Apr-95
Time: 12:00 PM - 1:30 PM
PostedBy: Edmund J. Delaney on 5-Apr-95 at 16:24 from andrew.cmu.edu
Abstract:
The last Graduate Student Seminar Series lunch will be held on Thursday, April 13 from noon-1:30 p.m. in room
207, Student Activities Center. Professor Sara Kiesler of SDS will speak on Carving A Successful Research Niche.
Output:
Slot Slot Filler(s)
Slot 1 (start time) 12:00PM
Slot 2 (end time) 1:30PM, 1:30 p.m.
Slot 3 (location) room 207, Student Activities Center
Slot 4 (speaker) Professor Sara Kiesler
</figure>
<figureCaption confidence="0.800194">
Slot 4 (irrelevant information) Edmund J. Delaney
Figure 1: An input text from a seminar announcement collection and the discovered IE template. Note that the slots
are automatically discovered and the slot names are manually assigned.
</figureCaption>
<bodyText confidence="0.999993259259259">
To construct such a template, we start with identi-
fying candidate slot fillers, hereafter referred to as
candidates, from the input text. Then we cluster
these candidates with the aim that each cluster will
represent a semantically meaningful slot. Figure 1
gives an example of an input text from a collection
of seminar announcements and the resulting tem-
plate discovered from the collection. As we can see,
the template contains some semantically meaningful
slots such as the start time, end time, location and
speaker of a seminar. Moreover, it also contains a
slot that covers an irrelevant candidate. We call such
slots covering irrelevant candidates garbage slots.
We can make two observations on the mapping
from candidates to template slots from real data,
such as the text in Figure 1. Firstly, a template
slot may be filled by more than one candidate from
a single document, although this number has been
observed to be small. For example, the template
slot end time in Figure 1 has two slot fillers: “1:30
PM” from the semi-structured header and “1:30
p.m.” from within the abstract. Secondly, a docu-
ment tends to contain candidates that cover different
template slots. We believe that this observation is a
consequence of the fact that a document will tend to
convey as much information as possible. We further
exploit these observations in Section 4.
</bodyText>
<subsectionHeader confidence="0.999298">
3.2 A General Solution
</subsectionHeader>
<bodyText confidence="0.992186666666667">
Recall that our general solution to the unsupervised
IE problem is to cluster candidate slot fillers in order
to identify meaningful slots. We leave the details of
how to extract the candidates to Section 7.1. In this
section, we assume that we have a set of candidates
x = {xi,j}, where xi,j is the j-th candidate from
the i-th document in the collection. We cluster these
candidates into K groups for a given K.
Let yi,j E {1, ... , K} denote the cluster label for
xi,j and y denote the set of all the yi,j’s. Let xi and
yi denote the sets of all the xi,j’s and the yi,j’s in the
i-th document respectively. We assume a generative
model for x and y as follows. For the i-th document
in our collection, we assume that the number of can-
didates is known and we draw a label assignment yi
according to some distribution parameterized by A.
Then for the j-th candidate, we generate xi,j from
yi,j according to a generative model parameterized
by R Since the labels y are hidden, the observed
log-likelihood of the parameters given the observa-
tions x is
</bodyText>
<equation confidence="0.984056538461538">
L(A, O) = log p(x; A, O)
E
log
Vi
p(xi,j|yi,j; O). (1)
E=
i
E=
i
E �
log p(yi; A)
Vi j
p(xi, yi; A, O)
</equation>
<page confidence="0.992474">
816
</page>
<figure confidence="0.9694995">
(b) The proposed Poisson-based
prior.
</figure>
<figureCaption confidence="0.99427275">
Figure 2: Generative models with different label assign-
ment priors. D denotes the number of documents in the
given collection, ni denotes the number of candidates in
the i-th document, and K is the number of slots (clusters).
</figureCaption>
<bodyText confidence="0.999787428571429">
For a given functional form of p(yi; A) and
p(xi,j|yi,j; O), the best model parameters can be es-
timated by maximizing Eq. (1). In the next section,
we detail two designs of the prior p(yi; A), followed
by different generative models for the distribution
p(xi,j|yi,j; O) in Section 5. Then we describe the
estimation of model parameters in Section 6.
</bodyText>
<sectionHeader confidence="0.976815" genericHeader="method">
4 Label Assignment Prior
</sectionHeader>
<bodyText confidence="0.9999676">
The label assignment prior, p(yi; A), models the
generation of labels for candidates in a document.
In this section, we first describe a commonly used
multinomial prior, and then introduce the proposed
Poisson-based prior for the unsupervised IE task.
</bodyText>
<subsectionHeader confidence="0.998796">
4.1 A Multinomial Prior
</subsectionHeader>
<bodyText confidence="0.999961214285714">
Usually, one would assume that the labels for
the different candidates in the same document
are generated independently, that is, p(yi; A) =
Hj p(yi,j; A). Under this model, we assume that
each yi,j is generated from a multinomial distribu-
tion parameterized by ϕ, where Oy denotes the prob-
ability of generating label y. Our objective function
in Eq. (1) then becomes:
Figure 2(a) depicts a generative model with this
multinomial prior in plate notation. Note that the in-
dependence assumption on label assignment in this
model does not capture our observation that candi-
dates in a document are likely to cover different se-
mantic roles.
</bodyText>
<subsectionHeader confidence="0.996181">
4.2 The Proposed Poisson-based Prior
</subsectionHeader>
<bodyText confidence="0.999343093023256">
We propose a prior distribution that favors more
diverse label assignments. Our proposal takes
into consideration the following three observations.
Firstly, candidates in the same document are likely
to cover different semantic roles. The proposed prior
distribution should therefore assign higher probabil-
ity to a label assignment that covers more distinct
slots. Secondly, the same piece of information is not
likely to be repeated many times in a document. Our
design thus allows a slot to generate multiple fillers
in a document, up to a limited number of times.
Thirdly, there may exist candidates that do not be-
long to slots in the extracted template. Therefore, we
introduce a dummy slot or garbage slot to the label
set to collect such candidates. Yet, we shall not as-
sume any prior/domain knowledge about candidates
generated by the garbage slot as they are essentially
irrelevant in the given domain.
We now detail the prior that exploits the above
observations. First, we fix the K-th slot (or cluster)
in the label set to be the garbage slot. For each of
the non-garbage slot k = 1, ... , K − 1, we also fix
the maximum number of fillers that can be gener-
ated, which we denote by Ak. There is no AK for the
garbage slot because the number of fillers is not con-
strained for this slot. This allows all candidates in a
document to be generated by the garbage slot. Let
ni be the number of candidates in the i-th document.
Given K, {Ak}K−1
k=1 and ni, the set of possible label
assignments for the i-th document can be generated.
We illustrate this with an example. Let K = 2 and
A1 = 1. The label set is {1, 2}, where 2 represents
the garbage slot. Let the number of candidates be
ni = 2. The possible label assignments within this
setting are (1, 2), (2, 1) and (2, 2).
The set of possible label assignments for the i-
th document is the sample space on which we place
the prior distribution p(yi; A). We need a prior that
gives a higher probability to a more diverse label
assignment. For a given yi for the i-th document,
let ni,k be the number of candidates in the docu-
ment that have been assigned to slot k. That is,
</bodyText>
<equation confidence="0.90515">
def
ni,k = �ni
j=1 1(yi,j = k), where 1(·) is the indica-
</equation>
<bodyText confidence="0.9980935">
tor variable. We propose the following distribution
based on the Poisson distribution:
</bodyText>
<figure confidence="0.919966583333333">
D
K-1
K-1 K
ni
D
ni
K
(a) A multinomial prior.
L(A, O) = log p(x; A, O)
�= � Oyp(xi,j|y; O). (2)
i,j log
y
</figure>
<page confidence="0.816139">
817
</page>
<equation confidence="0.9407915">
p(yi; A) &apos;!-&apos;-&apos; Zi−1 K−1H Poisson(ni,k; Tk), (3)
k=1
</equation>
<bodyText confidence="0.999968285714286">
where Zi is the normalizing constant, and Tk is the
mean parameter of the k-th Poisson distribution,
k = 1,... K − 1. The absence of a factor that
depends on ni,K reflects the lack of prior knowl-
edge on the number of garbage slot fillers. Fig-
ure 2(b) depicts the proposed generative model with
the Poisson-based prior in plate notation.
</bodyText>
<sectionHeader confidence="0.983804" genericHeader="method">
5 Generating Slot Fillers
</sectionHeader>
<bodyText confidence="0.999701285714286">
Different existing generative models can be used to
model the generation of a slot filler given a label, that
is, p(x|y; O). We explore four of them for our task,
namely, the naive Bayes model, the Bernoulli mix-
ture model, the Gaussian mixture model, and a lo-
cally normalized logistic regression model proposed
by Berg-Kirkpatrick et al. (2010).
</bodyText>
<subsectionHeader confidence="0.997918">
5.1 Multinomial Naive Bayes
</subsectionHeader>
<bodyText confidence="0.99995175">
In the multinomial naive Bayes model, features of
an observation x are assumed to be independent and
each generated from a multinomial distribution. We
first introduce some notations. Let f denote a fea-
ture (e.g. entity type) and Vf denote the set of possi-
ble values for f. Let xf E Vf be the value of feature
f in x (e.g. person). For a given label y, feature f
follows a multinomial distribution parameterized by
ψy,f, where Oy,f,v denotes the probability of feature
f taking the value v E Vf given label y. The func-
tional form of the conditional probability of x given
a label y is then
</bodyText>
<equation confidence="0.881644">
p(x|y; Θ) = ∏ p(xf|y; Θ) = ∏ ψy,f,xf . (4)
f f
</equation>
<bodyText confidence="0.998888625">
is the number of binary features. An example of a
binary features is “the entity type is person”.
We assume that, for a given label y, observations
are generated from a multivariate Bernoulli distribu-
tion parameterized by φy f, where coy, f,v denotes the
probability of feature f taking the value v E {0, 11
given label y. The conditional probability of x given
y can then be written as
</bodyText>
<equation confidence="0.9959105">
p(xf = 1|y; Θ)xf · p(xf = 0|y; Θ)1−xf
cPy,f,xf . (5)
</equation>
<subsectionHeader confidence="0.913632">
5.3 Gaussian Mixture Model
</subsectionHeader>
<bodyText confidence="0.999525333333333">
In the Gaussian mixture model, we assume that a
given label y generates observations with a mul-
tivariate Gaussian distribution N(µy, Ey), where
µy E IR,F is the mean and Ey E IR,F×F is the co-
variance matrix of the Gaussian. If we assume that
the different feature dimensions are independent and
have the same variance, that is, Ey = σyII, where I
is the identity matrix, then the conditional density of
x given y is
</bodyText>
<equation confidence="0.8590505">
_ 2
p(x |y; Θ) = (2πσ2)F/2 exp (—IIx vII J (6)
2u
\ l
</equation>
<subsectionHeader confidence="0.988127">
5.4 Locally Normalized Logistic Regression
</subsectionHeader>
<bodyText confidence="0.999431">
Berg-Kirkpatrick et al. (2010) proposed a method
for incorporating features into generative models for
unsupervised learning. Their method models the
generation of x given y as a logistic function param-
eterized by a weight vector wy, defined as follows:
</bodyText>
<equation confidence="0.991005222222223">
p(x|y; Θ) = ∏
f
∏=
f
exp(x, wy)
p(x|y; Θ)
=
∑
X′ exp (x′, wy) . (7)
</equation>
<subsectionHeader confidence="0.989337">
5.2 Bernoulli Mixture Model
</subsectionHeader>
<bodyText confidence="0.9998803">
In the naive Bayes model our features are defined
to be categorical. For the Bernoulli mixture model,
as well as the Gaussian mixture model and the lo-
cally normalized logistic regression model in the
next subsections, we first convert each observation
x into a binary feature vector x E {0,11F where F
(x, w) denotes the inner product between x and w.
The denominator considers all data points x′ in the
data set, thus Eq. (7) gives a probability distribution
over data points for a given y.
</bodyText>
<page confidence="0.995773">
818
</page>
<sectionHeader confidence="0.987423" genericHeader="method">
6 Parameter Estimation
</sectionHeader>
<bodyText confidence="0.9709758">
We can apply the Expectation-Maximization (EM)
algorithm (Dempster et al., 1977) to maximize
the log-likelihood functions under both multinomial
prior in Eq. (2) and the proposed Poisson-based prior
in Eq. (1). For the multinomial prior, there are stan-
dard closed form solutions for the naive Bayes, the
Bernoulli mixture and the Gaussian mixture models.
For locally normalized logistic regression, model
parameters can also be learned via EM, but with
a gradient-based M-step (Berg-Kirkpatrick et al.,
2010). We leave out the details here and focus on pa-
rameter estimation in the proposed generative model
with the Poisson-based prior.
We assume that in the Poisson-based prior, the
parameters {λk}K−1
</bodyText>
<equation confidence="0.60858875">
k=1 and {τk}K−1
k=1 are fixed rather
than learned in this work. For the distribution
p(x|y; O), let O(t−1) and O(t) denote parameter es-
</equation>
<bodyText confidence="0.942419666666667">
timates from two consecutive EM iterations. At the
t-th iteration, the E-step updates the responsibilities
of each label assignment yi for each document:
</bodyText>
<equation confidence="0.9985895">
� i; O(t−1)), (8)
y′ � p(y′ i; A)p(xi|y′
</equation>
<bodyText confidence="0.9999592">
where αi is a distribution over all possible label as-
signments yi’s for the i-th document. The M-step
updates the estimates of O(t) based on the current
values of αi’s and O(t−1). This is done by maximiz-
ing the following objective function:
</bodyText>
<equation confidence="0.985205">
)p(xi,j|yi,j; O(t−1)) . (9)
</equation>
<bodyText confidence="0.9791568">
The exact formulas used in the M-step for
updating O depend on the functional form of
p(xi,j|yi,j; O). As an example, we give the formulas
for the Gaussian mixture model, in which O contains
the set of means {µ(t)
k }Kk=1 and variances {Q(t)
k }Kk=1.
Taking the derivatives of Eq. (9) with respect to µk
and to Qk, and then setting the derivations to zero,
we can solve for µk and for Qk to get:
</bodyText>
<equation confidence="0.995263777777778">
∑ ∑ ∑
yi αi,yi j 1(yi,j = k)xi,j
µk =
(t) ∑ i ∑ ∑j 1(yi,j = k) , (10)
yi αi,yi
i
mkt) _ ∑i ��; ai,yi ∑j 1(yi,j = k)||xi,j − µkt)||2
— �` r = )
F Ei ` yi αi,yi ∑j 1(yi,j k
</equation>
<bodyText confidence="0.9995039">
where 1(·) is the indicator variable. We skip the
derivations here due to space limit.
Closed form solutions also exist for the naive
Bayes and the Bernoulli mixture models. For lo-
cally normalized logistic regression, parameters can
be learned with a gradient-based M-step as in the
multinomial prior setting. Existing optimization al-
gorithms, such as L-BFGS, can be used for optimiz-
ing model parameters in the M-step as discussed in
(Berg-Kirkpatrick et al., 2010).
</bodyText>
<sectionHeader confidence="0.999365" genericHeader="method">
7 Experiments
</sectionHeader>
<bodyText confidence="0.9999648">
In this section, we first describe the data sets we used
in our experiments, detailing the target slots and can-
didates in each data set, as well as features we ex-
tract for the candidates. We then describe our evalu-
ation metrics, followed by experimental results.
</bodyText>
<subsectionHeader confidence="0.997628">
7.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.99997132">
We use three data sets for evaluating our unsuper-
vised IE task. Note that to speed up computation,
we only include documents or text segments con-
taining no more than 10 candidates in our experi-
ments. The first data set contains a set of seminar an-
nouncements (Freitag and McCallum, 1999), anno-
tated with four slot labels, namely stime (start time),
etime (end time), speaker and location. We used as
candidates all strings labeled in the annotated data
as well as all named entities found by the Stanford
NER tagger for CoNLL (Finkel et al., 2005). There
are 309 seminar announcements with 2262 candi-
dates in this data set.
The second data set is a collection of para-
graphs describing aviation incidents, taken from the
Wikipedia article on “List of accidents and incidents
involving commercial aircraft” (Wikipedia, 2009).
Each paragraph in the article contains one to a few
sentences describing an incident. In this domain, we
take each paragraph as a separate document, and all
hyperlinked phrases in the original Wikipedia arti-
cle as candidates. For evaluation, we manually an-
notated the paragraphs of incidents from 2006 to
2009 with five slot labels: the flight number (FN),
the airline (AL), the aircraft model (AC), the exact
</bodyText>
<equation confidence="0.9992306">
αi,yz = p(yi|xi; A, O(t−1))
p(yi; A)p(xi|yi; O(t−1))
=
( ∏
αi,yi log p(yi; A)
j
∑
i
∑
yi
</equation>
<page confidence="0.992751">
819
</page>
<bodyText confidence="0.999847789473684">
location (LO) of the incident (e.g. airport name),
and the country (CO) where the incident occurred.
The entire data set consists of 564 paragraphs with
2783 candidates. The annotated portion consists of
74 paragraphs with 395 candidates.
The third data set comes from the management
succession domain used in the Sixth Message Un-
derstanding Conference (MUC-6, 1995). We extract
from the original data set all sentences that were
tagged with a management succession event, and use
as candidates all tagged strings in those sentences.
This domain has four target slots, namely PersonIn
(the person moving into a new position), PersonOut
(the person leaving a position), Org (the corpora-
tion’s name) and Post (the position title). Sentences
containing candidates with multiple labels (candi-
dates annotated as both PersonIn and PersonOut) are
discarded. The extracted data set consists of 757
sentences with 2288 candidates.
</bodyText>
<subsectionHeader confidence="0.877337">
7.2 Features
</subsectionHeader>
<bodyText confidence="0.9999461875">
To extract features for candidates, we first normal-
ize each word to its lower-case, with digits replaced
by the token digit. We extract the following fea-
tures for every candidate: the candidate phrase it-
self, its head word, the unigram and bigram be-
fore and after the candidate in the sentence where
it appeared, its entity type (person, location, or-
ganization, and date/time), as well as features de-
rived from dependency parse trees. Specifically, we
first apply the Stanford lexical parser to our data
(de Marneffe et al., 2006). Then for each candi-
date, we follow its dependencies in the correspond-
ing dependency parse tree until we find a relation
r E {nsubj, csubj, dobj, iobj, pobjI in which the
candidate is the dependent. We then construct a fea-
ture (r, v) where v is governor of the relation.
</bodyText>
<subsectionHeader confidence="0.999513">
7.3 Evaluation Baseline and Method
</subsectionHeader>
<bodyText confidence="0.9998770625">
We use the standard K-means algorithm (Macqueen,
1967) as a non-generative baseline, since K-means is
commonly used for clustering. To evaluate cluster-
ing results, we match each slot in the labeled data to
the cluster that gives the best F1-measure when eval-
uated for the slot. We report the precision (P), re-
call (R) and F1-measure for individual slot labels, as
well as the macro- and micro- average results across
all labels for each experiment. We conduct 10 trials
of experiment on each model and each data set with
different random initializations. We report the trials
that give the smallest within-cluster sum-of-squares
(WCSS) distance for K-means, and those that give
the highest log-likelihood of data for all other mod-
els. Experimental trials are run until the change in
WCSS/log-likelihood between two EM iterations is
smaller than 1 x 10−6. All trials converged within
30 minutes.
All models we evaluate involve a parameter K,
which is the number of values that y can take on.
The value of K is manually fixed in this study. As
noted, we use a garbage slot to capture irrelevant
candidates, thus the value of K is set to the number
of target slots plus 1 for each data set. We empir-
ically set the adjustable parameters in the proposed
prior, and the weight of the regularization term in the
locally normalized logistic regression model (Berg-
Kirkpatrick et al., 2010), denoted by β. Exact set-
tings are given in the next subsection. Note that the
focus of our experiments is on evaluating the effec-
tiveness of the proposed prior. We leave the task of
learning the various parameter values to future work.
</bodyText>
<sectionHeader confidence="0.693816" genericHeader="evaluation">
7.4 Results
</sectionHeader>
<bodyText confidence="0.988370636363636">
Evaluation on existing generative models
We first evaluate the existing generative models
described in Section 5 with the multinomial prior.
Table 1 summarizes the performance of Naive Bayes
(NB), the Bernoulli mixture model (BMM), the
Gaussian mixture model (GMM), the locally nor-
malized logistic regression (LNLR) model, and K-
means. We only show the F1 measures in the table
due to space limit.
We first observe that NB does not perform well
for our task. LNLR, which is an interesting contri-
bution in its own right, does not seem to be suitable
for our task as well. While NB and LNLR are infe-
rior to K-means for all three data sets, BMM shows
mixed results. Specifically, BMM outperforms K-
means for aviation incidents, but performs poorly
for seminar announcements. GMM and K-means
achieve similar results, which is not surprising be-
cause K-means can be viewed as a special case of
the spherical GMM we used (Duda et al., 2001).
Overall speaking, results show that GMM is the
best among the four generative models for the distri-
</bodyText>
<page confidence="0.991583">
820
</page>
<table confidence="0.93748816">
(a) Results on seminar announcements. No macro- and micro-average result is reported
for NB and BMM as they merged the etime cluster with the stime cluster. Numbers in
brackets are the respective measures of the stime cluster when evaluated for etime.
Model stime etime speaker location Macro-avg Micro-avg Parameter
NB 0.558 (0.342) 0.276 0.172 — — Nil
BMM 0.822 (0.440) 0.412 0.402 — — Nil
GMM 0.450 0.530 0.417 0.426 0.557 0.455 Nil
LNLR 0.386 0.239 0.200 0.208 0.264 0.266 β = .0005
K-means 0.560 0.574 0.335 0.426 0.538 0.452 Nil
(b) Results on aviation incidents. Target slots are airline (AL) , flight number (FN), aircraft
model (AC), location (LO) and country (CO).
Model AL FN AC LO CO Macro-avg Micro-avg Parameter
NB 0.896 0.473 0.676 0.504 0.533 0.618 0.628 Nil
BMM 0.862 0.794 0.656 0.695 0.614 0.741 0.724 Nil
GMM 0.859 0.914 0.635 0.576 0.538 0.730 0.692 Nil
LNLR 0.597 0.352 0.314 0.286 0.291 0.379 0.396 β = .0005
K-means 0.859 0.936 0.661 0.576 0.538 0.729 0.701 Nil
(c) Results on management succession events. Target slots are person joining (PersonIn),
person leaving (PersonOut), organization (Org), and position (Post).
Model PersonIn PersonOut Org Post Macro-avg Micro-avg Parameter
NB 0.545 0.257 0.473 0.455 0.459 0.437 Nil
BMM 0.550 0.437 0.800 0.767 0.650 0.648 Nil
GMM 0.583 0.432 0.813 0.803 0.679 0.676 Nil
LNLR 0.419 0.245 0.319 0.399 0.351 0.346 β = .0002
K-means 0.372 0.565 0.835 0.814 0.645 0.665 Nil
</table>
<tableCaption confidence="0.996851">
Table 1: Performance summary of the different generative models and K-means in terms of F1.
</tableCaption>
<table confidence="0.988291285714286">
Data set Parameter Value
Seminar announcements {λk}4k=1 {2}4k=1
{τk}4k=1 {1}4k=1
Aviation incidents {λk}5k=1 {1}5k=1
{τk}5k=1 {1}5k=1
Management succession {λk}4k=1 {1,2,2,2}
{τk}4k=1 {1,2,2,2}
</table>
<tableCaption confidence="0.998902">
Table 2: Parameter settings for p(yi; A).
</tableCaption>
<bodyText confidence="0.977550972972973">
bution p(x|y; O). We proceed with incorporating the
proposed prior into GMM for further explorations.
Effectiveness of the proposed prior
We evaluate the effectiveness of the proposed
prior by combining it with GMM. Specifically, the
combined model follows Eq. (1), with p(yi; A) com-
puted using the Poisson-based formula in Eq. (3) and
p(xi,j|yi,j; O) following Eq. (6) as in GMM.
We empirically determine the parameters used in
p(yi; A) to maximize data’s log-likelihood as noted.
Table 2 reports the values of {Ak}K−1
k=1 and {Tk}K−1
k=1
for different data sets. Recall that Ak specifies the
maximum number of candidates that the k-th slot can
generate, and its value is observed to be small in real
data. Tk specifies the expected number of candidates
that the k-th slot will generate.
Table 3 reports the performance of the combined
model (“GMM with prior”) on the three data sets,
along with results of GMM and K-means for easy
comparison. The combined model improves over
both GMM and K-means for seminar announce-
ments and aviation incidents, as can be seen from the
models’ macro- and micro-average performance.
The advantages brought by the proposed prior are
mainly reflected in slots that are difficult to clus-
ter under GMM and K-means. Taking seminar an-
nouncements as an example, GMM and K-means
achieve high precision but low recall for stime, and
low precision but high recall for etime. When exam-
ining the clusters produced by these two models, we
found one small cluster that contains mostly stime
fillers (thus high precision but low recall), and an-
other much larger cluster that contains mostly etime
fillers together with most of the remaining stime
fillers (thus low precision but high recall for etime).
</bodyText>
<page confidence="0.995399">
821
</page>
<table confidence="0.991388636363636">
(a) Results on seminar announcements.
Model Metric stime etime speaker location Macro-avg Micro-avg
GMM with Prior P 0.964 0.983 0.232 0.253 0.608 0.416
R 0.680 0.932 0.952 0.481 0.761 0.738
F1 0.798 0.957 0.374 0.331 0.676 0.532
GMM P 1.000 0.362 0.300 0.436 0.524 0.407
R 0.291 0.984 0.686 0.416 0.594 0.518
F1 0.450 0.530 0.417 0.426 0.557 0.455
K-means P 0.890 0.434 0.222 0.436 0.496 0.389
R 0.408 0.847 0.679 0.416 0.588 0.541
F1 0.560 0.574 0.335 0.426 0.538 0.452
(b) Results on aviation incidents.
Model Metric AL FN AC LO CO Macro-avg Micro-avg
GMM with Prior P 1.000 1.000 1.000 0.741 0.833 0.915 0.908
R 0.753 0.877 0.465 0.588 0.727 0.682 0.673
F1 0.859 0.935 0.635 0.656 0.777 0.782 0.773
GMM P 1.000 1.000 1.000 0.563 0.433 0.799 0.724
R 0.753 0.842 0.465 0.588 0.709 0.672 0.664
F1 0.859 0.914 0.635 0.576 0.538 0.730 0.692
K-means P 1.000 0.981 0.830 0.563 0.433 0.761 0.711
R 0.753 0.895 0.549 0.588 0.709 0.699 0.691
F1 0.859 0.936 0.661 0.576 0.538 0.729 0.701
(c) Results on management succession events.
Model Metric PersonIn PersonOut Org Post Macro-avg Micro-avg
GMM with Prior P 0.458 0.610 0.720 0.774 0.640 0.642
R 0.784 0.352 0.969 0.846 0.738 0.731
F1 0.578 0.447 0.826 0.809 0.686 0.683
GMM P 0.464 0.605 0.725 0.792 0.647 0.648
R 0.782 0.336 0.925 0.815 0.715 0.707
F1 0.583 0.432 0.813 0.803 0.679 0.676
K-means P 0.382 0.515 0.733 0.839 0.607 0.639
R 0.363 0.625 0.969 0.791 0.687 0.693
F1 0.372 0.565 0.835 0.814 0.645 0.665
</table>
<tableCaption confidence="0.999983">
Table 3: Comparison between the combined model (GMM with the proposed prior), GMM and K-means.
</tableCaption>
<bodyText confidence="0.9929872">
This shows that GMM, when used with the multi-
nomial prior, and K-means have difficulties sepa-
rating candidates from these two slots. In contrast,
the combined model improves the recall of stime to
68%, as compared to 29.1% achieved by GMM with
the multinomial prior and 40.8% by K-means, with-
out sacrificing precision. It also improves the preci-
sion of etime from 36.2% to 98.3%.
For aviation incidents, the advantage of the pro-
posed prior is reflected in the location (LO) and
country (CO) slots, which may confuse the various
models as they both belong to the entity type loca-
tion. The proposed prior improves the precision of
these two slots greatly by trying to distribute them
into appropriate slots in the clustering process.
The three models achieve very similar perfor-
mance on management succession events as Ta-
ble 3(c) shows. Surprisingly, incorporating the
Poisson-based prior into GMM does not seem useful
in separating PersonIn and PersonOut slot fillers. To
investigate the possible reasons for this, we exam-
ine feature values in the centriods of the two clusters
learned by the three models.
Tables 4 and 5 respectively list the top-10 features
in the PersonIn cluster and the PersonOut cluster
learned by the combined model1, and their corre-
sponding values in the centriods of the two clusters.
The two clusters share 3 of the top-5 features, some
&apos;We made similar observations from centriods learned in
GMM and K-Means, which are therefore not reported here.
</bodyText>
<page confidence="0.98558">
822
</page>
<figure confidence="0.651615769230769">
Values in the centriod of:
Values in the centriod of:
Top-10 features
type:(person)
unigram after:,
unigram before:(s)
bigram after:, (digits)
bigram after:, who
unigram before:,
dobj:succeeds
unigarm before:succeeds
nsubj:resigned
unigram before:said
</figure>
<table confidence="0.768555">
PersonIn PersonOut
0.9985 1
0.7251 0.3404
0.2705 0
0.2105 0.1879
0.1404 0.0567
0.1067 0.0035
0.0906 0
0.0892 0
0.0746 0.0284
0.0673 0
Top-10 features
type:(person)
unigram before:mr.
bigram before:(s) mr.
unigram after:,
bigram after:, (digits)
unigram after:was
nsubj:president
nsubj:succeeds
bigram before:, mr.
unigram after:’s
PersonOut PersonIn
1 0.9985
0.9894 0
0.5213 0
0.3404 0.7251
0.1879 0.2105
0.1667 0.0556
0.1667 0.0117
0.1028 0.0102
0.0957 0
0.0745 0.0073
</table>
<tableCaption confidence="0.99932275">
Table 4: Top-10 features in the PersonIn cluster, as
learned by GMM with the proposed prior.
Table 5: Top-10 features in the PersonOut cluster, as
learned by GMM with the proposed prior.
</tableCaption>
<bodyText confidence="0.999950863636364">
of them being general context features that might not
help characterizing candidates from different slots
(e.g. the unigram after the candidate is a comma).
Both lists also contain features from dependency
parse trees. Note that the “dobj:succeeds” feature
in the PersonIn cluster is in fact contributed by Per-
sonOut slot fillers, while the “nsubj:succeeds” fea-
ture in the PersonOut cluster is contributed by Per-
sonIn slot fillers. Although listed among the top-
10, these features have relatively low values in the
learned centriods (about 0.1). These observations
may suggest that the management succession data
set lacks strong, discriminative features for all mod-
els to effectively distinguish between PersonIn and
PersonOut candidates in an unsupervised manner.
To conclude, the proposed prior is effective in as-
signing different but confusing candidate slot fillers
into appropriate slots, when there exist reasonable
features that can be exploited in the label assign-
ment process. This is evident by the improvements
the proposed prior brings to GMM in the seminar
announcement and aviation incident data sets.
</bodyText>
<sectionHeader confidence="0.998485" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999994153846154">
We propose a generative model that incorporates
distributional prior knowledge about template slots
in a document for the unsupervised IE task. Specifi-
cally, we propose a Poisson-based prior that prefers
label assignments to cover more distinct slots in the
same document. The proposed prior also allows a
slot to generate multiple fillers in a document, up to
a certain number of times depending on the domain
of interest.
We experimented with four existing generative
models for the task of clustering slot fillers with
a multinomial prior, which assumes that labels are
generated independently in a document. We then
evaluate the effectiveness of the proposed prior by
incorporating it into the Gaussian mixture model
(GMM), which is shown to be the best among the
four existing models in our experiments. By incor-
porating the proposed prior into GMM, we can ob-
tain significantly better clustering results on two out
of three data sets.
Further improvements to this work are possible.
Firstly, we assume that some adjustable parameters
in the proposed prior can be manually fixed, such as
the number of template slots in the output and the
maximum numbers of fillers that can be generated
by different slots. We are looking into methods for
automatically learning such parameters. This will
help improve the applicability of our work to differ-
ent domains as an unsupervised model. Secondly,
we currently consider in the prior a probability dis-
tribution over all possible label assignments for ev-
ery document. This can be computationally expen-
sive if input documents are long, or when we aim
to discover large templates with large values of K.
An alternative is to consider an approximate solution
that evaluates, for instance, only the top few label as-
signments that are likely to maximize the likelihood
of our observations. This remains as an interesting
future work of this study.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998367333333333">
This work is supported by DSO National Laborato-
ries. We thank the anonymous reviewers for their
helpful comments.
</bodyText>
<page confidence="0.998308">
823
</page>
<sectionHeader confidence="0.993892" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.959808164948453">
Michele Banko, Michael J Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open infor-
mation extraction from the web. In International Joint
Conference on Artificial Intelligence, pages 2670–
2676.
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e,
John DeNero, and Dan Klein. 2010. Painless unsuper-
vised learning with features. In Proceedings of Human
Language Technologies: The 2010 Annual Conference
of the North American Chapter of the Association for
Computational Linguistics, pages 582–590.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
LREC.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum likelihood from incomplete data via the EM
algorithm. Journal of the Royal Statistical Society. Se-
ries B (Methodological), 39(1):1–38.
Gregory Druck, Gideon Mann, and Andrew McCallum.
2008. Learning from labeled features using gener-
alized expectation criteria. In Proceedings of the
31st annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 595–602.
Richard O. Duda, Peter E. Hart, and David G. Stork.
2001. Pattern classification. Wiley-Interscience, 2nd
edition.
Elena Filatova, Vasileios Hatzivassiloglou, and Kathleen
McKeown. 2006. Automatic creation of domain
templates. In Proceedings of the COLING/ACL on
Main conference poster sessions, COLING-ACL ’06,
pages 207–214, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics, pages 363–
370.
Dayne Freitag and Andrew Kachites McCallum. 1999.
Information extraction with HMMs and shrinkage. In
Proceedings of the AAAI-99 Workshop on Machine
Learning for Information Extraction.
Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007.
Expectation maximization and posterior constraints.
In Proceedings of the Twenty-First Annual Conference
on Neural Information Processing Systems.
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.
2004. Discovering relations among named entities
from large corpora. In Proceedings of the 42nd An-
nual Meeting on Association for Computational Lin-
guistics, page 415, Morristown, NJ, USA. Association
for Computational Linguistics.
J. B. Macqueen. 1967. Some methods for classification
and analysis of multivariate observations. In Proceed-
ings of the Fifth Berkeley Symposium on Mathematical
Statistics and Probability, Volume 1, pages 281–297.
Zvika Marx, Ido Dagan, and Eli Shamir. 2002. Cross-
component clustering for template induction. In Pro-
ceedings of the 2002 ICML Workshop on Text Learn-
ing.
MUC-6. 1995. Proceedings of the Sixth Message Under-
standing Conference. Morgan Kaufmann, San Fran-
cisco, CA.
Benjamin Rosenfeld and Ronen Feldman. 2006. URES
: An unsupervised Web relation extraction system.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 667–674.
Satoshi Sekine. 2006. On-demand information extrac-
tion. In Proceedings of the COLING/ACL Main con-
ference poster sessions, pages 731–738.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive
information extraction using unrestricted relation dis-
covery. In Proceedings of the Human Language Tech-
nology Conference of the North American Chapter of
the Association for Computational Linguistics, pages
304–311.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An improved extraction pattern representation
model for automatic ie pattern acquisition. In Pro-
ceedings of the 41st Annual Meeting on Association
for Computational Linguistics - Volume 1, ACL ’03,
pages 224–231, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Wikipedia. 2009. List of accidents and
incidents involving commercial aircraft.
http://en.wikipedia.org/wiki/List of accidents and
incidents involving commercial aircraft.
Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu
Yang, and Mitsuru Ishizuka. 2009. Unsupervised re-
lation extraction by mining Wikipedia texts using in-
formation from the web. In Proceedings of the 47th
Annual Meeting of the ACL and the 4th IJCNLP of the
AFNLP.
</reference>
<page confidence="0.998263">
824
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.547050">
<title confidence="0.999119">Unsupervised Information Extraction with Distributional Prior Knowledge</title>
<author confidence="0.999232">Wing-ki Jing Kian Ming A Hai Leong Loo-Nin</author>
<affiliation confidence="0.999835">of Information Systems, Singapore Management University,</affiliation>
<address confidence="0.55489">National Laboratories, Singapore</address>
<abstract confidence="0.9991502">We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="5863" citStr="Banko et al., 2007" startWordPosition="896" endWordPosition="899"> on the candidate’s feature similarity with candidates from other documents only. In other words, the algorithm did not consider a candidate’s relationships with other candidates in the same document. Our work is based on a different perspective: we model label assignments for all candidates in the same document with a distributional prior that prefers a document to cover more distinct slots. We show empirically that this prior improves slot clustering results greatly in some cases. Also related to our work is open domain IE, which aims to perform unsupervised relation extraction. TEXTRUNNER (Banko et al., 2007), for example, automatically extracts all possible relations between pairs of noun phrases from a given corpus. The main difference between open domain IE and our work is that open domain IE does not aim to induce domain templates, whereas we focus on a single domain with the goal of inducing a template that describes salient information structure of that domain. Furthermore, TEXTRUNNER and related studies on unsupervised relation extraction often rely on highly redundant information on the Web or in large corpus (Hasegawa et al., 2004; Rosenfeld and Feldman, 2006; Yan et al., 2009), which is </context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In International Joint Conference on Artificial Intelligence, pages 2670– 2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>582--590</pages>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 582–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In LREC.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="18965" citStr="Dempster et al., 1977" startWordPosition="3169" endWordPosition="3172">ernoulli Mixture Model In the naive Bayes model our features are defined to be categorical. For the Bernoulli mixture model, as well as the Gaussian mixture model and the locally normalized logistic regression model in the next subsections, we first convert each observation x into a binary feature vector x E {0,11F where F (x, w) denotes the inner product between x and w. The denominator considers all data points x′ in the data set, thus Eq. (7) gives a probability distribution over data points for a given y. 818 6 Parameter Estimation We can apply the Expectation-Maximization (EM) algorithm (Dempster et al., 1977) to maximize the log-likelihood functions under both multinomial prior in Eq. (2) and the proposed Poisson-based prior in Eq. (1). For the multinomial prior, there are standard closed form solutions for the naive Bayes, the Bernoulli mixture and the Gaussian mixture models. For locally normalized logistic regression, model parameters can also be learned via EM, but with a gradient-based M-step (Berg-Kirkpatrick et al., 2010). We leave out the details here and focus on parameter estimation in the proposed generative model with the Poisson-based prior. We assume that in the Poisson-based prior, </context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Druck</author>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Learning from labeled features using generalized expectation criteria.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>595--602</pages>
<contexts>
<context position="7017" citStr="Druck et al. (2008)" startWordPosition="1086" endWordPosition="1089">, 2004; Rosenfeld and Feldman, 2006; Yan et al., 2009), which is not assumed in our study. We propose a generative model with a distributional prior for the unsupervised IE task, where slot fillers correspond to observations in the model, and their labels correspond to hidden variables we want to learn. In the machine learning literature, researchers have explored the use of similar prior knowledge in the form of constraints through model expectation. For example, Grac¸a et al. (2007) proposed to place constraints on the posterior probabilities of hidden variables in a generative model, while Druck et al. (2008) studied a similar problem in a discriminative, semi-supervised setting. These studies model constraints as features, and enforce the constraints through expected feature values. In contrast, we place constraints on label assignments through a probabilistic prior on the distribution of slots. The proposed prior is simple and easy to interpret in a generative model. Nevertheless, it will be interesting to explore how the proposed prior can be implemented within the posterior constraint framework. 3 Problem Overview In this section, we first formally define our unsupervised IE problem. We then p</context>
</contexts>
<marker>Druck, Mann, McCallum, 2008</marker>
<rawString>Gregory Druck, Gideon Mann, and Andrew McCallum. 2008. Learning from labeled features using generalized expectation criteria. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 595–602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard O Duda</author>
<author>Peter E Hart</author>
<author>David G Stork</author>
</authors>
<date>2001</date>
<note>Pattern classification. Wiley-Interscience, 2nd edition.</note>
<contexts>
<context position="27171" citStr="Duda et al., 2001" startWordPosition="4568" endWordPosition="4571">R) model, and Kmeans. We only show the F1 measures in the table due to space limit. We first observe that NB does not perform well for our task. LNLR, which is an interesting contribution in its own right, does not seem to be suitable for our task as well. While NB and LNLR are inferior to K-means for all three data sets, BMM shows mixed results. Specifically, BMM outperforms Kmeans for aviation incidents, but performs poorly for seminar announcements. GMM and K-means achieve similar results, which is not surprising because K-means can be viewed as a special case of the spherical GMM we used (Duda et al., 2001). Overall speaking, results show that GMM is the best among the four generative models for the distri820 (a) Results on seminar announcements. No macro- and micro-average result is reported for NB and BMM as they merged the etime cluster with the stime cluster. Numbers in brackets are the respective measures of the stime cluster when evaluated for etime. Model stime etime speaker location Macro-avg Micro-avg Parameter NB 0.558 (0.342) 0.276 0.172 — — Nil BMM 0.822 (0.440) 0.412 0.402 — — Nil GMM 0.450 0.530 0.417 0.426 0.557 0.455 Nil LNLR 0.386 0.239 0.200 0.208 0.264 0.266 β = .0005 K-means </context>
</contexts>
<marker>Duda, Hart, Stork, 2001</marker>
<rawString>Richard O. Duda, Peter E. Hart, and David G. Stork. 2001. Pattern classification. Wiley-Interscience, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Automatic creation of domain templates.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06,</booktitle>
<pages>207--214</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2204" citStr="Filatova et al., 2006" startWordPosition="318" endWordPosition="321">main experts, and annotated documents are often created to facilitate supervised learning approaches to IE. However, both manual template construction and data annotation are labor-intensive. More importantly, templates and annotated data usually cannot be re-used in new domains due to domain dependency. It is therefore natural to consider the problem of unsupervised template induction and information extraction. This is the topic of this paper. There have been a few previous attempts to address the unsupervised IE problem (Shinyama and Sekine, 2006; Sekine, 2006; Rosenfeld and Feldman, 2006; Filatova et al., 2006). These approaches have a commonality: they try to cluster candidate slot fillers, which are often nouns and noun phrases, into slots of the template to be constructed. However, most of them have neglected the following important observation: a single document or text segment tends to cover different slots rather than redundantly fill the same slot. In other words, during clustering, candidates within the same text segment should be more likely to be distributed into different clusters. In this paper, we propose a generative model that incorporates this distributional prior knowledge. We defin</context>
<context position="4781" citStr="Filatova et al. (2006)" startWordPosition="723" endWordPosition="726">oposed different methods for automatic IE pattern acquisition for a given domain based on frequent subtree discovery in dependency parse trees. These methods leveraged heavily on the entity types of candidates when assigning them to template slots. As a consequence, potentially different semantic roles of candidates having the same entity type could become indistinguishable (Sudo et al., 2003; Sekine, 2006). This problem is alleviated in our work by exploiting distributional prior knowledge about template slots, which is shown effective when coupled with discriminative features of candidates. Filatova et al. (2006) also considered frequent subtrees in dependency parse trees, but their goal was to build templates around verbs that are statistically important in a given domain. Our work, in contrast, is not constrained to verb-centric templates. We aim to identify salient slots in the given domain by clustering. Marx et al. (2002) proposed the cross-component clustering algorithm for unsupervised IE. Their algorithm assigned a candidate from a document to a cluster based on the candidate’s feature similarity with candidates from other documents only. In other words, the algorithm did not consider a candid</context>
</contexts>
<marker>Filatova, Hatzivassiloglou, McKeown, 2006</marker>
<rawString>Elena Filatova, Vasileios Hatzivassiloglou, and Kathleen McKeown. 2006. Automatic creation of domain templates. In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06, pages 207–214, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="22059" citStr="Finkel et al., 2005" startWordPosition="3712" endWordPosition="3715"> our evaluation metrics, followed by experimental results. 7.1 Data Sets We use three data sets for evaluating our unsupervised IE task. Note that to speed up computation, we only include documents or text segments containing no more than 10 candidates in our experiments. The first data set contains a set of seminar announcements (Freitag and McCallum, 1999), annotated with four slot labels, namely stime (start time), etime (end time), speaker and location. We used as candidates all strings labeled in the annotated data as well as all named entities found by the Stanford NER tagger for CoNLL (Finkel et al., 2005). There are 309 seminar announcements with 2262 candidates in this data set. The second data set is a collection of paragraphs describing aviation incidents, taken from the Wikipedia article on “List of accidents and incidents involving commercial aircraft” (Wikipedia, 2009). Each paragraph in the article contains one to a few sentences describing an incident. In this domain, we take each paragraph as a separate document, and all hyperlinked phrases in the original Wikipedia article as candidates. For evaluation, we manually annotated the paragraphs of incidents from 2006 to 2009 with five slo</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 363– 370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Information extraction with HMMs and shrinkage.</title>
<date>1999</date>
<booktitle>In Proceedings of the AAAI-99 Workshop on Machine Learning for Information Extraction.</booktitle>
<contexts>
<context position="21799" citStr="Freitag and McCallum, 1999" startWordPosition="3667" endWordPosition="3670">as discussed in (Berg-Kirkpatrick et al., 2010). 7 Experiments In this section, we first describe the data sets we used in our experiments, detailing the target slots and candidates in each data set, as well as features we extract for the candidates. We then describe our evaluation metrics, followed by experimental results. 7.1 Data Sets We use three data sets for evaluating our unsupervised IE task. Note that to speed up computation, we only include documents or text segments containing no more than 10 candidates in our experiments. The first data set contains a set of seminar announcements (Freitag and McCallum, 1999), annotated with four slot labels, namely stime (start time), etime (end time), speaker and location. We used as candidates all strings labeled in the annotated data as well as all named entities found by the Stanford NER tagger for CoNLL (Finkel et al., 2005). There are 309 seminar announcements with 2262 candidates in this data set. The second data set is a collection of paragraphs describing aviation incidents, taken from the Wikipedia article on “List of accidents and incidents involving commercial aircraft” (Wikipedia, 2009). Each paragraph in the article contains one to a few sentences d</context>
</contexts>
<marker>Freitag, McCallum, 1999</marker>
<rawString>Dayne Freitag and Andrew Kachites McCallum. 1999. Information extraction with HMMs and shrinkage. In Proceedings of the AAAI-99 Workshop on Machine Learning for Information Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems.</booktitle>
<marker>Grac¸a, Ganchev, Taskar, 2007</marker>
<rawString>Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hasegawa</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Discovering relations among named entities from large corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>415</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6404" citStr="Hasegawa et al., 2004" startWordPosition="986" endWordPosition="989">ims to perform unsupervised relation extraction. TEXTRUNNER (Banko et al., 2007), for example, automatically extracts all possible relations between pairs of noun phrases from a given corpus. The main difference between open domain IE and our work is that open domain IE does not aim to induce domain templates, whereas we focus on a single domain with the goal of inducing a template that describes salient information structure of that domain. Furthermore, TEXTRUNNER and related studies on unsupervised relation extraction often rely on highly redundant information on the Web or in large corpus (Hasegawa et al., 2004; Rosenfeld and Feldman, 2006; Yan et al., 2009), which is not assumed in our study. We propose a generative model with a distributional prior for the unsupervised IE task, where slot fillers correspond to observations in the model, and their labels correspond to hidden variables we want to learn. In the machine learning literature, researchers have explored the use of similar prior knowledge in the form of constraints through model expectation. For example, Grac¸a et al. (2007) proposed to place constraints on the posterior probabilities of hidden variables in a generative model, while Druck </context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities from large corpora. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 415, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Macqueen</author>
</authors>
<title>Some methods for classification and analysis of multivariate observations.</title>
<date>1967</date>
<booktitle>In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability,</booktitle>
<volume>1</volume>
<pages>281--297</pages>
<contexts>
<context position="24665" citStr="Macqueen, 1967" startWordPosition="4141" endWordPosition="4142">e in the sentence where it appeared, its entity type (person, location, organization, and date/time), as well as features derived from dependency parse trees. Specifically, we first apply the Stanford lexical parser to our data (de Marneffe et al., 2006). Then for each candidate, we follow its dependencies in the corresponding dependency parse tree until we find a relation r E {nsubj, csubj, dobj, iobj, pobjI in which the candidate is the dependent. We then construct a feature (r, v) where v is governor of the relation. 7.3 Evaluation Baseline and Method We use the standard K-means algorithm (Macqueen, 1967) as a non-generative baseline, since K-means is commonly used for clustering. To evaluate clustering results, we match each slot in the labeled data to the cluster that gives the best F1-measure when evaluated for the slot. We report the precision (P), recall (R) and F1-measure for individual slot labels, as well as the macro- and micro- average results across all labels for each experiment. We conduct 10 trials of experiment on each model and each data set with different random initializations. We report the trials that give the smallest within-cluster sum-of-squares (WCSS) distance for K-mea</context>
</contexts>
<marker>Macqueen, 1967</marker>
<rawString>J. B. Macqueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1, pages 281–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zvika Marx</author>
<author>Ido Dagan</author>
<author>Eli Shamir</author>
</authors>
<title>Crosscomponent clustering for template induction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 ICML Workshop on Text Learning.</booktitle>
<contexts>
<context position="5101" citStr="Marx et al. (2002)" startWordPosition="776" endWordPosition="779"> the same entity type could become indistinguishable (Sudo et al., 2003; Sekine, 2006). This problem is alleviated in our work by exploiting distributional prior knowledge about template slots, which is shown effective when coupled with discriminative features of candidates. Filatova et al. (2006) also considered frequent subtrees in dependency parse trees, but their goal was to build templates around verbs that are statistically important in a given domain. Our work, in contrast, is not constrained to verb-centric templates. We aim to identify salient slots in the given domain by clustering. Marx et al. (2002) proposed the cross-component clustering algorithm for unsupervised IE. Their algorithm assigned a candidate from a document to a cluster based on the candidate’s feature similarity with candidates from other documents only. In other words, the algorithm did not consider a candidate’s relationships with other candidates in the same document. Our work is based on a different perspective: we model label assignments for all candidates in the same document with a distributional prior that prefers a document to cover more distinct slots. We show empirically that this prior improves slot clustering </context>
</contexts>
<marker>Marx, Dagan, Shamir, 2002</marker>
<rawString>Zvika Marx, Ido Dagan, and Eli Shamir. 2002. Crosscomponent clustering for template induction. In Proceedings of the 2002 ICML Workshop on Text Learning.</rawString>
</citation>
<citation valid="true">
<date>1995</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA.</location>
<marker>1995</marker>
<rawString>MUC-6. 1995. Proceedings of the Sixth Message Understanding Conference. Morgan Kaufmann, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Rosenfeld</author>
<author>Ronen Feldman</author>
</authors>
<title>URES : An unsupervised Web relation extraction system.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>667--674</pages>
<contexts>
<context position="2180" citStr="Rosenfeld and Feldman, 2006" startWordPosition="313" endWordPosition="317">s usually done manually by domain experts, and annotated documents are often created to facilitate supervised learning approaches to IE. However, both manual template construction and data annotation are labor-intensive. More importantly, templates and annotated data usually cannot be re-used in new domains due to domain dependency. It is therefore natural to consider the problem of unsupervised template induction and information extraction. This is the topic of this paper. There have been a few previous attempts to address the unsupervised IE problem (Shinyama and Sekine, 2006; Sekine, 2006; Rosenfeld and Feldman, 2006; Filatova et al., 2006). These approaches have a commonality: they try to cluster candidate slot fillers, which are often nouns and noun phrases, into slots of the template to be constructed. However, most of them have neglected the following important observation: a single document or text segment tends to cover different slots rather than redundantly fill the same slot. In other words, during clustering, candidates within the same text segment should be more likely to be distributed into different clusters. In this paper, we propose a generative model that incorporates this distributional p</context>
<context position="6433" citStr="Rosenfeld and Feldman, 2006" startWordPosition="990" endWordPosition="993">ised relation extraction. TEXTRUNNER (Banko et al., 2007), for example, automatically extracts all possible relations between pairs of noun phrases from a given corpus. The main difference between open domain IE and our work is that open domain IE does not aim to induce domain templates, whereas we focus on a single domain with the goal of inducing a template that describes salient information structure of that domain. Furthermore, TEXTRUNNER and related studies on unsupervised relation extraction often rely on highly redundant information on the Web or in large corpus (Hasegawa et al., 2004; Rosenfeld and Feldman, 2006; Yan et al., 2009), which is not assumed in our study. We propose a generative model with a distributional prior for the unsupervised IE task, where slot fillers correspond to observations in the model, and their labels correspond to hidden variables we want to learn. In the machine learning literature, researchers have explored the use of similar prior knowledge in the form of constraints through model expectation. For example, Grac¸a et al. (2007) proposed to place constraints on the posterior probabilities of hidden variables in a generative model, while Druck et al. (2008) studied a simil</context>
</contexts>
<marker>Rosenfeld, Feldman, 2006</marker>
<rawString>Benjamin Rosenfeld and Ronen Feldman. 2006. URES : An unsupervised Web relation extraction system. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 667–674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>On-demand information extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL Main conference poster sessions,</booktitle>
<pages>731--738</pages>
<contexts>
<context position="2137" citStr="Sekine, 2006" startWordPosition="309" endWordPosition="310">tes. Template construction is usually done manually by domain experts, and annotated documents are often created to facilitate supervised learning approaches to IE. However, both manual template construction and data annotation are labor-intensive. More importantly, templates and annotated data usually cannot be re-used in new domains due to domain dependency. It is therefore natural to consider the problem of unsupervised template induction and information extraction. This is the topic of this paper. There have been a few previous attempts to address the unsupervised IE problem (Shinyama and Sekine, 2006; Sekine, 2006; Rosenfeld and Feldman, 2006; Filatova et al., 2006). These approaches have a commonality: they try to cluster candidate slot fillers, which are often nouns and noun phrases, into slots of the template to be constructed. However, most of them have neglected the following important observation: a single document or text segment tends to cover different slots rather than redundantly fill the same slot. In other words, during clustering, candidates within the same text segment should be more likely to be distributed into different clusters. In this paper, we propose a generative mo</context>
<context position="4156" citStr="Sekine (2006)" startWordPosition="632" endWordPosition="633">the proposed prior will have little effect if there are no good discriminative features to begin with. In summary, we find that 814 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 814–824, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics our Poisson-based label assignment prior is effective when coupled with good discriminative features. 2 Related Work One common approach to unsupervised IE is based on automatic IE pattern acquisition on a cluster of similar documents. For instance, Sudo et al. (2003) and Sekine (2006) proposed different methods for automatic IE pattern acquisition for a given domain based on frequent subtree discovery in dependency parse trees. These methods leveraged heavily on the entity types of candidates when assigning them to template slots. As a consequence, potentially different semantic roles of candidates having the same entity type could become indistinguishable (Sudo et al., 2003; Sekine, 2006). This problem is alleviated in our work by exploiting distributional prior knowledge about template slots, which is shown effective when coupled with discriminative features of candidate</context>
</contexts>
<marker>Sekine, 2006</marker>
<rawString>Satoshi Sekine. 2006. On-demand information extraction. In Proceedings of the COLING/ACL Main conference poster sessions, pages 731–738.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="2137" citStr="Shinyama and Sekine, 2006" startWordPosition="307" endWordPosition="310">ion of templates. Template construction is usually done manually by domain experts, and annotated documents are often created to facilitate supervised learning approaches to IE. However, both manual template construction and data annotation are labor-intensive. More importantly, templates and annotated data usually cannot be re-used in new domains due to domain dependency. It is therefore natural to consider the problem of unsupervised template induction and information extraction. This is the topic of this paper. There have been a few previous attempts to address the unsupervised IE problem (Shinyama and Sekine, 2006; Sekine, 2006; Rosenfeld and Feldman, 2006; Filatova et al., 2006). These approaches have a commonality: they try to cluster candidate slot fillers, which are often nouns and noun phrases, into slots of the template to be constructed. However, most of them have neglected the following important observation: a single document or text segment tends to cover different slots rather than redundantly fill the same slot. In other words, during clustering, candidates within the same text segment should be more likely to be distributed into different clusters. In this paper, we propose a generative mo</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>An improved extraction pattern representation model for automatic ie pattern acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>224--231</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4138" citStr="Sudo et al. (2003)" startWordPosition="627" endWordPosition="630">data set and find that the proposed prior will have little effect if there are no good discriminative features to begin with. In summary, we find that 814 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 814–824, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics our Poisson-based label assignment prior is effective when coupled with good discriminative features. 2 Related Work One common approach to unsupervised IE is based on automatic IE pattern acquisition on a cluster of similar documents. For instance, Sudo et al. (2003) and Sekine (2006) proposed different methods for automatic IE pattern acquisition for a given domain based on frequent subtree discovery in dependency parse trees. These methods leveraged heavily on the entity types of candidates when assigning them to template slots. As a consequence, potentially different semantic roles of candidates having the same entity type could become indistinguishable (Sudo et al., 2003; Sekine, 2006). This problem is alleviated in our work by exploiting distributional prior knowledge about template slots, which is shown effective when coupled with discriminative fea</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An improved extraction pattern representation model for automatic ie pattern acquisition. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 224–231, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia</author>
</authors>
<title>List of accidents and incidents involving commercial aircraft. http://en.wikipedia.org/wiki/List of accidents and incidents involving commercial aircraft.</title>
<date>2009</date>
<contexts>
<context position="22334" citStr="Wikipedia, 2009" startWordPosition="3756" endWordPosition="3757">rst data set contains a set of seminar announcements (Freitag and McCallum, 1999), annotated with four slot labels, namely stime (start time), etime (end time), speaker and location. We used as candidates all strings labeled in the annotated data as well as all named entities found by the Stanford NER tagger for CoNLL (Finkel et al., 2005). There are 309 seminar announcements with 2262 candidates in this data set. The second data set is a collection of paragraphs describing aviation incidents, taken from the Wikipedia article on “List of accidents and incidents involving commercial aircraft” (Wikipedia, 2009). Each paragraph in the article contains one to a few sentences describing an incident. In this domain, we take each paragraph as a separate document, and all hyperlinked phrases in the original Wikipedia article as candidates. For evaluation, we manually annotated the paragraphs of incidents from 2006 to 2009 with five slot labels: the flight number (FN), the airline (AL), the aircraft model (AC), the exact αi,yz = p(yi|xi; A, O(t−1)) p(yi; A)p(xi|yi; O(t−1)) = ( ∏ αi,yi log p(yi; A) j ∑ i ∑ yi 819 location (LO) of the incident (e.g. airport name), and the country (CO) where the incident occu</context>
</contexts>
<marker>Wikipedia, 2009</marker>
<rawString>Wikipedia. 2009. List of accidents and incidents involving commercial aircraft. http://en.wikipedia.org/wiki/List of accidents and incidents involving commercial aircraft.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan Yan</author>
<author>Naoaki Okazaki</author>
<author>Yutaka Matsuo</author>
<author>Zhenglu Yang</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Unsupervised relation extraction by mining Wikipedia texts using information from the web.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</booktitle>
<contexts>
<context position="6452" citStr="Yan et al., 2009" startWordPosition="994" endWordPosition="997">TRUNNER (Banko et al., 2007), for example, automatically extracts all possible relations between pairs of noun phrases from a given corpus. The main difference between open domain IE and our work is that open domain IE does not aim to induce domain templates, whereas we focus on a single domain with the goal of inducing a template that describes salient information structure of that domain. Furthermore, TEXTRUNNER and related studies on unsupervised relation extraction often rely on highly redundant information on the Web or in large corpus (Hasegawa et al., 2004; Rosenfeld and Feldman, 2006; Yan et al., 2009), which is not assumed in our study. We propose a generative model with a distributional prior for the unsupervised IE task, where slot fillers correspond to observations in the model, and their labels correspond to hidden variables we want to learn. In the machine learning literature, researchers have explored the use of similar prior knowledge in the form of constraints through model expectation. For example, Grac¸a et al. (2007) proposed to place constraints on the posterior probabilities of hidden variables in a generative model, while Druck et al. (2008) studied a similar problem in a dis</context>
</contexts>
<marker>Yan, Okazaki, Matsuo, Yang, Ishizuka, 2009</marker>
<rawString>Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu Yang, and Mitsuru Ishizuka. 2009. Unsupervised relation extraction by mining Wikipedia texts using information from the web. In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>