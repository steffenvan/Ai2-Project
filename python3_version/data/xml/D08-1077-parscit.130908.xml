<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002551">
<title confidence="0.996423">
Syntactic Models for Structural Word Insertion and Deletion
</title>
<author confidence="0.941602">
Arul Menezes and Chris Quirk
</author>
<affiliation confidence="0.9159715">
Microsoft Research
One Microsoft Way, Redmond, WA 98052, USA
</affiliation>
<email confidence="0.993977">
{arulm, chrisq}@microsoft.com
</email>
<sectionHeader confidence="0.993811" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999734227272727">
An important problem in translation neglected
by most recent statistical machine translation
systems is insertion and deletion of words,
such as function words, motivated by linguistic
structure rather than adjacent lexical context.
Phrasal and hierarchical systems can only
insert or delete words in the context of a larger
phrase or rule. While this may suffice when
translating in-domain, it performs poorly when
trying to translate broad domains such as web
text. Various syntactic approaches have been
proposed that begin to address this problem by
learning lexicalized and unlexicalized rules.
Among these, the treelet approach uses
unlexicalized order templates to model
ordering separately from lexical choice. We
introduce an extension to the latter that allows
for structural word insertion and deletion,
without requiring a lexical anchor, and show
that it produces gains of more than 1.0% BLEU
over both phrasal and baseline treelet systems
on broad domain text.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998317948718">
Among the phenomena that are modeled poorly by
modern SMT systems is the insertion and deletion
of words, such as function words, that are
motivated by the divergent linguistic structure
between source and target language. To take the
simplest of examples, the English noun compound
“file name” would typically be translated into
Spanish as “nombre de archivo”, which requires
the insertion of the preposition “de”. Conversely,
when translating from Spanish to English, the “de”
must be deleted. At first glance, the problem may
seem trivial, yet the presence and position of these
function words can have crucial impact on the
adequacy and fluency of translation.
In particular, function words are often used to
denote key semantic information. They may be
used to denote case information, in languages such
as Japanese. Failing to insert the proper case
marker may render a sentence unreadable or
significantly change its meaning. Learning these
operations can be tricky for MT models best suited
to contiguous word sequences. From a fluency
standpoint, proper insertion of determiners and
prepositions can often make the difference between
laughably awkward output and natural sounding
translations; consider the output “it’s a cake piece”
as opposed to “it’s a piece of cake”.
Furthermore, since missing or spurious function
words can confuse the target language model,
handling these words properly can have an impact
beyond the words themselves.
This paper focuses on methods of inserting and
deleting words based on syntactic cues, to be used
in the context of a syntax-informed translation
system. While the models we build are relatively
simple and the underlying templates are easy to
extract, they add significant generalization ability
to the base translation system, and result in
significant gains.
</bodyText>
<sectionHeader confidence="0.98663" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999922">
As a motivating example, let us return to the
English/Spanish pair “file name” and “nombre de
archivo”. In principle, we would want a machine
translation system to be capable of learning the
following general transformation:
</bodyText>
<equation confidence="0.554207">
“ NOUN1 NOUN2” “ NOUN2 de NOUN1” (1)
</equation>
<bodyText confidence="0.9996004">
Yet even this simple example is beyond the
capabilities of many common approaches.
The heavily lexicalized approaches of phrasal
systems (Koehn et al., 2003), are inherently
incapable of this generalization. As a proxy, they
</bodyText>
<page confidence="0.990795">
735
</page>
<note confidence="0.9621065">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 735–744,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.9749212">
acquire phrase pairs such as “nombre de archivo”
“file name”, “nombre de” “name” and “de
archivo” “file”. Note that the inserted word is
attached to adjacent context word(s). When the test
set vocabulary has significant overlap with the
training vocabulary, the correct translation can
often be assembled based on the head or the
modifying noun. However, as we show in this
paper, this is woefully inadequate when translating
truly out-of-domain input.
In principle, phrase-based translation systems
may employ insertion phrase pairs such as
“[NULL]” “de” (2)
but the ungrounded nature of this transformation
makes its use during decoding difficult. Since there
are no constraints on where such a rule may apply
and the rule does not consume any input words, the
decoder must attempt these rules at every point in
the search.
The reverse operation
</bodyText>
<equation confidence="0.594941">
“de” “[NULL]” (3)
</equation>
<bodyText confidence="0.999835708333333">
is more feasible to implement, though again, there
is great ambiguity – a source word may be deleted
at any point during the search, with identical target
results. Few systems allow this operation in
practice. Estimating the likelihood of this operation
and correctly identifying the contexts in which it
should occur remain challenging problems.
Hierarchical systems, such as (Chiang, 2005) in
principle have the capacity to learn insertions and
deletions grounded by minimal lexical cues.
However, the extracted rules use a single non-
terminal. Hence, to avoid explosive ambiguity,
they are constrained to contain at least one aligned
pair of words. This restriction successfully limits
computational complexity at a cost of
generalization power.
Syntax-based approaches provide fertile context
for grounding insertions and deletions. Often we
may draw a strong correspondence between
function words in one language and syntactic
constructions in another. For instance, the syntactic
approach of Marcu et al. (2006) can learn
unlexicalized rules that insert function words in
isolation, such as:
</bodyText>
<equation confidence="0.975581">
NP(NN:x0 NN:x1) x1 de x0 (4)
</equation>
<bodyText confidence="0.999955333333333">
However, as discussed in (Wang, Knight &amp;
Marcu, 2007), joint modeling of structure and
lexical choice can exacerbate data sparsity, a
problem that they attempt to address by tree
binarization. Nevertheless, as we show below,
unlexicalized structural transformation rules such
as (1) and (4) that allow for insertion of isolated
function words, are essential for good quality
translation of truly out-of-domain test data.
In the treelet translation approach (Menezes &amp;
Quirk, 2007), lexical choice and syntactic re-
ordering are modeled separately using lexicalized
treelets and unlexicalized order templates. We
discuss this approach in more detail in Section 4.
In Section 5, we describe how we extend this
approach to allow for structural insertion and
deletion, without the need for content word
anchors.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999989923076923">
There is surprisingly little prior work in this area.
We previously (Menezes &amp; Quirk, 2005) explored
the use of deletion operations such as (3) above,
but these were not grounded in any syntactic
context, and the estimation was somewhat
heuristic1.
The tuple translation model of Crego et al.
(2005), a joint model over source and target
translations, also provides a means of deleting
words. In training, sentence pairs such as “nombre
de archivo” / “file name” are first word aligned,
then minimal bilingual tuples are identified, such
as “nombre / name”, “de / NULL” and “archivo /
file”. The tuples may involve deletion of words by
allowing an empty target side, but do not allow
insertion tuples with an empty source side. These
inserted words are bound to an adjacent neighbor.
An n-gram model is trained over the tuple
sequences. As a result, deletion probabilities have
the desirable property of being conditioned on
adjacent context, yet this context is heavily
lexicalized, therefore unlikely to generalize well.
More recently, Li et. al. (2008) describe three
models for handling “single word deletion” (they
discuss, but do not address, word insertion). The
first model uses a fixed probability of deletion
</bodyText>
<footnote confidence="0.990431666666667">
1 We assigned channel probabilities based on the sum of the
Model1 probability of the source word being aligned to NULL
or one of a list of &amp;quot;garbage collector&amp;quot; words. This exploits the
property of Model1 that certain high-frequency words tend to
act as &amp;quot;garbage collectors&amp;quot; for words that should remain
unaligned.
</footnote>
<page confidence="0.99826">
736
</page>
<bodyText confidence="0.9999185">
P(NULL), independent of the source word,
estimated by counting null alignments in the
training corpus. The second model estimates a
deletion probability per-word, P(NULL|w), also
directly from the aligned corpus, and the third
model trains an SVM to predict the probability of
deletion given source language context
(neighboring and dependency tree-adjacent words
and parts-of-speech). All three models give large
gains of 1.5% BLEU or more on Chinese-English
translation. It is interesting to note that the more
sophisticated models provide a relatively small
improvement over the simplest model in-domain,
and no benefit out-of-domain.
</bodyText>
<sectionHeader confidence="0.994374" genericHeader="method">
4 Dependency treelet translation
</sectionHeader>
<bodyText confidence="0.9998949">
As a baseline, we use the treelet translation
approach (which we previously described in
Menezes &amp; Quirk, 2007), a linguistically syntax-
based system leveraging a source parser. It first
unifies lexicalized treelets and unlexicalized
templates to construct a sentence-specific set of
synchronous rewrite rules. It then finds the highest
scoring derivation according to a linear
combination of models. We briefly review this
system before describing our current extension.
</bodyText>
<subsectionHeader confidence="0.996323">
4.1 The treelet translation model
</subsectionHeader>
<bodyText confidence="0.999916533333333">
Sentence-specific rewrite rules are constructed by
unifying information from three sources: a
dependency parse of the input sentence, a set of
treelet translation pairs, and a set of unlexicalized
order templates. Dependency parses are
represented as trees: each node has a lexical label
and a part of speech, as well as ordered lists of pre-
and post-modifiers.
A treelet represents a connected subgraph of a
dependency tree; treelet translation pairs consist
of source and target treelets and a node alignment.
This alignment is represented by indices: each
node is annotated with an integer alignment index.
A source node and a target node are aligned iff they
have the same alignment index. For instance:
</bodyText>
<equation confidence="0.9998865">
((old1/JJ) man2/NN) (hombre2 (viejo1)) (5)
(man1/NN) (hombre1) (6)
</equation>
<bodyText confidence="0.99548775">
Order templates are unlexicalized transduction
rules that describe the reorderings, insertions and
deletions associated with a single group of nodes
that are aligned together. For instance:
</bodyText>
<equation confidence="0.99999425">
((x0:/DT) (x1:/JJ) 1/NN) ((x0) 1 (x1)) (7)
((x0:/DT) (x1:/JJ) 1/NN) ((x0) (x1) 1) (8)
((x0:/DT) 1/NN) ((x0) 1) (9)
((x0:/RB) 1/JJ) ((x0) 1) (10)
</equation>
<bodyText confidence="0.99959209375">
Each node is either a placeholder or a variable.
Placeholders, such as 1/NN on the source side or
1 on the target side, have alignment indices and
constraints on their parts-of-speech on the source
side, but are unconstrained lexically (represented
by the ). These unify at translation time with
lexicalized treelet nodes with matching parts-of-
speech and alignment.
Variables, such as x0:/DT on the source side
and x0: on the target side, also have parts-of-
speech constraints on the source side. Variables are
used to indicate where rewrite rules are recursively
applied to translate subtrees. Thus each variable
label such as x0, must occur exactly once on each
side.
In effect, a template specifies how all the
children of a given source node are reordered
during translation. If translation were a word-
replacement task, then templates would be just
simple, single-level tree transducers. However, in
the presence of one-to-many and many-to-one
translations and unaligned words, templates may
span multiple levels in the tree.
As an example, order template (7) indicates that
an NN with two pre-modifying subtrees headed by
DT and JJ may be translated by using a single
word translation of the NN, placing the translation
of the DT subtree as a pre-modifier, and placing
the translation of the JJ subtree as a post-modifier.
As discussed below, this template can unify with
the treelet (6) to produce the following rewrite
rule:
</bodyText>
<equation confidence="0.9968615">
((x0:DT) (x1:JJ) man/NN)
((x0) hombre (x1)) (11)
</equation>
<bodyText confidence="0.998695888888889">
Matching: A treelet translation pair matches an
input parse iff there is a unique correspondence
between the source side of the treelet pair and a
connected subgraph of the input parse.
An order template matches an input parse iff
there is a unique correspondence between the
source side of the template and the input parse,
with the additional restriction that all children of
input nodes that correspond to placeholder
</bodyText>
<page confidence="0.98262">
737
</page>
<bodyText confidence="0.997793666666667">
template nodes must be included in the
correspondence. For instance, order template (7)
matches the parse
</bodyText>
<equation confidence="0.801784">
((the/DT) (young/JJ) colt/NN) (12)
</equation>
<bodyText confidence="0.792721">
but not the parse
</bodyText>
<equation confidence="0.972898">
((the/DT) (old/JJ) (grey/JJ) mare/NN) (13)
</equation>
<bodyText confidence="0.9998611875">
Finally, an order template matches a treelet
translation pair at a given node iff, on both source
and target sides, there is a correspondence between
the treelet translation nodes and template nodes
that is consistent with their tree structure and
alignments. Furthermore, all placeholder nodes in
the template must correspond to some treelet node.
Constructing a sentence-specific rewrite rule is
then a process of unifying each treelet with a
matching combination of order templates with
respect to an input parse. Each treelet node must
be unified with one and only one order template
placeholder node. Unifying under these constraints
produces a rewrite rule that has a one-to-one
correspondence between variables in source and
target. For instance, given the input parse:
</bodyText>
<equation confidence="0.970309">
((the/DT) ((very/RB) old/JJ) man/NN) (14)
</equation>
<bodyText confidence="0.991796666666667">
we can create a rewrite rule from the treelet
translation pair (5) by unifying it with the order
template (7), which matches at the node man and
its descendents, and template (10), which matches
at the node old, to produce the following sentence-
specific rewrite rule:
</bodyText>
<equation confidence="0.9815905">
((the/DT) ((x1:/RB) old/JJ) man/NN)
((el) hombre ((x1) viejo)) (15)
</equation>
<bodyText confidence="0.998985235294118">
Note that by using different combinations of
order templates, a single treelet can produce
multiple rewrite rules. Also, note how treelet
translation pairs capture contextual lexical
translations but are underspecified with respect to
ordering, while order templates separately capture
arbitrary reordering phenomena yet are
underspecified lexically. Keeping lexical and
ordering information orthogonal until runtime
allows for the production of novel transduction
rules never actually seen in the training corpus,
leading to improved generalization power.
Decoding: Given a set of sentence-specific
rewrite rules, a standard beam search algorithm is
used to find the highest scoring derivation.
Derivations are scored according to a linear
combination of models.
</bodyText>
<subsectionHeader confidence="0.969962">
4.2 Training
</subsectionHeader>
<bodyText confidence="0.998780181818182">
The process of extracting treelet translation pairs
and order templates begins with parallel sentences.
First, the sentence pairs are word segmented on
both sides, and the source language sentences are
parsed. Next, the sentence pairs are word aligned
and the alignments are used to project a target
language dependency tree.
Treelet extraction: From each sentence pair
with the alignment relation , a treelet translation
pair consisting of the source treelet and the
target treelet is extracted iff:
</bodyText>
<listItem confidence="0.99578">
(1) There exist and such that .
(2) For all , and such that , iff
</listItem>
<bodyText confidence="0.992567">
.
Order template extraction is attempted starting
from each node Sroot in the source whose parent is
not also aligned to the same target word(s). We
identify Troot, the highest target node aligned to
Sroot. We initialize the sets S0 as {Sroot} and T0 as
{Troot}. We expand S0 to include all nodes
adjacent to some element of S0 that are (a)
unaligned, or (b) aligned to some node in T0. The
converse is applied to T0. This expansion is
repeated until we reach a fixed point. Together, S0
and T0 make up the placeholder nodes in the
extracted order template. We then create one
variable in the order template for each direct child
of nodes in S0 and T0 that is not already included in
the order template. Iff there is a one-to-one word
alignment correspondence between source and
target variables, then a template is extracted. This
restriction leads to clean templates, at the cost of
excluding all templates involving extraposition.
</bodyText>
<sectionHeader confidence="0.948521" genericHeader="method">
5 Insertion/deletion order templates
</sectionHeader>
<bodyText confidence="0.9998394">
In this paper, we extend our previous work to
allow for insertion and deletion of words, by
allowing unaligned lexical items as part of the
otherwise unlexicalized order templates.
Grounding insertions and deletions in templates
rather than treelets has two major benefits. First,
insertion and deletion can be performed even in the
absence of specific lexical context, leading to
greater generalization power. Secondly, this
increased power is tempered by linguistically
</bodyText>
<page confidence="0.990237">
738
</page>
<bodyText confidence="0.999577791666666">
informative unlexicalized context. Rather than
proposing insertions and deletions in any arbitrary
setting, we are guided by specific syntactic
phenomena. For instance, when translating English
noun compounds into Spanish, we often must
include a preposition; this generalization is
naturally captured using just parts-of-speech.
The inclusion of lexical items in order templates
affects the translation system in only a few places:
dependency tree projection, order template
extraction, and rewrite rule construction at runtime.
Dependency tree projection: During this step of
the baseline treelet system, unaligned words are by
default attached low, to the lowest aligned
neighbor. Although this worked well in
conjunction with the discriminative order model, it
prevents unaligned nodes from conditioning on
relevant context in order templates. Therefore, we
change the default attachment of unaligned nodes
to be to the highest aligned neighbor; informal
experiments showed that this did not noticeably
impact translation quality in the baseline system.
For example, consider the source parse and aligned
target sentence:
</bodyText>
<equation confidence="0.998257">
((calibrated1/JJ) (camera2/NN) file3/NN)
archivo3 de4 cámara2 calibrado1 (16)
</equation>
<bodyText confidence="0.998328">
Using the baseline projection algorithm would
produce this target dependency tree:
</bodyText>
<equation confidence="0.844789333333333">
(archivo3 ((de4) cámara2) (calibrado1)) (17)
Instead, we attach unaligned words high:
(archivo3 (de4) (cámara2) (calibrado1)) (18)
</equation>
<bodyText confidence="0.999450833333333">
Order template extraction: In addition to the
purely unlexicalized templates extracted from each
training sentence, we also allow templates that
include lexical items for each unaligned token. For
each point in the original extraction procedure,
where S0 or T0 contain unaligned nodes, we now
extract two templates: The original unlexicalized
template, and a new template in which only the
unaligned node(s) contain the specific lexical
item(s). From the example sentence pair (16),
using the projected parse (18) we would extract the
following two templates:
</bodyText>
<equation confidence="0.99983375">
((x0:/JJ) (x1:/NN) 1/NN)
(1 (2) (x1) (x0)) (19)
((x0:/JJ) (x1:/NN) 1/NN)
(1 (de2) (x1) (x0)) (20)
</equation>
<bodyText confidence="0.999653833333333">
Template matching and unification: We extend
the template matching against the input parse to
require that any lexicalized source template nodes
match the input exactly. When matching templates
to treelet translation pairs, any unaligned treelet
nodes must be consistent with the corresponding
template node (i.e. the template node must be
unlexicalized, or the lexical items must match). On
the other hand, lexicalized template nodes do not
need to match any treelet nodes -- insertions or
deletions may now come from the template alone.
Consider the following example input parse:
</bodyText>
<equation confidence="0.9985095">
((digital/JJ) (camera/NN)
(file/NN) extension/NN) (21)
</equation>
<bodyText confidence="0.99846075">
The following treelet translation pair provides a
contextual translation for some of the children,
including the insertion of one necessary
preposition:
</bodyText>
<equation confidence="0.9994865">
((file1/NN) extension2/NN)
(extension2 (de3) (archivo1)) (22)
</equation>
<bodyText confidence="0.999839333333333">
The following order template can provide relative
ordering information between nodes as well as
insert the remaining prepositions:
</bodyText>
<equation confidence="0.999945">
((x0:/JJ) (x1:/NN) (x2:/NN) 1/NN)
(1 (de2) (x2) (de3) (x0) (x1)) (23)
</equation>
<bodyText confidence="0.9999618">
The unification of this template and treelet is
somewhat complex: the first inserted de is agreed
upon by both template and treelet, whereas the
second is inserted by the template alone. This
results in the following novel rewrite rule:
</bodyText>
<equation confidence="0.9988995">
((x0:/JJ) (x1:/NN) (file) extension)
(extension (de) (archivo) (de) (x0) (x1)) (24)
</equation>
<bodyText confidence="0.999785466666667">
These relatively minimal changes produce a
powerful contextualized model of insertion and
deletion.
Parameter estimation: The underlying treelet
system includes a template probability estimated
by relative frequency. We estimate our lexicalized
templates in the same way. However early
experiments showed that this feature alone was not
enough to allow even common insertions, since the
probability of even the most common insertion
templates is much lower than that of unlexicalized
templates. To improve the modeling capability, we
included two additional feature functions: a count
of structurally inserted words, and a count of
structurally deleted words.
</bodyText>
<page confidence="0.988845">
739
</page>
<figure confidence="0.999558638888889">
September is
NN VB
National
JJ
Cholesterol
NN
Education
NN
Month
NN
Input dependency tree
Treelets Templates Rewrite Rules
september is x0:* *1 xl:* september is xl:*
NN VB NN VB NN NN VB NN
septiembre es x0 *1 elz xl septiembre es el xl
month
NN
mes
x2:*
NN
xl:*
NN
x0:*
JJ
*1
NN
x0 dez x2 de3 xl
x2:*
NN
xl:*
NN
x0:*
JJ
month
NN
mes x0 de x2 de xl
</figure>
<figureCaption confidence="0.996386">
Figure 6.1: Example sentence, matching treelets, structural insertion templates and unified rewrite rules
</figureCaption>
<sectionHeader confidence="0.987838" genericHeader="method">
6 Example
</sectionHeader>
<bodyText confidence="0.993548066666667">
Consider the following English test sentence and
corresponding Spanish human translation:
September is National Cholesterol Education
Month
Septiembre es el Mes Nacional para la
Educación sobre el Colesterol
The baseline treelet system without structural
insertions translates this sentence as:
Septiembre es Nacional Colesterol Educación
Mes
Not only is the translation missing the appropriate
articles and prepositions, but also in their absence,
it fails to reorder the content words correctly.
Without the missing prepositions, the language
model does not show a strong preference among
various orderings of &amp;quot;nacional&amp;quot; &amp;quot;colesterol&amp;quot;
&amp;quot;educación&amp;quot; and &amp;quot;mes&amp;quot;.
Using structural insertion templates, the highest
scoring translation of the sentence is now:
Septiembre es el Mes Nacional de Educación de
colesterol
Although the choice of prepositions is not the same
as the reference, the fluency is much improved and
the translation is quite understandable. Figure 6.1,
lists the structural insertion templates that are used
to produce this translation, and shows how they are
unified with treelet translation pairs to produce
sentence-specific rewrite rules, which are in turn
composed during decoding to produce this
translation.
</bodyText>
<sectionHeader confidence="0.999216" genericHeader="method">
7 Experiments
</sectionHeader>
<bodyText confidence="0.999964375">
We evaluated the translation quality of the system
using the BLEU metric (Papineni et al., 2002). We
compared three systems: (a) a standard phrasal
system using a decoder based on Pharaoh, (Koehn
et al., 2003), (b) A baseline treelet system using
unlexicalized order templates and (c) The present
work, which adds structural insertion and deletion
templates.
</bodyText>
<subsectionHeader confidence="0.990009">
7.1 Data
</subsectionHeader>
<bodyText confidence="0.999792625">
We report results for two language pairs, English-
Spanish and English- Japanese. For English-
Spanish we use two training sets: (a) the Europarl
corpus provided by the NAACL 2006 Statistical
Machine Translation workshop (b) a “general-
domain” data set that includes a broad spectrum of
data such as governmental data, general web data
and technical corpora.
</bodyText>
<page confidence="0.991128">
740
</page>
<table confidence="0.905387571428572">
For English-Japanese we use only the “general-
domain” data set.
Sentence Tokens Phr MERT
pairs size data
Europarl E-S 730K 15M 7 Europarl
General E-S 3.7M 41M 4 Web
General E-J 2.6M 16M 4 Web
</table>
<tableCaption confidence="0.995648">
Table 7.1 Training data
</tableCaption>
<bodyText confidence="0.998901888888889">
For English-Spanish we report results using the
four test sets listed in Table 7.2. For English-
Japanese we use only the web test set. The first
two tests are from the 2006 SMT workshop and the
newswire test is from the 2008 workshop. The web
test sets were selected from a random sampling of
English web sites, with target language translations
provided by professional translation vendors. All
test sets have one reference translation.
</bodyText>
<table confidence="0.9997214">
Domain Sentence pairs
eu-test Europarl 2000
nc-test News commentary 1064
News News wire 2051
Web General web text 5000
</table>
<tableCaption confidence="0.993265">
Table 7.2 Test data
</tableCaption>
<subsectionHeader confidence="0.996895">
7.2 Models
</subsectionHeader>
<bodyText confidence="0.997412666666667">
The baseline treelet translation system uses all the
models described in Menezes &amp; Quirk (2007),
namely:
</bodyText>
<listItem confidence="0.983039">
• Treelet log probabilities, maximum likelihood
estimates with absolute discounting.
• Forward and backward lexical weighting,
using Model-1 translation log probabilities.
• Trigram language model using modified
Kneser-Ney smoothing.
• Word and phrase count feature functions.
• Order template log probabilities, maximum
likelihood estimates, absolute discounting.
• Count of artificial source order templates.2
• Discriminative tree-based order model.
The present work does not use the discriminative
tree-based order model3 but adds:
</listItem>
<footnote confidence="0.9302248">
2 When no template is compatible with a treelet, the decoder
creates an artificial template that preserves source order. This
count feature allows MERT to deprecate the use of such
templates. This is analogous to the glue rules of Chiang
(2005).
</footnote>
<listItem confidence="0.965257833333333">
• Count of structural insertions: This counts only
words inserted via templates, not lexical
insertions via treelets.
• Count of structural deletions: This counts only
words deleted via templates, not lexical
deletions via treelets.
</listItem>
<bodyText confidence="0.99766125">
The comparison phrasal system was constructed
using the same alignments and the heuristic
combination described in (Koehn et al., 2003).
This system used a standard set of models:
</bodyText>
<listItem confidence="0.9999625">
• Direct and inverse log probabilities, both
relative frequency and lexical weighting.
• Word count, phrase count.
• Trigram language model log probability.
• Length based distortion model.
• Lexicalized reordering model.
</listItem>
<subsectionHeader confidence="0.983275">
7.3 Training
</subsectionHeader>
<bodyText confidence="0.99997675">
We parsed the source (English) side of the corpus
using NLPWIN, a broad-coverage rule-based
parser able to produce syntactic analyses at varying
levels of depth (Heidorn, 2000). For the purposes
of these experiments, we used a dependency tree
output with part-of-speech tags and unstemmed,
case-normalized surface words. For word
alignment we used a training regimen of five
iterations of Model 1, followed by five iterations of
a word-dependent HMM model (He, 2007) in both
directions. The forward and backward alignments
were combined using a dependency tree-based
heuristic combination. The word alignments and
English dependency tree were used to project a
target tree. From the aligned tree pairs we
extracted treelet and order template tables.
For the Europarl systems, we use a
phrase/treelet size of 7 and train model weights
using 2000 sentences of Europarl data. For the
“general-domain” systems, we use a phrase/treelet
size of 4, and train model weights using 2000
sentences of web data.
For any given corpus, all systems used the same
treelet or phrase size (see Table 7.1) and the same
trigram language model. Model weights were
trained separately for each system, data set and
experimental condition, using minimum error rate
training to maximize BLEU (Och, 2003).
</bodyText>
<footnote confidence="0.609920666666667">
3 In our experiments, we find that the impact of this model is
small in the presence of order templates; also, it degrades the
overall speed of the decoder.
</footnote>
<page confidence="0.984599">
741
</page>
<table confidence="0.999093166666667">
% BLEU
Phrasal 13.41
Baseline treelet 15.89
+Deletion only 16.00
+Insertion only 16.16
+Deletion and Insertion 17.01
</table>
<tableCaption confidence="0.996239">
Table 8.1: English-Japanese system comparisons
</tableCaption>
<sectionHeader confidence="0.998292" genericHeader="evaluation">
8 Results and Discussion
</sectionHeader>
<bodyText confidence="0.966740975">
Tables 8.1 and 8.4 compare baseline phrasal and
treelet systems with systems that use various types
of insertion and deletion templates.
English-Japanese: As one might expect, the use
of structural insertion and deletion has the greatest
impact when translating between languages such as
English and Japanese that show significant
structural divergence. In this language pair, both
insertions and deletions have an impact, for a total
gain of 1.1% BLEU over the baseline treelet
system, and 3.6% over the phrasal system. To aid
our understanding of the system, we tabulated the
most commonly inserted and deleted words when
translating from English into Japanese in Tables
8.2 and 8.3 respectively. Satisfyingly, most of the
insertions and deletions correspond to well-known
structural differences between the languages. For
instance, in English the thematic role of a noun
phrase, such as subject or object, is typically
indicated by word order, whereas Japanese uses
case markers to express this information. Hence,
case markers such as “” and “” need to be
inserted. Also, when noun compounds are
translated, an intervening postposition such as “”
is usually needed. Among the most common
deletions are “the” and “a”. This is because
Japanese does not have a notion of definiteness.
Similarly, pronouns are often dropped in Japanese.
English-Spanish: We note, in Table 8.4 that
even between such closely related languages,
structural insertions give us noticeable
improvements over the baseline treelet system. On
the smaller Europarl training corpus the
improvements range from 0.5% to 1.1% BLEU.
On the larger training corpus we find that for the
more in-domain governmental4 and news test sets,
the effect is smaller or even slightly negative, but
4 The &amp;quot;general domain&amp;quot; training corpus is a superset of the
Europarl training set, therefore, the Europarl tests sets are &amp;quot;in-
domain&amp;quot; in both cases.
</bodyText>
<table confidence="0.99341925">
Word Count %age Type
2844 42% Postposition
1637 24% Postposition/case marker
630 9.3% Postposition/case marker
517 7.6% Punctuation
476 7.0% Postposition
266 3.9% Light verb
101 1.5% Postposition
68 1.0% Postposition
27 0.40% Light verb
26 0.38% Punctuation
19 0.28% Question marker
</table>
<tableCaption confidence="0.989698">
Table 8.2: E-J: Most commonly inserted words
</tableCaption>
<table confidence="0.999955333333333">
Word Count %age Type
the 875 59% Definite article
- 159 11% Punctuation
a 113 7.7% Indefinite article
you 53 3.6% Pronoun
it 53 3.6% Pronoun
that 26 1.8% Conjunction, Pronoun
&amp;quot; 23 1.6% Punctuation
in 16 1.1% Preposition
. 10 0.68% Punctuation
&apos;s 10 0.68% Possessive
I 9 0.61% Pronoun
</table>
<tableCaption confidence="0.999198">
Table 8.3: E-J: Most commonly deleted words
</tableCaption>
<bodyText confidence="0.999918608695652">
on the very broad web test set we still see an
improvement of about 0.7% BLEU.
As one might expect, as the training data size
increases, the generalization power of structural
insertion and deletions becomes less important
when translating in-domain text, as more insertions
and deletions can be handled lexically.
Nevertheless, the web test results indicate that if
one hopes to handle truly general input the need
for structural generalizations remains.
Unlike in English-Japanese, when translating
from English to Spanish, structural deletions are
less helpful. Used in isolation or in combination
with insertion templates they have a slightly
negative and/or insignificant impact in all cases.
We hypothesize that when translating from English
into Spanish, more words need to be inserted than
deleted. Conversely, when translating in the
reverse direction, deletion templates may play a
bigger role. We were unable to test the reverse
direction because our syntax-based systems depend
on a source language parser. In future work we
hope to address this.
</bodyText>
<page confidence="0.988223">
742
</page>
<table confidence="0.999906461538462">
EU-devtest EU-test NC-test Newswire Web test
EUROPARL E-S
Phrasal 27.9 28.5 24.7 17.7 17.0
Baseline treelet 27.65 28.38 27.00 18.46 18.71
+Deletion only 27.66 28.39 26.97 18.46 18.64
+Insertion only 28.23 28.93 28.10 19.08 19.43
+Deletion and Insertion 28.27 29.08 27.82 18.98 19.19
GENERAL E-S
Phrasal 28.79 29.19 29.45 21.12 27.91
Baseline treelet 28.67 29.33 32.49 21.90 27.42
+Deletion only 28.67 29.27 32.25 21.69 27.47
+Insertion only 28.90 29.70 32.53 21.84 28.30
+Deletion and Insertion 28.34 29.41 32.66 21.70 27.95
</table>
<tableCaption confidence="0.999204">
Table 8.4: English-Spanish system comparisons, %BLEU
</tableCaption>
<bodyText confidence="0.999974764705882">
In table 8.5 and 8.6, we list the words most
commonly inserted and deleted when translating
the web test using the general English-Spanish
system. As in English-Japanese, we find that the
insertions are what one would expect on linguistic
grounds. However, deletions are used much less
frequently than insertions and also much less
frequently than they are in English-Japanese. Only
53 words are structurally deleted in the 5000
sentence test set, as opposed to 4728 structural
insertions. Furthermore, the most common deletion
is of quotation marks, which is incorrect in most
cases, even though such deletion is evidenced in
the training corpus5.
On the other hand, the next most common
deletions “I” and “it” are linguistically well
grounded, since Spanish often drops pronouns.
</bodyText>
<sectionHeader confidence="0.994953" genericHeader="conclusions">
9 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999984214285714">
We have presented an extension of the treelet
translation method to include order templates with
structural insertion and deletion, which improves
translation quality under a variety of scenarios,
particularly between structurally divergent
languages. Even between closely related
languages, these operations significantly improve
the generalizability of the system, providing
benefit when handling out-of-domain test data.
Our experiments shed light on a little-studied
area of MT, but one that is nonetheless crucial for
high quality broad domain translation. Our results
affirm the importance of structural insertions, in
particular, when translating from English into other
</bodyText>
<footnote confidence="0.6963775">
5 In many parallel corpora, quotes are not consistently
preserved between source and target languages.
</footnote>
<table confidence="0.999756833333333">
de 3509 74% Preposition
la 555 12% Determiner
el 250 5.3% Determiner
se 77 1.6% Reflexive pronoun
que 63 1.3% Relative pronoun
los 63 1.3% Determiner
del 57 1.2% Preposition+Determiner
, 42 0.89% Punctuation
a 30 0.63% Preposition
en 21 0.44% Preposition
lo 9 0.19% Pronoun
las 6 0.13% Determiner
</table>
<tableCaption confidence="0.992153">
Table 8.5: E-S: Most commonly inserted words
</tableCaption>
<table confidence="0.999815">
&amp;quot; 38 72% Punctuation
I 5 9.4% Pronoun
it 2 3.8% Pronoun
, 2 3.8% Punctuation
- 2 3.8% Punctuation
</table>
<tableCaption confidence="0.999215">
Table 8.6: E-S: Most commonly deleted words
</tableCaption>
<bodyText confidence="0.999944">
languages, and the importance of both insertions
and deletions when translating between divergent
languages. In future, we hope to study translations
from other languages into English to study the role
of deletions in such cases.
</bodyText>
<sectionHeader confidence="0.999283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999426222222222">
Chiang, David. A hierarchical phrase-based model for
statistical machine translation. ACL 2005.
Crego, Josep, José Mariño and Adrià de Gispert.
Reordered search and tuple unfolding for Ngram-
based SMT. MT Summit 2005.
He, Xiaodong. Using Word Dependent Transition
Models in HMM based Word Alignment for
Statistical Machine Translation. Workshop on
Statistical Machine Translation, 2007
</reference>
<page confidence="0.985204">
743
</page>
<reference confidence="0.9995038">
Heidorn, George. “Intelligent writing assistance”. In
Dale et al. Handbook of Natural Language
Processing, Marcel Dekker. 2000
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
Statistical phrase based translation. NAACL 2003.
Chi-Ho Li, Dongdong Zhang, Mu Li, Ming Zhou, Hailei
Zhang. An Empirical Study in SourceWord Deletion
for Phrase-based Statistical Machine Translation.
Workshop on Statistical Machine Translation, 2008
Marcu, Daniel, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. SPMT: Statistical Machine
Translation with Syntactified Target Language
Phrases. EMNLP-2006.
Menezes, Arul, and Chris Quirk. Microsoft Research
Treelet translation system: IWSLT evaluation.
International Workshop on Spoken Language
Translation, 2005
Menezes, Arul, and Chris Quirk. Using Dependency
Order Templates to Improve Generality in
Translation. Workshop on Statistical Machine
Translation, 2007
Och, Franz Josef. Minimum error rate training in
statistical machine translation. ACL 2003.
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. BLEU: a method for automatic evaluation
of machine translation. ACL 2002.
Wang, Wei, Kevin Knight and Daniel Marcu.
Binarizing Syntax Trees to Improve Syntax-Based
Machine Translation Accuracy. EMNLP-CoNLL,
2007
</reference>
<page confidence="0.99829">
744
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429781">
<title confidence="0.8804225">Syntactic Models for Structural Word Insertion and Deletion Menezes</title>
<affiliation confidence="0.666718">Microsoft</affiliation>
<address confidence="0.994652">One Microsoft Way, Redmond, WA 98052,</address>
<email confidence="0.997047">arulm@microsoft.com</email>
<email confidence="0.997047">chrisq@microsoft.com</email>
<abstract confidence="0.999532347826087">An important problem in translation neglected by most recent statistical machine translation systems is insertion and deletion of words, such as function words, motivated by linguistic structure rather than adjacent lexical context. Phrasal and hierarchical systems can only insert or delete words in the context of a larger phrase or rule. While this may suffice when translating in-domain, it performs poorly when trying to translate broad domains such as web text. Various syntactic approaches have been proposed that begin to address this problem by learning lexicalized and unlexicalized rules. Among these, the treelet approach uses unlexicalized order templates to model ordering separately from lexical choice. We introduce an extension to the latter that allows for structural word insertion and deletion, without requiring a lexical anchor, and show that it produces gains of more than 1.0% BLEU over both phrasal and baseline treelet systems on broad domain text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation. ACL</title>
<date>2005</date>
<contexts>
<context position="4928" citStr="Chiang, 2005" startWordPosition="752" endWordPosition="753">cult. Since there are no constraints on where such a rule may apply and the rule does not consume any input words, the decoder must attempt these rules at every point in the search. The reverse operation “de” “[NULL]” (3) is more feasible to implement, though again, there is great ambiguity – a source word may be deleted at any point during the search, with identical target results. Few systems allow this operation in practice. Estimating the likelihood of this operation and correctly identifying the contexts in which it should occur remain challenging problems. Hierarchical systems, such as (Chiang, 2005) in principle have the capacity to learn insertions and deletions grounded by minimal lexical cues. However, the extracted rules use a single nonterminal. Hence, to avoid explosive ambiguity, they are constrained to contain at least one aligned pair of words. This restriction successfully limits computational complexity at a cost of generalization power. Syntax-based approaches provide fertile context for grounding insertions and deletions. Often we may draw a strong correspondence between function words in one language and syntactic constructions in another. For instance, the syntactic approa</context>
<context position="24595" citStr="Chiang (2005)" startWordPosition="3768" endWordPosition="3769">ies. • Trigram language model using modified Kneser-Ney smoothing. • Word and phrase count feature functions. • Order template log probabilities, maximum likelihood estimates, absolute discounting. • Count of artificial source order templates.2 • Discriminative tree-based order model. The present work does not use the discriminative tree-based order model3 but adds: 2 When no template is compatible with a treelet, the decoder creates an artificial template that preserves source order. This count feature allows MERT to deprecate the use of such templates. This is analogous to the glue rules of Chiang (2005). • Count of structural insertions: This counts only words inserted via templates, not lexical insertions via treelets. • Count of structural deletions: This counts only words deleted via templates, not lexical deletions via treelets. The comparison phrasal system was constructed using the same alignments and the heuristic combination described in (Koehn et al., 2003). This system used a standard set of models: • Direct and inverse log probabilities, both relative frequency and lexical weighting. • Word count, phrase count. • Trigram language model log probability. • Length based distortion mo</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, David. A hierarchical phrase-based model for statistical machine translation. ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josep Crego</author>
</authors>
<title>José Mariño and Adrià de Gispert. Reordered search and tuple unfolding for Ngrambased SMT. MT Summit</title>
<date>2005</date>
<marker>Crego, 2005</marker>
<rawString>Crego, Josep, José Mariño and Adrià de Gispert. Reordered search and tuple unfolding for Ngrambased SMT. MT Summit 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
</authors>
<title>Using Word Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation. Workshop on Statistical Machine Translation,</title>
<date>2007</date>
<contexts>
<context position="25711" citStr="He, 2007" startWordPosition="3936" endWordPosition="3937">d count, phrase count. • Trigram language model log probability. • Length based distortion model. • Lexicalized reordering model. 7.3 Training We parsed the source (English) side of the corpus using NLPWIN, a broad-coverage rule-based parser able to produce syntactic analyses at varying levels of depth (Heidorn, 2000). For the purposes of these experiments, we used a dependency tree output with part-of-speech tags and unstemmed, case-normalized surface words. For word alignment we used a training regimen of five iterations of Model 1, followed by five iterations of a word-dependent HMM model (He, 2007) in both directions. The forward and backward alignments were combined using a dependency tree-based heuristic combination. The word alignments and English dependency tree were used to project a target tree. From the aligned tree pairs we extracted treelet and order template tables. For the Europarl systems, we use a phrase/treelet size of 7 and train model weights using 2000 sentences of Europarl data. For the “general-domain” systems, we use a phrase/treelet size of 4, and train model weights using 2000 sentences of web data. For any given corpus, all systems used the same treelet or phrase </context>
</contexts>
<marker>He, 2007</marker>
<rawString>He, Xiaodong. Using Word Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation. Workshop on Statistical Machine Translation, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Heidorn</author>
</authors>
<title>Intelligent writing assistance”.</title>
<date>2000</date>
<booktitle>In Dale et al. Handbook of Natural Language Processing,</booktitle>
<publisher>Marcel Dekker.</publisher>
<contexts>
<context position="25421" citStr="Heidorn, 2000" startWordPosition="3891" endWordPosition="3892">eletions via treelets. The comparison phrasal system was constructed using the same alignments and the heuristic combination described in (Koehn et al., 2003). This system used a standard set of models: • Direct and inverse log probabilities, both relative frequency and lexical weighting. • Word count, phrase count. • Trigram language model log probability. • Length based distortion model. • Lexicalized reordering model. 7.3 Training We parsed the source (English) side of the corpus using NLPWIN, a broad-coverage rule-based parser able to produce syntactic analyses at varying levels of depth (Heidorn, 2000). For the purposes of these experiments, we used a dependency tree output with part-of-speech tags and unstemmed, case-normalized surface words. For word alignment we used a training regimen of five iterations of Model 1, followed by five iterations of a word-dependent HMM model (He, 2007) in both directions. The forward and backward alignments were combined using a dependency tree-based heuristic combination. The word alignments and English dependency tree were used to project a target tree. From the aligned tree pairs we extracted treelet and order template tables. For the Europarl systems, </context>
</contexts>
<marker>Heidorn, 2000</marker>
<rawString>Heidorn, George. “Intelligent writing assistance”. In Dale et al. Handbook of Natural Language Processing, Marcel Dekker. 2000</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase based translation. NAACL</title>
<date>2003</date>
<contexts>
<context position="3424" citStr="Koehn et al., 2003" startWordPosition="520" endWordPosition="523">build are relatively simple and the underlying templates are easy to extract, they add significant generalization ability to the base translation system, and result in significant gains. 2 Background As a motivating example, let us return to the English/Spanish pair “file name” and “nombre de archivo”. In principle, we would want a machine translation system to be capable of learning the following general transformation: “ NOUN1 NOUN2” “ NOUN2 de NOUN1” (1) Yet even this simple example is beyond the capabilities of many common approaches. The heavily lexicalized approaches of phrasal systems (Koehn et al., 2003), are inherently incapable of this generalization. As a proxy, they 735 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 735–744, Honolulu, October 2008.c�2008 Association for Computational Linguistics acquire phrase pairs such as “nombre de archivo” “file name”, “nombre de” “name” and “de archivo” “file”. Note that the inserted word is attached to adjacent context word(s). When the test set vocabulary has significant overlap with the training vocabulary, the correct translation can often be assembled based on the head or the modifying noun. However</context>
<context position="22391" citStr="Koehn et al., 2003" startWordPosition="3421" endWordPosition="3424"> prepositions is not the same as the reference, the fluency is much improved and the translation is quite understandable. Figure 6.1, lists the structural insertion templates that are used to produce this translation, and shows how they are unified with treelet translation pairs to produce sentence-specific rewrite rules, which are in turn composed during decoding to produce this translation. 7 Experiments We evaluated the translation quality of the system using the BLEU metric (Papineni et al., 2002). We compared three systems: (a) a standard phrasal system using a decoder based on Pharaoh, (Koehn et al., 2003), (b) A baseline treelet system using unlexicalized order templates and (c) The present work, which adds structural insertion and deletion templates. 7.1 Data We report results for two language pairs, EnglishSpanish and English- Japanese. For EnglishSpanish we use two training sets: (a) the Europarl corpus provided by the NAACL 2006 Statistical Machine Translation workshop (b) a “generaldomain” data set that includes a broad spectrum of data such as governmental data, general web data and technical corpora. 740 For English-Japanese we use only the “generaldomain” data set. Sentence Tokens Phr </context>
<context position="24965" citStr="Koehn et al., 2003" startWordPosition="3820" endWordPosition="3823">dds: 2 When no template is compatible with a treelet, the decoder creates an artificial template that preserves source order. This count feature allows MERT to deprecate the use of such templates. This is analogous to the glue rules of Chiang (2005). • Count of structural insertions: This counts only words inserted via templates, not lexical insertions via treelets. • Count of structural deletions: This counts only words deleted via templates, not lexical deletions via treelets. The comparison phrasal system was constructed using the same alignments and the heuristic combination described in (Koehn et al., 2003). This system used a standard set of models: • Direct and inverse log probabilities, both relative frequency and lexical weighting. • Word count, phrase count. • Trigram language model log probability. • Length based distortion model. • Lexicalized reordering model. 7.3 Training We parsed the source (English) side of the corpus using NLPWIN, a broad-coverage rule-based parser able to produce syntactic analyses at varying levels of depth (Heidorn, 2000). For the purposes of these experiments, we used a dependency tree output with part-of-speech tags and unstemmed, case-normalized surface words.</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och, and Daniel Marcu. Statistical phrase based translation. NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi-Ho Li</author>
<author>Dongdong Zhang</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
<author>Hailei Zhang</author>
</authors>
<title>An Empirical Study in SourceWord Deletion for Phrase-based Statistical Machine Translation. Workshop on Statistical Machine Translation,</title>
<date>2008</date>
<marker>Li, Zhang, Li, Zhou, Zhang, 2008</marker>
<rawString>Chi-Ho Li, Dongdong Zhang, Mu Li, Ming Zhou, Hailei Zhang. An Empirical Study in SourceWord Deletion for Phrase-based Statistical Machine Translation. Workshop on Statistical Machine Translation, 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical Machine Translation with Syntactified Target Language Phrases.</title>
<date>2006</date>
<contexts>
<context position="5553" citStr="Marcu et al. (2006)" startWordPosition="841" endWordPosition="844">inciple have the capacity to learn insertions and deletions grounded by minimal lexical cues. However, the extracted rules use a single nonterminal. Hence, to avoid explosive ambiguity, they are constrained to contain at least one aligned pair of words. This restriction successfully limits computational complexity at a cost of generalization power. Syntax-based approaches provide fertile context for grounding insertions and deletions. Often we may draw a strong correspondence between function words in one language and syntactic constructions in another. For instance, the syntactic approach of Marcu et al. (2006) can learn unlexicalized rules that insert function words in isolation, such as: NP(NN:x0 NN:x1) x1 de x0 (4) However, as discussed in (Wang, Knight &amp; Marcu, 2007), joint modeling of structure and lexical choice can exacerbate data sparsity, a problem that they attempt to address by tree binarization. Nevertheless, as we show below, unlexicalized structural transformation rules such as (1) and (4) that allow for insertion of isolated function words, are essential for good quality translation of truly out-of-domain test data. In the treelet translation approach (Menezes &amp; Quirk, 2007), lexical </context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Marcu, Daniel, Wei Wang, Abdessamad Echihabi, and Kevin Knight. SPMT: Statistical Machine Translation with Syntactified Target Language Phrases. EMNLP-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arul Menezes</author>
<author>Chris Quirk</author>
</authors>
<title>Microsoft Research Treelet translation system:</title>
<date>2005</date>
<booktitle>IWSLT evaluation. International Workshop on Spoken Language Translation,</booktitle>
<contexts>
<context position="6575" citStr="Menezes &amp; Quirk, 2005" startWordPosition="999" endWordPosition="1002"> that allow for insertion of isolated function words, are essential for good quality translation of truly out-of-domain test data. In the treelet translation approach (Menezes &amp; Quirk, 2007), lexical choice and syntactic reordering are modeled separately using lexicalized treelets and unlexicalized order templates. We discuss this approach in more detail in Section 4. In Section 5, we describe how we extend this approach to allow for structural insertion and deletion, without the need for content word anchors. 3 Related Work There is surprisingly little prior work in this area. We previously (Menezes &amp; Quirk, 2005) explored the use of deletion operations such as (3) above, but these were not grounded in any syntactic context, and the estimation was somewhat heuristic1. The tuple translation model of Crego et al. (2005), a joint model over source and target translations, also provides a means of deleting words. In training, sentence pairs such as “nombre de archivo” / “file name” are first word aligned, then minimal bilingual tuples are identified, such as “nombre / name”, “de / NULL” and “archivo / file”. The tuples may involve deletion of words by allowing an empty target side, but do not allow inserti</context>
</contexts>
<marker>Menezes, Quirk, 2005</marker>
<rawString>Menezes, Arul, and Chris Quirk. Microsoft Research Treelet translation system: IWSLT evaluation. International Workshop on Spoken Language Translation, 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arul Menezes</author>
<author>Chris Quirk</author>
</authors>
<title>Using Dependency Order Templates to Improve Generality in Translation.</title>
<date>2007</date>
<booktitle>Workshop on Statistical Machine Translation,</booktitle>
<contexts>
<context position="6143" citStr="Menezes &amp; Quirk, 2007" startWordPosition="931" endWordPosition="934"> approach of Marcu et al. (2006) can learn unlexicalized rules that insert function words in isolation, such as: NP(NN:x0 NN:x1) x1 de x0 (4) However, as discussed in (Wang, Knight &amp; Marcu, 2007), joint modeling of structure and lexical choice can exacerbate data sparsity, a problem that they attempt to address by tree binarization. Nevertheless, as we show below, unlexicalized structural transformation rules such as (1) and (4) that allow for insertion of isolated function words, are essential for good quality translation of truly out-of-domain test data. In the treelet translation approach (Menezes &amp; Quirk, 2007), lexical choice and syntactic reordering are modeled separately using lexicalized treelets and unlexicalized order templates. We discuss this approach in more detail in Section 4. In Section 5, we describe how we extend this approach to allow for structural insertion and deletion, without the need for content word anchors. 3 Related Work There is surprisingly little prior work in this area. We previously (Menezes &amp; Quirk, 2005) explored the use of deletion operations such as (3) above, but these were not grounded in any syntactic context, and the estimation was somewhat heuristic1. The tuple </context>
<context position="8803" citStr="Menezes &amp; Quirk, 2007" startWordPosition="1348" endWordPosition="1351">d, P(NULL|w), also directly from the aligned corpus, and the third model trains an SVM to predict the probability of deletion given source language context (neighboring and dependency tree-adjacent words and parts-of-speech). All three models give large gains of 1.5% BLEU or more on Chinese-English translation. It is interesting to note that the more sophisticated models provide a relatively small improvement over the simplest model in-domain, and no benefit out-of-domain. 4 Dependency treelet translation As a baseline, we use the treelet translation approach (which we previously described in Menezes &amp; Quirk, 2007), a linguistically syntaxbased system leveraging a source parser. It first unifies lexicalized treelets and unlexicalized templates to construct a sentence-specific set of synchronous rewrite rules. It then finds the highest scoring derivation according to a linear combination of models. We briefly review this system before describing our current extension. 4.1 The treelet translation model Sentence-specific rewrite rules are constructed by unifying information from three sources: a dependency parse of the input sentence, a set of treelet translation pairs, and a set of unlexicalized order tem</context>
<context position="23805" citStr="Menezes &amp; Quirk (2007)" startWordPosition="3653" endWordPosition="3656">ts listed in Table 7.2. For EnglishJapanese we use only the web test set. The first two tests are from the 2006 SMT workshop and the newswire test is from the 2008 workshop. The web test sets were selected from a random sampling of English web sites, with target language translations provided by professional translation vendors. All test sets have one reference translation. Domain Sentence pairs eu-test Europarl 2000 nc-test News commentary 1064 News News wire 2051 Web General web text 5000 Table 7.2 Test data 7.2 Models The baseline treelet translation system uses all the models described in Menezes &amp; Quirk (2007), namely: • Treelet log probabilities, maximum likelihood estimates with absolute discounting. • Forward and backward lexical weighting, using Model-1 translation log probabilities. • Trigram language model using modified Kneser-Ney smoothing. • Word and phrase count feature functions. • Order template log probabilities, maximum likelihood estimates, absolute discounting. • Count of artificial source order templates.2 • Discriminative tree-based order model. The present work does not use the discriminative tree-based order model3 but adds: 2 When no template is compatible with a treelet, the d</context>
</contexts>
<marker>Menezes, Quirk, 2007</marker>
<rawString>Menezes, Arul, and Chris Quirk. Using Dependency Order Templates to Improve Generality in Translation. Workshop on Statistical Machine Translation, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation. ACL</title>
<date>2003</date>
<contexts>
<context position="26523" citStr="Och, 2003" startWordPosition="4065" endWordPosition="4066">tree. From the aligned tree pairs we extracted treelet and order template tables. For the Europarl systems, we use a phrase/treelet size of 7 and train model weights using 2000 sentences of Europarl data. For the “general-domain” systems, we use a phrase/treelet size of 4, and train model weights using 2000 sentences of web data. For any given corpus, all systems used the same treelet or phrase size (see Table 7.1) and the same trigram language model. Model weights were trained separately for each system, data set and experimental condition, using minimum error rate training to maximize BLEU (Och, 2003). 3 In our experiments, we find that the impact of this model is small in the presence of order templates; also, it degrades the overall speed of the decoder. 741 % BLEU Phrasal 13.41 Baseline treelet 15.89 +Deletion only 16.00 +Insertion only 16.16 +Deletion and Insertion 17.01 Table 8.1: English-Japanese system comparisons 8 Results and Discussion Tables 8.1 and 8.4 compare baseline phrasal and treelet systems with systems that use various types of insertion and deletion templates. English-Japanese: As one might expect, the use of structural insertion and deletion has the greatest impact whe</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, Franz Josef. Minimum error rate training in statistical machine translation. ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<publisher>ACL</publisher>
<contexts>
<context position="22278" citStr="Papineni et al., 2002" startWordPosition="3402" endWordPosition="3405"> translation of the sentence is now: Septiembre es el Mes Nacional de Educación de colesterol Although the choice of prepositions is not the same as the reference, the fluency is much improved and the translation is quite understandable. Figure 6.1, lists the structural insertion templates that are used to produce this translation, and shows how they are unified with treelet translation pairs to produce sentence-specific rewrite rules, which are in turn composed during decoding to produce this translation. 7 Experiments We evaluated the translation quality of the system using the BLEU metric (Papineni et al., 2002). We compared three systems: (a) a standard phrasal system using a decoder based on Pharaoh, (Koehn et al., 2003), (b) A baseline treelet system using unlexicalized order templates and (c) The present work, which adds structural insertion and deletion templates. 7.1 Data We report results for two language pairs, EnglishSpanish and English- Japanese. For EnglishSpanish we use two training sets: (a) the Europarl corpus provided by the NAACL 2006 Statistical Machine Translation workshop (b) a “generaldomain” data set that includes a broad spectrum of data such as governmental data, general web da</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Salim Roukos, Todd Ward, and WeiJing Zhu. BLEU: a method for automatic evaluation of machine translation. ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Binarizing Syntax Trees to Improve Syntax-Based Machine Translation Accuracy. EMNLP-CoNLL,</title>
<date>2007</date>
<marker>Wang, Knight, Marcu, 2007</marker>
<rawString>Wang, Wei, Kevin Knight and Daniel Marcu. Binarizing Syntax Trees to Improve Syntax-Based Machine Translation Accuracy. EMNLP-CoNLL, 2007</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>