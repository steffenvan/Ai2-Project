<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000153">
<title confidence="0.998618">
Efficient retrieval of tree translation examples for
Syntax-Based Machine Translation
</title>
<author confidence="0.990684">
Fabien Cromieres
</author>
<affiliation confidence="0.899251666666667">
Graduate School of Informatics
Kyoto University
Kyoto, Japan
</affiliation>
<email confidence="0.996126">
fabien@nlp.kuee.kyoto-u.ac.jp
</email>
<author confidence="0.989281">
Sadao Kurohashi
</author>
<affiliation confidence="0.899361">
Graduate School of Informatics
Kyoto University
Kyoto, Japan
</affiliation>
<email confidence="0.997984">
kuro@i.kyoto-u.ac.jp
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998785">
We propose an algorithm allowing to effi-
ciently retrieve example treelets in a parsed
tree database in order to allow on-the-fly ex-
traction of syntactic translation rules. We also
propose improvements of this algorithm al-
lowing several kinds of flexible matchings.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923210526316">
The popular Example-Based (EBMT) and Statistical
Machine Translation (SMT) paradigms make use of
the translation examples provided by a parallel bilin-
gual corpus to produce new translations. Most of
these translation systems process the example data
in a similar way: The parallel sentences are first
word-aligned. Then, translation rules are extracted
from these aligned sentences. Finally, the transla-
tion rules are used in a decoding step to translate
sentences. We use the term translation rule in a very
broad sense here, as it may refer to substring pairs as
in (Koehn et al., 2003), synchronous grammar rules
as in (Chiang, 2007) or treelet pairs as in (Quirk et
al., 2005; Nakazawa and Kurohashi, 2008).
As the size of bilingual corpus grow larger, the
number of translation rules to be stored can easily
become unmanageable. As a solution to this prob-
lem in the context of phrase-based Machine Transla-
tion, (Callison-Burch et al., 2005) proposed to pre-
align the example corpora, but delay the rule extrac-
tion to the decoding stage. They showed that using
Suffix Arrays, it was possible to efficiently retrieve
all sentences containing substrings of the sentence
to be translated, and thus extract the needed trans-
lation rules on-the-fly. (Lopez, 2007) proposed an
extension of this method for retrieving discontinu-
ous substrings, making it suitable for systems such
as (Chiang, 2007).
In this paper, we propose a method to apply the
same idea to Syntax-Based SMT and EBMT (Quirk
et al., 2005; Mi et al., 2008; Nakazawa and Kuro-
hashi, 2008). Since Syntax-Based systems usually
work with the parse trees of the source-side sen-
tences, we will need to be able to retrieve effi-
ciently examples trees from fragments (treelets) of
the parse tree of the sentence we want to translate.
We will also propose extensions of this method al-
lowing more flexible matchings.
</bodyText>
<sectionHeader confidence="0.759017" genericHeader="introduction">
2 Overview of the method
</sectionHeader>
<subsectionHeader confidence="0.938485">
2.1 Treelet retrieval
</subsectionHeader>
<bodyText confidence="0.999702705882353">
We first formalize the setting of this chapter by pro-
viding some definitions.
Definition 2.1 (Treelets). A treelet is a connected
subgraph of a tree. A treelet T1 is a subtreelet of an-
other treelet T2 if T1 is itself a connected subgraph
of T2. We note |T |the number of nodes in a treelet.
If |T |= 1, T is called an elementary treelet. A lin-
ear treelet is a treelet whose nodes have at most 1
child. A subtree rooted at node n of a tree T is a
treelet containing all nodes descendants of n.
Definition 2.2 (Sub- and Supertreelets). If T1 is a
subtreelet of T2 and |T1 |= |T2 |− 1, we call T1
an immediate subtreelet of T2. Reciprocally, T2 is
an (immediate) supertreelet of T1. Furthermore, if
T2 and T1 are rooted at the same node in the original
tree, we say that T2 is a descending supertreelet of
T1. Otherwise it is an ascending supertreelet of T1.
</bodyText>
<page confidence="0.954414">
508
</page>
<note confidence="0.9579025">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 508–518,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999312580645161">
In treelet retrieval, we are given a certain treelet
type and want to find all of the tokens of this type in
the database DB. Each token of a given treelet type
will be identified by a mapping from the node of the
treelet type to the nodes of the treelet token in the
database.
Definition 2.3 (Matching). Given a treelet T and a
tree database DB, a matching of T in DB is a func-
tion M that associate the treelet T to a tree T in
DB and every node of T to nodes of T in such a
way that: bn E T, label(M(n)) = label(n) and
b(n1, n2) E T s.t n2 is a child of n1, M(n2) is a
child of M(n1).
In the common case where the siblings of a tree
are ordered, a matching must satisfy the additional
restriction: bn1, n2 E T, n1 &lt;3 n1 � M(n1) &lt;3
M(n1), where &lt;3 is the partial order relation be-
tween nodes meaning “is a sibling and to the left of”
We note occ(T) (for “occurrences of T ”) the set
of all possible matchings from T to DB. We will
call computing T the task of finding occ(T). If
|occ(T) |= 0, we call Tan empty treelet. Computing
a query tree TQ means computing all of its treelets.
Definition 2.4 (Notations). Although treelets are
themselves trees, we will use the word treelet to
emphasize they are a subpart of a bigger tree. We
will note T a treelet, and T a tree. TQ is the query
tree we want to compute. DB will refer to the set of
trees in our database. We will use a bracket notation
to describe trees or treelets. Thus “a(b c d(e))” is
the tree at the bottom of figure 2.
</bodyText>
<subsectionHeader confidence="0.996334">
2.2 General approach
</subsectionHeader>
<bodyText confidence="0.999990021739131">
There exists already a large body of research about
tree pattern matching (Dubiner et al., 1994; Bruno
et al., 2002). However, our problem is quite differ-
ent from finding the tokens of a given treelet in a
database. We actually want to find all the tokens of
all of the treelets of a given query tree. The query
tree itself is unlikely to appear in full even once in
the database. In this respect, our approach will have
many similarities with (Callison-Burch et al., 2005)
and (Lopez, 2007), and can be seen as an extension
of these works.
The basis of the method in (Lopez, 2007) is to
look for the occurrences of continuous substrings us-
ing a Suffix Array, and then intersect them to find the
occurrences of discontinuous substrings. We will
have a similar approach with two variants. The first
variant consists in using an adaptation of the con-
cept of suffix arrays to trees, which we will call Path-
To-Root Arrays (section 3.4), that allows us to find
efficiently the set of occurrences of a linear treelet.
Occurrences of non-linear treelets can then be com-
puted by intersection. The second variant is to use an
inverted index (section 3.5). Then the occurrences of
all treelets, even the linear treelets, are computed by
intersection.
The main additional difficulty in considering trees
instead of strings is that while a string has a
quadratic number of continuous substrings, a tree
has in general an exponential number of treelets (eg.
several trillion for the dependency tree of a 70 words
sentence). There is also an exponential number of
discontinuous substrings, but (Lopez, 2007) only
consider substrings of bounded size, limiting this
problem. We will not try to bound the size of treelets
retrieved. It is therefore crucial to avoid computing
the occurrences of treelets that have no occurrences
in the database, and also to eliminate as much redun-
dant calculation as is possible.
Lopez proposes to use Prefix Trees for avoiding
any redundant or useless computation. We will use
a similar idea but with an hypergraph that we will
call “computation hypergraph” (section 3.2). This
hypergraph will not only fit the same role as the Pre-
fix Tree of (Lopez, 2007), but also will allow us to
easily implement different search strategies for flex-
ible search (section 6).
</bodyText>
<subsectionHeader confidence="0.999753">
2.3 Representing positions
</subsectionHeader>
<bodyText confidence="0.999769642857143">
Whether we use a Path-to-Root Array or an inverted
index, we will need a compact way to represent the
position of a node in a tree. It is straightforward to
define such a position for strings, but slightly less for
trees. Especially, if we consider ordered trees, we
will want to be able to compare the relative location
of the nodes by comparing their positions.
The simplest possibility is to use an integer corre-
sponding to the rank of the node in a in-order depth-
first traversal of the tree. It is then easy, for two
nodes b and c, children of a parent node a, to check
if b is on the left of c, or on the left of a, for example.
A more advanced possibility is to use a represen-
tation inspired from (Zhang et al., 2001), in which
</bodyText>
<page confidence="0.996974">
509
</page>
<bodyText confidence="0.999945666666667">
the position of a node is a tuple consisting of its rank
in a preorder (ie. children last) and a postorder (chil-
dren first) depth-first traversal, and of its distance to
the root. This allows to test easily whether a node
is an ancestor of another, and their distance to each
other. This allows in turn to compute by intersec-
tion the occurrences of discontinuous treelets, much
like what is done in (Lopez, 2007) for discontinuous
strings. This is discussed in section 7.2.
</bodyText>
<sectionHeader confidence="0.951614" genericHeader="method">
3 Computing treelets incrementally
</sectionHeader>
<bodyText confidence="0.999763">
We describe here in more details how the treelets can
be efficiently computed incrementally.
</bodyText>
<subsectionHeader confidence="0.999748">
3.1 Dependence of treelet computation
</subsectionHeader>
<bodyText confidence="0.976127387096774">
Let us first define how it is possible to compute a
treelet from two of its subtreelets. Let us consider
a treelet T and two treelets T1 and T2 such that
T = T1 U T2, where, in the equality and the union,
the treelet are seen as the set of their nodes. There
are two possibilities. If T1 n T2 = 0, then the root of
T1 is a child of a node of T2 or vice-versa. We then
say that T1 and T2 form a disjoint coverage (abbrevi-
ated as D-coverage) of T. If T1nT2 =� 0, we will say
that T1 and T2 form an overlapping coverage (abbre-
viated as O-coverage) of T.
Given two treelets T1 and T2 forming a cover-
age of T, we can compute occ(T) from occ(T1) and
occ(T2) by combining their matchings.
Definition 3.1 (compatibility for O-coverage). Let
T be a treelet of TQ. Let T1 and T2 be 2 treelets
forming a O-coverage of T. Let M1 E occ(T1)
and M2 E occ(T2). M1 and M2 are compat-
ible if and only if M1|T1nT2 = M2|T1nT2 and
z(M1|T1\T2) n z(M2|T2\T1) = 0.
In the definition above, |S is the restriction of a func-
tion to a set 5 and z is the image set of a function.
If the children of a tree are ordered, we must add
the additional restriction: b(n1, n2) E (T1 \ T2) x
(T2 \ T1),n1 &lt;3 n2 � M1(n1) &lt;3 M2(n2).
Definition 3.2 (compatibility for D-coverage). Let
T1 and T2 be 2 treelets forming a D-coverage
of T. Let’s suppose that the root n2 of T2 is a
child of node n1 of T1. Let M1 E occ(T1) and
M2 E occ(T2). M1 and M2 are compatible if and
only if M2(n2) is a child of M1(n1).
</bodyText>
<figureCaption confidence="0.998322">
Figure 1: A computing hypergraph for “a(b c)”.
</figureCaption>
<construct confidence="0.4033535">
Definition 3.3 (intersection (®) operation). If two
matchings are compatible, we can form their union,
which is defined as (M1 U M2)(n) = M1(n)
if n E T1 and M2(n) else. We note
</construct>
<equation confidence="0.999894">
occ(T1) ® occ(T2) = {M1 U M2  |M1 E
occ(T1), M2 E occ(T2) and M1 is compati-
ble with M2 }. Then,we have the property:
occ(T) = occ(T1) ® occ(T2)
</equation>
<bodyText confidence="0.9997775">
In practice, the intersection operation will be im-
plemented using merge and binary merge algorithms
(Baeza-Yates and Salinger, 2005), following (Lopez,
2007).
</bodyText>
<subsectionHeader confidence="0.999399">
3.2 The computation hypergraph
</subsectionHeader>
<bodyText confidence="0.999975727272727">
We have seen that it is possible to compute occ(T)
from two subtreelets forming a coverage of T. This
can be represented by a hypergraph in which nodes
are all the treelets of a given query tree, and every
pair of overlapping or adjacent treelet is linked by
an hyperedge to their union treelet. Whenever we
have computed two starting points of an hyper-edge,
we can compute its destination treelet. An example
of a small computation hypergraph is described in
figure 1.
It is very convenient to represent the incremen-
tal computation of the treelets as a traversal of this
hypergraph. First because it contributes to avoid
redundant computations: each treelet is computed
only once, even if it is used to compute several other
treelets. Also, if a query tree contains two distinct
but identical treelets, only one computation will be
done, provided the two treelets are represented by
the same node in the hypergraph. The hypergraph
also allows us to avoid computing empty treelets, as
we describe in next section. This hypergraph there-
fore has the same role for us as the prefix tree used
</bodyText>
<page confidence="0.992475">
510
</page>
<figureCaption confidence="0.99903">
Figure 2: Inclusion DAG for the tree a(bcd(e))
</figureCaption>
<bodyText confidence="0.999829">
in (Lopez, 2007). Of course, the hypergraph is gen-
erated on-the-fly during the traversal.
Furthermore, different traversals will define dif-
ferent computation strategies, and we will be able to
use some more advanced graph exploration methods
in section 6.
</bodyText>
<subsectionHeader confidence="0.999474">
3.3 The Immediate Inclusion DAG
</subsectionHeader>
<bodyText confidence="0.9941642">
In many cases (but not always: see section 4.3),
the most optimal computation strategy should be
to always compute a treelet from two of its imme-
diate subtreelets. This is because the computation
time will be proportional to the size of the small-
est occurrence set of the two treelets, and thus the
“cheapest” subtreelet is always one of the immedi-
ate subtreelets. With this computation strategy, we
can replace the general computation hypergraph by
a DAG (Directed Acyclic Graph) in which every
treelet point to its immediate supertreelets. An ex-
ample is given on figure 2. We will call this DAG
the (Immediate) Inclusion DAG.
Traversals of the Inclusion DAG should be pruned
when an empty treelet is found, since all of its su-
pertreelets will also be empty. The algorithm 1 pro-
vide a general traversal of the DAG avoiding to com-
pute as many empty treelets as possible. It uses a
queue D of discovered treelets, and a data-structure
C that associate a treelet to those of its subtreelets
that have been already computed. Once a treelet T
has been computed and is found to be non empty, we
discover its immediate supertreelets TS1, TS2, ... (if
they have not been discovered already) and add T to
C (TS1), C (TS2), .... The operation min(C (T)) re-
</bodyText>
<figure confidence="0.974591722222222">
Algorithm 1: Generic DAG traversal
1 Add the set of precomputed treelets to D;
2 while ∃T ∈ D s.tT ∈ precomputed or |C(T) |&gt; 2
do
3 pop T from D;
4 if T in precomputed then
5 occ(T) ← precomputed[T];
6 else
7 T1,T2=min(C (T));
8 if |occ(T1) |= 0 then
9 occ(T) ← ∅;
10 else
11 occ(T) ← occ(T1) ⊗ occ(T2);
12 for TS ∈ supertree(T) do
13 if occ(TS) = undef then
14 Add T to C(TS);
15 if |occ(T) |&gt; 0 and TS ∈� D then
16 Add TS to D;
</figure>
<bodyText confidence="0.998247307692308">
trieve the 2 subtreelets from C (T) that have the least
occurrences. If one of them is empty, we can di-
rectly conclude that T is empty. No treelet whose all
immediate subtreelets are empty is ever put in the
discovered queue, which allows us to prune most of
the empty treelets of the Inclusion DAG.
A treelet in the inclusion DAG can be computed
as soon as two of its antecedents have been com-
puted. To start the computation (or rather, “seed”
it), it is necessary to know the occurrences of treelet
of smaller size. In the following sections 3.4 and
3.5, we describe two methods for efficiently obtain-
ing the set of occurrences of some initial treelets.
</bodyText>
<subsectionHeader confidence="0.97676">
3.4 Path-to-Root Array
</subsectionHeader>
<bodyText confidence="0.995079285714286">
We present here a method to compute very effi-
ciently occ(T) when T is linear. This method is sim-
ilar to the use of Suffix Arrays (Manber and My-
ers, 1990) to find the occurrences of continuous sub-
strings in a text.
Definition 3.4 (Paths-to-Root Array). Given a la-
beled tree T and a node n ∈ T, the path-to-root
of n is the sequence of labels from n to the root.
The Paths-to-Root Array of a set of trees DB is the
lexicographically sorted list of the Path-to-Roots of
every node in DB.
Just as with suffixes, a path-to-root can be rep-
resented compactly by a pointer to its starting node
in DB. We then need to keep the database DB in
</bodyText>
<page confidence="0.975501">
511
</page>
<figure confidence="0.856658875">
Pos PtR Pos PtR Pos PtR
1 3:4 a 8 2:2 bf 15 1:3 fba
2 1:7 a 9 1:6 ca 16 3:3 fga
3 2:6 af 10 1:8 da 17 3:2 ga
4 1:4 afba 11 2:7 daf 18 2:1 gbf
5 3:7 ba 12 3:1 ega 19 1:5 gca
6 1:2 ba 13 2:3 f 20 1:1 hba
7 2:5 baf 14 3:8 fba 21 3:5 heba
</figure>
<figureCaption confidence="0.6386448">
Figure 3: Path To Root Array for a set of three trees.
“Pos.” is the position of the starting point of a given path-
to-root (noted as indexOfTree:positionInTree), and PtR is
the sequence of labels on this path-to-root. The path-to-
root are sorted in lexicographic order. We can find the set
of occurrences of any linear treelet with a binary search.
For example, the treelet a(b) corresponds to the label se-
quence “ba”. With a binary search, we find that the path-
to-root starting with “ba” are between indexes 5 and 7.
The corresponding occurrences are then 3:7, 1:2 and 2:5.
</figureCaption>
<bodyText confidence="0.9708115">
memory to retrieve efficiently the pointed-to path-
to-root. Once the Path-to-Root Array is built, for a
linear treelet T, we can find its occurrences by a bi-
nary search of the first and last path-to-root starting
with the labels of T. See figure 3 for an example.
Memory cost is quite manageable, since we only
need 10 bytes per nodes in total. 5 bytes per pointer
in the array (tree id: 4 bytes, start position: 1 byte),
and 5 bytes per nodes to store the database in mem-
ory (label id:4 bytes, parent position: 1 byte).
All the optimization tricks proposed in (Lopez,
2007) for Suffix Arrays can be used here, espe-
cially the optimization proposed in (Zhang and Vo-
gel, 2005).
</bodyText>
<subsectionHeader confidence="0.869182">
3.5 Inverted Index and Precomputation
</subsectionHeader>
<bodyText confidence="0.999977">
Instead of a Path-to-Root array, one can simply use
an inverted index. The inverted index associates
with every label the set of its occurrences, each oc-
currences being represented by a tuple containing
the index of the tree, the position of the label in the
tree, and the position of the parent of the label in
the tree. Knowing the position of the parent will
allow to compute treelets of size 2 by intersection
(D-coverage). This is less effective than the Path-
To-Root Array approach, but open the possibilities
for the flexible search discussed in section 6.
Taking the idea further, we can actually con-
sider the possibility of precomputing treelets of size
greater than 1, especially if they appear frequently
in the corpus.
</bodyText>
<sectionHeader confidence="0.986845" genericHeader="method">
4 Practical implementation of the traversal
</sectionHeader>
<subsectionHeader confidence="0.989887">
4.1 Postorder traversal
</subsectionHeader>
<bodyText confidence="0.996654857142857">
The way we choose the treelet to be popped out on
line 3 of algorithm 1 will define different computa-
tion strategies. For concreteness, we describe now a
more specific traversal. We will process treelets in
an order depending on their root node. More pre-
cisely, we consider the nodes of the query tree in the
order given by a depth-first postorder traversal of the
query tree. This way, when a treelet rooted at n is
processed, all of the treelets rooted at a descendant
of n have already been processed.
We can suppose that every processed treelet is as-
signed an index that we note #T. This allows a con-
venient recursive representation of treelets.
Definition 4.1 (Recursive representation). Let T be
a treelet rooted at node n of TQ. We note ni the
ith child of n in TQ. For all i, ti is the subtree of
T rooted at ni. We note ti = 0 and #ti = 0 if T
does not contain ni. The recursive representation of
T is then: [n, (#t1, #t2, ... , #tm)]. We note Ti the
value #ti.
For example, if TQ =“a(b c d(e))” and the treelets
“b” and “d(e)” have been assigned the indexes 2
and 4, the recursive representation of the treelet “a(b
d(e))” would be [a,(2,0,4)].
Algorithm 2 describes this “postorder traversal”.
DNode is a priority queue containing the treelets
rooted at Node discovered so far. The priority queue
pop out the smallest treelets first. Line 14 maintain a
list L of processed treelets and assign the index of T
in L to #T. Line 22 keeps track of the non-empty
immediate supertreelets of every treelet through a
dictionary S. This is used in the procedure compute-
supertreelets (algorithm 3) to generate the immedi-
ate supertreelets of a treelet T given its recursive rep-
resentation. In this procedure, line 6 produces the
</bodyText>
<page confidence="0.97152">
512
</page>
<figure confidence="0.97786844">
Algorithm 2: DAG traversal by query-tree pos-
torder
1 for Node in postorder-traversal(query-tree) do
2 Telem = [Node, (0, 0,.., 0)];
3 DNode Telem;
4 while |DNode |&gt; 0 do
5 T=pop-first(DNode);
6 if T in precomputed then
7 occ(T) precomputed[Node.label];
8 else
9 T1, T2=min(C (t));
10 if |occ(T1) |= 0 then
11 occ(T) ;;
12 else
13 occ(T) occ(T1) ® occ(T2);
14 Append T to L;
15 #T |L|;
16 for TS in compute-supertree(T, #T) do
17 Add T to C(TS);
18 if |occ(T) |&gt; 0 then
19 if TS V DNode and
root(TS)=Node then
20 Add TS to D;
21 for #t in C (T) do
22 Add #T to S(#t);
</figure>
<bodyText confidence="0.985768588235294">
descending supertreelets, and line 8 produces the as-
cending supertreelet. Figure 4 describes the content
of all these data structures for a simple run of the
algorithm.
This postorder traversal has several advantages.
A treelet is only processed once all of its immedi-
ate supertreelets have been computed, which is op-
timal to reduce the cost of the ® operation. The
way the procedure compute-supertreelets discover
supertreelets from the info in S has also several
benefit. One is that, by not adding empty treelets
(line 18) to S, we naturally prevent the discovery
of larger empty treelets. Similarly, in the next sec-
tion, we will be able to prevent the discovery of non-
maximal treelets by modifying S. Modifications of
compute-supertreelets will also allow different kind
of retrieval in section 6.
</bodyText>
<subsectionHeader confidence="0.998826">
4.2 Pruning non-maximal treelets
</subsectionHeader>
<bodyText confidence="0.99954325">
We now try to address another aspect of the over-
whelming number of potential treelets in a query
tree. As we said, in most practical cases, most of the
larger treelets in a query tree will be empty. Still, it is
</bodyText>
<figure confidence="0.877499818181818">
Algorithm 3: compute-supertrees
Input: T,#T
Output: lst: list of immediate supertreelets of T
1 m |root(T)|;
2 for i in 1 ... m do
3 for #TS in S(#Ti) do
4 if root(#TS) =6 root(T) then
5 Tne,, [root(T), T°, ..#T&apos;, ... , Tm];
6 Append Tne,, to lst;
7 Tne,, [parent(root(T)), (0, ... , #T,... , 0)];
8 Append Tne,, to lst;
</figure>
<bodyText confidence="0.997989085714286">
possible that some tree exactly identical to the query
tree (or some tree having a very large treelet in com-
mon with the query tree) do exist in the database.
This case is obviously a best case for translation,
but unfortunately could be a worst-case for our al-
gorithm, as it means that all of the (possibly trillions
of) treelets of the query tree will be computed.
To solve this issue, we try to consider a concept
analogous to that of maximal substring, or substring
class, found in Suffix Trees and Suffix Arrays (Ya-
mamoto and Church, 2001). The idea is that in most
cases where a query tree is “full” (that is all of its
treelets are not empty), most of the larger treelets
will share the same occurrences (in the database
trees that are very similar to the query tree). We for-
malize this as follow:
Definition 4.2 (domination and maximal treelets).
Let T1 be a subtreelet of T2. If for every matching
M1 of occ(T1), there exist a matching M2 of
occ(T2) such that M2|T1 = M1, we say that T1 is
dominated by T2. A treelet is maximal if it is not
dominated by any other treelet.
If T1 is dominated by T2, it means that all occur-
rences of T1 are actually part of an occurrence of
T2. We will therefore be, in general, more interested
by the larger treelet T2 and can prune as many non-
maximal treelets as we want in the traversal. The key
point is that the algorithm has to avoid discovering
most non maximal treelets.The algorithm 2 can eas-
ily be modified to do this. We will use the following
property.
Property 4.1. Given k treelets T1 ... Tk with k dis-
tinct roots, all the roots being children of a same
node n. We note n(T1 ... Tk) the treelet whose root
is n, and for which the k subtrees rooted at the k
</bodyText>
<page confidence="0.995276">
513
</page>
<figure confidence="0.7631762">
T d e b b(d) [Empty] b(e) b(d e) [Empty] c a a(b) a(b(e)) a(c) a(b c) a(b(e) c)
# 1 2 3 4 5 6 7 8 9 10 11 12 13
R d e b(..) b(1.) b(.2) b(1 2) c a(..) a(3.) a(5.) a(.7) a(3 7) a(5 7)
C - - - 1,3 2,3 4,5 - - 8,3 5,9 7,8 9,11 10,12
S - - 5 - - - - 9,11 10,12 13 12 13 -
</figure>
<figureCaption confidence="0.992717857142857">
Figure 4: A run of the algorithm 2, for the query tree a(b(d e) c). The row “T” represents the treelets in the order
they are discovered. The row “#” is the index #T, and the row “R” is the recursive representation of the treelet. Also
represented are the content of C and S at the end of the computation. When a treelet is poped out of DN,,d,, occ(T) is
computed from the treelets listed in C (T). If occ(T) is not empty, the entries of the immediate subtreelets of T in S
are updated with #T. We suppose here that |occ( b(d))|=0. Then, b(d e) is marked as empty and neither b(d) nor b(d e)
are added to the entries of their subtreelets in S. This way, when considering treelets rooted at the upper node “a”, the
algorithm will not discover any of the treelets containing b(d).
</figureCaption>
<bodyText confidence="0.99980716">
children of n are T1 ... Tk. Let us further suppose
that for all i, Ti is dominated by a descending su-
pertreelet Tid (with the possibility that Ti = Tid).
Then n(T1 ... Tk) is dominated by n(T 1d . . .Tkd ).
For example, if b(c) is dominated by b(c d), then
a(b(c) e) will be dominated by a(b(c d) e).
In algorithm 2, after processing each node, we
proceed to a cleaning of the S dictionary in the fol-
lowing way: for every treelet T (considering the
treelets by increasing size) that is dominated by
one of its supertreelets TS E S(T) and for every
subtreelet T&apos; of T such that T E S(T&apos;), we re-
place T by TS in S(T&apos;). The procedure compute-
supertreelets, when called during the processing of
the parent node, will thus skip all of the treelets that
are ”trivially” dominated according to property 4.1.
Let’s note that testing for the domination of a
treelet T by one of its supertrelets TS is not a matter
of just testing if |occ(T) |= |occ(TS)|, as would be
the case with substring: a treelet can have less oc-
currences than one of its supertreelets (eg. b(a) has
more occurrences than b in b(a a) ). An efficient way
is to first check that the two treelets occurs in the
same number of sentences, then confirm this with a
systematic check of the definition.
</bodyText>
<subsectionHeader confidence="0.998575">
4.3 The case of constituent trees
</subsectionHeader>
<bodyText confidence="0.999969541666667">
We have focused our experiments on dependency
trees, but the method can be applied to any tree.
However, the computations strategies we have used
might not be optimal for all kind of trees. In a de-
pendency tree, nodes are labeled by words and most
non-elementary treelets have a small number of oc-
currences. In a constituent tree, many treelets con-
taining only internal nodes have a high frequency
and will be expensive to compute.
If we have enough memory, we can solve this by
precomputing the most common (and therefore ex-
pensive) treelets.
However, it is usually not very interesting to re-
trieve all the occurrences of treelets such as “NP(Det
NN)” in the context of a MT system. Such very com-
mon pattern are best treated by some pre-computed
rules. What is interesting is the retrieval of lexical-
ized rules. More precisely, we want to retrieve ef-
ficiently treelets containing at least one leaf of the
query tree. Therefore, an alternative computation
strategy would only explore treelets containing at
least one terminal node. We would thus compute
successively “dog”, “NN(dog)” “NP(NN(dog))”,
“NP(Det NN(dog))”, etc.
</bodyText>
<subsectionHeader confidence="0.990045">
4.4 Complexity
</subsectionHeader>
<bodyText confidence="0.99996">
Processing time will be mainly dependent on two
factors: the number of treelets in a query tree that
need to be computed, and the average time to com-
pute a treelet.
Let NC be the size of the corpus. It can be shown
quite easily that the time needed to compute a treelet
with our method is proportional to its number of oc-
currences, which is itself growing as O(NC).
Let m be the size of the query tree. The number
of treelets needing to be computed is, in the worst
case, exponential in m. In practice, the only case
where most of the treelets are non-empty is when the
database contains trees similar to the query tree in
the database, and this is handled by the modification
of the algorithm is section 4.2. In other cases, most
of the treelets are empty, and empirically, we find
that the number of non-empty treelets in a query tree
</bodyText>
<page confidence="0.993919">
514
</page>
<table confidence="0.9851555">
Database size (#nodes) 6M 60M
Largest non-empty treelet size 4.6 8.7
Processing time (PtR Array) 0.02 s 0.7 s
Processing time (Inv. Index) 0.02 s 0.9 s
Size on disk 40 MB 500 MB
Figure 5: Performances averaged on 100 sentences.
Method Treelet Our
dictionary method
Disk space used 23 GB 500 MB
BLEU 11.6% 12.0%
</table>
<figureCaption confidence="0.981372">
Figure 6: Comparison with a dictionary-based baseline
(performances averaged over 100 sentences).
</figureCaption>
<bodyText confidence="0.996313260869565">
grows approximately as O(m · N�.5
C ). It is also pos-
sible to bound the size of the retrieved treelets (only
retrieving treelets with less than 10 nodes, for exam-
ple), similarly to what is done in (Lopez, 2007). The
number of treelets will then only grows as O(m).
The total processing time of a given query tree
will therefore be on the order of O(m · N�.5
C ) (or
O(m · NC) if we bound the treelet size). The fact
that this give a complexity worse than linear with
respect to the database size might seem a concern,
but this is actually only because we are retrieving
more and more different types of treelets. The cost
of retrieving one treelet remain linear with respect to
the size of the corpus. We empirically find that even
for very large values of NC, processing time remain
very reasonable (see next section).
It should be also noted that the constant hid-
den in the big-O notation can be (almost) arbitrar-
ily reduced by precomputing more and more of the
most common (and more expensive) treelets (a time-
memory trade-off).
</bodyText>
<sectionHeader confidence="0.998691" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999983666666667">
We conducted experiments on a large database of
2.9 million automatically parsed dependency trees,
with a total of nearly 60 million nodes1. The largest
trees in the database have around 100 nodes. In or-
der to see how performance scale with the size of the
database, we also used a smaller subset of 230,000
trees containing near 6 million nodes.
We computed, using our algorithm, 100 randomly
selected query trees having from 10 to 70 nodes,
with an average of 27 nodes per tree. Table 5
shows the average performances per sentence. Con-
sidering the huge size of the database, a process-
</bodyText>
<footnote confidence="0.914005">
1This database was an aggregate of several Japanese-English
corpora, notably the Yomiuri newspaper corpus (Utiyama and
Isahara, 2003) and the JST paper abstract corpus created at
NICT(www.nict.go.jp) through (Utiyama and Isahara, 2007).
</footnote>
<bodyText confidence="0.9999876">
ing time below 1 second seems reasonable. The
increase in processing time between the small and
the large database is in line with the explanations
of section 4.4. Path-to-Root Arrays are slightly bet-
ter than Inverted indexes (we suspect a better im-
plementation could increase the difference further).
Both methods use up about the same disk space:
around 500MB. We also find that the approach of
section 4.2 brings virtually no overhead and gives
similar performances whether the query tree is in the
database or not (effectively reducing the worst-case
computation time from days to seconds).
We also conducted a small English-to-Japanese
translation experiment with a simple translation sys-
tem using Synchronous Tree Substitution Grammars
(STSG) for translating dependency trees. The sys-
tem we used is still in an experimental state and
probably not quite at the state-of-the-art level yet.
However, we considered it was good enough for our
purpose, since we mainly want to test our algorithm
is a practical way. As a baseline, from our cor-
pus of 2.9 millions dependency trees, we automat-
ically extracted STSG rules of size smaller than 6
and stored them in a database, considering that ex-
tracting rules of larger sizes would lead to an un-
manageable database size. We compared MT results
using only the rules of size smaller than 6 to using
all the rules computed on-the-fly after treelet retriev-
ing by our method. These results are summarized on
figure 6.
</bodyText>
<sectionHeader confidence="0.966397" genericHeader="method">
6 Flexible matching
</sectionHeader>
<bodyText confidence="0.999744571428572">
We now describe an extension of the algorithm for
approximate matching of treelets. We consider that
each node of the query tree and database is labeled
by 2 labels (or more) of different generality. For
concreteness, let’s consider dependency trees whose
nodes are labeled by words and the Part-Of-Speech
(POS) of these words. We want to retrieve treelets
</bodyText>
<page confidence="0.995668">
515
</page>
<bodyText confidence="0.998464533333333">
that match by word or POS with the query tree.
”.
We actually want to compute all of the treelets of
a query tree TQ labeled by words and POS (meaning
each node can be matched by either word or POS).
We can compute TQ without redundant computa-
tions by slightly modifying the algorithm 2. First,
we modify the recursive representation of a treelet
so that it also includes the chosen label of its root
node. Then, the only modifications needed in algo-
rithm 2 are the following: 1- at initialization (line 3),
the elementary treelets corresponding to every pos-
sible labels are added to the discovered treelets set
D; 2- in procedure compute-supertrees, at line 8, we
generate one ascending supertreelet per label.
</bodyText>
<subsectionHeader confidence="0.99368">
6.2 Weighted search
</subsectionHeader>
<bodyText confidence="0.999672238095238">
While the previous method would allow us to com-
pute as efficiently as possible all the treelets in-
cluded in a multi-labeled query tree, there is still
a problem: even avoiding redundant computations,
the number of treelets to compute can be huge, since
we are computing all combinations of labels. For
each treelet of size m we would have had in a single
label query tree, we now virtually have 2&apos; treelets.
Therefore, it is not reasonable in general to try to
compute all these treelets.
However, we are not really interested in comput-
ing all possible treelets. In our case, the POS la-
bels allow us to retrieve larger examples when none
containing only words would be available. But we
still prefer to find examples matched by words rather
than by POS. We therefore need to tell the algorithm
that some treelets are more important that some oth-
ers. While we have used the Computation Hypertree
representation to compute treelets efficiently, we can
also use it to prioritize the treelets we want to com-
pute. This is easily implemented by giving a weight
</bodyText>
<table confidence="0.9979882">
POS matchings Without With
Processing time 0.9 s 22 s
Largest non-empty treelet size 8.7 11.4
Treelets of size&gt;8 0.4 102
BLEU 12.0% 12.1%
</table>
<figureCaption confidence="0.998672">
Figure 7: Effect of POS-matching
</figureCaption>
<bodyText confidence="0.9997655">
to every treelet. We can then modify our traversal
strategy of the Inclusion DAG to compute treelets
having the biggest weights first: we just need to
specify that the treelet popped out on line 3 is the
treelet with the highest score (more generally, we
could consider a A* search).
</bodyText>
<subsectionHeader confidence="0.871817">
6.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999985">
Using the above ideas, we have made some experi-
ments for computing query dependency trees labeled
with both words and POS. We score the treelets by
giving them a penalty of -1 for each POS they con-
tain, and stop the search when all remaining treelets
have a score lower than -2 (in other words, treelets
are allowed at most 2 POS-matchings). We also re-
quire POS-matched nodes to be non-adjacent.
We only have some small modifications to do to
algorithm 2. In line 3 of algorithm 2, elementary
treelets are assigned a weight of 0 or -1 depend-
ing on whether their label is a word or POS. Line 5
is replaced by ”pop the first treelet with minimal
weight and break the loop if the minimal weight is
inferior to -2”. In compute-supertreelets, we give a
weight to the generated supertreelets by combining
the weights of the child treelets.
Table 7 shows the increase in the size of the
biggest non-empty treelets when allowing 2 nodes
to be matched by POS. It also shows the impact on
BLEU score of using these additional treelets for on-
the-fly rule generation in our simple MT system. Im-
provement on BLEU is limited, but it might be due
to a very experimental handling of approximately
matched treelet examples in our MT system.
The computation time, while manageable, was
much slower than in the one-label case. This is due
to the increased number of treelets to be computed,
and to the fact that POS-labeled elementary treelets
have a high number of occurrences. It would be
more efficient to use more specific labeling (e.g V-
</bodyText>
<subsectionHeader confidence="0.991286">
6.1 Processing multi-Label trees
</subsectionHeader>
<bodyText confidence="0.966130444444444">
To do this, the inverted index will just need to
include entries for both words and POS. For ex-
ample, the dependency tree “likes,V:1 (Paul,N:0
Salmon,N:2 (and,CC:3 (Tuna,N:4)))” would pro-
duce the following (node,parents) entries in the in-
verted index: {N:[(0,1) (2,1) (4,3)], Paul:[(0,1)],
Salmon:[(2,1)],... }. This allows to search for a
treelet containing any combination of labels, like
“likes(N Salmon(CC(N)))
</bodyText>
<page confidence="0.989243">
516
</page>
<figureCaption confidence="0.999891">
Figure 8: A packed forest.
</figureCaption>
<bodyText confidence="0.984424">
mvt for verbs of movement instead of V).
</bodyText>
<sectionHeader confidence="0.99336" genericHeader="method">
7 Additional extensions
</sectionHeader>
<bodyText confidence="0.999966">
We briefly discuss here some additional extensions
to our algorithm that we will not detail for lack of
room and practical experiments.
</bodyText>
<subsectionHeader confidence="0.816153">
7.1 Packed forest
</subsectionHeader>
<bodyText confidence="0.99999075">
Due to parsing ambiguities and automatic parsers
errors, it is often useful to use multiple parses of
a given sentence. These parses can be represented
by a packed forest such as the one in figure 8. Our
method allows the use of packed representation of
both the query tree and the database.
For the inverted index, the only difference is
that now, an occurrence of a label can have more
than one parent. For example, the inverted in-
dex of a database containing the packed forest
of figure 8 would contain the following entries:
{held: [(1,10a),(1,10b)], NP: [(6,9),(7,9),(9,10a)],
VP:[(10,N)], PP:[(8,10b)], a:[(2,6)], talk:[(3,6)],
with:[(4,7) (4,8)], Sharon:[(5,7) (5,8)]}. Where 10a
and 10b are some kind of virtual position that help to
specify that held and NP8 belong to the same chil-
dren list. We could also include a cost on edges
in the inverted index, which would allow to prune
matchings to unlikely parses.
The inverted index can now be used to search in
the trees contained in a packed forest database with-
out any modification. Modifications to the algorithm
in order to handle a packed forest query are similar
to the ones developed in section 6.
</bodyText>
<subsectionHeader confidence="0.988749">
7.2 Discontinuous treelets
</subsectionHeader>
<bodyText confidence="0.9999925">
As we discussed in section 2.3, using a representa-
tion for the position of every node similar to (Zhang
et al., 2001), it is possible to determine the distance
and ancestor relationship of two nodes by just com-
paring their positions. This opens the possibility of
computing the occurrences of discontinuous treelets
in much the same way as is done in (Lopez, 2007)
for discontinuous substrings. We have not studied
this aspect in depth yet, especially since we are not
aware of any MT system making use of discontin-
uous syntax tree examples. This is nevertheless an
interesting future possibility.
</bodyText>
<sectionHeader confidence="0.999896" genericHeader="method">
8 Related work
</sectionHeader>
<bodyText confidence="0.999988307692308">
As we previously mentioned, (Lopez, 2007) and
(Callison-Burch et al., 2005) propose a method sim-
ilar to ours for the string case.
We are not aware of previous proposals for ef-
ficient on-the-fly retrieving of translation examples
in the case of Syntax-Based Machine Translation.
Among the works involving rule precomputation,
(Zhang et al., 2009) describes a method for effi-
ciently matching precomputed treelets rules. These
rules are organized in a kind of prefix tree that al-
lows efficient matching of packed forests. (Liu et al.,
2006) also propose a greedy algorithm for matching
TSC rules to a query tree.
</bodyText>
<sectionHeader confidence="0.950181" genericHeader="conclusions">
9 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999996857142857">
We have presented a method for efficiently retriev-
ing examples of treelets contained in a query tree,
thus allowing on-the-fly computation of translation
rules for Syntax-Based systems. We did this by
building on approaches previously proposed for the
case of string examples, proposing an adaptation of
the concept of Suffix Arrays to trees, and formaliz-
ing computation as the traversal of an hypergraph.
This hypergraph allows us to easily formalize dif-
ferent computation strategy, and adapt the methods
to flexible matchings. We still have a lot to do with
respect to improving our implementation, exploring
the different possibilities offered by this framework
and proceeding to more experiments.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9990155">
We thank the anonymous reviewers for their useful
comments.
</bodyText>
<page confidence="0.993848">
517
</page>
<sectionHeader confidence="0.995878" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999950464788732">
R. Baeza-Yates and A. Salinger. 2005. Experimental
analysis of a fast intersection algorithm for sorted se-
quences. In String Processing and Information Re-
trieval, page 1324.
N. Bruno, N. Koudas, and D. Srivastava. 2002. Holis-
tic twig joins: optimal XML pattern matching. In
Proceedings of the 2002 ACM SIGMOD international
conference on Management of data, page 310321.
C. Callison-Burch, C. Bannard, and J. Schroeder. 2005.
Scaling phrase-based statistical machine translation to
larger corpora and longer phrases. In Proceedings of
the 43rd Annual Meeting on Association for Compu-
tational Linguistics, pages 255–262. Association for
Computational Linguistics Morristown, NJ, USA.
David Chiang. 2007. Hierarchical Phrase-Based trans-
lation. Computational Linguistics, 33(2):201–228,
June.
M. Dubiner, Z. Galil, and E. Magen. 1994. Faster
tree pattern matching. Journal of the ACM (JACM),
41(2):205213.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statisti-
cal phrase-based translation. In Proceedings of HLT-
NAACL, pages 48–54. Association for Computational
Linguistics.
Z. Liu, H. Wang, and H. Wu. 2006. Example-based
machine translation based on tree–string correspon-
dence and statistical generation. Machine translation,
20(1):25–41.
A. Lopez. 2007. Hierarchical phrase-based translation
with suffix arrays. In Proc. of EMNLP-CoNLL, page
976985.
U. Manber and G. Myers. 1990. Suffix arrays: a
new method for on-line string searches. In Proceed-
ings of the first annual ACM-SIAM symposium on Dis-
crete algorithms, pages 319–327, San Francisco, CA,
USA. Society for Industrial and Applied Mathematics
Philadelphia, PA, USA.
H. Mi, L. Huang, and Q. Liu. 2008. Forest based trans-
lation. Proceedings of ACL-08: HLT, page 192199.
Toshiaki Nakazawa and Sadao Kurohashi. 2008. Syn-
tactical EBMT system for NTCIR-7 patent translation
task. In Proceedings of NTCIR-7 Workshop Meeting,
Tokyo, Japon.
C. Quirk, A. Menezes, and C. Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, page 279.
M. Utiyama and H. Isahara. 2003. Reliable measures for
aligning japanese-english news articles and sentences.
In Proceedings of ACL, pages 72–79, Sapporo,Japon.
M. Utiyama and H. Isahara. 2007. A japanese-english
patent parallel corpus. In MT summit XI, pages 475–
482.
M. Yamamoto and K. W. Church. 2001. Using suffix
arrays to compute term frequency and document fre-
quency for all substrings in a corpus. Computational
Linguistics, 27(1):1–30.
Y. Zhang and S. Vogel. 2005. An efficient phrase-to-
phrase alignment model for arbitrarily long phrase and
large corpora. In Proceedings of EAMT, pages 294–
301, Budapest, Hungary.
C. Zhang, J. Naughton, D. DeWitt, Q. Luo, and
G. Lohman. 2001. On supporting containment queries
in relational database management systems. In Pro-
ceedings of the 2001 ACM SIGMOD international
conference on Management of data, page 425436.
H. Zhang, M. Zhang, H. Li, and Chew Lim Tan. 2009.
Fast translation rule matching for syntax-based statis-
tical machine translation. In Proc. of EMNLP, pages
1037–1045.
</reference>
<page confidence="0.993915">
518
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.023688">
<title confidence="0.999325">Efficient retrieval of tree translation examples Syntax-Based Machine Translation</title>
<author confidence="0.516654">Fabien</author>
<affiliation confidence="0.283997">Graduate School of Kyoto Kyoto,</affiliation>
<email confidence="0.914173">fabien@nlp.kuee.kyoto-u.ac.jp</email>
<note confidence="0.37907325">Sadao Graduate School of Kyoto Kyoto,</note>
<email confidence="0.930053">kuro@i.kyoto-u.ac.jp</email>
<abstract confidence="0.996417857142857">We propose an algorithm allowing to efficiently retrieve example treelets in a parsed tree database in order to allow on-the-fly extraction of syntactic translation rules. We also propose improvements of this algorithm allowing several kinds of flexible matchings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Baeza-Yates</author>
<author>A Salinger</author>
</authors>
<title>Experimental analysis of a fast intersection algorithm for sorted sequences.</title>
<date>2005</date>
<booktitle>In String Processing and Information Retrieval,</booktitle>
<pages>1324</pages>
<contexts>
<context position="10703" citStr="Baeza-Yates and Salinger, 2005" startWordPosition="1913" endWordPosition="1916"> a child of node n1 of T1. Let M1 E occ(T1) and M2 E occ(T2). M1 and M2 are compatible if and only if M2(n2) is a child of M1(n1). Figure 1: A computing hypergraph for “a(b c)”. Definition 3.3 (intersection (®) operation). If two matchings are compatible, we can form their union, which is defined as (M1 U M2)(n) = M1(n) if n E T1 and M2(n) else. We note occ(T1) ® occ(T2) = {M1 U M2 |M1 E occ(T1), M2 E occ(T2) and M1 is compatible with M2 }. Then,we have the property: occ(T) = occ(T1) ® occ(T2) In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). 3.2 The computation hypergraph We have seen that it is possible to compute occ(T) from two subtreelets forming a coverage of T. This can be represented by a hypergraph in which nodes are all the treelets of a given query tree, and every pair of overlapping or adjacent treelet is linked by an hyperedge to their union treelet. Whenever we have computed two starting points of an hyper-edge, we can compute its destination treelet. An example of a small computation hypergraph is described in figure 1. It is very convenient to represent the incremental computation of the t</context>
</contexts>
<marker>Baeza-Yates, Salinger, 2005</marker>
<rawString>R. Baeza-Yates and A. Salinger. 2005. Experimental analysis of a fast intersection algorithm for sorted sequences. In String Processing and Information Retrieval, page 1324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bruno</author>
<author>N Koudas</author>
<author>D Srivastava</author>
</authors>
<title>Holistic twig joins: optimal XML pattern matching.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 ACM SIGMOD international conference on Management of data,</booktitle>
<pages>310321</pages>
<contexts>
<context position="5170" citStr="Bruno et al., 2002" startWordPosition="902" endWordPosition="905"> Tan empty treelet. Computing a query tree TQ means computing all of its treelets. Definition 2.4 (Notations). Although treelets are themselves trees, we will use the word treelet to emphasize they are a subpart of a bigger tree. We will note T a treelet, and T a tree. TQ is the query tree we want to compute. DB will refer to the set of trees in our database. We will use a bracket notation to describe trees or treelets. Thus “a(b c d(e))” is the tree at the bottom of figure 2. 2.2 General approach There exists already a large body of research about tree pattern matching (Dubiner et al., 1994; Bruno et al., 2002). However, our problem is quite different from finding the tokens of a given treelet in a database. We actually want to find all the tokens of all of the treelets of a given query tree. The query tree itself is unlikely to appear in full even once in the database. In this respect, our approach will have many similarities with (Callison-Burch et al., 2005) and (Lopez, 2007), and can be seen as an extension of these works. The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of disco</context>
</contexts>
<marker>Bruno, Koudas, Srivastava, 2002</marker>
<rawString>N. Bruno, N. Koudas, and D. Srivastava. 2002. Holistic twig joins: optimal XML pattern matching. In Proceedings of the 2002 ACM SIGMOD international conference on Management of data, page 310321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>C Bannard</author>
<author>J Schroeder</author>
</authors>
<title>Scaling phrase-based statistical machine translation to larger corpora and longer phrases.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>255--262</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1526" citStr="Callison-Burch et al., 2005" startWordPosition="225" endWordPosition="228">en, translation rules are extracted from these aligned sentences. Finally, the translation rules are used in a decoding step to translate sentences. We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly. (Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). In this paper, we propose a method to apply the same idea to Syntax-Based SMT and EBMT (Quirk et al., 2005; Mi et al., 2008; Nakazawa and Kurohashi, 20</context>
<context position="5527" citStr="Callison-Burch et al., 2005" startWordPosition="967" endWordPosition="970">our database. We will use a bracket notation to describe trees or treelets. Thus “a(b c d(e))” is the tree at the bottom of figure 2. 2.2 General approach There exists already a large body of research about tree pattern matching (Dubiner et al., 1994; Bruno et al., 2002). However, our problem is quite different from finding the tokens of a given treelet in a database. We actually want to find all the tokens of all of the treelets of a given query tree. The query tree itself is unlikely to appear in full even once in the database. In this respect, our approach will have many similarities with (Callison-Burch et al., 2005) and (Lopez, 2007), and can be seen as an extension of these works. The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. We will have a similar approach with two variants. The first variant consists in using an adaptation of the concept of suffix arrays to trees, which we will call PathTo-Root Arrays (section 3.4), that allows us to find efficiently the set of occurrences of a linear treelet. Occurrences of non-linear treelets can then be computed by in</context>
<context position="37679" citStr="Callison-Burch et al., 2005" startWordPosition="6743" endWordPosition="6746">he position of every node similar to (Zhang et al., 2001), it is possible to determine the distance and ancestor relationship of two nodes by just comparing their positions. This opens the possibility of computing the occurrences of discontinuous treelets in much the same way as is done in (Lopez, 2007) for discontinuous substrings. We have not studied this aspect in depth yet, especially since we are not aware of any MT system making use of discontinuous syntax tree examples. This is nevertheless an interesting future possibility. 8 Related work As we previously mentioned, (Lopez, 2007) and (Callison-Burch et al., 2005) propose a method similar to ours for the string case. We are not aware of previous proposals for efficient on-the-fly retrieving of translation examples in the case of Syntax-Based Machine Translation. Among the works involving rule precomputation, (Zhang et al., 2009) describes a method for efficiently matching precomputed treelets rules. These rules are organized in a kind of prefix tree that allows efficient matching of packed forests. (Liu et al., 2006) also propose a greedy algorithm for matching TSC rules to a query tree. 9 Conclusion and future work We have presented a method for effic</context>
</contexts>
<marker>Callison-Burch, Bannard, Schroeder, 2005</marker>
<rawString>C. Callison-Burch, C. Bannard, and J. Schroeder. 2005. Scaling phrase-based statistical machine translation to larger corpora and longer phrases. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 255–262. Association for Computational Linguistics Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical Phrase-Based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1217" citStr="Chiang, 2007" startWordPosition="175" endWordPosition="176">ed (EBMT) and Statistical Machine Translation (SMT) paradigms make use of the translation examples provided by a parallel bilingual corpus to produce new translations. Most of these translation systems process the example data in a similar way: The parallel sentences are first word-aligned. Then, translation rules are extracted from these aligned sentences. Finally, the translation rules are used in a decoding step to translate sentences. We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules o</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical Phrase-Based translation. Computational Linguistics, 33(2):201–228, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dubiner</author>
<author>Z Galil</author>
<author>E Magen</author>
</authors>
<title>Faster tree pattern matching.</title>
<date>1994</date>
<journal>Journal of the ACM (JACM),</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="5149" citStr="Dubiner et al., 1994" startWordPosition="898" endWordPosition="901"> |occ(T) |= 0, we call Tan empty treelet. Computing a query tree TQ means computing all of its treelets. Definition 2.4 (Notations). Although treelets are themselves trees, we will use the word treelet to emphasize they are a subpart of a bigger tree. We will note T a treelet, and T a tree. TQ is the query tree we want to compute. DB will refer to the set of trees in our database. We will use a bracket notation to describe trees or treelets. Thus “a(b c d(e))” is the tree at the bottom of figure 2. 2.2 General approach There exists already a large body of research about tree pattern matching (Dubiner et al., 1994; Bruno et al., 2002). However, our problem is quite different from finding the tokens of a given treelet in a database. We actually want to find all the tokens of all of the treelets of a given query tree. The query tree itself is unlikely to appear in full even once in the database. In this respect, our approach will have many similarities with (Callison-Burch et al., 2005) and (Lopez, 2007), and can be seen as an extension of these works. The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the</context>
</contexts>
<marker>Dubiner, Galil, Magen, 1994</marker>
<rawString>M. Dubiner, Z. Galil, and E. Magen. 1994. Faster tree pattern matching. Journal of the ACM (JACM), 41(2):205213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLTNAACL,</booktitle>
<pages>48--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1169" citStr="Koehn et al., 2003" startWordPosition="166" endWordPosition="169">ible matchings. 1 Introduction The popular Example-Based (EBMT) and Statistical Machine Translation (SMT) paradigms make use of the translation examples provided by a parallel bilingual corpus to produce new translations. Most of these translation systems process the example data in a similar way: The parallel sentences are first word-aligned. Then, translation rules are extracted from these aligned sentences. Finally, the translation rules are used in a decoding step to translate sentences. We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated,</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLTNAACL, pages 48–54. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Liu</author>
<author>H Wang</author>
<author>H Wu</author>
</authors>
<title>Example-based machine translation based on tree–string correspondence and statistical generation.</title>
<date>2006</date>
<booktitle>Machine translation,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="38141" citStr="Liu et al., 2006" startWordPosition="6818" endWordPosition="6821">xamples. This is nevertheless an interesting future possibility. 8 Related work As we previously mentioned, (Lopez, 2007) and (Callison-Burch et al., 2005) propose a method similar to ours for the string case. We are not aware of previous proposals for efficient on-the-fly retrieving of translation examples in the case of Syntax-Based Machine Translation. Among the works involving rule precomputation, (Zhang et al., 2009) describes a method for efficiently matching precomputed treelets rules. These rules are organized in a kind of prefix tree that allows efficient matching of packed forests. (Liu et al., 2006) also propose a greedy algorithm for matching TSC rules to a query tree. 9 Conclusion and future work We have presented a method for efficiently retrieving examples of treelets contained in a query tree, thus allowing on-the-fly computation of translation rules for Syntax-Based systems. We did this by building on approaches previously proposed for the case of string examples, proposing an adaptation of the concept of Suffix Arrays to trees, and formalizing computation as the traversal of an hypergraph. This hypergraph allows us to easily formalize different computation strategy, and adapt the </context>
</contexts>
<marker>Liu, Wang, Wu, 2006</marker>
<rawString>Z. Liu, H. Wang, and H. Wu. 2006. Example-based machine translation based on tree–string correspondence and statistical generation. Machine translation, 20(1):25–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Hierarchical phrase-based translation with suffix arrays.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL,</booktitle>
<pages>976985</pages>
<contexts>
<context position="1841" citStr="Lopez, 2007" startWordPosition="277" endWordPosition="278">pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly. (Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). In this paper, we propose a method to apply the same idea to Syntax-Based SMT and EBMT (Quirk et al., 2005; Mi et al., 2008; Nakazawa and Kurohashi, 2008). Since Syntax-Based systems usually work with the parse trees of the source-side sentences, we will need to be able to retrieve efficiently examples trees from fragments (treelets) of the parse tree of the sentence we want to translate. We will also propose extensions of this method allowing more flexible matc</context>
<context position="5545" citStr="Lopez, 2007" startWordPosition="972" endWordPosition="973">t notation to describe trees or treelets. Thus “a(b c d(e))” is the tree at the bottom of figure 2. 2.2 General approach There exists already a large body of research about tree pattern matching (Dubiner et al., 1994; Bruno et al., 2002). However, our problem is quite different from finding the tokens of a given treelet in a database. We actually want to find all the tokens of all of the treelets of a given query tree. The query tree itself is unlikely to appear in full even once in the database. In this respect, our approach will have many similarities with (Callison-Burch et al., 2005) and (Lopez, 2007), and can be seen as an extension of these works. The basis of the method in (Lopez, 2007) is to look for the occurrences of continuous substrings using a Suffix Array, and then intersect them to find the occurrences of discontinuous substrings. We will have a similar approach with two variants. The first variant consists in using an adaptation of the concept of suffix arrays to trees, which we will call PathTo-Root Arrays (section 3.4), that allows us to find efficiently the set of occurrences of a linear treelet. Occurrences of non-linear treelets can then be computed by intersection. The se</context>
<context position="7228" citStr="Lopez, 2007" startWordPosition="1254" endWordPosition="1255">s substrings, but (Lopez, 2007) only consider substrings of bounded size, limiting this problem. We will not try to bound the size of treelets retrieved. It is therefore crucial to avoid computing the occurrences of treelets that have no occurrences in the database, and also to eliminate as much redundant calculation as is possible. Lopez proposes to use Prefix Trees for avoiding any redundant or useless computation. We will use a similar idea but with an hypergraph that we will call “computation hypergraph” (section 3.2). This hypergraph will not only fit the same role as the Prefix Tree of (Lopez, 2007), but also will allow us to easily implement different search strategies for flexible search (section 6). 2.3 Representing positions Whether we use a Path-to-Root Array or an inverted index, we will need a compact way to represent the position of a node in a tree. It is straightforward to define such a position for strings, but slightly less for trees. Especially, if we consider ordered trees, we will want to be able to compare the relative location of the nodes by comparing their positions. The simplest possibility is to use an integer corresponding to the rank of the node in a in-order depth</context>
<context position="8511" citStr="Lopez, 2007" startWordPosition="1491" endWordPosition="1492">ildren of a parent node a, to check if b is on the left of c, or on the left of a, for example. A more advanced possibility is to use a representation inspired from (Zhang et al., 2001), in which 509 the position of a node is a tuple consisting of its rank in a preorder (ie. children last) and a postorder (children first) depth-first traversal, and of its distance to the root. This allows to test easily whether a node is an ancestor of another, and their distance to each other. This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. This is discussed in section 7.2. 3 Computing treelets incrementally We describe here in more details how the treelets can be efficiently computed incrementally. 3.1 Dependence of treelet computation Let us first define how it is possible to compute a treelet from two of its subtreelets. Let us consider a treelet T and two treelets T1 and T2 such that T = T1 U T2, where, in the equality and the union, the treelet are seen as the set of their nodes. There are two possibilities. If T1 n T2 = 0, then the root of T1 is a child of a node of T2 or vice-versa. We then say </context>
<context position="10728" citStr="Lopez, 2007" startWordPosition="1918" endWordPosition="1919">and M2 E occ(T2). M1 and M2 are compatible if and only if M2(n2) is a child of M1(n1). Figure 1: A computing hypergraph for “a(b c)”. Definition 3.3 (intersection (®) operation). If two matchings are compatible, we can form their union, which is defined as (M1 U M2)(n) = M1(n) if n E T1 and M2(n) else. We note occ(T1) ® occ(T2) = {M1 U M2 |M1 E occ(T1), M2 E occ(T2) and M1 is compatible with M2 }. Then,we have the property: occ(T) = occ(T1) ® occ(T2) In practice, the intersection operation will be implemented using merge and binary merge algorithms (Baeza-Yates and Salinger, 2005), following (Lopez, 2007). 3.2 The computation hypergraph We have seen that it is possible to compute occ(T) from two subtreelets forming a coverage of T. This can be represented by a hypergraph in which nodes are all the treelets of a given query tree, and every pair of overlapping or adjacent treelet is linked by an hyperedge to their union treelet. Whenever we have computed two starting points of an hyper-edge, we can compute its destination treelet. An example of a small computation hypergraph is described in figure 1. It is very convenient to represent the incremental computation of the treelets as a traversal of</context>
<context position="16565" citStr="Lopez, 2007" startWordPosition="2998" endWordPosition="2999">occurrences are then 3:7, 1:2 and 2:5. memory to retrieve efficiently the pointed-to pathto-root. Once the Path-to-Root Array is built, for a linear treelet T, we can find its occurrences by a binary search of the first and last path-to-root starting with the labels of T. See figure 3 for an example. Memory cost is quite manageable, since we only need 10 bytes per nodes in total. 5 bytes per pointer in the array (tree id: 4 bytes, start position: 1 byte), and 5 bytes per nodes to store the database in memory (label id:4 bytes, parent position: 1 byte). All the optimization tricks proposed in (Lopez, 2007) for Suffix Arrays can be used here, especially the optimization proposed in (Zhang and Vogel, 2005). 3.5 Inverted Index and Precomputation Instead of a Path-to-Root array, one can simply use an inverted index. The inverted index associates with every label the set of its occurrences, each occurrences being represented by a tuple containing the index of the tree, the position of the label in the tree, and the position of the parent of the label in the tree. Knowing the position of the parent will allow to compute treelets of size 2 by intersection (D-coverage). This is less effective than the </context>
<context position="27823" citStr="Lopez, 2007" startWordPosition="5074" endWordPosition="5075">e size (#nodes) 6M 60M Largest non-empty treelet size 4.6 8.7 Processing time (PtR Array) 0.02 s 0.7 s Processing time (Inv. Index) 0.02 s 0.9 s Size on disk 40 MB 500 MB Figure 5: Performances averaged on 100 sentences. Method Treelet Our dictionary method Disk space used 23 GB 500 MB BLEU 11.6% 12.0% Figure 6: Comparison with a dictionary-based baseline (performances averaged over 100 sentences). grows approximately as O(m · N�.5 C ). It is also possible to bound the size of the retrieved treelets (only retrieving treelets with less than 10 nodes, for example), similarly to what is done in (Lopez, 2007). The number of treelets will then only grows as O(m). The total processing time of a given query tree will therefore be on the order of O(m · N�.5 C ) (or O(m · NC) if we bound the treelet size). The fact that this give a complexity worse than linear with respect to the database size might seem a concern, but this is actually only because we are retrieving more and more different types of treelets. The cost of retrieving one treelet remain linear with respect to the size of the corpus. We empirically find that even for very large values of NC, processing time remain very reasonable (see next </context>
<context position="37355" citStr="Lopez, 2007" startWordPosition="6694" endWordPosition="6695">n now be used to search in the trees contained in a packed forest database without any modification. Modifications to the algorithm in order to handle a packed forest query are similar to the ones developed in section 6. 7.2 Discontinuous treelets As we discussed in section 2.3, using a representation for the position of every node similar to (Zhang et al., 2001), it is possible to determine the distance and ancestor relationship of two nodes by just comparing their positions. This opens the possibility of computing the occurrences of discontinuous treelets in much the same way as is done in (Lopez, 2007) for discontinuous substrings. We have not studied this aspect in depth yet, especially since we are not aware of any MT system making use of discontinuous syntax tree examples. This is nevertheless an interesting future possibility. 8 Related work As we previously mentioned, (Lopez, 2007) and (Callison-Burch et al., 2005) propose a method similar to ours for the string case. We are not aware of previous proposals for efficient on-the-fly retrieving of translation examples in the case of Syntax-Based Machine Translation. Among the works involving rule precomputation, (Zhang et al., 2009) descr</context>
</contexts>
<marker>Lopez, 2007</marker>
<rawString>A. Lopez. 2007. Hierarchical phrase-based translation with suffix arrays. In Proc. of EMNLP-CoNLL, page 976985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Manber</author>
<author>G Myers</author>
</authors>
<title>Suffix arrays: a new method for on-line string searches.</title>
<date>1990</date>
<journal>Society for Industrial and Applied Mathematics</journal>
<booktitle>In Proceedings of the first annual ACM-SIAM symposium on Discrete algorithms,</booktitle>
<pages>319--327</pages>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="14699" citStr="Manber and Myers, 1990" startWordPosition="2628" endWordPosition="2632">iscovered queue, which allows us to prune most of the empty treelets of the Inclusion DAG. A treelet in the inclusion DAG can be computed as soon as two of its antecedents have been computed. To start the computation (or rather, “seed” it), it is necessary to know the occurrences of treelet of smaller size. In the following sections 3.4 and 3.5, we describe two methods for efficiently obtaining the set of occurrences of some initial treelets. 3.4 Path-to-Root Array We present here a method to compute very efficiently occ(T) when T is linear. This method is similar to the use of Suffix Arrays (Manber and Myers, 1990) to find the occurrences of continuous substrings in a text. Definition 3.4 (Paths-to-Root Array). Given a labeled tree T and a node n ∈ T, the path-to-root of n is the sequence of labels from n to the root. The Paths-to-Root Array of a set of trees DB is the lexicographically sorted list of the Path-to-Roots of every node in DB. Just as with suffixes, a path-to-root can be represented compactly by a pointer to its starting node in DB. We then need to keep the database DB in 511 Pos PtR Pos PtR Pos PtR 1 3:4 a 8 2:2 bf 15 1:3 fba 2 1:7 a 9 1:6 ca 16 3:3 fga 3 2:6 af 10 1:8 da 17 3:2 ga 4 1:4 a</context>
</contexts>
<marker>Manber, Myers, 1990</marker>
<rawString>U. Manber and G. Myers. 1990. Suffix arrays: a new method for on-line string searches. In Proceedings of the first annual ACM-SIAM symposium on Discrete algorithms, pages 319–327, San Francisco, CA, USA. Society for Industrial and Applied Mathematics Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mi</author>
<author>L Huang</author>
<author>Q Liu</author>
</authors>
<title>Forest based translation.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>192199</pages>
<contexts>
<context position="2098" citStr="Mi et al., 2008" startWordPosition="320" endWordPosition="323"> Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly. (Lopez, 2007) proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as (Chiang, 2007). In this paper, we propose a method to apply the same idea to Syntax-Based SMT and EBMT (Quirk et al., 2005; Mi et al., 2008; Nakazawa and Kurohashi, 2008). Since Syntax-Based systems usually work with the parse trees of the source-side sentences, we will need to be able to retrieve efficiently examples trees from fragments (treelets) of the parse tree of the sentence we want to translate. We will also propose extensions of this method allowing more flexible matchings. 2 Overview of the method 2.1 Treelet retrieval We first formalize the setting of this chapter by providing some definitions. Definition 2.1 (Treelets). A treelet is a connected subgraph of a tree. A treelet T1 is a subtreelet of another treelet T2 if</context>
</contexts>
<marker>Mi, Huang, Liu, 2008</marker>
<rawString>H. Mi, L. Huang, and Q. Liu. 2008. Forest based translation. Proceedings of ACL-08: HLT, page 192199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Toshiaki Nakazawa</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Syntactical EBMT system for NTCIR-7 patent translation task.</title>
<date>2008</date>
<booktitle>In Proceedings of NTCIR-7 Workshop Meeting,</booktitle>
<location>Tokyo, Japon.</location>
<contexts>
<context position="1291" citStr="Nakazawa and Kurohashi, 2008" startWordPosition="186" endWordPosition="189">gms make use of the translation examples provided by a parallel bilingual corpus to produce new translations. Most of these translation systems process the example data in a similar way: The parallel sentences are first word-aligned. Then, translation rules are extracted from these aligned sentences. Finally, the translation rules are used in a decoding step to translate sentences. We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly. (Lopez, 2007) proposed an extension of this method for retrievi</context>
</contexts>
<marker>Nakazawa, Kurohashi, 2008</marker>
<rawString>Toshiaki Nakazawa and Sadao Kurohashi. 2008. Syntactical EBMT system for NTCIR-7 patent translation task. In Proceedings of NTCIR-7 Workshop Meeting, Tokyo, Japon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>A Menezes</author>
<author>C Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>279</pages>
<contexts>
<context position="1260" citStr="Quirk et al., 2005" startWordPosition="182" endWordPosition="185">slation (SMT) paradigms make use of the translation examples provided by a parallel bilingual corpus to produce new translations. Most of these translation systems process the example data in a similar way: The parallel sentences are first word-aligned. Then, translation rules are extracted from these aligned sentences. Finally, the translation rules are used in a decoding step to translate sentences. We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008). As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable. As a solution to this problem in the context of phrase-based Machine Translation, (Callison-Burch et al., 2005) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage. They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly. (Lopez, 2007) proposed an extens</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>C. Quirk, A. Menezes, and C. Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, page 279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>Reliable measures for aligning japanese-english news articles and sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>72--79</pages>
<contexts>
<context position="29378" citStr="Utiyama and Isahara, 2003" startWordPosition="5343" endWordPosition="5346">rees, with a total of nearly 60 million nodes1. The largest trees in the database have around 100 nodes. In order to see how performance scale with the size of the database, we also used a smaller subset of 230,000 trees containing near 6 million nodes. We computed, using our algorithm, 100 randomly selected query trees having from 10 to 70 nodes, with an average of 27 nodes per tree. Table 5 shows the average performances per sentence. Considering the huge size of the database, a process1This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT(www.nict.go.jp) through (Utiyama and Isahara, 2007). ing time below 1 second seems reasonable. The increase in processing time between the small and the large database is in line with the explanations of section 4.4. Path-to-Root Arrays are slightly better than Inverted indexes (we suspect a better implementation could increase the difference further). Both methods use up about the same disk space: around 500MB. We also find that the approach of section 4.2 brings virtually no overhead and gives similar performances whether the query tree is i</context>
</contexts>
<marker>Utiyama, Isahara, 2003</marker>
<rawString>M. Utiyama and H. Isahara. 2003. Reliable measures for aligning japanese-english news articles and sentences. In Proceedings of ACL, pages 72–79, Sapporo,Japon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>A japanese-english patent parallel corpus.</title>
<date>2007</date>
<booktitle>In MT summit XI,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="29480" citStr="Utiyama and Isahara, 2007" startWordPosition="5357" endWordPosition="5360">s. In order to see how performance scale with the size of the database, we also used a smaller subset of 230,000 trees containing near 6 million nodes. We computed, using our algorithm, 100 randomly selected query trees having from 10 to 70 nodes, with an average of 27 nodes per tree. Table 5 shows the average performances per sentence. Considering the huge size of the database, a process1This database was an aggregate of several Japanese-English corpora, notably the Yomiuri newspaper corpus (Utiyama and Isahara, 2003) and the JST paper abstract corpus created at NICT(www.nict.go.jp) through (Utiyama and Isahara, 2007). ing time below 1 second seems reasonable. The increase in processing time between the small and the large database is in line with the explanations of section 4.4. Path-to-Root Arrays are slightly better than Inverted indexes (we suspect a better implementation could increase the difference further). Both methods use up about the same disk space: around 500MB. We also find that the approach of section 4.2 brings virtually no overhead and gives similar performances whether the query tree is in the database or not (effectively reducing the worst-case computation time from days to seconds). We </context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>M. Utiyama and H. Isahara. 2007. A japanese-english patent parallel corpus. In MT summit XI, pages 475– 482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yamamoto</author>
<author>K W Church</author>
</authors>
<title>Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="21714" citStr="Yamamoto and Church, 2001" startWordPosition="3918" endWordPosition="3922"> to lst; 7 Tne,, [parent(root(T)), (0, ... , #T,... , 0)]; 8 Append Tne,, to lst; possible that some tree exactly identical to the query tree (or some tree having a very large treelet in common with the query tree) do exist in the database. This case is obviously a best case for translation, but unfortunately could be a worst-case for our algorithm, as it means that all of the (possibly trillions of) treelets of the query tree will be computed. To solve this issue, we try to consider a concept analogous to that of maximal substring, or substring class, found in Suffix Trees and Suffix Arrays (Yamamoto and Church, 2001). The idea is that in most cases where a query tree is “full” (that is all of its treelets are not empty), most of the larger treelets will share the same occurrences (in the database trees that are very similar to the query tree). We formalize this as follow: Definition 4.2 (domination and maximal treelets). Let T1 be a subtreelet of T2. If for every matching M1 of occ(T1), there exist a matching M2 of occ(T2) such that M2|T1 = M1, we say that T1 is dominated by T2. A treelet is maximal if it is not dominated by any other treelet. If T1 is dominated by T2, it means that all occurrences of T1 </context>
</contexts>
<marker>Yamamoto, Church, 2001</marker>
<rawString>M. Yamamoto and K. W. Church. 2001. Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus. Computational Linguistics, 27(1):1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Vogel</author>
</authors>
<title>An efficient phrase-tophrase alignment model for arbitrarily long phrase and large corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<pages>294--301</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="16665" citStr="Zhang and Vogel, 2005" startWordPosition="3013" endWordPosition="3017">o-root. Once the Path-to-Root Array is built, for a linear treelet T, we can find its occurrences by a binary search of the first and last path-to-root starting with the labels of T. See figure 3 for an example. Memory cost is quite manageable, since we only need 10 bytes per nodes in total. 5 bytes per pointer in the array (tree id: 4 bytes, start position: 1 byte), and 5 bytes per nodes to store the database in memory (label id:4 bytes, parent position: 1 byte). All the optimization tricks proposed in (Lopez, 2007) for Suffix Arrays can be used here, especially the optimization proposed in (Zhang and Vogel, 2005). 3.5 Inverted Index and Precomputation Instead of a Path-to-Root array, one can simply use an inverted index. The inverted index associates with every label the set of its occurrences, each occurrences being represented by a tuple containing the index of the tree, the position of the label in the tree, and the position of the parent of the label in the tree. Knowing the position of the parent will allow to compute treelets of size 2 by intersection (D-coverage). This is less effective than the PathTo-Root Array approach, but open the possibilities for the flexible search discussed in section </context>
</contexts>
<marker>Zhang, Vogel, 2005</marker>
<rawString>Y. Zhang and S. Vogel. 2005. An efficient phrase-tophrase alignment model for arbitrarily long phrase and large corpora. In Proceedings of EAMT, pages 294– 301, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zhang</author>
<author>J Naughton</author>
<author>D DeWitt</author>
<author>Q Luo</author>
<author>G Lohman</author>
</authors>
<title>On supporting containment queries in relational database management systems.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 ACM SIGMOD international conference on Management of data,</booktitle>
<pages>425436</pages>
<contexts>
<context position="8084" citStr="Zhang et al., 2001" startWordPosition="1412" endWordPosition="1415">sition of a node in a tree. It is straightforward to define such a position for strings, but slightly less for trees. Especially, if we consider ordered trees, we will want to be able to compare the relative location of the nodes by comparing their positions. The simplest possibility is to use an integer corresponding to the rank of the node in a in-order depthfirst traversal of the tree. It is then easy, for two nodes b and c, children of a parent node a, to check if b is on the left of c, or on the left of a, for example. A more advanced possibility is to use a representation inspired from (Zhang et al., 2001), in which 509 the position of a node is a tuple consisting of its rank in a preorder (ie. children last) and a postorder (children first) depth-first traversal, and of its distance to the root. This allows to test easily whether a node is an ancestor of another, and their distance to each other. This allows in turn to compute by intersection the occurrences of discontinuous treelets, much like what is done in (Lopez, 2007) for discontinuous strings. This is discussed in section 7.2. 3 Computing treelets incrementally We describe here in more details how the treelets can be efficiently compute</context>
<context position="37108" citStr="Zhang et al., 2001" startWordPosition="6651" endWordPosition="6654">and 10b are some kind of virtual position that help to specify that held and NP8 belong to the same children list. We could also include a cost on edges in the inverted index, which would allow to prune matchings to unlikely parses. The inverted index can now be used to search in the trees contained in a packed forest database without any modification. Modifications to the algorithm in order to handle a packed forest query are similar to the ones developed in section 6. 7.2 Discontinuous treelets As we discussed in section 2.3, using a representation for the position of every node similar to (Zhang et al., 2001), it is possible to determine the distance and ancestor relationship of two nodes by just comparing their positions. This opens the possibility of computing the occurrences of discontinuous treelets in much the same way as is done in (Lopez, 2007) for discontinuous substrings. We have not studied this aspect in depth yet, especially since we are not aware of any MT system making use of discontinuous syntax tree examples. This is nevertheless an interesting future possibility. 8 Related work As we previously mentioned, (Lopez, 2007) and (Callison-Burch et al., 2005) propose a method similar to </context>
</contexts>
<marker>Zhang, Naughton, DeWitt, Luo, Lohman, 2001</marker>
<rawString>C. Zhang, J. Naughton, D. DeWitt, Q. Luo, and G. Lohman. 2001. On supporting containment queries in relational database management systems. In Proceedings of the 2001 ACM SIGMOD international conference on Management of data, page 425436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>M Zhang</author>
<author>H Li</author>
<author>Chew Lim Tan</author>
</authors>
<title>Fast translation rule matching for syntax-based statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1037--1045</pages>
<contexts>
<context position="37949" citStr="Zhang et al., 2009" startWordPosition="6786" endWordPosition="6789"> is done in (Lopez, 2007) for discontinuous substrings. We have not studied this aspect in depth yet, especially since we are not aware of any MT system making use of discontinuous syntax tree examples. This is nevertheless an interesting future possibility. 8 Related work As we previously mentioned, (Lopez, 2007) and (Callison-Burch et al., 2005) propose a method similar to ours for the string case. We are not aware of previous proposals for efficient on-the-fly retrieving of translation examples in the case of Syntax-Based Machine Translation. Among the works involving rule precomputation, (Zhang et al., 2009) describes a method for efficiently matching precomputed treelets rules. These rules are organized in a kind of prefix tree that allows efficient matching of packed forests. (Liu et al., 2006) also propose a greedy algorithm for matching TSC rules to a query tree. 9 Conclusion and future work We have presented a method for efficiently retrieving examples of treelets contained in a query tree, thus allowing on-the-fly computation of translation rules for Syntax-Based systems. We did this by building on approaches previously proposed for the case of string examples, proposing an adaptation of th</context>
</contexts>
<marker>Zhang, Zhang, Li, Tan, 2009</marker>
<rawString>H. Zhang, M. Zhang, H. Li, and Chew Lim Tan. 2009. Fast translation rule matching for syntax-based statistical machine translation. In Proc. of EMNLP, pages 1037–1045.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>