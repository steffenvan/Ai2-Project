<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.978951">
Discursive Usage of Six Chinese Punctuation Marks
</title>
<author confidence="0.997249">
YUE Ming
</author>
<affiliation confidence="0.9989635">
Department of Applied Linguistics
Communication University of China
</affiliation>
<address confidence="0.513439">
100024 Beijing, China
</address>
<email confidence="0.998781">
yueming@cuc.edu.cn
</email>
<sectionHeader confidence="0.995646" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99963275">
Both rhetorical structure and punctuation
have been helpful in discourse processing.
Based on a corpus annotation project, this
paper reports the discursive usage of 6
Chinese punctuation marks in news
commentary texts: Colon, Dash, Ellipsis,
Exclamation Mark, Question Mark, and
Semicolon. The rhetorical patterns of
these marks are compared against patterns
around cue phrases in general. Results
show that these Chinese punctuation
marks, though fewer in number than cue
phrases, are easy to identify, have strong
correlation with certain relations, and can
be used as distinctive indicators of
nuclearity in Chinese texts.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999290069767442">
Rhetorical structure has been proven useful in
NLP projects such as text generation,
summarization, machine translation and essay
scoring. Automatic discourse parsing remains an
elusive task, however, despite much rule-based
research on lexical cues such as anaphora and
conjunctions. Parsing through machine learning
has encountered a bottleneck, due to limited
resources--there is only one English RST
treebank publicly available, and one
RST-annotated German corpus on its way.
Punctuation marks (PMs) have been proven
useful in RST annotation as well as in many other
NLP tasks such as Part-of-Speech tagging, Word
Sense Disambiguation, Near-duplicate detection,
bilingual alignment (e.g. Chuang and Yeh, 2005),
etc. Dale (1991) noticed the role of PMs in
determining rhetorical relations. Say (1998) did a
study on their roles in English discourse structure.
Marcu (1997) and Corston-Oliver (1998) based
their automatic discourse parser partially on PMs
and other orthographical cues. Tsou et al. (1999)
and Chan et al. (2000) use PMs to disambiguate
candidate Discourse Markers for a Chinese
summarization system. Reitter (2003) also used
PMs to distinguish ATTRIBUTION and
ELABORATION relations in his Feature-rich
SVM rhetorical analysis system.
All these inspired us to survey on the rhetorical
patterns around Chinese PMs, so as to provide
more direct a priori scores for the coarse
rhetorical analyzer by Zhang et al. (2000) in their
hybrid summarization system.
This paper is organized into 5 parts: Section 2
gives an overview of a Chinese RST treebank
under construction, and a survey on the syntax of
six main PMs in the corpus: Colon, Dash,
Ellipses, Exclamation Mark, Question Mark, and
Semicolon. Section 3 reports rhetorical patterns
around these PMs. Section 4 is a discussion on the
effectiveness of these PMs in comparison with
Chinese cue phrases. Section 5 is a summary and
Section 6 directions for future work.
</bodyText>
<sectionHeader confidence="0.8912725" genericHeader="method">
2 Overview of Chinese RST treebank
under construction
</sectionHeader>
<subsectionHeader confidence="0.998021">
2.1 Corpus data
</subsectionHeader>
<bodyText confidence="0.99998125">
For the purpose of language engineering and
linguistic investigation, we are constructing a
Chinese corpus comparable to the English
WSJ-RST treebank and the German Potsdam
Commentary Corpus (Carlson et al. 2003; Stede
2004). Texts in our corpus were downloaded
from the official website of People’s Daily1,
where important Caijingpinlun2 (CJPL) articles
</bodyText>
<footnote confidence="0.9923425">
1 www.people.com.cn.
2 Caijinpinglun (CJPL) in Chinese means “financial and
business commentary”, and usually covers various topics in
social economic life, such as fiscal policies, financial reports,
</footnote>
<page confidence="0.996466">
43
</page>
<note confidence="0.570643">
Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 43–48,
</note>
<bodyText confidence="0.979633538461538">
Sydney, July 2006. c�2006 Association for Computational Linguistics
by major media entities were republished. With
over 400 authors and editors involved, our texts
can be regarded as a good indicator of the general
use of Chinese by Mainland native speakers.
At the moment our CJPL corpus has a total of
395 texts, 785,045 characters, and 84,182
punctuation marks (including pruned spaces).
Although on average there are 9.3 characters
between every two marks, sentences in CJPL are
long, with 51.8 characters per common sentence
delimiters (Full Stop, Question Mark and
Exclamation Mark).
</bodyText>
<subsectionHeader confidence="0.998862">
2.2 Segmentation
</subsectionHeader>
<bodyText confidence="0.999759411764706">
We are informed of the German Potsdam
Commentary Corpus construction, in which they
(Reitter 2003) designed a program for automatic
segmentation at clausal level after each
Sign=“$.”(including {., ?, !, ;, :, ...}) and
Sign=“$,”(including {,})3. Human interference
with the segmentation results was not allowed,
but annotators could retie over-segmented bits by
using the JOINT relation.
Given the workload of discourse annotation,
we decided to design a similar segmentation
program. So we first normalized different
encoding systems and variants of PMs (e.g.
Dashes and Ellipses of various lengths), and then
conducted a survey on the distribution (Fig. 1)
and syntax of major Chinese punctuation marks
(e.g. syntax of Chinese Dash in Table 1).
</bodyText>
<figureCaption confidence="0.975384">
Figure 1: Percentage of major punctuation
marks in the Chinese corpus4
</figureCaption>
<bodyText confidence="0.771978166666667">
C-Comma-1 is the most frequently used PM in
the Chinese corpus. While it does delimit clauses,
a study on 200 randomly selected C-Comma-1
tokens in our corpus shows that 55 of them are
trading, management, economic conferences, transportation,
entertainment, education, etc.
</bodyText>
<footnote confidence="0.810188166666667">
Collected by professional editors, most texts in our corpus
are commentaries; some are of marginal genres by the
Chinese standards.
3 Dash, as a Sign= “$(”, was not selected as a unit delimiter
in the Potsdam Commentary Corpus.
4 PMs are counted by individual symbols.
</footnote>
<bodyText confidence="0.997594857142857">
used after an independent NP or discourse
marker. This rate, times the total number of
C-Comma-1, means we would have to retie a
huge number of over-segmented elements. So we
decided not to take C-Comma-1 as a delimiter of
our Elementary Unit of Discourse Analysis
(EUDA) for the present.
</bodyText>
<table confidence="0.9976755">
Structure of C-——5 %
[NP+——NP+]NP 3.12%
[s+——s+]NP 0.44%
S*[NP——NP——VP]S 1.78%
S*[NP——s——VP]S 0.89%
S*[s——s——s]S 6.22%
&lt;title&gt;s+——Source:s+&lt;/title&gt; 2.67%
&lt;title&gt;Source:s——s+&lt;/title&gt; 0.44%
&lt;para&gt;S*s——&lt;/para&gt; 1.33%
&lt;para&gt;S——S+&lt;/para&gt; 2.22%
&lt;para&gt;S*s”——s+&lt;/para&gt; 7.56%
&lt;para&gt;——S+&lt;/para&gt; 12.44%
&lt;para&gt;S*s——s+&lt;/para&gt; 60.89%
TTL 100.00%
</table>
<tableCaption confidence="0.999906">
Table 1: Syntax of Chinese Dash
</tableCaption>
<bodyText confidence="0.898803777777778">
42.9% of the colons in CJPL are used in the
structural elements6 of the texts. Other than these,
56.5% of the colons are used between clausal
strings, only 0.6% of the colons are used after
non-clausal strings.
99.6% instances of Exclamation Mark,
Question Mark, Dash, Ellipses and Semicolon in
the Chinese corpus are used after clausal strings.
In our corpus, 4.3% of the left quotation marks
do not have a right match to indicate the end of a
quote. Because many articles do not give clear
indications of direct or indirect
it is very
difficult for the annotator to makeup.
Parentheses an
quotes7,
d brackets have a similar
problem, with 3.2% marks missing their matches.
The symbol
donates sentences with a common end
mark, while
denotes structures orthographically end with
one of the PMs studied here.
means one or more
occurrences,
means zero or more occurrences. The
category after a bracket pair indicates the syntactic role
played by the unit enclosed, for example
means
the ellipses functions as an NP within a clausal structure.
denotes paragraph opening and ending.
6 By
we mean documentary
information, such as Publishing Date, Source, Link, Editor,
etc. Although these are parts of a news text, they are not the
article proper, on which we annotate rhetorical relations.
After a comparative study on the rhetorical structure of
news published by some Hong Kong newspapers in both
English and Chinese, Scollon and Scollon (1997) observed
that
is at best ambiguous in Chinese. No standard
practice has been observed across newspapers in this set and
even within a newspaper, it is not obvious which portions of
the text are attributed to
We notice that Mainlan
</bodyText>
<figure confidence="0.941251891891892">
5
“S”
“s”
“+”
“*”
“[ ]NP”
“&lt;para&gt;&lt;/para&gt;”
“Structuralelements”
7
“quotation
whom.”
d
newspapers have a similar phenomenon.
Period
Exclamation
Question
Comma-1
Comma-2
Colon
Semicolon
Dash-half
Ellipsis-
Quote-L
Quote-R
Paren-L
Paren-R
Space
Other
Rate in total PMs 40.0% PM
35.0%
30.0%
25.0%
20.0%
15.0%
10.0%
5.0%
0.0%
</figure>
<page confidence="0.995618">
44
</page>
<bodyText confidence="0.9999586875">
Besides, 53.9% of the marks appear in structural
elements that we didn’t intend to analyze8.
Finally, we decided to use Period, the
End-of-line symbol, and these six marks
(Question Mark, Exclamation Mark, Colon,
Semicolon, Ellipsis and Dash) as delimiters of
our EUDA. Quotation mark, Parentheses, and
Brackets were not selected.
A special program was designed to conduct
the segmentation after each delimiter, with
proper adjustment in cases when the delimiter is
immediately followed by a right parenthesis, a
right quotation mark, or another delimiter.
A pseudo-relation, SAME-UNIT, has been used
during annotation to re-tie any discourse segment
cut by the segmentation program into fragments.
</bodyText>
<subsectionHeader confidence="0.99806">
2.3 Annotation and Validity Control
</subsectionHeader>
<bodyText confidence="0.9998204375">
We use O’Donnell’s RSTTool V3.43 9 as our
annotation software. We started from the
Extended-RST relation set embedded in the
software, adding gradually some new relations,
and finally got an inventory of 47 relations. We
take the same rhetorical predicate with switched
arguments as different relations, for instance,
SOLUTIONHOOD-S, SOLUTIONHOOD-M and
SOLUTIONHOOD-N are regarded as 3 relations.
Following Carlson et al. (2001) and Marcu’s
(1999) examples, we’ve composed a 60-page
Chinese RST annotation manual, which includes
preprocessing procedures, segmentation rules,
definitions and examples of the relations, tag
definitions for structural elements, tagging
conventions for special structures, and a relation
selection protocol. When annotating, we choose
the most indicative relation according to the
manual. Trees are constructed with binary
branches except for multinuclear relations.
One experienced annotator had sketched trees
for all the 395 files before the completion of the
manual. Then she annotated 97 shortest files
from 197 randomly selected texts, working
independently and with constant reference to the
manual. After a one-month break, she
re-annotated the 97 files, with reference to the
manual and with occasional consultation with
Chinese journalists and linguists. The last
version, though far from error-free, is currently
taken as the right version for reliability tests and
other statistics.
</bodyText>
<footnote confidence="0.966095">
8 Parentheses, and other PMs used in structural elements of
CJPL texts, are of high relevance to discourse parsing, since
they can be used in a preprocessor to filter out text
fragments that do not need be annotated in terms of RST.
9 Publicly downloadable at www.wagsoft.com.
</footnote>
<bodyText confidence="0.99788225">
An intra-coder accuracy test has bee taken
between the 1st and 2nd versions of 97 finished
trees. The intra-coder accuracy rate (Rv) for a
particular variable is defined as
</bodyText>
<equation confidence="0.961174">
2*(AT-AS)
Rv= *100%
TT-TS
</equation>
<bodyText confidence="0.994808">
Where
AT= number of agreed tags;
TT= number of total tags;
TS= number of total tags for structural
elements;
AS= number of agreed tags for structural
elements.
Rr for relation tags is 84.39%, Ru for unit tags is
85.61%, and Rn for nuclearity tags is 88.12%.
Because SPSS can only calculate Kappa
Coefficient for symmetric data, we’ve only
measured Kappa for relation tags to the EUDAs.
The outcome, Kr=.738, is quite high.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.999969444444444">
The 97 double-annotated files have in the main
body of their texts a total of 677 paragraphs and
1,914 EUDAs. Relational patterns of those PMs
are reported in Table 2-7 below10. The “N”, “S”
or “M” tags after each relation indicate the
nuclearity status of each EUDA ended with a
certain PM. The number of those PMs used in
structural elements of CJPL texts are also
reported as they make up the total percentage.
</bodyText>
<table confidence="0.999933714285714">
Relation (C-?) P(r|pm) P(pm|r)
Antithesis-N 1.14% 2.70%
Background-N 2.27% 3.39%
Concession-N 7.95% 7.29%
Conjunction-M 30.68% 5.24%
Disjunction-M 4.55% 36.36%
Elaboration-N 2.27% 1.10%
Elaboration-S 2.27% 1.10%
Evaluation-N 1.14% 0.72%
Interpretation-N 1.14% 0.67%
Joint-M 4.55% 6.90%
Justify-N 4.55% 1.75%
Justify-S 4.55% 1.75%
Nonvolitional-cause-S 2.27% 1.43%
Nonvolitional-result-S 1.14% 0.71%
Otherwise-S 1.14% 16.67%
Solutionhood-M 4.55% 5.33%
Solutionhood-S 14.78% 17.33%
Volitional-cause-N 1.14% 1.32%
Structural elements 7.96% 0.99%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.993593">
Table 2: Rhetorical pattern of C-Question
</tableCaption>
<page confidence="0.6759935">
10 Based on data from the 2nd version of annotated texts.
45
</page>
<table confidence="0.999944357142857">
Relation (C-!) P(r|pm) P(pm|r)
Addition-S 5.26% 14.29%
Conjunction-M 15.79% 0.58%
Elaboration-S 5.26% 0.55%
Evaluation-S 10.53% 1.44%
Evidence-S 10.53% 2.33%
Joint-M 5.26% 1.72%
Justify-N 5.26% 0.44%
Justify-S 5.26% 0.44%
Nonvolitional-cause-N 5.26% 0.71%
Solutionhood-N 5.26% 1.33%
Volitional-cause-S 5.26% 1.32%
Structural elements 21.05% 0.57%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.972138">
Table 3: Rhetorical pattern of C-Exclamation
</tableCaption>
<table confidence="0.999953285714286">
Relation (C-:) P(r|pm) P(pm|r)
Attribution-S 10.93% 68.00%
Background-N 0.64% 3.39%
Background-S 0.32% 1.69%
Concession-N 0.32% 1.04%
Elaboration-N 18.97% 32.42%
Evaluation-N 0.64% 1.44%
Justify-S 0.32% 0.44%
Nonvolitional-cause-N 0.32% 0.71%
Preparation-S 4.18% 13.40%
Same-unit-S 0.32% 4.35%
Volitional-cause-N 0.32% 1.32%
Structural elements 62.70%11 27.70%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.97118">
Table 4: Rhetorical pattern of C-Colon
</tableCaption>
<table confidence="0.999947416666667">
Relation (C-;) P(r|pm) P(pm|r)
Antithesis-S 1.00% 2.70%
Background-N 1.00% 1.69%
Background-S 1.00% 1.69%
Conjunction-M 59.00% 11.46%
Contrast-M 7.00% 7.69%
Disjunction-M 2.00% 18.18%
List-M 23.00% 24.73%
Purpose-N 1.00% 6.67%
Same-unit-M 2.00% 8.70%
Sequence-M 3.00% 6.12%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.957764">
Table 5: Rhetorical pattern of C-Semicolon
</tableCaption>
<table confidence="0.9992044">
Relation (C- ) P(r|pm) P(pm|r)
Conjunction-M 12.50% 0.19%
Disjunction-M 12.50% 9.09%
Elaboration-S 25.00% 1.10%
Evidence-S 25.00% 2.33%
</table>
<footnote confidence="0.712766666666667">
11 This is higher than the overall 42.93% rate for colons
used in structural elements, for we’ve only finished 97
shortest ones from the 197 randomly selected files.
</footnote>
<table confidence="0.988859666666667">
Evaluation-N 12.50% 0.72%
Volitional-result-S 12.50% 1.32%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.777743">
Table 6: Rhetorical pattern of C-Ellipses
</tableCaption>
<table confidence="0.999949230769231">
Relation (C-——) P(r|pm) P(pm|r)
Elaboration-N 32.00% 4.40%
Elaboration-S 4.00% 0.55%
Evaluation-N 12.00% 2.16%
Evaluation-S 4.00% 0.72%
Nonvolitional-cause-S 4.00% 0.71%
Nonvolitional-result-S 4.00% 0.71%
Otherwise-S 4.00% 16.67%
Preparation-N 4.00% 1.03%
Purpose-N 4.00% 6.67%
Restatement-N 4.00% 14.29%
Same-unit-M 24.00% 26.09%
TTL 100.00% N/A
</table>
<tableCaption confidence="0.998385">
Table 7: Rhetorical pattern of C-Dash
</tableCaption>
<bodyText confidence="0.938971">
The above data suggest at least the following:
</bodyText>
<listItem confidence="0.806269515151515">
1) There is no one-to-one mapping between any
of PM studied and a rhetorical relation. But
some PMs have dominant rhetorical usages.
2) C-Question Mark is not most frequently
related with SOLUTIONHOOD, but with
CONJUNCTION. That is because a high
percentage of questions in our corpus are
rhetorical and used in groups to achieve
certain argumentative force.
3) C-Colon is most frequently related with
ATTRIBUTION and ELABORATION, apart
from its usage in structural elements.
4) C-Semicolon is overwhelmingly associated
with multinuclear relations, particularly with
CONJUNCTION.
5) C-Dash usually indicates an ELABORATION
relation. But since it is often used in pairs, it
is often bound to both the Nucleus and
Satellite units of a relation.
6) 82.3% tokens of the six Chinese PMs are
uniquely related to EUDAs of certain
nucleus status in a rhetorical relation, taking
even C-Dash into account.
7) The following relations have more than 10%
of their instances related to one of the six
PMs studied here: ADDITION,
ATTRIBUTION, CONJUNCTION,
DISJUNCTION, ELABORATION, LIST,
OTHERWISE, PREPARTION,
RESTATEMENT and SOLUTIONHOOD.
8) Chinese PMs are used somewhat differently
from their German equivalents, Exclamation
Mark for instance (Fig.2):
</listItem>
<page confidence="0.999489">
46
</page>
<figureCaption confidence="0.980805">
Figure 2: Rhetorical Function of Exclamation
Mark in Chinese and German corpora
</figureCaption>
<sectionHeader confidence="0.99705" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999344128205128">
How useful are these six PMs in the prediction of
rhetorical relations in Chinese texts? In our
opinion, this question can be answered partly
through a comparison with Chinese cue phrases.
Cue phrases are widely discussed and
exploited in the literature of both Chinese studies
and RST applications as a major surface device.
Unfortunately, Chinese cue phrases in natural
texts are difficulty to identify automatically. As
known, Chinese words are made up of 1, 2, or
more characters, but there is no explicit word
delimiter between any pair of adjacent words in a
string of characters. Thus, they are not known
before tokenization (“fenci” in Chinese, meaning
“separating into words”, or “word segmentation”
so as to recognize meaningful words out of
possible overlaps or combinations). The task
may sound simple, but has been the focus of
considerable research efforts (e.g. Webster and
Kit, 1992; Guo 1997; Wu, 2003).
Since many cue phrases are made up of
high-frequency characters (e.g. “ffq-ER” in “ffq
-er” meaning “but/so/and”, “ 然 ffq -ran’er”
meaning “but/however”, “Qffq-yin’er” meaning
“so/because of this”, “ &amp;quot;
-ergie meaing “in
addition” etc.; “k-ci” in “krh-cihou” meaning
“later/hereafter”, “Qk-yinci” meaning “as a
result”, “EhkV来-youcikanlai” meaning “on
this ground/hence”, etc.), a considerable amount
of computation must be done before these cue
phrases can ever been exploited.
Apart from tokenization, POS and WSD are
other necessary steps that should be taken before
making use of some common cue phrases. They
are all hard nuts in Chinese language engineering.
Interestingly, many researches done in these
three areas have made use of the information
carried by PMs (e.g. Sun et al. 1998).
Chan et al. (2000) did a study on identify
Chinese connectives as signals of rhetorical
relations for their Chinese summarizer. Their
tests were successful. But like PMs, Chinese cue
phrases are not in a one-to-one mapping
relationship with rhetorical relations, either.
In our finished portion of CJPL corpus, we’ve
identified 161 Types of cue phrases12 at or above
our EUDA level, recording 539 tokens. These
cue phrases are scattered in 477 EDUAs,
indicating 20.5% of the total relations in our
finished portion of the corpus. Our six PMs, on
the other hand, have 551 tokens in the same
finished portion, delimiting 345 EUDAs (and
206 structural elements), and indicating 14.8% of
the total relations. However, since there are far
more types of cue phrases than types of
punctuation marks, 90.1% of cue phrases are
sparser at or above our EDUA level than the
least frequently used PM—Ellipsis in this case.
And Chinese cue phrases don’t signal all the
rhetorical relations at all levels. For instance,
CONJUNTION is the most frequently used
relation in our annotated text (taking 22.1% of all
the discursive relations), but it doesn’t have
strong correlation with any lexical item. Its most
frequent lexical cue is “th-ye”, taking 2.4%.
ELABORATION is another common relation in
CJPL, but it is rarely marked by cue phrases.
ATTRIBUTION, SOLUTIONHOOD and
DISJUNCTION are amongst other lowest marked
relations in Chinese—they happen to be signaled
quite significantly by a punctuation mark.
Given the cost to recognize Chinese cue
phrases accurately, the sparseness of many of
these cues, and the risk of missing all cue phrases
for a particular discursive relation, punctuation
marks with strong rhetorical preferences appear
to be useful supplements to cue phrases.
</bodyText>
<sectionHeader confidence="0.998957" genericHeader="method">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.939677">
Because rhetorical structure in Chinese texts is
not explicit by itself, systematic and quantitative
evaluation of various factors that can contribute
to the automatic analysis of texts is quite
necessary. The purpose of this study is to look
into the discursive patterns of Chinese PMs, to
see if they can facilitate discourse parsing
without deep semantic analysis.
We have in this study observed the discursive
usage of six Chinese PMs, from their overall
distribution in our Chinese discourse corpus,
their syntax in context, to their rhetorical roles at
12 We are yet to give a theoretical definition of Cue Phrases
in our study. But the identified ones range similarly to those
English cue phrases listed in Marcu (1997).
</bodyText>
<figure confidence="0.998106739130435">
Relation type
P(r|pm) 35.0% Chinese
30.0% German
25.0%
20.0%
15.0%
10.0%
5.0%
0.0%
Addition-S
Conjunc-M
Concess-S
Elabo-S
Evalu
Evidence-S
Joint-M
Justify-N
Justify-S
NV result-
Prepa-S
Solution-S
Sequence-M
V Cause-S
</figure>
<page confidence="0.997185">
47
</page>
<bodyText confidence="0.942512090909091">
Fall Symposium on Discourse Structure in Natural
Language Understanding and Generation. P13-13.
Asilomar.
or above our EUDA level. Current statistics seem
to suggest clear patterns of their rhetorical roles,
and their distinctive correlation with nuclearity in
most relations. These patterns and correlation
may be useful in NLP projects.
Jin GUO. 1997. Critical Tokenization and its
Properties. Computational Linguistics, 23(4):
569-596.
</bodyText>
<sectionHeader confidence="0.999324" genericHeader="discussions">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999955166666667">
We are conscious of the size and granularity of
our treebank on which this analysis is based. We
plan to get a larger team to work on the project,
so as to make it more comparable to the English
and German RST treebanks.
Since the distinctive nucleus status of EUDAs
ended with these PMs may be useful in deciding
growth point for RS-tree construction or for tree
pruning in summarization, we are also interested
in testing how well a baseline relation classifier
performs if it always predicts the most frequent
relations for these PMs.
</bodyText>
<sectionHeader confidence="0.987621" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999889285714286">
Special thanks to Dr. Manfred Stede for licensing
us to use the Potsdam Commentary Corpus. And
thanks to Dr. Michael O’Donnell, FAN Taizhi,
HU Fengguo, JIN Narisong, and MA Guangbin
for their technical support. The author also fully
appreciates the anonymous reviewers for their
constructive comments.
</bodyText>
<sectionHeader confidence="0.999257" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999517535211267">
Lynn Carlson and Daniel Marcu. 2001. Discourse
tagging reference manual, Technical Report
ISI/TR-545. www.isi.edu/~marcu.
Lynn Carlson, Daniel Marcu, and Mary. E. Okurowski.
2003. Building a discourse-tagged corpus in the
framework of Rhetorical Structure Theory. In Jan
van Kuppevelt and Ronnie Smith, editors, Current
Directions in Discourse and Dialogue. Kluwer
Academic Publishers. www.isi.edu/~marcu.
Samuel W. K. Chan, Tom B. Y. Lai, W. J. Gao and B.
K. T’sou. 2000. Mining discourse markers for
Chinese Textual Summarization. Workshop on
Automatic Summarization, ACL 2000.
Thomas C. Chuang and Kevin C. Yeh. 2005. Aligning
Parallel Bilingual Corpora Statistically with
Punctuation Criteria. Computational Linguistics
and Chinese Language Processing. Vol. 10, No. 1,
March 2005, pp. 95-122.
Simon H. Corston-Oliver. 1998. Computing
Representation of the Structure of Written
Discourse. Technical Report. MSR-TR-98-15.
Robert Dale. 1991. The role of punctuation in
discourse structure. Working Notes for the AAAI
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional
theory of text organization. Text, 8(3):243–281.
Daniel Marcu. 1997. The rhetorical parsing,
summarization, and generation of natural
language texts. PhD thesis. University of Toronto.
December 1997. www.isi.edu/~marcu
Daniel Marcu. 1999. Instructions for manually
annotating the discourse structures of texts.
www.isi.edu/~marcu
David Reitter. 2003. Rhetorical Analysis with
Rich-Feature Support Vector Models. University of
Potsdam, Diploma thesis in computational
linguistics.
Bilge Say. 1998. An Information-Based Approach to
Punctuation. Ph.D. dissertation, Bilkent University,
Ankara, Turkey.
http://www.cs.bilkent.edu.tr/~say/bilge.html.
Ron Scollon and Suzanne Wong Scollon. 1997. Point
of view and citation: Fourteen Chinese and English
versions of the ‘same’ news story. Text, 17 (1),
83-125.
Manfred Stede. 2004. The Potsdam Commentary
Corpus. In Proceedings of the ACL 2004 Workshop
‘Discourse Annotation’. Barcelona.
SUN Maosong, Dayang SHEN, and Benjamin K. Tsou,
1998. Chinese word segmentation without using
lexicon and hand-crafted training data. In
Proceedings of COLING-ACL’98.
Benjamin K.Tsou, Weijun Gao, T.V.Y Lai and S.W.K.
Chan. 1999. Applying machine learning to identify
Chinese discourse markers. Proceedings of 1999
International Conference on Information
Intelligence and Systems. p 548-53, 31 Oct.-3 Nov.
1999, Bethesda, MD, USA.
Jonathan J. Webster and Chunyu Kit. 1992.
Tokenization as the initial phase in NLP. In
Proceedings of the 14th International Conference
on Computational Linguistics (COLING&apos;92), pages
1,106-1,110, Nantes, France.
WU Andi. 2003. Chinese Word Segmentation in
MSR-NLP. In Proceedings of the Second SIGHAN
Workshop on Chinese Language Processing,
Sapporo, Japan.
ZHANG Yimin, LU Ru-Zhan and SHEN Li-Bin. 2000.
A hybrid method for automatic Chinese discourse
structure analysis. Journal of Software, v 11, n 11,
Nov. 2000, p 1527-33.
</reference>
<page confidence="0.999349">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.873085">
<title confidence="0.998814">Discursive Usage of Six Chinese Punctuation Marks</title>
<author confidence="0.996923">YUE Ming</author>
<affiliation confidence="0.9991025">Department of Applied Linguistics Communication University of China</affiliation>
<address confidence="0.999973">100024 Beijing, China</address>
<email confidence="0.988879">yueming@cuc.edu.cn</email>
<abstract confidence="0.985785294117647">Both rhetorical structure and punctuation have been helpful in discourse processing. Based on a corpus annotation project, this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts: Colon, Dash, Ellipsis, Exclamation Mark, Question Mark, and Semicolon. The rhetorical patterns of these marks are compared against patterns around cue phrases in general. Results show that these Chinese punctuation marks, though fewer in number than cue phrases, are easy to identify, have strong correlation with certain relations, and can be used as distinctive indicators of nuclearity in Chinese texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
</authors>
<title>Discourse tagging reference manual,</title>
<date>2001</date>
<tech>Technical Report ISI/TR-545. www.isi.edu/~marcu.</tech>
<marker>Carlson, Marcu, 2001</marker>
<rawString>Lynn Carlson and Daniel Marcu. 2001. Discourse tagging reference manual, Technical Report ISI/TR-545. www.isi.edu/~marcu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory.</title>
<date>2003</date>
<booktitle>Current Directions in Discourse and Dialogue.</booktitle>
<editor>In Jan van Kuppevelt and Ronnie Smith, editors,</editor>
<publisher>Kluwer Academic Publishers. www.isi.edu/~marcu.</publisher>
<marker>Okurowski, 2003</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary. E. Okurowski. 2003. Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory. In Jan van Kuppevelt and Ronnie Smith, editors, Current Directions in Discourse and Dialogue. Kluwer Academic Publishers. www.isi.edu/~marcu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel W K Chan</author>
<author>Tom B Y Lai</author>
<author>W J Gao</author>
<author>B K T’sou</author>
</authors>
<title>Mining discourse markers for Chinese Textual Summarization. Workshop on Automatic Summarization,</title>
<date>2000</date>
<location>ACL</location>
<marker>Chan, Lai, Gao, T’sou, 2000</marker>
<rawString>Samuel W. K. Chan, Tom B. Y. Lai, W. J. Gao and B. K. T’sou. 2000. Mining discourse markers for Chinese Textual Summarization. Workshop on Automatic Summarization, ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas C Chuang</author>
<author>Kevin C Yeh</author>
</authors>
<title>Aligning Parallel Bilingual Corpora Statistically with Punctuation Criteria.</title>
<date>2005</date>
<journal>Computational Linguistics and Chinese Language Processing.</journal>
<volume>10</volume>
<pages>95--122</pages>
<contexts>
<context position="1533" citStr="Chuang and Yeh, 2005" startWordPosition="213" endWordPosition="216">ation, machine translation and essay scoring. Automatic discourse parsing remains an elusive task, however, despite much rule-based research on lexical cues such as anaphora and conjunctions. Parsing through machine learning has encountered a bottleneck, due to limited resources--there is only one English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns a</context>
</contexts>
<marker>Chuang, Yeh, 2005</marker>
<rawString>Thomas C. Chuang and Kevin C. Yeh. 2005. Aligning Parallel Bilingual Corpora Statistically with Punctuation Criteria. Computational Linguistics and Chinese Language Processing. Vol. 10, No. 1, March 2005, pp. 95-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon H Corston-Oliver</author>
</authors>
<title>Computing Representation of the Structure of Written Discourse.</title>
<date>1998</date>
<tech>Technical Report. MSR-TR-98-15.</tech>
<contexts>
<context position="1721" citStr="Corston-Oliver (1998)" startWordPosition="244" endWordPosition="245">ns. Parsing through machine learning has encountered a bottleneck, due to limited resources--there is only one English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs, so as to provide more direct a priori scores for the coarse rhetorical analyzer by Zhang et al. (2000) in their hybrid summarization system. This paper is organized into</context>
</contexts>
<marker>Corston-Oliver, 1998</marker>
<rawString>Simon H. Corston-Oliver. 1998. Computing Representation of the Structure of Written Discourse. Technical Report. MSR-TR-98-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>The role of punctuation in discourse structure. Working Notes for the AAAI</title>
<date>1991</date>
<contexts>
<context position="1551" citStr="Dale (1991)" startWordPosition="218" endWordPosition="219">nd essay scoring. Automatic discourse parsing remains an elusive task, however, despite much rule-based research on lexical cues such as anaphora and conjunctions. Parsing through machine learning has encountered a bottleneck, due to limited resources--there is only one English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs,</context>
</contexts>
<marker>Dale, 1991</marker>
<rawString>Robert Dale. 1991. The role of punctuation in discourse structure. Working Notes for the AAAI</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The rhetorical parsing, summarization, and generation of natural language texts. PhD thesis.</title>
<date>1997</date>
<institution>University of Toronto.</institution>
<note>www.isi.edu/~marcu</note>
<contexts>
<context position="1695" citStr="Marcu (1997)" startWordPosition="241" endWordPosition="242">ra and conjunctions. Parsing through machine learning has encountered a bottleneck, due to limited resources--there is only one English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs, so as to provide more direct a priori scores for the coarse rhetorical analyzer by Zhang et al. (2000) in their hybrid summarization system. Th</context>
<context position="19788" citStr="Marcu (1997)" startWordPosition="2976" endWordPosition="2977"> various factors that can contribute to the automatic analysis of texts is quite necessary. The purpose of this study is to look into the discursive patterns of Chinese PMs, to see if they can facilitate discourse parsing without deep semantic analysis. We have in this study observed the discursive usage of six Chinese PMs, from their overall distribution in our Chinese discourse corpus, their syntax in context, to their rhetorical roles at 12 We are yet to give a theoretical definition of Cue Phrases in our study. But the identified ones range similarly to those English cue phrases listed in Marcu (1997). Relation type P(r|pm) 35.0% Chinese 30.0% German 25.0% 20.0% 15.0% 10.0% 5.0% 0.0% Addition-S Conjunc-M Concess-S Elabo-S Evalu Evidence-S Joint-M Justify-N Justify-S NV resultPrepa-S Solution-S Sequence-M V Cause-S 47 Fall Symposium on Discourse Structure in Natural Language Understanding and Generation. P13-13. Asilomar. or above our EUDA level. Current statistics seem to suggest clear patterns of their rhetorical roles, and their distinctive correlation with nuclearity in most relations. These patterns and correlation may be useful in NLP projects. Jin GUO. 1997. Critical Tokenization and</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. The rhetorical parsing, summarization, and generation of natural language texts. PhD thesis. University of Toronto. December 1997. www.isi.edu/~marcu</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Instructions for manually annotating the discourse structures of texts. www.isi.edu/~marcu</title>
<date>1999</date>
<marker>Marcu, 1999</marker>
<rawString>Daniel Marcu. 1999. Instructions for manually annotating the discourse structures of texts. www.isi.edu/~marcu</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Reitter</author>
</authors>
<title>Rhetorical Analysis with Rich-Feature Support Vector Models.</title>
<date>2003</date>
<institution>University of Potsdam,</institution>
<note>Diploma thesis in computational linguistics.</note>
<contexts>
<context position="1953" citStr="Reitter (2003)" startWordPosition="279" endWordPosition="280">n useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs, so as to provide more direct a priori scores for the coarse rhetorical analyzer by Zhang et al. (2000) in their hybrid summarization system. This paper is organized into 5 parts: Section 2 gives an overview of a Chinese RST treebank under construction, and a survey on the syntax of six main PMs in the corpus: Colon, Dash, Ellipses, Exclamation Mark, Question Mark, and Semicolon. Section 3 reports r</context>
<context position="4164" citStr="Reitter 2003" startWordPosition="618" endWordPosition="619">were republished. With over 400 authors and editors involved, our texts can be regarded as a good indicator of the general use of Chinese by Mainland native speakers. At the moment our CJPL corpus has a total of 395 texts, 785,045 characters, and 84,182 punctuation marks (including pruned spaces). Although on average there are 9.3 characters between every two marks, sentences in CJPL are long, with 51.8 characters per common sentence delimiters (Full Stop, Question Mark and Exclamation Mark). 2.2 Segmentation We are informed of the German Potsdam Commentary Corpus construction, in which they (Reitter 2003) designed a program for automatic segmentation at clausal level after each Sign=“$.”(including {., ?, !, ;, :, ...}) and Sign=“$,”(including {,})3. Human interference with the segmentation results was not allowed, but annotators could retie over-segmented bits by using the JOINT relation. Given the workload of discourse annotation, we decided to design a similar segmentation program. So we first normalized different encoding systems and variants of PMs (e.g. Dashes and Ellipses of various lengths), and then conducted a survey on the distribution (Fig. 1) and syntax of major Chinese punctuation</context>
</contexts>
<marker>Reitter, 2003</marker>
<rawString>David Reitter. 2003. Rhetorical Analysis with Rich-Feature Support Vector Models. University of Potsdam, Diploma thesis in computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bilge Say</author>
</authors>
<title>An Information-Based Approach to Punctuation.</title>
<date>1998</date>
<institution>Bilkent University,</institution>
<location>Ankara, Turkey. http://www.cs.bilkent.edu.tr/~say/bilge.html.</location>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="1623" citStr="Say (1998)" startWordPosition="229" endWordPosition="230">wever, despite much rule-based research on lexical cues such as anaphora and conjunctions. Parsing through machine learning has encountered a bottleneck, due to limited resources--there is only one English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs, so as to provide more direct a priori scores for the coarse rhetorical </context>
</contexts>
<marker>Say, 1998</marker>
<rawString>Bilge Say. 1998. An Information-Based Approach to Punctuation. Ph.D. dissertation, Bilkent University, Ankara, Turkey. http://www.cs.bilkent.edu.tr/~say/bilge.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Scollon</author>
<author>Suzanne Wong Scollon</author>
</authors>
<title>Point of view and citation: Fourteen Chinese and English versions of the ‘same’ news story.</title>
<date>1997</date>
<journal>Text,</journal>
<volume>17</volume>
<issue>1</issue>
<pages>83--125</pages>
<contexts>
<context position="7521" citStr="Scollon and Scollon (1997)" startWordPosition="1134" endWordPosition="1137">e or more occurrences, means zero or more occurrences. The category after a bracket pair indicates the syntactic role played by the unit enclosed, for example means the ellipses functions as an NP within a clausal structure. denotes paragraph opening and ending. 6 By we mean documentary information, such as Publishing Date, Source, Link, Editor, etc. Although these are parts of a news text, they are not the article proper, on which we annotate rhetorical relations. After a comparative study on the rhetorical structure of news published by some Hong Kong newspapers in both English and Chinese, Scollon and Scollon (1997) observed that is at best ambiguous in Chinese. No standard practice has been observed across newspapers in this set and even within a newspaper, it is not obvious which portions of the text are attributed to We notice that Mainlan 5 “S” “s” “+” “*” “[ ]NP” “&lt;para&gt;&lt;/para&gt;” “Structuralelements” 7 “quotation whom.” d newspapers have a similar phenomenon. Period Exclamation Question Comma-1 Comma-2 Colon Semicolon Dash-half EllipsisQuote-L Quote-R Paren-L Paren-R Space Other Rate in total PMs 40.0% PM 35.0% 30.0% 25.0% 20.0% 15.0% 10.0% 5.0% 0.0% 44 Besides, 53.9% of the marks appear in structura</context>
</contexts>
<marker>Scollon, Scollon, 1997</marker>
<rawString>Ron Scollon and Suzanne Wong Scollon. 1997. Point of view and citation: Fourteen Chinese and English versions of the ‘same’ news story. Text, 17 (1), 83-125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
</authors>
<title>The Potsdam Commentary Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL 2004 Workshop ‘Discourse Annotation’.</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="3049" citStr="Stede 2004" startWordPosition="454" endWordPosition="455"> main PMs in the corpus: Colon, Dash, Ellipses, Exclamation Mark, Question Mark, and Semicolon. Section 3 reports rhetorical patterns around these PMs. Section 4 is a discussion on the effectiveness of these PMs in comparison with Chinese cue phrases. Section 5 is a summary and Section 6 directions for future work. 2 Overview of Chinese RST treebank under construction 2.1 Corpus data For the purpose of language engineering and linguistic investigation, we are constructing a Chinese corpus comparable to the English WSJ-RST treebank and the German Potsdam Commentary Corpus (Carlson et al. 2003; Stede 2004). Texts in our corpus were downloaded from the official website of People’s Daily1, where important Caijingpinlun2 (CJPL) articles 1 www.people.com.cn. 2 Caijinpinglun (CJPL) in Chinese means “financial and business commentary”, and usually covers various topics in social economic life, such as fiscal policies, financial reports, 43 Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 43–48, Sydney, July 2006. c�2006 Association for Computational Linguistics by major media entities were republished. With over 400 authors and editors involved, our texts can be regarded as a good </context>
</contexts>
<marker>Stede, 2004</marker>
<rawString>Manfred Stede. 2004. The Potsdam Commentary Corpus. In Proceedings of the ACL 2004 Workshop ‘Discourse Annotation’. Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SUN Maosong</author>
<author>Dayang SHEN</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Chinese word segmentation without using lexicon and hand-crafted training data.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL’98.</booktitle>
<marker>Maosong, SHEN, Tsou, 1998</marker>
<rawString>SUN Maosong, Dayang SHEN, and Benjamin K. Tsou, 1998. Chinese word segmentation without using lexicon and hand-crafted training data. In Proceedings of COLING-ACL’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin K Tsou</author>
<author>Weijun Gao</author>
<author>T V Y Lai</author>
<author>S W K Chan</author>
</authors>
<title>Applying machine learning to identify Chinese discourse markers.</title>
<date>1999</date>
<booktitle>Proceedings of 1999 International Conference on Information Intelligence and Systems. p 548-53, 31 Oct.-3</booktitle>
<location>Bethesda, MD, USA.</location>
<contexts>
<context position="1827" citStr="Tsou et al. (1999)" startWordPosition="258" endWordPosition="261">e English RST treebank publicly available, and one RST-annotated German corpus on its way. Punctuation marks (PMs) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging, Word Sense Disambiguation, Near-duplicate detection, bilingual alignment (e.g. Chuang and Yeh, 2005), etc. Dale (1991) noticed the role of PMs in determining rhetorical relations. Say (1998) did a study on their roles in English discourse structure. Marcu (1997) and Corston-Oliver (1998) based their automatic discourse parser partially on PMs and other orthographical cues. Tsou et al. (1999) and Chan et al. (2000) use PMs to disambiguate candidate Discourse Markers for a Chinese summarization system. Reitter (2003) also used PMs to distinguish ATTRIBUTION and ELABORATION relations in his Feature-rich SVM rhetorical analysis system. All these inspired us to survey on the rhetorical patterns around Chinese PMs, so as to provide more direct a priori scores for the coarse rhetorical analyzer by Zhang et al. (2000) in their hybrid summarization system. This paper is organized into 5 parts: Section 2 gives an overview of a Chinese RST treebank under construction, and a survey on the sy</context>
</contexts>
<marker>Tsou, Gao, Lai, Chan, 1999</marker>
<rawString>Benjamin K.Tsou, Weijun Gao, T.V.Y Lai and S.W.K. Chan. 1999. Applying machine learning to identify Chinese discourse markers. Proceedings of 1999 International Conference on Information Intelligence and Systems. p 548-53, 31 Oct.-3 Nov. 1999, Bethesda, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan J Webster</author>
<author>Chunyu Kit</author>
</authors>
<title>Tokenization as the initial phase in NLP.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING&apos;92),</booktitle>
<pages>1--106</pages>
<location>Nantes, France.</location>
<contexts>
<context position="16463" citStr="Webster and Kit, 1992" startWordPosition="2448" endWordPosition="2451"> and RST applications as a major surface device. Unfortunately, Chinese cue phrases in natural texts are difficulty to identify automatically. As known, Chinese words are made up of 1, 2, or more characters, but there is no explicit word delimiter between any pair of adjacent words in a string of characters. Thus, they are not known before tokenization (“fenci” in Chinese, meaning “separating into words”, or “word segmentation” so as to recognize meaningful words out of possible overlaps or combinations). The task may sound simple, but has been the focus of considerable research efforts (e.g. Webster and Kit, 1992; Guo 1997; Wu, 2003). Since many cue phrases are made up of high-frequency characters (e.g. “ffq-ER” in “ffq -er” meaning “but/so/and”, “ 然 ffq -ran’er” meaning “but/however”, “Qffq-yin’er” meaning “so/because of this”, “ &amp;quot; -ergie meaing “in addition” etc.; “k-ci” in “krh-cihou” meaning “later/hereafter”, “Qk-yinci” meaning “as a result”, “EhkV来-youcikanlai” meaning “on this ground/hence”, etc.), a considerable amount of computation must be done before these cue phrases can ever been exploited. Apart from tokenization, POS and WSD are other necessary steps that should be taken before making u</context>
</contexts>
<marker>Webster, Kit, 1992</marker>
<rawString>Jonathan J. Webster and Chunyu Kit. 1992. Tokenization as the initial phase in NLP. In Proceedings of the 14th International Conference on Computational Linguistics (COLING&apos;92), pages 1,106-1,110, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WU Andi</author>
</authors>
<title>Chinese Word Segmentation in MSR-NLP.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing,</booktitle>
<location>Sapporo, Japan.</location>
<marker>Andi, 2003</marker>
<rawString>WU Andi. 2003. Chinese Word Segmentation in MSR-NLP. In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ZHANG Yimin</author>
<author>LU Ru-Zhan</author>
<author>SHEN Li-Bin</author>
</authors>
<title>A hybrid method for automatic Chinese discourse structure analysis.</title>
<date>2000</date>
<journal>Journal of Software, v</journal>
<volume>11</volume>
<pages>1527--33</pages>
<marker>Yimin, Ru-Zhan, Li-Bin, 2000</marker>
<rawString>ZHANG Yimin, LU Ru-Zhan and SHEN Li-Bin. 2000. A hybrid method for automatic Chinese discourse structure analysis. Journal of Software, v 11, n 11, Nov. 2000, p 1527-33.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>