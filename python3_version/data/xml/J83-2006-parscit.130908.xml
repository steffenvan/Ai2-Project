<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<author confidence="0.503043">
The FINITE STRING Newsletter
</author>
<affiliation confidence="0.675911">
Computational Linguistics Research
at the University of Pennsylvania
</affiliation>
<keyword confidence="0.385728875">
Faculty: Tim Finin, Aravind Joshi, Anthony Kroch,
Ellen Prince, Gillian Sankoff, Bonnie Webber, Scott
Weinstein, Ralph Weischedel (visiting).
Students: Debby Dahl (post-doc in Cognitive Science),
Anny Ewing, Julia Hirschberg, Sitaram Lanka, Eric
Mays, Kathy McCoy, Gopalan Nadathur, Susan Pint-
zuk, Martha Pollack, Robert Rubinoff, Ethel Schuster,
David Weir, Amy Zwarico.
</keyword>
<sectionHeader confidence="0.987067" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9999128">
This is a brief, informal and, because of Christmas
holidays, regrettably partial survey of current research
in computational linguistics at the University of Penn-
sylvania. Any inaccuracies can be blamed on the de-
partmental egg nog.
</bodyText>
<sectionHeader confidence="0.80846" genericHeader="method">
2. Extending the Range of Interactive Behavior
</sectionHeader>
<bodyText confidence="0.999946357142857">
Perhaps the most activity here in computational lin-
guistics is aimed at extending the kinds of behavior
that can be supported in interactions with data base
and expert systems. Elsewhere we have argued that
such systems have to do more than retrieve and pre-
sent appropriate facts and conclusions if they are to
satisfy their users&apos; real needs (Pollack, Hirschberg, and
Webber 1982). Out of this conviction have already
come systems able to recognize and respond to two
types of presupposition failures (Kaplan 1982, Mays
1980) and a system able to describe in Natural Lan-
guage what it knows about various entities (McKeown
1982). The following snippets indicate our current
efforts in this area.
</bodyText>
<subsectionHeader confidence="0.9935545">
2.1. Recognizing and Responding to Belief
Discrepancies
</subsectionHeader>
<bodyText confidence="0.999711272727273">
One reason for unsuccessful interactions is that the
participants fail to realize they hold different beliefs
about the world. Or if they do realize it, they fail to
do anything about it. As a result, each leaves the
interaction with very different ideas about what was
communicated. Such discrepancies differ widely with
respect to how easy they are to recognize and square
away. A disparity revealed on the surface by some
utterance or act may nevertheless be deeply embedded
in a person&apos;s whole system of beliefs and hence poten-
tially expensive to square away.
In the case of user-system interactions, as difficult
as the general problem may be, certain discrepancies
between the user&apos;s beliefs and those of the system may
be clearly revealed in the user&apos;s utterances to the sys-
tern and easily squared away. This has been a focus of
previous research here (Kaplan 1982, Mays 1980,
Webber and Mays 1983) and is currently the focus of
some new research on recognizing and responding to
object-related discrepancies (McCoy 1983). There are
several manifestations of these object-related discrep-
ancies
</bodyText>
<listItem confidence="0.92523">
1. the user&apos;s utterance describes an object in terms of
a class it doesn&apos;t belong to;
2. the utterance incorrectly attributes some property
to an object that it doesn&apos;t have; or
3. the utterance ascribes an impossible value to some
property the object does have.
For example,
S: Do you have any liquid assets?
</listItem>
<bodyText confidence="0.994080105263158">
U: I have a $5k money market certificate.
S: A money market certificate isn&apos;t a liquid asset.
Your money is tied up for several years in a money
market certificate. Do you mean a money market
account?
U: What&apos;s the interest rate on this stock?
S: Stocks don&apos;t have an interest rate. They may pay a
dividend periodically.
Our work to date in this area has concentrated on
factors involved in
■ constructing appropriate responses (that is, what
information to include, even if the system cannot
establish for certain what the underlying discrepan-
cy is), and
■ representing the system&apos;s beliefs and its model of
the user&apos;s beliefs in a well-motivated and well-
structured way.
This work is being done by Kathy McCoy, with super-
vision from Bonnie Webber and Aravind Joshi.
</bodyText>
<subsectionHeader confidence="0.999723">
2.2. Interacting with &amp;quot;Dynamic Data bases&amp;quot;
</subsectionHeader>
<bodyText confidence="0.985226916666667">
Most data bases are subject to change in the form of
&amp;quot;updates&amp;quot;. In the past, following an update, the pre-
vious information was either lost, archived or merged
into some summary information. Now, optical disk
technology can enable an organization to keep this
information accessible. Such a data base has been
called a &amp;quot;transactional&amp;quot; or &amp;quot;historical data base&amp;quot;
(Clifford and Warren 1983). Very often, there are
constraints on possible changes to the data base. How-
ever, this knowledge of &amp;quot;possible futures&amp;quot; is generally
only available as mechanically applied update con-
straints — the system cannot reason with it. In con-
trast, we have been working on enabling a system to
reason about how its data base has changed up to now
and how it can change in the future. We have termed
American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 95
The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania
this type of historical data base system a &amp;quot;dynamic
data base system&amp;quot; and have described its implementa-
tion using a branching time temporal logic (Ari, Man-
na, and Pueuli 1981) in Mays (1982, 1983).
In the context of dynamic data bases, we are devel-
oping support for several valuable interactive func-
tions, including enabling the system
</bodyText>
<listItem confidence="0.555455692307692">
■ to recognize and square away beliefs that reflect
ignorance of some event or its consequences
(Webber and Mays 1983) — for example,
U: Is John registered for CSE220?
S: No, he can&apos;t be, because he already has advance
placement credit for it.
■ to offer to monitor for additional information it will
provide to the user if and when it learns of it
(Mays 1983) — for example,
U: Did John take CSE110 last term?
S: No. Do you want me to let you know if he does
take it?
U: Did John pass CSE110?
</listItem>
<bodyText confidence="0.99350125">
S: No, the semester hasn&apos;t ended, so he hasn&apos;t re-
ceived a grade yet. Shall I let you know then if
he has passed CSE110?
To perform these useful services, a system must be
able to recognize what sequences of events are possi-
ble or what additional information it might really ac-
quire. Otherwise, it might not distinguish between the
following two situations, in which the same response is
clearly not appropriate:
U: Is the JFK within 15 miles of San Francisco?
S: No, but shall I let you know when it is?
U: Is Santa Cruz within 15 miles of San Francisco?
S: No, but shall I let you know when it is?
This work is being done by Eric Mays, with supervi-
sion from Aravind Joshi, Bonnie Webber, and Scott
Weinstein.
</bodyText>
<subsectionHeader confidence="0.999114">
2.3. &amp;quot;Expert Answers&amp;quot;
</subsectionHeader>
<bodyText confidence="0.999804">
To date, expert systems and help systems alike have
been banking on an assumption that the user knows
what advice he/she needs and knows how to ask for
it. As the audience for such systems grows, this as-
sumption becomes less and less warranted: people ask
for information they believe will help them, when in
point of fact, it won&apos;t (or it won&apos;t do so efficiently).
What a real expert does under such circumstances is
answer the question the user should have asked, possi-
bly after interacting with the user to establish what
that question should be. For example, consider some-
one using one of the DEC-20 mail systems. Part way
through creating a message, he accidently types a
Control-Z, whose effect is to end message creation
and return to prompt level. He then asks someone
how to delete a control character, but is told that he
can&apos;t — control characters are not treated as text. So
he proceeds to recreate his message.
If this user had consulted a real expert, the expert
would probably have recognized from his request —
&amp;quot;How do you delete a Control-Z?&amp;quot; — that the user had
typed a Control-Z unintentionally and wanted to con-
tinue what he was doing, probably creating a message.
While there is no way to delete a Control-Z, there is a
way to return to composing a message — that is, by
editing it. The expert&apos;s response would inform the
user that to continue composing a message the user
can enter the editor from where he is and add directly
to the message fragment.
The goal of our work here, as reported in Pollack
(1983), is to enable an expert system or help system
to deduce, from an incomplete or inappropriate query,
what advice is actually needed and thereby generate
appropriate responses to their users. Thus far, we
have mapped out the sequence of processes involved
in generating such responses and have experimented
with at least one representation system (a type of dy-
namic logic, Rosenschein 1981) in which to do the
reasoning involved. This work is being done by Mar-
tha Pollack, with supervision from Bonnie Webber and
Aravind Joshi.
</bodyText>
<subsectionHeader confidence="0.998706">
2.4. &amp;quot;Expert Questions&amp;quot;
</subsectionHeader>
<bodyText confidence="0.998876857142857">
One aspect of user-expert system interactions involves
the system attempting to get from the user the infor-
mation it needs to help solve his/her problem. The
most commonly used way of getting information is via
&amp;quot;menus&amp;quot; — essentially, multiple choice questions.
However, there are several problems with relying on
menus:
</bodyText>
<listItem confidence="0.975096833333333">
• The user may not understand either the question or
the menu options.
• The user may be influenced by the options — that is,
he/she assumes one of them must be appropriate to
his/her case, so he/she bends the facts to fit the
options.
• The user may not be satisfied with any of the op-
tions — that is, none seems appropriate to his/her
case.
• The user may want to qualify his/her response —
that is, he/she may feel that simply agreeing to a
particular option will be misconstrued.
</listItem>
<bodyText confidence="0.996364666666667">
In all these cases, the reliability of the user&apos;s response
is called into question.
Our research in this area attempts to provide users
with as much freedom in responding to questions as
other systems provide users in asking them. This in-
volves at least the following:
</bodyText>
<listItem confidence="0.94223825">
1. providing the user with more help when he/she
doesn&apos;t know how to respond.
2. allowing users more leeway in how they provide the
requested information, along with any additional
</listItem>
<bodyText confidence="0.969123823529412">
96 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983
The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania
information they believe relevant and want to con-
vey as well.
Work on the first area is just getting started, with
the implementation of a Prolog-based expert system
that can reason about whether to ask for some infor-
mation or try to deduce it. If it asks, but the user
cannot answer, then the system has recourse to deduc-
ing the information or — and this is speculation — find-
ing a way around it. This work is being done by Rob-
ert Rubinoff under the supervision of Tim Finin.
The next section describes briefly some research
under way that is both of general interest for question-
answering systems and of particular application for
allowing the user more leeway in responding to ques-
tions.
</bodyText>
<subsectionHeader confidence="0.9956485">
2.5. Comprehension and Use of Scalar lmplicature
in Question Answering
</subsectionHeader>
<bodyText confidence="0.99951575">
A major problem in Natural Language processing is
capturing the fact that hearers derive more from an
utterance than its syntax and semantics encode. Indi-
rect responses to yes/no questions, for example, often
permit inference of both the direct response and addi-
tional implicit information. For example, in the fol-
lowing Q may infer that R&apos;s direct response to her
query
</bodyText>
<listItem confidence="0.9360245">
Q: Has Jones taken all his medication?
R: He&apos;s had some of it.
</listItem>
<bodyText confidence="0.991307448275862">
is either &apos;no&apos; or &apos;I don&apos;t know&apos;. She will also infer that
R believes there may be some prescribed medicine
Jones has not taken.
Models of formal reasoning cannot explain such
inferences: In standard logic, if there is some medi-
cine that John has taken, it does not imply that it is
not all his medicine that he has taken. Studies of indi-
rect responses have generally sought to explain these
inferences in terms of particular higher goals of speak-
er and hearer (Hobbs and Robinson 1979). However,
linguistic pragmatics provides a more general explana-
tion in the concept of scalar implicature. Our goal in
this area is the formalization of scalar implicature to
facilitate the interpretation and generation of coopera-
tive responses in human-machine interaction
(Hirschberg 1984).
The concept of conversational implicature comes
from Grice (1975): An utterance conversationally
implicates a proposition P when it conveys P by virtue
of the Conversational Principle. Following Grice,
Horn (1972) observed that, when an utterance em-
ploys a scalar x on some scale m defined by semantic
entailment [W semantically entails T iff T is true
whenever W is.], such that y is less than x and x is less
than z, then x represents the highest value on m con-
sistent with S&apos;s observance of Grice&apos;s Maxim of Quali-
ty: &amp;quot;Be truthful.&amp;quot; Any proposition formed by substi-
tuting in P some z that is higher on m than x is there-
by marked by S either as not believed to be the case or
believed not to be the case. Any proposition formed
by substituting in P some y lower on m than x will be
true by entailment. Gazdar (1979) later termed this
phenomenon &amp;quot;Scalar Quantity Implicature&amp;quot; (SQI).
We have found Horn&apos;s definition is too limited for
our purposes. Utterances referencing entities, attri-
butes, events, or states that may be viewed as ordered
by some metric, such as set/set-member, process
stages, or ISA hierarchy, permit similar implicatures:
Q: Has Jones registered yet?
R: He&apos;s filled out the insurance forms.
Here registration and filling out insurance forms are
successive stages in a hospital admissions process. By
his response, R conveys implicitly that either he
doesn&apos;t know the direct answer to the question or the
direct answer is no.
By expanding the definition of scale to include
additional metrics, extending the notion of scalar im-
plicature to define implicatures resulting from the de-
nial of a scalar, and recognizing the correspondence
between responses referencing a higher value and re-
sponses referencing a lower value, one can develop a
powerful tool for deriving implicit information from
scalar assertions (Hirschberg 1984). Systems may
then use scalar implicature to derive inferences from
user assertions and to avoid conveying unwanted infer-
ences themselves. This work is being done by Julia
Hirschberg, with supervision from Bonnie Webber and
Aravind Joshi.
</bodyText>
<subsectionHeader confidence="0.999787">
2.6 Avoiding false inferences
</subsectionHeader>
<bodyText confidence="0.968602666666667">
In his 1982 paper on Mutual Belief, Joshi shows that
one of Grice&apos;s (1975) maxims, the Maxim of Quality:
Be truthful
doesn&apos;t go far enough towards accounting for coopera-
tive conversational behavior vis-a-vis conveying infor-
mation. He proposes the following revision:
Do not say anything which may imply for the
hearer something that you, the speaker, believe
to be false.
We are now working on applying this revised principle
to question answering. In particular, the goals of the
research are:
</bodyText>
<listItem confidence="0.934640444444445">
1. to characterize tractable cases in which the system
as respondent (R) can anticipate the possibility of
the user/questioner (Q) drawing false conclusions
from its response and can alter or expand its re-
sponse so as to prevent it happening;
2. to develop a formal method for computing the pro-
jected inferences that Q may draw from a particu-
lar response, identifying those factors whose pres-
ence or absence catalyzes the inferences;
</listItem>
<bodyText confidence="0.9557605">
American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 97
The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania
3. to enable the system to generate modifications of
its response that can defuse possible false inferenc-
es and that may provide additional useful informa-
tion as well.
Thus far, we have been focussing on one class of
false inferences — ones that follow from over-
generalizing the situation to which the response is
applicable. We have been attempting to identify ways
in which the questioner might take the response too
generally and to characterize the circumstances under
which he/she might do so. This then leads to a char-
acterization of the appropriate information to include
in a response, to block any false conclusions that
might so follow. What we see is that, if a system is to
be able to anticipate and prevent false inferences that
might be drawn from its response, it must be able to
reason about, inter alia, shared assumptions, the goals
of the user that underlie the question, &amp;quot;overloaded
terms&amp;quot;, and expectations raised by Grice&apos;s Coopera-
tive Principle and its maxims.
This work is being done by Aravind Joshi, Bonnie
Webber and Ralph Weischedel.
</bodyText>
<sectionHeader confidence="0.635294" genericHeader="method">
3. Aids in Creating Data Models
</sectionHeader>
<bodyText confidence="0.999915681818182">
The goal of this research is to understand how struc-
tural descriptions can be learned — in particular, how
they can be hypothesized from input data consisting of
a finite set of Natural Language queries. One advan-
tage of looking at queries is that they give implicit
cues about what form the structure should take to
provide an adequate response. For example, consider
the query,
Which employees work on hardware and software
projects?
The relation between employee and project can be
either 1-1 or 1-many, information that must be encod-
ed in the structural description to provide an adequate
response. If the relation is 1-1, then the response will
contain all employees who work on hardware projects
and all employees who work on software projects. If
it is 1-many, then the response will contain all employ-
ees who work on both hardware and software projects
simultaneously.
Thus the cues to data base structure that queries
provide relieve the user of the burden of explicitly
mentioning all the nitty-gritty details. A second ad-
vantage to acquiring the data base structure from ex-
pected queries is that often the user starts off with a
fuzzy notion of the domain but with a slightly better
grasp on the requirements the data base schema should
satisfy — that is, the range of queries it should be able
to provide responses to. Hence, a collection of fore-
casted queries justifies as the input data.
We are developing a learning procedure (LP) that
maps the incoming input data onto a set of consistent
hypotheses. To come up with a single hypothesis that
best accounts for the data, LP will be guided by no-
tions such as simplicity and naturalness, and above all,
by feedback from the user. The tack here is for LP to
narrow the number of possibilities as much as it can
from the available information. When it requires fur-
ther information to proceed, the user is called upon to
provide that information. In this manner the learning
procedure succeeds in arriving at the hypothesis that
best fits the data.
This work is being done by Sitaram Lanka under
the supervision of Aravind Joshi and Scott Weinstein.
A technical report is in preparation.
</bodyText>
<sectionHeader confidence="0.985734" genericHeader="method">
4. Aids for Second Language Learning
</sectionHeader>
<bodyText confidence="0.999839580645161">
People often rely heavily on their previous knowledge
when learning a new skill. This previous knowledge
can sometimes lead to misconceptions that hinder
learning. By modelling users&apos; previous knowledge and
resulting expectations, a cooperative Computer Assist-
ed Instruction (CAI) system can better predict errors
and thereby detect and correct them more easily. In
particular, when tutoring a user in a new Natural Lan-
guage, a CAI system might compare the user&apos;s native
language with the one to be learned to identify analo-
gous patterns. These patterns can then be used to
predict, detect and re-mediate errors.
We are building an interactive system, called
2WORD, that exploits this technique in teaching Eng-
lish as a second language. 2WORD concentrates on
the acquisition of English two-word verbs, such as
&amp;quot;turn up&amp;quot;, &amp;quot;dream about&amp;quot;, &amp;quot;talk over&amp;quot;, etc. These
verbs comprise a lexical verb and a modifier, used
together to produce a sentence that is both syntactical-
ly and semantically different from a sentence contain-
ing only the lexical verb. In addition, English two-
word verbs do not map simply to two-word verbs in
other Natural Languages. Even more insidious is the
fact that a particular verb and modifier may not al-
ways function as a two-word verb or the same two-
word verb. For example, in (a) &amp;quot;turn&amp;quot; is the verb and
&amp;quot;up the road&amp;quot; is just a prepositional phrase like &amp;quot;to
the left&amp;quot;. In (b), &amp;quot;turn up&amp;quot; is an intransitive two-
word verb (wherein &amp;quot;up&amp;quot; is not a movable particle),
while in (c) it is transitive - &amp;quot;up&amp;quot; can appear after the
object, as in (d).
</bodyText>
<listItem confidence="0.99928325">
(a) Raquel turned up the road.
(b) Raquel turned up at our house this morning.
(c) Raquel turned up the cuffs of her trousers.
(d) Raquel turned the cuffs up on her trousers.
</listItem>
<bodyText confidence="0.9985622">
The consequence is that two-word verbs are particu-
larly difficult for non-native speakers to acquire, thus
providing a rich area for CAI. This work is being done
by Ethel Schuster, with supervision from Bonnie Web-
ber and Tim Finin.
</bodyText>
<note confidence="0.918372">
98 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983
The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania
</note>
<sectionHeader confidence="0.424921" genericHeader="method">
5. A Formal Account of Intra-sentential
</sectionHeader>
<subsectionHeader confidence="0.801908">
Code-Switching
</subsectionHeader>
<bodyText confidence="0.99825004">
This project involves both an investigation into the
syntactic constraints on intra-sentential switching from
one language to another in the speech of bilinguals —
for example,
Khob gered Idish in Shanghai TOO.
I spoke Yiddish in Shanghai too.
and work on a formal framework for the production
and recognition of such sentences. Little is known
about their syntax, production, or comprehension. A
number of formal theories have been proposed, but
none is based on a corpus of naturally-occurring to-
kens of the phenomenon. In the study of syntactic
constraints, we have been testing hypotheses against
statistical analyses of a corpus of naturally-occurring
code-switching tokens in transcripts of interviews with
Yiddish-English, Spanish-English, Polish-English, and
Yiddish-Spanish bilinguals. The formal framework we
have been working on consists of two grammatical
systems and a mechanism for switching between the
two. Syntactic constraints are then explained in terms
of constraints on the switching mechanism. The facul-
ty members involved in this study are Aravind Joshi,
Ellen Prince and Gillian Sankoff. Students working
with them include Anny Ewing, Susan Pintzuk, and
Ethel Schuster.
</bodyText>
<sectionHeader confidence="0.8350795" genericHeader="method">
6. A Unified Account of Referring Expressions in
Discourse
</sectionHeader>
<bodyText confidence="0.999888615384615">
This research is aimed at sorting out some of the con-
fusion about the roles that syntactic, semantic and
pragmatic factors play in the use and interpretation of
definite descriptions and referring expressions in dis-
course. Out of this we hope will come a theoretical
framework that can account for a variety of discourse
phenomena in which the three interact — for example,
various types of ellipses. This work is being done by
Aravind Joshi and Scott Weinstein, together with Bar-
bara Grosz from SRI International, and is reported in
Grosz, Joshi, and Weinstein (1983). It brings together
work on global coherence — the way larger segments
of discourse fit together (Grosz 1982); local coherence
</bodyText>
<listItem confidence="0.670495">
— the way individual sentences bind together to form
larger discourse segments (Sidner 1982); and centering
— a local focusing process involving the single entity
that an individual utterance most centrally concerns,
that works to integrate an utterance into a discourse
(Joshi and Weinstein 1981). The work is of particular
significance for language generation, where one does
not want to call upon powerful inference mechanisms
to guide or bless the speaker&apos;s use of a particular ref-
erring phrase.
7. Grammar Formalisms — TAGs
</listItem>
<bodyText confidence="0.985022851851852">
During the last few years there has been vigorous ac-
tivity in constructing highly constrained grammatical
systems by eliminating the transformational component
either totally or partially (Kaplan and Bresnan 1983,
Pullum and Gazdar 1982, Peters and Ritchie 1982).
There is increasing recognition of the fact that the
dependencies that transformational grammars have
tried to account for can be captured satisfactorily by
classes of rules that are non-transformational and at
the same time highly constrained in terms of the
classes of grammars and languages that they define.
Two types of dependencies are especially impor-
tant: subcategorization and filler-gap dependencies. In
fact, one motivation for transformations was to ac-
count for unbounded dependencies. The so-called
&amp;quot;non-transformational grammars&amp;quot; account for un-
bounded dependencies in different ways. In the for-
malism under study here (Joshi 1983) — tree-adjoining
grammar (TAG) — unboundedness is achieved by fac-
toring the dependencies and recursion in a novel and,
we believe, linguistically interesting manner. All de-
pendencies are defined on a finite set of basic struc-
tures (trees) that are bounded. Unboundedness is
then a corollary of a particular composition operation,
called adjoining, that preserves dependencies.
So far we have described TAGs, characterized some
of their properties and compared them with other non-
transformational grammars (Joshi 1983). Currently
we are looking at the issue of linguistic relevance, both
for language analysis and generation. This work is
being done by Aravind Joshi and Tony Kroch.
8. Query-Driven Labelling of Objects in 3-D Scenes
If people are to interact comfortably and effectively
with perceptual systems (visual, tactile, etc.), they
must be provided with a better way of referring to
objects and parts of scenes than with respect to a co-
ordinate system — &amp;quot;the object centered at point
&lt;x,y&gt;&amp;quot;. A better means is in terms of labels: for
example, in a street scene, one can label things as
buildings, streets, cars, etc. — not only objects but
parts of objects as well, like the median line down a
street, the entrance to a building, etc. (Pointing is
also a possibility but for scenes of any complexity
must be augmented by a reference facility in the form
of labels/descriptions.)
We are looking at the problem of assigning
labels/descriptions and recognizing their referents in
the context of a query driven image understanding
system (being developed by faculty members Ruzena
Bajcsy and Sam Goldwasser) permitting queries posed
in Natural Language. In response to queries, the sys-
tem will automatically generate strategies for recogniz-
ing observable objects and relationships. It is envi-
American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 99
The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania
sioned as realizing a true interaction between a
textual/conceptual data base and a pictorial data base.
If a system is to be able to label objects and refer
to them correctly, it must be able to make use of its
sensory data, together with knowledge of the conse-
quences (for further interpretation and labelling) of a
particular label choice. There are several problems we
have begun to look at. The first has to do with the
specificity of the labelling: an object labelled in re-
sponse to one query may have to be relabelled in
terms of its parts for another. On the other hand,
separately labelled objects may later have to be rela-
belled as a single object. One should be able to take
advantage of this, rather than starting from scratch
each time. A second problem has to do with the fact
that what is conceptually a part of an object is not
necessarily something defined by natural segmentation,
so a vision system must have other means of partition-
ing objects at its disposal. Finally, the appropriate
way to describe objects is not simply a function of
their geometic properties and relationships to one an-
other. Correct usage depends in part on idealized
properties of an object, once its identity is known.
This work is just getting off the ground; it is being
done by Aravind Joshi and graduate student Amy
Zwarico.
</bodyText>
<sectionHeader confidence="0.990118" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999833759493671">
Ben Ari, M.; Manna, Z.; and Pneuli, A. 1981 The Temporal Logic
of Branching Time. In Eighth Annual ACM Symposium on Prin-
ciples of Programming Languages. Williamsburg, Virginia.
Clifford, J. and Warren, D. 1983 Formal Semantics for Time in
Data bases. ACM Trans. on Data Base Systems 8(2): 214-254.
Gazdar, G. 1979 A Solution to the Projection Problem. In Oh,
C.-K. and Dinneen, D., Eds., Syntax and Semantics. Academic
Press, New York, New York: 57-90.
Grice, H.P. 1975 Logic and Conversation. In Cole, P. and Mor-
gan, JL., Eds., Syntax and Semantics. Acadmic Press, New
York, New York.
Grosz, B.J. 1982 Focusing and Description in Natural Language
Dialogues. In Joshi, A.; Webber, B.; and Sag, I., Eds., Elements
of Discourse Understanding. Cambridge University Press, Cam-
bridge, England.
Grosz, B.; Joshi, AK.; and Weinstein, S. 1983 Providing a Unified
Account of Definite Noun Phrases in Discourse. In Proc. 21st
Annual Meeting, Association for Computational Linguistics. Cam-
bridge, Massachusetts: 44-50.
Hirschberg, J. 1984 Scalar Implicature and Indirect Responses in
Question-Answering. In Proc. CSCSI-84. London, Ontario.
(Submitted for presentation.)
Hobbs, J. and Robinson, J. 1979 Why Ask? Discourse Processes 2.
Horn, L.R. 1972 On the Semantic Properties of Logical Operators
in English. Ph.D. thesis, University of California at Los Ange-
les.
Joshi, A.K. 1982 Mutual Beliefs in Question Answering Systems.
In Smith, N., Ed., Mutual Belief. Academic Press, New York,
New York.
Joshi, A.K. 1983 Factoring Recursion and Dependencies. Proc.
21st Annual Meeting, Association for Computational Linguistics.
Cambridge, Massachusetts: 7-15.
Joshi, A.K. and Weinstein, S. 1981 Control of Inference: Center-
ing. In Proc. 1981 Meeting, Int&apos;l. Joint Conf. on Artificial
Intelligence. Vancouver, Canada: 385-387.
Kaplan, J. 1982 Cooperative Responses from a Portable Natural
Language Data Base Query System. In Brady, M., Ed., Compu-
tational Models of Discourse. MIT Press, Cambridge, Massachu-
setts.
Kaplan, R. and Bresnan, J. 1983 Lexical Funal Grammar: A For-
mal System for Grammatical Representation. In Bresnan, J.,
Ed., The Mental Representation of Grammatical Relations. MIT
Press, Cambridge, Massachusetts.
Mays, E. 1980 Failures in Natural Language Systems: Application
to Data Base Query Systems. In Proc. First National Conference
on Artificial Intelligence (AAAI). Stanford, California.
Mays, E. 1982 Monitors as Responses to Questions: Determining
Competence. In Proc. 1982 National Conference on Artificial
Intelligence. Pittsburgh, Pennsylvania.
Mays, E. 1983 A Modal Temporal Logic for Reasoning about
Change. In Proc. 1983 Assoc. for Computational Linguistics
Conference. Cambridge, Massachusetts.
McCoy, K. 1983 Correcting Misconceptions: What to Say. In
CHI&apos;83 Conference Human Factors in Computing Systems. Cam-
bridge, Massachusetts.
McKeown, K. 1982 Generating Natural Language Text in Re-
sponse to Questions About Data Base Structure. Ph.D. thesis,
University of Pennsylvania.
Peters, S. and Ritchie, R. 1982 Phrase Linking Grammars. Techni-
cal Report, Department of Linguistics, University of Texas.
Pollack, M.; Hirschberg, J.; and Webber, B. 1982 User Participa-
tion in the Reasoning Processes of Expert Systems. In Proc.
AAAI-82. Carnegie-Mellon University, Pittsburgh, Pennsylva-
nia. A longer version appears as Technical Report CIS-82-9,
Department of Computer and Information Science, University
of Pennsylvania.
Pollack, M. 1983 A Framework for Providing Appropriate Advice.
Technical Report CIS-83-28, Computer and Information Sci-
ence, University of Pennsylvania, Philadelphia, Pennsylvania.
Pullum, G. and Gazdar, G. 1982 Natural Languages and Context-
Free Languages. Linguistics and Philosophy 4: 471-504.
Rosenschein, S.J. 1981 Plan Synthesis: A Logical Perspective. In
Proceedings of the 7th Conference. IJCAI: 331-337.
Sidner, C.L. 1982 Focusing in the Comprehension of Definite
Anaphora. In Brady, M., Ed., Computational Models of
Discourse. MIT Press, Cambridge, Massachusetts.
Webber, B. and Mays. E. 1983 Varieties of User Misconceptions:
Detection and Correction. In Proc. IJCAI-8. Karlsruhe, Ger-
many.
</reference>
<page confidence="0.647205">
100 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.085975">
<title confidence="0.87789">The FINITE STRING Newsletter Computational Linguistics Research at the University of Pennsylvania</title>
<author confidence="0.723185">Faculty Tim Finin</author>
<author confidence="0.723185">Aravind Joshi</author>
<author confidence="0.723185">Anthony Kroch</author>
<author confidence="0.723185">Ellen Prince</author>
<author confidence="0.723185">Gillian Sankoff</author>
<author confidence="0.723185">Bonnie Webber</author>
<author confidence="0.723185">Scott</author>
<affiliation confidence="0.7134725">Weinstein, Ralph Weischedel (visiting). Students: Debby Dahl (post-doc in Cognitive Science),</affiliation>
<address confidence="0.846729">Anny Ewing, Julia Hirschberg, Sitaram Lanka, Eric</address>
<author confidence="0.704129">Kathy McCoy Mays</author>
<author confidence="0.704129">Gopalan Nadathur</author>
<author confidence="0.704129">Susan Pint-</author>
<affiliation confidence="0.894013">zuk, Martha Pollack, Robert Rubinoff, Ethel Schuster,</affiliation>
<address confidence="0.683306">David Weir, Amy Zwarico.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ben Ari</author>
<author>M Manna</author>
<author>Z</author>
<author>A Pneuli</author>
</authors>
<title>The Temporal Logic of Branching Time.</title>
<date>1981</date>
<booktitle>In Eighth Annual ACM Symposium on Principles of Programming Languages.</booktitle>
<location>Williamsburg, Virginia.</location>
<marker>Ari, Manna, Z, Pneuli, 1981</marker>
<rawString>Ben Ari, M.; Manna, Z.; and Pneuli, A. 1981 The Temporal Logic of Branching Time. In Eighth Annual ACM Symposium on Principles of Programming Languages. Williamsburg, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clifford</author>
<author>D Warren</author>
</authors>
<title>Formal Semantics for Time in Data bases.</title>
<date>1983</date>
<journal>ACM Trans. on Data Base Systems</journal>
<volume>8</volume>
<issue>2</issue>
<pages>214--254</pages>
<contexts>
<context position="4125" citStr="Clifford and Warren 1983" startWordPosition="657" endWordPosition="660">the system&apos;s beliefs and its model of the user&apos;s beliefs in a well-motivated and wellstructured way. This work is being done by Kathy McCoy, with supervision from Bonnie Webber and Aravind Joshi. 2.2. Interacting with &amp;quot;Dynamic Data bases&amp;quot; Most data bases are subject to change in the form of &amp;quot;updates&amp;quot;. In the past, following an update, the previous information was either lost, archived or merged into some summary information. Now, optical disk technology can enable an organization to keep this information accessible. Such a data base has been called a &amp;quot;transactional&amp;quot; or &amp;quot;historical data base&amp;quot; (Clifford and Warren 1983). Very often, there are constraints on possible changes to the data base. However, this knowledge of &amp;quot;possible futures&amp;quot; is generally only available as mechanically applied update constraints — the system cannot reason with it. In contrast, we have been working on enabling a system to reason about how its data base has changed up to now and how it can change in the future. We have termed American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 95 The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania this type of historical data base system</context>
</contexts>
<marker>Clifford, Warren, 1983</marker>
<rawString>Clifford, J. and Warren, D. 1983 Formal Semantics for Time in Data bases. ACM Trans. on Data Base Systems 8(2): 214-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>A Solution to the Projection Problem. In</title>
<date>1979</date>
<pages>57--90</pages>
<publisher>Academic Press,</publisher>
<location>New York, New York:</location>
<contexts>
<context position="12543" citStr="Gazdar (1979)" startWordPosition="2131" endWordPosition="2132">orn (1972) observed that, when an utterance employs a scalar x on some scale m defined by semantic entailment [W semantically entails T iff T is true whenever W is.], such that y is less than x and x is less than z, then x represents the highest value on m consistent with S&apos;s observance of Grice&apos;s Maxim of Quality: &amp;quot;Be truthful.&amp;quot; Any proposition formed by substituting in P some z that is higher on m than x is thereby marked by S either as not believed to be the case or believed not to be the case. Any proposition formed by substituting in P some y lower on m than x will be true by entailment. Gazdar (1979) later termed this phenomenon &amp;quot;Scalar Quantity Implicature&amp;quot; (SQI). We have found Horn&apos;s definition is too limited for our purposes. Utterances referencing entities, attributes, events, or states that may be viewed as ordered by some metric, such as set/set-member, process stages, or ISA hierarchy, permit similar implicatures: Q: Has Jones registered yet? R: He&apos;s filled out the insurance forms. Here registration and filling out insurance forms are successive stages in a hospital admissions process. By his response, R conveys implicitly that either he doesn&apos;t know the direct answer to the questi</context>
</contexts>
<marker>Gazdar, 1979</marker>
<rawString>Gazdar, G. 1979 A Solution to the Projection Problem. In Oh, C.-K. and Dinneen, D., Eds., Syntax and Semantics. Academic Press, New York, New York: 57-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic and Conversation. In</title>
<date>1975</date>
<publisher>Acadmic Press,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="11792" citStr="Grice (1975)" startWordPosition="1988" endWordPosition="1989"> that John has taken, it does not imply that it is not all his medicine that he has taken. Studies of indirect responses have generally sought to explain these inferences in terms of particular higher goals of speaker and hearer (Hobbs and Robinson 1979). However, linguistic pragmatics provides a more general explanation in the concept of scalar implicature. Our goal in this area is the formalization of scalar implicature to facilitate the interpretation and generation of cooperative responses in human-machine interaction (Hirschberg 1984). The concept of conversational implicature comes from Grice (1975): An utterance conversationally implicates a proposition P when it conveys P by virtue of the Conversational Principle. Following Grice, Horn (1972) observed that, when an utterance employs a scalar x on some scale m defined by semantic entailment [W semantically entails T iff T is true whenever W is.], such that y is less than x and x is less than z, then x represents the highest value on m consistent with S&apos;s observance of Grice&apos;s Maxim of Quality: &amp;quot;Be truthful.&amp;quot; Any proposition formed by substituting in P some z that is higher on m than x is thereby marked by S either as not believed to be </context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Grice, H.P. 1975 Logic and Conversation. In Cole, P. and Morgan, JL., Eds., Syntax and Semantics. Acadmic Press, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
</authors>
<title>Focusing and Description in Natural Language Dialogues. In</title>
<date>1982</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="22343" citStr="Grosz 1982" startWordPosition="3726" endWordPosition="3727">he roles that syntactic, semantic and pragmatic factors play in the use and interpretation of definite descriptions and referring expressions in discourse. Out of this we hope will come a theoretical framework that can account for a variety of discourse phenomena in which the three interact — for example, various types of ellipses. This work is being done by Aravind Joshi and Scott Weinstein, together with Barbara Grosz from SRI International, and is reported in Grosz, Joshi, and Weinstein (1983). It brings together work on global coherence — the way larger segments of discourse fit together (Grosz 1982); local coherence — the way individual sentences bind together to form larger discourse segments (Sidner 1982); and centering — a local focusing process involving the single entity that an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous act</context>
</contexts>
<marker>Grosz, 1982</marker>
<rawString>Grosz, B.J. 1982 Focusing and Description in Natural Language Dialogues. In Joshi, A.; Webber, B.; and Sag, I., Eds., Elements of Discourse Understanding. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>AK Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Providing a Unified Account of Definite Noun Phrases in Discourse.</title>
<date>1983</date>
<booktitle>In Proc. 21st Annual Meeting, Association for Computational Linguistics.</booktitle>
<pages>44--50</pages>
<location>Cambridge, Massachusetts:</location>
<marker>Grosz, Joshi, Weinstein, 1983</marker>
<rawString>Grosz, B.; Joshi, AK.; and Weinstein, S. 1983 Providing a Unified Account of Definite Noun Phrases in Discourse. In Proc. 21st Annual Meeting, Association for Computational Linguistics. Cambridge, Massachusetts: 44-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>Scalar Implicature and Indirect Responses in Question-Answering.</title>
<date>1984</date>
<booktitle>In Proc. CSCSI-84.</booktitle>
<location>London, Ontario.</location>
<note>(Submitted for presentation.)</note>
<contexts>
<context position="11725" citStr="Hirschberg 1984" startWordPosition="1979" endWordPosition="1980">t explain such inferences: In standard logic, if there is some medicine that John has taken, it does not imply that it is not all his medicine that he has taken. Studies of indirect responses have generally sought to explain these inferences in terms of particular higher goals of speaker and hearer (Hobbs and Robinson 1979). However, linguistic pragmatics provides a more general explanation in the concept of scalar implicature. Our goal in this area is the formalization of scalar implicature to facilitate the interpretation and generation of cooperative responses in human-machine interaction (Hirschberg 1984). The concept of conversational implicature comes from Grice (1975): An utterance conversationally implicates a proposition P when it conveys P by virtue of the Conversational Principle. Following Grice, Horn (1972) observed that, when an utterance employs a scalar x on some scale m defined by semantic entailment [W semantically entails T iff T is true whenever W is.], such that y is less than x and x is less than z, then x represents the highest value on m consistent with S&apos;s observance of Grice&apos;s Maxim of Quality: &amp;quot;Be truthful.&amp;quot; Any proposition formed by substituting in P some z that is high</context>
<context position="13574" citStr="Hirschberg 1984" startWordPosition="2288" endWordPosition="2289">and filling out insurance forms are successive stages in a hospital admissions process. By his response, R conveys implicitly that either he doesn&apos;t know the direct answer to the question or the direct answer is no. By expanding the definition of scale to include additional metrics, extending the notion of scalar implicature to define implicatures resulting from the denial of a scalar, and recognizing the correspondence between responses referencing a higher value and responses referencing a lower value, one can develop a powerful tool for deriving implicit information from scalar assertions (Hirschberg 1984). Systems may then use scalar implicature to derive inferences from user assertions and to avoid conveying unwanted inferences themselves. This work is being done by Julia Hirschberg, with supervision from Bonnie Webber and Aravind Joshi. 2.6 Avoiding false inferences In his 1982 paper on Mutual Belief, Joshi shows that one of Grice&apos;s (1975) maxims, the Maxim of Quality: Be truthful doesn&apos;t go far enough towards accounting for cooperative conversational behavior vis-a-vis conveying information. He proposes the following revision: Do not say anything which may imply for the hearer something tha</context>
</contexts>
<marker>Hirschberg, 1984</marker>
<rawString>Hirschberg, J. 1984 Scalar Implicature and Indirect Responses in Question-Answering. In Proc. CSCSI-84. London, Ontario. (Submitted for presentation.) Hobbs, J. and Robinson, J. 1979 Why Ask? Discourse Processes 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Horn</author>
</authors>
<title>On the Semantic Properties of Logical Operators in English.</title>
<date>1972</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California at Los Angeles.</institution>
<contexts>
<context position="11940" citStr="Horn (1972)" startWordPosition="2009" endWordPosition="2010">lain these inferences in terms of particular higher goals of speaker and hearer (Hobbs and Robinson 1979). However, linguistic pragmatics provides a more general explanation in the concept of scalar implicature. Our goal in this area is the formalization of scalar implicature to facilitate the interpretation and generation of cooperative responses in human-machine interaction (Hirschberg 1984). The concept of conversational implicature comes from Grice (1975): An utterance conversationally implicates a proposition P when it conveys P by virtue of the Conversational Principle. Following Grice, Horn (1972) observed that, when an utterance employs a scalar x on some scale m defined by semantic entailment [W semantically entails T iff T is true whenever W is.], such that y is less than x and x is less than z, then x represents the highest value on m consistent with S&apos;s observance of Grice&apos;s Maxim of Quality: &amp;quot;Be truthful.&amp;quot; Any proposition formed by substituting in P some z that is higher on m than x is thereby marked by S either as not believed to be the case or believed not to be the case. Any proposition formed by substituting in P some y lower on m than x will be true by entailment. Gazdar (19</context>
</contexts>
<marker>Horn, 1972</marker>
<rawString>Horn, L.R. 1972 On the Semantic Properties of Logical Operators in English. Ph.D. thesis, University of California at Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>Mutual Beliefs in Question Answering Systems. In</title>
<date>1982</date>
<publisher>Academic Press,</publisher>
<location>New York, New York.</location>
<marker>Joshi, 1982</marker>
<rawString>Joshi, A.K. 1982 Mutual Beliefs in Question Answering Systems. In Smith, N., Ed., Mutual Belief. Academic Press, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>Factoring Recursion and Dependencies.</title>
<date>1983</date>
<booktitle>Proc. 21st Annual Meeting, Association for Computational Linguistics.</booktitle>
<pages>7--15</pages>
<location>Cambridge, Massachusetts:</location>
<contexts>
<context position="23798" citStr="Joshi 1983" startWordPosition="3943" endWordPosition="3944">f the fact that the dependencies that transformational grammars have tried to account for can be captured satisfactorily by classes of rules that are non-transformational and at the same time highly constrained in terms of the classes of grammars and languages that they define. Two types of dependencies are especially important: subcategorization and filler-gap dependencies. In fact, one motivation for transformations was to account for unbounded dependencies. The so-called &amp;quot;non-transformational grammars&amp;quot; account for unbounded dependencies in different ways. In the formalism under study here (Joshi 1983) — tree-adjoining grammar (TAG) — unboundedness is achieved by factoring the dependencies and recursion in a novel and, we believe, linguistically interesting manner. All dependencies are defined on a finite set of basic structures (trees) that are bounded. Unboundedness is then a corollary of a particular composition operation, called adjoining, that preserves dependencies. So far we have described TAGs, characterized some of their properties and compared them with other nontransformational grammars (Joshi 1983). Currently we are looking at the issue of linguistic relevance, both for language</context>
</contexts>
<marker>Joshi, 1983</marker>
<rawString>Joshi, A.K. 1983 Factoring Recursion and Dependencies. Proc. 21st Annual Meeting, Association for Computational Linguistics. Cambridge, Massachusetts: 7-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Control of Inference: Centering.</title>
<date>1981</date>
<booktitle>In Proc. 1981 Meeting, Int&apos;l. Joint Conf. on Artificial Intelligence.</booktitle>
<pages>385--387</pages>
<location>Vancouver, Canada:</location>
<contexts>
<context position="22658" citStr="Joshi and Weinstein 1981" startWordPosition="3771" endWordPosition="3774">mple, various types of ellipses. This work is being done by Aravind Joshi and Scott Weinstein, together with Barbara Grosz from SRI International, and is reported in Grosz, Joshi, and Weinstein (1983). It brings together work on global coherence — the way larger segments of discourse fit together (Grosz 1982); local coherence — the way individual sentences bind together to form larger discourse segments (Sidner 1982); and centering — a local focusing process involving the single entity that an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous activity in constructing highly constrained grammatical systems by eliminating the transformational component either totally or partially (Kaplan and Bresnan 1983, Pullum and Gazdar 1982, Peters and Ritchie 1982). There is increasing recognition of the fact that the dependencies that transformational grammars have tr</context>
</contexts>
<marker>Joshi, Weinstein, 1981</marker>
<rawString>Joshi, A.K. and Weinstein, S. 1981 Control of Inference: Centering. In Proc. 1981 Meeting, Int&apos;l. Joint Conf. on Artificial Intelligence. Vancouver, Canada: 385-387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kaplan</author>
</authors>
<title>Cooperative Responses from a Portable Natural Language Data Base Query System. In</title>
<date>1982</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1280" citStr="Kaplan 1982" startWordPosition="189" endWordPosition="190">racies can be blamed on the departmental egg nog. 2. Extending the Range of Interactive Behavior Perhaps the most activity here in computational linguistics is aimed at extending the kinds of behavior that can be supported in interactions with data base and expert systems. Elsewhere we have argued that such systems have to do more than retrieve and present appropriate facts and conclusions if they are to satisfy their users&apos; real needs (Pollack, Hirschberg, and Webber 1982). Out of this conviction have already come systems able to recognize and respond to two types of presupposition failures (Kaplan 1982, Mays 1980) and a system able to describe in Natural Language what it knows about various entities (McKeown 1982). The following snippets indicate our current efforts in this area. 2.1. Recognizing and Responding to Belief Discrepancies One reason for unsuccessful interactions is that the participants fail to realize they hold different beliefs about the world. Or if they do realize it, they fail to do anything about it. As a result, each leaves the interaction with very different ideas about what was communicated. Such discrepancies differ widely with respect to how easy they are to recogniz</context>
</contexts>
<marker>Kaplan, 1982</marker>
<rawString>Kaplan, J. 1982 Cooperative Responses from a Portable Natural Language Data Base Query System. In Brady, M., Ed., Computational Models of Discourse. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical Funal Grammar: A Formal System for Grammatical Representation. In</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="23102" citStr="Kaplan and Bresnan 1983" startWordPosition="3839" endWordPosition="3842">focusing process involving the single entity that an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous activity in constructing highly constrained grammatical systems by eliminating the transformational component either totally or partially (Kaplan and Bresnan 1983, Pullum and Gazdar 1982, Peters and Ritchie 1982). There is increasing recognition of the fact that the dependencies that transformational grammars have tried to account for can be captured satisfactorily by classes of rules that are non-transformational and at the same time highly constrained in terms of the classes of grammars and languages that they define. Two types of dependencies are especially important: subcategorization and filler-gap dependencies. In fact, one motivation for transformations was to account for unbounded dependencies. The so-called &amp;quot;non-transformational grammars&amp;quot; acco</context>
</contexts>
<marker>Kaplan, Bresnan, 1983</marker>
<rawString>Kaplan, R. and Bresnan, J. 1983 Lexical Funal Grammar: A Formal System for Grammatical Representation. In Bresnan, J., Ed., The Mental Representation of Grammatical Relations. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mays</author>
</authors>
<title>Failures in Natural Language Systems: Application to Data Base Query Systems.</title>
<date>1980</date>
<booktitle>In Proc. First National Conference on Artificial Intelligence (AAAI).</booktitle>
<location>Stanford, California.</location>
<contexts>
<context position="1292" citStr="Mays 1980" startWordPosition="191" endWordPosition="192"> blamed on the departmental egg nog. 2. Extending the Range of Interactive Behavior Perhaps the most activity here in computational linguistics is aimed at extending the kinds of behavior that can be supported in interactions with data base and expert systems. Elsewhere we have argued that such systems have to do more than retrieve and present appropriate facts and conclusions if they are to satisfy their users&apos; real needs (Pollack, Hirschberg, and Webber 1982). Out of this conviction have already come systems able to recognize and respond to two types of presupposition failures (Kaplan 1982, Mays 1980) and a system able to describe in Natural Language what it knows about various entities (McKeown 1982). The following snippets indicate our current efforts in this area. 2.1. Recognizing and Responding to Belief Discrepancies One reason for unsuccessful interactions is that the participants fail to realize they hold different beliefs about the world. Or if they do realize it, they fail to do anything about it. As a result, each leaves the interaction with very different ideas about what was communicated. Such discrepancies differ widely with respect to how easy they are to recognize and square</context>
</contexts>
<marker>Mays, 1980</marker>
<rawString>Mays, E. 1980 Failures in Natural Language Systems: Application to Data Base Query Systems. In Proc. First National Conference on Artificial Intelligence (AAAI). Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mays</author>
</authors>
<title>Monitors as Responses to Questions: Determining Competence.</title>
<date>1982</date>
<booktitle>In Proc. 1982 National Conference on Artificial Intelligence.</booktitle>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="4874" citStr="Mays (1982" startWordPosition="784" endWordPosition="785">vailable as mechanically applied update constraints — the system cannot reason with it. In contrast, we have been working on enabling a system to reason about how its data base has changed up to now and how it can change in the future. We have termed American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 95 The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania this type of historical data base system a &amp;quot;dynamic data base system&amp;quot; and have described its implementation using a branching time temporal logic (Ari, Manna, and Pueuli 1981) in Mays (1982, 1983). In the context of dynamic data bases, we are developing support for several valuable interactive functions, including enabling the system ■ to recognize and square away beliefs that reflect ignorance of some event or its consequences (Webber and Mays 1983) — for example, U: Is John registered for CSE220? S: No, he can&apos;t be, because he already has advance placement credit for it. ■ to offer to monitor for additional information it will provide to the user if and when it learns of it (Mays 1983) — for example, U: Did John take CSE110 last term? S: No. Do you want me to let you know if h</context>
</contexts>
<marker>Mays, 1982</marker>
<rawString>Mays, E. 1982 Monitors as Responses to Questions: Determining Competence. In Proc. 1982 National Conference on Artificial Intelligence. Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mays</author>
</authors>
<title>A Modal Temporal Logic for Reasoning about Change. In</title>
<date>1983</date>
<booktitle>Proc. 1983 Assoc. for Computational Linguistics Conference.</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2423" citStr="Mays 1983" startWordPosition="378" endWordPosition="379">pancies differ widely with respect to how easy they are to recognize and square away. A disparity revealed on the surface by some utterance or act may nevertheless be deeply embedded in a person&apos;s whole system of beliefs and hence potentially expensive to square away. In the case of user-system interactions, as difficult as the general problem may be, certain discrepancies between the user&apos;s beliefs and those of the system may be clearly revealed in the user&apos;s utterances to the systern and easily squared away. This has been a focus of previous research here (Kaplan 1982, Mays 1980, Webber and Mays 1983) and is currently the focus of some new research on recognizing and responding to object-related discrepancies (McCoy 1983). There are several manifestations of these object-related discrepancies 1. the user&apos;s utterance describes an object in terms of a class it doesn&apos;t belong to; 2. the utterance incorrectly attributes some property to an object that it doesn&apos;t have; or 3. the utterance ascribes an impossible value to some property the object does have. For example, S: Do you have any liquid assets? U: I have a $5k money market certificate. S: A money market certificate isn&apos;t a liquid asset. </context>
<context position="5139" citStr="Mays 1983" startWordPosition="827" endWordPosition="828">al of Computational Linguistics, Volume 9, Number 2, April-June 1983 95 The FINITE STRING Newsletter Computational Linguistics Research, U. of Pennsylvania this type of historical data base system a &amp;quot;dynamic data base system&amp;quot; and have described its implementation using a branching time temporal logic (Ari, Manna, and Pueuli 1981) in Mays (1982, 1983). In the context of dynamic data bases, we are developing support for several valuable interactive functions, including enabling the system ■ to recognize and square away beliefs that reflect ignorance of some event or its consequences (Webber and Mays 1983) — for example, U: Is John registered for CSE220? S: No, he can&apos;t be, because he already has advance placement credit for it. ■ to offer to monitor for additional information it will provide to the user if and when it learns of it (Mays 1983) — for example, U: Did John take CSE110 last term? S: No. Do you want me to let you know if he does take it? U: Did John pass CSE110? S: No, the semester hasn&apos;t ended, so he hasn&apos;t received a grade yet. Shall I let you know then if he has passed CSE110? To perform these useful services, a system must be able to recognize what sequences of events are possib</context>
</contexts>
<marker>Mays, 1983</marker>
<rawString>Mays, E. 1983 A Modal Temporal Logic for Reasoning about Change. In Proc. 1983 Assoc. for Computational Linguistics Conference. Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McCoy</author>
</authors>
<title>Correcting Misconceptions: What to Say.</title>
<date>1983</date>
<booktitle>In CHI&apos;83 Conference Human Factors in Computing Systems.</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2546" citStr="McCoy 1983" startWordPosition="396" endWordPosition="397">by some utterance or act may nevertheless be deeply embedded in a person&apos;s whole system of beliefs and hence potentially expensive to square away. In the case of user-system interactions, as difficult as the general problem may be, certain discrepancies between the user&apos;s beliefs and those of the system may be clearly revealed in the user&apos;s utterances to the systern and easily squared away. This has been a focus of previous research here (Kaplan 1982, Mays 1980, Webber and Mays 1983) and is currently the focus of some new research on recognizing and responding to object-related discrepancies (McCoy 1983). There are several manifestations of these object-related discrepancies 1. the user&apos;s utterance describes an object in terms of a class it doesn&apos;t belong to; 2. the utterance incorrectly attributes some property to an object that it doesn&apos;t have; or 3. the utterance ascribes an impossible value to some property the object does have. For example, S: Do you have any liquid assets? U: I have a $5k money market certificate. S: A money market certificate isn&apos;t a liquid asset. Your money is tied up for several years in a money market certificate. Do you mean a money market account? U: What&apos;s the in</context>
</contexts>
<marker>McCoy, 1983</marker>
<rawString>McCoy, K. 1983 Correcting Misconceptions: What to Say. In CHI&apos;83 Conference Human Factors in Computing Systems. Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
</authors>
<title>Generating Natural Language Text in Response to Questions About Data Base Structure.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1394" citStr="McKeown 1982" startWordPosition="209" endWordPosition="210">t activity here in computational linguistics is aimed at extending the kinds of behavior that can be supported in interactions with data base and expert systems. Elsewhere we have argued that such systems have to do more than retrieve and present appropriate facts and conclusions if they are to satisfy their users&apos; real needs (Pollack, Hirschberg, and Webber 1982). Out of this conviction have already come systems able to recognize and respond to two types of presupposition failures (Kaplan 1982, Mays 1980) and a system able to describe in Natural Language what it knows about various entities (McKeown 1982). The following snippets indicate our current efforts in this area. 2.1. Recognizing and Responding to Belief Discrepancies One reason for unsuccessful interactions is that the participants fail to realize they hold different beliefs about the world. Or if they do realize it, they fail to do anything about it. As a result, each leaves the interaction with very different ideas about what was communicated. Such discrepancies differ widely with respect to how easy they are to recognize and square away. A disparity revealed on the surface by some utterance or act may nevertheless be deeply embedde</context>
</contexts>
<marker>McKeown, 1982</marker>
<rawString>McKeown, K. 1982 Generating Natural Language Text in Response to Questions About Data Base Structure. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Peters</author>
<author>R Ritchie</author>
</authors>
<title>Phrase Linking Grammars.</title>
<date>1982</date>
<tech>Technical Report,</tech>
<institution>Department of Linguistics, University of Texas.</institution>
<contexts>
<context position="23152" citStr="Peters and Ritchie 1982" startWordPosition="3847" endWordPosition="3850"> an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous activity in constructing highly constrained grammatical systems by eliminating the transformational component either totally or partially (Kaplan and Bresnan 1983, Pullum and Gazdar 1982, Peters and Ritchie 1982). There is increasing recognition of the fact that the dependencies that transformational grammars have tried to account for can be captured satisfactorily by classes of rules that are non-transformational and at the same time highly constrained in terms of the classes of grammars and languages that they define. Two types of dependencies are especially important: subcategorization and filler-gap dependencies. In fact, one motivation for transformations was to account for unbounded dependencies. The so-called &amp;quot;non-transformational grammars&amp;quot; account for unbounded dependencies in different ways. </context>
</contexts>
<marker>Peters, Ritchie, 1982</marker>
<rawString>Peters, S. and Ritchie, R. 1982 Phrase Linking Grammars. Technical Report, Department of Linguistics, University of Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pollack</author>
<author>J Hirschberg</author>
<author>B Webber</author>
</authors>
<title>User Participation in the Reasoning Processes of Expert Systems.</title>
<date>1982</date>
<booktitle>In Proc. AAAI-82.</booktitle>
<tech>Technical Report CIS-82-9,</tech>
<institution>Carnegie-Mellon University,</institution>
<location>Pittsburgh, Pennsylvania.</location>
<marker>Pollack, Hirschberg, Webber, 1982</marker>
<rawString>Pollack, M.; Hirschberg, J.; and Webber, B. 1982 User Participation in the Reasoning Processes of Expert Systems. In Proc. AAAI-82. Carnegie-Mellon University, Pittsburgh, Pennsylvania. A longer version appears as Technical Report CIS-82-9, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pollack</author>
</authors>
<title>A Framework for Providing Appropriate Advice.</title>
<date>1983</date>
<tech>Technical Report CIS-83-28,</tech>
<institution>Computer and Information Science, University of Pennsylvania,</institution>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="7777" citStr="Pollack (1983)" startWordPosition="1314" endWordPosition="1315">essage. If this user had consulted a real expert, the expert would probably have recognized from his request — &amp;quot;How do you delete a Control-Z?&amp;quot; — that the user had typed a Control-Z unintentionally and wanted to continue what he was doing, probably creating a message. While there is no way to delete a Control-Z, there is a way to return to composing a message — that is, by editing it. The expert&apos;s response would inform the user that to continue composing a message the user can enter the editor from where he is and add directly to the message fragment. The goal of our work here, as reported in Pollack (1983), is to enable an expert system or help system to deduce, from an incomplete or inappropriate query, what advice is actually needed and thereby generate appropriate responses to their users. Thus far, we have mapped out the sequence of processes involved in generating such responses and have experimented with at least one representation system (a type of dynamic logic, Rosenschein 1981) in which to do the reasoning involved. This work is being done by Martha Pollack, with supervision from Bonnie Webber and Aravind Joshi. 2.4. &amp;quot;Expert Questions&amp;quot; One aspect of user-expert system interactions inv</context>
</contexts>
<marker>Pollack, 1983</marker>
<rawString>Pollack, M. 1983 A Framework for Providing Appropriate Advice. Technical Report CIS-83-28, Computer and Information Science, University of Pennsylvania, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pullum</author>
<author>G Gazdar</author>
</authors>
<date>1982</date>
<journal>Natural Languages and ContextFree Languages. Linguistics and Philosophy</journal>
<volume>4</volume>
<pages>471--504</pages>
<contexts>
<context position="23126" citStr="Pullum and Gazdar 1982" startWordPosition="3843" endWordPosition="3846">g the single entity that an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous activity in constructing highly constrained grammatical systems by eliminating the transformational component either totally or partially (Kaplan and Bresnan 1983, Pullum and Gazdar 1982, Peters and Ritchie 1982). There is increasing recognition of the fact that the dependencies that transformational grammars have tried to account for can be captured satisfactorily by classes of rules that are non-transformational and at the same time highly constrained in terms of the classes of grammars and languages that they define. Two types of dependencies are especially important: subcategorization and filler-gap dependencies. In fact, one motivation for transformations was to account for unbounded dependencies. The so-called &amp;quot;non-transformational grammars&amp;quot; account for unbounded depend</context>
</contexts>
<marker>Pullum, Gazdar, 1982</marker>
<rawString>Pullum, G. and Gazdar, G. 1982 Natural Languages and ContextFree Languages. Linguistics and Philosophy 4: 471-504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Rosenschein</author>
</authors>
<title>Plan Synthesis: A Logical Perspective.</title>
<date>1981</date>
<booktitle>In Proceedings of the 7th Conference. IJCAI:</booktitle>
<pages>331--337</pages>
<contexts>
<context position="8166" citStr="Rosenschein 1981" startWordPosition="1376" endWordPosition="1377">. The expert&apos;s response would inform the user that to continue composing a message the user can enter the editor from where he is and add directly to the message fragment. The goal of our work here, as reported in Pollack (1983), is to enable an expert system or help system to deduce, from an incomplete or inappropriate query, what advice is actually needed and thereby generate appropriate responses to their users. Thus far, we have mapped out the sequence of processes involved in generating such responses and have experimented with at least one representation system (a type of dynamic logic, Rosenschein 1981) in which to do the reasoning involved. This work is being done by Martha Pollack, with supervision from Bonnie Webber and Aravind Joshi. 2.4. &amp;quot;Expert Questions&amp;quot; One aspect of user-expert system interactions involves the system attempting to get from the user the information it needs to help solve his/her problem. The most commonly used way of getting information is via &amp;quot;menus&amp;quot; — essentially, multiple choice questions. However, there are several problems with relying on menus: • The user may not understand either the question or the menu options. • The user may be influenced by the options — t</context>
</contexts>
<marker>Rosenschein, 1981</marker>
<rawString>Rosenschein, S.J. 1981 Plan Synthesis: A Logical Perspective. In Proceedings of the 7th Conference. IJCAI: 331-337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Focusing in the Comprehension of Definite Anaphora. In</title>
<date>1982</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="22453" citStr="Sidner 1982" startWordPosition="3742" endWordPosition="3743">ptions and referring expressions in discourse. Out of this we hope will come a theoretical framework that can account for a variety of discourse phenomena in which the three interact — for example, various types of ellipses. This work is being done by Aravind Joshi and Scott Weinstein, together with Barbara Grosz from SRI International, and is reported in Grosz, Joshi, and Weinstein (1983). It brings together work on global coherence — the way larger segments of discourse fit together (Grosz 1982); local coherence — the way individual sentences bind together to form larger discourse segments (Sidner 1982); and centering — a local focusing process involving the single entity that an individual utterance most centrally concerns, that works to integrate an utterance into a discourse (Joshi and Weinstein 1981). The work is of particular significance for language generation, where one does not want to call upon powerful inference mechanisms to guide or bless the speaker&apos;s use of a particular referring phrase. 7. Grammar Formalisms — TAGs During the last few years there has been vigorous activity in constructing highly constrained grammatical systems by eliminating the transformational component eit</context>
</contexts>
<marker>Sidner, 1982</marker>
<rawString>Sidner, C.L. 1982 Focusing in the Comprehension of Definite Anaphora. In Brady, M., Ed., Computational Models of Discourse. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E</author>
</authors>
<title>Varieties of User Misconceptions: Detection and Correction.</title>
<date>1983</date>
<booktitle>In Proc. IJCAI-8.</booktitle>
<location>Karlsruhe, Germany.</location>
<marker>E, 1983</marker>
<rawString>Webber, B. and Mays. E. 1983 Varieties of User Misconceptions: Detection and Correction. In Proc. IJCAI-8. Karlsruhe, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>