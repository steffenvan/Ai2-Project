<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.5488055">
Experiments in Graph-based Semi-Supervised Learning Methods for
Class-Instance Acquisition
</title>
<author confidence="0.263693">
Partha Pratim Talukdar*
</author>
<affiliation confidence="0.180251">
Search Labs, Microsoft Research
</affiliation>
<address confidence="0.797471">
Mountain View, CA 94043
</address>
<email confidence="0.993837">
partha@talukdar.net
</email>
<sectionHeader confidence="0.994664" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99944715">
Graph-based semi-supervised learning
(SSL) algorithms have been successfully
used to extract class-instance pairs from
large unstructured and structured text col-
lections. However, a careful comparison
of different graph-based SSL algorithms
on that task has been lacking. We com-
pare three graph-based SSL algorithms
for class-instance acquisition on a variety
of graphs constructed from different do-
mains. We find that the recently proposed
MAD algorithm is the most effective. We
also show that class-instance extraction
can be significantly improved by adding
semantic information in the form of
instance-attribute edges derived from
an independently developed knowledge
base. All of our code and data will be
made publicly available to encourage
reproducible research in this area.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999869142857143">
Traditionally, named-entity recognition (NER) has
focused on a small number of broad classes such
as person, location, organization. However, those
classes are too coarse to support important ap-
plications such as sense disambiguation, seman-
tic matching, and textual inference in Web search.
For those tasks, we need a much larger inventory
of specific classes and accurate classification of
terms into those classes. While supervised learn-
ing methods perform well for traditional NER,
they are impractical for fine-grained classification
because sufficient labeled data to train classifiers
for all the classes is unavailable and would be very
expensive to obtain.
</bodyText>
<footnote confidence="0.9002645">
* Research carried out while at the University of Penn-
sylvania, Philadelphia, PA, USA.
</footnote>
<note confidence="0.931415666666667">
Fernando Pereira
Google, Inc.
Mountain View, CA 94043
</note>
<email confidence="0.963978">
pereira@google.com
</email>
<bodyText confidence="0.995365346153846">
To overcome these difficulties, seed-based in-
formation extraction methods have been devel-
oped over the years (Hearst, 1992; Riloff and
Jones, 1999; Etzioni et al., 2005; Talukdar et
al., 2006; Van Durme and Pas¸ca, 2008). Start-
ing with a few seed instances for some classes,
these methods, through analysis of unstructured
text, extract new instances of the same class. This
line of work has evolved to incorporate ideas from
graph-based semi-supervised learning in extrac-
tion from semi-structured text (Wang and Cohen,
2007), and in combining extractions from free
text and from structured sources (Talukdar et al.,
2008). The benefits of combining multiple sources
have also been demonstrated recently (Pennac-
chiotti and Pantel, 2009).
We make the following contributions:
• Even though graph-based SSL algorithms
have achieved early success in class-instance
acquisition, there is no study comparing dif-
ferent graph-based SSL methods on this task.
We address this gap with a series of experi-
ments comparing three graph-based SSL al-
gorithms (Section 2) on graphs constructed
from several sources (Metaweb Technolo-
gies, 2009; Banko et al., 2007).
</bodyText>
<listItem confidence="0.837760230769231">
• We investigate whether semantic informa-
tion in the form of instance-attribute edges
derived from an independent knowledge
base (Suchanek et al., 2007) can improve
class-instance acquisition. The intuition be-
hind this is that instances that share attributes
are more likely to belong to the same class.
We demonstrate that instance-attribute edges
significantly improve the accuracy of class-
instance extraction. In addition, useful class-
attribute relationships are learned as a by-
product of this process.
• In contrast to previous studies involving pro-
</listItem>
<page confidence="0.885095">
1473
</page>
<note confidence="0.950838">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1473–1481,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.97353">
prietary datasets (Van Durme and Pas¸ca,
2008; Talukdar et al., 2008; Pennacchiotti
and Pantel, 2009), all of our experiments use
publicly available datasets and we plan to re-
lease our code1.
In Section 2, we review three graph-based
SSL algorithms that are compared for the class-
instance acquisition task in Section 3. In Section
3.6, we show how additional instance-attribute
based semantic constraints can be used to improve
class-instance acquisition performance. We sum-
marize the results and outline future work in Sec-
tion 4.
</bodyText>
<sectionHeader confidence="0.996656" genericHeader="method">
2 Graph-based SSL
</sectionHeader>
<bodyText confidence="0.998904333333333">
We now review the three graph-based SSL algo-
rithms for class inference over graphs that we have
evaluated.
</bodyText>
<subsectionHeader confidence="0.86668">
2.1 Notation
</subsectionHeader>
<bodyText confidence="0.998436368421053">
All the algorithms compute a soft assignment of
labels to the nodes of a graph G = (V, E, W),
where V is the set of nodes with JV J = n, E is
the set of edges, and W is an edge weight ma-
trix. Out of the n = nl + nu nodes in G, nl
nodes are labeled, while the remaining nu nodes
are unlabeled. If edge (u, v) E� E, Wuv = 0.
The (unnormalized) Laplacian, L, of G is given by
L = D_W, where D is an nxn diagonal degree
matrix with Duu = Pv Wuv. Let S be an n x n
diagonal matrix with Suu = 1 iff node u E V is
labeled. That is, S identifies the labeled nodes in
the graph. C is the set of labels, with JCJ = m
representing the total number of labels. Y is the
n x m matrix storing training label information,
if any. Y is an n x m matrix of soft label assign-
ments, with Yvl representing the score of label l
on node v. A graph-based SSL computes Y from
{G, SY }.
</bodyText>
<subsectionHeader confidence="0.998961">
2.2 Label Propagation (LP-ZGL)
</subsectionHeader>
<bodyText confidence="0.999992">
The label propagation method presented by Zhu
et al. (2003), which we shall refer to as LP-ZGL
in this paper, is one of the first graph-based SSL
methods. The objective minimized by LP-ZGL is:
</bodyText>
<equation confidence="0.94163625">
X
min Y� &gt;
l LY, s.t. SYl = S Y
Y l∈C
</equation>
<footnote confidence="0.779552">
1http://www.talukdar.net/datasets/class inst/
</footnote>
<bodyText confidence="0.99993625">
where Y of size n x 1 is the lth column of Y.
The constraint SY = S Y� makes sure that the su-
pervised labels are not changed during inference.
The above objective can be rewritten as:
</bodyText>
<equation confidence="0.99739">
X
Y� &gt;
l LY =
u,v∈V,l∈C
</equation>
<bodyText confidence="0.999920777777778">
From this, we observe that LP-ZGL penalizes any
label assignment where two nodes connected by a
highly weighted edge are assigned different labels.
In other words, LP-ZGL prefers smooth labelings
over the graph. This property is also shared by the
two algorithms we shall review next. LP-ZGL has
been the basis for much subsequent work in the
graph-based SSL area, and is still one of the most
effective graph-based SSL algorithms.
</bodyText>
<subsectionHeader confidence="0.996865">
2.3 Adsorption
</subsectionHeader>
<bodyText confidence="0.999896333333333">
Adsorption (Baluja et al., 2008) is a graph-based
SSL algorithm which has been used for open-
domain class-instance acquisition (Talukdar et al.,
2008). Adsorption is an iterative algorithm, where
label estimates on node v in the (t + 1)th iteration
are updated using estimates from the tth iteration:
</bodyText>
<equation confidence="0.948310714285714">
Y�(t+1)
v &apos;__ pinj
v xYv+pcont vx B(t)v+pvbnd xr (2)
where,
B(t) X= Wuv Y�(t)
v u u
Pu� Wu�v
</equation>
<bodyText confidence="0.956884">
In (2), pinj
v , pcont
v , and pabnd
v are three proba-
bilities defined on each node v E V by Ad-
sorption; and r is a vector used by Adsorption
to express label uncertainty at a node. On each
node v, the three probabilities sum to one, i.e.,
</bodyText>
<equation confidence="0.9110455">
pinj
v + pcont v+ pabnd
</equation>
<bodyText confidence="0.998014">
v = 1, and they are based on
the random-walk interpretation of the Adsorption
algorithm (Talukdar et al., 2008). The main idea
of Adsorption is to control label propagation more
tightly by limiting the amount of information that
passes through a node. For instance, Adsorption
can reduce the importance of a high-degree node
v during the label inference process by increas-
ing pabnd
v on that node. For more details on these,
please refer to Section 2 of (Talukdar and Cram-
mer, 2009). In contrast to LP-ZGL, Adsorption
allows labels on labeled (seed) nodes to change,
which is desirable in case of noisy input labels.
</bodyText>
<equation confidence="0.9921495">
(1)
X
l∈C
Wuv(�Yul _ kvl)2
</equation>
<page confidence="0.956432">
1474
</page>
<subsectionHeader confidence="0.551326">
2.4 Modified Adsorption (MAD)
</subsectionHeader>
<bodyText confidence="0.929967285714286">
Talukdar and Crammer (2009) introduced a modi-
fication of Adsorption called MAD, which shares
Adsorption’s desirable properties but can be ex-
pressed as an unconstrained optimization problem:
of this paper. Statistics of the graphs used during
experiments in this section are presented in Table
1.
</bodyText>
<equation confidence="0.72789325">
3.1 Freebase-1 Graph with Pantel Classes
2
µ2 �
l L Y + µ3 Y − Rl (3)
</equation>
<bodyText confidence="0.999480363636364">
where µ1, µ2, and µ3 are hyperparameters; L&apos;
is the Laplacian of an undirected graph derived
from G, but with revised edge weights; and R is
an n x m matrix of per-node label prior, if any,
with Rl representing the lth column of R. As in
Adsorption, MAD allows labels on seed nodes to
change. In case of MAD, the three random-walk
probabilities, pinj
v , pcont
v , and pabnd
v , defined by
Adsorption on each node are folded inside the ma-
trices 5, L, and R, respectively. The optimization
problem in (3) can be solved with an efficient iter-
ative algorithm described in detail by Talukdar and
Crammer (2009).
These three algorithms are all easily paralleliz-
able in a MapReduce framework (Talukdar et al.,
2008; Rao and Yarowsky, 2009), which makes
them suitable for SSL on large datasets. Addition-
ally, all three algorithms have similar space and
time complexity.
</bodyText>
<sectionHeader confidence="0.999207" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999537857142857">
We now compare the experimental performance
of the three graph-based SSL algorithms reviewed
in the previous section, using graphs constructed
from a variety of sources described below. Fol-
lowing previous work (Talukdar et al., 2008), we
use Mean Reciprocal Rank (MRR) as the evalua-
tion metric in all experiments:
</bodyText>
<equation confidence="0.997800666666667">
1 X 1
MRR = (4)
|Q |vEQ rv
</equation>
<bodyText confidence="0.999925875">
where Q C_ V is the set of test nodes, and rv is the
rank of the gold label among the labels assigned to
node v. Higher MRR reflects better performance.
We used iterative implementations of the graph-
based SSL algorithms, and the number of itera-
tions was treated as a hyperparameter which was
tuned, along with other hyperparameters, on sep-
arate held-out sets, as detailed in a longer version
</bodyText>
<tableCaption confidence="0.994671">
Table ID: people-person
</tableCaption>
<table confidence="0.989736833333334">
Name Place of Birth Gender
� � � � � � � � �
Isaac Newton Lincolnshire Male
Bob Dylan Duluth Male
Johnny Cash Kingsland Male
� � � � � � � � �
</table>
<tableCaption confidence="0.997423">
Table ID: film-music contributor
</tableCaption>
<figureCaption confidence="0.950857333333333">
Figure 1: Examples of two tables from Freebase,
one table is from the people domain while the
other is from the film domain.
</figureCaption>
<figure confidence="0.7046025">
Freebase-1 Graph, 23 Pantel Classes
Amount of Supervision (# Classes x seeds per Class)
</figure>
<figureCaption confidence="0.9522598">
Figure 3: Comparison of three graph transduction
methods on a graph constructed from the Freebase
dataset (see Section 3.1), with 23 classes. All re-
sults are averaged over 4 random trials. In each
group, MAD is the rightmost bar.
</figureCaption>
<bodyText confidence="0.986253333333333">
Freebase (Metaweb Technologies, 2009)2 is
a large collaborative knowledge base. The
knowledge base harvests information from many
open data sets (for instance Wikipedia and Mu-
sicBrainz), as well as from user contributions. For
our current purposes, we can think of the Freebase
</bodyText>
<footnote confidence="0.548564">
2http://www.freebase.com/
</footnote>
<figure confidence="0.96930685">
Name
Bob Dylan
� � �
� � �
Film Music Credits
No Direction Home
� � �
� � �
0.8
23 x 2 23 x 10
Mean Reciprocal Rank (MRR)
0.725
0.65
0.575
0.5
LP-ZGL Adsorption MAD
�
T
min µ1~Y− Y~ 5~Y− Y~+
Y� lEC
</figure>
<page confidence="0.667055">
1475
</page>
<table confidence="0.999689714285714">
Graph Vertices Edges Avg. Min. Max.
Deg. Deg. Deg.
Freebase-1 (Section 3.1) 32970 957076 29.03 1 13222
Freebase-2 (Section 3.2) 301638 2310002 7.66 1 137553
TextRunner (Section 3.3) 175818 529557 3.01 1 2738
YAGO (Section 3.6) 142704 777906 5.45 0 74389
TextRunner + YAGO (Section 3.6) 237967 1307463 5.49 1 74389
</table>
<tableCaption confidence="0.963468333333333">
Table 1: Statistics of various graphs used in experiments in Section 3. Some of the test instances in the
YAGO graph, added for fair comparison with the TextRunner graph in Section 3.6, had no attributes in
YAGO KB, and hence these instance nodes had degree 0 in the YAGO graph.
</tableCaption>
<figure confidence="0.999863571428571">
Isaac Newton
Bob Dylan
Johnny
Cash
film-music_contributor-name
people-person-name
people-person-name
Johnny
Cash
Bob Dylan
has_attribute:albums
Þlm-music_contributor-name
Isaac Newton
(a) (b)
</figure>
<figureCaption confidence="0.825011">
Figure 2: (a) Example of a section of the graph constructed from the two tables in Figure 1. Rectangular
nodes are properties, oval nodes are entities or cell values. (b) The graph in part (a) augmented with
</figureCaption>
<bodyText confidence="0.988785666666667">
an attribute node, has attribue:albums, along with the edges incident on it. This results is additional
constraints for the nodes Johnny Cash and Bob Dylan to have similar labels (see Section 3.6).
dataset as a collection of relational tables, where
each table is assigned a unique ID. A table con-
sists of one or more properties (column names)
and their corresponding cell values (column en-
tries). Examples of two Freebase tables are shown
in Figure 1. In this figure, Gender is a property
in the table people-person, and Male is a corre-
sponding cell value. We use the following process
to convert the Freebase data tables into a single
graph:
</bodyText>
<listItem confidence="0.9281975">
• Create a node for each unique cell value
• Create a node for each unique property name,
where unique property name is obtained by
prefixing the unique table ID to the prop-
erty name. For example, in Figure 1, people-
person-gender is a unique property name.
• Add an edge of weight 1.0 from cell-value
node v to unique property node p, iff value
</listItem>
<bodyText confidence="0.99827452631579">
v is present in the column corresponding to
property p. Similarly, add an edge in the re-
verse direction.
By applying this graph construction process on
the first column of the two tables in Figure 1, we
end up with the graph shown in Figure 2 (a). We
note that even though the resulting graph consists
of edges connecting nodes of different types: cell
value nodes to property nodes; the graph-based
SSL methods (Section 2) can still be applied on
such graphs as a cell value node and a property
node connected by an edge should be assigned
same or similar class labels. In other words, the la-
bel smoothness assumption (see Section 2.2) holds
on such graphs.
We applied the same graph construction pro-
cess on a subset of the Freebase dataset consist-
ing of topics from 18 randomly selected domains:
astronomy, automotive, biology, book, business,
</bodyText>
<page confidence="0.967051">
1476
</page>
<bodyText confidence="0.999008842105263">
chemistry, comic books, computer, film, food, ge-
ography, location, people, religion, spaceflight,
tennis, travel, and wine. The topics in this subset
were further filtered so that only cell-value nodes
with frequency 10 or more were retained. We call
the resulting graph Freebase-1 (see Table 1).
Pantel et al. (2009) have made available
a set of gold class-instance pairs derived
from Wikipedia, which is downloadable from
http://ow.ly/13B57. From this set, we selected
all classes which had more than 10 instances
overlapping with the Freebase graph constructed
above. This resulted in 23 classes, which along
with their overlapping instances were used as the
gold standard set for the experiments in this sec-
tion.
Experimental results with 2 and 10 seeds (la-
beled nodes) per class are shown in Figure 3. From
the figure, we see that that LP-ZGL and Adsorp-
tion performed comparably on this dataset, with
MAD significantly outperforming both methods.
lapping with the larger Freebase graph constructed
above. This resulted in 192 WN classes which we
use for the experiments in this section. The reason
behind imposing such frequency constraints dur-
ing class selection is to make sure that each class
is left with a sufficient number of instances during
testing.
Experimental results comparing LP-ZGL, Ad-
sorption, and MAD with 2 and 10 seeds per class
are shown in Figure 4. A total of 292k test nodes
were used for testing in the 10 seeds per class con-
dition, showing that these methods can be applied
to large datasets. Once again, we observe MAD
outperforming both LP-ZGL and Adsorption. It is
interesting to note that MAD with 2 seeds per class
outperforms LP-ZGL and adsorption even with 10
seeds per class.
</bodyText>
<figure confidence="0.961292625">
3.3 TextRunner Graph with WordNet
Classes
TextRunner Graph, 170 WordNet Classes
3.2 Freebase-2 Graph with WordNet Classes
0.35
LP-ZGL Adsorption MAD
Freebase-2 Graph, 192 WordNet Classes
Amount of Supervision (# classes x seeds per class)
</figure>
<figureCaption confidence="0.6748656">
Figure 4: Comparison of graph transduction meth-
ods on a graph constructed from the Freebase
dataset (see Section 3.2). All results are averaged
over 10 random trials. In each group, MAD is the
rightmost bar.
</figureCaption>
<bodyText confidence="0.9989365">
To evaluate how the algorithms scale up, we
construct a larger graph from the same 18 domains
as in Section 3.1, and using the same graph con-
struction process. We shall call the resulting graph
Freebase-2 (see Table 1). In order to scale up the
number of classes, we selected all Wordnet (WN)
classes, available in the YAGO KB (Suchanek et
al., 2007), that had more than 100 instances over-
</bodyText>
<figure confidence="0.994573833333333">
Mean Reciprocal Rank (MRR) 0.3
0.25
0.2
0.15
170 x 2 170 x 10
Amount of Supervision (# classes x seeds per class)
</figure>
<figureCaption confidence="0.998346">
Figure 5: Comparison of graph transduction meth-
</figureCaption>
<bodyText confidence="0.9818966">
ods on a graph constructed from the hypernym tu-
ples extracted by the TextRunner system (Banko
et al., 2007) (see Section 3.3). All results are aver-
aged over 10 random trials. In each group, MAD
is the rightmost bar.
In contrast to graph construction from struc-
tured tables as in Sections 3.1, 3.2, in this section
we use hypernym tuples extracted by TextRun-
ner (Banko et al., 2007), an open domain IE sys-
tem, to construct the graph. Example of a hyper-
nym tuple extracted by TextRunner is (http, proto-
col, 0.92), where 0.92 is the extraction confidence.
To convert such a tuple into a graph, we create a
node for the instance (http) and a node for the class
(protocol), and then connect the nodes with two
</bodyText>
<figure confidence="0.996645125">
0.39
192 x 2 192 x 10
Mean Reciprocal Rank (MRR)
0.355
0.32
0.285
0.25
LP-ZGL Adsorption MAD
</figure>
<page confidence="0.990407">
1477
</page>
<bodyText confidence="0.999943733333334">
directed edges in both directions, with the extrac-
tion confidence (0.92) as edge weights. The graph
created with this process from TextRunner out-
put is called the TextRunner Graph (see Table 1).
As in Section 3.2, we use WordNet class-instance
pairs as the gold set. In this case, we considered
all WordNet classes, once again from YAGO KB
(Suchanek et al., 2007), which had more than 50
instances overlapping with the constructed graph.
This resulted in 170 WordNet classes being used
for the experiments in this section.
Experimental results with 2 and 10 seeds per
class are shown in Figure 5. The three methods
are comparable in this setting, with MAD achiev-
ing the highest overall MRR.
</bodyText>
<subsectionHeader confidence="0.564057">
3.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999632633333333">
If we correlate the graph statistics in Table 1 with
the results of sections 3.1, 3.2, and 3.3, we see
that MAD is most effective for graphs with high
average degree, that is, graphs where nodes tend
to connect to many other nodes. For instance,
the Freebase-1 graph has a high average degree
of 29.03, with a corresponding large advantage
for MAD over the other methods. Even though
this might seem mysterious at first, it becomes
clearer if we look at the objectives minimized
by different algorithms. We find that the objec-
tive minimized by LP-ZGL (Equation 1) is under-
regularized, i.e., its model parameters (Y) are not
constrained enough, compared to MAD (Equation
3, specifically the third term), resulting in overfit-
ting in case of highly connected graphs. In con-
trast, MAD is able to avoid such overfitting be-
cause of its minimization of a well regularized ob-
jective (Equation 3). Based on this, we suggest
that average degree, an easily computable struc-
tural property of the graph, may be a useful indica-
tor in choosing which graph-based SSL algorithm
should be applied on a given graph.
Unlike MAD, Adsorption does not optimize
any well defined objective (Talukdar and Cram-
mer, 2009), and hence any analysis along the lines
described above is not possible. The heuristic
choices made in Adsorption may have lead to its
sub-optimal performance compared to MAD; we
leave it as a topic for future investigation.
</bodyText>
<subsectionHeader confidence="0.9986">
3.5 Effect of Per-Node Class Sparsity
</subsectionHeader>
<bodyText confidence="0.999607">
For all the experiments in Sections 3.1, 3.2, and
3.6, each node was allowed to have a maximum
of 15 classes during inference. After each update
</bodyText>
<subsectionHeader confidence="0.871218">
Effect of Per-node Sparsity Constraint
</subsectionHeader>
<figure confidence="0.9366672">
0.42
Mean Reciprocal Rank (MRR) 0.39
0.36
0.33
0.3
</figure>
<figureCaption confidence="0.76826">
Figure 6: Effect of per node class sparsity (maxi-
mum number of classes allowed per node) during
MAD inference in the experimental setting of Fig-
ure 4 (one random split).
</figureCaption>
<bodyText confidence="0.999939272727273">
on a node, all classes except for the top scoring
15 classes were discarded. Without such sparsity
constraints, a node in a connected graph will end
up acquiring all the labels injected into the graph.
This is undesirable for two reasons: (1) for ex-
periments involving a large numbers of classes (as
in the previous section and in the general case of
open domain IE), this increases the space require-
ment and also slows down inference; (2) a partic-
ular node is unlikely to belong to a large num-
ber of classes. In order to estimate the effect of
such sparsity constraints, we varied the number
of classes allowed per node from 5 to 45 on the
graph and experimental setup of Figure 4, with 10
seeds per class. The results for MAD inference
over the development split are shown in Figure
6. We observe that performance can vary signifi-
cantly as the maximum number of classes allowed
per node is changed, with the performance peak-
ing at 25. This suggests that sparsity constraints
during graph based SSL may have a crucial role to
play, a question that needs further investigation.
</bodyText>
<subsectionHeader confidence="0.9505195">
3.6 TextRunner Graph with additional
Semantic Constraints from YAGO
</subsectionHeader>
<bodyText confidence="0.997669285714286">
Recently, the problem of instance-attribute extrac-
tion has started to receive attention (Probst et al.,
2007; Bellare et al., 2007; Pasca and Durme,
2007). An example of an instance-attribute pair
is (Bob Dylan, albums). Given a set of seed
instance-attribute pairs, these methods attempt to
extract more instance-attribute pairs automatically
</bodyText>
<figure confidence="0.988245407407407">
5 15 25 35 45
Maximum Allowed Classes per Node
1478
170 WordNet Classes, 2 Seeds per Class
LP-ZGL Adsorption MAD
Algorithms
170 WordNet Classes, 10 Seeds per Class
LP-ZGL Adsorption MAD
Algorithms
0.38
Mean Reciprocal Rank (MRR)
0.33
0.28
0.23
0.18
TextRunner Graph
YAGO Graph
TextRunner + YAGO Graph
0.45
Mean Reciprocal Rank (MRR)
0.413
0.375
0.338
0.3
TextRunner Graph
YAGO Graph
TextRunner + YAGO Graph
</figure>
<figureCaption confidence="0.924685666666667">
Figure 7: Comparison of class-instance acquisition performance on the three different graphs described
in Section 3.6. All results are averaged over 10 random trials. Addition of YAGO attributes to the
TextRunner graph significantly improves performance.
</figureCaption>
<table confidence="0.988868083333333">
YAGO Top-2 WordNet Classes Assigned by MAD
Attribute (example instances for each class are shown in brackets)
has currency wordnet country 108544813 (Burma, Afghanistan)
wordnet region 108630039 (Aosta Valley, Southern Flinders Ranges)
works at wordnet scientist 110560637 (Aage Niels Bohr, Adi Shamir)
wordnet person 100007846 (Catherine Cornelius, Jamie White)
has capital wordnet state 108654360 (Agusan del Norte, Bali)
wordnet region 108630039 (Aosta Valley, Southern Flinders Ranges)
born in wordnet boxer 109870208 (George Chuvalo, Fernando Montiel)
wordnet chancellor 109906986 (Godon Brown, Bill Bryson)
has isbn wordnet book 106410904 (Past Imperfect, Berlin Diary)
wordnet magazine 106595351 (Railway Age, Investors Chronicle)
</table>
<tableCaption confidence="0.954837">
Table 2: Top 2 (out of 170) WordNet classes assigned by MAD on 5 randomly chosen YAGO attribute
</tableCaption>
<bodyText confidence="0.963485">
nodes (out of 80) in the TextRunner + YAGO graph used in Figure 7 (see Section 3.6), with 10 seeds per
class used. A few example instances of each WordNet class is shown within brackets. Top ranked class
for each attribute is shown in bold.
from various sources. In this section, we ex-
plore whether class-instance assignment can be
improved by incorporating new semantic con-
straints derived from (instance, attribute) pairs. In
particular, we experiment with the following type
of constraint: two instances with a common at-
tribute are likely to belong to the same class. For
example, in Figure 2 (b), instances Johnny Cash
and Bob Dylan are more likely to belong to the
same class as they have a common attribute, al-
bums. Because of the smooth labeling bias of
graph-based SSL methods (see Section 2.2), such
constraints are naturally captured by the methods
reviewed in Section 2. All that is necessary is the
introduction of bidirectional (instance, attribute)
edges to the graph, as shown in Figure 2 (b).
In Figure 7, we compare class-instance acqui-
sition performance of the three graph-based SSL
methods (Section 2) on the following three graphs
(also see Table 1):
TextRunner Graph: Graph constructed
from the hypernym tuples extracted by Tex-
tRunner, as in Figure 5 (Section 3.3), with
175k vertices and 529k edges.
YAGO Graph: Graph constructed from the
(instance, attribute) pairs obtained from the
YAGO KB (Suchanek et al., 2007), with 142k
nodes and 777k edges.
TextRunner + YAGO Graph: Union of the
</bodyText>
<page confidence="0.986829">
1479
</page>
<bodyText confidence="0.99947941025641">
two graphs above, with 237k nodes and 1.3m
edges.
In all experimental conditions with 2 and 10
seeds per class in Figure 7, we observe that the
three methods consistently achieved the best per-
formance on the TextRunner + YAGO graph. This
suggests that addition of attribute based seman-
tic constraints from YAGO to the TextRunner
graph results in a better connected graph which
in turn results in better inference by the graph-
based SSL algorithms, compared to using either
of the sources, i.e., TextRunner output or YAGO
attributes, in isolation. This further illustrates
the advantage of aggregating information across
sources (Talukdar et al., 2008; Pennacchiotti and
Pantel, 2009). However, we are the first, to the
best of our knowledge, to demonstrate the effec-
tiveness of attributes in class-instance acquisition.
We note that this work is similar in spirit to the
recent work by Carlson et al. (2010) which also
demonstrates the benefits of additional constraints
in SSL.
Because of the label propagation behavior,
graph-based SSL algorithms assign classes to all
nodes reachable in the graph from at least one
of the labeled instance nodes. This allows us
to check the classes assigned to nodes corre-
sponding to YAGO attributes in the TextRunner
+ YAGO graph, as shown in Table 2. Even
though the experiments were designed for class-
instance acquisition, it is encouraging to see that
the graph-based SSL algorithm (MAD in Table
2) is able to learn class-attribute relationships,
an important by-product that has been the fo-
cus of recent studies (Reisinger and Pasca, 2009).
For example, the algorithm is able to learn that
works at is an attribute of the WordNet class word-
net scientist 110560637, and thereby its instances
(e.g. Aage Niels Bohr, Adi Shamir).
</bodyText>
<sectionHeader confidence="0.99915" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999949318181818">
We have started a systematic experimental com-
parison of graph-based SSL algorithms for class-
instance acquisition on a variety of graphs con-
structed from different domains. We found that
MAD, a recently proposed graph-based SSL algo-
rithm, is consistently the most effective across the
various experimental conditions. We also showed
that class-instance acquisition performance can be
significantly improved by incorporating additional
semantic constraints in the class-instance acqui-
sition process, which for the experiments in this
paper were derived from instance-attribute pairs
available in an independently developed knowl-
edge base. All the data used in these experiments
was drawn from publicly available datasets and we
plan to release our code3 to foster reproducible
research in this area. Topics for future work in-
clude the incorporation of other kinds of semantic
constraint for improved class-instance acquisition,
further investigation into per-node sparsity con-
straints in graph-based SSL, and moving beyond
bipartite graph constructions.
</bodyText>
<sectionHeader confidence="0.998473" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993677125">
We thank William Cohen for valuable discussions,
and Jennifer Gillenwater, Alex Kulesza, and Gre-
gory Malecha for detailed comments on a draft of
this paper. We are also very grateful to the authors
of (Banko et al., 2007), Oren Etzioni and Stephen
Soderland in particular, for providing TextRunner
output. This work was supported in part by NSF
IIS-0447972 and DARPA HRO1107-1-0029.
</bodyText>
<sectionHeader confidence="0.998291" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99972812">
S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik,
S. Kumar, D. Ravichandran, and M. Aly. 2008.
Video suggestion and discovery for youtube: taking
random walks through the view graph. Proceedings
of WWW-2008.
M. Banko, M.J. Cafarella, S. Soderland, M. Broadhead,
and O. Etzioni. 2007. Open information extraction
from the web. Procs. of IJCAI.
K. Bellare, P. Talukdar, G. Kumaran, F. Pereira,
M. Liberman, A. McCallum, and M. Dredze. 2007.
Lightly-Supervised Attribute Extraction. NIPS 2007
Workshop on Machine Learning for Web Search.
A. Carlson, J. Betteridge, R.C. Wang, E.R. Hruschka Jr,
and T.M. Mitchell. 2010. Coupled Semi-Supervised
Learning for Information Extraction. In Proceed-
ings of the Third ACM International Conference on
Web Search and Data Mining (WSDM), volume 2,
page 110.
O. Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S. Weld, and Alexander Yates. 2005. Unsu-
pervised named-entity extraction from the web - an
experimental study. Artificial Intelligence Journal.
M. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Fourteenth International
</reference>
<footnote confidence="0.920861">
3http://www.talukdar.net/datasets/class inst/
</footnote>
<page confidence="0.967839">
1480
</page>
<reference confidence="0.9997741">
Conference on Computational Linguistics, Nantes,
France.
Metaweb Technologies. 2009. Freebase data dumps.
http://download.freebase.com/datadumps/.
P. Pantel, E. Crestan, A. Borkovsky, A.M. Popescu, and
V. Vyas. 2009. Web-scale distributional similarity
and entity set expansion. Proceedings of EMNLP-
09, Singapore.
M. Pasca and Benjamin Van Durme. 2007. What you
seek is what you get: Extraction of class attributes
from query logs. In IJCAI-07. Ferbruary, 2007.
M. Pennacchiotti and P. Pantel. 2009. Entity Ex-
traction via Ensemble Semantics. Proceedings of
EMNLP-09, Singapore.
K. Probst, R. Ghani, M. Krema, A. Fano, and Y. Liu.
2007. Semi-supervised learning of attribute-value
pairs from product descriptions. In IJCAI-07, Fer-
bruary, 2007.
D. Rao and D. Yarowsky. 2009. Ranking and Semi-
supervised Classification on Large Scale Graphs Us-
ing Map-Reduce. TextGraphs.
J. Reisinger and M. Pasca. 2009. Bootstrapped extrac-
tion of class attributes. In Proceedings of the 18th
international conference on World wide web, pages
1235–1236. ACM.
E. Riloff and R. Jones. 1999. Learning dictionar-
ies for information extraction by multi-level boot-
strapping. In Proceedings of the 16th National Con-
ference on Artificial Intelligence (AAAI-99), pages
474–479, Orlando, Florida.
F.M. Suchanek, G. Kasneci, and G. Weikum. 2007.
Yago: a core of semantic knowledge. In Proceed-
ings of the 16th international conference on World
Wide Web, page 706. ACM.
P. P. Talukdar and Koby Crammer. 2009. New regular-
ized algorithms for transductive learning. In ECML-
PKDD.
P. P. Talukdar, T. Brants, F. Pereira, and M. Liberman.
2006. A context pattern induction method for named
entity extraction. In Tenth Conference on Computa-
tional Natural Language Learning, page 141.
P. P. Talukdar, J. Reisinger, M. Pasca, D. Ravichan-
dran, R. Bhagat, and F. Pereira. 2008. Weakly-
Supervised Acquisition of Labeled Class Instances
using Graph Random Walks. In Proceedings of the
2008 Conference on Empirical Methods in Natural
Language Processing, pages 581–589.
B. Van Durme and M. Pas¸ca. 2008. Finding cars, god-
desses and enzymes: Parametrizable acquisition of
labeled instances for open-domain information ex-
traction. Twenty-Third AAAI Conference on Artifi-
cial Intelligence.
R. Wang and W. Cohen. 2007. Language-Independent
Set Expansion of Named Entities Using the Web.
Data Mining, 2007. ICDM 2007. Seventh IEEE In-
ternational Conference on, pages 342–350.
X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semi-
supervised learning using gaussian fields and har-
monic functions. ICML-03, 20th International Con-
ference on Machine Learning.
</reference>
<page confidence="0.993145">
1481
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341721">
<title confidence="0.9971575">Experiments in Graph-based Semi-Supervised Learning Methods for Class-Instance Acquisition</title>
<author confidence="0.413667">Pratim</author>
<affiliation confidence="0.478933">Search Labs, Microsoft Research</affiliation>
<address confidence="0.996704">Mountain View, CA 94043</address>
<email confidence="0.981379">partha@talukdar.net</email>
<abstract confidence="0.998464">Graph-based semi-supervised learning (SSL) algorithms have been successfully used to extract class-instance pairs from large unstructured and structured text collections. However, a careful comparison of different graph-based SSL algorithms on that task has been lacking. We compare three graph-based SSL algorithms for class-instance acquisition on a variety of graphs constructed from different domains. We find that the recently proposed MAD algorithm is the most effective. We also show that class-instance extraction can be significantly improved by adding semantic information in the form of instance-attribute edges derived from an independently developed knowledge base. All of our code and data will be made publicly available to encourage reproducible research in this area.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Baluja</author>
<author>R Seth</author>
<author>D Sivakumar</author>
<author>Y Jing</author>
<author>J Yagnik</author>
<author>S Kumar</author>
<author>D Ravichandran</author>
<author>M Aly</author>
</authors>
<title>Video suggestion and discovery for youtube: taking random walks through the view graph.</title>
<date>2008</date>
<booktitle>Proceedings of WWW-2008.</booktitle>
<contexts>
<context position="6244" citStr="Baluja et al., 2008" startWordPosition="1014" endWordPosition="1017"> Y� makes sure that the supervised labels are not changed during inference. The above objective can be rewritten as: X Y� &gt; l LY = u,v∈V,l∈C From this, we observe that LP-ZGL penalizes any label assignment where two nodes connected by a highly weighted edge are assigned different labels. In other words, LP-ZGL prefers smooth labelings over the graph. This property is also shared by the two algorithms we shall review next. LP-ZGL has been the basis for much subsequent work in the graph-based SSL area, and is still one of the most effective graph-based SSL algorithms. 2.3 Adsorption Adsorption (Baluja et al., 2008) is a graph-based SSL algorithm which has been used for opendomain class-instance acquisition (Talukdar et al., 2008). Adsorption is an iterative algorithm, where label estimates on node v in the (t + 1)th iteration are updated using estimates from the tth iteration: Y�(t+1) v &apos;__ pinj v xYv+pcont vx B(t)v+pvbnd xr (2) where, B(t) X= Wuv Y�(t) v u u Pu� Wu�v In (2), pinj v , pcont v , and pabnd v are three probabilities defined on each node v E V by Adsorption; and r is a vector used by Adsorption to express label uncertainty at a node. On each node v, the three probabilities sum to one, i.e.,</context>
</contexts>
<marker>Baluja, Seth, Sivakumar, Jing, Yagnik, Kumar, Ravichandran, Aly, 2008</marker>
<rawString>S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik, S. Kumar, D. Ravichandran, and M. Aly. 2008. Video suggestion and discovery for youtube: taking random walks through the view graph. Proceedings of WWW-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Banko</author>
<author>M J Cafarella</author>
<author>S Soderland</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open information extraction from the web. Procs. of IJCAI.</booktitle>
<contexts>
<context position="2971" citStr="Banko et al., 2007" startWordPosition="430" endWordPosition="433">and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009; Banko et al., 2007). • We investigate whether semantic information in the form of instance-attribute edges derived from an independent knowledge base (Suchanek et al., 2007) can improve class-instance acquisition. The intuition behind this is that instances that share attributes are more likely to belong to the same class. We demonstrate that instance-attribute edges significantly improve the accuracy of classinstance extraction. In addition, useful classattribute relationships are learned as a byproduct of this process. • In contrast to previous studies involving pro1473 Proceedings of the 48th Annual Meeting o</context>
<context position="16324" citStr="Banko et al., 2007" startWordPosition="2756" endWordPosition="2759">p, we construct a larger graph from the same 18 domains as in Section 3.1, and using the same graph construction process. We shall call the resulting graph Freebase-2 (see Table 1). In order to scale up the number of classes, we selected all Wordnet (WN) classes, available in the YAGO KB (Suchanek et al., 2007), that had more than 100 instances overMean Reciprocal Rank (MRR) 0.3 0.25 0.2 0.15 170 x 2 170 x 10 Amount of Supervision (# classes x seeds per class) Figure 5: Comparison of graph transduction methods on a graph constructed from the hypernym tuples extracted by the TextRunner system (Banko et al., 2007) (see Section 3.3). All results are averaged over 10 random trials. In each group, MAD is the rightmost bar. In contrast to graph construction from structured tables as in Sections 3.1, 3.2, in this section we use hypernym tuples extracted by TextRunner (Banko et al., 2007), an open domain IE system, to construct the graph. Example of a hypernym tuple extracted by TextRunner is (http, protocol, 0.92), where 0.92 is the extraction confidence. To convert such a tuple into a graph, we create a node for the instance (http) and a node for the class (protocol), and then connect the nodes with two 0.</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>M. Banko, M.J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. 2007. Open information extraction from the web. Procs. of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bellare</author>
<author>P Talukdar</author>
<author>G Kumaran</author>
<author>F Pereira</author>
<author>M Liberman</author>
<author>A McCallum</author>
<author>M Dredze</author>
</authors>
<title>Lightly-Supervised Attribute Extraction.</title>
<date>2007</date>
<booktitle>NIPS 2007 Workshop on Machine Learning</booktitle>
<institution>for Web Search.</institution>
<contexts>
<context position="20864" citStr="Bellare et al., 2007" startWordPosition="3539" endWordPosition="3542">imental setup of Figure 4, with 10 seeds per class. The results for MAD inference over the development split are shown in Figure 6. We observe that performance can vary significantly as the maximum number of classes allowed per node is changed, with the performance peaking at 25. This suggests that sparsity constraints during graph based SSL may have a crucial role to play, a question that needs further investigation. 3.6 TextRunner Graph with additional Semantic Constraints from YAGO Recently, the problem of instance-attribute extraction has started to receive attention (Probst et al., 2007; Bellare et al., 2007; Pasca and Durme, 2007). An example of an instance-attribute pair is (Bob Dylan, albums). Given a set of seed instance-attribute pairs, these methods attempt to extract more instance-attribute pairs automatically 5 15 25 35 45 Maximum Allowed Classes per Node 1478 170 WordNet Classes, 2 Seeds per Class LP-ZGL Adsorption MAD Algorithms 170 WordNet Classes, 10 Seeds per Class LP-ZGL Adsorption MAD Algorithms 0.38 Mean Reciprocal Rank (MRR) 0.33 0.28 0.23 0.18 TextRunner Graph YAGO Graph TextRunner + YAGO Graph 0.45 Mean Reciprocal Rank (MRR) 0.413 0.375 0.338 0.3 TextRunner Graph YAGO Graph Tex</context>
</contexts>
<marker>Bellare, Talukdar, Kumaran, Pereira, Liberman, McCallum, Dredze, 2007</marker>
<rawString>K. Bellare, P. Talukdar, G. Kumaran, F. Pereira, M. Liberman, A. McCallum, and M. Dredze. 2007. Lightly-Supervised Attribute Extraction. NIPS 2007 Workshop on Machine Learning for Web Search.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>J Betteridge</author>
<author>R C Wang</author>
<author>E R Hruschka Jr</author>
<author>T M Mitchell</author>
</authors>
<title>Coupled Semi-Supervised Learning for Information Extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM),</booktitle>
<volume>2</volume>
<pages>110</pages>
<contexts>
<context position="24995" citStr="Carlson et al. (2010)" startWordPosition="4188" endWordPosition="4191">tic constraints from YAGO to the TextRunner graph results in a better connected graph which in turn results in better inference by the graphbased SSL algorithms, compared to using either of the sources, i.e., TextRunner output or YAGO attributes, in isolation. This further illustrates the advantage of aggregating information across sources (Talukdar et al., 2008; Pennacchiotti and Pantel, 2009). However, we are the first, to the best of our knowledge, to demonstrate the effectiveness of attributes in class-instance acquisition. We note that this work is similar in spirit to the recent work by Carlson et al. (2010) which also demonstrates the benefits of additional constraints in SSL. Because of the label propagation behavior, graph-based SSL algorithms assign classes to all nodes reachable in the graph from at least one of the labeled instance nodes. This allows us to check the classes assigned to nodes corresponding to YAGO attributes in the TextRunner + YAGO graph, as shown in Table 2. Even though the experiments were designed for classinstance acquisition, it is encouraging to see that the graph-based SSL algorithm (MAD in Table 2) is able to learn class-attribute relationships, an important by-prod</context>
</contexts>
<marker>Carlson, Betteridge, Wang, Jr, Mitchell, 2010</marker>
<rawString>A. Carlson, J. Betteridge, R.C. Wang, E.R. Hruschka Jr, and T.M. Mitchell. 2010. Coupled Semi-Supervised Learning for Information Extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM), volume 2, page 110.</rawString>
</citation>
<citation valid="false">
<authors>
<author>O Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>AnaMaria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web - an experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence</journal>
<booktitle>In Fourteenth International Conference on Computational Linguistics,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="1993" citStr="Etzioni et al., 2005" startWordPosition="280" endWordPosition="283">classification of terms into those classes. While supervised learning methods perform well for traditional NER, they are impractical for fine-grained classification because sufficient labeled data to train classifiers for all the classes is unavailable and would be very expensive to obtain. * Research carried out while at the University of Pennsylvania, Philadelphia, PA, USA. Fernando Pereira Google, Inc. Mountain View, CA 94043 pereira@google.com To overcome these difficulties, seed-based information extraction methods have been developed over the years (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contribu</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>O. Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web - an experimental study. Artificial Intelligence Journal. M. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Fourteenth International Conference on Computational Linguistics, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Metaweb Technologies</author>
</authors>
<date>2009</date>
<note>Freebase data dumps. http://download.freebase.com/datadumps/.</note>
<contexts>
<context position="2950" citStr="Technologies, 2009" startWordPosition="427" endWordPosition="429">g and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009; Banko et al., 2007). • We investigate whether semantic information in the form of instance-attribute edges derived from an independent knowledge base (Suchanek et al., 2007) can improve class-instance acquisition. The intuition behind this is that instances that share attributes are more likely to belong to the same class. We demonstrate that instance-attribute edges significantly improve the accuracy of classinstance extraction. In addition, useful classattribute relationships are learned as a byproduct of this process. • In contrast to previous studies involving pro1473 Proceedings of the </context>
<context position="10204" citStr="Technologies, 2009" startWordPosition="1720" endWordPosition="1721">� � � � Isaac Newton Lincolnshire Male Bob Dylan Duluth Male Johnny Cash Kingsland Male � � � � � � � � � Table ID: film-music contributor Figure 1: Examples of two tables from Freebase, one table is from the people domain while the other is from the film domain. Freebase-1 Graph, 23 Pantel Classes Amount of Supervision (# Classes x seeds per Class) Figure 3: Comparison of three graph transduction methods on a graph constructed from the Freebase dataset (see Section 3.1), with 23 classes. All results are averaged over 4 random trials. In each group, MAD is the rightmost bar. Freebase (Metaweb Technologies, 2009)2 is a large collaborative knowledge base. The knowledge base harvests information from many open data sets (for instance Wikipedia and MusicBrainz), as well as from user contributions. For our current purposes, we can think of the Freebase 2http://www.freebase.com/ Name Bob Dylan � � � � � � Film Music Credits No Direction Home � � � � � � 0.8 23 x 2 23 x 10 Mean Reciprocal Rank (MRR) 0.725 0.65 0.575 0.5 LP-ZGL Adsorption MAD � T min µ1~Y− Y~ 5~Y− Y~+ Y� lEC 1475 Graph Vertices Edges Avg. Min. Max. Deg. Deg. Deg. Freebase-1 (Section 3.1) 32970 957076 29.03 1 13222 Freebase-2 (Section 3.2) 30</context>
</contexts>
<marker>Technologies, 2009</marker>
<rawString>Metaweb Technologies. 2009. Freebase data dumps. http://download.freebase.com/datadumps/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>E Crestan</author>
<author>A Borkovsky</author>
<author>A M Popescu</author>
<author>V Vyas</author>
</authors>
<title>Web-scale distributional similarity and entity set expansion.</title>
<date>2009</date>
<booktitle>Proceedings of EMNLP09,</booktitle>
<contexts>
<context position="13824" citStr="Pantel et al. (2009)" startWordPosition="2335" endWordPosition="2338"> similar class labels. In other words, the label smoothness assumption (see Section 2.2) holds on such graphs. We applied the same graph construction process on a subset of the Freebase dataset consisting of topics from 18 randomly selected domains: astronomy, automotive, biology, book, business, 1476 chemistry, comic books, computer, film, food, geography, location, people, religion, spaceflight, tennis, travel, and wine. The topics in this subset were further filtered so that only cell-value nodes with frequency 10 or more were retained. We call the resulting graph Freebase-1 (see Table 1). Pantel et al. (2009) have made available a set of gold class-instance pairs derived from Wikipedia, which is downloadable from http://ow.ly/13B57. From this set, we selected all classes which had more than 10 instances overlapping with the Freebase graph constructed above. This resulted in 23 classes, which along with their overlapping instances were used as the gold standard set for the experiments in this section. Experimental results with 2 and 10 seeds (labeled nodes) per class are shown in Figure 3. From the figure, we see that that LP-ZGL and Adsorption performed comparably on this dataset, with MAD signifi</context>
</contexts>
<marker>Pantel, Crestan, Borkovsky, Popescu, Vyas, 2009</marker>
<rawString>P. Pantel, E. Crestan, A. Borkovsky, A.M. Popescu, and V. Vyas. 2009. Web-scale distributional similarity and entity set expansion. Proceedings of EMNLP09, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pasca</author>
<author>Benjamin Van Durme</author>
</authors>
<title>What you seek is what you get: Extraction of class attributes from query logs.</title>
<date>2007</date>
<booktitle>In IJCAI-07. Ferbruary,</booktitle>
<marker>Pasca, Van Durme, 2007</marker>
<rawString>M. Pasca and Benjamin Van Durme. 2007. What you seek is what you get: Extraction of class attributes from query logs. In IJCAI-07. Ferbruary, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pennacchiotti</author>
<author>P Pantel</author>
</authors>
<title>Entity Extraction via Ensemble Semantics.</title>
<date>2009</date>
<booktitle>Proceedings of EMNLP-09,</booktitle>
<contexts>
<context position="2561" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="366" endWordPosition="370">ars (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009; Banko et al., 2007). • We investigate whether semantic information in the form of instance-attribute edges derived from an independent knowledge base (Suchanek et al., 2007) can improve class-instance acquisit</context>
<context position="3821" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="553" endWordPosition="556">s is that instances that share attributes are more likely to belong to the same class. We demonstrate that instance-attribute edges significantly improve the accuracy of classinstance extraction. In addition, useful classattribute relationships are learned as a byproduct of this process. • In contrast to previous studies involving pro1473 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1473–1481, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics prietary datasets (Van Durme and Pas¸ca, 2008; Talukdar et al., 2008; Pennacchiotti and Pantel, 2009), all of our experiments use publicly available datasets and we plan to release our code1. In Section 2, we review three graph-based SSL algorithms that are compared for the classinstance acquisition task in Section 3. In Section 3.6, we show how additional instance-attribute based semantic constraints can be used to improve class-instance acquisition performance. We summarize the results and outline future work in Section 4. 2 Graph-based SSL We now review the three graph-based SSL algorithms for class inference over graphs that we have evaluated. 2.1 Notation All the algorithms compute a sof</context>
<context position="24771" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="4149" endWordPosition="4152">n all experimental conditions with 2 and 10 seeds per class in Figure 7, we observe that the three methods consistently achieved the best performance on the TextRunner + YAGO graph. This suggests that addition of attribute based semantic constraints from YAGO to the TextRunner graph results in a better connected graph which in turn results in better inference by the graphbased SSL algorithms, compared to using either of the sources, i.e., TextRunner output or YAGO attributes, in isolation. This further illustrates the advantage of aggregating information across sources (Talukdar et al., 2008; Pennacchiotti and Pantel, 2009). However, we are the first, to the best of our knowledge, to demonstrate the effectiveness of attributes in class-instance acquisition. We note that this work is similar in spirit to the recent work by Carlson et al. (2010) which also demonstrates the benefits of additional constraints in SSL. Because of the label propagation behavior, graph-based SSL algorithms assign classes to all nodes reachable in the graph from at least one of the labeled instance nodes. This allows us to check the classes assigned to nodes corresponding to YAGO attributes in the TextRunner + YAGO graph, as shown in Tab</context>
</contexts>
<marker>Pennacchiotti, Pantel, 2009</marker>
<rawString>M. Pennacchiotti and P. Pantel. 2009. Entity Extraction via Ensemble Semantics. Proceedings of EMNLP-09, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Probst</author>
<author>R Ghani</author>
<author>M Krema</author>
<author>A Fano</author>
<author>Y Liu</author>
</authors>
<title>Semi-supervised learning of attribute-value pairs from product descriptions.</title>
<date>2007</date>
<booktitle>In IJCAI-07, Ferbruary,</booktitle>
<contexts>
<context position="20842" citStr="Probst et al., 2007" startWordPosition="3535" endWordPosition="3538">n the graph and experimental setup of Figure 4, with 10 seeds per class. The results for MAD inference over the development split are shown in Figure 6. We observe that performance can vary significantly as the maximum number of classes allowed per node is changed, with the performance peaking at 25. This suggests that sparsity constraints during graph based SSL may have a crucial role to play, a question that needs further investigation. 3.6 TextRunner Graph with additional Semantic Constraints from YAGO Recently, the problem of instance-attribute extraction has started to receive attention (Probst et al., 2007; Bellare et al., 2007; Pasca and Durme, 2007). An example of an instance-attribute pair is (Bob Dylan, albums). Given a set of seed instance-attribute pairs, these methods attempt to extract more instance-attribute pairs automatically 5 15 25 35 45 Maximum Allowed Classes per Node 1478 170 WordNet Classes, 2 Seeds per Class LP-ZGL Adsorption MAD Algorithms 170 WordNet Classes, 10 Seeds per Class LP-ZGL Adsorption MAD Algorithms 0.38 Mean Reciprocal Rank (MRR) 0.33 0.28 0.23 0.18 TextRunner Graph YAGO Graph TextRunner + YAGO Graph 0.45 Mean Reciprocal Rank (MRR) 0.413 0.375 0.338 0.3 TextRunne</context>
</contexts>
<marker>Probst, Ghani, Krema, Fano, Liu, 2007</marker>
<rawString>K. Probst, R. Ghani, M. Krema, A. Fano, and Y. Liu. 2007. Semi-supervised learning of attribute-value pairs from product descriptions. In IJCAI-07, Ferbruary, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rao</author>
<author>D Yarowsky</author>
</authors>
<title>Ranking and Semisupervised Classification on Large Scale Graphs Using Map-Reduce.</title>
<date>2009</date>
<tech>TextGraphs.</tech>
<contexts>
<context position="8647" citStr="Rao and Yarowsky, 2009" startWordPosition="1446" endWordPosition="1449">revised edge weights; and R is an n x m matrix of per-node label prior, if any, with Rl representing the lth column of R. As in Adsorption, MAD allows labels on seed nodes to change. In case of MAD, the three random-walk probabilities, pinj v , pcont v , and pabnd v , defined by Adsorption on each node are folded inside the matrices 5, L, and R, respectively. The optimization problem in (3) can be solved with an efficient iterative algorithm described in detail by Talukdar and Crammer (2009). These three algorithms are all easily parallelizable in a MapReduce framework (Talukdar et al., 2008; Rao and Yarowsky, 2009), which makes them suitable for SSL on large datasets. Additionally, all three algorithms have similar space and time complexity. 3 Experiments We now compare the experimental performance of the three graph-based SSL algorithms reviewed in the previous section, using graphs constructed from a variety of sources described below. Following previous work (Talukdar et al., 2008), we use Mean Reciprocal Rank (MRR) as the evaluation metric in all experiments: 1 X 1 MRR = (4) |Q |vEQ rv where Q C_ V is the set of test nodes, and rv is the rank of the gold label among the labels assigned to node v. Hi</context>
</contexts>
<marker>Rao, Yarowsky, 2009</marker>
<rawString>D. Rao and D. Yarowsky. 2009. Ranking and Semisupervised Classification on Large Scale Graphs Using Map-Reduce. TextGraphs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reisinger</author>
<author>M Pasca</author>
</authors>
<title>Bootstrapped extraction of class attributes.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th international conference on World wide web,</booktitle>
<pages>1235--1236</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="25668" citStr="Reisinger and Pasca, 2009" startWordPosition="4297" endWordPosition="4300">onal constraints in SSL. Because of the label propagation behavior, graph-based SSL algorithms assign classes to all nodes reachable in the graph from at least one of the labeled instance nodes. This allows us to check the classes assigned to nodes corresponding to YAGO attributes in the TextRunner + YAGO graph, as shown in Table 2. Even though the experiments were designed for classinstance acquisition, it is encouraging to see that the graph-based SSL algorithm (MAD in Table 2) is able to learn class-attribute relationships, an important by-product that has been the focus of recent studies (Reisinger and Pasca, 2009). For example, the algorithm is able to learn that works at is an attribute of the WordNet class wordnet scientist 110560637, and thereby its instances (e.g. Aage Niels Bohr, Adi Shamir). 4 Conclusion We have started a systematic experimental comparison of graph-based SSL algorithms for classinstance acquisition on a variety of graphs constructed from different domains. We found that MAD, a recently proposed graph-based SSL algorithm, is consistently the most effective across the various experimental conditions. We also showed that class-instance acquisition performance can be significantly im</context>
</contexts>
<marker>Reisinger, Pasca, 2009</marker>
<rawString>J. Reisinger and M. Pasca. 2009. Bootstrapped extraction of class attributes. In Proceedings of the 18th international conference on World wide web, pages 1235–1236. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th National Conference on Artificial Intelligence (AAAI-99),</booktitle>
<pages>474--479</pages>
<location>Orlando, Florida.</location>
<contexts>
<context position="1971" citStr="Riloff and Jones, 1999" startWordPosition="276" endWordPosition="279">ic classes and accurate classification of terms into those classes. While supervised learning methods perform well for traditional NER, they are impractical for fine-grained classification because sufficient labeled data to train classifiers for all the classes is unavailable and would be very expensive to obtain. * Research carried out while at the University of Pennsylvania, Philadelphia, PA, USA. Fernando Pereira Google, Inc. Mountain View, CA 94043 pereira@google.com To overcome these difficulties, seed-based information extraction methods have been developed over the years (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make </context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the 16th National Conference on Artificial Intelligence (AAAI-99), pages 474–479, Orlando, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>706</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3125" citStr="Suchanek et al., 2007" startWordPosition="453" endWordPosition="456">een demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009; Banko et al., 2007). • We investigate whether semantic information in the form of instance-attribute edges derived from an independent knowledge base (Suchanek et al., 2007) can improve class-instance acquisition. The intuition behind this is that instances that share attributes are more likely to belong to the same class. We demonstrate that instance-attribute edges significantly improve the accuracy of classinstance extraction. In addition, useful classattribute relationships are learned as a byproduct of this process. • In contrast to previous studies involving pro1473 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1473–1481, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics priet</context>
<context position="16017" citStr="Suchanek et al., 2007" startWordPosition="2700" endWordPosition="2703">Net Classes Amount of Supervision (# classes x seeds per class) Figure 4: Comparison of graph transduction methods on a graph constructed from the Freebase dataset (see Section 3.2). All results are averaged over 10 random trials. In each group, MAD is the rightmost bar. To evaluate how the algorithms scale up, we construct a larger graph from the same 18 domains as in Section 3.1, and using the same graph construction process. We shall call the resulting graph Freebase-2 (see Table 1). In order to scale up the number of classes, we selected all Wordnet (WN) classes, available in the YAGO KB (Suchanek et al., 2007), that had more than 100 instances overMean Reciprocal Rank (MRR) 0.3 0.25 0.2 0.15 170 x 2 170 x 10 Amount of Supervision (# classes x seeds per class) Figure 5: Comparison of graph transduction methods on a graph constructed from the hypernym tuples extracted by the TextRunner system (Banko et al., 2007) (see Section 3.3). All results are averaged over 10 random trials. In each group, MAD is the rightmost bar. In contrast to graph construction from structured tables as in Sections 3.1, 3.2, in this section we use hypernym tuples extracted by TextRunner (Banko et al., 2007), an open domain IE</context>
<context position="17383" citStr="Suchanek et al., 2007" startWordPosition="2946" endWordPosition="2949">fidence. To convert such a tuple into a graph, we create a node for the instance (http) and a node for the class (protocol), and then connect the nodes with two 0.39 192 x 2 192 x 10 Mean Reciprocal Rank (MRR) 0.355 0.32 0.285 0.25 LP-ZGL Adsorption MAD 1477 directed edges in both directions, with the extraction confidence (0.92) as edge weights. The graph created with this process from TextRunner output is called the TextRunner Graph (see Table 1). As in Section 3.2, we use WordNet class-instance pairs as the gold set. In this case, we considered all WordNet classes, once again from YAGO KB (Suchanek et al., 2007), which had more than 50 instances overlapping with the constructed graph. This resulted in 170 WordNet classes being used for the experiments in this section. Experimental results with 2 and 10 seeds per class are shown in Figure 5. The three methods are comparable in this setting, with MAD achieving the highest overall MRR. 3.4 Discussion If we correlate the graph statistics in Table 1 with the results of sections 3.1, 3.2, and 3.3, we see that MAD is most effective for graphs with high average degree, that is, graphs where nodes tend to connect to many other nodes. For instance, the Freebas</context>
<context position="24012" citStr="Suchanek et al., 2007" startWordPosition="4026" endWordPosition="4029">ints are naturally captured by the methods reviewed in Section 2. All that is necessary is the introduction of bidirectional (instance, attribute) edges to the graph, as shown in Figure 2 (b). In Figure 7, we compare class-instance acquisition performance of the three graph-based SSL methods (Section 2) on the following three graphs (also see Table 1): TextRunner Graph: Graph constructed from the hypernym tuples extracted by TextRunner, as in Figure 5 (Section 3.3), with 175k vertices and 529k edges. YAGO Graph: Graph constructed from the (instance, attribute) pairs obtained from the YAGO KB (Suchanek et al., 2007), with 142k nodes and 777k edges. TextRunner + YAGO Graph: Union of the 1479 two graphs above, with 237k nodes and 1.3m edges. In all experimental conditions with 2 and 10 seeds per class in Figure 7, we observe that the three methods consistently achieved the best performance on the TextRunner + YAGO graph. This suggests that addition of attribute based semantic constraints from YAGO to the TextRunner graph results in a better connected graph which in turn results in better inference by the graphbased SSL algorithms, compared to using either of the sources, i.e., TextRunner output or YAGO att</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>F.M. Suchanek, G. Kasneci, and G. Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web, page 706. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P Talukdar</author>
<author>Koby Crammer</author>
</authors>
<title>New regularized algorithms for transductive learning.</title>
<date>2009</date>
<booktitle>In ECMLPKDD.</booktitle>
<contexts>
<context position="7351" citStr="Talukdar and Crammer, 2009" startWordPosition="1216" endWordPosition="1220">tor used by Adsorption to express label uncertainty at a node. On each node v, the three probabilities sum to one, i.e., pinj v + pcont v+ pabnd v = 1, and they are based on the random-walk interpretation of the Adsorption algorithm (Talukdar et al., 2008). The main idea of Adsorption is to control label propagation more tightly by limiting the amount of information that passes through a node. For instance, Adsorption can reduce the importance of a high-degree node v during the label inference process by increasing pabnd v on that node. For more details on these, please refer to Section 2 of (Talukdar and Crammer, 2009). In contrast to LP-ZGL, Adsorption allows labels on labeled (seed) nodes to change, which is desirable in case of noisy input labels. (1) X l∈C Wuv(�Yul _ kvl)2 1474 2.4 Modified Adsorption (MAD) Talukdar and Crammer (2009) introduced a modification of Adsorption called MAD, which shares Adsorption’s desirable properties but can be expressed as an unconstrained optimization problem: of this paper. Statistics of the graphs used during experiments in this section are presented in Table 1. 3.1 Freebase-1 Graph with Pantel Classes 2 µ2 � l L Y + µ3 Y − Rl (3) where µ1, µ2, and µ3 are hyperparamet</context>
<context position="18919" citStr="Talukdar and Crammer, 2009" startWordPosition="3205" endWordPosition="3209"> underregularized, i.e., its model parameters (Y) are not constrained enough, compared to MAD (Equation 3, specifically the third term), resulting in overfitting in case of highly connected graphs. In contrast, MAD is able to avoid such overfitting because of its minimization of a well regularized objective (Equation 3). Based on this, we suggest that average degree, an easily computable structural property of the graph, may be a useful indicator in choosing which graph-based SSL algorithm should be applied on a given graph. Unlike MAD, Adsorption does not optimize any well defined objective (Talukdar and Crammer, 2009), and hence any analysis along the lines described above is not possible. The heuristic choices made in Adsorption may have lead to its sub-optimal performance compared to MAD; we leave it as a topic for future investigation. 3.5 Effect of Per-Node Class Sparsity For all the experiments in Sections 3.1, 3.2, and 3.6, each node was allowed to have a maximum of 15 classes during inference. After each update Effect of Per-node Sparsity Constraint 0.42 Mean Reciprocal Rank (MRR) 0.39 0.36 0.33 0.3 Figure 6: Effect of per node class sparsity (maximum number of classes allowed per node) during MAD i</context>
</contexts>
<marker>Talukdar, Crammer, 2009</marker>
<rawString>P. P. Talukdar and Koby Crammer. 2009. New regularized algorithms for transductive learning. In ECMLPKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P Talukdar</author>
<author>T Brants</author>
<author>F Pereira</author>
<author>M Liberman</author>
</authors>
<title>A context pattern induction method for named entity extraction.</title>
<date>2006</date>
<booktitle>In Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>141</pages>
<contexts>
<context position="2016" citStr="Talukdar et al., 2006" startWordPosition="284" endWordPosition="287">s into those classes. While supervised learning methods perform well for traditional NER, they are impractical for fine-grained classification because sufficient labeled data to train classifiers for all the classes is unavailable and would be very expensive to obtain. * Research carried out while at the University of Pennsylvania, Philadelphia, PA, USA. Fernando Pereira Google, Inc. Mountain View, CA 94043 pereira@google.com To overcome these difficulties, seed-based information extraction methods have been developed over the years (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though gr</context>
</contexts>
<marker>Talukdar, Brants, Pereira, Liberman, 2006</marker>
<rawString>P. P. Talukdar, T. Brants, F. Pereira, and M. Liberman. 2006. A context pattern induction method for named entity extraction. In Tenth Conference on Computational Natural Language Learning, page 141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P Talukdar</author>
<author>J Reisinger</author>
<author>M Pasca</author>
<author>D Ravichandran</author>
<author>R Bhagat</author>
<author>F Pereira</author>
</authors>
<title>WeaklySupervised Acquisition of Labeled Class Instances using Graph Random Walks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>581--589</pages>
<contexts>
<context position="2447" citStr="Talukdar et al., 2008" startWordPosition="351" endWordPosition="354">To overcome these difficulties, seed-based information extraction methods have been developed over the years (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009; Banko et al., 2007). • We investigate whether semantic information in the form of instance-attr</context>
<context position="3788" citStr="Talukdar et al., 2008" startWordPosition="549" endWordPosition="552">he intuition behind this is that instances that share attributes are more likely to belong to the same class. We demonstrate that instance-attribute edges significantly improve the accuracy of classinstance extraction. In addition, useful classattribute relationships are learned as a byproduct of this process. • In contrast to previous studies involving pro1473 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1473–1481, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics prietary datasets (Van Durme and Pas¸ca, 2008; Talukdar et al., 2008; Pennacchiotti and Pantel, 2009), all of our experiments use publicly available datasets and we plan to release our code1. In Section 2, we review three graph-based SSL algorithms that are compared for the classinstance acquisition task in Section 3. In Section 3.6, we show how additional instance-attribute based semantic constraints can be used to improve class-instance acquisition performance. We summarize the results and outline future work in Section 4. 2 Graph-based SSL We now review the three graph-based SSL algorithms for class inference over graphs that we have evaluated. 2.1 Notation</context>
<context position="6361" citStr="Talukdar et al., 2008" startWordPosition="1032" endWordPosition="1035">: X Y� &gt; l LY = u,v∈V,l∈C From this, we observe that LP-ZGL penalizes any label assignment where two nodes connected by a highly weighted edge are assigned different labels. In other words, LP-ZGL prefers smooth labelings over the graph. This property is also shared by the two algorithms we shall review next. LP-ZGL has been the basis for much subsequent work in the graph-based SSL area, and is still one of the most effective graph-based SSL algorithms. 2.3 Adsorption Adsorption (Baluja et al., 2008) is a graph-based SSL algorithm which has been used for opendomain class-instance acquisition (Talukdar et al., 2008). Adsorption is an iterative algorithm, where label estimates on node v in the (t + 1)th iteration are updated using estimates from the tth iteration: Y�(t+1) v &apos;__ pinj v xYv+pcont vx B(t)v+pvbnd xr (2) where, B(t) X= Wuv Y�(t) v u u Pu� Wu�v In (2), pinj v , pcont v , and pabnd v are three probabilities defined on each node v E V by Adsorption; and r is a vector used by Adsorption to express label uncertainty at a node. On each node v, the three probabilities sum to one, i.e., pinj v + pcont v+ pabnd v = 1, and they are based on the random-walk interpretation of the Adsorption algorithm (Tal</context>
<context position="8622" citStr="Talukdar et al., 2008" startWordPosition="1442" endWordPosition="1445">rived from G, but with revised edge weights; and R is an n x m matrix of per-node label prior, if any, with Rl representing the lth column of R. As in Adsorption, MAD allows labels on seed nodes to change. In case of MAD, the three random-walk probabilities, pinj v , pcont v , and pabnd v , defined by Adsorption on each node are folded inside the matrices 5, L, and R, respectively. The optimization problem in (3) can be solved with an efficient iterative algorithm described in detail by Talukdar and Crammer (2009). These three algorithms are all easily parallelizable in a MapReduce framework (Talukdar et al., 2008; Rao and Yarowsky, 2009), which makes them suitable for SSL on large datasets. Additionally, all three algorithms have similar space and time complexity. 3 Experiments We now compare the experimental performance of the three graph-based SSL algorithms reviewed in the previous section, using graphs constructed from a variety of sources described below. Following previous work (Talukdar et al., 2008), we use Mean Reciprocal Rank (MRR) as the evaluation metric in all experiments: 1 X 1 MRR = (4) |Q |vEQ rv where Q C_ V is the set of test nodes, and rv is the rank of the gold label among the labe</context>
<context position="24738" citStr="Talukdar et al., 2008" startWordPosition="4145" endWordPosition="4148">nodes and 1.3m edges. In all experimental conditions with 2 and 10 seeds per class in Figure 7, we observe that the three methods consistently achieved the best performance on the TextRunner + YAGO graph. This suggests that addition of attribute based semantic constraints from YAGO to the TextRunner graph results in a better connected graph which in turn results in better inference by the graphbased SSL algorithms, compared to using either of the sources, i.e., TextRunner output or YAGO attributes, in isolation. This further illustrates the advantage of aggregating information across sources (Talukdar et al., 2008; Pennacchiotti and Pantel, 2009). However, we are the first, to the best of our knowledge, to demonstrate the effectiveness of attributes in class-instance acquisition. We note that this work is similar in spirit to the recent work by Carlson et al. (2010) which also demonstrates the benefits of additional constraints in SSL. Because of the label propagation behavior, graph-based SSL algorithms assign classes to all nodes reachable in the graph from at least one of the labeled instance nodes. This allows us to check the classes assigned to nodes corresponding to YAGO attributes in the TextRun</context>
</contexts>
<marker>Talukdar, Reisinger, Pasca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>P. P. Talukdar, J. Reisinger, M. Pasca, D. Ravichandran, R. Bhagat, and F. Pereira. 2008. WeaklySupervised Acquisition of Labeled Class Instances using Graph Random Walks. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 581–589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Van Durme</author>
<author>M Pas¸ca</author>
</authors>
<title>Finding cars, goddesses and enzymes: Parametrizable acquisition of labeled instances for open-domain information extraction.</title>
<date>2008</date>
<booktitle>Twenty-Third AAAI Conference on Artificial Intelligence.</booktitle>
<marker>Van Durme, Pas¸ca, 2008</marker>
<rawString>B. Van Durme and M. Pas¸ca. 2008. Finding cars, goddesses and enzymes: Parametrizable acquisition of labeled instances for open-domain information extraction. Twenty-Third AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wang</author>
<author>W Cohen</author>
</authors>
<title>Language-Independent Set Expansion of Named Entities Using the Web. Data Mining,</title>
<date>2007</date>
<booktitle>ICDM 2007. Seventh IEEE International Conference on,</booktitle>
<pages>342--350</pages>
<contexts>
<context position="2350" citStr="Wang and Cohen, 2007" startWordPosition="336" endWordPosition="339">Philadelphia, PA, USA. Fernando Pereira Google, Inc. Mountain View, CA 94043 pereira@google.com To overcome these difficulties, seed-based information extraction methods have been developed over the years (Hearst, 1992; Riloff and Jones, 1999; Etzioni et al., 2005; Talukdar et al., 2006; Van Durme and Pas¸ca, 2008). Starting with a few seed instances for some classes, these methods, through analysis of unstructured text, extract new instances of the same class. This line of work has evolved to incorporate ideas from graph-based semi-supervised learning in extraction from semi-structured text (Wang and Cohen, 2007), and in combining extractions from free text and from structured sources (Talukdar et al., 2008). The benefits of combining multiple sources have also been demonstrated recently (Pennacchiotti and Pantel, 2009). We make the following contributions: • Even though graph-based SSL algorithms have achieved early success in class-instance acquisition, there is no study comparing different graph-based SSL methods on this task. We address this gap with a series of experiments comparing three graph-based SSL algorithms (Section 2) on graphs constructed from several sources (Metaweb Technologies, 2009</context>
</contexts>
<marker>Wang, Cohen, 2007</marker>
<rawString>R. Wang and W. Cohen. 2007. Language-Independent Set Expansion of Named Entities Using the Web. Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on, pages 342–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
<author>J Lafferty</author>
</authors>
<title>Semisupervised learning using gaussian fields and harmonic functions.</title>
<date>2003</date>
<booktitle>ICML-03, 20th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="5339" citStr="Zhu et al. (2003)" startWordPosition="852" endWordPosition="855">malized) Laplacian, L, of G is given by L = D_W, where D is an nxn diagonal degree matrix with Duu = Pv Wuv. Let S be an n x n diagonal matrix with Suu = 1 iff node u E V is labeled. That is, S identifies the labeled nodes in the graph. C is the set of labels, with JCJ = m representing the total number of labels. Y is the n x m matrix storing training label information, if any. Y is an n x m matrix of soft label assignments, with Yvl representing the score of label l on node v. A graph-based SSL computes Y from {G, SY }. 2.2 Label Propagation (LP-ZGL) The label propagation method presented by Zhu et al. (2003), which we shall refer to as LP-ZGL in this paper, is one of the first graph-based SSL methods. The objective minimized by LP-ZGL is: X min Y� &gt; l LY, s.t. SYl = S Y Y l∈C 1http://www.talukdar.net/datasets/class inst/ where Y of size n x 1 is the lth column of Y. The constraint SY = S Y� makes sure that the supervised labels are not changed during inference. The above objective can be rewritten as: X Y� &gt; l LY = u,v∈V,l∈C From this, we observe that LP-ZGL penalizes any label assignment where two nodes connected by a highly weighted edge are assigned different labels. In other words, LP-ZGL pre</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semisupervised learning using gaussian fields and harmonic functions. ICML-03, 20th International Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>