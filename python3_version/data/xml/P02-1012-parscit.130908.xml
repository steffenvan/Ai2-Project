<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.95205">
Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 88-95.
</note>
<title confidence="0.989325">
Pronominalization in Generated Discourse and Dialogue
</title>
<author confidence="0.804123">
Charles B. Callaway James C. Lester
</author>
<affiliation confidence="0.4556195">
Istituto per la Ricerca Scientifica e Department of Computer Science
Tecnologica (ITC-irst), Italy North Carolina State University, USA
</affiliation>
<email confidence="0.996199">
callaway@irst.itc.it lester@adm.csc.ncsu.edu
</email>
<sectionHeader confidence="0.99557" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905071428572">
Previous approaches to pronominalization
have largely been theoretical rather than
applied in nature. Frequently, such meth-
ods are based on Centering Theory, which
deals with the resolution of anaphoric pro-
nouns. But it is not clear that complex the-
oretical mechanisms, while having satis-
fying explanatory power, are necessary for
the actual generation of pronouns. We first
illustrate examples of pronouns from vari-
ous domains, describe a simple method for
generating pronouns in an implemented
multi-page generation system, and present
an evaluation of its performance.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949083333333">
Pronominalization is an important element in the au-
tomatic creation of multi-paragraph and multi-page
texts using natural language generation (NLG). Au-
thors routinely use pronouns in texts spanning all
types of genres, such as newspaper copy, science
fiction and even academic papers. Indeed, without
pronouns, texts quickly become confusing as readers
begin to pay more attention to the writing style than
to the content that makes the text informative or en-
joyable (Callaway and Lester, 2001a). Even worse,
incorrect pronouns can lead readers to misinterpret
the text or draw unsound inferences.
Furthermore, current pronominalization strategies
are ill-equipped to deal with the wide variety of
reasons that pronouns are used in naturally occur-
ring texts. Almost without exception, they focus on
anaphoric pronouns as described in Focus/Centering
Theory (Webber, 1979; Sidner, 1983; Grosz and Sid-
ner, 1986; Walker, 1998), ignoring the multitude of
other possible types. However, it is certainly true
that authors make use of pronouns which are not mo-
tivated by anaphoric reference.
In addition, because such approaches are oriented
towards anaphora resolution during parsing, they ig-
nore structures such as the discourse plan which are
present during generation but not parsing. A typi-
cal discourse plan can include vital information for
pronominalization such as time and clause bound-
aries, ordering of propositions, and semantic de-
tails verbal arguments. Current approaches based
on Centering algorithms thus attempt to recreate a
text coherence structure that duplicates work already
done by the discourse planner.
Finally, there are significant obstacles to verifying
the correctness of existing pronominalization algo-
rithms for any pronominalization theory (Not, 1996;
Yeh and Mellish, 1997; McCoy and Strube, 1999;
Henschel et al., 2000; Kibble and Power, 2000): the
lack of natural language generation systems that can
produce large enough texts to bring discourse-level
processes into play. Because of this, researchers are
forced to simulate by hand how their algorithms will
work on a given text. It is also not sufficient to use
template generation systems to perform this task be-
cause they lack the low-level discourse representa-
tion needed to provide the information upon which
most algorithms base their decisions.
In this paper we first summarize related work
in both anaphora resolution and anaphora genera-
tion. We next describe the range of pronoun types
that we found in a wide variety of texts. We pro-
ceed to describe an algorithm for determining ap-
propriate pronominalizations that uses existing NLG
structures and simple numeric techniques. We also
briefly describe an implemented generation system
that contains enough low-level discourse informa-
tion to motivate pronominalization decisions using
this method. Finally, we quantitatively demonstrate
the performance of this simple numerical approach
in both a newspaper and fictional narrative domain.
</bodyText>
<sectionHeader confidence="0.871009" genericHeader="introduction">
2 Background and Related Work
</sectionHeader>
<bodyText confidence="0.999891678571429">
Because most NLG systems have focused on lin-
guistic phenomena at the paragraph level and be-
low, there has been intensive investigation into the
core areas of generation that are required to pro-
duce them: discourse planning, sentence planning
and surface realization. Since pronouns are more
likely to be a multiparagraph, discourse-level phe-
nomenon, it has been possible to ignore their inclu-
sion into working NLG systems which are not called
upon to generate lengthy passages.
Indeed, most work on pronouns in computational
linguistics has come under the heading of anaphora
resolution as an element of parsing rather than the
heading of pronominalization as an element of gen-
eration. Since discourse anaphora resolution was
first studied theoretically (Grosz, 1977; Webber,
1979; Sidner, 1983; Grosz and Sidner, 1986), it has
come to be dominated by Centering Theory (Grosz
et al., 1995; Di Eugenio, 1998; Walker, 1998) which
proposes rules for the determination of focus and
salience within a given segment of discourse. Rel-
atively little work has been done on alternate ap-
proaches to pronoun resolution (Hobbs, 1976; Bald-
win, 1995).
While many NLG researchers have attempted to
transfer the ideas of Centering Theory to genera-
tion (Not, 1996; Yeh and Mellish, 1997; McCoy
and Strube, 1999; Henschel et al., 2000; Kibble
and Power, 2000), there has yet been no substan-
tial return contribution to the field of anaphora res-
olution. There are two principal reasons for this.
First, it is extremely difficult to create an NLG sys-
tem that generates the large quantity of texts needed
to exhibit discourse-level phenomena while consis-
tently employing the deep linguistic representations
needed to determine appropriate pronominal forms.
Second, Centering Theory is still vague on the ex-
act definition of terms such as “segment” (Poesio et
al., 1999a), making it difficult to create a mutually
agreeable implementation.
An additional area of NLG research that deals
with pronouns is that of referring expression gen-
eration (Appelt, 1985; Heeman and Hirst, 1986;
Claassen, 1992; Dale, 1992), which attempts to find
the optimal noun phrase (whether full description,
definite description, deixis, pronoun, or reduced
noun phrase) to enable a reader to mentally select the
intended referent from the set of possible referents
(Reiter and Dale, 1997). Comparatively, referring
expression generation is a process for local disam-
biguation and is not generally concerned with single
phenomena spanning multiple paragraphs. Because
of this, and because the domains and genres we have
studied typically do not involve sets of very simi-
lar referents, we concentrate on discourse-motivated
sources of pronominalization.
</bodyText>
<sectionHeader confidence="0.827361" genericHeader="method">
3 Examples of Pronominalization
</sectionHeader>
<bodyText confidence="0.985237230769231">
Pronominalization is the appropriate determination,
marking and grammatical agreement of pronouns
(he, she, their, herself, it, mine, those, each other,
one, etc.) as a short-hand reference to an entity or
event mentioned in the discourse. As with anaphora
resolution, the task of a pronominalization algorithm
is to correctly predict which pronoun a person would
prefer in the same situation. The range of possibili-
ties includes leaving the noun phrase as it is, reduc-
ing it by removing some of its modifiers, or replac-
ing it with a pronoun construction.
Our corpora analyses have identified a number of
motivations for converting nouns into pronouns:
</bodyText>
<listItem confidence="0.9316809">
1. Anaphoric pronouns: These are the most-
studied cases of pronoun occurrences, which
sequentially follow a specific entity known as
the referent. Anaphors are divided into two
classes, short-distance (within the same sen-
tence) and long-distance (previous sentences).
But John, had never been to New Orleans,
and he, couldn’t remember if anyone in hiss
family had either.
2. Cataphoric pronouns: According to Quirk et
</listItem>
<bodyText confidence="0.990736">
al. (1985), cataphors are those pronouns which
occur before their referents in the linear flow of
text within the same sentence, where the pro-
noun is either at a lower structural level or is
part of a fronted circumstantial clause or prepo-
sitional phrase which could have appeared after
the reference. Additionally, this category could
include clefting pronouns.
Before hei joined the navy, Geraldi made
peace with his family.
</bodyText>
<listItem confidence="0.554258">
3. Pronouns Lacking Textual Antecedents: This
category includes document deixis (via a
demonstrative pronoun), authorial or reader
reference, and situational pronouns.
</listItem>
<bodyText confidence="0.997016333333333">
This is the first document to show ...
We discuss these strategies in the next section.
The group had never seen anything like it.
</bodyText>
<listItem confidence="0.7309612">
4. Reflexive and Reciprocal Pronouns: Most
verbs use special pronouns when the subject
and object corefer. A discourse history algo-
rithm can employ that knowledge to mark re-
flexive and reciprocal pronouns appropriately.
</listItem>
<bodyText confidence="0.9831345">
Kittensi often watch themselvesi in mirrors.
Baby lionsj tackle each otherj when playing.
</bodyText>
<listItem confidence="0.780616666666667">
5. Partitive pronouns: It is important to know con-
ceptually what it is that the pronoun is trying
to replace. Otherwise, it becomes impossible
</listItem>
<bodyText confidence="0.9296193">
to achieve the types of pronominalizations that
authors are routinely capable of creating. This
requires accurate information in the knowledge
base or linguistic structure from which the sen-
tences are derived.
As the horses ran by, she roped one.
* As the horses ran by, she roped it.
* As the horses ran by, she roped them.
In addition to these motivations, we identified
several factors that prevent pronouns from occurring
where they otherwise might:
6. Pronouns across boundaries: After a chapter,
section or other obvious boundary, such as a
change in time, place, or both, as in (McCoy
and Strube, 1999), authors will typically “re-
set” pronominalization just as if it were the
beginning of the entire text. Antecedent ref-
erences that break these boundaries are some-
times marked by the authors in academic texts:
As we saw in the previous section, ...
</bodyText>
<listItem confidence="0.649539">
7. Restrictions from modifiers: Because pronouns
cannot have modifiers like nouns, adding an ad-
jective, relative clause, or some other modifier
prevents a noun from being replaced by a pro-
noun. For instance:
</listItem>
<bodyText confidence="0.914586909090909">
The mayor had already read the full proposal.
* The mayor had already read the full it.
8. Focused nouns: Especially after a vocally
stressed discourse marker (Wolters and Byron,
2000) or some other marked shift in topic, a
word that normally would be pronominalized
is often not, as in this example:
... and you frequently find that mice occupy
an important part of the modern medical labo-
ratory. In other words, mice are especially nec-
essary for diagnosing human cancers ...
</bodyText>
<listItem confidence="0.915868333333333">
9. Semantic and syntactic considerations: A
small number of semantic relations and syntac-
tic constructions prohibit pronominalization:
* The stranger was just called him. (Bob)
* Roberta was no longer a her. (child)
*The father, a tyrant of a him, ... (man)
10. Optional pronominalization: Often there are
borderline cases where some authors will use
pronouns while others won’t. A single algo-
rithm may be tuned to match a particular au-
thor’s style, but parameterization will be nec-
essary to match a variety of styles. Thus it is
extremely difficult to exactly match any partic-
ular text without having the ability to adjust the
pronominalization algorithm.
</listItem>
<bodyText confidence="0.9905955">
Pronominalization occurs equally as often in ex-
position as in dialogue, but dialogue can have
slightly different pronominalizations depending on
the relationship between the utterer and the hearer:
</bodyText>
<listItem confidence="0.623403">
11. Speaker self-reference:
</listItem>
<bodyText confidence="0.889858333333334">
“John thinks John will go find John’s shoes,”
John said.
changes to first person singular pronouns:
“I think I will go find my shoes,” John said.
12. Speaker references hearer(s):
“Mary should go find Mary’s shoes,” John
said.
changes to second person pronouns:
“You should go find your shoes,” John said.
</bodyText>
<listItem confidence="0.7214995">
13. Reference to speaker and hearer (or to speaker
and a third party):
</listItem>
<bodyText confidence="0.900822842105263">
“John and Mary should go find John and
Mary’s shoes,” John said.
changes to first person plural pronouns:
“We should go find our shoes,” John said.
14. Reference to a third party:
“Bob and Mary went to eat Bob and Mary’s
breakfast,” John said.
changes to third person plural pronouns:
“They went to eat their breakfast,” John said.
15. Finally, the treatment of pronouns differs de-
pending if they are inside or outside of the di-
rect quotation. For example:
“Oh man, I forgot to eat my breakfast!” John
muttered to himself while grabbing his shoes.
Although this enumeration is surely incomplete,
it provides a basic description of the types of phe-
nomena that must be handled by a generation system
in order to produce text with the types of pronouns
found in routine human-produced prose.
</bodyText>
<sectionHeader confidence="0.997661" genericHeader="method">
4 Architectural Concerns
</sectionHeader>
<bodyText confidence="0.999984388888889">
In order to correctly account for these phenomena
during generation, it is necessary to have detailed
information about the underlying discourse struc-
ture. Although a template generation system could
be augmented to record this information, in practice
only deep structure, full-scale NLG systems have the
requisite flexibility. Because a pronominalization al-
gorithm typically follows the discourse planner, it
frequently has access to the full discourse plan.
A typical discourse plan is a tree structure, where
internal nodes represent structuring relations while
leaf nodes represent individual sentential elements
that are organized semantically. In addition, the ele-
ments of the discourse tree are typically rooted in the
semantic knowledge base which the discourse plan-
ner drew from when constructing the discourse plan.
The discourse plan supplies the following informa-
tion that is useful for pronominalization:
</bodyText>
<listItem confidence="0.966629642857143">
• Linearization: The sequencing information
stored in the discourse tree can be used to mo-
tivate anaphoric and cataphoric pronouns as
shown in items 1 &amp; 2 of Section 3.
• Semantic Structure: The original subgraphs
(or semantic subnetworks) derived from the
knowledge base can motivate content vs. sit-
uational knowledge (item 3) reflexive and re-
ciprocal pronouns via argument lists (item 4),
partitive pronouns (item 5), and the existence
of NP modifiers (item 7), and can identify se-
mantic types in relations (item 9).
• Discourse Structure: The rhetorical relations
that hold between different sentences typically
</listItem>
<bodyText confidence="0.9517412">
imply where section boundaries are located
(item 6), indicate what types of discourse mark-
ers are employed (item 8), and in the case of
dialogue, know which actors are speaking, lis-
tening, or not present (items 11-15).
This detailed knowledge of the discourse is avail-
able to an implemented pronominalization compo-
nent utilizing any theory, including Centering the-
ory. We thus now turn our attention to what role this
information plays in a pronominalization algorithm.
</bodyText>
<sectionHeader confidence="0.992588" genericHeader="method">
5 A Simple Pronominalization Algorithm
</sectionHeader>
<bodyText confidence="0.974043894736842">
At an abstract level, the pronominalization algo-
rithms derived from Centering theory are easily ex-
pressed: if Centering theory predicts a pronoun
would be used in anaphora resolution in a given seg-
ment of text, then generate the appropriate pronoun.
While this works for many cases of anaphoric pro-
nouns [84.7% in (McCoy and Strube, 1999), 87-
90% in (Henschel et al., 2000)], we have seen that
these form only a subset of the potential reasons for
pronominalization. Furthermore, this approach as-
sumes that the discourse tree was constructed with
Centering theory in mind.
Given:
LNE, the linearized list of nominal elements
NE, the current nominal element
SEEN, the list of encountered nominal elements
D, the dialogue state of the current leaf node
RS, the rhetorical structure near the leaf node
SC, the sentence counter
</bodyText>
<figure confidence="0.968472884615385">
Do:
SEEN 0, SC 0
while LNE =� 0 do
NE first(LNE)
if NE E6 SEEN
then reset-counters(NE),
SEEN SEEN + NE
else update-counters(NE)
D updateDialogueState()
RS updateLocalRhetoricalStructure()
if (topic-shift V time-shift) E RS
then SC SC + 10
else if modifiers(NE, RS) = 0 n
(special-relation V appositive) E6 RS
if D == QuotedDialogue
then mark(quoted-pronoun(NE, RS))
else if subject-matches-object(NE, RS)
then mark(ReflexivePronoun)
else if sent-distance(NE, SC) = 0
then mark(MultipleInSentencePronoun)
else if 3 &lt;= sent-distance(NE, SC) &lt; 1
and nominal-distance(NE) &lt; 3
then mark(LongDistancePronoun),
else if recency(NE) &gt; 3
then mark(ShortDistancePronoun),
LNE remove-first(LNE), SC SC + 1
</figure>
<figureCaption confidence="0.999999">
Figure 1: The Pronominalization Algorithm
</figureCaption>
<bodyText confidence="0.999857363636364">
However, it is not clear that Centering theory itself
is necessary in generation, let alone its accompany-
ing algorithms and data structures. Because Cen-
tering theory is typically applied to parsing (which
starts with no discourse tree), it may not be the most
efficient technique to use in generation (which has a
complete discourse tree available for inference).
Instead, we attempted to determine if the informa-
tion already present in the discourse tree was enough
to motivate a simpler algorithm based on the follow-
ing available data:
</bodyText>
<listItem confidence="0.695828631578947">
• Ordered sequence of nominal elements: Be-
cause the discourse tree is linearized and in-
dividual leaves of the tree annotate which ele-
ments have certain semantic roles, a very good
guess can be made as to which nominal ele-
ments precede others at the clause level.
. Known paragraph and sentence boundaries:
Analysis of the rhetorical structure of the dis-
course tree allows for the determination of
boundaries and thus the concept of metric dis-
tance between elements.
• Rhetorical relations: The rhetorical relations
can tell us which nominal elements follow dis-
course markers and which are used reflexively
or reciprocally.
• Dialogue: By recording the participants in dia-
logue, the discourse tree allows for the appro-
priate assignment of pronouns both inside and
outside of the direct quote itself.
</listItem>
<bodyText confidence="0.970235333333333">
The algorithm we developed considers the cur-
rent discourse leaf node and the rhetorical structure
above it, and also makes use of the following data:
</bodyText>
<listItem confidence="0.978963875">
• Nominal element distance: How many total
(non-distinct) nominal elements ago a particu-
lar element was last used.
• Recency: How many distinct nominal elements
have been seen since its last use.
• Sentential distance: How many sentences (pro-
totypical clauses) have appeared since the last
usage of this nominal element.
</listItem>
<bodyText confidence="0.999969875">
The algorithm itself (Figure 1) is best character-
ized as a counting method, that is, it loops once
through the linearized list of nominal elements and
makes pronominalization decisions based on the lo-
cal information described above, and then updates
those numerical counters. Numerical parameters
(e.g., recency(NE) &gt; 3) are derived from empir-
ical experimentation in generating multi-page prose
in a narrative domain.
While it lacks the explanatory power of a rela-
tively mature linguistic theory, it also lacks the ac-
companying complexity and is immediately appli-
cable to real-world deep generation systems. The al-
gorithm is traced in Figure 2, although due to space
limitations some phenomena such as dialogue, long
distance and reflexive pronouns are not shown.
</bodyText>
<sectionHeader confidence="0.951081" genericHeader="method">
6 Implementation and Evaluation
</sectionHeader>
<bodyText confidence="0.994760692307692">
STORYBOOK (Callaway and Lester, 2001b; Call-
away and Lester, in press) is an implemented nar-
rative generation system that converts a pre-existing
Sentences as seen by the reader (antecedents underlined, pronouns in bold):
Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3 as
she 4 passed, and he5 longed to eat her6 for his 7 breakfasts. But he 9 knew Hugh 10, the woodman 11,
was at work12 very near with his13 great dog14.
Sentences as produced by the discourse planner before revision:
S1: Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3
as Little Red Riding Hood4 passed.
S2: The wolf 5 longed to eat Little Red Riding Hood6 for the wolf’s 7 breakfasts.
S3: But the wolf 9 knew Hugh 10, the woodman 11, was at work 12 very near with Hugh’s13 great dog 14.
Each noun element is processed in the order linearized from the discourse plan:
</bodyText>
<listItem confidence="0.995596166666667">
1. The first mention of wolf1 in the narrative resets its discourse history entry.
2. Creature2 is the second mention of wolf, but it is in an appositive structure (see pronoun category #9).
3. LRRH3 was mentioned just before in the prior paragraph, but “Now,” is a prosodic discourse marker
(see pronoun category #8), thus modifiers(NE, RS) 7� 0.
4. For LRRH3 and LRRH4, sentence-distance(NE, SC) = 0 resulting in a multiple-in-sentence-pronoun.
5. Sentence-distance(NE, SC) = 1, but recency(NE) = 2, resulting in a short-distance-pronoun.
6. Similarly, LRRH6 is converted into a short-distance-pronoun.
7. As with element #4, this is a case resulting in a multiple-in-sentence-pronoun.
9. As with element #5, this is a case resulting in a short-distance-pronoun.
10. The first mention of Hugh10 in the narrative resets its discourse history entry.
11. As with element #2, the discourse plan reports that this is an appositive.
13. Finally, Hugh13 is repeated in the same sentence.
</listItem>
<figureCaption confidence="0.994158">
Figure 2: A Brief Trace of the Pronominalization Algorithm for Anaphoric Pronouns from STORYBOOK
</figureCaption>
<bodyText confidence="0.996079954545455">
narrative (discourse) plan into a multi-page fic-
tional narrative in the fairy tale domain. Using a
pipelined generation architecture, STORYBOOK per-
forms pronominalization before sentence planning,
and includes a revision component that is sensitive
to pronominalization choices during clause aggre-
gation. A previous large-scale evaluation of STORY-
BOOK (Callaway and Lester, 2001a) which included
both a full version and a version with the pronomi-
nalization component ablated showed that including
such a component significantly increases the quality
of the resulting prose.
However, there are significant practical obstacles
to comparing the performance of different pronomi-
nalization algorithms using corpus matching criteria
instead of “quality” as evaluated by human judges.
Because systems that can handle a large quantity of
text are very recent and because it can require years
to create and organize the necessary knowledge to
produce even one multi-paragraph text, much re-
search on anaphora generation has instead relied on
one of two techniques:
</bodyText>
<listItem confidence="0.977330666666667">
• Checking algorithms by hand: One verification
method is to manually examine a text, identify-
ing candidates for pronominalization and simu-
lating the rules of a particular theory. However,
this method is prone to human error.
• Checking algorithms semiautomatically: Other
</listItem>
<bodyText confidence="0.9888265">
researchers opt instead to annotate a corpus
for pronominalization and their antecedents as
well as the pronoun forms that should occur,
and then simulate a pronominalization algo-
rithm on the marked-up text (Henschel et al.,
2000). Similarly, this approach can suffer from
interannotator agreement errors (Poesio et al.,
1999b).
To verify our pronominalization algorithm more
rigorously, we instead used the STORYBOOK deep
generation system to recreate pre-existing multi-
page texts with automatically selected pronouns.
</bodyText>
<table confidence="0.999186555555555">
McCoy &amp; Strube Henschel et al. STORYBOOK STORYBOOK
NYT News NYT News NYT News LRRH Narrative
Animate Anaphora 370/437 (84.7%) N/A 415/449 (92.4%) 170/174 (97.7%)
All Anaphora N/A 469/527 (89.0%) 441/475 (92.8%) 177/181 (97.8%)
Cataphora N/A N/A 1/2 (50.0%) 1/2 (50.0%)
Dialogue N/A N/A 46/46 (100.0%) 65/65 (100.0%)
Deixis N/A N/A 9/9 (100.0%) None present
Reflex./Recip. N/A N/A 5/6 (83.3%) 2/2 (100.0%)
Partitive N/A N/A 1/2 (50.0%) 1/1 (100.0%)
</table>
<tableCaption confidence="0.999905">
Table 1: Pronouns Correct by Algorithm/Text vs. Pronoun Type
</tableCaption>
<bodyText confidence="0.999954458333333">
Without a full-scale implementation, it is impossible
to determine whether an algorithm performs imper-
fectly due to human error, a lack of available corpus
data for making decisions, or if it is a fault with the
algorithm itself.
Using the algorithm described in Figure 1, we
modified STORYBOOK to substitute the types of
pronouns described in Section 3. We then created
the discourse plan and lexicon necessary to generate
the same three articles from the New York Times as
(McCoy and Strube, 1999). The results for both the
newspaper texts and the Little Red Riding Hood nar-
rative described in (Callaway and Lester, in press)
are shown in Table 1.
With the same three texts from the New York
Times, STORYBOOK performed better than the pre-
vious reported results of 85-90% described in (Mc-
Coy and Strube, 1999; Henschel et al., 2000) on both
animate and all anaphora using a corpus matching
technique. Furthermore, this was obtained solely by
adjusting the recency parameter to 4 (it was 3 in our
narrative domain), and without considering other en-
hancements such as gender/number constraints or
domain-specific alterations.1
</bodyText>
<sectionHeader confidence="0.999346" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.8740445">
Pronominalization is an important element in the au-
tomatic creation of multi-paragraph and multi-page
</bodyText>
<footnote confidence="0.7416385">
1It is important to note, however, that our counts of pronouns
and antecedents do not match theirs. This may stem from a vari-
ety of factors, such as including single instances of nominal de-
scriptions, whether dialogue pronouns were considered, and if
borderline quantifiers and words like “everyone” were counted.
The generation community to-date has not settled on standard,
marked corpora for comparison purposes as has the rest of the
computational linguistics community.
</footnote>
<bodyText confidence="0.999497388888889">
texts. Previous approaches, based largely on theo-
retical approaches such as Centering Theory, deal
exclusively with anaphoric pronouns and have com-
plex processing and definitional requirements.
Given the full rhetorical structure available to an
implemented generation system, we devised a sim-
pler method of determining appropriate pronom-
inalizations which was more accurate than exist-
ing methods simulated by hand or performed semi-
automatically. This shows that approaches designed
for use with anaphora resolution, which must build
up discourse knowledge from scratch, may not be
the most desirable method for use in NLG, where
discourse knowledge already exists. The positive re-
sults from our simple counting algorithm, after only
minor changes in parameters from a narrative do-
main to that of newspaper text, indicates that future
high-quality prose generation systems are very near.
</bodyText>
<sectionHeader confidence="0.99768" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999797571428571">
We would like to thank Michael Young and Renate
Henschel for their helpful comments; Kathy McCoy
very quickly provided the original 3 NYT articles
upon request; the anonymous reviewers whose com-
ments greatly improved this paper. Support for this
work was provided by ITC-irst and the IntelliMedia
Initiative of North Carolina State University.
</bodyText>
<sectionHeader confidence="0.998399" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999829785714286">
Douglas E. Appelt. 1985. Planning English referring
expressions. Artificial Intelligence, 26:1–33.
Frederick Baldwin. 1995. CogNIAC: A Discourse Pro-
cessing Engine. Ph.D. thesis, The University of Penn-
sylvania, Philadelphia, PA.
Charles B. Callaway and James C. Lester. 2001a. Eval-
uating the effects of natural language generation on
reader satisfaction. In Proceedings of the Twenty-
Third Annual Conference of the Cognitive Science So-
ciety, pages 164–169, Edinburgh, UK.
Charles B. Callaway and James C. Lester. 2001b. Nar-
rative prose generation. In Proceedings of the Seven-
teenth International Joint Conference on Artificial In-
telligence, pages 1241–1248, Seattle, WA.
Charles B. Callaway and James C. Lester. 2003. Narra-
tive prose generation. Artificial Intelligence. In press.
Wim Claassen. 1992. Generating referring expressions
in a multimodal environment. In R. Dale, E. Hovy,
D. Rosner, and O. Stock, editors, Aspects of Auto-
mated Natural Language Generation, pages 247–62.
Springer-Verlag, Berlin.
Robert Dale. 1992. Generating Referring Expressions.
MIT Press.
Barbara Di Eugenio. 1998. Centering in Italian. In
Marilyn A. Walker, Aravind K. Joshi, and Ellen F.
Prince, editors, Centering in Discourse. Oxford Uni-
versity Press, Cambridge, MA.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Com-
putational Linguistics, 12(3):175–204.
Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
1995. Centering: A framework for modelling the lo-
cal coherence of discourse. Computational Linguis-
tics, 21(2).
Barbara J. Grosz. 1977. The representation and use of
focus in a system for understanding dialogs. In Pro-
ceedings ofthe Fifth International Joint Conference on
Artificial Intelligence, pages 67–76, Cambridge, MA.
Peter Heeman and Graeme Hirst. 1986. Collaborating
on referring expressions. Computational Linguistics,
12(3):351–382.
Renate Henschel, Hua Cheng, and Massimo Poesio.
2000. Pronominalization revisited. In COLING–
2000: Proceedings of the 18th International Con-
ference on Computational Linguistics, Saarbruecken,
Germany.
Jerry R. Hobbs. 1976. Pronoun resolution. Technical
Report 76-1, Department of Computer Science, City
College, CUNY, New York, NY.
Roger Kibble and Richard Power. 2000. An inte-
grated framework for text planning and pronominali-
sation. In Proceedings of the First International Con-
ference on Natural Language Generation, pages 194–
200, Mitzpe Ramon, Israel.
Kathleen F. McCoy and Michael Strube. 1999. Taking
time to structure discourse: Pronoun generation be-
yond accessibility. In Proceedings of the Twenty-First
Conference of the Cognitive Science Society, pages
378–383, Vancouver, CA, August.
Elena Not. 1996. A computational model for generating
referring expressions in a multilingual application do-
main. In COLING–1996: Proceedings of the 16th In-
ternational Conference on Computational Linguistics,
Copenhagen, Denmark, August.
M. Poesio, H. Cheng, R. Henschel, J. Hitzeman, R. Kib-
ble, and R. Stevenson. 1999a. Specifying the parame-
ters of centering theory: A corpus-based evaluation us-
ing text from application-oriented domains. In Book-
title, page Pages, Address, Month.
M. Poesio, R. Henschel, J. Hitzeman, R. Kibble, S. Mon-
tague, and K. van Deemter. 1999b. Towards an anno-
tation scheme for noun phrase generation. In Bookti-
tle, page Pages, Address, Month.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985.
A Comprehensive Grammar of the English Language.
Longman Publishers.
Ehud Reiter and Robert Dale. 1997. Building ap-
plied natural-language generation systems. Journal of
Natural-Language Engineering, 3:57–87.
Candace L. Sidner. 1983. Focusing in the com-
prehension of definite anaphora. In M. Brady and
R. Berwick, editors, Computational Models of Dis-
course, pages 267–330. MIT Press, Cambridge, MA.
Marilyn A. Walker. 1998. Centering, anaphora resolu-
tion, and discourse structure. In Marilyn A. Walker,
Aravind K. Joshi, and Ellen F. Prince, editors, Center-
ing in Discourse. Oxford University Press, Cambridge,
MA.
Bonnie Webber. 1979. A Formal Approach to Discourse
Anaphora. Garland, NY.
Maria Wolters and Donna K. Byron. 2000. Prosody and
the resolution of pronominal anaphora. In COLING–
2000: Proceedings of the 18th International Con-
ference on Computational Linguistics, Saarbruecken,
Germany.
C. Yeh and C. Mellish. 1997. An empirical study on
the generation of anaphora in Chinese. Computational
Linguistics, 23(1):169–190.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.780798">
<note confidence="0.9979145">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 88-95.</note>
<title confidence="0.989786">Pronominalization in Generated Discourse and Dialogue</title>
<author confidence="0.99933">Charles B Callaway James C Lester</author>
<affiliation confidence="0.993174">Istituto per la Ricerca Scientifica e Department of Computer Science</affiliation>
<address confidence="0.801992">Tecnologica (ITC-irst), Italy North Carolina State University, USA</address>
<email confidence="0.998635">callaway@irst.itc.itlester@adm.csc.ncsu.edu</email>
<abstract confidence="0.999482533333333">Previous approaches to pronominalization have largely been theoretical rather than applied in nature. Frequently, such methods are based on Centering Theory, which deals with the resolution of anaphoric pronouns. But it is not clear that complex theoretical mechanisms, while having satisfying explanatory power, are necessary for the actual generation of pronouns. We first illustrate examples of pronouns from various domains, describe a simple method for generating pronouns in an implemented multi-page generation system, and present an evaluation of its performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning English referring expressions.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<pages>26--1</pages>
<contexts>
<context position="6036" citStr="Appelt, 1985" startWordPosition="910" endWordPosition="911"> resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not generally concerned with single phenomena spanning multiple paragraphs. Because of this, and because the domains and genres we have studied typically do not involve sets of very similar refere</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning English referring expressions. Artificial Intelligence, 26:1–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Baldwin</author>
</authors>
<title>CogNIAC: A Discourse Processing Engine.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>The University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="5139" citStr="Baldwin, 1995" startWordPosition="767" endWordPosition="769">nal linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. S</context>
</contexts>
<marker>Baldwin, 1995</marker>
<rawString>Frederick Baldwin. 1995. CogNIAC: A Discourse Processing Engine. Ph.D. thesis, The University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Evaluating the effects of natural language generation on reader satisfaction.</title>
<date>2001</date>
<booktitle>In Proceedings of the TwentyThird Annual Conference of the Cognitive Science Society,</booktitle>
<pages>164--169</pages>
<location>Edinburgh, UK.</location>
<contexts>
<context position="1491" citStr="Callaway and Lester, 2001" startWordPosition="210" endWordPosition="213">or generating pronouns in an implemented multi-page generation system, and present an evaluation of its performance. 1 Introduction Pronominalization is an important element in the automatic creation of multi-paragraph and multi-page texts using natural language generation (NLG). Authors routinely use pronouns in texts spanning all types of genres, such as newspaper copy, science fiction and even academic papers. Indeed, without pronouns, texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addit</context>
<context position="18850" citStr="Callaway and Lester, 2001" startWordPosition="2931" endWordPosition="2934">ormation described above, and then updates those numerical counters. Numerical parameters (e.g., recency(NE) &gt; 3) are derived from empirical experimentation in generating multi-page prose in a narrative domain. While it lacks the explanatory power of a relatively mature linguistic theory, it also lacks the accompanying complexity and is immediately applicable to real-world deep generation systems. The algorithm is traced in Figure 2, although due to space limitations some phenomena such as dialogue, long distance and reflexive pronouns are not shown. 6 Implementation and Evaluation STORYBOOK (Callaway and Lester, 2001b; Callaway and Lester, in press) is an implemented narrative generation system that converts a pre-existing Sentences as seen by the reader (antecedents underlined, pronouns in bold): Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3 as she 4 passed, and he5 longed to eat her6 for his 7 breakfasts. But he 9 knew Hugh 10, the woodman 11, was at work12 very near with his13 great dog14. Sentences as produced by the discourse planner before revision: S1: Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3 </context>
<context position="21207" citStr="Callaway and Lester, 2001" startWordPosition="3314" endWordPosition="3317">e history entry. 11. As with element #2, the discourse plan reports that this is an appositive. 13. Finally, Hugh13 is repeated in the same sentence. Figure 2: A Brief Trace of the Pronominalization Algorithm for Anaphoric Pronouns from STORYBOOK narrative (discourse) plan into a multi-page fictional narrative in the fairy tale domain. Using a pipelined generation architecture, STORYBOOK performs pronominalization before sentence planning, and includes a revision component that is sensitive to pronominalization choices during clause aggregation. A previous large-scale evaluation of STORYBOOK (Callaway and Lester, 2001a) which included both a full version and a version with the pronominalization component ablated showed that including such a component significantly increases the quality of the resulting prose. However, there are significant practical obstacles to comparing the performance of different pronominalization algorithms using corpus matching criteria instead of “quality” as evaluated by human judges. Because systems that can handle a large quantity of text are very recent and because it can require years to create and organize the necessary knowledge to produce even one multi-paragraph text, much </context>
</contexts>
<marker>Callaway, Lester, 2001</marker>
<rawString>Charles B. Callaway and James C. Lester. 2001a. Evaluating the effects of natural language generation on reader satisfaction. In Proceedings of the TwentyThird Annual Conference of the Cognitive Science Society, pages 164–169, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative prose generation.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1241--1248</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="1491" citStr="Callaway and Lester, 2001" startWordPosition="210" endWordPosition="213">or generating pronouns in an implemented multi-page generation system, and present an evaluation of its performance. 1 Introduction Pronominalization is an important element in the automatic creation of multi-paragraph and multi-page texts using natural language generation (NLG). Authors routinely use pronouns in texts spanning all types of genres, such as newspaper copy, science fiction and even academic papers. Indeed, without pronouns, texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addit</context>
<context position="18850" citStr="Callaway and Lester, 2001" startWordPosition="2931" endWordPosition="2934">ormation described above, and then updates those numerical counters. Numerical parameters (e.g., recency(NE) &gt; 3) are derived from empirical experimentation in generating multi-page prose in a narrative domain. While it lacks the explanatory power of a relatively mature linguistic theory, it also lacks the accompanying complexity and is immediately applicable to real-world deep generation systems. The algorithm is traced in Figure 2, although due to space limitations some phenomena such as dialogue, long distance and reflexive pronouns are not shown. 6 Implementation and Evaluation STORYBOOK (Callaway and Lester, 2001b; Callaway and Lester, in press) is an implemented narrative generation system that converts a pre-existing Sentences as seen by the reader (antecedents underlined, pronouns in bold): Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3 as she 4 passed, and he5 longed to eat her6 for his 7 breakfasts. But he 9 knew Hugh 10, the woodman 11, was at work12 very near with his13 great dog14. Sentences as produced by the discourse planner before revision: S1: Now, it happened that a wolf1, a very cruel, greedy creature2 also heard Little Red Riding Hood3 </context>
<context position="21207" citStr="Callaway and Lester, 2001" startWordPosition="3314" endWordPosition="3317">e history entry. 11. As with element #2, the discourse plan reports that this is an appositive. 13. Finally, Hugh13 is repeated in the same sentence. Figure 2: A Brief Trace of the Pronominalization Algorithm for Anaphoric Pronouns from STORYBOOK narrative (discourse) plan into a multi-page fictional narrative in the fairy tale domain. Using a pipelined generation architecture, STORYBOOK performs pronominalization before sentence planning, and includes a revision component that is sensitive to pronominalization choices during clause aggregation. A previous large-scale evaluation of STORYBOOK (Callaway and Lester, 2001a) which included both a full version and a version with the pronominalization component ablated showed that including such a component significantly increases the quality of the resulting prose. However, there are significant practical obstacles to comparing the performance of different pronominalization algorithms using corpus matching criteria instead of “quality” as evaluated by human judges. Because systems that can handle a large quantity of text are very recent and because it can require years to create and organize the necessary knowledge to produce even one multi-paragraph text, much </context>
</contexts>
<marker>Callaway, Lester, 2001</marker>
<rawString>Charles B. Callaway and James C. Lester. 2001b. Narrative prose generation. In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, pages 1241–1248, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative prose generation. Artificial Intelligence.</title>
<date>2003</date>
<note>In press.</note>
<marker>Callaway, Lester, 2003</marker>
<rawString>Charles B. Callaway and James C. Lester. 2003. Narrative prose generation. Artificial Intelligence. In press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim Claassen</author>
</authors>
<title>Generating referring expressions in a multimodal environment. In</title>
<date>1992</date>
<booktitle>Aspects of Automated Natural Language Generation,</booktitle>
<pages>247--62</pages>
<editor>R. Dale, E. Hovy, D. Rosner, and O. Stock, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="6076" citStr="Claassen, 1992" startWordPosition="916" endWordPosition="917">easons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not generally concerned with single phenomena spanning multiple paragraphs. Because of this, and because the domains and genres we have studied typically do not involve sets of very similar referents, we concentrate on discourse-motivat</context>
</contexts>
<marker>Claassen, 1992</marker>
<rawString>Wim Claassen. 1992. Generating referring expressions in a multimodal environment. In R. Dale, E. Hovy, D. Rosner, and O. Stock, editors, Aspects of Automated Natural Language Generation, pages 247–62. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Generating Referring Expressions.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6089" citStr="Dale, 1992" startWordPosition="918" endWordPosition="919"> First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not generally concerned with single phenomena spanning multiple paragraphs. Because of this, and because the domains and genres we have studied typically do not involve sets of very similar referents, we concentrate on discourse-motivated sources of</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>Robert Dale. 1992. Generating Referring Expressions. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
</authors>
<title>Centering in Italian.</title>
<date>1998</date>
<booktitle>Centering in Discourse.</booktitle>
<editor>In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Di Eugenio, 1998</marker>
<rawString>Barbara Di Eugenio. 1998. Centering in Italian. In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors, Centering in Discourse. Oxford University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1906" citStr="Grosz and Sidner, 1986" startWordPosition="269" endWordPosition="273">ndeed, without pronouns, texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms</context>
<context position="4823" citStr="Grosz and Sidner, 1986" startWordPosition="713" endWordPosition="716">e them: discourse planning, sentence planning and surface realization. Since pronouns are more likely to be a multiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphor</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modelling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="4892" citStr="Grosz et al., 1995" startWordPosition="726" endWordPosition="729">ce pronouns are more likely to be a multiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is </context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modelling the local coherence of discourse. Computational Linguistics, 21(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The representation and use of focus in a system for understanding dialogs.</title>
<date>1977</date>
<booktitle>In Proceedings ofthe Fifth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>67--76</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="4770" citStr="Grosz, 1977" startWordPosition="707" endWordPosition="708">of generation that are required to produce them: discourse planning, sentence planning and surface realization. Since pronouns are more likely to be a multiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no su</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Barbara J. Grosz. 1977. The representation and use of focus in a system for understanding dialogs. In Proceedings ofthe Fifth International Joint Conference on Artificial Intelligence, pages 67–76, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Heeman</author>
<author>Graeme Hirst</author>
</authors>
<title>Collaborating on referring expressions.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="6060" citStr="Heeman and Hirst, 1986" startWordPosition="912" endWordPosition="915">here are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not generally concerned with single phenomena spanning multiple paragraphs. Because of this, and because the domains and genres we have studied typically do not involve sets of very similar referents, we concentrate on d</context>
</contexts>
<marker>Heeman, Hirst, 1986</marker>
<rawString>Peter Heeman and Graeme Hirst. 1986. Collaborating on referring expressions. Computational Linguistics, 12(3):351–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renate Henschel</author>
<author>Hua Cheng</author>
<author>Massimo Poesio</author>
</authors>
<title>Pronominalization revisited.</title>
<date>2000</date>
<booktitle>In COLING– 2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="2843" citStr="Henschel et al., 2000" startWordPosition="409" endWordPosition="412">plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt to recreate a text coherence structure that duplicates work already done by the discourse planner. Finally, there are significant obstacles to verifying the correctness of existing pronominalization algorithms for any pronominalization theory (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000): the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play. Because of this, researchers are forced to simulate by hand how their algorithms will work on a given text. It is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions. In this paper we first summarize related work in both anaphora resolution and anaphora generation. We next descri</context>
<context position="5319" citStr="Henschel et al., 2000" startWordPosition="796" endWordPosition="799">scourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation.</context>
<context position="15023" citStr="Henschel et al., 2000" startWordPosition="2333" endWordPosition="2336">s available to an implemented pronominalization component utilizing any theory, including Centering theory. We thus now turn our attention to what role this information plays in a pronominalization algorithm. 5 A Simple Pronominalization Algorithm At an abstract level, the pronominalization algorithms derived from Centering theory are easily expressed: if Centering theory predicts a pronoun would be used in anaphora resolution in a given segment of text, then generate the appropriate pronoun. While this works for many cases of anaphoric pronouns [84.7% in (McCoy and Strube, 1999), 87- 90% in (Henschel et al., 2000)], we have seen that these form only a subset of the potential reasons for pronominalization. Furthermore, this approach assumes that the discourse tree was constructed with Centering theory in mind. Given: LNE, the linearized list of nominal elements NE, the current nominal element SEEN, the list of encountered nominal elements D, the dialogue state of the current leaf node RS, the rhetorical structure near the leaf node SC, the sentence counter Do: SEEN 0, SC 0 while LNE =� 0 do NE first(LNE) if NE E6 SEEN then reset-counters(NE), SEEN SEEN + NE else update-counters(NE) D updateDialogueState</context>
<context position="22387" citStr="Henschel et al., 2000" startWordPosition="3493" endWordPosition="3496">oduce even one multi-paragraph text, much research on anaphora generation has instead relied on one of two techniques: • Checking algorithms by hand: One verification method is to manually examine a text, identifying candidates for pronominalization and simulating the rules of a particular theory. However, this method is prone to human error. • Checking algorithms semiautomatically: Other researchers opt instead to annotate a corpus for pronominalization and their antecedents as well as the pronoun forms that should occur, and then simulate a pronominalization algorithm on the marked-up text (Henschel et al., 2000). Similarly, this approach can suffer from interannotator agreement errors (Poesio et al., 1999b). To verify our pronominalization algorithm more rigorously, we instead used the STORYBOOK deep generation system to recreate pre-existing multipage texts with automatically selected pronouns. McCoy &amp; Strube Henschel et al. STORYBOOK STORYBOOK NYT News NYT News NYT News LRRH Narrative Animate Anaphora 370/437 (84.7%) N/A 415/449 (92.4%) 170/174 (97.7%) All Anaphora N/A 469/527 (89.0%) 441/475 (92.8%) 177/181 (97.8%) Cataphora N/A N/A 1/2 (50.0%) 1/2 (50.0%) Dialogue N/A N/A 46/46 (100.0%) 65/65 (10</context>
<context position="24019" citStr="Henschel et al., 2000" startWordPosition="3751" endWordPosition="3754"> algorithm itself. Using the algorithm described in Figure 1, we modified STORYBOOK to substitute the types of pronouns described in Section 3. We then created the discourse plan and lexicon necessary to generate the same three articles from the New York Times as (McCoy and Strube, 1999). The results for both the newspaper texts and the Little Red Riding Hood narrative described in (Callaway and Lester, in press) are shown in Table 1. With the same three texts from the New York Times, STORYBOOK performed better than the previous reported results of 85-90% described in (McCoy and Strube, 1999; Henschel et al., 2000) on both animate and all anaphora using a corpus matching technique. Furthermore, this was obtained solely by adjusting the recency parameter to 4 (it was 3 in our narrative domain), and without considering other enhancements such as gender/number constraints or domain-specific alterations.1 7 Conclusions Pronominalization is an important element in the automatic creation of multi-paragraph and multi-page 1It is important to note, however, that our counts of pronouns and antecedents do not match theirs. This may stem from a variety of factors, such as including single instances of nominal desc</context>
</contexts>
<marker>Henschel, Cheng, Poesio, 2000</marker>
<rawString>Renate Henschel, Hua Cheng, and Massimo Poesio. 2000. Pronominalization revisited. In COLING– 2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Pronoun resolution.</title>
<date>1976</date>
<tech>Technical Report 76-1,</tech>
<institution>Department of Computer Science,</institution>
<location>City College, CUNY, New York, NY.</location>
<contexts>
<context position="5123" citStr="Hobbs, 1976" startWordPosition="765" endWordPosition="766">in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pro</context>
</contexts>
<marker>Hobbs, 1976</marker>
<rawString>Jerry R. Hobbs. 1976. Pronoun resolution. Technical Report 76-1, Department of Computer Science, City College, CUNY, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Kibble</author>
<author>Richard Power</author>
</authors>
<title>An integrated framework for text planning and pronominalisation.</title>
<date>2000</date>
<booktitle>In Proceedings of the First International Conference on Natural Language Generation,</booktitle>
<pages>194--200</pages>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="2868" citStr="Kibble and Power, 2000" startWordPosition="413" endWordPosition="416">during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt to recreate a text coherence structure that duplicates work already done by the discourse planner. Finally, there are significant obstacles to verifying the correctness of existing pronominalization algorithms for any pronominalization theory (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000): the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play. Because of this, researchers are forced to simulate by hand how their algorithms will work on a given text. It is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions. In this paper we first summarize related work in both anaphora resolution and anaphora generation. We next describe the range of pronoun t</context>
<context position="5344" citStr="Kibble and Power, 2000" startWordPosition="800" endWordPosition="803">tion was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NL</context>
</contexts>
<marker>Kibble, Power, 2000</marker>
<rawString>Roger Kibble and Richard Power. 2000. An integrated framework for text planning and pronominalisation. In Proceedings of the First International Conference on Natural Language Generation, pages 194– 200, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen F McCoy</author>
<author>Michael Strube</author>
</authors>
<title>Taking time to structure discourse: Pronoun generation beyond accessibility.</title>
<date>1999</date>
<booktitle>In Proceedings of the Twenty-First Conference of the Cognitive Science Society,</booktitle>
<pages>378--383</pages>
<location>Vancouver, CA,</location>
<contexts>
<context position="2820" citStr="McCoy and Strube, 1999" startWordPosition="405" endWordPosition="408">s such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt to recreate a text coherence structure that duplicates work already done by the discourse planner. Finally, there are significant obstacles to verifying the correctness of existing pronominalization algorithms for any pronominalization theory (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000): the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play. Because of this, researchers are forced to simulate by hand how their algorithms will work on a given text. It is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions. In this paper we first summarize related work in both anaphora resolution and anaphora gen</context>
<context position="5296" citStr="McCoy and Strube, 1999" startWordPosition="792" endWordPosition="795"> of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually ag</context>
<context position="9599" citStr="McCoy and Strube, 1999" startWordPosition="1463" endWordPosition="1466">es impossible to achieve the types of pronominalizations that authors are routinely capable of creating. This requires accurate information in the knowledge base or linguistic structure from which the sentences are derived. As the horses ran by, she roped one. * As the horses ran by, she roped it. * As the horses ran by, she roped them. In addition to these motivations, we identified several factors that prevent pronouns from occurring where they otherwise might: 6. Pronouns across boundaries: After a chapter, section or other obvious boundary, such as a change in time, place, or both, as in (McCoy and Strube, 1999), authors will typically “reset” pronominalization just as if it were the beginning of the entire text. Antecedent references that break these boundaries are sometimes marked by the authors in academic texts: As we saw in the previous section, ... 7. Restrictions from modifiers: Because pronouns cannot have modifiers like nouns, adding an adjective, relative clause, or some other modifier prevents a noun from being replaced by a pronoun. For instance: The mayor had already read the full proposal. * The mayor had already read the full it. 8. Focused nouns: Especially after a vocally stressed di</context>
<context position="14987" citStr="McCoy and Strube, 1999" startWordPosition="2326" endWordPosition="2329">detailed knowledge of the discourse is available to an implemented pronominalization component utilizing any theory, including Centering theory. We thus now turn our attention to what role this information plays in a pronominalization algorithm. 5 A Simple Pronominalization Algorithm At an abstract level, the pronominalization algorithms derived from Centering theory are easily expressed: if Centering theory predicts a pronoun would be used in anaphora resolution in a given segment of text, then generate the appropriate pronoun. While this works for many cases of anaphoric pronouns [84.7% in (McCoy and Strube, 1999), 87- 90% in (Henschel et al., 2000)], we have seen that these form only a subset of the potential reasons for pronominalization. Furthermore, this approach assumes that the discourse tree was constructed with Centering theory in mind. Given: LNE, the linearized list of nominal elements NE, the current nominal element SEEN, the list of encountered nominal elements D, the dialogue state of the current leaf node RS, the rhetorical structure near the leaf node SC, the sentence counter Do: SEEN 0, SC 0 while LNE =� 0 do NE first(LNE) if NE E6 SEEN then reset-counters(NE), SEEN SEEN + NE else updat</context>
<context position="23685" citStr="McCoy and Strube, 1999" startWordPosition="3692" endWordPosition="3695">83.3%) 2/2 (100.0%) Partitive N/A N/A 1/2 (50.0%) 1/1 (100.0%) Table 1: Pronouns Correct by Algorithm/Text vs. Pronoun Type Without a full-scale implementation, it is impossible to determine whether an algorithm performs imperfectly due to human error, a lack of available corpus data for making decisions, or if it is a fault with the algorithm itself. Using the algorithm described in Figure 1, we modified STORYBOOK to substitute the types of pronouns described in Section 3. We then created the discourse plan and lexicon necessary to generate the same three articles from the New York Times as (McCoy and Strube, 1999). The results for both the newspaper texts and the Little Red Riding Hood narrative described in (Callaway and Lester, in press) are shown in Table 1. With the same three texts from the New York Times, STORYBOOK performed better than the previous reported results of 85-90% described in (McCoy and Strube, 1999; Henschel et al., 2000) on both animate and all anaphora using a corpus matching technique. Furthermore, this was obtained solely by adjusting the recency parameter to 4 (it was 3 in our narrative domain), and without considering other enhancements such as gender/number constraints or dom</context>
</contexts>
<marker>McCoy, Strube, 1999</marker>
<rawString>Kathleen F. McCoy and Michael Strube. 1999. Taking time to structure discourse: Pronoun generation beyond accessibility. In Proceedings of the Twenty-First Conference of the Cognitive Science Society, pages 378–383, Vancouver, CA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Not</author>
</authors>
<title>A computational model for generating referring expressions in a multilingual application domain.</title>
<date>1996</date>
<booktitle>In COLING–1996: Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="2773" citStr="Not, 1996" startWordPosition="399" endWordPosition="400">ing parsing, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt to recreate a text coherence structure that duplicates work already done by the discourse planner. Finally, there are significant obstacles to verifying the correctness of existing pronominalization algorithms for any pronominalization theory (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000): the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play. Because of this, researchers are forced to simulate by hand how their algorithms will work on a given text. It is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions. In this paper we first summarize related wo</context>
<context position="5249" citStr="Not, 1996" startWordPosition="786" endWordPosition="787">of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999</context>
</contexts>
<marker>Not, 1996</marker>
<rawString>Elena Not. 1996. A computational model for generating referring expressions in a multilingual application domain. In COLING–1996: Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>H Cheng</author>
<author>R Henschel</author>
<author>J Hitzeman</author>
<author>R Kibble</author>
<author>R Stevenson</author>
</authors>
<title>Specifying the parameters of centering theory: A corpus-based evaluation using text from application-oriented domains. In Booktitle,</title>
<date>1999</date>
<location>page Pages, Address, Month.</location>
<contexts>
<context position="5849" citStr="Poesio et al., 1999" startWordPosition="880" endWordPosition="883">neration (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not gener</context>
<context position="22482" citStr="Poesio et al., 1999" startWordPosition="3506" endWordPosition="3509">e of two techniques: • Checking algorithms by hand: One verification method is to manually examine a text, identifying candidates for pronominalization and simulating the rules of a particular theory. However, this method is prone to human error. • Checking algorithms semiautomatically: Other researchers opt instead to annotate a corpus for pronominalization and their antecedents as well as the pronoun forms that should occur, and then simulate a pronominalization algorithm on the marked-up text (Henschel et al., 2000). Similarly, this approach can suffer from interannotator agreement errors (Poesio et al., 1999b). To verify our pronominalization algorithm more rigorously, we instead used the STORYBOOK deep generation system to recreate pre-existing multipage texts with automatically selected pronouns. McCoy &amp; Strube Henschel et al. STORYBOOK STORYBOOK NYT News NYT News NYT News LRRH Narrative Animate Anaphora 370/437 (84.7%) N/A 415/449 (92.4%) 170/174 (97.7%) All Anaphora N/A 469/527 (89.0%) 441/475 (92.8%) 177/181 (97.8%) Cataphora N/A N/A 1/2 (50.0%) 1/2 (50.0%) Dialogue N/A N/A 46/46 (100.0%) 65/65 (100.0%) Deixis N/A N/A 9/9 (100.0%) None present Reflex./Recip. N/A N/A 5/6 (83.3%) 2/2 (100.0%) </context>
</contexts>
<marker>Poesio, Cheng, Henschel, Hitzeman, Kibble, Stevenson, 1999</marker>
<rawString>M. Poesio, H. Cheng, R. Henschel, J. Hitzeman, R. Kibble, and R. Stevenson. 1999a. Specifying the parameters of centering theory: A corpus-based evaluation using text from application-oriented domains. In Booktitle, page Pages, Address, Month.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Henschel</author>
<author>J Hitzeman</author>
<author>R Kibble</author>
<author>S Montague</author>
<author>K van Deemter</author>
</authors>
<title>Towards an annotation scheme for noun phrase generation. In Booktitle,</title>
<date>1999</date>
<location>page Pages, Address, Month.</location>
<marker>Poesio, Henschel, Hitzeman, Kibble, Montague, van Deemter, 1999</marker>
<rawString>M. Poesio, R. Henschel, J. Hitzeman, R. Kibble, S. Montague, and K. van Deemter. 1999b. Towards an annotation scheme for noun phrase generation. In Booktitle, page Pages, Address, Month.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<publisher>Longman Publishers.</publisher>
<contexts>
<context position="7821" citStr="Quirk et al. (1985)" startWordPosition="1179" endWordPosition="1182">s, reducing it by removing some of its modifiers, or replacing it with a pronoun construction. Our corpora analyses have identified a number of motivations for converting nouns into pronouns: 1. Anaphoric pronouns: These are the moststudied cases of pronoun occurrences, which sequentially follow a specific entity known as the referent. Anaphors are divided into two classes, short-distance (within the same sentence) and long-distance (previous sentences). But John, had never been to New Orleans, and he, couldn’t remember if anyone in hiss family had either. 2. Cataphoric pronouns: According to Quirk et al. (1985), cataphors are those pronouns which occur before their referents in the linear flow of text within the same sentence, where the pronoun is either at a lower structural level or is part of a fronted circumstantial clause or prepositional phrase which could have appeared after the reference. Additionally, this category could include clefting pronouns. Before hei joined the navy, Geraldi made peace with his family. 3. Pronouns Lacking Textual Antecedents: This category includes document deixis (via a demonstrative pronoun), authorial or reader reference, and situational pronouns. This is the fir</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building applied natural-language generation systems.</title>
<date>1997</date>
<journal>Journal of Natural-Language Engineering,</journal>
<pages>3--57</pages>
<contexts>
<context position="6346" citStr="Reiter and Dale, 1997" startWordPosition="955" endWordPosition="958">ominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult to create a mutually agreeable implementation. An additional area of NLG research that deals with pronouns is that of referring expression generation (Appelt, 1985; Heeman and Hirst, 1986; Claassen, 1992; Dale, 1992), which attempts to find the optimal noun phrase (whether full description, definite description, deixis, pronoun, or reduced noun phrase) to enable a reader to mentally select the intended referent from the set of possible referents (Reiter and Dale, 1997). Comparatively, referring expression generation is a process for local disambiguation and is not generally concerned with single phenomena spanning multiple paragraphs. Because of this, and because the domains and genres we have studied typically do not involve sets of very similar referents, we concentrate on discourse-motivated sources of pronominalization. 3 Examples of Pronominalization Pronominalization is the appropriate determination, marking and grammatical agreement of pronouns (he, she, their, herself, it, mine, those, each other, one, etc.) as a short-hand reference to an entity or</context>
</contexts>
<marker>Reiter, Dale, 1997</marker>
<rawString>Ehud Reiter and Robert Dale. 1997. Building applied natural-language generation systems. Journal of Natural-Language Engineering, 3:57–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Focusing in the comprehension of definite anaphora.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse,</booktitle>
<pages>267--330</pages>
<editor>In M. Brady and R. Berwick, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1882" citStr="Sidner, 1983" startWordPosition="267" endWordPosition="268">emic papers. Indeed, without pronouns, texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based</context>
<context position="4798" citStr="Sidner, 1983" startWordPosition="711" endWordPosition="712">ired to produce them: discourse planning, sentence planning and surface realization. Since pronouns are more likely to be a multiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contributio</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Candace L. Sidner. 1983. Focusing in the comprehension of definite anaphora. In M. Brady and R. Berwick, editors, Computational Models of Discourse, pages 267–330. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Centering, anaphora resolution, and discourse structure.</title>
<date>1998</date>
<booktitle>Centering in Discourse.</booktitle>
<editor>In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1921" citStr="Walker, 1998" startWordPosition="274" endWordPosition="275"> texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt t</context>
<context position="4925" citStr="Walker, 1998" startWordPosition="733" endWordPosition="734">ltiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an </context>
</contexts>
<marker>Walker, 1998</marker>
<rawString>Marilyn A. Walker. 1998. Centering, anaphora resolution, and discourse structure. In Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors, Centering in Discourse. Oxford University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
</authors>
<title>A Formal Approach to Discourse Anaphora.</title>
<date>1979</date>
<location>Garland, NY.</location>
<contexts>
<context position="1868" citStr="Webber, 1979" startWordPosition="265" endWordPosition="266"> and even academic papers. Indeed, without pronouns, texts quickly become confusing as readers begin to pay more attention to the writing style than to the content that makes the text informative or enjoyable (Callaway and Lester, 2001a). Even worse, incorrect pronouns can lead readers to misinterpret the text or draw unsound inferences. Furthermore, current pronominalization strategies are ill-equipped to deal with the wide variety of reasons that pronouns are used in naturally occurring texts. Almost without exception, they focus on anaphoric pronouns as described in Focus/Centering Theory (Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986; Walker, 1998), ignoring the multitude of other possible types. However, it is certainly true that authors make use of pronouns which are not motivated by anaphoric reference. In addition, because such approaches are oriented towards anaphora resolution during parsing, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current ap</context>
<context position="4784" citStr="Webber, 1979" startWordPosition="709" endWordPosition="710"> that are required to produce them: discourse planning, sentence planning and surface realization. Since pronouns are more likely to be a multiparagraph, discourse-level phenomenon, it has been possible to ignore their inclusion into working NLG systems which are not called upon to generate lengthy passages. Indeed, most work on pronouns in computational linguistics has come under the heading of anaphora resolution as an element of parsing rather than the heading of pronominalization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial retu</context>
</contexts>
<marker>Webber, 1979</marker>
<rawString>Bonnie Webber. 1979. A Formal Approach to Discourse Anaphora. Garland, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Wolters</author>
<author>Donna K Byron</author>
</authors>
<title>Prosody and the resolution of pronominal anaphora.</title>
<date>2000</date>
<booktitle>In COLING– 2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="10239" citStr="Wolters and Byron, 2000" startWordPosition="1569" endWordPosition="1572">ypically “reset” pronominalization just as if it were the beginning of the entire text. Antecedent references that break these boundaries are sometimes marked by the authors in academic texts: As we saw in the previous section, ... 7. Restrictions from modifiers: Because pronouns cannot have modifiers like nouns, adding an adjective, relative clause, or some other modifier prevents a noun from being replaced by a pronoun. For instance: The mayor had already read the full proposal. * The mayor had already read the full it. 8. Focused nouns: Especially after a vocally stressed discourse marker (Wolters and Byron, 2000) or some other marked shift in topic, a word that normally would be pronominalized is often not, as in this example: ... and you frequently find that mice occupy an important part of the modern medical laboratory. In other words, mice are especially necessary for diagnosing human cancers ... 9. Semantic and syntactic considerations: A small number of semantic relations and syntactic constructions prohibit pronominalization: * The stranger was just called him. (Bob) * Roberta was no longer a her. (child) *The father, a tyrant of a him, ... (man) 10. Optional pronominalization: Often there are b</context>
</contexts>
<marker>Wolters, Byron, 2000</marker>
<rawString>Maria Wolters and Donna K. Byron. 2000. Prosody and the resolution of pronominal anaphora. In COLING– 2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Yeh</author>
<author>C Mellish</author>
</authors>
<title>An empirical study on the generation of anaphora in Chinese.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="2796" citStr="Yeh and Mellish, 1997" startWordPosition="401" endWordPosition="404">, they ignore structures such as the discourse plan which are present during generation but not parsing. A typical discourse plan can include vital information for pronominalization such as time and clause boundaries, ordering of propositions, and semantic details verbal arguments. Current approaches based on Centering algorithms thus attempt to recreate a text coherence structure that duplicates work already done by the discourse planner. Finally, there are significant obstacles to verifying the correctness of existing pronominalization algorithms for any pronominalization theory (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000): the lack of natural language generation systems that can produce large enough texts to bring discourse-level processes into play. Because of this, researchers are forced to simulate by hand how their algorithms will work on a given text. It is also not sufficient to use template generation systems to perform this task because they lack the low-level discourse representation needed to provide the information upon which most algorithms base their decisions. In this paper we first summarize related work in both anaphora res</context>
<context position="5272" citStr="Yeh and Mellish, 1997" startWordPosition="788" endWordPosition="791">alization as an element of generation. Since discourse anaphora resolution was first studied theoretically (Grosz, 1977; Webber, 1979; Sidner, 1983; Grosz and Sidner, 1986), it has come to be dominated by Centering Theory (Grosz et al., 1995; Di Eugenio, 1998; Walker, 1998) which proposes rules for the determination of focus and salience within a given segment of discourse. Relatively little work has been done on alternate approaches to pronoun resolution (Hobbs, 1976; Baldwin, 1995). While many NLG researchers have attempted to transfer the ideas of Centering Theory to generation (Not, 1996; Yeh and Mellish, 1997; McCoy and Strube, 1999; Henschel et al., 2000; Kibble and Power, 2000), there has yet been no substantial return contribution to the field of anaphora resolution. There are two principal reasons for this. First, it is extremely difficult to create an NLG system that generates the large quantity of texts needed to exhibit discourse-level phenomena while consistently employing the deep linguistic representations needed to determine appropriate pronominal forms. Second, Centering Theory is still vague on the exact definition of terms such as “segment” (Poesio et al., 1999a), making it difficult</context>
</contexts>
<marker>Yeh, Mellish, 1997</marker>
<rawString>C. Yeh and C. Mellish. 1997. An empirical study on the generation of anaphora in Chinese. Computational Linguistics, 23(1):169–190.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>