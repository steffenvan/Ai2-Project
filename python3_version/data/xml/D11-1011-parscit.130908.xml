<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.761052">
Class Label Enhancement via Related Instances
</title>
<author confidence="0.933305">
Zornitsa Kozareva
</author>
<affiliation confidence="0.904358">
USC Information Sciences Institute
</affiliation>
<address confidence="0.875674">
4676 Admiralty Way
Marina del Rey, CA 90292-6695
</address>
<email confidence="0.999171">
kozareva@isi.edu
</email>
<author confidence="0.988607">
Konstantin Voevodski
</author>
<affiliation confidence="0.991934">
Boston University
</affiliation>
<address confidence="0.915608">
111 Cummington St.
Boston, MA, 02215
</address>
<email confidence="0.999532">
kvodski@bu.edu
</email>
<author confidence="0.97706">
Shang-Hua Teng
</author>
<affiliation confidence="0.996665">
University of Southern California
</affiliation>
<address confidence="0.891151">
941 Bloom Walk, SAL 300
Los Angeles, CA 90089
</address>
<email confidence="0.999607">
shanghua@usc.edu
</email>
<sectionHeader confidence="0.998582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99770235">
Class-instance label propagation algorithms
have been successfully used to fuse informa-
tion from multiple sources in order to enrich
a set of unlabeled instances with class labels.
Yet, nobody has explored the relationships be-
tween the instances themselves to enhance an
initial set of class-instance pairs. We pro-
pose two graph-theoretic methods (centrality
and regularization), which start with a small
set of labeled class-instance pairs and use the
instance-instance network to extend the class
labels to all instances in the network. We carry
out a comparative study with state-of-the-art
knowledge harvesting algorithm and show that
our approach can learn additional class labels
while maintaining high accuracy. We conduct
a comparative study between class-instance
and instance-instance graphs used to propa-
gate the class labels and show that the latter
one achieves higher accuracy.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961391304348">
Many natural language processing applications use
and rely on semantic knowledge resources. Since
manually built lexical repositories such as Word-
Net (Fellbaum, 1998) cover a limited amount of
knowledge and are tedious to maintain over time, re-
searchers have developed algorithms for automatic
knowledge extraction from structured and unstruc-
tured texts. There is a substantial body of work
on extracting is-a relations (Etzioni et al., 2005;
Kozareva et al., 2008), part-of relations (Girju et al.,
2003; Pantel and Pennacchiotti, 2006) and general
facts (Lin and Pantel, 2001; Davidov and Rappoport,
2009; Jain and Pantel, 2010). The usefulness of the
generated resources has been shown to be valuable
to information extraction (Riloff and Jones, 1999),
question answering (Katz et al., 2003) and textual
entailment (Zanzotto et al., 2006) systems.
Among the most common knowledge acquisi-
tion approaches are those based on lexical patterns
(Hearst, 1992; Etzioni et al., 2005; Kozareva et al.,
2008) and clustering (Lin and Pantel, 2002; Davidov
and Rappoport, 2008). While clustering can find in-
stances and classes that are not explicitly expressed
in text, they often may not generate the granularity
needed by the users. In contrast, pattern-based ap-
proaches generate highly accurate lists, but they are
constraint to the information matched by the pattern
and often suffer from recall. (Pas¸ca, 2004; Snow
et al., 2006; Kozareva and Hovy, 2010) have shown
that complete lists of semantic classes and instances
are valuable for the enrichment of existing resources
like WordNet and for taxonomy induction. There-
fore, researchers have focused on the development
of methods that can automatically augment the ini-
tially extracted class-instance pairs.
(Pennacchiotti and Pantel, 2009) fused informa-
tion from pattern-based and distributional systems
using an ensemble method and a rich set of features
derived from query logs, web-crawl and Wikipedia.
(Talukdar et al., 2008) improved class-instance ex-
tractions exploring the relationships between the
classes and the instances to propagate the initial
class-labels to the remaining unlabeled instances.
Later on (Talukdar and Pereira, 2010) showed that
class-instance extraction with label propagation can
be further improved by adding semantic information
</bodyText>
<page confidence="0.95659">
118
</page>
<note confidence="0.9579655">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 118–128,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999949606060606">
in the form of instance-attribute edges derived from
independently developed knowledge base. Similarly
to (Talukdar et al., 2008) and (Talukdar and Pereira,
2010), we are interested in enriching class-instance
extractions with label propagation. However, un-
like the previous work, we model the relationships
between the instances themselves to propagate the
initial set of class labels to the remaining unlabeled
instances. To our knowledge, this is the first work
to explore the connections between instances for the
task of class-label propagation.
Our work addresses the following question: Is it
possible to effectively explore the structure of the
text-mined instance-instance networks to enhance
an incomplete set of class labels? Our intuition is
that if an instance like bear belongs to a seman-
tic class carnivore, and the instance bear is con-
nected to the instance fox, then it is more likely that
the unlabeled instance fox is also of class carnivore.
To solve this problem, we propose two graph-based
approaches that use the structure of the instance-
instance graph to propagate the class labels. Our
methods are agnostic to the sources of semantic in-
stances and classes. In this work, we carried out ex-
periments with a state-of-the-art instance extraction
system and conducted a comparative study between
the original and the enhanced class-instance pairs.
The results show that this labeling procedure can be-
gin to bridge the gap between the extraction power
of the pattern-based approaches and the desired re-
call by finding class-instance pairs that are not ex-
plicitly mentioned in text. The contributions of the
paper are as follows:
</bodyText>
<listItem confidence="0.593974947368421">
• We use only the relationships between the in-
stances themselves to propagate class labels.
• We observe how often labels are propagated
along the edges of our semantic network, and
propose two ways to extend an initial set of
class labels to all the instance nodes in the net-
work. The first approach uses a linear sys-
tem to compute the network centrality relative
to the initially labeled instances. The second
approach uses a regularization framework with
respect to a random walk on the network.
• We evaluate the proposed approaches and show
that they discover many new class-instance
pairs compared to state-of-the-art knowledge
harvesting algorithm, while still maintaining
high accuracy.
• We conduct a comparative study between class-
instance and instance-instance graphs used
to propagate class labels. The experiments
</listItem>
<bodyText confidence="0.9827116">
show that considering relationships between in-
stances achieves higher accuracy.
The rest of the paper is organized as follows. In
Section 2, we review related work. Section 3 de-
scribes the Web-based knowledge harvesting algo-
rithm used to extract the instance network and the
class-instance pairs necessary for our experimen-
tal evaluation. Section 4 describes the two graph-
theoretic methods for class label propagation using
an instance-instance network. Section 5 shows a
comparative study between the proposed graph al-
gorithms and different baselines. We also show
a comparison between class-instance and instance-
instance graphs used in the label propagation. Fi-
nally, we conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999629333333333">
In the past decade, we have reached a good under-
standing on the knowledge harvesting technology
from structured (Suchanek et al., 2007) and unstruc-
tured text. Researchers have harvested with vary-
ing success semantic lexicons (Riloff and Shepherd,
1997) and concept lists (Katz et al., 2003). Many
efforts have also focused on the extraction of is-a
relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al.,
2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of re-
lations (Girju et al., 2003; Pantel and Pennacchiotti,
2006) and general facts (Etzioni et al., 2005; Davi-
dov and Rappoport, 2009; Jain and Pantel, 2010).
Various approaches have been proposed following
the patterns of (Hearst, 1992) and clustering (Lin
and Pantel, 2002; Davidov and Rappoport, 2008). A
substantial body of work has explored issues such as
reranking the harvested knowledge using mutual in-
formation (Etzioni et al., 2005) and graph algorithms
(Hovy et al., 2009), estimating the goodness of text-
mining seeds (Vyas et al., 2009), organizing the
extracted information (Cafarella et al., 2007a; Ca-
farella et al., 2007b) and inducing term taxonomies
with WordNet (Snow et al., 2006) or starting from
scratch (Kozareva and Hovy, 2010).
</bodyText>
<page confidence="0.998481">
119
</page>
<bodyText confidence="0.999938205882353">
Since pattern-based approaches tend to be high-
precision and low-recall in nature, recently of great
interest to the research community is the develop-
ment of approaches that can increment the recall of
the harvested class-instance pairs. (Pennacchiotti
and Pantel, 2009) proposed an ensemble seman-
tic framework that mixes distributional and pattern-
based systems with a large set of features from a
web-crawl, query logs, and Wikipedia. (Talukdar
et al., 2008) combined extractions from free text
and structured sources using graph-based label prop-
agation algorithm. (Talukdar and Pereira, 2010)
conducted a comparative study of graph algorithms
and showed that class-instance extraction can be
improved using additional information that can be
modeled as instance-attribute edges.
Closest to our work is that of (Talukdar et al.,
2008; Talukdar and Pereira, 2010) who model class-
instance relations to propagate class-labels. Al-
though these algorithms can be applied to other rela-
tions (Alfonseca et al., 2010), to our knowledge yet
nobody has modeled the connections between the in-
stances themselves for the task of class-label prop-
agation. We propose regularization and centrality
graph-theoretic methods, which exploit the instance-
instance network and a small set of class-instance
pairs to propagate the class-labels to the remaining
unlabeled instances. While objectives similar to reg-
ularization have been used for class-label propaga-
tion, the application of node centrality for this task is
also novel. The proposed solutions are intuitive and
almost parameter-free (both methods have a single
parameter, which is easy to interpret and does not
require careful tuning).
</bodyText>
<sectionHeader confidence="0.919386" genericHeader="method">
3 Knowledge Harvesting from the Web
</sectionHeader>
<bodyText confidence="0.999873425">
Our proposed class-label enhancement approaches
are agnostic to the sources of semantic instances and
classes. Several methods have been developed to
harvest instances from the Web (Pas¸ca, 2004; Et-
zioni et al., 2005; Pas¸ca, 2007; Kozareva et al.,
2008) and potentially we can use any of them.
In our experiments, we use the doubly-anchored
(DAP) method of (Kozareva et al., 2008), because it
achieves higher precision than (Etzioni et al., 2005;
Pas¸ca, 2007), it is easy to implement and requires
minimum supervision (only one seed instance and a
lexico-syntactic pattern).
For a given semantic class of interest say ani-
mals, the algorithm starts with a seed example of
the class, say whales. The seed instance is fed into
a doubly-anchored pattern “&lt;semantic-class&gt; such
as &lt;seed&gt; and *”, which extracts on the position
of the * new instances of the semantic class. Then,
the newly acquired instances are individually placed
on the position of the seed in the DAP pattern. The
bootstrapping procedure is repeated until no new in-
stances are found. We use the harvested instances to
build the instance-instance graph in which the nodes
are the learned instances and directed edges like
(whales,dolphins) indicate that the instance whales
extracted the instance dolphins. The edges between
the instances are weighted based on the number of
times the DAP pattern extracted the instances to-
gether.
Different strategies can be employed to acquire
semantic classes for each instance. We follow the
fully automated approach of (Hovy et al., 2009),
which takes the learned instance pairs from DAP and
feeds them into the pattern “* such as &lt;instance1&gt;
and &lt;instance2&gt;”. The algorithm extracts on the
position of the * new semantic classes related to
instance1. According to (Hovy et al., 2009), the
usage of two instances acts as a disambiguator and
leads to much more accurate semantic class extrac-
tion compared to (Ritter et al., 2009).
</bodyText>
<sectionHeader confidence="0.998747" genericHeader="method">
4 Methods
</sectionHeader>
<bodyText confidence="0.9999934">
We model the output of the instance harvesting al-
gorithm as a directed weighted graph that is given
by a set of vertices V and a set of edges E. We use
n to denote the number of vertices. A node u corre-
sponds to a learned instance, and an edge (u, v) ∈ E
indicates that the instance v was learned from the in-
stance u using the DAP pattern. The weight of the
edge w(u, v) specifies the number of times the pair
of instances were found by the DAP pattern. We de-
fine the adjacency matrix of the graph as:
</bodyText>
<equation confidence="0.919745333333333">
� A v) w(u, v) if (u, v) ∈ E
(u, _
0 otherwise.
</equation>
<bodyText confidence="0.956638">
We use dout(u) to specify the out-degree of u:
dout(u) = E(u,v)∈E w(u, v), and din(v) to specify
the in-degree of v: din(v) = E(u,v)∈E w(u, v).
</bodyText>
<page confidence="0.971391">
120
</page>
<bodyText confidence="0.999184125">
We represent the initial set of instances L that are
believed to belong to class C (the set of labeled in-
stances) by a row vector l E {0,1}n, where l(u) = 1
if u E L. Our objective is to compute a vector lˆ
where ˆl(u) is proportional to how likely it is that u
belongs to C. We write all vectors as row vectors,
and use c� to denote a 1 by n constant vector such
that clu) = c for all u E V .
</bodyText>
<subsectionHeader confidence="0.995517">
4.1 Personalized Centrality
</subsectionHeader>
<bodyText confidence="0.995664529411765">
Our first approach is based on the intuition that if
u E C and (u, v) E E, then it is more likely that
v E C. Moreover, the larger the weight of the edge
w(u, v), the more likely it is that v E C. When we
extend this intuition to all the in-neighbors, we say
that the score of each node is proportional to the sum
of the scores of its in-neighbors scaled by the edge
weights: ˆl(v) = α P(u,v)EE ˆl(u)w(u, v). We can
verify that the vector lˆ must then satisfy lˆ = αˆlA,
so it is an eigenvector of the adjacency matrix of the
graph with an eigenvalue of α.
However, this formulation is insufficient because
even though it captures our intuition that the nodes
get their scores from their in-neighbors, we are still
ignoring the initial scores of the nodes. A way to
take the initial scores into consideration is to com-
pute the following steady-state equation:
</bodyText>
<equation confidence="0.990531">
lˆ= l + α ·ˆlA. (1)
</equation>
<bodyText confidence="0.977292894736842">
Equation 1 specifies that the score ˆl(u) of each node
u is the sum of its initial score l(u) and the weighted
sum of the scores of its neighbors, which is scaled
by α. This equation is known as α-centrality, which
was first introduced by (Bonacich and Lloyd, 2001).
The α parameter controls how much the score of
each node depends on the scores of its neighbors.
When α = 0 the score of each node is equivalent to
its initial score, and does not depend on the scores
of its neighbors at all.
Alternately, we can think of the vector lˆ as the
fixed-point of the process in which in each iteration
some node v updates its score ˜l(v) by setting ˜l(v) =
l(v) + α P(u,v)EE w(u, v)˜l(u).
Solving Equation 1 we can see that lˆ = l(I −
αA)−1, where I is the identity matrix of size n.
The solution is also closely related to the following
expression, which is known as a Katz score (Katz,
1953):
</bodyText>
<equation confidence="0.995254666666667">
°O
sX
t=1
</equation>
<bodyText confidence="0.998002333333333">
We can verify that At(u, v) gives the number of
paths of length t between u and v. Katz proposed
using the above expression with the starting vector
</bodyText>
<equation confidence="0.830943">
�
s = 1 to measure centrality in a network. Therefore,
</equation>
<bodyText confidence="0.974263">
the score of node v is given by the number of paths
from u to v for all u E V , with longer paths given
less weight based on the value of α. The method
proposed here measures a similar quantity with a
non-uniform starting vector. To show the relation-
ship between the two measures we use the identity
that P°Ot=1 αtAt = (I − αA)−1 − I. It is easy to see
</bodyText>
<equation confidence="0.9954508">
that lˆ = l(I − αA)−1
= l(P°Ot=1 αtAt + I)
= l P°O t=1 αtAt + l (2)
= l°O αtAt.
Pt=0
</equation>
<bodyText confidence="0.999632">
Equation 2 shows that ˆl(v) is given by the number
of paths from u to v for all u E L (the initial labeled
set). Using a larger value of α corresponds to giving
more weight to paths of longer length. The summa-
tion P°Ot=0 αtAt converges as long as |α |&lt; 1/λmax,
where λmax is the largest eigenvalue of A. There-
fore, we can only consider values of α in this range.
</bodyText>
<subsectionHeader confidence="0.996407">
4.2 Regularization Using Random Walks
</subsectionHeader>
<bodyText confidence="0.999796">
Our second approach constrains lˆto be as consistent
or smooth as possible with respect to the structure
of the graph. The simplest way to express this is
to require that for each edge (u, v) E E, the scores
of the endpoints ˆl(u) and ˆl(v) must be as similar as
possible. Moreover, the greater the weight of the
edge w(u, v) the more important it is for the scores
to match. Using this intuition we can define the fol-
lowing optimization problem:
</bodyText>
<equation confidence="0.974808">
XargminˆlE{0,1J&apos;t (ˆl(u) − ˆl(v))2.
(u,v)EE
</equation>
<bodyText confidence="0.9047987">
Setting lˆ = 0�or lˆ= �
1 clearly optimizes this func-
tion, but does not give a meaningful solution. How-
ever, we can additionally constrain lˆ by requiring
that the initial labels cannot be modified, or more
generally penalizing the discrepancy between ˆl(u)
and l(u) for u E L. The methods of (Talukdar and
Pereira, 2010) optimize objective functions of this
type.
αtAt.
</bodyText>
<page confidence="0.939374">
121
</page>
<bodyText confidence="0.999975043478261">
Unlike the work of (Talukdar and Pereira, 2010),
here we use an objective function that considers
smoothness with respect to a random walk on the
graph. Performing a random walk allows us to take
more of the graph structure into account. For exam-
ple, if nodes u and v are part of the same cluster then
it is likely that the edge (u, v) is heavily traversed
during the random walk, and should have a lot of
probability in the stationary distribution of the walk.
Simply considering the weight of the edge w(u, v)
gives us no such information. Therefore if our objec-
tive function requires the scores to be consistent with
respect to the stationary probability of the edges in
the random walk, we can compute scores that are
consistent with the clustering structure of the graph.
Our semantic network is not strongly connected,
so we must make some modifications to the random
walk to ensure that it has a stationary distribution.
Section 4.2.1 describes our random walk and how
we compute the transition probability matrix P and
its stationary probability distribution π. The defini-
tion of our objective function and the description of
how it is optimized is given in Section 4.2.2.
</bodyText>
<subsectionHeader confidence="0.904877">
4.2.1 Teleporting Random Walk
</subsectionHeader>
<bodyText confidence="0.9999905">
Formally, a random walk is a process where at
each step we move from some node to one of its
neighbors. The transition probabilities are given
by edge weights, therefore the transition probability
matrix W is the normalized adjacency matrix where
each row sums to one:
</bodyText>
<equation confidence="0.974931">
W = D−1A.
</equation>
<bodyText confidence="0.998929">
Here the D matrix is the degree matrix, which is a
diagonal matrix given by
</bodyText>
<equation confidence="0.959487666666667">
� dout(u) if u = v
D(u, v) =
0 otherwise.
</equation>
<bodyText confidence="0.999792">
In our semantic network some nodes have no out-
neighbors, so in order to compute W we first add a
self-loop to any such node. In addition, we modify
the random walk to reset at each step with nonzero
probability β to ensure that it has a steady-state
probability distribution. When the walk resets it
jumps or teleports to any node in the graph with
equal probability. The transition probability matrix
of this process is given by
</bodyText>
<equation confidence="0.999087">
P = βK + (1 − β)W,
</equation>
<bodyText confidence="0.8470702">
where K is an n by n matrix given by K(u, v) = 1
n
for all u, v ∈ V . The stationary distribution π must
satisfy π = πP. Equivalently π can be viewed as a
solution to the following PageRank equation:
</bodyText>
<equation confidence="0.986973">
π = βs + (1 − β)πW.
</equation>
<bodyText confidence="0.9997605">
Here the starting vector s = 1n~1 gives the prob-
ability distribution for where the walk transitions
when it resets. In our computations we use a jump
probability β = 0.15, which is standard for com-
putations of PageRank. The stationary distribution
π can be computed by either solving the PageRank
equation or computing the eigenvector of P corre-
sponding to the eigenvalue of 1.
</bodyText>
<subsubsectionHeader confidence="0.63318">
4.2.2 Regularization
</subsubsectionHeader>
<bodyText confidence="0.968273">
(Zhou et al., 2005) propose the following function
to measure the smoothness of lˆ with respect to the
stationary distribution of the random walk:
</bodyText>
<equation confidence="0.9492285">
l(v) 2
\/π(v) ) .
</equation>
<bodyText confidence="0.999484928571429">
Here π(u)P(u, v) gives the steady-state proba-
bility of traversing the edge (u, v), and π(u) and
π(v) specify how much probability u and v have
in the stationary distribution π. Zhou et al. point
out that using this function gives better results than
smoothness with respect to the edge weights, which
can be formulated by replacing π(u)p(u, v) with
w(u, v), and replacing π(u) and π(v) with dout(u)
and din(v), respectively. This observation is con-
sistent with our intuition that considering a random
walk takes more of the graph structure into account.
In addition to minimizing Ω(ˆl), we also want lˆ to
be as close as possible to l, which gives the follow-
ing optimization problem:
</bodyText>
<equation confidence="0.988572">
argminˆl∈R-{Ω(ˆy) + µ||ˆl − l||2}. (3)
</equation>
<bodyText confidence="0.997504">
Here the µ &gt; 0 parameter specifies the tradeoff be-
tween the two terms: using a larger µ corresponds to
placing more emphasis on agreement with the initial
labels. (Zhou et al., 2005) show that this objective is
optimized by computing
</bodyText>
<equation confidence="0.954693">
lˆ = (I − γΘ)−1l, (4)
where Θ = (Π1/2PΠ−1/2 + Π−1/2PΠ1/2)/2, and
γ = 1/(1 + µ). Π is a diagonal matrix given by
Ω( � Cπ(u)P(u, v) ˆl(u)
ˆl) = 1 \/π (u)
2
(u,v)∈E
122
II(u, v) =
π(u) if u = v
0 otherwise.
</equation>
<bodyText confidence="0.999957142857143">
Zhou et al. propose this approach for semi-
supervised learning of labels on the graph, given an
initial vector l such that l(u) = 1 if vertex u has the
label, l(u) = −1 if u does not have the label, and
l(u) = 0 if the vertex is unlabeled. They propose
taking the sign of ˆl(u) to classify u as positive or
negative. Using our labeling procedure we do not
have any negative examples, so our initial vector l
is non-negative, resulting in a non-negative vector ˆl.
This is not a problem because we can still interpret
ˆl(u) to be proportional to how likely it is that u has
the label. Rather than trying different settings of µ,
we directly vary -y, with a smaller -y placing more
emphasis on agreement with initial labels.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="method">
5 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.907413">
5.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.999463631578947">
For our experimental study, we select three widely
used domains in the harvesting community (Et-
zioni et al., 2005; Pas¸ca, 2007; Hovy et al., 2009;
Kozareva and Hovy, 2010): animals and vehicles.
For each domain we randomly selected different se-
mantic classes, which resulted in 20 classes alto-
gether. To generate the instance-instance seman-
tic network, we use the harvesting procedure de-
scribed in Section 3. For example, to learn instances
associated with animals, we instantiate the boot-
strapping algorithm with the semantic class animals,
the seed instance bears and the pattern “animals
such as bears and *”. We submitted the pattern as
queries to Yahoo!Boss and collected new instances.
We ranked the instances following (Kozareva et al.,
2008) which resulted in 397 animal, 4471 plant and
1425 vehicle instances. Table 1 shows the number
of nodes (instances) and directed edges for the con-
structed semantic networks.
</bodyText>
<table confidence="0.962239333333333">
class #instances #directed-edges
animals 397 2812
vehicles 1425 3191
</table>
<tableCaption confidence="0.998794">
Table 1: Nodes &amp; Edges in the Instance Network.
</tableCaption>
<bodyText confidence="0.999796636363636">
Next, we use the harvested instances to auto-
matically learn the semantic classes associated with
them. For example, bears and wolves are animals
but also mammals, predators, vertebrates among
others. The obtained class harvesting results are
shown in Table 2. We indicate with Inst(Hovy et
al., 2009) the number of instances in the semantic
network that discovered the class during the pattern-
based harvesting, and with InstInWordNet the num-
ber of instances in the semantic network belonging
to the class according to WordNet.
</bodyText>
<table confidence="0.9927914375">
ClassName Inst(Hovy et al., 2009) InstInWordNet
arthropods 12 50
carnivores 24 57
chordates 2 313
eutherians 3 193
insects 5 29
invertebrates 53 84
mammals 114 205
reptile 5 22
ruminants 14 34
ungulates 16 66
crafts 24 68
motor vehicles 27 127
self-propelled vehicles 36 145
vessels 11 36
wheeled vehicles 54 190
</table>
<tableCaption confidence="0.997425">
Table 2: Learned &amp; Gold Standard Class-Instances.
</tableCaption>
<bodyText confidence="0.9999023">
We can see that the pattern-based approach of
(Hovy et al., 2009) does not recover a lot of the
class-instance relations present in WordNet. Be-
cause of this gap between the actual and the har-
vested class-instance pairs arises the objective of our
work, which is to explore the relationships between
the instances to propagate the initially learned class
labels to the remaining unlabeled instances. To eval-
uate the performance of our approach, we use as a
gold standard the WordNet class-instance mappings.
</bodyText>
<subsectionHeader confidence="0.999682">
5.2 Testing Our Approach
</subsectionHeader>
<bodyText confidence="0.999846785714286">
Our approach is based on the intuition that given a
labeled instance u of class C, and an instance v in
our network, if there is an edge (u, v) then it is more
likely that v has the label C as well. For example,
if the instance bears is of class vertebrates and there
is an edge between the instances bears and wolves,
then it is likely that wolves are also vertebrates.
Before proceeding with the instance-instance class-
label propagation algorithms, first we study whether
this intuition is correct.
Individually for each class label C, we construct a
set Tc that contains all instances in the network be-
longing to C according to WordNet. Then we com-
pute the probability that v belongs to C in WordNet
</bodyText>
<page confidence="0.997798">
123
</page>
<bodyText confidence="0.9968328125">
given that (u, v) is an edge in the instance network
and u belongs to C in WordNet: Prh = Pr[v E
TC  |(u, v) E E and u E TC]. We compare
this to the background probability Prb = Pr[v E
TC  |u, v E V and u E TC], which gives the proba-
bility that v belongs to C in WordNet if it is chosen
at random. In other words, if Prh = 1, this means
that whenever u has the label C and (u, v) is an
edge, then v is always labeled with C. If indeed this
is the case, then a good classifier can simply take the
initial set L and extend the labels to all nodes reach-
able from L in the semantic network. The larger the
difference between Prh and Prb, the more informa-
tion the links of the instance network carry for the
task of label propagation. Table 3 shows the Prh
and Prb values for each class.
</bodyText>
<table confidence="0.9982399375">
CLASS Prh Prb
arthropods .46 .12
carnivores .49 .14
chordates .95 .80
eutherians .80 .49
insects .31 .07
invertebrates .74 .21
mammals .82 .52
reptile .27 .05
ruminants .39 .08
ungulates .60 .16
crafts .07 .05
motor vehicles .10 .09
self-propelled vehicles .11 .10
vessels .08 .02
wheeled vehicles .13 .13
</table>
<tableCaption confidence="0.999623">
Table 3: Learned &amp; Gold Standard Class-Instances.
</tableCaption>
<bodyText confidence="0.9999426">
This study verifies our intuition that using the re-
lationships between the instances to extend a class
label to the remaining unlabeled nodes is an effec-
tive approach to enhancing an incomplete set of ini-
tial labels.
</bodyText>
<subsectionHeader confidence="0.998363">
5.3 Comparative Study
</subsectionHeader>
<bodyText confidence="0.983557413793103">
The objective of our work is given a set of initially
labeled nodes L, to assign to each node a score
that indicates how likely it is to belong to L. The
simplest way to do this using the edges of the in-
stance network is to say that a node that has more
in-neighbors that have a certain label is more likely
to have this label. We define the in-neighbor score
i(v) of a node v as i(v) =|{u E V |(u,v) E
E and u E L}|. We expect that the higher the in-
neighbor score of v, the more likely it is that v has
the label L. The personalized centrality method
that we proposed generalizes this intuition to indi-
rect neighbors (see Methods). Our regularization
using random walks technique further explores the
link structure of the instance network by considering
a random walk on it (see Methods). We compare our
approaches with a method that labels nodes at ran-
dom. The expected accuracy for class C is given by
|TC|
n , where n is the number of nodes in the network,
and TC is the set containing all nodes that belong to
C according to WordNet. In other words, given that
there are 84 nodes in the network that are classified
as invertebrate according to WordNet, and there are
397 nodes in total, if we choose any number of nodes
at random our expected accuracy is 21%.
We evaluate the performance of our approaches
against the WordNet gold standard and show the ob-
tained results in Tables 4 and 5.
</bodyText>
<table confidence="0.998377285714286">
Invertebrates
rank centrality regularization in-neighbor random
5 1.0 1.0 .80 .21
10 1.0 1.0 .70 .21
20 .95 1.0 .75 .21
50 .96 .98 .76 .21
100 .69 .73 .67 .21
Mammals
rank centrality regularization in-neighbor random
5 .80 1.0 .80 .52
10 .90 1.0 .90 .52
20 .95 .95 .85 .52
50 .86 .96 .80 .52
100 .92 .92 .76 .52
Carnivores
rank centrality regularization in-neighbor random
5 1.0 1.0 .80 .14
10 .80 .80 .60 .14
20 .80 .85 .55 .14
50 .50 .68 .48 .14
100 .41 .44 .41 .14
</table>
<tableCaption confidence="0.999773">
Table 4: Accuracy @ Different Ranks.
</tableCaption>
<bodyText confidence="0.998310636363636">
Table 4 shows the accuracy at rank R calculated
as the number of correctly labeled instances with
class C at rank R divided by the total number of
instances with class C at rank R. Due to space limi-
tation, we show detailed ranking only for three of the
classes. We can see that using the semantic network
significantly enhances our ability to learn class la-
bels. Even the simple in-neighbor method produces
results that are very significant compared to chance.
Our centrality and regularization techniques further
explore the structure of the semantic network to give
</bodyText>
<page confidence="0.996534">
124
</page>
<bodyText confidence="0.999103571428571">
better predictions.
Table 5 shows the accuracy of the class label prop-
agation algorithms for each class. For each class we
consider the top k ranked nodes, where k is the num-
ber of instances that belong to this class according
to WordNet. For example, the accuracy of central-
ity for carnivores is 80% showing that from the top
57 ranked animal instances, 80% belong to carni-
vores. In the final column we also report the per-
formance of a label propagation algorithm that uses
class-instance graph instead of an instance-instance
graph. To build the graph we remove the edges
between the instances and keep the class-instance
mappings discovered by the harvesting algorithm of
(Hovy et al., 2009). We use the modified adsorption
algorithm (MAD) of (Talukdar et al., 2008), which
is freely available from the Junto toolkit1. To rank
the instances for each class label produced by Junto,
we use the computed label scores as a ranking crite-
ria and measure accuracy similarly to centrality and
regularization.
</bodyText>
<table confidence="0.998831875">
class Centrality Regular. Rand MAD
arthropods .50 .60 .12 .56
carnivores .80 .85 .14 .44
chordates .81 .83 .80 .79
eutherians .54 .60 .49 .60
insects .38 .52 .07 .17
invertebrates .94 .96 .21 .64
mammals .82 .90 .52 .63
reptile .45 .55 .05 .14
ruminants .41 .44 .08 .41
ungulates .44 .61 .16 .32
crafts .47 .56 .05 .35
motor vehicle .45 .48 .09 .24
self-propelled vehicle .49 .47 .10 .27
vessel .33 .39 .02 .31
wheeled vehicle .51 .52 .13 .33
</table>
<tableCaption confidence="0.99962">
Table 5: Comparative Study.
</tableCaption>
<bodyText confidence="0.9999243">
The obtained results show that for almost all cases
the methods that use the structure of the instance net-
work significantly outperform predictions that use
the class-instance graph. This indicates that we
can indeed learn a lot form the instance-instance
relationships by exploring the structure of the in-
stance network. Among all approaches regulariza-
tion achieves the best results. We believe that reg-
ularization works well because it considers a ran-
dom walk on the semantic graph, and within-cluster
</bodyText>
<footnote confidence="0.947949">
1http://code.google.com/p/junto/
</footnote>
<bodyText confidence="0.999276181818182">
edges are traversed more often in a random walk.
The regularization technique computes scores that
are consistent with the clustering structure of the
graph by requiring that the endpoints of highly tra-
versed edges, which are likely in the same cluster,
have similar scores (see Methods). Overall, regu-
larization enhanced the original output generated by
the pattern-based knowledge harvesting approach of
(Hovy et al., 2009) with 1219 new class-instance
pairs (75% additional information) while maintain-
ing 61.87% accuracy.
</bodyText>
<sectionHeader confidence="0.3432035" genericHeader="method">
Centrality
Regularization
</sectionHeader>
<subsectionHeader confidence="0.993804">
5.4 Parameter Tuning
</subsectionHeader>
<bodyText confidence="0.999891">
Both of our centrality and regularization methods
have a single tunable parameter. For centrality the
parameter α controls how much the label of each
node depends on the labels of its neighbors in the
</bodyText>
<figure confidence="0.997241565217391">
50 100 150 200 250 300 350
Rank
Accuracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
_=0.01/hmax
_=0.05/hmax
_=0.10/hmax
_=0.25/hmax
_=0.50/hmax
_=0.99/hmax
Random
50 100 150 200 250 300 350
Rank
</figure>
<figureCaption confidence="0.996618">
Figure 1: Parameter Tuning For Invertebrates.
</figureCaption>
<figure confidence="0.999320210526316">
Accuracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
a=0.01
a=0.05
a=0.10
a=0.25
a=0.50
a=0.99
Random
</figure>
<page confidence="0.995051">
125
</page>
<bodyText confidence="0.999989052631579">
graph. The values range from 0 to 1/λmax, where
λmax is the largest eigenvalue of the adjacency ma-
trix of the semantic network. When α = 0 the label
of each node is equivalent to its initial label, while
higher values of α give more weight to the labels of
nodes that are further away.
For regularization the parameter γ controls how
much emphasis is placed on the agreement between
the initial and learned labels. The values of γ are
between 0 and 1. Smaller values require that the
learned labels be more consistent with the original
labels. When γ = 0 the learned labels will exactly
match the original labels.
For each method we try several parameter settings
and show the results in Figure 1 for the propagation
of the class label invertebrate. We can see that both
methods are quite insensitive to the parameter set-
tings, unless we choose very extreme values that ig-
nore the original labels.
</bodyText>
<subsectionHeader confidence="0.996514">
5.5 Effect of number of labeled class-instances
</subsectionHeader>
<bodyText confidence="0.9999765625">
We also study how the quality of the results is af-
fected by the number of initial class-instance pairs
used by our propagation methods. We conduct ex-
periments using only 25%, 50%, 75% and 100% of
the initial class-instance pairs learned by (Hovy et
al., 2009). Figure 2 shows the results for the label
propagation of the class invertebrate.
The performance of our methods significantly im-
proves when we incorporate more labels. Still, if we
are less concerned with recall and want to find small
sets of nodes with very high accuracy, the number
of initial labels is less important. For example, start-
ing with only 13 labeled nodes we can still achieve
100% accuracy for the top 30 nodes using regular-
ization, and 96% accuracy for the top 25 nodes using
centrality.
</bodyText>
<sectionHeader confidence="0.999555" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.998629875">
In this paper we proposed a centrality and regular-
ization graph-theoretic methods that explore the re-
lationships between the instances themselves to ef-
fectively extend a small set of class-instance labels
to all instances in a semantic network. The proposed
approaches are intuitive and almost parameter-free.
We conducted a series of experiments in which we
compared the effectiveness of the centrality and reg-
</bodyText>
<figure confidence="0.9955018">
Centrality
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
50 100 150 200
Rank
Regularization
</figure>
<figureCaption confidence="0.931618">
Figure 2: Effect of Number of Initial Class-Instance
Pairs for Invertebrates.
</figureCaption>
<bodyText confidence="0.999644428571429">
ularization methods to learn new labels for the un-
labeled instances. We showed that the enhanced
class labels improve the original output generated by
the pattern-based knowledge harvesting approach of
(Hovy et al., 2009). Finally, we have studied the
impact of the class-instance and instance-instance
graphs for the class-label propagation task. The lat-
ter approach has shown to produce much more ac-
curate results. In the future, we want to apply our
approach to Web-based taxonomy induction, which
according to (Kozareva and Hovy, 2010) is stifled
due to the lacking relations between the instances
and the classes, and the classes themselves. The pro-
posed methods can be also applied to enhance fact
</bodyText>
<figure confidence="0.998163652173913">
50 100 150 200
Rank
Accuracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Random
25% Initial Label
50% Initial Label
100% Initial Label
Accuracy
Random
25% Initial Label
50% Initial Label
100% Initial Label
</figure>
<page confidence="0.965925">
126
</page>
<bodyText confidence="0.676586">
farms (Jain and Pantel, 2010).
</bodyText>
<sectionHeader confidence="0.996357" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999465">
We acknowledge the support of DARPA contract
number FA8750-09-C-3705 and NSF grant IIS-
0429360. We would like to thank the three anony-
mous reviewers for their useful comments and sug-
gestions and Partha Talukdar for the discussions on
modified adsorption.
</bodyText>
<sectionHeader confidence="0.998893" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999357784946237">
Enrique Alfonseca, Marius Pasca, and Enrique Robledo-
Arnuncio. 2010. Acquisition of instance attributes
via labeled and related instances. In Proceeding of
the 33rd international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’10, pages 58–65.
Phillip Bonacich and Paulette Lloyd. 2001. Social Net-
works, 23(3):191–201.
Michael J. Cafarella, Christopher R, Dan Suciu, Oren Et-
zioni, and Michele Banko. 2007a. Structured query-
ing of web text: A technical challenge. In in CIDR.
Michael J. Cafarella, Dan Suciu, and Oren Etzioni.
2007b. Navigating extracted data with schema discov-
ery. In Tenth International Workshop on the Web and
Databases, WebDB 2007WebDB.
Dmitry Davidov and Ari Rappoport. 2008. Classification
of semantic relationships between nominals using pat-
tern clusters. In Proceedings of ACL-08: HLT, pages
227–235, June.
Dmitry Davidov and Ari Rappoport. 2009. Geo-mining:
Discovery of road and transport networks using direc-
tional patterns. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP-09, pages 267–275.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S. Weld, and Alexander Yates. 2005. Unsuper-
vised named-entity extraction from the web: an exper-
imental study. Artificial Intelligence, 165(1):91–134,
June.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. Bradford Books.
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2003. Learning semantic constraints for the automatic
discovery of part-whole relations. In Proceedings of
the 2003 Conference of the North American Chapter of
the Association for Computational Linguistics on Hu-
man Language Technology, pages 1–8.
Marti Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proceedings of the 14th
conference on Computational linguistics, pages 539–
545.
Eduard Hovy, Zornitsa Kozareva, and Ellen Riloff. 2009.
Toward completeness in concept extraction and clas-
sification. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
pages 948–957.
Alpa Jain and Patrick Pantel. 2010. Factrank: Random
walks on a web of facts. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics
(Coling 2010), pages 501–509.
Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hilde-
brandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-
des, Gregory Marton, and Federico Mora. 2003. In-
tegrating web-based and corpus-based techniques for
question answering. In Proceedings of the twelfth text
retrieval conference (TREC), pages 426–435.
Leo Katz. 1953. A new status index derived from socio-
metric analysis. Psychometrika, 18:39–43.
Zornitsa Kozareva and Eduard Hovy. 2010. A semi-
supervised method to learn and construct taxonomies
using the web. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1110–1118.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008.
Semantic class learning from the web with hyponym
pattern linkage graphs. In Proceedings of the 46th
Annual Meeting of the Association for Computational
Linguistics ACL-08: HLT, pages 1048–1056.
Dekang Lin and Patrick Pantel. 2001. Dirt - discovery
of inference rules from text. In In Proceedings of the
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 323–328.
Dekang Lin and Patrick Pantel. 2002. Concept discovery
from text. In Proc. of the 19th international confer-
ence on Computational linguistics, pages 1–7.
Marius Pas¸ca. 2004. Acquisition of categorized named
entities for web search. In Proceedings of the thir-
teenth ACM international conference on Information
and knowledge management, pages 137–145.
Marius Pas¸ca. 2007. Organizing and searching the world
wide web of facts – step two: harnessing the wisdom
of the crowds. In Proceedings of the 16th international
conference on World Wide Web, pages 101–110.
Patrick Pantel and Marco Pennacchiotti. 2006. Espresso:
leveraging generic patterns for automatically harvest-
ing semantic relations. In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, ACL-44, pages 113–120.
Marco Pennacchiotti and Patrick Pantel. 2009. Entity
extraction via ensemble semantics. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
</reference>
<page confidence="0.974107">
127
</page>
<reference confidence="0.997706358490566">
Language Processing: Volume 1 - Volume 1, EMNLP
’09, pages 238–247.
Ellen Riloff and Rosie Jones. 1999. Learning dictionar-
ies for information extraction by multi-level bootstrap-
ping. In AAAI ’99/IAAI ’99: Proceedings of the Six-
teenth National Conference on Artificial intelligence.
Ellen Riloff and Jessica Shepherd. 1997. A corpus-based
approach for building semantic lexicons. In Proceed-
ings of the Empirical Methods for Natural Language
Processing, pages 117–124.
Alan Ritter, Stephen Soderland, and Oren Etzioni. 2009.
What is this, anyway: Automatic hypernym discov-
ery. In Proceedings of the AAAI Spring Symposium on
Learning by Reading and Learning to Read.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous evi-
dence. In Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, ACL-44, pages 801–808.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowledge.
In WWW ’07: Proceedings of the 16th international
conference on World Wide Web, pages 697–706.
Partha Pratim Talukdar and Fernando Pereira. 2010.
Experiments in graph-based semi-supervised learning
methods for class-instance acquisition. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1473–1481.
Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca,
Deepak Ravichandran, Rahul Bhagat, and Fernando
Pereira. 2008. Weakly-supervised acquisition of la-
beled class instances using graph random walks. In
Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages 582–
590.
Vishnu Vyas, Patrick Pantel, and Eric Crestan. 2009.
Helping editors choose better seed sets for entity set
expansion. In Proceeding of the 18th ACM conference
on Information and knowledge management, CIKM
’09, pages 225–234.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using selec-
tional preferences. InACL-44: Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association for
Computational Linguistics, pages 849–856.
Dengyong Zhou, Jiayuan Huang, and Bernhard
Sch¨olkopf. 2005. Learning from labeled and
unlabeled data on a directed graph. In Proceedings
of the 22nd international conference on Machine
learning, ICML ’05, pages 1036–1043.
</reference>
<page confidence="0.996701">
128
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.210403">
<title confidence="0.998249">Class Label Enhancement via Related Instances</title>
<author confidence="0.94845">Zornitsa</author>
<affiliation confidence="0.990541">USC Information Sciences</affiliation>
<address confidence="0.98548">4676 Admiralty</address>
<author confidence="0.944962">Marina del Rey</author>
<author confidence="0.944962">CA</author>
<email confidence="0.99876">kozareva@isi.edu</email>
<author confidence="0.7101">Konstantin</author>
<affiliation confidence="0.881946">Boston</affiliation>
<address confidence="0.6462085">111 Cummington Boston, MA,</address>
<email confidence="0.999166">kvodski@bu.edu</email>
<author confidence="0.913494">Shang-Hua</author>
<affiliation confidence="0.999952">University of Southern</affiliation>
<address confidence="0.9337935">941 Bloom Walk, SAL Los Angeles, CA</address>
<email confidence="0.99865">shanghua@usc.edu</email>
<abstract confidence="0.999785571428572">Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Alfonseca</author>
<author>Marius Pasca</author>
<author>Enrique RobledoArnuncio</author>
</authors>
<title>Acquisition of instance attributes via labeled and related instances.</title>
<date>2010</date>
<booktitle>In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’10,</booktitle>
<pages>58--65</pages>
<contexts>
<context position="9196" citStr="Alfonseca et al., 2010" startWordPosition="1390" endWordPosition="1393">ures from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. (Talukdar and Pereira, 2010) conducted a comparative study of graph algorithms and showed that class-instance extraction can be improved using additional information that can be modeled as instance-attribute edges. Closest to our work is that of (Talukdar et al., 2008; Talukdar and Pereira, 2010) who model classinstance relations to propagate class-labels. Although these algorithms can be applied to other relations (Alfonseca et al., 2010), to our knowledge yet nobody has modeled the connections between the instances themselves for the task of class-label propagation. We propose regularization and centrality graph-theoretic methods, which exploit the instanceinstance network and a small set of class-instance pairs to propagate the class-labels to the remaining unlabeled instances. While objectives similar to regularization have been used for class-label propagation, the application of node centrality for this task is also novel. The proposed solutions are intuitive and almost parameter-free (both methods have a single parameter</context>
</contexts>
<marker>Alfonseca, Pasca, RobledoArnuncio, 2010</marker>
<rawString>Enrique Alfonseca, Marius Pasca, and Enrique RobledoArnuncio. 2010. Acquisition of instance attributes via labeled and related instances. In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’10, pages 58–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip Bonacich</author>
<author>Paulette Lloyd</author>
</authors>
<date>2001</date>
<journal>Social Networks,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="14108" citStr="Bonacich and Lloyd, 2001" startWordPosition="2264" endWordPosition="2267">f the graph with an eigenvalue of α. However, this formulation is insufficient because even though it captures our intuition that the nodes get their scores from their in-neighbors, we are still ignoring the initial scores of the nodes. A way to take the initial scores into consideration is to compute the following steady-state equation: lˆ= l + α ·ˆlA. (1) Equation 1 specifies that the score ˆl(u) of each node u is the sum of its initial score l(u) and the weighted sum of the scores of its neighbors, which is scaled by α. This equation is known as α-centrality, which was first introduced by (Bonacich and Lloyd, 2001). The α parameter controls how much the score of each node depends on the scores of its neighbors. When α = 0 the score of each node is equivalent to its initial score, and does not depend on the scores of its neighbors at all. Alternately, we can think of the vector lˆ as the fixed-point of the process in which in each iteration some node v updates its score ˜l(v) by setting ˜l(v) = l(v) + α P(u,v)EE w(u, v)˜l(u). Solving Equation 1 we can see that lˆ = l(I − αA)−1, where I is the identity matrix of size n. The solution is also closely related to the following expression, which is known as a </context>
</contexts>
<marker>Bonacich, Lloyd, 2001</marker>
<rawString>Phillip Bonacich and Paulette Lloyd. 2001. Social Networks, 23(3):191–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Cafarella</author>
<author>R Christopher</author>
<author>Dan Suciu</author>
<author>Oren Etzioni</author>
<author>Michele Banko</author>
</authors>
<title>Structured querying of web text: A technical challenge.</title>
<date>2007</date>
<booktitle>In in CIDR.</booktitle>
<contexts>
<context position="8042" citStr="Cafarella et al., 2007" startWordPosition="1215" endWordPosition="1218">008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2</context>
</contexts>
<marker>Cafarella, Christopher, Suciu, Etzioni, Banko, 2007</marker>
<rawString>Michael J. Cafarella, Christopher R, Dan Suciu, Oren Etzioni, and Michele Banko. 2007a. Structured querying of web text: A technical challenge. In in CIDR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Cafarella</author>
<author>Dan Suciu</author>
<author>Oren Etzioni</author>
</authors>
<title>Navigating extracted data with schema discovery.</title>
<date>2007</date>
<booktitle>In Tenth International Workshop on the Web and Databases, WebDB 2007WebDB.</booktitle>
<contexts>
<context position="8042" citStr="Cafarella et al., 2007" startWordPosition="1215" endWordPosition="1218">008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2</context>
</contexts>
<marker>Cafarella, Suciu, Etzioni, 2007</marker>
<rawString>Michael J. Cafarella, Dan Suciu, and Oren Etzioni. 2007b. Navigating extracted data with schema discovery. In Tenth International Workshop on the Web and Databases, WebDB 2007WebDB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Classification of semantic relationships between nominals using pattern clusters.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>227--235</pages>
<contexts>
<context position="2352" citStr="Davidov and Rappoport, 2008" startWordPosition="341" endWordPosition="344">5; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of</context>
<context position="7736" citStr="Davidov and Rappoport, 2008" startWordPosition="1167" endWordPosition="1170">2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the develo</context>
</contexts>
<marker>Davidov, Rappoport, 2008</marker>
<rawString>Dmitry Davidov and Ari Rappoport. 2008. Classification of semantic relationships between nominals using pattern clusters. In Proceedings of ACL-08: HLT, pages 227–235, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Geo-mining: Discovery of road and transport networks using directional patterns.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, EMNLP-09,</booktitle>
<pages>267--275</pages>
<contexts>
<context position="1890" citStr="Davidov and Rappoport, 2009" startWordPosition="270" endWordPosition="273">racy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity n</context>
<context position="7565" citStr="Davidov and Rappoport, 2009" startWordPosition="1141" endWordPosition="1145">e conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozarev</context>
</contexts>
<marker>Davidov, Rappoport, 2009</marker>
<rawString>Dmitry Davidov and Ari Rappoport. 2009. Geo-mining: Discovery of road and transport networks using directional patterns. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, EMNLP-09, pages 267–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>AnaMaria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="1725" citStr="Etzioni et al., 2005" startWordPosition="245" endWordPosition="248">t a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; D</context>
<context position="7386" citStr="Etzioni et al., 2005" startWordPosition="1113" endWordPosition="1116">he proposed graph algorithms and different baselines. We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), orga</context>
<context position="10115" citStr="Etzioni et al., 2005" startWordPosition="1527" endWordPosition="1531">lass-labels to the remaining unlabeled instances. While objectives similar to regularization have been used for class-label propagation, the application of node centrality for this task is also novel. The proposed solutions are intuitive and almost parameter-free (both methods have a single parameter, which is easy to interpret and does not require careful tuning). 3 Knowledge Harvesting from the Web Our proposed class-label enhancement approaches are agnostic to the sources of semantic instances and classes. Several methods have been developed to harvest instances from the Web (Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008) and potentially we can use any of them. In our experiments, we use the doubly-anchored (DAP) method of (Kozareva et al., 2008), because it achieves higher precision than (Etzioni et al., 2005; Pas¸ca, 2007), it is easy to implement and requires minimum supervision (only one seed instance and a lexico-syntactic pattern). For a given semantic class of interest say animals, the algorithm starts with a seed example of the class, say whales. The seed instance is fed into a doubly-anchored pattern “&lt;semantic-class&gt; such as &lt;seed&gt; and *”, which extracts on the p</context>
<context position="21535" citStr="Etzioni et al., 2005" startWordPosition="3638" endWordPosition="3642">e sign of ˆl(u) to classify u as positive or negative. Using our labeling procedure we do not have any negative examples, so our initial vector l is non-negative, resulting in a non-negative vector ˆl. This is not a problem because we can still interpret ˆl(u) to be proportional to how likely it is that u has the label. Rather than trying different settings of µ, we directly vary -y, with a smaller -y placing more emphasis on agreement with initial labels. 5 Experimental Evaluation 5.1 Data Collection For our experimental study, we select three widely used domains in the harvesting community (Etzioni et al., 2005; Pas¸ca, 2007; Hovy et al., 2009; Kozareva and Hovy, 2010): animals and vehicles. For each domain we randomly selected different semantic classes, which resulted in 20 classes altogether. To generate the instance-instance semantic network, we use the harvesting procedure described in Section 3. For example, to learn instances associated with animals, we instantiate the bootstrapping algorithm with the semantic class animals, the seed instance bears and the pattern “animals such as bears and *”. We submitted the pattern as queries to Yahoo!Boss and collected new instances. We ranked the instan</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. Artificial Intelligence, 165(1):91–134, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>Bradford Books.</publisher>
<contexts>
<context position="1450" citStr="Fellbaum, 1998" startWordPosition="204" endWordPosition="205">nce-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question a</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. Bradford Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Adriana Badulescu</author>
<author>Dan Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="1788" citStr="Girju et al., 2003" startWordPosition="255" endWordPosition="258">e graphs used to propagate the class labels and show that the latter one achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instance</context>
<context position="7463" citStr="Girju et al., 2003" startWordPosition="1126" endWordPosition="1129"> between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., </context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="2239" citStr="Hearst, 1992" startWordPosition="325" endWordPosition="326">ured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of exis</context>
<context position="7350" citStr="Hearst, 1992" startWordPosition="1109" endWordPosition="1110"> comparative study between the proposed graph algorithms and different baselines. We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmi</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th conference on Computational linguistics, pages 539– 545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
</authors>
<title>Toward completeness in concept extraction and classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>948--957</pages>
<contexts>
<context position="7915" citStr="Hovy et al., 2009" startWordPosition="1196" endWordPosition="1199">sed on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distri</context>
<context position="11441" citStr="Hovy et al., 2009" startWordPosition="1742" endWordPosition="1745">aced on the position of the seed in the DAP pattern. The bootstrapping procedure is repeated until no new instances are found. We use the harvested instances to build the instance-instance graph in which the nodes are the learned instances and directed edges like (whales,dolphins) indicate that the instance whales extracted the instance dolphins. The edges between the instances are weighted based on the number of times the DAP pattern extracted the instances together. Different strategies can be employed to acquire semantic classes for each instance. We follow the fully automated approach of (Hovy et al., 2009), which takes the learned instance pairs from DAP and feeds them into the pattern “* such as &lt;instance1&gt; and &lt;instance2&gt;”. The algorithm extracts on the position of the * new semantic classes related to instance1. According to (Hovy et al., 2009), the usage of two instances acts as a disambiguator and leads to much more accurate semantic class extraction compared to (Ritter et al., 2009). 4 Methods We model the output of the instance harvesting algorithm as a directed weighted graph that is given by a set of vertices V and a set of edges E. We use n to denote the number of vertices. A node u c</context>
<context position="21568" citStr="Hovy et al., 2009" startWordPosition="3645" endWordPosition="3648">itive or negative. Using our labeling procedure we do not have any negative examples, so our initial vector l is non-negative, resulting in a non-negative vector ˆl. This is not a problem because we can still interpret ˆl(u) to be proportional to how likely it is that u has the label. Rather than trying different settings of µ, we directly vary -y, with a smaller -y placing more emphasis on agreement with initial labels. 5 Experimental Evaluation 5.1 Data Collection For our experimental study, we select three widely used domains in the harvesting community (Etzioni et al., 2005; Pas¸ca, 2007; Hovy et al., 2009; Kozareva and Hovy, 2010): animals and vehicles. For each domain we randomly selected different semantic classes, which resulted in 20 classes altogether. To generate the instance-instance semantic network, we use the harvesting procedure described in Section 3. For example, to learn instances associated with animals, we instantiate the bootstrapping algorithm with the semantic class animals, the seed instance bears and the pattern “animals such as bears and *”. We submitted the pattern as queries to Yahoo!Boss and collected new instances. We ranked the instances following (Kozareva et al., 2</context>
<context position="23023" citStr="Hovy et al., 2009" startWordPosition="3873" endWordPosition="3876">1425 3191 Table 1: Nodes &amp; Edges in the Instance Network. Next, we use the harvested instances to automatically learn the semantic classes associated with them. For example, bears and wolves are animals but also mammals, predators, vertebrates among others. The obtained class harvesting results are shown in Table 2. We indicate with Inst(Hovy et al., 2009) the number of instances in the semantic network that discovered the class during the patternbased harvesting, and with InstInWordNet the number of instances in the semantic network belonging to the class according to WordNet. ClassName Inst(Hovy et al., 2009) InstInWordNet arthropods 12 50 carnivores 24 57 chordates 2 313 eutherians 3 193 insects 5 29 invertebrates 53 84 mammals 114 205 reptile 5 22 ruminants 14 34 ungulates 16 66 crafts 24 68 motor vehicles 27 127 self-propelled vehicles 36 145 vessels 11 36 wheeled vehicles 54 190 Table 2: Learned &amp; Gold Standard Class-Instances. We can see that the pattern-based approach of (Hovy et al., 2009) does not recover a lot of the class-instance relations present in WordNet. Because of this gap between the actual and the harvested class-instance pairs arises the objective of our work, which is to explo</context>
<context position="29134" citStr="Hovy et al., 2009" startWordPosition="4988" endWordPosition="4991">n algorithms for each class. For each class we consider the top k ranked nodes, where k is the number of instances that belong to this class according to WordNet. For example, the accuracy of centrality for carnivores is 80% showing that from the top 57 ranked animal instances, 80% belong to carnivores. In the final column we also report the performance of a label propagation algorithm that uses class-instance graph instead of an instance-instance graph. To build the graph we remove the edges between the instances and keep the class-instance mappings discovered by the harvesting algorithm of (Hovy et al., 2009). We use the modified adsorption algorithm (MAD) of (Talukdar et al., 2008), which is freely available from the Junto toolkit1. To rank the instances for each class label produced by Junto, we use the computed label scores as a ranking criteria and measure accuracy similarly to centrality and regularization. class Centrality Regular. Rand MAD arthropods .50 .60 .12 .56 carnivores .80 .85 .14 .44 chordates .81 .83 .80 .79 eutherians .54 .60 .49 .60 insects .38 .52 .07 .17 invertebrates .94 .96 .21 .64 mammals .82 .90 .52 .63 reptile .45 .55 .05 .14 ruminants .41 .44 .08 .41 ungulates .44 .61 .1</context>
<context position="30877" citStr="Hovy et al., 2009" startWordPosition="5270" endWordPosition="5273">egularization achieves the best results. We believe that regularization works well because it considers a random walk on the semantic graph, and within-cluster 1http://code.google.com/p/junto/ edges are traversed more often in a random walk. The regularization technique computes scores that are consistent with the clustering structure of the graph by requiring that the endpoints of highly traversed edges, which are likely in the same cluster, have similar scores (see Methods). Overall, regularization enhanced the original output generated by the pattern-based knowledge harvesting approach of (Hovy et al., 2009) with 1219 new class-instance pairs (75% additional information) while maintaining 61.87% accuracy. Centrality Regularization 5.4 Parameter Tuning Both of our centrality and regularization methods have a single tunable parameter. For centrality the parameter α controls how much the label of each node depends on the labels of its neighbors in the 50 100 150 200 250 300 350 Rank Accuracy 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 1 _=0.01/hmax _=0.05/hmax _=0.10/hmax _=0.25/hmax _=0.50/hmax _=0.99/hmax Random 50 100 150 200 250 300 350 Rank Figure 1: Parameter Tuning For Invertebrates. Accuracy 0.9 0</context>
<context position="32770" citStr="Hovy et al., 2009" startWordPosition="5596" endWordPosition="5599">match the original labels. For each method we try several parameter settings and show the results in Figure 1 for the propagation of the class label invertebrate. We can see that both methods are quite insensitive to the parameter settings, unless we choose very extreme values that ignore the original labels. 5.5 Effect of number of labeled class-instances We also study how the quality of the results is affected by the number of initial class-instance pairs used by our propagation methods. We conduct experiments using only 25%, 50%, 75% and 100% of the initial class-instance pairs learned by (Hovy et al., 2009). Figure 2 shows the results for the label propagation of the class invertebrate. The performance of our methods significantly improves when we incorporate more labels. Still, if we are less concerned with recall and want to find small sets of nodes with very high accuracy, the number of initial labels is less important. For example, starting with only 13 labeled nodes we can still achieve 100% accuracy for the top 30 nodes using regularization, and 96% accuracy for the top 25 nodes using centrality. 6 Conclusions In this paper we proposed a centrality and regularization graph-theoretic method</context>
<context position="34086" citStr="Hovy et al., 2009" startWordPosition="5811" endWordPosition="5814">t of class-instance labels to all instances in a semantic network. The proposed approaches are intuitive and almost parameter-free. We conducted a series of experiments in which we compared the effectiveness of the centrality and regCentrality 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 50 100 150 200 Rank Regularization Figure 2: Effect of Number of Initial Class-Instance Pairs for Invertebrates. ularization methods to learn new labels for the unlabeled instances. We showed that the enhanced class labels improve the original output generated by the pattern-based knowledge harvesting approach of (Hovy et al., 2009). Finally, we have studied the impact of the class-instance and instance-instance graphs for the class-label propagation task. The latter approach has shown to produce much more accurate results. In the future, we want to apply our approach to Web-based taxonomy induction, which according to (Kozareva and Hovy, 2010) is stifled due to the lacking relations between the instances and the classes, and the classes themselves. The proposed methods can be also applied to enhance fact 50 100 150 200 Rank Accuracy 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 1 Random 25% Initial Label 50% Initial Label 100% </context>
</contexts>
<marker>Hovy, Kozareva, Riloff, 2009</marker>
<rawString>Eduard Hovy, Zornitsa Kozareva, and Ellen Riloff. 2009. Toward completeness in concept extraction and classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 948–957.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alpa Jain</author>
<author>Patrick Pantel</author>
</authors>
<title>Factrank: Random walks on a web of facts.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>501--509</pages>
<contexts>
<context position="1914" citStr="Jain and Pantel, 2010" startWordPosition="274" endWordPosition="277">ural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In c</context>
<context position="7589" citStr="Jain and Pantel, 2010" startWordPosition="1146" endWordPosition="1149">lated Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 S</context>
</contexts>
<marker>Jain, Pantel, 2010</marker>
<rawString>Alpa Jain and Patrick Pantel. 2010. Factrank: Random walks on a web of facts. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 501–509.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
</authors>
<location>Daniel Loreto, Wesley Hildebrandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-</location>
<marker>Katz, Lin, </marker>
<rawString>Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hildebrandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Marton des</author>
<author>Federico Mora</author>
</authors>
<title>Integrating web-based and corpus-based techniques for question answering.</title>
<date>2003</date>
<booktitle>In Proceedings of the twelfth text retrieval conference (TREC),</booktitle>
<pages>426--435</pages>
<marker>des, Mora, 2003</marker>
<rawString>des, Gregory Marton, and Federico Mora. 2003. Integrating web-based and corpus-based techniques for question answering. In Proceedings of the twelfth text retrieval conference (TREC), pages 426–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Katz</author>
</authors>
<title>A new status index derived from sociometric analysis.</title>
<date>1953</date>
<tech>Psychometrika,</tech>
<pages>18--39</pages>
<contexts>
<context position="14731" citStr="Katz, 1953" startWordPosition="2387" endWordPosition="2388">meter controls how much the score of each node depends on the scores of its neighbors. When α = 0 the score of each node is equivalent to its initial score, and does not depend on the scores of its neighbors at all. Alternately, we can think of the vector lˆ as the fixed-point of the process in which in each iteration some node v updates its score ˜l(v) by setting ˜l(v) = l(v) + α P(u,v)EE w(u, v)˜l(u). Solving Equation 1 we can see that lˆ = l(I − αA)−1, where I is the identity matrix of size n. The solution is also closely related to the following expression, which is known as a Katz score (Katz, 1953): °O sX t=1 We can verify that At(u, v) gives the number of paths of length t between u and v. Katz proposed using the above expression with the starting vector � s = 1 to measure centrality in a network. Therefore, the score of node v is given by the number of paths from u to v for all u E V , with longer paths given less weight based on the value of α. The method proposed here measures a similar quantity with a non-uniform starting vector. To show the relationship between the two measures we use the identity that P°Ot=1 αtAt = (I − αA)−1 − I. It is easy to see that lˆ = l(I − αA)−1 = l(P°Ot=</context>
</contexts>
<marker>Katz, 1953</marker>
<rawString>Leo Katz. 1953. A new status index derived from sociometric analysis. Psychometrika, 18:39–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard Hovy</author>
</authors>
<title>A semisupervised method to learn and construct taxonomies using the web.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1110--1118</pages>
<contexts>
<context position="2734" citStr="Kozareva and Hovy, 2010" startWordPosition="402" endWordPosition="405">o et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class-instance pairs. (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. (Talukdar et al., 2008) improved class-instance extractions exploring the relationships between t</context>
<context position="8182" citStr="Kozareva and Hovy, 2010" startWordPosition="1238" endWordPosition="1241">t, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. (Talukdar and Pereira, 2010) </context>
<context position="21594" citStr="Kozareva and Hovy, 2010" startWordPosition="3649" endWordPosition="3652">Using our labeling procedure we do not have any negative examples, so our initial vector l is non-negative, resulting in a non-negative vector ˆl. This is not a problem because we can still interpret ˆl(u) to be proportional to how likely it is that u has the label. Rather than trying different settings of µ, we directly vary -y, with a smaller -y placing more emphasis on agreement with initial labels. 5 Experimental Evaluation 5.1 Data Collection For our experimental study, we select three widely used domains in the harvesting community (Etzioni et al., 2005; Pas¸ca, 2007; Hovy et al., 2009; Kozareva and Hovy, 2010): animals and vehicles. For each domain we randomly selected different semantic classes, which resulted in 20 classes altogether. To generate the instance-instance semantic network, we use the harvesting procedure described in Section 3. For example, to learn instances associated with animals, we instantiate the bootstrapping algorithm with the semantic class animals, the seed instance bears and the pattern “animals such as bears and *”. We submitted the pattern as queries to Yahoo!Boss and collected new instances. We ranked the instances following (Kozareva et al., 2008) which resulted in 397</context>
<context position="34404" citStr="Kozareva and Hovy, 2010" startWordPosition="5861" endWordPosition="5864">zation Figure 2: Effect of Number of Initial Class-Instance Pairs for Invertebrates. ularization methods to learn new labels for the unlabeled instances. We showed that the enhanced class labels improve the original output generated by the pattern-based knowledge harvesting approach of (Hovy et al., 2009). Finally, we have studied the impact of the class-instance and instance-instance graphs for the class-label propagation task. The latter approach has shown to produce much more accurate results. In the future, we want to apply our approach to Web-based taxonomy induction, which according to (Kozareva and Hovy, 2010) is stifled due to the lacking relations between the instances and the classes, and the classes themselves. The proposed methods can be also applied to enhance fact 50 100 150 200 Rank Accuracy 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 1 Random 25% Initial Label 50% Initial Label 100% Initial Label Accuracy Random 25% Initial Label 50% Initial Label 100% Initial Label 126 farms (Jain and Pantel, 2010). Acknowledgments We acknowledge the support of DARPA contract number FA8750-09-C-3705 and NSF grant IIS0429360. We would like to thank the three anonymous reviewers for their useful comments and sugg</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard Hovy. 2010. A semisupervised method to learn and construct taxonomies using the web. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1110–1118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics ACL-08: HLT,</booktitle>
<pages>1048--1056</pages>
<contexts>
<context position="1749" citStr="Kozareva et al., 2008" startWordPosition="249" endWordPosition="252">between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 20</context>
<context position="7424" citStr="Kozareva et al., 2008" startWordPosition="1119" endWordPosition="1122">ferent baselines. We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafa</context>
<context position="10153" citStr="Kozareva et al., 2008" startWordPosition="1534" endWordPosition="1537">ed instances. While objectives similar to regularization have been used for class-label propagation, the application of node centrality for this task is also novel. The proposed solutions are intuitive and almost parameter-free (both methods have a single parameter, which is easy to interpret and does not require careful tuning). 3 Knowledge Harvesting from the Web Our proposed class-label enhancement approaches are agnostic to the sources of semantic instances and classes. Several methods have been developed to harvest instances from the Web (Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008) and potentially we can use any of them. In our experiments, we use the doubly-anchored (DAP) method of (Kozareva et al., 2008), because it achieves higher precision than (Etzioni et al., 2005; Pas¸ca, 2007), it is easy to implement and requires minimum supervision (only one seed instance and a lexico-syntactic pattern). For a given semantic class of interest say animals, the algorithm starts with a seed example of the class, say whales. The seed instance is fed into a doubly-anchored pattern “&lt;semantic-class&gt; such as &lt;seed&gt; and *”, which extracts on the position of the * new instances of the </context>
<context position="22172" citStr="Kozareva et al., 2008" startWordPosition="3739" endWordPosition="3742"> Hovy et al., 2009; Kozareva and Hovy, 2010): animals and vehicles. For each domain we randomly selected different semantic classes, which resulted in 20 classes altogether. To generate the instance-instance semantic network, we use the harvesting procedure described in Section 3. For example, to learn instances associated with animals, we instantiate the bootstrapping algorithm with the semantic class animals, the seed instance bears and the pattern “animals such as bears and *”. We submitted the pattern as queries to Yahoo!Boss and collected new instances. We ranked the instances following (Kozareva et al., 2008) which resulted in 397 animal, 4471 plant and 1425 vehicle instances. Table 1 shows the number of nodes (instances) and directed edges for the constructed semantic networks. class #instances #directed-edges animals 397 2812 vehicles 1425 3191 Table 1: Nodes &amp; Edges in the Instance Network. Next, we use the harvested instances to automatically learn the semantic classes associated with them. For example, bears and wolves are animals but also mammals, predators, vertebrates among others. The obtained class harvesting results are shown in Table 2. We indicate with Inst(Hovy et al., 2009) the numb</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the web with hyponym pattern linkage graphs. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics ACL-08: HLT, pages 1048–1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Dirt - discovery of inference rules from text. In</title>
<date>2001</date>
<booktitle>In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>323--328</pages>
<contexts>
<context position="1861" citStr="Lin and Pantel, 2001" startWordPosition="266" endWordPosition="269">e achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may n</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Dirt - discovery of inference rules from text. In In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th international conference on Computational linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="2322" citStr="Lin and Pantel, 2002" startWordPosition="337" endWordPosition="340">s (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have</context>
<context position="7706" citStr="Lin and Pantel, 2002" startWordPosition="1163" endWordPosition="1166">red (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the re</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Dekang Lin and Patrick Pantel. 2002. Concept discovery from text. In Proc. of the 19th international conference on Computational linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
</authors>
<title>Acquisition of categorized named entities for web search.</title>
<date>2004</date>
<booktitle>In Proceedings of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>137--145</pages>
<marker>Pas¸ca, 2004</marker>
<rawString>Marius Pas¸ca. 2004. Acquisition of categorized named entities for web search. In Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 137–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
</authors>
<title>Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>101--110</pages>
<marker>Pas¸ca, 2007</marker>
<rawString>Marius Pas¸ca. 2007. Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds. In Proceedings of the 16th international conference on World Wide Web, pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="1821" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="259" endWordPosition="262">pagate the class labels and show that the latter one achieves higher accuracy. 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explic</context>
<context position="7496" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="1130" endWordPosition="1133">nce and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomi</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: leveraging generic patterns for automatically harvesting semantic relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Entity extraction via ensemble semantics.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09,</booktitle>
<pages>238--247</pages>
<contexts>
<context position="3070" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="450" endWordPosition="453">text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class-instance pairs. (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. (Talukdar et al., 2008) improved class-instance extractions exploring the relationships between the classes and the instances to propagate the initial class-labels to the remaining unlabeled instances. Later on (Talukdar and Pereira, 2010) showed that class-instance extraction with label propagation can be further improved by adding semantic information 118 Proceedings of the 2011 Conference on Empirical Methods in Natural Langua</context>
<context position="8457" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="1279" endWordPosition="1282"> using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. (Talukdar and Pereira, 2010) conducted a comparative study of graph algorithms and showed that class-instance extraction can be improved using additional information that can be modeled as instance-attribute edges. Closest to our work is that of (Talukdar et al., 2008; Talukdar and Pereira, 2010) who mo</context>
</contexts>
<marker>Pennacchiotti, Pantel, 2009</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2009. Entity extraction via ensemble semantics. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09, pages 238–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In AAAI ’99/IAAI ’99: Proceedings of the Sixteenth National Conference on Artificial intelligence.</booktitle>
<contexts>
<context position="2038" citStr="Riloff and Jones, 1999" startWordPosition="293" endWordPosition="296">es such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the </context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In AAAI ’99/IAAI ’99: Proceedings of the Sixteenth National Conference on Artificial intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A corpus-based approach for building semantic lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of the Empirical Methods for Natural Language Processing,</booktitle>
<pages>117--124</pages>
<contexts>
<context position="7230" citStr="Riloff and Shepherd, 1997" startWordPosition="1087" endWordPosition="1090">. Section 4 describes the two graphtheoretic methods for class label propagation using an instance-instance network. Section 5 shows a comparative study between the proposed graph algorithms and different baselines. We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge usi</context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Ellen Riloff and Jessica Shepherd. 1997. A corpus-based approach for building semantic lexicons. In Proceedings of the Empirical Methods for Natural Language Processing, pages 117–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>What is this, anyway: Automatic hypernym discovery.</title>
<date>2009</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Learning by Reading and Learning to Read.</booktitle>
<contexts>
<context position="11831" citStr="Ritter et al., 2009" startWordPosition="1808" endWordPosition="1811">ghted based on the number of times the DAP pattern extracted the instances together. Different strategies can be employed to acquire semantic classes for each instance. We follow the fully automated approach of (Hovy et al., 2009), which takes the learned instance pairs from DAP and feeds them into the pattern “* such as &lt;instance1&gt; and &lt;instance2&gt;”. The algorithm extracts on the position of the * new semantic classes related to instance1. According to (Hovy et al., 2009), the usage of two instances acts as a disambiguator and leads to much more accurate semantic class extraction compared to (Ritter et al., 2009). 4 Methods We model the output of the instance harvesting algorithm as a directed weighted graph that is given by a set of vertices V and a set of edges E. We use n to denote the number of vertices. A node u corresponds to a learned instance, and an edge (u, v) ∈ E indicates that the instance v was learned from the instance u using the DAP pattern. The weight of the edge w(u, v) specifies the number of times the pair of instances were found by the DAP pattern. We define the adjacency matrix of the graph as: � A v) w(u, v) if (u, v) ∈ E (u, _ 0 otherwise. We use dout(u) to specify the out-degr</context>
</contexts>
<marker>Ritter, Soderland, Etzioni, 2009</marker>
<rawString>Alan Ritter, Stephen Soderland, and Oren Etzioni. 2009. What is this, anyway: Automatic hypernym discovery. In Proceedings of the AAAI Spring Symposium on Learning by Reading and Learning to Read.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44,</booktitle>
<pages>801--808</pages>
<contexts>
<context position="2708" citStr="Snow et al., 2006" startWordPosition="398" endWordPosition="401">entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class-instance pairs. (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. (Talukdar et al., 2008) improved class-instance extractions exploring t</context>
<context position="8131" citStr="Snow et al., 2006" startWordPosition="1230" endWordPosition="1233">s (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al., 2005) and graph algorithms (Hovy et al., 2009), estimating the goodness of textmining seeds (Vyas et al., 2009), organizing the extracted information (Cafarella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label p</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44, pages 801–808.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<contexts>
<context position="7113" citStr="Suchanek et al., 2007" startWordPosition="1070" endWordPosition="1073">rithm used to extract the instance network and the class-instance pairs necessary for our experimental evaluation. Section 4 describes the two graphtheoretic methods for class label propagation using an instance-instance network. Section 5 shows a comparative study between the proposed graph algorithms and different baselines. We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. Finally, we conclude in Section 6. 2 Related Work In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al., 2007) and unstructured text. Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al., 2003). Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas¸ca, 2004; Etzioni et al., 2005; Pas¸ca, 2007; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al., 2005; Davidov and Rappoport, 2009; Jain and Pantel, 2010). Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; David</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In WWW ’07: Proceedings of the 16th international conference on World Wide Web, pages 697–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Fernando Pereira</author>
</authors>
<title>Experiments in graph-based semi-supervised learning methods for class-instance acquisition.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1473--1481</pages>
<contexts>
<context position="3476" citStr="Talukdar and Pereira, 2010" startWordPosition="508" endWordPosition="511">rces like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class-instance pairs. (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. (Talukdar et al., 2008) improved class-instance extractions exploring the relationships between the classes and the instances to propagate the initial class-labels to the remaining unlabeled instances. Later on (Talukdar and Pereira, 2010) showed that class-instance extraction with label propagation can be further improved by adding semantic information 118 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 118–128, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics in the form of instance-attribute edges derived from independently developed knowledge base. Similarly to (Talukdar et al., 2008) and (Talukdar and Pereira, 2010), we are interested in enriching class-instance extractions with label propagation. However, unlike the previous work, we </context>
<context position="8781" citStr="Talukdar and Pereira, 2010" startWordPosition="1327" endWordPosition="1330">ch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. (Talukdar and Pereira, 2010) conducted a comparative study of graph algorithms and showed that class-instance extraction can be improved using additional information that can be modeled as instance-attribute edges. Closest to our work is that of (Talukdar et al., 2008; Talukdar and Pereira, 2010) who model classinstance relations to propagate class-labels. Although these algorithms can be applied to other relations (Alfonseca et al., 2010), to our knowledge yet nobody has modeled the connections between the instances themselves for the task of class-label propagation. We propose regularization and centrality graph-theore</context>
<context position="16598" citStr="Talukdar and Pereira, 2010" startWordPosition="2745" endWordPosition="2748">(u, v) E E, the scores of the endpoints ˆl(u) and ˆl(v) must be as similar as possible. Moreover, the greater the weight of the edge w(u, v) the more important it is for the scores to match. Using this intuition we can define the following optimization problem: XargminˆlE{0,1J&apos;t (ˆl(u) − ˆl(v))2. (u,v)EE Setting lˆ = 0�or lˆ= � 1 clearly optimizes this function, but does not give a meaningful solution. However, we can additionally constrain lˆ by requiring that the initial labels cannot be modified, or more generally penalizing the discrepancy between ˆl(u) and l(u) for u E L. The methods of (Talukdar and Pereira, 2010) optimize objective functions of this type. αtAt. 121 Unlike the work of (Talukdar and Pereira, 2010), here we use an objective function that considers smoothness with respect to a random walk on the graph. Performing a random walk allows us to take more of the graph structure into account. For example, if nodes u and v are part of the same cluster then it is likely that the edge (u, v) is heavily traversed during the random walk, and should have a lot of probability in the stationary distribution of the walk. Simply considering the weight of the edge w(u, v) gives us no such information. Ther</context>
</contexts>
<marker>Talukdar, Pereira, 2010</marker>
<rawString>Partha Pratim Talukdar and Fernando Pereira. 2010. Experiments in graph-based semi-supervised learning methods for class-instance acquisition. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1473–1481.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Joseph Reisinger</author>
<author>Marius Pasca</author>
<author>Deepak Ravichandran</author>
<author>Rahul Bhagat</author>
<author>Fernando Pereira</author>
</authors>
<title>Weakly-supervised acquisition of labeled class instances using graph random walks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>582--590</pages>
<contexts>
<context position="3260" citStr="Talukdar et al., 2008" startWordPosition="479" endWordPosition="482">pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. Therefore, researchers have focused on the development of methods that can automatically augment the initially extracted class-instance pairs. (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. (Talukdar et al., 2008) improved class-instance extractions exploring the relationships between the classes and the instances to propagate the initial class-labels to the remaining unlabeled instances. Later on (Talukdar and Pereira, 2010) showed that class-instance extraction with label propagation can be further improved by adding semantic information 118 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 118–128, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics in the form of instance-attribute edges derived from independently d</context>
<context position="8646" citStr="Talukdar et al., 2008" startWordPosition="1309" endWordPosition="1312">rella et al., 2007a; Cafarella et al., 2007b) and inducing term taxonomies with WordNet (Snow et al., 2006) or starting from scratch (Kozareva and Hovy, 2010). 119 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. (Talukdar et al., 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. (Talukdar and Pereira, 2010) conducted a comparative study of graph algorithms and showed that class-instance extraction can be improved using additional information that can be modeled as instance-attribute edges. Closest to our work is that of (Talukdar et al., 2008; Talukdar and Pereira, 2010) who model classinstance relations to propagate class-labels. Although these algorithms can be applied to other relations (Alfonseca et al., 2010), to our knowledge yet nobody has modeled the conn</context>
<context position="29209" citStr="Talukdar et al., 2008" startWordPosition="5000" endWordPosition="5003">d nodes, where k is the number of instances that belong to this class according to WordNet. For example, the accuracy of centrality for carnivores is 80% showing that from the top 57 ranked animal instances, 80% belong to carnivores. In the final column we also report the performance of a label propagation algorithm that uses class-instance graph instead of an instance-instance graph. To build the graph we remove the edges between the instances and keep the class-instance mappings discovered by the harvesting algorithm of (Hovy et al., 2009). We use the modified adsorption algorithm (MAD) of (Talukdar et al., 2008), which is freely available from the Junto toolkit1. To rank the instances for each class label produced by Junto, we use the computed label scores as a ranking criteria and measure accuracy similarly to centrality and regularization. class Centrality Regular. Rand MAD arthropods .50 .60 .12 .56 carnivores .80 .85 .14 .44 chordates .81 .83 .80 .79 eutherians .54 .60 .49 .60 insects .38 .52 .07 .17 invertebrates .94 .96 .21 .64 mammals .82 .90 .52 .63 reptile .45 .55 .05 .14 ruminants .41 .44 .08 .41 ungulates .44 .61 .16 .32 crafts .47 .56 .05 .35 motor vehicle .45 .48 .09 .24 self-propelled v</context>
</contexts>
<marker>Talukdar, Reisinger, Pasca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca, Deepak Ravichandran, Rahul Bhagat, and Fernando Pereira. 2008. Weakly-supervised acquisition of labeled class instances using graph random walks. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 582– 590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vishnu Vyas</author>
</authors>
<title>Patrick Pantel, and Eric Crestan.</title>
<date>2009</date>
<booktitle>In Proceeding of the 18th ACM conference on Information and knowledge management, CIKM ’09,</booktitle>
<pages>225--234</pages>
<marker>Vyas, 2009</marker>
<rawString>Vishnu Vyas, Patrick Pantel, and Eric Crestan. 2009. Helping editors choose better seed sets for entity set expansion. In Proceeding of the 18th ACM conference on Information and knowledge management, CIKM ’09, pages 225–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Maria Teresa Pazienza</author>
</authors>
<title>Discovering asymmetric entailment relations between verbs using selectional preferences.</title>
<date>2006</date>
<booktitle>InACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>849--856</pages>
<contexts>
<context position="2125" citStr="Zanzotto et al., 2006" startWordPosition="306" endWordPosition="309">to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. There is a substantial body of work on extracting is-a relations (Etzioni et al., 2005; Kozareva et al., 2008), part-of relations (Girju et al., 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001; Davidov and Rappoport, 2009; Jain and Pantel, 2010). The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al., 2003) and textual entailment (Zanzotto et al., 2006) systems. Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al., 2005; Kozareva et al., 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. (Pas¸ca, 2004; Snow et al., 2006; Kozareva and Ho</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Pazienza, 2006</marker>
<rawString>Fabio Massimo Zanzotto, Marco Pennacchiotti, and Maria Teresa Pazienza. 2006. Discovering asymmetric entailment relations between verbs using selectional preferences. InACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 849–856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dengyong Zhou</author>
<author>Jiayuan Huang</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>Learning from labeled and unlabeled data on a directed graph.</title>
<date>2005</date>
<booktitle>In Proceedings of the 22nd international conference on Machine learning, ICML ’05,</booktitle>
<pages>1036--1043</pages>
<marker>Zhou, Huang, Sch¨olkopf, 2005</marker>
<rawString>Dengyong Zhou, Jiayuan Huang, and Bernhard Sch¨olkopf. 2005. Learning from labeled and unlabeled data on a directed graph. In Proceedings of the 22nd international conference on Machine learning, ICML ’05, pages 1036–1043.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>