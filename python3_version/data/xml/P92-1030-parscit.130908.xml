<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.769226">
TENSE TREES AS THE &amp;quot;FINE STRUCTURE&amp;quot; OF DISCOURSE
</title>
<author confidence="0.993255">
Chung Hee Hwang &amp; Lenhart K. Schubert
</author>
<affiliation confidence="0.837556666666667">
Department of Computer Science
University of Rochester
Rochester, New York 14627, U. S. A.
</affiliation>
<email confidence="0.962896">
{hwang,schubert}Ocs.rochester.edu
</email>
<sectionHeader confidence="0.985001" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999980375">
We present a new compositional tense-aspect deindex-
ing mechanism that makes use of tense trees as com-
ponents of discourse contexts. The mechanism allows
reference episodes to be correctly identified even for
embedded clauses and for discourse that involves shifts
in temporal perspective, and permits deindexed logical
forms to be automatically computed with a small num-
ber of deindexing rules.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942918367347">
Work on discourse structure, e.g., [Reichman, 1985;
Grosz and Sidner, 1986; Allen, 1987], has so far taken
a rather coarse, high-level view of discourse, mostly
treating sentences or sentence-like entities (&amp;quot;utterance
units,&amp;quot; &amp;quot;contributions,&amp;quot; etc.) as the lowest-level dis-
course elements. To the extent that sentences are ana-
lyzed at all, they are simply viewed as carriers of certain
features relevant to supra-sentential discourse structure:
cue words, tense, time adverbials, aspectual class, into-
national cues, and others. These features are presumed
to be extractable in some straightforward fashion and
provide the inputs to a higher-level discourse segment
analyzer.
However, sentences (or their logical forms) are not in
general &amp;quot;flat,&amp;quot; with a single level of structure and fea-
tures, but may contain multiple levels of clausal and ad-
verbial embedding. This substructure can give rise to
arbitrarily complex relations among the contributions
made by the parts, such as temporal and discourse rela-
tions among subordinate clausal constituents and events
or states of affairs they evoke. It is therefore essen-
tial, in a comprehensive analysis of discourse structure,
that these intra-sentential relations be systematically
brought to light and integrated with larger-scale dis-
course structures.
Our particular interest is in tense, aspect and other
indicators of temporal structure. We are developing a
uniform, compositional approach to interpretation in
which a parse tree leads directly (in rule-to-rule fash-
ion) to a preliminary, indexical logical form, and this
LF is deindexed by processing it in the current context
(a well-defined structure). Deindexing simultaneously
transforms the LF and the context: context-dependent
constituents of the LF, such as operators past, pres and
pen f and adverbs like today or earlier, are replaced by
explicit relations among quantified episodes; (anaphora
are also deindexed, but this is not discussed here); and
new structural components and episode tokens (and
other information) are added to the context. This
dual transformation is accomplished by simple recur-
sive equivalences and equalities. The relevant context
structures are called tense trees; these are what we pro-
pose as the &amp;quot;fine structure&amp;quot; of discourse, or at least as
a key component of that fine structure.
In this paper, we first review Reichenbach&apos;s influen-
tial work on tense and aspect. Then we describe tem-
poral deindexing using tense trees, and extensions of
the mechanism to handle discourse involving shifts in
temporal perspective.
</bodyText>
<sectionHeader confidence="0.854106" genericHeader="method">
2 Farewell to Reichenbach
</sectionHeader>
<bodyText confidence="0.999627333333333">
Researchers concerned with higher-level discourse struc-
ture, e.g., Webber [1987; 1988], Passonneau [1988] and
Song and Cohen [1991], have almost invariably relied on
some Reichenbach [19471-like conception of tense. The
syntactic part of this conception is that there are nine
tenses in English, namely simple past, present and fu-
ture tense, past, present and future perfect tense, and
posterior past, present and future tensel (plus progres-
sive variants). The semantic part of the conception is
that each tense specifies temporal relations among ex-
actly three times particular to a tensed clause, namely
the event time (E), the reference time (R) and the
speech time (S). On this conception, information in
discourse is a matter of &amp;quot;extracting&amp;quot; one of the nine Re-
ichenbachian tenses from each sentence, asserting the
</bodyText>
<note confidence="0.691867">
1 Examples of expressions in posterior tense are would, was
going to (posterior past), is going to (posterior present), and will
be going to (posterior future).
</note>
<page confidence="0.988499">
232
</page>
<bodyText confidence="0.999868214285714">
appropriate relations among E, R and S, and appro-
priately relating these times to previously introduced
times, taking account of discourse structure cues im-
plicit in tense shifts.
It is easy to understand the appeal of this approach
when one&apos;s concern is with higher-level structure. By
viewing sentences as essentially flat, carrying tense as a
top-level feature with nine possible values and evoking a
triplet of related times, one can get on with the higher-
level processing with minimum fuss. But while there is
much that is right and insightful about Reichenbach&apos;s
conception, it seems to us unsatisfactory from a mod-
ern perspective. One basic problem concerns embedded
clauses. Consider, for instance, the following passage.
</bodyText>
<listItem confidence="0.9976175">
(1) John will find this note when he gets home.
(2) He will think(a) Mary has left(b).
</listItem>
<bodyText confidence="0.918606">
Reichenbach&apos;s analysis of (2) gives us Eb &lt; S, Rb &lt;
R., E0, where ti &lt;t2 means t1 is before t2, as below.
</bodyText>
<sectionHeader confidence="0.3201125" genericHeader="method">
Ra
Ea
</sectionHeader>
<bodyText confidence="0.969125285714286">
That is, John will think that Mary&apos;s leaving took
place some time before the speaker uttered sentence
(2). This is incorrect; it is not even likely that John
would know about the utterance of (2). In actuality,
(2) only implies that John will think Mary&apos;s leaving
took place some time before the time of his thinking,
i.e., S &lt; Ra, E. and Eb &lt; Rb, Ra , as shown below.
</bodyText>
<figure confidence="0.73895475">
S
Ra, Ea
Rb
Eb
</figure>
<bodyText confidence="0.999892456140351">
Thus, Reichenbach&apos;s system fails to take into account
the local context created by syntactic embedding.
Attempts have been made to refine Reichenbach&apos;s
theory (e.g., [Hornstein, 1977; Smith, 1978; Nerbonne,
1986]), but we think the lumping together of tense
and aspect, and the assignment of E, R, S triples to
all clauses, are out of step with modern syntax and se-
mantics, providing a poor basis for a systematic, com-
positional account of temporal relations within clauses
and between clauses. In particular, we contend that
English past, present, future and perfect are separate
morphemes making separate contributions to syntactic
structure and meaning. Note that perfect have, like
most verbs, can occur untensed (&amp;quot;She is likely to have
left by now&amp;quot;). Therefore, if the meaning of other tensed
verbs such as walks or became is regarded as compos-
ite, with the tense morpheme supplying a &amp;quot;present&amp;quot; or
&amp;quot;past&amp;quot; component of the meaning, the same ought to be
said about tensed forms of have. The modals will and
would do not have untensed forms. Nevertheless, con-
siderations of syntactic and semantic uniformity suggest
that they too have composite meanings, present or past
tense being one part and &amp;quot;future modality&amp;quot; the other.
This unifies the analyses of the modals in sentences like
&amp;quot;He knows he will see her again&amp;quot; and &amp;quot;He knew he
would see her again,&amp;quot; and makes them entirely parallel
to paraphrases in terms of going to, viz., &amp;quot;He knows he
is going to see her again&amp;quot; and &amp;quot;He knew he was going
to see her again.&amp;quot; We take these latter &amp;quot;posterior tense&amp;quot;
forms to be patently hierarchical (e.g., is going to see
her has 4 levels of VP structure, counting to as an aux-
iliary verb) and hence semantically composite on any
compositional account. Moreover, going to can both
subordinate, and be subordinated by, perfect have, as
in &amp;quot;He is going to have left by then.&amp;quot; This leads to ad-
ditional &amp;quot;complex tenses&amp;quot; missing from Reichenbach&apos;s
list.
We therefore offer a compositional account in which
operators corresponding to past (past), present (pres),
future (futr) and perfect (per!) contribute separately
and uniformly to the meanings of their operands, i.e.,
formulas at the level of LF. Thus, for instance, the tem-
poral relations implicit in &amp;quot;John will have left&amp;quot; are ob-
tained not by extracting a &amp;quot;future perfect&amp;quot; and asserting
relations among E, R and S, but rather by successively
taking account of the meanings of the nested pres, futr
and pen f operators in the LF of the sentence. As it
happens, each of those operators implicitly introduces
exactly one episode, yielding a Reichenbach-like result
in this case. (But note: a simple present sentence like
&amp;quot;John is tired&amp;quot; would introduce only one episode con-
current with the speech time, not two, as in Reichen-
bach&apos;s analysis.) Even more importantly for present
purposes, each of pres, past, futr and pen f is treated uni-
formly in deindexing and context change. More specif-
ically, they drive the generation and traversal of tense
trees in deindexing.
</bodyText>
<sectionHeader confidence="0.991068" genericHeader="method">
3 Tense Trees
</sectionHeader>
<bodyText confidence="0.999232">
Tense trees provide that part of a discourse context
structure2 which is needed to interpret (and deindex)
temporal operators and modifiers within the logical
form of English sentences. They differ from simple lists
of Reichenbachian indices in that they organize episode
tokens (for described episodes and the utterances them-
selves) in a way that echoes the hierarchy of temporal
and modal operators of the sentences and clauses from
which the tokens arose. In this respect, they are anal-
</bodyText>
<footnote confidence="0.869132">
21n general, the context structure would also contain speaker
and hearer parameters, temporal and spatial frames, and to-
kens for salient referents other than episodes, among other
components—see [Allen, 1987].
Eb Rb
</footnote>
<page confidence="0.995279">
233
</page>
<bodyText confidence="0.99998825">
ogous to larger-scale representations of discourse struc-
ture which encode the hierarchic segment structure of
discourse. (As will be seen, the analogy goes further.)
Tense trees for successive sentences are &amp;quot;overlaid&amp;quot; in
such a way that related episode tokens typically end up
as adjacent elements of lists at tree nodes. The traver-
sal of trees and the addition of new tokens is simply and
fully determined by the logical forms of the sentences
being interpreted.
The major advantage of tense trees is that they al-
low simple, systematic interpretation (by deindexing)
of tense, aspect, and time adverbials in texts consisting
of arbitrarily complex sentences, and involving implicit
temporal reference across clause and sentence bound-
aries. This includes certain relations implicit in the
ordering of clauses and sentences. As has been fre-
quently observed, for a sequence of sentences within
the same discourse segment, the temporal reference of
a sentence is almost invariably connected to that of the
previous sentence in some fashion. Typically, the rela-
tion is one of temporal precedence or concurrency, de-
pending on the aspectual class or aktionsart involved
(cf., &amp;quot;John closed his suitcase; He walked to the door&amp;quot;
versus &amp;quot;John opened the door; Mary was sleeping&amp;quot;).
However, in &amp;quot;Mary got in her Ferrari. She bought it
with her own money,&amp;quot; the usual temporal precedence is
reversed (based on world knowledge). Also, other dis-
course relations could be implied, such as cause-of, ex-
plains, elaborates, etc. (more on this later). Whatever
the relation may be, finding the right pair of episodes
involved in such relations is of crucial importance for
discourse understanding. Echoing Leech [1987, p41], we
use the predicate constant orients, which subsumes all
such relations. Note that the orients predications can
later be used to make probabilistic or default inferences
about the temporal or causal relations between the two
episodes, based on their aspectual class and other infor-
mation. In this way they supplement the information
provided by larger-scale discourse segment structures.
We now describe tense trees more precisely.
</bodyText>
<subsectionHeader confidence="0.97334">
Tense Tree Structure
</subsectionHeader>
<bodyText confidence="0.999975538461538">
The form of a tense tree is illustrated in Figure 1. As
an aid to intuition, the nodes in Figure 1 are annotated
with simple sentences whose indexical LFs would lead
to those nodes in the course of deindexing. A tense tree
node may have up to three branches—a leftward past
branch, a downward perfect branch, and a rightward
future branch. Each node contains a stack-like list of
recently introduced episode tokens (which we will often
refer to simply as episodes).
In addition to the three branches, the tree may have
(horizontal) embedding links to the roots of embed-
ded tense trees. There are two kinds of these embed-
ding links, both illustrated in Figure 1. One kind,
</bodyText>
<figure confidence="0.932233666666667">
utterance pres
node • He is home
He would have left
</figure>
<figureCaption confidence="0.999925">
Figure 1. A Tense Tree
</figureCaption>
<bodyText confidence="0.999960588235294">
indicated by dashed lines, is created by subordinat-
ing constructions such as VPs with that-complement
clauses. The other kind, indicated by dotted lines, is
derived from the surface speech act (e.g., telling, ask-
ing or requesting) implicit in the mood of a sentence.
On our view, the utterances of a speaker (or sentences
of a text, etc.) are ultimately to be represented in
terms of modal predications expressing these surface
speech acts, such as [Speaker tell Hearer (That 4)]
or [Speaker ask Hearer (Whether 4)]. Although these
speech acts are not explicitly part of what the speaker
uttered, they are part of what the hearer gathers from
an utterance. Speaker and Hearer are indexical con-
stants to be replaced by the speaker(s) and the hearer(s)
of the utterance context. The two kinds of embedding
links require slightly different tree traversal techniques
as will be seen later.
A set of trees connected by embedding links is called
a tense tree structure (though we often refer loosely to
tense tree structures as tense trees). This is in effect a
tree of tense trees, since a tense tree can be embedded
by only one other tree. At any time, exactly one node
of the tense tree structure for a discourse is in focus,
and the focal node is indicated by C). Note that the
&amp;quot;tense tree&amp;quot; in Figure 1 is in fact a tense tree structure,
with the lowest node in focus.
By default, an episode added to the right end of a
list at a node is &amp;quot;oriented&amp;quot; by the episode which was
previously rightmost. For episodes stored at different
nodes, we can read off their temporal relations from the
tree roughly as follows. At any given moment, for a
pair of episodes e and e&apos; that are rightmost at nodes n
and n&apos;, respectively, where n&apos; is a daughter of n, if the
branch connecting the two nodes is a past branch, [e&apos;
</bodyText>
<figure confidence="0.927461384615385">
utr
He has left He ill leave
perf
He left
He had left
He w uld
le ye
He will
have left
She will think
that he will
leave
per!
</figure>
<page confidence="0.993012">
234
</page>
<bodyText confidence="0.999834">
before e]3; if it is a perfect branch, [e&apos; impinges-on e]
(as we explain later, this yields entailments [e&apos; before e]
if e&apos; is nonstative and [e&apos; until e] if e&apos; is stative, respec-
tively illustrated by &amp;quot;John has left&amp;quot; and &amp;quot;John has been
working&amp;quot;); if it is a future branch, [e&apos; after e]; and if it
is an embedding link, [e&apos; at-about e]. These orienting
relations and temporal relations are not extracted post
hoc, but rather are automatically asserted in the course
of deindexing using the rules shown later.
As a preliminary example, consider the following pas-
sage and a tense tree annotated with episodes derived
from it by our deindexing rules:
</bodyText>
<listItem confidence="0.9916706">
(3) John picked up the phone. eeall
(4) He had told Mary that
he would call her.
u3 and u4 are utterance episodes for sentences (3) and
(4) respectively.
</listItem>
<bodyText confidence="0.98855925">
Intuitively, the temporal content of sentence (4) is
that the event of John&apos;s telling, eta&apos;, took place before
some time el, which is at the same time as the event
of John&apos;s picking up the phone, epick; and the event of
John&apos;s calling, ecan, is located after some time e2, which
is the at the same time as the event of John&apos;s telling,
eten. For the most part, this information can be read
off directly from the tree; [epick orients el], [eteu before
el] and [eeatt after e2]. In addition, the deindexing rules
yield [e2 same-time eted. From this, one may infer [eta/
before epick] and [eetat after etch], assuming that the
orients relation defaults to same-time here.
How does [epiek orients el] default to [eek same-time
ea? In the tense tree, el is an episode evoked by the
past tense operator which is part of the meaning of had
in (4). It is a stative episode, since this past opera-
tor logically operates on a sentence of form (perf (I)),
and such a sentence describes a state in which (1) has
occurred—in this instance, a state in which John has
told Mary that he will call her. It is this stativity of
el which (by default) leads to a same-time interpreta-
tion of orients.4 Thus, on our account, the tendency
of past perfect &amp;quot;reference time&amp;quot; to align itself with a
30r, sometimes, same-time (cf., &amp;quot;John noticed that Mary
looked pale&amp;quot; vs. &amp;quot;Mary realized that someone broke her vase&amp;quot;).
This is not decided in an ad hoc manner, but as a result of sys-
tematically interpreting the context-charged relation bef T. More
on this later.
</bodyText>
<footnote confidence="0.9842875">
4More accurately, the default interpretation is [(end-of ep,ck )
same-time el], in view of examples involving a longer preceding
event, such as &amp;quot;John painted a picture. He was pleased with the
result.&amp;quot;
</footnote>
<bodyText confidence="0.986891142857143">
previously introduced past event is just an instance of a
general tendency of stative episodes to align themselves
with their orienting episode. This is the same tendency
noted previously for &amp;quot;John opened the door. Mary was
sleeping.&amp;quot; We leave further comments about particu-
larizing the orients relation to a later subsection.
We remarked that the relation [e2 same-time eted is
obtained directly from the deindexing rules. We leave it
to the reader to verify this in detail (see Past and Futr
rules stated below). We note only that e2 is evoked
by the past tense component of would in (4), and de-
notes a (possible) state in which John will call Mary.
Its stativity, and the fact that the subordinate clause
in (4) is &amp;quot;past-dominated,&amp;quot; causes [e2 befT eteld to be
deindexed to [e2 same-time ei 1
et6.
We now show how tense trees are modified as dis-
course is processed, in particular, how episode tokens
are stored at appropriate nodes of the tense tree, and
how deindexed LFs, with orients and temporal ordering
relations incorporated into them, are obtained.
</bodyText>
<subsectionHeader confidence="0.826083">
Processing of Utterances
</subsectionHeader>
<bodyText confidence="0.991741433333333">
The processing of the (indexical) LF of a new utter-
ance always begins with the root node of the current
tense tree (structure) in focus. The processing of the
top-level operator immediately pushes a token for the
surface speech act onto the episode list of the root node.
Here is a typical indexical LF:
(decl (past [John know (That
(past (perf [Mary leave]))))]))
&amp;quot;John knew that Mary had not left.&amp;quot;
(decl stands for declarative; its deindexing rule intro-
duces the surface speech act of type &amp;quot;tell&amp;quot;). As men-
tioned earlier, our deindexing mechanism is a composi-
tional one in which operators past, futr, perf, That,
decl, etc., contribute separately to the meaning of their
operands. As the LF is recursively transformed, the
tense and aspect operators encountered, past, perf and
futr, in particular, cause the focus to shift &amp;quot;downward&amp;quot;
along existing branches (or new ones if necessary). That
is, processing a past operator shifts the current focus
down to the left, creating a new branch if necessary.
The resulting tense tree is symbolized as / T. Similarly
perf shifts straight down, and futr shifts down to the
right, with respective results IT and \ T. pres maintains
the current focus. Certain operators embed new trees
at the current node, written 1-0 T (e.g., That), or shift
focus to an existing embedded tree, written T (e.g.,
decl). Focus shifts to a parent or embedding node are
symbolized as I T and T respectively. As a final tree
operation, OT denotes storage of episode token eT (a
new episode symbol not yet used in T) at the current
</bodyText>
<footnote confidence="0.998994">
5A node is past-dominated if there is a past branch in its an-
cestry (where embedding links also count as ancestry links).
</footnote>
<page confidence="0.996449">
235
</page>
<bodyText confidence="0.99999525">
focus, as rightmost element of its episode list. As each
node comes into focus, its episode list and the lists at
certain nodes on the same tree path provide explicit ref-
erence episodes in terms of which past, pres, futr, perf,
time adverbials, and implicit &amp;quot;orienting&amp;quot; relations are
rewritten nonindexically. Eventually the focus returns
to the root, and at this point, we have a nonindexical
LF, as well as a modified tense tree.
</bodyText>
<subsectionHeader confidence="0.909994">
Deindexing Rules
</subsectionHeader>
<bodyText confidence="0.9978326">
Before we proceed with an example, we show some of
the basic deindexing rules here.6 In the following,&amp;quot;**&amp;quot; is
an episodic operator that connects a formula with the
situation it characterizes. Predicates are infixed and
quantifiers have restrictions (following a colon).7
</bodyText>
<table confidence="0.94030148">
Decl: (decl 4)1
(3eT:HeT same-time NOWT] A
[LastT immediately-precedes eT[]
[(Speaker tell Hearer (That 4&apos;,-.0T)]
** eT])
Tree transform: (decl 49 • T = (4)•(,-00T))
Pres: (pres (D)T
(3eT:ffeT at-about EmbT] A [LastT orients eT]]
ROT ** eT])
Tree transform: (pres 4)) • T = et • (OT))
Past: (past (1).1.
PeT.ReT befT EmbT] A [Last/1 orients eT]]
[Ito,T ** eT])
Tree transform: (past 4)) • T = i (4) • (0,/ T))
Futr: (futr 49T
4-* (3eT:ReT after EmbT] A [Last\T orients eT]]
[4)01. ** eT])
Tree transform: (futr 4)) • T = (4) (0 \ T))
Peri: (perf (11)1.
(3e1:Re1 impinges-on LastT] A
[LastiT orients eT]]
[400. ** eT])
Tree transform: (perf 4)) • T = i (4) • (01 T))
That: (That 4)1 4--) (That 4),T)
Tree transform: (That 4)) • T = 4- (4) • (&gt;—&gt;T))
</table>
<bodyText confidence="0.999602">
As mentioned earlier, Speaker and Hearer in the Decl-
rule are to be replaced by the speaker(s) and the
hearer(s) of the utterance. Note that each equivalence
pushes the dependence on context one level deeper into
the LF, thus deindexing the top-level operator. The
</bodyText>
<footnote confidence="0.899325">
6See [Hwang, 1992] for the rest of our deindexing rules. Some
of the omitted ones are: Fpres ( &amp;quot;futural present,&amp;quot; as in &amp;quot;John has
a meeting tomorrow&amp;quot;), Prog (progressive aspect), Pred (predica-
tion), It, Ka and Xe (&amp;quot;kinds&amp;quot;), those for deindexing various oper-
ators (especially, negation and adverbials), etc.
7 For details of Episodic Logic, our semantic representation, see
[Schubert and Hwang, 1989; Hwang and Schubert, 1991].
</footnote>
<bodyText confidence="0.999482333333333">
symbols NOWT, LastT and EmbT refer respectively to the
speech time for the most recent utterance in T, the last-
stored episode at the current focal node, and the last-
stored episode at the current embedding node. befT
in the Past-rule will be replaced by either before or
same-time, depending on the aspectual class of its first
argument and on whether the focal node of T is past-
dominated. In the Peri-rule, LastT is analogous to
the Reichenbachian reference time for the perfect. The
impinges-on relation confines its first argument eT (the
situation or event described by the sentential operand of
perf) to the temporal region preceding the second argu-
ment. As in the case of orients, its more specific import
depends on the aspectual types of its arguments. If eT is
a stative episode, impinges-on entails that the state or
process involved persists to the reference time (episode),
i.e., [eT until LastT]. If eT is an event (e.g., an accom-
plishment), impinges- on entails that it occurred some-
time before the reference time, i.e., [eT before LastT],
and (by default) its main effects persist to the reference
time.8
</bodyText>
<subsectionHeader confidence="0.672268">
An Example
</subsectionHeader>
<bodyText confidence="0.992313">
To see the deindexing mechanism at work, consider now
sentences (5a) and (6a).
</bodyText>
<listItem confidence="0.73737">
(5) a. John went to the hospital.
b. (decl la (past 1)) [John goto Hospital] ) ) Ic
c. (3 el:[el same-time Now]]
</listItem>
<equation confidence="0.41294275">
[[Speaker tell Hearer (That
(3 e2:[e2 before el]
[(John goto Hospital] ** e2]))]
** el])
</equation>
<listItem confidence="0.5052065">
(6) a. The doctor told John he had broken his ankle.
b. (decl (past [Doctor tell John (That
</listItem>
<subsectionHeader confidence="0.356362">
Td Te If
</subsectionHeader>
<bodyText confidence="0.436484">
(past (perf [John break Ankle])))]))
</bodyText>
<equation confidence="0.911243916666667">
Ig th ti
c. (3 e3:[[e3 same-time Now2] A
[el immediately-precedes e3]]
[[Speaker tell Hearer (That
(3 e4:[[e4 before e3] A [e2 orients e4]]
[[Doctor tell John (That
(3 e5:[e5 same-time e4]
[(3 e6:[e6 before e5]
[[John Ankle] ** e6])
** 5D
** e4]))]
** e3])
</equation>
<footnote confidence="0.846095333333333">
8We have formulated tentative meaning postulates to this ef-
fect but cannot dwell on the issue here. Also, we are setting
aside certain well-known problems involving temporal adverbials
in perfect sentences, such as the inadmissibility of *&amp;quot;John has left
yesterday.&amp;quot; For a possible approach, see [Schubert and Hwang,
1990].
</footnote>
<page confidence="0.997941">
236
</page>
<bodyText confidence="0.999883693333333">
The LFs before deindexing are shown in (5,6b) (where
the labelled arrows mark points we will refer to); the
final, context-independent LFs are in (5,6c). The trans-
formation from (b)&apos;s to (c)&apos;s and the corresponding
tense tree transformations are done with the deindex-
ing rules shown earlier. Anaphoric processing is presup-
posed here.
The snapshots of the tense tree while processing (5b)
and (6b), at points are as follows (with a null
initial context).
The resultant tree happens to be unary, but additional
branches would be added by further text, e.g., a future
branch by &amp;quot;It will take several weeks to heal.&amp;quot;
What is important here is, first, that Reichenbach-like
relations are introduced compositionally; e.g., [e6 before
e5], i.e., the breaking of the ankle, e6, is before the state
John is in at the time of the doctor&apos;s talking to him, e4.
In addition, the recursive rules take correct account of
embedding. For instance, the embedded present perfect
in a sentence such as &amp;quot;John will think that Mary has
left&amp;quot; will be correctly interpreted as relativized to John&apos;s
(future) thinking time, rather than the speech time, as
in a Reichenbachian analysis.
But beyond that, episodes evoked by successive sen-
tences, or by embedded clauses within the same sen-
tence, are correctly connected to each other. In par-
ticular, note that the orienting relation between John&apos;s
going to the hospital, e2, and the doctor&apos;s diagnosis, e4,
is automatically incorporated into the deindexed for-
mula (6c). We can plausibly particularize this orienting
relation to [e4 after e2], based on the aspectual class of
&amp;quot;goto&amp;quot; and &amp;quot;tell&amp;quot; (see below). Thus we have established
inter-clausal connections automatically, which in other
approaches require heuristic discourse processing. This
was a primary motivation for tense trees. Our scheme
is easy to implement, and has been successfully used in
the TRAINS interactive planning advisor at Rochester
[Allen and Schubert, 1991].
More on Particularizing the ORIENTS Relation
The orients relation is essentially an indicator that
there could be a more specific discourse relation between
the argument episodes. As mentioned, it can usually
be particularized to one or more temporal, causal, or
other &amp;quot;standard&amp;quot; discourse relation. Existing propos-
als for getting these discourse relations right appear to
be of two kinds. The first uses the aspectual classes
of the predicates involved to decide on discourse re-
lations, especially temporal ones, e.g., [Partee, 1984],
[Dowty, 1986] and [Hinrichs, 1986]. The second ap-
proach emphasizes inference based on world knowledge,
e.g., [Hobbs, 1985] and [Lascarides and Asher, 1991;
Lascarides and Oberlander, 1992]. The work by Las-
carides et al. is particularly interesting in that it makes
use of a default logic and is capable of retracting previ-
ously inferred discourse relations.
Our approach fully combines the use of aspectual
class information and world knowledge. For example, in
&amp;quot;Mary got in her Ferrari. She bought it with her own
money,&amp;quot; the successively reported &amp;quot;achievements&amp;quot; are
by default in chronological order. Here, however, this
default interpretation of orients is reversed by world
knowledge: one owns things after buying them, rather
than before. But sometimes world knowledge is mute on
the connection. For instance, in &amp;quot;John raised his arm.
A great gust of wind shook the trees,&amp;quot; there seems to be
no world knowledge supporting temporal adjacency or
a causal connection. Yet we tend to infer both, perhaps
attributing magical powers to John (precisely because
of the lack of support for a causal connection by world
knowledge). So in this case default conclusions based
on orients seem decisive. In particular, we would as-
sume that if e and e&apos; are nonstative episodes,9 where e
is the performance of a volitional action and e&apos; is not,
then [e orients e] suggests [e right-before e] and (less
firmly) [e cause-of 41°
</bodyText>
<sectionHeader confidence="0.904666" genericHeader="method">
4 Beyond Sentence Pairs
</sectionHeader>
<bodyText confidence="0.9990424">
The tense tree mechanism, and particularly the way in
which it automatically supplies orienting relations, is
well suited for longer narratives, including ones with
tense shifts. Consider, for example, the following
(slightly simplified) text from [Allen, 1987, p400]:
</bodyText>
<listItem confidence="0.985067">
(7) a. Jack and Sue went{„} to a hardware store
b. as someone had{e,} stolen{ea} their lawnmower.
c. Sue had{e,} seen{„} a man take it
</listItem>
<bodyText confidence="0.976054444444444">
9Non-statives could be achievements, accomplishments, cul-
minations, etc. Our aspectual class system is not entirely settled
yet, but we expect to have one similar to that of [Moens and
Steedman, 1988].
wOur approach to plausible inference in episodic logic in gen-
eral, and to such default inferences in particular, is probabilistic
(see [Schubert and Hwang, 1989; Hwang, 1992]). The hope is that
we will be able to &amp;quot;weigh the evidence&amp;quot; for or against alternative
discourse relations (as particularizations of orients).
</bodyText>
<figure confidence="0.989597166666667">
at
ei , e3
•
e2, e4
at i
C, e3
at h
el, e3
at c
ei
at d ate
, e3 e3
• •
C2
40
at a
Cl
•
</figure>
<page confidence="0.965083">
237
</page>
<listItem confidence="0.953384">
d. and had{ee} chasedie,) him down the street,
e. but he had{„} driven{e,} away in a truck.
f. After lookingfeio in the store, they realized{eii}
that they couldn&apos;t afford{e„} a new one.
</listItem>
<bodyText confidence="0.999645642857143">
Even though {b-e} would normally be considered a sub-
segment of the main discourse {a, f}, both the temporal
relations within each segment and the relations between
segments (i.e., that the substory temporally precedes
the main one) are automatically captured by our rules.
For instance, el and en are recognized as successive
episodes, both preceded at some time in the past by
e3, es, e2, and e9, in that order.
This is not to say that our tense tree mechanism ob-
viates the need for larger-scale discourse structures. As
has been pointed out by Webber [1987;1988] and oth-
ers, many subnarratives introduced by a past perfect
sentence may continue in simple past. The following is
one of Webber&apos;s examples:
</bodyText>
<listItem confidence="0.996605857142857">
(8) a. I wasleo at Mary&apos;s house yesterday.
b. We talked{e,} about her sister Jane.
c. She had{e,} spent{e4) five weeks in Alaska
with two friends.
d. Together, they climbed{eb} Mt. McKinley.
e. Mary asked{e.) whether I would want to go to
Alaska some time.
</listItem>
<bodyText confidence="0.9838304">
Note the shift to simple past in d, though as Web-
ber points out, past perfect could have been used. The
abandonment of the past perfect in favor of simple past
signals the temporary abandonment of a perspective
anchored in the main narrative - thus bringing read-
ers &amp;quot;closer&amp;quot; to the scene (a zoom-in effect). In such
cases, the tense tree mechanism, unaided by a notion of
higher-level discourse segment structure, would derive
incorrect temporal relations such as [es orients es] or
te6 right-after es].
We now show possible deindexing rules for perspec-
tive shifts, assuming for now that such shifts are inde-
pendently identifiable, so that they can be incorporated
into the indexical LFs. new-pers is a sentence operator
initiating a perspective shift for its operand, and prey-
pers is a sentence (with otherwise no content) which
gets back to the previous perspective. RecentT is the
episode most recently stored in the subtree immediately
embedded by the focal node of T.
New-pers: (new-pers (1))T
</bodyText>
<listItem confidence="0.435398">
4-* [.-T A [Recent/. orients RecentT,]]
</listItem>
<bodyText confidence="0.828478">
where T&apos; = (I) • ()--T)
</bodyText>
<equation confidence="0.86806125">
Tree transform:
(new-pers (I)) T = (I) • (1-+T)
Prev-pers: prev-persT -+ T (True)
Tree transform: prev-pers • T = T
</equation>
<bodyText confidence="0.999458">
When new-pers is encountered, a new tree is created
and embedded at the focal node, the focus is moved to
the root node of the new tree, and the next sentence is
processed in that context. In contrast with other op-
erators, new-pers causes an overall focus shift to the
new tree, rather than returning the focus to the orig-
inal root. Note that the predication [RecentT orients
RecentT,] connects an episode of the new sentence with
an episode of the previous sentence. prev-pers produces
a trivial True, but it returns the focus to the embed-
ding tree, simultaneously blocking the link between the
embedding and the embedded tree (as emphasized by
use of 4-e- instead of 4-).
We now illustrate how tense trees get modified over
perspective changes, using (8) as example. We re-
peat (8d,e) below, augmenting them with perspective
changes, and show snapshots of the tense trees at the
points marked. In the trees, ul, ..., us are utterance
episodes for sentences a, ..., e, respectively.
</bodyText>
<equation confidence="0.810262105263158">
(8) d. TT(new-pers Together, they climbed{,5} Mt.
i
McKinley.) TT,
prev-pers 1T3
e. Mary asked{,6} whether I would want to go to
Alaska some time. TT.
T1: T2: 54
51, 52, 53
0 /
e2, e3 Ul , 52, U3
trlz• e5
e2, e3
• e4 •e4
T3: 54 T4: 244
Ul , U2, U3 Ui , 52,
53,55 • /
•e5
1e1, e2, 53, es
• 54
</equation>
<bodyText confidence="0.9995405">
Notice the blocked links to the embedded tree in T3 and
T4. Also, note that RecentT, = e4 and Recent/.2 = e5.
So, by New-pers, we get [e4 orients e5], which can be
later particularized to [e5 during e4]. It is fairly obvi-
ous that the placement of new-pers and prev-pers oper-
ators is fully determined by discourse segment bound-
aries (though not in general coinciding with them). So,
as long as the higher-level discourse segment structure
is known, our perspective rules are easily applied. In
that sense, the higher-level structure supplements the
&amp;quot;fine structure&amp;quot; in a crucial way.
However, this leaves us with a serious problem: dein-
dexing and the context change it induces is supposed
to be independent of &amp;quot;plausible inferencing&amp;quot;; in fact,
</bodyText>
<page confidence="0.99091">
238
</page>
<bodyText confidence="0.999836923076923">
it is intended to set the stage for the latter. Yet the
determination of higher-level discourse structure—and
hence of perspective shifts—is unquestionably a matter
of plausible inference. For example, if past perfect is fol-
lowed by past, this could signal either a new perspective
within the current segment (see 8c,d), or the closing of
the current subsegment with no perspective shift (see
7e,f). If past is followed by past, we may have either
a continuation of the current perspective and segment
(see 9a,b below), or a perspective shift with opening of
a new segment (see 9b,c), or closing of the current seg-
ment, with resumption of the previous perspective (see
9c,d).
</bodyText>
<listItem confidence="0.5469955">
(9) a. Mary found that her favorite vase was broken.
b. She was upset.
</listItem>
<bodyText confidence="0.998427">
c. She bought it at a special antique auction,
d. and she was afraid she wouldn&apos;t be able to find
anything that beautiful again.
Only plausible inference can resolve these ambiguities.
This inference process will interact with resolution of
anaphora and introduction of new individuals, identifi-
cation of spatial and temporal frames, the presence of
modal/cognition/ perception verbs, and most of all will
depend on world knowledge. In (9), for instance, one
may have to rely on the knowledge that one normally
would not buy broken things, or that one does not buy
things one already owns.
As approaches to this general difficulty, we are think-
ing of the following two strategies: (A) Make a best ini-
tial guess about presence or absence of new-pers/ prey-
pres, based on surface (syntactic) cues and then use
failure-driven backtracking if the resulting interpreta-
tion is incoherent. A serious disadvantage would be lack
of integration with other forms of disambiguation. (B)
Change the interpretation of LastT, in effect providing
multiple alternative referents for the first argument of
orients. In particular, we might use
LastT = {ei I ei is the last-stored episode at the
focus of T, or was stored in the subtree
rooted at the focus of T after the last-
stored episode at the focus of T}.
Subsequent processing would resemble anaphora disam-
biguation. In the course of further interpreting the dein-
dexed LF, plausible inference would particularize the
schematic orienting relation to a temporal (or causal,
etc.) relation involving just two episodes. The result
would then be used to make certain structural changes
to the tense tree (after LF deindexing).
For instance, suppose such a schematic orienting re-
lation is computed for a simple past sentence following
a past perfect sentence (like 8c,d). Suppose further that
the most coherent interpretation of the second sentence
(i.e., 8d) is one that disambiguates the orienting rela-
tion as a simple temporal inclusion relation between the
successively reported events. One might then move the
event token for the second event (reported in simple
past) from its position at the past node to the right-
most position at the past perfect node, just as if the sec-
ond event had been reported in the past perfect. (One
might in addition record a perspective shift, if this is
still considered useful.) In other words, we would &amp;quot;re-
pair&amp;quot; the distortion of the tense tree brought about by
the speaker&apos;s &amp;quot;lazy&amp;quot; use of simple past in place of past
perfect. Then we would continue as before.
In both strategies we have assumed a general
coherence-seeking plausible inference process. While it
is clear that the attainment of coherence entails delin-
eation of discourse segment structure and of all relevant
temporal relations, it remains unclear in which direction
the information flows. Are there independent principles
of discourse and temporal structure operating above the
level of syntax and LF, guiding the achievement of full
understanding, or are higher-level discourse and tem-
poral relations a mere byproduct of full understanding?
Webber [1987] has proposed independent temporal fo-
cusing principles similar to those in [Grosz and Sid-
ner, 1986] for discourse. These are not deterministic,
and Song and Cohen [1991] sought to add heuristic con-
straints as a step toward determinism. For instance,
one constraint is based on the presumed incoherence
of simple present followed by past perfect or posterior
past. But there are counterexamples; e.g., &amp;quot;Mary is
angry about the accident. The other driver had been
drinking.&amp;quot; Thus, we take the question about indepen-
dent structural principles above the level of syntax and
LF to be still open.
</bodyText>
<sectionHeader confidence="0.999271" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999924111111111">
We have shown that tense and aspect can be analyzed
compositionally in a way that accounts not only for their
more obvious effects on sentence meaning but also, via
tense trees, for their cumulative effect on context and
the temporal relations implicit in such contexts. As
such, the analysis seems to fit well with higher-level
analyses of discourse segment structure, though ques-
tions remain about the flow of information between lev-
els.
</bodyText>
<sectionHeader confidence="0.997517" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.992724">
We gratefully acknowledge helpful comments by James
Allen and Philip Harrison on an earlier draft and much
useful feedback from the members of TRAINS group
at the University of Rochester. This work was sup-
ported in part by NSERC Operating Grant A8818 and
</bodyText>
<page confidence="0.992039">
239
</page>
<bodyText confidence="0.962205166666667">
ONR/DARPA research contract no. N00014-82-K-0193,
and the Boeing Co. under Purchase Contract W-288104.
A preliminary version of this paper was presented at
the AAAI Fall Symposium on Discourse Structure in
Natural Language Understanding and Generation, Pa-
cific Grove, CA, November 1991.
</bodyText>
<sectionHeader confidence="0.996296" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995424234567902">
[Allen, 1987] J. Allen, Natural Language Understand-
ing, Chapter 14. Benjamin/Cummings Publ. Co.,
Reading, MA.
[Allen and Schubert, 1991] J. Allen and L. K. Schu-
bert, &amp;quot;The TRAINS project,&amp;quot; TR 382, Dept. of Comp.
Sci., U. of Rochester, Rochester, NY.
[Dowty, 1986] D. Dowty, &amp;quot;The effect of aspectual
classes on the temporal structure of discourse: se-
mantics or pragmatics?&amp;quot; Linguistics and Philosophy,
9(437-61.
[Grosz and Sidner, 1986] B. J. Grosz and C. L. Sid-
ner, &amp;quot;Attention, intentions, and the structure of dis-
course,&amp;quot; Computational Linguistics, 12:175-204.
[Hinrichs, 1986] E. Hinrichs, &amp;quot;Temporal anaphora in
discourses of English,&amp;quot; Linguistics and Philosophy,
9(463-82.
[Hobbs, 1985] J. R. Hobbs, &amp;quot;On the coherence and
structure of discourse,&amp;quot; Technical Report CSLI-85-
37, Stanford, CA.
[Hornstein, 1977] N. Hornstein, &amp;quot;Towards a theory of
tense,&amp;quot; Linguistic Inquiry, 3:521-557.
[Hwang, 1992] C. H. Hwang, A Logical Framework for
Narrative Understanding, PhD thesis, U. of Alberta,
Edmonton, Canada, 1992, To appear.
[Hwang and Schubert, 1991] C. H. Hwang and L. K.
Schubert, &amp;quot;Episodic Logic: A situational logic for
natural language processing,&amp;quot; In 3rd Conf. on Sit-
uation Theory and its Applications (STA-3), Oiso,
Kanagawa, Japan, November 18-21, 1991.
[Lascarides and Asher, 1991] A. Lascarides and N.
Asher, &amp;quot;Discourse relations and defeasible knowl-
edge,&amp;quot; In Proc. 29th Annual Meeting of the ACL,
pages 55-62. Berkeley, CA, June 18-21, 1991.
[Lascarides and Oberlander, 1992] A. Lascarides and
J. Oberlander, &amp;quot;Temporal coherence and defeasible
knowledge,&amp;quot; Theoretical Linguistics, 8, 1992, To ap-
pear.
[Leech, 1987] G. Leech, Meaning and the English Verb
(2nd ed), Longman, London, UK.
[Moens and Steedman, 1988] M. Moens and M. Steed-
man, &amp;quot;Temporal ontology and temporal reference,&amp;quot;
Computational Linguistics, 14(2):15-28.
[Nerbonne, 1986] J. Nerbonne, &amp;quot;Reference time and
time in narration,&amp;quot; Linguistics and Philosophy,
9(1):83-95.
[Partee, 1984] B. Partee, &amp;quot;Nominal and Temporal
Anaphora,&amp;quot; Linguistics and Philosophy, 7:243-286.
[Passonneau, 1988] R. J. Passonneau, &amp;quot;A Computa-
tional model of the semantics of tense and aspect,&amp;quot;
Computational Linguistics, 14(2):44-60.
[Reichenbach, 1947] H. Reichenbach, Elements of Sym-
bolic Logic, Macmillan, New York, NY.
[Reichman, 1985] R. Reichman, Getting Computers to
Talk Like You and Me, MIT Press, Cambridge, MA.
[Schubert and Hwang, 1989] L. K. Schubert and C. H.
Hwang, &amp;quot;An Episodic knowledge representation for
Narrative Texts,&amp;quot; In Proc. 1st Inter. Conf on Prin-
ciples of Knowledge Representation and Reasoning
(KR &apos;89), pages 444-458, Toronto, Canada, May 15-
18, 1989. Revised, extended version available as TR
345, Dept. of Comp. Sci., U. of Rochester, Rochester,
NY, May 1990.
[Schubert and Hwang, 1990] L. K. Schubert and C. H.
Hwang, &amp;quot;Picking reference events from tense trees: A
formal, implementable theory of English tense-aspect
semantics,&amp;quot; In Proc. Speech and Natural Language,
DARPA Workshop, pages 34-41, Hidden Valley, PA,
June 24-27, 1990.
[Smith, 1978] C. Smith, &amp;quot;The syntax and interpreta-
tions of temporal expressions in English,&amp;quot; Linguistics
and Philosophy, 2:43-99.
[Song and Cohen, 1991] F. Song and R. Cohen, &amp;quot;Tense
interpretation in the context of narrative,&amp;quot; In Proc.
AAAI-91, pages 131-136. Anaheim, CA, July 14-19,
1991.
[Webber, 1987] B. L. Webber, &amp;quot;The Interpretation of
tense in discourse,&amp;quot; In Proc. 25th Annual Meeting
of the ACL, pages 147-154, Stanford, CA, July 6-9,
1987.
[Webber, 1988] B. L. Webber, &amp;quot;Tense as discourse
anaphor,&amp;quot; Computational Linguistics, 14(2):61-73.
</reference>
<page confidence="0.996943">
240
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.951557">
<title confidence="0.995652">TENSE TREES AS THE &amp;quot;FINE STRUCTURE&amp;quot; OF DISCOURSE</title>
<author confidence="0.999907">Chung Hee Hwang</author>
<author confidence="0.999907">Lenhart K Schubert</author>
<affiliation confidence="0.9999515">Department of Computer Science University of Rochester</affiliation>
<address confidence="0.967028">Rochester, New York 14627, U. S. A.</address>
<email confidence="0.999729">hwangOcs.rochester.edu</email>
<email confidence="0.999729">schubertOcs.rochester.edu</email>
<abstract confidence="0.998723">We present a new compositional tense-aspect deindexmechanism that makes use of trees as components of discourse contexts. The mechanism allows reference episodes to be correctly identified even for embedded clauses and for discourse that involves shifts in temporal perspective, and permits deindexed logical forms to be automatically computed with a small number of deindexing rules.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>J Allen</author>
</authors>
<title>Natural Language Understanding, Chapter 14. Benjamin/Cummings Publ.</title>
<publisher>Co.,</publisher>
<location>Reading, MA.</location>
<marker>[Allen, 1987]</marker>
<rawString>J. Allen, Natural Language Understanding, Chapter 14. Benjamin/Cummings Publ. Co., Reading, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Allen</author>
<author>L K Schubert</author>
</authors>
<title>The TRAINS project,&amp;quot;</title>
<tech>TR 382,</tech>
<institution>Dept. of Comp. Sci., U. of Rochester,</institution>
<location>Rochester, NY.</location>
<marker>[Allen and Schubert, 1991]</marker>
<rawString>J. Allen and L. K. Schubert, &amp;quot;The TRAINS project,&amp;quot; TR 382, Dept. of Comp. Sci., U. of Rochester, Rochester, NY.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Dowty</author>
</authors>
<title>The effect of aspectual classes on the temporal structure of discourse: semantics or pragmatics?&amp;quot; Linguistics and Philosophy,</title>
<pages>9--437</pages>
<marker>[Dowty, 1986]</marker>
<rawString>D. Dowty, &amp;quot;The effect of aspectual classes on the temporal structure of discourse: semantics or pragmatics?&amp;quot; Linguistics and Philosophy, 9(437-61.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse,&amp;quot;</title>
<journal>Computational Linguistics,</journal>
<pages>12--175</pages>
<marker>[Grosz and Sidner, 1986]</marker>
<rawString>B. J. Grosz and C. L. Sidner, &amp;quot;Attention, intentions, and the structure of discourse,&amp;quot; Computational Linguistics, 12:175-204.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Hinrichs</author>
</authors>
<title>Temporal anaphora in discourses of English,&amp;quot;</title>
<journal>Linguistics and Philosophy,</journal>
<pages>9--463</pages>
<marker>[Hinrichs, 1986]</marker>
<rawString>E. Hinrichs, &amp;quot;Temporal anaphora in discourses of English,&amp;quot; Linguistics and Philosophy, 9(463-82.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J R Hobbs</author>
</authors>
<title>On the coherence and structure of discourse,&amp;quot;</title>
<tech>Technical Report CSLI-85-37,</tech>
<location>Stanford, CA.</location>
<marker>[Hobbs, 1985]</marker>
<rawString>J. R. Hobbs, &amp;quot;On the coherence and structure of discourse,&amp;quot; Technical Report CSLI-85-37, Stanford, CA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>N Hornstein</author>
</authors>
<title>Towards a theory of tense,&amp;quot;</title>
<journal>Linguistic Inquiry,</journal>
<pages>3--521</pages>
<marker>[Hornstein, 1977]</marker>
<rawString>N. Hornstein, &amp;quot;Towards a theory of tense,&amp;quot; Linguistic Inquiry, 3:521-557.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Hwang</author>
</authors>
<title>A Logical Framework for Narrative Understanding,</title>
<date>1992</date>
<tech>PhD thesis,</tech>
<institution>U. of Alberta,</institution>
<location>Edmonton, Canada,</location>
<note>To appear.</note>
<marker>[Hwang, 1992]</marker>
<rawString>C. H. Hwang, A Logical Framework for Narrative Understanding, PhD thesis, U. of Alberta, Edmonton, Canada, 1992, To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Hwang</author>
<author>L K Schubert</author>
</authors>
<title>Episodic Logic: A situational logic for natural language processing,&amp;quot;</title>
<date>1991</date>
<booktitle>In 3rd Conf. on Situation Theory and its Applications (STA-3), Oiso,</booktitle>
<location>Kanagawa, Japan,</location>
<marker>[Hwang and Schubert, 1991]</marker>
<rawString>C. H. Hwang and L. K. Schubert, &amp;quot;Episodic Logic: A situational logic for natural language processing,&amp;quot; In 3rd Conf. on Situation Theory and its Applications (STA-3), Oiso, Kanagawa, Japan, November 18-21, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lascarides</author>
<author>N Asher</author>
</authors>
<title>Discourse relations and defeasible knowledge,&amp;quot;</title>
<date>1991</date>
<booktitle>In Proc. 29th Annual Meeting of the ACL,</booktitle>
<pages>55--62</pages>
<location>Berkeley, CA,</location>
<marker>[Lascarides and Asher, 1991]</marker>
<rawString>A. Lascarides and N. Asher, &amp;quot;Discourse relations and defeasible knowledge,&amp;quot; In Proc. 29th Annual Meeting of the ACL, pages 55-62. Berkeley, CA, June 18-21, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lascarides</author>
<author>J Oberlander</author>
</authors>
<title>Temporal coherence and defeasible knowledge,&amp;quot;</title>
<date>1992</date>
<journal>Theoretical Linguistics,</journal>
<volume>8</volume>
<note>To appear.</note>
<marker>[Lascarides and Oberlander, 1992]</marker>
<rawString>A. Lascarides and J. Oberlander, &amp;quot;Temporal coherence and defeasible knowledge,&amp;quot; Theoretical Linguistics, 8, 1992, To appear.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Leech</author>
</authors>
<title>Meaning and the English Verb (2nd ed),</title>
<location>Longman, London, UK.</location>
<marker>[Leech, 1987]</marker>
<rawString>G. Leech, Meaning and the English Verb (2nd ed), Longman, London, UK.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Moens</author>
<author>M Steedman</author>
</authors>
<title>Temporal ontology and temporal reference,&amp;quot;</title>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<marker>[Moens and Steedman, 1988]</marker>
<rawString>M. Moens and M. Steedman, &amp;quot;Temporal ontology and temporal reference,&amp;quot; Computational Linguistics, 14(2):15-28.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Nerbonne</author>
</authors>
<title>Reference time and time in narration,&amp;quot;</title>
<journal>Linguistics and Philosophy,</journal>
<pages>9--1</pages>
<marker>[Nerbonne, 1986]</marker>
<rawString>J. Nerbonne, &amp;quot;Reference time and time in narration,&amp;quot; Linguistics and Philosophy, 9(1):83-95.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Partee</author>
</authors>
<title>Nominal and Temporal Anaphora,&amp;quot;</title>
<journal>Linguistics and Philosophy,</journal>
<pages>7--243</pages>
<marker>[Partee, 1984]</marker>
<rawString>B. Partee, &amp;quot;Nominal and Temporal Anaphora,&amp;quot; Linguistics and Philosophy, 7:243-286.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R J Passonneau</author>
</authors>
<title>A Computational model of the semantics of tense and aspect,&amp;quot;</title>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<marker>[Passonneau, 1988]</marker>
<rawString>R. J. Passonneau, &amp;quot;A Computational model of the semantics of tense and aspect,&amp;quot; Computational Linguistics, 14(2):44-60.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Reichenbach</author>
</authors>
<title>Elements of Symbolic Logic,</title>
<publisher>Macmillan,</publisher>
<location>New York, NY.</location>
<marker>[Reichenbach, 1947]</marker>
<rawString>H. Reichenbach, Elements of Symbolic Logic, Macmillan, New York, NY.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Reichman</author>
</authors>
<title>Getting Computers to Talk Like You and Me,</title>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>[Reichman, 1985]</marker>
<rawString>R. Reichman, Getting Computers to Talk Like You and Me, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L K Schubert</author>
<author>C H Hwang</author>
</authors>
<title>An Episodic knowledge representation for Narrative Texts,&amp;quot; In</title>
<date>1989</date>
<booktitle>Proc. 1st Inter. Conf on Principles of Knowledge Representation and Reasoning (KR &apos;89),</booktitle>
<tech>TR 345,</tech>
<pages>444--458</pages>
<institution>Dept. of Comp. Sci., U. of Rochester,</institution>
<location>Toronto, Canada,</location>
<marker>[Schubert and Hwang, 1989]</marker>
<rawString>L. K. Schubert and C. H. Hwang, &amp;quot;An Episodic knowledge representation for Narrative Texts,&amp;quot; In Proc. 1st Inter. Conf on Principles of Knowledge Representation and Reasoning (KR &apos;89), pages 444-458, Toronto, Canada, May 15-18, 1989. Revised, extended version available as TR 345, Dept. of Comp. Sci., U. of Rochester, Rochester, NY, May 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L K Schubert</author>
<author>C H Hwang</author>
</authors>
<title>Picking reference events from tense trees: A formal, implementable theory of English tense-aspect semantics,&amp;quot;</title>
<date>1990</date>
<booktitle>In Proc. Speech and Natural Language, DARPA Workshop,</booktitle>
<pages>34--41</pages>
<location>Hidden Valley, PA,</location>
<marker>[Schubert and Hwang, 1990]</marker>
<rawString>L. K. Schubert and C. H. Hwang, &amp;quot;Picking reference events from tense trees: A formal, implementable theory of English tense-aspect semantics,&amp;quot; In Proc. Speech and Natural Language, DARPA Workshop, pages 34-41, Hidden Valley, PA, June 24-27, 1990.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Smith</author>
</authors>
<title>The syntax and interpretations of temporal expressions in English,&amp;quot; Linguistics and Philosophy,</title>
<pages>2--43</pages>
<marker>[Smith, 1978]</marker>
<rawString>C. Smith, &amp;quot;The syntax and interpretations of temporal expressions in English,&amp;quot; Linguistics and Philosophy, 2:43-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Song</author>
<author>R Cohen</author>
</authors>
<title>Tense interpretation in the context of narrative,&amp;quot;</title>
<date>1991</date>
<booktitle>In Proc. AAAI-91,</booktitle>
<pages>131--136</pages>
<location>Anaheim, CA,</location>
<marker>[Song and Cohen, 1991]</marker>
<rawString>F. Song and R. Cohen, &amp;quot;Tense interpretation in the context of narrative,&amp;quot; In Proc. AAAI-91, pages 131-136. Anaheim, CA, July 14-19, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Webber</author>
</authors>
<title>The Interpretation of tense in discourse,&amp;quot;</title>
<date>1987</date>
<booktitle>In Proc. 25th Annual Meeting of the ACL,</booktitle>
<pages>147--154</pages>
<location>Stanford, CA,</location>
<marker>[Webber, 1987]</marker>
<rawString>B. L. Webber, &amp;quot;The Interpretation of tense in discourse,&amp;quot; In Proc. 25th Annual Meeting of the ACL, pages 147-154, Stanford, CA, July 6-9, 1987.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B L Webber</author>
</authors>
<title>Tense as discourse anaphor,&amp;quot;</title>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<marker>[Webber, 1988]</marker>
<rawString>B. L. Webber, &amp;quot;Tense as discourse anaphor,&amp;quot; Computational Linguistics, 14(2):61-73.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>