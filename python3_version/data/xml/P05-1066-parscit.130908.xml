<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988929">
Clause Restructuring for Statistical Machine Translation
</title>
<author confidence="0.892747">
Michael Collins Philipp Koehn Ivona Kuˇcerov´a
</author>
<affiliation confidence="0.8196975">
MIT CSAIL School of Informatics MIT Linguistics Department
mcollins@csail.mit.edu University of Edinburgh kucerova@mit.edu
</affiliation>
<email confidence="0.97707">
pkoehn@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.993453" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999819071428571">
We describe a method for incorporating syntactic informa-
tion in statistical machine translation systems. The first step
of the method is to parse the source language string that is be-
ing translated. The second step is to apply a series of trans-
formations to the parse tree, effectively reordering the surface
string on the source language side of the translation system. The
goal of this step is to recover an underlying word order that is
closer to the target language word-order than the original string.
The reordering approach is applied as a pre-processing step in
both the training and decoding phases of a phrase-based statis-
tical MT system. We describe experiments on translation from
German to English, showing an improvement from 25.2% Bleu
score for a baseline system to 26.8% Bleu score for the system
with reordering, a statistically significant improvement.
</bodyText>
<sectionHeader confidence="0.998773" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996072489795918">
Recent research on statistical machine translation
(SMT) has lead to the development of phrase-
based systems (Och et al., 1999; Marcu and Wong,
2002; Koehn et al., 2003). These methods go be-
yond the original IBM machine translation models
(Brown et al., 1993), by allowing multi-word units
(“phrases”) in one language to be translated directly
into phrases in another language. A number of em-
pirical evaluations have suggested that phrase-based
systems currently represent the state–of–the–art in
statistical machine translation.
In spite of their success, a key limitation of
phrase-based systems is that they make little or no
direct use of syntactic information. It appears likely
that syntactic information will be crucial in accu-
rately modeling many phenomena during transla-
tion, for example systematic differences between the
word order of different languages. For this reason
there is currently a great deal of interest in meth-
ods which incorporate syntactic information within
statistical machine translation systems (e.g., see (Al-
shawi, 1996; Wu, 1997; Yamada and Knight, 2001;
Gildea, 2003; Melamed, 2004; Graehl and Knight,
2004; Och et al., 2004; Xia and McCord, 2004)).
In this paper we describe an approach for the use
of syntactic information within phrase-based SMT
systems. The approach constitutes a simple, direct
method for the incorporation of syntactic informa-
tion in a phrase–based system, which we will show
leads to significant improvements in translation ac-
curacy. The first step of the method is to parse the
source language string that is being translated. The
second step is to apply a series of transformations
to the resulting parse tree, effectively reordering the
surface string on the source language side of the
translation system. The goal of this step is to re-
cover an underlying word order that is closer to the
target language word-order than the original string.
Finally, we apply a phrase-based system to the re-
ordered string to give a translation into the target
language.
We describe experiments involving machine
translation from German to English. As an illustra-
tive example of our method, consider the following
German sentence, together with a “translation” into
English that follows the original word order:
Original sentence: Ich werde Ihnen die entsprechenden An-
merkungen aushaendigen, damit Sie das eventuell bei der
Abstimmung uebernehmen koennen.
</bodyText>
<construct confidence="0.5275445">
English translation: I will to you the corresponding comments
pass on, so that you them perhaps in the vote adopt can.
</construct>
<bodyText confidence="0.999943666666667">
The German word order in this case is substan-
tially different from the word order that would be
seen in English. As we will show later in this pa-
per, translations of sentences of this type pose dif-
ficulties for phrase-based systems. In our approach
we reorder the constituents in a parse of the German
sentence to give the following word order, which is
much closer to the target English word order (words
which have been “moved” are underlined):
</bodyText>
<footnote confidence="0.773963">
Reordered sentence: Ich werde aushaendigen Ihnen die
entsprechenden Anmerkungen, damit Sie koennen
uebernehmen das eventuell bei der Abstimmung.
English translation: I will pass on to you the corresponding
comments, so that you can adopt them perhaps in the vote.
</footnote>
<page confidence="0.911415">
531
</page>
<note confidence="0.9915655">
Proceedings of the 43rd Annual Meeting of the ACL, pages 531–540,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998428">
We applied our approach to translation from Ger-
man to English in the Europarl corpus. Source lan-
guage sentences are reordered in test data, and also
in training data that is used by the underlying phrase-
based system. Results using the method show an
improvement from 25.2% Bleu score to 26.8% Bleu
score (a statistically significant improvement), using
a phrase-based system (Koehn et al., 2003) which
has been shown in the past to be a highly competi-
tive SMT system.
</bodyText>
<sectionHeader confidence="0.991649" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.8073355">
2.1 Previous Work
2.1.1 Research on Phrase-Based SMT
</subsectionHeader>
<bodyText confidence="0.999974514285714">
The original work on statistical machine transla-
tion was carried out by researchers at IBM (Brown
et al., 1993). More recently, phrase-based models
(Och et al., 1999; Marcu and Wong, 2002; Koehn
et al., 2003) have been proposed as a highly suc-
cessful alternative to the IBM models. Phrase-based
models generalize the original IBM models by al-
lowing multiple words in one language to corre-
spond to multiple words in another language. For
example, we might have a translation entry specify-
ing that I will in English is a likely translation for Ich
werde in German.
In this paper we use the phrase-based system
of (Koehn et al., 2003) as our underlying model.
This approach first uses the original IBM models
to derive word-to-word alignments in the corpus
of example translations. Heuristics are then used
to grow these alignments to encompass phrase-to-
phrase pairs. The end result of the training process is
a lexicon of phrase-to-phrase pairs, with associated
costs or probabilities. In translation with the sys-
tem, a beam search method with left-to-right search
is used to find a high scoring translation for an in-
put sentence. At each stage of the search, one or
more English words are added to the hypothesized
string, and one or more consecutive German words
are “absorbed” (i.e., marked as having already been
translated—note that each word is absorbed at most
once). Each step of this kind has a number of costs:
for example, the log probability of the phrase-to-
phrase correspondance involved, the log probability
from a language model, and some “distortion” score
indicating how likely it is for the proposed words in
the English string to be aligned to the corresponding
position in the German string.
</bodyText>
<subsectionHeader confidence="0.928385">
2.1.2 Research on Syntax-Based SMT
</subsectionHeader>
<bodyText confidence="0.999850131578948">
A number of researchers (Alshawi, 1996; Wu,
1997; Yamada and Knight, 2001; Gildea, 2003;
Melamed, 2004; Graehl and Knight, 2004; Galley
et al., 2004) have proposed models where the trans-
lation process involves syntactic representations of
the source and/or target languages. One class of ap-
proaches make use of “bitext” grammars which si-
multaneously parse both the source and target lan-
guages. Another class of approaches make use of
syntactic information in the target language alone,
effectively transforming the translation problem into
a parsing problem. Note that these models have radi-
cally different structures and parameterizations from
phrase–based models for SMT. As yet, these sys-
tems have not shown significant gains in accuracy
in comparison to phrase-based systems.
Reranking methods have also been proposed as a
method for using syntactic information (Koehn and
Knight, 2003; Och et al., 2004; Shen et al., 2004). In
these approaches a baseline system is used to gener-
ate -best output. Syntactic features are then used
in a second model that reranks the -best lists, in
an attempt to improve over the baseline approach.
(Koehn and Knight, 2003) apply a reranking ap-
proach to the sub-task of noun-phrase translation.
(Och et al., 2004; Shen et al., 2004) describe the
use of syntactic features in reranking the output of
a full translation system, but the syntactic features
give very small gains: for example the majority of
the gain in performance in the experiments in (Och
et al., 2004) was due to the addition of IBM Model
1 translation probabilities, a non-syntactic feature.
An alternative use of syntactic information is to
employ an existing statistical parsing model as a lan-
guage model within an SMT system. See (Charniak
et al., 2003) for an approach of this form, which
shows improvements in accuracy over a baseline
system.
</bodyText>
<subsectionHeader confidence="0.916694">
2.1.3 Research on Preprocessing Approaches
</subsectionHeader>
<bodyText confidence="0.99997425">
Our approach involves a preprocessing step,
where sentences in the language being translated are
modified before being passed to an existing phrase-
based translation system. A number of other re-
</bodyText>
<page confidence="0.994837">
532
</page>
<bodyText confidence="0.999848916666667">
searchers (Berger et al., 1996; Niessen and Ney,
2004; Xia and McCord, 2004) have described previ-
ous work on preprocessing methods. (Berger et al.,
1996) describe an approach that targets translation
of French phrases of the form NOUN de NOUN
(e.g., conflit d’int´erˆet). This was a relatively lim-
ited study, concentrating on this one syntactic phe-
nomenon which involves relatively local transfor-
mations (a parser was not required in this study).
(Niessen and Ney, 2004) describe a method that
combines morphologically–split verbs in German,
and also reorders questions in English and German.
Our method goes beyond this approach in several
respects, for example considering phenomena such
as declarative (non-question) clauses, subordinate
clauses, negation, and so on.
(Xia and McCord, 2004) describe an approach for
translation from French to English, where reorder-
ing rules are acquired automatically. The reorder-
ing rules in their approach operate at the level of
context-free rules in the parse tree. Our method
differs from that of (Xia and McCord, 2004) in a
couple of important respects. First, we are consid-
ering German, which arguably has more challeng-
ing word order phenonema than French. German
has relatively free word order, in contrast to both
English and French: for example, there is consid-
erable flexibility in terms of which phrases can ap-
pear in the first position in a clause. Second, Xia
et. al’s (2004) use of reordering rules stated at the
context-free level differs from ours. As one exam-
ple, in our approach we use a single transformation
that moves an infinitival verb to the first position in
a verb phrase. Xia et. al’s approach would require
learning of a different rule transformation for every
production of the form VP =&gt; .... In practice the
German parser that we are using creates relatively
“flat” structures at the VP and clause levels, leading
to a huge number of context-free rules (the flatness
is one consequence of the relatively free word order
seen within VP’s and clauses in German). There are
clearly some advantages to learning reordering rules
automatically, as in Xia et. al’s approach. How-
ever, we note that our approach involves a hand-
ful of linguistically–motivated transformations and
achieves comparable improvements (albeit on a dif-
ferent language pair) to Xia et. al’s method, which
in contrast involves over 56,000 transformations.
</bodyText>
<figure confidence="0.998185">
S PPER-SB Ich
VAFIN-HD werde
VP PPER-DA Ihnen
NP-OA ART die
ADJA entsprechenden
NN Anmerkungen
VVINF-HD aushaendigen
, ,
S KOUS damit
PPER-SB Sie
VP PDS-OA das
ADJD eventuell
PP APPR bei
ART der
NN Abstimmung
VVINF-HD uebernehmen
VMFIN-HD koennen
</figure>
<figureCaption confidence="0.823986333333333">
Figure 1: An example parse tree. Key to non-terminals:
PPER = personal pronoun; VAFIN = finite verb; VVINF = in-
finitival verb; KOUS = complementizer; APPR = preposition;
ART = article; ADJA = adjective; ADJD = adverb; -SB = sub-
ject; -HD = head of a phrase; -DA = dative object; -OA = ac-
cusative object.
</figureCaption>
<subsectionHeader confidence="0.993695">
2.2 German Clause Structure
</subsectionHeader>
<bodyText confidence="0.97555752">
In this section we give a brief description of the syn-
tactic structure of German clauses. The character-
istics we describe motivate the reordering rules de-
scribed later in the paper.
Figure 1 gives an example parse tree for a German
sentence. This sentence contains two clauses:
Clause 1: Ich/I werde/will Ihnen/to you die/the
entsprechenden/corresponding
Anmerkungen/comments aushaendigen/pass on
Clause 2: damit/so that Sie/you das/them
eventuell/perhaps bei/in der/the Abstimmung/vote
uebernehmen/adopt koennen/can
These two clauses illustrate a number of syntactic
phenomena in German which lead to quite different
word order from English:
Position of finite verbs. In Clause 1, which is a
matrix clause, the finite verb werde is in the second
position in the clause. Finite verbs appear rigidly in
2nd position in matrix clauses. In contrast, in sub-
ordinate clauses, such as Clause 2, the finite verb
comes last in the clause. For example, note that
koennen is a finite verb which is the final element
of Clause 2.
Position of infinitival verbs. In German, infini-
tival verbs are final within their associated verb
</bodyText>
<page confidence="0.991875">
533
</page>
<bodyText confidence="0.999966238095238">
phrase. For example, returning to Figure 1, no-
tice that aushaendigen is the last element in its verb
phrase, and that uebernehmen is the final element of
its verb phrase in the figure.
Relatively flexible word ordering. German has
substantially freer word order than English. In par-
ticular, note that while the verb comes second in ma-
trix clauses, essentially any element can be in the
first position. For example, in Clause 1, while the
subject Ich is seen in the first position, potentially
any of the other constituents (e.g., Ihnen) could also
appear in this position. Note that this often leads
to the subject following the finite verb, something
which happens very rarely in English.
There are many other phenomena which lead to
differing word order between German and English.
Two others that we focus on in this paper are nega-
tion (the differing placement of items such as not in
English and nicht in German), and also verb-particle
constructions. We describe our treatment of these
phenomena later in this paper.
</bodyText>
<subsectionHeader confidence="0.999896">
2.3 Reordering with Phrase-Based SMT
</subsectionHeader>
<bodyText confidence="0.999842188405797">
We have seen in the last section that German syntax
has several characteristics that lead to significantly
different word order from that of English. We now
describe how these characteristics can lead to dif-
ficulties for phrase–based translation systems when
applied to German to English translation.
Typically, reordering models in phrase-based sys-
tems are based solely on movement distance. In par-
ticular, at each point in decoding a “cost” is associ-
ated with skipping over 1 or more German words.
For example, assume that in translating
Ich werde Ihnen die entsprechenden An-
merkungen aushaendigen.
we have reached a state where “Ich” and “werde”
have been translated into “I will” in English. A
potential decoding decision at this point is to add
the phrase “pass on” to the English hypothesis, at
the same time absorbing “aushaendigen” from the
German string. The cost of this decoding step
will involve a number of factors, including a cost
of skipping over a phrase of length 4 (i.e., Ihnen
die entsprechenden Anmerkungen) in the German
string.
The ability to penalise “skips” of this type, and
the potential to model multi-word phrases, are es-
sentially the main strategies that the phrase-based
system is able to employ when modeling differing
word-order across different languages. In practice,
when training the parameters of an SMT system, for
example using the discriminative methods of (Och,
2003), the cost for skips of this kind is typically set
to a very high value. In experiments with the sys-
tem of (Koehn et al., 2003) we have found that in
practice a large number of complete translations are
completely monotonic (i.e., have skips), suggest-
ing that the system has difficulty learning exactly
what points in the translation should allow reorder-
ing. In summary, phrase-based systems have rela-
tively limited potential to model word-order differ-
ences between different languages.
The reordering stage described in this paper at-
tempts to modify the source language (e.g., German)
in such a way that its word order is very similar to
that seen in the target language (e.g., English). In
an ideal approach, the resulting translation problem
that is passed on to the phrase-based system will be
solvable using a completely monotonic translation,
without any skips, and without requiring extremely
long phrases to be translated (for example a phrasal
translation corresponding to Ihnen die entsprechen-
den Anmerkungen aushaendigen).
Note than an additional benefit of the reordering
phase is that it may bring together groups of words
in German which have a natural correspondance to
phrases in English, but were unseen or rare in the
original German text. For example, in the previous
example, we might derive a correspondance between
werde aushaendigen and will pass on that was not
possible before reordering. Another example con-
cerns verb-particle constructions, for example in
Wir machen die Tuer auf
machen and auf form a verb-particle construction.
The reordering stage moves auf to precede machen,
allowing a phrasal entry that “auf machen” is trans-
lated to to open in English. Without the reordering,
the particle can be arbitrarily far from the verb that
it modifies, and there is a danger in this example of
translating machen as to make, the natural transla-
tion when no particle is present.
</bodyText>
<page confidence="0.991831">
534
</page>
<table confidence="0.6456219">
Original sentence: Ich werde Ihnen die entsprechenden
Anmerkungen aushaendigen, damit Sie das eventuell bei
der Abstimmung uebernehmen koennen. (I will to you the
corresponding comments pass on, so that you them perhaps
in the vote adopt can.)
Reordered sentence: Ich werde aushaendigen Ihnen
die entsprechenden Anmerkungen, damit Sie koennen ue-
bernehmen das eventuell bei der Abstimmung.
(I will pass on to you the corresponding comments, so that you
can adopt them perhaps in the vote.)
</table>
<figureCaption confidence="0.9880495">
Figure 2: An example of the reordering process, showing the
original German sentence and the sentence after reordering.
</figureCaption>
<sectionHeader confidence="0.96963" genericHeader="method">
3 Clause Restructuring
</sectionHeader>
<bodyText confidence="0.998208681818182">
We now describe the method we use for reordering
German sentences. As a first step in the reordering
process, we parse the sentence using the parser de-
scribed in (Dubey and Keller, 2003). The second
step is to apply a sequence of rules that reorder the
German sentence depending on the parse tree struc-
ture. See Figure 2 for an example German sentence
before and after the reordering step.
In the reordering phase, each of the following six
restructuring steps were applied to a German parse
tree, in sequence (see table 1 also, for examples of
the reordering steps):
[1] Verb initial In any verb phrase (i.e., phrase
with label VP-...) find the head of the phrase (i.e.,
the child with label -HD) and move it into the ini-
tial position within the verb phrase. For example,
in the parse tree in Figure 1, aushaendigen would be
moved to precede Ihnen in the first verb phrase (VP-
OC), and uebernehmen would be moved to precede
das in the second VP-OC. The subordinate clause
would have the following structure after this trans-
formation:
</bodyText>
<table confidence="0.852441333333333">
S-MO KOUS-CP damit
PPER-SB Sie
VP-OC VVINF-HD uebernehmen
PDS-OA das
ADJD-MO eventuell
PP-MO APPR-DA bei
ART-DA der
NN-NK Abstimmung
VMFIN-HD koennen
</table>
<listItem confidence="0.91766125">
[2] Verb 2nd In any subordinate clause labelled
S-..., with a complementizer KOUS, PREL, PWS
or PWAV, find the head of the clause, and move it to
directly follow the complementizer.
</listItem>
<bodyText confidence="0.992707">
For example, in the subordinate clause in Fig-
ure 1, the head of the clause koennen would be
moved to follow the complementizer damit, giving
the following structure:
</bodyText>
<table confidence="0.930373444444445">
S-MO KOUS-CP damit
VMFIN-HD koennen
PPER-SB Sie
VP-OC VVINF-HD uebernehmen
PDS-OA das
ADJD-MO eventuell
PP-MO APPR-DA bei
ART-DA der
NN-NK Abstimmung
</table>
<bodyText confidence="0.862685555555556">
[3] Move Subject For any clause (i.e., phrase with
label S...), move the subject to directly precede
the head. We define the subject to be the left-most
child of the clause with label ...-SB or PPER-
EP, and the head to be the leftmost child with label
...-HD.
For example, in the subordinate clause in Fig-
ure 1, the subject Sie would be moved to precede
koennen, giving the following structure:
</bodyText>
<figure confidence="0.511507555555555">
S-MO KOUS-CP damit
PPER-SB Sie
VMFIN-HD koennen
VP-OC VVINF-HD uebernehmen
PDS-OA das
ADJD-MO eventuell
PP-MO APPR-DA bei
ART-DA der
NN-NK Abstimmung
</figure>
<bodyText confidence="0.895423">
[4] Particles In verb particle constructions, move
the particle to immediately precede the verb. More
specifically, if a finite verb (i.e., verb tagged as
VVFIN) and a particle (i.e., word tagged as PTKVZ)
are found in the same clause, move the particle to
precede the verb.
As one example, the following clause contains
both a verb (forden) as well as a particle (auf):
</bodyText>
<figure confidence="0.8569328">
S PPER-SB Wir
VVFIN-HD fordern
NP-OA ART das
NN Praesidium
PTKVZ-SVP auf
</figure>
<footnote confidence="0.685544333333333">
After the transformation, the clause is altered to:
S PPER-SB Wir
PTKVZ-SVP auf
VVFIN-HD fordern
NP-OA ART das
NN Praesidium
</footnote>
<page confidence="0.947527">
535
</page>
<table confidence="0.99935952">
Transformation Example
Verb Initial Before: Ich werde Ihnen die entsprechenden Anmerkungen aushaendigen,
After:
Ich werde aushaendigen Ihnen die entsprechenden Anmerkungen,
I shall be passing on to you some comments,
Verb 2nd Before: damit Sie uebernehmen das eventuell bei der Abstimmung koennen.
After:
damit koennen Sie uebernehmen das eventuell bei der Abstimmung .
so that could you adopt this perhaps in the voting.
Move Subject Before: damit koennen Sie uebernehmen das eventuell bei der Abstimmung.
After:
damit Sie koennen uebernehmen das eventuell bei der Abstimmung .
so that you could adopt this perhaps in the voting.
Particles Before: Wir fordern das Praesidium auf,
After:
Wir auf fordern das Praesidium,
We ask the Bureau,
Infinitives Before: Ich werde der Sache nachgehen dann,
After:
Ich werde nachgehen der Sache dann,
I will look into the matter then,
Negation Before: Wir konnten einreichen es nicht mehr rechtzeitig,
After:
Wir konnten nicht einreichen es mehr rechtzeitig,
We could not hand it in in time,
</table>
<tableCaption confidence="0.998759">
Table 1: Examples for each of the reordering steps. In each case the item that is moved is underlined.
</tableCaption>
<bodyText confidence="0.992987384615385">
[5] Infinitives In some cases, infinitival verbs are
still not in the correct position after transformations
[1]–[4]. For this reason we add a second step that
involves infinitives. First, we remove all internal VP
nodes within the parse tree. Second, for any clause
(i.e., phrase labeled S...), if the clause dominates
both a finite and infinitival verb, and there is an argu-
ment (i.e., a subject, or an object) between the two
verbs, then the infinitive is moved to directly follow
the finite verb.
As an example, the following clause contains an
infinitival (einreichen) that is separated from a finite
verb konnten by the direct object es:
</bodyText>
<equation confidence="0.7183405">
S PPER-SB Wir
VMFIN-HD konnten
PPER-OA es
PTKNEG-NG nicht
</equation>
<sectionHeader confidence="0.765416666666667" genericHeader="method">
VP-OC VVINF-HD einreichen
AP-MO ADV-MO mehr
ADJD-HD rechtzeitig
</sectionHeader>
<bodyText confidence="0.968291">
The transformation removes the VP-OC, and
moves the infinitive, giving:
</bodyText>
<equation confidence="0.4075836">
S PPER-SB Wir
VMFIN-HD konnten
VVINF-HD einreichen
PPER-OA es
PTKNEG-NG nicht
</equation>
<sectionHeader confidence="0.8459095" genericHeader="method">
AP-MO ADV-MO mehr
ADJD-HD rechtzeitig
</sectionHeader>
<bodyText confidence="0.9983075">
[6] Negation As a final step, we move negative
particles. If a clause dominates both a finite and in-
finitival verb, as well as a negative particle (i.e., a
word tagged as PTKNEG), then the negative particle
is moved to directly follow the finite verb.
As an example, the previous example now has the
negative particle nicht moved, to give the following
clause structure:
</bodyText>
<figure confidence="0.443250142857143">
S PPER-SB Wir
VMFIN-HD konnten
PTKNEG-NG nicht
VVINF-HD einreichen
PPER-OA es
AP-MO ADV-MO mehr
ADJD-HD rechtzeitig
</figure>
<sectionHeader confidence="0.994004" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999917">
This section describes experiments with the reorder-
ing approach. Our baseline is the phrase-based
MT system of (Koehn et al., 2003). We trained
this system on the Europarl corpus, which consists
of 751,088 sentence pairs with 15,256,792 German
words and 16,052,269 English words. Translation
performance is measured on a 2000 sentence test set
from a different part of the Europarl corpus, with av-
erage sentence length of 28 words.
We use BLEU scores (Papineni et al., 2002) to
measure translation accuracy. We applied our re-
</bodyText>
<page confidence="0.996614">
536
</page>
<table confidence="0.9994622">
Annotator 2
Annotator 1 R B E
R 33 2 5
B 2 13 5
E 9 4 27
</table>
<tableCaption confidence="0.909963166666667">
Table 2: Table showing the level of agreement between two
annotators on 100 translation judgements. R gives counts cor-
responding to translations where an annotator preferred the re-
ordered system; B signifies that the annotator preferred the
baseline system; E means an annotator judged the two systems
to give equal quality translations.
</tableCaption>
<bodyText confidence="0.9996812">
ordering method to both the training and test data,
and retrained the system on the reordered training
data. The BLEU score for the new system was
26.8%, an improvement from 25.2% BLEU for the
baseline system.
</bodyText>
<subsectionHeader confidence="0.997826">
4.1 Human Translation Judgements
</subsectionHeader>
<bodyText confidence="0.995715777777778">
We also used human judgements of translation qual-
ity to evaluate the effectiveness of the reordering
rules. We randomly selected 100 sentences from the
test corpus where the English reference translation
was between 10 and 20 words in length.&apos; For each
of these 100 translations, we presented the two anno-
tators with three translations: the reference (human)
translation, the output from the baseline system, and
the output from the system with reordering. No in-
dication was given as to which system was the base-
line system, and the ordering in which the baseline
and reordered translations were presented was cho-
sen at random on each example, to prevent ordering
effects in the annotators’ judgements. For each ex-
ample, we asked each of the annotators to make one
of two choices: 1) an indication that one translation
was an improvement over the other; or 2) an indica-
tion that the translations were of equal quality.
Annotator 1 judged 40 translations to be improved
by the reordered model; 40 translations to be of
equal quality; and 20 translations to be worse under
the reordered model. Annotator 2 judged 44 trans-
lations to be improved by the reordered model; 37
translations to be of equal quality; and 19 transla-
tions to be worse under the reordered model. Ta-
ble 2 gives figures indicating agreement rates be-
tween the annotators. Note that if we only consider
preferences where both annotators were in agree-
&apos;We chose these shorter sentences for human evaluation be-
cause in general they include a single clause, which makes hu-
man judgements relatively straightforward.
ment (and consider all disagreements to fall into the
“equal” category), then 33 translations improved un-
der the reordering system, and 13 translations be-
came worse. Figure 3 shows a random selection
of the translations where annotator 1 judged the re-
ordered model to give an improvement; Figure 4
shows examples where the baseline system was pre-
ferred by annotator 1. We include these examples to
give a qualitative impression of the differences be-
tween the baseline and reordered system. Our (no
doubt subjective) impression is that the cases in fig-
ure 3 are more clear cut instances of translation im-
provements, but we leave the reader to make his/her
own judgement on this point.
</bodyText>
<subsectionHeader confidence="0.998076">
4.2 Statistical Significance
</subsectionHeader>
<bodyText confidence="0.988411789473684">
We now describe statistical significance tests for our
results. We believe that applying significance tests
to Bleu scores is a subtle issue, for this reason we go
into some detail in this section.
We used the sign test (e.g., see page 166 of
(Lehmann, 1986)) to test the statistical significance
of our results. For a source sentence , the sign test
requires a function that is defined as follows:
If reordered system produces a better
translation for than the baseline
If baseline produces a better translation
for than the reordered system.
If the two systems produce equal
quality translations on
We assume that sentences are drawn from
some underlying distribution , and that the test
set consists of independently, identically distributed
(IID) sentences from this distribution. We can define
the following probabilities:
</bodyText>
<equation confidence="0.76343">
Probability
Probability (2)
</equation>
<bodyText confidence="0.984265142857143">
where the probability is taken with respect to the
distribution . The sign test has the null hy-
pothesis and the alternative
hypothesis . Given a sam-
ple of test points ,the sign test
depends on calculation of the following counts:
, ,
</bodyText>
<equation confidence="0.806636">
(1)
</equation>
<page confidence="0.991487">
537
</page>
<bodyText confidence="0.972735131147541">
and ,where is the car-
dinality of the set .
We now come to the definition of — how
should we judge whether a translation from one sys-
tem is better or worse than the translation from an-
other system? A critical problem with Bleu scores is
that they are a function of an entire test corpus and
do not give translation scores for single sentences.
Ideally we would have some measure
of the quality of the translation of sentence un-
der the reordered system, and a corresponding func-
tion that measures the quality of the baseline
translation. We could then define as follows:
If
If
If
Unfortunately Bleu scores do not give per-
sentence measures and , and thus do
not allow a definition of in this way. In general
the lack of per-sentence scores makes it challenging
to apply significance tests to Bleu scores.2
To get around this problem, we make the follow-
ing approximation. For any test sentence , we cal-
culate as follows. First, we define to be the
Bleu score for the test corpus when translated by the
baseline model. Next, we define to be the Bleu
score when all sentences other than are translated
by the baseline model, and where itself is trans-
lated by the reordered model. We then define
If
If
If
Note that strictly speaking, this definition of
is not valid, as it depends on the entire set of sample
points rather than alone. However, we
believe it is a reasonable approximation to an ideal
2The lack of per-sentence scores means that it is not possible
to apply standard statistical tests such as the sign test or the t-
test (which would test the hypothesis ,
where is the expected value under ). Note that previous
work (Koehn, 2004; Zhang and Vogel, 2004) has suggested the
use of bootstrap tests (Efron and Tibshirani, 1993) for the cal-
culation of confidence intervals for Bleu scores. (Koehn, 2004)
gives empirical evidence that these give accurate estimates for
Bleu statistics. However, correctness of the bootstrap method
relies on some technical properties of the statistic (e.g., Bleu
scores) being used (e.g., see (Wasserman, 2004) theorem 8.3);
(Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether
Bleu scores meet any such criteria, which makes us uncertain of
their correctness when applied to Bleu scores.
.
We can also calculate confidence intervals for the
results. Define to be the probability that the re-
ordered system improves on the baseline system,
given that the two systems do not have equal per-
formance. The relative frequency estimate of is
. Using a nor-
mal approximation (e.g., see Example 6.17 from
(Wasserman, 2004)) a 95% confidence interval for
a sample size of 1785 is , giving a 95%
confidence interval of for .
</bodyText>
<sectionHeader confidence="0.999094" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999994875">
We have demonstrated that adding knowledge about
syntactic structure can significantly improve the per-
formance of an existing state-of-the-art statistical
machine translation system. Our approach makes
use of syntactic knowledge to overcome a weakness
of tradition SMT systems, namely long-distance re-
ordering. We pose clause restructuring as a prob-
lem for machine translation. Our current approach
is based on hand-crafted rules, which are based on
our linguistic knowledge of how German and En-
glish syntax differs. In the future we may investigate
data-driven approaches, in an effort to learn reorder-
ing models automatically. While our experiments
are on German, other languages have word orders
that are very different from English, so we believe
our methods will be generally applicable.
</bodyText>
<sectionHeader confidence="0.996513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998168842105263">
We would like to thank Amit Dubey for providing the German
parser used in our experiments. Thanks to Brooke Cowan and
Luke Zettlemoyer for providing the human judgements of trans-
lation performance. Thanks also to Regina Barzilay for many
helpful comments on an earlier draft of this paper. Any remain-
ing errors are of course our own. Philipp Koehn was supported
by a grant from NTT, Agmt. dtd. 6/21/1998. Michael Collins
was supported by NSF grants IIS-0347631 and IIS-0415030.
function that indicates whether the transla-
tions have improved or not under the reordered sys-
tem. Given this definition of , we found that
, , and
. (Thus 52.85%
of all test sentences had improved translations un-
der the baseline system, 36.4% of all sentences had
worse translations, and 10.75% of all sentences had
the same quality as before.) If our definition of
was correct, these values for and would be
significant at the level
</bodyText>
<page confidence="0.934165">
538
</page>
<bodyText confidence="0.99264171875">
R: the current difficulties should encourage us to redouble our efforts to promote cooperation in the euro-mediterranean
framework.
C: the current problems should spur us to intensify our efforts to promote cooperation within the framework of the europa-
mittelmeerprozesses.
the current problems should spur us, our efforts to promote cooperation within the framework of the europa-
mittelmeerprozesses to be intensified.
R: propaganda of any sort will not get us anywhere.
with any propaganda to lead to nothing.
with any of the propaganda is nothing to do here.
R: yet we would point out again that it is absolutely vital to guarantee independent financial control.
however, we would like once again refer to the absolute need for the independence of the financial control.
however, we would like to once again to the absolute need for the independence of the financial control out.
R: i cannot go along with the aims mr brok hopes to achieve via his report.
i cannot agree with the intentions of mr brok in his report persecuted.
i can intentions, mr brok in his report is not agree with.
R: on method, i think the nice perspectives, from that point of view, are very interesting.
what the method is concerned, i believe that the prospects of nice are on this point very interesting.
what the method, i believe that the prospects of nice in this very interesting point.
R: secondly, without these guarantees, the fall in consumption will impact negatively upon the entire industry.
and, secondly, the collapse of consumption without these guarantees will have a negative impact on the whole sector.
and secondly, the collapse of the consumption of these guarantees without a negative impact on the whole sector.
R: awarding a diploma in this way does not contravene uk legislation and can thus be deemed legal.
since the award of a diploms is not in this form contrary to the legislation of the united kingdom, it can be recognised
as legitimate.
since the award of a diploms in this form not contrary to the legislation of the united kingdom is, it can be recognised
as legitimate.
R: i should like to comment briefly on the directive concerning undesirable substances in products and animal nutrition.
i would now like to comment briefly on the directive on undesirable substances and products of animal feed.
i would now like to briefly to the directive on undesirable substances and products in the nutrition of them.
R: it was then clearly shown that we can in fact tackle enlargement successfully within the eu ’s budget.
at that time was clear that we can cope with enlargement, in fact, within the framework drawn by the eu budget.
B: at that time was clear that we actually enlargement within the framework able to cope with the eu budget, the drawn.
</bodyText>
<figureCaption confidence="0.92574325">
Figure 3: Examples where annotator 1 judged the reordered system to give an improved translation when compared to the baseline
system. Recall that annotator 1 judged 40 out of 100 translations to fall into this category. These examples were chosen at random
from these 40 examples, and are presented in random order. R is the human (reference) translation; C is the translation from the
system with reordering; B is the output from the baseline system.
</figureCaption>
<sectionHeader confidence="0.996962" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999320363636364">
Alshawi, H. (1996). Head automata and bilingual tiling: Trans-
lation with minimal representations (invited talk). In Pro-
ceedings ofACL 1996.
Berger, A. L., Pietra, S. A. D., and Pietra, V. J. D. (1996). A
maximum entropy approach to natural language processing.
Computational Linguistics, 22(1):39–69.
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., and Mercer, R. L.
(1993). The mathematics of statistical machine translation.
Computational Linguistics, 19(2):263–313.
Charniak, E., Knight, K., and Yamada, K. (2003). Syntax-based
language models for statistical machine translation. In Pro-
ceedings of the MT Summit IX.
Dubey, A. and Keller, F. (2003). Parsing german with sister-
head dependencies. In Proceedings ofACL 2003.
Efron, B. and Tibshirani, R. J. (1993). An Introduction to the
Bootstrap. Springer-Verlag.
Galley, M., Hopkins, M., Knight, K., and Marcu, D. (2004).
What’s in a translation rule? In Proceedings ofHLT-NAACL
2004.
Gildea, D. (2003). Loosely tree-based alignment for machine
translation. In Proceedings ofACL 2003.
Graehl, J. and Knight, K. (2004). Training tree transducers. In
Proceedings of HLT-NAACL 2004.
Koehn, P. (2004). Statistical significance tests for machine
translation evaluation. In Lin, D. and Wu, D., editors, Pro-
ceedings ofEMNLP 2004.
Koehn, P. and Knight, K. (2003). Feature-rich statistical trans-
lation of noun phrases. In Hinrichs, E. and Roth, D., editors,
Proceedings ofACL 2003, pages 311–318.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase
based translation. In Proceedings ofHLT-NAACL 2003.
Lehmann, E. L. (1986). Testing Statistical Hypotheses (Second
Edition). Springer-Verlag.
</reference>
<page confidence="0.995639">
539
</page>
<bodyText confidence="0.9984906875">
R: on the other hand non-british hauliers pay nothing when travelling in britain.
C: on the other hand, foreign kraftverkehrsunternehmen figures anything if their lorries travelling through the united king-
dom.
on the other hand, figures foreign kraftverkehrsunternehmen nothing if their lorries travel by the united kingdom.
R: i think some of the observations made by the consumer organisations are included in the commission ’s proposal.
i think some of these considerations, the social organisations will be addressed in the commission proposal.
i think some of these considerations, the social organisations will be taken up in the commission ’s proposal.
R: during the nineties the commission produced several recommendations on the issue but no practical solutions were
found.
in the nineties, there were a number of recommendations to the commission on this subject to achieve without, however,
concrete results.
in the 1990s, there were a number of recommendations to the commission on this subject without, however, to achieve
concrete results.
R: now, in a panic, you resign yourselves to action.
in the current paniksituation they must react necessity.
in the current paniksituation they must of necessity react.
R: the human aspect of the whole issue is extremely important.
the whole problem is also a not inconsiderable human side.
the whole problem also has a not inconsiderable human side.
R: in this area we can indeed talk of a european public prosecutor.
and we are talking here, in fact, a european public prosecutor.
and here we can, in fact speak of a european public prosecutor.
R: we have to make decisions in nice to avoid endangering enlargement, which is our main priority.
we must take decisions in nice, enlargement to jeopardise our main priority.
we must take decisions in nice, about enlargement be our priority, not to jeopardise.
R: we will therefore vote for the amendments facilitating its use.
in this sense, we will vote in favour of the amendments which, in order to increase the use of.
in this sense we vote in favour of the amendments which seek to increase the use of.
R: the fvo mission report mentioned refers specifically to transporters whose journeys originated in ireland.
the quoted report of the food and veterinary office is here in particular to hauliers, whose rushed into shipments of
ireland.
B: the quoted report of the food and veterinary office relates in particular, to hauliers, the transport of rushed from ireland.
</bodyText>
<figureCaption confidence="0.978806">
Figure 4: Examples where annotator 1 judged the reordered system to give a worse translation than the baseline system. Recall
that annotator 1 judged 20 out of 100 translations to fall into this category. These examples were chosen at random from these 20
examples, and are presented in random order. R is the human (reference) translation; C is the translation from the system with
reordering; B is the output from the baseline system.
</figureCaption>
<reference confidence="0.975952">
Marcu, D. and Wong, W. (2002). A phrase-based, joint proba-
bility model for statistical machine translation. In Proceed-
ings of EMNLP 2002.
Melamed, I. D. (2004). Statistical machine translation by pars-
ing. In Proceedings ofACL 2004.
Niessen, S. and Ney, H. (2004). Statistical machine translation
with scarce resources using morpho-syntactic information.
Computational Linguistics, 30(2):181–204.
Och, F. J. (2003). Minimum error rate training in statistical
machine translation. In Proceedings ofACL 2003.
Och, F. J., Gildea, D., Khudanpur, S., Sarkar, A., Yamada, K.,
Fraser, A., Kumar, S., Shen, L., Smith, D., Eng, K., Jain, V.,
Jin, Z., and Radev, D. (2004). A smorgasbord of features
for statistical machine translation. In Proceedings of HLT-
NAACL 2004.
Och, F. J., Tillmann, C., and Ney, H. (1999). Improved align-
ment models for statistical machine translation. In Proceed-
ings of EMNLP 1999, pages 20–28.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002).
BLEU: a method for automatic evaluation of machine trans-
lation. In Proceedings ofACL 2002.
Shen, L., Sarkar, A., and Och, F. J. (2004). Discriminative
reranking for machine translation. In Proceedings of HLT-
NAACL 2004.
Wasserman, L. (2004). All of Statistics. Springer-Verlag.
Wu, D. (1997). Stochastic inversion transduction grammars and
bilingual parsing of parallel corpora. Computational Lin-
guistics, 23(3).
Xia, F. and McCord, M. (2004). Improving a statistical MT
system with automatically learned rewrite patterns. In Pro-
ceedings of Coling 2004.
Yamada, K. and Knight, K. (2001). A syntax-based statistical
translation model. In Proceedings ofACL 2001.
Zhang, Y. and Vogel, S. (2004). Measuring confidence intervals
for the machine translation evaluation metrics. In Proceed-
ings of the Tenth Conference on Theoretical and Method-
ological Issues in Machine Translation (TMI).
</reference>
<page confidence="0.997002">
540
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.926421">
<title confidence="0.99989">Clause Restructuring for Statistical Machine Translation</title>
<author confidence="0.999511">Michael Collins Philipp Koehn Ivona Kuˇcerov´a</author>
<affiliation confidence="0.9848215">MIT CSAIL School of Informatics MIT Linguistics Department of Edinburgh</affiliation>
<email confidence="0.997258">pkoehn@inf.ed.ac.uk</email>
<abstract confidence="0.996075266666667">We describe a method for incorporating syntactic information in statistical machine translation systems. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the parse tree, effectively reordering the surface string on the source language side of the translation system. The goal of this step is to recover an underlying word order that is closer to the target language word-order than the original string. The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>Head automata and bilingual tiling: Translation with minimal representations (invited talk).</title>
<date>1996</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2192" citStr="Alshawi, 1996" startWordPosition="326" endWordPosition="328">e-based systems currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the re</context>
<context position="6830" citStr="Alshawi, 1996" startWordPosition="1086" endWordPosition="1087">English words are added to the hypothesized string, and one or more consecutive German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterization</context>
</contexts>
<marker>Alshawi, 1996</marker>
<rawString>Alshawi, H. (1996). Head automata and bilingual tiling: Translation with minimal representations (invited talk). In Proceedings ofACL 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="8914" citStr="Berger et al., 1996" startWordPosition="1418" endWordPosition="1421">) was due to the addition of IBM Model 1 translation probabilities, a non-syntactic feature. An alternative use of syntactic information is to employ an existing statistical parsing model as a language model within an SMT system. See (Charniak et al., 2003) for an approach of this form, which shows improvements in accuracy over a baseline system. 2.1.3 Research on Preprocessing Approaches Our approach involves a preprocessing step, where sentences in the language being translated are modified before being passed to an existing phrasebased translation system. A number of other re532 searchers (Berger et al., 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods. (Berger et al., 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g., conflit d’int´erˆet). This was a relatively limited study, concentrating on this one syntactic phenomenon which involves relatively local transformations (a parser was not required in this study). (Niessen and Ney, 2004) describe a method that combines morphologically–split verbs in German, and also reorders questions in English and German. Our method goes beyond this approach </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A. L., Pietra, S. A. D., and Pietra, V. J. D. (1996). A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1401" citStr="Brown et al., 1993" startWordPosition="209" endWordPosition="212">oach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement. 1 Introduction Recent research on statistical machine translation (SMT) has lead to the development of phrasebased systems (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003). These methods go beyond the original IBM machine translation models (Brown et al., 1993), by allowing multi-word units (“phrases”) in one language to be translated directly into phrases in another language. A number of empirical evaluations have suggested that phrase-based systems currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different lan</context>
<context position="5158" citStr="Brown et al., 1993" startWordPosition="807" endWordPosition="810"> translation from German to English in the Europarl corpus. Source language sentences are reordered in test data, and also in training data that is used by the underlying phrasebased system. Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al., 2003) which has been shown in the past to be a highly competitive SMT system. 2 Background 2.1 Previous Work 2.1.1 Research on Phrase-Based SMT The original work on statistical machine translation was carried out by researchers at IBM (Brown et al., 1993). More recently, phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003) have been proposed as a highly successful alternative to the IBM models. Phrase-based models generalize the original IBM models by allowing multiple words in one language to correspond to multiple words in another language. For example, we might have a translation entry specifying that I will in English is a likely translation for Ich werde in German. In this paper we use the phrase-based system of (Koehn et al., 2003) as our underlying model. This approach first uses the original IBM models to de</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., and Mercer, R. L. (1993). The mathematics of statistical machine translation. Computational Linguistics, 19(2):263–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>K Knight</author>
<author>K Yamada</author>
</authors>
<title>Syntax-based language models for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the MT Summit IX.</booktitle>
<contexts>
<context position="8552" citStr="Charniak et al., 2003" startWordPosition="1362" endWordPosition="1365">ehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004; Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains: for example the majority of the gain in performance in the experiments in (Och et al., 2004) was due to the addition of IBM Model 1 translation probabilities, a non-syntactic feature. An alternative use of syntactic information is to employ an existing statistical parsing model as a language model within an SMT system. See (Charniak et al., 2003) for an approach of this form, which shows improvements in accuracy over a baseline system. 2.1.3 Research on Preprocessing Approaches Our approach involves a preprocessing step, where sentences in the language being translated are modified before being passed to an existing phrasebased translation system. A number of other re532 searchers (Berger et al., 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods. (Berger et al., 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g., conflit d’int´erˆe</context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>Charniak, E., Knight, K., and Yamada, K. (2003). Syntax-based language models for statistical machine translation. In Proceedings of the MT Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dubey</author>
<author>F Keller</author>
</authors>
<title>Parsing german with sisterhead dependencies.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="18168" citStr="Dubey and Keller, 2003" startWordPosition="2913" endWordPosition="2916">so that you them perhaps in the vote adopt can.) Reordered sentence: Ich werde aushaendigen Ihnen die entsprechenden Anmerkungen, damit Sie koennen uebernehmen das eventuell bei der Abstimmung. (I will pass on to you the corresponding comments, so that you can adopt them perhaps in the vote.) Figure 2: An example of the reordering process, showing the original German sentence and the sentence after reordering. 3 Clause Restructuring We now describe the method we use for reordering German sentences. As a first step in the reordering process, we parse the sentence using the parser described in (Dubey and Keller, 2003). The second step is to apply a sequence of rules that reorder the German sentence depending on the parse tree structure. See Figure 2 for an example German sentence before and after the reordering step. In the reordering phase, each of the following six restructuring steps were applied to a German parse tree, in sequence (see table 1 also, for examples of the reordering steps): [1] Verb initial In any verb phrase (i.e., phrase with label VP-...) find the head of the phrase (i.e., the child with label -HD) and move it into the initial position within the verb phrase. For example, in the parse </context>
</contexts>
<marker>Dubey, Keller, 2003</marker>
<rawString>Dubey, A. and Keller, F. (2003). Parsing german with sisterhead dependencies. In Proceedings ofACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Efron</author>
<author>R J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1993</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="29651" citStr="Efron and Tibshirani, 1993" startWordPosition="4832" endWordPosition="4835"> baseline model, and where itself is translated by the reordered model. We then define If If If Note that strictly speaking, this definition of is not valid, as it depends on the entire set of sample points rather than alone. However, we believe it is a reasonable approximation to an ideal 2The lack of per-sentence scores means that it is not possible to apply standard statistical tests such as the sign test or the ttest (which would test the hypothesis , where is the expected value under ). Note that previous work (Koehn, 2004; Zhang and Vogel, 2004) has suggested the use of bootstrap tests (Efron and Tibshirani, 1993) for the calculation of confidence intervals for Bleu scores. (Koehn, 2004) gives empirical evidence that these give accurate estimates for Bleu statistics. However, correctness of the bootstrap method relies on some technical properties of the statistic (e.g., Bleu scores) being used (e.g., see (Wasserman, 2004) theorem 8.3); (Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether Bleu scores meet any such criteria, which makes us uncertain of their correctness when applied to Bleu scores. . We can also calculate confidence intervals for the results. Define to be the probability that the </context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Efron, B. and Tibshirani, R. J. (1993). An Introduction to the Bootstrap. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>M Hopkins</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings ofHLT-NAACL</booktitle>
<contexts>
<context position="6941" citStr="Galley et al., 2004" startWordPosition="1102" endWordPosition="1105">ed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have not shown significant gains in accuracy in compa</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Galley, M., Hopkins, M., Knight, K., and Marcu, D. (2004). What’s in a translation rule? In Proceedings ofHLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
</authors>
<title>Loosely tree-based alignment for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2241" citStr="Gildea, 2003" startWordPosition="335" endWordPosition="336">he–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reordering the su</context>
<context position="6879" citStr="Gildea, 2003" startWordPosition="1094" endWordPosition="1095">, and one or more consecutive German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these</context>
</contexts>
<marker>Gildea, 2003</marker>
<rawString>Gildea, D. (2003). Loosely tree-based alignment for machine translation. In Proceedings ofACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Graehl</author>
<author>K Knight</author>
</authors>
<title>Training tree transducers.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<contexts>
<context position="2281" citStr="Graehl and Knight, 2004" startWordPosition="339" endWordPosition="342"> translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reordering the surface string on the source language side</context>
<context position="6919" citStr="Graehl and Knight, 2004" startWordPosition="1098" endWordPosition="1101"> German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have not shown significant gain</context>
</contexts>
<marker>Graehl, Knight, 2004</marker>
<rawString>Graehl, J. and Knight, K. (2004). Training tree transducers. In Proceedings of HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>Proceedings ofEMNLP</booktitle>
<editor>In Lin, D. and Wu, D., editors,</editor>
<contexts>
<context position="29557" citStr="Koehn, 2004" startWordPosition="4819" endWordPosition="4820">efine to be the Bleu score when all sentences other than are translated by the baseline model, and where itself is translated by the reordered model. We then define If If If Note that strictly speaking, this definition of is not valid, as it depends on the entire set of sample points rather than alone. However, we believe it is a reasonable approximation to an ideal 2The lack of per-sentence scores means that it is not possible to apply standard statistical tests such as the sign test or the ttest (which would test the hypothesis , where is the expected value under ). Note that previous work (Koehn, 2004; Zhang and Vogel, 2004) has suggested the use of bootstrap tests (Efron and Tibshirani, 1993) for the calculation of confidence intervals for Bleu scores. (Koehn, 2004) gives empirical evidence that these give accurate estimates for Bleu statistics. However, correctness of the bootstrap method relies on some technical properties of the statistic (e.g., Bleu scores) being used (e.g., see (Wasserman, 2004) theorem 8.3); (Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether Bleu scores meet any such criteria, which makes us uncertain of their correctness when applied to Bleu scores. . We c</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Koehn, P. (2004). Statistical significance tests for machine translation evaluation. In Lin, D. and Wu, D., editors, Proceedings ofEMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Feature-rich statistical translation of noun phrases.</title>
<date>2003</date>
<booktitle>Proceedings ofACL 2003,</booktitle>
<pages>311--318</pages>
<editor>In Hinrichs, E. and Roth, D., editors,</editor>
<contexts>
<context position="7681" citStr="Koehn and Knight, 2003" startWordPosition="1213" endWordPosition="1216">guages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have not shown significant gains in accuracy in comparison to phrase-based systems. Reranking methods have also been proposed as a method for using syntactic information (Koehn and Knight, 2003; Och et al., 2004; Shen et al., 2004). In these approaches a baseline system is used to generate -best output. Syntactic features are then used in a second model that reranks the -best lists, in an attempt to improve over the baseline approach. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004; Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains: for example the majority of the gain in performance in the experiments in (Oc</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Koehn, P. and Knight, K. (2003). Feature-rich statistical translation of noun phrases. In Hinrichs, E. and Roth, D., editors, Proceedings ofACL 2003, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase based translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofHLT-NAACL</booktitle>
<contexts>
<context position="1311" citStr="Koehn et al., 2003" startWordPosition="194" endWordPosition="197"> is closer to the target language word-order than the original string. The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement. 1 Introduction Recent research on statistical machine translation (SMT) has lead to the development of phrasebased systems (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003). These methods go beyond the original IBM machine translation models (Brown et al., 1993), by allowing multi-word units (“phrases”) in one language to be translated directly into phrases in another language. A number of empirical evaluations have suggested that phrase-based systems currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena duri</context>
<context position="4908" citStr="Koehn et al., 2003" startWordPosition="763" endWordPosition="766">to you the corresponding comments, so that you can adopt them perhaps in the vote. 531 Proceedings of the 43rd Annual Meeting of the ACL, pages 531–540, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics We applied our approach to translation from German to English in the Europarl corpus. Source language sentences are reordered in test data, and also in training data that is used by the underlying phrasebased system. Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al., 2003) which has been shown in the past to be a highly competitive SMT system. 2 Background 2.1 Previous Work 2.1.1 Research on Phrase-Based SMT The original work on statistical machine translation was carried out by researchers at IBM (Brown et al., 1993). More recently, phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003) have been proposed as a highly successful alternative to the IBM models. Phrase-based models generalize the original IBM models by allowing multiple words in one language to correspond to multiple words in another language. For example, we might have a</context>
<context position="15569" citStr="Koehn et al., 2003" startWordPosition="2500" endWordPosition="2503">of factors, including a cost of skipping over a phrase of length 4 (i.e., Ihnen die entsprechenden Anmerkungen) in the German string. The ability to penalise “skips” of this type, and the potential to model multi-word phrases, are essentially the main strategies that the phrase-based system is able to employ when modeling differing word-order across different languages. In practice, when training the parameters of an SMT system, for example using the discriminative methods of (Och, 2003), the cost for skips of this kind is typically set to a very high value. In experiments with the system of (Koehn et al., 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. In summary, phrase-based systems have relatively limited potential to model word-order differences between different languages. The reordering stage described in this paper attempts to modify the source language (e.g., German) in such a way that its word order is very similar to that seen in the target language (e.g., English). In an ideal approach, the resulting tr</context>
<context position="23499" citStr="Koehn et al., 2003" startWordPosition="3782" endWordPosition="3785">As a final step, we move negative particles. If a clause dominates both a finite and infinitival verb, as well as a negative particle (i.e., a word tagged as PTKNEG), then the negative particle is moved to directly follow the finite verb. As an example, the previous example now has the negative particle nicht moved, to give the following clause structure: S PPER-SB Wir VMFIN-HD konnten PTKNEG-NG nicht VVINF-HD einreichen PPER-OA es AP-MO ADV-MO mehr ADJD-HD rechtzeitig 4 Experiments This section describes experiments with the reordering approach. Our baseline is the phrase-based MT system of (Koehn et al., 2003). We trained this system on the Europarl corpus, which consists of 751,088 sentence pairs with 15,256,792 German words and 16,052,269 English words. Translation performance is measured on a 2000 sentence test set from a different part of the Europarl corpus, with average sentence length of 28 words. We use BLEU scores (Papineni et al., 2002) to measure translation accuracy. We applied our re536 Annotator 2 Annotator 1 R B E R 33 2 5 B 2 13 5 E 9 4 27 Table 2: Table showing the level of agreement between two annotators on 100 translation judgements. R gives counts corresponding to translations </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase based translation. In Proceedings ofHLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E L Lehmann</author>
</authors>
<title>Testing Statistical Hypotheses (Second Edition).</title>
<date>1986</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="27082" citStr="Lehmann, 1986" startWordPosition="4386" endWordPosition="4387">nnotator 1. We include these examples to give a qualitative impression of the differences between the baseline and reordered system. Our (no doubt subjective) impression is that the cases in figure 3 are more clear cut instances of translation improvements, but we leave the reader to make his/her own judgement on this point. 4.2 Statistical Significance We now describe statistical significance tests for our results. We believe that applying significance tests to Bleu scores is a subtle issue, for this reason we go into some detail in this section. We used the sign test (e.g., see page 166 of (Lehmann, 1986)) to test the statistical significance of our results. For a source sentence , the sign test requires a function that is defined as follows: If reordered system produces a better translation for than the baseline If baseline produces a better translation for than the reordered system. If the two systems produce equal quality translations on We assume that sentences are drawn from some underlying distribution , and that the test set consists of independently, identically distributed (IID) sentences from this distribution. We can define the following probabilities: Probability Probability (2) wh</context>
</contexts>
<marker>Lehmann, 1986</marker>
<rawString>Lehmann, E. L. (1986). Testing Statistical Hypotheses (Second Edition). Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>W Wong</author>
</authors>
<title>A phrase-based, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="1290" citStr="Marcu and Wong, 2002" startWordPosition="190" endWordPosition="193">rlying word order that is closer to the target language word-order than the original string. The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement. 1 Introduction Recent research on statistical machine translation (SMT) has lead to the development of phrasebased systems (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003). These methods go beyond the original IBM machine translation models (Brown et al., 1993), by allowing multi-word units (“phrases”) in one language to be translated directly into phrases in another language. A number of empirical evaluations have suggested that phrase-based systems currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modelin</context>
<context position="5234" citStr="Marcu and Wong, 2002" startWordPosition="819" endWordPosition="822"> sentences are reordered in test data, and also in training data that is used by the underlying phrasebased system. Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al., 2003) which has been shown in the past to be a highly competitive SMT system. 2 Background 2.1 Previous Work 2.1.1 Research on Phrase-Based SMT The original work on statistical machine translation was carried out by researchers at IBM (Brown et al., 1993). More recently, phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003) have been proposed as a highly successful alternative to the IBM models. Phrase-based models generalize the original IBM models by allowing multiple words in one language to correspond to multiple words in another language. For example, we might have a translation entry specifying that I will in English is a likely translation for Ich werde in German. In this paper we use the phrase-based system of (Koehn et al., 2003) as our underlying model. This approach first uses the original IBM models to derive word-to-word alignments in the corpus of example translations. Heuristi</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Marcu, D. and Wong, W. (2002). A phrase-based, joint probability model for statistical machine translation. In Proceedings of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Statistical machine translation by parsing.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2256" citStr="Melamed, 2004" startWordPosition="337" endWordPosition="338">istical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reordering the surface string on</context>
<context position="6894" citStr="Melamed, 2004" startWordPosition="1096" endWordPosition="1097">ore consecutive German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have n</context>
</contexts>
<marker>Melamed, 2004</marker>
<rawString>Melamed, I. D. (2004). Statistical machine translation by parsing. In Proceedings ofACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Niessen</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morpho-syntactic information.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="8937" citStr="Niessen and Ney, 2004" startWordPosition="1422" endWordPosition="1425">tion of IBM Model 1 translation probabilities, a non-syntactic feature. An alternative use of syntactic information is to employ an existing statistical parsing model as a language model within an SMT system. See (Charniak et al., 2003) for an approach of this form, which shows improvements in accuracy over a baseline system. 2.1.3 Research on Preprocessing Approaches Our approach involves a preprocessing step, where sentences in the language being translated are modified before being passed to an existing phrasebased translation system. A number of other re532 searchers (Berger et al., 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods. (Berger et al., 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g., conflit d’int´erˆet). This was a relatively limited study, concentrating on this one syntactic phenomenon which involves relatively local transformations (a parser was not required in this study). (Niessen and Ney, 2004) describe a method that combines morphologically–split verbs in German, and also reorders questions in English and German. Our method goes beyond this approach in several respects, fo</context>
</contexts>
<marker>Niessen, Ney, 2004</marker>
<rawString>Niessen, S. and Ney, H. (2004). Statistical machine translation with scarce resources using morpho-syntactic information. Computational Linguistics, 30(2):181–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="15442" citStr="Och, 2003" startWordPosition="2476" endWordPosition="2477">t the same time absorbing “aushaendigen” from the German string. The cost of this decoding step will involve a number of factors, including a cost of skipping over a phrase of length 4 (i.e., Ihnen die entsprechenden Anmerkungen) in the German string. The ability to penalise “skips” of this type, and the potential to model multi-word phrases, are essentially the main strategies that the phrase-based system is able to employ when modeling differing word-order across different languages. In practice, when training the parameters of an SMT system, for example using the discriminative methods of (Och, 2003), the cost for skips of this kind is typically set to a very high value. In experiments with the system of (Koehn et al., 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. In summary, phrase-based systems have relatively limited potential to model word-order differences between different languages. The reordering stage described in this paper attempts to modify the source language (e.g., German) in such a way </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings ofACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>D Gildea</author>
<author>S Khudanpur</author>
<author>A Sarkar</author>
<author>K Yamada</author>
<author>A Fraser</author>
<author>S Kumar</author>
<author>L Shen</author>
<author>D Smith</author>
<author>K Eng</author>
<author>V Jain</author>
<author>Z Jin</author>
<author>D Radev</author>
</authors>
<title>A smorgasbord of features for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLTNAACL</booktitle>
<contexts>
<context position="2299" citStr="Och et al., 2004" startWordPosition="343" endWordPosition="346"> their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reordering the surface string on the source language side of the translatio</context>
<context position="7699" citStr="Och et al., 2004" startWordPosition="1217" endWordPosition="1220">roaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have not shown significant gains in accuracy in comparison to phrase-based systems. Reranking methods have also been proposed as a method for using syntactic information (Koehn and Knight, 2003; Och et al., 2004; Shen et al., 2004). In these approaches a baseline system is used to generate -best output. Syntactic features are then used in a second model that reranks the -best lists, in an attempt to improve over the baseline approach. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004; Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains: for example the majority of the gain in performance in the experiments in (Och et al., 2004) wa</context>
</contexts>
<marker>Och, Gildea, Khudanpur, Sarkar, Yamada, Fraser, Kumar, Shen, Smith, Eng, Jain, Jin, Radev, 2004</marker>
<rawString>Och, F. J., Gildea, D., Khudanpur, S., Sarkar, A., Yamada, K., Fraser, A., Kumar, S., Shen, L., Smith, D., Eng, K., Jain, V., Jin, Z., and Radev, D. (2004). A smorgasbord of features for statistical machine translation. In Proceedings of HLTNAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>20--28</pages>
<contexts>
<context position="1268" citStr="Och et al., 1999" startWordPosition="186" endWordPosition="189">to recover an underlying word order that is closer to the target language word-order than the original string. The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement. 1 Introduction Recent research on statistical machine translation (SMT) has lead to the development of phrasebased systems (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003). These methods go beyond the original IBM machine translation models (Brown et al., 1993), by allowing multi-word units (“phrases”) in one language to be translated directly into phrases in another language. A number of empirical evaluations have suggested that phrase-based systems currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial</context>
<context position="5212" citStr="Och et al., 1999" startWordPosition="815" endWordPosition="818">s. Source language sentences are reordered in test data, and also in training data that is used by the underlying phrasebased system. Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al., 2003) which has been shown in the past to be a highly competitive SMT system. 2 Background 2.1 Previous Work 2.1.1 Research on Phrase-Based SMT The original work on statistical machine translation was carried out by researchers at IBM (Brown et al., 1993). More recently, phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Koehn et al., 2003) have been proposed as a highly successful alternative to the IBM models. Phrase-based models generalize the original IBM models by allowing multiple words in one language to correspond to multiple words in another language. For example, we might have a translation entry specifying that I will in English is a likely translation for Ich werde in German. In this paper we use the phrase-based system of (Koehn et al., 2003) as our underlying model. This approach first uses the original IBM models to derive word-to-word alignments in the corpus of example </context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Och, F. J., Tillmann, C., and Ney, H. (1999). Improved alignment models for statistical machine translation. In Proceedings of EMNLP 1999, pages 20–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="23842" citStr="Papineni et al., 2002" startWordPosition="3838" endWordPosition="3841">clause structure: S PPER-SB Wir VMFIN-HD konnten PTKNEG-NG nicht VVINF-HD einreichen PPER-OA es AP-MO ADV-MO mehr ADJD-HD rechtzeitig 4 Experiments This section describes experiments with the reordering approach. Our baseline is the phrase-based MT system of (Koehn et al., 2003). We trained this system on the Europarl corpus, which consists of 751,088 sentence pairs with 15,256,792 German words and 16,052,269 English words. Translation performance is measured on a 2000 sentence test set from a different part of the Europarl corpus, with average sentence length of 28 words. We use BLEU scores (Papineni et al., 2002) to measure translation accuracy. We applied our re536 Annotator 2 Annotator 1 R B E R 33 2 5 B 2 13 5 E 9 4 27 Table 2: Table showing the level of agreement between two annotators on 100 translation judgements. R gives counts corresponding to translations where an annotator preferred the reordered system; B signifies that the annotator preferred the baseline system; E means an annotator judged the two systems to give equal quality translations. ordering method to both the training and test data, and retrained the system on the reordered training data. The BLEU score for the new system was 26.</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). BLEU: a method for automatic evaluation of machine translation. In Proceedings ofACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>A Sarkar</author>
<author>F J Och</author>
</authors>
<title>Discriminative reranking for machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLTNAACL</booktitle>
<contexts>
<context position="7719" citStr="Shen et al., 2004" startWordPosition="1221" endWordPosition="1224">f “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT. As yet, these systems have not shown significant gains in accuracy in comparison to phrase-based systems. Reranking methods have also been proposed as a method for using syntactic information (Koehn and Knight, 2003; Och et al., 2004; Shen et al., 2004). In these approaches a baseline system is used to generate -best output. Syntactic features are then used in a second model that reranks the -best lists, in an attempt to improve over the baseline approach. (Koehn and Knight, 2003) apply a reranking approach to the sub-task of noun-phrase translation. (Och et al., 2004; Shen et al., 2004) describe the use of syntactic features in reranking the output of a full translation system, but the syntactic features give very small gains: for example the majority of the gain in performance in the experiments in (Och et al., 2004) was due to the additio</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Shen, L., Sarkar, A., and Och, F. J. (2004). Discriminative reranking for machine translation. In Proceedings of HLTNAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Wasserman</author>
</authors>
<title>All of Statistics.</title>
<date>2004</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="29965" citStr="Wasserman, 2004" startWordPosition="4880" endWordPosition="4881">eans that it is not possible to apply standard statistical tests such as the sign test or the ttest (which would test the hypothesis , where is the expected value under ). Note that previous work (Koehn, 2004; Zhang and Vogel, 2004) has suggested the use of bootstrap tests (Efron and Tibshirani, 1993) for the calculation of confidence intervals for Bleu scores. (Koehn, 2004) gives empirical evidence that these give accurate estimates for Bleu statistics. However, correctness of the bootstrap method relies on some technical properties of the statistic (e.g., Bleu scores) being used (e.g., see (Wasserman, 2004) theorem 8.3); (Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether Bleu scores meet any such criteria, which makes us uncertain of their correctness when applied to Bleu scores. . We can also calculate confidence intervals for the results. Define to be the probability that the reordered system improves on the baseline system, given that the two systems do not have equal performance. The relative frequency estimate of is . Using a normal approximation (e.g., see Example 6.17 from (Wasserman, 2004)) a 95% confidence interval for a sample size of 1785 is , giving a 95% confidence interval</context>
</contexts>
<marker>Wasserman, 2004</marker>
<rawString>Wasserman, L. (2004). All of Statistics. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="2202" citStr="Wu, 1997" startWordPosition="329" endWordPosition="330"> currently represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting pa</context>
<context position="6840" citStr="Wu, 1997" startWordPosition="1088" endWordPosition="1089">re added to the hypothesized string, and one or more consecutive German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phr</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Wu, D. (1997). Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>M McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<contexts>
<context position="2322" citStr="Xia and McCord, 2004" startWordPosition="347" endWordPosition="350">key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reordering the surface string on the source language side of the translation system. The goal of t</context>
<context position="8960" citStr="Xia and McCord, 2004" startWordPosition="1426" endWordPosition="1429">nslation probabilities, a non-syntactic feature. An alternative use of syntactic information is to employ an existing statistical parsing model as a language model within an SMT system. See (Charniak et al., 2003) for an approach of this form, which shows improvements in accuracy over a baseline system. 2.1.3 Research on Preprocessing Approaches Our approach involves a preprocessing step, where sentences in the language being translated are modified before being passed to an existing phrasebased translation system. A number of other re532 searchers (Berger et al., 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods. (Berger et al., 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g., conflit d’int´erˆet). This was a relatively limited study, concentrating on this one syntactic phenomenon which involves relatively local transformations (a parser was not required in this study). (Niessen and Ney, 2004) describe a method that combines morphologically–split verbs in German, and also reorders questions in English and German. Our method goes beyond this approach in several respects, for example considering p</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Xia, F. and McCord, M. (2004). Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of Coling 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2227" citStr="Yamada and Knight, 2001" startWordPosition="331" endWordPosition="334"> represent the state–of–the–art in statistical machine translation. In spite of their success, a key limitation of phrase-based systems is that they make little or no direct use of syntactic information. It appears likely that syntactic information will be crucial in accurately modeling many phenomena during translation, for example systematic differences between the word order of different languages. For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g., see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al., 2004; Xia and McCord, 2004)). In this paper we describe an approach for the use of syntactic information within phrase-based SMT systems. The approach constitutes a simple, direct method for the incorporation of syntactic information in a phrase–based system, which we will show leads to significant improvements in translation accuracy. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the resulting parse tree, effectively reo</context>
<context position="6865" citStr="Yamada and Knight, 2001" startWordPosition="1090" endWordPosition="1093">o the hypothesized string, and one or more consecutive German words are “absorbed” (i.e., marked as having already been translated—note that each word is absorbed at most once). Each step of this kind has a number of costs: for example, the log probability of the phrase-tophrase correspondance involved, the log probability from a language model, and some “distortion” score indicating how likely it is for the proposed words in the English string to be aligned to the corresponding position in the German string. 2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al., 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages. One class of approaches make use of “bitext” grammars which simultaneously parse both the source and target languages. Another class of approaches make use of syntactic information in the target language alone, effectively transforming the translation problem into a parsing problem. Note that these models have radically different structures and parameterizations from phrase–based models for SMT.</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada, K. and Knight, K. (2001). A syntax-based statistical translation model. In Proceedings ofACL 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Vogel</author>
</authors>
<title>Measuring confidence intervals for the machine translation evaluation metrics.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth Conference on Theoretical and Methodological Issues in Machine Translation (TMI).</booktitle>
<contexts>
<context position="29581" citStr="Zhang and Vogel, 2004" startWordPosition="4821" endWordPosition="4824">he Bleu score when all sentences other than are translated by the baseline model, and where itself is translated by the reordered model. We then define If If If Note that strictly speaking, this definition of is not valid, as it depends on the entire set of sample points rather than alone. However, we believe it is a reasonable approximation to an ideal 2The lack of per-sentence scores means that it is not possible to apply standard statistical tests such as the sign test or the ttest (which would test the hypothesis , where is the expected value under ). Note that previous work (Koehn, 2004; Zhang and Vogel, 2004) has suggested the use of bootstrap tests (Efron and Tibshirani, 1993) for the calculation of confidence intervals for Bleu scores. (Koehn, 2004) gives empirical evidence that these give accurate estimates for Bleu statistics. However, correctness of the bootstrap method relies on some technical properties of the statistic (e.g., Bleu scores) being used (e.g., see (Wasserman, 2004) theorem 8.3); (Koehn, 2004; Zhang and Vogel, 2004) do not discuss whether Bleu scores meet any such criteria, which makes us uncertain of their correctness when applied to Bleu scores. . We can also calculate confid</context>
</contexts>
<marker>Zhang, Vogel, 2004</marker>
<rawString>Zhang, Y. and Vogel, S. (2004). Measuring confidence intervals for the machine translation evaluation metrics. In Proceedings of the Tenth Conference on Theoretical and Methodological Issues in Machine Translation (TMI).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>