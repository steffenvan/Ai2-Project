<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008417">
<title confidence="0.998862">
Extractive Summaries for Educational Science Content
</title>
<author confidence="0.998159">
Sebastian de la Chica, Faisal Ahmad, James H. Martin, Tamara Sumner
</author>
<affiliation confidence="0.997654666666667">
Institute of Cognitive Science
Department of Computer Science
University of Colorado at Boulder
</affiliation>
<address confidence="0.606093">
sebastian.delachica, faisal.ahmad, james.martin,
</address>
<email confidence="0.987149">
tamara.sumner@colorado.edu
</email>
<sectionHeader confidence="0.998592" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99967175">
This paper describes an extractive summarizer
for educational science content called
COGENT. COGENT extends MEAD based
on strategies elicited from an empirical study
with domain and instructional experts.
COGENT implements a hybrid approach inte-
grating both domain independent sentence
scoring features and domain-aware features.
Initial evaluation results indicate that
COGENT outperforms existing summarizers
and generates summaries that closely resem-
ble those generated by human experts.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998752">
Knowledge maps consist of nodes containing rich
concept descriptions interconnected using a limited
set of relationship types (Holley and Dansereau,
1984). Learning research indicates that knowledge
maps may be useful for learners to understand the
macro-level structure of an information space
(O&apos;Donnell et al., 2002). Knowledge maps have
also emerged as an effective computational infra-
structure to support the automated generation of
conceptual browsers. Such conceptual browsers
appear to allow students to focus on the science
content of large educational digital libraries (Sum-
ner et al., 2003), such as the Digital Library for
Earth System Education (DLESE.org). Knowledge
maps have also shown promise as domain and stu-
dent knowledge representations to support person-
alized learning interactions (de la Chica et al.,
2008).
In this paper we describe our progress towards
the generation of science concept inventories as
summaries of digital library collections. Such in-
ventories provide the basis for the construction of
knowledge maps useful both as computational
knowledge representations and as learning re-
sources for presentation to the student.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999968296296296">
Our work is informed by efforts to automate the
acquisition of ontology concepts from text. On-
toLearn extracts candidate domain terms from texts
using a syntactic parse and updates an existing on-
tology with the identified concepts and relation-
ships (Navigli and Velardi, 2004). Knowledge
Puzzle focuses on n-gram identification to produce
a list of candidate terms pruned using information
extraction techniques to derive the ontology
(Zouaq et al., 2007). Lin and Pantel (2002) dis-
cover concepts using clustering by committee to
group terms into conceptually related clusters.
These approaches produce ontologies of very fine
granularity and therefore graphs that may not be
suitable for presentation to a student.
Multi-document summarization (MDS) re-
search also informs our work. XDoX analyzes
large document sets to extract important themes
using n-gram scoring and clustering (Hardy et al.,
2002). Topic representation and topic themes have
also served as the basis for the exploration of
promising MDS techniques (Harabagiu and Laca-
tusu, 2005). Finally, MEAD is a widely used MDS
and evaluation platform (Radev et al., 2000).
While all these systems have produced promising
results in automated evaluations, none have di-
rectly targeted educational content collections.
</bodyText>
<page confidence="0.992958">
17
</page>
<affiliation confidence="0.278074">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 17–20,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</affiliation>
<sectionHeader confidence="0.986605" genericHeader="method">
3 Empirical Study
</sectionHeader>
<bodyText confidence="0.999914625">
We have conducted a study to capture how human
experts processed digital library resources to create
a domain knowledge map. Four geology and in-
structional design experts selected 20 resources
from DLESE to construct a knowledge map on
earthquakes and plates tectonics for high school
age learners. The resulting knowledge map con-
sists of 564 concepts and 578 relationships.
</bodyText>
<figureCaption confidence="0.994377">
Figure 1. Expert knowledge map excerpt
</figureCaption>
<bodyText confidence="0.999608636363636">
The concepts include 7,846 words, or 5% of
the resources. Our experts relied on copying-and-
pasting (58%) and paraphrasing (37%) to create
most concepts. Only 5% of the concepts could not
be traced directly to the original resources. Rela-
tionship types were used in a Zipf-like distribution
with the top 2 relationship types each accounting
for more than 10% of all relationships: elabora-
tions (19%) and examples (14%).
Analysis by an independent instructional expert
indicates that this knowledge map provides ade-
quate coverage of nationally-recognized educa-
tional goals on earthquakes and plate tectonics for
high school learners using the American Associa-
tion for the Advancement of Science (AAAS)
Benchmarks (Project 2061, 1993).
Verbal protocol analysis shows that all experts
used external sources to create the knowledge map,
including their own expertise, other digital library
resources, and the National Science Education
Standards (NSES), a comprehensive collection of
nationally-recognized science learning goals for K-
12 students (National Research Council, 1996).
We have examined sentence extraction agree-
ment between experts using the prevalence-
adjusted bias-adjusted (PABA) kappa to account
for prevalence of judgments and conflicting biases
amongst experts (Byrt et al., 1993). The average
PABA-kappa value of 0.62 indicates that experts
substantially agree on sentence extraction from
digital library resources. This level of agreement
suggests that these concepts may serve as the ref-
erence summary to evaluate our system.
</bodyText>
<sectionHeader confidence="0.999106" genericHeader="method">
4 Summarizer for Science Education
</sectionHeader>
<bodyText confidence="0.999987194444445">
We have implemented an extractive summarizer
for educational science content, COGENT, based
on MEAD version 3.11 (Radev et al., 2000).
COGENT complements the default MEAD sen-
tence scoring features with features based on find-
ings from the empirical study. COGENT
represents a hybrid approach integrating bottom-up
(hypertext and content word density) and top-down
(educational standards and gazetteer) features.
We model how human experts used external in-
formation sources with the educational standards
feature. This feature leverages the text of the rele-
vant AAAS Benchmarks and associated NSES.
Each sentence receives a score based on its TFIDF
similarity to the textual contents of these learning
goals and educational standards.
We have developed a feature that reflects the
large number of examples extracted by the experts.
Earth science examples often refer to geographical
locations and geological formations. The gazetteer
feature checks named entities from each sentence
against the Alexandria Digital Library (ADL) Gaz-
etteer (Hill, 2000). A gazetteer is a geo-referencing
resource containing location and type information
about place-names. Each sentence receives a
TFIDF score based on place-name term frequency
and overall uniqueness in the gazetteer. Our as-
sumption is that geographical locations with more
unique names may be more pedagogically relevant.
Based on the intuition that the HTML structure
of a resource reflects relevancy, we have devel-
oped the hypertext feature. This feature computes a
sentence score directly proportional to the HTML
heading level and inversely proportional to the
relative paragraph number within a heading and to
the relative sentence position within a paragraph.
</bodyText>
<page confidence="0.995999">
18
</page>
<bodyText confidence="0.999989055555556">
To promote the extraction of sentences contain-
ing science concepts, we have developed the con-
tent word density feature. This feature computes
the ratio of content to function words in a sentence.
Function words are identified using a stopword list,
and the feature only keeps sentences featuring
more content words than function words.
We compute the final sentence score by adding
the MEAD default feature scores (centroid and
position) to the COGENT feature scores (educa-
tional standards, gazetteer, and hypertext).
COGENT keeps sentences that pass the cut-off
constraints, including the MEAD sentence length
of 9 and COGENT content word density of 50%.
The default MEAD cosine re-ranker eliminates
redundant sentences. Since the experts used 5% of
the total word count in the resources, we produce
summaries of that same length.
</bodyText>
<sectionHeader confidence="0.999559" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99934115">
We have evaluated COGENT by processing the 20
digital library resources used in the empirical study
and comparing the output against the concepts
identified by the experts. Three configurations are
considered: Random, Default, and COGENT. The
Random summary uses MEAD to extract random
sentences. The Default summary uses the MEAD
centroid, position and length default features. Fi-
nally, the COGENT summary extends MEAD with
the COGENT features.
We use ROUGE (Lin, 2004) to assess summary
quality using common n-gram counts and longest
common subsequence (LCS) measures. We report
on ROUGE-1 (unigrams), ROUGE-2 (bigrams),
ROUGE W-1.2 (weighted LCS), and ROUGE-S*
(skip bigrams) as they have been shown to corre-
late well with human judgments for longer multi-
document summaries (Lin, 2004). Table 1 shows
the results for recall (R), precision (P), and bal-
anced f-measure (F).
</bodyText>
<table confidence="0.997148785714286">
Random Default COGENT
R-1 R 0.4855 0.4976 0.6073
P 0.5026 0.5688 0.6034
F 0.4939 0.5308 0.6054
R-2 R 0.0972 0.1321 0.1907
P 0.1006 0.1510 0.1895
F 0.0989 0.1409 0.1901
R-W-1.2 R 0.0929 0.0951 0.1185
P 0.1533 0.1733 0.1877
F 0.1157 0.1228 0.1453
Random Default COGENT
R-S* R 0.2481 0.2620 0.3820
P 0.2657 0.3424 0.3772
F 0.2566 0.2969 0.3796
</table>
<tableCaption confidence="0.903753">
Table 1. Quality evaluation results
Table 1 indicates that COGENT consistently
</tableCaption>
<bodyText confidence="0.991485047619048">
outperforms the Random and Default summaries.
These results indicate the promise of our approach
to generate extractive summaries of educational
science content. Given our interest in generating a
pedagogically effective domain knowledge map,
we have also conducted a content-centric evalua-
tion.
To characterize the COGENT summary con-
tents, one of the authors manually constructed a
summary corresponding to the best case output for
an extractive summarizer. This Best Case summary
comprises all the sentences from the resources that
align to all the concepts selected by the experts.
This summary comprises 621 sentences consisting
of 13,116 words, or about a 9% word compression.
We use ROUGE-L to examine the union LCS
between the reference and candidate summaries,
thus capturing their linguistic surface structure
similarity. We also use MEAD to report on cosine
similarity. Table 2 shows the results for recall (R),
precision (P), and balanced f-measure (F).
</bodyText>
<table confidence="0.9986295">
Random Default COGENT Best Case
(5%) (5%) (5%) (9%)
R 0.4814 0.4919 0.6021 0.9669
R-L P 0.4982 0.5623 0.5982 0.6256
F 0.4897 0.5248 0.6001 0.7597
Cosine 0.5382 0.6748 0.8325 0.9323
</table>
<tableCaption confidence="0.999923">
Table 2. Content evaluation results (word compression)
</tableCaption>
<bodyText confidence="0.99967">
The ROUGE-L scores consistently indicate that
the COGENT summary may be closer to the refer-
ence in linguistic surface structure than either the
Random or Default summaries. Since the
COGENT ROUGE-L recall score (R=0. 6021) is
lower than the Best Case (R=0.9669), it is likely
that COGENT may be extracting different sen-
tences than those selected by the experts. Based on
the high cosine similarity with the reference
(0.8325), we hypothesize that COGENT may be
selecting sentences that cover very similar con-
cepts to those selected by the experts, but ex-
pressed differently.
Given the difference in word compression for
the Best Case summary, we have performed an
</bodyText>
<page confidence="0.998172">
19
</page>
<bodyText confidence="0.9980995">
incremental analysis using the ROUGE-L measure
shown in Figure 2.
</bodyText>
<figure confidence="0.965952571428571">
ROUGE-L COGENT Evaluation
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
0 5 10 15 20 25 30
MEAD Word Percent Compression
</figure>
<figureCaption confidence="0.8100495">
Figure 2. Incremental COGENT ROUGE-L analysis
Figure 2 indicates that COGENT can match the
</figureCaption>
<bodyText confidence="0.988567166666667">
Best Case recall (R=0.9669) by generating a longer
summary. For educational applications, lengthier
summaries may be better suited for computational
purposes, such as diagnosing student understand-
ing, while shorter summaries may be more appro-
priate for display to the student.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.992533454545455">
COGENT extends MEAD based on strategies elic-
ited from an empirical study with domain and in-
structional experts. Initial evaluation results
indicate that COGENT holds promise for identify-
ing important domain pedagogical concepts. We
are exploring portability to other science education
domains and machine learning techniques to con-
nect concepts into a knowledge map. Automating
the creation of inventories of pedagogically impor-
tant concepts may represent an important step to-
wards scalable intelligent tutoring systems.
</bodyText>
<sectionHeader confidence="0.994941" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999791">
This research is funded in part by the National Sci-
ence Foundation under NSF IIS/ALT Award
0537194. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the author(s) and do not necessarily reflect
the views of the NSF.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999760836065574">
T. Byrt, J. Bishop and J. B. Carlin. Bias, prevalence, and
kappa. Journal of Clinical Epidemiology, 46, 5
(1993), 423-429.
S. de la Chica, F. Ahmad, T. Sumner, J. H. Martin and
K. Butcher. Computational foundations for personal-
izing instruction with digital libraries. International
Journal of Digital Libraries, to appear in the Special
Issue on Digital Libraries and Education.
S. Harabagiu and F. Lacatusu. Topic themes for multi-
document summarization. In Proc. of the 28th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
(Salvador, Brazil, 2005), 202-209.
H. Hardy, N. Shimizu, T. Strzalkowski, L. Ting, G. B.
Wise and X. Zhang. Summarizing large document
sets using concept-based clustering. In Proc. of the
Human Language Technology Conference 2002,
(San Diego, California, United States, 2002), 222-
227.
L. L. Hill. Core elements of digital gazetteers: place-
names, categories, and footprints. In Proc. of the 4th
European Conference on Digital Libraries, (Lisbon,
Portugal, 2000), 280-290.
C. D. Holley and D. F. Dansereau. Spatial learning
strategies: Techniques, applications, and related is-
sues. Academic Press, Orlando, Florida, 1984.
C. Y. Lin. ROUGE: A package for automatic evaluation
of summaries. In Proc. of the Workshop on Text
Summarization Branches Out, (Barcelona, Spain,
2004).
D. Lin and P. Pantel. Concept discovery from text. In
Proc. of the 19th International Conference on Com-
putational Linguistics, (Taipei, Taiwan, 2002), 1-7.
National Research Council. National Science Education
Standards. National Academy Press, Washington,
DC, 1996.
R. Navigli and P. Velardi. Learning domain ontologies
from document warehouses and dedicated websites.
Computational Linguistics, 30, 2 (2004), 151-179.
A. M. O&apos;Donnell, D. F. Dansereau and R. H. Hall.
Knowledge maps as scaffolds for cognitive process-
ing. Educational Psychology Review, 14, 1 (2002),
71-86.
Project 2061. Benchmarks for science literacy. Oxford
University Press, New York, New York, United
States, 1993.
D. R. Radev, H. Jing and M. Budzikowska. Centroid-
based summarization of multiple documents: sen-
tence extraction, utility-based evaluation, and user
studies. In Proc. of the ANLP/NAACL 2000 Work-
shop on Summarization, (2000), 21-30.
T. Sumner, S. Bhushan, F. Ahmad and Q. Gu. Design-
ing a language for creating conceptual browsing in-
terfaces for digital libraries. In Proc. of the 3rd
ACM/IEEE-CS Joint Conference on Digital Librar-
ies, (Houston, Texas, 2003), 258-260.
A. Zouaq, R. Nkambou and C. Frasson. Learning a do-
main ontology in the Knowledge Puzzle project. In
Proc. of the Fifth International Workshop on Ontolo-
gies and Semantic Web for E-Learning, (Marina del
Rey, California, 2007).
</reference>
<figure confidence="0.879041">
Recall
Precision F-Measure
</figure>
<page confidence="0.615376">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.871826">
<title confidence="0.990685">Extractive Summaries for Educational Science Content</title>
<author confidence="0.986451">Sebastian de_la Chica</author>
<author confidence="0.986451">Faisal Ahmad</author>
<author confidence="0.986451">James H Martin</author>
<author confidence="0.986451">Tamara Sumner</author>
<affiliation confidence="0.999227">Institute of Cognitive Science Department of Computer Science University of Colorado at Boulder</affiliation>
<email confidence="0.9472705">sebastian.delachica,faisal.ahmad,james.martin,tamara.sumner@colorado.edu</email>
<abstract confidence="0.999422">This paper describes an extractive summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with domain and instructional experts. COGENT implements a hybrid approach integrating both domain independent sentence scoring features and domain-aware features. Initial evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Byrt</author>
<author>J Bishop</author>
<author>J B Carlin</author>
</authors>
<title>Bias, prevalence, and kappa.</title>
<date>1993</date>
<journal>Journal of Clinical Epidemiology,</journal>
<volume>46</volume>
<pages>423--429</pages>
<contexts>
<context position="5138" citStr="Byrt et al., 1993" startWordPosition="741" endWordPosition="744">ncement of Science (AAAS) Benchmarks (Project 2061, 1993). Verbal protocol analysis shows that all experts used external sources to create the knowledge map, including their own expertise, other digital library resources, and the National Science Education Standards (NSES), a comprehensive collection of nationally-recognized science learning goals for K12 students (National Research Council, 1996). We have examined sentence extraction agreement between experts using the prevalenceadjusted bias-adjusted (PABA) kappa to account for prevalence of judgments and conflicting biases amongst experts (Byrt et al., 1993). The average PABA-kappa value of 0.62 indicates that experts substantially agree on sentence extraction from digital library resources. This level of agreement suggests that these concepts may serve as the reference summary to evaluate our system. 4 Summarizer for Science Education We have implemented an extractive summarizer for educational science content, COGENT, based on MEAD version 3.11 (Radev et al., 2000). COGENT complements the default MEAD sentence scoring features with features based on findings from the empirical study. COGENT represents a hybrid approach integrating bottom-up (hy</context>
</contexts>
<marker>Byrt, Bishop, Carlin, 1993</marker>
<rawString>T. Byrt, J. Bishop and J. B. Carlin. Bias, prevalence, and kappa. Journal of Clinical Epidemiology, 46, 5 (1993), 423-429.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S de la Chica</author>
<author>F Ahmad</author>
<author>T Sumner</author>
<author>J H Martin</author>
<author>K Butcher</author>
</authors>
<title>Computational foundations for personalizing instruction with digital libraries.</title>
<booktitle>International Journal of Digital Libraries, to appear in the Special Issue on Digital Libraries and Education.</booktitle>
<marker>Chica, Ahmad, Sumner, Martin, Butcher, </marker>
<rawString>S. de la Chica, F. Ahmad, T. Sumner, J. H. Martin and K. Butcher. Computational foundations for personalizing instruction with digital libraries. International Journal of Digital Libraries, to appear in the Special Issue on Digital Libraries and Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>F Lacatusu</author>
</authors>
<title>Topic themes for multidocument summarization.</title>
<date>2005</date>
<booktitle>In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>202--209</pages>
<location>Salvador, Brazil,</location>
<contexts>
<context position="3030" citStr="Harabagiu and Lacatusu, 2005" startWordPosition="429" endWordPosition="433">e the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Finally, MEAD is a widely used MDS and evaluation platform (Radev et al., 2000). While all these systems have produced promising results in automated evaluations, none have directly targeted educational content collections. 17 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 17–20, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 3 Empirical Study We have conducted a study to capture how human experts processed digital library resources to create a domain knowledge map. Four geology and instructional design experts selected 20 resources from </context>
</contexts>
<marker>Harabagiu, Lacatusu, 2005</marker>
<rawString>S. Harabagiu and F. Lacatusu. Topic themes for multidocument summarization. In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, (Salvador, Brazil, 2005), 202-209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hardy</author>
<author>N Shimizu</author>
<author>T Strzalkowski</author>
<author>L Ting</author>
<author>G B Wise</author>
<author>X Zhang</author>
</authors>
<title>Summarizing large document sets using concept-based clustering.</title>
<date>2002</date>
<booktitle>In Proc. of the Human Language Technology Conference</booktitle>
<contexts>
<context position="2882" citStr="Hardy et al., 2002" startWordPosition="407" endWordPosition="410">ledge Puzzle focuses on n-gram identification to produce a list of candidate terms pruned using information extraction techniques to derive the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Finally, MEAD is a widely used MDS and evaluation platform (Radev et al., 2000). While all these systems have produced promising results in automated evaluations, none have directly targeted educational content collections. 17 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 17–20, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 3 Empirical Study We have conducted a study to capture how human exp</context>
</contexts>
<marker>Hardy, Shimizu, Strzalkowski, Ting, Wise, Zhang, 2002</marker>
<rawString>H. Hardy, N. Shimizu, T. Strzalkowski, L. Ting, G. B. Wise and X. Zhang. Summarizing large document sets using concept-based clustering. In Proc. of the Human Language Technology Conference 2002,</rawString>
</citation>
<citation valid="false">
<date>2002</date>
<pages>222--227</pages>
<location>California, United States,</location>
<contexts>
<context position="2459" citStr="(2002)" startWordPosition="348" endWordPosition="348">seful both as computational knowledge representations and as learning resources for presentation to the student. 2 Related Work Our work is informed by efforts to automate the acquisition of ontology concepts from text. OntoLearn extracts candidate domain terms from texts using a syntactic parse and updates an existing ontology with the identified concepts and relationships (Navigli and Velardi, 2004). Knowledge Puzzle focuses on n-gram identification to produce a list of candidate terms pruned using information extraction techniques to derive the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Finally, MEAD is a widely u</context>
</contexts>
<marker>2002</marker>
<rawString>(San Diego, California, United States, 2002), 222-227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L L Hill</author>
</authors>
<title>Core elements of digital gazetteers: placenames, categories, and footprints.</title>
<date>2000</date>
<booktitle>In Proc. of the 4th European Conference on Digital Libraries,</booktitle>
<pages>280--290</pages>
<location>Lisbon,</location>
<contexts>
<context position="6470" citStr="Hill, 2000" startWordPosition="939" endWordPosition="940"> used external information sources with the educational standards feature. This feature leverages the text of the relevant AAAS Benchmarks and associated NSES. Each sentence receives a score based on its TFIDF similarity to the textual contents of these learning goals and educational standards. We have developed a feature that reflects the large number of examples extracted by the experts. Earth science examples often refer to geographical locations and geological formations. The gazetteer feature checks named entities from each sentence against the Alexandria Digital Library (ADL) Gazetteer (Hill, 2000). A gazetteer is a geo-referencing resource containing location and type information about place-names. Each sentence receives a TFIDF score based on place-name term frequency and overall uniqueness in the gazetteer. Our assumption is that geographical locations with more unique names may be more pedagogically relevant. Based on the intuition that the HTML structure of a resource reflects relevancy, we have developed the hypertext feature. This feature computes a sentence score directly proportional to the HTML heading level and inversely proportional to the relative paragraph number within a </context>
</contexts>
<marker>Hill, 2000</marker>
<rawString>L. L. Hill. Core elements of digital gazetteers: placenames, categories, and footprints. In Proc. of the 4th European Conference on Digital Libraries, (Lisbon, Portugal, 2000), 280-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Holley</author>
<author>D F Dansereau</author>
</authors>
<title>Spatial learning strategies: Techniques, applications, and related issues.</title>
<date>1984</date>
<publisher>Academic Press,</publisher>
<location>Orlando, Florida,</location>
<contexts>
<context position="962" citStr="Holley and Dansereau, 1984" startWordPosition="119" endWordPosition="122">e summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with domain and instructional experts. COGENT implements a hybrid approach integrating both domain independent sentence scoring features and domain-aware features. Initial evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts. 1 Introduction Knowledge maps consist of nodes containing rich concept descriptions interconnected using a limited set of relationship types (Holley and Dansereau, 1984). Learning research indicates that knowledge maps may be useful for learners to understand the macro-level structure of an information space (O&apos;Donnell et al., 2002). Knowledge maps have also emerged as an effective computational infrastructure to support the automated generation of conceptual browsers. Such conceptual browsers appear to allow students to focus on the science content of large educational digital libraries (Sumner et al., 2003), such as the Digital Library for Earth System Education (DLESE.org). Knowledge maps have also shown promise as domain and student knowledge representati</context>
</contexts>
<marker>Holley, Dansereau, 1984</marker>
<rawString>C. D. Holley and D. F. Dansereau. Spatial learning strategies: Techniques, applications, and related issues. Academic Press, Orlando, Florida, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ROUGE</author>
</authors>
<title>A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Proc. of the Workshop on Text Summarization Branches Out,</booktitle>
<location>Barcelona, Spain,</location>
<marker>ROUGE, 2004</marker>
<rawString>C. Y. Lin. ROUGE: A package for automatic evaluation of summaries. In Proc. of the Workshop on Text Summarization Branches Out, (Barcelona, Spain, 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="2459" citStr="Lin and Pantel (2002)" startWordPosition="345" endWordPosition="348">nowledge maps useful both as computational knowledge representations and as learning resources for presentation to the student. 2 Related Work Our work is informed by efforts to automate the acquisition of ontology concepts from text. OntoLearn extracts candidate domain terms from texts using a syntactic parse and updates an existing ontology with the identified concepts and relationships (Navigli and Velardi, 2004). Knowledge Puzzle focuses on n-gram identification to produce a list of candidate terms pruned using information extraction techniques to derive the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Finally, MEAD is a widely u</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>D. Lin and P. Pantel. Concept discovery from text. In Proc. of the 19th International Conference on Computational Linguistics, (Taipei, Taiwan, 2002), 1-7.</rawString>
</citation>
<citation valid="false">
<date>1996</date>
<publisher>Academy Press,</publisher>
<institution>National Research Council. National Science Education Standards. National</institution>
<location>Washington, DC,</location>
<marker>1996</marker>
<rawString>National Research Council. National Science Education Standards. National Academy Press, Washington, DC, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>P Velardi</author>
</authors>
<title>Learning domain ontologies from document warehouses and dedicated websites.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<pages>151--179</pages>
<contexts>
<context position="2257" citStr="Navigli and Velardi, 2004" startWordPosition="315" endWordPosition="318">, 2008). In this paper we describe our progress towards the generation of science concept inventories as summaries of digital library collections. Such inventories provide the basis for the construction of knowledge maps useful both as computational knowledge representations and as learning resources for presentation to the student. 2 Related Work Our work is informed by efforts to automate the acquisition of ontology concepts from text. OntoLearn extracts candidate domain terms from texts using a syntactic parse and updates an existing ontology with the identified concepts and relationships (Navigli and Velardi, 2004). Knowledge Puzzle focuses on n-gram identification to produce a list of candidate terms pruned using information extraction techniques to derive the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and cluste</context>
</contexts>
<marker>Navigli, Velardi, 2004</marker>
<rawString>R. Navigli and P. Velardi. Learning domain ontologies from document warehouses and dedicated websites. Computational Linguistics, 30, 2 (2004), 151-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M O&apos;Donnell</author>
<author>D F Dansereau</author>
<author>R H Hall</author>
</authors>
<title>Knowledge maps as scaffolds for cognitive processing.</title>
<date>2002</date>
<journal>Educational Psychology Review,</journal>
<volume>14</volume>
<pages>71--86</pages>
<contexts>
<context position="1127" citStr="O&apos;Donnell et al., 2002" startWordPosition="143" endWordPosition="146">s. COGENT implements a hybrid approach integrating both domain independent sentence scoring features and domain-aware features. Initial evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts. 1 Introduction Knowledge maps consist of nodes containing rich concept descriptions interconnected using a limited set of relationship types (Holley and Dansereau, 1984). Learning research indicates that knowledge maps may be useful for learners to understand the macro-level structure of an information space (O&apos;Donnell et al., 2002). Knowledge maps have also emerged as an effective computational infrastructure to support the automated generation of conceptual browsers. Such conceptual browsers appear to allow students to focus on the science content of large educational digital libraries (Sumner et al., 2003), such as the Digital Library for Earth System Education (DLESE.org). Knowledge maps have also shown promise as domain and student knowledge representations to support personalized learning interactions (de la Chica et al., 2008). In this paper we describe our progress towards the generation of science concept invent</context>
</contexts>
<marker>O&apos;Donnell, Dansereau, Hall, 2002</marker>
<rawString>A. M. O&apos;Donnell, D. F. Dansereau and R. H. Hall. Knowledge maps as scaffolds for cognitive processing. Educational Psychology Review, 14, 1 (2002), 71-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Project</author>
</authors>
<title>Benchmarks for science literacy.</title>
<date>1993</date>
<publisher>Oxford University Press,</publisher>
<location>New York, New York, United States,</location>
<marker>Project, 1993</marker>
<rawString>Project 2061. Benchmarks for science literacy. Oxford University Press, New York, New York, United States, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Radev</author>
<author>H Jing</author>
<author>M Budzikowska</author>
</authors>
<title>Centroidbased summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.</title>
<date>2000</date>
<booktitle>In Proc. of the ANLP/NAACL 2000 Workshop on Summarization,</booktitle>
<pages>21--30</pages>
<contexts>
<context position="3111" citStr="Radev et al., 2000" startWordPosition="444" endWordPosition="447">ng by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Finally, MEAD is a widely used MDS and evaluation platform (Radev et al., 2000). While all these systems have produced promising results in automated evaluations, none have directly targeted educational content collections. 17 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 17–20, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 3 Empirical Study We have conducted a study to capture how human experts processed digital library resources to create a domain knowledge map. Four geology and instructional design experts selected 20 resources from DLESE to construct a knowledge map on earthquakes and plates tectonics for high s</context>
<context position="5555" citStr="Radev et al., 2000" startWordPosition="803" endWordPosition="806">ed sentence extraction agreement between experts using the prevalenceadjusted bias-adjusted (PABA) kappa to account for prevalence of judgments and conflicting biases amongst experts (Byrt et al., 1993). The average PABA-kappa value of 0.62 indicates that experts substantially agree on sentence extraction from digital library resources. This level of agreement suggests that these concepts may serve as the reference summary to evaluate our system. 4 Summarizer for Science Education We have implemented an extractive summarizer for educational science content, COGENT, based on MEAD version 3.11 (Radev et al., 2000). COGENT complements the default MEAD sentence scoring features with features based on findings from the empirical study. COGENT represents a hybrid approach integrating bottom-up (hypertext and content word density) and top-down (educational standards and gazetteer) features. We model how human experts used external information sources with the educational standards feature. This feature leverages the text of the relevant AAAS Benchmarks and associated NSES. Each sentence receives a score based on its TFIDF similarity to the textual contents of these learning goals and educational standards. </context>
</contexts>
<marker>Radev, Jing, Budzikowska, 2000</marker>
<rawString>D. R. Radev, H. Jing and M. Budzikowska. Centroidbased summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies. In Proc. of the ANLP/NAACL 2000 Workshop on Summarization, (2000), 21-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sumner</author>
<author>S Bhushan</author>
<author>F Ahmad</author>
<author>Q Gu</author>
</authors>
<title>Designing a language for creating conceptual browsing interfaces for digital libraries.</title>
<date>2003</date>
<booktitle>In Proc. of the 3rd ACM/IEEE-CS Joint Conference on Digital Libraries,</booktitle>
<pages>258--260</pages>
<location>Houston, Texas,</location>
<contexts>
<context position="1409" citStr="Sumner et al., 2003" startWordPosition="184" endWordPosition="188">ts. 1 Introduction Knowledge maps consist of nodes containing rich concept descriptions interconnected using a limited set of relationship types (Holley and Dansereau, 1984). Learning research indicates that knowledge maps may be useful for learners to understand the macro-level structure of an information space (O&apos;Donnell et al., 2002). Knowledge maps have also emerged as an effective computational infrastructure to support the automated generation of conceptual browsers. Such conceptual browsers appear to allow students to focus on the science content of large educational digital libraries (Sumner et al., 2003), such as the Digital Library for Earth System Education (DLESE.org). Knowledge maps have also shown promise as domain and student knowledge representations to support personalized learning interactions (de la Chica et al., 2008). In this paper we describe our progress towards the generation of science concept inventories as summaries of digital library collections. Such inventories provide the basis for the construction of knowledge maps useful both as computational knowledge representations and as learning resources for presentation to the student. 2 Related Work Our work is informed by effo</context>
</contexts>
<marker>Sumner, Bhushan, Ahmad, Gu, 2003</marker>
<rawString>T. Sumner, S. Bhushan, F. Ahmad and Q. Gu. Designing a language for creating conceptual browsing interfaces for digital libraries. In Proc. of the 3rd ACM/IEEE-CS Joint Conference on Digital Libraries, (Houston, Texas, 2003), 258-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zouaq</author>
<author>R Nkambou</author>
<author>C Frasson</author>
</authors>
<title>Learning a domain ontology in the Knowledge Puzzle project.</title>
<date>2007</date>
<booktitle>In Proc. of the Fifth International Workshop on Ontologies and Semantic Web for E-Learning,</booktitle>
<location>Marina del Rey, California,</location>
<contexts>
<context position="2436" citStr="Zouaq et al., 2007" startWordPosition="341" endWordPosition="344">the construction of knowledge maps useful both as computational knowledge representations and as learning resources for presentation to the student. 2 Related Work Our work is informed by efforts to automate the acquisition of ontology concepts from text. OntoLearn extracts candidate domain terms from texts using a syntactic parse and updates an existing ontology with the identified concepts and relationships (Navigli and Velardi, 2004). Knowledge Puzzle focuses on n-gram identification to produce a list of candidate terms pruned using information extraction techniques to derive the ontology (Zouaq et al., 2007). Lin and Pantel (2002) discover concepts using clustering by committee to group terms into conceptually related clusters. These approaches produce ontologies of very fine granularity and therefore graphs that may not be suitable for presentation to a student. Multi-document summarization (MDS) research also informs our work. XDoX analyzes large document sets to extract important themes using n-gram scoring and clustering (Hardy et al., 2002). Topic representation and topic themes have also served as the basis for the exploration of promising MDS techniques (Harabagiu and Lacatusu, 2005). Fina</context>
</contexts>
<marker>Zouaq, Nkambou, Frasson, 2007</marker>
<rawString>A. Zouaq, R. Nkambou and C. Frasson. Learning a domain ontology in the Knowledge Puzzle project. In Proc. of the Fifth International Workshop on Ontologies and Semantic Web for E-Learning, (Marina del Rey, California, 2007).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>