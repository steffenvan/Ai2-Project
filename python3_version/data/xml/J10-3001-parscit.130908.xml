<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000129">
<title confidence="0.5711885">
Squibs
Does GIZA++ Make Search Errors?
</title>
<author confidence="0.955148">
Sujith Ravi*
</author>
<affiliation confidence="0.990146">
University of Southern California
</affiliation>
<author confidence="0.991556">
Kevin Knight**
</author>
<affiliation confidence="0.991791">
University of Southern California
</affiliation>
<bodyText confidence="0.9904725">
Word alignment is a critical procedure within statistical machine translation (SMT). Brown
et al. (1993) have provided the most popular word alignment algorithm to date, one that has
been implemented in the GIZA (Al-Onaizan et al. 1999) and GIZA++ (Och and Ney 2003)
software and adopted by nearly every SMT project. In this article, we investigate whether this
algorithm makes search errors when it computes Viterbi alignments, that is, whether it returns
alignments that are sub-optimal according to a trained model.
</bodyText>
<sectionHeader confidence="0.964201" genericHeader="abstract">
1. Background
</sectionHeader>
<bodyText confidence="0.984622466666667">
Word alignment is the problem of annotating a bilingual text with links connecting
words that have the same meanings. Brown et al. (1993) align an English/French sen-
tence pair by positing a probabilistic model by which an English sentence is translated
into French.1 The model provides a set of non-deterministic choices. When a particular
sequence of choices is applied to an English input sentence e1...el, the result is a partic-
ular French output sentence f1...fm. In the Brown et al. models, a decision sequence also
implies a specific word alignment vector a1...am. We say aj = i when French word fj was
produced by English word ei during the translation. Here is a sample sentence pair (e, f)
and word alignment a:
e: NULL0 Mary1 did2 not3 slap4 the5 green6 witch7
f: Mary1 no2 di´o3 una4 bofetada5 a6 la7 bruja8 verde9
a: [ 1 3 4 5 5 0 5 7 6 ]
Notice that the English sentence contains a special NULL word (e0) that generates
“spurious” target words (in this case, a6). The Brown et al. (1993) models are many-
to-one, meaning that each English word can produce several French children, but each
</bodyText>
<footnote confidence="0.813155555555556">
* Information Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,
CA 90292. E-mail: sravi@isi.edu.
** Information Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,
CA 90292. E-mail: knight@isi.edu.
1 We follow standard convention in using “English” and “French” simply as shorthand for “source” and
“target”. In fact, we use English/Spanish examples in this article.
Submission received: 16 December 2009; accepted for publication: 7 April 2010.
© 2010 Association for Computational Linguistics
Computational Linguistics Volume 36, Number 3
</footnote>
<bodyText confidence="0.327257666666667">
French word has only one English parent. This is why we can represent an alignment as
a vector a1...am. There are (l + 1)m ways to align (e, f). For Brown et al. the goal of word
alignment is to find the alignment a that is most likely, given a sentence pair (e, f):
</bodyText>
<equation confidence="0.533358">
argmaxa P(a|e,f) = argmaxaP(a,f|e) (1)
</equation>
<sectionHeader confidence="0.761469" genericHeader="method">
2. IBM Model 3
</sectionHeader>
<bodyText confidence="0.969439666666667">
Supplied with a formula for P(a|e,f), we can search through the (l + 1)m alignments
for the highest-scoring one. Brown et al. (1993) come up with such a formula by first
positing this generative story (IBM Model 3):
</bodyText>
<listItem confidence="0.968508">
Given an English sentence e1...el:
1. Choose a fertility φi for each English word ei, according to the distribution
n(φi|ei).
2. Let m&apos; = �i=1...l φi.
3. Choose a number φ0 of “spurious” French words, by doing the following
m&apos; times: with probability p1, increment φ0 by one.
4. Let m = m&apos; + φ0.
5. Choose a French translation τik for each English word (including e0) and
fertility value, according to the distribution t(τik|ei).
6. Choose a French position j for each τik (i &gt; 0), according to d(j|i,l, m). If the
same j is chosen twice, fail the procedure.
7. Place each of the φ0 spuriously generated words, one by one, into vacant
positions in the English string, according to uniform probability.
8. Output the French string f1...fm, where fj is the French word τik that was
placed into position j in Step 6 or 7.
9. Output alignment a1...am, where aj is the English position i from that
same τik.
</listItem>
<bodyText confidence="0.773491">
Different decision sequences can result in the same outputs f and a. With this in
mind, Brown et al. provide the following formula:
</bodyText>
<equation confidence="0.99180525">
P(a,f|e) = m t(fj|eaj) · Hl n(φi|ei) · m d(j|aj,l, m)
H i=1 H
j=1 aj#0,j=1
l −
Cm φo 0)
pφ0
1 ii · po 2φ0 (2)
i=0
</equation>
<bodyText confidence="0.971257">
Note that terms φ0...φl are only shorthand, as their values are completely deter-
mined by the alignment a1...am.
</bodyText>
<page confidence="0.991645">
296
</page>
<note confidence="0.839469">
Ravi and Knight Does GIZA++ Make Search Errors?
</note>
<sectionHeader confidence="0.814129" genericHeader="method">
3. Finding the Viterbi Alignment
</sectionHeader>
<bodyText confidence="0.999964111111111">
We assume that probability tables n, t, d, and p have already been learned from data,
using the EM method described by Brown et al. (1993). We are concerned solely with the
problem of then finding the best alignment for a given sentence pair (e, f) as described
in Equation 1. Brown et al. were unable to discover a polynomial time algorithm for
this problem, which was in fact subsequently shown to be NP-complete (Udupa and
Maji 2006). Brown et al. therefore devise a hill-climbing algorithm. This algorithm starts
with a reasonably good alignment (Viterbi IBM Model 2, computable in quadratic time),
after which it greedily executes small changes to the alignment structure, gradually
increasing P(a,f|e). The small changes consist of moves, in which the value of some
aj is changed, and swaps, in which a pair aj and ak exchange values. At each step in
the greedy search, all possible moves and swaps are considered, and the one which
increases P(a,f|e) the most is executed. When P(a,f|e) can no longer be improved, the
search halts.2
Our question is whether this hill-climbing algorithm, as implemented in GIZA++,
makes search errors when it tries to locate IBM Model 3 Viterbi alignments. To answer
this, we built a slow but optimal IBM Model 3 aligner, by casting the problem in the
integer linear programming (ILP) framework. Given a sentence pair (e1...el, f1...fm), we
set up the following variables:
</bodyText>
<listItem confidence="0.961241333333334">
• Binary link variables linkij. We have one such variable for each pair of
English and French tokens. If linkij = 1, then there is an alignment link
between ei and fj. The English NULL word is represented by i = 0.
• Binary fertility variables fertik. We have one variable for each English token
paired with an integer fertility value 0..9. If fertik = 1, then token ei has
fertility k.
</listItem>
<bodyText confidence="0.993627733333333">
To ensure that values we assign to variables are legal and self-consistent, we in-
troduce several constraints. First, we require that for each j, all linkxj values sum to
one. This means each French token has exactly one alignment link, as required by IBM
Model 3. Second, we require that for each i, all fertix values sum to one, so that each
English token has a unique fertility. Third, we require that link and fertility variable
assignments be consistent with one another: for each i, the sum of linkix variables equals
1 · ferti1 + 2 · ferti2 + ... + 9 · ferti9.3
We then define an objective function whose minimization corresponds to finding
the Viterbi IBM Model 3 alignment. Figure 1 presents the components of the objective
function, alongside counterparts from the P(a, f|e) formula previously given. Note that
the coefficients for the objective function are derived from the already-learned probabil-
ity tables n, d, t, and p.
For each sentence pair in our test set, we create and solve an ILP problem. Figure 2
demonstrates this for a simple example. The reader can extract the optimal alignment
from the alignment variables chosen in the ILP solution.
</bodyText>
<footnote confidence="0.966918">
2 Brown et al. (1993) describe a variation called pegging, which carries out multiple additional greedy
hill-climbs, each with a different IBM Model 2 Viterbi link fixed (pegged) for the duration of the
hill-climb. In practice, pegging is slow, and the vast majority of GIZA++ users do not employ it.
3 The default configuration of GIZA++ includes this same fertility cap of 9, though the Brown et al. (1993)
description does not.
</footnote>
<page confidence="0.990646">
297
</page>
<figure confidence="0.83169">
Computational Linguistics Volume 36, Number 3
</figure>
<figureCaption confidence="0.996016">
Figure 1
</figureCaption>
<bodyText confidence="0.997348333333333">
Objective function and constraints (left) for the ILP formulation that encodes the problem of
selecting the Viterbi alignment for a sentence pair under IBM Model 3. Components of the ILP
objective function are paired with counterparts (right) from the Model 3’s P(a, fie) formula.
</bodyText>
<sectionHeader confidence="0.998047" genericHeader="method">
4. Experiments
</sectionHeader>
<bodyText confidence="0.9943474">
For Chinese/English experiments, we run GIZA++ training on 101,880 sentence pairs.
We evaluate Viterbi alignments on a smaller test set of 1,880 sentence pairs with manual
alignments. For Arabic/English, we train on 300,000 sentence pairs and test on 2,000.
In tests, we compare GIZA++ Viterbi alignments (based on greedy hill-climbing) with
optimal ILP alignments. We use CPLEX to solve our ILP problems.
</bodyText>
<page confidence="0.995854">
298
</page>
<note confidence="0.801416">
Ravi and Knight Does GIZA++ Make Search Errors?
</note>
<figureCaption confidence="0.983946">
Figure 2
</figureCaption>
<bodyText confidence="0.988575125">
Illustration of ILP-based optimal alignment of a single sentence pair. Already-trained log
probabilities are shown at the top of the figure. In the middle is a schematic of variables
introduced for the English/Spanish sentence pair seatbelts / los cinturones de seguridad.
At the bottom is the ILP formulation and its solution.
Figure 3 compares the results from GIZA++ alignment with optimal ILP alignment
for different language pairs and alignment directions, and for unions of uni-directional
alignments. We measure the rate at which GIZA++ makes search errors, and we com-
pute alignment F-scores for the various testing conditions. We conclude that although
</bodyText>
<page confidence="0.993281">
299
</page>
<figure confidence="0.703006">
Computational Linguistics Volume 36, Number 3
</figure>
<figureCaption confidence="0.931844">
Figure 3
</figureCaption>
<bodyText confidence="0.98046925">
Comparison of GIZA++ Viterbi alignments (based on greedy hill-climbing) with optimal ILP
alignments for different language pairs and alignment directions in terms of alignment quality
(F-score). The figure also shows the alignment F-scores for UNION alignments that combine
alignment links from both directions. The fourth column shows the percentage of sentences on
which GIZA++ makes search errors in comparison to optimal ILP alignments.
GIZA++ makes search errors on 5–15% of sentence pairs, these errors do not contribute
to an overall loss in alignment task accuracy, as measured by F-score.
Focusing on sentence pairs where GIZA++ makes a search error, we plot the av-
</bodyText>
<figureCaption confidence="0.975629333333333">
erage difference in log model scores between GIZA++ and ILP Viterbi alignments in
Figure 4. We notice a positive correlation between sentence length and the search error
Figure 4
</figureCaption>
<footnote confidence="0.716404">
Average difference in log model scores between GIZA++ and ILP alignments at different English
sentence lengths for English/Chinese alignment. Points in the plot that appear to be on the
x-axis actually lie just above it.
</footnote>
<page confidence="0.991774">
300
</page>
<note confidence="0.888025">
Ravi and Knight Does GIZA++ Make Search Errors?
</note>
<figureCaption confidence="0.967182">
Figure 5
</figureCaption>
<bodyText confidence="0.624318">
Average time (msec) taken by the ILP aligner at different English sentence lengths for
English/Chinese alignment. The experiments were run on a single machine with a 64-bit,
</bodyText>
<subsectionHeader confidence="0.49861">
2.4 GHz AMD Opteron 850 processor.
</subsectionHeader>
<bodyText confidence="0.999963">
gap between GIZA++ and ILP scores. As we move to longer sentences, the alignment
procedure becomes harder and GIZA++ makes more errors. Finally, Figure 5 plots the
time taken for ILP alignment at different sentence lengths showing a positive correlation
as well.
</bodyText>
<sectionHeader confidence="0.999229" genericHeader="discussions">
5. Discussion
</sectionHeader>
<bodyText confidence="0.999835">
We have determined that GIZA++ makes few search errors, despite the heuristic nature
of the algorithm. These search errors do not materially affect overall alignment accuracy.
In practice, this means that researchers should not spend time optimizing this particular
aspect of SMT systems.
Search errors can occur in many areas of SMT. The area that has received the most
attention is runtime decoding/translation. For example, Germann et al. (2001) devise an
optimal ILP decoder to identify types of search errors made by other decoders. A second
area (this article) is finding Viterbi alignments, given a set of alignment parameter
values. A third area is actually learning those parameter values. Brown et al.’s (1993)
EM learning algorithm aims to optimize the probability of the French side of the parallel
corpus given the English side. For Model 3 and above, Brown et al. collect parameter
counts over subsets of alignments, instead of over all alignments. These subsets, like
Viterbi alignments, are generated heuristically, and it may be that true n-best lists of
</bodyText>
<page confidence="0.992098">
301
</page>
<note confidence="0.562561">
Computational Linguistics Volume 36, Number 3
</note>
<bodyText confidence="0.9999515">
alignments would yield better counts and better overall parameter values. Of course,
even if we were able to collect accurate counts, EM is not guaranteed to find a global
optimum, which provides further opportunity for search errors. We leave the problem
of search errors in alignment training to future study.
</bodyText>
<sectionHeader confidence="0.998525" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<copyright confidence="0.592976">
This work was supported by NSF grant
0904684 and DARPA GALE Contract
Number HR0011-06-C-0022.
</copyright>
<sectionHeader confidence="0.997593" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999718517241379">
Al-Onaizan, Yaser, Jan Curin, Michael Jahr,
Kevin Knight, John Lafferty, Franz
Josef Och Dan Melamed, David Purdy,
Noah Smith, and David Yarowsky. 1999.
Statistical machine translation. Technical
report, Johns Hopkins University.
Brown, Peter, Vincent Della Pietra,
Stephen Della Pietra, and Robert Mercer.
1993. The mathematics of statistical
machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.
Germann, Ulrich, Michael Jahr, Kevin
Knight, Daniel Marcu, and Kenji Yamada.
2001. Fast decoding and optimal decoding
for machine translation. In Proceedings of
the 39th Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 228–235, Toulouse.
Och, Franz Josef and Hermann Ney. 2003.
A systematic comparison of various
statistical alignment models. Computational
Linguistics, 29(1):19–51.
Udupa, Raghavendra and Hemanta K. Maji.
2006. Computational complexity of
statistical machine translation. In
Proceedings of the Conference of the
European Chapter of the Association of
Computational Linguistics (EACL), pages
25–32, Trento.
</reference>
<page confidence="0.998718">
302
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000116">
<title confidence="0.997018">Squibs</title>
<author confidence="0.979164">Does GIZA Make Search Errors</author>
<affiliation confidence="0.9964545">University of Southern California University of Southern California</affiliation>
<author confidence="0.630317">Word alignment is a critical procedure within statistical machine translation</author>
<abstract confidence="0.968977454545454">et al. (1993) have provided the most popular word alignment algorithm to date, one that has been implemented in the GIZA (Al-Onaizan et al. 1999) and GIZA++ (Och and Ney 2003) software and adopted by nearly every SMT project. In this article, we investigate whether this algorithm makes search errors when it computes Viterbi alignments, that is, whether it returns alignments that are sub-optimal according to a trained model. 1. Background Word alignment is the problem of annotating a bilingual text with links connecting words that have the same meanings. Brown et al. (1993) align an English/French sentence pair by positing a probabilistic model by which an English sentence is translated The model provides a set of non-deterministic choices. When a particular of choices is applied to an English input sentence the result is a partic- French output sentence In the Brown et al. models, a decision sequence also a specific word alignment vector We say French word by English word the translation. Here is a sample sentence pair word alignment e: f: [ 1 3 4 5 5 0 5 7 6 ] that the English sentence contains a special NULL word that generates target words (in this case, The Brown et al. (1993) models are manyto-one, meaning that each English word can produce several French children, but each Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,</abstract>
<address confidence="0.662876">CA 90292. E-mail: sravi@isi.edu.</address>
<note confidence="0.884237285714286">Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey, CA 90292. E-mail: knight@isi.edu. 1 We follow standard convention in using “English” and “French” simply as shorthand for “source” and “target”. In fact, we use English/Spanish examples in this article. Submission received: 16 December 2009; accepted for publication: 7 April 2010. © 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3</note>
<abstract confidence="0.987468374999999">French word has only one English parent. This is why we can represent an alignment as vector There are ways to align For Brown et al. the goal of word is to find the alignment is most likely, given a sentence pair (1) 2. IBM Model 3 with a formula for we can search through the alignments for the highest-scoring one. Brown et al. (1993) come up with such a formula by first positing this generative story (IBM Model 3): an English sentence Choose a fertility each English word according to the distribution Let Choose a number “spurious” French words, by doing the following with probability increment one. Let Choose a French translation each English word (including and value, according to the distribution Choose a French position each according to If the chosen twice, fail the procedure. Place each of the generated words, one by one, into vacant positions in the English string, according to uniform probability. Output the French string where the French word was into position Step 6 or 7. Output alignment where the English position that decision sequences can result in the same outputs With this in mind, Brown et al. provide the following formula: m m H H ii that terms only shorthand, as their values are completely deterby the alignment 296 Ravi and Knight Does GIZA++ Make Search Errors? 3. Finding the Viterbi Alignment assume that probability tables and already been learned from data, using the EM method described by Brown et al. (1993). We are concerned solely with the of then finding the best alignment for a given sentence pair as described in Equation 1. Brown et al. were unable to discover a polynomial time algorithm for this problem, which was in fact subsequently shown to be NP-complete (Udupa and Maji 2006). Brown et al. therefore devise a hill-climbing algorithm. This algorithm starts with a reasonably good alignment (Viterbi IBM Model 2, computable in quadratic time), after which it greedily executes small changes to the alignment structure, gradually The small changes consist of in which the value of some changed, and in which a pair values. At each step in the greedy search, all possible moves and swaps are considered, and the one which the most is executed. When can no longer be improved, the Our question is whether this hill-climbing algorithm, as implemented in GIZA++, makes search errors when it tries to locate IBM Model 3 Viterbi alignments. To answer this, we built a slow but optimal IBM Model 3 aligner, by casting the problem in the linear programming (ILP) framework. Given a sentence pair we set up the following variables: Binary link variables We have one such variable for each pair of and French tokens. If 1, then there is an alignment link The English NULL word is represented by Binary fertility variables We have one variable for each English token with an integer fertility value 0..9. If 1, then token To ensure that values we assign to variables are legal and self-consistent, we inseveral constraints. First, we require that for each all sum to one. This means each French token has exactly one alignment link, as required by IBM 3. Second, we require that for each all values sum to one, so that each English token has a unique fertility. Third, we require that link and fertility variable be consistent with one another: for each the sum of variables equals We then define an objective function whose minimization corresponds to finding the Viterbi IBM Model 3 alignment. Figure 1 presents the components of the objective alongside counterparts from the formula previously given. Note that the coefficients for the objective function are derived from the already-learned probabiltables and For each sentence pair in our test set, we create and solve an ILP problem. Figure 2 demonstrates this for a simple example. The reader can extract the optimal alignment from the alignment variables chosen in the ILP solution. Brown et al. (1993) describe a variation called which carries out multiple additional hill-climbs, each with a different IBM Model 2 Viterbi link fixed (pegged) for the duration of hill-climb. In practice, pegging is slow, and the vast majority of GIZA++ users do not employ it. 3 The default configuration of GIZA++ includes this same fertility cap of 9, though the Brown et al. (1993) description does not. 297 Computational Linguistics Volume 36, Number 3 Figure 1 Objective function and constraints (left) for the ILP formulation that encodes the problem of selecting the Viterbi alignment for a sentence pair under IBM Model 3. Components of the ILP function are paired with counterparts (right) from the Model 3’s formula. 4. Experiments For Chinese/English experiments, we run GIZA++ training on 101,880 sentence pairs. We evaluate Viterbi alignments on a smaller test set of 1,880 sentence pairs with manual alignments. For Arabic/English, we train on 300,000 sentence pairs and test on 2,000. In tests, we compare GIZA++ Viterbi alignments (based on greedy hill-climbing) with optimal ILP alignments. We use CPLEX to solve our ILP problems. 298 Ravi and Knight Does GIZA++ Make Search Errors? Figure 2 Illustration of ILP-based optimal alignment of a single sentence pair. Already-trained log probabilities are shown at the top of the figure. In the middle is a schematic of variables for the English/Spanish sentence pair cinturones de At the bottom is the ILP formulation and its solution. Figure 3 compares the results from GIZA++ alignment with optimal ILP alignment for different language pairs and alignment directions, and for unions of uni-directional alignments. We measure the rate at which GIZA++ makes search errors, and we compute alignment F-scores for the various testing conditions. We conclude that although 299 Computational Linguistics Volume 36, Number 3 Figure 3 Comparison of GIZA++ Viterbi alignments (based on greedy hill-climbing) with optimal ILP alignments for different language pairs and alignment directions in terms of alignment quality (F-score). The figure also shows the alignment F-scores for UNION alignments that combine alignment links from both directions. The fourth column shows the percentage of sentences on which GIZA++ makes search errors in comparison to optimal ILP alignments. GIZA++ makes search errors on 5–15% of sentence pairs, these errors do not contribute to an overall loss in alignment task accuracy, as measured by F-score. on sentence pairs where GIZA++ makes a search error, we plot the average difference in log model scores between GIZA++ and ILP Viterbi alignments in Figure 4. We notice a positive correlation between sentence length and the search error Figure 4 Average difference in log model scores between GIZA++ and ILP alignments at different English sentence lengths for English/Chinese alignment. Points in the plot that appear to be on the actually lie just above it. 300 Ravi and Knight Does GIZA++ Make Search Errors? Figure 5 Average time (msec) taken by the ILP aligner at different English sentence lengths for English/Chinese alignment. The experiments were run on a single machine with a 64-bit, 2.4 GHz AMD Opteron 850 processor. gap between GIZA++ and ILP scores. As we move to longer sentences, the alignment procedure becomes harder and GIZA++ makes more errors. Finally, Figure 5 plots the time taken for ILP alignment at different sentence lengths showing a positive correlation as well. 5. Discussion We have determined that GIZA++ makes few search errors, despite the heuristic nature of the algorithm. These search errors do not materially affect overall alignment accuracy. In practice, this means that researchers should not spend time optimizing this particular aspect of SMT systems. Search errors can occur in many areas of SMT. The area that has received the most attention is runtime decoding/translation. For example, Germann et al. (2001) devise an optimal ILP decoder to identify types of search errors made by other decoders. A second area (this article) is finding Viterbi alignments, given a set of alignment parameter values. A third area is actually learning those parameter values. Brown et al.’s (1993) EM learning algorithm aims to optimize the probability of the French side of the parallel corpus given the English side. For Model 3 and above, Brown et al. collect parameter counts over subsets of alignments, instead of over all alignments. These subsets, like alignments, are generated heuristically, and it may be that true lists of 301 Computational Linguistics Volume 36, Number 3 alignments would yield better counts and better overall parameter values. Of course, even if we were able to collect accurate counts, EM is not guaranteed to find a global optimum, which provides further opportunity for search errors. We leave the problem of search errors in alignment training to future study.</abstract>
<note confidence="0.921475">Acknowledgments This work was supported by NSF grant 0904684 and DARPA GALE Contract Number HR0011-06-C-0022.</note>
<title confidence="0.48135">References</title>
<affiliation confidence="0.778488">Statistical machine translation. Technical report, Johns Hopkins University.</affiliation>
<address confidence="0.406615">Brown, Peter, Vincent Della Pietra,</address>
<author confidence="0.793814">Stephen Della Pietra</author>
<author confidence="0.793814">Robert Mercer</author>
<note confidence="0.68137375">1993. The mathematics of statistical machine translation: Parameter estimation. 19(2):263–311. Germann, Ulrich, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001. Fast decoding and optimal decoding machine translation. In of the 39th Annual Meeting of the Association Computational Linguistics pages 228–235, Toulouse. Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various</note>
<abstract confidence="0.84688025">alignment models. 29(1):19–51. Udupa, Raghavendra and Hemanta K. Maji. 2006. Computational complexity of statistical machine translation. In Proceedings of the Conference of the European Chapter of the Association of Linguistics pages</abstract>
<address confidence="0.6277795">25–32, Trento. 302</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Jan Curin</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>John Lafferty</author>
<author>Franz Josef Och Dan Melamed</author>
<author>David Purdy</author>
<author>Noah Smith</author>
<author>David Yarowsky</author>
</authors>
<title>Statistical machine translation.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>Johns Hopkins University.</institution>
<marker>Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Al-Onaizan, Yaser, Jan Curin, Michael Jahr, Kevin Knight, John Lafferty, Franz Josef Och Dan Melamed, David Purdy, Noah Smith, and David Yarowsky. 1999. Statistical machine translation. Technical report, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>Vincent Della Pietra</author>
<author>Stephen Della Pietra</author>
<author>Robert Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="805" citStr="Brown et al. (1993)" startWordPosition="120" endWordPosition="123">stical machine translation (SMT). Brown et al. (1993) have provided the most popular word alignment algorithm to date, one that has been implemented in the GIZA (Al-Onaizan et al. 1999) and GIZA++ (Och and Ney 2003) software and adopted by nearly every SMT project. In this article, we investigate whether this algorithm makes search errors when it computes Viterbi alignments, that is, whether it returns alignments that are sub-optimal according to a trained model. 1. Background Word alignment is the problem of annotating a bilingual text with links connecting words that have the same meanings. Brown et al. (1993) align an English/French sentence pair by positing a probabilistic model by which an English sentence is translated into French.1 The model provides a set of non-deterministic choices. When a particular sequence of choices is applied to an English input sentence e1...el, the result is a particular French output sentence f1...fm. In the Brown et al. models, a decision sequence also implies a specific word alignment vector a1...am. We say aj = i when French word fj was produced by English word ei during the translation. Here is a sample sentence pair (e, f) and word alignment a: e: NULL0 Mary1 d</context>
<context position="2843" citStr="Brown et al. (1993)" startWordPosition="462" endWordPosition="465">on received: 16 December 2009; accepted for publication: 7 April 2010. © 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 French word has only one English parent. This is why we can represent an alignment as a vector a1...am. There are (l + 1)m ways to align (e, f). For Brown et al. the goal of word alignment is to find the alignment a that is most likely, given a sentence pair (e, f): argmaxa P(a|e,f) = argmaxaP(a,f|e) (1) 2. IBM Model 3 Supplied with a formula for P(a|e,f), we can search through the (l + 1)m alignments for the highest-scoring one. Brown et al. (1993) come up with such a formula by first positing this generative story (IBM Model 3): Given an English sentence e1...el: 1. Choose a fertility φi for each English word ei, according to the distribution n(φi|ei). 2. Let m&apos; = �i=1...l φi. 3. Choose a number φ0 of “spurious” French words, by doing the following m&apos; times: with probability p1, increment φ0 by one. 4. Let m = m&apos; + φ0. 5. Choose a French translation τik for each English word (including e0) and fertility value, according to the distribution t(τik|ei). 6. Choose a French position j for each τik (i &gt; 0), according to d(j|i,l, m). If the s</context>
<context position="4411" citStr="Brown et al. (1993)" startWordPosition="750" endWordPosition="753">nglish position i from that same τik. Different decision sequences can result in the same outputs f and a. With this in mind, Brown et al. provide the following formula: P(a,f|e) = m t(fj|eaj) · Hl n(φi|ei) · m d(j|aj,l, m) H i=1 H j=1 aj#0,j=1 l − Cm φo 0) pφ0 1 ii · po 2φ0 (2) i=0 Note that terms φ0...φl are only shorthand, as their values are completely determined by the alignment a1...am. 296 Ravi and Knight Does GIZA++ Make Search Errors? 3. Finding the Viterbi Alignment We assume that probability tables n, t, d, and p have already been learned from data, using the EM method described by Brown et al. (1993). We are concerned solely with the problem of then finding the best alignment for a given sentence pair (e, f) as described in Equation 1. Brown et al. were unable to discover a polynomial time algorithm for this problem, which was in fact subsequently shown to be NP-complete (Udupa and Maji 2006). Brown et al. therefore devise a hill-climbing algorithm. This algorithm starts with a reasonably good alignment (Viterbi IBM Model 2, computable in quadratic time), after which it greedily executes small changes to the alignment structure, gradually increasing P(a,f|e). The small changes consist of </context>
<context position="7256" citStr="Brown et al. (1993)" startWordPosition="1236" endWordPosition="1239">.3 We then define an objective function whose minimization corresponds to finding the Viterbi IBM Model 3 alignment. Figure 1 presents the components of the objective function, alongside counterparts from the P(a, f|e) formula previously given. Note that the coefficients for the objective function are derived from the already-learned probability tables n, d, t, and p. For each sentence pair in our test set, we create and solve an ILP problem. Figure 2 demonstrates this for a simple example. The reader can extract the optimal alignment from the alignment variables chosen in the ILP solution. 2 Brown et al. (1993) describe a variation called pegging, which carries out multiple additional greedy hill-climbs, each with a different IBM Model 2 Viterbi link fixed (pegged) for the duration of the hill-climb. In practice, pegging is slow, and the vast majority of GIZA++ users do not employ it. 3 The default configuration of GIZA++ includes this same fertility cap of 9, though the Brown et al. (1993) description does not. 297 Computational Linguistics Volume 36, Number 3 Figure 1 Objective function and constraints (left) for the ILP formulation that encodes the problem of selecting the Viterbi alignment for a</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, Peter, Vincent Della Pietra, Stephen Della Pietra, and Robert Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Germann</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Kenji Yamada</author>
</authors>
<title>Fast decoding and optimal decoding for machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>228--235</pages>
<location>Toulouse.</location>
<contexts>
<context position="11277" citStr="Germann et al. (2001)" startWordPosition="1865" endWordPosition="1868">r and GIZA++ makes more errors. Finally, Figure 5 plots the time taken for ILP alignment at different sentence lengths showing a positive correlation as well. 5. Discussion We have determined that GIZA++ makes few search errors, despite the heuristic nature of the algorithm. These search errors do not materially affect overall alignment accuracy. In practice, this means that researchers should not spend time optimizing this particular aspect of SMT systems. Search errors can occur in many areas of SMT. The area that has received the most attention is runtime decoding/translation. For example, Germann et al. (2001) devise an optimal ILP decoder to identify types of search errors made by other decoders. A second area (this article) is finding Viterbi alignments, given a set of alignment parameter values. A third area is actually learning those parameter values. Brown et al.’s (1993) EM learning algorithm aims to optimize the probability of the French side of the parallel corpus given the English side. For Model 3 and above, Brown et al. collect parameter counts over subsets of alignments, instead of over all alignments. These subsets, like Viterbi alignments, are generated heuristically, and it may be th</context>
</contexts>
<marker>Germann, Jahr, Knight, Marcu, Yamada, 2001</marker>
<rawString>Germann, Ulrich, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001. Fast decoding and optimal decoding for machine translation. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 228–235, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>Hemanta K Maji</author>
</authors>
<title>Computational complexity of statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the European Chapter of the Association of Computational Linguistics (EACL),</booktitle>
<pages>25--32</pages>
<location>Trento.</location>
<contexts>
<context position="4709" citStr="Udupa and Maji 2006" startWordPosition="802" endWordPosition="805">ms φ0...φl are only shorthand, as their values are completely determined by the alignment a1...am. 296 Ravi and Knight Does GIZA++ Make Search Errors? 3. Finding the Viterbi Alignment We assume that probability tables n, t, d, and p have already been learned from data, using the EM method described by Brown et al. (1993). We are concerned solely with the problem of then finding the best alignment for a given sentence pair (e, f) as described in Equation 1. Brown et al. were unable to discover a polynomial time algorithm for this problem, which was in fact subsequently shown to be NP-complete (Udupa and Maji 2006). Brown et al. therefore devise a hill-climbing algorithm. This algorithm starts with a reasonably good alignment (Viterbi IBM Model 2, computable in quadratic time), after which it greedily executes small changes to the alignment structure, gradually increasing P(a,f|e). The small changes consist of moves, in which the value of some aj is changed, and swaps, in which a pair aj and ak exchange values. At each step in the greedy search, all possible moves and swaps are considered, and the one which increases P(a,f|e) the most is executed. When P(a,f|e) can no longer be improved, the search halt</context>
</contexts>
<marker>Udupa, Maji, 2006</marker>
<rawString>Udupa, Raghavendra and Hemanta K. Maji. 2006. Computational complexity of statistical machine translation. In Proceedings of the Conference of the European Chapter of the Association of Computational Linguistics (EACL), pages 25–32, Trento.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>