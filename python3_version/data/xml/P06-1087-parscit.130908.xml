<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9971975">
Noun Phrase Chunking in Hebrew
Influence of Lexical and Morphological Features
</title>
<author confidence="0.993297">
Yoav Goldberg and Meni Adler and Michael Elhadad
</author>
<affiliation confidence="0.9718375">
Computer Science Department
Ben Gurion University of the Negev
</affiliation>
<address confidence="0.877343">
P.O.B 653 Be&apos;er Sheva 84105, Israel
</address>
<email confidence="0.998849">
{yoavg,adlerm,elhadad}@cs.bgu.ac.il
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999778545454545">
We present a method for Noun Phrase
chunking in Hebrew. We show that the
traditional definition of base-NPs as non-
recursive noun phrases does not apply in
Hebrew, and propose an alternative defi-
nition of Simple NPs. We review syntac-
tic properties of Hebrew related to noun
phrases, which indicate that the task of
Hebrew SimpleNP chunking is harder
than base-NP chunking in English. As a
confirmation, we apply methods known
to work well for English to Hebrew data.
These methods give low results (F from
76 to 86) in Hebrew. We then discuss our
method, which applies SVM induction
over lexical and morphological features.
Morphological features improve the av-
erage precision by —0.5%, recall by —1%,
and F-measure by —0.75, resulting in a
system with average performance of 93%
precision, 93.4% recall and 93.2 F-
measure.*
</bodyText>
<sectionHeader confidence="0.999469" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9370406">
Modern Hebrew is an agglutinative Semitic lan-
guage, with rich morphology. Like most other
non-European languages, it lacks NLP resources
and tools, and specifically there are currently no
available syntactic parsers for Hebrew. We ad-
dress the task of NP chunking in Hebrew as a
* This work was funded by the Israel Ministry of Sci-
ence and Technology under the auspices of the
Knowledge Center for Processing Hebrew. Addi-
tional funding was provided by the Lynn and William
Frankel Center for Computer Sciences.
first step to fulfill the need for such tools. We
also illustrate how this task can successfully be
approached with little resource requirements, and
indicate how the method is applicable to other
resource-scarce languages.
NP chunking is the task of labelling noun
phrases in natural language text. The input to this
task is free text with part-of-speech tags. The
output is the same text with brackets around base
noun phrases. A base noun phrase is an NP
which does not contain another NP (it is not re-
cursive). NP chunking is the basis for many
other NLP tasks such as shallow parsing, argu-
ment structure identification, and information
extraction
We first realize that the definition of base-NPs
must be adapted to the case of Hebrew (and
probably other Semitic languages as well) to cor-
rectly handle its syntactic nature. We propose
such a definition, which we call simple NPs and
assess the difficulty of chunking such NPs by
applying methods that perform well in English to
Hebrew data. While the syntactic problem in
Hebrew is indeed more difficult than in English,
morphological clues do provide additional hints,
which we exploit using an SVM learning
method. The resulting method reaches perform-
ance in Hebrew comparable to the best results
published in English.
</bodyText>
<sectionHeader confidence="0.999009" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99987275">
Text chunking (and NP chunking in particular),
first proposed by Abney (1991), is a well studied
problem for English. The CoNLL2000 shared
task (Tjong Kim Sang et al., 2000) was general
chunking. The best result achieved for the shared
task data was by Zhang et al (2002), who
achieved NP chunking results of 94.39% preci-
sion, 94.37% recall and 94.38 F-measure using a
</bodyText>
<page confidence="0.986596">
689
</page>
<note confidence="0.537051">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 689–696,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99945724137931">
generalized Winnow algorithm, and enhancing
the feature set with the output of a dependency
parser. Kudo and Matsumoto (2000) used an
SVM based algorithm, and achieved NP chunk-
ing results of 93.72% precision, 94.02% recall
and 93.87 F-measure for the same shared task
data, using only the words and their PoS tags.
Similar results were obtained using Conditional
Random Fields on similar features (Sha and
Pereira, 2003).
The NP chunks in the shared task data are
base-NP chunks – which are non-recursive NPs,
a definition first proposed by Ramshaw and
Marcus (1995). This definition yields good NP
chunks for English, but results in very short and
uninformative chunks for Hebrew (and probably
other Semitic languages).
Recently, Diab et al (2004) used SVM based
approach for Arabic text chunking. Their chunks
data was derived from the LDC Arabic TreeBank
using the same program that extracted the chunks
for the shared task. They used the same features
as Kudo and Matsumoto (2000), and achieved
over-all chunking performance of 92.06% preci-
sion, 92.09% recall and 92.08 F-measure (The
results for NP chunks alone were not reported).
Since Arabic syntax is quite similar to Hebrew,
we expect that the issues reported below apply to
Arabic results as well.
</bodyText>
<sectionHeader confidence="0.992154" genericHeader="method">
3 Hebrew Simple NP Chunks
</sectionHeader>
<bodyText confidence="0.999725538461538">
The standard definition of English base-NPs is
any noun phrase that does not contain another
noun phrase, with possessives treated as a special
case, viewing the possessive marker as the first
word of a new base-NP (Ramshaw and Marcus,
1995). To evaluate the applicability of this defi-
nition to Hebrew, we tested this definition on the
Hebrew TreeBank (Sima’an et al, 2001) pub-
lished by the Hebrew Knowledge Center. We
extracted all base-NPs from this TreeBank,
which is similar in genre and contents to the
English one. This results in extremely simple
chunks.
</bodyText>
<table confidence="0.992858333333334">
English Hebrew Hebrew
BaseNPs BaseNPs SimpleNPs
Avg # of words 2.17 1.39 2.49
% length 1 30.95 63.32 32.83
% length 2 39.35 35.48 32.12
% length 3 18.68 0.83 14.78
% length 4 6.65 0.16 9.47
% length 5 2.70 0.16 4.56
% length &gt; 5 1.67 0.05 6.22
</table>
<tableCaption confidence="0.999897">
Table 1. Size of Hebrew and English NPs
</tableCaption>
<bodyText confidence="0.993598714285714">
Table 1 shows the average number of words in a
base-NP for English and Hebrew. The Hebrew
chunks are basically one-word groups around
Nouns, which is not useful for any practical pur-
pose, and so we propose a new definition for He-
brew NP chunks, which allows for some nested-
ness. We call our chunks Simple NP chunks.
</bodyText>
<subsectionHeader confidence="0.999947">
3.1 Syntax of NPs in Hebrew
</subsectionHeader>
<bodyText confidence="0.999457166666667">
One of the reasons the traditional base-NP defi-
nition fails for the Hebrew TreeBank is related to
syntactic features of Hebrew – specifically,
smixut (construct state – used to express noun
compounds), definite marker and the expression
of possessives. These differences are reflected to
some extent by the tagging guidelines used to
annotate the Hebrew Treebank and they result in
trees which are in general less flat than the Penn
TreeBank ones.
Consider the example base noun phrase [The
homeless people]. The Hebrew equivalent is
</bodyText>
<equation confidence="0.935026">
(1) n,2,7 ,�c7m n,wix,7
</equation>
<bodyText confidence="0.975609826086957">
which by the non-recursive NP definition will be
bracketed as:
[n,2 ,7� ,�c7�� [n,wix ,7�, or, loosely translating
back to English: [the home]less [people].
In this case, the fact that the bound-morpheme
less appears as a separate construct state word
with its own definite marker (ha-) in Hebrew
would lead the chunker to create two separate
NPs for a simple expression. We present below
syntactic properties of Hebrew which are rele-
vant to NP chunking. We then present our defini-
tion of Simple NP Chunks.
Construct State: The Hebrew genitive case is
achieved by placing two nouns next to each other.
This is called “noun construct”, or smixut. The
semantic interpretation of this construct is varied
(Netzer and Elhadad, 1998), but it specifically
covers possession. The second noun can be
treated as an adjective modifying the next noun.
The first noun is morphologically marked in a
form known as the construct form (denoted by
const). The definite article marker is placed on
the second word of the construction:
</bodyText>
<figure confidence="0.689089">
(2) -iE)o n-a
beit sefer / house-[const] book
School
(3) -iE)on n-a
beit ha-sefer / house-[const] the-book
</figure>
<subsectionHeader confidence="0.427518">
The school
</subsectionHeader>
<bodyText confidence="0.828468">
The construct form can also be embedded:
</bodyText>
<listItem confidence="0.602453">
(4) nyvinnn vix-i --ivin
</listItem>
<page confidence="0.922246">
690
</page>
<figure confidence="0.31301">
misrad ro$ ha-mem$ala
Office-[const poss] head-[const] the-government
</figure>
<subsectionHeader confidence="0.649529">
The prime-minister’s office
</subsectionHeader>
<bodyText confidence="0.998064166666667">
Possessive: the smixut form can be used to indi-
cate possession. Other ways to express posses-
sion include the possessive marker &apos;gym - ‘$el’ /
‘of’ - (5), or adding a possessive suffix on the
noun (6). The various forms can be mixed to-
gether, as in (7):
</bodyText>
<figure confidence="0.9363304">
(5) -5vj man
ha-bait $el-i / the-house of-[poss 1st person]
My house
(6) m-a
beit-i / house-[poss 1st person]
My house
(7) nyvinnn vix-i yvi invin
misrad-o $el ro$ ha-mem$ala
Office-[poss 3rd] of head-[const] the-government
The prime minister office
</figure>
<listItem confidence="0.8905145">
Adjective: Hebrew adjectives come after the
noun, and agree with it in number, gender and
definite marker:
(8) i7n-n mmnn
</listItem>
<bodyText confidence="0.9990175">
ha-tapu’ah ha-yarok / the-Apple the-green
The green apple
Some aspects of the predicate structure in He-
brew directly affect the task of NP chunking, as
they make the decision to “split” NPs more or
less difficult than in English.
Word order and the preposition &apos;et&apos;: Hebrew
sentences can be either in SVO or VSO form. In
order to keep the object separate from the sub-
ject, definite direct objects are marked with the
special preposition &apos;et&apos;, which has no analog in
English.
Possible null equative: The equative form in
Hebrew can be null. Sentence (9) is a non-null
equative, (10) a null equative, while (11) and
(12) are predicative NPs, which look very similar
to the null-equative form:
Morphological Issues: In Hebrew morphology,
several lexical units can be concatenated into a
single textual unit. Most prepositions, the defi-
nite article marker and some conjunctions are
concatenated as prefixes, and possessive pro-
nouns and some adverbs are concatenated as suf-
fixes. The Hebrew Treebank is annotated over a
segmented version of the text, in which prefixes
and suffixes appear as separate lexical units. On
the other hand, many bound morphemes in Eng-
lish appear as separate lexical units in Hebrew.
For example, the English morphemes re-, ex-,
un-, -less, -like, -able, appear in Hebrew as sepa-
rate lexical units – mann, -inum�, �n&apos;��/�H/rt&apos;�, -iorn, nn-r,
-in, .x&apos; ,,n&apos; n ,norn
In our experiment, we use as input to the
chunker the text after it has been morphologi-
cally disambiguated and segmented. Our
analyzer provides segmentation and PoS tags
with 92.5% accuracy and full morphology with
88.5% accuracy (Adler and Elhadad, 2006).
</bodyText>
<subsectionHeader confidence="0.99951">
3.2 Defining Simple NPs
</subsectionHeader>
<bodyText confidence="0.999622636363636">
Our definition of Simple NPs is pragmatic. We
want to tag phrases that are complete in their
syntactic structure, avoid the requirement of tag-
ging recursive structures that include full clauses
(relative clauses for example) and in general, tag
phrases that have a simple denotation. To estab-
lish our definition, we start with the most com-
plex NPs, and break them into smaller parts by
stating what should not appear inside a Simple
NP. This can be summarized by the following
table:
</bodyText>
<table confidence="0.897983714285714">
Outside SimpleNP Exceptions
Prepositional Phrases % related PPs are
Relative Clauses allowed:
Verb Phrases nn-min n 5%
Apposition1 5% of the sales
Some conjunctions
(Conjunctions are Possessive 3� - &apos;$el&apos; /
</table>
<bodyText confidence="0.999666411764706">
marked according to the &apos;of&apos; - is not consid-
TreeBank guidelines)2. ered a PP
(9) yrri xin man (10) yrn n-an Table 2. Definition of Simple NP chunks
ha-bait hu gadol ha-bait gadol Examples for some Simple NP chunks resulting
The-house is big The-house big from that definition:
The house is big The house is big
(11) yrri n-a (12) yrrin n-an
bait gadol ha-bait ha-gadol
House big The-house the-big
A big house The big house
1 Apposition structure is not annotated in the TreeBank. As
a heuristic, we consider every comma inside a non conjunct-
ive NP which is not followed by an adjective or an adjective
phrase to be marking the beginning of an apposition.
2
As a special case, Adjectival Phrases and possessive con-
junctions are considered to be inside the Simple NP.
</bodyText>
<page confidence="0.778025">
691
</page>
<equation confidence="0.462868">
nninni nTnyn nmvii � a ymnx n112nn [ it nyE)in ]
[O&apos;1T O&apos;71131 n70lln xVJ13 ] 1 n]TVJ [n0Dn `VJ
</equation>
<bodyText confidence="0.968400538461539">
[This phenomenon] was highlighted yesterday at
[the labor and welfare committee-const of the
Knesset] that dealt with [the topic-const of for-
eign workers employment-const].
[The employers] do not expect to succeed in at-
tracting [a significant number of Israeli workers]
for [the fruit-picking] because of [the low salaries]
paid for [this work].
This definition can also yield some rather long
and complex chunks, such as:
[ I`VJ &apos;loon &apos;`JI.131nn xaynl xn 0&apos;.13&apos;.1 `VJ �������� �
[The conquests of Genghis Khan and his Mongol
Tartar army]
</bodyText>
<equation confidence="0.699623666666667">
novi ] yy [ o-yyE)n � ![ Dmi7n -*vjnn -T-7E) na-r ] y
3 . 7 yu -10 � i-1-12Y VJ [ i13VJ in � a in-inn [ nou
oyu nx ] vi ! � � -*rT -rix-yro 2 . 2 ) ���� �������
</equation>
<bodyText confidence="0.930509333333333">
[ napom ] nnpy
According to [reports of local government offi-
cials], [factories] on [Tartar territory] earned in
[the year] that passed [a sum of 3.7 billion Rb (2.2
billion dollars)], which [Moscow] took [almost all].
Note that Simple NPs are split, for example, by
the preposition ‘on’ ([factories] on [Tartar terri-
tory]), and by a relative clause ([a sum of 3.7Bn
Rb] which [Moscow] took [almost all]).
</bodyText>
<subsectionHeader confidence="0.6387215">
3.3 Hebrew Simple NPs are harder
than English base NPs
</subsectionHeader>
<bodyText confidence="0.98162">
The Simple NPs derived from our definition are
highly coherent units, but are also more complex
than the non-recursive English base NPs.
As can be seen in Table 1, our definition of Sim-
ple NP yields chunks which are on average con-
siderably longer than the English chunks, with
about 20% of the chunks with 4 or more words
(as opposed to about 10% in English) and a sig-
nificant portion (6.22%) of chunks with 6 or
more words (1.67% in english).
Moreover, the baseline used at the CoNLL
shared task4 (selecting the chunk tag which was
most frequently associated with the current PoS)
3 For readers familiar with Hebrew and feel that n�lvn; t is
an adjective and should be inside the NP, we note that this is
not the case – n�lvn; t here is actually a Verb in the Beinoni
form and the definite marker is actually used as relative
marker.
</bodyText>
<footnote confidence="0.718304">
4 http://www.cnts.ua.ac.be/conll2000/chunking/
</footnote>
<bodyText confidence="0.995484">
gives far inferior results for Hebrew SimpleNPs
(see Table 3).
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="method">
4 Chunking Methods
</sectionHeader>
<subsectionHeader confidence="0.96401">
4.1 Baseline Approaches
</subsectionHeader>
<bodyText confidence="0.99999290625">
We have experimented with different known
methods for English NP chunking, which re-
sulted in poor results for Hebrew. We describe
here our experiment settings, and provide the
best scores obtained for each method, in com-
parison to the reported scores for English.
All tests were done on the corpus derived from
the Hebrew Tree Bank. The corpus contains
5,000 sentences, for a total of 120K tokens (ag-
glutinated words) and 27K NP chunks (more de-
tails on the corpus appear below). The last 500
sentences were used as the test set, and all the
other sentences were used for training. The re-
sults were evaluated using the CoNLL shared
task evaluation tools 5 . The approaches tested
were Error Driven Pruning (EDP) (Cardie and
Pierce, 1998) and Transformational Based Learn-
ing of IOB tagging (TBL) (Ramshaw and Mar-
cus, 1995).
The Error Driven Pruning method does not
take into account lexical information and uses
only the PoS tags. For the Transformation Based
method, we have used both the PoS tag and the
word itself, with the same templates as described
in (Ramshaw and Marcus, 1995). We tried the
Transformational Based method with more fea-
tures than just the PoS and the word, but ob-
tained lower performance. Our best results for
these methods, as well as the CoNLL baseline
(BASE), are presented in Table 3. These results
confirm that the task of Simple NP chunking is
harder in Hebrew than in English.
</bodyText>
<subsectionHeader confidence="0.997163">
4.2 Support Vector Machines
</subsectionHeader>
<bodyText confidence="0.999768454545455">
We chose to adopt a tagging perspective for
the Simple NP chunking task, in which each
word is to be tagged as either B, I or O depend-
ing on wether it is in the Beginning, Inside, or
Outside of the given chunk, an approach first
taken by Ramshaw and Marcus (1995), and
which has become the de-facto standard for this
task. Using this tagging method, chunking be-
comes a classification problem – each token is
predicted as being either I, O or B, given features
from a predefined linguistic context (such as the
</bodyText>
<footnote confidence="0.738791">
5http://www.cnts.ua.ac.be/conll2000/chunking/conllev
al.txt
</footnote>
<figure confidence="0.9981406875">
]
55.12
[9&apos;07]
y
[
O&amp;quot;`Jx1VJ&apos; O&apos;711.1
DyivJnn [1in3n 13Wn
yVJ 13&apos;3 19on] 1ivjn`J In&apos;`JYw O&apos;9yn D3&apos;x [O-irovnn
3
]
]
y
.[
it nTny
[
ovn:)
</figure>
<page confidence="0.983364">
692
</page>
<bodyText confidence="0.998622090909091">
words surrounding the given word, and their PoS
tags).
One model that allows for this prediction is
Support Vector Machines - SVM (Vapnik,
1995). SVM is a supervised machine learning
algorithm which can handle gracefully a large set
of overlapping features. SVMs learn binary clas-
sifiers, but the method can be extended to multi-
class classification (Allwein et al., 2000; Kudo
and Matsumoto, 2000).
SVMs have been successfully applied to many
NLP tasks since (Joachims, 1998), and specifi-
cally for base phrase chunking (Kudo and Ma-
tsumoto, 2000; 2003). It was also successfully
used in Arabic (Diab et al., 2004).
The traditional setting of SVM for chunking
uses for the context of the token to be classified a
window of two tokens around the word, and the
features are the PoS tags and lexical items (word
forms) of all the tokens in the context. Some set-
tings (Kudo and Matsumoto, 2000) also include
the IOB tags of the two “previously tagged” to-
kens as features (see Fig. 1).
This setting (including the last 2 IOB tags)
performs nicely for the case of Hebrew Simple
NPs chunking as well.
Linguistic features are mapped to SVM fea-
ture vectors by translating each feature such as
“PoS at location n-2 is NOUN” or “word at loca-
tion n+1 is DOG” to a unique vector entry, and
setting this entry to 1 if the feature occurs, and 0
otherwise. This results in extremely large yet
extremely sparse feature vectors.
</bodyText>
<table confidence="0.998793666666667">
Method English Hebrew Sim-
BaseNPs pleNPs
Prec Rec Prec Rec F
BASE 72.58 82.14 64.7 75.4 69.78
EDP 92.7 93.7 74.6 78.1 76.3
TBL 91.3 91.8 84.7 87.7 86.2
</table>
<tableCaption confidence="0.829768">
Table 3. Baseline results for Simple NP chunking
</tableCaption>
<table confidence="0.9202962">
SVM Chunking in Hebrew
WORD POS CHUNK
� NA B-NP
P!LKJO NOUN I-NP Feature
1&apos;L PREP O Set
</table>
<footnote confidence="0.376988">
W700 NOUN I-NP
</footnote>
<figureCaption confidence="0.8166095">
Figure 1. Linguistic features considered in the
basic SVM setting for Hebrew
</figureCaption>
<subsectionHeader confidence="0.995087">
4.3 Augmentation of Morphological
Features
</subsectionHeader>
<bodyText confidence="0.999983826086956">
Hebrew is a morphologically rich language. Re-
cent PoS taggers and morphological analyzers
for Hebrew (Adler and Elhadad, 2006) address
this issue and provide for each word not only the
PoS, but also full morphological features, such as
Gender, Number, Person, Construct, Tense, and
the affixes&apos; properties. Our system, currently,
computes these features with an accuracy of
88.5%.
Our original intuition is that the difficulty of
Simple NP chunking can be overcome by relying
on morphological features in a small context.
These features would help the classifier decide
on agreement, and split NPs more accurately.
Since SVMs can handle large feature sets, we
utilize additional morphological features. In par-
ticular, we found the combination of the Number
and the Construct features to be most effective in
improving chunking results. Indeed, our experi-
ments show that introducing morphological fea-
tures improves chunking quality by as much as
3-point in F-measure when compared with lexi-
cal and PoS features only.
</bodyText>
<sectionHeader confidence="0.998382" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<subsectionHeader confidence="0.949316">
5.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.99435455">
The Hebrew TreeBank6 consists of 4,995 hand
annotated sentences from the Ha’aretz newspa-
per. Besides the syntactic structure, every word
is PoS annotated, and also includes morphologi-
cal features. The words in the TreeBank are
segmented: nru &apos;gym m i ;i :i (instead of n ty mri).
Our morphological analyzer also provides such
segmentation.
We derived the Simple NPs structure from the
TreeBank using the definition given in Section
3.2. We then converted the original Hebrew
TreeBank tagset to the tagset of our PoS tagger.
For each token, we specify its word form, its
PoS, its morphological features, and its correct
IOB tag. The result is the Hebrew Simple NP
chunks corpus7. The corpus consists of 4,995
sentences, 27,226 chunks and 120,396 seg-
mented tokens. 67,919 of these tokens are cov-
ered by NP chunks. A sample annotated sentence
is given in Fig. 2.
</bodyText>
<footnote confidence="0.906516">
6http://mila.cs.technion.ac.il/website/english/resources
/corpora/treebank/index.html
7 http://www.cs.bgu.ac.il/~nlpproj/chunking
</footnote>
<figure confidence="0.7597065">
7110111 NAME B-NP
y PREP O
01 NA B-NP
Estimated Tag
</figure>
<page confidence="0.995771">
693
</page>
<note confidence="0.999228727272727">
* PREPOSITION NA NA N NA N NA N NA NA O
� DEF_ART NA NA N NA N NA N NA NA B-NP
-iav NOUN M S N NA N NA N NA NA I-NP
n&apos;n AUXVERB M S N 3 N PAST N NA NA O
�p ADJECTIVE M S N NA N NA N NA NA O
-illi&apos; ADVERB NA NA N NA N NA N NA NA O
N1-lp� VERB NA NA N NA Y TOINF N NA NA O
PN ET_PREP NA NA N NA N NA N NA NA B-NP
� DEF_ART NA NA N NA N NA N NA NA I-NP
nen NOUN F S N NA N NA N NA NA I-NP
. PUNCUATION NA NA N NA N NA N NA NA O
</note>
<figureCaption confidence="0.999452">
Figure 2. A Sample annotated sentence
</figureCaption>
<subsectionHeader confidence="0.922593">
5.2 Morphological Features:
</subsectionHeader>
<table confidence="0.95521412">
The PoS tagset we use consists of 22 tags:
ADJECTIVE ADVERB ET_PREP
AUXVERB CONJUNCTION DEF_ART
DETERMINER EXISTENTIAL INTERJECTION
INTEROGATIVE MODAL NEGATION
PARTICLE NOUN NUMBER
PRONOUN PREFIX PREPOSITION
UNKNOWN PROPERNAME PUNCTUATION
VERB
For each token, we also supply the following
morphological features (in that order):
Feature Possible Values
Gender (M)ale, (F)emale,
(B)oth (unmarked case), (NA)
Number (S)ingle, (P)lurar, (D)ual,
can be (ALL), (NA)
Construct (Y)es, (N)o
Person (1)st, (2)nd, (3)rd, (123)all, (NA)
To-Infinitive (Y)es, (N)o
Tense Past, Present, Future, Beinoni,
Imperative, ToInf, BareInf
(has) Suffix (Y)es, (N)o
Suffix-Num (M)ale, (F)emale, (B)oth, (NA)
Suffix-Gen (S)ingle, (P)lurar, (D)ual, (DP)-
dual plural, can be (ALL), (NA)
</table>
<bodyText confidence="0.998717833333333">
As noted in (Rambow and Habash 2005), one
cannot use the same tagset for a Semitic lan-
guage as for English. The tagset we have de-
rived has been extensively validated through
manual tagging by several testers and cross-
checked for agreement.
</bodyText>
<subsectionHeader confidence="0.998039">
5.3 Setup and Evaluation
</subsectionHeader>
<bodyText confidence="0.9998322">
For all the SVM chunking experiments, we use
the YamCha 8 toolkit (Kudo and Matsumoto,
2003). We use forward moving tagging, using
standard SVM with polynomial kernel of degree
2, and C=1. For the multiclass classification, we
</bodyText>
<footnote confidence="0.658614">
8 http://chasen.org/~taku/software/yamcha/
</footnote>
<bodyText confidence="0.99993015">
use pairwise voting. For all the reported experi-
ments, we chose the context to be a –2/+2 tokens
windows, centered at the current token.
We use the standard metrics of accuracy (% of
correctly tagged tokens), precision, recall and F-
measure, with the only exception of normalizing
all punctuation tokens from the data prior to
evaluation, as the TreeBank is highly inconsis-
tent regarding the bracketing of punctuations,
and we don’t consider the exclusions/inclusions
of punctuations from our chunks to be errors
(i.e., “[a book ,] [an apple]” “[a book] , [an ap-
ple]” and “[a book] [, an apple]” are all equiva-
lent chunkings in our view).
All our development work was done with the
first 500 sentences allocated for testing, and the
rest for training. For evaluation, we used a 10-
fold cross-validation scheme, each time with dif-
ferent consecutive 500 sentences serving for test-
ing and the rest for training.
</bodyText>
<subsectionHeader confidence="0.96733">
5.4 Features Used
</subsectionHeader>
<bodyText confidence="0.999950176470588">
We run several SVM experiments, each with the
settings described in section 5.3, but with a dif-
ferent feature set. In all of the experiments the
two previously tagged IOB tags were included in
the feature set. In the first experiment (denoted
WP) we considered the word and PoS tags of the
context tokens to be part of the feature set.
In the other experiments, we used different
subsets of the morphological features of the to-
kens to enhance the features set. We found that
good results were achieved by using the Number
and Construct features together with the word
and PoS tags (we denote this WPNC). Bad re-
sults were achieved when using all the morpho-
logical features together. The usefulness of fea-
ture sets was stable across all tests in the ten-fold
cross validation scheme.
</bodyText>
<subsectionHeader confidence="0.557912">
5.5 Results
</subsectionHeader>
<bodyText confidence="0.999094142857143">
We discuss the results of the WP and WPNC
experiments in details, and also provide the re-
sults for the WPG (using the Gender feature),
and ALL (using all available morphological fea-
tures) experiments, and P (using only PoS tags).
As can be seen in Table 4, lexical information
is very important: augmenting the PoS tag with
lexical information boosted the F-measure from
77.88 to 92.44. The addition of the extra mor-
phological features of Construct and Number
yields another increase in performance, resulting
in a final F-measure of 93.2%. Note that the ef-
fect of these morphological features on the over-
all accuracy (the number of BIO tagged cor-
</bodyText>
<page confidence="0.996645">
694
</page>
<bodyText confidence="0.999678695652174">
rectly) is minimal (Table 5), yet the effect on the
precision and recall is much more significant. It
is also interesting to note that the Gender feature
hurts performance, even though Hebrew has
agreement on both Number and Gender. We do
not have a good explanation for this observation
– but we are currently verifying the consistency
of the gender annotation in the corpus (in par-
ticular, the effect of the unmarked gender tag).
We performed the WP and WPNC experiment
on two forms of the corpus: (1) WP,WPNC using
the manually tagged morphological features in-
cluded in the TreeBank and (2) WPE, WPNCE
using the results of our automatic morphological
analyzer, which includes about 10% errors (both
in PoS and morphological features). With the
manual morphology tags, the final F-measure is
93.20, while it is 91.40 with noise. Interestingly,
the improvement brought by adding morphologi-
cal features to chunking in the noisy case
(WPNCE) is almost 3.0 F-measure points (as
opposed to 0.758 for the &amp;quot;clean&amp;quot; morphology
case WPNC).
</bodyText>
<table confidence="0.998704">
Features Acc Prec Rec F
P 91.77 77.03 78.79 77.88
WP 97.49 92.54 92.35 92.44
WPE 94.87 89.14 87.69 88.41
WPG 97.41 92.41 92.22 92.32
ALL 96.68 90.21 90.60 90.40
WPNC 97.61 92.99 93.41 93.20
WPNCE 96.99 91.49 91.32 91.40
</table>
<tableCaption confidence="0.996122">
Table 4. SVM results for Hebrew
</tableCaption>
<table confidence="0.999674333333333">
Features Prec Rec F
WPNC 0.456 1.058 0.758
WPNCE 2.35 3.60 2.99
</table>
<tableCaption confidence="0.999243">
Table 5. Improvement over WP
</tableCaption>
<subsectionHeader confidence="0.883101">
5.6 Error Analysis and the Effect of
Morphological Features
</subsectionHeader>
<bodyText confidence="0.999587">
We performed detailed error analysis on the
WPNC results for the entire corpus. At the indi-
vidual token level, Nouns and Conjunctions
caused the most confusion, followed by Adverbs
and Adjectives. Table 6 presents the confusion
matrix for all POSs with a substantial amount of
errors. I�O means that the correct chunk tag was
I, but the system classified it as O. By examin-
ing the errors on the chunks level, we identified 7
common classes of errors:
Conjunction related errors: bracketing “[a]
and [b]” instead of “[a and b]” and vice versa.
Split errors: bracketing [a][b] instead of [a b]
Merge errors: bracketing [a b] instead of [a][b]
Short errors: bracketing “a [b]” or “[a] b” in-
stead of [a b]
Long errors: bracketing “[a b]” instead of “[a]
b” or “a [b]”
Whole Chunk errors: either missing a whole
chunk, or bracketing something which doesn’t
overlap with a chunk at all (extra chunk).
Missing/ExtraToken errors: this is a general-
ized form of conjunction errors: either “[a] T
[b]” instead of “[a T b]” or vice versa, where T
is a single token. The most frequent of such
words (other than the conjuncts) was &apos;�V - the
possessive &apos;$el&apos;.
</bodyText>
<subsectionHeader confidence="0.340748">
Table 6. WPNC Confusion Matrix
</subsectionHeader>
<bodyText confidence="0.999917045454546">
The data in Table 6 suggests that Adverbs and
Adjectives related errors are mostly of the
“short” or “long” types, while the Noun (includ-
ing proper names and pronouns) related errors
are of the “split” or “merge” types.
The most frequent error type was conjunction
related, closely followed by split and merge.
Much less significant errors were cases of extra
Adverbs or Adjectives at the end of the chunk,
and missing adverbs before or after the chunk.
Conjunctions are a major source of errors for
English chunking as well (Ramshaw and Marcus,
1995, Cardie and Pierce, 1998)9, and we plan to
address them in future work. The split and merge
errors are related to argument structure, which
can be more complicated in Hebrew than in Eng-
lish, because of possible null equatives. The too-
long and too-short errors were mostly attachment
related. Most of the errors are related to linguis-
tic phenomena that cannot be inferred by the lo-
calized context used in our SVM encoding. We
examine the types of errors that the addition of
</bodyText>
<footnote confidence="0.55932675">
9 Although base-NPs are by definition non-recursive,
they may still contain CCs when the coordinators are
‘trapped’: “[securities and exchange commission]” or
conjunctions of adjectives.
</footnote>
<page confidence="0.982262">
695
</page>
<table confidence="0.994340307692308">
Number and Construct features fixed. Table 7 editors, Principle Based Parsing. Kluwer Aca-
summarizes this information. demic Publishers.
ERROR WP WPNC # Fixed % Fixed
CONJUNCTION 256 251 5 1.95
SPLIT 198 225 -27 -13.64
MERGE 366 222 144 39.34
LONG (ADJ AFTER) 120 117 3 2.50
EXTRA CHUNK 89 88 1 1.12
LONG (ADV AFTER) 77 81 -4 -5.19
SHORT (ADV AFTER) 67 65 2 2.99
MISSING CHUNK 50 54 -4 -8.00
SHORT (ADV BEFORE) 53 48 5 9.43
EXTRA `vj TOK 47 47 0 0.00
</table>
<tableCaption confidence="0.9898">
Table 7. Effect of Number and Construct informa-
tion on most frequent error classes
</tableCaption>
<bodyText confidence="0.999985">
The error classes most affected by the number
and construct information were split and merge –
WPNC has a tendency of splitting chunks, which
resulted in some unjustified splits, but compen-
sates this by fixing over a third of the merging
mistakes. This result makes sense – construct and
local agreement information can aid in the identi-
fication of predicate boundaries. This confirms
our original intuition that morphological features
do help in identifying boundaries of NP chunks.
</bodyText>
<sectionHeader confidence="0.997112" genericHeader="conclusions">
6 Conclusion and Future work
</sectionHeader>
<bodyText confidence="0.999995388888889">
We have noted that due to syntactic features such
as smixut, the traditional definition of base NP
chunks does not translate well to Hebrew and
probably to other Semitic languages. We defined
the notion of Simple NP chunks instead. We
have presented a method for identifying Hebrew
Simple NPs by supervised learning using SVM,
providing another evidence for the suitability of
SVM to chunk identification.
We have also shown that using morphological
features enhances chunking accuracy. However,
the set of morphological features used should be
chosen with care, as some features actually hurt
performance.
Like in the case of English, a large part of the
errors were caused by conjunctions – this prob-
lem clearly requires more than local knowledge.
We plan to address this issue in future work.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999718929824562">
Meni Adler and Michael Elhadad, 2006. Unsuper-
vised Morpheme-based HMM for Hebrew Mor-
phological Disambiguation. In Proc. of
COLING/ACL 2006, Sidney.
Steven P. Abney. 1991. Parsing by Chunks. In Robert
C. Berwick, Steven P. Abney, and Carol Tenny
Erin L. Allwein, Robert E. Schapire, and Yoram
Singer. 2000. Reducing Multiclass to Binary: A
Unifying Approach for Margin Classifiers. Journal
of Machine Learning Research, 1:113-141.
Claire Cardie and David Pierce. 1998. Error-Driven
Pruning of Treebank Grammars for Base Noun
Phrase Identification. In Proc. of COLING-98,
Montréal.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004. Automatic Tagging of Arabic Text: From
Raw Text to Base Phrase Chunks, In Proc. of
HLT/NAACL 2004, Boston.
Nizar Habash and Owen Rambow, 2005. Arabic To-
kenization, Part-of-speech Tagging and Mor-
phological Disambiguation in One Fell Swoop. In
Proc. of ACL 2005, Ann Arbor.
Thorsten Joachims. 1998. Text Categorization with
Support Vector Machines: Learning with Many
Relevant Features. In Proc. of ECML-98,
Chemnitz.
Taku Kudo and Yuji Matsumato. 2000. Use of Sup-
port Vector Learning for Chunk Identification. In
Proc. of CoNLL-2000 and LLL-2000, Lisbon.
Taku Kudo and Yuji Matsumato. 2003. Fast Methods
for Kernel-Based Text Analysis. In Proc. of ACL
2003, Sapporo.
Yael Netzer-Dahan and Michael Elhadad, 1998. Gen-
eration of Noun Compounds in Hebrew: Can Syn-
tactic Knowledge be Fully Encapsulated? In Proc.
of INLG-98, Ontario.
Lance A. Ramshaw and Mitchel P. Marcus. 1995.
Text Chunking Using Transformation-based Learn-
ing. In Proc. of the 3rd ACL Workshop on Very
Large Corpora. Cambridge.
Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman
and N. Nativ, 2001. Building a Tree-bank of Mod-
ern Hebrew Text, in Traitement Automatique des
Langues 42(2).
Fei Sha and Fernando Pereira. 2003. Shallow Parsing
with Conditional Random Fields. Technical Report
CIS TR MS-CIS-02-35, University of Pennsylvania.
Erik F. Tjong Kim Sang and Sabine Buchholz. 2000.
Introduction to the CoNLL-2000 Shared Task:
Chunking. In Proc. of CoNLL-2000 and LLL-2000,
Lisbon.
Vladimir Vapnik. 1995. The Nature of Statistical
Learning Theory. Springer Verlag, New York, NY.
Tong Zhang, Fred Damerau and David Johnson.
2002. Text Chunking based on a Generalization of
Winnow. Journal of Machine Learning Research,
2: 615-637.
</reference>
<page confidence="0.99875">
696
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.275855">
<title confidence="0.9993175">Noun Phrase Chunking in Hebrew Influence of Lexical and Morphological Features</title>
<author confidence="0.999227">Yoav Goldberg</author>
<author confidence="0.999227">Meni Adler</author>
<author confidence="0.999227">Michael Elhadad</author>
<affiliation confidence="0.782791">Computer Science Department Ben Gurion University of the Negev</affiliation>
<address confidence="0.972255">P.O.B 653 Be&apos;er Sheva 84105, Israel</address>
<email confidence="0.998502">yoavg@cs.bgu.ac.il</email>
<email confidence="0.998502">adlerm@cs.bgu.ac.il</email>
<email confidence="0.998502">elhadad@cs.bgu.ac.il</email>
<abstract confidence="0.998391523809524">We present a method for Noun Phrase chunking in Hebrew. We show that the traditional definition of base-NPs as nonrecursive noun phrases does not apply in Hebrew, and propose an alternative definition of Simple NPs. We review syntactic properties of Hebrew related to noun phrases, which indicate that the task of Hebrew SimpleNP chunking is harder than base-NP chunking in English. As a confirmation, we apply methods known to work well for English to Hebrew data. These methods give low results (F from 76 to 86) in Hebrew. We then discuss our method, which applies SVM induction over lexical and morphological features. Morphological features improve the average precision by —0.5%, recall by —1%, and F-measure by —0.75, resulting in a system with average performance of 93%</abstract>
<intro confidence="0.492048">precision, 93.4% recall and 93.2 F-</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>Unsupervised Morpheme-based HMM for Hebrew Morphological Disambiguation.</title>
<date>2006</date>
<booktitle>In Proc. of COLING/ACL 2006,</booktitle>
<location>Sidney.</location>
<contexts>
<context position="10084" citStr="Adler and Elhadad, 2006" startWordPosition="1658" endWordPosition="1661">gmented version of the text, in which prefixes and suffixes appear as separate lexical units. On the other hand, many bound morphemes in English appear as separate lexical units in Hebrew. For example, the English morphemes re-, ex-, un-, -less, -like, -able, appear in Hebrew as separate lexical units – mann, -inum�, �n&apos;��/�H/rt&apos;�, -iorn, nn-r, -in, .x&apos; ,,n&apos; n ,norn In our experiment, we use as input to the chunker the text after it has been morphologically disambiguated and segmented. Our analyzer provides segmentation and PoS tags with 92.5% accuracy and full morphology with 88.5% accuracy (Adler and Elhadad, 2006). 3.2 Defining Simple NPs Our definition of Simple NPs is pragmatic. We want to tag phrases that are complete in their syntactic structure, avoid the requirement of tagging recursive structures that include full clauses (relative clauses for example) and in general, tag phrases that have a simple denotation. To establish our definition, we start with the most complex NPs, and break them into smaller parts by stating what should not appear inside a Simple NP. This can be summarized by the following table: Outside SimpleNP Exceptions Prepositional Phrases % related PPs are Relative Clauses allow</context>
<context position="17918" citStr="Adler and Elhadad, 2006" startWordPosition="3021" endWordPosition="3024">ise. This results in extremely large yet extremely sparse feature vectors. Method English Hebrew SimBaseNPs pleNPs Prec Rec Prec Rec F BASE 72.58 82.14 64.7 75.4 69.78 EDP 92.7 93.7 74.6 78.1 76.3 TBL 91.3 91.8 84.7 87.7 86.2 Table 3. Baseline results for Simple NP chunking SVM Chunking in Hebrew WORD POS CHUNK � NA B-NP P!LKJO NOUN I-NP Feature 1&apos;L PREP O Set W700 NOUN I-NP Figure 1. Linguistic features considered in the basic SVM setting for Hebrew 4.3 Augmentation of Morphological Features Hebrew is a morphologically rich language. Recent PoS taggers and morphological analyzers for Hebrew (Adler and Elhadad, 2006) address this issue and provide for each word not only the PoS, but also full morphological features, such as Gender, Number, Person, Construct, Tense, and the affixes&apos; properties. Our system, currently, computes these features with an accuracy of 88.5%. Our original intuition is that the difficulty of Simple NP chunking can be overcome by relying on morphological features in a small context. These features would help the classifier decide on agreement, and split NPs more accurately. Since SVMs can handle large feature sets, we utilize additional morphological features. In particular, we found</context>
</contexts>
<marker>Adler, Elhadad, 2006</marker>
<rawString>Meni Adler and Michael Elhadad, 2006. Unsupervised Morpheme-based HMM for Hebrew Morphological Disambiguation. In Proc. of COLING/ACL 2006, Sidney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven P Abney</author>
</authors>
<title>Parsing by Chunks. In</title>
<date>1991</date>
<institution>and Carol Tenny</institution>
<contexts>
<context position="2988" citStr="Abney (1991)" startWordPosition="483" endWordPosition="484">er Semitic languages as well) to correctly handle its syntactic nature. We propose such a definition, which we call simple NPs and assess the difficulty of chunking such NPs by applying methods that perform well in English to Hebrew data. While the syntactic problem in Hebrew is indeed more difficult than in English, morphological clues do provide additional hints, which we exploit using an SVM learning method. The resulting method reaches performance in Hebrew comparable to the best results published in English. 2 Previous Work Text chunking (and NP chunking in particular), first proposed by Abney (1991), is a well studied problem for English. The CoNLL2000 shared task (Tjong Kim Sang et al., 2000) was general chunking. The best result achieved for the shared task data was by Zhang et al (2002), who achieved NP chunking results of 94.39% precision, 94.37% recall and 94.38 F-measure using a 689 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 689–696, Sydney, July 2006. c�2006 Association for Computational Linguistics generalized Winnow algorithm, and enhancing the feature set with the output of a dependency parser. Kudo an</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Steven P. Abney. 1991. Parsing by Chunks. In Robert C. Berwick, Steven P. Abney, and Carol Tenny</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erin L Allwein</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers.</title>
<date>2000</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>1--113</pages>
<contexts>
<context position="16330" citStr="Allwein et al., 2000" startWordPosition="2742" endWordPosition="2745">from a predefined linguistic context (such as the 5http://www.cnts.ua.ac.be/conll2000/chunking/conllev al.txt ] 55.12 [9&apos;07] y [ O&amp;quot;`Jx1VJ&apos; O&apos;711.1 DyivJnn [1in3n 13Wn yVJ 13&apos;3 19on] 1ivjn`J In&apos;`JYw O&apos;9yn D3&apos;x [O-irovnn 3 ] ] y .[ it nTny [ ovn:) 692 words surrounding the given word, and their PoS tags). One model that allows for this prediction is Support Vector Machines - SVM (Vapnik, 1995). SVM is a supervised machine learning algorithm which can handle gracefully a large set of overlapping features. SVMs learn binary classifiers, but the method can be extended to multiclass classification (Allwein et al., 2000; Kudo and Matsumoto, 2000). SVMs have been successfully applied to many NLP tasks since (Joachims, 1998), and specifically for base phrase chunking (Kudo and Matsumoto, 2000; 2003). It was also successfully used in Arabic (Diab et al., 2004). The traditional setting of SVM for chunking uses for the context of the token to be classified a window of two tokens around the word, and the features are the PoS tags and lexical items (word forms) of all the tokens in the context. Some settings (Kudo and Matsumoto, 2000) also include the IOB tags of the two “previously tagged” tokens as features (see </context>
</contexts>
<marker>Allwein, Schapire, Singer, 2000</marker>
<rawString>Erin L. Allwein, Robert E. Schapire, and Yoram Singer. 2000. Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers. Journal of Machine Learning Research, 1:113-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>David Pierce</author>
</authors>
<title>Error-Driven Pruning of Treebank Grammars for Base Noun Phrase Identification.</title>
<date>1998</date>
<booktitle>In Proc. of COLING-98,</booktitle>
<location>Montréal.</location>
<contexts>
<context position="14552" citStr="Cardie and Pierce, 1998" startWordPosition="2438" endWordPosition="2441">brew. We describe here our experiment settings, and provide the best scores obtained for each method, in comparison to the reported scores for English. All tests were done on the corpus derived from the Hebrew Tree Bank. The corpus contains 5,000 sentences, for a total of 120K tokens (agglutinated words) and 27K NP chunks (more details on the corpus appear below). The last 500 sentences were used as the test set, and all the other sentences were used for training. The results were evaluated using the CoNLL shared task evaluation tools 5 . The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). The Error Driven Pruning method does not take into account lexical information and uses only the PoS tags. For the Transformation Based method, we have used both the PoS tag and the word itself, with the same templates as described in (Ramshaw and Marcus, 1995). We tried the Transformational Based method with more features than just the PoS and the word, but obtained lower performance. Our best results for these methods, as well as the CoNLL baseline (BASE), are presented in Table 3. These results confirm tha</context>
<context position="27230" citStr="Cardie and Pierce, 1998" startWordPosition="4603" endWordPosition="4606">ossessive &apos;$el&apos;. Table 6. WPNC Confusion Matrix The data in Table 6 suggests that Adverbs and Adjectives related errors are mostly of the “short” or “long” types, while the Noun (including proper names and pronouns) related errors are of the “split” or “merge” types. The most frequent error type was conjunction related, closely followed by split and merge. Much less significant errors were cases of extra Adverbs or Adjectives at the end of the chunk, and missing adverbs before or after the chunk. Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998)9, and we plan to address them in future work. The split and merge errors are related to argument structure, which can be more complicated in Hebrew than in English, because of possible null equatives. The toolong and too-short errors were mostly attachment related. Most of the errors are related to linguistic phenomena that cannot be inferred by the localized context used in our SVM encoding. We examine the types of errors that the addition of 9 Although base-NPs are by definition non-recursive, they may still contain CCs when the coordinators are ‘trapped’: “[securities and exchange commissi</context>
</contexts>
<marker>Cardie, Pierce, 1998</marker>
<rawString>Claire Cardie and David Pierce. 1998. Error-Driven Pruning of Treebank Grammars for Base Noun Phrase Identification. In Proc. of COLING-98, Montréal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks,</title>
<date>2004</date>
<booktitle>In Proc. of HLT/NAACL 2004,</booktitle>
<location>Boston.</location>
<contexts>
<context position="4229" citStr="Diab et al (2004)" startWordPosition="679" endWordPosition="682">an SVM based algorithm, and achieved NP chunking results of 93.72% precision, 94.02% recall and 93.87 F-measure for the same shared task data, using only the words and their PoS tags. Similar results were obtained using Conditional Random Fields on similar features (Sha and Pereira, 2003). The NP chunks in the shared task data are base-NP chunks – which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995). This definition yields good NP chunks for English, but results in very short and uninformative chunks for Hebrew (and probably other Semitic languages). Recently, Diab et al (2004) used SVM based approach for Arabic text chunking. Their chunks data was derived from the LDC Arabic TreeBank using the same program that extracted the chunks for the shared task. They used the same features as Kudo and Matsumoto (2000), and achieved over-all chunking performance of 92.06% precision, 92.09% recall and 92.08 F-measure (The results for NP chunks alone were not reported). Since Arabic syntax is quite similar to Hebrew, we expect that the issues reported below apply to Arabic results as well. 3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase </context>
<context position="16572" citStr="Diab et al., 2004" startWordPosition="2782" endWordPosition="2785">) 692 words surrounding the given word, and their PoS tags). One model that allows for this prediction is Support Vector Machines - SVM (Vapnik, 1995). SVM is a supervised machine learning algorithm which can handle gracefully a large set of overlapping features. SVMs learn binary classifiers, but the method can be extended to multiclass classification (Allwein et al., 2000; Kudo and Matsumoto, 2000). SVMs have been successfully applied to many NLP tasks since (Joachims, 1998), and specifically for base phrase chunking (Kudo and Matsumoto, 2000; 2003). It was also successfully used in Arabic (Diab et al., 2004). The traditional setting of SVM for chunking uses for the context of the token to be classified a window of two tokens around the word, and the features are the PoS tags and lexical items (word forms) of all the tokens in the context. Some settings (Kudo and Matsumoto, 2000) also include the IOB tags of the two “previously tagged” tokens as features (see Fig. 1). This setting (including the last 2 IOB tags) performs nicely for the case of Hebrew Simple NPs chunking as well. Linguistic features are mapped to SVM feature vectors by translating each feature such as “PoS at location n-2 is NOUN” </context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks, In Proc. of HLT/NAACL 2004, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proc. of ACL</booktitle>
<location>Ann Arbor.</location>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow, 2005. Arabic Tokenization, Part-of-speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proc. of ACL 2005, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machines: Learning with Many Relevant Features.</title>
<date>1998</date>
<booktitle>In Proc. of ECML-98,</booktitle>
<location>Chemnitz.</location>
<contexts>
<context position="16435" citStr="Joachims, 1998" startWordPosition="2760" endWordPosition="2761">] 55.12 [9&apos;07] y [ O&amp;quot;`Jx1VJ&apos; O&apos;711.1 DyivJnn [1in3n 13Wn yVJ 13&apos;3 19on] 1ivjn`J In&apos;`JYw O&apos;9yn D3&apos;x [O-irovnn 3 ] ] y .[ it nTny [ ovn:) 692 words surrounding the given word, and their PoS tags). One model that allows for this prediction is Support Vector Machines - SVM (Vapnik, 1995). SVM is a supervised machine learning algorithm which can handle gracefully a large set of overlapping features. SVMs learn binary classifiers, but the method can be extended to multiclass classification (Allwein et al., 2000; Kudo and Matsumoto, 2000). SVMs have been successfully applied to many NLP tasks since (Joachims, 1998), and specifically for base phrase chunking (Kudo and Matsumoto, 2000; 2003). It was also successfully used in Arabic (Diab et al., 2004). The traditional setting of SVM for chunking uses for the context of the token to be classified a window of two tokens around the word, and the features are the PoS tags and lexical items (word forms) of all the tokens in the context. Some settings (Kudo and Matsumoto, 2000) also include the IOB tags of the two “previously tagged” tokens as features (see Fig. 1). This setting (including the last 2 IOB tags) performs nicely for the case of Hebrew Simple NPs c</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text Categorization with Support Vector Machines: Learning with Many Relevant Features. In Proc. of ECML-98, Chemnitz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumato</author>
</authors>
<title>Use of Support Vector Learning for Chunk Identification.</title>
<date>2000</date>
<booktitle>In Proc. of CoNLL-2000 and LLL-2000,</booktitle>
<location>Lisbon.</location>
<marker>Kudo, Matsumato, 2000</marker>
<rawString>Taku Kudo and Yuji Matsumato. 2000. Use of Support Vector Learning for Chunk Identification. In Proc. of CoNLL-2000 and LLL-2000, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumato</author>
</authors>
<title>Fast Methods for Kernel-Based Text Analysis.</title>
<date>2003</date>
<booktitle>In Proc. of ACL 2003,</booktitle>
<location>Sapporo.</location>
<marker>Kudo, Matsumato, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumato. 2003. Fast Methods for Kernel-Based Text Analysis. In Proc. of ACL 2003, Sapporo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Netzer-Dahan</author>
<author>Michael Elhadad</author>
</authors>
<title>Generation of Noun Compounds in Hebrew: Can Syntactic Knowledge be Fully Encapsulated?</title>
<date>1998</date>
<booktitle>In Proc. of INLG-98,</booktitle>
<location>Ontario.</location>
<marker>Netzer-Dahan, Elhadad, 1998</marker>
<rawString>Yael Netzer-Dahan and Michael Elhadad, 1998. Generation of Noun Compounds in Hebrew: Can Syntactic Knowledge be Fully Encapsulated? In Proc. of INLG-98, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchel P Marcus</author>
</authors>
<title>Text Chunking Using Transformation-based Learning.</title>
<date>1995</date>
<booktitle>In Proc. of the 3rd ACL Workshop on Very Large Corpora.</booktitle>
<location>Cambridge.</location>
<contexts>
<context position="4047" citStr="Ramshaw and Marcus (1995)" startWordPosition="651" endWordPosition="654">uly 2006. c�2006 Association for Computational Linguistics generalized Winnow algorithm, and enhancing the feature set with the output of a dependency parser. Kudo and Matsumoto (2000) used an SVM based algorithm, and achieved NP chunking results of 93.72% precision, 94.02% recall and 93.87 F-measure for the same shared task data, using only the words and their PoS tags. Similar results were obtained using Conditional Random Fields on similar features (Sha and Pereira, 2003). The NP chunks in the shared task data are base-NP chunks – which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995). This definition yields good NP chunks for English, but results in very short and uninformative chunks for Hebrew (and probably other Semitic languages). Recently, Diab et al (2004) used SVM based approach for Arabic text chunking. Their chunks data was derived from the LDC Arabic TreeBank using the same program that extracted the chunks for the shared task. They used the same features as Kudo and Matsumoto (2000), and achieved over-all chunking performance of 92.06% precision, 92.09% recall and 92.08 F-measure (The results for NP chunks alone were not reported). Since Arabic syntax is quite </context>
<context position="14636" citStr="Ramshaw and Marcus, 1995" startWordPosition="2451" endWordPosition="2455">d for each method, in comparison to the reported scores for English. All tests were done on the corpus derived from the Hebrew Tree Bank. The corpus contains 5,000 sentences, for a total of 120K tokens (agglutinated words) and 27K NP chunks (more details on the corpus appear below). The last 500 sentences were used as the test set, and all the other sentences were used for training. The results were evaluated using the CoNLL shared task evaluation tools 5 . The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995). The Error Driven Pruning method does not take into account lexical information and uses only the PoS tags. For the Transformation Based method, we have used both the PoS tag and the word itself, with the same templates as described in (Ramshaw and Marcus, 1995). We tried the Transformational Based method with more features than just the PoS and the word, but obtained lower performance. Our best results for these methods, as well as the CoNLL baseline (BASE), are presented in Table 3. These results confirm that the task of Simple NP chunking is harder in Hebrew than in English. 4.2 Support Ve</context>
<context position="27204" citStr="Ramshaw and Marcus, 1995" startWordPosition="4599" endWordPosition="4602">conjuncts) was &apos;�V - the possessive &apos;$el&apos;. Table 6. WPNC Confusion Matrix The data in Table 6 suggests that Adverbs and Adjectives related errors are mostly of the “short” or “long” types, while the Noun (including proper names and pronouns) related errors are of the “split” or “merge” types. The most frequent error type was conjunction related, closely followed by split and merge. Much less significant errors were cases of extra Adverbs or Adjectives at the end of the chunk, and missing adverbs before or after the chunk. Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998)9, and we plan to address them in future work. The split and merge errors are related to argument structure, which can be more complicated in Hebrew than in English, because of possible null equatives. The toolong and too-short errors were mostly attachment related. Most of the errors are related to linguistic phenomena that cannot be inferred by the localized context used in our SVM encoding. We examine the types of errors that the addition of 9 Although base-NPs are by definition non-recursive, they may still contain CCs when the coordinators are ‘trapped’: “[securi</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance A. Ramshaw and Mitchel P. Marcus. 1995. Text Chunking Using Transformation-based Learning. In Proc. of the 3rd ACL Workshop on Very Large Corpora. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Alon Itai</author>
<author>Yoad Winter</author>
<author>Alon Altman</author>
<author>N Nativ</author>
</authors>
<title>Building a Tree-bank of Modern Hebrew Text,</title>
<date>2001</date>
<booktitle>in Traitement Automatique des Langues</booktitle>
<volume>42</volume>
<issue>2</issue>
<marker>Sima’an, Itai, Winter, Altman, Nativ, 2001</marker>
<rawString>Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman and N. Nativ, 2001. Building a Tree-bank of Modern Hebrew Text, in Traitement Automatique des Langues 42(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Sha</author>
<author>Fernando Pereira</author>
</authors>
<title>Shallow Parsing with Conditional Random Fields.</title>
<date>2003</date>
<tech>Technical Report CIS TR MS-CIS-02-35,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="3901" citStr="Sha and Pereira, 2003" startWordPosition="626" endWordPosition="629"> 689 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 689–696, Sydney, July 2006. c�2006 Association for Computational Linguistics generalized Winnow algorithm, and enhancing the feature set with the output of a dependency parser. Kudo and Matsumoto (2000) used an SVM based algorithm, and achieved NP chunking results of 93.72% precision, 94.02% recall and 93.87 F-measure for the same shared task data, using only the words and their PoS tags. Similar results were obtained using Conditional Random Fields on similar features (Sha and Pereira, 2003). The NP chunks in the shared task data are base-NP chunks – which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995). This definition yields good NP chunks for English, but results in very short and uninformative chunks for Hebrew (and probably other Semitic languages). Recently, Diab et al (2004) used SVM based approach for Arabic text chunking. Their chunks data was derived from the LDC Arabic TreeBank using the same program that extracted the chunks for the shared task. They used the same features as Kudo and Matsumoto (2000), and achieved over-all chunking per</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>Fei Sha and Fernando Pereira. 2003. Shallow Parsing with Conditional Random Fields. Technical Report CIS TR MS-CIS-02-35, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 Shared Task: Chunking.</title>
<date>2000</date>
<booktitle>In Proc. of CoNLL-2000 and LLL-2000,</booktitle>
<location>Lisbon.</location>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 Shared Task: Chunking. In Proc. of CoNLL-2000 and LLL-2000, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer Verlag,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="16104" citStr="Vapnik, 1995" startWordPosition="2708" endWordPosition="2709">shaw and Marcus (1995), and which has become the de-facto standard for this task. Using this tagging method, chunking becomes a classification problem – each token is predicted as being either I, O or B, given features from a predefined linguistic context (such as the 5http://www.cnts.ua.ac.be/conll2000/chunking/conllev al.txt ] 55.12 [9&apos;07] y [ O&amp;quot;`Jx1VJ&apos; O&apos;711.1 DyivJnn [1in3n 13Wn yVJ 13&apos;3 19on] 1ivjn`J In&apos;`JYw O&apos;9yn D3&apos;x [O-irovnn 3 ] ] y .[ it nTny [ ovn:) 692 words surrounding the given word, and their PoS tags). One model that allows for this prediction is Support Vector Machines - SVM (Vapnik, 1995). SVM is a supervised machine learning algorithm which can handle gracefully a large set of overlapping features. SVMs learn binary classifiers, but the method can be extended to multiclass classification (Allwein et al., 2000; Kudo and Matsumoto, 2000). SVMs have been successfully applied to many NLP tasks since (Joachims, 1998), and specifically for base phrase chunking (Kudo and Matsumoto, 2000; 2003). It was also successfully used in Arabic (Diab et al., 2004). The traditional setting of SVM for chunking uses for the context of the token to be classified a window of two tokens around the w</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir Vapnik. 1995. The Nature of Statistical Learning Theory. Springer Verlag, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Zhang</author>
<author>Fred Damerau</author>
<author>David Johnson</author>
</authors>
<title>Text Chunking based on a Generalization of Winnow.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>2</volume>
<pages>615--637</pages>
<contexts>
<context position="3182" citStr="Zhang et al (2002)" startWordPosition="516" endWordPosition="519">thods that perform well in English to Hebrew data. While the syntactic problem in Hebrew is indeed more difficult than in English, morphological clues do provide additional hints, which we exploit using an SVM learning method. The resulting method reaches performance in Hebrew comparable to the best results published in English. 2 Previous Work Text chunking (and NP chunking in particular), first proposed by Abney (1991), is a well studied problem for English. The CoNLL2000 shared task (Tjong Kim Sang et al., 2000) was general chunking. The best result achieved for the shared task data was by Zhang et al (2002), who achieved NP chunking results of 94.39% precision, 94.37% recall and 94.38 F-measure using a 689 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 689–696, Sydney, July 2006. c�2006 Association for Computational Linguistics generalized Winnow algorithm, and enhancing the feature set with the output of a dependency parser. Kudo and Matsumoto (2000) used an SVM based algorithm, and achieved NP chunking results of 93.72% precision, 94.02% recall and 93.87 F-measure for the same shared task data, using only the words and th</context>
</contexts>
<marker>Zhang, Damerau, Johnson, 2002</marker>
<rawString>Tong Zhang, Fred Damerau and David Johnson. 2002. Text Chunking based on a Generalization of Winnow. Journal of Machine Learning Research, 2: 615-637.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>