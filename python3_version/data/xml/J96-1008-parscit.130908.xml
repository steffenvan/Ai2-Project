<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047956">
<figure confidence="0.653973666666667">
Book Reviews
Japanese Sentence Processing
Reiko Mazuka and Noriko Nagai (editors)
(Duke University)
Hillsdale, NJ: Lawrence Erlbaum
Associates, 1995, x+360 pp; hardbound,
ISBN 0-8058-1125-7, $89.95
Reviewed by
Patrick Sturt
</figure>
<affiliation confidence="0.716985">
University of Edinburgh
</affiliation>
<sectionHeader confidence="0.873286" genericHeader="abstract">
1. Overview
</sectionHeader>
<bodyText confidence="0.9990798">
Japanese Sentence Processing is a collection of fourteen papers that arose from &amp;quot;The In-
ternational Symposium on Japanese Sentence Processing&amp;quot; held at Duke University in
1991. The approach of the book is deliberately interdisciplinary aiming, in the words
of the editors in their introductory chapter, &amp;quot;to illuminate the mechanisms of Japanese
sentence processing from the viewpoints of linguistics, psycholinguistics, and com-
puter science&amp;quot; (p. 1). It would be fair to say that, of the three disciplines, psycholin-
guistics emerges as the main beneficiary of the book; in particular, the chapters by
Inoue and Fodor (&amp;quot;Information paced parsing of Japanese,&amp;quot; chapter 2), and Mazuka
and Itoh (&amp;quot;Can Japanese speakers be led down the garden path?,&amp;quot; chapter 13), which
give an overview of the particular problems of processing Japanese and their impli-
cations for existing processing models, have already contributed a great deal towards
bringing a cross-linguistic perspective to psycholinguistic research. Despite this, the
book does contain material that is interesting to computational linguists, though there
are certain areas of computational linguistics that are not represented at all, one obvi-
ous example being corpus-based statistical NLP.
Three of the papers are directly relevant to computational linguistics in that they
describe actual implementations—Koiti Hasida&apos;s &amp;quot;A constraint-based view of lan-
guage&amp;quot; (chapter 6) describes a constraint–logic-programming system that uses numeric
computation to allow for a graded notion of constraint violation. He gives two exam-
ples to show how the system can be used for abductive inference and disambiguation
using discourse context. Megumi Kameyama&apos;s &amp;quot;The Japanese language engine&amp;quot; (chap-
ter 7) describes the Japanese descendant of the Core Language Engine (Alshawi 1992).
Like the CLE, Kameyama&apos;s JLE builds up logical forms via an underspecified repre-
sentation called &amp;quot;Quasi logical form&amp;quot; (QLF) using a unification-based grammar. The
paper contains an interesting discussion of how linguistic aspects of Japanese led to
design features of the system that differ radically from the English CLE; an example
is that in the JLE, relative clause dependencies are left underspecified at QLF, to be
resolved, with the aid of discourse knowledge, in the mapping to logical form proper,
while in the CLE, standard gap-threading techniques are used to build the depen-
dencies during grammatical analysis. Robert Berwick and Sandiway Fong&apos;s &amp;quot;Madama
Butterfly redux&amp;quot; (chapter 8) describes a principle-based parsing system that can be pa-
rameterized to handle Japanese or English input. One interesting aspect of the paper is
the authors&apos; discussion of how they tackle the serious problem of nondeterminism that
is inherent in parsing directly with GB principles, while trying to remain as faithful
as possible to the modular organization of the grammatical theory.
</bodyText>
<page confidence="0.990899">
145
</page>
<note confidence="0.615867">
Computational Linguistics Volume 22, Number 1
</note>
<bodyText confidence="0.99888847368421">
The volume also contains an overview of Japanese Phrase Structure Grammar
(JPSG) by Takao Gunji (chapter 5). JPSG is a declarative unification formalism similar
to HPSG (Pollard and Sag 1994), but designed specifically for Japanese. The chapter
introduces the main mechanisms of the theory, and shows how they can be applied
to capture certain control and binding phenomena in Japanese.
The book also contains papers that describe models based on well-known com-
putational formalisms, but which are stated at a theoretical level—Amy Weinberg&apos;s
&amp;quot;Licensing constraints and the theory of language processing&amp;quot; (chapter 10) and Paul
Gorrell&apos;s &amp;quot;Japanese trees and the garden path&amp;quot; (chapter 14) both discuss Japanese pro-
cessing effects in the light of theoretical models based on Description Theory (Marcus,
Hindle, and Fleck 1983).
Apart from the papers mentioned above, there are psycholinguistic papers report-
ing experimental results—Mineharu Nakayama&apos;s &amp;quot;Scrambling and probe recognition&amp;quot;
(chapter 11) and Tsutomu Sakamoto&apos;s &amp;quot;Transparency between parser and grammar&amp;quot;
(chapter 12). There are also papers that approach Japanese from the perspective of
theoretical linguistics, but which make important use of processing and discourse—
Bradley Pritchett and John Whitman&apos;s &amp;quot;Syntactic representation and interpretive pref-
erence&amp;quot; (chapter 3), Noriko Nagai&apos;s &amp;quot;Constraints on topics and their gaps&amp;quot; (chapter 4),
and Susumu Kuno&apos;s &amp;quot;Null elements in parallel structures in Japanese&amp;quot; (chapter 9).
</bodyText>
<sectionHeader confidence="0.989894" genericHeader="keywords">
2. Discussion
</sectionHeader>
<bodyText confidence="0.99963604">
The book certainly succeeds in its aim of presenting Japanese sentence processing in
an interdisciplinary light, yet there are places where a fuller synthesis could have
been achieved. In general, the book would have benefited if the editors had arranged
for each chapter to be followed by a short commentary discussing the content of the
chapter from the perspective of a different discipline. For example, Mazuka and Itoh
(chapter 13, p. 313) outline a &amp;quot;tentative attachment strategy,&amp;quot; which involves a distinc-
tion between &amp;quot;segmenting&amp;quot; phrases and clauses (identifying the beginning and the
end of each unit) and &amp;quot;attaching&amp;quot; them into the parse tree. As it stands, it is fairly dif-
ficult to gain a concrete grasp how this would work in an incremental parse. However,
a commentary by a computational linguist could have outlined techniques to imple-
ment such a strategy (for example, various forms of underspecification, or chunking),
and discussed the empirical consequences of adopting these. Equally, Hasida&apos;s pa-
per (chapter 6), which argues for nonmodular information flow in a computational
language processing system might have been followed by a commentary by a psy-
cholinguist outlining the experimental evidence for and against modular information
flow in human language processing, and comparing his model with other simulta-
neous constraint satisfaction models proposed within psycholinguistics (for example,
that of MacDonald, Pearlmutter, and Seidenberg (1994)). Hasida&apos;s chapter would also
have benefited from a discussion of the contributions that the proposed constraint-
based system could make to the particular problems involved in processing Japanese;
as it stands, the Japanese language does not even receive a mention, which, given the
title of the book, is surprising to say the least.
The quality of editing is very high, and I have only found a small number of
typos. Since none of them drastically affects the interpretation of the text, I will not
list them here.
</bodyText>
<page confidence="0.995745">
146
</page>
<reference confidence="0.906917533333333">
Book Reviews
References about Talking about Trees. Proceedings,
Alshawi, Hiyan, ed. (1992). The Core Language 21st Annual Meeting of the Association for
Engine. Cambridge, MA: The MIT Press. Computational Linguistics, 129-136.
MacDonald, Maryellen C.; Pearlmutter, Pollard, Carl and Sag, Ivan A. (1994).
Neal J.; and Seidenberg, Mark S. (1994). Head-driven Phrase Structure Grammar.
&amp;quot;Lexical Nature of Syntactic Ambiguity Stanford, CA: Center for the Study of
Resolution.&amp;quot; Psychological Review, 101(4): Language and Information and Chicago:
676-703. The University of Chicago Press.
Marcus, Mitchell C.; Hindle, Donald; and
Fleck, Margaret. (1983). D-theory: Talking
Patrick Sturt is a Ph.D. student at the Centre for Cognitive Science, University of Edinburgh.
His research interests include computational and experimental psycholinguistics, in particular,
issues related to reanalysis and head-final processing. Sturt&apos;s address is: Centre for Cognitive
Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, UK; e-mail: sturt@cogsci.ed.ac.uk
</reference>
<page confidence="0.998032">
147
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.061508">
<title confidence="0.939723">Book Reviews Japanese Sentence Processing</title>
<author confidence="0.850033">Reiko Mazuka</author>
<author confidence="0.850033">Noriko Nagai</author>
<affiliation confidence="0.855657">(Duke University)</affiliation>
<address confidence="0.730562">Hillsdale, NJ: Lawrence Erlbaum</address>
<note confidence="0.908453">Associates, 1995, x+360 pp; hardbound, ISBN 0-8058-1125-7, $89.95 Reviewed by</note>
<author confidence="0.997669">Patrick Sturt</author>
<affiliation confidence="0.995798">University of Edinburgh</affiliation>
<abstract confidence="0.962579168674699">1. Overview Sentence Processing collection of fourteen papers that arose from &amp;quot;The International Symposium on Japanese Sentence Processing&amp;quot; held at Duke University in 1991. The approach of the book is deliberately interdisciplinary aiming, in the words of the editors in their introductory chapter, &amp;quot;to illuminate the mechanisms of Japanese sentence processing from the viewpoints of linguistics, psycholinguistics, and computer science&amp;quot; (p. 1). It would be fair to say that, of the three disciplines, psycholinguistics emerges as the main beneficiary of the book; in particular, the chapters by Inoue and Fodor (&amp;quot;Information paced parsing of Japanese,&amp;quot; chapter 2), and Mazuka and Itoh (&amp;quot;Can Japanese speakers be led down the garden path?,&amp;quot; chapter 13), which give an overview of the particular problems of processing Japanese and their implications for existing processing models, have already contributed a great deal towards bringing a cross-linguistic perspective to psycholinguistic research. Despite this, the book does contain material that is interesting to computational linguists, though there are certain areas of computational linguistics that are not represented at all, one obvious example being corpus-based statistical NLP. Three of the papers are directly relevant to computational linguistics in that they describe actual implementations—Koiti Hasida&apos;s &amp;quot;A constraint-based view of language&amp;quot; (chapter 6) describes a constraint–logic-programming system that uses numeric computation to allow for a graded notion of constraint violation. He gives two examples to show how the system can be used for abductive inference and disambiguation using discourse context. Megumi Kameyama&apos;s &amp;quot;The Japanese language engine&amp;quot; (chapter 7) describes the Japanese descendant of the Core Language Engine (Alshawi 1992). Like the CLE, Kameyama&apos;s JLE builds up logical forms via an underspecified representation called &amp;quot;Quasi logical form&amp;quot; (QLF) using a unification-based grammar. The paper contains an interesting discussion of how linguistic aspects of Japanese led to design features of the system that differ radically from the English CLE; an example is that in the JLE, relative clause dependencies are left underspecified at QLF, to be resolved, with the aid of discourse knowledge, in the mapping to logical form proper, while in the CLE, standard gap-threading techniques are used to build the dependencies during grammatical analysis. Robert Berwick and Sandiway Fong&apos;s &amp;quot;Madama Butterfly redux&amp;quot; (chapter 8) describes a principle-based parsing system that can be parameterized to handle Japanese or English input. One interesting aspect of the paper is the authors&apos; discussion of how they tackle the serious problem of nondeterminism that is inherent in parsing directly with GB principles, while trying to remain as faithful as possible to the modular organization of the grammatical theory. 145 Computational Linguistics Volume 22, Number 1 The volume also contains an overview of Japanese Phrase Structure Grammar (JPSG) by Takao Gunji (chapter 5). JPSG is a declarative unification formalism similar to HPSG (Pollard and Sag 1994), but designed specifically for Japanese. The chapter introduces the main mechanisms of the theory, and shows how they can be applied to capture certain control and binding phenomena in Japanese. The book also contains papers that describe models based on well-known computational formalisms, but which are stated at a theoretical level—Amy Weinberg&apos;s &amp;quot;Licensing constraints and the theory of language processing&amp;quot; (chapter 10) and Paul Gorrell&apos;s &amp;quot;Japanese trees and the garden path&amp;quot; (chapter 14) both discuss Japanese processing effects in the light of theoretical models based on Description Theory (Marcus, Hindle, and Fleck 1983). Apart from the papers mentioned above, there are psycholinguistic papers reporting experimental results—Mineharu Nakayama&apos;s &amp;quot;Scrambling and probe recognition&amp;quot; (chapter 11) and Tsutomu Sakamoto&apos;s &amp;quot;Transparency between parser and grammar&amp;quot; (chapter 12). There are also papers that approach Japanese from the perspective of theoretical linguistics, but which make important use of processing and discourse— Bradley Pritchett and John Whitman&apos;s &amp;quot;Syntactic representation and interpretive preference&amp;quot; (chapter 3), Noriko Nagai&apos;s &amp;quot;Constraints on topics and their gaps&amp;quot; (chapter 4), and Susumu Kuno&apos;s &amp;quot;Null elements in parallel structures in Japanese&amp;quot; (chapter 9). 2. Discussion The book certainly succeeds in its aim of presenting Japanese sentence processing in an interdisciplinary light, yet there are places where a fuller synthesis could have been achieved. In general, the book would have benefited if the editors had arranged for each chapter to be followed by a short commentary discussing the content of the chapter from the perspective of a different discipline. For example, Mazuka and Itoh (chapter 13, p. 313) outline a &amp;quot;tentative attachment strategy,&amp;quot; which involves a distinction between &amp;quot;segmenting&amp;quot; phrases and clauses (identifying the beginning and the end of each unit) and &amp;quot;attaching&amp;quot; them into the parse tree. As it stands, it is fairly difficult to gain a concrete grasp how this would work in an incremental parse. However, a commentary by a computational linguist could have outlined techniques to implement such a strategy (for example, various forms of underspecification, or chunking), and discussed the empirical consequences of adopting these. Equally, Hasida&apos;s paper (chapter 6), which argues for nonmodular information flow in a computational language processing system might have been followed by a commentary by a psycholinguist outlining the experimental evidence for and against modular information flow in human language processing, and comparing his model with other simultaneous constraint satisfaction models proposed within psycholinguistics (for example, that of MacDonald, Pearlmutter, and Seidenberg (1994)). Hasida&apos;s chapter would also have benefited from a discussion of the contributions that the proposed constraintbased system could make to the particular problems involved in processing Japanese; as it stands, the Japanese language does not even receive a mention, which, given the title of the book, is surprising to say the least. The quality of editing is very high, and I have only found a small number of typos. Since none of them drastically affects the interpretation of the text, I will not list them here.</abstract>
<note confidence="0.667331363636364">146 Book Reviews References Talking about Trees. 21st Annual Meeting of the Association for Linguistics, Hiyan, ed. (1992). Core Language MA: The MIT Press. Pollard, Carl and Sag, Ivan A. (1994). Head-driven Phrase Structure Grammar. Stanford, CA: Center for the Study of Language and Information and Chicago: The University of Chicago Press. MacDonald, Maryellen C.; Pearlmutter, Neal J.; and Seidenberg, Mark S. (1994). &amp;quot;Lexical Nature of Syntactic Ambiguity Review, 676-703. Marcus, Mitchell C.; Hindle, Donald; and Fleck, Margaret. (1983). D-theory: Talking Sturt a Ph.D. student at the Centre for Cognitive Science, University of Edinburgh. His research interests include computational and experimental psycholinguistics, in particular, issues related to reanalysis and head-final processing. Sturt&apos;s address is: Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, UK; e-mail: sturt@cogsci.ed.ac.uk 147</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Maryellen C MacDonald</author>
<author>Neal J Pearlmutter</author>
<author>Mark S Seidenberg</author>
</authors>
<title>The Core Language Engine.</title>
<date>1992</date>
<journal>Psychological Review,</journal>
<booktitle>D-theory: Talking about Talking about Trees. Proceedings, 21st Annual Meeting of the Association for Computational Linguistics, 129-136. Pollard, Carl and Sag, Ivan A.</booktitle>
<volume>101</volume>
<issue>4</issue>
<pages>676--703</pages>
<editor>Book Reviews References Alshawi, Hiyan, ed.</editor>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>MacDonald, Pearlmutter, Seidenberg, 1992</marker>
<rawString>Book Reviews References Alshawi, Hiyan, ed. (1992). The Core Language Engine. Cambridge, MA: The MIT Press. MacDonald, Maryellen C.; Pearlmutter, Neal J.; and Seidenberg, Mark S. (1994). &amp;quot;Lexical Nature of Syntactic Ambiguity Resolution.&amp;quot; Psychological Review, 101(4): 676-703. Marcus, Mitchell C.; Hindle, Donald; and Fleck, Margaret. (1983). D-theory: Talking about Talking about Trees. Proceedings, 21st Annual Meeting of the Association for Computational Linguistics, 129-136. Pollard, Carl and Sag, Ivan A. (1994). Head-driven Phrase Structure Grammar. Stanford, CA: Center for the Study of Language and Information and Chicago: The University of Chicago Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>