<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000093">
<title confidence="0.9981005">
Hierarchical Sequential Learning for Extracting Opinions and their
Attributes
</title>
<author confidence="0.996534">
Yejin Choi and Claire Cardie
</author>
<affiliation confidence="0.9946245">
Department of Computer Science
Cornell University
</affiliation>
<address confidence="0.759804">
Ithaca, NY 14853
</address>
<email confidence="0.99958">
{ychoi,cardie}@cs.cornell.edu
</email>
<sectionHeader confidence="0.994817" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999865590909091">
Automatic opinion recognition involves a
number of related tasks, such as identi-
fying the boundaries of opinion expres-
sion, determining their polarity, and de-
termining their intensity. Although much
progress has been made in this area, ex-
isting research typically treats each of the
above tasks in isolation. In this paper,
we apply a hierarchical parameter shar-
ing technique using Conditional Random
Fields for fine-grained opinion analysis,
jointly detecting the boundaries of opinion
expressions as well as determining two of
their key attributes — polarity and inten-
sity. Our experimental results show that
our proposed approach improves the per-
formance over a baseline that does not
exploit hierarchical structure among the
classes. In addition, we find that the joint
approach outperforms a baseline that is
based on cascading two separate compo-
nents.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="categories and subject descriptors">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927088235294">
Automatic opinion recognition involves a number
of related tasks, such as identifying expressions of
opinion (e.g. Kim and Hovy (2005), Popescu and
Etzioni (2005), Breck et al. (2007)), determining
their polarity (e.g. Hu and Liu (2004), Kim and
Hovy (2004), Wilson et al. (2005)), and determin-
ing their strength, or intensity (e.g. Popescu and
Etzioni (2005), Wilson et al. (2006)). Most pre-
vious work treats each subtask in isolation: opin-
ion expression extraction (i.e. detecting the bound-
aries of opinion expressions) and opinion attribute
classification (e.g. determining values for polar-
ity and intensity) are tackled as separate steps in
opinion recognition systems. Unfortunately, er-
rors from individual components will propagate in
systems with cascaded component architectures,
causing performance degradation in the end-to-
end system (e.g. Finkel et al. (2006)) — in our
case, in the end-to-end opinion recognition sys-
tem.
In this paper, we apply a hierarchical param-
eter sharing technique (e.g., Cai and Hofmann
(2004), Zhao et al. (2008)) using Conditional Ran-
dom Fields (CRFs) (Lafferty et al., 2001) to fine-
grained opinion analysis. In particular, we aim to
jointly identify the boundaries of opinion expres-
sions as well as to determine two of their key at-
tributes — polarity and intensity.
Experimental results show that our proposed ap-
proach improves the performance over the base-
line that does not exploit the hierarchical structure
among the classes. In addition, we find that the
joint approach outperforms a baseline that is based
on cascading two separate systems.
</bodyText>
<sectionHeader confidence="0.911843" genericHeader="general terms">
2 Hierarchical Sequential Learning
</sectionHeader>
<bodyText confidence="0.999779777777778">
We define the problem of joint extraction of opin-
ion expressions and their attributes as a sequence
tagging task as follows. Given a sequence of to-
kens, x = x1 ... x, we predict a sequence of
labels, y = y1 ... y, where yi ∈ {0, ..., 9} are
defined as conjunctive values of polarity labels
and intensity labels, as shown in Table 1. Then
the conditional probability p(y|x) for linear-chain
CRFs is given as (Lafferty et al., 2001)
</bodyText>
<equation confidence="0.931176">
�
1 � �
P(y|x) = exp λ f(yi, x, i)+λ′ f′(yi−1, yi, x, i)
Z. i
</equation>
<bodyText confidence="0.991426">
where Zx is the normalization factor.
In order to apply a hierarchical parameter shar-
ing technique (e.g., Cai and Hofmann (2004),
Zhao et al. (2008)), we extend parameters as fol-
lows.
</bodyText>
<page confidence="0.985992">
269
</page>
<note confidence="0.8437825">
Proceedings of the ACL 2010 Conference Short Papers, pages 269–274,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.989281">
Figure 1: The hierarchical structure of classes for opinion expressions with polarity (positive, neutral,
negative) and intensity (high, medium, low)
</figureCaption>
<table confidence="0.783956">
LABEL 0 1 2 3 4 5 6 7 8 9
POLARITY none positive positive positive neutral neutral neutral negative negative negative
INTENSITY none high medium low high medium low high medium low
</table>
<tableCaption confidence="0.961186">
Table 1: Labels for Opinion Extraction with Polarity and Intensity
</tableCaption>
<equation confidence="0.878173666666667">
λ f(yi, x, i) = λα gO(α, x, i) (1)
+ λβ gP(β, x, i)
+ λγ gS(γ, x, i)
λ′ f′(yi−1, yi, x, i) = λ′α,« g′O(α, �α, x, i)
+ λ′β, β� g′P(β, �β, x, i)
+ λ′γ,y g′S(γ, �γ, x, i)
</equation>
<bodyText confidence="0.9138276">
where gO and g′O are feature vectors defined for
Opinion extraction, gP and g′P are feature vectors
defined for Polarity extraction, and gS and g′S are
feature vectors defined for Strength extraction, and
For instance, if yi = 1, then
</bodyText>
<equation confidence="0.946153666666667">
λ f(1, x, i) = λOPINION gO(OPINION, x, i)
+ λPOSITIVE gP(POSITVE, x, i)
+ λHIGH gS(HIGH, x, i)
If yi−1 = 0, yi = 4, then
λ′ f′(0, 4, x, i)
= λ′NO-OPINION,OPINION g′O(NO-OPINION, OPINION, x, i)
</equation>
<bodyText confidence="0.981981666666667">
yi E 11, 2,3} will share the same compo-
nent λPOSITIVE gP(POSITVE, x, i). Note that there
can be other variations of hierarchical construc-
tion. For instance, one can add λδ gI(δ, x, i)
�δ, x, i) to Equation (1) for δ E
10, 1, ..., 9}, in order to allow more individualized
learning for each label.
Notice also that the number of sets of param-
eters constructed by Equation (1) is significantly
smaller than the number of sets of parameters that
are needed without the hierarchy. The former re-
quires (2 + 4 +4) +(2 x 2 +4 x 4+ 4 x 4) = 46
sets of parameters, but the latter requires (10) +
(10 x 10) = 110 sets of parameters. Because a
combination of a polarity component and an in-
tensity component can distinguish each label, it is
not necessary to define a separate set of parameters
for each label.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="keywords">
3 Features
</sectionHeader>
<bodyText confidence="0.9872535">
We first introduce definitions of key terms that will
be used to describe features.
</bodyText>
<listItem confidence="0.901854">
• PRIOR-POLARITY &amp; PRIOR-INTENSITY:
We obtain these prior-attributes from the polar-
ity lexicon populated by Wilson et al. (2005).
• EXP-POLARITY, EXP-INTENSITY &amp; EXP-SPAN:
</listItem>
<equation confidence="0.700960428571429">
α, α� E {OPINION, NO-OPINION}
β, β� E {POSITIVE, NEGATIVE, NEUTRAL, NO-POLARITY}
γ, γ� E {HIGH, MEDIUM, LOW, NO-INTENSITY}
and λ′ �δ g′ I(δ,
δ,
+ λ′ NO-POLARITY, NEUTRAL g′ P(NO-POLARITY, NEUTRAL, x, i)
+ λ′NO-INTENSITY, HIGH g′S(NO-INTENSITY, HIGH, x, i)
</equation>
<bodyText confidence="0.999939666666667">
This hierarchical construction of feature and
weight vectors allows similar labels to share the
same subcomponents of feature and weight vec-
tors. For instance, all λ f(yi, x, i) such that
Words in a given opinion expression often do
not share the same prior-attributes. Such dis-
continuous distribution of features can make
it harder to learn the desired opinion expres-
sion boundaries. Therefore, we try to obtain
expression-level attributes (EXP-POLARITY and
EXP-INTENSITY) using simple heuristics. In or-
der to derive EXP-POLARITY, we perform simple
</bodyText>
<page confidence="0.959206">
270
</page>
<bodyText confidence="0.999974">
voting. If there is a word with a negation effect,
such as “never”, “not”, “hardly”, “against”, then
we flip the polarity. For EXP-INTENSITY, we use
the highest PRIOR-INTENSITY in the span. The text
span with the same expression-level attributes
are referred to as EXP-SPAN.
</bodyText>
<subsectionHeader confidence="0.997832">
3.1 Per-Token Features
</subsectionHeader>
<bodyText confidence="0.999832">
Per-token features are defined in the form of
gO(α, x, i), gP(β, x, i) and gS(γ, x, i). The do-
mains of α, β, γ are as given in Section 3.
</bodyText>
<subsectionHeader confidence="0.902731">
Common Per-Token Features
</subsectionHeader>
<bodyText confidence="0.998109333333333">
Following features are common for all class labels.
The notation ® indicates conjunctive operation of
two values.
</bodyText>
<listItem confidence="0.982231888888889">
• PART-OF-SPEECH(xi):
based on GATE (Cunningham et al., 2002).
• WORD(xi), WORD(xi−1), WORD(xi+1)
• WORDNET-HYPERNYM(xi):
based on WordNet (Miller, 1995).
• OPINION-LEXICON(xi):
based on opinion lexicon (Wiebe et al., 2002).
• SHALLOW-PARSER(xi):
based on CASS partial parser (Abney, 1996).
• PRIOR-POLARITY(xi) ® PRIOR-INTENSITY(xi)
• EXP-POLARITY(xi) ® EXP-INTENSITY(xi)
• EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ®
STEM(xi)
• EXP-SPAN(xi):
boolean to indicate whether xi is in an EXP-SPAN.
• DISTANCE-TO-EXP-SPAN(xi): 0, 1, 2, 3+.
• EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ®
EXP-SPAN(xi)
</listItem>
<subsectionHeader confidence="0.567116">
Polarity Per-Token Features
</subsectionHeader>
<bodyText confidence="0.999613333333333">
These features are included only for gO(α, x, i)
and gP(β, x, i), which are the feature functions
corresponding to the polarity-based classes.
</bodyText>
<listItem confidence="0.999565">
• PRIOR-POLARITY(xi), EXP-POLARITY((xi)
• STEM(xi) ® EXP-POLARITY(xi)
• COUNT-OF-Polarity:
</listItem>
<bodyText confidence="0.998835">
where Polarity E {positive, neutral, negative}.
This feature encodes the number of positive,
neutral, and negative EXP-POLARITY words re-
spectively, in the current sentence.
</bodyText>
<listItem confidence="0.999973">
• STEM(xi) ® COUNT-OF-Polarity
• EXP-POLARITY(xi) ® COUNT-OF-Polarity
• EXP-SPAN(xi) and EXP-POLARITY(xi)
• DISTANCE-TO-EXP-SPAN(xi) ® EXP-POLARITY(xp)
</listItem>
<subsubsectionHeader confidence="0.569059">
Intensity Per-Token Features
</subsubsectionHeader>
<bodyText confidence="0.999893">
These features are included only for gO(α,x,i)
and gS(γ, x, i), which are the feature functions cor-
responding to the intensity-based classes.
</bodyText>
<listItem confidence="0.982630285714286">
• PRIOR-INTENSITY(xi), EXP-INTENSITY(xi)
• STEM(xi) ® EXP-INTENSITY(xi)
• COUNT-OF-STRONG, COUNT-OF-WEAK:
the number of strong and weak EXP-INTENSITY
words in the current sentence.
• INTENSIFIER(xi): whether xi is an intensifier,
such as “extremely”, “highly”, “really”.
• STRONGMODAL(xi): whether xi is a strong modal
verb, such as “must”, “can”, “will”.
• WEAKMODAL(xi): whether xi is a weak modal
verb, such as “may”, “could”, “would”.
• DIMINISHER(xi): whether xi is a diminisher, such
as “little”, “somewhat”, “less”.
• PRECEDED-BY-T(xi),
</listItem>
<equation confidence="0.670216833333333">
PRECEDED-BY-T(xi) ® EXP-INTENSITY(xi):
where τ E { INTENSIFIER, STRONGMODAL, WEAK-
MODAL, DIMINISHER}
• T(xi) ® EXP-INTENSITY(xi),
T(xi) ® EXP-INTENSITY(xi−1),
T(xi−1) ® EXP-INTENSITY(xi+1)
</equation>
<listItem confidence="0.9912535">
• EXP-SPAN(xi) ® EXP-INTENSITY(xi)
• DISTANCE-TO-EXP-SPAN(xi) ® EXP-INTENSITY(xp)
</listItem>
<subsectionHeader confidence="0.999056">
3.2 Transition Features
</subsectionHeader>
<bodyText confidence="0.9993655">
Transition features are employed to help with
boundary extraction as follows:
</bodyText>
<subsectionHeader confidence="0.548656">
Polarity Transition Features
</subsectionHeader>
<bodyText confidence="0.98853">
Polarity transition features are features that are
used only for g′O(α, a, x, i) and g′P(β, �β, x, i).
</bodyText>
<listItem confidence="0.999606">
• PART-OF-SPEECH(xi) ® PART-OF-SPEECH(xi+1) ®
EXP-POLARITY(xi)
• EXP-POLARITY(xi) ® EXP-POLARITY(xi+1)
</listItem>
<subsectionHeader confidence="0.451531">
Intensity Transition Features
</subsectionHeader>
<bodyText confidence="0.9899235">
Intensity transition features are features that are
used only for g′O(α, a, x, i) and g′S(γ, ry, x, i).
</bodyText>
<listItem confidence="0.999668333333333">
• PART-OF-SPEECH(xi) ® PART-OF-SPEECH(xi+1) ®
EXP-INTENSITY(xi)
• EXP-INTENSITY(xi) ® EXP-INTENSITY(xi+1)
</listItem>
<sectionHeader confidence="0.995231" genericHeader="introduction">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.956756">
We evaluate our system using the Multi-
Perspective Question Answering (MPQA) cor-
pus1. Our gold standard opinion expressions cor-
</bodyText>
<footnote confidence="0.99746">
1The MPQA corpus can be obtained at
http://nrrc.mitre.org/NRRC/publications.htm.
</footnote>
<page confidence="0.98921">
271
</page>
<table confidence="0.9990956">
Method Description Positive Neutral Negative
r(%) p(%) f(%) r(%) p(%) f(%) r(%) p(%) f(%)
Polarity-Only n Intensity-Only (BASELINE1) 29.6 65.7 40.8 26.5 69.1 38.3 35.5 77.0 48.6
Joint without Hierarchy (BASELINE2) 30.7 65.7 41.9 29.9 66.5 41.2 37.3 77.1 50.3
Joint with Hierarchy 31.8 67.1 43.1 31.9 66.6 43.1 40.4 76.2 52.8
</table>
<tableCaption confidence="0.966714">
Table 2: Performance of Opinion Extraction with Correct Polarity Attribute
</tableCaption>
<table confidence="0.9995884">
Method Description High Medium Low
r(%) p(%) f(%) r(%) p(%) f(%) r(%) p(%) f(%)
Polarity-Only n Intensity-Only (BASELINE1) 26.4 58.3 36.3 29.7 59.0 39.6 15.4 60.3 24.5
Joint without Hierarchy (BASELINE2) 29.7 54.2 38.4 28.0 57.4 37.6 18.8 55.0 28.0
Joint with Hierarchy 27.1 55.2 36.3 32.0 56.5 40.9 21.1 56.3 30.7
</table>
<tableCaption confidence="0.996169">
Table 3: Performance of Opinion Extraction with Correct Intensity Attribute
</tableCaption>
<table confidence="0.99831275">
Method Description r(%) p(%) f(%)
Polar-Only n Intensity-Only 43.3 92.0 58.9
Joint without Hierarchy 46.0 88.4 60.5
Joint with Hierarchy 48.0 87.8 62.0
</table>
<tableCaption confidence="0.999713">
Table 4: Performance of Opinion Extraction
</tableCaption>
<bodyText confidence="0.985599090909091">
respond to direct subjective expression and expres-
sive subjective element (Wiebe et al., 2005).2
Our implementation of hierarchical sequential
learning is based on the Mallet (McCallum, 2002)
code for CRFs. In all experiments, we use a Gaus-
sian prior of 1.0 for regularization. We use 135
documents for development, and test on a dif-
ferent set of 400 documents using 10-fold cross-
validation. We investigate three options for jointly
extracting opinion expressions with their attributes
as follows:
[Baseline-1] Polarity-Only n Intensity-Only:
For this baseline, we train two separate sequence
tagging CRFs: one that extracts opinion expres-
sions only with the polarity attribute (using com-
mon features and polarity extraction features in
Section 3), and another that extracts opinion ex-
pressions only with the intensity attribute (using
common features and intensity extraction features
in Section 3). We then combine the results from
two separate CRFs by collecting all opinion en-
tities extracted by both sequence taggers.3 This
</bodyText>
<footnote confidence="0.9971892">
2Only 1.5% of the polarity annotations correspond to
both; hence, we merge both into the neutral. Similarly, for
gold standard intensity, we merge extremely high into high.
3We collect all entities whose portions of text spans are
extracted by both models.
</footnote>
<bodyText confidence="0.968866444444444">
baseline effectively represents a cascaded compo-
nent approach.
[Baseline-2] Joint without Hierarchy: Here
we use simple linear-chain CRFs without exploit-
ing the class hierarchy for the opinion recognition
task. We use the tags shown in Table 1.
Joint with Hierarchy: Finally, we test the hi-
erarchical sequential learning approach elaborated
in Section 3.
</bodyText>
<subsectionHeader confidence="0.999064">
4.1 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.918314125">
We evaluate all experiments at the opinion entity
level, i.e. at the level of each opinion expression
rather than at the token level. We use three evalua-
tion metrics: recall, precision, and F-measure with
equally weighted recall and precision.
Table 4 shows the performance of opinion ex-
traction without matching any attribute. That is, an
extracted opinion entity is counted as correct if it
overlaps4 with a gold standard opinion expression,
without checking the correctness of its attributes.
Table 2 and 3 show the performance of opinion
extraction with the correct polarity and intensity
respectively.
From all of these evaluation criteria, JOINT WITH
4Overlap matching is a reasonable choice as the annotator
agreement study is also based on overlap matching (Wiebe
et al., 2005). One might wonder whether the overlap match-
ing scheme could allow a degenerative case where extracting
the entire test dataset as one giant opinion expression would
yield 100% recall and precision. Because each sentence cor-
responds to a different test instance in our model, and because
some sentences do not contain any opinion expression in the
dataset, such degenerative case is not possible in our experi-
ments.
</bodyText>
<page confidence="0.991964">
272
</page>
<bodyText confidence="0.999984690476191">
HIERARCHY performs the best, and the least effec-
tive one is BASELINE-1, which cascades two sepa-
rately trained models. It is interesting that the sim-
ple sequential tagging approach even without ex-
ploiting the hierarchy (BASELINE-2) performs better
than the cascaded approach (BASELINE-1).
When evaluating with respect to the polarity at-
tribute, the performance of the negative class is
substantially higher than the that of other classes.
This is not surprising as there is approximately
twice as much data for the negative class. When
evaluating with respect to the intensity attribute,
the performance of the LOW class is substantially
lower than that of other classes. This result reflects
the fact that it is inherently harder to distinguish
an opinion expression with low intensity from no
opinion. In general, we observe that determining
correct intensity attributes is a much harder task
than determining correct polarity attributes.
In order to have a sense of upper bound, we
also report the individual performance of two sep-
arately trained models used for BASELINE-1: for the
Polarity-Only model that extracts opinion bound-
aries only with polarity attribute, the F-scores with
respect to the positive, neutral, negative classes are
46.7, 47.5, 57.0, respectively. For the Intensity-
Only model, the F-scores with respect to the high,
medium, low classes are 37.1, 40.8, 26.6, respec-
tively. Remind that neither of these models alone
fully solve the joint task of extracting boundaries
as well as determining two attributions simultane-
ously. As a result, when conjoining the results
from the two models (BASELINE-1), the final per-
formance drops substantially.
We conclude from our experiments that the sim-
ple joint sequential tagging approach even with-
out exploiting the hierarchy brings a better perfor-
mance than combining two separately developed
systems. In addition, our hierarchical joint se-
quential learning approach brings a further perfor-
mance gain over the simple joint sequential tag-
ging method.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99968625">
Although there have been much research for fine-
grained opinion analysis (e.g., Hu and Liu (2004),
Wilson et al. (2005), Wilson et al. (2006), Choi
and Claire (2008), Wilson et al. (2009)),5 none is
</bodyText>
<footnote confidence="0.962635">
5For instance, the results of Wilson et al. (2005) is not
comparable even for our Polarity-Only model used inside
BASELINE-1, because Wilson et al. (2005) does not operate
</footnote>
<bodyText confidence="0.9998656875">
directly comparable to our results; much of previ-
ous work studies only a subset of what we tackle
in this paper. However, as shown in Section 4.1,
when we train the learning models only for a sub-
set of the tasks, we can achieve a better perfor-
mance instantly by making the problem simpler.
Our work differs from most of previous work in
that we investigate how solving multiple related
tasks affects performance on sub-tasks.
The hierarchical parameter sharing technique
used in this paper has been previously used by
Zhao et al. (2008) for opinion analysis. However,
Zhao et al. (2008) employs this technique only to
classify sentence-level attributes (polarity and in-
tensity), without involving a much harder task of
detecting boundaries of sub-sentential entities.
</bodyText>
<sectionHeader confidence="0.999438" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999943923076923">
We applied a hierarchical parameter sharing tech-
nique using Conditional Random Fields for fine-
grained opinion analysis. Our proposed approach
jointly extract opinion expressions from unstruc-
tured text and determine their attributes — polar-
ity and intensity. Empirical results indicate that
the simple joint sequential tagging approach even
without exploiting the hierarchy brings a better
performance than combining two separately de-
veloped systems. In addition, we found that the
hierarchical joint sequential learning approach im-
proves the performance over the simple joint se-
quential tagging method.
</bodyText>
<sectionHeader confidence="0.997561" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999866666666667">
This work was supported in part by National
Science Foundation Grants BCS-0904822, BCS-
0624277, IIS-0535099 and by the Department of
Homeland Security under ONR Grant N0014-07-
1-0152. We thank the reviewers and Ainur Yesse-
nalina for many helpful comments.
</bodyText>
<sectionHeader confidence="0.998313" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9535826">
S. Abney. 1996. Partial parsing via finite-state cas-
cades. In Journal ofNatural Language Engineering,
2(4).
E. Breck, Y. Choi and C. Cardie. 2007. Identifying
Expressions of Opinion in Context. In IJCAI.
</reference>
<bodyText confidence="0.9966986">
on the entire corpus as unstructured input. Instead, Wilson
et al. (2005) evaluate only on known words that are in their
opinion lexicon. Furthermore, Wilson et al. (2005) simplifies
the problem by combining neutral opinions and no opinions
into the same class, while our system distinguishes the two.
</bodyText>
<page confidence="0.998501">
273
</page>
<reference confidence="0.999966290909091">
L. Cai and T. Hofmann. 2004. Hierarchical docu-
ment categorization with support vector machines.
In CIKM.
Y. Choi and C. Cardie. 2008. Learning with Composi-
tional Semantics as Structural Inference for Subsen-
tential Sentiment Analysis. In EMNLP.
H. Cunningham, D. Maynard, K. Bontcheva and V.
Tablan. 2002. GATE: A Framework and Graphical
Development Environment for Robust NLP Tools
and Applications. In ACL.
J. R. Finkel, C. D. Manning and A. Y. Ng. 2006.
Solving the Problem of Cascading Errors: Approx-
imate Bayesian Inference for Linguistic Annotation
Pipelines. In EMNLP.
M. Hu and B. Liu. 2004. Mining and Summarizing
Customer Reviews. In KDD.
S. Kim and E. Hovy. 2004. Determining the sentiment
of opinions. In COLING.
S. Kim and E. Hovy. 2005. Automatic Detection of
Opinion Bearing Words and Sentences. In Com-
panion Volume to the Proceedings of the Second In-
ternational Joint Conference on Natural Language
Processing (IJCNLP-05).
J. Lafferty, A. McCallum and F. Pereira. 2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In ICML.
A. McCallum. 2002. MALLET: A Machine Learning
for Language Toolkit. http://mallet.cs.umass.edu.
G. A. Miller. 1995. WordNet: a lexical database for
English. In Communications of the ACM, 38(11).
Ana-Maria Popescu and O. Etzioni. 2005. Extracting
Product Features and Opinions from Reviews. In
HLT-EMNLP.
J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis,
B. Fraser, D. Litman, D. Pierce, E. Riloff and T.
Wilson. 2002. Summer Workshop on Multiple-
Perspective Question Answering: Final Report. In
NRRC.
J. Wiebe and T. Wilson and C. Cardie 2005. Annotat-
ing Expressions of Opinions and Emotions in Lan-
guage. In Language Resources and Evaluation, vol-
ume 39, issue 2-3.
T. Wilson, J. Wiebe and P. Hoffmann. 2005. Recogniz-
ing Contextual Polarity in Phrase-Level Sentiment
Analysis. In HLT-EMNLP.
T. Wilson, J. Wiebe and R. Hwa. 2006. Recognizing
strong and weak opinion clauses. In Computational
Intelligence. 22 (2): 73-99.
T. Wilson, J. Wiebe and P. Hoffmann. 2009. Recogniz-
ing Contextual Polarity: an exploration of features
for phrase-level sentiment analysis. Computational
Linguistics 35(3).
J. Zhao, K. Liu and G. Wang. 2008. Adding Redun-
dant Features for CRFs-based Sentence Sentiment
Classification. In EMNLP.
</reference>
<page confidence="0.998301">
274
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854389">
<title confidence="0.999221">Hierarchical Sequential Learning for Extracting Opinions and their Attributes</title>
<author confidence="0.998777">Yejin Choi</author>
<author confidence="0.998777">Claire Cardie</author>
<affiliation confidence="0.999776">Department of Computer Science Cornell University</affiliation>
<address confidence="0.999919">Ithaca, NY 14853</address>
<abstract confidence="0.993550913043478">Automatic opinion recognition involves a number of related tasks, such as identifying the boundaries of opinion expression, determining their polarity, and determining their intensity. Although much progress has been made in this area, existing research typically treats each of the above tasks in isolation. In this paper, we apply a hierarchical parameter sharing technique using Conditional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1996</date>
<journal>In Journal ofNatural Language Engineering,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="7274" citStr="Abney, 1996" startWordPosition="1198" endWordPosition="1199">erred to as EXP-SPAN. 3.1 Per-Token Features Per-token features are defined in the form of gO(α, x, i), gP(β, x, i) and gS(γ, x, i). The domains of α, β, γ are as given in Section 3. Common Per-Token Features Following features are common for all class labels. The notation ® indicates conjunctive operation of two values. • PART-OF-SPEECH(xi): based on GATE (Cunningham et al., 2002). • WORD(xi), WORD(xi−1), WORD(xi+1) • WORDNET-HYPERNYM(xi): based on WordNet (Miller, 1995). • OPINION-LEXICON(xi): based on opinion lexicon (Wiebe et al., 2002). • SHALLOW-PARSER(xi): based on CASS partial parser (Abney, 1996). • PRIOR-POLARITY(xi) ® PRIOR-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® STEM(xi) • EXP-SPAN(xi): boolean to indicate whether xi is in an EXP-SPAN. • DISTANCE-TO-EXP-SPAN(xi): 0, 1, 2, 3+. • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® EXP-SPAN(xi) Polarity Per-Token Features These features are included only for gO(α, x, i) and gP(β, x, i), which are the feature functions corresponding to the polarity-based classes. • PRIOR-POLARITY(xi), EXP-POLARITY((xi) • STEM(xi) ® EXP-POLARITY(xi) • COUNT-OF-Polarity: where Polarity E {positive, neutral, negati</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>S. Abney. 1996. Partial parsing via finite-state cascades. In Journal ofNatural Language Engineering, 2(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Breck</author>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Identifying Expressions of Opinion in Context.</title>
<date>2007</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="1269" citStr="Breck et al. (2007)" startWordPosition="183" endWordPosition="186">ysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectu</context>
</contexts>
<marker>Breck, Choi, Cardie, 2007</marker>
<rawString>E. Breck, Y. Choi and C. Cardie. 2007. Identifying Expressions of Opinion in Context. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Cai</author>
<author>T Hofmann</author>
</authors>
<title>Hierarchical document categorization with support vector machines.</title>
<date>2004</date>
<booktitle>In CIKM.</booktitle>
<contexts>
<context position="2115" citStr="Cai and Hofmann (2004)" startWordPosition="311" endWordPosition="314">ts each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in our case, in the end-to-end opinion recognition system. In this paper, we apply a hierarchical parameter sharing technique (e.g., Cai and Hofmann (2004), Zhao et al. (2008)) using Conditional Random Fields (CRFs) (Lafferty et al., 2001) to finegrained opinion analysis. In particular, we aim to jointly identify the boundaries of opinion expressions as well as to determine two of their key attributes — polarity and intensity. Experimental results show that our proposed approach improves the performance over the baseline that does not exploit the hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate systems. 2 Hierarchical Sequential Learning We defin</context>
</contexts>
<marker>Cai, Hofmann, 2004</marker>
<rawString>L. Cai and T. Hofmann. 2004. Hierarchical document categorization with support vector machines. In CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<marker>Choi, Cardie, 2008</marker>
<rawString>Y. Choi and C. Cardie. 2008. Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>K Bontcheva</author>
<author>V Tablan</author>
</authors>
<title>GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7046" citStr="Cunningham et al., 2002" startWordPosition="1166" endWordPosition="1169">ere is a word with a negation effect, such as “never”, “not”, “hardly”, “against”, then we flip the polarity. For EXP-INTENSITY, we use the highest PRIOR-INTENSITY in the span. The text span with the same expression-level attributes are referred to as EXP-SPAN. 3.1 Per-Token Features Per-token features are defined in the form of gO(α, x, i), gP(β, x, i) and gS(γ, x, i). The domains of α, β, γ are as given in Section 3. Common Per-Token Features Following features are common for all class labels. The notation ® indicates conjunctive operation of two values. • PART-OF-SPEECH(xi): based on GATE (Cunningham et al., 2002). • WORD(xi), WORD(xi−1), WORD(xi+1) • WORDNET-HYPERNYM(xi): based on WordNet (Miller, 1995). • OPINION-LEXICON(xi): based on opinion lexicon (Wiebe et al., 2002). • SHALLOW-PARSER(xi): based on CASS partial parser (Abney, 1996). • PRIOR-POLARITY(xi) ® PRIOR-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® STEM(xi) • EXP-SPAN(xi): boolean to indicate whether xi is in an EXP-SPAN. • DISTANCE-TO-EXP-SPAN(xi): 0, 1, 2, 3+. • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® EXP-SPAN(xi) Polarity Per-Token Features These features are included only for gO(α, x, i) </context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>H. Cunningham, D. Maynard, K. Bontcheva and V. Tablan. 2002. GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>C D Manning</author>
<author>A Y Ng</author>
</authors>
<title>Solving the Problem of Cascading Errors: Approximate Bayesian Inference for Linguistic Annotation Pipelines.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1956" citStr="Finkel et al. (2006)" startWordPosition="284" endWordPosition="287"> (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in our case, in the end-to-end opinion recognition system. In this paper, we apply a hierarchical parameter sharing technique (e.g., Cai and Hofmann (2004), Zhao et al. (2008)) using Conditional Random Fields (CRFs) (Lafferty et al., 2001) to finegrained opinion analysis. In particular, we aim to jointly identify the boundaries of opinion expressions as well as to determine two of their key attributes — polarity and intensity. Experimental results show that our proposed approach improves the performance over the baseline that does not exploit the hierarchical structure among the classes. I</context>
</contexts>
<marker>Finkel, Manning, Ng, 2006</marker>
<rawString>J. R. Finkel, C. D. Manning and A. Y. Ng. 2006. Solving the Problem of Cascading Errors: Approximate Bayesian Inference for Linguistic Annotation Pipelines. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="1322" citStr="Hu and Liu (2004)" startWordPosition="191" endWordPosition="194">ssions as well as determining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend</context>
<context position="15919" citStr="Hu and Liu (2004)" startWordPosition="2476" endWordPosition="2479">ermining two attributions simultaneously. As a result, when conjoining the results from the two models (BASELINE-1), the final performance drops substantially. We conclude from our experiments that the simple joint sequential tagging approach even without exploiting the hierarchy brings a better performance than combining two separately developed systems. In addition, our hierarchical joint sequential learning approach brings a further performance gain over the simple joint sequential tagging method. 5 Related Work Although there have been much research for finegrained opinion analysis (e.g., Hu and Liu (2004), Wilson et al. (2005), Wilson et al. (2006), Choi and Claire (2008), Wilson et al. (2009)),5 none is 5For instance, the results of Wilson et al. (2005) is not comparable even for our Polarity-Only model used inside BASELINE-1, because Wilson et al. (2005) does not operate directly comparable to our results; much of previous work studies only a subset of what we tackle in this paper. However, as shown in Section 4.1, when we train the learning models only for a subset of the tasks, we can achieve a better performance instantly by making the problem simpler. Our work differs from most of previo</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and Summarizing Customer Reviews. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="1343" citStr="Kim and Hovy (2004)" startWordPosition="195" endWordPosition="198">etermining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel </context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>E Hovy</author>
</authors>
<title>Automatic Detection of Opinion Bearing Words and Sentences.</title>
<date>2005</date>
<booktitle>In Companion Volume to the Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP-05).</booktitle>
<contexts>
<context position="1220" citStr="Kim and Hovy (2005)" startWordPosition="175" endWordPosition="178">ional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propag</context>
</contexts>
<marker>Kim, Hovy, 2005</marker>
<rawString>S. Kim and E. Hovy. 2005. Automatic Detection of Opinion Bearing Words and Sentences. In Companion Volume to the Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="2199" citStr="Lafferty et al., 2001" startWordPosition="325" endWordPosition="328">daries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in our case, in the end-to-end opinion recognition system. In this paper, we apply a hierarchical parameter sharing technique (e.g., Cai and Hofmann (2004), Zhao et al. (2008)) using Conditional Random Fields (CRFs) (Lafferty et al., 2001) to finegrained opinion analysis. In particular, we aim to jointly identify the boundaries of opinion expressions as well as to determine two of their key attributes — polarity and intensity. Experimental results show that our proposed approach improves the performance over the baseline that does not exploit the hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate systems. 2 Hierarchical Sequential Learning We define the problem of joint extraction of opinion expressions and their attributes as a s</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum and F. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<location>http://mallet.cs.umass.edu.</location>
<contexts>
<context position="11119" citStr="McCallum, 2002" startWordPosition="1729" endWordPosition="1730"> 24.5 Joint without Hierarchy (BASELINE2) 29.7 54.2 38.4 28.0 57.4 37.6 18.8 55.0 28.0 Joint with Hierarchy 27.1 55.2 36.3 32.0 56.5 40.9 21.1 56.3 30.7 Table 3: Performance of Opinion Extraction with Correct Intensity Attribute Method Description r(%) p(%) f(%) Polar-Only n Intensity-Only 43.3 92.0 58.9 Joint without Hierarchy 46.0 88.4 60.5 Joint with Hierarchy 48.0 87.8 62.0 Table 4: Performance of Opinion Extraction respond to direct subjective expression and expressive subjective element (Wiebe et al., 2005).2 Our implementation of hierarchical sequential learning is based on the Mallet (McCallum, 2002) code for CRFs. In all experiments, we use a Gaussian prior of 1.0 for regularization. We use 135 documents for development, and test on a different set of 400 documents using 10-fold crossvalidation. We investigate three options for jointly extracting opinion expressions with their attributes as follows: [Baseline-1] Polarity-Only n Intensity-Only: For this baseline, we train two separate sequence tagging CRFs: one that extracts opinion expressions only with the polarity attribute (using common features and polarity extraction features in Section 3), and another that extracts opinion expressi</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>A. McCallum. 2002. MALLET: A Machine Learning for Language Toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: a lexical database for English.</title>
<date>1995</date>
<journal>In Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="7138" citStr="Miller, 1995" startWordPosition="1179" endWordPosition="1180">arity. For EXP-INTENSITY, we use the highest PRIOR-INTENSITY in the span. The text span with the same expression-level attributes are referred to as EXP-SPAN. 3.1 Per-Token Features Per-token features are defined in the form of gO(α, x, i), gP(β, x, i) and gS(γ, x, i). The domains of α, β, γ are as given in Section 3. Common Per-Token Features Following features are common for all class labels. The notation ® indicates conjunctive operation of two values. • PART-OF-SPEECH(xi): based on GATE (Cunningham et al., 2002). • WORD(xi), WORD(xi−1), WORD(xi+1) • WORDNET-HYPERNYM(xi): based on WordNet (Miller, 1995). • OPINION-LEXICON(xi): based on opinion lexicon (Wiebe et al., 2002). • SHALLOW-PARSER(xi): based on CASS partial parser (Abney, 1996). • PRIOR-POLARITY(xi) ® PRIOR-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® STEM(xi) • EXP-SPAN(xi): boolean to indicate whether xi is in an EXP-SPAN. • DISTANCE-TO-EXP-SPAN(xi): 0, 1, 2, 3+. • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® EXP-SPAN(xi) Polarity Per-Token Features These features are included only for gO(α, x, i) and gP(β, x, i), which are the feature functions corresponding to the polarity-based classes</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>G. A. Miller. 1995. WordNet: a lexical database for English. In Communications of the ACM, 38(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP.</booktitle>
<contexts>
<context position="1248" citStr="Popescu and Etzioni (2005)" startWordPosition="179" endWordPosition="182">or fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and O. Etzioni. 2005. Extracting Product Features and Opinions from Reviews. In HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>E Breck</author>
<author>C Buckley</author>
<author>C Cardie</author>
<author>P Davis</author>
<author>B Fraser</author>
<author>D Litman</author>
<author>D Pierce</author>
<author>E Riloff</author>
<author>T Wilson</author>
</authors>
<title>Summer Workshop on MultiplePerspective Question Answering: Final Report.</title>
<date>2002</date>
<booktitle>In NRRC.</booktitle>
<contexts>
<context position="7208" citStr="Wiebe et al., 2002" startWordPosition="1187" endWordPosition="1190">the span. The text span with the same expression-level attributes are referred to as EXP-SPAN. 3.1 Per-Token Features Per-token features are defined in the form of gO(α, x, i), gP(β, x, i) and gS(γ, x, i). The domains of α, β, γ are as given in Section 3. Common Per-Token Features Following features are common for all class labels. The notation ® indicates conjunctive operation of two values. • PART-OF-SPEECH(xi): based on GATE (Cunningham et al., 2002). • WORD(xi), WORD(xi−1), WORD(xi+1) • WORDNET-HYPERNYM(xi): based on WordNet (Miller, 1995). • OPINION-LEXICON(xi): based on opinion lexicon (Wiebe et al., 2002). • SHALLOW-PARSER(xi): based on CASS partial parser (Abney, 1996). • PRIOR-POLARITY(xi) ® PRIOR-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® STEM(xi) • EXP-SPAN(xi): boolean to indicate whether xi is in an EXP-SPAN. • DISTANCE-TO-EXP-SPAN(xi): 0, 1, 2, 3+. • EXP-POLARITY(xi) ® EXP-INTENSITY(xi) ® EXP-SPAN(xi) Polarity Per-Token Features These features are included only for gO(α, x, i) and gP(β, x, i), which are the feature functions corresponding to the polarity-based classes. • PRIOR-POLARITY(xi), EXP-POLARITY((xi) • STEM(xi) ® EXP-POLARITY(xi</context>
</contexts>
<marker>Wiebe, Breck, Buckley, Cardie, Davis, Fraser, Litman, Pierce, Riloff, Wilson, 2002</marker>
<rawString>J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis, B. Fraser, D. Litman, D. Pierce, E. Riloff and T. Wilson. 2002. Summer Workshop on MultiplePerspective Question Answering: Final Report. In NRRC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>C Cardie</author>
</authors>
<date>2005</date>
<booktitle>Annotating Expressions of Opinions and Emotions in Language. In Language Resources and Evaluation,</booktitle>
<volume>39</volume>
<pages>2--3</pages>
<contexts>
<context position="11022" citStr="Wiebe et al., 2005" startWordPosition="1714" endWordPosition="1717">(%) r(%) p(%) f(%) Polarity-Only n Intensity-Only (BASELINE1) 26.4 58.3 36.3 29.7 59.0 39.6 15.4 60.3 24.5 Joint without Hierarchy (BASELINE2) 29.7 54.2 38.4 28.0 57.4 37.6 18.8 55.0 28.0 Joint with Hierarchy 27.1 55.2 36.3 32.0 56.5 40.9 21.1 56.3 30.7 Table 3: Performance of Opinion Extraction with Correct Intensity Attribute Method Description r(%) p(%) f(%) Polar-Only n Intensity-Only 43.3 92.0 58.9 Joint without Hierarchy 46.0 88.4 60.5 Joint with Hierarchy 48.0 87.8 62.0 Table 4: Performance of Opinion Extraction respond to direct subjective expression and expressive subjective element (Wiebe et al., 2005).2 Our implementation of hierarchical sequential learning is based on the Mallet (McCallum, 2002) code for CRFs. In all experiments, we use a Gaussian prior of 1.0 for regularization. We use 135 documents for development, and test on a different set of 400 documents using 10-fold crossvalidation. We investigate three options for jointly extracting opinion expressions with their attributes as follows: [Baseline-1] Polarity-Only n Intensity-Only: For this baseline, we train two separate sequence tagging CRFs: one that extracts opinion expressions only with the polarity attribute (using common fe</context>
<context position="13377" citStr="Wiebe et al., 2005" startWordPosition="2077" endWordPosition="2080"> recall, precision, and F-measure with equally weighted recall and precision. Table 4 shows the performance of opinion extraction without matching any attribute. That is, an extracted opinion entity is counted as correct if it overlaps4 with a gold standard opinion expression, without checking the correctness of its attributes. Table 2 and 3 show the performance of opinion extraction with the correct polarity and intensity respectively. From all of these evaluation criteria, JOINT WITH 4Overlap matching is a reasonable choice as the annotator agreement study is also based on overlap matching (Wiebe et al., 2005). One might wonder whether the overlap matching scheme could allow a degenerative case where extracting the entire test dataset as one giant opinion expression would yield 100% recall and precision. Because each sentence corresponds to a different test instance in our model, and because some sentences do not contain any opinion expression in the dataset, such degenerative case is not possible in our experiments. 272 HIERARCHY performs the best, and the least effective one is BASELINE-1, which cascades two separately trained models. It is interesting that the simple sequential tagging approach </context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>J. Wiebe and T. Wilson and C. Cardie 2005. Annotating Expressions of Opinions and Emotions in Language. In Language Resources and Evaluation, volume 39, issue 2-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP.</booktitle>
<contexts>
<context position="1365" citStr="Wilson et al. (2005)" startWordPosition="199" endWordPosition="202">ir key attributes — polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in ou</context>
<context position="5555" citStr="Wilson et al. (2005)" startWordPosition="928" endWordPosition="931">an the number of sets of parameters that are needed without the hierarchy. The former requires (2 + 4 +4) +(2 x 2 +4 x 4+ 4 x 4) = 46 sets of parameters, but the latter requires (10) + (10 x 10) = 110 sets of parameters. Because a combination of a polarity component and an intensity component can distinguish each label, it is not necessary to define a separate set of parameters for each label. 3 Features We first introduce definitions of key terms that will be used to describe features. • PRIOR-POLARITY &amp; PRIOR-INTENSITY: We obtain these prior-attributes from the polarity lexicon populated by Wilson et al. (2005). • EXP-POLARITY, EXP-INTENSITY &amp; EXP-SPAN: α, α� E {OPINION, NO-OPINION} β, β� E {POSITIVE, NEGATIVE, NEUTRAL, NO-POLARITY} γ, γ� E {HIGH, MEDIUM, LOW, NO-INTENSITY} and λ′ �δ g′ I(δ, δ, + λ′ NO-POLARITY, NEUTRAL g′ P(NO-POLARITY, NEUTRAL, x, i) + λ′NO-INTENSITY, HIGH g′S(NO-INTENSITY, HIGH, x, i) This hierarchical construction of feature and weight vectors allows similar labels to share the same subcomponents of feature and weight vectors. For instance, all λ f(yi, x, i) such that Words in a given opinion expression often do not share the same prior-attributes. Such discontinuous distributio</context>
<context position="15941" citStr="Wilson et al. (2005)" startWordPosition="2480" endWordPosition="2483">utions simultaneously. As a result, when conjoining the results from the two models (BASELINE-1), the final performance drops substantially. We conclude from our experiments that the simple joint sequential tagging approach even without exploiting the hierarchy brings a better performance than combining two separately developed systems. In addition, our hierarchical joint sequential learning approach brings a further performance gain over the simple joint sequential tagging method. 5 Related Work Although there have been much research for finegrained opinion analysis (e.g., Hu and Liu (2004), Wilson et al. (2005), Wilson et al. (2006), Choi and Claire (2008), Wilson et al. (2009)),5 none is 5For instance, the results of Wilson et al. (2005) is not comparable even for our Polarity-Only model used inside BASELINE-1, because Wilson et al. (2005) does not operate directly comparable to our results; much of previous work studies only a subset of what we tackle in this paper. However, as shown in Section 4.1, when we train the learning models only for a subset of the tasks, we can achieve a better performance instantly by making the problem simpler. Our work differs from most of previous work in that we inv</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe and P. Hoffmann. 2005. Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. In HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>R Hwa</author>
</authors>
<title>Recognizing strong and weak opinion clauses.</title>
<date>2006</date>
<journal>In Computational Intelligence.</journal>
<volume>22</volume>
<issue>2</issue>
<pages>73--99</pages>
<contexts>
<context position="1467" citStr="Wilson et al. (2006)" startWordPosition="215" endWordPosition="218">mproves the performance over a baseline that does not exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components. 1 Introduction Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g. Kim and Hovy (2005), Popescu and Etzioni (2005), Breck et al. (2007)), determining their polarity (e.g. Hu and Liu (2004), Kim and Hovy (2004), Wilson et al. (2005)), and determining their strength, or intensity (e.g. Popescu and Etzioni (2005), Wilson et al. (2006)). Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in our case, in the end-to-end opinion recognition system. In this paper, we apply a hierarchical parameter</context>
<context position="15963" citStr="Wilson et al. (2006)" startWordPosition="2484" endWordPosition="2487"> As a result, when conjoining the results from the two models (BASELINE-1), the final performance drops substantially. We conclude from our experiments that the simple joint sequential tagging approach even without exploiting the hierarchy brings a better performance than combining two separately developed systems. In addition, our hierarchical joint sequential learning approach brings a further performance gain over the simple joint sequential tagging method. 5 Related Work Although there have been much research for finegrained opinion analysis (e.g., Hu and Liu (2004), Wilson et al. (2005), Wilson et al. (2006), Choi and Claire (2008), Wilson et al. (2009)),5 none is 5For instance, the results of Wilson et al. (2005) is not comparable even for our Polarity-Only model used inside BASELINE-1, because Wilson et al. (2005) does not operate directly comparable to our results; much of previous work studies only a subset of what we tackle in this paper. However, as shown in Section 4.1, when we train the learning models only for a subset of the tasks, we can achieve a better performance instantly by making the problem simpler. Our work differs from most of previous work in that we investigate how solving m</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2006</marker>
<rawString>T. Wilson, J. Wiebe and R. Hwa. 2006. Recognizing strong and weak opinion clauses. In Computational Intelligence. 22 (2): 73-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity: an exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Computational Linguistics</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="16009" citStr="Wilson et al. (2009)" startWordPosition="2492" endWordPosition="2495"> the two models (BASELINE-1), the final performance drops substantially. We conclude from our experiments that the simple joint sequential tagging approach even without exploiting the hierarchy brings a better performance than combining two separately developed systems. In addition, our hierarchical joint sequential learning approach brings a further performance gain over the simple joint sequential tagging method. 5 Related Work Although there have been much research for finegrained opinion analysis (e.g., Hu and Liu (2004), Wilson et al. (2005), Wilson et al. (2006), Choi and Claire (2008), Wilson et al. (2009)),5 none is 5For instance, the results of Wilson et al. (2005) is not comparable even for our Polarity-Only model used inside BASELINE-1, because Wilson et al. (2005) does not operate directly comparable to our results; much of previous work studies only a subset of what we tackle in this paper. However, as shown in Section 4.1, when we train the learning models only for a subset of the tasks, we can achieve a better performance instantly by making the problem simpler. Our work differs from most of previous work in that we investigate how solving multiple related tasks affects performance on s</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>T. Wilson, J. Wiebe and P. Hoffmann. 2009. Recognizing Contextual Polarity: an exploration of features for phrase-level sentiment analysis. Computational Linguistics 35(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zhao</author>
<author>K Liu</author>
<author>G Wang</author>
</authors>
<title>Adding Redundant Features for CRFs-based Sentence Sentiment Classification.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2135" citStr="Zhao et al. (2008)" startWordPosition="315" endWordPosition="318">tion: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems. Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g. Finkel et al. (2006)) — in our case, in the end-to-end opinion recognition system. In this paper, we apply a hierarchical parameter sharing technique (e.g., Cai and Hofmann (2004), Zhao et al. (2008)) using Conditional Random Fields (CRFs) (Lafferty et al., 2001) to finegrained opinion analysis. In particular, we aim to jointly identify the boundaries of opinion expressions as well as to determine two of their key attributes — polarity and intensity. Experimental results show that our proposed approach improves the performance over the baseline that does not exploit the hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate systems. 2 Hierarchical Sequential Learning We define the problem of joi</context>
<context position="16729" citStr="Zhao et al. (2008)" startWordPosition="2615" endWordPosition="2618">-Only model used inside BASELINE-1, because Wilson et al. (2005) does not operate directly comparable to our results; much of previous work studies only a subset of what we tackle in this paper. However, as shown in Section 4.1, when we train the learning models only for a subset of the tasks, we can achieve a better performance instantly by making the problem simpler. Our work differs from most of previous work in that we investigate how solving multiple related tasks affects performance on sub-tasks. The hierarchical parameter sharing technique used in this paper has been previously used by Zhao et al. (2008) for opinion analysis. However, Zhao et al. (2008) employs this technique only to classify sentence-level attributes (polarity and intensity), without involving a much harder task of detecting boundaries of sub-sentential entities. 6 Conclusion We applied a hierarchical parameter sharing technique using Conditional Random Fields for finegrained opinion analysis. Our proposed approach jointly extract opinion expressions from unstructured text and determine their attributes — polarity and intensity. Empirical results indicate that the simple joint sequential tagging approach even without exploit</context>
</contexts>
<marker>Zhao, Liu, Wang, 2008</marker>
<rawString>J. Zhao, K. Liu and G. Wang. 2008. Adding Redundant Features for CRFs-based Sentence Sentiment Classification. In EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>