<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999208">
Uncertainty Reduction in Collaborative Bootstrapping:
Measure and Algorithm
</title>
<author confidence="0.996693">
Yunbo Cao
</author>
<affiliation confidence="0.995741">
Microsoft Research Asia
</affiliation>
<address confidence="0.986396">
5F Sigma Center,
No.49 Zhichun Road, Haidian
Beijing, China, 100080
</address>
<email confidence="0.995984">
i-yucao@microsoft.com
</email>
<author confidence="0.993863">
Hang Li
</author>
<affiliation confidence="0.993747">
Microsoft Research Asia
</affiliation>
<address confidence="0.986396666666667">
5F Sigma Center,
No.49 Zhichun Road, Haidian
Beijing, China, 100080
</address>
<email confidence="0.995856">
hangli@microsoft.com
</email>
<author confidence="0.978779">
Li Lian
</author>
<affiliation confidence="0.995808">
Computer Science Department
Fudan University
</affiliation>
<address confidence="0.976673">
No. 220 Handan Road
Shanghai, China, 200433
</address>
<email confidence="0.994152">
leelix@yahoo.com
</email>
<sectionHeader confidence="0.998579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99976905">
This paper proposes the use of uncertainty
reduction in machine learning methods
such as co-training and bilingual boot-
strapping, which are referred to, in a gen-
eral term, as ‘collaborative bootstrapping’.
The paper indicates that uncertainty re-
duction is an important factor for enhanc-
ing the performance of collaborative
bootstrapping. It proposes a new measure
for representing the degree of uncertainty
correlation of the two classifiers in col-
laborative bootstrapping and uses the
measure in analysis of collaborative boot-
strapping. Furthermore, it proposes a new
algorithm of collaborative bootstrapping
on the basis of uncertainty reduction. Ex-
perimental results have verified the cor-
rectness of the analysis and have
demonstrated the significance of the new
algorithm.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999897568627451">
We consider here the problem of collaborative
bootstrapping. It includes co-training (Blum and
Mitchell, 1998; Collins and Singer, 1998; Nigam
and Ghani, 2000) and bilingual bootstrapping (Li
and Li, 2002).
Collaborative bootstrapping begins with a small
number of labelled data and a large number of
unlabelled data. It trains two (types of) classifiers
from the labelled data, uses the two classifiers to
label some unlabelled data, trains again two new
classifiers from all the labelled data, and repeats
the above process. During the process, the two
classifiers help each other by exchanging the la-
belled data. In co-training, the two classifiers have
different feature structures, and in bilingual boot-
strapping, the two classifiers have different class
structures.
Dasgupta et al (2001) and Abney (2002) con-
ducted theoretical analyses on the performance
(generalization error) of co-training. Their analyses,
however, cannot be directly used in studies of co-
training in (Nigam &amp; Ghani, 2000) and bilingual
bootstrapping.
In this paper, we propose the use of uncertainty
reduction in the study of collaborative bootstrap-
ping (both co-training and bilingual bootstrapping).
We point out that uncertainty reduction is an im-
portant factor for enhancing the performances of
the classifiers in collaborative bootstrapping. Here,
the uncertainty of a classifier is defined as the por-
tion of instances on which it cannot make classifi-
cation decisions. Exchanging labelled data in
bootstrapping can help reduce the uncertainties of
classifiers.
Uncertainty reduction was previously used in
active learning. We think that it is this paper which
for the first time uses it for bootstrapping.
We propose a new measure for representing the
uncertainty correlation between the two classifiers
in collaborative bootstrapping and refer to it as
‘uncertainty correlation coefficient’ (UCC). We
use UCC for analysis of collaborative bootstrap-
ping. We also propose a new algorithm to improve
the performance of existing collaborative boot-
strapping algorithms. In the algorithm, one classi-
fier always asks the other classifier to label the
most uncertain instances for it.
Experimental results indicate that our theoreti-
cal analysis is correct. Experimental results also
indicate that our new algorithm outperforms exist-
ing algorithms.
</bodyText>
<sectionHeader confidence="0.999899" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.998591">
2.1 Co-Training and Bilingual Bootstrapping
</subsectionHeader>
<bodyText confidence="0.998342716981132">
Co-training, proposed by Blum and Mitchell
(1998), conducts two bootstrapping processes in
parallel, and makes them collaborate with each
other. More specifically, it repeatedly trains two
classifiers from the labelled data, labels some
unlabelled data with the two classifiers, and ex-
changes the newly labelled data between the two
classifiers. Blum and Mitchell assume that the two
classifiers are based on two subsets of the entire
feature set and the two subsets are conditionally
independent with one another given a class. This
assumption is called ‘view independence’. In their
algorithm of co-training, one classifier always asks
the other classifier to label the most certain in-
stances for the collaborator. The word sense dis-
ambiguation method proposed in Yarowsky (1995)
can also be viewed as a kind of co-training.
Since the assumption of view independence
cannot always be met in practice, Collins and
Singer (1998) proposed a co-training algorithm
based on ‘agreement’ between the classifiers.
As for theoretical analysis, Dasgupta et al.
(2001) gave a bound on the generalization error of
co-training within the framework of PAC learning.
The generalization error is a function of ‘dis-
agreement’ between the two classifiers. Dasgupta
et al’s result is based on the view independence
assumption, which is strict in practice.
Abney (2002) refined Dasgupta et al’s result by
relaxing the view independence assumption with a
new constraint. He also proposed a new co-training
algorithm on the basis of the constraint.
Nigam and Ghani (2000) empirically demon-
strated that bootstrapping with a random feature
split (i.e. co-training), even violating the view in-
dependence assumption, can still work better than
bootstrapping without a feature split (i.e., boot-
strapping with a single classifier).
For other work on co-training, see (Muslea et al
200; Pierce and Cardie 2001).
Li and Li (2002) proposed an algorithm for
word sense disambiguation in translation between
two languages, which they called ‘bilingual boot-
strapping’. Instead of making an assumption on the
features, bilingual bootstrapping makes an assump-
tion on the classes. Specifically, it assumes that the
classes of the classifiers in bootstrapping do not
overlap. Thus, bilingual bootstrapping is different
from co-training.
Because the notion of agreement is not involved
in bootstrapping in (Nigam &amp; Ghani 2000) and
bilingual bootstrapping, Dasgupta et al and
Abney’s analyses cannot be directly used on them.
</bodyText>
<subsectionHeader confidence="0.999424">
2.2 Active Learning
</subsectionHeader>
<bodyText confidence="0.999932125">
Active leaning is a learning paradigm. Instead of
passively using all the given labelled instances for
training as in supervised learning, active learning
repeatedly asks a supervisor to label what it con-
siders as the most critical instances and performs
training with the labelled instances. Thus, active
learning can eventually create a reliable classifier
with fewer labelled instances than supervised
learning. One of the strategies to select critical in-
stances is called ‘uncertain reduction’ (e.g., Lewis
and Gale, 1994). Under the strategy, the most un-
certain instances to the current classifier are se-
lected and asked to be labelled by a supervisor.
The notion of uncertainty reduction was not
used for bootstrapping, to the best of our knowl-
edge.
</bodyText>
<sectionHeader confidence="0.9100545" genericHeader="method">
3 Collaborative Bootstrapping and Un-
certainty Reduction
</sectionHeader>
<bodyText confidence="0.987892942857143">
We consider the collaborative bootstrapping prob-
lem.
Let X denote a set of instances (feature vectors)
and letT denote a set of labels (classes). Given a
number of labelled instances, we are to construct a
function h : X —&gt; T . We also refer to it as a classi-
fier.
In collaborative bootstrapping, we consider the
use of two partial functions h1 and h2 , which either
output a class label or a special symbol 1 denoting
‘no decision’.
Co-training and bilingual bootstrapping are two
examples of collaborative bootstrapping.
In co-training, the two collaborating classifiers
are assumed to be based on two different views,
namely two different subsets of the entire feature
set. Formally, the two views are respectively inter-
preted as two functions X1(x) and X2( x ), x� X .
Thus, the two collaborating classifiers h1 and h2 in
co-training can be respectively represented as
h1(X1(x)) and h2(X2(x)).
In bilingual bootstrapping, a number of classifi-
ers are created in the two languages. The classes of
the classifiers correspond to word senses and do
not overlap, as shown in Figure 1. For example, the
classifier h1( x  |E1) in language 1 takes sense 2
and sense 3 as classes. The classifier h2 ( x  |C1 ) in
language 2 takes sense 1 and sense 2 as classes,
and the classifier h2 ( x  |C2 ) takes sense 3 and
sense 4 as classes. Here we use E1 , C1 , C 2 to de-
note different words in the two languages. Collabo-
rative bootstrapping is performed between the
classifiers h1(*) in language 1 and the classifiers
h2(*) in language 2. (See Li and Li 2002 for de-
tails).
</bodyText>
<figureCaption confidence="0.98893">
Figure 1: Bilingual Bootstrapping
</figureCaption>
<bodyText confidence="0.946034142857142">
For the classifier h1 ( x  |E1 ) in language 1, we
assume that there is a pseudo classifier
h2 ( x  |C1 , C2 ) in language 2, which functions as a
collaborator of h1 ( x  |E1 ) . The pseudo classifier
h2( x  |C1, C2) is based on h2( x  |C1) and
h2 ( x  |C2 ), and takes sense 2 and sense 3 as classes.
Formally, the two collaborating classifiers (one
real classifier and one pseudo classifier) in bilin-
gual bootstrapping are respectively represented as
h1(x |E) and h2(x  |C), xe X.
Next, we introduce the notion of uncertainty re-
duction in collaborative bootstrapping.
Definition 1 The uncertainty U (h ) of a classi-
fierh is defined as:
</bodyText>
<equation confidence="0.757312">
U h = P x h x =1 xe X
( ) ( {  |( ) , }) (1)
In practice, we define U ( h ) as
U(h) = P( {x  |C(h(x) = y) &lt; q, dy e r, x e X}) (2)
</equation>
<bodyText confidence="0.993388333333333">
where q denotes a predetermined threshold and
C ( * ) denotes the confidence score of the classifier
h.
Definition 2 The conditional uncer-
tainty U (h  |y) of a classifier h given a class y is
defined as:
</bodyText>
<equation confidence="0.69001">
U(h  |y) = P( {x  |h(x) =1, x e X}  |Y = y) (3)
</equation>
<bodyText confidence="0.999204833333334">
We note that the uncertainty (or conditional un-
certainty) of a classifier (a partial function) is an
indicator of the accuracy of the classifier. Let us
consider an ideal case in which the classifier
achieves 100% accuracy when it can make a classi-
fication decision and achieves 50% accuracy when
it cannot (assume that there are only two classes).
Thus, the total accuracy on the entire data space is
1−0 . 5xU(h).
Definition 3 Given the two classifiers h1 and h2
in collaborative bootstrapping, the uncertainty re-
duction of h1 with respect to h2 (denoted as
</bodyText>
<equation confidence="0.9630308">
UR(h1 \ h2) ), is defined as
UR(h1\h2)=P( {x|4(x)=1,h2(x)11,xeX}) (4)
Similarly, we have
UR(h2 \ 4) = P( {x  |h1 (x) 11, h2 (x) =1, xe X
})
</equation>
<bodyText confidence="0.999019428571429">
Uncertainty reduction is an important factor for
determining the performance of collaborative boot-
strapping. In collaborative bootstrapping, the more
the uncertainty of one classifier can be reduced by
the other classifier, the higher the performance can
be achieved by the classifier (the more effective
the collaboration is).
</bodyText>
<sectionHeader confidence="0.9941045" genericHeader="method">
4 Uncertainty Correlation Coefficient
Measure
</sectionHeader>
<subsectionHeader confidence="0.999274">
4.1 Measure
</subsectionHeader>
<bodyText confidence="0.999946142857143">
We introduce the measure of uncertainty correla-
tion coefficient (UCC) to collaborative bootstrap-
ping.
Definition 4 Given the two classifiers h1 and h2,
the conditional uncertainty correlation coefficient
(CUCC) between h1 and h2 given a class y (denoted
as rh1h2y ), is defined as
</bodyText>
<equation confidence="0.99742375">
P
( 1
(x)
)P(h ( x)
</equation>
<bodyText confidence="0.935007333333333">
Definition 5 The uncertainty correlation coeffi-
cient (UCC) between h1 and h2 (denoted as Rh1h2 ),
is defined as
</bodyText>
<equation confidence="0.9697215">
Rh1h2 = 1: P( y )rh1 h2y (6)
y
</equation>
<bodyText confidence="0.592539">
UCC represents the degree to which the uncer-
</bodyText>
<equation confidence="0.996828625">
r=
h1h2y P(h1(x) =1 |Y = y 2
=1, h2 (x) =1
 |Y y )
=
(5)
=1 =
|Y y)
</equation>
<bodyText confidence="0.9722285">
Similarly we have
We can rewrite them as
</bodyText>
<equation confidence="0.982604315789474">
P h u h v Y y P h u Y y P h v Y y
( , ,
= = = = = =
 |) (  |) (  |)
= =
1 2 1 2
Thus, we have
P x h x h x x
( {  |( ) , ( ) ,
= =
1 2
=P x h x x
( {  |( ) , }  |) ( {  |( )
=  � Y y P x h x x
= =  �}
1 2
It means
rhh y =1. 0 , y � ❑
1 2
</equation>
<bodyText confidence="0.9592">
Theorem 2 indicates that in co-training with
view independence, the CUCC values
( rh h y , y  � ) are small, since by defini-
</bodyText>
<equation confidence="0.9842425">
1 2
tion &lt; rh 1 h2y &lt; 
</equation>
<bodyText confidence="0.934959142857143">
0 . According to Theorem 1, it is
easy to reduce the uncertainties of the classifiers.
That is to say, co-training with view independence
can perform well.
How to conduct theoretical evaluation on the
CUCC measure in bilingual bootstrapping is still
an open problem.
</bodyText>
<subsectionHeader confidence="0.998478">
4.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999981">
We conducted experiments to empirically evaluate
the UCC values of collaborative bootstrapping. We
also investigated the relationship between UCC
and accuracy. The results indicate that the theoreti-
cal analysis in Section 4.2 is correct.
In the experiments, we define accuracy as the
percentage of instances whose assigned labels
</bodyText>
<equation confidence="0.997833584269663">
)
UR (h1 \h2)UR(h1\h2
X}|

Y = y)P(Y=y)
U h
( ) = � P x h x x
( {  |( ) ,
=
1 1
( ( {  |( ) , ( ) ,
P x h x h x x
= =
1 2
z
Y y
= )
|
X} |
Y y
=
))P(Y = y)
+ P x h x h x x
( {  |( ) , ( ) ,
=  
1 2
Y y
= )
|
}
y


P
X
( {x  |h2 (x) =, x
( (  |) (  |)
r U h y U h y
h h y 1 2
1 2
y
Y y P Y y
= )) ( )
=
+ P x h x h x
({  |( ) , ( ) , } |
=  
x �
1 2
h2 (x) , x 
+P( {x |h1(x)=,
( (  |) (  |) (
r U h y U h y P
h h y 1 2
1 2
Thus,
( \ ) ({  |( ) , ( ) ,
h h P x h x
= = h x  
x �
1 2 1
−Z r U h y U h y P Y
(  |) (  |) ( =
hh y 1 2
1 2
y
UR
})
Y y
=
}))
)
X
=
U
(h1)
)
y
=Z
y
=�
+P x h x h x x
( {  |( ) , ( ) ,
=  
1 2
Y y P Y y
= )) ( =
X} |
)
</equation>
<bodyText confidence="0.99991">
tainties of the two classifiers are related. If UCC is
high, then there are a large portion of instances
which are uncertain for both of the classifiers. Note
that UCC is a symmetric measure from both classi-
fiers’ perspectives, while UR is an asymmetric
measure from one classifier’s perspective (ei-
therUR(h1\h2)or UR(h2\h1)).
</bodyText>
<subsectionHeader confidence="0.980469">
4.2 Theoretical Analysis
</subsectionHeader>
<bodyText confidence="0.961824166666667">
Theorem 1 reveals the relationship between the
CUCC (UCC) measure and uncertainty reduction.
Assume that the classifier h1 can collaborate
with either of the two classifiers h2 and h&apos;2 . The
two classifiers h2 and 2h have equal conditional
uncertainties. The CUCC values between h1 and
2h are smaller than the CUCC values between h1
and h2 . Then, according to Theorem 1, h1 should
collaborate with 2h , because 2h can help reduce its
uncertainty more, thus, improve its accuracy more.
Theorem 1 Given the two classifier pairs
(h1, h2) and (h1, h2) , if r h h y  r h h  y , y  � and
</bodyText>
<equation confidence="0.955887333333333">
1 2 1 2
U(h2  |y) = U(h2  |y), y  T , then we have
Proof:
</equation>
<bodyText confidence="0.989819">
We can decompose the uncertainty U(h1) of h1 as
follows:
</bodyText>
<equation confidence="0.994028388888889">
y
y
=j: (rh1h2yP( {x  |h1 (x) =, x
X} |
Y y
= )
=
}

X
Y=y
P(X2 =x2 |
,X1 =x1)=P(X2 =x2 |Y=y)
UR(h1\hz)=U(h1)−ZrkyU(h1  |y)U(hz  |y)P(Y=y)
y
Under the conditions, rh1h2y  rh1h2y , y  T and
U (h2  |y) = U (h  |y2 ), y  T , we have
UR(h1 \h2)  UR(h1 \h2) ❑
</equation>
<bodyText confidence="0.962577142857143">
Theorem 1 states that the lower the CUCC val-
ues are, the higher the performances can be
achieved in collaborative bootstrapping.
Definition 6 The two classifiers in co-training
are said to satisfy the view independence assump-
tion (Blum and Mitchell, 1998), if the following
equations hold for any class y.
</bodyText>
<equation confidence="0.542205259259259">
= x2)= P(X1 = x1  |Y = y)
Theorem 2 If the view independence assump-
tion holds, then rh1h2y =1. 0 holds for any class y.
Proof:
According to (Abney, 2002), view independence
implies classifier independence:
x1 |
Y=y
P(X1
,X2
= v ) =P(
h1 =u
Y =y
|
Ph1=u Y=yh2
(
|
)
,
Ph2=v Y=yh1
= u ) =P(
h2 =v
Y =y
I
|
)
 X}|Y=y)
</equation>
<bodyText confidence="0.841738833333333">
= )
 |Y y
agree with their ‘true’ labels. Moreover, when we
refer to UCC, we mean that it is the UCC value on
the test data. We set the value of B in Equation (2)
to 0.8.
</bodyText>
<subsectionHeader confidence="0.931793">
Co-Training for Artificial Data Classification
</subsectionHeader>
<bodyText confidence="0.99454675">
We used the data in (Nigam and Ghani 2000) to
conduct co-training. We utilized the articles from
four newsgroups (see Table 1). Each group had
1000 texts.
</bodyText>
<tableCaption confidence="0.996919">
Table 1: Artificial Data for Co-Trainin
</tableCaption>
<table confidence="0.940442333333333">
Class Feature Set A Feature Set B
Pos comp.os.ms-windows.misc talk.politics.misc
Neg comp.sys.ibm.pc.hardware talk.politics.guns
</table>
<bodyText confidence="0.999674326086956">
By joining together randomly selected texts
from each of the two newsgroups in the first row as
positive instances and joining together randomly
selected texts from each of the two newsgroups in
the second row as negative instances, we created a
two-class classification data with view independ-
ence. The joining was performed under the condi-
tion that the words in the two newsgroups in the
first column came from one vocabulary, while the
words in the newsgroups in the second column
came from the other vocabulary.
We also created a set of classification data
without view independence. To do so, we ran-
domly split all the features of the pseudo texts into
two subsets such that each of the subsets contained
half of the features.
We next applied the co-training algorithm to the
two data sets.
We conducted the same pre-processing in the
two experiments. We discarded the header of each
text, removed stop words from each text, and made
each text have the same length, as did in (Nigam
and Ghani, 2000). We discarded 18 texts from the
entire 2000 texts, because their main contents were
binary codes, encoding errors, etc.
We randomly separated the data and performed
co-training with random feature split and co-
training with natural feature split in five times. The
results obtained (cf., Table 2), thus, were averaged
over five trials. In each trial, we used 3 texts for
each class as labelled training instances, 976 texts
as testing instances, and the remaining 1000 texts
as unlabelled training instances.
From Table 2, we see that the UCC value of the
natural split (in which view independence holds) is
lower than that of the random split (in which view
independence does not hold). That is to say, in
natural split, there are fewer instances which are
uncertain for both of the classifiers. The accuracy
of the natural split is higher than that of the random
split. Theorem 1 states that the lower the CUCC
values are, the higher the performances can be
achieved. The results in Table 2 agree with the
claim of Theorem 1. (Note that it is easier to use
CUCC for theoretical analysis, but it is easier to
use UCC for empirical analysis).
</bodyText>
<tableCaption confidence="0.999696">
Table 2: Results with Artificial Data
</tableCaption>
<table confidence="0.997496666666667">
Feature Accuracy UCC
Natural Split 0.928 1.006
Random Split 0.712 2.399
</table>
<bodyText confidence="0.992849666666667">
We also see that the UCC value of the natural
split (view independence) is about 1.0. The result
agrees with Theorem 2.
</bodyText>
<subsectionHeader confidence="0.916948">
Co-Training for Web Page Classification
</subsectionHeader>
<bodyText confidence="0.9997735">
We used the same data in (Blum and Mitchell,
1998) to perform co-training for web page classifi-
cation.
The web page data consisted of 1051 web pages
collected from the computer science departments
of four universities. The goal of classification was
to determine whether a web page was concerned
with an academic course. 22% of the pages were
actually related to academic courses. The features
for each page were possible to be separated into
two independent parts. One part consisted of words
occurring in the current page and the other part
consisted of words occurring in the anchor texts
pointed to the current page.
We randomly split the data into three subsets:
labelled training set, unlabeled training set, and test
set. The labelled training set had 3 course pages
and 9 non-course pages. The test set had 25% of
the pages. The unlabelled training set had the re-
maining data.
</bodyText>
<tableCaption confidence="0.8481035">
Table 3: Results with Web Page Data and Bilin-
gual Bootstrapping Data
</tableCaption>
<table confidence="0.9349441">
Data Accuracy UCC
Web Page 0.943 1.147
Word Sense Dis- bass 0.925 2.648
ambiguation
drug 0.868 0.986
duty 0.751 0.840
palm 0.924 1.174
plant 0.959 1.226
space 0.878 1.007
tank 0.844 1.177
</table>
<bodyText confidence="0.812379">
We used the data to perform co-training and
web page classification. The setting for the
</bodyText>
<tableCaption confidence="0.944577">
Table 4: Data for Bilingual Bootstrapping
</tableCaption>
<table confidence="0.9974288">
Word Unlabelled instances Seed words Test instances
English Chinese
bass 142 8811 fish / music 200
drug 3053 5398 treatment / smuggler 197
duty 1428 4338 discharge / export 197
palm 366 465 tree / hand 197
plant 7542 24977 industry / life 197
Space 3897 14178 volume / outer 197
tank 417 1400 combat / fuel 199
Total 16845 59567 - 1384
</table>
<bodyText confidence="0.999823625">
experiment was almost the same as that of Nigam
and Ghani’s. One exception was that we did not
conduct feature selection, because we were not
able to follow their method from their paper.
We repeated the experiment five times and
evaluated the results in terms of UCC and accuracy.
Table 3 shows the average accuracy and UCC
value over the five trials.
</bodyText>
<subsectionHeader confidence="0.992208">
Bilingual Bootstrapping
</subsectionHeader>
<bodyText confidence="0.9961743">
We also used the same data in (Li and Li, 2002) to
conduct bilingual bootstrapping and word sense
disambiguation.
The sense disambiguation data were related to
seven ambiguous English words, each having two
Chinese translations. The goal was to determine
the correct Chinese translations of the ambiguous
English words, given English sentences containing
the ambiguous words.
For each word, there were two seed words used
as labelled instances for training, a large number of
unlabeled instances (sentences) in both English and
Chinese for training, and about 200 labelled in-
stances (sentences) for testing. Details on data are
shown in Table 4.
We used the data to perform bilingual boot-
strapping and word sense disambiguation. The set-
ting for the experiment was exactly the same as
that of Li and Li’s. Table 3 shows the accuracy and
UCC value for each word.
From Table 3 we see that both co-training and
bilingual bootstrapping have low UCC values
(around 1.0). With lower UCC (CUCC) values,
higher performances can be achieved, according to
Theorem 1. The accuracies of them are indeed high.
Note that since the features and classes for each
word in bilingual bootstrapping and those for web
page classification in co-training are different, it is
not meaningful to directly compare the UCC val-
ues of them.
</bodyText>
<sectionHeader confidence="0.848742" genericHeader="method">
5 Uncertainty Reduction Algorithm
</sectionHeader>
<subsectionHeader confidence="0.584929">
5.1 Algorithm
</subsectionHeader>
<bodyText confidence="0.73211075">
Input: A set of labeled instances and a set of unla-
belled instances.
Loop while there exist unlabelled instances{
Create classifier h1 using the labeled instances;
</bodyText>
<equation confidence="0.81068725">
Create classifier h2 using the labeled instances;
For each class ( Y = y ){
Pick up by unlabelled instances whose labels
(Y = y ) are most certain for h1 and are most
</equation>
<bodyText confidence="0.980506">
uncertain for h2, label them with h1 and add
them into the set of labeled instances;
Pick up by unlabelled instances whose labels
(Y = y ) are most certain for h2 and are most
uncertain for h1 , label them with h2 and add
them into the set of labeled instances;
}
</bodyText>
<figure confidence="0.9048725">
}
Output: Two classifiers h1 and h2
</figure>
<figureCaption confidence="0.996806">
Figure 2: Uncertainty Reduction Algorithm
</figureCaption>
<bodyText confidence="0.999022545454546">
We propose a new algorithm for collaborative
bootstrapping (both co-training and bilingual boot-
strapping).
In the algorithm, the collaboration between the
classifiers is driven by uncertainty reduction. Spe-
cifically, one classifier always selects the most un-
certain unlabelled instances for it and asks the
other classifier to label. Thus, the two classifiers
can help each other more effectively.
There exists, therefore, a similarity between our
algorithm and active learning. In active learning
the learner always asks the supervisor to label the
most uncertain examples for it, while in our algo-
rithm one classifier always asks the other classifier
to label the most uncertain examples for it.
Figure 2 shows the algorithm. Actually, our
new algorithm is different from the previous algo-
rithm only in one point. Figure 2 highlights the
point in italic fonts. In the previous algorithm,
when a classifier labels unlabeled instances, it la-
bels those instances whose labels are most certain
for the classifier. In contrast, in our new algorithm,
when a classifier labels unlabeled instances, it la-
bels those instances whose labels are most certain
for the classifier, but at the same time most uncer-
tain for the other classifier.
As one implementation, for each class y, h1 first
selects its most certain a y instances, h2 next se-
lects from them its most uncertain b y instances
( ay &gt;_ by ), and finally h1 labels the b y instances
with label y (Collaboration from the opposite di-
rection is performed similarly.). We use this im-
plementation in our experiments described below.
</bodyText>
<subsectionHeader confidence="0.99251">
5.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9998874">
We conducted experiments to test the effectiveness
of our new algorithm. Experimental results indi-
cate that the new algorithm performs better than
the previous algorithm. We refer to them as ‘new’
and ‘old’ respectively.
</bodyText>
<subsectionHeader confidence="0.42799">
Co-Training for Artificial Data Classification
</subsectionHeader>
<tableCaption confidence="0.999648">
Table 5: Accuracies with Artificial Data
</tableCaption>
<table confidence="0.998101">
Feature Accuracy UCC
Old New
Natural Split 0.928 0.924 1.006
Random Split 0.712 0.775 2.399
</table>
<bodyText confidence="0.999887">
We used the artificial data in Section 4.3 and con-
ducted co-training with both the old and new algo-
rithms. Table 5 shows the results.
We see that in co-training the new algorithm
performs as well as the old algorithm when UCC is
low (view independence holds), and the new algo-
rithm performs significantly better than the old al-
gorithm when UCC is high (view independence
does not hold).
</bodyText>
<subsectionHeader confidence="0.77504">
Co-Training for Web Page Classification
</subsectionHeader>
<bodyText confidence="0.999121">
We used the web page classification data in Sec-
tion 4.3 and conducted co-training using both the
old and new algorithms. Table 6 shows the results.
We see that the new algorithm performs as well as
the old algorithm for this data set. Note that here
UCC is low.
</bodyText>
<tableCaption confidence="0.999245">
Table 6: Accuracies with Web Page Data
</tableCaption>
<table confidence="0.996093">
Data Accuracy UCC
Old New
Web Page 0.943 0.943 1.147
</table>
<subsectionHeader confidence="0.995115">
Bilingual Bootstrapping
</subsectionHeader>
<bodyText confidence="0.999074571428571">
We used the word sense disambiguation data in
Section 4.3 and conducted bilingual bootstrapping
using both the old and new algorithms. Table 7
shows the results. We see that the performance of
the new algorithm is slightly better than that of the
old algorithm. Note that here the UCC values are
also low.
</bodyText>
<tableCaption confidence="0.999501">
Table 7: Accuracies with Bilingual Bootstrapping
</tableCaption>
<table confidence="0.499729">
Data
Word Accuracy UCC
Old New
bass 0.925 0.955 2.648
drug 0.868 0.863 0.986
duty 0.751 0. 797 0.840
palm 0.924 0.914 1.174
plant 0.959 0.944 1.226
space 0.878 0.888 1.007
tank 0.844 0.854 1.177
Average 0.878 0.888 -
</table>
<bodyText confidence="0.9998973">
We conclude that for both co-training and bi-
lingual bootstrapping, the new algorithm performs
significantly better than the old algorithm when
UCC is high, and performs as well as the old algo-
rithm when UCC is low. Recall that when UCC is
high, there are more instances which are uncertain
for both classifiers and when UCC is low, there are
fewer instances which are uncertain for both classi-
fiers.
Note that in practice it is difficult to find a
situation in which UCC is completely low (e.g., the
view independence assumption completely holds),
and thus the new algorithm will be more useful
than the old algorithm in practice. To verify this,
we conducted an additional experiment.
Again, since the features and classes for each
word in bilingual bootstrapping and those for web
page classification in co-training are different, it is
not meaningful to directly compare the UCC val-
ues of them.
</bodyText>
<subsectionHeader confidence="0.492715">
Co-Training for News Article Classification
</subsectionHeader>
<bodyText confidence="0.99990744">
In the additional experiment, we used the data
from two newsgroups (comp.graphics and
comp.os.ms-windows.misc) in the dataset of
(Joachims, 1997) to construct co-training and text
classification.
There were 1000 texts for each group. We
viewed the former group as positive class and the
latter group as negative class. We applied the new
and old algorithms. We conducted 20 trials in the
experimentation. In each trial we randomly split
the data into labelled training, unlabeled training
and test data sets. We used 3 texts per class as la-
belled instances for training, 994 texts for testing,
and the remaining 1000 texts as unlabelled in-
stances for training. We performed the same pre-
processing as that in (Nigam and Ghani 2000).
Table 8 shows the results with the 20 trials. The
accuracies are averaged over each 5 trials. From
the table, we see that co-training with the new al-
gorithm significantly outperforms that using the
old algorithm and also ‘single bootstrapping’. Here,
‘single bootstrapping’ refers to the conventional
bootstrapping method in which a single classifier
repeatedly boosts its performances with all the fea-
tures.
</bodyText>
<tableCaption confidence="0.998323">
Table 8: Accuracies with News Data
</tableCaption>
<table confidence="0.74668725">
Average Single Boot- Collaborative Boot-
Accuracy strapping strapping
Old New
Trial 1-5 0.725 0.737 0.768
Trial 6-10 0.708 0.702 0.793
Trial 11-15 0.679 0.647 0.769
Trial 16-20 0.699 0.689 0.767
All 0.703 0.694 0.774
</table>
<bodyText confidence="0.99995125">
The above experimental results indicate that our
new algorithm for collaborative bootstrapping per-
forms significantly better than the old algorithm
when the collaboration is difficult. It performs as
well as the old algorithm when the collaboration is
easy. Therefore, it is better to always employ the
new algorithm.
Another conclusion from the results is that we
can apply our new algorithm into any single boot-
strapping problem. More specifically, we can ran-
domly split the feature set and use our algorithm to
perform co-training with the split subsets.
</bodyText>
<sectionHeader confidence="0.99965" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99982875">
This paper has theoretically and empirically dem-
onstrated that uncertainty reduction is the essence
of collaborative bootstrapping, which includes
both co-training and bilingual bootstrapping.
The paper has conducted a new theoretical
analysis of collaborative bootstrapping, and has
proposed a new algorithm for collaborative boot-
strapping, both on the basis of uncertainty reduc-
tion. Experimental results have verified the
correctness of the analysis and have indicated that
the new algorithm performs better than the existing
algorithms.
</bodyText>
<sectionHeader confidence="0.999189" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999656931818182">
S. Abney, 2002. Bootstrapping. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics.
A. Blum and T. Mitchell, 1998. Combining Labeled
Data and Unlabelled Data with Co-training. In Pro-
ceedings of the 11th Annual Conference on Compu-
tational learning Theory.
M. Collins and Y. Singer, 1999. Unsupervised Models
for Named Entity Classification. In Proceedings of
the 1999 Joint SIGDAT Conference on Empirical
Methods in Natural Language Processing and Very
Large Corpora.
S. Dasgupta, M. Littman and D. McAllester, 2001. PAC
Generalization Bounds for Co-Training. In Proceed-
ings of Neural Information Processing System, 2001.
T. Joachims, 1997. A Probabilistic Analysis of the Roc-
chio Algorithm with TFIDF for Text Categorization.
In Proceedings of the 14th International Conference
on Machine Learning.
D. Lewis and W. Gale, 1994. A Sequential Algorithm
for Training Text Classifiers. In Proceedings of the
17th International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval.
C. Li and H. Li, 2002. Word Translation Disambigua-
tion Using Bilingual Bootstrapping. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics.
I. Muslea, S.Minton, and C. A. Knoblock 2000. Selec-
tive Sampling With Redundant Views. In Proceed-
ings of the Seventeenth National Conference on
Artificial Intelligence.
K. Nigam and R. Ghani, 2000. Analyzing the Effective-
ness and Applicability of Co-Training. In Proceed-
ings of the 9th International Conference on
Information and Knowledge Management.
D. Pierce and C. Cardie 2001. Limitations of Co-
Training for Natural Language Learning from Large
Datasets. In Proceedings of the 2001 Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2001).
D. Yarowsky, 1995. Unsupervised Word Sense Disam-
biguation Rivaling Supervised Methods. In Proceed-
ings of the 33rd Annual Meeting of the Association
for Computational Linguistics.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.708524">
<title confidence="0.999159">Uncertainty Reduction in Collaborative Bootstrapping: Measure and Algorithm</title>
<author confidence="0.998035">Yunbo Cao</author>
<affiliation confidence="0.944509">Microsoft Research Asia 5F Sigma Center,</affiliation>
<address confidence="0.995713">No.49 Zhichun Road, Haidian Beijing, China, 100080</address>
<email confidence="0.998235">i-yucao@microsoft.com</email>
<author confidence="0.998762">Hang Li</author>
<affiliation confidence="0.944639">Microsoft Research Asia 5F Sigma Center,</affiliation>
<address confidence="0.9957055">No.49 Zhichun Road, Haidian Beijing, China, 100080</address>
<email confidence="0.998536">hangli@microsoft.com</email>
<author confidence="0.998063">Li Lian</author>
<affiliation confidence="0.9999115">Computer Science Department Fudan University</affiliation>
<address confidence="0.999404">No. 220 Handan Road Shanghai, China, 200433</address>
<email confidence="0.999845">leelix@yahoo.com</email>
<abstract confidence="0.996263">paper proposes the use of machine learning methods such as co-training and bilingual bootstrapping, which are referred to, in a general term, as ‘collaborative bootstrapping’. The paper indicates that uncertainty reduction is an important factor for enhancing the performance of collaborative bootstrapping. It proposes a new measure for representing the degree of uncertainty correlation of the two classifiers in collaborative bootstrapping and uses the measure in analysis of collaborative bootstrapping. Furthermore, it proposes a new algorithm of collaborative bootstrapping on the basis of uncertainty reduction. Experimental results have verified the correctness of the analysis and have demonstrated the significance of the new algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<date>2002</date>
<booktitle>Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2046" citStr="Abney (2002)" startWordPosition="295" endWordPosition="296">, 2002). Collaborative bootstrapping begins with a small number of labelled data and a large number of unlabelled data. It trains two (types of) classifiers from the labelled data, uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class structures. Dasgupta et al (2001) and Abney (2002) conducted theoretical analyses on the performance (generalization error) of co-training. Their analyses, however, cannot be directly used in studies of cotraining in (Nigam &amp; Ghani, 2000) and bilingual bootstrapping. In this paper, we propose the use of uncertainty reduction in the study of collaborative bootstrapping (both co-training and bilingual bootstrapping). We point out that uncertainty reduction is an important factor for enhancing the performances of the classifiers in collaborative bootstrapping. Here, the uncertainty of a classifier is defined as the portion of instances on which </context>
<context position="4969" citStr="Abney (2002)" startWordPosition="735" endWordPosition="736">guation method proposed in Yarowsky (1995) can also be viewed as a kind of co-training. Since the assumption of view independence cannot always be met in practice, Collins and Singer (1998) proposed a co-training algorithm based on ‘agreement’ between the classifiers. As for theoretical analysis, Dasgupta et al. (2001) gave a bound on the generalization error of co-training within the framework of PAC learning. The generalization error is a function of ‘disagreement’ between the two classifiers. Dasgupta et al’s result is based on the view independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s result by relaxing the view independence assumption with a new constraint. He also proposed a new co-training algorithm on the basis of the constraint. Nigam and Ghani (2000) empirically demonstrated that bootstrapping with a random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without a feature split (i.e., bootstrapping with a single classifier). For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). Li and Li (2002) proposed an algorithm for word sense disambiguati</context>
<context position="14665" citStr="Abney, 2002" startWordPosition="2683" endWordPosition="2684">U(h1)−ZrkyU(h1 |y)U(hz |y)P(Y=y) y Under the conditions, rh1h2y  rh1h2y , y  T and U (h2 |y) = U (h |y2 ), y  T , we have UR(h1 \h2)  UR(h1 \h2) ❑ Theorem 1 states that the lower the CUCC values are, the higher the performances can be achieved in collaborative bootstrapping. Definition 6 The two classifiers in co-training are said to satisfy the view independence assumption (Blum and Mitchell, 1998), if the following equations hold for any class y. = x2)= P(X1 = x1 |Y = y) Theorem 2 If the view independence assumption holds, then rh1h2y =1. 0 holds for any class y. Proof: According to (Abney, 2002), view independence implies classifier independence: x1 | Y=y P(X1 ,X2 = v ) =P( h1 =u Y =y | Ph1=u Y=yh2 ( | ) , Ph2=v Y=yh1 = u ) =P( h2 =v Y =y I | )  X}|Y=y) = ) |Y y agree with their ‘true’ labels. Moreover, when we refer to UCC, we mean that it is the UCC value on the test data. We set the value of B in Equation (2) to 0.8. Co-Training for Artificial Data Classification We used the data in (Nigam and Ghani 2000) to conduct co-training. We utilized the articles from four newsgroups (see Table 1). Each group had 1000 texts. Table 1: Artificial Data for Co-Trainin Class Feature Set A Featu</context>
</contexts>
<marker>Abney, 2002</marker>
<rawString>S. Abney, 2002. Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining Labeled Data and Unlabelled Data with Co-training.</title>
<date>1998</date>
<booktitle>In Proceedings of the 11th Annual Conference on Computational learning Theory.</booktitle>
<contexts>
<context position="1345" citStr="Blum and Mitchell, 1998" startWordPosition="184" endWordPosition="187">r enhancing the performance of collaborative bootstrapping. It proposes a new measure for representing the degree of uncertainty correlation of the two classifiers in collaborative bootstrapping and uses the measure in analysis of collaborative bootstrapping. Furthermore, it proposes a new algorithm of collaborative bootstrapping on the basis of uncertainty reduction. Experimental results have verified the correctness of the analysis and have demonstrated the significance of the new algorithm. 1 Introduction We consider here the problem of collaborative bootstrapping. It includes co-training (Blum and Mitchell, 1998; Collins and Singer, 1998; Nigam and Ghani, 2000) and bilingual bootstrapping (Li and Li, 2002). Collaborative bootstrapping begins with a small number of labelled data and a large number of unlabelled data. It trains two (types of) classifiers from the labelled data, uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual boots</context>
<context position="3667" citStr="Blum and Mitchell (1998)" startWordPosition="532" endWordPosition="535">strapping and refer to it as ‘uncertainty correlation coefficient’ (UCC). We use UCC for analysis of collaborative bootstrapping. We also propose a new algorithm to improve the performance of existing collaborative bootstrapping algorithms. In the algorithm, one classifier always asks the other classifier to label the most uncertain instances for it. Experimental results indicate that our theoretical analysis is correct. Experimental results also indicate that our new algorithm outperforms existing algorithms. 2 Related Work 2.1 Co-Training and Bilingual Bootstrapping Co-training, proposed by Blum and Mitchell (1998), conducts two bootstrapping processes in parallel, and makes them collaborate with each other. More specifically, it repeatedly trains two classifiers from the labelled data, labels some unlabelled data with the two classifiers, and exchanges the newly labelled data between the two classifiers. Blum and Mitchell assume that the two classifiers are based on two subsets of the entire feature set and the two subsets are conditionally independent with one another given a class. This assumption is called ‘view independence’. In their algorithm of co-training, one classifier always asks the other c</context>
<context position="14462" citStr="Blum and Mitchell, 1998" startWordPosition="2641" endWordPosition="2644">2 U(h2 |y) = U(h2 |y), y  T , then we have Proof: We can decompose the uncertainty U(h1) of h1 as follows: y y =j: (rh1h2yP( {x |h1 (x) =, x X} | Y y = ) = }  X Y=y P(X2 =x2 | ,X1 =x1)=P(X2 =x2 |Y=y) UR(h1\hz)=U(h1)−ZrkyU(h1 |y)U(hz |y)P(Y=y) y Under the conditions, rh1h2y  rh1h2y , y  T and U (h2 |y) = U (h |y2 ), y  T , we have UR(h1 \h2)  UR(h1 \h2) ❑ Theorem 1 states that the lower the CUCC values are, the higher the performances can be achieved in collaborative bootstrapping. Definition 6 The two classifiers in co-training are said to satisfy the view independence assumption (Blum and Mitchell, 1998), if the following equations hold for any class y. = x2)= P(X1 = x1 |Y = y) Theorem 2 If the view independence assumption holds, then rh1h2y =1. 0 holds for any class y. Proof: According to (Abney, 2002), view independence implies classifier independence: x1 | Y=y P(X1 ,X2 = v ) =P( h1 =u Y =y | Ph1=u Y=yh2 ( | ) , Ph2=v Y=yh1 = u ) =P( h2 =v Y =y I | )  X}|Y=y) = ) |Y y agree with their ‘true’ labels. Moreover, when we refer to UCC, we mean that it is the UCC value on the test data. We set the value of B in Equation (2) to 0.8. Co-Training for Artificial Data Classification We used the data </context>
<context position="17836" citStr="Blum and Mitchell, 1998" startWordPosition="3234" endWordPosition="3237">r than that of the random split. Theorem 1 states that the lower the CUCC values are, the higher the performances can be achieved. The results in Table 2 agree with the claim of Theorem 1. (Note that it is easier to use CUCC for theoretical analysis, but it is easier to use UCC for empirical analysis). Table 2: Results with Artificial Data Feature Accuracy UCC Natural Split 0.928 1.006 Random Split 0.712 2.399 We also see that the UCC value of the natural split (view independence) is about 1.0. The result agrees with Theorem 2. Co-Training for Web Page Classification We used the same data in (Blum and Mitchell, 1998) to perform co-training for web page classification. The web page data consisted of 1051 web pages collected from the computer science departments of four universities. The goal of classification was to determine whether a web page was concerned with an academic course. 22% of the pages were actually related to academic courses. The features for each page were possible to be separated into two independent parts. One part consisted of words occurring in the current page and the other part consisted of words occurring in the anchor texts pointed to the current page. We randomly split the data in</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>A. Blum and T. Mitchell, 1998. Combining Labeled Data and Unlabelled Data with Co-training. In Proceedings of the 11th Annual Conference on Computational learning Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Y Singer</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<marker>Collins, Singer, 1999</marker>
<rawString>M. Collins and Y. Singer, 1999. Unsupervised Models for Named Entity Classification. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>M Littman</author>
<author>D McAllester</author>
</authors>
<title>PAC Generalization Bounds for Co-Training.</title>
<date>2001</date>
<booktitle>In Proceedings of Neural Information Processing System,</booktitle>
<contexts>
<context position="2029" citStr="Dasgupta et al (2001)" startWordPosition="290" endWordPosition="293">l bootstrapping (Li and Li, 2002). Collaborative bootstrapping begins with a small number of labelled data and a large number of unlabelled data. It trains two (types of) classifiers from the labelled data, uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class structures. Dasgupta et al (2001) and Abney (2002) conducted theoretical analyses on the performance (generalization error) of co-training. Their analyses, however, cannot be directly used in studies of cotraining in (Nigam &amp; Ghani, 2000) and bilingual bootstrapping. In this paper, we propose the use of uncertainty reduction in the study of collaborative bootstrapping (both co-training and bilingual bootstrapping). We point out that uncertainty reduction is an important factor for enhancing the performances of the classifiers in collaborative bootstrapping. Here, the uncertainty of a classifier is defined as the portion of in</context>
<context position="4677" citStr="Dasgupta et al. (2001)" startWordPosition="687" endWordPosition="690">ature set and the two subsets are conditionally independent with one another given a class. This assumption is called ‘view independence’. In their algorithm of co-training, one classifier always asks the other classifier to label the most certain instances for the collaborator. The word sense disambiguation method proposed in Yarowsky (1995) can also be viewed as a kind of co-training. Since the assumption of view independence cannot always be met in practice, Collins and Singer (1998) proposed a co-training algorithm based on ‘agreement’ between the classifiers. As for theoretical analysis, Dasgupta et al. (2001) gave a bound on the generalization error of co-training within the framework of PAC learning. The generalization error is a function of ‘disagreement’ between the two classifiers. Dasgupta et al’s result is based on the view independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s result by relaxing the view independence assumption with a new constraint. He also proposed a new co-training algorithm on the basis of the constraint. Nigam and Ghani (2000) empirically demonstrated that bootstrapping with a random feature split (i.e. co-training), even violating </context>
</contexts>
<marker>Dasgupta, Littman, McAllester, 2001</marker>
<rawString>S. Dasgupta, M. Littman and D. McAllester, 2001. PAC Generalization Bounds for Co-Training. In Proceedings of Neural Information Processing System, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of the 14th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="26273" citStr="Joachims, 1997" startWordPosition="4650" endWordPosition="4651">s completely low (e.g., the view independence assumption completely holds), and thus the new algorithm will be more useful than the old algorithm in practice. To verify this, we conducted an additional experiment. Again, since the features and classes for each word in bilingual bootstrapping and those for web page classification in co-training are different, it is not meaningful to directly compare the UCC values of them. Co-Training for News Article Classification In the additional experiment, we used the data from two newsgroups (comp.graphics and comp.os.ms-windows.misc) in the dataset of (Joachims, 1997) to construct co-training and text classification. There were 1000 texts for each group. We viewed the former group as positive class and the latter group as negative class. We applied the new and old algorithms. We conducted 20 trials in the experimentation. In each trial we randomly split the data into labelled training, unlabeled training and test data sets. We used 3 texts per class as labelled instances for training, 994 texts for testing, and the remaining 1000 texts as unlabelled instances for training. We performed the same preprocessing as that in (Nigam and Ghani 2000). Table 8 shows</context>
</contexts>
<marker>Joachims, 1997</marker>
<rawString>T. Joachims, 1997. A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization. In Proceedings of the 14th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
<author>W Gale</author>
</authors>
<title>A Sequential Algorithm for Training Text Classifiers.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th International ACM-SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="6652" citStr="Lewis and Gale, 1994" startWordPosition="987" endWordPosition="990">ping, Dasgupta et al and Abney’s analyses cannot be directly used on them. 2.2 Active Learning Active leaning is a learning paradigm. Instead of passively using all the given labelled instances for training as in supervised learning, active learning repeatedly asks a supervisor to label what it considers as the most critical instances and performs training with the labelled instances. Thus, active learning can eventually create a reliable classifier with fewer labelled instances than supervised learning. One of the strategies to select critical instances is called ‘uncertain reduction’ (e.g., Lewis and Gale, 1994). Under the strategy, the most uncertain instances to the current classifier are selected and asked to be labelled by a supervisor. The notion of uncertainty reduction was not used for bootstrapping, to the best of our knowledge. 3 Collaborative Bootstrapping and Uncertainty Reduction We consider the collaborative bootstrapping problem. Let X denote a set of instances (feature vectors) and letT denote a set of labels (classes). Given a number of labelled instances, we are to construct a function h : X —&gt; T . We also refer to it as a classifier. In collaborative bootstrapping, we consider the u</context>
</contexts>
<marker>Lewis, Gale, 1994</marker>
<rawString>D. Lewis and W. Gale, 1994. A Sequential Algorithm for Training Text Classifiers. In Proceedings of the 17th International ACM-SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Li</author>
<author>H Li</author>
</authors>
<title>Word Translation Disambiguation Using Bilingual Bootstrapping.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1441" citStr="Li and Li, 2002" startWordPosition="199" endWordPosition="202">the degree of uncertainty correlation of the two classifiers in collaborative bootstrapping and uses the measure in analysis of collaborative bootstrapping. Furthermore, it proposes a new algorithm of collaborative bootstrapping on the basis of uncertainty reduction. Experimental results have verified the correctness of the analysis and have demonstrated the significance of the new algorithm. 1 Introduction We consider here the problem of collaborative bootstrapping. It includes co-training (Blum and Mitchell, 1998; Collins and Singer, 1998; Nigam and Ghani, 2000) and bilingual bootstrapping (Li and Li, 2002). Collaborative bootstrapping begins with a small number of labelled data and a large number of unlabelled data. It trains two (types of) classifiers from the labelled data, uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class structures. Dasgupta et al (2001) and Abney (</context>
<context position="5519" citStr="Li and Li (2002)" startWordPosition="819" endWordPosition="822">independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s result by relaxing the view independence assumption with a new constraint. He also proposed a new co-training algorithm on the basis of the constraint. Nigam and Ghani (2000) empirically demonstrated that bootstrapping with a random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without a feature split (i.e., bootstrapping with a single classifier). For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). Li and Li (2002) proposed an algorithm for word sense disambiguation in translation between two languages, which they called ‘bilingual bootstrapping’. Instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes. Specifically, it assumes that the classes of the classifiers in bootstrapping do not overlap. Thus, bilingual bootstrapping is different from co-training. Because the notion of agreement is not involved in bootstrapping in (Nigam &amp; Ghani 2000) and bilingual bootstrapping, Dasgupta et al and Abney’s analyses cannot be directly used on them. 2.2 Active Le</context>
<context position="8481" citStr="Li and Li 2002" startWordPosition="1311" endWordPosition="1314">umber of classifiers are created in the two languages. The classes of the classifiers correspond to word senses and do not overlap, as shown in Figure 1. For example, the classifier h1( x |E1) in language 1 takes sense 2 and sense 3 as classes. The classifier h2 ( x |C1 ) in language 2 takes sense 1 and sense 2 as classes, and the classifier h2 ( x |C2 ) takes sense 3 and sense 4 as classes. Here we use E1 , C1 , C 2 to denote different words in the two languages. Collaborative bootstrapping is performed between the classifiers h1(*) in language 1 and the classifiers h2(*) in language 2. (See Li and Li 2002 for details). Figure 1: Bilingual Bootstrapping For the classifier h1 ( x |E1 ) in language 1, we assume that there is a pseudo classifier h2 ( x |C1 , C2 ) in language 2, which functions as a collaborator of h1 ( x |E1 ) . The pseudo classifier h2( x |C1, C2) is based on h2( x |C1) and h2 ( x |C2 ), and takes sense 2 and sense 3 as classes. Formally, the two collaborating classifiers (one real classifier and one pseudo classifier) in bilingual bootstrapping are respectively represented as h1(x |E) and h2(x |C), xe X. Next, we introduce the notion of uncertainty reduction in collaborative boo</context>
<context position="19819" citStr="Li and Li, 2002" startWordPosition="3577" endWordPosition="3580">1428 4338 discharge / export 197 palm 366 465 tree / hand 197 plant 7542 24977 industry / life 197 Space 3897 14178 volume / outer 197 tank 417 1400 combat / fuel 199 Total 16845 59567 - 1384 experiment was almost the same as that of Nigam and Ghani’s. One exception was that we did not conduct feature selection, because we were not able to follow their method from their paper. We repeated the experiment five times and evaluated the results in terms of UCC and accuracy. Table 3 shows the average accuracy and UCC value over the five trials. Bilingual Bootstrapping We also used the same data in (Li and Li, 2002) to conduct bilingual bootstrapping and word sense disambiguation. The sense disambiguation data were related to seven ambiguous English words, each having two Chinese translations. The goal was to determine the correct Chinese translations of the ambiguous English words, given English sentences containing the ambiguous words. For each word, there were two seed words used as labelled instances for training, a large number of unlabeled instances (sentences) in both English and Chinese for training, and about 200 labelled instances (sentences) for testing. Details on data are shown in Table 4. W</context>
</contexts>
<marker>Li, Li, 2002</marker>
<rawString>C. Li and H. Li, 2002. Word Translation Disambiguation Using Bilingual Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Muslea</author>
<author>S Minton</author>
<author>C A Knoblock</author>
</authors>
<title>Selective Sampling With Redundant Views.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth National Conference on Artificial Intelligence.</booktitle>
<marker>Muslea, Minton, Knoblock, 2000</marker>
<rawString>I. Muslea, S.Minton, and C. A. Knoblock 2000. Selective Sampling With Redundant Views. In Proceedings of the Seventeenth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>R Ghani</author>
</authors>
<title>Analyzing the Effectiveness and Applicability of Co-Training.</title>
<date>2000</date>
<booktitle>In Proceedings of the 9th International Conference on Information and Knowledge Management.</booktitle>
<contexts>
<context position="1395" citStr="Nigam and Ghani, 2000" startWordPosition="192" endWordPosition="195">rapping. It proposes a new measure for representing the degree of uncertainty correlation of the two classifiers in collaborative bootstrapping and uses the measure in analysis of collaborative bootstrapping. Furthermore, it proposes a new algorithm of collaborative bootstrapping on the basis of uncertainty reduction. Experimental results have verified the correctness of the analysis and have demonstrated the significance of the new algorithm. 1 Introduction We consider here the problem of collaborative bootstrapping. It includes co-training (Blum and Mitchell, 1998; Collins and Singer, 1998; Nigam and Ghani, 2000) and bilingual bootstrapping (Li and Li, 2002). Collaborative bootstrapping begins with a small number of labelled data and a large number of unlabelled data. It trains two (types of) classifiers from the labelled data, uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class</context>
<context position="5169" citStr="Nigam and Ghani (2000)" startWordPosition="765" endWordPosition="768">proposed a co-training algorithm based on ‘agreement’ between the classifiers. As for theoretical analysis, Dasgupta et al. (2001) gave a bound on the generalization error of co-training within the framework of PAC learning. The generalization error is a function of ‘disagreement’ between the two classifiers. Dasgupta et al’s result is based on the view independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s result by relaxing the view independence assumption with a new constraint. He also proposed a new co-training algorithm on the basis of the constraint. Nigam and Ghani (2000) empirically demonstrated that bootstrapping with a random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without a feature split (i.e., bootstrapping with a single classifier). For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). Li and Li (2002) proposed an algorithm for word sense disambiguation in translation between two languages, which they called ‘bilingual bootstrapping’. Instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes. Speci</context>
<context position="15087" citStr="Nigam and Ghani 2000" startWordPosition="2773" endWordPosition="2776"> the following equations hold for any class y. = x2)= P(X1 = x1 |Y = y) Theorem 2 If the view independence assumption holds, then rh1h2y =1. 0 holds for any class y. Proof: According to (Abney, 2002), view independence implies classifier independence: x1 | Y=y P(X1 ,X2 = v ) =P( h1 =u Y =y | Ph1=u Y=yh2 ( | ) , Ph2=v Y=yh1 = u ) =P( h2 =v Y =y I | )  X}|Y=y) = ) |Y y agree with their ‘true’ labels. Moreover, when we refer to UCC, we mean that it is the UCC value on the test data. We set the value of B in Equation (2) to 0.8. Co-Training for Artificial Data Classification We used the data in (Nigam and Ghani 2000) to conduct co-training. We utilized the articles from four newsgroups (see Table 1). Each group had 1000 texts. Table 1: Artificial Data for Co-Trainin Class Feature Set A Feature Set B Pos comp.os.ms-windows.misc talk.politics.misc Neg comp.sys.ibm.pc.hardware talk.politics.guns By joining together randomly selected texts from each of the two newsgroups in the first row as positive instances and joining together randomly selected texts from each of the two newsgroups in the second row as negative instances, we created a two-class classification data with view independence. The joining was pe</context>
<context position="16373" citStr="Nigam and Ghani, 2000" startWordPosition="2983" endWordPosition="2986"> in the first column came from one vocabulary, while the words in the newsgroups in the second column came from the other vocabulary. We also created a set of classification data without view independence. To do so, we randomly split all the features of the pseudo texts into two subsets such that each of the subsets contained half of the features. We next applied the co-training algorithm to the two data sets. We conducted the same pre-processing in the two experiments. We discarded the header of each text, removed stop words from each text, and made each text have the same length, as did in (Nigam and Ghani, 2000). We discarded 18 texts from the entire 2000 texts, because their main contents were binary codes, encoding errors, etc. We randomly separated the data and performed co-training with random feature split and cotraining with natural feature split in five times. The results obtained (cf., Table 2), thus, were averaged over five trials. In each trial, we used 3 texts for each class as labelled training instances, 976 texts as testing instances, and the remaining 1000 texts as unlabelled training instances. From Table 2, we see that the UCC value of the natural split (in which view independence ho</context>
<context position="26858" citStr="Nigam and Ghani 2000" startWordPosition="4747" endWordPosition="4750">) in the dataset of (Joachims, 1997) to construct co-training and text classification. There were 1000 texts for each group. We viewed the former group as positive class and the latter group as negative class. We applied the new and old algorithms. We conducted 20 trials in the experimentation. In each trial we randomly split the data into labelled training, unlabeled training and test data sets. We used 3 texts per class as labelled instances for training, 994 texts for testing, and the remaining 1000 texts as unlabelled instances for training. We performed the same preprocessing as that in (Nigam and Ghani 2000). Table 8 shows the results with the 20 trials. The accuracies are averaged over each 5 trials. From the table, we see that co-training with the new algorithm significantly outperforms that using the old algorithm and also ‘single bootstrapping’. Here, ‘single bootstrapping’ refers to the conventional bootstrapping method in which a single classifier repeatedly boosts its performances with all the features. Table 8: Accuracies with News Data Average Single Boot- Collaborative BootAccuracy strapping strapping Old New Trial 1-5 0.725 0.737 0.768 Trial 6-10 0.708 0.702 0.793 Trial 11-15 0.679 0.6</context>
<context position="2234" citStr="Nigam &amp; Ghani, 2000" startWordPosition="321" endWordPosition="324"> uses the two classifiers to label some unlabelled data, trains again two new classifiers from all the labelled data, and repeats the above process. During the process, the two classifiers help each other by exchanging the labelled data. In co-training, the two classifiers have different feature structures, and in bilingual bootstrapping, the two classifiers have different class structures. Dasgupta et al (2001) and Abney (2002) conducted theoretical analyses on the performance (generalization error) of co-training. Their analyses, however, cannot be directly used in studies of cotraining in (Nigam &amp; Ghani, 2000) and bilingual bootstrapping. In this paper, we propose the use of uncertainty reduction in the study of collaborative bootstrapping (both co-training and bilingual bootstrapping). We point out that uncertainty reduction is an important factor for enhancing the performances of the classifiers in collaborative bootstrapping. Here, the uncertainty of a classifier is defined as the portion of instances on which it cannot make classification decisions. Exchanging labelled data in bootstrapping can help reduce the uncertainties of classifiers. Uncertainty reduction was previously used in active lea</context>
<context position="6007" citStr="Nigam &amp; Ghani 2000" startWordPosition="890" endWordPosition="893">trapping with a single classifier). For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). Li and Li (2002) proposed an algorithm for word sense disambiguation in translation between two languages, which they called ‘bilingual bootstrapping’. Instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes. Specifically, it assumes that the classes of the classifiers in bootstrapping do not overlap. Thus, bilingual bootstrapping is different from co-training. Because the notion of agreement is not involved in bootstrapping in (Nigam &amp; Ghani 2000) and bilingual bootstrapping, Dasgupta et al and Abney’s analyses cannot be directly used on them. 2.2 Active Learning Active leaning is a learning paradigm. Instead of passively using all the given labelled instances for training as in supervised learning, active learning repeatedly asks a supervisor to label what it considers as the most critical instances and performs training with the labelled instances. Thus, active learning can eventually create a reliable classifier with fewer labelled instances than supervised learning. One of the strategies to select critical instances is called ‘unce</context>
</contexts>
<marker>Nigam, Ghani, 2000</marker>
<rawString>K. Nigam and R. Ghani, 2000. Analyzing the Effectiveness and Applicability of Co-Training. In Proceedings of the 9th International Conference on Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pierce</author>
<author>C Cardie</author>
</authors>
<title>Limitations of CoTraining for Natural Language Learning from Large Datasets.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP-2001).</booktitle>
<contexts>
<context position="5501" citStr="Pierce and Cardie 2001" startWordPosition="815" endWordPosition="818">ult is based on the view independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s result by relaxing the view independence assumption with a new constraint. He also proposed a new co-training algorithm on the basis of the constraint. Nigam and Ghani (2000) empirically demonstrated that bootstrapping with a random feature split (i.e. co-training), even violating the view independence assumption, can still work better than bootstrapping without a feature split (i.e., bootstrapping with a single classifier). For other work on co-training, see (Muslea et al 200; Pierce and Cardie 2001). Li and Li (2002) proposed an algorithm for word sense disambiguation in translation between two languages, which they called ‘bilingual bootstrapping’. Instead of making an assumption on the features, bilingual bootstrapping makes an assumption on the classes. Specifically, it assumes that the classes of the classifiers in bootstrapping do not overlap. Thus, bilingual bootstrapping is different from co-training. Because the notion of agreement is not involved in bootstrapping in (Nigam &amp; Ghani 2000) and bilingual bootstrapping, Dasgupta et al and Abney’s analyses cannot be directly used on t</context>
</contexts>
<marker>Pierce, Cardie, 2001</marker>
<rawString>D. Pierce and C. Cardie 2001. Limitations of CoTraining for Natural Language Learning from Large Datasets. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP-2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4399" citStr="Yarowsky (1995)" startWordPosition="646" endWordPosition="647"> repeatedly trains two classifiers from the labelled data, labels some unlabelled data with the two classifiers, and exchanges the newly labelled data between the two classifiers. Blum and Mitchell assume that the two classifiers are based on two subsets of the entire feature set and the two subsets are conditionally independent with one another given a class. This assumption is called ‘view independence’. In their algorithm of co-training, one classifier always asks the other classifier to label the most certain instances for the collaborator. The word sense disambiguation method proposed in Yarowsky (1995) can also be viewed as a kind of co-training. Since the assumption of view independence cannot always be met in practice, Collins and Singer (1998) proposed a co-training algorithm based on ‘agreement’ between the classifiers. As for theoretical analysis, Dasgupta et al. (2001) gave a bound on the generalization error of co-training within the framework of PAC learning. The generalization error is a function of ‘disagreement’ between the two classifiers. Dasgupta et al’s result is based on the view independence assumption, which is strict in practice. Abney (2002) refined Dasgupta et al’s resu</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky, 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>