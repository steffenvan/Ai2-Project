<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.250346">
<title confidence="0.996447">
CarSim: An Automatic 3D Text-to-Scene Conversion System Applied to
Road Accident Reports
</title>
<author confidence="0.928786">
Ola Akerbergt Hans Svenssont Bastian Schulz.t. Pierre Nuguest
</author>
<affiliation confidence="0.9330785">
tLund University, LTH tTechnische Universitat Hamburg-Harburg
Department of Computer science Schwarzenbergstrae 95
</affiliation>
<address confidence="0.943395">
Box 118, S-221 00 Lund, Sweden D-21071 Hamburg, Germany
</address>
<email confidence="0.8372785">
le94oa, e94hsvl@efd.lth.se b.schulz@tuhh.de
Pierre.Nugues@cs.lth.se
</email>
<sectionHeader confidence="0.998128" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9993994375">
CarSim is an automatic text-to-scene
conversion system. It analyzes written
descriptions of car accidents and synthe-
sizes 3D scenes of them. The conver-
sion process consists of two stages. An
information extraction module creates a
tabular description of the accident and a
visual simulator generates and animates
the scene.
We implemented a first version of Car-
Sim that considered a corpus of texts
in French. We redesigned its linguis-
tic modules and its interface and we
applied it to texts in English from the
National Transportation Safety Board in
the United States.
</bodyText>
<sectionHeader confidence="0.998326" genericHeader="keywords">
1 Text-to-Scene Conversion
</sectionHeader>
<bodyText confidence="0.999861956521739">
Text-to-scene conversion consists in creating a 2D
or 3D geometric description from a natural lan-
guage text. The resulting scene can be static or
animated. To be converted, the text must be ap-
propriate in some sense, that is, contains explicit
descriptions of objects and events for which we
can form mental images.
Animated 3D graphics have some advantages
for the visualization of information. They can re-
produce a real scene more accurately and render a
sequence of events.
Automatic text-to-scene conversion has been in-
vestigated in a few projects. NALIG (Adomi et
al., 1984; Di Manzo et al., 1986) is an early sys-
tem that was designed to recreate static 2D scenes
from simple phrases in Italian. WordsEye (Coyne
and Sproat, 2001) is a recent and ambitious exam-
ple. It features a large database of 3D objects that
can be animated. CogViSys (Nagel, 2001; Arens
et al., 2002) is aimed a visualizing descriptions of
simple car maneuvers at crossroads.
All these systems use apparently invented nar-
ratives.
</bodyText>
<sectionHeader confidence="0.991332" genericHeader="introduction">
2 CarSim
</sectionHeader>
<bodyText confidence="0.999855666666667">
CarSim (Egges et al., 2001; Dupuy et al., 2001)
is a program that analyzes texts describing car ac-
cidents and visualizes them in a 3D environment.
The CarSim architecture consists of two modules.
A first module carries out a linguistic analysis of
the accident and creates a template — a tabular rep-
resentation — of the text. A second module creates
the 3D scene from the template. The template has
been designed so that it contains the information
necessary to reproduce and animate the accidents
(Figure 1).
A first version of CarSim was designed to pro-
cess texts in French. We used a corpus of 87 car
accident reports written in French and provided by
the MAIF insurance company. Texts are short nar-
ratives written by one of the drivers after the ac-
cident. They correspond to relatively simple acci-
dents: There were no casualties and both drivers
agreed on what happened. In spite of this, many
reports are pretty complex and sometimes difficult
to understand.
</bodyText>
<page confidence="0.991581">
191
</page>
<figure confidence="0.740239833333333">
Infi
WordNet
rr ran on Extraction lnterurdiate XML ■ Graphical Module - Java3D Display
Module Template
Link
Cirammar
</figure>
<figureCaption confidence="0.999909">
Figure 1: The CarSim architecture.
</figureCaption>
<bodyText confidence="0.999985555555555">
We describe here a new system that accepts re-
ports in English. We developed and tested it using
twenty road accident summaries from the National
Transportation Safety Board (www.ntsb.gov), an
accident research organization of the United States
government. The accidents described by the
NTSB are more complex or spectacular than the
ones we analyzed in French. To visualize them,
we had to add new vehicle actions like &amp;quot;overturn.&amp;quot;
</bodyText>
<sectionHeader confidence="0.945574" genericHeader="method">
3 An Example of Report
</sectionHeader>
<bodyText confidence="0.99934717948718">
The next text is an example of summaries from the
NTSB (HAR-00-02):
About 10:30 a.m. on October 21,
1999, in Schoharie County, New York,
a Kinnicutt Bus Company school bus
was transporting 44 students, 5 to 9
years old, and 8 adults on an Albany
City School No. 18 field trip. The bus
was traveling north on State Route 30A
as it approached the intersection with
State Route 7, which is about 1.5 miles
east of Central Bridge, New York. Con-
currently, an MVF Construction Com-
pany dump truck, towing a utility trailer,
was traveling west on State Route 7.
The dump truck was occupied by the
driver and a passenger. As the bus ap-
proached the intersection, it failed to
stop as required and was struck by the
dump truck. Seven bus passengers sus-
tained serious injuries, 28 bus passen-
gers and the truckdriver received minor
injuries. Thirteen bus passengers, the
busdriver, and the truck passenger were
uninjured.
This text is a good example of the possible con-
tent of the NTSB summaries. It describes a bus
driving on State Route 30A and a truck on State
Route 7 and their accident in an intersection. Al-
though the interaction is visually simple, the text
is rather difficult to understand because of the pro-
fusion of details.
We believe that the conversion of a text to a
scene can help understand its information content
as it can make it more concrete to a user. Although
we don&apos;t claim that a sequence of images can re-
place a text, we are sure that it can complement
it. And automatic conversion techniques can make
this process faster and easier.
</bodyText>
<sectionHeader confidence="0.992409" genericHeader="method">
4 The Language Processing Module
</sectionHeader>
<bodyText confidence="0.99997775">
The CarSim language processing module uses in-
formation extraction techniques to fill a template
from the accident narrative. The information ex-
tracted from the text is mapped onto a predefined
XML structure that consists of three parts: the
static objects, the dynamic objects, and the colli-
sion objects. The static objects are the non-moving
objects such as trees, obstacles, and road signs.
The dynamic objects are moving objects, the ve-
hicles. Examples of dynamic objects are cars and
trucks. The collision object structure describes the
interaction between dynamic objects and/or static
objects.
We used two available linguistic resources to
analyze the texts: the WordNet lexical database
(Fellbaum, 1998) and the Link Grammar depen-
</bodyText>
<page confidence="0.992747">
192
</page>
<bodyText confidence="0.999604">
dency parser (Sleator and Temperley, 1993). The
strategy to determine the accidents and the actors
is to find the collision verbs. CarSim uses reg-
ular expressions to search verb patterns in texts,
Then, CarSim extracts the dependents of the verb.
It evaluates the grammatical function of the word
groups, examines words, classifies them using the
WordNet hierarchy, and fills the XML template
(Akerberg and Svensson, 2002). Table 1 shows
the template corresponding to text HAR-00-02.
</bodyText>
<tableCaption confidence="0.9796915">
Table 1: The template representing the text HAR-
00-02 from the NTSB.
</tableCaption>
<figure confidence="0.991022965517241">
&lt;?xmi version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?›
&lt;!DOCTYPE accident SYSTEM &amp;quot;accident.dtd&amp;quot;›
&lt;accident&gt;
&lt;staticObjects&gt;
&lt;road kind=&amp;quot;crossroads&amp;quot;/&gt;
&lt;/staticObjects&gt;
&lt;dynamicObjects&gt;
&lt;vehicle id=&amp;quot;busl&amp;quot; kind=&amp;quot;truck&amp;quot;
initDirection=&amp;quot;north&amp;quot;›
&lt;startSign&gt;Route 30A&lt;/startSign&gt;
&lt;eventChain&gt;
&lt;event kind=&amp;quot;driving forward&amp;quot;/&gt;
&lt;/eventChain&gt;
&lt;/vehicle&gt;
&lt;vehicle id=&amp;quot;truck2&amp;quot; kind=&amp;quot;truck&amp;quot;
initDirection=&amp;quot;west&amp;quot;›
&lt;startSign&gt;State Route 7&lt;/startSign&gt;
&lt;eventChain&gt;
&lt;event kind=&amp;quot;driving_forward&amp;quot;/&gt;
&lt;/eventChain&gt;
&lt;/vehicle&gt;
&lt;/dynamicObjects&gt;
&lt;collisions&gt;
&lt;collision&gt;
&lt;actor id=&amp;quot;busl&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt;
&lt;victim id=&amp;quot;truck2&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt;
&lt;/collision&gt;
&lt;/collisions&gt;
&lt;/accident&gt;
</figure>
<sectionHeader confidence="0.986037" genericHeader="method">
5 The Visualization Module
</sectionHeader>
<bodyText confidence="0.999882647058824">
The visualizer reads its input from the template de-
scription. It synthesizes a symbolic 3D scene and
animates the vehicles (Egges et al., 2001). The
scene generation algorithm positions the static ob-
jects and plans the vehicle motions. It uses infer-
ence rules to check the consistency of the template
description and to estimate the 3D start and end
coordinates of the vehicles.
The visualizer uses a planner to generate the ve-
hicle trajectories. A first stage determines the start
and end positions of the vehicles from the initial
directions, the configuration of the other objects in
the scene, and the chain of events as if they were
no accident, Then, a second stage alters these tra-
jectories to insert the collisions according to the
accident slots in the template. Figure 2 shows the
visual output corresponding to text HAR-00-02.
</bodyText>
<figureCaption confidence="0.9594065">
Figure 2: Generated scene corresponding to text
HAR-00-02 of the NTSB.
</figureCaption>
<bodyText confidence="0.999227944444444">
The information extraction and visualization
modules are both written in Java. They use JNI as
an interface with the external C libraries. All the
modules are integrated in a same graphical user
interface (Figure 3). The interface is designed to
represent text-to-scene processing flow. The left
pane contains the original text. The middle pane
contains the XML template, and the 3D animation
is displayed in a floating window (Schulz, 2002).
The interface supports direct editing of the origi-
nal text file and the XML template. The user can
launch the information extraction and the three di-
mensional simulation of an accident using the bot-
tom buttons. S/he can also adjust the settings of
the program.
As far as we know, CarSim is the only text-to-
scene converter that is applied to non-invented nar-
ratives.
</bodyText>
<page confidence="0.996857">
193
</page>
<table confidence="0.997480685185185">
Program Pep. MIL Doc. VisualvaPan ,
00,11.11,
Peron Visualization
&apos;ar1300&apos; •STAPT nog.=
.olp 10q7 in.,tor Pop, •,
Ile re: 11, Objec
•Po lcOlpect,
/Ode WM&apos; InIldrection,sourr kird,rucH,
.event,eln.
•everit kin,tliMnsLioneard,
pipet kinWehanne lane r11-0,
.leverTheln.
-,hrEIC•
.,ovon,Pain•
.vell tie Id—InectopeemPple,&amp;quot; InClrecton-&amp;quot;sout PppPlltruclfl&gt;
.vennhaln&gt;
•Pient kintk. stop&amp;quot;,
•feeerb:Paln*
&lt;fdpien
qo !Pions,
•collplon•
•a..ori,t1&amp;quot; sitlec&amp;quot;unknown,
1...trectepeemball err sple,rear,
, Melo,
•coinslone
•at tor i,tractor-sernitraller2&amp;quot; sitle,nknown,
.vit1111 itl,IrdtlOr.Sentraller,
•P °Peden.
•kollisla Ps&gt;
= dent&gt;
.END HarE101.
• 1,arn P11011.. rip p I
nrtn Atpr pi- an
FI;rtagenneVa&apos;::o1
neMedtractopserninpler.
howl was pushed Porpa-d
a.
struckineled elde 0,^^1111
neMed liractomeernieppr P
e 11 peOple On OOP line
us. Pe Oder end 6
assenpara were IPred.
ther 16 neeleennerSwuf
nPed.The.
Of Una. OMB first
■aolopeirnitrailempe
ironed. end occupant of
e se ond
aplopeerntrailerwas
nelin ed
Mar1,1111,
ar0001 111-11&amp;quot;ar&apos;
&apos;arr°071 Off Pee
ar0102
</table>
<figureCaption confidence="0.996234">
Figure 3: The CarSim graphical user interface.
</figureCaption>
<sectionHeader confidence="0.987683" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999511">
This work is partly supported by grant num-
ber 2002-02380 from the Vinnova Sprakteknologi
program.
</bodyText>
<sectionHeader confidence="0.997331" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9990229375">
Giovanni Adorni, Mauro Di Manzo, and Fausto
Giunchiglia. 1984. Natural language driven image
generation. In Proceedings of COLING 84, pages
495-500, Stanford, California.
Michael Arens, Artur Ottlik, and Hans-Hellmut Nagel.
2002. Natural language texts for a cognitive vision
system. In Frank van Harmelen, editor, ECAI2002,
Proceedings of the 15th European Conference on
Artificial Intelligence, Lyon, July 21-26.
Bob Coyne and Richard Sproat. 2001. Wordseye: An
automatic text-to-scene conversion system. In Pro-
ceedings of the Siggraph Conference, Los Angeles.
Sylvain Dupuy, Arjan Egges, Vincent Legendre, and
Pierre Nugues. 2001. Generating a 3D simulation
of a car accident from a written description in natu-
ral language: The Carsim system. In Proceedings of
The Workshop on Temporal and Spatial Information
Processing, pages 1-8, Toulouse, July 7. Associa-
tion for Computational Linguistics.
Arjan Egges, Anton Nijholt, and Pierre Nugues. 2001.
Generating a 3D simulation of a car accident
from a formal description. In Venetia Giagourta
and Michael G. Strintzis, editors, Proceedings of
The International Conference on Augmented, Vir-
tual Environments and Three-Dimensional Imaging
(ICAV3D), pages 220-223, Mykonos, Greece, May
30-June 01.
Christiane Fellbaum, editor. 1998. WordNet: An elec-
tronic lexical database. MIT Press.
Mauro Di Manzo, Giovanni Adorni, and Fausto
Giunchiglia. 1986. Reasoning about scene descrip-
tions. IEEE Proceedings — Special Issue on Natural
Language, 74(7): 1013-1025 .
Hans-Hellmut Nagel. 2001. Toward a cognitive vi-
sion system. Technical report, Universitat Karlsruhe
(TH), http://kogs.iaks.uni-karlsruhe.de/CogViSys.
Ola Akerberg and Hans Svensson. 2002. Development
and integration of linguistic components for an au-
tomatic text-to-scene conversion system. Master&apos;s
thesis, Lunds universitet, Sweden.
Bastian Schulz. 2002. Development of an interface
and visualization components for a text-to-scene
converter. Master&apos;s thesis, Lunds universitet, Swe-
den.
Daniel Sleator and Davy Temperley. 1993. Parsing
English with a link grammar. In Third Interna-
tional Workshop on Parsing Technologies, Tilburg,
The Netherlands, August.
</reference>
<page confidence="0.998753">
194
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000061">
<title confidence="0.9929705">CarSim: An Automatic 3D Text-to-Scene Conversion System Applied to Road Accident Reports</title>
<author confidence="0.997795">Ola Akerbergt Hans Svenssont Bastian Schulz t Pierre Nuguest</author>
<affiliation confidence="0.9820485">tLund University, LTH tTechnische Universitat Hamburg-Harburg Department of Computer science Schwarzenbergstrae 95</affiliation>
<address confidence="0.998306">Box 118, S-221 00 Lund, Sweden D-21071 Hamburg, Germany</address>
<email confidence="0.6094365">le94oa,e94hsvl@efd.lth.seb.schulz@tuhh.dePierre.Nugues@cs.lth.se</email>
<abstract confidence="0.97954856504065">CarSim is an automatic text-to-scene conversion system. It analyzes written descriptions of car accidents and synthesizes 3D scenes of them. The conversion process consists of two stages. An information extraction module creates a tabular description of the accident and a visual simulator generates and animates the scene. We implemented a first version of Car- Sim that considered a corpus of texts in French. We redesigned its linguistic modules and its interface and we applied it to texts in English from the National Transportation Safety Board in the United States. Conversion Text-to-scene conversion consists in creating a 2D or 3D geometric description from a natural language text. The resulting scene can be static or animated. To be converted, the text must be appropriate in some sense, that is, contains explicit descriptions of objects and events for which we can form mental images. Animated 3D graphics have some advantages for the visualization of information. They can reproduce a real scene more accurately and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of the text. A second module creates the 3D scene from the template. The template has been designed so that it contains the information necessary to reproduce and animate the accidents (Figure 1). A first version of CarSim was designed to process texts in French. We used a corpus of 87 car accident reports written in French and provided by the MAIF insurance company. Texts are short narratives written by one of the drivers after the accident. They correspond to relatively simple accidents: There were no casualties and both drivers agreed on what happened. In spite of this, many reports are pretty complex and sometimes difficult to understand. 191 Infi rrran on Extraction Module lnterurdiate XML ■ Graphical Module - Java3DDisplay Template Link Cirammar Figure 1: The CarSim architecture. We describe here a new system that accepts reports in English. We developed and tested it using twenty road accident summaries from the National Transportation Safety Board (www.ntsb.gov), an accident research organization of the United States government. The accidents described by the NTSB are more complex or spectacular than the ones we analyzed in French. To visualize them, we had to add new vehicle actions like &amp;quot;overturn.&amp;quot; 3 An Example of Report The next text is an example of summaries from the NTSB (HAR-00-02): About 10:30 a.m. on October 21, 1999, in Schoharie County, New York, a Kinnicutt Bus Company school bus was transporting 44 students, 5 to 9 years old, and 8 adults on an Albany City School No. 18 field trip. The bus was traveling north on State Route 30A as it approached the intersection with State Route 7, which is about 1.5 miles east of Central Bridge, New York. Concurrently, an MVF Construction Company dump truck, towing a utility trailer, was traveling west on State Route 7. The dump truck was occupied by the driver and a passenger. As the bus approached the intersection, it failed to stop as required and was struck by the dump truck. Seven bus passengers sustained serious injuries, 28 bus passengers and the truckdriver received minor injuries. Thirteen bus passengers, the busdriver, and the truck passenger were uninjured. This text is a good example of the possible content of the NTSB summaries. It describes a bus driving on State Route 30A and a truck on State Route 7 and their accident in an intersection. Although the interaction is visually simple, the text is rather difficult to understand because of the profusion of details. We believe that the conversion of a text to a scene can help understand its information content as it can make it more concrete to a user. Although we don&apos;t claim that a sequence of images can replace a text, we are sure that it can complement it. And automatic conversion techniques can make this process faster and easier. 4 The Language Processing Module The CarSim language processing module uses information extraction techniques to fill a template from the accident narrative. The information extracted from the text is mapped onto a predefined XML structure that consists of three parts: the static objects, the dynamic objects, and the collision objects. The static objects are the non-moving objects such as trees, obstacles, and road signs. The dynamic objects are moving objects, the vehicles. Examples of dynamic objects are cars and trucks. The collision object structure describes the interaction between dynamic objects and/or static objects. We used two available linguistic resources to analyze the texts: the WordNet lexical database 1998) and the Link Grammar depen- 192 dency parser (Sleator and Temperley, 1993). The strategy to determine the accidents and the actors is to find the collision verbs. CarSim uses regular expressions to search verb patterns in texts, Then, CarSim extracts the dependents of the verb. It evaluates the grammatical function of the word groups, examines words, classifies them using the WordNet hierarchy, and fills the XML template (Akerberg and Svensson, 2002). Table 1 shows the template corresponding to text HAR-00-02. Table 1: The template representing the text HAR- 00-02 from the NTSB. &lt;?xmi version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?› &lt;!DOCTYPE accident SYSTEM &amp;quot;accident.dtd&amp;quot;› &lt;accident&gt; &lt;staticObjects&gt; &lt;road kind=&amp;quot;crossroads&amp;quot;/&gt; &lt;/staticObjects&gt; &lt;dynamicObjects&gt; &lt;vehicle id=&amp;quot;busl&amp;quot; kind=&amp;quot;truck&amp;quot; initDirection=&amp;quot;north&amp;quot;› &lt;startSign&gt;Route 30A&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving forward&amp;quot;/&gt; &lt;/eventChain&gt; &lt;/vehicle&gt; &lt;vehicle id=&amp;quot;truck2&amp;quot; kind=&amp;quot;truck&amp;quot; initDirection=&amp;quot;west&amp;quot;› &lt;startSign&gt;State Route 7&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving_forward&amp;quot;/&gt; &lt;/eventChain&gt; &lt;/vehicle&gt; &lt;/dynamicObjects&gt; &lt;collisions&gt; &lt;collision&gt; &lt;actor id=&amp;quot;busl&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt; &lt;victim id=&amp;quot;truck2&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt; &lt;/collision&gt; &lt;/collisions&gt; &lt;/accident&gt; 5 The Visualization Module The visualizer reads its input from the template description. It synthesizes a symbolic 3D scene and animates the vehicles (Egges et al., 2001). The scene generation algorithm positions the static objects and plans the vehicle motions. It uses inference rules to check the consistency of the template description and to estimate the 3D start and end coordinates of the vehicles. The visualizer uses a planner to generate the vehicle trajectories. A first stage determines the start and end positions of the vehicles from the initial directions, the configuration of the other objects in the scene, and the chain of events as if they were no accident, Then, a second stage alters these trajectories to insert the collisions according to the accident slots in the template. Figure 2 shows the visual output corresponding to text HAR-00-02. Figure 2: Generated scene corresponding to text HAR-00-02 of the NTSB. The information extraction and visualization modules are both written in Java. They use JNI as an interface with the external C libraries. All the modules are integrated in a same graphical user interface (Figure 3). The interface is designed to represent text-to-scene processing flow. The left pane contains the original text. The middle pane contains the XML template, and the 3D animation is displayed in a floating window (Schulz, 2002). The interface supports direct editing of the original text file and the XML template. The user can launch the information extraction and the three dimensional simulation of an accident using the bottom buttons. S/he can also adjust the settings of the program. As far as we know, CarSim is the only text-toscene converter that is applied to non-invented narratives. 193 Pep.MILDoc. VisualvaPan, Peron Visualization &apos;ar1300&apos; •STAPT nog.= .olp 10q7 in.,tor Pop, •, 11, Objec •Po lcOlpect, WM&apos; .event,eln. •everit kin,tliMnsLioneard, kinWehanne lane .leverTheln. tie Id—InectopeemPple,&amp;quot; .vennhaln&gt; Pient stop&amp;quot;, •feeerb:Paln* &lt;fdpien •collplon• a..ori,t1&amp;quot; err , Melo, •coinslone •at tor i,tractor-sernitraller2&amp;quot; sitle,nknown, •P °Peden. kollisla = dent&gt; .END HarE101. • p I Atpr an neMedtractopserninpler. was pushed a. struckineled elde 0,^^1111 neMed liractomeernieppr P e 11 peOple On OOP line Pe Oder end6 ther 16 neeleennerSwuf nPed.The. Una. OMB ■aolopeirnitrailempe end of e se ond aplopeerntrailerwas nelin ed</abstract>
<note confidence="0.794238689655172">ar0001 ar0102 Figure 3: The CarSim graphical user interface. Acknowledgments This work is partly supported by grant number 2002-02380 from the Vinnova Sprakteknologi program. References Giovanni Adorni, Mauro Di Manzo, and Fausto Giunchiglia. 1984. Natural language driven image In of COLING 84, 495-500, Stanford, California. Michael Arens, Artur Ottlik, and Hans-Hellmut Nagel. 2002. Natural language texts for a cognitive vision van Harmelen, editor, Proceedings of the 15th European Conference on Intelligence, July 21-26. Bob Coyne and Richard Sproat. 2001. Wordseye: An text-to-scene conversion system. Proof the Siggraph Conference, Angeles. Sylvain Dupuy, Arjan Egges, Vincent Legendre, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident from a written description in natulanguage: The Carsim system. In of The Workshop on Temporal and Spatial Information 1-8, Toulouse, July 7. Association for Computational Linguistics. Arjan Egges, Anton Nijholt, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident</note>
<title confidence="0.672328">from a formal description. In Venetia Giagourta</title>
<author confidence="0.704296">Michael G Strintzis</author>
<author confidence="0.704296">of editors</author>
<affiliation confidence="0.543503">The International Conference on Augmented, Virtual Environments and Three-Dimensional Imaging</affiliation>
<address confidence="0.518013">220-223, Mykonos, Greece, May</address>
<abstract confidence="0.735998833333333">30-June 01. Fellbaum, editor. 1998. An eleclexical database. Press. Mauro Di Manzo, Giovanni Adorni, and Fausto Giunchiglia. 1986. Reasoning about scene descrip- Proceedings — Special Issue on Natural 1013-1025 . Hans-Hellmut Nagel. 2001. Toward a cognitive vision system. Technical report, Universitat Karlsruhe (TH), http://kogs.iaks.uni-karlsruhe.de/CogViSys. Ola Akerberg and Hans Svensson. 2002. Development and integration of linguistic components for an automatic text-to-scene conversion system. Master&apos;s thesis, Lunds universitet, Sweden. Bastian Schulz. 2002. Development of an interface and visualization components for a text-to-scene converter. Master&apos;s thesis, Lunds universitet, Sweden.</abstract>
<note confidence="0.6597516">Daniel Sleator and Davy Temperley. 1993. Parsing with a link grammar. In Interna- Workshop on Parsing Technologies, The Netherlands, August. 194</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Giovanni Adorni</author>
<author>Mauro Di Manzo</author>
<author>Fausto Giunchiglia</author>
</authors>
<title>Natural language driven image generation.</title>
<date>1984</date>
<booktitle>In Proceedings of COLING 84,</booktitle>
<pages>495--500</pages>
<location>Stanford, California.</location>
<marker>Adorni, Di Manzo, Giunchiglia, 1984</marker>
<rawString>Giovanni Adorni, Mauro Di Manzo, and Fausto Giunchiglia. 1984. Natural language driven image generation. In Proceedings of COLING 84, pages 495-500, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Arens</author>
<author>Artur Ottlik</author>
<author>Hans-Hellmut Nagel</author>
</authors>
<title>Natural language texts for a cognitive vision system.</title>
<date>2002</date>
<booktitle>ECAI2002, Proceedings of the 15th European Conference on Artificial Intelligence,</booktitle>
<pages>21--26</pages>
<editor>In Frank van Harmelen, editor,</editor>
<location>Lyon,</location>
<contexts>
<context position="1874" citStr="Arens et al., 2002" startWordPosition="286" endWordPosition="289">f objects and events for which we can form mental images. Animated 3D graphics have some advantages for the visualization of information. They can reproduce a real scene more accurately and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of the text. A second module creates the 3D scene from the template. The template has been designed so that it contains the information necessary to</context>
</contexts>
<marker>Arens, Ottlik, Nagel, 2002</marker>
<rawString>Michael Arens, Artur Ottlik, and Hans-Hellmut Nagel. 2002. Natural language texts for a cognitive vision system. In Frank van Harmelen, editor, ECAI2002, Proceedings of the 15th European Conference on Artificial Intelligence, Lyon, July 21-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Richard Sproat</author>
</authors>
<title>Wordseye: An automatic text-to-scene conversion system.</title>
<date>2001</date>
<booktitle>In Proceedings of the Siggraph Conference,</booktitle>
<location>Los Angeles.</location>
<contexts>
<context position="1731" citStr="Coyne and Sproat, 2001" startWordPosition="260" endWordPosition="263">e resulting scene can be static or animated. To be converted, the text must be appropriate in some sense, that is, contains explicit descriptions of objects and events for which we can form mental images. Animated 3D graphics have some advantages for the visualization of information. They can reproduce a real scene more accurately and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of th</context>
</contexts>
<marker>Coyne, Sproat, 2001</marker>
<rawString>Bob Coyne and Richard Sproat. 2001. Wordseye: An automatic text-to-scene conversion system. In Proceedings of the Siggraph Conference, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Dupuy</author>
<author>Arjan Egges</author>
<author>Vincent Legendre</author>
<author>Pierre Nugues</author>
</authors>
<title>Generating a 3D simulation of a car accident from a written description in natural language: The Carsim system.</title>
<date>2001</date>
<booktitle>In Proceedings of The Workshop on Temporal and Spatial Information Processing,</booktitle>
<pages>1--8</pages>
<location>Toulouse,</location>
<contexts>
<context position="2060" citStr="Dupuy et al., 2001" startWordPosition="316" endWordPosition="319">and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of the text. A second module creates the 3D scene from the template. The template has been designed so that it contains the information necessary to reproduce and animate the accidents (Figure 1). A first version of CarSim was designed to process texts in French. We used a corpus of 87 car accident reports written in French and prov</context>
</contexts>
<marker>Dupuy, Egges, Legendre, Nugues, 2001</marker>
<rawString>Sylvain Dupuy, Arjan Egges, Vincent Legendre, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident from a written description in natural language: The Carsim system. In Proceedings of The Workshop on Temporal and Spatial Information Processing, pages 1-8, Toulouse, July 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjan Egges</author>
<author>Anton Nijholt</author>
<author>Pierre Nugues</author>
</authors>
<title>Generating a 3D simulation of a car accident from a formal description.</title>
<date>2001</date>
<booktitle>In Venetia Giagourta and</booktitle>
<pages>220--223</pages>
<editor>Michael G. Strintzis, editors,</editor>
<location>Mykonos, Greece,</location>
<contexts>
<context position="2039" citStr="Egges et al., 2001" startWordPosition="312" endWordPosition="315">ene more accurately and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of the text. A second module creates the 3D scene from the template. The template has been designed so that it contains the information necessary to reproduce and animate the accidents (Figure 1). A first version of CarSim was designed to process texts in French. We used a corpus of 87 car accident reports writt</context>
<context position="7273" citStr="Egges et al., 2001" startWordPosition="1130" endWordPosition="1133">truck&amp;quot; initDirection=&amp;quot;north&amp;quot;› &lt;startSign&gt;Route 30A&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving forward&amp;quot;/&gt; &lt;/eventChain&gt; &lt;/vehicle&gt; &lt;vehicle id=&amp;quot;truck2&amp;quot; kind=&amp;quot;truck&amp;quot; initDirection=&amp;quot;west&amp;quot;› &lt;startSign&gt;State Route 7&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving_forward&amp;quot;/&gt; &lt;/eventChain&gt; &lt;/vehicle&gt; &lt;/dynamicObjects&gt; &lt;collisions&gt; &lt;collision&gt; &lt;actor id=&amp;quot;busl&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt; &lt;victim id=&amp;quot;truck2&amp;quot; side=&amp;quot;unknown&amp;quot;/&gt; &lt;/collision&gt; &lt;/collisions&gt; &lt;/accident&gt; 5 The Visualization Module The visualizer reads its input from the template description. It synthesizes a symbolic 3D scene and animates the vehicles (Egges et al., 2001). The scene generation algorithm positions the static objects and plans the vehicle motions. It uses inference rules to check the consistency of the template description and to estimate the 3D start and end coordinates of the vehicles. The visualizer uses a planner to generate the vehicle trajectories. A first stage determines the start and end positions of the vehicles from the initial directions, the configuration of the other objects in the scene, and the chain of events as if they were no accident, Then, a second stage alters these trajectories to insert the collisions according to the acc</context>
</contexts>
<marker>Egges, Nijholt, Nugues, 2001</marker>
<rawString>Arjan Egges, Anton Nijholt, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident from a formal description. In Venetia Giagourta and Michael G. Strintzis, editors, Proceedings of The International Conference on Augmented, Virtual Environments and Three-Dimensional Imaging (ICAV3D), pages 220-223, Mykonos, Greece, May 30-June 01.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Di Manzo</author>
<author>Giovanni Adorni</author>
<author>Fausto Giunchiglia</author>
</authors>
<title>Reasoning about scene descriptions.</title>
<date>1986</date>
<journal>IEEE Proceedings — Special Issue on Natural Language,</journal>
<volume>74</volume>
<issue>7</issue>
<pages>1013--1025</pages>
<marker>Di Manzo, Adorni, Giunchiglia, 1986</marker>
<rawString>Mauro Di Manzo, Giovanni Adorni, and Fausto Giunchiglia. 1986. Reasoning about scene descriptions. IEEE Proceedings — Special Issue on Natural Language, 74(7): 1013-1025 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Hellmut Nagel</author>
</authors>
<title>Toward a cognitive vision system.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>Universitat</institution>
<location>Karlsruhe (TH), http://kogs.iaks.uni-karlsruhe.de/CogViSys.</location>
<contexts>
<context position="1853" citStr="Nagel, 2001" startWordPosition="284" endWordPosition="285">escriptions of objects and events for which we can form mental images. Animated 3D graphics have some advantages for the visualization of information. They can reproduce a real scene more accurately and render a sequence of events. Automatic text-to-scene conversion has been investigated in a few projects. NALIG (Adomi et al., 1984; Di Manzo et al., 1986) is an early system that was designed to recreate static 2D scenes from simple phrases in Italian. WordsEye (Coyne and Sproat, 2001) is a recent and ambitious example. It features a large database of 3D objects that can be animated. CogViSys (Nagel, 2001; Arens et al., 2002) is aimed a visualizing descriptions of simple car maneuvers at crossroads. All these systems use apparently invented narratives. 2 CarSim CarSim (Egges et al., 2001; Dupuy et al., 2001) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment. The CarSim architecture consists of two modules. A first module carries out a linguistic analysis of the accident and creates a template — a tabular representation — of the text. A second module creates the 3D scene from the template. The template has been designed so that it contains the inf</context>
</contexts>
<marker>Nagel, 2001</marker>
<rawString>Hans-Hellmut Nagel. 2001. Toward a cognitive vision system. Technical report, Universitat Karlsruhe (TH), http://kogs.iaks.uni-karlsruhe.de/CogViSys.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ola Akerberg</author>
<author>Hans Svensson</author>
</authors>
<title>Development and integration of linguistic components for an automatic text-to-scene conversion system. Master&apos;s thesis, Lunds universitet,</title>
<date>2002</date>
<contexts>
<context position="6331" citStr="Akerberg and Svensson, 2002" startWordPosition="1032" endWordPosition="1035">s the interaction between dynamic objects and/or static objects. We used two available linguistic resources to analyze the texts: the WordNet lexical database (Fellbaum, 1998) and the Link Grammar depen192 dency parser (Sleator and Temperley, 1993). The strategy to determine the accidents and the actors is to find the collision verbs. CarSim uses regular expressions to search verb patterns in texts, Then, CarSim extracts the dependents of the verb. It evaluates the grammatical function of the word groups, examines words, classifies them using the WordNet hierarchy, and fills the XML template (Akerberg and Svensson, 2002). Table 1 shows the template corresponding to text HAR-00-02. Table 1: The template representing the text HAR00-02 from the NTSB. &lt;?xmi version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?› &lt;!DOCTYPE accident SYSTEM &amp;quot;accident.dtd&amp;quot;› &lt;accident&gt; &lt;staticObjects&gt; &lt;road kind=&amp;quot;crossroads&amp;quot;/&gt; &lt;/staticObjects&gt; &lt;dynamicObjects&gt; &lt;vehicle id=&amp;quot;busl&amp;quot; kind=&amp;quot;truck&amp;quot; initDirection=&amp;quot;north&amp;quot;› &lt;startSign&gt;Route 30A&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving forward&amp;quot;/&gt; &lt;/eventChain&gt; &lt;/vehicle&gt; &lt;vehicle id=&amp;quot;truck2&amp;quot; kind=&amp;quot;truck&amp;quot; initDirection=&amp;quot;west&amp;quot;› &lt;startSign&gt;State Route 7&lt;/startSign&gt; &lt;eventChain&gt; &lt;event kind=&amp;quot;driving_forward&amp;quot;/&gt; &lt;/even</context>
</contexts>
<marker>Akerberg, Svensson, 2002</marker>
<rawString>Ola Akerberg and Hans Svensson. 2002. Development and integration of linguistic components for an automatic text-to-scene conversion system. Master&apos;s thesis, Lunds universitet, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bastian Schulz</author>
</authors>
<title>Development of an interface and visualization components for a text-to-scene converter. Master&apos;s thesis, Lunds universitet,</title>
<date>2002</date>
<contexts>
<context position="8480" citStr="Schulz, 2002" startWordPosition="1329" endWordPosition="1330">he accident slots in the template. Figure 2 shows the visual output corresponding to text HAR-00-02. Figure 2: Generated scene corresponding to text HAR-00-02 of the NTSB. The information extraction and visualization modules are both written in Java. They use JNI as an interface with the external C libraries. All the modules are integrated in a same graphical user interface (Figure 3). The interface is designed to represent text-to-scene processing flow. The left pane contains the original text. The middle pane contains the XML template, and the 3D animation is displayed in a floating window (Schulz, 2002). The interface supports direct editing of the original text file and the XML template. The user can launch the information extraction and the three dimensional simulation of an accident using the bottom buttons. S/he can also adjust the settings of the program. As far as we know, CarSim is the only text-toscene converter that is applied to non-invented narratives. 193 Program Pep. MIL Doc. VisualvaPan , 00,11.11, Peron Visualization &apos;ar1300&apos; •STAPT nog.= .olp 10q7 in.,tor Pop, •, Ile re: 11, Objec •Po lcOlpect, /Ode WM&apos; InIldrection,sourr kird,rucH, .event,eln. •everit kin,tliMnsLioneard, pip</context>
</contexts>
<marker>Schulz, 2002</marker>
<rawString>Bastian Schulz. 2002. Development of an interface and visualization components for a text-to-scene converter. Master&apos;s thesis, Lunds universitet, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies,</booktitle>
<location>Tilburg, The Netherlands,</location>
<contexts>
<context position="5951" citStr="Sleator and Temperley, 1993" startWordPosition="972" endWordPosition="975"> the text is mapped onto a predefined XML structure that consists of three parts: the static objects, the dynamic objects, and the collision objects. The static objects are the non-moving objects such as trees, obstacles, and road signs. The dynamic objects are moving objects, the vehicles. Examples of dynamic objects are cars and trucks. The collision object structure describes the interaction between dynamic objects and/or static objects. We used two available linguistic resources to analyze the texts: the WordNet lexical database (Fellbaum, 1998) and the Link Grammar depen192 dency parser (Sleator and Temperley, 1993). The strategy to determine the accidents and the actors is to find the collision verbs. CarSim uses regular expressions to search verb patterns in texts, Then, CarSim extracts the dependents of the verb. It evaluates the grammatical function of the word groups, examines words, classifies them using the WordNet hierarchy, and fills the XML template (Akerberg and Svensson, 2002). Table 1 shows the template corresponding to text HAR-00-02. Table 1: The template representing the text HAR00-02 from the NTSB. &lt;?xmi version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?› &lt;!DOCTYPE accident SYSTEM &amp;quot;accident.dtd&amp;quot;› &lt;accident</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Daniel Sleator and Davy Temperley. 1993. Parsing English with a link grammar. In Third International Workshop on Parsing Technologies, Tilburg, The Netherlands, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>