<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9991805">
Speakers’ Intention Prediction Using Statistics of Multi-level Features in
a Schedule Management Domain
</title>
<author confidence="0.995763">
Donghyun Kim Hyunjung Lee Choong-Nyoung Seon
</author>
<affiliation confidence="0.9928825">
Diquest Research Center Computer Science &amp; Engineering Computer Science &amp; Engineering
Diquest Inc. Sogang University Sogang University
</affiliation>
<address confidence="0.68197">
Seoul, Korea Seoul, Korea Seoul, Korea
</address>
<email confidence="0.979946">
kdh2007@sogang.ac.kr juvenile@sogang.ac.kr wilowisp@gmail.com
</email>
<author confidence="0.997606">
Harksoo Kim Jungyun Seo
</author>
<affiliation confidence="0.885313">
Computer &amp; Communications Engineering Computer Science &amp; Engineering
Kangwon National University Sogang University
Chuncheon, Korea Seoul, Korea
</affiliation>
<email confidence="0.981832">
nlpdrkim@kangwon.ac.kr seojy@sogang.ac.kr
</email>
<sectionHeader confidence="0.998492" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999393055555556">
Speaker’s intention prediction modules can be
widely used as a pre-processor for reducing
the search space of an automatic speech re-
cognizer. They also can be used as a pre-
processor for generating a proper sentence in a
dialogue system. We propose a statistical
model to predict speakers’ intentions by using
multi-level features. Using the multi-level fea-
tures (morpheme-level features, discourse-
level features, and domain knowledge-level
features), the proposed model predicts speak-
ers’ intentions that may be implicated in next
utterances. In the experiments, the proposed
model showed better performances (about
29% higher accuracies) than the previous
model. Based on the experiments, we found
that the proposed multi-level features are very
effective in speaker’s intention prediction.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.942033">
A dialogue system is a program in which a user
and system communicate in natural language. To
understand user’s utterance, the dialogue system
should identify his/her intention. To respond
his/her question, the dialogue system should gen-
erate the counterpart of his/her intention by refer-
ring to dialogue history and domain knowledge.
Most previous researches on speakers’ intentions
have been focused on intention identification tech-
niques. On the contrary, intention prediction tech-
niques have been not studied enough although
there are many practical needs, as shown in Figure
1.
</bodyText>
<figureCaption confidence="0.461709">
Example 1: Prediction of user’s intention
</figureCaption>
<bodyText confidence="0.999973944444445">
In Figure 1, the first example shows that an inten-
tion prediction module can be used as a pre-
processor for reducing the search space of an ASR
(automatic speech recognizer). The second exam-
ple shows that an intention prediction module can
be used as a pre-processor for generating a proper
sentence based on dialogue history.
There are some researches on user’s intention
prediction (Ronnie, 1995; Reithinger, 1995). Rei-
thinger’s model used n-grams of speech acts as
input features. Reithinger showed that his model
can reduce the searching complexity of an ASR to
19~60%. However, his model did not achieve good
performances because the input features were not
rich enough to predict next speech acts. The re-
searches on system’s intention prediction have
been treated as a part of researches on dialogue
models such as a finite-state model, a frame-based
</bodyText>
<figure confidence="0.994766041666667">
Prediction of
user’s intention
Response, Timetable-update-date
Prediction of
system’s intention
Response, Timetable-insert-phonenum
Ask-confirm, Timetable-insert-phonenum
Ask-ref, Timetable-update-date
Identification of
system’s intention
Reducing the search space
of an ASR
It is changed into 4 May.
It is changed into 14 May.
...
It is changed into 12:40.
The date is changed.
Is it changed into 4 May?
...
Response generation
Identification of
user’s intention
It is 706-8954.
Is it 706-8954?
</figure>
<figureCaption confidence="0.997554">
Figure 1. Motivational example
</figureCaption>
<figure confidence="0.4280644">
The result of
speech recognition
It is changed into 4 May.
When is the changed date?
Example 2: Prediction of system’s intention
</figure>
<page confidence="0.979406">
229
</page>
<reference confidence="0.222508">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 229–232,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.999854761904762">
model (Goddeau, 1996), and a plan-based model
(Litman, 1987). However, a finite-state model has
a weak point that dialogue flows should be prede-
fined. Although a plan-based model can manage
complex dialogue phenomena using plan inference,
a plan-based model is not easy to be applied to the
real world applications because it is difficult to
maintain plan recipes. In this paper, we propose a
statistical model to reliably predict both user’s in-
tention and system’s intention in a schedule man-
agement domain. The proposed model determines
speakers’ intentions by using various levels of lin-
guistic features such as clue words, previous inten-
tions, and a current state of a domain frame.
to a three-layer annotation scheme (i.e. Fully con-
necting basic concepts with bar symbols) (Kim,
2007) based on Table 2. Then, we generalize
speaker’s intention into a pair of a speech act and a
concept sequence. In the remains of this paper, we
call a pair of a speech act and a concept sequence)
an intention.
</bodyText>
<subsectionHeader confidence="0.992831">
2.2 Intention prediction model
</subsectionHeader>
<bodyText confidence="0.99959025">
Given n utterances U1,n in a dialogue, let SIn+1 de-
note speaker’s intention of the n+1th utterance.
Then, the intention prediction model can be for-
mally defined as the following equation:
</bodyText>
<equation confidence="0.384701">
2 Statistical prediction of speakers’ inten- P(SIn+1  |U1,n) ≈ arg max P(SAn+1, CSn+1  |U1,n ) (1)
tions SAn+1,CSn+1
</equation>
<subsectionHeader confidence="0.995335">
2.1 Generalization of speakers’ intentions
</subsectionHeader>
<bodyText confidence="0.999805285714286">
In a goal-oriented dialogue, speaker’s intention can
be represented by a semantic form that consists of
a speech act and a concept sequence (Levin, 2003).
In the semantic form, the speech act represents the
general intention expressed in an utterance, and the
concept sequence captures the semantic focus of
the utterance.
</bodyText>
<tableCaption confidence="0.821960125">
Table 1. Speech acts and their meanings
Speech act Description
Greeting The opening greeting of a dialogue
Expressive The closing greeting of a dialogue
Opening Sentences for opening a goal-oriented dialogue
Ask-ref WH-questions
Ask-if YN-questions
Response Responses of questions or requesting actions
</tableCaption>
<table confidence="0.8707135">
Request Declarative sentences for requesting actions
Ask- Questions for confirming the previous actions
confirm
Confirm Reponses of ask-confirm
Inform Declarative sentences for giving some information
Accept Agreement
</table>
<tableCaption confidence="0.96834425">
Table 2. Basic concepts in a schedule management
domain.
Table name Operation name Field name
Timetable Insert, Delete,
</tableCaption>
<construct confidence="0.48098975">
Select, Update
Insert, Delete,
Alarm Date, Time
Select, Update
</construct>
<bodyText confidence="0.99916275">
Based on these assumptions, we define 11 domain-
independent speech acts, as shown in Table 1, and
53 domain-dependent concept sequences according
In Equation (1), SAn+1 and CSn+1 are the speech act
and the concept sequence of the n+1th utterance,
respectively. Based on the assumption that the
concept sequences are independent of the speech
acts, we can rewrite Equation (1) as Equation (2).
</bodyText>
<equation confidence="0.9978085">
P(SIn+1  |U1,n) ≈ arg max P(SAn+1  |U1,n)P(CSn+1  |U1,n ) (2)
SAn+1,CSn+ 1
</equation>
<bodyText confidence="0.978228230769231">
In Equation (2), it is impossible to directly com-
pute P(SAn+1  |U1,n) and P(CSn+1  |U1,n) because a speaker
expresses identical contents with various surface
forms of n sentences according to a personal lin-
guistic sense in a real dialogue. To overcome this
problem, we assume that n utterances in a dialogue
can be generalized by a set of linguistic features
containing various observations from the first ut-
terance to the nth utterance. Therefore, we simplify
Equation (2) by using a linguistic feature set FSn+1
(a set of features that are accumulated from the
first utterance to nth utterance) for predicting the
n+1th intention, as shown in Equation (3).
</bodyText>
<equation confidence="0.99968975">
P(SIn+1  |U1,n) ≈ arg max P(SAn+1  |FSn+1)P(CSn+1  |FSn+1
SA CS
1 ,
n+ n + 1
</equation>
<bodyText confidence="0.999758833333333">
All terms of the right hand side in Equation (3) are
represented by conditional probabilities given a
various feature values. These conditional probabili-
ties can be effectively evaluated by CRFs (condi-
tional random fields) (Lafferty, 2001) that globally
consider transition probabilities from the first ut-
</bodyText>
<table confidence="0.773361333333333">
Agent, Date, Day-of-week,
Time, Person, Place
) (3)
</table>
<page confidence="0.981519">
230
</page>
<bodyText confidence="0.98475425">
terance to the n+1th utterance, as shown in Equa-
tion (4).
In Equation (4), Fj (SAi , FSi) and Fj (CSi, FSi) are fea-
ture functions for predicting the speech act and the
concept sequence of the ith utterance, respectively.
Z(FS) is a normalization factor. The feature func-
tions receive binary values (i.e. zero or one) ac-
cording to absence or existence of each feature.
</bodyText>
<subsectionHeader confidence="0.967391">
2.3 Multi-level features
</subsectionHeader>
<bodyText confidence="0.9995915">
The proposed model uses multi-level features as
input values of the feature functions in Equation
(4). The followings give the details of the proposed
multi-level features.
</bodyText>
<listItem confidence="0.7963685">
• Morpheme-level feature: Sometimes a few
words in a current utterance give important
</listItem>
<bodyText confidence="0.969965571428572">
clues to predict an intention of a next utterance.
We propose two types of morpheme-level fea-
tures that are extracted from a current utterance:
One is lexical features (content words annotated
with parts-of-speech) and the other is POS fea-
tures (part-of-speech bi-grams of all words in
an utterance). To obtain the morpheme-level
features, we use a conventional morphological
analyzer. Then, we remove non-informative
feature values by using a well-known 2
χ statis-
tic because the previous works in document
classification have shown that effective feature
selection can increase precisions (Yang, 1997).
</bodyText>
<listItem confidence="0.903321928571429">
• Discourse-level feature: An intention of a cur-
rent utterance affects that dialogue participants
determine intentions of next utterances because
a dialogue consists of utterances that are se-
quentially associated with each other. We pro-
pose discourse-level features (bigrams of
speakers’ intentions; a pair of a current inten-
tion and a next intention) that are extracted
from a sequence of utterances in a current di-
alogue.
• Domain knowledge-level feature: In a goal-
oriented dialogue, dialogue participants accom-
plish a given task by using shared domain
knowledge. Since a frame-based model is more
</listItem>
<bodyText confidence="0.999871166666667">
flexible than a finite-state model and is more
easy-implementable than a plan-based model,
we adopt the frame-based model in order to de-
scribe domain knowledge. We propose two
types of domain knowledge-level features; slot-
modification features and slot-retrieval features.
The slot-modification features represent which
slots are filled with suitable items, and the slot-
retrieval features represent which slots are
looked up. The slot-modification features and
the slot-retrieval features are represented by bi-
nary notation. In the slot-modification features,
‘1’ means that the slot is filled with a proper
item, and ‘0’ means that the slot is empty. In
the slot-retrieval features, ‘1’ means that the
slot is looked up one or more times. To obtain
domain knowledge-level features, we prede-
fined speakers’ intentions associated with slot
modification (e.g. ‘response &amp; timetable-
update-date’) and slot retrieval (e.g. ‘request &amp;
timetable-select-date’), respectively. Then, we
automatically generated domain knowledge-
level features by looking up the predefined in-
tentions at each dialogue step.
</bodyText>
<sectionHeader confidence="0.999838" genericHeader="introduction">
3 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999983">
3.1 Data sets and experimental settings
</subsectionHeader>
<bodyText confidence="0.999939352941177">
We collected a Korean dialogue corpus simulated
in a schedule management domain such as ap-
pointment scheduling and alarm setting. The dialo-
gue corpus consists of 956 dialogues, 21,336
utterances (22.3 utterances per dialogue). Each
utterance in dialogues was manually annotated
with speech acts and concept sequences. The ma-
nual tagging of speech acts and concept sequences
was done by five graduate students with the know-
ledge of a dialogue analysis and post-processed by
a student in a doctoral course for consistency. To
experiment the proposed model, we divided the
annotated messages into the training corpus and
the testing corpus by a ratio of four (764 dialogues)
to one (192 dialogues). Then, we performed 5-fold
cross validation. We used training factors of CRFs
as L-BGFS and Gaussian Prior.
</bodyText>
<subsectionHeader confidence="0.999208">
3.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.996902333333333">
Table 3 and Table 4 show the accuracies of the
proposed model in speech act prediction and con-
cept sequence prediction, respectively.
</bodyText>
<equation confidence="0.766817371428572">
1
=
PCRF
(SA1,n+1  |FS1, n
1
+
n
1
)
+
exp(EE
λ j j i
F SA FS
( , ))
i (4)
Z(FS1,n+1) i j
= 1
1
+
n
1
( , ))
CSFS
i i
1
=
+
)
PCRF
λjFj
(CS1,n+1  |FS1,n
exp(EE
i j
=1
Z(FS1,n+1)
</equation>
<page confidence="0.9743">
231
</page>
<tableCaption confidence="0.957671">
Table 3. The accuracies of speech act prediction
</tableCaption>
<figure confidence="0.709314777777778">
Features Accuracy-S (%) Accuracy-U (%)
Morpheme-level 76.51 72.01
features
Discourse-level 87.31 72.80
features
Domain know- 63.44 49.03
ledge-level feature
All features 88.11 76.25
Table 4. The accuracies of concept sequence pre-
diction
Features Accuracy-S (%) Accuracy-U (%)
Morpheme-level 66.35 59.40
features
Discourse-level 86.56 62.62
features
Domain know- 37.68 49.03
ledge-level feature
All features 87.19 64.21
</figure>
<bodyText confidence="0.9997811">
We proposed a statistical prediction model of
speakers’ intentions using multi-level features. The
model uses three levels (a morpheme level, a dis-
course level, and a domain knowledge level) of
features as input features of the statistical model
based on CRFs. In the experiments, the proposed
model showed better performances than the pre-
vious model. Based on the experiments, we found
that the proposed multi-level features are very ef-
fective in speaker’s intention prediction.
</bodyText>
<sectionHeader confidence="0.998107" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9906094">
This research (paper) was performed for the Intel-
ligent Robotics Development Program, one of the
21st Century Frontier R&amp;D Programs funded by
the Ministry of Commerce, Industry and Energy of
Korea.
</bodyText>
<sectionHeader confidence="0.987642" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.999940928571429">
In Table 3 and Table 4, Accuracy-S means the ac-
curacy of system’s intention prediction, and Accu-
racy-U means the accuracy of user’s intention
prediction. Based on these experimental results, we
found that multi-level features include different
types of information and cooperation of the multi-
level features brings synergy effect. We also found
the degree of feature importance in intention pre-
diction (i.e. discourse level features &gt; morpheme-
level features &gt; domain knowledge-level features).
To evaluate the proposed model, we compare
the accuracies of the proposed model with those of
Reithinger’s model (Reithinger, 1995) by using the
same training and test corpus, as shown in Table 5.
</bodyText>
<tableCaption confidence="0.989988">
Table 5. The comparison of accuracies
</tableCaption>
<table confidence="0.978955833333333">
Speaker Type Reithinger’s The proposed
model model
System Speech act 43.37 88.11
Concept sequence 68.06 87.19
User Speech act 37.59 76.25
Concept sequence 49.48 64.21
</table>
<bodyText confidence="0.999329714285714">
As shown in Table 5, the proposed model outper-
formed Reithinger’s model in all kinds of predic-
tions. We think that the differences between
accuracies were mainly caused by input features:
The proposed model showed similar accuracies to
Reithinger’s model when it used only domain
knowledge-level features.
</bodyText>
<sectionHeader confidence="0.999797" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<reference confidence="0.999627451612903">
D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and S.
Busayapongchai. 1996. “A Form-Based Dialogue
Manager for Spoken Language Applications”, Pro-
ceedings of International Conference on Spoken
Language Processing, 701-704.
D. Litman and J. Allen. 1987. A Plan Recognition Mod-
el for Subdialogues in Conversations, Cognitive
Science, 11:163-200.
H. Kim. 2007. A Dialogue-based NLIDB System in a
Schedule Management Domain: About the method to
Find User’s Intentions, Lecture Notes in Computer
Science, 4362:869-877.
J. Lafferty, A. McCallum, and F. Pereira. 2001. “Condi-
tional Random Fields: Probabilistic Models for Seg-
menting And Labeling Sequence Data”, Proceedings
of ICML, 282-289.
L. Levin, C. Langley, A. Lavie, D. Gates, D. Wallace,
and K. Peterson. 2003. “Domain Specific Speech
Acts for Spoken Language Translation”, Proceedings
of the 4th SIGdial Workshop on Discourse and Di-
alogue.
N. Reithinger and E. Maier. 1995. “Utilizing Statistical
Dialog Act Processing in VerbMobil”, Proceedings
of ACL, 116-121.
R. W. Smith and D. R. Hipp, 1995. Spoken Natural
Language Dialogue Systems: A Practical Approach,
Oxford University Press.
Y. Yang and J. Pedersen. 1997. “A Comparative Study
on Feature Selection in Text Categorization”, Pro-
ceedings of the 14th International Conference on
Machine Learning.
</reference>
<page confidence="0.995077">
232
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.526544">
<title confidence="0.904261">Speakers’ Intention Prediction Using Statistics of Multi-level Features in a Schedule Management Domain</title>
<author confidence="0.812843">Donghyun Kim Hyunjung Lee Choong-Nyoung Seon</author>
<affiliation confidence="0.980584">Diquest Research Center Computer Science &amp; Engineering Computer Science &amp; Engineering Diquest Inc. Sogang University Sogang University</affiliation>
<address confidence="0.977656">Seoul, Korea Seoul, Korea Seoul, Korea</address>
<email confidence="0.986651">juvenile@sogang.ac.krwilowisp@gmail.com</email>
<author confidence="0.99997">Kim Seo</author>
<affiliation confidence="0.9987795">Computer &amp; Communications Engineering Computer Science &amp; Engineering Kangwon National University Sogang University</affiliation>
<address confidence="0.982983">Chuncheon, Korea Seoul, Korea</address>
<email confidence="0.75747">nlpdrkim@kangwon.ac.krseojy@sogang.ac.kr</email>
<abstract confidence="0.999070578947368">Speaker’s intention prediction modules can be widely used as a pre-processor for reducing the search space of an automatic speech recognizer. They also can be used as a preprocessor for generating a proper sentence in a dialogue system. We propose a statistical model to predict speakers’ intentions by using multi-level features. Using the multi-level features (morpheme-level features, discourselevel features, and domain knowledge-level features), the proposed model predicts speakers’ intentions that may be implicated in next utterances. In the experiments, the proposed model showed better performances (about 29% higher accuracies) than the previous model. Based on the experiments, we found that the proposed multi-level features are very effective in speaker’s intention prediction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>229--232</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 229–232,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<title>c�2008 Association for Computational Linguistics</title>
<date>2008</date>
<booktitle>Proceedings of International Conference on Spoken Language Processing,</booktitle>
<pages>701--704</pages>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and S. Busayapongchai. 1996. “A Form-Based Dialogue Manager for Spoken Language Applications”, Proceedings of International Conference on Spoken Language Processing, 701-704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>J Allen</author>
</authors>
<title>A Plan Recognition Model for Subdialogues in Conversations,</title>
<date>1987</date>
<journal>Cognitive Science,</journal>
<pages>11--163</pages>
<marker>Litman, Allen, 1987</marker>
<rawString>D. Litman and J. Allen. 1987. A Plan Recognition Model for Subdialogues in Conversations, Cognitive Science, 11:163-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kim</author>
</authors>
<title>A Dialogue-based NLIDB System in a Schedule Management Domain: About the method to Find User’s Intentions,</title>
<date>2007</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>4362--869</pages>
<marker>Kim, 2007</marker>
<rawString>H. Kim. 2007. A Dialogue-based NLIDB System in a Schedule Management Domain: About the method to Find User’s Intentions, Lecture Notes in Computer Science, 4362:869-877.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting And Labeling Sequence Data”,</title>
<date>2001</date>
<booktitle>Proceedings of ICML,</booktitle>
<pages>282--289</pages>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. “Conditional Random Fields: Probabilistic Models for Segmenting And Labeling Sequence Data”, Proceedings of ICML, 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Levin</author>
<author>C Langley</author>
<author>A Lavie</author>
<author>D Gates</author>
<author>D Wallace</author>
<author>K Peterson</author>
</authors>
<title>Domain Specific Speech Acts for Spoken Language Translation”,</title>
<date>2003</date>
<booktitle>Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue.</booktitle>
<marker>Levin, Langley, Lavie, Gates, Wallace, Peterson, 2003</marker>
<rawString>L. Levin, C. Langley, A. Lavie, D. Gates, D. Wallace, and K. Peterson. 2003. “Domain Specific Speech Acts for Spoken Language Translation”, Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
<author>E Maier</author>
</authors>
<title>Utilizing Statistical Dialog Act Processing in VerbMobil”,</title>
<date>1995</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>116--121</pages>
<marker>Reithinger, Maier, 1995</marker>
<rawString>N. Reithinger and E. Maier. 1995. “Utilizing Statistical Dialog Act Processing in VerbMobil”, Proceedings of ACL, 116-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Smith</author>
<author>D R Hipp</author>
</authors>
<title>Spoken Natural Language Dialogue Systems: A Practical Approach,</title>
<date>1995</date>
<publisher>University Press.</publisher>
<location>Oxford</location>
<marker>Smith, Hipp, 1995</marker>
<rawString>R. W. Smith and D. R. Hipp, 1995. Spoken Natural Language Dialogue Systems: A Practical Approach, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>J Pedersen</author>
</authors>
<title>A Comparative Study on Feature Selection in Text Categorization”,</title>
<date>1997</date>
<booktitle>Proceedings of the 14th International Conference on Machine Learning.</booktitle>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Y. Yang and J. Pedersen. 1997. “A Comparative Study on Feature Selection in Text Categorization”, Proceedings of the 14th International Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>