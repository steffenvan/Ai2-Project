<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010183">
<title confidence="0.979248">
Language model adaptation with MAP estimation
and the perceptron algorithm
</title>
<author confidence="0.645545">
Michiel Bacchiani, Brian Roark and Murat Saraclar
</author>
<address confidence="0.251918">
AT&amp;T Labs-Research, 180 Park Ave., Florham Park, NJ 07932, USA
</address>
<email confidence="0.990449">
{michiel,roark,murat}@research.att.com
</email>
<sectionHeader confidence="0.993678" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999887461538461">
In this paper, we contrast two language model
adaptation approaches: MAP estimation and
the perceptron algorithm. Used in isolation, we
show that MAP estimation outperforms the lat-
ter approach, for reasons which argue for com-
bining the two approaches. When combined,
the resulting system provides a 0.7 percent ab-
solute reduction in word error rate over MAP
estimation alone. In addition, we demonstrate
that, in a multi-pass recognition scenario, it is
better to use the perceptron algorithm on early
pass word lattices, since the improved error rate
improves acoustic model adaptation.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991153846154">
Most common approaches to language model adapta-
tion, such as count merging and model interpolation, are
special cases of maximum a posteriori (MAP) estima-
tion (Bacchiani and Roark, 2003). In essence, these ap-
proaches involve beginning from a smoothed language
model trained on out-of-domain observations, and adjust-
ing the model parameters based on in-domain observa-
tions. The approach ensures convergence, in the limit, to
the maximum likelihood model of the in-domain obser-
vations. The more in-domain observations, the less the
out-of-domain model is relied upon. In this approach, the
main idea is to change the out-of-domain model parame-
ters to match the in-domain distribution.
Another approach to language model adaptation would
be to change model parameters to correct the errors
made by the out-of-domain model on the in-domain data
through discriminative training. In such an approach,
the baseline recognizer would be used to recognize in-
domain utterances, and the parameters of the model ad-
justed to minimize recognition errors. Discriminative
training has been used for language modeling, using vari-
ous estimation techniques (Stolcke and Weintraub, 1998;
Roark et al., 2004), but language model adaptation to
novel domains is a particularly attractive scenario for dis-
criminative training, for reasons we discuss next.
A key requirement for discriminative modeling ap-
proaches is training data produced under conditions that
are close to testing conditions. For example, (Roark et al.,
2004) showed that excluding an utterance from the lan-
guage model training corpus of the baseline model used
to recognize that utterance is essential to getting word
error rate (WER) improvements with the perceptron al-
gorithm in the Switchboard domain. In that paper, 28
different language models were built, each omitting one
of 28 sections, for use in generating word lattices for the
omitted section. Without removing the section, no benefit
was had from models built with the perceptron algorithm;
with removal, the approach yielded a solid improvement.
More time consuming is controlling acoustic model train-
ing. For a task such as Switchboard, on which the above
citation was evaluated, acoustic model estimation is ex-
pensive. Hence building multiple models, omitting var-
ious subsections is a substantial undertaking, especially
when discriminative estimation techniques are used.
Language model adaptation to a new domain, how-
ever, can dramatically simplify the issue of controlling
the baseline model for producing discriminative training
data, since the in-domain training data is not used for
building the baseline models. The purpose of this paper is
to compare a particular discriminative approach, the per-
ceptron algorithm, which has been successfully applied
in the Switchboard domain, with MAP estimation, for
adapting a language model to a novel domain. In addi-
tion, since the MAP and perceptron approaches optimize
different objectives, we investigate the benefit from com-
bination of these approaches within a multi-pass recogni-
tion system.
The task that we focus upon, adaptation of a general
voicemail recognition language model to a customer ser-
vice domain, has been shown to benefit greatly from
MAP estimation (Bacchiani and Roark, 2003). It is an
attractive test for studying language model adaptation,
since the out-of-domain acoustic model is matched to
the new domain, and the domain shift does not raise the
OOV rate significantly. Using 17 hours of in-domain
observations, versus 100 hours of out-of-domain utter-
ances, (Bacchiani and Roark, 2003) reported a reduction
in WER from 28.0% using the baseline system to 20.3%
with the best performing MAP adapted model. In this pa-
per, our best scenario, which uses MAP adaptation and
the perceptron algorithm in combination, achieves an ad-
ditional 0.7% reduction, to 19.6% WER.
The rest of the paper is structured as follows. In the
next section, we provide a brief background for both
MAP estimation and the perceptron algorithm. This is
followed by an experimental results section, in which we
present the performance of each approach in isolation, as
well as several ways of combining them.
</bodyText>
<sectionHeader confidence="0.987957" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.994972">
2.1 MAP language model adaptation
</subsectionHeader>
<bodyText confidence="0.9999876">
To build an adapted n-gram model, we use a count
merging approach, much as presented in (Bacchiani and
Roark, 2003), which is shown to be a special case of max-
imum a posteriori (MAP) adaptation. Let wO be the out-
of-domain corpus, and wI be the in-domain sample. Let
h represent an n-gram history of zero or more words. Let
ck(hw) denote the raw count of an n-gram hw in wk,
for k E {O, I}. Let ˆpk(hw) denote the standard Katz
backoff model estimate of hw given wk. We define the
corrected count of an n-gram hw as:
</bodyText>
<equation confidence="0.97023">
ˆck(hw) = |wk |ˆpk(hw) (1)
</equation>
<bodyText confidence="0.929161928571429">
where |wk |denotes the size of the sample wk. Then:
τhˆcO(hw) + ˆcI(hw) ˜p(w  |h) = τh Ew, ˆcO (hw&apos;) + Ew, ˆcI (hw&apos;)
(2)
where τh is a state dependent parameter that dictates how
much the out-of-domain prior counts should be relied
upon. The model is then defined as:
p* (w  |h) = (t α p* (w  |h&apos;) othe )ise cI (hw) &gt; 0 (3)
where α is the backoff weight and h&apos; the backoff history
for history h.
The principal difficulty in MAP adaptation of this sort
is determining the mixing parameters τh in Eq. 2. Follow-
ing (Bacchiani and Roark, 2003), we chose a single mix-
ing parameter for each model that we built, i.e. τh = τ
for all states h in the model.
</bodyText>
<subsectionHeader confidence="0.999078">
2.2 Perceptron algorithm
</subsectionHeader>
<bodyText confidence="0.999962357142857">
Our discriminative n-gram model training approach uses
the perceptron algorithm, as presented in (Roark et al.,
2004), which follows the general approach presented in
(Collins, 2002). For brevity, we present the algorithm,
not in full generality, but for the specific case of n-gram
model training.
The training set consists of N weighted word lattices
produced by the baseline recognizer, and a gold-standard
transcription for each of the N lattices. Following (Roark
et al., 2004), we use the lowest WER hypothesis in the
lattice as the gold-standard, rather than the reference tran-
scription. The perceptron model is a linear model with k
feature weights, all of which are initialized to 0. The al-
gorithm is incremental, i.e. the parameters are updated at
each example utterance in the training set in turn, and the
updated parameters are used for the next utterance. Af-
ter each pass over the training set, the model is evaluated
on a held-out set, and the best performing model on this
held-out set is the model used for testing.
For a given path π in a weighted word lattice L, let
w[π] be the cost of that path as given by the baseline rec-
ognizer. Let 9L be the gold-standard transcription for
L. Let Φ(π) be the K-dimensional feature vector for π,
which contains the count within the path π of each fea-
ture. In our case, these are unigram, bigram and trigram
feature counts. Let ¯αt E RK be the K-dimensional fea-
ture weight vector of the perceptron model at time t. The
perceptron model feature weights are updated as follows
</bodyText>
<listItem confidence="0.931766">
1. For the example lattice L at time t, find ˆπt such that
</listItem>
<equation confidence="0.991258">
ˆπt = argmin (w[π] + λΦ(π) · ¯αt) (4)
πEL
</equation>
<bodyText confidence="0.945002">
where λ is a scaling constant.
</bodyText>
<listItem confidence="0.7568035">
2. For the 0 &lt; k &lt; K features in the feature weight
vector ¯αt,
</listItem>
<equation confidence="0.99846">
¯αt+1[k] = ¯αt[k] + Φ(ˆπt)[k] − Φ(9L)[k] (5)
</equation>
<bodyText confidence="0.999038615384615">
Note that if ˆπt = 9L, then the features are left un-
changed.
As shown in (Roark et al., 2004), the perceptron fea-
ture weight vector can be encoded in a deterministic
weighted finite state automaton (FSA), so that much of
the feature weight update involves basic FSA operations,
making the training relatively efficient in practice. As
suggested in (Collins, 2002), we use the averaged per-
ceptron when applying the model to held-out or test data.
After each pass over the training data, the averaged per-
ceptron model is output as a weighted FSA, which can be
used by intersecting with a lattice output from the base-
line system.
</bodyText>
<sectionHeader confidence="0.998625" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.999978442622951">
We evaluated the language model adaptation algorithms
by measuring the transcription accuracy of an adapted
voicemail transcription system on voicemail messages re-
ceived at a customer care line of a telecommunications
network center. The initial voicemail system, named
Scanmail, was trained on general voicemail messages
collected from the mailboxes of people at our research
site in Florham Park, NJ. The target domain is also com-
posed of voicemail messages, but for a mailbox that re-
ceives messages from customer care agents regarding
network outages. In contrast to the general voicemail
messages from the training corpus of the Scanmail sys-
tem, the messages from the target domain, named SS-
NIFR, will be focused solely on network related prob-
lems. It contains frequent mention of various network
related acronyms and trouble ticket numbers, rarely (if at
all) found in the training corpus of the Scanmail system.
To evaluate the transcription accuracy, we used a multi-
pass speech recognition system that employs various
unsupervised speaker and channel normalization tech-
niques. An initial search pass produces word-lattice out-
put that is used as the grammar in subsequent search
passes. The system is almost identical to the one de-
scribed in detail in (Bacchiani, 2001). The main differ-
ences in terms of the acoustic model of the system are
the use of linear discriminant analysis features; use of a
100 hour training set as opposed to a 60 hour training set;
and the modeling of the speaker gender which in this sys-
tem is identical to that described in (Woodland and Hain,
1998). Note that the acoustic model is appropriate for ei-
ther domain as the messages are collected on a voicemail
system of the same type. This parallels the experiments
in (Lamel et al., 2002), where the focus was on AM adap-
tation in the case where the LM was deemed appropriate
for either domain.
The language model of the Scanmail system is a Katz
backoff trigram, trained on hand-transcribed messages of
approximately 100 hours of voicemail (1 million words).
The model contains 13460 unigram, 175777 bigram, and
495629 trigram probabilities. The lexicon of the Scan-
mail system contains 13460 words and was compiled
from all the unique words found in the 100 hours of tran-
scripts of the Scanmail training set.
For every experiment, we report the accuracy of the
one-best transcripts obtained at 2 stages of the recog-
nition process: after the first pass lattice construction
(FP), and after vocal tract length normalization and gen-
der modeling (VTLN), Constrained Model-space Adap-
tation (CMA), and Maximum Likelihood Linear regres-
sion adaptation (MLLR). Results after FP will be denoted
FP; results after VTLN, CMA and MLLR will be denoted
MP.
For the SSNIFR domain we have available a 1 hour
manually transcribed test set (10819 words) and approx-
imately 17 hours of manually transcribed adaptation data
(163343 words). In all experiments, the vocabulary of
the system is left unchanged. Generally, for a domain
shift this can raise the error rate significantly due to an
increase in the OOV rate. However, this increase in error
rate is limited in these experiments, because the majority
of the new domain-dependent vocabulary are acronyms
</bodyText>
<table confidence="0.9989448">
System FP MP
Baseline 32.7 28.0
MAP estimation 23.7 20.3
Perceptron (FP) 26.8 23.0
Perceptron (MP) – 23.9
</table>
<tableCaption confidence="0.80607275">
Table 1: Recognition on the 1 hour SSNIFR test set us-
ing systems obtained by supervised LM adaptation on the
17 hour adaptation set using the two methods, versus the
baseline out-of-domain system.
</tableCaption>
<bodyText confidence="0.997124809523809">
which are covered by the Scanmail vocabulary through
individual letters. The OOV rate of the SSNIFR test set,
using the Scanmail vocabulary is 2%.
Following (Bacchiani and Roark, 2003), τh in Eq. 2 is
set to 0.2 for all reported MAP estimation trials. Follow-
ing (Roark et al., 2004), λ in Eq. 4 is also (coincidentally)
set to 0.2 for all reported perceptron trials. For the percep-
tron algorithm, approximately 10 percent of the training
data is reserved as a held-out set, for deciding when to
stop the algorithm.
Table 1 shows the results using MAP estimation and
the perceptron algorithm independently. For the percep-
tron algorithm, the baseline Scanmail system was used to
produce the word lattices used in estimating the feature
weights. There are two ways to do this. One is to use the
lattices produced after FP; the other is to use the lattices
produced after MP.
These results show two things. First, MAP estimation
on its own is clearly better than the perceptron algorithm
on its own. Since the MAP model is used in the ini-
tial search pass that produces the lattices, it can consider
all possible hypotheses. In contrast, the perceptron algo-
rithm is limited to the hypotheses available in the lattice
produced with the unadapted model.
Second, training the perceptron model on FP lattices
and applying that perceptron at each decoding step out-
performed training on MP lattices and only applying the
perceptron on that decoding step. This demonstrates the
benefit of better transcripts for the unsupervised adapta-
tion steps.
The benefit of MAP adaptation that leads to its supe-
rior performance in Table 1 suggests a hybrid approach,
that uses MAP estimation to ensure that good hypotheses
are present in the lattices, and the perceptron algorithm
to further reduce the WER. Within the multi-pass recog-
nition approach, several scenarios could be considered to
implement this combination. We investigate two here.
For each scenario, we split the 17 hour adaptation set
into four roughly equi-sized sets. In a first scenario, we
produced a MAP estimated model on the first 4.25 hour
subset, and produced word lattices on the other three sub-
sets, for use with the perceptron algorithm. Table 2 shows
</bodyText>
<table confidence="0.997573833333333">
System MAP Pct. FP MP
Baseline 0 32.7 28.0
MAP estimation 100 23.7 20.3
MAP estimation 25 25.6 21.5
Perceptron (FP) 25 23.8 20.5
Perceptron (MP) 25 – 20.8
</table>
<tableCaption confidence="0.998678">
Table 2: Recognition on the 1 hour SSNIFR test set using
</tableCaption>
<bodyText confidence="0.980429714285714">
systems obtained by supervised LM adaptation on the 17
hour adaptation set using the first method of combination
of the two methods, versus the baseline out-of-domain
system.
the results for this training scenario.
A second scenario involves making use of all of the
adaptation data for both MAP estimation and the percep-
tron algorithm. As a result, it requires a more compli-
cated control of the baseline models used for producing
the word lattices for perceptron training. For each of the
four sub-sections of the adaptation data, we produced a
baseline MAP estimated model using the other three sub-
sections. Using these models, we produced training lat-
tices for the perceptron algorithm for the entire adaptation
data set. At test time, we used the MAP estimated model
trained on the entire adaptation set, as well as the percep-
tron model trained on the entire set. The results for this
training scenario are shown in table 3.
Both of these hybrid training scenarios demonstrate a
small improvement by using the perceptron algorithm on
FP lattices rather than MP lattices. Closely matching the
testing condition for perceptron training is important: ap-
plying a perceptron trained on MP lattices to FP lattices
hurts performance. Iterative training did not produce fur-
ther improvements: training a perceptron on MP lattices
produced by using both MAP estimation and a perceptron
trained on FP lattices, achieved no improvement over the
19.6 percent WER shown above.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999728642857143">
This paper has presented a series of experimental re-
sults that compare using MAP estimation for language
model domain adaptation to a discriminative modeling
approach for correcting errors produced by an out-of-
domain model when applied to the novel domain. Be-
cause the MAP estimation produces a model that is used
during first pass search, it has an advantage over the
perceptron algorithm, which simply re-weights paths al-
ready in the word lattice. In support of this argument, we
showed that, by using a subset of the in-domain adapta-
tion data for MAP estimation, and the rest for use in the
perceptron algorithm, we achieved results at nearly the
same level as MAP estimation on the entire adaptation
set.
</bodyText>
<table confidence="0.9965958">
System MAP Pct. FP MP
Baseline 0 32.7 28.0
MAP estimation 100 23.7 20.3
Perceptron (FP) 100 22.9 19.6
Perceptron (MP) 100 – 19.9
</table>
<tableCaption confidence="0.99875">
Table 3: Recognition on the 1 hour SSNIFR test set us-
</tableCaption>
<bodyText confidence="0.963123875">
ing systems obtained by supervised LM adaptation on the
17 hour adaptation set using the second method of com-
bination of the two methods, versus the baseline out-of-
domain system.
With a more complicated training scenario, which used
all of the in-domain adaptation data for both methods
jointly, we were able to improve WER over MAP estima-
tion alone by 0.7 percent, for a total improvement over
the baseline of 8.4 percent.
Studying the various options for incorporating the per-
ceptron algorithm within the multi-pass rescoring frame-
work, our results show that there is a benefit from incor-
porating the perceptron at an early search pass, as it pro-
duces more accurate transcripts for unsupervised adapta-
tion. Furthermore, it is important to closely match testing
conditions for perceptron training.
</bodyText>
<sectionHeader confidence="0.99904" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996605214285714">
Michiel Bacchiani and Brian Roark. 2003. Unsupervised
language model adaptation. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing (ICASSP), pages 224–227.
Michiel Bacchiani. 2001. Automatic transcription of
voicemail at AT&amp;T. In Proceedings of the Interna-
tional Conference on Acoustics, Speech, and Signal
Processing (ICASSP).
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1–8.
L. Lamel, J.-L. Gauvain, and G. Adda. 2002. Unsuper-
vised acoustic model training. In Proceedings of the
International Conference on Acoustics, Speech, and
Signal Processing (ICASSP), pages 877–880.
Brian Roark, Murat Saraclar, and Michael Collins. 2004.
Corrective language modeling for large vocabulary
ASR with the perceptron algorithm. In Proceedings
of the International Conference on Acoustics, Speech,
and Signal Processing (ICASSP).
A. Stolcke and M. Weintraub. 1998. Discriminitive lan-
guage modeling. In Proceedings of the 9th Hub-5
Conversational Speech Recog nition Workshop.
P.C. Woodland and T. Hain. 1998. The September 1998
HTK Hub 5E System. In The Proceedings of the 9th
Hub-5 Conversational Speech Recognition Workshop.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.828848">
<title confidence="0.9929305">Language model adaptation with MAP and the perceptron algorithm</title>
<author confidence="0.975911">Michiel Bacchiani</author>
<author confidence="0.975911">Brian Roark</author>
<author confidence="0.975911">Murat</author>
<affiliation confidence="0.852862">AT&amp;T Labs-Research, 180 Park Ave., Florham Park, NJ 07932,</affiliation>
<abstract confidence="0.999271142857143">In this paper, we contrast two language model adaptation approaches: MAP estimation and the perceptron algorithm. Used in isolation, we show that MAP estimation outperforms the latter approach, for reasons which argue for combining the two approaches. When combined, the resulting system provides a 0.7 percent absolute reduction in word error rate over MAP estimation alone. In addition, we demonstrate that, in a multi-pass recognition scenario, it is better to use the perceptron algorithm on early pass word lattices, since the improved error rate improves acoustic model adaptation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michiel Bacchiani</author>
<author>Brian Roark</author>
</authors>
<title>Unsupervised language model adaptation.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>224--227</pages>
<contexts>
<context position="1025" citStr="Bacchiani and Roark, 2003" startWordPosition="147" endWordPosition="150">tperforms the latter approach, for reasons which argue for combining the two approaches. When combined, the resulting system provides a 0.7 percent absolute reduction in word error rate over MAP estimation alone. In addition, we demonstrate that, in a multi-pass recognition scenario, it is better to use the perceptron algorithm on early pass word lattices, since the improved error rate improves acoustic model adaptation. 1 Introduction Most common approaches to language model adaptation, such as count merging and model interpolation, are special cases of maximum a posteriori (MAP) estimation (Bacchiani and Roark, 2003). In essence, these approaches involve beginning from a smoothed language model trained on out-of-domain observations, and adjusting the model parameters based on in-domain observations. The approach ensures convergence, in the limit, to the maximum likelihood model of the in-domain observations. The more in-domain observations, the less the out-of-domain model is relied upon. In this approach, the main idea is to change the out-of-domain model parameters to match the in-domain distribution. Another approach to language model adaptation would be to change model parameters to correct the errors</context>
<context position="4094" citStr="Bacchiani and Roark, 2003" startWordPosition="614" endWordPosition="617">The purpose of this paper is to compare a particular discriminative approach, the perceptron algorithm, which has been successfully applied in the Switchboard domain, with MAP estimation, for adapting a language model to a novel domain. In addition, since the MAP and perceptron approaches optimize different objectives, we investigate the benefit from combination of these approaches within a multi-pass recognition system. The task that we focus upon, adaptation of a general voicemail recognition language model to a customer service domain, has been shown to benefit greatly from MAP estimation (Bacchiani and Roark, 2003). It is an attractive test for studying language model adaptation, since the out-of-domain acoustic model is matched to the new domain, and the domain shift does not raise the OOV rate significantly. Using 17 hours of in-domain observations, versus 100 hours of out-of-domain utterances, (Bacchiani and Roark, 2003) reported a reduction in WER from 28.0% using the baseline system to 20.3% with the best performing MAP adapted model. In this paper, our best scenario, which uses MAP adaptation and the perceptron algorithm in combination, achieves an additional 0.7% reduction, to 19.6% WER. The rest</context>
<context position="6128" citStr="Bacchiani and Roark, 2003" startWordPosition="977" endWordPosition="980">hw given wk. We define the corrected count of an n-gram hw as: ˆck(hw) = |wk |ˆpk(hw) (1) where |wk |denotes the size of the sample wk. Then: τhˆcO(hw) + ˆcI(hw) ˜p(w |h) = τh Ew, ˆcO (hw&apos;) + Ew, ˆcI (hw&apos;) (2) where τh is a state dependent parameter that dictates how much the out-of-domain prior counts should be relied upon. The model is then defined as: p* (w |h) = (t α p* (w |h&apos;) othe )ise cI (hw) &gt; 0 (3) where α is the backoff weight and h&apos; the backoff history for history h. The principal difficulty in MAP adaptation of this sort is determining the mixing parameters τh in Eq. 2. Following (Bacchiani and Roark, 2003), we chose a single mixing parameter for each model that we built, i.e. τh = τ for all states h in the model. 2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (Roark et al., 2004), which follows the general approach presented in (Collins, 2002). For brevity, we present the algorithm, not in full generality, but for the specific case of n-gram model training. The training set consists of N weighted word lattices produced by the baseline recognizer, and a gold-standard transcription for each of the N lattices. Following (Ro</context>
<context position="12397" citStr="Bacchiani and Roark, 2003" startWordPosition="2038" endWordPosition="2041">ver, this increase in error rate is limited in these experiments, because the majority of the new domain-dependent vocabulary are acronyms System FP MP Baseline 32.7 28.0 MAP estimation 23.7 20.3 Perceptron (FP) 26.8 23.0 Perceptron (MP) – 23.9 Table 1: Recognition on the 1 hour SSNIFR test set using systems obtained by supervised LM adaptation on the 17 hour adaptation set using the two methods, versus the baseline out-of-domain system. which are covered by the Scanmail vocabulary through individual letters. The OOV rate of the SSNIFR test set, using the Scanmail vocabulary is 2%. Following (Bacchiani and Roark, 2003), τh in Eq. 2 is set to 0.2 for all reported MAP estimation trials. Following (Roark et al., 2004), λ in Eq. 4 is also (coincidentally) set to 0.2 for all reported perceptron trials. For the perceptron algorithm, approximately 10 percent of the training data is reserved as a held-out set, for deciding when to stop the algorithm. Table 1 shows the results using MAP estimation and the perceptron algorithm independently. For the perceptron algorithm, the baseline Scanmail system was used to produce the word lattices used in estimating the feature weights. There are two ways to do this. One is to </context>
</contexts>
<marker>Bacchiani, Roark, 2003</marker>
<rawString>Michiel Bacchiani and Brian Roark. 2003. Unsupervised language model adaptation. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 224–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michiel Bacchiani</author>
</authors>
<title>Automatic transcription of voicemail at AT&amp;T.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="9961" citStr="Bacchiani, 2001" startWordPosition="1634" endWordPosition="1635">ges from the target domain, named SSNIFR, will be focused solely on network related problems. It contains frequent mention of various network related acronyms and trouble ticket numbers, rarely (if at all) found in the training corpus of the Scanmail system. To evaluate the transcription accuracy, we used a multipass speech recognition system that employs various unsupervised speaker and channel normalization techniques. An initial search pass produces word-lattice output that is used as the grammar in subsequent search passes. The system is almost identical to the one described in detail in (Bacchiani, 2001). The main differences in terms of the acoustic model of the system are the use of linear discriminant analysis features; use of a 100 hour training set as opposed to a 60 hour training set; and the modeling of the speaker gender which in this system is identical to that described in (Woodland and Hain, 1998). Note that the acoustic model is appropriate for either domain as the messages are collected on a voicemail system of the same type. This parallels the experiments in (Lamel et al., 2002), where the focus was on AM adaptation in the case where the LM was deemed appropriate for either doma</context>
</contexts>
<marker>Bacchiani, 2001</marker>
<rawString>Michiel Bacchiani. 2001. Automatic transcription of voicemail at AT&amp;T. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--8</pages>
<contexts>
<context position="6445" citStr="Collins, 2002" startWordPosition="1032" endWordPosition="1033">e model is then defined as: p* (w |h) = (t α p* (w |h&apos;) othe )ise cI (hw) &gt; 0 (3) where α is the backoff weight and h&apos; the backoff history for history h. The principal difficulty in MAP adaptation of this sort is determining the mixing parameters τh in Eq. 2. Following (Bacchiani and Roark, 2003), we chose a single mixing parameter for each model that we built, i.e. τh = τ for all states h in the model. 2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (Roark et al., 2004), which follows the general approach presented in (Collins, 2002). For brevity, we present the algorithm, not in full generality, but for the specific case of n-gram model training. The training set consists of N weighted word lattices produced by the baseline recognizer, and a gold-standard transcription for each of the N lattices. Following (Roark et al., 2004), we use the lowest WER hypothesis in the lattice as the gold-standard, rather than the reference transcription. The perceptron model is a linear model with k feature weights, all of which are initialized to 0. The algorithm is incremental, i.e. the parameters are updated at each example utterance i</context>
<context position="8399" citStr="Collins, 2002" startWordPosition="1383" endWordPosition="1384">s follows 1. For the example lattice L at time t, find ˆπt such that ˆπt = argmin (w[π] + λΦ(π) · ¯αt) (4) πEL where λ is a scaling constant. 2. For the 0 &lt; k &lt; K features in the feature weight vector ¯αt, ¯αt+1[k] = ¯αt[k] + Φ(ˆπt)[k] − Φ(9L)[k] (5) Note that if ˆπt = 9L, then the features are left unchanged. As shown in (Roark et al., 2004), the perceptron feature weight vector can be encoded in a deterministic weighted finite state automaton (FSA), so that much of the feature weight update involves basic FSA operations, making the training relatively efficient in practice. As suggested in (Collins, 2002), we use the averaged perceptron when applying the model to held-out or test data. After each pass over the training data, the averaged perceptron model is output as a weighted FSA, which can be used by intersecting with a lattice output from the baseline system. 3 Experimental Results We evaluated the language model adaptation algorithms by measuring the transcription accuracy of an adapted voicemail transcription system on voicemail messages received at a customer care line of a telecommunications network center. The initial voicemail system, named Scanmail, was trained on general voicemail </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lamel</author>
<author>J-L Gauvain</author>
<author>G Adda</author>
</authors>
<title>Unsupervised acoustic model training.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>877--880</pages>
<contexts>
<context position="10459" citStr="Lamel et al., 2002" startWordPosition="1723" endWordPosition="1726">e grammar in subsequent search passes. The system is almost identical to the one described in detail in (Bacchiani, 2001). The main differences in terms of the acoustic model of the system are the use of linear discriminant analysis features; use of a 100 hour training set as opposed to a 60 hour training set; and the modeling of the speaker gender which in this system is identical to that described in (Woodland and Hain, 1998). Note that the acoustic model is appropriate for either domain as the messages are collected on a voicemail system of the same type. This parallels the experiments in (Lamel et al., 2002), where the focus was on AM adaptation in the case where the LM was deemed appropriate for either domain. The language model of the Scanmail system is a Katz backoff trigram, trained on hand-transcribed messages of approximately 100 hours of voicemail (1 million words). The model contains 13460 unigram, 175777 bigram, and 495629 trigram probabilities. The lexicon of the Scanmail system contains 13460 words and was compiled from all the unique words found in the 100 hours of transcripts of the Scanmail training set. For every experiment, we report the accuracy of the one-best transcripts obtain</context>
</contexts>
<marker>Lamel, Gauvain, Adda, 2002</marker>
<rawString>L. Lamel, J.-L. Gauvain, and G. Adda. 2002. Unsupervised acoustic model training. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 877–880.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Murat Saraclar</author>
<author>Michael Collins</author>
</authors>
<title>Corrective language modeling for large vocabulary ASR with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="2025" citStr="Roark et al., 2004" startWordPosition="298" endWordPosition="301">n this approach, the main idea is to change the out-of-domain model parameters to match the in-domain distribution. Another approach to language model adaptation would be to change model parameters to correct the errors made by the out-of-domain model on the in-domain data through discriminative training. In such an approach, the baseline recognizer would be used to recognize indomain utterances, and the parameters of the model adjusted to minimize recognition errors. Discriminative training has been used for language modeling, using various estimation techniques (Stolcke and Weintraub, 1998; Roark et al., 2004), but language model adaptation to novel domains is a particularly attractive scenario for discriminative training, for reasons we discuss next. A key requirement for discriminative modeling approaches is training data produced under conditions that are close to testing conditions. For example, (Roark et al., 2004) showed that excluding an utterance from the language model training corpus of the baseline model used to recognize that utterance is essential to getting word error rate (WER) improvements with the perceptron algorithm in the Switchboard domain. In that paper, 28 different language </context>
<context position="6380" citStr="Roark et al., 2004" startWordPosition="1021" endWordPosition="1024">ates how much the out-of-domain prior counts should be relied upon. The model is then defined as: p* (w |h) = (t α p* (w |h&apos;) othe )ise cI (hw) &gt; 0 (3) where α is the backoff weight and h&apos; the backoff history for history h. The principal difficulty in MAP adaptation of this sort is determining the mixing parameters τh in Eq. 2. Following (Bacchiani and Roark, 2003), we chose a single mixing parameter for each model that we built, i.e. τh = τ for all states h in the model. 2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (Roark et al., 2004), which follows the general approach presented in (Collins, 2002). For brevity, we present the algorithm, not in full generality, but for the specific case of n-gram model training. The training set consists of N weighted word lattices produced by the baseline recognizer, and a gold-standard transcription for each of the N lattices. Following (Roark et al., 2004), we use the lowest WER hypothesis in the lattice as the gold-standard, rather than the reference transcription. The perceptron model is a linear model with k feature weights, all of which are initialized to 0. The algorithm is increme</context>
<context position="8129" citStr="Roark et al., 2004" startWordPosition="1340" endWordPosition="1343">for π, which contains the count within the path π of each feature. In our case, these are unigram, bigram and trigram feature counts. Let ¯αt E RK be the K-dimensional feature weight vector of the perceptron model at time t. The perceptron model feature weights are updated as follows 1. For the example lattice L at time t, find ˆπt such that ˆπt = argmin (w[π] + λΦ(π) · ¯αt) (4) πEL where λ is a scaling constant. 2. For the 0 &lt; k &lt; K features in the feature weight vector ¯αt, ¯αt+1[k] = ¯αt[k] + Φ(ˆπt)[k] − Φ(9L)[k] (5) Note that if ˆπt = 9L, then the features are left unchanged. As shown in (Roark et al., 2004), the perceptron feature weight vector can be encoded in a deterministic weighted finite state automaton (FSA), so that much of the feature weight update involves basic FSA operations, making the training relatively efficient in practice. As suggested in (Collins, 2002), we use the averaged perceptron when applying the model to held-out or test data. After each pass over the training data, the averaged perceptron model is output as a weighted FSA, which can be used by intersecting with a lattice output from the baseline system. 3 Experimental Results We evaluated the language model adaptation </context>
<context position="12495" citStr="Roark et al., 2004" startWordPosition="2058" endWordPosition="2061">dependent vocabulary are acronyms System FP MP Baseline 32.7 28.0 MAP estimation 23.7 20.3 Perceptron (FP) 26.8 23.0 Perceptron (MP) – 23.9 Table 1: Recognition on the 1 hour SSNIFR test set using systems obtained by supervised LM adaptation on the 17 hour adaptation set using the two methods, versus the baseline out-of-domain system. which are covered by the Scanmail vocabulary through individual letters. The OOV rate of the SSNIFR test set, using the Scanmail vocabulary is 2%. Following (Bacchiani and Roark, 2003), τh in Eq. 2 is set to 0.2 for all reported MAP estimation trials. Following (Roark et al., 2004), λ in Eq. 4 is also (coincidentally) set to 0.2 for all reported perceptron trials. For the perceptron algorithm, approximately 10 percent of the training data is reserved as a held-out set, for deciding when to stop the algorithm. Table 1 shows the results using MAP estimation and the perceptron algorithm independently. For the perceptron algorithm, the baseline Scanmail system was used to produce the word lattices used in estimating the feature weights. There are two ways to do this. One is to use the lattices produced after FP; the other is to use the lattices produced after MP. These resu</context>
</contexts>
<marker>Roark, Saraclar, Collins, 2004</marker>
<rawString>Brian Roark, Murat Saraclar, and Michael Collins. 2004. Corrective language modeling for large vocabulary ASR with the perceptron algorithm. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>M Weintraub</author>
</authors>
<title>Discriminitive language modeling.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th Hub-5 Conversational Speech Recog nition Workshop.</booktitle>
<contexts>
<context position="2004" citStr="Stolcke and Weintraub, 1998" startWordPosition="294" endWordPosition="297">omain model is relied upon. In this approach, the main idea is to change the out-of-domain model parameters to match the in-domain distribution. Another approach to language model adaptation would be to change model parameters to correct the errors made by the out-of-domain model on the in-domain data through discriminative training. In such an approach, the baseline recognizer would be used to recognize indomain utterances, and the parameters of the model adjusted to minimize recognition errors. Discriminative training has been used for language modeling, using various estimation techniques (Stolcke and Weintraub, 1998; Roark et al., 2004), but language model adaptation to novel domains is a particularly attractive scenario for discriminative training, for reasons we discuss next. A key requirement for discriminative modeling approaches is training data produced under conditions that are close to testing conditions. For example, (Roark et al., 2004) showed that excluding an utterance from the language model training corpus of the baseline model used to recognize that utterance is essential to getting word error rate (WER) improvements with the perceptron algorithm in the Switchboard domain. In that paper, 2</context>
</contexts>
<marker>Stolcke, Weintraub, 1998</marker>
<rawString>A. Stolcke and M. Weintraub. 1998. Discriminitive language modeling. In Proceedings of the 9th Hub-5 Conversational Speech Recog nition Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P C Woodland</author>
<author>T Hain</author>
</authors>
<title>HTK Hub 5E System.</title>
<date>1998</date>
<booktitle>In The Proceedings of the 9th Hub-5 Conversational Speech Recognition Workshop.</booktitle>
<publisher>The</publisher>
<contexts>
<context position="10271" citStr="Woodland and Hain, 1998" startWordPosition="1690" endWordPosition="1693">used a multipass speech recognition system that employs various unsupervised speaker and channel normalization techniques. An initial search pass produces word-lattice output that is used as the grammar in subsequent search passes. The system is almost identical to the one described in detail in (Bacchiani, 2001). The main differences in terms of the acoustic model of the system are the use of linear discriminant analysis features; use of a 100 hour training set as opposed to a 60 hour training set; and the modeling of the speaker gender which in this system is identical to that described in (Woodland and Hain, 1998). Note that the acoustic model is appropriate for either domain as the messages are collected on a voicemail system of the same type. This parallels the experiments in (Lamel et al., 2002), where the focus was on AM adaptation in the case where the LM was deemed appropriate for either domain. The language model of the Scanmail system is a Katz backoff trigram, trained on hand-transcribed messages of approximately 100 hours of voicemail (1 million words). The model contains 13460 unigram, 175777 bigram, and 495629 trigram probabilities. The lexicon of the Scanmail system contains 13460 words an</context>
</contexts>
<marker>Woodland, Hain, 1998</marker>
<rawString>P.C. Woodland and T. Hain. 1998. The September 1998 HTK Hub 5E System. In The Proceedings of the 9th Hub-5 Conversational Speech Recognition Workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>