<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.93421725">
Conceptual Analysis of Garden-Path Sentences
Michael J. Pazzani
The MITRE Corporation
Bedford, MA 01730
</note>
<email confidence="0.593975">
ABSTRACT
</email>
<bodyText confidence="0.999561428571429">
By integrating syntactic and semantic processing, our parser
(LAZY) is able to deterministically parse sentences which
syntactically appear to be garden path sentences although native
speakers do not need conscious reanalysis to understand them.
LAZY comprises an extension to conceptual analysis which yields an
explicit representation of syntactic information and a flexible
interaction between semantic and syntactic knowledge.
</bodyText>
<sectionHeader confidence="0.980031" genericHeader="method">
I. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.954258265625">
The phenomenon we wish to model is the understanding of
garden path sentences (GPs) by native speakers of English.
Parsers designed by Marcus [811 and Shieber [83] duplicate a
reader&apos;s first reaction to a GP such as (1) by rejecting it as
ungrammatical, even though the sentence is, in some sense,
grammatical.
(1)The horse raced past the barn fell.
Thinking first that •raced • is the main verb, most readers
become confused when they see the word, •fell&amp;quot;. Our parser,
responding like the average reader, initially makes this mistake, but
later determines that &amp;quot;fell • is intended to be the main verb, and
•raced • is a passive participle modifying •horse.
We are particularly interested in a class of sentences which
Shieber&apos;s and Marcus&apos; parsers will consider to be GPs and reject as
ungrammatical although many people do not. For example, most
people can easily understand (2) and (3) without conscious
reanalysis.
(2) Three percent of the courses filled with freshmen were
cancelled.
(3)The chicken cooked with broccoli is delicious.
The syntactic structure of (2) is similar to that of sentence (1).
However, most readers do not initially mistake &amp;quot;filled • to be the
Current Address:
The Aerospace Corporation
P.O. Box 92957
Los Angeles, CA 90009
main verb. LAZY goes a step further than previous parsers by
modeling the average readers ability to deterministically recognize
sentences (2) and (3).
If &apos;filled were the main verb, then its subject would be the
noun phrase &apos;three percent of the courses* and the selectional
restrictions [KATZ 631 associated with *to fill&apos; would be violated.
LAZY prefers not to violate selectional restrictions. Therefore, when
processing (2), LAZY will delay deciding the relationship among
•filled • and •three percent of the courses&apos; until the word •were • is
seen and it is clear that &apos;filled • is a passive participle. We call
sentences like (2) semantically disambiguatable garden path
sentences (SDGPs). Crain and Croker (79) have reported
experimental evidence which demonstrates that not all potential
garden path sentences are actual garden paths.
LAZY uses a language recognition scheme capable of waiting
long enough to select the correct parse of both (1) and (2) without
guessing and backing up [MARCUS 761. However, when conceptual
links are strong enough, LAZY is careless and will assume one
syntactic (and therefore semantic) representation before waiting long
enough to consider alternatives. We claim that we can model the
performance of native English speakers understanding SDGPs and
misunderstanding GPs by using this type of strategy. For example,
when processing (1), LAZY assumes that •the horse&amp;quot; is the subject
of the main verb &amp;quot;raced • as soon as the word •raced • is seen
because the selectional restrictions associated with •raced • are
satisfied.
One implication of LAZY&apos;s parsing strategy, is that people
could understand some true GPs if they were more careful and
waited longer to select among alternative parses. Experimental
evidence [Matthews 791 suggests that people can recognize garden
path sentences as grammatical if properly prepared. Mathhews
found that subjects recognized sentences such as (2) as being
grammatical, and after doing so, when later presented with a
sentence like (1) will also judge it to be grammatical. (In a more
informal experiment, we have found that colle2.gues who read papers
on GPs, understand new GPs easily by the end of a paper.) LAZY
exhibits this behavior by being more careful after encountering
SDGPs or when reanalyzing garden path sentences.
</bodyText>
<page confidence="0.999178">
486
</page>
<sectionHeader confidence="0.870975" genericHeader="method">
II. SYNTAX IN A CONCEPTUAL ANALYZER
</sectionHeader>
<bodyText confidence="0.997110375">
The goal of conceptual analysis is to map natural language
text into memory structures that represent the meaning of the text.
It is claimed that this mapping can be accomplished without a prior
syntactic analysis, relying instead on a variety of knowledge sources
including expectations from both word definitions and inferential
memory (see Illiesbeck 761, 1Schank 801, 1Gershman 821, (Birnbaum
811, (Pazzani 83) and (Dyer 83)). Given this model of processing, in
sentence (4),
</bodyText>
<listItem confidence="0.429728">
(4) Mlry kicked John.
</listItem>
<bodyText confidence="0.958662672727273">
how is it possible to tell who kicked whom? There is a very
simple answer: Syntax. Sentence (9) is a simple active sentence
whose verb is &apos;to kick&apos;. &apos;Mary&apos; is the subject of the sentence and
&apos;Bill&apos; is the direct object. There may be a more complicated
answer, if, for example, John and Mary are married, Mary is ill-
tempered, John is passive, and Mary has just found out that John
has been unfaithful. In this case, it is possible to expect that Mary
might hit John, and confirm this prediction by noticing that the
words in (4) refer to Mary, John, and hitting. In fact, if this
prediction was formulated and the sentence were &apos;John kicked
Mary&apos; we might take it to mean &apos;Mary kicked John&apos; and usually
notice that the speaker had made a mistake. Although we feel that
this type of processing is an important part of understanding, it
cannot account for ail language comprehension. Certainly, (4) can
be understood in contexts which do not predict that Mary might bit
John. requiring syntactic knowledge to determine who kicked whom.
Ila. Precedes and Follows
Syntactic information is represented in a conceptual analyzer,
in a number of ways, the simplest of which is the notion of one word
preceding or following another. Such information is encoded as a
positional predicate in the test of a type of production which
Ricsbeek calls a request. The test also contains a semantic predicate
(i.e., the selectional restrictions). A set of requests make up the
definition of a word. For example, the definition of &apos;kick&apos; has three
requests:
REQ 1: Test: true
Action: Add the meaning structure
for &apos;kick&apos; to an ordered
list of concepts typically
called the C-list.
The action of a request typically builds or connects concepts.
Although people who build conceptual analyzers have reasons for
not building a representation of the syntax of a sentence, there is no
reason that they can not. LAZY builds syntactic representations.
fib. Requests in LAZY
LAZY, unlike other conceptual analyzers, separates the
syntactic (or positional) information from the selections] restrictions
by dividing the test part of request into a number of facets. There
are three reasons for doing this. First, it allows for a distinction
between different kinds of knowledge. Secondly, it is possible to
selectively ignore some facets. Finally, it permits a request to access
the information encoded in other requests.
In many conceptual analyzers, some syntactic information is
hidden in the control structure. At certain times during the parse,
not all of the request are considered. For example, in (5) it is
necessary to delay considering a request.
(5) Who is Mary recruiting?
To avoid understanding the first three words of sentence (5) as
a complete sentence, &apos;Who is Mary”, some request from &apos;is&apos; must
be delayed until the word &apos;recruiting&apos; is processed. In LAZY, the
time that a request can be considered is explicitly represented as a
facet of the request. Additionally, separate tests exist for the
selectional restriction, the expected part of speech, and the expected
sentential position.
In LAZY, REQ2 of &apos;kick&amp;quot; would be:
</bodyText>
<sectionHeader confidence="0.716074" genericHeader="method">
REQ2a: Position: Subject of &apos;kick&apos;
Restriction: Animate
Action: Make the concept
</sectionHeader>
<bodyText confidence="0.990199294117647">
found the syntactic
subject of &apos;kick&apos;
Part-Of-Speech: (noun pronoun)
Time: Clause-Type-Known?
In REQ2a, Subject is a function which examines the state of
the C-list and returns the proper constituent as a function of the
clause type. In an active declarative sentence, the subject precedes
the verb, in a passive sentence it may follow the word &apos;by&apos;, etc.
(The usage of &apos;subject&apos; is incorrect in the usual sense of the word.)
The Time facet of REQ2a states that the request should be
considered only after the type of the clause is know. The predicates
which are included in a request to control the time of consideration
are: End-Of-Noun-Group?, Clause-Type-Known?, Head-Of-
Immediate-Noun-Group?, and End-Of-Sentence?. These operate by
examining the C-list in a manner similar to the positional predicates.
The other facets of REQ2a state that the subject of &apos;kick&apos; must be
animate, and should be a noun or a pronoun.
</bodyText>
<footnote confidence="0.520973">
REQ2: Test: Is there a concept
Action: preceding the concept for
REQ3: Test: &apos;kick&apos; which is animate?
Action: Is there a concept
following the concept for
&apos;kick&apos; which is a physical object?
</footnote>
<page confidence="0.976124">
487
</page>
<sectionHeader confidence="0.899351" genericHeader="method">
III GARDEN PATH SENTENCES
</sectionHeader>
<bodyText confidence="0.986215421052631">
Several different types of local ambiguities cause GPs.
Misunderstanding sentences 1, 2 and 3 is a result of confusing a
participle for the main verb of a sentence. Although there are other
types of GPs (e.g., imperative and yes/no questions with an initial
&amp;quot;have), we will only demonstrate how LAZY understands or
misunderstands passive participle and main verb conflicts.
Passive participles and past main verbs are indicated by a
&amp;quot;ed&amp;quot; suffix on the verb form. Therefore, the definition of &amp;quot;ed&amp;quot; must
discriminate between these two cases. The definition of •ed&amp;quot; is
shown in Figure 3a. A simpler definition for &amp;quot;et!&apos; is possible if the
morphology routine reconstructs sentences so that the suffix of a
verb is a separate &apos;word&apos; which precedes the verb. The definition
of •ed&amp;quot; is shown in Figure 3a. Throughout this discussion, we will
use the name Root for the verb immediately following &amp;quot;ed&amp;quot; on the
C-list.
If Root appears to be passive
Then mark Root as a passive participle.
Otherwise if Root does not appear to be passive
Then note the tense of Root.
</bodyText>
<figureCaption confidence="0.964692">
Figure 3a. Definition of &apos;et!&amp;quot;.
</figureCaption>
<bodyText confidence="0.993548">
It is safe to consider this request only at the end of the
sentence or if a verb is seen following Root which could be the main
verb. One test that is used to determine if Root could be passive is:
</bodyText>
<listItem confidence="0.699384125">
1. There is no known main verb seen preceding &amp;quot;ed&amp;quot;, and
2. The word which would be the subject of Root if Root
were active agrees with the selectional restrictions for
the word which would precede Root if Root were passive
(i.e., the selectional restrictions of the direct object if
there is no indirect object), and
3. There is a verb which could be the main verb following
Root.
</listItem>
<figureCaption confidence="0.88257">
Figure 3b.
</figureCaption>
<bodyText confidence="0.9552495">
One test performed to determine if Root does not appear to be
passive is:
</bodyText>
<listItem confidence="0.939885">
1. The verb is not marked as passive, and
2. The word which would be the subject of Root if Root
were active agrees with the selectional restrictions for
the subject.
</listItem>
<figureCaption confidence="0.879998">
Figure 3c.
</figureCaption>
<bodyText confidence="0.982319857142857">
Note that these tests rely on the fact that one request can
examine the semantic or syntactic information encoded in another
request.
As we have presented requests so far, four separate tests must
be true to fire a request (i.e., to execute the request&apos;s action): a word
must be found in a particular position in the sentence, the word
must have the proper part of speech, the word must meet the
selectional restrictions, and the parse must be in a state in which it
is safe to execute the positional predicate. We have relaxed the
requirement that the selectional restrictions be met if all of the other
tests are true. This avoids problems present in some previous
conceptual analyzers which are unable to parse some sentences such
as &amp;quot;Do rocks talk?&amp;quot;. Additionally, we have experimented with not
requiring that the Time test succeed if all other tests have passed
unless we are reanalyzing a sentence that we have previously not
been able to parse. We will demonstrate that this yields the
performance that people exhibit when comprehending GPs.
LAZY processes a sentence one word at a time from left to
right. When processing a word, its representation is added to the
C-list and its requests are activated. Next, all active requests are
considered. When a request is fired, a syntactic structure is built by
connecting two or more constituents on the C-list. At the end of a
parse the C-list should contain one constituent as the root of a tree
describing the structure of the sentence.
Sentence (6) is a GP which people normally have trouble
reading:
(6)The boat sailed across the river sank.
When parsing this sentence, LAZY reads the word &amp;quot;the&apos; and
adds it to the C-list. Next, the word &amp;quot;boat&amp;quot; is added to the C-list.
A request from &apos;the&amp;quot; looking for a noun to modify is considered and
all tests pass. This request constructs a noun phrase with &amp;quot;the&amp;quot;
modifying &apos;boat&amp;quot;. Next, &amp;quot;ed&amp;quot; is added to the C-list. All of its
requests look for a verb following, so they can not fire yet. The
work *sail&apos; is added to the C-list. The request of •ed• which sets
the tense of the immediately following verb is considered. It check
the semantic features of &amp;quot;boat&apos; and finds that they match the
selectional restrictions required of the subject of &apos;sail&apos;. The action
of this request is executed, in spite of the fact that its Time reports
that it is not safe to do so. Next, a request from &amp;quot;sail* finds that
that &apos;boat&amp;quot; could serve as the subject since it precedes the verb in
what is erroneously assumed to be an active clause. The structure
built by this request notes that &amp;quot;boat&amp;quot; is the subject of &amp;quot;sail&apos;. A
request looking for the direct object of &amp;quot;sail&apos; is then considered. It
notices that the subject has been found and it is not animate,
therefore &amp;quot;sail&amp;quot; is not being used transitively. This request is
deactivated. The word &amp;quot;across* is added to the C-list and •the
river&apos; is then parsed analogously to &amp;quot;the boat&apos;. Next, a request
from &amp;quot;across&amp;quot; looking for the object of the preposition is considered...
and finds the noun phrase, &amp;quot;the river&amp;quot;. Another request is then
activated and attaches this prepositional phrase to &amp;quot;sail&amp;quot;. At this
point in the parse, we have built a structure describing an active
sentence &amp;quot;The boat sailed across the river.&amp;quot; and the C-list contains
one constituent. After adding the verb suffix and &apos;sink&apos; to the C-
list we find that &amp;quot;sink&amp;quot; cannot find a subject and there are two
constituents left on the C-list. This is an error condition and the
sentence must be reanalyzed more carefully.
</bodyText>
<page confidence="0.997772">
488
</page>
<bodyText confidence="0.949286435483871">
It is possible to recover from misreading some garden path
sentences by reading more carefully. In LAZY, this corresponds to
not letting a request fire until all the tests are true. Although other
recovery schemes are possible, our current implementation starts
over from the beginning. When reanalyzing (6), the request from
•ed&apos; which sets the tense of the main verb is not fired because all
facets of its test never become true. This request is deactivated
when the word &amp;quot;sank&apos; is read and another request from &apos;ed • notes
that •sailed&amp;quot; is a participle. At the end of the parse there is one
constituent left on the C-list, similar to that which would be
produced when processing &apos;The boat which was sailed across the
river sank&apos;.
It is possible to parse SDGPs without reanalysis. For example,
most readers easily understand (7) which is simplified from
[Birnbaum 811.
(7)The plane stuffed with marijuana crashed.
Sentence (7) is parsed analogously to (6) until the word &apos;stuff*
is encountered. A request from &amp;quot;ed&apos; tries to determine the sentence
type by testing if &apos;plane&amp;quot; could be the subject of *stuff&apos; and fails
because •plane&amp;quot; does not meet the selectional restrictions of &apos;stuff&amp;quot;.
This request also checks to see if &apos;stuff&apos; could be passive, but fails
at this time (see condition 3 of Figure 3b). A request from &amp;quot;stuff&apos;
then finds that &apos;plane&apos; is in the default position to be the subject,
but its action is not executed because two of the four tests have not
passed: the selectional restrictions are violated and it is too early to
consider the positional predicate because the sentence type is
unknow. A request looking for the direct object of &apos;stuff&apos; does not
succeed at this time because the default location of the direct object
follows the verb. Next, the prepositional phrase •with marijuana&apos; is
parsed analogously to &apos;across the lake&amp;quot; in (6). After the suffix of
&apos;crash&apos; (i.e., &apos;ed&apos;) and &amp;quot;crash&apos; are added to the C-list; the request
from the •ed&apos; of &amp;quot;stuff&apos; is considered, and it finds that &apos;stuff&apos; could
be a passive participle because &apos;plane&apos; can fulfill the selectional
restrictions of the direct object of *stuff&apos;. A request from &apos;stuff&apos;
then notes that &apos;plane&apos; is the direct object, and a request from the
&apos;ed&apos; of &apos;crash&apos; marks the tense of &apos;crash&apos;. Finally, &apos;crash&apos; finds
&apos;plane&apos; as its subject. The only constituent of the C-list is a tree
similar to that which would be produced by &amp;quot;The plane which was--
stuffed with marijuana crashed&amp;quot;.
There are some situations in which garden path sentences
cannot be understood even with a careful reanalysis. For example,
many people have problems understanding sentence (8).
(8)The canoe floated down the river sank.
To help some people understand this sentence, it is necessary
to inform them that *float&apos; can be a transitive verb by giving a
simple example sentence such as &apos;The man floated the canoe&apos;. Our
parser would fail to reanalyze this sentence if it did not have a
request associated with &apos;float&amp;quot; which looks for a direct object.
We have been rather conservative in giving rules to determine
when &amp;quot;ed&amp;quot; indicates a past participle instead of the past tense. In
particular, condition 3 of Figure 3b may not be necessary. By
removing it, as soon as &apos;the plane stuffed&apos; is processed we would
assume that &amp;quot;stuffed&amp;quot; is a participle phrase. This would not change
the parse of (7). However, there would be an impact when parsing
(9).
(9)The chicken cooked with broccoli.
With condition 3 removed, this parses as a noun phrase. With
it included, (9) would currently be recognized as a sentence. We
have decided to include condition 3, because it delays the resolving
of this ambiguity until both possibilities are clear. It is our belief
that this ambiguity should be resolved by appealing to episodic and
conceptual knowledge more powerful than selectional restrictions.
</bodyText>
<sectionHeader confidence="0.997118" genericHeader="method">
IV. PREVIOUS WORK
</sectionHeader>
<bodyText confidence="0.999679151515151">
In PARSIFAL, Marcus&apos; parser, the misunderstanding of GPs is
caused by having grammar rules which can look ahead only three
constituents. To deterministically parse a GP such as (1), it is
necessary to have a look ahead buffer of at least four constituents.
PARSIFAL&apos;s grammar rules make the same guess that readers make
when presented with a true GP. For a participle/main verb conflict,
readers prefer to choose a main verb. However, PARSIFAL will
make the same guess when processing SDGPs. Therefore,
PARSIFAL fails to parse some sentences (SDGPs) deterministically
which people can parse without conscious backtracking. In LAZY,
the C-list corresponds to the look ahead buffer. When parsing most
sentences, the C-list will contain at most three constituents.
However, when understanding a SDGP or reanalyzing a true garden
path sentence, there are four constituents in the C-list. Instead of
modeling the misunderstanding of GPs, by limiting the size of the
look-ahead buffer and the look ahead in the grammar, LAZY models
this phenomenon by deciding on a syntactic representation before
waiting long enough to disambiguate on a purely syntactic basis
when semantic expectations are strong enough.
Shieber models the misunderstanding of GPs in a LALR(1)
parser lAho 771 by the selection of an incorrect reduction in a
reduce-reduce conflict. In a participle/main verb conflict, there is a
state in his parser which requires choosing between a participle
phrase and a verb phrase. Instead of guessing like PARSIFAL,
Shieber&apos;s parser looks up the &apos;lexical preference&amp;quot; of the verb. Some
verbs are marked as preferring participle forms; others prefer being
main verbs. While this lexical preference can account for the
understanding of SDGPs and the misunderstanding of GPs in any
one particular example, it is not a very general mechanism. One
implication of using lexical preference to select the correct form is
that some verbs are only understood or misunderstood as main verbs
and others only as participles. If this were true, then sentences (10a)
and (10b) would both be either easily understood or GPs.
</bodyText>
<footnote confidence="0.549349333333333">
(l0a) No freshmen registered for Calculus failed.
(10b) No car registered in California should be driven in
Mexico.
</footnote>
<page confidence="0.998359">
489
</page>
<bodyText confidence="0.99991125">
We find that most people easily understand (10b), but require
conscious backtracking to understand (I0a). Instead of using a
predetermined preference for one syntactic form, LAZY utilizes
semantic clues to favor a particular parse.
</bodyText>
<sectionHeader confidence="0.933462" genericHeader="method">
V. FUTURE WORK
</sectionHeader>
<bodyText confidence="0.997961857142857">
We intend to extend LAZY by allowing it to consult and
episodic memory during parsing. The format that we have chosen
for requests can be augmented by adding an EPISODIC facet to the
test. This will enable expectation to predict individual objects in
addition to semantic features. We have seen examples of potential
garden path sentences which we speculate are misunderstood or
understood by consulting world knowledge (e.g., 11 and 12)
</bodyText>
<listItem confidence="0.62879625">
(11) At MIT, ninety five percent of the freshmen registered
for Calculus passed.
(12) At MIT, five percent of the freshmen registered for
Calculus failed.
</listItem>
<bodyText confidence="0.976566214285714">
We have observed that more people mistake &apos;registered&apos; for
the main verb in (11) than (12). This could be accounted forby the
fact that the proposition that &apos;At MIT, ninety five percent of the
freshmen registered for Calculus&apos; is more easily accepted than &apos;At
MIT, five percent of the freshmen registered for Calculus&apos;.
Evidence such as this suggests that semantic and episodic processing
are done at early stages of understanding.
VI. CONCLUSION
We have augmented the basic request consideration algorithm
of a conceptual analyzer to include information to determine the
time that an expectation should be considered and shown that by
ignoring this information when syntactic and semantic expectations
agree, we can model the performance of native English speakers
understanding and misunderstanding garden path sentences.
</bodyText>
<sectionHeader confidence="0.979337" genericHeader="method">
VII. ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.996126333333333">
This work was supported by USAF Electronics System
Division under Air Force contract F19628-84-C-0001 and monitored
by the Rome Air Development Center.
</bodyText>
<sectionHeader confidence="0.954863" genericHeader="method">
BIBLIOGRAPHY
</sectionHeader>
<reference confidence="0.999526735294118">
Birnbaum, L. and M. Selfridge, &apos;Conceptual Analysis of
Natural Language&amp;quot;, in Inside Artificial Intelligence: Five Programs
Plus Miniatures, Hillsdale, NJ: Lawrence Erlbaum Associates, 1981.
Crain, S. and P. Coker, °A Semantic Constraint on Parsing&apos;,
Paper presented at Linguistic Society of America Annual Meeting.
University of California at Irvine, 1979.
Dyer, M.G., In-Depth Understanding: A Computer Model of
Integrated Processing for Narrative Corn prehension, Cambridge,
MA: The MIT Press, 1983.
Gershman, A.V., &apos;A Framework for Conceptual Analyzers&apos;, in
Strategies for Natural Language Processing, Hillsdale, NJ: Lawrence
Erlbaum Associates, 1982.
Katz, J. S. and J. A. Fodor, &apos;The Structure of Semantic
Theory&apos;, in Language, 39, 1963.
Marcus, M., A Theory of Syntactic Recognition for Natural
Language, Cambridge, MA: The MIT Press, 1980.
Marcus, M., &amp;quot;Wait-and-See Strategies for Parsing Natural
Language&apos;, MIT WP-75, Cambridge, MA: 1974.
Matthews, R., &apos;Are the Grammatical Sentences of a Language
of Recursive Set?&apos;, in Systhese 40, 1979.
Pazzani, M. J., &apos;Interactive Script Instantiation&apos;, in
Proceedings of the National Conference on Artificial Intelligence,
1983.
Riesbeck, C. and R. C. Schank, &apos;Comprehension by
Computer: Expectation Based Analysis of Sentences in Context&apos;,
Research Report #78, Dept. of Computer Science, Yale University,
1976.
Schank, R. C. and L. Birnbaum, Memory, Meaning, and
Syntax, Research Report 189, Yale University Department of
Computer Science, 1980.
Shieber, S. M., *Sentence Disambiguation by a Shift-Reduce
Parsing Technique&apos;, 21st Annual Meeting of the Association for
Computational Lias2j2ja, Association for Computational
Linguistics, 1983.
</reference>
<page confidence="0.998265">
490
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.982260">
<title confidence="0.999529">Conceptual Analysis of Garden-Path Sentences</title>
<author confidence="0.999999">Michael J Pazzani</author>
<affiliation confidence="0.999207">The MITRE Corporation</affiliation>
<address confidence="0.999928">Bedford, MA 01730</address>
<abstract confidence="0.99792475">By integrating syntactic and semantic processing, our parser (LAZY) is able to deterministically parse sentences which syntactically appear to be garden path sentences although native speakers do not need conscious reanalysis to understand them. LAZY comprises an extension to conceptual analysis which yields an explicit representation of syntactic information and a flexible interaction between semantic and syntactic knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Birnbaum</author>
<author>M Selfridge</author>
</authors>
<title>Conceptual Analysis of Natural Language&amp;quot;,</title>
<date>1981</date>
<booktitle>in Inside Artificial Intelligence: Five Programs Plus Miniatures,</booktitle>
<location>Hillsdale, NJ: Lawrence</location>
<marker>Birnbaum, Selfridge, 1981</marker>
<rawString>Birnbaum, L. and M. Selfridge, &apos;Conceptual Analysis of Natural Language&amp;quot;, in Inside Artificial Intelligence: Five Programs Plus Miniatures, Hillsdale, NJ: Lawrence Erlbaum Associates, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>P Coker</author>
</authors>
<title>A Semantic Constraint on Parsing&apos;, Paper presented at Linguistic Society of America Annual Meeting. University of California at Irvine,</title>
<date>1979</date>
<marker>Crain, Coker, 1979</marker>
<rawString>Crain, S. and P. Coker, °A Semantic Constraint on Parsing&apos;, Paper presented at Linguistic Society of America Annual Meeting. University of California at Irvine, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Dyer</author>
</authors>
<title>In-Depth Understanding: A Computer Model of Integrated Processing for Narrative Corn prehension,</title>
<date>1983</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA:</location>
<marker>Dyer, 1983</marker>
<rawString>Dyer, M.G., In-Depth Understanding: A Computer Model of Integrated Processing for Narrative Corn prehension, Cambridge, MA: The MIT Press, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Gershman</author>
</authors>
<title>A Framework for Conceptual Analyzers&apos;,</title>
<date>1982</date>
<booktitle>in Strategies for Natural Language Processing,</booktitle>
<location>Hillsdale, NJ: Lawrence</location>
<marker>Gershman, 1982</marker>
<rawString>Gershman, A.V., &apos;A Framework for Conceptual Analyzers&apos;, in Strategies for Natural Language Processing, Hillsdale, NJ: Lawrence Erlbaum Associates, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Katz</author>
<author>J A Fodor</author>
</authors>
<title>The Structure of Semantic Theory&apos;,</title>
<date>1963</date>
<journal>in Language,</journal>
<volume>39</volume>
<marker>Katz, Fodor, 1963</marker>
<rawString>Katz, J. S. and J. A. Fodor, &apos;The Structure of Semantic Theory&apos;, in Language, 39, 1963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language,</title>
<date>1980</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA:</location>
<marker>Marcus, 1980</marker>
<rawString>Marcus, M., A Theory of Syntactic Recognition for Natural Language, Cambridge, MA: The MIT Press, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
</authors>
<title>Wait-and-See Strategies for Parsing Natural Language&apos;,</title>
<date>1974</date>
<booktitle>MIT WP-75,</booktitle>
<location>Cambridge, MA:</location>
<marker>Marcus, 1974</marker>
<rawString>Marcus, M., &amp;quot;Wait-and-See Strategies for Parsing Natural Language&apos;, MIT WP-75, Cambridge, MA: 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Matthews</author>
</authors>
<title>Are the Grammatical Sentences of a Language of Recursive Set?&apos;,</title>
<date>1979</date>
<booktitle>in Systhese 40,</booktitle>
<marker>Matthews, 1979</marker>
<rawString>Matthews, R., &apos;Are the Grammatical Sentences of a Language of Recursive Set?&apos;, in Systhese 40, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Pazzani</author>
</authors>
<title>Interactive Script Instantiation&apos;,</title>
<date>1983</date>
<booktitle>in Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<marker>Pazzani, 1983</marker>
<rawString>Pazzani, M. J., &apos;Interactive Script Instantiation&apos;, in Proceedings of the National Conference on Artificial Intelligence, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Riesbeck</author>
<author>R C Schank</author>
</authors>
<title>Comprehension by Computer: Expectation Based Analysis of Sentences in Context&apos;,</title>
<date>1976</date>
<tech>Research Report #78,</tech>
<institution>Dept. of Computer Science, Yale University,</institution>
<marker>Riesbeck, Schank, 1976</marker>
<rawString>Riesbeck, C. and R. C. Schank, &apos;Comprehension by Computer: Expectation Based Analysis of Sentences in Context&apos;, Research Report #78, Dept. of Computer Science, Yale University, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
<author>L Birnbaum</author>
<author>Memory</author>
</authors>
<title>Meaning, and Syntax,</title>
<date>1980</date>
<journal>Research Report</journal>
<volume>189</volume>
<institution>Yale University Department of Computer Science,</institution>
<marker>Schank, Birnbaum, Memory, 1980</marker>
<rawString>Schank, R. C. and L. Birnbaum, Memory, Meaning, and Syntax, Research Report 189, Yale University Department of Computer Science, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Sentence Disambiguation by a Shift-Reduce Parsing Technique&apos;,</title>
<date>1983</date>
<booktitle>21st Annual Meeting of the Association for Computational Lias2j2ja, Association for Computational Linguistics,</booktitle>
<marker>Shieber, 1983</marker>
<rawString>Shieber, S. M., *Sentence Disambiguation by a Shift-Reduce Parsing Technique&apos;, 21st Annual Meeting of the Association for Computational Lias2j2ja, Association for Computational Linguistics, 1983.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>