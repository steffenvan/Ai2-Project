<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.977811">
Medical Relation Extraction with Manifold Models
</title>
<author confidence="0.823085">
Chang Wang
</author>
<note confidence="0.8559635">
IBM T. J. Watson Research Center
Yorktown Heights, New York, 10598
</note>
<email confidence="0.615516">
changwangnk@gmail.com
</email>
<note confidence="0.852559">
James Fan
IBM T. J. Watson Research Center
Yorktown Heights, New York, 10598
</note>
<email confidence="0.885199">
fanj@us.ibm.com
</email>
<sectionHeader confidence="0.996204" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999724">
In this paper, we present a manifold model
for medical relation extraction. Our model
is built upon a medical corpus containing
80M sentences (11 gigabyte text) and de-
signed to accurately and efficiently detect
the key medical relations that can facilitate
clinical decision making. Our approach
integrates domain specific parsing and typ-
ing systems, and can utilize labeled as well
as unlabeled examples. To provide users
with more flexibility, we also take label
weight into consideration. Effectiveness
of our model is demonstrated both theo-
retically with a proof to show that the so-
lution is a closed-form solution and exper-
imentally with positive results in experi-
ments.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996295491525424">
There exists a vast amount of knowledge sources
and ontologies in the medical domain. Such in-
formation is also growing and changing extremely
quickly, making the information difficult for peo-
ple to read, process and remember. The combi-
nation of recent developments in information ex-
traction and the availability of unparalleled medi-
cal resources thus offers us the unique opportunity
to develop new techniques to help healthcare pro-
fessionals overcome the cognitive challenges they
face in clinical decision making.
Relation extraction plays a key role in informa-
tion extraction. Using question answering as an
example (Wang et al., 2012): in question analy-
sis, the semantic relations between the question
focus and each term in the clue can be used to
identify the weight of each term so that better
search queries can be generated. In candidate an-
swer generation, relations enable the background
knowledge base to be used for potential candidate
answer generation. In candidate answer scoring,
relation-based matching algorithms can go beyond
explicit lexical and syntactic information to detect
implicit semantic relations shared across the ques-
tion and passages.
To construct a medical relation extraction sys-
tem, several challenges have to be addressed:
• The first challenge is how to identify a set of
relations that has sufficient coverage in the
medical domain. To address this issue, we
study a real-world diagnosis related question
set and identify a set of relations that has a
good coverage of the clinical questions.
• The second challenge is how to efficiently de-
tect relations in a large amount of medical
text. The medical corpus underlying our re-
lation extraction system contains 80M sen-
tences (11 gigabytes pure text). To extract
relations from a dataset at this scale, the re-
lation detectors have to be fast. In this paper,
we speed up relation detectors through pars-
ing adaptation and replacing non-linear clas-
sifiers with linear classifiers.
• The third challenge is that the labeled rela-
tion examples are often insufficient due to the
high labeling cost. When we build a naive
model to detect relations, the model tends to
overfit for the labeled data. To address this
issue, we develop a manifold model (Belkin
et al., 2006) that encourages examples (in-
cluding both labeled and unlabeled exam-
ples) with similar contents to be assigned
with similar scores. Our model goes beyond
regular regression models in that it applies
constraints to those coefficients, such that the
topology of the given data manifold will be
respected. Computing the optimal weights
in a regression model and preserving mani-
fold topology are conflicting objectives, we
</bodyText>
<page confidence="0.967359">
828
</page>
<note confidence="0.8315485">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 828–838,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.993396863636363">
present a closed-form solution to ideally bal-
ance these two goals.
The contributions of this paper on medical rela-
tion extraction are three-fold:
• The problem setup is new. There is a
“fundamental” difference between our prob-
lem setup and the conventional setups, like
i2b2 (Uzuner et al., 2011). In i2b2 rela-
tion extraction task, entity mentions are man-
ually labeled, and each mention has 1 of 3
concepts: ‘treatment’, ‘problem’, and ‘test’.
To resemble real-world medical relation ex-
traction challenges where perfect entity men-
tions do not exist, our new setup requires
the entity mentions to be automatically de-
tected. The most well-known tool to detect
medical entity mentions is MetaMap (Aron-
son, 2001), which considers all terms as en-
tities and automatically associates each term
with a number of concepts from UMLS CUI
dictionary (Lindberg et al., 1993) with more
than 2.7 million distinct concepts (compared
to 3 in i2b2). The huge amount of entity
mentions, concepts and noisy concept assign-
ments provide a tough situation that people
have to face in real-world applications.
• From the perspective of relation extraction
applications, we identify “super relations”-
the key relations that can facilitate clinical
decision making (Table 1). We also present
approaches to collect training data for these
relations with a small amount of labeling ef-
fort.
• From the perspective of relation extraction
methodologies, we present a manifold model
for relation extraction utilizing both labeled
and unlabeled data. Our approach can also
take the label weight into consideration.
The experimental results show that our relation
detectors are fast and outperform the state-of-the-
art approaches on medical relation extraction by a
large margin. We also apply our model to build a
new medical relation knowledge base as a comple-
ment to the existing knowledge bases.
</bodyText>
<sectionHeader confidence="0.998581" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.999774">
2.1 Medical Ontologies and Sources
</subsectionHeader>
<bodyText confidence="0.9994763125">
Medical domain has a huge amount of natural lan-
guage content found in textbooks, encyclopedias,
guidelines, electronic medical records, and many
other sources. It is also growing at an extremely
high speed. Substantial understanding of the med-
ical domain has already been included in the Uni-
fied Medical Language System (UMLS) (Lind-
berg et al., 1993), which includes medical con-
cepts, relations, definitions, etc. The 2012 version
of the UMLS contains information about more
than 2.7 million concepts from over 160 source
vocabularies. Softwares for using this knowledge
also exist: MetaMap (Aronson, 2001) is able to
identify concepts in text. SEMREP (Rindflesch
and Fiszman, 2003) can detect some relations us-
ing hand-crafted rules.
</bodyText>
<subsectionHeader confidence="0.997484">
2.2 Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999882735294117">
To extract semantic relations from text, three types
of approaches have been applied. Rule-based
methods (Miller et al., 2000) employ a number
of linguistic rules to capture relation patterns.
Feature-based methods (Kambhatla, 2004; Zhao
and Grishman, 2005) transform relation instances
into a large amount of linguistic features like lex-
ical, syntactic and semantic features, and capture
the similarity between these feature vectors. Re-
cent results mainly rely on kernel-based meth-
ods. Many of them focus on using tree kernels to
learn parse tree structure related features (Collins
and Duffy, 2001; Culotta and Sorensen, 2004;
Bunescu and Mooney, 2005).
Other researchers study how different ap-
proaches can be combined to improve the extrac-
tion performance. For example, by combining tree
kernels and convolution string kernels, (Zhang et
al., 2006) achieved the state of the art performance
on ACE data (ACE, 2004). Recently, “distant su-
pervision” has emerged to be a popular choice for
training relation extractors without using manually
labeled data (Mintz et al., 2009; Jiang, 2009; Chan
and Roth, 2010; Wang et al., 2011; Riedel et al.,
2010; Ji et al., 2011; Hoffmann et al., 2011; Sur-
deanu et al., 2012; Takamatsu et al., 2012; Min et
al., 2013).
Various relation extraction approaches have
been adapted to the medical domain, most of
which focus on designing heuristic rules targeted
for diagnosis and integrating the medical ontology
in the existing extraction approaches. Results of
some of these approaches are reported on the i2b2
data (Uzuner et al., 2011).
</bodyText>
<page confidence="0.99912">
829
</page>
<sectionHeader confidence="0.992089" genericHeader="method">
3 Identifying Key Medical Relations
</sectionHeader>
<subsectionHeader confidence="0.999538">
3.1 Super Relations in Medical Domain
</subsectionHeader>
<bodyText confidence="0.999632769230769">
The first step in building a relation extraction sys-
tem for medical domain is to identify the relations
that are important for clinical decision making.
Four main clinical tasks that physicians engage
in are discussed in (Demner-Fushman and Lin,
2007). They are Therapy- select treatments to of-
fer a patient, taking consideration of effectiveness,
risk, cost and other factors (prevention is under the
general category of Therapy), Diagnosis (includ-
ing differential diagnosis based on findings and di-
agnostic test), Etiology- identify the factors that
cause the disease and Prognosis- estimate the pa-
tient’s likely course over time. These activities can
be translated into “search tasks”. For example, the
search for therapy is usually the therapy selection
given a disease.
We did an independent study regarding what
clinical questions usually ask for on a set of 5,000
Doctor Dilemma (DD) questions from the Ameri-
can College of Physicians (ACP). This set includes
questions about diseases, treatments, lab tests, and
general facts1. Our analysis shows that about 15%
of these questions ask for treatments, preventions
or contraindicated drugs for a disease or another
way around, 4% are about diagnosis tests, 6% are
about the causes of a disease, 1% are about the lo-
cations of a disease, 25% are about the symptoms
of a disease, 8% are asking for definitions, 7% are
about guidelines and the remaining 34% questions
either express no relations or some relations that
are not very popular.
Based on the analysis in (Demner-Fushman and
Lin, 2007) and our own results, we decided to fo-
cus on seven key relations in the medical domain,
which are described in Table 1. We call these re-
lations “super relations”, since they cover most
questions in the DD question set and align well
with the analysis result in (Demner-Fushman and
Lin, 2007).
</bodyText>
<subsectionHeader confidence="0.999884">
3.2 Collect Training Data
</subsectionHeader>
<bodyText confidence="0.999579666666667">
This section presents how we collect training data
for each relation. The overall procedure is illus-
trated in Figure 1.
</bodyText>
<footnote confidence="0.42364575">
1Here’s an example of these questions and its answer:
Question: The syndrome characterized by joint pain, abdom-
inal pain, palpable purpura, and a nephritic sediment. An-
swer: Henoch-Schonlein purpura.
</footnote>
<figureCaption confidence="0.99863">
Figure 1: Collect Training Data
</figureCaption>
<bodyText confidence="0.8912906">
Our medical corpus has incorporated a set
of medical books/journals2 and MEDLINE ab-
stracts. We also complemented these sources with
Wikipedia articles. In total, the corpus contains
80M sentences (11 gigabyte pure text).
The UMLS 2012 Release contains more than
600 relations and 50M relation instances under
around 15 categories. The RO category (RO
stands for “has Relationship Other than synony-
mous, narrower, or broader”) is the most inter-
esting one, and covers relations like “may treat”,
“has finding site”, etc. Each relation has a
certain number of Concept Unique Identifier
(CUI) pairs that are known to bear that rela-
tion. In UMLS, some relation information is
redundant. Firstly, half of these relations are
simply inverse of each other (e.g. the relation
“may treat” and “may be treated by”). Secondly,
there is a significant amount of redundancy even
among non-inverse relations (e.g. the relation
“has manifestation” and “disease has finding”).
From UMLS relations, we manually chose a
subset of them that are directly related to the su-
per relations discussed in Section 3.1. The cor-
respondences between them are given in Table 1.
One thing to note is that super relations are more
general than the UMLS relations, and one super
relation might integrate multiple UMLS relations.
Using the CUI pairs in the UMLS relation knowl-
2This is a full list of the books and journals used in
our corpus: ACP-Medical Knowledge Self-Assessment Pro-
gram, EBSCO-Dynamed, EBSCO-Quick Lessons, EBSCO-
EBCS, EBSCO-Clinical Review, Wiley-Essential Evidence
Plus: EBMG Guidelines, Wiley-Essential Evidence Topics,
Wiley-Essential Evidence Plus: EBMG Summaries, Wiley-
POEMs, Wiley-The Breast Journal, New England Journal
of Medicine, Journal Watch, NCCN-CME, NCCN-GUS,
NCCN-Compendium, NCCN-Templates, NCCN-Guidelines
for Patients, NCCN-Physician Guidelines, Merck Manual of
Diagnosis and Therapy, and UpToDate.
</bodyText>
<figure confidence="0.909038357142857">
Large Amount of
Noisy Relation
Data
For each relation, choose a
small amount of the most
representative examples
Labeled Data
Unlabeled Data
Training Data for
Each Relation
Annotation
Medical Text
Relation Knowledge in
Medical Domain
</figure>
<page confidence="0.979631">
830
</page>
<tableCaption confidence="0.999412">
Table 1: Super relations &amp; their arguments, UMLS sources and noise% in the annotation data
</tableCaption>
<bodyText confidence="0.999547952380953">
Super Relations Argument 1 Argument 2 UMLS Sources Noise% in Annotation Data
treats disease treatments may treat, treats 16%
prevents disease treatments may prevent 49%
contraindicates disease treatments contraindicated drug 97%
diagnoses disease tests may diagnose 63%
causes disease causes cause of, causative agent of 66%
location of disease locations has finding site 41%
disease has primary anatomic site
symptom of disease symptoms disease has finding 66%
disease may have finding
has manifestation
has definitional manifestation
edge base, we associate each super relation with a
set of CUI pairs.
To collect the training data for each super re-
lation, we need to collect sentences that express
the relation. To achieve this, we parsed all 80M
sentences in our medical corpus, looking for the
sentences containing the terms that are associated
with the CUI pairs in the knowledge base. This
(distant supervision) approach resulted in a huge
amount of sentences that contain the desired rela-
tions, but also brought in a lot of noise in the form
of false positives. For example, we know from
the knowledge base that “antibiotic drug” may
treat “Lyme disease”. However the sentence “This
paper studies the relationship between antibiotic
drug and Lyme disease” contains both terms but
does not express the “treats” relation.
The most reliable way to clean the training data
is to ask annotators to go through the sentences
and assign the sentences with positive/negative la-
bels. However, it will not work well when we have
millions of sentences to vet. To minimize the hu-
man labeling effort, we ran a K-medoids clustering
on the sentences associated with each super rela-
tion and kept the cluster centers as the most rep-
resentative sentences for annotation. Depending
on the number of the sentences we collected for
each relation, the #clusters was chosen from 3,000
- 6,000. The similarity of two sentences is defined
as the bag-of-words similarity of the dependency
paths connecting arguments. Part of the resulting
data was manually vetted by our annotators, and
the remaining was held as unlabeled data for fur-
ther experiments.
Our relation annotation task is quite straightfor-
ward, since both arguments are given and the de-
cision is a Yes-or-No decision. The noise rate of
each relation (#sentences expressing the relation
/ #sentences) is reported in Table 1 based on the
annotation results. The noise rates differ signifi-
cantly from one relation to another. For “treats”
relation, only 16% of the sentences are false posi-
tives. For “contraindicates” relation, the noise rate
is 97%.
To grow the size of the negative training set for
each super relation, we also added a small amount
of the most representative examples (also coming
from K-medoids clustering) from each unrelated
UMLS relation to the training set as negative ex-
amples. This resulted in more than 10,000 extra
negative examples for each relation.
</bodyText>
<subsectionHeader confidence="0.999536">
3.3 Parsing and Typing
</subsectionHeader>
<bodyText confidence="0.99996836">
The most well-known tool to detect medical en-
tity mentions is MetaMap (Aronson, 2001), which
considers all terms as entities and automatically
associates each term with a number of concepts
from UMLS CUI dictionary (Lindberg et al.,
1993) with 2.7 million distinct concepts.
The parser used in our system is Medi-
calESG, an adaptation of ESG (English Slot
Grammar) (McCord et al., 2012) to the medical
domain with extensions of medical lexicons inte-
grated in the UMLS 2012 Release. Compared to
MetaMap, MedicalESG is based on the same med-
ical lexicons, 10 times faster and produces very
similar parsing results.
We use the semantic types defined in
UMLS (Lindberg et al., 1993) to categorize
argument types. The UMLS consists of a set
of 133 subject categories, or semantic types,
that provide a consistent categorization of more
than 2M concepts represented in the UMLS
Metathesaurus. Our system assigns each relation
argument with one or more UMLS semantic types
through a two step process. Firstly, we use Med-
icalESG to process the input sentence, identify
segments of text that correspond to concepts in
</bodyText>
<page confidence="0.995356">
831
</page>
<figureCaption confidence="0.999709">
Figure 2: A Parse Tree Example
</figureCaption>
<bodyText confidence="0.99963154054054">
the UMLS Metathesaurus and associate each of
them with one or more UMLS CUIs (Concept
Unique Identifier). Then we do a CUI lookup in
UMLS to find the corresponding semantic types
for each CUI.
Most relation arguments are associated with
multiple semantic types. For example, the term
“tetracycline hydrochloride” has two types: “Or-
ganic Chemical” and “Antibiotic”. Sometimes,
the semantic types are noisy due to ambiguity of
terms. For example, the term “Hepatitis b” is asso-
ciated with both “Pharmacologic Substance” and
“Disease or Syndrome” based on UMLS. The rea-
son for this is that people use “Hepatitis b” to rep-
resent both “the disease of Hepatitis b” and “Hep-
atitis b vaccine”, so UMLS assigns both types to it.
This is a concern for relation extraction, since two
types bear opposite meanings. Our current strat-
egy is to integrate all associated types, and rely on
the relation detector trained with the labeled data
to decide how to weight different types based upon
the context.
Here is an illustrative example. Consider the
sentence: “Antibiotics are the standard therapy
for Lyme disease”: MedicalESG first generates
a dependency parse tree (Figure 2) to represent
grammatical relations between the words in the
sentence, and then associates the words with CUIs.
For example, “Antibiotics” is associated with CUI
“C0003232” and “Lyme disease” is associated
with two CUIs: “C0024198” and “C0717360”.
CUI lookup will assign “Antibiotics” with a se-
mantic type “Antibiotic”, and “Lyme disease” with
three semantic types: “Disease or Syndrome”,
“Pharmacologic Substance” and “Immunologic
Factor”. This sentence expresses a “treats” rela-
tion between “Antibiotics” and “Lyme disease”.
</bodyText>
<sectionHeader confidence="0.997528" genericHeader="method">
4 Relation Extraction with Manifold
Models
</sectionHeader>
<subsectionHeader confidence="0.99795">
4.1 Motivations
</subsectionHeader>
<bodyText confidence="0.999962166666667">
Given a few labeled examples and many unlabeled
examples for a relation, we want to build a re-
lation detector leveraging both labeled and unla-
beled data. Following the manifold regularization
idea (Belkin et al., 2006), our strategy is to learn
a function that assigns a score to each example.
Scores are fit so that examples (both labeled and
unlabeled) with similar content get similar scores,
and scores of labeled examples are close to their
labels. Integration of the unlabeled data can help
solve overfitting problems when the labeled data
is not sufficient.
</bodyText>
<sectionHeader confidence="0.509242" genericHeader="method">
4.2 Features
</sectionHeader>
<bodyText confidence="0.999980333333333">
We use 8 groups of features to represent each rela-
tion example. These features are commonly used
for relation extraction.
</bodyText>
<listItem confidence="0.960645333333333">
• (1) Semantic types of argument 1, such as
“Antibiotic”.
• (2) Semantic types of argument 2.
• (3) Syntactic features representing the depen-
dency path between two arguments, such as
“subj”, “pred”, “mod nprep” and “objprep”
(between arguments “antibiotic” and “lyme
disease”) in Figure 2.
• (4) Features modeling the incoming and out-
</listItem>
<bodyText confidence="0.739876333333333">
going links of both arguments. These fea-
tures are useful to determine if a relation goes
from argument 1 to argument 2 or vice versa.
• (5) Topic features modeling the words in
the dependency path. In the example given
in Figure 2, the dependency path contains
the following words: “be”, “standard ther-
apy” and “for”. These features as well as
the features in (6) are achieved by projecting
the words onto a 100 dimensional LSI topic
space (Deerwester et al., 1990) constructed
from our medical corpus.
</bodyText>
<listItem confidence="0.871600833333333">
• (6) Topic features modeling the words in the
whole sentence.
• (7) Bag-of-words features modeling the de-
pendency path. In (7) and (8), we only con-
sider the words that have occurred in the pos-
itive training data.
</listItem>
<page confidence="0.990007">
832
</page>
<sectionHeader confidence="0.444347" genericHeader="method">
Notations:
</sectionHeader>
<bodyText confidence="0.959418222222222">
The input dataset X = {x1, · · · , xm} is repre-
sented as a feature-instance matrix.
The desired label vector Y = {y1, · · · , yl} repre-
sents the labels of {x1, · · · , xl}, where l &lt; m.
W is a weight matrix, where Wi,j = e−kxi−xjk2
models the similarity of xi and xj.
I Ixi − xjI I stands for the Euclidean distance be-
tween xi and xj in the vector space.
D is a diagonal matrix: Di,i = Ej Wi,j.
</bodyText>
<equation confidence="0.923132">
L = D−0.5(D − W)D−0.5 is called normalized
</equation>
<bodyText confidence="0.762308">
graph Laplacian matrix.
A is a user defined l x l diagonal matrix, where
Ai represents the weight of label yi.
</bodyText>
<equation confidence="0.9945935">
A = (� 00) is an m x m matrix.
V = [y1, · · · yl, 0, · · · , 0] is a 1 x m matrix.
</equation>
<bodyText confidence="0.488806">
p is a weight scalar.
()+ represents pseudo inverse.
</bodyText>
<sectionHeader confidence="0.322575" genericHeader="method">
Algorithm:
</sectionHeader>
<listItem confidence="0.99840125">
1. Represent each example using features:
X = {x1, · · · , xm}, where xi is the ith ex-
ample.
2. Construct graph Laplacian matrix L
modeling the data manifold.
3. Construct vector V = [y1, · · · yl, 0, · · · , 0].
4. Compute projection function f for each
relation: f = (X(A + pL)XT )+XAVT.
</listItem>
<figureCaption confidence="0.689397">
Figure 3: Notations and the Algorithm to Train a
Manifold Model for Relation Extraction
</figureCaption>
<bodyText confidence="0.954323842105263">
• (8) Bag-of-words features modeling the
whole sentence.
In relation extraction, many recent approaches
use non-linear kernels to get the similarity of two
relation examples. To classify a relation exam-
ple, a lot of dot product computations are required.
This is very time consuming and becomes a bottle-
neck in using relation extraction to facilitate clin-
ical decision making. To speed up the classifier
during the apply time, we decided to use a linear
classifier instead of non-linear classifiers.
We represent all features in a single feature
space. For example, we use a vector of 133 en-
tries (UMLS contains 133 semantic types) to rep-
resent the types of argument 1. If argument 1 is
associated with two types: “Organic Chemical”
and “Antibiotic”, we set the two corresponding en-
tries to 1 and all the other entries to 0. Similar ap-
proaches are used to represent the other features.
</bodyText>
<subsectionHeader confidence="0.997295">
4.3 The Main Algorithm
</subsectionHeader>
<bodyText confidence="0.999760538461538">
The problem we want to solve is formalized as fol-
lows: given a relation dataset X = {x1, · · · , xm},
and the desired label Y = {y1, · · · , yl} for
{x1, · · · , xl}, where l &lt; m, we want to construct
a mapping function f to project any example xi to
a new space, where fT xi matches xi’s desired la-
bel yi. In addition, we also want f to preserve the
manifold topology of the dataset, such that similar
examples (both labeled and unlabeled) get simi-
lar scores. Here, the label is ‘+1’ for positive ex-
amples, and ‘-1’ for negative examples. Notations
and the main algorithm to construct f for each re-
lation are given in Figure 3.
</bodyText>
<subsectionHeader confidence="0.990366">
4.4 Justification
</subsectionHeader>
<bodyText confidence="0.9999734">
The solution to the problem defined in Section 4.3
is given by the mapping function f to minimize
the following cost function:
The first term of C(f) is based on labeled ex-
amples, and penalizes the difference between the
mapping result of xi and its desired label yi. αi is
a user specified parameter, representing the weight
of label yi. The second term of C(f) does not take
label information into account. It encourages the
neighborhood relationship (geometry of the man-
ifold) within X to be preserved in the mapping.
When xi and xj are similar, the corresponding
Wi,j is big. If f maps xi and xj to different posi-
tions, f will be penalized. The second term is use-
ful to bound the mapping function f and prevents
overfitting from happening. Here p is the weight
of the second term. When p = 0, the model dis-
regards the unlabeled data, and the data manifold
topology is not respected.
Compared to manifold regularization (Belkin
et al., 2006), we do not include the RKHS norm
term. Instead, we associate each labeled example
with an extra weight for label confidence. This
weight is particularly useful when the training
data comes from “Crowdsourcing”, where we ask
</bodyText>
<equation confidence="0.9922295">
C(f) = � �αi(fT xi − yi)2 + � Wi,j(fT xi −fT xj)2.
i&lt;l i,j
</equation>
<page confidence="0.993731">
833
</page>
<bodyText confidence="0.807325125">
multiple workers to complete the same task to
correct errors. In that scenario, weights can be as-
signed to labels based upon annotator agreement.
Theorem 1: f = (X(A + µL)XT)+XAV T
minimizes the cost function C(f).
Proof:
Given the input X, we want to find the optimal
mapping function f such that C(f) is minimized:
</bodyText>
<equation confidence="0.611626888888889">
f = arg min
f
It can be verified that
E αi(fT xi − yi)2 = fT XAXT f − 2fT XAVT + V AV T .
i&lt;l
We can also verify that
(fT xi − fT xj)2Wi,j = µfT XLXT f.
So C(f) can be written as
fT XAXT f − 2fT XAV T + V AV T + AfT XGXT f.
</equation>
<bodyText confidence="0.330337">
Using the Lagrange multiplier trick to differentiate
C(f) with respect to f, we have
</bodyText>
<equation confidence="0.4934466">
2XAXT f + 2µXLXT f = 2XAVT .
This implies that
X(A + µL)XT f = XAVT .
So
f = (X(A + µL)XT)+XAV T,
</equation>
<bodyText confidence="0.784918">
where “+” represents pseudo inverse.
</bodyText>
<subsectionHeader confidence="0.840059">
4.5 Advantages
</subsectionHeader>
<bodyText confidence="0.979648">
Our algorithm offers the following advantages:
</bodyText>
<listItem confidence="0.962348230769231">
• The algorithm exploits unlabeled data, which
helps prevent “overfitting” from happening.
• The algorithm provides users with the flex-
ibility to assign different labels with differ-
ent weights. This feature is useful when the
training data comes from “crowdsourcing” or
“distant supervision”.
• Different from many approaches in this area,
our algorithm provides a closed-form solu-
tion of the result. The solution is global opti-
mal regarding the cost function C(f).
• The algorithm is computationally efficient at
the apply time (as fast as linear regressions).
</listItem>
<sectionHeader confidence="0.998896" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995743">
5.1 Cross-Validation Test
</subsectionHeader>
<bodyText confidence="0.9999853">
We use a cross-validation testa with the relation
data generated in Section 3.2 to compare our ap-
proaches against the state-of-the-art approaches.
The task is to classify the examples into positive
or negative for each relation. We applied a 5-fold
cross-validation. In each round of validation, we
used 20% of the data for training and 80% for test-
ing. The F1 scores reported here are the average
of all 5 rounds. We used MedicalESG to process
the input text for all approaches.
</bodyText>
<subsubsectionHeader confidence="0.743144">
5.1.1 Data and Parameters
</subsubsectionHeader>
<bodyText confidence="0.999992388888889">
This dataset includes 7 relations. We do not con-
sider the relation of “contraindicates” in this test,
since it has too few positive examples. On average,
each relation contains about 800 positive examples
and more than 13,000 negative examples. To elim-
inate the examples that are trivial to classify, we
removed the negative examples that do not bear
the valid argument types. This removed the exam-
ples that can be easily classified by a type filter,
resulting in 3,000 negatives on average per rela-
tion. For each relation, we also collected 5,000
unlabeled examples and put them into two sets:
unlabeled set 1 and 2 (2,500 examples in each set).
No parameter tuning was taken and no relation
specific heuristic rules were applied in all tests. In
all manifold models, µ = 1. In SVM implemen-
tations, the trade-off parameter between training
error and margin was set to 1 for all experiments.
</bodyText>
<subsubsectionHeader confidence="0.787983">
5.1.2 Baseline Approaches
</subsubsectionHeader>
<bodyText confidence="0.998906842105263">
We compare our approaches to three state-of-the-
art approaches including SVM with convolution
tree kernels (Collins and Duffy, 2001), linear re-
gression and SVM with linear kernels (Sch¨olkopf
and Smola, 2002). To adapt the tree kernel to med-
ical domain, we followed the approach in (Nguyen
et al., 2009) to take the syntactic structures into
consideration. We also added the argument types
as features to the tree kernel. In the tree kernel im-
plementation, we assigned the tree structure and
the vector corresponding to the argument types
3If we take the perfect entity mentions and the associated
concepts provided by i2b2 (Uzuner et al., 2011) as the input,
our system can directly apply to i2b2 relation extraction data.
However, the i2b2 data has a tough data use agreement. Our
legal team held several rounds of negotiations with the i2b2
data owner and then decided we should not use it due to the
high legal risks. We are not aware of other available medical
relation extraction datasets that fit for our evaluations.
</bodyText>
<figure confidence="0.77321625">
C(f).
�
µ
i,j
</figure>
<page confidence="0.997176">
834
</page>
<tableCaption confidence="0.985853">
Table 2: F1 Scores from a Five-Fold Cross Validation Experiment
</tableCaption>
<table confidence="0.9934593">
SVM SVM Linear Manifold Manifold Manifold Manifold
Tree Linear Regression Unlabeled Predicted Labels Predicted Labels Unlabeled+Predicted
Kernel Kernel with Weights without Weights Labels with Weights
treats 0.7648 0.7850 0.7267 0.8025 0.8041 0.7884 0.8085
prevents 0.2859 0.3887 0.3922 0.5502 0.5696 0.6349 0.6332
causes 0.3885 0.5024 0.5219 0.5779 0.5088 0.3978 0.5081
location of 0.6113 0.6009 0.4968 0.7275 0.7363 0.6964 0.7454
diagnoses 0.5520 0.4934 0.3202 0.6468 0.6485 0.5720 0.6954
symptom of 0.4398 0.5611 0.5984 0.6347 0.5314 0.4515 0.5968
average 0.5071 0.5553 0.5094 0.6566 0.6331 0.5902 0.6646
</table>
<bodyText confidence="0.996503">
with equal weights. The SVM with linear kernels
and the linear regression model used the same fea-
tures as the manifold models.
</bodyText>
<subsubsectionHeader confidence="0.913428">
5.1.3 Settings for the Manifold Models
</subsubsectionHeader>
<bodyText confidence="0.9996055">
We tested our manifold model for each relation un-
der three different settings:
</bodyText>
<listItem confidence="0.998017833333333">
(1) Manifold Unlabeled: We combined the la-
beled data and unlabeled set 1 in training. We set
αi = 1 for i ∈ [1, l].
(2) Manifold Predicted Labels: We combined
labeled data and unlabeled set 2 in training. αi =
1 for i ∈ [1, l]. Different from the previous set-
</listItem>
<bodyText confidence="0.643481666666667">
ting, we gave a label estimation to all the exam-
ples in the unlabeled set 2 based on the noise rate
(Noise%) from Table 1. The label of all unla-
beled examples was set to “+1” when 100% − 2 ·
Noise% &gt; 0, or “-1” otherwise. Two weighting
strategies were applied:
</bodyText>
<listItem confidence="0.891189875">
• With Weights: We let label weight αi =
|100% − 2 · Noise% |for all xi coming from
the unlabeled set 2. This setting represents an
empirical rule to estimate the label and con-
fidence of each unlabeled example based on
the sampling result.
• Without Weights: αi is always set to 1.
(3) Manifold UnLabeled+Predicted Labels: a
</listItem>
<bodyText confidence="0.8999955">
combination of setting (1) and (2). In this setting,
the data from unlabeled set 1 was used as unla-
beled data and the data from unlabeled set 2 was
used as labeled data (With Weights).
</bodyText>
<sectionHeader confidence="0.869558" genericHeader="evaluation">
5.1.4 Results
</sectionHeader>
<bodyText confidence="0.99963575">
The results are summarized in Table 2.
The tree kernel-based approach and linear re-
gression achieved similar F1 scores, while linear
SVM made a 5% improvement over them. One
thing to note is that the results from these ap-
proaches vary significantly. The reason for this is
that the labeled training data is not sufficient. So
the approaches that completely depend on the la-
beled data are likely to run into overfitting. Linear
SVM performed better than the other two, since
the large-margin constraint together with the lin-
ear model constraint can alleviate overfitting.
By integrating unlabeled data, the manifold
model under setting (1) made a 15% improvement
over linear regression model on F1 score, where
the improvement was significant across all rela-
tions.
Under setting (2), the With Weights strategy
achieved a slightly worse F1 score than the previ-
ous setting but much better result than the baseline
approaches. This tells us that estimating the label
of unlabeled examples based upon the sampling
result is one way to utilize unlabeled data and may
help improve the relation extraction results. The
results also show that the label weight is important
for this setting, since the Without Weights strategy
did not perform very well.
Compared to setting (1) and (2), setting (3)
made use of 2,500 more unlabeled examples,
and achieved the best performance among all ap-
proaches. On one hand, this result shows that
using more unlabeled data can further improve
the result. On the other hand, the insignificant
improvement over (1) and (2) strongly indicates
that how to utilize more unlabeled data to achieve
a significant improvement is non-trivial and de-
serves more attention. To what extensions the un-
labeled data can help the learning process is an
open problem. Generally speaking, when the ex-
isting data is sufficient to characterize the dataset
geometry, adding more unlabeled data will not
help (Singh et al., 2008).
We tested the tree kernel-based approach with-
out integrating the medical types as well. That re-
sulted in very poor performance: the average F1
score was below 30%. We also applied the rules
used in SEMREP (Rindflesch and Fiszman, 2003)
to this dataset. Since the relations detected by
</bodyText>
<page confidence="0.995146">
835
</page>
<bodyText confidence="0.9997564">
SEMREP rules cannot be perfectly aligned with
super relations, we cannot directly compare the re-
sults. Overall speaking, SEMREP rules are very
conservative and detect very few relations from the
same text.
</bodyText>
<subsectionHeader confidence="0.989708">
5.2 Knowledge Base (KB) Construction
</subsectionHeader>
<bodyText confidence="0.999917538461539">
The UMLS Metathesaurus (Lindberg et al., 1993)
contains a large amount of manually extracted re-
lation knowledge. Such knowledge is invaluable
for people to collect training data to build new
relation detectors. One downside of using this
KB is its incompleteness. For example, it only
contains the treatments for about 8,000 diseases,
which are far from sufficient. Further, the medical
knowledge is changing extremely quickly, making
people hard to understand it, and update it in the
knowledge base in a timely manner.
To address these challenges, we constructed our
own relation KB as a complement to the UMLS
relation KB. We directly ran our relation detec-
tors (trained with all labeled and unlabeled exam-
ples) on our medical corpus to extract relations.
Then we combined the results and put them in a
new KB. The new KB covers all super relations
and stores the knowledge in the format of (rela-
tion name, argument 1, argument 2, confidence),
where the confidence is computed based on the re-
lation detector confidence score and relation pop-
ularity in the corpus. The most recent version of
our relation KB contains 3.4 million such entries.
We compared this new KB against UMLS KB
using an answer generation task on a set of 742
Doctor Dilemma questions. We first ran our rela-
tion detectors to detect the relation(s) in the ques-
tion clue involving question focus (what the ques-
tion asks for). Then we searched against both KBs
using the relation name and the non-focus argu-
ment for the missing argument. The search re-
sults were then generated as potential answers. We
used the same relations to do KB lookup, so the
results are directly comparable. Since most ques-
tions only have one correct answer, the precision
number is not very important in this experiment.
If we detect multiple relations in the question,
and the same answer is generated from more than
one relations, we sum up all those confidence
scores to make such answers more preferable.
Sometimes, we may generate too many answers
from KBs. For example, if the detected relation
is “location of” and the non-focus argument is
“skin”, then thousands of answers can be gener-
ated. In this scenario, we sort the answers based
upon the confidence scores and only consider up
to p answers for each question. In our test, we
considered three numbers for p: 20, 50 and 3,000.
From Table 3, we can see that the new KB out-
performs the most popularly-used UMLS KB at
all recall levels by a large margin. This result in-
dicates that the new KB has a much better knowl-
edge coverage. The UMLS KB is manually cre-
ated and thus more precise. In our experiment, the
UMLS KB generated fewer answers than the new
KB. For example, when up to 20 answers were
generated for each question, the UMLS KB gen-
erated around 4,700 answers for the whole ques-
tion set, while the new KB generated about 7,600
answers.
Construction of the new KB cost 16 machines
(using 4x2.8G cores per machine) 8 hours. The
reported computation time is for the whole corpus
with 11G pure text.
</bodyText>
<tableCaption confidence="0.997598">
Table 3: Knowledge Base Comparison
</tableCaption>
<table confidence="0.991579666666667">
Recall@20 Recall@50 Recall@3000
Our KB 135/742 182/742 301/742
UMLS KB 42/742 52/742 73/742
</table>
<sectionHeader confidence="0.999363" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999853416666667">
In this paper, we identify a list of key relations that
can facilitate clinical decision making. We also
present a new manifold model to efficiently extract
these relations from text. Our model is developed
to utilize both labeled and unlabeled examples. It
further provides users with the flexibility to take
label weight into consideration. Effectiveness of
the new model is demonstrated both theoretically
and experimentally. We apply the new model to
construct a relation knowledge base (KB), and use
it as a complement to the existing manually cre-
ated KBs.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998618">
We thank Siddharth Patwardhan for help on tree
kernels, Sugato Bagchi and Dr. Herbert Chase’s
team for categorizing the Doctor Dilemma ques-
tions. We also thank Anthony Levas, Karen In-
graffea, Mark Mergen, Katherine Modzelewski,
Jonathan Hodax, Matthew Schoenfeld and Adarsh
Thaker for vetting the training data.
</bodyText>
<page confidence="0.997537">
836
</page>
<sectionHeader confidence="0.951361" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993021971698113">
ACE. 2004. The automatic content extraction projects,
http://projects.ldc.upenn.edu/ace/.
A. Aronson. 2001. Effective mapping of biomedical
text to the UMLS metathesaurus: the MetaMap pro-
gram. In Proceedings of the 2001 Annual Sympo-
sium of the American Medical Informatics Associa-
tion.
M. Belkin, P. Niyogi, and V. Sindhwani. 2006.
Manifold regularization: a geometric framework
for learning from labeled and unlabeled exam-
ples. Journal of Machine Learning Research, pages
2399–2434.
R. Bunescu and R. Mooney. 2005. A shortest path de-
pendency kernel for relation extraction. In Proceed-
ings of the Conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing.
Y. Chan and D. Roth. 2010. Exploiting background
knowledge for relation extraction. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 152–160.
M. Collins and N. Duffy. 2001. Convolution ker-
nels for natural language. In Proceedings of the
Advances in Neural Information Processing Systems
(NIPS), pages 625–632.
A. Culotta and J. Sorensen. 2004. Dependency tree
kernels for relation extraction. In Proceedings of the
42nd Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 423–429.
S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Lan-
dauer, and R. Harshman. 1990. Indexing by latent
semantic analysis. Journal of the American Society
for Information Science, 41(6):391–407.
D. Demner-Fushman and J. Lin. 2007. Answering
clinical questions with knowledge-based and statis-
tical techniques. Journal of Computational Linguis-
tics, 56:63–103.
R. Hoffmann, C. Zhang, X. Ling, L. Zettlemoyer, and
D. S. Weld. 2011. Knowledge-based weak supervi-
sion for information extraction of overlapping rela-
tions. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics (ACL).
H. Ji, R. Grishman, and H. T. Dang. 2011. Overview
of the TAC 2011 knowledge base population track.
In Proceedings of the Text Analytics Conference.
J. Jiang. 2009. Multi-task transfer learning for weakly-
supervised relation extraction. In Proceedings of
the Joint Conference of the 47th Annual Meeting
of the Association for Computational Linguistics
(ACL) and the 4th International Joint Conference
on Natural Language Processing (IJCNLP), pages
1012–1020.
N. Kambhatla. 2004. Combining lexical, syntactic,
and semantic features with maximum entropy mod-
els for extracting relations. In Proceedings of the
ACL 2004 on Interactive poster and demonstration
sessions.
D. Lindberg, B. Humphreys, and A. McCray. 1993.
The Unified Medical Language System. Methods of
Information in Medicine, 32:281–291.
M. McCord, J. W. Murdock, and B. K. Boguraev.
2012. Deep parsing in Watson. IBM Journal of Re-
search and Development, 56.
S. Miller, H. Fox, L. Ramshaw, and R. Weischedel.
2000. A novel use of statistical parsing to extract in-
formation from text. In Proceedings of the 1st North
American Chapter of the Association for Computa-
tional Linguistics Conference.
B. Min, R. Grishman, L. Wan, C. Wang, and
D. Gondek. 2013. Distant supervision for relation
extraction with an incomplete knowledge base. In
The 2013 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (NAACL-HLT).
M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009.
Distant supervision for relation extraction without
labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the Association
for Computational Linguistics (ACL) and the 4th In-
ternational Joint Conference on Natural Language
Processing (IJCNLP), pages 1003–1011.
T. Nguyen, A. Moschitti, and G. Riccardi. 2009. Con-
volution kernels on constituent, dependency and se-
quential structures for relation extraction. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).
S. Riedel, L. Yao, and A. McCallum. 2010. Mod-
eling relations and their mentions without labeled
text. In Proceedings of the European Conference
on Machine Learning and Knowledge Discovery in
Databases (ECML PKDD).
T. C. Rindflesch and M. Fiszman. 2003. The inter-
action of domain knowledge and linguistic structure
in natural language processing: interpreting hyper-
nymic propositions in biomedical text. Journal of
Biomedical Informatics, 36:462–477.
B. Sch¨olkopf and A. J. Smola. 2002. Learning with
Kernels: Support Vector Machines, Regularization,
Optimization, and Beyond. MIT Press.
A. Singh, R. D. Nowak, and X. Zhu. 2008. Unlabeled
data: now it helps, now it doesnot. In Proceedings
of the Advances in Neural Information Processing
Systems (NIPS).
M. Surdeanu, J. Tibshirani, R. Nallapati, and C. D.
Manning. 2012. Multi-instance multilabel learning
for relation extraction. In Proceedings of the 2012
</reference>
<page confidence="0.977777">
837
</page>
<reference confidence="0.999493225806452">
Conference on Empirical Methods in Natural Lan-
guage Processing and Natural Language Learning
(EMNLP).
S. Takamatsu, I. Sato, and H. Nakagawa. 2012. Re-
ducing wrong labels in distant supervision for rela-
tion extraction. In Proceedings of the Annual Meet-
ing of the Association for Computational Linguistics
(ACL).
¨O. Uzuner, B. R. South, S. Shen, and S. L. DuVall.
2011. 2010 i2b2/VA challenge on concepts, asser-
tions, and relations in clinical text. Journal ofAmer-
ican Medical Informatics Association, 18:552–556.
C. Wang, J. Fan, A. Kalyanpur, and D. Gondek. 2011.
Relation extraction with relation topics. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP).
C. Wang, A. Kalyanpur, J. Fan, B. Boguraev, and
D. Gondek. 2012. Relation extraction and scoring
in DeepQA. IBM Journal of Research and Develop-
ment, 56.
M. Zhang, J. Zhang, J. Su, and G. Zhou. 2006. A com-
posite kernel to extract relations between entities
with both flat and structured features. In Proceed-
ings of the 21st International Conference on Compu-
tational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics (ACL).
S. Zhao and R. Grishman. 2005. Extracting relations
with integrated information using kernel methods.
In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL),
pages 419–426.
</reference>
<page confidence="0.997604">
838
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732427">
<title confidence="0.999102">Medical Relation Extraction with Manifold Models</title>
<author confidence="0.951168">Chang</author>
<affiliation confidence="0.969977">IBM T. J. Watson Research Yorktown Heights, New York,</affiliation>
<email confidence="0.999731">changwangnk@gmail.com</email>
<author confidence="0.988646">James</author>
<affiliation confidence="0.9904665">IBM T. J. Watson Research Yorktown Heights, New York,</affiliation>
<email confidence="0.99995">fanj@us.ibm.com</email>
<abstract confidence="0.990847722222223">In this paper, we present a manifold model for medical relation extraction. Our model is built upon a medical corpus containing 80M sentences (11 gigabyte text) and designed to accurately and efficiently detect the key medical relations that can facilitate clinical decision making. Our approach integrates domain specific parsing and typing systems, and can utilize labeled as well as unlabeled examples. To provide users with more flexibility, we also take label weight into consideration. Effectiveness of our model is demonstrated both theoretically with a proof to show that the solution is a closed-form solution and experimentally with positive results in experiments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ACE</author>
</authors>
<title>The automatic content extraction projects,</title>
<date>2004</date>
<location>http://projects.ldc.upenn.edu/ace/.</location>
<contexts>
<context position="7399" citStr="ACE, 2004" startWordPosition="1155" endWordPosition="1156">of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approach</context>
</contexts>
<marker>ACE, 2004</marker>
<rawString>ACE. 2004. The automatic content extraction projects, http://projects.ldc.upenn.edu/ace/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aronson</author>
</authors>
<title>Effective mapping of biomedical text to the UMLS metathesaurus: the MetaMap program.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Annual Symposium of the American Medical Informatics Association.</booktitle>
<contexts>
<context position="4517" citStr="Aronson, 2001" startWordPosition="710" endWordPosition="712">aper on medical relation extraction are three-fold: • The problem setup is new. There is a “fundamental” difference between our problem setup and the conventional setups, like i2b2 (Uzuner et al., 2011). In i2b2 relation extraction task, entity mentions are manually labeled, and each mention has 1 of 3 concepts: ‘treatment’, ‘problem’, and ‘test’. To resemble real-world medical relation extraction challenges where perfect entity mentions do not exist, our new setup requires the entity mentions to be automatically detected. The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with more than 2.7 million distinct concepts (compared to 3 in i2b2). The huge amount of entity mentions, concepts and noisy concept assignments provide a tough situation that people have to face in real-world applications. • From the perspective of relation extraction applications, we identify “super relations”- the key relations that can facilitate clinical decision making (Table 1). We also present approaches to collect training data for t</context>
<context position="6329" citStr="Aronson, 2001" startWordPosition="992" endWordPosition="993">Sources Medical domain has a huge amount of natural language content found in textbooks, encyclopedias, guidelines, electronic medical records, and many other sources. It is also growing at an extremely high speed. Substantial understanding of the medical domain has already been included in the Unified Medical Language System (UMLS) (Lindberg et al., 1993), which includes medical concepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent resul</context>
<context position="15609" citStr="Aronson, 2001" startWordPosition="2455" endWordPosition="2456"> differ significantly from one relation to another. For “treats” relation, only 16% of the sentences are false positives. For “contraindicates” relation, the noise rate is 97%. To grow the size of the negative training set for each super relation, we also added a small amount of the most representative examples (also coming from K-medoids clustering) from each unrelated UMLS relation to the training set as negative examples. This resulted in more than 10,000 extra negative examples for each relation. 3.3 Parsing and Typing The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with 2.7 million distinct concepts. The parser used in our system is MedicalESG, an adaptation of ESG (English Slot Grammar) (McCord et al., 2012) to the medical domain with extensions of medical lexicons integrated in the UMLS 2012 Release. Compared to MetaMap, MedicalESG is based on the same medical lexicons, 10 times faster and produces very similar parsing results. We use the semantic types defined in UMLS (Lindberg et al., 1993) to categ</context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>A. Aronson. 2001. Effective mapping of biomedical text to the UMLS metathesaurus: the MetaMap program. In Proceedings of the 2001 Annual Symposium of the American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
<author>V Sindhwani</author>
</authors>
<title>Manifold regularization: a geometric framework for learning from labeled and unlabeled examples.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2399--2434</pages>
<contexts>
<context position="3190" citStr="Belkin et al., 2006" startWordPosition="504" endWordPosition="507">The medical corpus underlying our relation extraction system contains 80M sentences (11 gigabytes pure text). To extract relations from a dataset at this scale, the relation detectors have to be fast. In this paper, we speed up relation detectors through parsing adaptation and replacing non-linear classifiers with linear classifiers. • The third challenge is that the labeled relation examples are often insufficient due to the high labeling cost. When we build a naive model to detect relations, the model tends to overfit for the labeled data. To address this issue, we develop a manifold model (Belkin et al., 2006) that encourages examples (including both labeled and unlabeled examples) with similar contents to be assigned with similar scores. Our model goes beyond regular regression models in that it applies constraints to those coefficients, such that the topology of the given data manifold will be respected. Computing the optimal weights in a regression model and preserving manifold topology are conflicting objectives, we 828 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 828–838, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computa</context>
<context position="18634" citStr="Belkin et al., 2006" startWordPosition="2935" endWordPosition="2938">isease” is associated with two CUIs: “C0024198” and “C0717360”. CUI lookup will assign “Antibiotics” with a semantic type “Antibiotic”, and “Lyme disease” with three semantic types: “Disease or Syndrome”, “Pharmacologic Substance” and “Immunologic Factor”. This sentence expresses a “treats” relation between “Antibiotics” and “Lyme disease”. 4 Relation Extraction with Manifold Models 4.1 Motivations Given a few labeled examples and many unlabeled examples for a relation, we want to build a relation detector leveraging both labeled and unlabeled data. Following the manifold regularization idea (Belkin et al., 2006), our strategy is to learn a function that assigns a score to each example. Scores are fit so that examples (both labeled and unlabeled) with similar content get similar scores, and scores of labeled examples are close to their labels. Integration of the unlabeled data can help solve overfitting problems when the labeled data is not sufficient. 4.2 Features We use 8 groups of features to represent each relation example. These features are commonly used for relation extraction. • (1) Semantic types of argument 1, such as “Antibiotic”. • (2) Semantic types of argument 2. • (3) Syntactic features</context>
<context position="23756" citStr="Belkin et al., 2006" startWordPosition="3880" endWordPosition="3883">t of label yi. The second term of C(f) does not take label information into account. It encourages the neighborhood relationship (geometry of the manifold) within X to be preserved in the mapping. When xi and xj are similar, the corresponding Wi,j is big. If f maps xi and xj to different positions, f will be penalized. The second term is useful to bound the mapping function f and prevents overfitting from happening. Here p is the weight of the second term. When p = 0, the model disregards the unlabeled data, and the data manifold topology is not respected. Compared to manifold regularization (Belkin et al., 2006), we do not include the RKHS norm term. Instead, we associate each labeled example with an extra weight for label confidence. This weight is particularly useful when the training data comes from “Crowdsourcing”, where we ask C(f) = � �αi(fT xi − yi)2 + � Wi,j(fT xi −fT xj)2. i&lt;l i,j 833 multiple workers to complete the same task to correct errors. In that scenario, weights can be assigned to labels based upon annotator agreement. Theorem 1: f = (X(A + µL)XT)+XAV T minimizes the cost function C(f). Proof: Given the input X, we want to find the optimal mapping function f such that C(f) is minimi</context>
</contexts>
<marker>Belkin, Niyogi, Sindhwani, 2006</marker>
<rawString>M. Belkin, P. Niyogi, and V. Sindhwani. 2006. Manifold regularization: a geometric framework for learning from labeled and unlabeled examples. Journal of Machine Learning Research, pages 2399–2434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>R Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="7136" citStr="Bunescu and Mooney, 2005" startWordPosition="1111" endWordPosition="1114"> from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013)</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>R. Bunescu and R. Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chan</author>
<author>D Roth</author>
</authors>
<title>Exploiting background knowledge for relation extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>152--160</pages>
<contexts>
<context position="7590" citStr="Chan and Roth, 2010" startWordPosition="1183" endWordPosition="1186">ny of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system f</context>
</contexts>
<marker>Chan, Roth, 2010</marker>
<rawString>Y. Chan and D. Roth. 2010. Exploiting background knowledge for relation extraction. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 152–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<booktitle>In Proceedings of the Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>625--632</pages>
<contexts>
<context position="7081" citStr="Collins and Duffy, 2001" startWordPosition="1103" endWordPosition="1106">2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu </context>
<context position="27024" citStr="Collins and Duffy, 2001" startWordPosition="4455" endWordPosition="4458">ssified by a type filter, resulting in 3,000 negatives on average per relation. For each relation, we also collected 5,000 unlabeled examples and put them into two sets: unlabeled set 1 and 2 (2,500 examples in each set). No parameter tuning was taken and no relation specific heuristic rules were applied in all tests. In all manifold models, µ = 1. In SVM implementations, the trade-off parameter between training error and margin was set to 1 for all experiments. 5.1.2 Baseline Approaches We compare our approaches to three state-of-theart approaches including SVM with convolution tree kernels (Collins and Duffy, 2001), linear regression and SVM with linear kernels (Sch¨olkopf and Smola, 2002). To adapt the tree kernel to medical domain, we followed the approach in (Nguyen et al., 2009) to take the syntactic structures into consideration. We also added the argument types as features to the tree kernel. In the tree kernel implementation, we assigned the tree structure and the vector corresponding to the argument types 3If we take the perfect entity mentions and the associated concepts provided by i2b2 (Uzuner et al., 2011) as the input, our system can directly apply to i2b2 relation extraction data. However,</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>M. Collins and N. Duffy. 2001. Convolution kernels for natural language. In Proceedings of the Advances in Neural Information Processing Systems (NIPS), pages 625–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>J Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>423--429</pages>
<contexts>
<context position="7109" citStr="Culotta and Sorensen, 2004" startWordPosition="1107" endWordPosition="1110">o extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et a</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>A. Culotta and J. Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 423–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="19915" citStr="Deerwester et al., 1990" startWordPosition="3150" endWordPosition="3153">such as “subj”, “pred”, “mod nprep” and “objprep” (between arguments “antibiotic” and “lyme disease”) in Figure 2. • (4) Features modeling the incoming and outgoing links of both arguments. These features are useful to determine if a relation goes from argument 1 to argument 2 or vice versa. • (5) Topic features modeling the words in the dependency path. In the example given in Figure 2, the dependency path contains the following words: “be”, “standard therapy” and “for”. These features as well as the features in (6) are achieved by projecting the words onto a 100 dimensional LSI topic space (Deerwester et al., 1990) constructed from our medical corpus. • (6) Topic features modeling the words in the whole sentence. • (7) Bag-of-words features modeling the dependency path. In (7) and (8), we only consider the words that have occurred in the positive training data. 832 Notations: The input dataset X = {x1, · · · , xm} is represented as a feature-instance matrix. The desired label vector Y = {y1, · · · , yl} represents the labels of {x1, · · · , xl}, where l &lt; m. W is a weight matrix, where Wi,j = e−kxi−xjk2 models the similarity of xi and xj. I Ixi − xjI I stands for the Euclidean distance between xi and xj</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Demner-Fushman</author>
<author>J Lin</author>
</authors>
<title>Answering clinical questions with knowledge-based and statistical techniques.</title>
<date>2007</date>
<journal>Journal of Computational Linguistics,</journal>
<pages>56--63</pages>
<contexts>
<context position="8384" citStr="Demner-Fushman and Lin, 2007" startWordPosition="1312" endWordPosition="1315">extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical decision making. Four main clinical tasks that physicians engage in are discussed in (Demner-Fushman and Lin, 2007). They are Therapy- select treatments to offer a patient, taking consideration of effectiveness, risk, cost and other factors (prevention is under the general category of Therapy), Diagnosis (including differential diagnosis based on findings and diagnostic test), Etiology- identify the factors that cause the disease and Prognosis- estimate the patient’s likely course over time. These activities can be translated into “search tasks”. For example, the search for therapy is usually the therapy selection given a disease. We did an independent study regarding what clinical questions usually ask fo</context>
<context position="9680" citStr="Demner-Fushman and Lin, 2007" startWordPosition="1520" endWordPosition="1523"> College of Physicians (ACP). This set includes questions about diseases, treatments, lab tests, and general facts1. Our analysis shows that about 15% of these questions ask for treatments, preventions or contraindicated drugs for a disease or another way around, 4% are about diagnosis tests, 6% are about the causes of a disease, 1% are about the locations of a disease, 25% are about the symptoms of a disease, 8% are asking for definitions, 7% are about guidelines and the remaining 34% questions either express no relations or some relations that are not very popular. Based on the analysis in (Demner-Fushman and Lin, 2007) and our own results, we decided to focus on seven key relations in the medical domain, which are described in Table 1. We call these relations “super relations”, since they cover most questions in the DD question set and align well with the analysis result in (Demner-Fushman and Lin, 2007). 3.2 Collect Training Data This section presents how we collect training data for each relation. The overall procedure is illustrated in Figure 1. 1Here’s an example of these questions and its answer: Question: The syndrome characterized by joint pain, abdominal pain, palpable purpura, and a nephritic sedim</context>
</contexts>
<marker>Demner-Fushman, Lin, 2007</marker>
<rawString>D. Demner-Fushman and J. Lin. 2007. Answering clinical questions with knowledge-based and statistical techniques. Journal of Computational Linguistics, 56:63–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hoffmann</author>
<author>C Zhang</author>
<author>X Ling</author>
<author>L Zettlemoyer</author>
<author>D S Weld</author>
</authors>
<title>Knowledge-based weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="7670" citStr="Hoffmann et al., 2011" startWordPosition="1199" endWordPosition="1202">eatures (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical d</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>R. Hoffmann, C. Zhang, X. Ling, L. Zettlemoyer, and D. S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
<author>R Grishman</author>
<author>H T Dang</author>
</authors>
<title>knowledge base population track.</title>
<date>2011</date>
<journal>Overview of the TAC</journal>
<booktitle>In Proceedings of the Text Analytics Conference.</booktitle>
<contexts>
<context position="7647" citStr="Ji et al., 2011" startWordPosition="1195" endWordPosition="1198">ructure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are i</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>H. Ji, R. Grishman, and H. T. Dang. 2011. Overview of the TAC 2011 knowledge base population track. In Proceedings of the Text Analytics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
</authors>
<title>Multi-task transfer learning for weaklysupervised relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>1012--1020</pages>
<contexts>
<context position="7569" citStr="Jiang, 2009" startWordPosition="1181" endWordPosition="1182">d methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relatio</context>
</contexts>
<marker>Jiang, 2009</marker>
<rawString>J. Jiang. 2009. Multi-task transfer learning for weaklysupervised relation extraction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP), pages 1012–1020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kambhatla</author>
</authors>
<title>Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL</booktitle>
<contexts>
<context position="6713" citStr="Kambhatla, 2004" startWordPosition="1048" endWordPosition="1049">concepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, </context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>N. Kambhatla. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. In Proceedings of the ACL 2004 on Interactive poster and demonstration sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lindberg</author>
<author>B Humphreys</author>
<author>A McCray</author>
</authors>
<title>The Unified Medical Language System.</title>
<date>1993</date>
<journal>Methods of Information in Medicine,</journal>
<pages>32--281</pages>
<contexts>
<context position="4670" citStr="Lindberg et al., 1993" startWordPosition="734" endWordPosition="737"> the conventional setups, like i2b2 (Uzuner et al., 2011). In i2b2 relation extraction task, entity mentions are manually labeled, and each mention has 1 of 3 concepts: ‘treatment’, ‘problem’, and ‘test’. To resemble real-world medical relation extraction challenges where perfect entity mentions do not exist, our new setup requires the entity mentions to be automatically detected. The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with more than 2.7 million distinct concepts (compared to 3 in i2b2). The huge amount of entity mentions, concepts and noisy concept assignments provide a tough situation that people have to face in real-world applications. • From the perspective of relation extraction applications, we identify “super relations”- the key relations that can facilitate clinical decision making (Table 1). We also present approaches to collect training data for these relations with a small amount of labeling effort. • From the perspective of relation extraction methodologies, we present a manifold model for relat</context>
<context position="6073" citStr="Lindberg et al., 1993" startWordPosition="952" endWordPosition="956">re fast and outperform the state-of-theart approaches on medical relation extraction by a large margin. We also apply our model to build a new medical relation knowledge base as a complement to the existing knowledge bases. 2 Background 2.1 Medical Ontologies and Sources Medical domain has a huge amount of natural language content found in textbooks, encyclopedias, guidelines, electronic medical records, and many other sources. It is also growing at an extremely high speed. Substantial understanding of the medical domain has already been included in the Unified Medical Language System (UMLS) (Lindberg et al., 1993), which includes medical concepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns</context>
<context position="15762" citStr="Lindberg et al., 1993" startWordPosition="2477" endWordPosition="2480">elation, the noise rate is 97%. To grow the size of the negative training set for each super relation, we also added a small amount of the most representative examples (also coming from K-medoids clustering) from each unrelated UMLS relation to the training set as negative examples. This resulted in more than 10,000 extra negative examples for each relation. 3.3 Parsing and Typing The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with 2.7 million distinct concepts. The parser used in our system is MedicalESG, an adaptation of ESG (English Slot Grammar) (McCord et al., 2012) to the medical domain with extensions of medical lexicons integrated in the UMLS 2012 Release. Compared to MetaMap, MedicalESG is based on the same medical lexicons, 10 times faster and produces very similar parsing results. We use the semantic types defined in UMLS (Lindberg et al., 1993) to categorize argument types. The UMLS consists of a set of 133 subject categories, or semantic types, that provide a consistent categorization of more than 2M c</context>
<context position="32408" citStr="Lindberg et al., 1993" startWordPosition="5355" endWordPosition="5358">ed data will not help (Singh et al., 2008). We tested the tree kernel-based approach without integrating the medical types as well. That resulted in very poor performance: the average F1 score was below 30%. We also applied the rules used in SEMREP (Rindflesch and Fiszman, 2003) to this dataset. Since the relations detected by 835 SEMREP rules cannot be perfectly aligned with super relations, we cannot directly compare the results. Overall speaking, SEMREP rules are very conservative and detect very few relations from the same text. 5.2 Knowledge Base (KB) Construction The UMLS Metathesaurus (Lindberg et al., 1993) contains a large amount of manually extracted relation knowledge. Such knowledge is invaluable for people to collect training data to build new relation detectors. One downside of using this KB is its incompleteness. For example, it only contains the treatments for about 8,000 diseases, which are far from sufficient. Further, the medical knowledge is changing extremely quickly, making people hard to understand it, and update it in the knowledge base in a timely manner. To address these challenges, we constructed our own relation KB as a complement to the UMLS relation KB. We directly ran our </context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>D. Lindberg, B. Humphreys, and A. McCray. 1993. The Unified Medical Language System. Methods of Information in Medicine, 32:281–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M McCord</author>
<author>J W Murdock</author>
<author>B K Boguraev</author>
</authors>
<title>Deep parsing in Watson.</title>
<date>2012</date>
<journal>IBM Journal of Research and Development,</journal>
<volume>56</volume>
<contexts>
<context position="15909" citStr="McCord et al., 2012" startWordPosition="2502" endWordPosition="2505">sentative examples (also coming from K-medoids clustering) from each unrelated UMLS relation to the training set as negative examples. This resulted in more than 10,000 extra negative examples for each relation. 3.3 Parsing and Typing The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with 2.7 million distinct concepts. The parser used in our system is MedicalESG, an adaptation of ESG (English Slot Grammar) (McCord et al., 2012) to the medical domain with extensions of medical lexicons integrated in the UMLS 2012 Release. Compared to MetaMap, MedicalESG is based on the same medical lexicons, 10 times faster and produces very similar parsing results. We use the semantic types defined in UMLS (Lindberg et al., 1993) to categorize argument types. The UMLS consists of a set of 133 subject categories, or semantic types, that provide a consistent categorization of more than 2M concepts represented in the UMLS Metathesaurus. Our system assigns each relation argument with one or more UMLS semantic types through a two step pr</context>
</contexts>
<marker>McCord, Murdock, Boguraev, 2012</marker>
<rawString>M. McCord, J. W. Murdock, and B. K. Boguraev. 2012. Deep parsing in Watson. IBM Journal of Research and Development, 56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>H Fox</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>A novel use of statistical parsing to extract information from text.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference.</booktitle>
<contexts>
<context position="6608" citStr="Miller et al., 2000" startWordPosition="1032" endWordPosition="1035">y been included in the Unified Medical Language System (UMLS) (Lindberg et al., 1993), which includes medical concepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to im</context>
</contexts>
<marker>Miller, Fox, Ramshaw, Weischedel, 2000</marker>
<rawString>S. Miller, H. Fox, L. Ramshaw, and R. Weischedel. 2000. A novel use of statistical parsing to extract information from text. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Min</author>
<author>R Grishman</author>
<author>L Wan</author>
<author>C Wang</author>
<author>D Gondek</author>
</authors>
<title>Distant supervision for relation extraction with an incomplete knowledge base.</title>
<date>2013</date>
<booktitle>In The 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).</booktitle>
<contexts>
<context position="7736" citStr="Min et al., 2013" startWordPosition="1212" endWordPosition="1215">and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical decision making. Four main clinical tasks that physicians engage in</context>
</contexts>
<marker>Min, Grishman, Wan, Wang, Gondek, 2013</marker>
<rawString>B. Min, R. Grishman, L. Wan, C. Wang, and D. Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In The 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mintz</author>
<author>S Bills</author>
<author>R Snow</author>
<author>D Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="7556" citStr="Mintz et al., 2009" startWordPosition="1177" endWordPosition="1180"> rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in build</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP), pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nguyen</author>
<author>A Moschitti</author>
<author>G Riccardi</author>
</authors>
<title>Convolution kernels on constituent, dependency and sequential structures for relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="27195" citStr="Nguyen et al., 2009" startWordPosition="4485" endWordPosition="4488">eled set 1 and 2 (2,500 examples in each set). No parameter tuning was taken and no relation specific heuristic rules were applied in all tests. In all manifold models, µ = 1. In SVM implementations, the trade-off parameter between training error and margin was set to 1 for all experiments. 5.1.2 Baseline Approaches We compare our approaches to three state-of-theart approaches including SVM with convolution tree kernels (Collins and Duffy, 2001), linear regression and SVM with linear kernels (Sch¨olkopf and Smola, 2002). To adapt the tree kernel to medical domain, we followed the approach in (Nguyen et al., 2009) to take the syntactic structures into consideration. We also added the argument types as features to the tree kernel. In the tree kernel implementation, we assigned the tree structure and the vector corresponding to the argument types 3If we take the perfect entity mentions and the associated concepts provided by i2b2 (Uzuner et al., 2011) as the input, our system can directly apply to i2b2 relation extraction data. However, the i2b2 data has a tough data use agreement. Our legal team held several rounds of negotiations with the i2b2 data owner and then decided we should not use it due to the</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2009</marker>
<rawString>T. Nguyen, A. Moschitti, and G. Riccardi. 2009. Convolution kernels on constituent, dependency and sequential structures for relation extraction. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>L Yao</author>
<author>A McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD).</booktitle>
<contexts>
<context position="7630" citStr="Riedel et al., 2010" startWordPosition="1191" endWordPosition="1194">o learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the rel</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>S. Riedel, L. Yao, and A. McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T C Rindflesch</author>
<author>M Fiszman</author>
</authors>
<title>The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text.</title>
<date>2003</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>36--462</pages>
<contexts>
<context position="6405" citStr="Rindflesch and Fiszman, 2003" startWordPosition="1002" endWordPosition="1005">content found in textbooks, encyclopedias, guidelines, electronic medical records, and many other sources. It is also growing at an extremely high speed. Substantial understanding of the medical domain has already been included in the Unified Medical Language System (UMLS) (Lindberg et al., 1993), which includes medical concepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree ker</context>
<context position="32065" citStr="Rindflesch and Fiszman, 2003" startWordPosition="5302" endWordPosition="5305">and (2) strongly indicates that how to utilize more unlabeled data to achieve a significant improvement is non-trivial and deserves more attention. To what extensions the unlabeled data can help the learning process is an open problem. Generally speaking, when the existing data is sufficient to characterize the dataset geometry, adding more unlabeled data will not help (Singh et al., 2008). We tested the tree kernel-based approach without integrating the medical types as well. That resulted in very poor performance: the average F1 score was below 30%. We also applied the rules used in SEMREP (Rindflesch and Fiszman, 2003) to this dataset. Since the relations detected by 835 SEMREP rules cannot be perfectly aligned with super relations, we cannot directly compare the results. Overall speaking, SEMREP rules are very conservative and detect very few relations from the same text. 5.2 Knowledge Base (KB) Construction The UMLS Metathesaurus (Lindberg et al., 1993) contains a large amount of manually extracted relation knowledge. Such knowledge is invaluable for people to collect training data to build new relation detectors. One downside of using this KB is its incompleteness. For example, it only contains the treat</context>
</contexts>
<marker>Rindflesch, Fiszman, 2003</marker>
<rawString>T. C. Rindflesch and M. Fiszman. 2003. The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text. Journal of Biomedical Informatics, 36:462–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Sch¨olkopf</author>
<author>A J Smola</author>
</authors>
<title>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<marker>Sch¨olkopf, Smola, 2002</marker>
<rawString>B. Sch¨olkopf and A. J. Smola. 2002. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Singh</author>
<author>R D Nowak</author>
<author>X Zhu</author>
</authors>
<title>Unlabeled data: now it helps, now it doesnot.</title>
<date>2008</date>
<booktitle>In Proceedings of the Advances in Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="31828" citStr="Singh et al., 2008" startWordPosition="5262" endWordPosition="5265">nlabeled examples, and achieved the best performance among all approaches. On one hand, this result shows that using more unlabeled data can further improve the result. On the other hand, the insignificant improvement over (1) and (2) strongly indicates that how to utilize more unlabeled data to achieve a significant improvement is non-trivial and deserves more attention. To what extensions the unlabeled data can help the learning process is an open problem. Generally speaking, when the existing data is sufficient to characterize the dataset geometry, adding more unlabeled data will not help (Singh et al., 2008). We tested the tree kernel-based approach without integrating the medical types as well. That resulted in very poor performance: the average F1 score was below 30%. We also applied the rules used in SEMREP (Rindflesch and Fiszman, 2003) to this dataset. Since the relations detected by 835 SEMREP rules cannot be perfectly aligned with super relations, we cannot directly compare the results. Overall speaking, SEMREP rules are very conservative and detect very few relations from the same text. 5.2 Knowledge Base (KB) Construction The UMLS Metathesaurus (Lindberg et al., 1993) contains a large am</context>
</contexts>
<marker>Singh, Nowak, Zhu, 2008</marker>
<rawString>A. Singh, R. D. Nowak, and X. Zhu. 2008. Unlabeled data: now it helps, now it doesnot. In Proceedings of the Advances in Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>J Tibshirani</author>
<author>R Nallapati</author>
<author>C D Manning</author>
</authors>
<title>Multi-instance multilabel learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP).</booktitle>
<contexts>
<context position="7693" citStr="Surdeanu et al., 2012" startWordPosition="1203" endWordPosition="1207">ffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical decision making. Four ma</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>M. Surdeanu, J. Tibshirani, R. Nallapati, and C. D. Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Takamatsu</author>
<author>I Sato</author>
<author>H Nakagawa</author>
</authors>
<title>Reducing wrong labels in distant supervision for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="7717" citStr="Takamatsu et al., 2012" startWordPosition="1208" endWordPosition="1211">Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical decision making. Four main clinical tasks that p</context>
</contexts>
<marker>Takamatsu, Sato, Nakagawa, 2012</marker>
<rawString>S. Takamatsu, I. Sato, and H. Nakagawa. 2012. Reducing wrong labels in distant supervision for relation extraction. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨O Uzuner</author>
<author>B R South</author>
<author>S Shen</author>
<author>S L DuVall</author>
</authors>
<title>i2b2/VA challenge on concepts, assertions, and relations in clinical text.</title>
<date>2011</date>
<journal>Journal ofAmerican Medical Informatics Association,</journal>
<pages>18--552</pages>
<contexts>
<context position="4105" citStr="Uzuner et al., 2011" startWordPosition="643" endWordPosition="646">pected. Computing the optimal weights in a regression model and preserving manifold topology are conflicting objectives, we 828 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 828–838, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics present a closed-form solution to ideally balance these two goals. The contributions of this paper on medical relation extraction are three-fold: • The problem setup is new. There is a “fundamental” difference between our problem setup and the conventional setups, like i2b2 (Uzuner et al., 2011). In i2b2 relation extraction task, entity mentions are manually labeled, and each mention has 1 of 3 concepts: ‘treatment’, ‘problem’, and ‘test’. To resemble real-world medical relation extraction challenges where perfect entity mentions do not exist, our new setup requires the entity mentions to be automatically detected. The most well-known tool to detect medical entity mentions is MetaMap (Aronson, 2001), which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary (Lindberg et al., 1993) with more than 2.7 million distinc</context>
<context position="8053" citStr="Uzuner et al., 2011" startWordPosition="1260" endWordPosition="1263">has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain is to identify the relations that are important for clinical decision making. Four main clinical tasks that physicians engage in are discussed in (Demner-Fushman and Lin, 2007). They are Therapy- select treatments to offer a patient, taking consideration of effectiveness, risk, cost and other factors (prevention is under the general category of Therapy), Diagnosis (including differential diagnosis based on findings and diagnostic test), Etio</context>
<context position="27537" citStr="Uzuner et al., 2011" startWordPosition="4541" endWordPosition="4544">s to three state-of-theart approaches including SVM with convolution tree kernels (Collins and Duffy, 2001), linear regression and SVM with linear kernels (Sch¨olkopf and Smola, 2002). To adapt the tree kernel to medical domain, we followed the approach in (Nguyen et al., 2009) to take the syntactic structures into consideration. We also added the argument types as features to the tree kernel. In the tree kernel implementation, we assigned the tree structure and the vector corresponding to the argument types 3If we take the perfect entity mentions and the associated concepts provided by i2b2 (Uzuner et al., 2011) as the input, our system can directly apply to i2b2 relation extraction data. However, the i2b2 data has a tough data use agreement. Our legal team held several rounds of negotiations with the i2b2 data owner and then decided we should not use it due to the high legal risks. We are not aware of other available medical relation extraction datasets that fit for our evaluations. C(f). � µ i,j 834 Table 2: F1 Scores from a Five-Fold Cross Validation Experiment SVM SVM Linear Manifold Manifold Manifold Manifold Tree Linear Regression Unlabeled Predicted Labels Predicted Labels Unlabeled+Predicted </context>
</contexts>
<marker>Uzuner, South, Shen, DuVall, 2011</marker>
<rawString>¨O. Uzuner, B. R. South, S. Shen, and S. L. DuVall. 2011. 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text. Journal ofAmerican Medical Informatics Association, 18:552–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>J Fan</author>
<author>A Kalyanpur</author>
<author>D Gondek</author>
</authors>
<title>Relation extraction with relation topics.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7609" citStr="Wang et al., 2011" startWordPosition="1187" endWordPosition="1190">sing tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data (Uzuner et al., 2011). 829 3 Identifying Key Medical Relations 3.1 Super Relations in Medical Domain The first step in building a relation extraction system for medical domain i</context>
</contexts>
<marker>Wang, Fan, Kalyanpur, Gondek, 2011</marker>
<rawString>C. Wang, J. Fan, A. Kalyanpur, and D. Gondek. 2011. Relation extraction with relation topics. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>A Kalyanpur</author>
<author>J Fan</author>
<author>B Boguraev</author>
<author>D Gondek</author>
</authors>
<title>Relation extraction and scoring in DeepQA.</title>
<date>2012</date>
<journal>IBM Journal of Research and Development,</journal>
<volume>56</volume>
<contexts>
<context position="1580" citStr="Wang et al., 2012" startWordPosition="239" endWordPosition="242">amount of knowledge sources and ontologies in the medical domain. Such information is also growing and changing extremely quickly, making the information difficult for people to read, process and remember. The combination of recent developments in information extraction and the availability of unparalleled medical resources thus offers us the unique opportunity to develop new techniques to help healthcare professionals overcome the cognitive challenges they face in clinical decision making. Relation extraction plays a key role in information extraction. Using question answering as an example (Wang et al., 2012): in question analysis, the semantic relations between the question focus and each term in the clue can be used to identify the weight of each term so that better search queries can be generated. In candidate answer generation, relations enable the background knowledge base to be used for potential candidate answer generation. In candidate answer scoring, relation-based matching algorithms can go beyond explicit lexical and syntactic information to detect implicit semantic relations shared across the question and passages. To construct a medical relation extraction system, several challenges h</context>
</contexts>
<marker>Wang, Kalyanpur, Fan, Boguraev, Gondek, 2012</marker>
<rawString>C. Wang, A. Kalyanpur, J. Fan, B. Boguraev, and D. Gondek. 2012. Relation extraction and scoring in DeepQA. IBM Journal of Research and Development, 56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhang</author>
<author>J Zhang</author>
<author>J Su</author>
<author>G Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="7333" citStr="Zhang et al., 2006" startWordPosition="1141" endWordPosition="1144"> Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE data (ACE, 2004). Recently, “distant supervision” has emerged to be a popular choice for training relation extractors without using manually labeled data (Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010; Wang et al., 2011; Riedel et al., 2010; Ji et al., 2011; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012; Min et al., 2013). Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>M. Zhang, J. Zhang, J. Su, and G. Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>R Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>419--426</pages>
<contexts>
<context position="6739" citStr="Zhao and Grishman, 2005" startWordPosition="1050" endWordPosition="1053">ns, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap (Aronson, 2001) is able to identify concepts in text. SEMREP (Rindflesch and Fiszman, 2003) can detect some relations using hand-crafted rules. 2.2 Relation Extraction To extract semantic relations from text, three types of approaches have been applied. Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns. Feature-based methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors. Recent results mainly rely on kernel-based methods. Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). Other researchers study how different approaches can be combined to improve the extraction performance. For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achie</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>S. Zhao and R. Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 419–426.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>