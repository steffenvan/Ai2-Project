<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.9995455">
A Hybrid Morpheme-Word Representation
for Machine Translation of Morphologically Rich Languages*
</title>
<author confidence="0.994938">
Minh-Thang Luong Preslav Nakov Min-Yen Kan
</author>
<affiliation confidence="0.9999245">
Department of Computer Science
National University of Singapore
</affiliation>
<address confidence="0.9714475">
13 Computing Drive
Singapore 117417
</address>
<email confidence="0.999576">
{luongmin,nakov,kanmy}@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99959085">
We propose a language-independent approach
for improving statistical machine translation
for morphologically rich languages using a
hybrid morpheme-word representation where
the basic unit of translation is the morpheme,
but word boundaries are respected at all stages
of the translation process. Our model extends
the classic phrase-based model by means
of (1) word boundary-aware morpheme-level
phrase extraction, (2) minimum error-rate
training for a morpheme-level translation
model using word-level BLEU, and (3) joint
scoring with morpheme- and word-level lan-
guage models. Further improvements are
achieved by combining our model with the
classic one. The evaluation on English to
Finnish using Europarl (714K sentence pairs;
15.5M English words) shows statistically sig-
nificant improvements over the classic model
based on BLEU and human judgments.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996453441176471">
The fast progress of statistical machine translation
(SMT) has boosted translation quality significantly.
While research keeps diversifying, the word remains
the atomic token-unit of translation. This is fine for
languages with limited morphology like English and
French, or no morphology at all like Chinese, but
it is inadequate for morphologically rich languages
like Arabic, Czech or Finnish (Lee, 2004; Goldwater
and McClosky, 2005; Yang and Kirchhoff, 2006).
This research was sponsored in part by CSIDM (grant #
200805) and by a National Research Foundation grant entitled
“Interactive Media Search” (grant # R-252-000-325-279).
There has been a line of recent SMT research
that incorporates morphological analysis as part of
the translation process, thus providing access to the
information within the individual words. Unfortu-
nately, most of this work either relies on language-
specific tools, or only works for very small datasets.
Below we propose a language-independent ap-
proach to SMT of morphologically rich lan-
guages using a hybrid morpheme-word representa-
tion where the basic unit of translation is the mor-
pheme, but word boundaries are respected at all
stages of the translation process. We use unsuper-
vised morphological analysis and we incorporate its
output into the process of translation, as opposed to
relying on pre-processing and post-processing only
as has been done in previous work.
The remainder of the paper is organized as fol-
lows. Section 2 reviews related work. Sections 3
and 4 present our morphological and phrase merging
enhancements. Section 5 describes our experiments,
and Section 6 analyzes the results. Finally, Section 7
concludes and suggests directions for future work.
</bodyText>
<sectionHeader confidence="0.999947" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9983462">
Most previous work on morphology-aware ap-
proaches relies heavily on language-specific tools,
e.g., the TreeTagger (Schmid, 1994) or the Buck-
walter Arabic Morphological Analyzer (Buckwal-
ter, 2004), which hampers their portability to
other languages. Moreover, the prevalent method
for incorporating morphological information is by
heuristically-driven pre- or post-processing. For
example, Sadat and Habash (2006) use different
combinations of Arabic pre-processing schemes
</bodyText>
<page confidence="0.962489">
148
</page>
<note confidence="0.817854">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 148–157,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999836590909091">
for Arabic-English SMT, whereas Oflazer and El-
Kahlout (2007) post-processes Turkish morpheme-
level translations by re-scoring n-best lists with a
word-based language model. These systems, how-
ever, do not attempt to incorporate their analysis as
part of the decoding process, but rather rely on mod-
els designed for word-token translation.
We should also note the importance of the trans-
lation direction: it is much harder to translate from a
morphologically poor to a morphologically rich lan-
guage, where morphological distinctions not present
in the source need to be generated in the target lan-
guage. Research in translating into morphologically
rich languages, has attracted interest for languages
like Arabic (Badr et al., 2008), Greek (Avramidis
and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn
and Haddow, 2009), Russian (Toutanova et al.,
2008), and Turkish (Oflazer and El-Kahlout, 2007).
These approaches, however, either only succeed in
enhancing the performance for small bi-texts (Badr
et al., 2008; Oflazer and El-Kahlout, 2007), or im-
prove only modestly for large bi-texts1.
</bodyText>
<sectionHeader confidence="0.996378" genericHeader="method">
3 Morphological Enhancements
</sectionHeader>
<bodyText confidence="0.999533416666667">
We present a morphologically-enhanced version of
the classic phrase-based SMT model (Koehn et al.,
2003). We use a hybrid morpheme-word representa-
tion where the basic unit of translation is the mor-
pheme, but word boundaries are respected at all
stages of the translation process. This is in con-
trast with previous work, where morphological en-
hancements are typically performed as pre-/post-
processing steps only.
In addition to changing the basic translation token
unit from a word to a morpheme, our model extends
the phrase-based SMT model with the following:
</bodyText>
<listItem confidence="0.993104666666667">
1. word boundary-aware morpheme-level phrase
extraction;
2. minimum error-rate training for a morpheme-
level model using word-level BLEU;
3. joint scoring with morpheme- and word-level
language models.
</listItem>
<bodyText confidence="0.958512">
We first introduce our morpheme-level represen-
tation, and then describe our enhancements.
</bodyText>
<footnote confidence="0.849554666666667">
1Avramidis and Koehn (2008) improved by 0.15 BLEU over
a 18.05 English-Greek baseline; Toutanova et al. (2008) im-
proved by 0.72 BLEU over a 36.00 English-Russian baseline.
</footnote>
<subsectionHeader confidence="0.999393">
3.1 Morphological Representation
</subsectionHeader>
<bodyText confidence="0.9998938">
Our morphological representation is based on the
output of an unsupervised morphological analyzer.
Following Virpioja et al. (2007), we use Morfessor,
which is trained on raw tokenized text (Creutz and
Lagus, 2007). The tool segments words into mor-
phemes annotated with the following labels: PRE
(prefix), STM (stem), SUF (suffix). Multiple prefixes
and suffixes can be proposed for each word; word
compounding is allowed as well. The output can be
described by the following regular expression:
</bodyText>
<equation confidence="0.914943666666667">
WORD = ( PRE* STM SUF* )+
For example, uncarefully is analyzed as
un/PRE+ care/STM+ ful/SUF+ ly/SUF
</equation>
<bodyText confidence="0.999707333333333">
The above token sequence forms the input to our
system. We keep the PRE/STM/SUF tags as part
of the tokens, and distinguish between care/STM+
and care/STM. Note also that the “+” sign is ap-
pended to each nonfinal tag so that we can distin-
guish word-internal from word-final morphemes.
</bodyText>
<subsectionHeader confidence="0.999863">
3.2 Word Boundary-aware Phrase Extraction
</subsectionHeader>
<bodyText confidence="0.9999478">
The core translation structure of a phrase-based
SMT model is the phrase table, which is learned
from a bilingual parallel sentence-aligned corpus,
typically using the alignment template approach
(Och and Ney, 2004). It contains a set of bilingual
phrase pairs, each associated with five scores: for-
ward and backward phrase translation probabilities,
forward and backward lexicalized translation proba-
bilities, and a constant phrase penalty.
The maximum phrase length n is normally limited
to seven words; higher values of n increase the table
size exponentially without actually yielding perfor-
mance benefit (Koehn et al., 2003). However, things
are different when translating with morphemes, for
two reasons: (1) morpheme-token phrases of length
n can span less than n words; and (2) morpheme-
token phrases may only partially span words.
The first point means that morpheme-token
phrase pairs span fewer word tokens, and thus cover
a smaller context, which may result in fewer total
extracted pairs compared to a word-level approach.
Figure 1 shows a case where three Finnish words
consist of nine morphemes. Previously, this issue
was addressed by simply increasing the value of n
when using morphemes, which is of limited help.
</bodyText>
<page confidence="0.97126">
149
</page>
<equation confidence="0.768648666666667">
SRC = theSTM newSTM , unPRE+democraticSTM immigrationSTM policySTM
TGT = uusiSTM , epäPRE+demokraatSTM+ tSUF+ iSUF+ sSUF+ enSUF maahanmuuttoPRE+ politiikanSTM
(uusi=new , epädemokraattisen=undemocratic maahanmuuttopolitiikan=immigration policy)
</equation>
<figureCaption confidence="0.96725">
Figure 1: Example of English-Finnish bilingual fragments morphologically segmented by Morfessor. Solid links
represent IBM Model 4 alignments at the morpheme-token level. Translation glosses for Finnish are given below.
</figureCaption>
<bodyText confidence="0.99973452">
The second point is more interesting: morpheme-
level phrases may span words partially, making them
potentially usable in translating unknown inflected
forms of known source language words, but also
creates the danger of generating sequences of mor-
phemes that are not legal target language words.
For example, let us consider the phrase in Fig-
ure 1: unPRE+ democraticSTM. The original
algorithm will extract the spurious phrase ep¨aPRE+
demokraatSTM+ tSUF+ iSUF+ sSUF+, beside
the correct one that has enSUF appended at the
end. Such a spurious phrase does not generally help
in translating unknown inflected forms, especially
for morphologically-rich languages that feature mul-
tiple affixes, but negatively affects the translation
model in terms of complexity and quality.
We solve both problems by modifying the phrase-
pair extraction algorithm so that morpheme-token
phrases can extend longer than n, as long as they
span n words or less. We further require that
word boundaries be respected2, i.e., morpheme-
token phrases span a sequence of whole words. This
is a fair extension of the morpheme-token system
with respect to a word-token one since both are re-
stricted to span up to n word-tokens.
</bodyText>
<subsectionHeader confidence="0.980776">
3.3 Morpheme-Token MERT Optimizing
Word-Token BLEU
</subsectionHeader>
<bodyText confidence="0.996988333333333">
Modern phrase-based SMT systems use a log-linear
model with the following typical feature functions:
language model probabilities, word penalty, distor-
tion cost, and the five parameters from the phrase ta-
ble. Their weights are set by optimizing BLEU score
(Papineni et al., 2001) directly using minimum error
rate training (MERT), as suggested by Och (2003).
In previous work, phrase-based SMT systems
using morpheme-token input/output naturally per-
</bodyText>
<footnote confidence="0.900794666666667">
2This means that we miss the opportunity to generate new
wordforms for known baseforms, but removes the problem of
proposing nonwords in the target language.
</footnote>
<bodyText confidence="0.998703611111111">
formed MERT at the morpheme-token level as well.
This is not optimal since the final expected system
output is a sequence of words, not morphemes. The
main danger is that optimizing a morpheme-token
BLEU score could lead to a suboptimal weight for
the word penalty feature function: this is because
the brevity penalty of BLEU is calculated with re-
spect to the number of morphemes, which may vary
for sentences with an identical number of words.
This motivates us to perform MERT at the word-
token level, although our input consists of mor-
phemes. In particular, for each iteration of MERT,
as soon as the decoder generates a morpheme-token
translation for a sentence, we convert it into a word-
token sequence, which is used to calculate BLEU.
We thus achieve MERT optimization at the word-
token level while translating a morpheme-token in-
put and generating a morpheme-token output.
</bodyText>
<subsectionHeader confidence="0.999676">
3.4 Scoring with Twin Language Models
</subsectionHeader>
<bodyText confidence="0.99999665">
An SMT system that takes morpheme-token input
and generates morpheme-token output should natu-
rally use a morpheme-token language model (LM).
This has the advantage of alleviating the problem of
data sparseness, especially when translating into a
morphologically rich language, since the LM would
be able to handle some new unseen inflected forms
of known words. On the negative side, a morpheme-
token LM spans fewer word-tokens and thus has a
more limited word “horizon” compared to one op-
erating at the word level. As with the maximum
phrase length, mechanically increasing the order of
the morpheme-token LM has a limited impact.
In order to address the issue in a more princi-
pled manner, we enhance our model with a second
LM that works at the word-token level. This LM is
used together with the morpheme-token LM, which
is achieved by using two separate feature functions
in the log-linear SMT model: one for each LM. We
further had to modify the Moses decoder so that
</bodyText>
<page confidence="0.985619">
150
</page>
<subsubsectionHeader confidence="0.904648">
Previous hypotheses Current hypothesis
</subsubsectionHeader>
<bodyText confidence="0.830776">
uusiSTM , epäPRE+ demokraatSTM+ tSUF+ iSUF+ sSUF+ enSUF maahanmuuttoPRE+ politiikanSTM
</bodyText>
<listItem confidence="0.999946333333333">
• Score: “sSUF+enSUF maahanmuuttoPRE+” ; “enSUF maahanmuuttoPRE+ politiikanSTM ”
• Concatenate: uusi , epädemokraattisen maahanmuuttopolitiikan
• Score: “, epädemokraattisen maahanmuuttopolitiikan”
</listItem>
<figureCaption confidence="0.749952857142857">
Figure 2: Scoring with twin LMs. Shown are: (i) The current state of the decoding process with the target phrases
covered by the current partial hypotheses. (ii, iii) Scoring with 3-gram morpheme-token and 3-gram word-token LMs,
respectively. For the word-token LM, the morpheme-token sequence is concatenated into word-tokens before scoring.
it can be enhanced with an appropriate word-token
“view” on the partial morpheme-level hypotheses3.
The interaction of the twin LMs is illustrated in
Figure 2. The word-token LM can capture much
</figureCaption>
<bodyText confidence="0.977116380952381">
longer phrases and more complete contexts such
as “, ep¨ademokraattisen maahanmuuttopolitiikan”
compared to the morpheme-token LM.
Note that scoring with two LMs that see the out-
put sequence as different numbers of tokens is not
readily offered by the existing SMT decoders. For
example, the phrase-based model in Moses (Koehn
et al., 2007) allows scoring with multiple LMs, but
assumes they use the same token granularity, which
is useful for LMs trained on different monolingual
corpora, but cannot handle our case. While the fac-
tored translation model (Koehn and Hoang, 2007) in
Moses does allow scoring with models of different
granularity, e.g., lemma-token and word-token LMs,
it requires a 1:1 correspondence between the tokens
in the different factors, which clearly is not our case.
Note that scoring with twin LMs is conceptu-
ally superior to n-best re-scoring with a word-token
LM, e.g., (Oflazer and El-Kahlout, 2007), since it is
tightly integrated into decoding: it scores partial hy-
potheses and influenced the search process directly.
</bodyText>
<sectionHeader confidence="0.987795" genericHeader="method">
4 Enriching the Translation Model
</sectionHeader>
<bodyText confidence="0.999525555555556">
Another general strategy for combining evidence
from the word-token and the morpheme-token rep-
resentations is to build two separate SMT systems
and then combine them. This can be done as a
post-processing system combination step; see (Chen
et al., 2009a) for an overview of such approaches.
3We use the term “hypothesis” to collectively refer to the
following (Koehn, 2003): the source phrase covered, the cor-
responding target phrase, and most importantly, a reference to
the previous hypothesis that it extends.
However, for phrase-based SMT systems, it is theo-
retically more appealing to combine their phrase ta-
bles since this allows the translation models of both
systems to influence the hypothesis search directly.
We now describe our phrase table combination
approach. Note that it is orthogonal to the work pre-
sented in the previous section, which suggests com-
bining the two (which we will do in Section 5).
</bodyText>
<subsectionHeader confidence="0.999669">
4.1 Building a Twin Translation Model
</subsectionHeader>
<bodyText confidence="0.9999653">
Figure 3 shows a general scheme of our twin trans-
lation model. First, we tokenize the input at differ-
ent granularities: (1) morpheme-token and (2) word-
token. We then build separate phrase tables (PT) for
the two inputs: a word-token PTw and a morpheme-
token PTm. Second, we re-tokenize PTw at the
morpheme level, thus obtaining a new phrase table
PTw,m, which is of the same granularity as PTm.
Finally, we merge PTw,m and PTm, and we input
the resulting phrase table to the decoder.
</bodyText>
<figure confidence="0.399601">
PT merging
</figure>
<figureCaption confidence="0.863439">
Figure 3: Building a twin phrase table (PT). First, sep-
arate PTs are generated for different input granularities:
word-token and morpheme-token. Second, the word-
token PT is retokenized at the morpheme-token level. Fi-
nally, the two PTs are merged and used by the decoder.
</figureCaption>
<figure confidence="0.996022166666667">
Word Morpheme
GIZA++
Word alignment Morpheme alignment
GIZA++
Phrase Extraction
PTS
Phrase Extraction
PTm
Morphological
segmentation
PTS→m
Decoding
</figure>
<page confidence="0.940589">
151
</page>
<subsectionHeader confidence="0.983126">
4.2 Merging and Normalizing Phrase Tables
</subsectionHeader>
<bodyText confidence="0.999956961538462">
Below we first describe the two general phrase ta-
ble combination strategies used in previous work:
(1) direct merging using additional feature func-
tions, and (2) phrase table interpolation. We then
introduce our approach.
Add-feature methods. The first line of research
on phrase table merging is exemplified by (Niehues
et al., 2009; Chen et al., 2009b; Do et al., 2009;
Nakov and Ng, 2009). The idea is to select one of
the phrase tables as primary and to add to it all non-
duplicating phrase pairs from the second table to-
gether with their associated scores. For each entry,
features can be added to indicate its origin (whether
from the primary or from the secondary table). Later
in our experiments, we will refer to these baseline
methods as add-1 and add-2, depending on how
many additional features have been added. The val-
ues we used for these features in the baseline are
given in Section 5.4; their weights in the log-linear
model were set in the standard way using MERT.
Interpolation-based methods. A problem with
the above method is that the scores in the merged
phrase table that correspond to forward and back-
ward phrase translation probabilities, and forward
and backward lexicalized translation probabilities
can no longer be interpreted as probabilities since
they are not normalized any more. Theoretically,
this is not necessarily a problem since the log-linear
model used by the decoder does not assume that the
scores for the feature functions come from a normal-
ized probability distribution. While it is possible to
re-normalize the scores to convert them into prob-
abilities, this is rarely done; it also does not solve
the problem with the dropped scores for the dupli-
cated phrases. Instead, the conditional probabilities
in the two phrase tables are often interpolated di-
rectly, e.g., using linear interpolation. Representa-
tive work adopting this approach is (Wu and Wang,
2007). We refer to this method as interpolation.
Our method. The above phrase merging ap-
proaches have been proposed for phrase tables de-
rived from different sources. This is in contrast with
our twin translation scenario, where the morpheme-
token phrase tables are built from the same training
dataset; the main difference being that word align-
ments and phrase extraction were performed at the
word-token level for PTw→m and at the morpheme-
token level for PTm. Thus, we propose different
merging approaches for the phrase translation prob-
abilities and for the lexicalized probabilities.
In phrase-based SMT, phrase translation probabil-
ities are computed using maximum likelihood (ML)
</bodyText>
<equation confidence="0.95054">
estimation φ(¯f|¯e) = #(�f,�e) e�,where #(
Ef #(f,
</equation>
<bodyText confidence="0.9997116">
the number of times the pair ( f, ¯e) is extracted from
the training dataset (Koehn et al., 2003). In order to
preserve the normalized ML estimations as much as
possible, we refrain from interpolation. Instead, we
use the raw counts for the two models #m( ¯f, ¯e) and
</bodyText>
<equation confidence="0.833025666666667">
#w→m( f, ¯e) directly as follows:
f, ¯e) + #w→m( f, ¯e)
f, ¯e) + Ef� #w→m( f, ¯e)
</equation>
<bodyText confidence="0.999994444444444">
For lexicalized translation probabilities, we would
like to use simple interpolation. However, we notice
that when a phrase pair belongs to only one of the
phrase tables, the corresponding lexicalized score
for the other table would be zero. This might cause
some good phrases to be penalized just because they
were not extracted in both tables, which we want to
prevent. We thus perform interpolation from PTm
and PTw according to the following formula:
</bodyText>
<equation confidence="0.981499">
lex( f|¯e) = α x lexm( ¯fm|¯em)
+ (1 − α) x lexw( ¯fw|¯ew)
</equation>
<bodyText confidence="0.983705421052631">
where the concatenation of fm and ¯em into word-
token sequences yields ¯fw and ¯ew, respectively.
If both ( ¯fm, ¯em) and (¯fw, ¯ew) are present in PTm
and PTw, respectively, we have a simple interpola-
tion of their corresponding lexicalized scores lexm
and lexw. However, if one of them is missing, we
do not use a zero for its corresponding lexicalized
score, but use an estimate as follows.
For example, if only the entry ( fm, ¯em) is present
in PTm, we first convert ( fm,¯em) into a word-token
pair ( fm→w,¯em→w), and then induce a correspond-
ing word alignment from the morpheme-token align-
ment of (¯fm,¯em). We then estimate a lexicalized
phrase score using the original formula given in
(Koehn et al., 2003), where we plug this induced
word alignment and word-token lexical translation
probabilities estimated from the word-token dataset
The case when (¯fw, ¯ew) is present in PTw, but
(¯fm, ¯em) is not, is solved similarly.
</bodyText>
<equation confidence="0.99441">
f, ¯e) is
¯f, ¯e) = #m(
f� #m(
φ(
</equation>
<page confidence="0.993478">
152
</page>
<sectionHeader confidence="0.997789" genericHeader="method">
5 Experiments and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.840559">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.99825925">
In our experiments, we use the English-Finnish data
from the 2005 shared task (Koehn and Monz, 2005),
which is split into training, development, and test
portions; see Table 1 for details. We further split
the training dataset into four subsets T1, T2, T3, and
T4 of sizes 40K, 80K, 160K, and 320K parallel sen-
tence pairs, which we use for studying the impact of
training data size on translation performance.
</bodyText>
<table confidence="0.9972318">
Sent. Avg. words Avg. morph.
en fi en fi
Train 714K 21.62 15.80 24.68 26.15
Dev 2K 29.33 20.99 33.40 34.94
Test 2K 28.98 20.72 33.10 34.47
</table>
<tableCaption confidence="0.999688">
Table 1: Dataset statistics. Shown are the number of
</tableCaption>
<bodyText confidence="0.726101666666667">
parallel sentences, and the average number of words and
Morfessor morphemes on the English and Finnish sides
of the training, development and test datasets.
</bodyText>
<subsectionHeader confidence="0.998201">
5.2 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.9977355">
We build two phrase-based baseline SMT systems,
both using Moses (Koehn et al., 2007):
w-system: works at the word-token level, extracts
phrases of up to seven words, and uses a 4-gram
word-token LM (as typical for phrase-based SMT);
m-system: works at the morpheme level, tok-
enized using Morfessor4 and augmented with “+” as
described in Section 3.1.
Following Oflazer and El-Kahlout (2007) and Vir-
pioja et al. (2007), we use phrases of up to 10
morpheme-tokens and a 5-gram morpheme-token
LM. None of the enhancements described previ-
ously is applied yet. After decoding, morphemes are
concatenated back to words using the “+” markers.
To evaluate the translation quality, we compute
BLEU (Papineni et al., 2001) at the word-token
level. We further introduce a morpheme-token ver-
sion of BLEU, which we call m-BLEU: it first seg-
ments the system output and the reference trans-
lation into morpheme-tokens and then calculates a
BLEU score as usual. Table 2 shows the baseline re-
sults. We can see that the m-system achieves much
</bodyText>
<footnote confidence="0.981116">
4We retrained Morfessor for Finnish/English on the
Finnish/English side of the training dataset.
</footnote>
<table confidence="0.998892857142857">
w-system m-system
BLEU m-BLEU BLEU m-BLEU
T1 11.56 45.57 11.07 49.15
T2 12.95 48.63 12.68 53.78
T3 13.64 50.30 13.32 54.40
T4 14.20 50.85 13.57 54.70
Full 14.58 53.05 14.08 55.26
</table>
<tableCaption confidence="0.992724">
Table 2: Baseline system performance (on the test
dataset). Shown are word BLEU and morpheme m-
BLEU scores for the w-system and m-system.
</tableCaption>
<bodyText confidence="0.999831285714286">
higher m-BLEU scores, indicating that it may have
better morpheme coverage5. However, the m-system
is outperformed by the w-system on the classic word-
token BLEU, which means that it either does not
perform as well as the w-system or that word-token
BLEU is not capable of measuring the morpheme-
level improvements. We return to this question later.
</bodyText>
<subsectionHeader confidence="0.999261">
5.3 Adding Morphological Enhancements
</subsectionHeader>
<bodyText confidence="0.999834166666667">
We now add our three morphological enhancements
from Section 3 to the baseline m-system:
phr (training) allow morpheme-token phrases to
get potentially longer than seven morpheme-tokens
as long as they cover no more than seven words;
tune (tuning) MERT for morpheme-token trans-
lations while optimizing word-token BLEU;
lm (decoding) scoring morpheme-token transla-
tion hypotheses with a 5-gram morpheme-token and
a 4-gram word-token LM.
The results are shown in Table 3 (ii). As we can
see, each of the three enhancements yields improve-
ments in BLEU score over the m-system, both for
small and for large training corpora. In terms of per-
formance ranking, tune achieves the best absolute
improvement of 0.66 BLEU points on T1 and of 0.47
points on the full dataset, followed by lm and phr.
Table 3 (iii) further shows that using phr and
lm together yields absolute improvements of 0.70
BLEU points on T1 and 0.50 points on the full train-
ing dataset. Further incorporating tune, however,
only helps when training on T1.
Overall, the morphological enhancements are on
par with the w-system baseline, and yield sizable im-
</bodyText>
<footnote confidence="0.967347">
5Note that these morphemes were generated automatically
and thus many of them are erroneous.
</footnote>
<page confidence="0.995814">
153
</page>
<table confidence="0.9997195">
System T1 (40K) Full (714K)
w-system (w) 11.56 14.58
m-system (m) 11.07 14.08
m+phr 11.44+0.37 14.43+0.35
m+tune 11.73+0.66 14.55+0.47
m+lm 11.58+0.51 14.53+0.45
m+phr+lm 11.77+0.70 14.58+0.50
m+phr+lm+tune 11.90+0.83 14.39+0.31
</table>
<tableCaption confidence="0.999277">
Table 3: Impact of the morphological enhancements
</tableCaption>
<bodyText confidence="0.772741166666667">
(on test dataset). Shown are BLEU scores (in %) for
training on Tl and on the full dataset for (i) baselines,
(ii) enhancements individually, and (iii) combined. Su-
perscripts indicate absolute improvements w.r.t m-system.
provements over the m-system baseline: 0.83 BLEU
points on T1 and 0.50 on the full training dataset.
</bodyText>
<subsectionHeader confidence="0.995585">
5.4 Combining Translation Tables
</subsectionHeader>
<bodyText confidence="0.999426428571428">
Finally, we investigate the effect of combining
phrase tables derived from a word-token and a
morpheme-token input, as described in Section 4.
We experiment with the following merging methods:
add-1: phrase table merging using one table as
primary and adding one extra feature6;
add-2: phrase table merging using one table as
primary and adding two extra features7;
interpolation: simple linear interpolation with
one parameter α;
ourMethod: our interpolation-like merging
method described in Section 4.2.
Parameter tuning. We tune the parameters of the
above methods on the development dataset.
</bodyText>
<equation confidence="0.427163">
T1 (40K) Full (714K)
PTm is primary 11.99 13.45
PTw,m is primary 12.26 14.19
</equation>
<tableCaption confidence="0.7921505">
Table 4: Effect of selection of primary phrase table for
add-1 (on dev dataset): PT�-,,,,, derived from a word-
token input, vs. PT,,,,, from a morpheme-token input.
Shown is BLEU (in %) on Tl and the full training dataset.
</tableCaption>
<bodyText confidence="0.99923">
For add-1 and add-2, we need to decide which
(PTw,m or PTm) phrase table should be consid-
</bodyText>
<footnote confidence="0.968071833333333">
6The feature values are e1, e213 or e1/3 (e=2.71828...);
when the phrase pair comes from both tables, from the primary
table only, and from the secondary table only, respectively.
7The feature values are (e1, e1), (e1, e°) or (e°, e1) when
the phrase pair comes from both tables, from the primary table
only, and from the secondary table only, respectively.
</footnote>
<bodyText confidence="0.9997818">
ered the primary table. Table 4 shows the results
when trying both strategies on add-1. As we can see,
using PTw,m as primary performs better on T1 and
on the full training dataset; thus, we will use it as
primary on the test dataset for add-1 and add-2.
For interpolation-based methods, we need to
choose a value for the interpolation parameters. Due
to time constraints, we use the same value for the
phrase translation probabilities and for the lexical-
ized probabilities, and we perform grid search for
α E 10.3, 0.4, 0.5, 0.6, 0.71 using interpolate on the
full training dataset. As Table 5 shows, α = 0.6
turns out to work best on the development dataset;
we will use this value in our experiments on the test
dataset both for interpolate and for ourMethod8.
</bodyText>
<table confidence="0.939912">
α 0.3 0.4 0.5 0.6 0.7
BLEU 14.17 14.49 14.6 14.73 14.52
</table>
<tableCaption confidence="0.976935">
Table 5: Trying different values for interpolate (on dev
dataset). BLEU (in %) is for the full training dataset.
</tableCaption>
<bodyText confidence="0.980026636363636">
Evaluation on the test dataset. We integrate the
morphologically enhanced system m+phr+lm and
the word-token based w-system using the four merg-
ing methods above. The results for the full train-
ing dataset are shown in Table 6. As we can see,
add-1 and add-2 make little difference compared to
the m-system baseline. In contrast, interpolation and
ourMethod yield sizable absolute improvements of
0.55 and 0.74 BLEU points, respectively, over the
m-system; moreover, they outperform the w-system.
Merging methods Full (714K)
</bodyText>
<equation confidence="0.808312666666667">
m-system 14.08
(i) w-system 14.58
(ii) add-1 14.25+0.17
add-2 13.89−0.19
(iii) interpolation 14.63+0.55
ourMethod 14.82+0.74
</equation>
<tableCaption confidence="0.904845333333333">
Table 6: Merging m+phr+lm and w-system (on test
dataset). BLEU (in %) is for the full training dataset. Su-
perscripts indicate performance gain/loss w.r.t m-system.
</tableCaption>
<sectionHeader confidence="0.998503" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.9870205">
Below we assess the significance of our results based
on micro-analysis and human judgments.
</bodyText>
<footnote confidence="0.89427">
8Note that this might put ourMethod at disadvantage.
</footnote>
<page confidence="0.999006">
154
</page>
<subsectionHeader confidence="0.891882">
6.1 Translation Model Comparison
</subsectionHeader>
<bodyText confidence="0.999804857142857">
We first compare the following three phrase ta-
bles: PTm of m-system, maximum phrase length of
10 morpheme-tokens; PTw,m of w-system, maxi-
mum phrase length of 7 word-tokens, re-segmented
into morpheme-tokens; and PTm+phr – morpheme-
token input using word boundary-aware phrase ex-
traction, maximum phrase length of 7 word-tokens.
</bodyText>
<equation confidence="0.973404">
Full (714K)
PTm 43.5M
PTw,m 28.9M
PTm+phr 22.5M
(ii) PTm+phr n PTm 21.4M
PTm+phr � P Tw�m 10.7M
</equation>
<tableCaption confidence="0.9985995">
Table 7: Phrase table statistics. The number of phrase
pairs in (i) individual PTs and (ii) PT overlap, is shown.
</tableCaption>
<bodyText confidence="0.993247833333333">
PT.,,,+ph, versus PT.,,,. Table 7 shows that
PTm+phr is about half the size of PTm. Still, as
Table 3 shows, m+phr outperforms the m-system.
Moreover, 95.07% (21.4M/22.5M) of the phrase
pairs in PTm+phr are also in PTm, which confirms
that boundary-aware phrase extraction selects good
phrase pairs from PTm to be retained in PTm+phr.
PT.,,,+ph, versus PT.,,,,. These two tables
are comparable in size: 22.5M and 28.9M pairs,
but their overlap is only 47.67% (10.7M/22.5M) of
PTm+phr. Thus, enriching the translation model
with PTw,m helps improve coverage.
</bodyText>
<subsectionHeader confidence="0.999878">
6.2 Significance of the Results
</subsectionHeader>
<bodyText confidence="0.999455733333333">
Table 8 shows the performance of our system com-
pared to the two baselines: m-system and w-system.
We achieve an absolute improvement of 0.74 BLEU
points over the m-system, from which our system
evolved. This might look modest, but note that
the baseline BLEU is only 14.08, and thus the rel-
ative improvement is 5.6%, which is not trivial.
Furthermore, we outperform the w-system by 0.24
points (1.56% relative). Both improvements are sta-
tistically significant with p &lt; 0.01, according to
Collins’ sign test (Collins et al., 2005).
In terms of m-BLEU, we achieve an improvement
of 2.59 points over the w-system, which suggest our
system might be performing better than what stan-
dard BLEU suggests. Below we test this hypothesis
</bodyText>
<table confidence="0.97322575">
BLEU m-BLEU
ourSystem 14.82 55.64
m-system 14.08 55.26
w-system 14.58 53.05
</table>
<tableCaption confidence="0.9090985">
Table 8: Our system vs. the two baselines (on the test
dataset): BLEU and m-BLEU scores (in %).
</tableCaption>
<bodyText confidence="0.969068421052631">
by means of micro-analysis and human evaluation.
Translation Proximity Match. We performed
automatic comparison based on corresponding
phrases between the translation output (out) and the
reference (ref), using the source (src) test dataset as
a pivot. The decoding log gave us the phrases used
to translate src to out, and we only needed to find
correspondences between src and ref, which we ac-
complished by appending the test dataset to training
and performing IBM Model 4 word alignments.
We then looked for phrase triples (src, out, ref),
where there was a high character-level similarity be-
tween out and ref, measured using longest common
subsequence ratio with a threshold of 0.7, set ex-
perimentally. We extracted 16,262 triples: for 6,758
of them, the translations matched the references ex-
actly, while in the remaining triples, they were close
wordforms9. These numbers support the hypothesis
that our approach yields translations close to the ref-
erence wordforms but unjustly penalized by BLEU,
which only gives credit for exact word matches10.
Human Evaluation. We asked four native
Finnish speakers to evaluate 50 random test sen-
tences. Following (Callison-Burch et al., 2009), we
provided them with the source sentence, its refer-
ence translation, and the outputs of three SMT sys-
tems (m-system, w-system, and ourSystem), which
were shown in different order for each example and
were named sys1, sys2 and sys3 (by order of ap-
pearance). We asked for three pairwise judgments:
(i) sys1 vs. sys2, (ii) sys1 vs. sys3, and (iii) sys2 vs.
sys3. For each pair, a winner had to be designated;
ties were allowed. The results are shown in Table 10.
We can see that the judges consistently preferred
9Examples of such triples are (constitutional
structure, perustuslaillinen rakenne, perustuslaillisempi
rakenne) and (economic and social, taloudellisia ja
sosiaalisia, taloudellisten ja sosiaalisten)
</bodyText>
<footnote confidence="0.768594666666667">
10As a reference, the w-system yielded 15,673 triples, and
6,392 of them were exact matches. Compared to our system,
this means 589 triples and 366 exact matches less.
</footnote>
<page confidence="0.99692">
155
</page>
<tableCaption confidence="0.798980555555555">
src: as a conservative , i am incredibly thrifty with taxpayers ’ money .
ref: maltillisen kokoomuspuolueen edustajana suhtaudun erittain saastavaisesti veronmaksajien rahoihin .
our: konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .
w : konservatiivinen , olen aarettoman tarkeaa kanssa veronmaksajien rahoja .
m : kuten konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .
Comment: our &gt;- m &gt;- w. our uses better paraphrases, from which the correct meaning could be inferred. The part
“aarettoman tarkeaa kanssa” in w does not mention the “thriftiness” and replaces it with “important” (tarkeaa), which
is wrong. m introduces “kuten”, which slightly alters the meaning towards “like a conservative, ...”.
src: we were very constructive and we negotiated until the last minute of these talks in the hague .
ref: olimme erittain rakentavia ja neuvottelimme haagissa viime hetkeen saakka .
our: olemme olleet hyvin rakentavia ja olemme neuvotelleet viime hetkeen saakka naiden neuvottelujen haagissa .
w : olemme olleet hyvin rakentavia ja olemme neuvotelleet viime tippaan niin naiden neuvottelujen haagissa .
m : olimme erittain rakentavan ja neuvottelimme viime hetkeen saakka naiden neuvotteluiden haagissa .
Comment: our &gt;- m &gt;- w. In our, the meaning is very close to ref with only a minor difference in tense at the
beginning. m only gets the case wrong in “rakentavan”, and the correct case is easily guessable. For w, the “viime
tippaan” is in principle correct but somewhat colloquial, and the “niin” is extra and somewhat confusing.
src: it would be a very dangerous situation if the europeans were to become logistically reliant on russia .
ref: olisi erittiin vaarallinen tilanne , jos eurooppalaiset tulisivat logistisesti riippuvaisiksi ven¨aj¨ast¨a .
our: olisi erittiin vaarallinen tilanne , jos eurooppalaiset tulee logistisesti riippuvaisia ven¨aj¨an .
w : se olisi erittiin vaarallinen tilanne , jos eurooppalaisten tulisi logistically riippuvaisia ven¨aj¨an .
m : se olisi hyvin vaarallinen tilanne , jos eurooppalaiset haluavat tulla logistisesti riippuvaisia ven¨aj¨an .
Comment: our &gt;- w &gt;- m. our is almost correct except for the wrong inflections at the end. w is inferior since it
failed to translate “logistically”. “haluavat tulla” in m suggests that the Europeans would “want to become logistically
dependent”, which is not the case. The “se” (it), and “hyvin” (a synonym of “eritt¨ain”) are minor mistakes/differences.
Table 9: English-Finnish translation examples. Shown are the source (src), the reference (ref), and the transla-
tions of three systems (our, w, m). Text in bold indicates matches with respect to the ref, while italics show where a
system was judged inferior to the rest, as judged by native Finnish speakers.
</tableCaption>
<bodyText confidence="0.597488333333333">
(1) ourSystem to the m-system, (2) ourSystem to the
w-system, (3) w-system to the m-system. These pref-
erences are statistically significant, as found by the
sign test. Comparing to Table 8, we can see that
BLEU correlates with human judgments better than
m-BLEU; we plan to investigate this in future work.
</bodyText>
<table confidence="0.988324166666667">
our vs. m our vs. w w vs. m
Judge 1 25 18 19 12 21 19
Judge 2 24 16 19 15 25 14
Judge 3 27† 12 17 11 27† 15
Judge 4 25 20 26† 12 22 22
Total 101$ 66 81$ 50 95† 70
</table>
<tableCaption confidence="0.9588994">
Table 10: Human judgments: ourSystem (our) vs. m-
system (m) vs. w-system (w). For each pair, we show
the number of times each system was judged better than
the other one, ignoring ties. Statistically significant dif-
ferences are marked with † (p &lt; 0.05) and $ (p &lt; 0.01).
</tableCaption>
<bodyText confidence="0.99987">
Finally, Table 9 shows some examples demon-
strating how our system improves over the w-system
and the m-system.
</bodyText>
<sectionHeader confidence="0.995789" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999945">
In the quest towards a morphology-aware SMT that
only uses unannotated data, there are two key chal-
lenges: (1) to bring the performance of morpheme-
token systems to a level rivaling the standard word-
token ones, and (2) to incorporate morphological
analysis directly into the translation process.
This work satisfies the first challenge: we have
achieved statistically significant improvements in
BLEU for a large training dataset of 714K sentence
pairs and this was confirmed by human evaluation.
We think we have built a solid framework for the
second challenge, and we plan to extend it further.
</bodyText>
<sectionHeader confidence="0.998713" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999318">
We thank Joanna Bergstr¨om-Lehtovirta (Helsinki
Institute for Information Technology), Katri Haveri-
nen (University of Turku and Turku Centre for Com-
puter Science), Veronika Laippala (University of
Turku), and Sampo Pyysalo (University of Tokyo)
for judging the Finnish translations.
</bodyText>
<page confidence="0.99837">
156
</page>
<sectionHeader confidence="0.99831" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999703166666667">
Eleftherios Avramidis and Philipp Koehn. 2008. Enrich-
ing morphologically poor languages for statistical ma-
chine translation. In ACL-HLT.
Ibrahim Badr, Rabih Zbib, and James Glass. 2008. Seg-
mentation for English-to-Arabic statistical machine
translation. In ACL-HLT.
Tim Buckwalter. 2004. Buckwalter Arabic Morphologi-
cal Analyzer Version 2.0. Linguistic Data Consortium,
Philadelphia”.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In
EACL.
Boxing Chen, Min Zhang, Haizhou Li, and Aiti Aw.
2009a. A comparative study of hypothesis alignment
and its improvement for machine translation system
combination. In ACL-IJCNLP.
Yu Chen, Michael Jellinghaus, Andreas Eisele, Yi Zhang,
Sabine Hunsicker, Silke Theison, Christian Feder-
mann, and Hans Uszkoreit. 2009b. Combining multi-
engine translations with Moses. In EACL.
Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a.
2005. Clause restructuring for statistical machine
translation. In ACL.
Mathias Creutz and Krista Lagus. 2007. Unsupervised
models for morpheme segmentation and morphology
learning. ACM Trans. Speech Lang. Process., 4(1):3.
Thi Ngoc Diep Do, Viet Bac Le, Brigitte Bigi, Laurent
Besacier, and Eric Castelli. 2009. Mining a compa-
rable text corpus for a Vietnamese-French statistical
machine translation system. In EACL.
Sharon Goldwater and David McClosky. 2005. Improv-
ing statistical MT through morphological analysis. In
HLT.
Philipp Koehn and Barry Haddow. 2009. Edinburgh’s
submission to all tracks of the WMT2009 shared task
with reordering and speed improvements to Moses. In
EACL.
Philipp Koehn and Hieu Hoang. 2007. Factored transla-
tion models. In EMNLP-CoNLL.
Philipp Koehn and Christof Monz. 2005. Shared task:
Statistical machine translation between European lan-
guages. In WPT.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,
Christopher Callison-Burch, Marcello Federico,
Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-
tine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In ACL, Demonstration Session.
Philipp Koehn. 2003. Noun phrase translation. Ph.D.
thesis, University of Southern California, Los Angeles,
CA, USA.
Young-Suk Lee. 2004. Morphological analysis for sta-
tistical machine translation. In HLT-NAACL.
Preslav Nakov and Hwee Tou Ng. 2009. Improved statis-
tical machine translation for resource-poor languages
using related resource-rich languages. In EMNLP.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and Alex
Waibel. 2009. The Universit¨at Karlsruhe translation
system for the EACL-WMT 2009. In EACL.
Attila Nov´ak. 2009. MorphoLogic’s submission for the
WMT 2009 shared task. In EACL.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics, 30(4):417–449.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In ACL.
Kemal Oflazer and Ilknur El-Kahlout. 2007. Exploring
different representational units in English-to-Turkish
statistical machine translation. In StatMT.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a method for automatic evalua-
tion of machine translation. In ACL.
Fatiha Sadat and Nizar Habash. 2006. Combination of
Arabic preprocessing schemes for statistical machine
translation. In ACL.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In International Conference
on New Methods in Language Processing.
Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying morphology generation models to
machine translation. In ACL-HLT.
Sami Virpioja, Jaakko J. Vyrynen, Mathias Creutz, and
Markus Sadeniemi. 2007. Morphology-aware statisti-
cal machine translation based on morphs induced in an
unsupervised manner. In Machine Translation Summit
XI.
Hua Wu and Haifeng Wang. 2007. Pivot language
approach for phrase-based statistical machine transla-
tion. Machine Translation, 21(3):165–181.
Mei Yang and Katrin Kirchhoff. 2006. Phrase-based
backoff models for machine translation of highly in-
flected languages. In EACL.
</reference>
<page confidence="0.997749">
157
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.517747">
<title confidence="0.9164225">A Hybrid Morpheme-Word Representation Machine Translation of Morphologically Rich</title>
<author confidence="0.999912">Minh-Thang Luong Preslav Nakov Min-Yen Kan</author>
<affiliation confidence="0.900527666666667">Department of Computer National University of 13 Computing</affiliation>
<address confidence="0.846248">Singapore</address>
<abstract confidence="0.999771238095238">We propose a language-independent approach for improving statistical machine translation for morphologically rich languages using a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. Our model extends the classic phrase-based model by means of (1) word boundary-aware morpheme-level phrase extraction, (2) minimum error-rate training for a morpheme-level translation model using word-level BLEU, and (3) joint scoring with morphemeand word-level language models. Further improvements are achieved by combining our model with the classic one. The evaluation on English to using sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eleftherios Avramidis</author>
<author>Philipp Koehn</author>
</authors>
<title>Enriching morphologically poor languages for statistical machine translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="4325" citStr="Avramidis and Koehn, 2008" startWordPosition="618" endWordPosition="621">ith a word-based language model. These systems, however, do not attempt to incorporate their analysis as part of the decoding process, but rather rely on models designed for word-token translation. We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language. Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stag</context>
<context position="5555" citStr="Avramidis and Koehn (2008)" startWordPosition="800" endWordPosition="803">f the translation process. This is in contrast with previous work, where morphological enhancements are typically performed as pre-/postprocessing steps only. In addition to changing the basic translation token unit from a word to a morpheme, our model extends the phrase-based SMT model with the following: 1. word boundary-aware morpheme-level phrase extraction; 2. minimum error-rate training for a morphemelevel model using word-level BLEU; 3. joint scoring with morpheme- and word-level language models. We first introduce our morpheme-level representation, and then describe our enhancements. 1Avramidis and Koehn (2008) improved by 0.15 BLEU over a 18.05 English-Greek baseline; Toutanova et al. (2008) improved by 0.72 BLEU over a 36.00 English-Russian baseline. 3.1 Morphological Representation Our morphological representation is based on the output of an unsupervised morphological analyzer. Following Virpioja et al. (2007), we use Morfessor, which is trained on raw tokenized text (Creutz and Lagus, 2007). The tool segments words into morphemes annotated with the following labels: PRE (prefix), STM (stem), SUF (suffix). Multiple prefixes and suffixes can be proposed for each word; word compounding is allowed </context>
</contexts>
<marker>Avramidis, Koehn, 2008</marker>
<rawString>Eleftherios Avramidis and Philipp Koehn. 2008. Enriching morphologically poor languages for statistical machine translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ibrahim Badr</author>
<author>Rabih Zbib</author>
<author>James Glass</author>
</authors>
<title>Segmentation for English-to-Arabic statistical machine translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="4290" citStr="Badr et al., 2008" startWordPosition="613" endWordPosition="616">y re-scoring n-best lists with a word-based language model. These systems, however, do not attempt to incorporate their analysis as part of the decoding process, but rather rely on models designed for word-token translation. We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language. Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word b</context>
</contexts>
<marker>Badr, Zbib, Glass, 2008</marker>
<rawString>Ibrahim Badr, Rabih Zbib, and James Glass. 2008. Segmentation for English-to-Arabic statistical machine translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium,</title>
<date>2004</date>
<location>Philadelphia”.</location>
<contexts>
<context position="3082" citStr="Buckwalter, 2004" startWordPosition="442" endWordPosition="444">on, as opposed to relying on pre-processing and post-processing only as has been done in previous work. The remainder of the paper is organized as follows. Section 2 reviews related work. Sections 3 and 4 present our morphological and phrase merging enhancements. Section 5 describes our experiments, and Section 6 analyzes the results. Finally, Section 7 concludes and suggests directions for future work. 2 Related Work Most previous work on morphology-aware approaches relies heavily on language-specific tools, e.g., the TreeTagger (Schmid, 1994) or the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004), which hampers their portability to other languages. Moreover, the prevalent method for incorporating morphological information is by heuristically-driven pre- or post-processing. For example, Sadat and Habash (2006) use different combinations of Arabic pre-processing schemes 148 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 148–157, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics for Arabic-English SMT, whereas Oflazer and ElKahlout (2007) post-processes Turkish morphemelevel translations by re-scori</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium, Philadelphia”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<date>2009</date>
<booktitle>Findings of the 2009 Workshop on Statistical Machine Translation. In EACL.</booktitle>
<contexts>
<context position="31416" citStr="Callison-Burch et al., 2009" startWordPosition="4939" endWordPosition="4942">a high character-level similarity between out and ref, measured using longest common subsequence ratio with a threshold of 0.7, set experimentally. We extracted 16,262 triples: for 6,758 of them, the translations matched the references exactly, while in the remaining triples, they were close wordforms9. These numbers support the hypothesis that our approach yields translations close to the reference wordforms but unjustly penalized by BLEU, which only gives credit for exact word matches10. Human Evaluation. We asked four native Finnish speakers to evaluate 50 random test sentences. Following (Callison-Burch et al., 2009), we provided them with the source sentence, its reference translation, and the outputs of three SMT systems (m-system, w-system, and ourSystem), which were shown in different order for each example and were named sys1, sys2 and sys3 (by order of appearance). We asked for three pairwise judgments: (i) sys1 vs. sys2, (ii) sys1 vs. sys3, and (iii) sys2 vs. sys3. For each pair, a winner had to be designated; ties were allowed. The results are shown in Table 10. We can see that the judges consistently preferred 9Examples of such triples are (constitutional structure, perustuslaillinen rakenne, per</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Schroeder, 2009</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, and Josh Schroeder. 2009. Findings of the 2009 Workshop on Statistical Machine Translation. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boxing Chen</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
<author>Aiti Aw</author>
</authors>
<title>A comparative study of hypothesis alignment and its improvement for machine translation system combination.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP.</booktitle>
<contexts>
<context position="14300" citStr="Chen et al., 2009" startWordPosition="2147" endWordPosition="2150">tween the tokens in the different factors, which clearly is not our case. Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly. 4 Enriching the Translation Model Another general strategy for combining evidence from the word-token and the morpheme-token representations is to build two separate SMT systems and then combine them. This can be done as a post-processing system combination step; see (Chen et al., 2009a) for an overview of such approaches. 3We use the term “hypothesis” to collectively refer to the following (Koehn, 2003): the source phrase covered, the corresponding target phrase, and most importantly, a reference to the previous hypothesis that it extends. However, for phrase-based SMT systems, it is theoretically more appealing to combine their phrase tables since this allows the translation models of both systems to influence the hypothesis search directly. We now describe our phrase table combination approach. Note that it is orthogonal to the work presented in the previous section, whi</context>
<context position="16312" citStr="Chen et al., 2009" startWordPosition="2472" endWordPosition="2475">-token level. Finally, the two PTs are merged and used by the decoder. Word Morpheme GIZA++ Word alignment Morpheme alignment GIZA++ Phrase Extraction PTS Phrase Extraction PTm Morphological segmentation PTS→m Decoding 151 4.2 Merging and Normalizing Phrase Tables Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation. We then introduce our approach. Add-feature methods. The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009). The idea is to select one of the phrase tables as primary and to add to it all nonduplicating phrase pairs from the second table together with their associated scores. For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table). Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added. The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linear model were set in</context>
</contexts>
<marker>Chen, Zhang, Li, Aw, 2009</marker>
<rawString>Boxing Chen, Min Zhang, Haizhou Li, and Aiti Aw. 2009a. A comparative study of hypothesis alignment and its improvement for machine translation system combination. In ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Chen</author>
<author>Michael Jellinghaus</author>
<author>Andreas Eisele</author>
<author>Yi Zhang</author>
</authors>
<title>Sabine Hunsicker, Silke Theison, Christian Federmann, and Hans Uszkoreit.</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="14300" citStr="Chen et al., 2009" startWordPosition="2147" endWordPosition="2150">tween the tokens in the different factors, which clearly is not our case. Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly. 4 Enriching the Translation Model Another general strategy for combining evidence from the word-token and the morpheme-token representations is to build two separate SMT systems and then combine them. This can be done as a post-processing system combination step; see (Chen et al., 2009a) for an overview of such approaches. 3We use the term “hypothesis” to collectively refer to the following (Koehn, 2003): the source phrase covered, the corresponding target phrase, and most importantly, a reference to the previous hypothesis that it extends. However, for phrase-based SMT systems, it is theoretically more appealing to combine their phrase tables since this allows the translation models of both systems to influence the hypothesis search directly. We now describe our phrase table combination approach. Note that it is orthogonal to the work presented in the previous section, whi</context>
<context position="16312" citStr="Chen et al., 2009" startWordPosition="2472" endWordPosition="2475">-token level. Finally, the two PTs are merged and used by the decoder. Word Morpheme GIZA++ Word alignment Morpheme alignment GIZA++ Phrase Extraction PTS Phrase Extraction PTm Morphological segmentation PTS→m Decoding 151 4.2 Merging and Normalizing Phrase Tables Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation. We then introduce our approach. Add-feature methods. The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009). The idea is to select one of the phrase tables as primary and to add to it all nonduplicating phrase pairs from the second table together with their associated scores. For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table). Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added. The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linear model were set in</context>
</contexts>
<marker>Chen, Jellinghaus, Eisele, Zhang, 2009</marker>
<rawString>Yu Chen, Michael Jellinghaus, Andreas Eisele, Yi Zhang, Sabine Hunsicker, Silke Theison, Christian Federmann, and Hans Uszkoreit. 2009b. Combining multiengine translations with Moses. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2007</date>
<journal>ACM Trans. Speech Lang. Process.,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="5947" citStr="Creutz and Lagus, 2007" startWordPosition="858" endWordPosition="861"> for a morphemelevel model using word-level BLEU; 3. joint scoring with morpheme- and word-level language models. We first introduce our morpheme-level representation, and then describe our enhancements. 1Avramidis and Koehn (2008) improved by 0.15 BLEU over a 18.05 English-Greek baseline; Toutanova et al. (2008) improved by 0.72 BLEU over a 36.00 English-Russian baseline. 3.1 Morphological Representation Our morphological representation is based on the output of an unsupervised morphological analyzer. Following Virpioja et al. (2007), we use Morfessor, which is trained on raw tokenized text (Creutz and Lagus, 2007). The tool segments words into morphemes annotated with the following labels: PRE (prefix), STM (stem), SUF (suffix). Multiple prefixes and suffixes can be proposed for each word; word compounding is allowed as well. The output can be described by the following regular expression: WORD = ( PRE* STM SUF* )+ For example, uncarefully is analyzed as un/PRE+ care/STM+ ful/SUF+ ly/SUF The above token sequence forms the input to our system. We keep the PRE/STM/SUF tags as part of the tokens, and distinguish between care/STM+ and care/STM. Note also that the “+” sign is appended to each nonfinal tag s</context>
</contexts>
<marker>Creutz, Lagus, 2007</marker>
<rawString>Mathias Creutz and Krista Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning. ACM Trans. Speech Lang. Process., 4(1):3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thi Ngoc Diep Do</author>
<author>Viet Bac Le</author>
<author>Brigitte Bigi</author>
<author>Laurent Besacier</author>
<author>Eric Castelli</author>
</authors>
<title>Mining a comparable text corpus for a Vietnamese-French statistical machine translation system.</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="16330" citStr="Do et al., 2009" startWordPosition="2476" endWordPosition="2479">y, the two PTs are merged and used by the decoder. Word Morpheme GIZA++ Word alignment Morpheme alignment GIZA++ Phrase Extraction PTS Phrase Extraction PTm Morphological segmentation PTS→m Decoding 151 4.2 Merging and Normalizing Phrase Tables Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation. We then introduce our approach. Add-feature methods. The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009). The idea is to select one of the phrase tables as primary and to add to it all nonduplicating phrase pairs from the second table together with their associated scores. For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table). Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added. The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linear model were set in the standard way </context>
</contexts>
<marker>Do, Le, Bigi, Besacier, Castelli, 2009</marker>
<rawString>Thi Ngoc Diep Do, Viet Bac Le, Brigitte Bigi, Laurent Besacier, and Eric Castelli. 2009. Mining a comparable text corpus for a Vietnamese-French statistical machine translation system. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>David McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In HLT.</booktitle>
<contexts>
<context position="1595" citStr="Goldwater and McClosky, 2005" startWordPosition="213" endWordPosition="216">lish to Finnish using Europarl (714K sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments. 1 Introduction The fast progress of statistical machine translation (SMT) has boosted translation quality significantly. While research keeps diversifying, the word remains the atomic token-unit of translation. This is fine for languages with limited morphology like English and French, or no morphology at all like Chinese, but it is inadequate for morphologically rich languages like Arabic, Czech or Finnish (Lee, 2004; Goldwater and McClosky, 2005; Yang and Kirchhoff, 2006). This research was sponsored in part by CSIDM (grant # 200805) and by a National Research Foundation grant entitled “Interactive Media Search” (grant # R-252-000-325-279). There has been a line of recent SMT research that incorporates morphological analysis as part of the translation process, thus providing access to the information within the individual words. Unfortunately, most of this work either relies on languagespecific tools, or only works for very small datasets. Below we propose a language-independent approach to SMT of morphologically rich languages using</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>Sharon Goldwater and David McClosky. 2005. Improving statistical MT through morphological analysis. In HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Barry Haddow</author>
</authors>
<title>Edinburgh’s submission to all tracks of the WMT2009 shared task with reordering and speed improvements to Moses.</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="4375" citStr="Koehn and Haddow, 2009" startWordPosition="625" endWordPosition="628">er, do not attempt to incorporate their analysis as part of the decoding process, but rather rely on models designed for word-token translation. We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language. Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. This is in contrast</context>
</contexts>
<marker>Koehn, Haddow, 2009</marker>
<rawString>Philipp Koehn and Barry Haddow. 2009. Edinburgh’s submission to all tracks of the WMT2009 shared task with reordering and speed improvements to Moses. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="13543" citStr="Koehn and Hoang, 2007" startWordPosition="2029" endWordPosition="2032">igure 2. The word-token LM can capture much longer phrases and more complete contexts such as “, ep¨ademokraattisen maahanmuuttopolitiikan” compared to the morpheme-token LM. Note that scoring with two LMs that see the output sequence as different numbers of tokens is not readily offered by the existing SMT decoders. For example, the phrase-based model in Moses (Koehn et al., 2007) allows scoring with multiple LMs, but assumes they use the same token granularity, which is useful for LMs trained on different monolingual corpora, but cannot handle our case. While the factored translation model (Koehn and Hoang, 2007) in Moses does allow scoring with models of different granularity, e.g., lemma-token and word-token LMs, it requires a 1:1 correspondence between the tokens in the different factors, which clearly is not our case. Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly. 4 Enriching the Translation Model Another general strategy for combining evidence from the word-token and the morpheme-token repr</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Shared task: Statistical machine translation between European languages.</title>
<date>2005</date>
<booktitle>In WPT.</booktitle>
<contexts>
<context position="20568" citStr="Koehn and Monz, 2005" startWordPosition="3191" endWordPosition="3194">-token pair ( fm→w,¯em→w), and then induce a corresponding word alignment from the morpheme-token alignment of (¯fm,¯em). We then estimate a lexicalized phrase score using the original formula given in (Koehn et al., 2003), where we plug this induced word alignment and word-token lexical translation probabilities estimated from the word-token dataset The case when (¯fw, ¯ew) is present in PTw, but (¯fm, ¯em) is not, is solved similarly. f, ¯e) is ¯f, ¯e) = #m( f� #m( φ( 152 5 Experiments and Evaluation 5.1 Datasets In our experiments, we use the English-Finnish data from the 2005 shared task (Koehn and Monz, 2005), which is split into training, development, and test portions; see Table 1 for details. We further split the training dataset into four subsets T1, T2, T3, and T4 of sizes 40K, 80K, 160K, and 320K parallel sentence pairs, which we use for studying the impact of training data size on translation performance. Sent. Avg. words Avg. morph. en fi en fi Train 714K 21.62 15.80 24.68 26.15 Dev 2K 29.33 20.99 33.40 34.94 Test 2K 28.98 20.72 33.10 34.47 Table 1: Dataset statistics. Shown are the number of parallel sentences, and the average number of words and Morfessor morphemes on the English and Fin</context>
</contexts>
<marker>Koehn, Monz, 2005</marker>
<rawString>Philipp Koehn and Christof Monz. 2005. Shared task: Statistical machine translation between European languages. In WPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="4780" citStr="Koehn et al., 2003" startWordPosition="683" endWordPosition="686">Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. This is in contrast with previous work, where morphological enhancements are typically performed as pre-/postprocessing steps only. In addition to changing the basic translation token unit from a word to a morpheme, our model extends the phrase-based SMT model with the following: 1. word boundary-aware morpheme-level phrase extraction; 2. minimum error-rate training for a morphemelevel model using word-level BLEU; 3. joi</context>
<context position="7285" citStr="Koehn et al., 2003" startWordPosition="1067" endWordPosition="1070">ranslation structure of a phrase-based SMT model is the phrase table, which is learned from a bilingual parallel sentence-aligned corpus, typically using the alignment template approach (Och and Ney, 2004). It contains a set of bilingual phrase pairs, each associated with five scores: forward and backward phrase translation probabilities, forward and backward lexicalized translation probabilities, and a constant phrase penalty. The maximum phrase length n is normally limited to seven words; higher values of n increase the table size exponentially without actually yielding performance benefit (Koehn et al., 2003). However, things are different when translating with morphemes, for two reasons: (1) morpheme-token phrases of length n can span less than n words; and (2) morphemetoken phrases may only partially span words. The first point means that morpheme-token phrase pairs span fewer word tokens, and thus cover a smaller context, which may result in fewer total extracted pairs compared to a word-level approach. Figure 1 shows a case where three Finnish words consist of nine morphemes. Previously, this issue was addressed by simply increasing the value of n when using morphemes, which is of limited help</context>
<context position="18689" citStr="Koehn et al., 2003" startWordPosition="2861" endWordPosition="2864">scenario, where the morphemetoken phrase tables are built from the same training dataset; the main difference being that word alignments and phrase extraction were performed at the word-token level for PTw→m and at the morphemetoken level for PTm. Thus, we propose different merging approaches for the phrase translation probabilities and for the lexicalized probabilities. In phrase-based SMT, phrase translation probabilities are computed using maximum likelihood (ML) estimation φ(¯f|¯e) = #(�f,�e) e�,where #( Ef #(f, the number of times the pair ( f, ¯e) is extracted from the training dataset (Koehn et al., 2003). In order to preserve the normalized ML estimations as much as possible, we refrain from interpolation. Instead, we use the raw counts for the two models #m( ¯f, ¯e) and #w→m( f, ¯e) directly as follows: f, ¯e) + #w→m( f, ¯e) f, ¯e) + Ef� #w→m( f, ¯e) For lexicalized translation probabilities, we would like to use simple interpolation. However, we notice that when a phrase pair belongs to only one of the phrase tables, the corresponding lexicalized score for the other table would be zero. This might cause some good phrases to be penalized just because they were not extracted in both tables, w</context>
<context position="20169" citStr="Koehn et al., 2003" startWordPosition="3123" endWordPosition="3126">y. If both ( ¯fm, ¯em) and (¯fw, ¯ew) are present in PTm and PTw, respectively, we have a simple interpolation of their corresponding lexicalized scores lexm and lexw. However, if one of them is missing, we do not use a zero for its corresponding lexicalized score, but use an estimate as follows. For example, if only the entry ( fm, ¯em) is present in PTm, we first convert ( fm,¯em) into a word-token pair ( fm→w,¯em→w), and then induce a corresponding word alignment from the morpheme-token alignment of (¯fm,¯em). We then estimate a lexicalized phrase score using the original formula given in (Koehn et al., 2003), where we plug this induced word alignment and word-token lexical translation probabilities estimated from the word-token dataset The case when (¯fw, ¯ew) is present in PTw, but (¯fm, ¯em) is not, is solved similarly. f, ¯e) is ¯f, ¯e) = #m( f� #m( φ( 152 5 Experiments and Evaluation 5.1 Datasets In our experiments, we use the English-Finnish data from the 2005 shared task (Koehn and Monz, 2005), which is split into training, development, and test portions; see Table 1 for details. We further split the training dataset into four subsets T1, T2, T3, and T4 of sizes 40K, 80K, 160K, and 320K par</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch Mayne</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL, Demonstration Session.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="13305" citStr="Koehn et al., 2007" startWordPosition="1991" endWordPosition="1994">en LM, the morpheme-token sequence is concatenated into word-tokens before scoring. it can be enhanced with an appropriate word-token “view” on the partial morpheme-level hypotheses3. The interaction of the twin LMs is illustrated in Figure 2. The word-token LM can capture much longer phrases and more complete contexts such as “, ep¨ademokraattisen maahanmuuttopolitiikan” compared to the morpheme-token LM. Note that scoring with two LMs that see the output sequence as different numbers of tokens is not readily offered by the existing SMT decoders. For example, the phrase-based model in Moses (Koehn et al., 2007) allows scoring with multiple LMs, but assumes they use the same token granularity, which is useful for LMs trained on different monolingual corpora, but cannot handle our case. While the factored translation model (Koehn and Hoang, 2007) in Moses does allow scoring with models of different granularity, e.g., lemma-token and word-token LMs, it requires a 1:1 correspondence between the tokens in the different factors, which clearly is not our case. Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it i</context>
<context position="21333" citStr="Koehn et al., 2007" startWordPosition="3321" endWordPosition="3324">1, T2, T3, and T4 of sizes 40K, 80K, 160K, and 320K parallel sentence pairs, which we use for studying the impact of training data size on translation performance. Sent. Avg. words Avg. morph. en fi en fi Train 714K 21.62 15.80 24.68 26.15 Dev 2K 29.33 20.99 33.40 34.94 Test 2K 28.98 20.72 33.10 34.47 Table 1: Dataset statistics. Shown are the number of parallel sentences, and the average number of words and Morfessor morphemes on the English and Finnish sides of the training, development and test datasets. 5.2 Baseline Systems We build two phrase-based baseline SMT systems, both using Moses (Koehn et al., 2007): w-system: works at the word-token level, extracts phrases of up to seven words, and uses a 4-gram word-token LM (as typical for phrase-based SMT); m-system: works at the morpheme level, tokenized using Morfessor4 and augmented with “+” as described in Section 3.1. Following Oflazer and El-Kahlout (2007) and Virpioja et al. (2007), we use phrases of up to 10 morpheme-tokens and a 5-gram morpheme-token LM. None of the enhancements described previously is applied yet. After decoding, morphemes are concatenated back to words using the “+” markers. To evaluate the translation quality, we compute </context>
</contexts>
<marker>Koehn, Hoang, Mayne, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL, Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Noun phrase translation.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Southern</institution>
<location>California, Los Angeles, CA, USA.</location>
<contexts>
<context position="14421" citStr="Koehn, 2003" startWordPosition="2168" endWordPosition="2169">rior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly. 4 Enriching the Translation Model Another general strategy for combining evidence from the word-token and the morpheme-token representations is to build two separate SMT systems and then combine them. This can be done as a post-processing system combination step; see (Chen et al., 2009a) for an overview of such approaches. 3We use the term “hypothesis” to collectively refer to the following (Koehn, 2003): the source phrase covered, the corresponding target phrase, and most importantly, a reference to the previous hypothesis that it extends. However, for phrase-based SMT systems, it is theoretically more appealing to combine their phrase tables since this allows the translation models of both systems to influence the hypothesis search directly. We now describe our phrase table combination approach. Note that it is orthogonal to the work presented in the previous section, which suggests combining the two (which we will do in Section 5). 4.1 Building a Twin Translation Model Figure 3 shows a gen</context>
</contexts>
<marker>Koehn, 2003</marker>
<rawString>Philipp Koehn. 2003. Noun phrase translation. Ph.D. thesis, University of Southern California, Los Angeles, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="1565" citStr="Lee, 2004" startWordPosition="211" endWordPosition="212">tion on English to Finnish using Europarl (714K sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments. 1 Introduction The fast progress of statistical machine translation (SMT) has boosted translation quality significantly. While research keeps diversifying, the word remains the atomic token-unit of translation. This is fine for languages with limited morphology like English and French, or no morphology at all like Chinese, but it is inadequate for morphologically rich languages like Arabic, Czech or Finnish (Lee, 2004; Goldwater and McClosky, 2005; Yang and Kirchhoff, 2006). This research was sponsored in part by CSIDM (grant # 200805) and by a National Research Foundation grant entitled “Interactive Media Search” (grant # R-252-000-325-279). There has been a line of recent SMT research that incorporates morphological analysis as part of the translation process, thus providing access to the information within the individual words. Unfortunately, most of this work either relies on languagespecific tools, or only works for very small datasets. Below we propose a language-independent approach to SMT of morpho</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Young-Suk Lee. 2004. Morphological analysis for statistical machine translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Improved statistical machine translation for resource-poor languages using related resource-rich languages.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="16351" citStr="Nakov and Ng, 2009" startWordPosition="2480" endWordPosition="2483">e merged and used by the decoder. Word Morpheme GIZA++ Word alignment Morpheme alignment GIZA++ Phrase Extraction PTS Phrase Extraction PTm Morphological segmentation PTS→m Decoding 151 4.2 Merging and Normalizing Phrase Tables Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation. We then introduce our approach. Add-feature methods. The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009). The idea is to select one of the phrase tables as primary and to add to it all nonduplicating phrase pairs from the second table together with their associated scores. For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table). Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added. The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linear model were set in the standard way using MERT. Interpola</context>
</contexts>
<marker>Nakov, Ng, 2009</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2009. Improved statistical machine translation for resource-poor languages using related resource-rich languages. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Niehues</author>
<author>Teresa Herrmann</author>
<author>Muntsin Kolss</author>
<author>Alex Waibel</author>
</authors>
<title>The Universit¨at Karlsruhe translation system for the EACL-WMT</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="16293" citStr="Niehues et al., 2009" startWordPosition="2468" endWordPosition="2471">enized at the morpheme-token level. Finally, the two PTs are merged and used by the decoder. Word Morpheme GIZA++ Word alignment Morpheme alignment GIZA++ Phrase Extraction PTS Phrase Extraction PTm Morphological segmentation PTS→m Decoding 151 4.2 Merging and Normalizing Phrase Tables Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation. We then introduce our approach. Add-feature methods. The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009). The idea is to select one of the phrase tables as primary and to add to it all nonduplicating phrase pairs from the second table together with their associated scores. For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table). Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added. The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linea</context>
</contexts>
<marker>Niehues, Herrmann, Kolss, Waibel, 2009</marker>
<rawString>Jan Niehues, Teresa Herrmann, Muntsin Kolss, and Alex Waibel. 2009. The Universit¨at Karlsruhe translation system for the EACL-WMT 2009. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Attila Nov´ak</author>
</authors>
<title>MorphoLogic’s submission for the WMT</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<marker>Nov´ak, 2009</marker>
<rawString>Attila Nov´ak. 2009. MorphoLogic’s submission for the WMT 2009 shared task. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="6871" citStr="Och and Ney, 2004" startWordPosition="1005" endWordPosition="1008">+ For example, uncarefully is analyzed as un/PRE+ care/STM+ ful/SUF+ ly/SUF The above token sequence forms the input to our system. We keep the PRE/STM/SUF tags as part of the tokens, and distinguish between care/STM+ and care/STM. Note also that the “+” sign is appended to each nonfinal tag so that we can distinguish word-internal from word-final morphemes. 3.2 Word Boundary-aware Phrase Extraction The core translation structure of a phrase-based SMT model is the phrase table, which is learned from a bilingual parallel sentence-aligned corpus, typically using the alignment template approach (Och and Ney, 2004). It contains a set of bilingual phrase pairs, each associated with five scores: forward and backward phrase translation probabilities, forward and backward lexicalized translation probabilities, and a constant phrase penalty. The maximum phrase length n is normally limited to seven words; higher values of n increase the table size exponentially without actually yielding performance benefit (Koehn et al., 2003). However, things are different when translating with morphemes, for two reasons: (1) morpheme-token phrases of length n can span less than n words; and (2) morphemetoken phrases may onl</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9960" citStr="Och (2003)" startWordPosition="1470" endWordPosition="1471">i.e., morphemetoken phrases span a sequence of whole words. This is a fair extension of the morpheme-token system with respect to a word-token one since both are restricted to span up to n word-tokens. 3.3 Morpheme-Token MERT Optimizing Word-Token BLEU Modern phrase-based SMT systems use a log-linear model with the following typical feature functions: language model probabilities, word penalty, distortion cost, and the five parameters from the phrase table. Their weights are set by optimizing BLEU score (Papineni et al., 2001) directly using minimum error rate training (MERT), as suggested by Och (2003). In previous work, phrase-based SMT systems using morpheme-token input/output naturally per2This means that we miss the opportunity to generate new wordforms for known baseforms, but removes the problem of proposing nonwords in the target language. formed MERT at the morpheme-token level as well. This is not optimal since the final expected system output is a sequence of words, not morphemes. The main danger is that optimizing a morpheme-token BLEU score could lead to a suboptimal weight for the word penalty feature function: this is because the brevity penalty of BLEU is calculated with resp</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>Ilknur El-Kahlout</author>
</authors>
<title>Exploring different representational units in English-to-Turkish statistical machine translation. In StatMT.</title>
<date>2007</date>
<contexts>
<context position="4453" citStr="Oflazer and El-Kahlout, 2007" startWordPosition="636" endWordPosition="639"> process, but rather rely on models designed for word-token translation. We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language. Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. This is in contrast with previous work, where morphological enhancements are typically performed </context>
<context position="13893" citStr="Oflazer and El-Kahlout, 2007" startWordPosition="2084" endWordPosition="2087">based model in Moses (Koehn et al., 2007) allows scoring with multiple LMs, but assumes they use the same token granularity, which is useful for LMs trained on different monolingual corpora, but cannot handle our case. While the factored translation model (Koehn and Hoang, 2007) in Moses does allow scoring with models of different granularity, e.g., lemma-token and word-token LMs, it requires a 1:1 correspondence between the tokens in the different factors, which clearly is not our case. Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly. 4 Enriching the Translation Model Another general strategy for combining evidence from the word-token and the morpheme-token representations is to build two separate SMT systems and then combine them. This can be done as a post-processing system combination step; see (Chen et al., 2009a) for an overview of such approaches. 3We use the term “hypothesis” to collectively refer to the following (Koehn, 2003): the source phrase covered, the corresponding target phrase, and most i</context>
<context position="21639" citStr="Oflazer and El-Kahlout (2007)" startWordPosition="3369" endWordPosition="3372"> 34.47 Table 1: Dataset statistics. Shown are the number of parallel sentences, and the average number of words and Morfessor morphemes on the English and Finnish sides of the training, development and test datasets. 5.2 Baseline Systems We build two phrase-based baseline SMT systems, both using Moses (Koehn et al., 2007): w-system: works at the word-token level, extracts phrases of up to seven words, and uses a 4-gram word-token LM (as typical for phrase-based SMT); m-system: works at the morpheme level, tokenized using Morfessor4 and augmented with “+” as described in Section 3.1. Following Oflazer and El-Kahlout (2007) and Virpioja et al. (2007), we use phrases of up to 10 morpheme-tokens and a 5-gram morpheme-token LM. None of the enhancements described previously is applied yet. After decoding, morphemes are concatenated back to words using the “+” markers. To evaluate the translation quality, we compute BLEU (Papineni et al., 2001) at the word-token level. We further introduce a morpheme-token version of BLEU, which we call m-BLEU: it first segments the system output and the reference translation into morpheme-tokens and then calculates a BLEU score as usual. Table 2 shows the baseline results. We can se</context>
</contexts>
<marker>Oflazer, El-Kahlout, 2007</marker>
<rawString>Kemal Oflazer and Ilknur El-Kahlout. 2007. Exploring different representational units in English-to-Turkish statistical machine translation. In StatMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9882" citStr="Papineni et al., 2001" startWordPosition="1456" endWordPosition="1459">long as they span n words or less. We further require that word boundaries be respected2, i.e., morphemetoken phrases span a sequence of whole words. This is a fair extension of the morpheme-token system with respect to a word-token one since both are restricted to span up to n word-tokens. 3.3 Morpheme-Token MERT Optimizing Word-Token BLEU Modern phrase-based SMT systems use a log-linear model with the following typical feature functions: language model probabilities, word penalty, distortion cost, and the five parameters from the phrase table. Their weights are set by optimizing BLEU score (Papineni et al., 2001) directly using minimum error rate training (MERT), as suggested by Och (2003). In previous work, phrase-based SMT systems using morpheme-token input/output naturally per2This means that we miss the opportunity to generate new wordforms for known baseforms, but removes the problem of proposing nonwords in the target language. formed MERT at the morpheme-token level as well. This is not optimal since the final expected system output is a sequence of words, not morphemes. The main danger is that optimizing a morpheme-token BLEU score could lead to a suboptimal weight for the word penalty feature</context>
<context position="21961" citStr="Papineni et al., 2001" startWordPosition="3422" endWordPosition="3425">stem: works at the word-token level, extracts phrases of up to seven words, and uses a 4-gram word-token LM (as typical for phrase-based SMT); m-system: works at the morpheme level, tokenized using Morfessor4 and augmented with “+” as described in Section 3.1. Following Oflazer and El-Kahlout (2007) and Virpioja et al. (2007), we use phrases of up to 10 morpheme-tokens and a 5-gram morpheme-token LM. None of the enhancements described previously is applied yet. After decoding, morphemes are concatenated back to words using the “+” markers. To evaluate the translation quality, we compute BLEU (Papineni et al., 2001) at the word-token level. We further introduce a morpheme-token version of BLEU, which we call m-BLEU: it first segments the system output and the reference translation into morpheme-tokens and then calculates a BLEU score as usual. Table 2 shows the baseline results. We can see that the m-system achieves much 4We retrained Morfessor for Finnish/English on the Finnish/English side of the training dataset. w-system m-system BLEU m-BLEU BLEU m-BLEU T1 11.56 45.57 11.07 49.15 T2 12.95 48.63 12.68 53.78 T3 13.64 50.30 13.32 54.40 T4 14.20 50.85 13.57 54.70 Full 14.58 53.05 14.08 55.26 Table 2: Bas</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fatiha Sadat</author>
<author>Nizar Habash</author>
</authors>
<title>Combination of Arabic preprocessing schemes for statistical machine translation.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="3299" citStr="Sadat and Habash (2006)" startWordPosition="468" endWordPosition="471">t our morphological and phrase merging enhancements. Section 5 describes our experiments, and Section 6 analyzes the results. Finally, Section 7 concludes and suggests directions for future work. 2 Related Work Most previous work on morphology-aware approaches relies heavily on language-specific tools, e.g., the TreeTagger (Schmid, 1994) or the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004), which hampers their portability to other languages. Moreover, the prevalent method for incorporating morphological information is by heuristically-driven pre- or post-processing. For example, Sadat and Habash (2006) use different combinations of Arabic pre-processing schemes 148 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 148–157, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics for Arabic-English SMT, whereas Oflazer and ElKahlout (2007) post-processes Turkish morphemelevel translations by re-scoring n-best lists with a word-based language model. These systems, however, do not attempt to incorporate their analysis as part of the decoding process, but rather rely on models designed for word-token translation. We</context>
</contexts>
<marker>Sadat, Habash, 2006</marker>
<rawString>Fatiha Sadat and Nizar Habash. 2006. Combination of Arabic preprocessing schemes for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="3015" citStr="Schmid, 1994" startWordPosition="433" endWordPosition="434">sis and we incorporate its output into the process of translation, as opposed to relying on pre-processing and post-processing only as has been done in previous work. The remainder of the paper is organized as follows. Section 2 reviews related work. Sections 3 and 4 present our morphological and phrase merging enhancements. Section 5 describes our experiments, and Section 6 analyzes the results. Finally, Section 7 concludes and suggests directions for future work. 2 Related Work Most previous work on morphology-aware approaches relies heavily on language-specific tools, e.g., the TreeTagger (Schmid, 1994) or the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004), which hampers their portability to other languages. Moreover, the prevalent method for incorporating morphological information is by heuristically-driven pre- or post-processing. For example, Sadat and Habash (2006) use different combinations of Arabic pre-processing schemes 148 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 148–157, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics for Arabic-English SMT, whereas Oflazer and ElKahlout (</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Hisami Suzuki</author>
<author>Achim Ruopp</author>
</authors>
<title>Applying morphology generation models to machine translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="4409" citStr="Toutanova et al., 2008" startWordPosition="630" endWordPosition="633">their analysis as part of the decoding process, but rather rely on models designed for word-token translation. We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language. Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Nov´ak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007). These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts1. 3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003). We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. This is in contrast with previous work, where morphol</context>
<context position="5638" citStr="Toutanova et al. (2008)" startWordPosition="813" endWordPosition="816"> enhancements are typically performed as pre-/postprocessing steps only. In addition to changing the basic translation token unit from a word to a morpheme, our model extends the phrase-based SMT model with the following: 1. word boundary-aware morpheme-level phrase extraction; 2. minimum error-rate training for a morphemelevel model using word-level BLEU; 3. joint scoring with morpheme- and word-level language models. We first introduce our morpheme-level representation, and then describe our enhancements. 1Avramidis and Koehn (2008) improved by 0.15 BLEU over a 18.05 English-Greek baseline; Toutanova et al. (2008) improved by 0.72 BLEU over a 36.00 English-Russian baseline. 3.1 Morphological Representation Our morphological representation is based on the output of an unsupervised morphological analyzer. Following Virpioja et al. (2007), we use Morfessor, which is trained on raw tokenized text (Creutz and Lagus, 2007). The tool segments words into morphemes annotated with the following labels: PRE (prefix), STM (stem), SUF (suffix). Multiple prefixes and suffixes can be proposed for each word; word compounding is allowed as well. The output can be described by the following regular expression: WORD = ( </context>
</contexts>
<marker>Toutanova, Suzuki, Ruopp, 2008</marker>
<rawString>Kristina Toutanova, Hisami Suzuki, and Achim Ruopp. 2008. Applying morphology generation models to machine translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sami Virpioja</author>
<author>Jaakko J Vyrynen</author>
<author>Mathias Creutz</author>
<author>Markus Sadeniemi</author>
</authors>
<title>Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner.</title>
<date>2007</date>
<booktitle>In Machine Translation</booktitle>
<location>Summit XI.</location>
<contexts>
<context position="5864" citStr="Virpioja et al. (2007)" startWordPosition="844" endWordPosition="847">rd boundary-aware morpheme-level phrase extraction; 2. minimum error-rate training for a morphemelevel model using word-level BLEU; 3. joint scoring with morpheme- and word-level language models. We first introduce our morpheme-level representation, and then describe our enhancements. 1Avramidis and Koehn (2008) improved by 0.15 BLEU over a 18.05 English-Greek baseline; Toutanova et al. (2008) improved by 0.72 BLEU over a 36.00 English-Russian baseline. 3.1 Morphological Representation Our morphological representation is based on the output of an unsupervised morphological analyzer. Following Virpioja et al. (2007), we use Morfessor, which is trained on raw tokenized text (Creutz and Lagus, 2007). The tool segments words into morphemes annotated with the following labels: PRE (prefix), STM (stem), SUF (suffix). Multiple prefixes and suffixes can be proposed for each word; word compounding is allowed as well. The output can be described by the following regular expression: WORD = ( PRE* STM SUF* )+ For example, uncarefully is analyzed as un/PRE+ care/STM+ ful/SUF+ ly/SUF The above token sequence forms the input to our system. We keep the PRE/STM/SUF tags as part of the tokens, and distinguish between car</context>
<context position="21666" citStr="Virpioja et al. (2007)" startWordPosition="3374" endWordPosition="3378">. Shown are the number of parallel sentences, and the average number of words and Morfessor morphemes on the English and Finnish sides of the training, development and test datasets. 5.2 Baseline Systems We build two phrase-based baseline SMT systems, both using Moses (Koehn et al., 2007): w-system: works at the word-token level, extracts phrases of up to seven words, and uses a 4-gram word-token LM (as typical for phrase-based SMT); m-system: works at the morpheme level, tokenized using Morfessor4 and augmented with “+” as described in Section 3.1. Following Oflazer and El-Kahlout (2007) and Virpioja et al. (2007), we use phrases of up to 10 morpheme-tokens and a 5-gram morpheme-token LM. None of the enhancements described previously is applied yet. After decoding, morphemes are concatenated back to words using the “+” markers. To evaluate the translation quality, we compute BLEU (Papineni et al., 2001) at the word-token level. We further introduce a morpheme-token version of BLEU, which we call m-BLEU: it first segments the system output and the reference translation into morpheme-tokens and then calculates a BLEU score as usual. Table 2 shows the baseline results. We can see that the m-system achieve</context>
</contexts>
<marker>Virpioja, Vyrynen, Creutz, Sadeniemi, 2007</marker>
<rawString>Sami Virpioja, Jaakko J. Vyrynen, Mathias Creutz, and Markus Sadeniemi. 2007. Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner. In Machine Translation Summit XI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
</authors>
<title>Pivot language approach for phrase-based statistical machine translation.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="17863" citStr="Wu and Wang, 2007" startWordPosition="2729" endWordPosition="2732">e not normalized any more. Theoretically, this is not necessarily a problem since the log-linear model used by the decoder does not assume that the scores for the feature functions come from a normalized probability distribution. While it is possible to re-normalize the scores to convert them into probabilities, this is rarely done; it also does not solve the problem with the dropped scores for the duplicated phrases. Instead, the conditional probabilities in the two phrase tables are often interpolated directly, e.g., using linear interpolation. Representative work adopting this approach is (Wu and Wang, 2007). We refer to this method as interpolation. Our method. The above phrase merging approaches have been proposed for phrase tables derived from different sources. This is in contrast with our twin translation scenario, where the morphemetoken phrase tables are built from the same training dataset; the main difference being that word alignments and phrase extraction were performed at the word-token level for PTw→m and at the morphemetoken level for PTm. Thus, we propose different merging approaches for the phrase translation probabilities and for the lexicalized probabilities. In phrase-based SMT</context>
</contexts>
<marker>Wu, Wang, 2007</marker>
<rawString>Hua Wu and Haifeng Wang. 2007. Pivot language approach for phrase-based statistical machine translation. Machine Translation, 21(3):165–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mei Yang</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Phrase-based backoff models for machine translation of highly inflected languages.</title>
<date>2006</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="1622" citStr="Yang and Kirchhoff, 2006" startWordPosition="217" endWordPosition="220"> (714K sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments. 1 Introduction The fast progress of statistical machine translation (SMT) has boosted translation quality significantly. While research keeps diversifying, the word remains the atomic token-unit of translation. This is fine for languages with limited morphology like English and French, or no morphology at all like Chinese, but it is inadequate for morphologically rich languages like Arabic, Czech or Finnish (Lee, 2004; Goldwater and McClosky, 2005; Yang and Kirchhoff, 2006). This research was sponsored in part by CSIDM (grant # 200805) and by a National Research Foundation grant entitled “Interactive Media Search” (grant # R-252-000-325-279). There has been a line of recent SMT research that incorporates morphological analysis as part of the translation process, thus providing access to the information within the individual words. Unfortunately, most of this work either relies on languagespecific tools, or only works for very small datasets. Below we propose a language-independent approach to SMT of morphologically rich languages using a hybrid morpheme-word rep</context>
</contexts>
<marker>Yang, Kirchhoff, 2006</marker>
<rawString>Mei Yang and Katrin Kirchhoff. 2006. Phrase-based backoff models for machine translation of highly inflected languages. In EACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>