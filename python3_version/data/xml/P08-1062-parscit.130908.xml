<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000387">
<title confidence="0.9990385">
Chinese-English Backward Transliteration Assisted with Mining Mono-
lingual Web Pages
</title>
<author confidence="0.994575">
Fan Yang, Jun Zhao, Bo Zou, Kang Liu, Feifan Liu
</author>
<affiliation confidence="0.99313">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China
</affiliation>
<email confidence="0.995708">
{fyang,jzhao,bzou,kliu,ffliu}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.993849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999277285714286">
In this paper, we present a novel backward
transliteration approach which can further as-
sist the existing statistical model by mining
monolingual web resources. Firstly, we em-
ploy the syllable-based search to revise the
transliteration candidates from the statistical
model. By mapping all of them into existing
words, we can filter or correct some pseudo
candidates and improve the overall recall.
Secondly, an AdaBoost model is used to re-
rank the revised candidates based on the in-
formation extracted from monolingual web
pages. To get a better precision during the re-
ranking process, a variety of web-based in-
formation is exploited to adjust the ranking
score, so that some candidates which are less
possible to be transliteration names will be as-
signed with lower ranks. The experimental re-
sults show that the proposed framework can
significantly outperform the baseline translit-
eration system in both precision and recall.
</bodyText>
<sectionHeader confidence="0.998952" genericHeader="keywords">
1 Introduction*
</sectionHeader>
<bodyText confidence="0.999917071428571">
The task of Name Entity (NE) translation is to
translate a name entity from source language to
target language, which plays an important role in
machine translation and cross-language informa-
tion retrieval (CLIR). Transliteration is a subtask in
NE translation, which translates NEs based on the
phonetic similarity. In NE translation, most person
names are transliterated, and some parts of location
names or organization names also need to be trans-
literated. Transliteration has two directions: for-
ward transliteration which transforms an original
name into target language, and backward translit-
eration which recovers a name back to its original
expression. For instance, the original English per-
</bodyText>
<note confidence="0.316775">
*Contact: Jun ZHAO, jzhao@nlpr.ia.ac.cn.
</note>
<bodyText confidence="0.99993025">
son name “Clinton” can be forward transliterated
to its Chinese expression “克/ke 林/lin顿/dun” and
the backward transliteration is the inverse process-
ing. In this paper, we focus on backward translit-
eration from Chinese to English.
Many previous researches have tried to build a
transliteration model using statistical approach
[Knight and Graehl, 1998; Lin and Chen, 2002;
Virga and Khudanpur, 2003; Gao, 2004]. There are
two main challenges in statistical backward trans-
literation: First, statistical transliteration approach
selects the most probable translations based on the
knowledge learned from the training data. This
approach, however, does not work well when there
are multiple standards [Gao, 2004]. Second, back-
ward transliteration is more challenging than for-
ward transliteration as it is required to
disambiguate the noises introduced in the forward
transliteration and estimate the original name as
close as possible [Lin and Chen, 2002]. One of the
most important causes in introducing noises is that:
some silent syllables in original names have been
missing when they are transliterated to target lan-
guage. For example, when “Campbell” is translit-
erated into “坎/kan贝/bei尔/er”, the “p” is missing.
In order to make up the disadvantages of statisti-
cal approach, some researchers have been seeking
for the assistance of web resource. [Wang et al.,
2004; Cheng et al., 2004; Nagata et al., 2001;
Zhang et al, 2005] used bilingual web pages to ex-
tract translation pairs. Other efforts have been
made to combine a statistical transliteration model
with web mining [Al-Onaizan and Knight, 2002;
Long Jiang et al, 2007]. Most of these methods
need bilingual resources. However, those kinds of
resources are not readily available in many cases.
Moreover, to search for bilingual pages, we have to
depend on the performance of search engines. We
can’t get Chinese-English bilingual pages when the
input is a Chinese query. Therefore, the existing
</bodyText>
<page confidence="0.962987">
541
</page>
<note confidence="0.28233">
Proceedings ofACL-08: HLT, pages 541–549,
</note>
<page confidence="0.6015">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.989455836734694">
assistance approaches using web-mining to assist
transliteration are not suitable for Chinese to Eng-
lish backward transliteration.
Thus in this paper, we mainly focus on the fol-
lowing two problems to be solved in transliteration.
Problem I: Some silent syllables are missing in
English-Chinese forward transliteration. How to
recover them effectively and efficiently in back-
ward transliteration is still an open problem.
Problem II: Statistical transliteration always
chooses the translations based on probabilities.
However, in some cases, the correct translation
may have lower probability. Therefore, more stud-
ies are needed on combination with other tech-
niques as supplements.
Aiming at these two problems, we propose a
method which mines monolingual web resources to
assist backward transliteration. The main ideas are
as follows. We assume that for every Chinese en-
tity name which needs to be backward transliter-
ated to an English original name, the correct
transliteration exists somewhere in the web. What
we need to do is to find out the answers based on
the clues given by statistical transliteration results.
Different from the traditional methods which ex-
tract transliteration pairs from bilingual pages, we
only use monolingual web resources. Our method
has two advantages. Firstly, there are much more
monolingual web resources available to be used.
Secondly, our method can revise the transliteration
candidates to the existing words before the subse-
quent re-ranking process, so that we can better
mine the correct transliteration from the Web.
Concretely, there are two phases involved in our
approach. In the first phase, we split the result of
transliteration into syllables, and then a syllable-
based searching processing can be employed to
revise the result in a word list generated from web
pages, with an expectation of higher recall of trans-
literation. In the second phase, we use a revised
word as a search query to get its contexts and hit
information, which are integrated into the
AdaBoost classifier to determine whether the word
is a transliteration name or not with a confidence
score. This phase can readjust the candidate’s score
to a more reasonable point so that precision of
transliteration can be improved. Table 1 illustrates
how to transliterate the Chinese name “阿/a加/jia
西/xi” back to “Agassi”.
</bodyText>
<table confidence="0.994248857142857">
Chinese Transliteration Revised Re-rank
name results Candidate Results
阿加西 aggasi agasi agassi
a jia xi agahi agathi agasi
Agassi agacy agathe agache
agasie agassi agga
É É É
</table>
<tableCaption confidence="0.99994">
Table 1. An example of transliteration flow
</tableCaption>
<bodyText confidence="0.999988153846154">
The experimental results show that our approach
improves the recall from 41.73% to 59.28% in
open test when returning the top-100 results, and
the top-5 precision is improved from 19.69% to
52.19%.
The remainder of the paper is structured as fol-
lows. Section 2 presents the framework of our sys-
tem. We discuss the details of our statistical
transliteration model in Section 3. In Section 4, we
introduce the approach of revising and re-ranking
the results of transliteration. The experiments are
reported in Section 5. The last section gives the
conclusion and the prediction of future work.
</bodyText>
<sectionHeader confidence="0.978548" genericHeader="introduction">
2 System Framework
</sectionHeader>
<bodyText confidence="0.868424">
Our system has three main modules.
</bodyText>
<figureCaption confidence="0.977627">
Figure 1. System framework
</figureCaption>
<listItem confidence="0.995805615384616">
1) Statistical transliteration: This module re-
ceives a Chinese Pinyin sequence as its input, and
output the N-best results as the transliteration can-
didates.
2) Candidate transliteration revision
through syllable-based searching: In the module,
a transliteration candidate is transformed into a
syllable query. We use a syllable-based searching
strategy to select the revised candidate from a huge
word list. Each word in the list is indexed by sylla-
bles, and the similarity between the word and the
query is calculated. The most similar words are
returned as the revision results. This module guar-
</listItem>
<figure confidence="0.997917083333333">
Syllable-based search
Monolingual
web pages
Revised candidates
Words list
Search engine
Re-ranking phase
Statistical model
Transliteration
candidates
Chinese name
Final results
</figure>
<page confidence="0.985387">
542
</page>
<bodyText confidence="0.999988642857143">
method contains two main phases: “revision” and
“re-ranking”. In the revision phase, transliteration
candidates are revised using syllable-based search
in the word list, which are generated by collecting
the existing words in web pages. Because the proc-
ess of named entity recognition may lose some
NEs, we will reserve all the words in web corpus
without any filtering. The revision process can im-
prove the recall through correcting some mistakes
in the transliteration results of statistical model.
In the re-ranking phase, we search every revised
candidate on English pages, score them according
to their contexts and hit information so that the
right answer will be given a higher rank.
</bodyText>
<subsectionHeader confidence="0.996926">
4.1 Using Syllable-based Retrieval to Revise
Transliteration Candidates
</subsectionHeader>
<bodyText confidence="0.999974333333333">
In this section, we will propose two methods re-
spectively for the two problems of statistical model
mentioned in section 1.
</bodyText>
<subsectionHeader confidence="0.827939">
4.1.1 Syllable-based retrieval model
</subsectionHeader>
<bodyText confidence="0.999823">
When we search a transliteration candidate tci in
the word list, we firstly split it into syllables
{es1,es2,É..esn}. Then this syllable sequence is
used as a query for syllable-based searching.
We define some notions here.
</bodyText>
<listItem confidence="0.988230166666667">
• Term set T={t1,t2É.tk} is an orderly set of
all syllables which can be viewed as terms.
• Pinyin set P={py1,py2É.pyk} is an orderly
set of all Pinyin.
• An input word can be represented by a vec-
tor of syllables {es1,es2,É..esn}.
</listItem>
<bodyText confidence="0.999352095238095">
We calculate the similarity between a translitera-
tion result and each word in the list to select the
most similar words as the revised candidates. The
{es1,es2,É..,esn} will be transformed into a vector
Vquery={t1,t2É.tk} where ti represents the ith term in
T. The value of ti is equal to 0 if the ith term
doesn’t appear in query. In the same way, the word
in list can also be transformed into vector represen-
tation. So the similarity can be calculated as the
inner product between these two vectors.
We don’t use tf and idf conceptions as traditional
information retrieval (IR) to calculate the terms’
weight. We use the weight of ti to express the ex-
pectation probability of ith term having pronuncia-
tion. If the term has a lower probability of having
pronunciation, its weight is low. So when we
searching, the missing silent syllables in the results
of statistical transliteration model can be recovered
because such syllables have little impact on simi-
larity measurement. The formula we used is as fol-
lows.
</bodyText>
<equation confidence="0.637054666666667">
Sim(query, word) = Vquery x Vwora
L / L
word py
</equation>
<bodyText confidence="0.999601307692308">
The numerator is the inner product of two vec-
tors. The denominator is the length of word Lword
divided by the length of Chinese pinyin sequence
Lpy. In this formula, the more syllables in one
word, the higher score of inner production it may
get, but the word will get a loss for its longer
length. The word which has the shortest length and
the highest syllable hitting ratio will be the best.
Another difference from traditional IR is how to
deal with the order of the words in a query. Ac-
cording to transliteration, the similarity must be
calculated under the limitation of keeping order,
which can’t be satisfied by current methods. We
use the algorithm like calculating the edit distance
between two words. The syllables are viewed as
the units which construct a word. The edit distance
calculation finds the best matching with the least
operation cost to change one word to another word
by using deletion/addition/insertion operations on
syllables. But the complexity will be too high to
afford if we calculate the edit distance between a
query and each word in the list. So, we just calcu-
late the edit distance for the words which get high
score without the order limitation. This trade off
method can save much time but still keep perform-
ance.
</bodyText>
<sectionHeader confidence="0.773075" genericHeader="method">
4.1.2 Mining the Equivalent through Syllable
Expansion
</sectionHeader>
<bodyText confidence="0.9990648">
In most collections, the same concept may be re-
ferred to using different words. This issue, known
as synonymy, has an impact on the recall of most
information retrieval systems. In this section, we
try to use the expansion technology to solve prob-
lem II. There are three kinds of expansions to be
explained below.
Syllable expansion based on phonetic similar-
ity: The syllables which correspond to the same
Chinese pinyin can be viewed as synonymies. For
example, the English syllables “din” and “tin” can
be aligned to the same Chinese pinyin “ding”.
Given a Chinese pinyin sequence
{py1,py2,É..pyn} as the input of transliteration
model, for every pyi, there are a set of syllables
</bodyText>
<figure confidence="0.41514">
(3)
</figure>
<page confidence="0.983754">
544
</page>
<bodyText confidence="0.999357422222222">
{es1, es2 É.. esk} which can be selected as its
translation. The statistical model will select the
most probable one, while others containing the
right answer are discarded. To solve this problem,
we expand the query to take the synonymies of
terms into consideration. We create an expansion
set for each Chinese pinyin. A syllable esi will be
selected into the expansion set of pyj based on the
alignment probability P(esi|pyj) which can be ex-
tracted from the training corpus. The phonetic
similarity expansion is based on the input Chinese
Pinyin sequence, so it’s same for all candidates.
Syllable expansion based on syllable similar-
ity: If two syllables have similar alignment prob-
ability with every pinyin, we can view these two
syllables as synonymy. Therefore, if a syllable is in
the query, its synonymies should be contained too.
For example, “fea” and “fe” can replace each other.
To calculate the similarity, we first obtain the
alignment probability P(pyj|esk) of every syllable.
Then the distance between any two syllables will
be calculated using formula (4).
This formula is used to evaluate the similarity of
two syllables in alignment. The expansion set of
the ith syllable can be generated by selecting the
most similar N syllables. This kind of expansion is
conducted upon the output of statistical translitera-
tion model.
Syllable expansion based on syllable edit dis-
tance: The disadvantage of last two expansions is
that they are entirely dependent on the training set.
In other word, if some syllables haven’t appeared
in the training corpus, they will not be expanded.
To solve the problem, we use the method of expan-
sion based on edit distance. We use edit distance to
measure the similarity between two syllables, one
is in training set and the other is absent. Because
the edit distance expansion is not very relevant to
pronunciation, we will give this expansion method
a low weight in combination. It works when new
syllables arise.
Combine the above three strategies: We will
combine the three kinds of expansion method to-
gether. We use the linear interpolation to integrate
them. The formulas are follows.
</bodyText>
<equation confidence="0.9953295">
S = (1#a)Spre +aSsy + ∀Sed
S = (1# a )SpTe + aSp� +∀ S�,
</equation>
<bodyText confidence="0.999982833333333">
where Spre is the score of exact matching, Ssy is the
score of expansion based on syllables similarity
and Spy based on phonetic similarity. We will ad-
just these parameters to get the best performance.
The experimental results and analysis will be re-
ported in section 5.3.
</bodyText>
<subsectionHeader confidence="0.945958">
4.2 Re-Ranking the Revised Candidates Set
using the Monolingual Web Resource
</subsectionHeader>
<bodyText confidence="0.999516268292683">
In the first phase, we have generated the revised
candidate set {rc1,rc2,É,rcn} from the word list us-
ing the transliteration results as clues. The objec-
tive is to improve the overall recall. In the second
phase, we try to improve the precision, i.e. we wish
to re-rank the candidate set so that the correct an-
swer will be put in a higher rank.
[Al-Onaizan et al., 2002] has proposed some
methods to re-score the transliteration candidates.
The limitation of their approach is that some can-
didates are propbale not existing words, with
which we will not get any information from web.
So it can only re-rank the transliteration results to
improve the precision of top-5. In our work, we
can improve the recall of transliteration through
the revising process before re-ranking.
In this section, we employ the AdaBoost frame-
work which integrates several kinds of features to
re-rank the revised candidate set. The function of
the AdaBoost classifier is to calculate the probabil-
ity of the candidate being a NE. Then we can re-
rank the revised candidate set based on the score.
The features used in our system are as follows.
NE or not: Using rci as query to search for
monolingual English Web Pages, we can get the
context set {Ti1, Ti2 Tin} of rci. Then for every
Tik, we use the named entity recognition (NER)
software to determine whether rci is a NE or not. If
rci is recognized as a NE in some Tik, rci will get a
score. If rci can’t be recognized as NE in any con-
texts, it will be pruned.
The hit of the revised candidate: We can get
the hit information of rci from search engine. It is
used to evaluate the importance of rci. Unlike [Al-
Onaizan et al., 2002], in which the hit can be used
to eliminate the translation results which contain
illegal spelling, we just use hit number as a feature.
The limitation of compound NEs: When trans-
literating a compound NE, we always split them
into several parts, and then combine their translit-
eration results together. But in this circumstance,
</bodyText>
<figure confidence="0.8547958">
1
(esj , esk ) = N �- ; P(pyi  |esj)P(pyi  |esk )
N
Sim
(4)
</figure>
<page confidence="0.996254">
545
</page>
<bodyText confidence="0.99836084">
every part can add a limitation in the selection of
the whole NE. For example: “*/xik/laM/li ⋅ A
/ke#/lin*/dun” is a compound name. “*/xik/la
M/li” can be transliterate to “Hilary” or “Hilaly”
and “A/ke#/lin*/dun” can be transliterate to
“Clinton” or “Klinton”. But the combination of
“Hilary⋅Clinton” will be selected for it is the most
common combination. So the hit of combination
query will be extracted as a feature in classifier.
Hint words around the NE: We can take some
hint words around the NE into the query, in order
to add some limitations to filter out noisy words.
For example: “AM* (president)” can be used as
hint word for “A#* (Clinton)”. To find the hint
words, we first search the Chinese name in Chi-
nese web pages. The frequent words can be ex-
tracted as hint words and they will be translated to
English using a bilingual dictionary. These hint
words are combined with the revised candidates to
search English web pages. So, the hit of the query
will be extracted as feature.
The formula of AdaBoost is as follow.
Where at is the weight for the ith weak classifier
ht (x) . at can be calculated based on the precision
of its corresponding classifier.
</bodyText>
<sectionHeader confidence="0.998634" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999986933333334">
We carry out experiments to investigate how much
the revision process and the re-ranking process can
improve the performance compared with the base-
line of statistical transliteration model. We will
also evaluate to which extents we can solve the
two problems mentioned in section 1 with the as-
sistance of Web resources.
pairs are selected randomly as the close test data.
1,294 pairs out of training set are selected as the
open test data. To set up the word list, a 2GB-sized
collection of web pages is used. Since 7.42% of the
names in the test data don’t appear in the list, we
use Google to get the web page containing the ab-
sent names and add these pages into the collection.
The word list contains 672,533 words.
</bodyText>
<subsectionHeader confidence="0.9993">
5.2 Revision phase vs. statistical approach
</subsectionHeader>
<bodyText confidence="0.9997503">
Using the results generated from statistical model
as baseline, we evaluate the revision module in
recall first. The statistical transliteration model
works in the following 4 steps: 1) Chinese name
are transformed into pinyin representation and the
English names are split into syllables. 2) The
GIZA++1 tool is invoked to align pinyin to sylla-
bles, and the alignment probabilities P(py  |es) are
obtained. 3) Those frequent sequences of syllables
are combined as phrases. For example,
“be/r/g”4”berg”, “s/ky”4”sky”. 4) Camel2 de-
coder is executed to generate 100-best candidates
for every name.
We compare the statistical transliteration results
with the revised results in Table 2. From Table 2
we can find that the recall of top-100 after revision
is improved by 13.26% in close test set and
17.55% in open test set. It proves that the revision
module is effective for correcting the mistakes
made in statistical transliteration model.
</bodyText>
<table confidence="0.993558444444445">
Transliteration Revised results
results
close open close open
Top1 33.64% 9.41% 27.15% 11.04%
Top5 40.37% 13.38% 42.83% 19.69%
Top10 47.79% 17.56% 56.98% 26.52%
Top20 61.88% 25.44% 71.05% 37.81%
Top50 66.49% 36.19% 82.16% 46.22%
Top100 72.52% 41.73% 85.78% 59.28%
</table>
<equation confidence="0.380576">
T
H(x) = sign( !,h, (x))
(7)
</equation>
<tableCaption confidence="0.996234">
Table 2. Statistical model vs. Revision module
</tableCaption>
<subsectionHeader confidence="0.98136">
5.1 Experimental data
</subsectionHeader>
<bodyText confidence="0.999278235294118">
The training corpus for statistical transliteration
model comes from the corpus of Chinese &lt;-&gt; Eng-
lish Name Entity Lists v 1.0 (LDC2005T34). It
contains 565,935 transliteration pairs. Ruling out
those pairs which are not suitable for the research
on Chinese-English backward transliteration, such
as Chinese-Japanese, we select a training set which
contains 14,443 pairs of Chinese-European &amp;
American person names. In the training set, 1,344
To show the effects of the revision on the two
above-mentioned problems in which the statistical
model does not solve well: the losing of silent syl-
lables and the selection bias problem, we make a
statistics of the improvements with a measurement
of “correction time”.
For a Chinese word whose correct transliteration
appears in top-100 candidates only if it has been
</bodyText>
<footnote confidence="0.9994195">
1 http://www.fjoch.com/GIZA++.html
2 http://www.nlp.org.cn
</footnote>
<page confidence="0.99672">
546
</page>
<bodyText confidence="0.9987226">
revised, we count the “correction time”. For exam-
ple, when “Argahi” is revised to “Agassi” the cor-
rection time is “1” for Problem II and “1” for
Problem I, because in “hi”4 “si” the syllable is
expanded, and in “si” 4”ssi” an “s” is added.
</bodyText>
<table confidence="0.994957">
Close test Open test
Problem I 0.6931 0.7853
Problem II 0.9264 1.1672
</table>
<tableCaption confidence="0.999826">
Table 3. Average time of correction
</tableCaption>
<bodyText confidence="0.999860666666667">
This measurement reflects the efficiency of the
revision of search strategy, in contrast to those
spelling correction techniques in which several
operations of “add” and “expand” are inevitable. It
has proved that the more an average correction
time is, the more efficient our strategy is.
</bodyText>
<figureCaption confidence="0.997244">
Figure 2. Length influence in recall comparison
</figureCaption>
<bodyText confidence="0.999985416666667">
The recall of the statistical model relies on the
length of English name in some degree. It is more
difficult to obtain an absolutely correct answer for
longer names, because they may contain more si-
lent and confused syllables. However, through the
revision phase, this tendency can be effectively
alleviated. In Figure 2, we make a comparison be-
tween the results of the statistical model and the
revision module with the changing of syllable’s
length in open test. The curves demonstrate that
the revision indeed prevents the decrease of recall
for longer names.
</bodyText>
<subsectionHeader confidence="0.886652">
5.3 Parameter setting in the revision
phase
</subsectionHeader>
<bodyText confidence="0.999871269230769">
We will show the experimental results when set-
ting different parameters for query expansion. In
the expansion based on phonetic similarity, for
every Chinese pinyin, we select at most 20 sylla-
bles to create an expansion set. We set P = 0.1 in
formula (5). The results are shown in the columns
labeled “exp1” in Table 4.
From the results we can conclude that, we get
the best performance when a = 0.4. That means
the performance is best when the weight of exact
matching is a little larger than the weight of fuzzy
matching. We can also see that, higher weight of
exact matching will lead to low recall, while higher
weight of fuzzy matching will bring noise in.
The expansion method based on syllable similar-
ity is also evaluated. For every syllable, we select
at most 15 syllables to create the expansion set. We
set P = 0.1. The results are shown in the columns
labeled “exp2” in Table 4.
From the results we can conclude that, we get
the best performance when a = 0.5. It means that
we can’t put emphasis on any matching methods.
Comparison with the expansion based on phonetic
similarity, the performance is poorer. It means that
the expansion based on phonetic similarity is more
suitable for revising transliteration candidates.
</bodyText>
<subsectionHeader confidence="0.943497">
5.4 Revision phase vs. re-ranking phase
</subsectionHeader>
<bodyText confidence="0.999959230769231">
After the phase of revising transliteration candi-
dates, we re-rank the revised candidate set with the
assistance of monolingual web resources. In this
section, we will show the improvement in preci-
sion after re-ranking.
We have selected four kinds of features to inte-
grate in the AdaBoost framework. To determine
whether the candidate is NE or not in its context,
we use the software tool Lingpipe3. The queries are
sent to google, so that we can get the hit of queries
and the top-10 snippets will be extracted as context.
The comparison of revision results and re-
ranking results is shown as follows.
</bodyText>
<table confidence="0.999607625">
Revised results Re-ranked results
close open close open
Top1 27.15% 11.04% 58.08% 38.63%
Top5 42.83% 19.69% 76.35% 52.19%
Top10 56.98% 26.52% 83..92% 54.33%
Top20 71.05% 37.81% 83.92% 57.61%
Top50 82.16% 46.22% 83.92% 57.61%
Top100 85.78% 59.28% 85.78% 59.28%
</table>
<tableCaption confidence="0.999661">
Table 5. Revision results vs. Re-ranking results
</tableCaption>
<bodyText confidence="0.979792">
From these results we can conclude that, after
re-ranking phase, the noisy words will get a lower
</bodyText>
<figure confidence="0.962375857142857">
3 http://www.alias-i.com/lingpipe/
#
!&amp;quot;+
!&amp;quot;*
!&amp;quot;)
!&amp;quot;(
!&amp;quot;&apos;
!&amp;quot;&amp;
!&amp;quot;%
!&amp;quot;$
!&amp;quot;#
!
# $ % &amp; &apos; ( ) * +
,-./0-1 0232/02/4
</figure>
<page confidence="0.95518">
547
</page>
<reference confidence="0.999227181818182">
Paola Virga and Sanjeev Khudanpur. 2003. Translitera-
tion of proper names in cross-lingual information re-
trieval. In Proc. of the ACL workshop on Multi-
lingual Named Entity Recognition.
Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, Wen-
Hsiang Lu, Lee-Feng Chien. 2004. Translating un-
known cross-lingual queries in digital libraries using
a web-based approach. In Proc. of JCDL 2004.
E.M.Voorhees and D.M.Tice. 2000. The trec-8 question
answering track report. In Eighth Text Retrieval Con-
ference (TREC-8)
</reference>
<page confidence="0.99872">
549
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000793">
<title confidence="0.8231275">Chinese-English Backward Transliteration Assisted with Mining Monolingual Web Pages</title>
<author confidence="0.851819">Jun Zhao Yang</author>
<author confidence="0.851819">Bo Liu</author>
<author confidence="0.851819">Feifan Liu</author>
<affiliation confidence="0.7665355">National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China</affiliation>
<email confidence="0.972098">fyang@nlpr.ia.ac.cn</email>
<email confidence="0.972098">jzhao@nlpr.ia.ac.cn</email>
<email confidence="0.972098">bzou@nlpr.ia.ac.cn</email>
<email confidence="0.972098">kliu@nlpr.ia.ac.cn</email>
<email confidence="0.972098">ffliu@nlpr.ia.ac.cn</email>
<abstract confidence="0.976477961199296">In this paper, we present a novel backward transliteration approach which can further assist the existing statistical model by mining monolingual web resources. Firstly, we employ the syllable-based search to revise the transliteration candidates from the statistical model. By mapping all of them into existing words, we can filter or correct some pseudo candidates and improve the overall recall. Secondly, an AdaBoost model is used to rerank the revised candidates based on the information extracted from monolingual web pages. To get a better precision during the reranking process, a variety of web-based information is exploited to adjust the ranking score, so that some candidates which are less possible to be transliteration names will be assigned with lower ranks. The experimental results show that the proposed framework can significantly outperform the baseline transliteration system in both precision and recall. The task of Name Entity (NE) translation is to translate a name entity from source language to target language, which plays an important role in machine translation and cross-language information retrieval (CLIR). Transliteration is a subtask in NE translation, which translates NEs based on the phonetic similarity. In NE translation, most person names are transliterated, and some parts of location names or organization names also need to be transliterated. Transliteration has two directions: forward transliteration which transforms an original name into target language, and backward transliteration which recovers a name back to its original For instance, the original English per- Jun ZHAO, jzhao@nlpr.ia.ac.cn. son name “Clinton” can be forward transliterated its Chinese expression and the backward transliteration is the inverse processing. In this paper, we focus on backward transliteration from Chinese to English. Many previous researches have tried to build a transliteration model using statistical approach [Knight and Graehl, 1998; Lin and Chen, 2002; Virga and Khudanpur, 2003; Gao, 2004]. There are two main challenges in statistical backward transliteration: First, statistical transliteration approach selects the most probable translations based on the knowledge learned from the training data. This approach, however, does not work well when there are multiple standards [Gao, 2004]. Second, backward transliteration is more challenging than forward transliteration as it is required to disambiguate the noises introduced in the forward transliteration and estimate the original name as close as possible [Lin and Chen, 2002]. One of the most important causes in introducing noises is that: some silent syllables in original names have been missing when they are transliterated to target language. For example, when “Campbell” is translitinto the “p” is missing. In order to make up the disadvantages of statistical approach, some researchers have been seeking for the assistance of web resource. [Wang et al., 2004; Cheng et al., 2004; Nagata et al., 2001; Zhang et al, 2005] used bilingual web pages to extract translation pairs. Other efforts have been made to combine a statistical transliteration model with web mining [Al-Onaizan and Knight, 2002; Long Jiang et al, 2007]. Most of these methods need bilingual resources. However, those kinds of resources are not readily available in many cases. Moreover, to search for bilingual pages, we have to depend on the performance of search engines. We can’t get Chinese-English bilingual pages when the input is a Chinese query. Therefore, the existing 541 ofACL-08: pages 541–549, Ohio, USA, June 2008. Association for Computational Linguistics assistance approaches using web-mining to assist transliteration are not suitable for Chinese to English backward transliteration. Thus in this paper, we mainly focus on the following two problems to be solved in transliteration. Some silent syllables are missing in English-Chinese forward transliteration. How to recover them effectively and efficiently in backward transliteration is still an open problem. II: transliteration always chooses the translations based on probabilities. However, in some cases, the correct translation may have lower probability. Therefore, more studies are needed on combination with other techniques as supplements. Aiming at these two problems, we propose a method which mines monolingual web resources to assist backward transliteration. The main ideas are as follows. We assume that for every Chinese entity name which needs to be backward transliterated to an English original name, the correct transliteration exists somewhere in the web. What we need to do is to find out the answers based on the clues given by statistical transliteration results. Different from the traditional methods which extract transliteration pairs from bilingual pages, we only use monolingual web resources. Our method has two advantages. Firstly, there are much more monolingual web resources available to be used. Secondly, our method can revise the transliteration candidates to the existing words before the subsequent re-ranking process, so that we can better mine the correct transliteration from the Web. Concretely, there are two phases involved in our approach. In the first phase, we split the result of transliteration into syllables, and then a syllablebased searching processing can be employed to revise the result in a word list generated from web pages, with an expectation of higher recall of transliteration. In the second phase, we use a revised word as a search query to get its contexts and hit information, which are integrated into the AdaBoost classifier to determine whether the word is a transliteration name or not with a confidence score. This phase can readjust the candidate’s score to a more reasonable point so that precision of transliteration can be improved. Table 1 illustrates to transliterate the Chinese name back to “Agassi”. Chinese name Transliteration Revised Re-rank Results results Candidate 阿加西 aggasi agasi agassi a jia xi agahi agathi agasi Agassi agacy agathe agache agasie agassi agga É É É Table 1. An example of transliteration flow The experimental results show that our approach improves the recall from 41.73% to 59.28% in open test when returning the top-100 results, and the top-5 precision is improved from 19.69% to 52.19%. The remainder of the paper is structured as follows. Section 2 presents the framework of our system. We discuss the details of our statistical transliteration model in Section 3. In Section 4, we introduce the approach of revising and re-ranking the results of transliteration. The experiments are reported in Section 5. The last section gives the conclusion and the prediction of future work. 2 System Framework Our system has three main modules. Figure 1. System framework Statistical This module receives a Chinese Pinyin sequence as its input, and the results as the transliteration candidates. 2) Candidate transliteration revision syllable-based In the module, a transliteration candidate is transformed into a syllable query. We use a syllable-based searching strategy to select the revised candidate from a huge word list. Each word in the list is indexed by syllables, and the similarity between the word and the query is calculated. The most similar words are as the revision results. This module guar- Syllable-based search Monolingual web pages Revised candidates Words list Search engine Re-ranking phase Statistical model Transliteration candidates Chinese name Final results 542 method contains two main phases: “revision” and “re-ranking”. In the revision phase, transliteration candidates are revised using syllable-based search in the word list, which are generated by collecting the existing words in web pages. Because the process of named entity recognition may lose some NEs, we will reserve all the words in web corpus without any filtering. The revision process can improve the recall through correcting some mistakes in the transliteration results of statistical model. In the re-ranking phase, we search every revised candidate on English pages, score them according to their contexts and hit information so that the right answer will be given a higher rank. 4.1 Using Syllable-based Retrieval to Revise Transliteration Candidates In this section, we will propose two methods respectively for the two problems of statistical model mentioned in section 1. 4.1.1 Syllable-based retrieval model we search a transliteration candidate the word list, we firstly split it into syllables Then this syllable sequence is used as a query for syllable-based searching. We define some notions here. Term set is an orderly set of all syllables which can be viewed as terms. Pinyin set is an orderly set of all Pinyin. • An input word can be represented by a vecof syllables We calculate the similarity between a transliteration result and each word in the list to select the most similar words as the revised candidates. The will be transformed into a vector where the term in The value of equal to 0 if the term doesn’t appear in query. In the same way, the word in list can also be transformed into vector representation. So the similarity can be calculated as the inner product between these two vectors. don’t use as traditional information retrieval (IR) to calculate the terms’ We use the weight of express the exprobability of term having pronunciation. If the term has a lower probability of having pronunciation, its weight is low. So when we searching, the missing silent syllables in the results of statistical transliteration model can be recovered because such syllables have little impact on similarity measurement. The formula we used is as follows. x word py The numerator is the inner product of two vec- The denominator is the length of word divided by the length of Chinese pinyin sequence In this formula, the more syllables in one word, the higher score of inner production it may get, but the word will get a loss for its longer length. The word which has the shortest length and the highest syllable hitting ratio will be the best. Another difference from traditional IR is how to deal with the order of the words in a query. According to transliteration, the similarity must be calculated under the limitation of keeping order, which can’t be satisfied by current methods. We use the algorithm like calculating the edit distance between two words. The syllables are viewed as the units which construct a word. The edit distance calculation finds the best matching with the least operation cost to change one word to another word by using deletion/addition/insertion operations on syllables. But the complexity will be too high to afford if we calculate the edit distance between a query and each word in the list. So, we just calculate the edit distance for the words which get high score without the order limitation. This trade off method can save much time but still keep performance. 4.1.2 Mining the Equivalent through Syllable Expansion In most collections, the same concept may be referred to using different words. This issue, known as synonymy, has an impact on the recall of most information retrieval systems. In this section, we try to use the expansion technology to solve problem II. There are three kinds of expansions to be explained below. Syllable expansion based on phonetic similarsyllables which correspond to the same Chinese pinyin can be viewed as synonymies. For example, the English syllables “din” and “tin” can be aligned to the same Chinese pinyin “ding”. Given a Chinese pinyin sequence as the input of transliteration for every there are a set of syllables (3) 544 which can be selected as its translation. The statistical model will select the most probable one, while others containing the right answer are discarded. To solve this problem, we expand the query to take the synonymies of terms into consideration. We create an expansion for each Chinese pinyin. A syllable be into the expansion set of on the probability which can be extracted from the training corpus. The phonetic similarity expansion is based on the input Chinese Pinyin sequence, so it’s same for all candidates. Syllable expansion based on syllable similartwo syllables have similar alignment probability with every pinyin, we can view these two syllables as synonymy. Therefore, if a syllable is in the query, its synonymies should be contained too. For example, “fea” and “fe” can replace each other. To calculate the similarity, we first obtain the probability of every syllable. Then the distance between any two syllables will be calculated using formula (4). This formula is used to evaluate the similarity of two syllables in alignment. The expansion set of syllable can be generated by selecting the most similar N syllables. This kind of expansion is conducted upon the output of statistical transliteration model. Syllable expansion based on syllable edit disdisadvantage of last two expansions is that they are entirely dependent on the training set. In other word, if some syllables haven’t appeared in the training corpus, they will not be expanded. To solve the problem, we use the method of expansion based on edit distance. We use edit distance to the similarity between two is in training set and the other is absent. Because the edit distance expansion is not very relevant to pronunciation, we will give this expansion method a low weight in combination. It works when new syllables arise. the above three strategies: will combine the three kinds of expansion method together. We use the linear interpolation to integrate them. The formulas are follows. S = S = + is the score of exact matching, is the score of expansion based on syllables similarity based on phonetic similarity. We will adjust these parameters to get the best performance. The experimental results and analysis will be reported in section 5.3. 4.2 Re-Ranking the Revised Candidates Set using the Monolingual Web Resource In the first phase, we have generated the revised set from the word list using the transliteration results as clues. The objective is to improve the overall recall. In the second phase, we try to improve the precision, i.e. we wish to re-rank the candidate set so that the correct answer will be put in a higher rank. [Al-Onaizan et al., 2002] has proposed some methods to re-score the transliteration candidates. The limitation of their approach is that some candidates are propbale not existing words, with which we will not get any information from web. So it can only re-rank the transliteration results to improve the precision of top-5. In our work, we can improve the recall of transliteration through the revising process before re-ranking. In this section, we employ the AdaBoost framework which integrates several kinds of features to re-rank the revised candidate set. The function of the AdaBoost classifier is to calculate the probability of the candidate being a NE. Then we can rerank the revised candidate set based on the score. The features used in our system are as follows. or not: query to search for monolingual English Web Pages, we can get the set of Then for every we use the named entity recognition (NER) to determine whether a NE or not. If recognized as a NE in some get a If be recognized as NE in any contexts, it will be pruned. hit of the revised candidate: can get hit information of search engine. It is to evaluate the importance of Unlike [Al- Onaizan et al., 2002], in which the hit can be used to eliminate the translation results which contain illegal spelling, we just use hit number as a feature. limitation of compound NEs: transliterating a compound NE, we always split them into several parts, and then combine their transliteration results together. But in this circumstance, 1 , )   ||) N Sim (4) 545 every part can add a limitation in the selection of whole NE. For example: is a compound name. can be transliterate to “Hilary” or “Hilaly” can be transliterate to “Clinton” or “Klinton”. But the combination of will be selected for it is the most common combination. So the hit of combination query will be extracted as a feature in classifier. words around the NE: can take some hint words around the NE into the query, in order to add some limitations to filter out noisy words. example: can be used as word for To find the hint words, we first search the Chinese name in Chinese web pages. The frequent words can be extracted as hint words and they will be translated to English using a bilingual dictionary. These hint words are combined with the revised candidates to search English web pages. So, the hit of the query will be extracted as feature. The formula of AdaBoost is as follow. the weight for the weak classifier be calculated based on the precision of its corresponding classifier. 5 Experiments We carry out experiments to investigate how much the revision process and the re-ranking process can improve the performance compared with the baseline of statistical transliteration model. We will also evaluate to which extents we can solve the two problems mentioned in section 1 with the assistance of Web resources. pairs are selected randomly as the close test data. 1,294 pairs out of training set are selected as the open test data. To set up the word list, a 2GB-sized collection of web pages is used. Since 7.42% of the names in the test data don’t appear in the list, we get the web page containing the absent names and add these pages into the collection. The word list contains 672,533 words. phase vs. statistical approach Using the results generated from statistical model as baseline, we evaluate the revision module in recall first. The statistical transliteration model works in the following 4 steps: 1) Chinese name are transformed into pinyin representation and the English names are split into syllables. 2) The is invoked to align pinyin to syllaand the alignment probabilities  |es) obtained. 3) Those frequent sequences of syllables are combined as phrases. For example, 4) decoder is executed to generate 100-best candidates for every name. We compare the statistical transliteration results with the revised results in Table 2. From Table 2 we can find that the recall of top-100 after revision is improved by 13.26% in close test set and 17.55% in open test set. It proves that the revision module is effective for correcting the mistakes made in statistical transliteration model. Transliteration Revised results results close open close open Top1 33.64% 9.41% 27.15% 11.04% Top5 40.37% 13.38% 42.83% 19.69% Top10 47.79% 17.56% 56.98% 26.52% Top20 61.88% 25.44% 71.05% 37.81% Top50 66.49% 36.19% 82.16% 46.22% Top100 72.52% 41.73% 85.78% 59.28% T (7) Table 2. Statistical model vs. Revision module data The training corpus for statistical transliteration model comes from the corpus of Chinese &lt;-&gt; English Name Entity Lists v 1.0 (LDC2005T34). It contains 565,935 transliteration pairs. Ruling out those pairs which are not suitable for the research on Chinese-English backward transliteration, such as Chinese-Japanese, we select a training set which contains 14,443 pairs of Chinese-European &amp; American person names. In the training set, 1,344 To show the effects of the revision on the two above-mentioned problems in which the statistical model does not solve well: the losing of silent syllables and the selection bias problem, we make a statistics of the improvements with a measurement of “correction time”. For a Chinese word whose correct transliteration appears in top-100 candidates only if it has been 546 revised, we count the “correction time”. For example, when “Argahi” is revised to “Agassi” the correction time is “1” for Problem II and “1” for I, because in the syllable is and in “si” an “s” is added. Close test Open test Problem I 0.6931 0.7853 Problem II 0.9264 1.1672 Table 3. Average time of correction This measurement reflects the efficiency of the revision of search strategy, in contrast to those spelling correction techniques in which several operations of “add” and “expand” are inevitable. It has proved that the more an average correction time is, the more efficient our strategy is. Figure 2. Length influence in recall comparison The recall of the statistical model relies on the length of English name in some degree. It is more difficult to obtain an absolutely correct answer for longer names, because they may contain more silent and confused syllables. However, through the revision phase, this tendency can be effectively alleviated. In Figure 2, we make a comparison between the results of the statistical model and the revision module with the changing of syllable’s length in open test. The curves demonstrate that the revision indeed prevents the decrease of recall for longer names. setting in the revision phase We will show the experimental results when setting different parameters for query expansion. In the expansion based on phonetic similarity, for every Chinese pinyin, we select at most 20 syllato create an expansion set. We set formula (5). The results are shown in the columns labeled “exp1” in Table 4. From the results we can conclude that, we get best performance when That means the performance is best when the weight of exact matching is a little larger than the weight of fuzzy matching. We can also see that, higher weight of exact matching will lead to low recall, while higher weight of fuzzy matching will bring noise in. The expansion method based on syllable similarity is also evaluated. For every syllable, we select at most 15 syllables to create the expansion set. We The results are shown in the columns labeled “exp2” in Table 4. From the results we can conclude that, we get best performance when It means that we can’t put emphasis on any matching methods. Comparison with the expansion based on phonetic similarity, the performance is poorer. It means that the expansion based on phonetic similarity is more suitable for revising transliteration candidates. phase vs. re-ranking phase After the phase of revising transliteration candidates, we re-rank the revised candidate set with the assistance of monolingual web resources. In this section, we will show the improvement in precision after re-ranking. We have selected four kinds of features to integrate in the AdaBoost framework. To determine whether the candidate is NE or not in its context, use the software tool The queries are to so that we can get the hit of queries and the top-10 snippets will be extracted as context. The comparison of revision results and reranking results is shown as follows. Revised results Re-ranked results close open close open Top1 27.15% 11.04% 58.08% 38.63% Top5 42.83% 19.69% 76.35% 52.19% Top10 56.98% 26.52% 83..92% 54.33% Top20 71.05% 37.81% 83.92% 57.61% Top50 82.16% 46.22% 83.92% 57.61% Top100 85.78% 59.28% 85.78% 59.28% Table 5. Revision results vs. Re-ranking results From these results we can conclude that, after re-ranking phase, the noisy words will get a lower ,-./0-1 0232/02/4 547 Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-lingual information retrieval. In Proc. of the ACL workshop on Multilingual Named Entity Recognition. Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, Wen- Hsiang Lu, Lee-Feng Chien. 2004. Translating unknown cross-lingual queries in digital libraries using a web-based approach. In Proc. of JCDL 2004. E.M.Voorhees and D.M.Tice. 2000. The trec-8 question answering track report. In Eighth Text Retrieval Conference (TREC-8)</abstract>
<intro confidence="0.544826">549</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-lingual information retrieval.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL workshop on Multilingual Named Entity Recognition.</booktitle>
<contexts>
<context position="2386" citStr="Virga and Khudanpur, 2003" startWordPosition="351" endWordPosition="354">teration which transforms an original name into target language, and backward transliteration which recovers a name back to its original expression. For instance, the original English per*Contact: Jun ZHAO, jzhao@nlpr.ia.ac.cn. son name “Clinton” can be forward transliterated to its Chinese expression “克/ke 林/lin顿/dun” and the backward transliteration is the inverse processing. In this paper, we focus on backward transliteration from Chinese to English. Many previous researches have tried to build a transliteration model using statistical approach [Knight and Graehl, 1998; Lin and Chen, 2002; Virga and Khudanpur, 2003; Gao, 2004]. There are two main challenges in statistical backward transliteration: First, statistical transliteration approach selects the most probable translations based on the knowledge learned from the training data. This approach, however, does not work well when there are multiple standards [Gao, 2004]. Second, backward transliteration is more challenging than forward transliteration as it is required to disambiguate the noises introduced in the forward transliteration and estimate the original name as close as possible [Lin and Chen, 2002]. One of the most important causes in introduc</context>
</contexts>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-lingual information retrieval. In Proc. of the ACL workshop on Multilingual Named Entity Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenq-Haur Wang</author>
<author>Jei-Wen Teng</author>
<author>Pu-Jen Cheng</author>
<author>WenHsiang Lu</author>
<author>Lee-Feng Chien</author>
</authors>
<title>Translating unknown cross-lingual queries in digital libraries using a web-based approach.</title>
<date>2004</date>
<booktitle>In Proc. of JCDL</booktitle>
<contexts>
<context position="3355" citStr="Wang et al., 2004" startWordPosition="499" endWordPosition="502">e challenging than forward transliteration as it is required to disambiguate the noises introduced in the forward transliteration and estimate the original name as close as possible [Lin and Chen, 2002]. One of the most important causes in introducing noises is that: some silent syllables in original names have been missing when they are transliterated to target language. For example, when “Campbell” is transliterated into “坎/kan贝/bei尔/er”, the “p” is missing. In order to make up the disadvantages of statistical approach, some researchers have been seeking for the assistance of web resource. [Wang et al., 2004; Cheng et al., 2004; Nagata et al., 2001; Zhang et al, 2005] used bilingual web pages to extract translation pairs. Other efforts have been made to combine a statistical transliteration model with web mining [Al-Onaizan and Knight, 2002; Long Jiang et al, 2007]. Most of these methods need bilingual resources. However, those kinds of resources are not readily available in many cases. Moreover, to search for bilingual pages, we have to depend on the performance of search engines. We can’t get Chinese-English bilingual pages when the input is a Chinese query. Therefore, the existing 541 Proceedi</context>
</contexts>
<marker>Wang, Teng, Cheng, Lu, Chien, 2004</marker>
<rawString>Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, WenHsiang Lu, Lee-Feng Chien. 2004. Translating unknown cross-lingual queries in digital libraries using a web-based approach. In Proc. of JCDL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
<author>D M Tice</author>
</authors>
<title>The trec-8 question answering track report.</title>
<date>2000</date>
<booktitle>In Eighth Text Retrieval Conference (TREC-8)</booktitle>
<marker>Voorhees, Tice, 2000</marker>
<rawString>E.M.Voorhees and D.M.Tice. 2000. The trec-8 question answering track report. In Eighth Text Retrieval Conference (TREC-8)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>