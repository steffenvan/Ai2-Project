<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012380">
<title confidence="0.993586">
Insertion, Deletion, or Substitution? Normalizing Text Messages without
Pre-categorization nor Supervision
</title>
<author confidence="0.999184">
Fei Liu1 Fuliang Weng2 Bingqing Wang3 Yang Liu1
</author>
<affiliation confidence="0.999514666666667">
1Computer Science Department, The University of Texas at Dallas
2Research and Technology Center, Robert Bosch LLC
3School of Computer Science, Fudan University
</affiliation>
<email confidence="0.9531855">
{feiliu, yangl}@hlt.utdallas.edu1
fuliang.weng@us.bosch.com2, wbq@fudan.edu.cn3
</email>
<sectionHeader confidence="0.998507" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99975128">
Most text message normalization approaches
are based on supervised learning and rely on
human labeled training data. In addition, the
nonstandard words are often categorized into
different types and specific models are de-
signed to tackle each type. In this paper,
we propose a unified letter transformation ap-
proach that requires neither pre-categorization
nor human supervision. Our approach mod-
els the generation process from the dictionary
words to nonstandard tokens under a sequence
labeling framework, where each letter in the
dictionary word can be retained, removed, or
substituted by other letters/digits. To avoid
the expensive and time consuming hand label-
ing process, we automatically collected a large
set of noisy training pairs using a novel web-
based approach and performed character-level
alignment for model training. Experiments on
both Twitter and SMS messages show that our
system significantly outperformed the state-
of-the-art deletion-based abbreviation system
and the jazzy spell checker (absolute accuracy
gain of 21.69% and 18.16% over jazzy spell
checker on the two test sets respectively).
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999763142857143">
Recent years have witnessed the explosive growth
of text message usage, including the mobile phone
text messages (SMS), chat logs, emails, and sta-
tus updates from the social network websites such
as Twitter and Facebook. These text message col-
lections serve as valuable information sources, yet
the nonstandard contents within them often degrade
</bodyText>
<page confidence="0.939929">
71
</page>
<table confidence="0.85536425">
2gether (6326) togetha (919) tgthr (250) togeda (20)
2getha (1266) togather (207) t0gether (57) toqethaa (10)
2gthr (178) togehter (94) togeter (49) 2getter (10)
2qetha (46) togethor (29) tagether (18) 2gtr (6)
</table>
<tableCaption confidence="0.987866">
Table 1: Nonstandard tokens originated from “together”
and their frequencies in the Edinburgh Twitter corpus.
</tableCaption>
<bodyText confidence="0.986938422535212">
the existing language processing systems, calling
the need of text normalization before applying the
traditional information extraction, retrieval, senti-
ment analysis (Celikyilmaz et al., 2010), or sum-
marization techniques. Text message normalization
is also of crucial importance for building text-to-
speech (TTS) systems, which need to determine pro-
nunciation for nonstandard words.
Text message normalization aims to replace the
non-standard tokens that carry significant mean-
ings with the context-appropriate standard English
words. This is a very challenging task due to the
vast amount and wide variety of existing nonstan-
dard tokens. We found more than 4 million dis-
tinct out-of-vocabulary tokens in the English tweets
of the Edinburgh Twitter corpus (see Section 2.2).
Table 1 shows examples of nonstandard tokens orig-
inated from the word “together”. We can see that
some variants can be generated by dropping let-
ters from the original word (“tgthr”) or substitut-
ing letters with digit (“2gether”); however, many
variants are generated by combining the letter in-
sertion, deletion, and substitution operations (“to-
qethaa”, “2gthr”). This shows that it is difficult to
divide the nonstandard tokens into exclusive cate-
gories.
Among the literature of text normalization
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 71–76,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
(for text messages or other domains), Sproat et
al. (2001), Cook and Stevenson (2009) employed the
noisy channel model to find the most probable word
sequence given the observed noisy message. Their
approaches first classified the nonstandard tokens
into various categories (e.g., abbreviation, stylistic
variation, prefix-clipping), then calculated the pos-
terior probability of the nonstandard tokens based
on each category. Choudhury et al. (2007) de-
veloped a hidden Markov model using hand anno-
tated training data. Yang et al. (2009), Pennell and
Liu (2010) focused on modeling word abbreviations
formed by dropping characters from the original
word. Toutanova and Moore (2002) addressed the
phonetic substitution problem by extending the ini-
tial letter-to-phone model. Aw et al. (2006), Kobus
et al. (2008) viewed the text message normalization
as a statistical machine translation process from the
texting language to standard English. Beaufort et
al. (2010) experimented with the weighted finite-
state machines for normalizing French SMS mes-
sages. Most of the above approaches rely heavily
on the hand annotated data and involve categorizing
the nonstandard tokens in the first place, which gives
rise to three problems: (1) the labeled data is very
expensive and time consuming to obtain; (2) it is
hard to establish a standard taxonomy for categoriz-
ing the tokens found in text messages; (3) the lack of
optimized way to integrate various category-specific
models often compromises the system performance,
as confirmed by (Cook and Stevenson, 2009).
In this paper, we propose a general letter trans-
formation approach that normalizes nonstandard to-
kens without categorizing them. A large set of noisy
training word pairs were automatically collected via
a novel web-based approach and aligned at the char-
acter level for model training. The system was tested
on both Twitter and SMS messages. Results show
that our system significantly outperformed the jazzy
spell checker and the state-of-the-art deletion-based
abbreviation system, and also demonstrated good
cross-domain portability.
</bodyText>
<sectionHeader confidence="0.969372" genericHeader="method">
2 Letter Transformation Approach
</sectionHeader>
<subsectionHeader confidence="0.727453">
2.1 General Framework
</subsectionHeader>
<bodyText confidence="0.9704965">
Given a noisy text message T, our goal is to nor-
malize it into a standard English word sequence S.
</bodyText>
<figureCaption confidence="0.9988045">
Figure 1: Examples of nonstandard tokens generated by
performing letter transformation on the dictionary words.
</figureCaption>
<bodyText confidence="0.9953595">
Under the noisy channel model, this is equivalent to
finding the sequence S that maximizes p(S|T):
</bodyText>
<equation confidence="0.9915665">
S = arg maxS p(S|T) = arg maxS(Il p(Ti|Si))p(S)
i
</equation>
<bodyText confidence="0.999994961538462">
where we assume that each non-standard token Ti
is dependent on only one English word Si, that is,
we are not considering acronyms (e.g., “bbl” for
“be back later”) in this study. p(S) can be cal-
culated using a language model (LM). We formu-
late the process of generating a nonstandard token
Ti from dictionary word Si using a letter transfor-
mation model, and use the model confidence as the
probability p(Ti|Si). Figure 1 shows several exam-
ple (word, token) pairs1. To form a nonstandard to-
ken, each letter in the dictionary word can be labeled
with: (a) one of the 0-9 digits; (b) one of the 26 char-
acters including itself; (c) the null character “-”; (d)
a letter combination. This transformation process
from dictionary words to nonstandard tokens will be
learned automatically through a sequence labeling
framework that integrates character-, phonetic-, and
syllable-level information.
In general, the letter transformation approach will
handle the nonstandard tokens listed in Table 2 yet
without explicitly categorizing them. Note for the
tokens with letter repetition, we first generate a set
of variants by varying the repetitive letters (e.g. Ci =
{“pleas”, “pleeas”, “pleaas”, “pleeaas”, ‘pleeeaas”}
for Ti = {“pleeeaas”}), then select the maximum
posterior probability among all the variants:
</bodyText>
<equation confidence="0.9712575">
p(Ti|Si) = max
�TiECi
</equation>
<footnote confidence="0.885665">
1The ideal transform for example (5) would be “for” to “4”.
But in this study we are treating each letter in the English word
separately and not considering the phrase-level transformation.
</footnote>
<figure confidence="0.998307388888889">
(1) birthday --&gt; bday (2) photos --&gt; fotoz
(4) hubby --&gt; hubbie
b i r t h d a y
b - - - - d a y
h u b b y
h u b b i e
(5) forever --&gt; 4eva
4 - - e v a -
f o r e v e r
photos
f - o t o z
(6) someone --&gt; some1
(3) nothing --&gt; nuthin
s o m e o n e
s o m e 1 - -
n o t h i n g
n u t h i n -
p( �Ti|Si)
</figure>
<page confidence="0.900563">
72
</page>
<listItem confidence="0.994569">
(1) abbreviation tgthr, weeknd, shudnt
(2) phonetic sub w/- or w/o digit 4got, sumbody, kulture
(3) graphemic sub w/- or w/o digit t0gether, h3r3, 5top, doinq
(4) typographic error thimg, macam
(5) stylistic variation betta, hubbie, cutie
(6) letter repetition pleeeaas, togtherrr
(7) any combination of (1) to (6) luvvvin, 2moro, m0rnin
</listItem>
<tableCaption confidence="0.9979095">
Table 2: Nonstandard tokens that can be processed by the
unified letter transformation approach.
</tableCaption>
<subsectionHeader confidence="0.999545">
2.2 Web based Data Collection w/o Supervision
</subsectionHeader>
<bodyText confidence="0.99987">
We propose to automatically collect training data
(annotate nonstandard words with the corresponding
English forms) using a web-based approach, there-
fore avoiding the expensive human annotation. We
use the Edinburgh Twitter corpus (Petrovic et al.,
2010) for data collection, which contains 97 mil-
lion Twitter messages. The English tweets were
extracted using the TextCat language identification
toolkit (Cavnar and Trenkle, 1994), and tokenized
into a sequence of clean tokens consisting of letters,
digits, and apostrophe.
For the out-of-vocabulary (OOV) tokens consist-
ing of letters and apostrophe, we form n Google
queries for each of them in the form of either
«w1 w2 w3&amp;quot; OOV or OOV «w1 w2 w3&amp;quot;, where w1
to w3 are consecutive context words extracted from
the tweets that contain this OOV. n is set to 6 in this
study. The first 32 returned snippets for each query
are parsed and the words in boldface that are differ-
ent from both the OOV and the context words are
collected as candidate normalized words. Among
them, we further select the words that have longer
common character sequence with the OOV than with
the context words, and pair each of them with the
OOV to form the training pairs. For the OOV tokens
consisting of both letters and digits, we use simple
rules to recover possible original words. These rules
include: 1 → “one”, “won”, “i”; 2 → “to”, “two”,
“too”; 3 → “e”; 4 → “for”, “fore”, “four”; 5 → “s”;
6 → “b”; 8 → “ate”, “ait”, “eat”, “eate”, “ight”,
“aight”. The OOV tokens and any resulting words
from the above process are included in the noisy
training pairs. In addition, we add 932 word pairs
of chat slangs and their normalized word forms col-
lected from InternetSlang.com that are not covered
by the above training set.
These noisy training pairs were further expanded
and purged. We apply the transitive rule on these
initially collected training pairs. For example, if the
two pairs “(cause, cauz)” and “(cauz, coz)” are in the
data set, we will add “(cause, coz)” as another train-
ing pair. We remove the data pairs whose word can-
didate is not in the CMU dictionary. We also remove
the pairs whose word candidate and OOV are simply
inflections of each other, e.g., “(headed, heading)”,
using a set of rules. In total, this procedure generated
62,907 training word pairs including 20,880 unique
candidate words and 46,356 unique OOVs.2
</bodyText>
<subsectionHeader confidence="0.997756">
2.3 Automatic Letter-level Alignment
</subsectionHeader>
<bodyText confidence="0.812816363636364">
Given a training pair (Si, Ti) consisting of a word Si
and its nonstandard variant Ti, we propose a proce-
dure to align each letter in Si with zero, one, or more
letters/digits in Ti. First we align the letters of the
longest common sequence between the dictionary
word and the variant (which gives letter-to-letter cor-
respondence in those common subsequences). Then
for the letter chunks in between each of the obtained
alignments, we process them based on the following
three cases:
(a) (many-to-0): a chunk in the dictionary word
needs to be aligned to zero letters in the variant.
In this case, we map each letter in the chunk to
“-” (e.g., “birthday” to “bday”), obtaining letter-
level alignments.
(b) (0-to-many): zero letters in the dictionary word
need to be aligned to a letter/digit chunk in the
variant. In this case, if the first letter in the
chunk can be combined with the previous letter
to form a digraph (such as “wh” when aligning
“sandwich” to “sandwhich”), we combine these
two letters. The remaining letters, or the entire
chunk when the first letter does not form a di-
graph with the previous letter, are put together
with the following aligned letter in the variant.
(c) (many-to-many): non-zero letters in the dictio-
nary word need to be aligned to a chunk in the
variant. Similar to (b), the first letter in the vari-
ant chunk is merged with the previous alignment
if they form a digraph. Then we map the chunk
in the dictionary word to the chunk in the vari-
ant as one alignment, e.g., “someone” aligned to
“some1”.
</bodyText>
<footnote confidence="0.917156">
2Please contact the first author for the collected word pairs.
</footnote>
<page confidence="0.999194">
73
</page>
<bodyText confidence="0.9998595">
The (b) and (c) cases above generate chunk-level
(with more than one letter) alignments. To elimi-
nate possible noisy training pairs, such as (“you”,
“haveu”), we keep all data pairs containing digits,
but remove the data pairs with chunks involving
three letters or more in either the dictionary word or
the variant. For the chunk alignments in the remain-
ing pairs, we sequentially align the letters (e.g., “ph”
aligned to “f-”). Note that for those 1-to-2 align-
ments, we align the single letter in the dictionary
word to a two-letter combination in the variant. We
limit to the top 5 most frequent letter combinations,
which are “ck”, “ey”, “ie”, “ou”, “wh”, and the pairs
involving other combinations are removed.
After applying the letter alignment to the col-
lected noisy training word pairs, we obtained
298,160 letter-level alignments. Some example
alignments and corresponding word pairs are:
</bodyText>
<equation confidence="0.996627333333333">
e — ’ ’ (have, hav) q — k (iraq, irak)
e — a (another, anotha) q — g (iraq, irag)
e — 3 (online, 0nlin3) w — wh (watch, whatch)
</equation>
<subsectionHeader confidence="0.985554">
2.4 Sequence Labeling Model for P(Ti|Si)
</subsectionHeader>
<bodyText confidence="0.9978757">
For a letter sequence Si, we use the conditional ran-
dom fields (CRF) model to perform sequence tag-
ging to generate its variant Ti. To train the model,
we first align the collected dictionary word and its
variant at the letter level, then construct a feature
vector for each letter in the dictionary word, using
its mapped character as the reference label. This la-
beled data set is used to train a CRF model with L-
BFGS (Lafferty et al., 2001; Kudo, 2005). We use
the following features:
</bodyText>
<listItem confidence="0.992043">
• Character-level features
</listItem>
<equation confidence="0.992451333333333">
Character n-grams: c−1, c0, c1, (c−2 c−1),
(c−1 c0), (c0 c1), (c1 c2), (c−3 c−2 c−1),
(c−2 c−1 c0), (c−1 c0 c1), (c0 c1 c2), (c1 c2 c3).
</equation>
<bodyText confidence="0.895805">
The relative position of character in the word.
</bodyText>
<listItem confidence="0.961393">
• Phonetic-level features
</listItem>
<bodyText confidence="0.945207857142857">
Phoneme n-grams: p−1, p0, p1, (p−1 p0),
(p0 p1). We use the many-to-many letter-
phoneme alignment algorithm (Jiampojamarn
et al., 2007) to map each letter to multiple
phonemes (1-to-2 alignment). We use three bi-
nary features to indicate whether the current,
previous, or next character is a vowel.
</bodyText>
<listItem confidence="0.987757">
• Syllable-level features
</listItem>
<bodyText confidence="0.967756625">
Relative position of the current syllable in the
word; two binary features indicating whether
the character is at the beginning or the end of
the current syllable. The English hyphenation
dictionary (Hindson, 2006) is used to mark all
the syllable information.
The trained CRF model can be applied to any En-
glish word to generate its variants with probabilities.
</bodyText>
<sectionHeader confidence="0.999674" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999926487179488">
We evaluate the system performance on both Twitter
and SMS message test sets. The SMS data was used
in previous work (Choudhury et al., 2007; Cook and
Stevenson, 2009). It consists of 303 distinct non-
standard tokens and their corresponding dictionary
words. We developed our own Twitter message test
set consisting of 6,150 tweets manually annotated
via the Amazon Mechanical Turk. 3 to 6 turkers
were required to convert the nonstandard tokens in
the tweets to the standard English words. We extract
the nonstandard tokens whose most frequently nor-
malized word consists of letters/digits/apostrophe,
and is different from the token itself. This results
in 3,802 distinct nonstandard tokens that we use as
the test set. 147 (3.87%) of them have more than
one corresponding standard English words. Similar
to prior work, we use isolated nonstandard tokens
without any context, that is, the LM probabilities
P(S) are based on unigrams.
We compare our system against three approaches.
The first one is a comprehensive list of chat slangs,
abbreviations, and acronyms collected by Internet-
Slang.com; it contains normalized word forms for
6,105 commonly used slangs. The second is the
word-abbreviation lookup table generated by the su-
pervised deletion-based abbreviation approach pro-
posed in (Pennell and Liu, 2010). It contains
477,941 (word, abbreviation) pairs automatically
generated for 54,594 CMU dictionary words. The
third is the jazzy spell checker based on the Aspell
algorithm (Idzelis, 2005). It integrates the phonetic
matching algorithm (DoubleMetaphone) and Leven-
shtein distance that enables the interchanging of two
adjacent letters, and changing/deleting/adding of let-
ters. The system performance is measured using the
n-best accuracy (n=1,3). For each nonstandard to-
ken, the system is considered correct if any of the
corresponding standard words is among the n-best
output from the system.
</bodyText>
<page confidence="0.995487">
74
</page>
<table confidence="0.9950831">
System Accuracy Twitter (3802 pairs) SMS (303 pairs)
1-best 3-best 1-best 3-best
InternetSlang 7.94 8.07 4.95 4.95
(Pennell et al. 2010) 20.02 27.09 21.12 28.05
Jazzy Spell Checker 47.19 56.92 43.89 55.45
LetterTran (Trim) 57.44 64.89 58.09 70.63
LetterTran (All) 59.15 67.02 58.09 70.96
LetterTran (All) + Jazzy 68.88 78.27 62.05 75.91
(Choudhury et al. 2007) n/a n/a 59.9 n/a
(Cook et al. 2009) n/a n/a 59.4 n/a
</table>
<tableCaption confidence="0.9909545">
Table 3: N-best performance on Twitter and SMS data
sets using different systems.
</tableCaption>
<bodyText confidence="0.999472242424242">
Results of system accuracies are shown in Ta-
ble 3. For the system “LetterTran (All)”, we first
generate a lookup table by applying the trained CRF
model to the CMU dictionary to generate up to
30 variants for each dictionary word.3 To make
the comparison more meaningful, we also trim our
lookup table to the same size as the deletion ta-
ble, namely “LetterTran (Trim)”. The trimming was
performed by selecting the most frequent dictionary
words and their generated variants until the length
limit is reached. Word frequency information was
obtained from the entire Edinburgh corpus. For both
the deletion and letter transformation lookup tables,
we generate a ranked list of candidate words for each
nonstandard token, by sorting the combined score
p(Ti|Si) x C(Si), where p(Ti|Si) is the model con-
fidence and C(Si) is the unigram count generated
from the Edinburgh corpus (we used counts instead
of unigram probability P(Si)). Since the string sim-
ilarity and letter switching algorithms implemented
in jazzy can compensate the letter transformation
model, we also investigate combining it with our ap-
proach, “LetterTran(All) + Jazzy”. In this configura-
tion, we combine the candidate words from both sys-
tems and rerank them according to the unigram fre-
quency; since the “LetterTran” itself is very effective
in ranking candidate words, we only use the jazzy
output for tokens where “LetterTran” is not very
confident about its best candidate ((p(Ti|Si)xC(Si)
is less than a threshold 0 = 100).
We notice the accuracy using the InternetSlang
list is very poor, indicating text message normal-
ization is a very challenging task that can hardly
</bodyText>
<footnote confidence="0.981618666666667">
3We heuristically choose this large number since the learned
letter/digit insertion, substitution, and deletion patterns tend to
generate many variants for each dictionary word.
</footnote>
<bodyText confidence="0.999976548387097">
be tackled by using a hand-crafted list. The dele-
tion table has modest performance given the fact
that it covers only deletion-based abbreviations and
letter repetitions (see Section 2.1). The “Letter-
Tran” approach significantly outperforms all base-
lines even after trimming. This is because it han-
dles different ways of forming nonstandard tokens
in an unified framework. Taking the Twitter test
set for an example, the lookup table generated by
“LetterTran” covered 69.94% of the total test to-
kens, and among them, 96% were correctly normal-
ized in the 3-best output, resulting in 67.02% over-
all accuracy. The test tokens that were not covered
by the “LetterTrans” model include those generated
by accidentally switching and inserting letters (e.g.,
“absolotuely” for “absolutely”) and slangs (“addy”
or “address”). Adding the output from jazzy com-
pensates these problems and boosts the 1-best ac-
curacy, achieving 21.69% and 18.16% absolute per-
formance gain respectively on the Twitter and SMS
test sets, as compared to using jazzy only. We also
observe that the “LetterTran” model can be easily
ported to the SMS domain. When combined with
the jazzy module, it achieved 62.05% 1-best accu-
racy, outperforming the domain-specific supervised
system in (Choudhury et al., 2007) (59.9%) and
the pre-categorized approach by (Cook and Steven-
son, 2009) (59.4%). Regarding different feature cat-
egories, we found the character-level features are
strong indicators, and using phonetic- and syllabic-
level features also slightly benefits the performance.
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999950866666667">
In this paper, we proposed a generic letter trans-
formation approach for text message normaliza-
tion without pre-categorizing the nonstandard to-
kens into insertion, deletion, substitution, etc. We
also avoided the expensive and time consuming hand
labeling process by automatically collecting a large
set of noisy training pairs. Results in the Twitter
and SMS domains show that our system can signif-
icantly outperform the state-of-the-art systems and
have good domain portability. In the future, we
would like to compare our method with a statistical
machine translation approach performed at the let-
ter level, evaluate the system using sentences by in-
corporating context word information, and consider
many-to-one letter transformation in the model.
</bodyText>
<page confidence="0.99712">
75
</page>
<sectionHeader confidence="0.936747" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999929">
The authors thank Deana Pennell for sharing the
look-up table generated using the deletion-based ab-
breviation approach. Thank Sittichai Jiampojamarn
for providing the many-to-many letter-phoneme
alignment data sets and toolkit. Part of this work
was done while Fei Liu was working as a research
intern in Bosch Research and Technology Center.
</bodyText>
<sectionHeader confidence="0.956386" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.996820769230769">
better than one? In Proceedings of the COLING, pages
441–448.
Taku Kudo. 2005. CRF++: Yet another CRF took kit.
http://crfpp.sourceforge.net/.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the ICML, pages 282–289.
Deana L. Pennell and Yang Liu. 2010. Normalization
of text messages for text-to-speech. In Proceedings of
the ICASSP, pages 4842–4845.
Sasa Petrovic, Miles Osborne, and Victor Lavrenko.
2010. The edinburgh twitter corpus. In Proceedings
of the NAACL HLT Workshop on Computational Lin-
guistics in a World of Social Media, pages 25–26.
Richard Sproat, Alan W. Black, Stanley Chen, Shankar
Kumar, Mari Ostendorf, and Christopher Richards.
2001. Normalization of non-standard words. Com-
puter Speech and Language, 15(3):287–333.
Kristina Toutanova and Robert C. Moore. 2002. Pronun-
ciation modeling for improved spelling correction. In
Proceedings of the ACL, pages 144–151.
Dong Yang, Yi cheng Pan, and Sadaoki Furui. 2009.
Automatic chinese abbreviation generation using con-
ditional random field. In Proceedings of the NAACL
HLT, pages 273–276.
</bodyText>
<reference confidence="0.99951495">
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A
phrase-based statistical model for sms text normaliza-
tion. In Proceedings of the COLING/ACL, pages 33–
40.
Richard Beaufort, Sophie Roekhaut, Louise-Am´elie
Cougnon, and C´edrick Fairon. 2010. A hybrid
rule/model-based finite-state framework for normaliz-
ing sms messages. In Proceedings of the ACL, pages
770–779.
William B. Cavnar and John M. Trenkle. 1994. N-gram-
based text categorization. In Proceedings of Third An-
nual Symposium on Document Analysis and Informa-
tion Retrieval, pages 161–175.
Asli Celikyilmaz, Dilek Hakkani-Tur, and Junlan Feng.
2010. Probabilistic model-based sentiment analysis of
twitter messages. In Proceedings of the IEEE Work-
shop on Spoken Language Technology, pages 79–84.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar, and Anupam Basu.
2007. Investigation and modeling of the structure of
texting language. International Journal on Document
Analysis and Recognition, 10(3):157–174.
Paul Cook and Suzanne Stevenson. 2009. An unsuper-
vised model for text messages normalization. In Pro-
ceedings of the NAACL HLT Workshop on Computa-
tional Approaches to Linguistic Creativity, pages 71–
78.
Matthew Hindson. 2006. En-
glish language hyphenation dictionary.
http://www.hindson.com.au/wordpress/2006/11/11/english-
language-hyphenation-dictionary/.
Mindaugas Idzelis. 2005. Jazzy: The java open source
spell checker. http://jazzy.sourceforge.net/.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme con-
version. In Proceedings of the HLT/NAACL, pages
372–379.
Catherine Kobus, Franc¸ois Yvon, and G´eraldine
Damnati. 2008. Normalizing sms: Are two metaphors
</reference>
<page confidence="0.991823">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.197814">
<title confidence="0.7587305">Insertion, Deletion, or Substitution? Normalizing Text Messages Pre-categorization nor Supervision Fuliang Bingqing Yang Science Department, The University of Texas at</title>
<author confidence="0.812412">Technology Center</author>
<author confidence="0.812412">Robert Bosch</author>
<affiliation confidence="0.468205">of Computer Science, Fudan</affiliation>
<abstract confidence="0.999389">Most text message normalization approaches are based on supervised learning and rely on human labeled training data. In addition, the nonstandard words are often categorized into different types and specific models are designed to tackle each type. In this paper, we propose a unified letter transformation approach that requires neither pre-categorization nor human supervision. Our approach models the generation process from the dictionary words to nonstandard tokens under a sequence labeling framework, where each letter in the dictionary word can be retained, removed, or substituted by other letters/digits. To avoid the expensive and time consuming hand labeling process, we automatically collected a large set of noisy training pairs using a novel webbased approach and performed character-level alignment for model training. Experiments on both Twitter and SMS messages show that our system significantly outperformed the stateof-the-art deletion-based abbreviation system and the jazzy spell checker (absolute accuracy gain of 21.69% and 18.16% over jazzy spell checker on the two test sets respectively).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>AiTi Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for sms text normalization.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="4468" citStr="Aw et al. (2006)" startWordPosition="642" endWordPosition="645">rved noisy message. Their approaches first classified the nonstandard tokens into various categories (e.g., abbreviation, stylistic variation, prefix-clipping), then calculated the posterior probability of the nonstandard tokens based on each category. Choudhury et al. (2007) developed a hidden Markov model using hand annotated training data. Yang et al. (2009), Pennell and Liu (2010) focused on modeling word abbreviations formed by dropping characters from the original word. Toutanova and Moore (2002) addressed the phonetic substitution problem by extending the initial letter-to-phone model. Aw et al. (2006), Kobus et al. (2008) viewed the text message normalization as a statistical machine translation process from the texting language to standard English. Beaufort et al. (2010) experimented with the weighted finitestate machines for normalizing French SMS messages. Most of the above approaches rely heavily on the hand annotated data and involve categorizing the nonstandard tokens in the first place, which gives rise to three problems: (1) the labeled data is very expensive and time consuming to obtain; (2) it is hard to establish a standard taxonomy for categorizing the tokens found in text mess</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for sms text normalization. In Proceedings of the COLING/ACL, pages 33– 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Beaufort</author>
<author>Sophie Roekhaut</author>
<author>Louise-Am´elie Cougnon</author>
<author>C´edrick Fairon</author>
</authors>
<title>A hybrid rule/model-based finite-state framework for normalizing sms messages.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>770--779</pages>
<contexts>
<context position="4642" citStr="Beaufort et al. (2010)" startWordPosition="668" endWordPosition="671">lculated the posterior probability of the nonstandard tokens based on each category. Choudhury et al. (2007) developed a hidden Markov model using hand annotated training data. Yang et al. (2009), Pennell and Liu (2010) focused on modeling word abbreviations formed by dropping characters from the original word. Toutanova and Moore (2002) addressed the phonetic substitution problem by extending the initial letter-to-phone model. Aw et al. (2006), Kobus et al. (2008) viewed the text message normalization as a statistical machine translation process from the texting language to standard English. Beaufort et al. (2010) experimented with the weighted finitestate machines for normalizing French SMS messages. Most of the above approaches rely heavily on the hand annotated data and involve categorizing the nonstandard tokens in the first place, which gives rise to three problems: (1) the labeled data is very expensive and time consuming to obtain; (2) it is hard to establish a standard taxonomy for categorizing the tokens found in text messages; (3) the lack of optimized way to integrate various category-specific models often compromises the system performance, as confirmed by (Cook and Stevenson, 2009). In thi</context>
</contexts>
<marker>Beaufort, Roekhaut, Cougnon, Fairon, 2010</marker>
<rawString>Richard Beaufort, Sophie Roekhaut, Louise-Am´elie Cougnon, and C´edrick Fairon. 2010. A hybrid rule/model-based finite-state framework for normalizing sms messages. In Proceedings of the ACL, pages 770–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William B Cavnar</author>
<author>John M Trenkle</author>
</authors>
<title>N-grambased text categorization.</title>
<date>1994</date>
<booktitle>In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval,</booktitle>
<pages>161--175</pages>
<contexts>
<context position="8914" citStr="Cavnar and Trenkle, 1994" startWordPosition="1387" endWordPosition="1390">ny combination of (1) to (6) luvvvin, 2moro, m0rnin Table 2: Nonstandard tokens that can be processed by the unified letter transformation approach. 2.2 Web based Data Collection w/o Supervision We propose to automatically collect training data (annotate nonstandard words with the corresponding English forms) using a web-based approach, therefore avoiding the expensive human annotation. We use the Edinburgh Twitter corpus (Petrovic et al., 2010) for data collection, which contains 97 million Twitter messages. The English tweets were extracted using the TextCat language identification toolkit (Cavnar and Trenkle, 1994), and tokenized into a sequence of clean tokens consisting of letters, digits, and apostrophe. For the out-of-vocabulary (OOV) tokens consisting of letters and apostrophe, we form n Google queries for each of them in the form of either «w1 w2 w3&amp;quot; OOV or OOV «w1 w2 w3&amp;quot;, where w1 to w3 are consecutive context words extracted from the tweets that contain this OOV. n is set to 6 in this study. The first 32 returned snippets for each query are parsed and the words in boldface that are different from both the OOV and the context words are collected as candidate normalized words. Among them, we furth</context>
</contexts>
<marker>Cavnar, Trenkle, 1994</marker>
<rawString>William B. Cavnar and John M. Trenkle. 1994. N-grambased text categorization. In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval, pages 161–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
<author>Junlan Feng</author>
</authors>
<title>Probabilistic model-based sentiment analysis of twitter messages.</title>
<date>2010</date>
<booktitle>In Proceedings of the IEEE Workshop on Spoken Language Technology,</booktitle>
<pages>79--84</pages>
<contexts>
<context position="2399" citStr="Celikyilmaz et al., 2010" startWordPosition="336" endWordPosition="339">e collections serve as valuable information sources, yet the nonstandard contents within them often degrade 71 2gether (6326) togetha (919) tgthr (250) togeda (20) 2getha (1266) togather (207) t0gether (57) toqethaa (10) 2gthr (178) togehter (94) togeter (49) 2getter (10) 2qetha (46) togethor (29) tagether (18) 2gtr (6) Table 1: Nonstandard tokens originated from “together” and their frequencies in the Edinburgh Twitter corpus. the existing language processing systems, calling the need of text normalization before applying the traditional information extraction, retrieval, sentiment analysis (Celikyilmaz et al., 2010), or summarization techniques. Text message normalization is also of crucial importance for building text-tospeech (TTS) systems, which need to determine pronunciation for nonstandard words. Text message normalization aims to replace the non-standard tokens that carry significant meanings with the context-appropriate standard English words. This is a very challenging task due to the vast amount and wide variety of existing nonstandard tokens. We found more than 4 million distinct out-of-vocabulary tokens in the English tweets of the Edinburgh Twitter corpus (see Section 2.2). Table 1 shows exa</context>
</contexts>
<marker>Celikyilmaz, Hakkani-Tur, Feng, 2010</marker>
<rawString>Asli Celikyilmaz, Dilek Hakkani-Tur, and Junlan Feng. 2010. Probabilistic model-based sentiment analysis of twitter messages. In Proceedings of the IEEE Workshop on Spoken Language Technology, pages 79–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
<author>Rahul Saraf</author>
<author>Vijit Jain</author>
<author>Animesh Mukherjee</author>
<author>Sudeshna Sarkar</author>
<author>Anupam Basu</author>
</authors>
<title>Investigation and modeling of the structure of texting language.</title>
<date>2007</date>
<journal>International Journal on Document Analysis and Recognition,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="4128" citStr="Choudhury et al. (2007)" startWordPosition="589" endWordPosition="592">nnual Meeting of the Association for Computational Linguistics:shortpapers, pages 71–76, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (for text messages or other domains), Sproat et al. (2001), Cook and Stevenson (2009) employed the noisy channel model to find the most probable word sequence given the observed noisy message. Their approaches first classified the nonstandard tokens into various categories (e.g., abbreviation, stylistic variation, prefix-clipping), then calculated the posterior probability of the nonstandard tokens based on each category. Choudhury et al. (2007) developed a hidden Markov model using hand annotated training data. Yang et al. (2009), Pennell and Liu (2010) focused on modeling word abbreviations formed by dropping characters from the original word. Toutanova and Moore (2002) addressed the phonetic substitution problem by extending the initial letter-to-phone model. Aw et al. (2006), Kobus et al. (2008) viewed the text message normalization as a statistical machine translation process from the texting language to standard English. Beaufort et al. (2010) experimented with the weighted finitestate machines for normalizing French SMS messag</context>
<context position="15123" citStr="Choudhury et al., 2007" startWordPosition="2463" endWordPosition="2466">tures to indicate whether the current, previous, or next character is a vowel. • Syllable-level features Relative position of the current syllable in the word; two binary features indicating whether the character is at the beginning or the end of the current syllable. The English hyphenation dictionary (Hindson, 2006) is used to mark all the syllable information. The trained CRF model can be applied to any English word to generate its variants with probabilities. 3 Experiments We evaluate the system performance on both Twitter and SMS message test sets. The SMS data was used in previous work (Choudhury et al., 2007; Cook and Stevenson, 2009). It consists of 303 distinct nonstandard tokens and their corresponding dictionary words. We developed our own Twitter message test set consisting of 6,150 tweets manually annotated via the Amazon Mechanical Turk. 3 to 6 turkers were required to convert the nonstandard tokens in the tweets to the standard English words. We extract the nonstandard tokens whose most frequently normalized word consists of letters/digits/apostrophe, and is different from the token itself. This results in 3,802 distinct nonstandard tokens that we use as the test set. 147 (3.87%) of them </context>
<context position="17251" citStr="Choudhury et al. 2007" startWordPosition="2786" endWordPosition="2789">and changing/deleting/adding of letters. The system performance is measured using the n-best accuracy (n=1,3). For each nonstandard token, the system is considered correct if any of the corresponding standard words is among the n-best output from the system. 74 System Accuracy Twitter (3802 pairs) SMS (303 pairs) 1-best 3-best 1-best 3-best InternetSlang 7.94 8.07 4.95 4.95 (Pennell et al. 2010) 20.02 27.09 21.12 28.05 Jazzy Spell Checker 47.19 56.92 43.89 55.45 LetterTran (Trim) 57.44 64.89 58.09 70.63 LetterTran (All) 59.15 67.02 58.09 70.96 LetterTran (All) + Jazzy 68.88 78.27 62.05 75.91 (Choudhury et al. 2007) n/a n/a 59.9 n/a (Cook et al. 2009) n/a n/a 59.4 n/a Table 3: N-best performance on Twitter and SMS data sets using different systems. Results of system accuracies are shown in Table 3. For the system “LetterTran (All)”, we first generate a lookup table by applying the trained CRF model to the CMU dictionary to generate up to 30 variants for each dictionary word.3 To make the comparison more meaningful, we also trim our lookup table to the same size as the deletion table, namely “LetterTran (Trim)”. The trimming was performed by selecting the most frequent dictionary words and their generated</context>
<context position="20481" citStr="Choudhury et al., 2007" startWordPosition="3300" endWordPosition="3303">“LetterTrans” model include those generated by accidentally switching and inserting letters (e.g., “absolotuely” for “absolutely”) and slangs (“addy” or “address”). Adding the output from jazzy compensates these problems and boosts the 1-best accuracy, achieving 21.69% and 18.16% absolute performance gain respectively on the Twitter and SMS test sets, as compared to using jazzy only. We also observe that the “LetterTran” model can be easily ported to the SMS domain. When combined with the jazzy module, it achieved 62.05% 1-best accuracy, outperforming the domain-specific supervised system in (Choudhury et al., 2007) (59.9%) and the pre-categorized approach by (Cook and Stevenson, 2009) (59.4%). Regarding different feature categories, we found the character-level features are strong indicators, and using phonetic- and syllabiclevel features also slightly benefits the performance. 4 Conclusion In this paper, we proposed a generic letter transformation approach for text message normalization without pre-categorizing the nonstandard tokens into insertion, deletion, substitution, etc. We also avoided the expensive and time consuming hand labeling process by automatically collecting a large set of noisy traini</context>
</contexts>
<marker>Choudhury, Saraf, Jain, Mukherjee, Sarkar, Basu, 2007</marker>
<rawString>Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. International Journal on Document Analysis and Recognition, 10(3):157–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>An unsupervised model for text messages normalization.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="3764" citStr="Cook and Stevenson (2009)" startWordPosition="539" endWordPosition="542"> original word (“tgthr”) or substituting letters with digit (“2gether”); however, many variants are generated by combining the letter insertion, deletion, and substitution operations (“toqethaa”, “2gthr”). This shows that it is difficult to divide the nonstandard tokens into exclusive categories. Among the literature of text normalization Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 71–76, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (for text messages or other domains), Sproat et al. (2001), Cook and Stevenson (2009) employed the noisy channel model to find the most probable word sequence given the observed noisy message. Their approaches first classified the nonstandard tokens into various categories (e.g., abbreviation, stylistic variation, prefix-clipping), then calculated the posterior probability of the nonstandard tokens based on each category. Choudhury et al. (2007) developed a hidden Markov model using hand annotated training data. Yang et al. (2009), Pennell and Liu (2010) focused on modeling word abbreviations formed by dropping characters from the original word. Toutanova and Moore (2002) addr</context>
<context position="5234" citStr="Cook and Stevenson, 2009" startWordPosition="762" endWordPosition="765">d English. Beaufort et al. (2010) experimented with the weighted finitestate machines for normalizing French SMS messages. Most of the above approaches rely heavily on the hand annotated data and involve categorizing the nonstandard tokens in the first place, which gives rise to three problems: (1) the labeled data is very expensive and time consuming to obtain; (2) it is hard to establish a standard taxonomy for categorizing the tokens found in text messages; (3) the lack of optimized way to integrate various category-specific models often compromises the system performance, as confirmed by (Cook and Stevenson, 2009). In this paper, we propose a general letter transformation approach that normalizes nonstandard tokens without categorizing them. A large set of noisy training word pairs were automatically collected via a novel web-based approach and aligned at the character level for model training. The system was tested on both Twitter and SMS messages. Results show that our system significantly outperformed the jazzy spell checker and the state-of-the-art deletion-based abbreviation system, and also demonstrated good cross-domain portability. 2 Letter Transformation Approach 2.1 General Framework Given a </context>
<context position="15150" citStr="Cook and Stevenson, 2009" startWordPosition="2467" endWordPosition="2470">r the current, previous, or next character is a vowel. • Syllable-level features Relative position of the current syllable in the word; two binary features indicating whether the character is at the beginning or the end of the current syllable. The English hyphenation dictionary (Hindson, 2006) is used to mark all the syllable information. The trained CRF model can be applied to any English word to generate its variants with probabilities. 3 Experiments We evaluate the system performance on both Twitter and SMS message test sets. The SMS data was used in previous work (Choudhury et al., 2007; Cook and Stevenson, 2009). It consists of 303 distinct nonstandard tokens and their corresponding dictionary words. We developed our own Twitter message test set consisting of 6,150 tweets manually annotated via the Amazon Mechanical Turk. 3 to 6 turkers were required to convert the nonstandard tokens in the tweets to the standard English words. We extract the nonstandard tokens whose most frequently normalized word consists of letters/digits/apostrophe, and is different from the token itself. This results in 3,802 distinct nonstandard tokens that we use as the test set. 147 (3.87%) of them have more than one correspo</context>
<context position="20552" citStr="Cook and Stevenson, 2009" startWordPosition="3310" endWordPosition="3314"> and inserting letters (e.g., “absolotuely” for “absolutely”) and slangs (“addy” or “address”). Adding the output from jazzy compensates these problems and boosts the 1-best accuracy, achieving 21.69% and 18.16% absolute performance gain respectively on the Twitter and SMS test sets, as compared to using jazzy only. We also observe that the “LetterTran” model can be easily ported to the SMS domain. When combined with the jazzy module, it achieved 62.05% 1-best accuracy, outperforming the domain-specific supervised system in (Choudhury et al., 2007) (59.9%) and the pre-categorized approach by (Cook and Stevenson, 2009) (59.4%). Regarding different feature categories, we found the character-level features are strong indicators, and using phonetic- and syllabiclevel features also slightly benefits the performance. 4 Conclusion In this paper, we proposed a generic letter transformation approach for text message normalization without pre-categorizing the nonstandard tokens into insertion, deletion, substitution, etc. We also avoided the expensive and time consuming hand labeling process by automatically collecting a large set of noisy training pairs. Results in the Twitter and SMS domains show that our system c</context>
</contexts>
<marker>Cook, Stevenson, 2009</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2009. An unsupervised model for text messages normalization. In Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 71– 78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Hindson</author>
</authors>
<title>English language hyphenation dictionary.</title>
<date>2006</date>
<contexts>
<context position="14820" citStr="Hindson, 2006" startWordPosition="2412" endWordPosition="2413">). The relative position of character in the word. • Phonetic-level features Phoneme n-grams: p−1, p0, p1, (p−1 p0), (p0 p1). We use the many-to-many letterphoneme alignment algorithm (Jiampojamarn et al., 2007) to map each letter to multiple phonemes (1-to-2 alignment). We use three binary features to indicate whether the current, previous, or next character is a vowel. • Syllable-level features Relative position of the current syllable in the word; two binary features indicating whether the character is at the beginning or the end of the current syllable. The English hyphenation dictionary (Hindson, 2006) is used to mark all the syllable information. The trained CRF model can be applied to any English word to generate its variants with probabilities. 3 Experiments We evaluate the system performance on both Twitter and SMS message test sets. The SMS data was used in previous work (Choudhury et al., 2007; Cook and Stevenson, 2009). It consists of 303 distinct nonstandard tokens and their corresponding dictionary words. We developed our own Twitter message test set consisting of 6,150 tweets manually annotated via the Amazon Mechanical Turk. 3 to 6 turkers were required to convert the nonstandard</context>
</contexts>
<marker>Hindson, 2006</marker>
<rawString>Matthew Hindson. 2006. English language hyphenation dictionary.</rawString>
</citation>
<citation valid="false">
<pages>2006--11</pages>
<marker></marker>
<rawString>http://www.hindson.com.au/wordpress/2006/11/11/englishlanguage-hyphenation-dictionary/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mindaugas Idzelis</author>
</authors>
<title>Jazzy: The java open source spell checker.</title>
<date>2005</date>
<note>http://jazzy.sourceforge.net/.</note>
<contexts>
<context position="16482" citStr="Idzelis, 2005" startWordPosition="2672" endWordPosition="2673">the LM probabilities P(S) are based on unigrams. We compare our system against three approaches. The first one is a comprehensive list of chat slangs, abbreviations, and acronyms collected by InternetSlang.com; it contains normalized word forms for 6,105 commonly used slangs. The second is the word-abbreviation lookup table generated by the supervised deletion-based abbreviation approach proposed in (Pennell and Liu, 2010). It contains 477,941 (word, abbreviation) pairs automatically generated for 54,594 CMU dictionary words. The third is the jazzy spell checker based on the Aspell algorithm (Idzelis, 2005). It integrates the phonetic matching algorithm (DoubleMetaphone) and Levenshtein distance that enables the interchanging of two adjacent letters, and changing/deleting/adding of letters. The system performance is measured using the n-best accuracy (n=1,3). For each nonstandard token, the system is considered correct if any of the corresponding standard words is among the n-best output from the system. 74 System Accuracy Twitter (3802 pairs) SMS (303 pairs) 1-best 3-best 1-best 3-best InternetSlang 7.94 8.07 4.95 4.95 (Pennell et al. 2010) 20.02 27.09 21.12 28.05 Jazzy Spell Checker 47.19 56.9</context>
</contexts>
<marker>Idzelis, 2005</marker>
<rawString>Mindaugas Idzelis. 2005. Jazzy: The java open source spell checker. http://jazzy.sourceforge.net/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proceedings of the HLT/NAACL,</booktitle>
<pages>372--379</pages>
<contexts>
<context position="14417" citStr="Jiampojamarn et al., 2007" startWordPosition="2347" endWordPosition="2350"> then construct a feature vector for each letter in the dictionary word, using its mapped character as the reference label. This labeled data set is used to train a CRF model with LBFGS (Lafferty et al., 2001; Kudo, 2005). We use the following features: • Character-level features Character n-grams: c−1, c0, c1, (c−2 c−1), (c−1 c0), (c0 c1), (c1 c2), (c−3 c−2 c−1), (c−2 c−1 c0), (c−1 c0 c1), (c0 c1 c2), (c1 c2 c3). The relative position of character in the word. • Phonetic-level features Phoneme n-grams: p−1, p0, p1, (p−1 p0), (p0 p1). We use the many-to-many letterphoneme alignment algorithm (Jiampojamarn et al., 2007) to map each letter to multiple phonemes (1-to-2 alignment). We use three binary features to indicate whether the current, previous, or next character is a vowel. • Syllable-level features Relative position of the current syllable in the word; two binary features indicating whether the character is at the beginning or the end of the current syllable. The English hyphenation dictionary (Hindson, 2006) is used to mark all the syllable information. The trained CRF model can be applied to any English word to generate its variants with probabilities. 3 Experiments We evaluate the system performance</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion. In Proceedings of the HLT/NAACL, pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Kobus</author>
<author>Franc¸ois Yvon</author>
<author>G´eraldine Damnati</author>
</authors>
<title>Normalizing sms: Are two metaphors</title>
<date>2008</date>
<contexts>
<context position="4489" citStr="Kobus et al. (2008)" startWordPosition="646" endWordPosition="649">. Their approaches first classified the nonstandard tokens into various categories (e.g., abbreviation, stylistic variation, prefix-clipping), then calculated the posterior probability of the nonstandard tokens based on each category. Choudhury et al. (2007) developed a hidden Markov model using hand annotated training data. Yang et al. (2009), Pennell and Liu (2010) focused on modeling word abbreviations formed by dropping characters from the original word. Toutanova and Moore (2002) addressed the phonetic substitution problem by extending the initial letter-to-phone model. Aw et al. (2006), Kobus et al. (2008) viewed the text message normalization as a statistical machine translation process from the texting language to standard English. Beaufort et al. (2010) experimented with the weighted finitestate machines for normalizing French SMS messages. Most of the above approaches rely heavily on the hand annotated data and involve categorizing the nonstandard tokens in the first place, which gives rise to three problems: (1) the labeled data is very expensive and time consuming to obtain; (2) it is hard to establish a standard taxonomy for categorizing the tokens found in text messages; (3) the lack of</context>
</contexts>
<marker>Kobus, Yvon, Damnati, 2008</marker>
<rawString>Catherine Kobus, Franc¸ois Yvon, and G´eraldine Damnati. 2008. Normalizing sms: Are two metaphors</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>