<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014818">
<title confidence="0.992269">
Accurate Collocation Extraction Using a Multilingual Parser
</title>
<author confidence="0.990644">
Violeta Seretan
</author>
<affiliation confidence="0.99626">
Language Technology Laboratory
University of Geneva
</affiliation>
<address confidence="0.835387">
2, rue de Candolle, 1211 Geneva
</address>
<email confidence="0.992951">
Violeta.Seretan@latl.unige.ch
</email>
<author confidence="0.997576">
Eric Wehrli
</author>
<affiliation confidence="0.997858">
Language Technology Laboratory
University of Geneva
</affiliation>
<address confidence="0.835136">
2, rue de Candolle, 1211 Geneva
</address>
<email confidence="0.994322">
Eric.Wehrli@latl.unige.ch
</email>
<sectionHeader confidence="0.993714" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962692307692">
This paper focuses on the use of advanced
techniques of text analysis as support for
collocation extraction. A hybrid system is
presented that combines statistical meth-
ods and multilingual parsing for detecting
accurate collocational information from
English, French, Spanish and Italian cor-
pora. The advantage of relying on full
parsing over using a traditional window
method (which ignores the syntactic in-
formation) is first theoretically motivated,
then empirically validated by a compara-
tive evaluation experiment.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977428571429">
Recent computational linguistics research fully ac-
knowledged the stringent need for a systematic
and appropriate treatment of phraseological units
in natural language processing applications (Sag
et al., 2002). Syntagmatic relations between words
— also called multi-word expressions, or “id-
iosyncratic interpretations that cross word bound-
aries” (Sag et al., 2002, 2) — constitute an im-
portant part of the lexicon of a language: accord-
ing to Jackendoff (1997), they are at least as nu-
merous as the single words, while according to
Mel’ˇcuk (1998) they outnumber single words ten
to one.
Phraseological units include a wide range of
phenomena, among which we mention compound
nouns (dead end), phrasal verbs (ask out), idioms
(lend somebody a hand), and collocations (fierce
battle, daunting task, schedule a meeting). They
pose important problems for NLP applications,
both text analysis and text production perspectives
being concerned.
In particular, collocations1 are highly problem-
atic, for at least two reasons: first, because their
linguistic status and properties are unclear (as
pointed out by McKeown and Radev (2000), their
definition is rather vague, and the distinction from
other types of expressions is not clearly drawn);
second, because they are prevalent in language.
Mel’ˇcuk (1998, 24) claims that “collocations make
up the lions share of the phraseme inventory”, and
a recent study referred in (Pearce, 2001) showed
that each sentence is likely to contain at least one
collocation.
Collocational information is not only useful, but
also indispensable in many applications. In ma-
chine translation, for instance, it is considered “the
key to producing more acceptable output” (Orliac
and Dillinger, 2003, 292).
This article presents a system that extracts ac-
curate collocational information from corpora by
using a syntactic parser that supports several lan-
guages. After describing the underlying method-
ology (section 2), we report several extraction re-
sults for English, French, Spanish and Italian (sec-
tion 3). Then we present in sections 4 and 5 a com-
parative evaluation experiment proving that a hy-
brid approach leads to more accurate results than a
classical approach in which syntactic information
is not taken into account.
</bodyText>
<sectionHeader confidence="0.989448" genericHeader="method">
2 Hybrid Collocation Extraction
</sectionHeader>
<bodyText confidence="0.9983386">
We consider that syntactic analysis of source cor-
pora is an inescapable precondition for colloca-
tion extraction, and that the syntactic structure of
source text has to be taken into account in order to
ensure the quality and interpretability of results.
</bodyText>
<footnote confidence="0.9174875">
1To put it simply, collocations are non-idiomatical, but
restricted, conventional lexical combinations.
</footnote>
<page confidence="0.972148">
953
</page>
<note confidence="0.541386">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 953–960,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99924887254902">
As a matter of fact, some of the existing colloca-
tion extraction systems already employ (but only
to a limited extent) linguistic tools in order to sup-
port the collocation identification in text corpora.
For instance, lemmatizers are often used for recog-
nizing all the inflected forms of a lexical item, and
POS taggers are used for ruling out certain cate-
gories of words, e.g., in (Justeson and Katz, 1995).
Syntactic analysis has long since been recog-
nized as a prerequisite for collocation extraction
(for instance, by Smadja2), but the traditional sys-
tems simply ignored it because of the lack, at that
time, of efficient and robust parsers required for
processing large corpora. Oddly enough, this situ-
ation is nowadays perpetuated, in spite of the dra-
matic advances in parsing technology. Only a few
exceptions exists, e.g., (Lin, 1998; Krenn and Ev-
ert, 2001).
One possible reason for this might be the way
that collocations are generally understood, as a
purely statistical phenomenon. Some of the best-
known definitions are the following: “Colloca-
tions of a given word are statements of the ha-
bitual and customary places of that word” (Firth,
1957, 181); “arbitrary and recurrent word combi-
nation” (Benson, 1990); or “sequences of lexical
items that habitually co-occur” (Cruse, 1986, 40).
Most of the authors make no claims with respect to
the grammatical status of the collocation, although
this can indirectly inferred from the examples they
provide.
On the contrary, other definitions state explic-
itly that a collocation is an expression of language:
“co-occurrence of two or more lexical items as
realizations of structural elements within a given
syntactic pattern” (Cowie, 1978); “a sequence of
two or more consecutive words, that has character-
istics of a syntactic and semantic unit” (Choueka,
1988). Our approach is committed to these later
definitions, hence the importance we lend to us-
ing appropriate extraction methodologies, based
on syntactic analysis.
The hybrid method we developed relies on the
parser Fips (Wehrli, 2004), that implements the
Government and Binding formalism and supports
several languages (besides the ones mentioned in
2“Ideally, in order to identify lexical relations in a corpus
one would need to first parse it to verify that the words are
used in a single phrase structure. However, in practice, free-
style texts contain a great deal of nonstandard features over
which automatic parsers would fail. This fact is being seri-
ously challenged by current research (...), and might not be
true in the near future” (Smadja, 1993, 151).
the abstract, a few other are also partly dealt with).
We will not present details about the parser here;
what is relevant for this paper is the type of syn-
tactic structures it uses. Each constituent is rep-
resented by a simplified X-bar structure (without
intermediate level), in which to the lexical head is
attached a list of left constituents (its specifiers)
and right constituents (its complements), and each
of these are in turn represented by the same type
of structure, recursively.
Generally speaking, a collocation extraction can
be seen as a two-stage process:
I. in stage one, collocation candidates are iden-
tified from the text corpora, based on criteria
which are specific to each system;
II. in stage two, the candidates are scored and
ranked using specific association measures
(a review can be found in (Manning and
Sch¨utze, 1999; Evert, 2004; Pecina, 2005)).
According to this description, in our approach
the parser is used in the first stage of extraction,
for identifying the collocation candidates. A pair
of lexical items is selected as a candidate only if
there is a syntactic relation holding between the
two items (one being the head of the current parse
structure, and the other the lexical head of its spec-
ifier/complement). Therefore, the criterion we em-
ploy for candidate selection is the syntactic prox-
imity, as opposed to the linear proximity used by
traditional, window-based methods.
As the parsing goes on, the syntactic word pairs
are extracted from the parse structures created,
from each head-specifier or head-complement re-
lation. The pairs obtained are then partitioned
according to their syntactic configuration (e.g.,
noun + adjectival or nominal specifier, noun +
argument, noun + adjective in predications, verb
+ adverbial specifier, verb + argument (subject,
object), verb + adjunt, etc). Finally, the log-
likelihood ratios test (henceforth LLR) (Dunning,
1993) is applied on each set of pairs. We call
this method hybrid, since it combines syntactic
and statistical information (about word and co-
occurrence frequency).
The following examples — which, like all the
examples in this paper, are actual extraction re-
sults — demonstrate the potential of our system
to detect collocation candidates, even if subject to
complex syntactic transformations.
</bodyText>
<page confidence="0.996516">
954
</page>
<listItem confidence="0.8584095">
1.a) raise question: The question of
political leadership has been raised
several times by previous speakers.
1.b) play role: What role can Canada’s
immigration program play in help-
ing developing nations... ?
1.c) make mistake: We could look back
and probably see a lot of mistakes
that all parties including Canada
perhaps may have made.
</listItem>
<sectionHeader confidence="0.97736" genericHeader="method">
3 Multilingual Extraction Results
</sectionHeader>
<bodyText confidence="0.99073104">
In this section, we present several extraction re-
sults obtained with the system presented in sec-
tion 2. The experiments were performed on data
in the four languages, and involved the following
corpora: for English and French, a subpart or the
Hansard Corpus of proceedings from the Canadian
Parliament; for Italian, documents from the Swiss
Parliament; and for Spanish, a news corpus dis-
tributed by the Linguistic Data Consortium.
Some statistics on these corpora, some process-
ing details and quantitative results are provided in
Table 1. The first row lists the corpora size (in
tokens); the next three rows show some parsing
statistics3, and the last rows display the number of
collocation candidates extracted and of candidates
for which the LLR score could be computed4.
Statistics English French Spanish Italian
tokens 3509704 1649914 1023249 287804
sentences 197401 70342 67502 12008
compl. parse 139498 50458 13245 4511
avg. length 17.78 23.46 15.16 23.97
pairs 725025 370932 162802 58258
(extracted) 276670 147293 56717 37914
pairs 633345 308410 128679 47771
(scored) 251046 131384 49495 30586
</bodyText>
<tableCaption confidence="0.99764">
Table 1: Extraction statistics
</tableCaption>
<bodyText confidence="0.989953181818182">
In Table 2 we list the top collocations (of length
two) extracted for each language. We do not
specifically discuss here multilingual issues in col-
location extraction; these are dealt with in a sepa-
rate paper (Seretan and Wehrli, 2006).
3The low rate of completely parsed sentences for Spanish
and Italian are due to the relatively reduced coverage of the
parsers of these two languages (under development). How-
ever, even if a sentence is not assigned a complete parse tree,
some syntactic pairs can still be collected from the partial
parses.
</bodyText>
<footnote confidence="0.930246">
4The log-likelihood ratios score is undefined for those
pairs having a cell of the contingency table equal to 0.
</footnote>
<table confidence="0.999887926829268">
Language Key1 Key2 LLR score
English federal government 7229.69
reform party 6530.69
house common 6006.84
minister finance 5829.05
acting speaker 5551.09
red book 5292.63
create job 4131.55
right Hon 4117.52
official opposition 3640.00
deputy speaker 3549.09
French premier ministre 4317.57
bloc qu´eb´ecois 3946.08
discours trˆone 3894.04
v´erificateur g´en´eral 3796.68
parti r´eformiste 3615.04
gouvernement f´ed´eral 3461.88
missile croisi`ere 3147.42
Chambre commune 3083.02
livre rouge 2536.94
secr´etaire parlementaire 2524.68
Spanish banco central 4210.48
mill´on d´olar 3312.68
mill´on peso 2335.00
libre comercio 2169.02
nuevo peso 1322.06
tasa inter´es 1179.62
deuda externo 1119.91
c´amara representante 1015.07
asamblea ordinario 992.85
papel comercial 963.95
Italian consiglio federale 3513.19
scrivere consiglio 594.54
unione europeo 479.73
servizio pubblico 452.92
milione franco 447.63
formazione continuo 388.80
iniziativa popolare 383.68
testo interpellanza 377.46
punto vista 373.24
scrivere risposta 348.77
</table>
<tableCaption confidence="0.7484385">
Table 2: Top ten collocations extracted for each
language
</tableCaption>
<bodyText confidence="0.9663789375">
The collocation pairs obtained were further pro-
cessed with a procedure of long collocations ex-
traction described elsewhere (Seretan et al., 2003).
Some examples of collocations of length 3, 4
and 5 obtained are: minister of Canadian her-
itage, house proceed to statement by, secretary to
leader of gouvernment in house of common (En),
question adresser a` ministre, programme de aide
a` r´enovation r´esidentielle, agent employer force
susceptible causer (Fr), bolsa de comercio local,
peso en cuota de fondo de inversi´on, permitir uso
de papel de deuda esterno (Sp), consiglio federale
disporre, creazione di nuovo posto di lavoro, cos-
tituire fattore penalizzante per regione (It)5.
5Note that the output of the procedure contains lemmas
rather than inflected forms.
</bodyText>
<page confidence="0.99739">
955
</page>
<sectionHeader confidence="0.982533" genericHeader="method">
4 Comparative Evaluation Hypotheses
</sectionHeader>
<subsectionHeader confidence="0.985694">
4.1 Does Parsing Really Help?
</subsectionHeader>
<bodyText confidence="0.999978607843137">
Extracting collocations from raw text, without pre-
processing the source corpora, offers some clear
advantages over linguistically-informed methods
such as ours, which is based on the syntactic anal-
ysis: speed (in contrast, parsing large corpora of
texts is expected to be much more time consum-
ing), robustness (symbolic parsers are often not
robust enough for processing large quantities of
data), portability (no need to a priori define syn-
tactic configurations for collocations candidates).
On the other hand, these basic systems suffer
from the combinatorial explosion if the candidate
pairs are chosen from a large search space. To
cope with this problem, a candidate pair is usu-
ally chosen so that both words are inside a context
(‘collocational’) window of a small length. A 5-
word window is the norm, while longer windows
prove impractical (Dias, 2003).
It has been argued that a window size of 5 is
actually sufficient for capturing most of the col-
locational relations from texts in English. But
there is no evidence sustaining that the same holds
for other languages, like German or the Romance
ones that exhibit freer word order. Therefore, as
window-based systems miss the ‘long-distance’
pairs, their recall is presumably lower than that of
parse-based systems. However, the parser could
also miss relevant pairs due to inherent analysis
errors.
As for precision, the window systems are sus-
ceptible to return more noise, produced by the
grammatically unrelated pairs inside the colloca-
tional window. By dividing the number of gram-
matical pairs by the total number of candidates
considered, we obtain the overall precision with
respect to grammaticality; this result is expected to
be considerably worse in the case of basic method
than for the parse-based methods, just by virtue
of the parsing task. As for the overall precision
with respect to collocability, we expect the propor-
tional figures to be preserved. This is because the
parser-based methods return less, but better pairs
(i.e., only the pairs identified as grammatical), and
because collocations are a subset of the grammat-
ical pairs.
Summing up, the evaluation hypothesis that can
be stated here is the following: parse-based meth-
ods outperform basic methods thanks to a drastic
reduction of noise. While unquestionable under
the assumption of perfect parsing, this hypothesis
has to be empirically validated in an actual setting.
</bodyText>
<subsectionHeader confidence="0.980068">
4.2 Is More Data Better Than Better Data?
</subsectionHeader>
<bodyText confidence="0.99989">
The hypothesis above refers to the overall preci-
sion and recall, that is, relative to the entire list of
selected candidates. One might argue that these
numbers are less relevant for practice than they
are from a theoretical (evaluation) perspective, and
that the exact composition of the list of candi-
dates identified is unimportant if only the top re-
sults (i.e., those pairs situated above a threshold)
are looked at by a lexicographer or an application.
Considering a threshold for the n-best candi-
dates works very much in the favor of basic meth-
ods. As the amount of data increases, there is
a reduction of the noise among the best-scored
pairs, which tend to be more grammatical because
the likelihood of encountering many similar noisy
pairs is lower. However, as the following example
shows, noisy pairs may still appear in top, if they
occur often in a longer collocation:
</bodyText>
<listItem confidence="0.4962035">
2.a) les essais du missile de croisi`ere
2.b) essai - croisi`ere
</listItem>
<bodyText confidence="0.999917653846154">
The pair essai - croisi`ere is marked by the basic
systems as a collocation because of the recurrent
association of the two words in text as part or the
longer collocation essai du missile de croisi`ere. It
is an grammatically unrelated pair, while the cor-
rect pairs reflecting the right syntactic attachment
are essai missile and missile (de) croisi`ere.
We mentioned that parsing helps detecting the
‘long-distance’ pairs that are outside the limits
of the collocational window. Retrieving all such
complex instances (including all the extraposition
cases) certainly augment the recall of extraction
systems, but this goal might seem unjustified, be-
cause the risk of not having a collocation repre-
sented at all diminishes as more and more data
is processed. One might think that systematically
missing long-distance pairs might be very simply
compensated by supplying the system with more
data, and thus that larger data is a valid alternative
to performing complex processing.
While we agree that the inclusion of more data
compensates for the ‘difficult’ cases, we do con-
sider this truly helpful in deriving collocational
information, for the following reasons: (1) more
data means more noise for the basic methods; (2)
some collocations might systematically appear in
</bodyText>
<page confidence="0.993649">
956
</page>
<bodyText confidence="0.999843444444444">
a complex grammatical environment (such as pas-
sive constructions or with additional material in-
serted between the two items); (3) more impor-
tantly, the complex cases not taken into account
alter the frequency profile of the pairs concerned.
These observations entitle us to believe that,
even when more data is added, the n-best precision
might remain lower for the basic methods with re-
spect to the parse-based ones.
</bodyText>
<subsectionHeader confidence="0.991657">
4.3 How Real the Counts Are?
</subsectionHeader>
<bodyText confidence="0.999979545454545">
Syntactic analysis (including shallower levels of
linguistic analysis traditionally used in collocation
extraction, such as lemmatization, POS tagging, or
chunking) has two main functions.
On the one hand, it guides the extraction system
in the candidate selection process, in order to bet-
ter pinpoint the pairs that might form collocations
and to exclude the ones considered as inappropri-
ate (e.g., the pairs combining function words, such
as a preposition followed by a determiner).
On the other, parsing supports the association
measures that will be applied on the selected can-
didates, by providing more exact frequency infor-
mation on words — the inflected forms count as
instances of the same lexical item — and on their
co-occurrence frequency — certain pairs might
count as instance of the same pair, others do not.
In the following example, the pair loi modifier
is an instance of a subject-verb collocation in 3.a),
and of a verb-object collocation type in 3.b). Basic
methods are unable to distinguish between the two
types, and therefore count them as equivalent.
</bodyText>
<listItem confidence="0.962561">
3.a) Loi modifiant la Loi sur la respons-
abilit´e civile
3.b) la loi devrait ˆetre modifi´ee
</listItem>
<bodyText confidence="0.99995525">
Parsing helps to create a more realistic fre-
quency profile for the candidate pairs, not only be-
cause of the grammaticality constraint it applies
on the pairs (wrong pairs are excluded), but also
because it can detect the long-distance pairs that
are outside the collocational window.
Given that the association measures rely heav-
ily on the frequency information, the erroneous
counts have a direct influence on the ranking of
candidates and, consequently, on the top candi-
dates returned. We believe that in order to achieve
a good performance, extraction systems should be
as close as possible to the real frequency counts
and, of course, to the real syntactic interpretation
provided in the source texts6.
Since parser-based methods rely on more accu-
rate frequency information for words and their co-
occurrence than window methods, it follows that
the n-best list obtained with the first methods will
probably show an increase in quality over the sec-
ond.
To conclude this section, we enumerate the hy-
potheses that have been formulated so far: (1)
Parse methods provide a noise-freer list of collo-
cation candidates, in comparison with the window
methods; (2) Local precision (of best-scored re-
sults) with respect to grammaticality is higher for
parse methods, since in basic methods some noise
still persists, even if more data is included; (3) Lo-
cal precision with respect to collocability is higher
for parse methods, because they use a more realis-
tic image of word co-occurrence frequency.
</bodyText>
<sectionHeader confidence="0.996527" genericHeader="method">
5 Comparative Evaluation
</sectionHeader>
<bodyText confidence="0.9997728">
We compare our hybrid method (based on syntac-
tic processing of texts) against the window method
classically used in collocation extraction, from the
point of view of their precision with respect to
grammaticality and collocability.
</bodyText>
<subsectionHeader confidence="0.984059">
5.1 The Method
</subsectionHeader>
<bodyText confidence="0.999986315789474">
The n-best extraction results, for a given n (in our
experiment, n varies from 50 to 500 at intervals
of 50) are checked in each case for grammatical
well-formedness and for lexicalization. By lexi-
calization we mean the quality of a pair to con-
stitute (part of) a multi-word expression — be it
compound, collocation, idiom or another type of
syntagmatic lexical combination. We avoid giving
collocability judgments since the classification of
multi-word expressions cannot be made precisely
and with objective criteria (McKeown and Radev,
2000). We rather distinguish between lexicaliz-
able and trivial combinations (completely regular
productions, such as big house, buy bread, that
do not deserve a place in the lexicon). As in
(Choueka, 1988) and (Evert, 2004), we consider
that a dominant feature of collocations is that they
are unpredictable for speakers and therefore have
to be stored into a lexicon.
</bodyText>
<footnote confidence="0.9965774">
6To exemplify this point: the pair d´eveloppement hu-
main (which has been detected as a collocation by the basic
method) looks like a valid expression, but the source text con-
sistently offers a different interpretation: d´eveloppement des
ressources humaines.
</footnote>
<page confidence="0.996545">
957
</page>
<bodyText confidence="0.999975615384615">
Each collocation from the n-best list at the
different levels considered is therefore annotated
with one of the three flags: 1. ungrammatical;
2. trivial combination; 3. multi-word expression
(MWE).
On the one side, we evaluate the results of our
hybrid, parse-based method; on the other, we sim-
ulate a window method, by performing the fol-
lowing steps: POS-tag the source texts; filter the
lexical items and retain only the open-class POS;
consider all their combinations within a colloca-
tional window of length 5; and, finally, apply the
log-likelihood ratios test on the pairs of each con-
figuration type.
In accordance with (Evert and Kermes, 2003),
we consider that the comparative evaluation of
collocation extraction systems should not be done
at the end of the extraction process, but separately
for each stage: after the candidate selection stage,
for evaluating the quality (in terms of grammati-
cality) of candidates proposed; and after the ap-
plication of collocability measures, for evaluating
the measures applied. In each of these cases, dif-
ferent evaluation methodologies and resources are
required. In our case, since we used the same mea-
sure for the second stage (the log-likelihood ratios
test), we could still compare the final output of ba-
sic and parse-based methods, as given by the com-
bination of the first stage with the same collocabil-
ity measure.
Again, similarly to Krenn and Evert (2001), we
believe that the homogeneity of data is important
for the collocability measures. We therefore ap-
plied the LLR test on our data after first partition-
ing it into separate sets, according to the syntacti-
cal relation holding in each candidate pair. As the
data used in the basic method contains no syntac-
tic information, the partitioning was done based on
POS-combination type.
</bodyText>
<subsectionHeader confidence="0.999803">
5.2 The Data
</subsectionHeader>
<bodyText confidence="0.99999053125">
The evaluation experiment was performed on the
whole French corpus used in the extraction exper-
iment (section 2), that is, a subpart of the Hansard
corpus of Canadian Parliament proceedings. It
contains 112 text files totalling 8.43 MB, with
an average of 628.1 sentences/file and 23.46 to-
kens/sentence (as detected by the parser). The to-
tal number of tokens is 1, 649, 914.
On the one hand, the texts were parsed and
370,932 candidate pairs were extracted using the
hybrid method we presented. Among the pairs ex-
tracted, 11.86% (44,002 pairs) were multi-word
expressions identified at parse-time, since present
in the parser’s lexicon. The log-likelihood ratios
test was applied on the rest of pairs. A score
could be associated to 308, 410 of these pairs (cor-
responding to 131,384 types); for the others, the
score was undefined.
On the other hand, the texts were POS-tagged
using the same parser as in the first case. If in the
first case the candidate pairs were extracted dur-
ing the parsing, in the second they were generated
after the open-class filtering. From 673, 789 POS-
filtered tokens, a number of 1, 024,888 combina-
tions (560, 073 types) were created using the 5-
length window criterion, while taking care not to
cross a punctuation mark. A score could be asso-
ciated to 1, 018, 773 token pairs (554, 202 types),
which means that the candidate list is considerably
larger than in the first case. The processing time
was more than twice longer than in the first case,
because of the large amount of data to handle.
</bodyText>
<subsectionHeader confidence="0.885092">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.999709833333333">
The 500 best-scored collocations retrieved with
the two methods were manually checked by three
human judges and annotated, as explained in 5.1,
as either ungrammatical, trivial or MWE. The
agreement statistics on the annotations for each
method are shown in Table 3.
</bodyText>
<table confidence="0.9792234">
Method Agr. 1,2,3 1,2 1,3 2,3
parse observed 285 365 362 340
k-score 55.4% 62.6% 69% 64%
window observed 226 339 327 269
k-score 43.1% 63.8% 61.1% 48%
</table>
<tableCaption confidence="0.999669">
Table 3: Inter-annotator agreement
</tableCaption>
<bodyText confidence="0.999685285714286">
For reporting n-best precision results, we used
as reference set the annotated pairs on which at
least two of the three annotators agreed. That
is, from the 500 initial pairs retrieved with each
method, 497 pairs were retained in the first case
(parse method), and 483 pairs in the second (win-
dow method).
Table 4 shows the comparative evaluation re-
sults for precision at different levels in the list
of best-scored pairs, both with respect to gram-
maticality and to collocability (or, more exactly,
the potential of a pair to constitute a MWE). The
numbers show that a drastic reduction of noise is
achieved by parsing the texts. The error rate with
</bodyText>
<page confidence="0.993481">
958
</page>
<table confidence="0.999845333333333">
n Precision (gram.) Precision (MWE)
window parse window parse
50 94.0 96.0 80.0 72.0
100 91.0 98.0 75.0 74.0
150 87.3 98.7 72.7 73.3
200 85.5 98.5 70.5 74.0
250 82.8 98.8 67.6 69.6
300 82.3 98.7 65.0 69.3
350 80.3 98.9 63.7 67.4
400 80.0 99.0 62.5 67.0
450 79.6 99.1 61.1 66.0
500 78.3 99.0 60.1 66.0
</table>
<tableCaption confidence="0.999719">
Table 4: Comparative evaluation results
</tableCaption>
<bodyText confidence="0.9999736">
respect to grammaticality is, on average, 15.9%
for the window method; with parsing, it drops to
1.5% (i.e., 10.6 times smaller).
This result confirms our hypothesis regarding
the local precision which was stated in section 4.2.
Despite the inherent parsing errors, the noise re-
duction is substantial. It is also worth noting that
we compared our method against a rather high
baseline, as we made a series of choices suscep-
tible to alleviate the candidates identification with
the window-based method: we filtered out func-
tion words, we used a parser for POS-tagging (that
eliminated POS-ambiguity), and we filtered out
cross-punctuation pairs.
As for the MWE precision, the window method
performs better for the first 100 pairs7); on the re-
maining part, the parsing-based method is on aver-
age 3.7% better. The precision curve for the win-
dow method shows a more rapid degradation than
it does for the other. Therefore we can conclude
that parsing is especially advantageous if one in-
vestigates more that the first hundred results (as
it seems reasonable for large extraction experi-
ments).
In spite of the rough classification we used in
annotation, we believe that the comparison per-
formed is nonetheless meaningful since results
should be first checked for grammaticality and
’triviality’ before defining more difficult tasks
such as collocability.
</bodyText>
<sectionHeader confidence="0.999483" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9983045">
In this paper, we provided both theoretical and em-
pirical arguments in the favor of performing syn-
tactic analysis of texts prior to the extraction of
collocations with statistical methods.
</bodyText>
<footnote confidence="0.950636">
7A closer look at the data revealed that this might be ex-
plained by some inconsistencies between annotations.
</footnote>
<bodyText confidence="0.9999705">
Part of the extraction work that, like ours, re-
lies on parsing was cited in section 2. Most of-
ten, it concerns chunking rather than complete
parsing; specific syntactic configurations (such as
adjective-noun, preposition-noun-verb); and lan-
guages other than the ones we deal with (usually,
English and German). Parsing has been also used
after extraction (Smadja, 1993) for filtering out in-
valid results. We believe that this is not enough
and that parsing is required prior to the applica-
tion of statistical tests, for computing a realistic
frequency profile for the pairs tested.
As for evaluation, unlike most of the existing
work, we are not concerned here with compar-
ing the performance of association measures (cf.
(Evert, 2004; Pecina, 2005) for comprehensive
references), but with a contrastive evaluation of
syntactic-based and standard extraction methods,
combined with the same statistical computation.
Our study finally clear the doubts on the use-
fulness of parsing for collocation extraction. Pre-
vious work that quantified the influence of parsing
on the quality of results suggested the performance
for tagged and parsed texts is similar (Evert and
Kermes, 2003). This result applies to a quite rigid
syntactic pattern, namely adjective-noun in Ger-
man. But a preceding study on noun-verb pairs
(Breidt, 1993) came to the conclusion that good
precision can only be achieved for German with
parsing. Its author had to simulate parsing because
of the lack, at the time, of parsing tools for Ger-
man. Our report, that concerns an actual system
and a large data set, validates Breidt’s finding for
a new language (French).
Our experimental results confirm the hypothe-
ses put forth in section 4, and show that parsing
(even if imperfect) benefits to extraction, notably
by a drastic reduction of the noise in the top of
the significance list. In future work, we consider
investigating other levels of the significance list,
extending the evaluation to other languages, com-
paring against shallow-parsing methods instead of
the window method, and performing recall-based
evaluation as well.
</bodyText>
<sectionHeader confidence="0.996513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999834">
We would like to thank Jorge Antonio Leoni de
Leon, Mar Ndiaye, Vincenzo Pallotta and Yves
Scherrer for participating to the annotation task.
We are also grateful to Gabrielle Musillo and to
the anonymous reviewers of an earlier version of
</bodyText>
<page confidence="0.995469">
959
</page>
<bodyText confidence="0.863927">
this paper for useful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.986396" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999840106796116">
Morton Benson. 1990. Collocations and general-
purpose dictionaries. International Journal of Lexi-
cography, 3(1):23–35.
Elisabeth Breidt. 1993. Extraction of V-N-collocations
from text corpora: A feasibility study for Ger-
man. In Proceedings of the Workshop on Very
Large Corpora: Academic and Industrial Perspec-
tives, Columbus, U.S.A.
Yaacov Choueka. 1988. Looking for needles in a
haystack, or locating interesting collocational ex-
pressions in large textual databases expressions in
large textual databases. In Proceedings of the In-
ternational Conference on User-Oriented Content-
Based Text and Image Handling, pages 609–623,
Cambridge, MA.
Anthony P. Cowie. 1978. The place of illustrative ma-
terial and collocations in the design of a learner’s
dictionary. In P. Strevens, editor, In Honour of A.S.
Hornby, pages 127–139. Oxford: Oxford University
Press.
D. Alan Cruse. 1986. Lexical Semantics. Cambridge
University Press, Cambridge.
Ga¨el Dias. 2003. Multiword unit hybrid extraction.
In Proceedings of the ACL Workshop on Multiword
Expressions, pages 41–48, Sapporo, Japan.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Stefan Evert and Hannah Kermes. 2003. Experi-
ments on candidate data for collocation extraction.
In Companion Volume to the Proceedings of the 10th
Conference of The European Chapter of the Associ-
ation for Computational Linguistics, pages 83–86,
Budapest, Hungary.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations Word Pairs and
Collocations. Ph.D. thesis, University of Stuttgart.
John Rupert Firth. 1957. Papers in Linguistics 1934-
1951. Oxford Univ. Press, Oxford.
Ray Jackendoff. 1997. The Architecture of the Lan-
guage Faculty. MIT Press, Cambridge, MA.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: Some linguistis properties and an al-
gorithm for identification in text. Natural Language
Engineering, 1:9–27.
Brigitte Krenn and Stefan Evert. 2001. Can we do
better than frequency? A case study on extracting
PP-verb collocations. In Proceedings of the ACL
Workshop on Collocations, pages 39–46, Toulouse,
France.
Dekang Lin. 1998. Extracting collocations from text
corpora. In First Workshop on Computational Ter-
minology, pages 57–63, Montreal.
Christopher Manning and Heinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. MIT Press, Cambridge, Mass.
Kathleen R. McKeown and Dragomir R. Radev. 2000.
Collocations. In Robert Dale, Hermann Moisl,
and Harold Somers, editors, A Handbook of Nat-
ural Language Processing, pages 507–523. Marcel
Dekker, New York, U.S.A.
Igor Mel’ˇcuk. 1998. Collocations and lexical func-
tions. In Anthony P. Cowie, editor, Phraseology.
Theory, Analysis, and Applications, pages 23–53.
Claredon Press, Oxford.
Brigitte Orliac and Mike Dillinger. 2003. Collocation
extraction for machine translation. In Proceedings
of Machine Translation Summit IX, pages 292–298,
New Orleans, Lousiana, U.S.A.
Darren Pearce. 2001. Synonymy in collocation extrac-
tion. In WordNet and Other Lexical Resources: Ap-
plications, Extensions and Customizations (NAACL
2001 Workshop), pages 41–46, Carnegie Mellon
University, Pittsburgh.
Pavel Pecina. 2005. An extensive empirical study of
collocation extraction methods. In Proceedings of
the ACL Student Research Workshop, pages 13–18,
Ann Arbor, Michigan, June. Association for Com-
putational Linguistics.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1–15, Mexico City.
Violeta Seretan and Eric Wehrli. 2006. Multilingual
collocation extraction: Issues and solutions solu-
tions. In Proceedings or COLING/ACL Workshop
on Multilingual Language Resources and Interoper-
ability, Sydney, Australia, July. To appear.
Violeta Seretan, Luka Nerima, and Eric Wehrli. 2003.
Extraction of multi-word collocations using syn-
tactic bigram composition. In Proceedings of
the Fourth International Conference on Recent Ad-
vances in NLP (RANLP-2003), pages 424–431,
Borovets, Bulgaria.
Frank Smadja. 1993. Retrieving collocations form
text: Xtract. Computational Linguistics, 19(1):143–
177.
Eric Wehrli. 2004. Un mod`ele multilingue d’analyse
syntaxique. In A. Auchlin et al., editor, Structures
et discours - M´elanges offerts a` Eddy Roulet, pages
311–329. ´Editions Nota bene, Qu´ebec.
</reference>
<page confidence="0.997541">
960
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.401788">
<title confidence="0.998084">Accurate Collocation Extraction Using a Multilingual Parser</title>
<author confidence="0.987685">Violeta Seretan</author>
<affiliation confidence="0.999853">Language Technology Laboratory University of Geneva</affiliation>
<address confidence="0.92861">2, rue de Candolle, 1211 Geneva</address>
<email confidence="0.477713">Violeta.Seretan@latl.unige.ch</email>
<author confidence="0.999922">Eric Wehrli</author>
<affiliation confidence="0.9999475">Language Technology Laboratory University of Geneva</affiliation>
<address confidence="0.9664">2, rue de Candolle, 1211 Geneva</address>
<email confidence="0.938374">Eric.Wehrli@latl.unige.ch</email>
<abstract confidence="0.997686857142857">This paper focuses on the use of advanced techniques of text analysis as support for collocation extraction. A hybrid system is presented that combines statistical methods and multilingual parsing for detecting accurate collocational information from English, French, Spanish and Italian corpora. The advantage of relying on full parsing over using a traditional window method (which ignores the syntactic information) is first theoretically motivated, then empirically validated by a comparative evaluation experiment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Morton Benson</author>
</authors>
<title>Collocations and generalpurpose dictionaries.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="4916" citStr="Benson, 1990" startWordPosition="743" endWordPosition="744"> time, of efficient and robust parsers required for processing large corpora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the bestknown definitions are the following: “Collocations of a given word are statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has characteristics of a syntactic and semantic unit” (Choueka, 1988). Our</context>
</contexts>
<marker>Benson, 1990</marker>
<rawString>Morton Benson. 1990. Collocations and generalpurpose dictionaries. International Journal of Lexicography, 3(1):23–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Breidt</author>
</authors>
<title>Extraction of V-N-collocations from text corpora: A feasibility study for German.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<location>Columbus, U.S.A.</location>
<contexts>
<context position="29655" citStr="Breidt, 1993" startWordPosition="4693" endWordPosition="4694">asures (cf. (Evert, 2004; Pecina, 2005) for comprehensive references), but with a contrastive evaluation of syntactic-based and standard extraction methods, combined with the same statistical computation. Our study finally clear the doubts on the usefulness of parsing for collocation extraction. Previous work that quantified the influence of parsing on the quality of results suggested the performance for tagged and parsed texts is similar (Evert and Kermes, 2003). This result applies to a quite rigid syntactic pattern, namely adjective-noun in German. But a preceding study on noun-verb pairs (Breidt, 1993) came to the conclusion that good precision can only be achieved for German with parsing. Its author had to simulate parsing because of the lack, at the time, of parsing tools for German. Our report, that concerns an actual system and a large data set, validates Breidt’s finding for a new language (French). Our experimental results confirm the hypotheses put forth in section 4, and show that parsing (even if imperfect) benefits to extraction, notably by a drastic reduction of the noise in the top of the significance list. In future work, we consider investigating other levels of the significan</context>
</contexts>
<marker>Breidt, 1993</marker>
<rawString>Elisabeth Breidt. 1993. Extraction of V-N-collocations from text corpora: A feasibility study for German. In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, Columbus, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaacov Choueka</author>
</authors>
<title>Looking for needles in a haystack, or locating interesting collocational expressions in large textual databases expressions in large textual databases.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on User-Oriented ContentBased Text and Image Handling,</booktitle>
<pages>609--623</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="5511" citStr="Choueka, 1988" startWordPosition="835" endWordPosition="836">ion” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has characteristics of a syntactic and semantic unit” (Choueka, 1988). Our approach is committed to these later definitions, hence the importance we lend to using appropriate extraction methodologies, based on syntactic analysis. The hybrid method we developed relies on the parser Fips (Wehrli, 2004), that implements the Government and Binding formalism and supports several languages (besides the ones mentioned in 2“Ideally, in order to identify lexical relations in a corpus one would need to first parse it to verify that the words are used in a single phrase structure. However, in practice, freestyle texts contain a great deal of nonstandard features over whic</context>
<context position="21454" citStr="Choueka, 1988" startWordPosition="3346" endWordPosition="3347">ase for grammatical well-formedness and for lexicalization. By lexicalization we mean the quality of a pair to constitute (part of) a multi-word expression — be it compound, collocation, idiom or another type of syntagmatic lexical combination. We avoid giving collocability judgments since the classification of multi-word expressions cannot be made precisely and with objective criteria (McKeown and Radev, 2000). We rather distinguish between lexicalizable and trivial combinations (completely regular productions, such as big house, buy bread, that do not deserve a place in the lexicon). As in (Choueka, 1988) and (Evert, 2004), we consider that a dominant feature of collocations is that they are unpredictable for speakers and therefore have to be stored into a lexicon. 6To exemplify this point: the pair d´eveloppement humain (which has been detected as a collocation by the basic method) looks like a valid expression, but the source text consistently offers a different interpretation: d´eveloppement des ressources humaines. 957 Each collocation from the n-best list at the different levels considered is therefore annotated with one of the three flags: 1. ungrammatical; 2. trivial combination; 3. mul</context>
</contexts>
<marker>Choueka, 1988</marker>
<rawString>Yaacov Choueka. 1988. Looking for needles in a haystack, or locating interesting collocational expressions in large textual databases expressions in large textual databases. In Proceedings of the International Conference on User-Oriented ContentBased Text and Image Handling, pages 609–623, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony P Cowie</author>
</authors>
<title>The place of illustrative material and collocations in the design of a learner’s dictionary.</title>
<date>1978</date>
<booktitle>In Honour of A.S. Hornby,</booktitle>
<pages>127--139</pages>
<editor>In P. Strevens, editor,</editor>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<contexts>
<context position="5389" citStr="Cowie, 1978" startWordPosition="815" endWordPosition="816">statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has characteristics of a syntactic and semantic unit” (Choueka, 1988). Our approach is committed to these later definitions, hence the importance we lend to using appropriate extraction methodologies, based on syntactic analysis. The hybrid method we developed relies on the parser Fips (Wehrli, 2004), that implements the Government and Binding formalism and supports several languages (besides the ones mentioned in 2“Ideally, in order to identify lexical relations in a corpus one would need to first parse it to verify that the words are used </context>
</contexts>
<marker>Cowie, 1978</marker>
<rawString>Anthony P. Cowie. 1978. The place of illustrative material and collocations in the design of a learner’s dictionary. In P. Strevens, editor, In Honour of A.S. Hornby, pages 127–139. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Alan Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="4987" citStr="Cruse, 1986" startWordPosition="753" endWordPosition="754">ora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the bestknown definitions are the following: “Collocations of a given word are statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has characteristics of a syntactic and semantic unit” (Choueka, 1988). Our approach is committed to these later definitions, hence the importance</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. Alan Cruse. 1986. Lexical Semantics. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ga¨el Dias</author>
</authors>
<title>Multiword unit hybrid extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL Workshop on Multiword Expressions,</booktitle>
<pages>41--48</pages>
<location>Sapporo, Japan.</location>
<marker>Ga¨el Dias, 2003</marker>
<rawString>Ga¨el Dias. 2003. Multiword unit hybrid extraction. In Proceedings of the ACL Workshop on Multiword Expressions, pages 41–48, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="8180" citStr="Dunning, 1993" startWordPosition="1261" endWordPosition="1262">candidate selection is the syntactic proximity, as opposed to the linear proximity used by traditional, window-based methods. As the parsing goes on, the syntactic word pairs are extracted from the parse structures created, from each head-specifier or head-complement relation. The pairs obtained are then partitioned according to their syntactic configuration (e.g., noun + adjectival or nominal specifier, noun + argument, noun + adjective in predications, verb + adverbial specifier, verb + argument (subject, object), verb + adjunt, etc). Finally, the loglikelihood ratios test (henceforth LLR) (Dunning, 1993) is applied on each set of pairs. We call this method hybrid, since it combines syntactic and statistical information (about word and cooccurrence frequency). The following examples — which, like all the examples in this paper, are actual extraction results — demonstrate the potential of our system to detect collocation candidates, even if subject to complex syntactic transformations. 954 1.a) raise question: The question of political leadership has been raised several times by previous speakers. 1.b) play role: What role can Canada’s immigration program play in helping developing nations... ?</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Hannah Kermes</author>
</authors>
<title>Experiments on candidate data for collocation extraction.</title>
<date>2003</date>
<booktitle>In Companion Volume to the Proceedings of the 10th Conference of The European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>83--86</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="22531" citStr="Evert and Kermes, 2003" startWordPosition="3516" endWordPosition="3519">-best list at the different levels considered is therefore annotated with one of the three flags: 1. ungrammatical; 2. trivial combination; 3. multi-word expression (MWE). On the one side, we evaluate the results of our hybrid, parse-based method; on the other, we simulate a window method, by performing the following steps: POS-tag the source texts; filter the lexical items and retain only the open-class POS; consider all their combinations within a collocational window of length 5; and, finally, apply the log-likelihood ratios test on the pairs of each configuration type. In accordance with (Evert and Kermes, 2003), we consider that the comparative evaluation of collocation extraction systems should not be done at the end of the extraction process, but separately for each stage: after the candidate selection stage, for evaluating the quality (in terms of grammaticality) of candidates proposed; and after the application of collocability measures, for evaluating the measures applied. In each of these cases, different evaluation methodologies and resources are required. In our case, since we used the same measure for the second stage (the log-likelihood ratios test), we could still compare the final output</context>
<context position="29509" citStr="Evert and Kermes, 2003" startWordPosition="4668" endWordPosition="4671">rofile for the pairs tested. As for evaluation, unlike most of the existing work, we are not concerned here with comparing the performance of association measures (cf. (Evert, 2004; Pecina, 2005) for comprehensive references), but with a contrastive evaluation of syntactic-based and standard extraction methods, combined with the same statistical computation. Our study finally clear the doubts on the usefulness of parsing for collocation extraction. Previous work that quantified the influence of parsing on the quality of results suggested the performance for tagged and parsed texts is similar (Evert and Kermes, 2003). This result applies to a quite rigid syntactic pattern, namely adjective-noun in German. But a preceding study on noun-verb pairs (Breidt, 1993) came to the conclusion that good precision can only be achieved for German with parsing. Its author had to simulate parsing because of the lack, at the time, of parsing tools for German. Our report, that concerns an actual system and a large data set, validates Breidt’s finding for a new language (French). Our experimental results confirm the hypotheses put forth in section 4, and show that parsing (even if imperfect) benefits to extraction, notably</context>
</contexts>
<marker>Evert, Kermes, 2003</marker>
<rawString>Stefan Evert and Hannah Kermes. 2003. Experiments on candidate data for collocation extraction. In Companion Volume to the Proceedings of the 10th Conference of The European Chapter of the Association for Computational Linguistics, pages 83–86, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations Word Pairs and Collocations.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="7133" citStr="Evert, 2004" startWordPosition="1099" endWordPosition="1100">ithout intermediate level), in which to the lexical head is attached a list of left constituents (its specifiers) and right constituents (its complements), and each of these are in turn represented by the same type of structure, recursively. Generally speaking, a collocation extraction can be seen as a two-stage process: I. in stage one, collocation candidates are identified from the text corpora, based on criteria which are specific to each system; II. in stage two, the candidates are scored and ranked using specific association measures (a review can be found in (Manning and Sch¨utze, 1999; Evert, 2004; Pecina, 2005)). According to this description, in our approach the parser is used in the first stage of extraction, for identifying the collocation candidates. A pair of lexical items is selected as a candidate only if there is a syntactic relation holding between the two items (one being the head of the current parse structure, and the other the lexical head of its specifier/complement). Therefore, the criterion we employ for candidate selection is the syntactic proximity, as opposed to the linear proximity used by traditional, window-based methods. As the parsing goes on, the syntactic wor</context>
<context position="21472" citStr="Evert, 2004" startWordPosition="3349" endWordPosition="3350">well-formedness and for lexicalization. By lexicalization we mean the quality of a pair to constitute (part of) a multi-word expression — be it compound, collocation, idiom or another type of syntagmatic lexical combination. We avoid giving collocability judgments since the classification of multi-word expressions cannot be made precisely and with objective criteria (McKeown and Radev, 2000). We rather distinguish between lexicalizable and trivial combinations (completely regular productions, such as big house, buy bread, that do not deserve a place in the lexicon). As in (Choueka, 1988) and (Evert, 2004), we consider that a dominant feature of collocations is that they are unpredictable for speakers and therefore have to be stored into a lexicon. 6To exemplify this point: the pair d´eveloppement humain (which has been detected as a collocation by the basic method) looks like a valid expression, but the source text consistently offers a different interpretation: d´eveloppement des ressources humaines. 957 Each collocation from the n-best list at the different levels considered is therefore annotated with one of the three flags: 1. ungrammatical; 2. trivial combination; 3. multi-word expression</context>
<context position="29066" citStr="Evert, 2004" startWordPosition="4605" endWordPosition="4606">ther than complete parsing; specific syntactic configurations (such as adjective-noun, preposition-noun-verb); and languages other than the ones we deal with (usually, English and German). Parsing has been also used after extraction (Smadja, 1993) for filtering out invalid results. We believe that this is not enough and that parsing is required prior to the application of statistical tests, for computing a realistic frequency profile for the pairs tested. As for evaluation, unlike most of the existing work, we are not concerned here with comparing the performance of association measures (cf. (Evert, 2004; Pecina, 2005) for comprehensive references), but with a contrastive evaluation of syntactic-based and standard extraction methods, combined with the same statistical computation. Our study finally clear the doubts on the usefulness of parsing for collocation extraction. Previous work that quantified the influence of parsing on the quality of results suggested the performance for tagged and parsed texts is similar (Evert and Kermes, 2003). This result applies to a quite rigid syntactic pattern, namely adjective-noun in German. But a preceding study on noun-verb pairs (Breidt, 1993) came to th</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. The Statistics of Word Cooccurrences: Word Pairs and Collocations Word Pairs and Collocations. Ph.D. thesis, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Rupert Firth</author>
</authors>
<title>Papers in Linguistics 1934-1951.</title>
<date>1957</date>
<publisher>Univ. Press,</publisher>
<location>Oxford</location>
<contexts>
<context position="4851" citStr="Firth, 1957" startWordPosition="734" endWordPosition="735">ditional systems simply ignored it because of the lack, at that time, of efficient and robust parsers required for processing large corpora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the bestknown definitions are the following: “Collocations of a given word are statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has chara</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John Rupert Firth. 1957. Papers in Linguistics 1934-1951. Oxford Univ. Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The Architecture of the Language Faculty.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1316" citStr="Jackendoff (1997)" startWordPosition="181" endWordPosition="182">which ignores the syntactic information) is first theoretically motivated, then empirically validated by a comparative evaluation experiment. 1 Introduction Recent computational linguistics research fully acknowledged the stringent need for a systematic and appropriate treatment of phraseological units in natural language processing applications (Sag et al., 2002). Syntagmatic relations between words — also called multi-word expressions, or “idiosyncratic interpretations that cross word boundaries” (Sag et al., 2002, 2) — constitute an important part of the lexicon of a language: according to Jackendoff (1997), they are at least as numerous as the single words, while according to Mel’ˇcuk (1998) they outnumber single words ten to one. Phraseological units include a wide range of phenomena, among which we mention compound nouns (dead end), phrasal verbs (ask out), idioms (lend somebody a hand), and collocations (fierce battle, daunting task, schedule a meeting). They pose important problems for NLP applications, both text analysis and text production perspectives being concerned. In particular, collocations1 are highly problematic, for at least two reasons: first, because their linguistic status and</context>
</contexts>
<marker>Jackendoff, 1997</marker>
<rawString>Ray Jackendoff. 1997. The Architecture of the Language Faculty. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: Some linguistis properties and an algorithm for identification in text. Natural Language Engineering,</title>
<date>1995</date>
<contexts>
<context position="4104" citStr="Justeson and Katz, 1995" startWordPosition="610" endWordPosition="613">l combinations. 953 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 953–960, Sydney, July 2006. c�2006 Association for Computational Linguistics As a matter of fact, some of the existing collocation extraction systems already employ (but only to a limited extent) linguistic tools in order to support the collocation identification in text corpora. For instance, lemmatizers are often used for recognizing all the inflected forms of a lexical item, and POS taggers are used for ruling out certain categories of words, e.g., in (Justeson and Katz, 1995). Syntactic analysis has long since been recognized as a prerequisite for collocation extraction (for instance, by Smadja2), but the traditional systems simply ignored it because of the lack, at that time, of efficient and robust parsers required for processing large corpora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the be</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: Some linguistis properties and an algorithm for identification in text. Natural Language Engineering, 1:9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting PP-verb collocations.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations,</booktitle>
<pages>39--46</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="4562" citStr="Krenn and Evert, 2001" startWordPosition="683" endWordPosition="687">d for recognizing all the inflected forms of a lexical item, and POS taggers are used for ruling out certain categories of words, e.g., in (Justeson and Katz, 1995). Syntactic analysis has long since been recognized as a prerequisite for collocation extraction (for instance, by Smadja2), but the traditional systems simply ignored it because of the lack, at that time, of efficient and robust parsers required for processing large corpora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the bestknown definitions are the following: “Collocations of a given word are statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the examples they provide. On t</context>
<context position="23292" citStr="Krenn and Evert (2001)" startWordPosition="3639" endWordPosition="3642">t separately for each stage: after the candidate selection stage, for evaluating the quality (in terms of grammaticality) of candidates proposed; and after the application of collocability measures, for evaluating the measures applied. In each of these cases, different evaluation methodologies and resources are required. In our case, since we used the same measure for the second stage (the log-likelihood ratios test), we could still compare the final output of basic and parse-based methods, as given by the combination of the first stage with the same collocability measure. Again, similarly to Krenn and Evert (2001), we believe that the homogeneity of data is important for the collocability measures. We therefore applied the LLR test on our data after first partitioning it into separate sets, according to the syntactical relation holding in each candidate pair. As the data used in the basic method contains no syntactic information, the partitioning was done based on POS-combination type. 5.2 The Data The evaluation experiment was performed on the whole French corpus used in the extraction experiment (section 2), that is, a subpart of the Hansard corpus of Canadian Parliament proceedings. It contains 112 </context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb collocations. In Proceedings of the ACL Workshop on Collocations, pages 39–46, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Extracting collocations from text corpora.</title>
<date>1998</date>
<booktitle>In First Workshop on Computational Terminology,</booktitle>
<pages>57--63</pages>
<location>Montreal.</location>
<contexts>
<context position="4538" citStr="Lin, 1998" startWordPosition="681" endWordPosition="682">e often used for recognizing all the inflected forms of a lexical item, and POS taggers are used for ruling out certain categories of words, e.g., in (Justeson and Katz, 1995). Syntactic analysis has long since been recognized as a prerequisite for collocation extraction (for instance, by Smadja2), but the traditional systems simply ignored it because of the lack, at that time, of efficient and robust parsers required for processing large corpora. Oddly enough, this situation is nowadays perpetuated, in spite of the dramatic advances in parsing technology. Only a few exceptions exists, e.g., (Lin, 1998; Krenn and Evert, 2001). One possible reason for this might be the way that collocations are generally understood, as a purely statistical phenomenon. Some of the bestknown definitions are the following: “Collocations of a given word are statements of the habitual and customary places of that word” (Firth, 1957, 181); “arbitrary and recurrent word combination” (Benson, 1990); or “sequences of lexical items that habitually co-occur” (Cruse, 1986, 40). Most of the authors make no claims with respect to the grammatical status of the collocation, although this can indirectly inferred from the exa</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Extracting collocations from text corpora. In First Workshop on Computational Terminology, pages 57–63, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Heinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher Manning and Heinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Dragomir R Radev</author>
</authors>
<date>2000</date>
<booktitle>A Handbook of Natural Language Processing,</booktitle>
<pages>507--523</pages>
<editor>Collocations. In Robert Dale, Hermann Moisl, and Harold Somers, editors,</editor>
<publisher>Marcel Dekker,</publisher>
<location>New York, U.S.A.</location>
<contexts>
<context position="1983" citStr="McKeown and Radev (2000)" startWordPosition="281" endWordPosition="284">le words, while according to Mel’ˇcuk (1998) they outnumber single words ten to one. Phraseological units include a wide range of phenomena, among which we mention compound nouns (dead end), phrasal verbs (ask out), idioms (lend somebody a hand), and collocations (fierce battle, daunting task, schedule a meeting). They pose important problems for NLP applications, both text analysis and text production perspectives being concerned. In particular, collocations1 are highly problematic, for at least two reasons: first, because their linguistic status and properties are unclear (as pointed out by McKeown and Radev (2000), their definition is rather vague, and the distinction from other types of expressions is not clearly drawn); second, because they are prevalent in language. Mel’ˇcuk (1998, 24) claims that “collocations make up the lions share of the phraseme inventory”, and a recent study referred in (Pearce, 2001) showed that each sentence is likely to contain at least one collocation. Collocational information is not only useful, but also indispensable in many applications. In machine translation, for instance, it is considered “the key to producing more acceptable output” (Orliac and Dillinger, 2003, 292</context>
<context position="21254" citStr="McKeown and Radev, 2000" startWordPosition="3313" endWordPosition="3316">heir precision with respect to grammaticality and collocability. 5.1 The Method The n-best extraction results, for a given n (in our experiment, n varies from 50 to 500 at intervals of 50) are checked in each case for grammatical well-formedness and for lexicalization. By lexicalization we mean the quality of a pair to constitute (part of) a multi-word expression — be it compound, collocation, idiom or another type of syntagmatic lexical combination. We avoid giving collocability judgments since the classification of multi-word expressions cannot be made precisely and with objective criteria (McKeown and Radev, 2000). We rather distinguish between lexicalizable and trivial combinations (completely regular productions, such as big house, buy bread, that do not deserve a place in the lexicon). As in (Choueka, 1988) and (Evert, 2004), we consider that a dominant feature of collocations is that they are unpredictable for speakers and therefore have to be stored into a lexicon. 6To exemplify this point: the pair d´eveloppement humain (which has been detected as a collocation by the basic method) looks like a valid expression, but the source text consistently offers a different interpretation: d´eveloppement de</context>
</contexts>
<marker>McKeown, Radev, 2000</marker>
<rawString>Kathleen R. McKeown and Dragomir R. Radev. 2000. Collocations. In Robert Dale, Hermann Moisl, and Harold Somers, editors, A Handbook of Natural Language Processing, pages 507–523. Marcel Dekker, New York, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Collocations and lexical functions.</title>
<date>1998</date>
<booktitle>Phraseology. Theory, Analysis, and Applications,</booktitle>
<pages>23--53</pages>
<editor>In Anthony P. Cowie, editor,</editor>
<publisher>Claredon Press,</publisher>
<location>Oxford.</location>
<marker>Mel’ˇcuk, 1998</marker>
<rawString>Igor Mel’ˇcuk. 1998. Collocations and lexical functions. In Anthony P. Cowie, editor, Phraseology. Theory, Analysis, and Applications, pages 23–53. Claredon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Orliac</author>
<author>Mike Dillinger</author>
</authors>
<title>Collocation extraction for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of Machine Translation Summit IX,</booktitle>
<pages>292--298</pages>
<location>New Orleans, Lousiana, U.S.A.</location>
<contexts>
<context position="2578" citStr="Orliac and Dillinger, 2003" startWordPosition="372" endWordPosition="375">out by McKeown and Radev (2000), their definition is rather vague, and the distinction from other types of expressions is not clearly drawn); second, because they are prevalent in language. Mel’ˇcuk (1998, 24) claims that “collocations make up the lions share of the phraseme inventory”, and a recent study referred in (Pearce, 2001) showed that each sentence is likely to contain at least one collocation. Collocational information is not only useful, but also indispensable in many applications. In machine translation, for instance, it is considered “the key to producing more acceptable output” (Orliac and Dillinger, 2003, 292). This article presents a system that extracts accurate collocational information from corpora by using a syntactic parser that supports several languages. After describing the underlying methodology (section 2), we report several extraction results for English, French, Spanish and Italian (section 3). Then we present in sections 4 and 5 a comparative evaluation experiment proving that a hybrid approach leads to more accurate results than a classical approach in which syntactic information is not taken into account. 2 Hybrid Collocation Extraction We consider that syntactic analysis of s</context>
</contexts>
<marker>Orliac, Dillinger, 2003</marker>
<rawString>Brigitte Orliac and Mike Dillinger. 2003. Collocation extraction for machine translation. In Proceedings of Machine Translation Summit IX, pages 292–298, New Orleans, Lousiana, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In WordNet and Other Lexical Resources: Applications, Extensions and Customizations (NAACL 2001 Workshop),</booktitle>
<pages>41--46</pages>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh.</location>
<contexts>
<context position="2285" citStr="Pearce, 2001" startWordPosition="330" endWordPosition="331">). They pose important problems for NLP applications, both text analysis and text production perspectives being concerned. In particular, collocations1 are highly problematic, for at least two reasons: first, because their linguistic status and properties are unclear (as pointed out by McKeown and Radev (2000), their definition is rather vague, and the distinction from other types of expressions is not clearly drawn); second, because they are prevalent in language. Mel’ˇcuk (1998, 24) claims that “collocations make up the lions share of the phraseme inventory”, and a recent study referred in (Pearce, 2001) showed that each sentence is likely to contain at least one collocation. Collocational information is not only useful, but also indispensable in many applications. In machine translation, for instance, it is considered “the key to producing more acceptable output” (Orliac and Dillinger, 2003, 292). This article presents a system that extracts accurate collocational information from corpora by using a syntactic parser that supports several languages. After describing the underlying methodology (section 2), we report several extraction results for English, French, Spanish and Italian (section 3</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>Darren Pearce. 2001. Synonymy in collocation extraction. In WordNet and Other Lexical Resources: Applications, Extensions and Customizations (NAACL 2001 Workshop), pages 41–46, Carnegie Mellon University, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>An extensive empirical study of collocation extraction methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Student Research Workshop,</booktitle>
<pages>13--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="7148" citStr="Pecina, 2005" startWordPosition="1101" endWordPosition="1102">ediate level), in which to the lexical head is attached a list of left constituents (its specifiers) and right constituents (its complements), and each of these are in turn represented by the same type of structure, recursively. Generally speaking, a collocation extraction can be seen as a two-stage process: I. in stage one, collocation candidates are identified from the text corpora, based on criteria which are specific to each system; II. in stage two, the candidates are scored and ranked using specific association measures (a review can be found in (Manning and Sch¨utze, 1999; Evert, 2004; Pecina, 2005)). According to this description, in our approach the parser is used in the first stage of extraction, for identifying the collocation candidates. A pair of lexical items is selected as a candidate only if there is a syntactic relation holding between the two items (one being the head of the current parse structure, and the other the lexical head of its specifier/complement). Therefore, the criterion we employ for candidate selection is the syntactic proximity, as opposed to the linear proximity used by traditional, window-based methods. As the parsing goes on, the syntactic word pairs are ext</context>
<context position="29081" citStr="Pecina, 2005" startWordPosition="4607" endWordPosition="4608">plete parsing; specific syntactic configurations (such as adjective-noun, preposition-noun-verb); and languages other than the ones we deal with (usually, English and German). Parsing has been also used after extraction (Smadja, 1993) for filtering out invalid results. We believe that this is not enough and that parsing is required prior to the application of statistical tests, for computing a realistic frequency profile for the pairs tested. As for evaluation, unlike most of the existing work, we are not concerned here with comparing the performance of association measures (cf. (Evert, 2004; Pecina, 2005) for comprehensive references), but with a contrastive evaluation of syntactic-based and standard extraction methods, combined with the same statistical computation. Our study finally clear the doubts on the usefulness of parsing for collocation extraction. Previous work that quantified the influence of parsing on the quality of results suggested the performance for tagged and parsed texts is similar (Evert and Kermes, 2003). This result applies to a quite rigid syntactic pattern, namely adjective-noun in German. But a preceding study on noun-verb pairs (Breidt, 1993) came to the conclusion th</context>
</contexts>
<marker>Pecina, 2005</marker>
<rawString>Pavel Pecina. 2005. An extensive empirical study of collocation extraction methods. In Proceedings of the ACL Student Research Workshop, pages 13–18, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING</booktitle>
<pages>1--15</pages>
<location>Mexico City.</location>
<contexts>
<context position="1065" citStr="Sag et al., 2002" startWordPosition="139" endWordPosition="142"> presented that combines statistical methods and multilingual parsing for detecting accurate collocational information from English, French, Spanish and Italian corpora. The advantage of relying on full parsing over using a traditional window method (which ignores the syntactic information) is first theoretically motivated, then empirically validated by a comparative evaluation experiment. 1 Introduction Recent computational linguistics research fully acknowledged the stringent need for a systematic and appropriate treatment of phraseological units in natural language processing applications (Sag et al., 2002). Syntagmatic relations between words — also called multi-word expressions, or “idiosyncratic interpretations that cross word boundaries” (Sag et al., 2002, 2) — constitute an important part of the lexicon of a language: according to Jackendoff (1997), they are at least as numerous as the single words, while according to Mel’ˇcuk (1998) they outnumber single words ten to one. Phraseological units include a wide range of phenomena, among which we mention compound nouns (dead end), phrasal verbs (ask out), idioms (lend somebody a hand), and collocations (fierce battle, daunting task, schedule a </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2002), pages 1–15, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Eric Wehrli</author>
</authors>
<title>Multilingual collocation extraction: Issues and solutions solutions.</title>
<date>2006</date>
<booktitle>In Proceedings or COLING/ACL Workshop on Multilingual Language Resources and Interoperability,</booktitle>
<location>Sydney, Australia,</location>
<note>To appear.</note>
<contexts>
<context position="10313" citStr="Seretan and Wehrli, 2006" startWordPosition="1595" endWordPosition="1598">e LLR score could be computed4. Statistics English French Spanish Italian tokens 3509704 1649914 1023249 287804 sentences 197401 70342 67502 12008 compl. parse 139498 50458 13245 4511 avg. length 17.78 23.46 15.16 23.97 pairs 725025 370932 162802 58258 (extracted) 276670 147293 56717 37914 pairs 633345 308410 128679 47771 (scored) 251046 131384 49495 30586 Table 1: Extraction statistics In Table 2 we list the top collocations (of length two) extracted for each language. We do not specifically discuss here multilingual issues in collocation extraction; these are dealt with in a separate paper (Seretan and Wehrli, 2006). 3The low rate of completely parsed sentences for Spanish and Italian are due to the relatively reduced coverage of the parsers of these two languages (under development). However, even if a sentence is not assigned a complete parse tree, some syntactic pairs can still be collected from the partial parses. 4The log-likelihood ratios score is undefined for those pairs having a cell of the contingency table equal to 0. Language Key1 Key2 LLR score English federal government 7229.69 reform party 6530.69 house common 6006.84 minister finance 5829.05 acting speaker 5551.09 red book 5292.63 create </context>
</contexts>
<marker>Seretan, Wehrli, 2006</marker>
<rawString>Violeta Seretan and Eric Wehrli. 2006. Multilingual collocation extraction: Issues and solutions solutions. In Proceedings or COLING/ACL Workshop on Multilingual Language Resources and Interoperability, Sydney, Australia, July. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Luka Nerima</author>
<author>Eric Wehrli</author>
</authors>
<title>Extraction of multi-word collocations using syntactic bigram composition.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fourth International Conference on Recent Advances in NLP (RANLP-2003),</booktitle>
<pages>424--431</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="11966" citStr="Seretan et al., 2003" startWordPosition="1825" endWordPosition="1828">bre comercio 2169.02 nuevo peso 1322.06 tasa inter´es 1179.62 deuda externo 1119.91 c´amara representante 1015.07 asamblea ordinario 992.85 papel comercial 963.95 Italian consiglio federale 3513.19 scrivere consiglio 594.54 unione europeo 479.73 servizio pubblico 452.92 milione franco 447.63 formazione continuo 388.80 iniziativa popolare 383.68 testo interpellanza 377.46 punto vista 373.24 scrivere risposta 348.77 Table 2: Top ten collocations extracted for each language The collocation pairs obtained were further processed with a procedure of long collocations extraction described elsewhere (Seretan et al., 2003). Some examples of collocations of length 3, 4 and 5 obtained are: minister of Canadian heritage, house proceed to statement by, secretary to leader of gouvernment in house of common (En), question adresser a` ministre, programme de aide a` r´enovation r´esidentielle, agent employer force susceptible causer (Fr), bolsa de comercio local, peso en cuota de fondo de inversi´on, permitir uso de papel de deuda esterno (Sp), consiglio federale disporre, creazione di nuovo posto di lavoro, costituire fattore penalizzante per regione (It)5. 5Note that the output of the procedure contains lemmas rather</context>
</contexts>
<marker>Seretan, Nerima, Wehrli, 2003</marker>
<rawString>Violeta Seretan, Luka Nerima, and Eric Wehrli. 2003. Extraction of multi-word collocations using syntactic bigram composition. In Proceedings of the Fourth International Conference on Recent Advances in NLP (RANLP-2003), pages 424–431, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations form text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>177</pages>
<contexts>
<context position="6265" citStr="Smadja, 1993" startWordPosition="956" endWordPosition="957">yntactic analysis. The hybrid method we developed relies on the parser Fips (Wehrli, 2004), that implements the Government and Binding formalism and supports several languages (besides the ones mentioned in 2“Ideally, in order to identify lexical relations in a corpus one would need to first parse it to verify that the words are used in a single phrase structure. However, in practice, freestyle texts contain a great deal of nonstandard features over which automatic parsers would fail. This fact is being seriously challenged by current research (...), and might not be true in the near future” (Smadja, 1993, 151). the abstract, a few other are also partly dealt with). We will not present details about the parser here; what is relevant for this paper is the type of syntactic structures it uses. Each constituent is represented by a simplified X-bar structure (without intermediate level), in which to the lexical head is attached a list of left constituents (its specifiers) and right constituents (its complements), and each of these are in turn represented by the same type of structure, recursively. Generally speaking, a collocation extraction can be seen as a two-stage process: I. in stage one, col</context>
<context position="28702" citStr="Smadja, 1993" startWordPosition="4544" endWordPosition="4545">al arguments in the favor of performing syntactic analysis of texts prior to the extraction of collocations with statistical methods. 7A closer look at the data revealed that this might be explained by some inconsistencies between annotations. Part of the extraction work that, like ours, relies on parsing was cited in section 2. Most often, it concerns chunking rather than complete parsing; specific syntactic configurations (such as adjective-noun, preposition-noun-verb); and languages other than the ones we deal with (usually, English and German). Parsing has been also used after extraction (Smadja, 1993) for filtering out invalid results. We believe that this is not enough and that parsing is required prior to the application of statistical tests, for computing a realistic frequency profile for the pairs tested. As for evaluation, unlike most of the existing work, we are not concerned here with comparing the performance of association measures (cf. (Evert, 2004; Pecina, 2005) for comprehensive references), but with a contrastive evaluation of syntactic-based and standard extraction methods, combined with the same statistical computation. Our study finally clear the doubts on the usefulness of</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations form text: Xtract. Computational Linguistics, 19(1):143– 177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Un mod`ele multilingue d’analyse syntaxique.</title>
<date>2004</date>
<booktitle>Structures et discours - M´elanges offerts a` Eddy Roulet,</booktitle>
<pages>311--329</pages>
<editor>In A. Auchlin et al., editor,</editor>
<location>Qu´ebec.</location>
<contexts>
<context position="5743" citStr="Wehrli, 2004" startWordPosition="870" endWordPosition="871"> the examples they provide. On the contrary, other definitions state explicitly that a collocation is an expression of language: “co-occurrence of two or more lexical items as realizations of structural elements within a given syntactic pattern” (Cowie, 1978); “a sequence of two or more consecutive words, that has characteristics of a syntactic and semantic unit” (Choueka, 1988). Our approach is committed to these later definitions, hence the importance we lend to using appropriate extraction methodologies, based on syntactic analysis. The hybrid method we developed relies on the parser Fips (Wehrli, 2004), that implements the Government and Binding formalism and supports several languages (besides the ones mentioned in 2“Ideally, in order to identify lexical relations in a corpus one would need to first parse it to verify that the words are used in a single phrase structure. However, in practice, freestyle texts contain a great deal of nonstandard features over which automatic parsers would fail. This fact is being seriously challenged by current research (...), and might not be true in the near future” (Smadja, 1993, 151). the abstract, a few other are also partly dealt with). We will not pre</context>
</contexts>
<marker>Wehrli, 2004</marker>
<rawString>Eric Wehrli. 2004. Un mod`ele multilingue d’analyse syntaxique. In A. Auchlin et al., editor, Structures et discours - M´elanges offerts a` Eddy Roulet, pages 311–329. ´Editions Nota bene, Qu´ebec.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>