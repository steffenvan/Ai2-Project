<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001714">
<title confidence="0.98457">
Disambiguating Temporal–Contrastive Discourse Connectives for Machine
Translation
</title>
<author confidence="0.990191">
Thomas Meyer
</author>
<affiliation confidence="0.983876">
Idiap Research Institute / Martigny, Switzerland
</affiliation>
<address confidence="0.692346">
EPFL - EDEE doctoral school / Lausanne, Switzerland
</address>
<email confidence="0.990454">
Thomas.Meyer@idiap.ch
</email>
<sectionHeader confidence="0.995508" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997916666666667">
Temporal–contrastive discourse connectives
(although, while, since, etc.) signal various
types of relations between clauses such as tem-
poral, contrast, concession and cause. They
are often ambiguous and therefore difficult to
translate from one language to another. We
discuss several new and translation-oriented
experiments for the disambiguation of a spe-
cific subset of discourse connectives in order
to correct some of the translation errors made
by current statistical machine translation sys-
tems.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999898263157895">
The probabilistic phrase-based models used in sta-
tistical machine translation (SMT) have been im-
proved by integrating linguistic information during
training stages. Recent attempts include, for exam-
ple, the reordering of the source language syntax in
order to align it closer to the target language word
order (Collins et al., 2010) or the tagging of pro-
nouns for grammatical gender agreement (Le Na-
gard and Koehn, 2010). On the other hand, inte-
grating discourse information, such as discourse re-
lations holding between two spans of text or between
sentences, has not yet been applied to SMT.
This paper describes several disambiguation and
translation experiments for a specific subset of dis-
course connectives. Based on examinations in mul-
tilingual corpora, we identified the connectives al-
though, but, however, meanwhile, since, though,
when and while as being particularly problematic for
machine translation. These discourse connectives
</bodyText>
<page confidence="0.989759">
46
</page>
<bodyText confidence="0.999969705882353">
signal various types of relations between clauses,
such as temporal, contrast, concession, expansion,
cause and condition, which are, as we also show,
hard to annotate even by humans. Disambiguating
these senses and tagging them in large corpora is
hypothesized to help in improving SMT systems to
avoid translation errors.
The paper is organized as follows. Section 2
exemplifies translation and human annotation dif-
ficulties. Resources and the state of the art for
discourse connective disambiguation and parsing
are described in Section 3. Section 4 summarizes
our experiments for disambiguating the senses of
temporal–contrastive connectives. The impact of
connective disambiguation on SMT is briefly pre-
sented in Section 5. Section 6 concludes the paper
with an outline of future work.
</bodyText>
<sectionHeader confidence="0.984736" genericHeader="method">
2 Translating Connectives
</sectionHeader>
<bodyText confidence="0.9998268">
Discourse connectives can signal multiple
senses (Miltsakaki et al., 2005). For instance,
the connective since can have a temporal and causal
meaning. The disambiguation of these senses is
crucial to the correct translation of texts from one
language to another. Translation can be difficult
because there may be no direct lexical correspon-
dence for the explicit source language connective
in the target language, as shown by the reference
translation of the first example in Table 1, taken
from the Europarl corpus (Koehn, 2005).
More often, the incorrect rendering of the sense of
a connective can lead to wrong translations, as in the
second, third and fourth example in Table 1, which
were translated by the Moses SMT decoder (Koehn
</bodyText>
<note confidence="0.382598">
Proceedings of the ACL-HLT 2011 Student Session, pages 46–51,
</note>
<table confidence="0.788644407407407">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
EN So what we want the European Patent Office to do
FR is something on behalf of the European Commission
[while] temporal the Office itself is not a Community insti-
tution.
Aussi, ce que nous souhaitons, c’est que l’Office europeen
des brevets agisse au nom de la Commission europeenne
[tout en n’etant] temporal pas une institution communau-
taire.
EN Finally, and in conclusion, Mr President, with the expiry of
FR the ECSC Treaty, the regulations will have to be reviewed
[since] causal I think that the aid system will have to con-
tinue beyond 2002...
*Enfin, et en conclusion, Monsieur le president, a`
l’expiration du traitececa, la reglementation devra ˆetre revu
[depuis que] temporal je pense que le syst`eme d’aides de-
vront continuer au-del`a de 2002...
EN Between 1998 and 1999, loyalists assaulted and shot 123
FR people, [while] contrast republicans assaulted and shot 93
people.
Entre 1998 et 1999, les loyalistes ont attaqueet abattu 123
personnes, [ ] 93 pour les republicains.
EN He said Akzo is considering alliances with American drug
DE companies, [although] contrast he wouldn’t elaborate.
*Er sagte Akzo erw¨agt Allianzen mit amerikanischen Phar-
makonzerne, [obwohl] concession er m¨ochte nicht n¨aher
eingehen.
</table>
<tableCaption confidence="0.978691285714286">
Table 1: Translation examples from Europarl and the
PDTB. The discourse connectives, their translations, and
their senses are indicated in bold. The first example is a
reference translation from EN into FR, while the second,
third and fourth example are wrong translations gener-
ated by MT (EN–FR and EN–DE), hence marked with
an asterisk.
</tableCaption>
<bodyText confidence="0.999881571428571">
et al., 2007) trained on the Europarl EN–FR and re-
spectively EN–DE subcorpora. The reference trans-
lation for the second example uses the French con-
nective car with a correct causal sense, instead of
the wrong depuis que generated by SMT, which ex-
presses a temporal relation. In the third example,
the SMT system failed to translate the English con-
nective while to French. The French translation is
therefore not coherent, the contrastive discourse in-
formation cannot be established without an explicit
connective. The last example in Table 1 is a sen-
tence from the Penn Discourse Treebank (Prasad et
al., 2008), see Section 3. In its German translation,
it would be correct to use the connective auch wenn
(for contrast) instead of obwohl (for concession).
These examples illustrate the difficulties in trans-
lating discourse connectives, even when they are
lexically explicit. Our hypothesis is, that the auto-
matic annotation of the senses prior to translation
can help finding more often the correct lexical cor-
respondences of a connective (see Section 5 for one
</bodyText>
<table confidence="0.997881875">
while (489) Translation EN-FR
56% T tout en V-gerund (22%), tant que (22%),
tandis que (11%)
30% CT tandis que (56%), alors que (40%)
14% CO mˆeme si (100%)
although (347) Translation EN-DE
76.7% CO obwohl (74%), zwar (9%), auch wenn (9%)
23.3% CT obgleich (43%), obwohl (29%)
</table>
<tableCaption confidence="0.5778504">
Table 2: The English connectives while and although in
the Europarl corpus (sections numbered 199x, EN-FR
and EN-DE) with token frequency, sense distribution and
most frequent translations ordered by the corresponding
senses (T = temporal, CO = concession, CT = contrast).
</tableCaption>
<bodyText confidence="0.999231970588235">
of the methods to achieve this).
When examining the frequency and sense distri-
bution of these connectives and their translations in
the Europarl corpus, the results confirm that at least
such a fine-grained disambiguation as the one be-
tween contrast and concession is necessary for a cor-
rect translation. Table 2 shows cases where the dif-
ferent senses of the connectives while and although
lead to different translations. Disambiguation of the
senses here can help finding the correct lexical cor-
respondence of the connective.
To confirm that the automatic translation of dis-
course connectives is not straightforward, we anno-
tated 80 sentences from the Europarl corpus con-
taining the connective while with the correspond-
ing sense (T, CO or CT) and another 60 sentences
containing the French connective alors que (T or
CT). We then translated these sentences with the al-
ready mentioned EN–FR and FR–EN Moses SMT
system and compared the output manually to the ref-
erence translations from the corpus. The overall sys-
tem performance was 61% of correct translations for
sentences with while and 55% of correct translations
with alors que. As mistakes we either counted miss-
ing target connective words (only when the output
sentence became incoherent) or wrong connective
words because of failure in correct sense rendering.
Also, the manual sense annotation task is not triv-
ial. In a manual annotation experiment, the senses of
the connective while (T, CO and CT) were indicated
in 30 sentences by 4 annotators. The overall agree-
ment on the senses was not higher than a kappa value
of 0.6, which is acceptable but would need improve-
ment in order to produce a reliable resource.
</bodyText>
<page confidence="0.998694">
47
</page>
<sectionHeader confidence="0.963271" genericHeader="method">
3 Data and Related Work
</sectionHeader>
<bodyText confidence="0.999993948275862">
One of the few available discourse annotated cor-
pora in English is the Penn Discourse Treebank
(PDTB) (Prasad et al., 2008). For this resource, one
hundred types of explicit connectives were manually
annotated, as well as implicit relations not signaled
by a connective.
For French, the ANNODIS project for anno-
tation of discourse (Pery-Woodley et al., 2009)
will provide an original, discourse-annotated cor-
pus. Resources for Czech are also becoming avail-
able (Zikanova et al., 2010). For German, a lexi-
con of discourse connectives exists since the 1990s,
namely DiMLex for lexicon of discourse markers
(Stede and Umbach, 1998). An equivalent, more re-
cent database for French is LexConn for lexicon of
connectives (Roze et al., 2010) – containing a list
of 328 explicit connectives. For each of them, Lex-
Conn indicates and exemplifies the possible senses,
chosen from a list of 30 labels inspired from Rhetor-
ical Structure Theory (Mann and Thompson, 1988).
For the first classification experiments in Sec-
tion 4, we concentrated on English and the explicit
connectives in the PDTB data. The sense hierarchy
used in the PDTB consists of three levels, reach-
ing from four top level senses (Temporal, Contin-
gency, Comparison and Expansion) via 16 subsenses
on the second level to 23 further subsenses on the
third level. As the annotators were allowed to as-
sign one or two senses for each connective there
are 129 possible simple or complex senses for more
than 18,000 explicit connectives. The PDTB fur-
ther sees connectives as discourse-level predicates
that have two propositional arguments. Argument 2
is the one containing the explicit connective. The
sentence from the first example in Table 1 can be
represented as while(So what we...[argument 1], the
Office itself...[argument 2]), which is very helpful to
examine the context of a connective (see Section 4.1
on features).
The release of the PDTB had quite an impact on
disambiguation experiments. The state of the art for
recognizing explicit connectives in English is there-
fore already high, at a level of 94% for disambiguat-
ing the four main senses on the first level of the
PDTB sense hierarchy (Pitler and Nenkova, 2009).
However, when using all 100 types of connectives
and the whole PDTB training set, it is not so dif-
ficult to achieve such a high score, because of the
large amount of instances and the rather broad dis-
tinction of the four main classes only. As we show
in the next section, when building separate classi-
fiers for specific connectives with senses from the
more detailed second hierarchy level of the PDTB, it
is more difficult to reach high accuracies. Recently,
Lin et al. (2010) built the first end-to-end PDTB dis-
course parser, which is able to parse unrestricted text
with an F1 score of 38.18% on PDTB test data and
for senses on the second hierarchy level.
</bodyText>
<sectionHeader confidence="0.995555" genericHeader="method">
4 Disambiguation Experiments
</sectionHeader>
<bodyText confidence="0.999954466666667">
For the experiments described here we used the
WEKA machine learning toolkit (Hall et al., 2009)
and its implementation of a RandomForest classi-
fier (Breiman, 2001). This method outperformed, in
our task, the C4.5 decision tree and NaiveBayes al-
gorithms often used in recent research on discourse
connective classification.
Our first experiment was aimed at sense disam-
biguation down to the third level of the PDTB hi-
erarchy. The training set here consisted of all 100
types of explicit connectives annotated in the PDTB
training set (15,366 instances). To make the figures
and results of this paper comparable to related work,
we use the subdivision of the PDTB recommended
in the annotation manual: sections 02–21 as train-
ing set and section 23 as test set. The only two
features were the (capitalized) connective word to-
kens from the PDTB and their Part of Speech (POS)
tags. For all 129 possible sense combinations, in-
cluding complex senses, results reach 66.51% ac-
curacy with 10-fold cross validation on the train-
ing set and 74.53% accuracy on the PDTB test set1.
This can be seen as a baseline experiment. For in-
stance, Pitler and Nenkova (2009) report an accu-
racy of 85.86% for correctly classified connectives
(with the 4 main senses), when using the connective
token as the only feature.
Based on the analysis of translations and frequen-
cies from Section 2, we then reduced the list of
senses to the following six: temporal (T), cause (C),
</bodyText>
<footnote confidence="0.520374">
1As far as we know, Versley (2010) is the only reference
reporting results down to the third level, reaching an accuracy of
79%, using more features, but not stating whether the complex
sense annotations were included.
</footnote>
<page confidence="0.997067">
48
</page>
<table confidence="0.9997916">
Connective Senses with number of occurrences Best feature subset Accuracy Baseline kappa
although 134 CO, 133 CT 8, 9, 10 58.4% 48.7% 0.17
but 2090 CT, 485 CO, 77 E 5, 8, 9, 10 76.4% 78.8% 0.02
however 261 CT, 119 CO 1–10 68.4% 68.7% 0.05
meanwhile 77 T, 57 E, 22 CT 1–10 51.9% 49.4% 0.09
since 83 C, 67 T 1, 4, 6, 8, 9, 10 75.3% 55.3% 0.49
though 136 CO, 125 CT 1, 2, 3, 9, 10 65.1% 52.1% 0.30
when 640 T, 135 COND, 17 C, 8 CO, 2 CT 1, 2, 10 79.9% 79.8% 0.05
while 342 CT, 159 T, 77 CO, 53 E 3, 5, 7, 8, 9, 10 59.6% 54.1% 0.23
all 2975 CT, 959 CO, 943 T, 187 E, 135 COND, 100 C 1–10 72.6% 56.1% 0.50
</table>
<tableCaption confidence="0.99932">
Table 3: Disambiguation of temporal–contrastive connectives.
</tableCaption>
<bodyText confidence="0.999407411764706">
condition (COND), contrast (CT), concession (CO)
and expansion (E). All subsenses from the third
PDTB hierarchy level were merged under second
level ones (C, COND, CT, CO). Exceptions were
the top level senses T and E, which, so far, need
no further disambiguation for translation. In addi-
tion, we extracted separate training sets for each of
the 8 temporal–contrastive connectives in question
and one training set for all them. The number of oc-
currences and senses in the sets for the single con-
nectives is listed in Table 3. The total number of
instances in the training set for all 8 connectives
is 5,299 occurrences, with a sense distribution of
56.1% CT, 18% CO, 17.8% T, 3.5% E, 2.5% COND,
1.9% C.
Before summarizing the results, we describe the
features implemented and used so far.
</bodyText>
<subsectionHeader confidence="0.848732">
4.1 Features
</subsectionHeader>
<bodyText confidence="0.999854">
The following basic surface features were consid-
ered when disambiguating the senses signaled by
connectives. Their values were extracted from the
PDTB manual gold annotation. Future automated
disambiguation will be applied to unrestricted text,
identifying the discourse arguments and syntactical
elements in automatically parsed and POS–tagged
sentences.
</bodyText>
<listItem confidence="0.9947458">
1. the (capitalized) connective word form
2. its POS tag
3. first word of argument 1
4. last word of argument 1
5. first word of argument 2
6. last word of argument 2
7. POS tag of the first word of argument 2
8. type of first word of argument 2
9. parent syntactical categories of the connective
10. punctuation pattern
</listItem>
<bodyText confidence="0.999815653846154">
The cased word forms (feature 1) were left as is,
therefore also indicating whether the connective is
located at the beginning of a sentence or not. The
variations from the PDTB (e.g. when – back when
etc.) were also included, supplemented by their POS
tags (feature 2). As shown by Lin et al. (2010)
and duVerle and Prendinger (2009), the context of
a connective is very important. The arguments may
include other (reinforcing or opposite) connectives,
numbers and antonyms (to express contrastive rela-
tions). We extracted the words at the beginning and
at the end of argument 1 (features 3, 4) and argu-
ment 2 (features 5, 6) which are, as observed, other
connectives, gerunds, adverbs or determiners (fur-
ther generalized by features 7 and 8). The paths to
syntactical ancestors (feature 9) in which the con-
nective word form appears are quite numerous and
were therefore truncated to a maximum of four an-
cestors (e.g. |SBARIIVPIIS|, |ADVPIIADJPIIVPIIS|,
etc). Punctuation patterns (feature 10) are of the
form C,A – A,CA etc. where C is the explicit con-
nective and A a placeholder for all the other words.
Punctuation is important for locating connectives as
many of them are subordinating and coordinating
conjunctions, separated by commas (Haddow, 2005,
p. 23).
</bodyText>
<subsectionHeader confidence="0.759678">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999973666666667">
In the disambiguation experiments described
here, results were generated separately for every
temporal–contrastive connective (supposing one
may try to improve the translation of only certain
connectives), in addition to one result for the whole
subset. The results in Table 3 above are based
on 10-fold cross validation on the training sets.
They were measured using accuracy (percentage
of correctly classified instances) and the kappa
</bodyText>
<page confidence="0.9987">
49
</page>
<bodyText confidence="0.994227333333333">
priate translation of the connective in the French
equivalent phrase. We also increased the lexical
probability scores for such modified phrases. The
following example gives an idea of the changes in
the phrase table of the above-mentioned EN–FR
Moses SMT system:
</bodyText>
<equation confidence="0.909143333333333">
G original:
&gt; modified:
    1 2
</equation>
<bodyText confidence="0.999922161290323">
Experiments with such modifications have al-
ready demonstrated a slight increase of BLEU
scores (by 0.8% absolute) on a small test corpus
(20 hand-labeled sentences). The analysis of results
has shown that the system behaves as expected, i.e.
labeled connectives are correctly translated. This
tends to confirm the hypothesis of this paper, that
information regarding discourse connectives indeed
can lead to better translations.
value. The baseline is the majority class, i.e. the
prediction for the most frequent sense annotated for
the corresponding connective. Feature selection was
performed in order to find the best feature subset,
which also improved the accuracy in a range of
1% to 2%. Marked in bold are the accuracy values
significantly above the baseline ones2. The last
result for all 8 temporal–contrastive connectives
reports a six-way classification of senses very close
to one another: the accuracy and kappa values are
well above random agreement and prediction of the
majority class.
Note that experiments for specific subsets of con-
nectives have very rarely been tried in research.
Miltsakaki et al. (2005) describe results for since,
while and when, reporting accuracies of 89.5%,
71.8% and 61.6%. The results for the single connec-
tives are comparable with ours in the case of since
and while, where similar senses were used. For when
they only distinguished three senses, whereas we re-
port a higher accuracy for 5 different senses, see Ta-
ble 3.
</bodyText>
<sectionHeader confidence="0.9924565" genericHeader="method">
5 SMT Experiments
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99998675">
We have started to explore how to constrain an SMT
system to use labeled connectives resulting from the
experiments above. There are at least two meth-
ods to integrate labeled discourse connectives in the
SMT process. A first method modifies the phrase ta-
ble of the Moses SMT decoder (Koehn et al., 2007)
in order to encourage it to translate a specific sense
of a connective with an acceptable equivalent. A
second, more natural method for an SMT system
would be to apply the discourse information ob-
tained from the disambiguation module, adding the
sense tags to the discourse connectives in a large par-
allel corpus. This corpus could then be used to train
a new SMT system learning and weighting these
tags during the training.
So far, we experimented with method one. Infor-
mation about the possible senses of the connective
while, labeled as temporal(1), contrast(2) or con-
cession(3)) was directly introduced to the English
source language phrases when there was an appro-
</bodyText>
<footnote confidence="0.56849">
2Paired t-tests were performed at 95% confidence level. The
other accuracy values are either near to the baseline ones or not
significantly below them.
</footnote>
<bodyText confidence="0.999976222222222">
The paper described new translation-oriented ap-
proaches to the disambiguation of a subset of ex-
plicit discourse connectives with highly ambiguous
temporal–contrastive senses. Although lexically ex-
plicit, their translation by current SMT systems is
often wrong. Disambiguation results in reasonably
high accuracies but also shows that one should find
more accurate and additional features. We will try
to better model the context of a connective, for in-
stance by integrating word similarity distances from
WordNet as features.
In addition, the paper showed a first method to
force an existing and trained SMT system to trans-
late discourse connectives correctly. This led to
noticeable improvements on the translations of the
tested sentences. We will continue to train SMT sys-
tems on automatically labeled discourse connectives
in large corpora.
</bodyText>
<sectionHeader confidence="0.998319" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9775115">
This work is funded by the Swiss National Sci-
ence Foundation (SNSF) under the Project Sinergia
</bodyText>
<page confidence="0.985271">
50
</page>
<bodyText confidence="0.9982528">
COMTIS, contract number CRSI22 127510, www.
idiap.ch/comtis/. Many thanks go to Dr. An-
drei Popescu-Belis, Dr. Bruno Cartoni and Dr. San-
drine Zufferey, for insightful comments and collab-
oration.
</bodyText>
<sectionHeader confidence="0.998388" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994445625">
Leo Breiman. 2001. Random Forests. Machine Learn-
ing, 45(1):5–32.
Michael Collins, Phillipp Koehn, Ivona Kucerova. 2005.
Clause Restructuring for Statistical Machine Transla-
tion. Proceedings of the 43rd Annual Meeting of the
ACL, 531–540
David duVerle, Helmut Prendinger. 2009. A Novel Dis-
course Parser Based on Support Vector Machine Clas-
sification. Proceedings of the 47th Annual Meeting of
the ACL and the 4th IJCNLP of the AFNLP, 665–673.
Barry Haddow. 2005. Acquiring a Disambiguation
Model For Discourse Connectives. Master Thesis.
University of Edinburgh, School of Informatics.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-
hard Pfahringer, Peter Reutemann, Ian H. Witten.
2009. The WEKA Data Mining Software: An Update.
SIGKDD Explorations, 11(1).
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. Proceedings of MT
Summit X, 79–86.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico,
Nicola Bertoldi, Brooke Cowan, Wade Shen,
Christine Moran, Richard Zens, Chris Dyer, On-
drej Bojar, Alexandra Constantin, Evan Herbs. 2007.
Moses: Open Source Toolkit for Statistical Machine
Translation. Proceedings of the 45th Annual Meeting
of the ACL, Demonstration session, 177–180.
Ronan Le Nagard, Philipp Koehn. 2010. Aiding Pronoun
Translation with Co-Reference Resolution. Proceed-
ings of the Joint 5th Workshop on Statistical Machine
Translation and Metrics MATR, 258–267.
Ziheng Lin, Hwee Tou Ng, Min-Yen Kan. 2010. A
PDTB-Styled End-to-End Discourse Parser. Techni-
cal Report TRB8/10. School of Computing, National
University of Singapore, 1–15.
William C. Mann, Sandra A. Thompson. 1988. Rhetori-
cal structure theory: towards a functional theory of text
organization. Text 8(3):243–281.
Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Ar-
avind Joshi, Bonnie Webber. 2005. Experiments on
Sense Annotations and Sense Disambiguation of Dis-
course Connectives. Proceedings of the Fourth Work-
shop on Treebanks and Linguistic Theories (TLT).
Marie-Paule P´ery-Woodley, Nicholas Asher, Patrice En-
jalbert, Farah Benamara, Myriam Bras, C´ecile Fabre,
St´ephane Ferrari, Lydia-Mai Ho-Dac, Anne Le
Draoulec, Yann Mathet, Philippe Muller, Lau-
rent Pr´evot, Josette Rebeyrolle, Ludovic Tan-
guy, Marianne Vergez-Couret, Laure Vieu, An-
toine Widl¨ocher. 2009. ANNODIS: une approche out-
ille de l’annotation de structures discursives. Proceed-
ings of TALN.
Emily Pitler, Ani Nenkova. 2009. Using Syntax to
Disambiguate Explicit Discourse Connectives in Text.
Proceedings of the ACL-IJCNLP 2009 Conference,
Short Papers. 13–16.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, Bonnie Webber.
2008. The Penn Discourse Treebank 2.0. Proceed-
ings of the 6th International Conference on Language
Resources and Evaluation (LREC), 29641-2968.
Charlotte Roze, Laurence Danlos, Philippe Muller. 2010.
LEXCONN: a French Lexicon of Discourse Connec-
tives. Proceedings of Multidisciplinary Approaches to
Discourse (MAD).
Manfred Stede, Carla Umbach. 1998. DiMLex: a lex-
icon of discourse markers for text generation and un-
derstanding. Proceedings of the 36th Annual Meeting
of the ACL, 1238–1242.
Yannick Versley. 2010. Discovery of Ambiguous and
Unambiguous Discourse Connectives via Annotation
Projection. Proceedings of Workshop on Annotation
and Exploitation of Parallel Corpora (AEPC), 83–82
S´arka Zik´anov´a, Lucie Mladov´a, Jiˇr´ı M´ırovsk´y,
Pavlina J´ınov´a. 2010. Typical Cases of Annotators’
Disagreement in Discourse Annotations in Prague
Dependency Treebank. Proceedings of the Seventh
International Conference on Language Resources and
Evaluation (LREC), 2002–2006.
</reference>
<page confidence="0.999118">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.595820">
<title confidence="0.9995095">Disambiguating Temporal–Contrastive Discourse Connectives for Machine Translation</title>
<author confidence="0.958688">Thomas</author>
<affiliation confidence="0.983874">Idiap Research Institute / Martigny, EPFL - EDEE doctoral school / Lausanne,</affiliation>
<email confidence="0.74974">Thomas.Meyer@idiap.ch</email>
<abstract confidence="0.989051692307692">Temporal–contrastive discourse connectives etc.) signal various of relations between clauses such as temcontrast, concession They are often ambiguous and therefore difficult to translate from one language to another. We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>COMTIS</author>
</authors>
<title>contract number CRSI22 127510, www. idiap.ch/comtis/. Many thanks go to Dr. Andrei Popescu-Belis, Dr. Bruno Cartoni and Dr. Sandrine Zufferey, for insightful comments and collaboration.</title>
<marker>COMTIS, </marker>
<rawString>COMTIS, contract number CRSI22 127510, www. idiap.ch/comtis/. Many thanks go to Dr. Andrei Popescu-Belis, Dr. Bruno Cartoni and Dr. Sandrine Zufferey, for insightful comments and collaboration.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random Forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="11306" citStr="Breiman, 2001" startWordPosition="1799" endWordPosition="1800"> As we show in the next section, when building separate classifiers for specific connectives with senses from the more detailed second hierarchy level of the PDTB, it is more difficult to reach high accuracies. Recently, Lin et al. (2010) built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38.18% on PDTB test data and for senses on the second hierarchy level. 4 Disambiguation Experiments For the experiments described here we used the WEKA machine learning toolkit (Hall et al., 2009) and its implementation of a RandomForest classifier (Breiman, 2001). This method outperformed, in our task, the C4.5 decision tree and NaiveBayes algorithms often used in recent research on discourse connective classification. Our first experiment was aimed at sense disambiguation down to the third level of the PDTB hierarchy. The training set here consisted of all 100 types of explicit connectives annotated in the PDTB training set (15,366 instances). To make the figures and results of this paper comparable to related work, we use the subdivision of the PDTB recommended in the annotation manual: sections 02–21 as training set and section 23 as test set. The </context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random Forests. Machine Learning, 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Phillipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause Restructuring for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>531--540</pages>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Phillipp Koehn, Ivona Kucerova. 2005. Clause Restructuring for Statistical Machine Translation. Proceedings of the 43rd Annual Meeting of the ACL, 531–540</rawString>
</citation>
<citation valid="true">
<authors>
<author>David duVerle</author>
<author>Helmut Prendinger</author>
</authors>
<title>A Novel Discourse Parser Based on Support Vector Machine Classification.</title>
<date>2009</date>
<booktitle>Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP,</booktitle>
<pages>665--673</pages>
<contexts>
<context position="15289" citStr="duVerle and Prendinger (2009)" startWordPosition="2499" endWordPosition="2502">ctive word form 2. its POS tag 3. first word of argument 1 4. last word of argument 1 5. first word of argument 2 6. last word of argument 2 7. POS tag of the first word of argument 2 8. type of first word of argument 2 9. parent syntactical categories of the connective 10. punctuation pattern The cased word forms (feature 1) were left as is, therefore also indicating whether the connective is located at the beginning of a sentence or not. The variations from the PDTB (e.g. when – back when etc.) were also included, supplemented by their POS tags (feature 2). As shown by Lin et al. (2010) and duVerle and Prendinger (2009), the context of a connective is very important. The arguments may include other (reinforcing or opposite) connectives, numbers and antonyms (to express contrastive relations). We extracted the words at the beginning and at the end of argument 1 (features 3, 4) and argument 2 (features 5, 6) which are, as observed, other connectives, gerunds, adverbs or determiners (further generalized by features 7 and 8). The paths to syntactical ancestors (feature 9) in which the connective word form appears are quite numerous and were therefore truncated to a maximum of four ancestors (e.g. |SBARIIVPIIS|, </context>
</contexts>
<marker>duVerle, Prendinger, 2009</marker>
<rawString>David duVerle, Helmut Prendinger. 2009. A Novel Discourse Parser Based on Support Vector Machine Classification. Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, 665–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Haddow</author>
</authors>
<title>Acquiring a Disambiguation Model For Discourse Connectives. Master Thesis.</title>
<date>2005</date>
<institution>University of Edinburgh, School of Informatics.</institution>
<contexts>
<context position="16210" citStr="Haddow, 2005" startWordPosition="2649" endWordPosition="2650">served, other connectives, gerunds, adverbs or determiners (further generalized by features 7 and 8). The paths to syntactical ancestors (feature 9) in which the connective word form appears are quite numerous and were therefore truncated to a maximum of four ancestors (e.g. |SBARIIVPIIS|, |ADVPIIADJPIIVPIIS|, etc). Punctuation patterns (feature 10) are of the form C,A – A,CA etc. where C is the explicit connective and A a placeholder for all the other words. Punctuation is important for locating connectives as many of them are subordinating and coordinating conjunctions, separated by commas (Haddow, 2005, p. 23). 4.2 Results In the disambiguation experiments described here, results were generated separately for every temporal–contrastive connective (supposing one may try to improve the translation of only certain connectives), in addition to one result for the whole subset. The results in Table 3 above are based on 10-fold cross validation on the training sets. They were measured using accuracy (percentage of correctly classified instances) and the kappa 49 priate translation of the connective in the French equivalent phrase. We also increased the lexical probability scores for such modified </context>
</contexts>
<marker>Haddow, 2005</marker>
<rawString>Barry Haddow. 2005. Acquiring a Disambiguation Model For Discourse Connectives. Master Thesis. University of Edinburgh, School of Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="11238" citStr="Hall et al., 2009" startWordPosition="1787" endWordPosition="1790">nstances and the rather broad distinction of the four main classes only. As we show in the next section, when building separate classifiers for specific connectives with senses from the more detailed second hierarchy level of the PDTB, it is more difficult to reach high accuracies. Recently, Lin et al. (2010) built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38.18% on PDTB test data and for senses on the second hierarchy level. 4 Disambiguation Experiments For the experiments described here we used the WEKA machine learning toolkit (Hall et al., 2009) and its implementation of a RandomForest classifier (Breiman, 2001). This method outperformed, in our task, the C4.5 decision tree and NaiveBayes algorithms often used in recent research on discourse connective classification. Our first experiment was aimed at sense disambiguation down to the third level of the PDTB hierarchy. The training set here consisted of all 100 types of explicit connectives annotated in the PDTB training set (15,366 instances). To make the figures and results of this paper comparable to related work, we use the subdivision of the PDTB recommended in the annotation man</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, Ian H. Witten. 2009. The WEKA Data Mining Software: An Update. SIGKDD Explorations, 11(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>Proceedings of MT Summit X,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="3036" citStr="Koehn, 2005" startWordPosition="445" endWordPosition="446">on 6 concludes the paper with an outline of future work. 2 Translating Connectives Discourse connectives can signal multiple senses (Miltsakaki et al., 2005). For instance, the connective since can have a temporal and causal meaning. The disambiguation of these senses is crucial to the correct translation of texts from one language to another. Translation can be difficult because there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown by the reference translation of the first example in Table 1, taken from the Europarl corpus (Koehn, 2005). More often, the incorrect rendering of the sense of a connective can lead to wrong translations, as in the second, third and fourth example in Table 1, which were translated by the Moses SMT decoder (Koehn Proceedings of the ACL-HLT 2011 Student Session, pages 46–51, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics EN So what we want the European Patent Office to do FR is something on behalf of the European Commission [while] temporal the Office itself is not a Community institution. Aussi, ce que nous souhaitons, c’est que l’Office europeen des brevets agi</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. Proceedings of MT Summit X, 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbs.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the ACL, Demonstration session,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="18782" citStr="Koehn et al., 2007" startWordPosition="3057" endWordPosition="3060">5%, 71.8% and 61.6%. The results for the single connectives are comparable with ours in the case of since and while, where similar senses were used. For when they only distinguished three senses, whereas we report a higher accuracy for 5 different senses, see Table 3. 5 SMT Experiments 6 Conclusion and Future Work We have started to explore how to constrain an SMT system to use labeled connectives resulting from the experiments above. There are at least two methods to integrate labeled discourse connectives in the SMT process. A first method modifies the phrase table of the Moses SMT decoder (Koehn et al., 2007) in order to encourage it to translate a specific sense of a connective with an acceptable equivalent. A second, more natural method for an SMT system would be to apply the discourse information obtained from the disambiguation module, adding the sense tags to the discourse connectives in a large parallel corpus. This corpus could then be used to train a new SMT system learning and weighting these tags during the training. So far, we experimented with method one. Information about the possible senses of the connective while, labeled as temporal(1), contrast(2) or concession(3)) was directly in</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbs. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. Proceedings of the 45th Annual Meeting of the ACL, Demonstration session, 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Le Nagard</author>
<author>Philipp Koehn</author>
</authors>
<title>Aiding Pronoun Translation with Co-Reference Resolution.</title>
<date>2010</date>
<booktitle>Proceedings of the Joint 5th Workshop on Statistical Machine Translation and Metrics MATR,</booktitle>
<pages>258--267</pages>
<marker>Le Nagard, Koehn, 2010</marker>
<rawString>Ronan Le Nagard, Philipp Koehn. 2010. Aiding Pronoun Translation with Co-Reference Resolution. Proceedings of the Joint 5th Workshop on Statistical Machine Translation and Metrics MATR, 258–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>A PDTB-Styled End-to-End Discourse Parser.</title>
<date>2010</date>
<tech>Technical Report TRB8/10.</tech>
<pages>1--15</pages>
<institution>School of Computing, National University of Singapore,</institution>
<contexts>
<context position="10930" citStr="Lin et al. (2010)" startWordPosition="1735" endWordPosition="1738"> high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). However, when using all 100 types of connectives and the whole PDTB training set, it is not so difficult to achieve such a high score, because of the large amount of instances and the rather broad distinction of the four main classes only. As we show in the next section, when building separate classifiers for specific connectives with senses from the more detailed second hierarchy level of the PDTB, it is more difficult to reach high accuracies. Recently, Lin et al. (2010) built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38.18% on PDTB test data and for senses on the second hierarchy level. 4 Disambiguation Experiments For the experiments described here we used the WEKA machine learning toolkit (Hall et al., 2009) and its implementation of a RandomForest classifier (Breiman, 2001). This method outperformed, in our task, the C4.5 decision tree and NaiveBayes algorithms often used in recent research on discourse connective classification. Our first experiment was aimed at sense disambiguation down to t</context>
<context position="15255" citStr="Lin et al. (2010)" startWordPosition="2494" endWordPosition="2497">he (capitalized) connective word form 2. its POS tag 3. first word of argument 1 4. last word of argument 1 5. first word of argument 2 6. last word of argument 2 7. POS tag of the first word of argument 2 8. type of first word of argument 2 9. parent syntactical categories of the connective 10. punctuation pattern The cased word forms (feature 1) were left as is, therefore also indicating whether the connective is located at the beginning of a sentence or not. The variations from the PDTB (e.g. when – back when etc.) were also included, supplemented by their POS tags (feature 2). As shown by Lin et al. (2010) and duVerle and Prendinger (2009), the context of a connective is very important. The arguments may include other (reinforcing or opposite) connectives, numbers and antonyms (to express contrastive relations). We extracted the words at the beginning and at the end of argument 1 (features 3, 4) and argument 2 (features 5, 6) which are, as observed, other connectives, gerunds, adverbs or determiners (further generalized by features 7 and 8). The paths to syntactical ancestors (feature 9) in which the connective word form appears are quite numerous and were therefore truncated to a maximum of fo</context>
</contexts>
<marker>Lin, Ng, Kan, 2010</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, Min-Yen Kan. 2010. A PDTB-Styled End-to-End Discourse Parser. Technical Report TRB8/10. School of Computing, National University of Singapore, 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: towards a functional theory of text organization.</title>
<date>1988</date>
<journal>Text</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="9228" citStr="Mann and Thompson, 1988" startWordPosition="1448" endWordPosition="1451">Pery-Woodley et al., 2009) will provide an original, discourse-annotated corpus. Resources for Czech are also becoming available (Zikanova et al., 2010). For German, a lexicon of discourse connectives exists since the 1990s, namely DiMLex for lexicon of discourse markers (Stede and Umbach, 1998). An equivalent, more recent database for French is LexConn for lexicon of connectives (Roze et al., 2010) – containing a list of 328 explicit connectives. For each of them, LexConn indicates and exemplifies the possible senses, chosen from a list of 30 labels inspired from Rhetorical Structure Theory (Mann and Thompson, 1988). For the first classification experiments in Section 4, we concentrated on English and the explicit connectives in the PDTB data. The sense hierarchy used in the PDTB consists of three levels, reaching from four top level senses (Temporal, Contingency, Comparison and Expansion) via 16 subsenses on the second level to 23 further subsenses on the third level. As the annotators were allowed to assign one or two senses for each connective there are 129 possible simple or complex senses for more than 18,000 explicit connectives. The PDTB further sees connectives as discourse-level predicates that </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann, Sandra A. Thompson. 1988. Rhetorical structure theory: towards a functional theory of text organization. Text 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Nikhil Dinesh</author>
<author>Rashmi Prasad</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<date>2005</date>
<booktitle>Experiments on Sense Annotations and Sense Disambiguation of Discourse Connectives. Proceedings of the Fourth Workshop on Treebanks and Linguistic Theories (TLT).</booktitle>
<contexts>
<context position="2581" citStr="Miltsakaki et al., 2005" startWordPosition="370" endWordPosition="373">lp in improving SMT systems to avoid translation errors. The paper is organized as follows. Section 2 exemplifies translation and human annotation difficulties. Resources and the state of the art for discourse connective disambiguation and parsing are described in Section 3. Section 4 summarizes our experiments for disambiguating the senses of temporal–contrastive connectives. The impact of connective disambiguation on SMT is briefly presented in Section 5. Section 6 concludes the paper with an outline of future work. 2 Translating Connectives Discourse connectives can signal multiple senses (Miltsakaki et al., 2005). For instance, the connective since can have a temporal and causal meaning. The disambiguation of these senses is crucial to the correct translation of texts from one language to another. Translation can be difficult because there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown by the reference translation of the first example in Table 1, taken from the Europarl corpus (Koehn, 2005). More often, the incorrect rendering of the sense of a connective can lead to wrong translations, as in the second, third and fourth example in </context>
<context position="18091" citStr="Miltsakaki et al. (2005)" startWordPosition="2937" endWordPosition="2940">st frequent sense annotated for the corresponding connective. Feature selection was performed in order to find the best feature subset, which also improved the accuracy in a range of 1% to 2%. Marked in bold are the accuracy values significantly above the baseline ones2. The last result for all 8 temporal–contrastive connectives reports a six-way classification of senses very close to one another: the accuracy and kappa values are well above random agreement and prediction of the majority class. Note that experiments for specific subsets of connectives have very rarely been tried in research. Miltsakaki et al. (2005) describe results for since, while and when, reporting accuracies of 89.5%, 71.8% and 61.6%. The results for the single connectives are comparable with ours in the case of since and while, where similar senses were used. For when they only distinguished three senses, whereas we report a higher accuracy for 5 different senses, see Table 3. 5 SMT Experiments 6 Conclusion and Future Work We have started to explore how to constrain an SMT system to use labeled connectives resulting from the experiments above. There are at least two methods to integrate labeled discourse connectives in the SMT proc</context>
</contexts>
<marker>Miltsakaki, Dinesh, Prasad, Joshi, Webber, 2005</marker>
<rawString>Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Aravind Joshi, Bonnie Webber. 2005. Experiments on Sense Annotations and Sense Disambiguation of Discourse Connectives. Proceedings of the Fourth Workshop on Treebanks and Linguistic Theories (TLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Paule P´ery-Woodley</author>
<author>Nicholas Asher</author>
<author>Patrice Enjalbert</author>
<author>Farah Benamara</author>
<author>Myriam Bras</author>
<author>C´ecile Fabre</author>
<author>St´ephane Ferrari</author>
</authors>
<title>ANNODIS: une approche outille de l’annotation de structures discursives.</title>
<date>2009</date>
<booktitle>Proceedings of TALN.</booktitle>
<institution>Lydia-Mai Ho-Dac, Anne Le Draoulec, Yann Mathet, Philippe Muller, Laurent Pr´evot, Josette Rebeyrolle, Ludovic Tanguy, Marianne Vergez-Couret, Laure</institution>
<marker>P´ery-Woodley, Asher, Enjalbert, Benamara, Bras, Fabre, Ferrari, 2009</marker>
<rawString>Marie-Paule P´ery-Woodley, Nicholas Asher, Patrice Enjalbert, Farah Benamara, Myriam Bras, C´ecile Fabre, St´ephane Ferrari, Lydia-Mai Ho-Dac, Anne Le Draoulec, Yann Mathet, Philippe Muller, Laurent Pr´evot, Josette Rebeyrolle, Ludovic Tanguy, Marianne Vergez-Couret, Laure Vieu, Antoine Widl¨ocher. 2009. ANNODIS: une approche outille de l’annotation de structures discursives. Proceedings of TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
</authors>
<title>Ani Nenkova.</title>
<date>2009</date>
<booktitle>Proceedings of the ACL-IJCNLP 2009 Conference, Short Papers.</booktitle>
<pages>13--16</pages>
<marker>Pitler, 2009</marker>
<rawString>Emily Pitler, Ani Nenkova. 2009. Using Syntax to Disambiguate Explicit Discourse Connectives in Text. Proceedings of the ACL-IJCNLP 2009 Conference, Short Papers. 13–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<date>2008</date>
<booktitle>The Penn Discourse Treebank 2.0. Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>29641--2968</pages>
<contexts>
<context position="5568" citStr="Prasad et al., 2008" startWordPosition="851" endWordPosition="854">asterisk. et al., 2007) trained on the Europarl EN–FR and respectively EN–DE subcorpora. The reference translation for the second example uses the French connective car with a correct causal sense, instead of the wrong depuis que generated by SMT, which expresses a temporal relation. In the third example, the SMT system failed to translate the English connective while to French. The French translation is therefore not coherent, the contrastive discourse information cannot be established without an explicit connective. The last example in Table 1 is a sentence from the Penn Discourse Treebank (Prasad et al., 2008), see Section 3. In its German translation, it would be correct to use the connective auch wenn (for contrast) instead of obwohl (for concession). These examples illustrate the difficulties in translating discourse connectives, even when they are lexically explicit. Our hypothesis is, that the automatic annotation of the senses prior to translation can help finding more often the correct lexical correspondences of a connective (see Section 5 for one while (489) Translation EN-FR 56% T tout en V-gerund (22%), tant que (22%), tandis que (11%) 30% CT tandis que (56%), alors que (40%) 14% CO mˆeme</context>
<context position="8395" citStr="Prasad et al., 2008" startWordPosition="1315" endWordPosition="1318">hen the output sentence became incoherent) or wrong connective words because of failure in correct sense rendering. Also, the manual sense annotation task is not trivial. In a manual annotation experiment, the senses of the connective while (T, CO and CT) were indicated in 30 sentences by 4 annotators. The overall agreement on the senses was not higher than a kappa value of 0.6, which is acceptable but would need improvement in order to produce a reliable resource. 47 3 Data and Related Work One of the few available discourse annotated corpora in English is the Penn Discourse Treebank (PDTB) (Prasad et al., 2008). For this resource, one hundred types of explicit connectives were manually annotated, as well as implicit relations not signaled by a connective. For French, the ANNODIS project for annotation of discourse (Pery-Woodley et al., 2009) will provide an original, discourse-annotated corpus. Resources for Czech are also becoming available (Zikanova et al., 2010). For German, a lexicon of discourse connectives exists since the 1990s, namely DiMLex for lexicon of discourse markers (Stede and Umbach, 1998). An equivalent, more recent database for French is LexConn for lexicon of connectives (Roze et</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC), 29641-2968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charlotte Roze</author>
<author>Laurence Danlos</author>
<author>Philippe Muller</author>
</authors>
<title>LEXCONN: a French Lexicon of Discourse Connectives.</title>
<date>2010</date>
<booktitle>Proceedings of Multidisciplinary Approaches to Discourse (MAD).</booktitle>
<contexts>
<context position="9006" citStr="Roze et al., 2010" startWordPosition="1411" endWordPosition="1414">, 2008). For this resource, one hundred types of explicit connectives were manually annotated, as well as implicit relations not signaled by a connective. For French, the ANNODIS project for annotation of discourse (Pery-Woodley et al., 2009) will provide an original, discourse-annotated corpus. Resources for Czech are also becoming available (Zikanova et al., 2010). For German, a lexicon of discourse connectives exists since the 1990s, namely DiMLex for lexicon of discourse markers (Stede and Umbach, 1998). An equivalent, more recent database for French is LexConn for lexicon of connectives (Roze et al., 2010) – containing a list of 328 explicit connectives. For each of them, LexConn indicates and exemplifies the possible senses, chosen from a list of 30 labels inspired from Rhetorical Structure Theory (Mann and Thompson, 1988). For the first classification experiments in Section 4, we concentrated on English and the explicit connectives in the PDTB data. The sense hierarchy used in the PDTB consists of three levels, reaching from four top level senses (Temporal, Contingency, Comparison and Expansion) via 16 subsenses on the second level to 23 further subsenses on the third level. As the annotators</context>
</contexts>
<marker>Roze, Danlos, Muller, 2010</marker>
<rawString>Charlotte Roze, Laurence Danlos, Philippe Muller. 2010. LEXCONN: a French Lexicon of Discourse Connectives. Proceedings of Multidisciplinary Approaches to Discourse (MAD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
<author>Carla Umbach</author>
</authors>
<title>DiMLex: a lexicon of discourse markers for text generation and understanding.</title>
<date>1998</date>
<booktitle>Proceedings of the 36th Annual Meeting of the ACL,</booktitle>
<pages>1238--1242</pages>
<contexts>
<context position="8900" citStr="Stede and Umbach, 1998" startWordPosition="1393" endWordPosition="1396">f the few available discourse annotated corpora in English is the Penn Discourse Treebank (PDTB) (Prasad et al., 2008). For this resource, one hundred types of explicit connectives were manually annotated, as well as implicit relations not signaled by a connective. For French, the ANNODIS project for annotation of discourse (Pery-Woodley et al., 2009) will provide an original, discourse-annotated corpus. Resources for Czech are also becoming available (Zikanova et al., 2010). For German, a lexicon of discourse connectives exists since the 1990s, namely DiMLex for lexicon of discourse markers (Stede and Umbach, 1998). An equivalent, more recent database for French is LexConn for lexicon of connectives (Roze et al., 2010) – containing a list of 328 explicit connectives. For each of them, LexConn indicates and exemplifies the possible senses, chosen from a list of 30 labels inspired from Rhetorical Structure Theory (Mann and Thompson, 1988). For the first classification experiments in Section 4, we concentrated on English and the explicit connectives in the PDTB data. The sense hierarchy used in the PDTB consists of three levels, reaching from four top level senses (Temporal, Contingency, Comparison and Exp</context>
</contexts>
<marker>Stede, Umbach, 1998</marker>
<rawString>Manfred Stede, Carla Umbach. 1998. DiMLex: a lexicon of discourse markers for text generation and understanding. Proceedings of the 36th Annual Meeting of the ACL, 1238–1242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
</authors>
<title>Discovery of Ambiguous and Unambiguous Discourse Connectives via Annotation Projection.</title>
<date>2010</date>
<booktitle>Proceedings of Workshop on Annotation</booktitle>
<contexts>
<context position="12625" citStr="Versley (2010)" startWordPosition="2024" endWordPosition="2025">OS) tags. For all 129 possible sense combinations, including complex senses, results reach 66.51% accuracy with 10-fold cross validation on the training set and 74.53% accuracy on the PDTB test set1. This can be seen as a baseline experiment. For instance, Pitler and Nenkova (2009) report an accuracy of 85.86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. Based on the analysis of translations and frequencies from Section 2, we then reduced the list of senses to the following six: temporal (T), cause (C), 1As far as we know, Versley (2010) is the only reference reporting results down to the third level, reaching an accuracy of 79%, using more features, but not stating whether the complex sense annotations were included. 48 Connective Senses with number of occurrences Best feature subset Accuracy Baseline kappa although 134 CO, 133 CT 8, 9, 10 58.4% 48.7% 0.17 but 2090 CT, 485 CO, 77 E 5, 8, 9, 10 76.4% 78.8% 0.02 however 261 CT, 119 CO 1–10 68.4% 68.7% 0.05 meanwhile 77 T, 57 E, 22 CT 1–10 51.9% 49.4% 0.09 since 83 C, 67 T 1, 4, 6, 8, 9, 10 75.3% 55.3% 0.49 though 136 CO, 125 CT 1, 2, 3, 9, 10 65.1% 52.1% 0.30 when 640 T, 135 C</context>
</contexts>
<marker>Versley, 2010</marker>
<rawString>Yannick Versley. 2010. Discovery of Ambiguous and Unambiguous Discourse Connectives via Annotation Projection. Proceedings of Workshop on Annotation</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>