<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000021">
<title confidence="0.9946355">
Logic Form Transformation of WordNet and its Applicability
to Question Answering
</title>
<author confidence="0.963166">
Dan I. Moldovan and Vasile Rus
</author>
<affiliation confidence="0.866557">
Department of Computer Science and Engineering
Southern Methodist University
</affiliation>
<address confidence="0.649357">
Dallas, TX 75275-0122
</address>
<email confidence="0.587405">
{moldovan, vasile}Aseas.smu.edu
</email>
<sectionHeader confidence="0.989825" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999928454545454">
WordNet is a rich source of world knowl-
edge from which formal axioms can be
derived. In this paper we present a
method for transforming the WordNet
glosses into logic forms and further into
axioms. The transformation of Word-
Net glosses into logic forms is useful for
theorem proving and other applications.
The paper demonstrates the utility of the
WordNet axioms in a question answering
system to rank and extract answers.
</bodyText>
<sectionHeader confidence="0.997924" genericHeader="introduction">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.934629">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.973284">
It is well understood and agreed that world knowl-
edge is necessary for many common sense reason-
ing problems. In this paper we argue that Word-
Net is an important source of world knowledge and
show how this knowledge can be put to work for
open-domain Question Answering systems.
Consider the TREC-QA question (NIST, 2000):
Q198: How did Socrates die?
The answer to this question appears in the text
&amp;quot;...Socrates&apos; death came when he chose to drink
poisoned wine...&amp;quot;. To prove that this is a plausible
answer one needs to know that drinking poisoned
wine may be a cause of death. This extra knowl-
edge is found in WordNet glosses (Miller, 1995).
The gloss of concept poison:v#2 (the second sense
of verb poison) contains {kill with poison} and the
first sense of verb ki//74/ is {cause to die}, which
collectively justify the answer.
This paper presents a simple but consistent
logic notation suitable for representing the English
texts of the WordNet glosses. The WordNet logic
forms supply us with a rich set of axioms essen-
tial for boosting the performance of a Question
Answering system.
</bodyText>
<subsectionHeader confidence="0.964093">
1.2 Research Goal
</subsectionHeader>
<bodyText confidence="0.99951635">
The goal of this research project is to transform
all the WordNet glosses into logic representations
that enables reasoning mechanisms for many prac-
tical applications. In this paper we limit the dis-
cussion to the definitions and ignore the gloss ex-
amples.
The logic form is an intermediary step between
the syntactic parse and the deep semantic form.
The Logic Form Transformation (LFT) codifica-
tion acknowledges syntax-based relationships such
as: (1) syntactic subjects, (2) syntactic objects,
(3) prepositional attachments, (4) complex nomi-
nals, and (5) adjectival/adverbial adjuncts.
The main problems encountered are the selec-
tion of an appropriate logic representation and the
actual implementation of the rules that transform
the English definitions into logic forms. Before the
rules are applied, the glosses are passed through
a preprocessing phase consisting of tokenization,
part-of-speech tagging and syntactic parsing.
</bodyText>
<subsectionHeader confidence="0.893738">
1.3 Approach
</subsectionHeader>
<bodyText confidence="0.999937391304348">
There are two criteria that guide our approach:
(1) the notation be as close as possible to En-
glish, and (2) the notation be syntactically sim-
ple. Our approach is to derive the LFT directly
from the output of the syntactic parser. The parser
resolves the structural and syntactic ambiguities.
This way, we avoid the very hard problems of
logic representation of natural language. We fol-
low closely the successful representation used by
Hobbs in TACITUS (Hobbs, 1986). Hobbs ex-
plains that for many linguistic applications it is
acceptable to relax ontological scruples, intricate
syntactic explanations, and the desire for efficient
deductions in favor of a simpler notation closer to
English. For the logic representation of WordNet
glosses we ignore: plurals and sets, verb tenses,
auxiliary verbs, quantifiers and modal operators,
comparatives and negation. This decision is based
on our desire to provide manageable and consis-
tent logic representation that otherwise would be
unfeasible. We have not noticed that these sim-
plifications had any adverse effect on the TREC
questions.
</bodyText>
<sectionHeader confidence="0.58631" genericHeader="related work">
1.4 Related Work
</sectionHeader>
<bodyText confidence="0.999913125">
This work is part of a larger project to extend
WordNet outlined in (Harabagiu et al., 1999).
Our work of processing WordNet glosses resem-
bles previous efforts of extracting lexical informa-
tion from machine readable dictionaries (MRD),
as LDOCE (Longman Dictionary of Contempo-
rary English) or Webster&apos;s 2nd International Dic-
tionary (W2). Different parsing methods of dic-
tionary definitions were used: pattern-matching
(Chodorow et al., 1985), genus disambiguation
(Bruce and Guthrie, 1992), especially constructed
definition parsers (Wilks et al., 1996) or broad cov-
erage parsers (Richardson et al., 1998), (Rigau et
al., 1998), (ISI, 1998). All those efforts were lim-
ited to extracting genus terms, unlabeled or la-
beled relations, or build taxonomies.
</bodyText>
<sectionHeader confidence="0.986173" genericHeader="method">
2 LFT Definitions
</sectionHeader>
<bodyText confidence="0.968709777777778">
Predicates
A predicate is generated for every noun, verb, ad-
jective or adverb encountered in any gloss. The
name of the predicate is a concatenation of the
morpheme&apos;s base form, the part-of-speech and the
WordNet semantic sense, thus capturing the full
lexical and semantic disambiguation. For exam-
ple, the LFT of the gloss of {student, pupil,
educatee} is (a learner who is enrolled in
an educational institution). It will con-
tain the predicates learner:n, enroll:v and educa-
tional_institution:n.
Fix slot-allocation
In the spirit of the Davidsonian treatment of the
action predicates (Davidson, 1967), all verb pred-
icates (as well as the nominalizations representing
actions, events or states) have three arguments:
action/state/event-predicate(e,xi,x2), where:
</bodyText>
<listItem confidence="0.674656142857143">
• e represents the eventuality of the action, state
or event stated by the verb to take place,
• x1 represents the syntactic subject of the action,
event or state, and
• x2 represents the syntactic direct object of the
action, event or state.
For example, the LFT of (a person who backs
a politician), the gloss of {supporter,
protagonist, champion, admirer, booster,
friend} is: [person:n(xi) &amp; back:v(ei,xi,x2) &amp;
politician:n(x2) ]. Several clarifications are in
order here.
(a) In case when the predicate is a ditransi-
tive verb, its representation is verb(e,xi,x2,
</listItem>
<bodyText confidence="0.996188327272727">
X3). For example: professor gives students
the grades is represented as: professor(xi) &amp;
give(ei,xi,x2,x3) &amp; grade(x2) &amp; student(x3). This
condition is detected by the presence of two noun
phrases following a verb in active voice.
(b) The arguments of verb predicates are always
in the order: subject, direct object, indirect
object. In the case when one of these syntactic
roles is missing, its respective argument appears
under the verb predicate, but that argument will
not be used by any other predicate. This is a
so-called &amp;quot;slot-allocation&amp;quot; representation since
the position of the arguments is fixed for the
purpose of a simpler notation. Since in WordNet
glosses not many verbs have indirect objects,
the argument x3 is used only when necessary,
otherwise is ommited. However, the arguments
for the subjects and direct objects are always
present, even when the verb does not have these
syntactic roles. We found that this simple but
consistant representation is easy to derive and
use.
Modifiers
The role of complements within a phrase is repli-
cated in the LFTs. Predicates generated from
modifiers share the same arguments with the pred-
icates corresponding to the phrase heads. Ad-
jective predicates share the same argument as
the predicate corresponding to the noun they
modify. An exemplification is the LFT of the
gloss of {art if act , artifact}, which maps (a
man-made object) into [ object:n(xi) &amp; man-
made:a(xi)]. Similarly, the argument of adverbial
predicate is the argument marking the eventuality
of the event/state/action they modify. For exam-
ple, the gloss of the verb synset {hare} is (run
quickly), producing the LFT = [run (el ,xi,x2) &amp;
quickly(ei)].
Conjunctions
Conjunctions are transformed in predicates, which
enable the aggregation of several predicates un-
der the same syntactic role (e.g. subject, ob-
ject or prepositional object). By convention,
conjunction-predicates have a variable number of
arguments, since they cover a variable number of
predicates. The first argument represents the &amp;quot;re-
sult&amp;quot; of the logical operation induced by the con-
junction (e.g. a logical and in the case of the and
conjunction, or a logical or in the case of the or
conjunction). The rest of the arguments indicate
the predicates covered by the conjunction, as they
are arguments of those predicates as well. Table 1
provides examples of conjunction predicates.
Prepositions
We also generate predicates for every preposition
</bodyText>
<table confidence="0.965392">
Synset Gloss LFT
{masterstroke} (an achievement demonstrating achievennent:n(xi) &amp; dernonstrate(ei,xi,x2)
great skill or mastery) &amp; or(x2,x3,x4) &amp; skill:n(x3) &amp; great:a(x3)
&amp; mastery: n (x4)
{tumble} (roll and turn skillfully) and(ei,e2,e3) &amp; roll:v(e2,xi,x2) &amp;
turn:v(e3,xi,x2) &amp; skillfully:r(ei)
{trip, stumble, (an unintentional but embarrassing blundern(xi) &amp; but(xi,x2,x3) &amp;
misstep} blunder) unintentional :a (x2) &amp; em ba rrassi ng:a (x3)
</table>
<tableCaption confidence="0.996495">
Table 1: Examples of conjunction predicates
</tableCaption>
<table confidence="0.9084098">
Synset Gloss LFT
{demonetize} (deprive of value for payment) deprive:v(ei,xi,x2) &amp; of(ei,x3) &amp; vaIue:n(x3)
&amp; for(x3,x4) &amp; payment:n(x4)
{pitching} (playing the position of pitcher playing:n(ei,xi,x2) &amp; position :n (x2) &amp; of(x2,x3)
on a baseball team) &amp; pitchern(x3) on(ei,x4) &amp; baseball_team:n(x4)
</table>
<tableCaption confidence="0.998247">
Table 2: Examples of preposition predicates
</tableCaption>
<bodyText confidence="0.99134128">
encountered in the gloss. The preposition predi-
cates always have two arguments: the first argu-
ment corresponding to the predicate of the head
of the phrase to which prepositional phrase is at-
tached, whereas the second argument corresponds
to the prepositional object. This predicative treat-
ment of prepositional attachments was first re-
ported in (Bear and Hobbs, 1988). Table 2 shows
some examples of preposition predicates.
Complex nominals
Many complex nominals are encoded currently
in WordNet as synset entries comprising several
words, known as WordNet collocations (e.g. flea
market, baseball team, joint venture). Still,
many compound nouns are not encoded as Word-
Net entries, and need to be recognized as a single
nominal. The way of doing this was first devised
in TACITUS (Hobbs, 1986), when the predicate nn
was first introduced. Similar to conjunction pred-
icates, the nn predicates can have a variable num-
ber of arguments, with the first one representing
the result of the aggregation of the nouns corre-
sponding to the rest of the arguments. Exam-
ples from Table 3 show the transformation of some
complex nominals.
</bodyText>
<sectionHeader confidence="0.979069" genericHeader="method">
3 Logic Form Transformation
Rules
</sectionHeader>
<bodyText confidence="0.814146081632653">
The implementation of LFTs relies on information
provided by the syntactic parser. We have de-
veloped a set of transformation rules that create
predicates and assign them arguments. There are
two classes of rules: (1) intra-phrase and (2) inter-
phrase transformation rules. The intra-phrase
transformation rules generate predicates for ev-
ery noun, verb, adjective or adverb. They also
assign the variables that describe dependencies lo-
cal to the phrase. The inter-phrase transformation
rules provide the arguments of the verb predicates,
preposition predicates and inter-phrasal conjunc-
tions. Verb predicate arguments are identified
by recognizing the syntactic subject and object
of the respective verb, based on a few grammar
rules and relative pronoun interpretation. Depen-
dencies between adjectival (adverbial) phrases and
noun (verb) phrases are predicted based on vicin-
ity. Both intra- and inter-phrase transformation
rules are produced from the parser. Examples of
transformation rules are shown in Table 4.
Implementation
The system consists of several modules: pre-
processing, POS tagging, parsing, rules selection
and logic form transformation. The preprocessing
module extracts definitions from glosses, discards
comments from definitions and eliminates unim-
portant particles. An effort was made to develop
a highly accurate POS tagging dedicated to the
processing of WordNet glosses. By using several
taggers and a voting scheme we can automatically
tag 92.48% with an accuracy of 98.5% and the re-
maining 7.52% words are tagged manually.
Since the logic form transformations rely on the
output of a parser we have developed a highly ac-
curate syntactic parser specialized for WordNet
glosses. Glosses were extended to full sentences.
For example for noun glosses the first word of the
synset followed by be is added to the definition.
For instance the definition of prophet, oracle
becomes Prophet is an authoritative person who
divines the future. Other improvements to the
syntactic parser include the special treatment of
compound concepts and idioms. These improve-
ments led to an over 90% precision in parsing
WordNet glosses. This precision is measured at
constituent level.
The parser output is further transformed to pre-
pare for the derivation of logic forms. Two ba-
</bodyText>
<table confidence="0.999442571428571">
Synset Gloss LFT
{enterprise} (an organization created for organization:n(x2) &amp; create(ei,xi,x2) &amp;
business ventures) for(ei,x3) &amp; nn(x3,x4,x5) &amp; business:n(x4)
&amp; venture:n(x5)
{tax income, taxation, (government income credited to nn(x2,x3,x4) &amp; governmentm(x3) &amp;
tax revenue, revenue} taxation) income:n(x4) &amp; credit:v(ei,xi,x2) &amp;
to(ei,x5) &amp; taxation:n(x5)
</table>
<tableCaption confidence="0.993723">
Table 3: Examples of complex nominal predicates
</tableCaption>
<table confidence="0.995456791666667">
Intra-phrase transformation rules
Rule Transformation(LFT) Gloss Synset
ART ADJi ADJ2 NOUN—›- return:n(x)) &amp; (a hard straight {drive}
noun(xi) &amp; adji(xi) &amp; adj2(xi) hard:a(xi) &amp; return (as in
straight:a(xi) tennis or squash))
ART ADJi AND ADJ2 NOUN—›- light:n(xi) &amp; weak:a(xi) (a weak and {shimmer, play}
noun(xi) &amp; adji(xi) &amp; adj2(xi) &amp; trernulous:a(xi) tremulous light)
VERB ADV—›- cut:v(ei,xi,x2) &amp; (cut open) {slash, gash}
verb(ei,xi,x2) &amp; adv(ei) open:r(ei)
ART NOUNi &apos;S NOUN2—&gt;- body:n(xi) &amp; (a person&apos;s body) {body}
noun2(x1) &amp; nouni(x2) &amp; pos(x1,x2) person:n(x2) &amp; pos(xi,x2)
Inter-phrase transformation rules
Rule Transformation Gloss Synset
VPi CONJVP2 PREP NP—›- or(ei,e2, e3) &amp; (keep or {continue, uphold
coni(ei,e2, e3) &amp; LFT(VP1 (e2,xi,x2)) keep:v(e2,xi ,x2)) &amp; maintain in carry_on,
&amp; LFT(VP2(e3,xi,x2)) &amp; prep(ei,x3) maintain:v(e3,x2,x2)) &amp; unaltered bear_on
&amp; LFT(NP) in(ei,x3) &amp; condition:n(x3) condition) preserve}
&amp; unaltered:a(x3)
NPi VP by NP2 PREP NP3—&gt;- nn(x2,x4,x5) &amp; (a garment closure {fly,
LFT(NP1(x2)) &amp; LFT(VP(ei,xi,x2)) garment:n(x4 (zipper or fly front}
&amp; LFT(NP2(xi)) &amp; prep(xi,x3) &amp; closure:n(x6 buttons)
LFT(NP3(x3)) conceal:v(ei ,xi ,x2) &amp; concealed by a fold
fold:n(xi) &amp; of(xi,x3) of cloth)
&amp; cloth:n(x3)
</table>
<tableCaption confidence="0.999035">
Table 4: Examples of LFT rules
</tableCaption>
<figure confidence="0.85110175">
NP DT JJ NNI NNS I NNP I NNPS
NP DT VBG NNI NNS I NNP I NNPS
NP DT VBN NNI NNS I NNP I NNPS
Base NP
rule
Result
rule
NP JJ NN
</figure>
<bodyText confidence="0.997453315789474">
sic techniques are used: (1) tag reduction and (2)
transformations of parse trees. Tag reduction is
motivated by the simplifications in notation: (1)
determiners are eliminated, (2) plurals are ignored
and we can replace NNS with NN, (3) proper
nouns are treated identically as common nouns
and thus NNP is changed into NN and (4) every-
thing in a prenominal position plays the function
of a modifier. Examples of rule reduction due to
tag reduction are illustrated in Table 5. For verbs
we ignore tenses; VBG, VBP, VBZ, VBN, VB are
all mapped into VB. Keeping the passive informa-
tion is important for syntactic role detection and
thus we add a new tag VP-PASS to indicate that
the head of the VP is passive. Modals and aux-
iliaries are eliminated and negations are ignored.
The second technique consists of rearranging the
parse trees so that more complex structures are
reduced to simpler ones (see Figure 1).
</bodyText>
<tableCaption confidence="0.968683">
Table 5: An example of mapping parser rules into
a simplified rule that becomes a LFT rule
</tableCaption>
<sectionHeader confidence="0.999296" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999844454545455">
To validate our procedure we experimented on a
subset of WordNet 1.6 noun glosses. The set of
rules is formed by taking the most frequent rules
for each grammar phrase detected in a corpus of
10,000 noun glosses randomly selected from the
noun data file of WordNet 1.6. From parse trees
we extract automatically all grammar rules and
their number of occurrences then select the most
frequent ones up to the point where the gain in
coverage is less than 1%. Then we manually de-
rived the LFTs corresponding to the selected rules
</bodyText>
<figure confidence="0.9968795">
NP
NP
NP CC NP
DT
NN CC NN
DT NN
NN
a ruler or institution
institution
a ruler or
</figure>
<table confidence="0.681968166666667">
Colombian(xl) of(xl, x2) &amp; Columbia(x2)
Colombian(x1) relate(el, xl, x2) &amp; Columbia(x2)
Colombian(xl) characteristic(xl) &amp; of(xl, x2) &amp; Columbia(x2)
Colombian(xl) of(xl, x2) &amp; people(x2) &amp; of(x2, x3) &amp; Columbia(x3)
Colombian(xl) relate(el, xl, x2) &amp; people(x2) &amp; of(x2, x3) &amp; Columbia(x3)
Colombian(xl) characteristic(xl) &amp; of(xl, x2) &amp; people(x2) &amp; of(x2, x3) &amp; Columbia(x3)
</table>
<tableCaption confidence="0.940872">
Table 6: Axioms extracted from the gloss of adjective Colombian:a#1: {of or relating to or characteristic
of Colombia or its people}
kill:v#1(e, x, y, z) cause(el, x, y, z) &amp; die(e2, y)
kill:v#1(e, x, y, z) put(e, x, y, w) &amp; to(e, w) &amp; death(w)
Table 7: Axioms extracted from the gloss of verb ki//:v#/ : {cause to die; put to death}
</tableCaption>
<listItem confidence="0.723579">
3. Apply unification on lexical chains.
</listItem>
<bodyText confidence="0.992373909090909">
Once chains are established between a pair of
concepts from the QLF and ALF, the logic form
representation provides us with a mechanism for
performing agreement unification. This checks
the syntactic constraints. Two concepts along the
chain are unified if their predicates and arguments
match. In a successful unification the arguments
of question predicate will be bound to the argu-
ments of answer predicate and the QLF and ALF
updated to reflect the new status of arguments.
Step 0 in Table 8 shows the QLF, respectively
ALF. In step 1, the matching is peformed between
some predicates, e.g. Lucelly_Garcia from QLF,
respectively ALF, and xl is bound to xl&apos; which is
reflected in the new QLF shown in step 1.
4. Extract inferences to provide explana-
tion.
The concepts along those lexical chains that sur-
vive the unification test lead to inferences that ex-
plain the answer. It is only necessary to retrieve
the concepts along the chain and the hypernymy
and axioms explain the relation between them.
</bodyText>
<subsectionHeader confidence="0.959708">
5.3 Examples
</subsectionHeader>
<bodyText confidence="0.948358789473684">
Example 1
Consider the TREC question:
Q045: When did Lucelly Garcia, former ambassador
of Colombia to Honduras, die?
The answer is found in &amp;quot;Several gunmen on a
highway leading to the Colombian city of Ibague
murdered Colombian Ambassador to Honduras
Lucelly Garcia today&amp;quot;. As illustrated in Table 8
at Step 0 we are able to match a few predicates:
Lucelly_Garcia, ambassador, T IME-S TAMP.
With the help of the axioms, chains are found:
from Colombian in the answer to Colombia in
the question, respectively from murder to die
(see Figure 1). For former there was no link
to a concept in the answer and we just ignore
it (as being a modifier of an already matched
predicate ambassador). The ALF in Step 1
shows Colombian expanded with axioms from
WordNet (see Table 6). The new QLF to be
proven contains only the predicate die. Step 2
in Table 8 shows the ALF after the expansion of
murder with its corresponding axiom:
murder(el, xl, z2) kill(e14142) inten-
tionally(el) with(e143) premeditation(x3).
Then Step 3 is derived using: kill(e4142)
cause(e141,e2) die(e242). As explained
earlier, the subject of kill is propagated as
subject of cause and the object of kill, which is
Lucelly_Garcia, as the subject to die. Also, we
replicate the TIME-STAMP predicate to modify
both e2 and e3. The QLF is successfully proven
as it becomes empty.
Example 2
Consider the TREC-9&apos;s question:
Q481: Who shot Billy the Kid?
The Q/A system identifies a few paragraphs that
contain all the keywords from the question and
the answer type. Two such paragraphs are:
</bodyText>
<listItem confidence="0.980603857142857">
• P1: The scene called for Phillips &apos; character
to be saved from a lynching when Billy the
Kid ( Emilio Estevez ) shot the rope in half
just as he was about to be hanged .
• P2: In 1881 , outlaw William H. Bonney Jr.
, alias Billy the Kid , was shot and killed by
Sheriff Pat Garrett in Fort Sumner , N.M.
</listItem>
<bodyText confidence="0.93797775">
The answer is provided by paragraph P2 and
is depicted by the system as follows. Using
LFT, the question has a representation of the
form: Q: PERSON(xl) &amp; shoot(el, xl, z2) &amp;
</bodyText>
<figure confidence="0.989916025">
chain
official:n#1
negotiation:n#1
die:v#1
axiom
axiom
South_America:n#1
change:v#2
derivation chain
chain
official:n#1
hyper
axiom
axiom
axiom
South_America:n#1
hyper
diplomat:n#1
turn:v#3
kill:v#1
Colombia:n#1
pass:v#18
pass:v#18
diplomat:n#1
kill:v#1
hyper
characteristic:a#1
axiom
hyper
axiom
axiom
chain
axiom
axiom
derivation chain
ambassador:n#1 Colombia:n#1 die:v#1
ambassador:n#1 Colombian:a#1 murder:v#1
ground concepts
Answer
Q045
</figure>
<table confidence="0.998017333333333">
Question Initial rank Final rank
Q074 2 1
Q331 2 1
Q381 5 1
Q481 3 1
Q640 2 1
</table>
<tableCaption confidence="0.9609555">
Table 9: Examples of improvements to the TREC-
9 results obtained by the system
</tableCaption>
<table confidence="0.999804666666667">
Q Pairs Paths Chains Concepts Chains
used
006 28 391 161 729 2
034 30 257 20 90 2
045 84 685 223 1025 3
198 24 548 182 858 1
302 54 617 251 1142 4
424 27 472 180 840 2
471 18 447 90 421 1
498 21 157 12 52 2
580 18 467 233 1087 2
719 12 202 81 371 1
</table>
<tableCaption confidence="0.980312">
Table 10: Statistics for 10 questions
</tableCaption>
<bodyText confidence="0.999909133333334">
disambiguation task has been done manually for
the questions, answers and for a set of targeted
glosses. The Pairs of Concepts column illustrates
the number of pairs of concepts from the ques-
tion, respectively answer paragraph (ground con-
cepts). The paths column shows the number of
paths retrieved: these are paths that originate in
the ground concepts, some of which intersect and
form lexical chains. The chains column shows how
many lexical chains were established. The next
column, shows how many concepts were encoun-
tered along those paths. The Chains used column
shows how many chains were selected to perform
unification. In each case, one chain led to the cor-
rect answer.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999979444444444">
We have presented here a procedure to transform
WordNet glosses into logic forms. The notation
used is first order logic and contains syntactic
information as positional arguments. An overall
precision of 81% on 400 WordNet glosses was ob-
tained. The paper demonstrates how WordNet
glosses provide world knowledge axioms essential
for boosting the performance of a Question An-
swering system.
</bodyText>
<sectionHeader confidence="0.997909" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999811255319149">
John Bear and R. Jerry Hobbs. 1988. Localizing ex-
pression of ambiguity. In Proceedings of the Second
Conference on Applied Natural Language Process-
ing, pages 235-242.
R. Bruce and L. Guthrie. 1992. Genus disambigua-
tion: A study in weighted preference. In Proceed-
ings of COLING &apos;92, Nantes, France.
M. Chodorow, R. Byrd, and G. Heidorn. 1985. Ex-
tracting semantic hierarchies from a large on-line
dictionary. In Proceedings of the 23rd Annual Met-
ing of the Association for Computational Linguis-
tics, pages 299-304.
David Davidson. 1967. The logical form of action sen-
tences. In N. Rescher, editor, The Logic of Decision
and Action, pages 81-95. University of Pittsburgh
Press.
Sanda M. Harabagiu, A. George Miller, and Dan I.
Moldovan. 1999. Wordnet 2 - a morphologically
and semantically enhanced resource. In Proceedings
of SICLEX-99, pages 1-8, University of Maryland,
June.
Sanda Harabagiu, Dan Moldovan, Marius Pasca, Rada
Mihalcea, Mihai Surdeanu, Razvan Bunescu, Rox-
ana Girju, Vasile Rus, and Paul Morarescu. 2000.
FALCON: Boosting knowledge for answer engines.
In Proceedings of the Text Retrieval Conference
(TREC-9), November.
Jerry R. Hobbs. 1986. Overview of the tacitus project.
Computational Linguistics, 12(3).
ISI. 1998. http://www.isi.edu/natural-
language/dpp/.
George Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39-
41.
NIST. 2000. National institute for science and tech-
nology. http://trec.nist.gov.
Stephen D. Richardson, William B. Dolan, and Lucy
Vanderwende. 1998. Mindnet: acquiring and struc-
turing semantic information from text. In Proceed-
ings of COLING &apos;98.
G. Rigau, H. Rogdriguez, and E. Agirre. 1998. Build-
ing accurate semantic taxonomies from monolingual
mrds. In Proceedings of COLING-ACL&apos;98, Mon-
treal, Canada.
Y.A. Wilks, B.M. Slator, and L.M. Guthrie.
1996. Electric Words- Dictionaries, Computers and
Meanings. The MIT Press.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973447">
<title confidence="0.997456">Logic Form Transformation of WordNet and its Applicability to Question Answering</title>
<author confidence="0.998925">Dan I Moldovan</author>
<author confidence="0.998925">Vasile Rus</author>
<affiliation confidence="0.997139">Department of Computer Science and Engineering Southern Methodist University</affiliation>
<address confidence="0.99696">Dallas, TX 75275-0122</address>
<email confidence="0.99965">moldovanAseas.smu.edu</email>
<email confidence="0.99965">vasileAseas.smu.edu</email>
<abstract confidence="0.99859125">WordNet is a rich source of world knowledge from which formal axioms can be derived. In this paper we present a method for transforming the WordNet glosses into logic forms and further into axioms. The transformation of Word- Net glosses into logic forms is useful for theorem proving and other applications. The paper demonstrates the utility of the WordNet axioms in a question answering system to rank and extract answers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bear</author>
<author>R Jerry Hobbs</author>
</authors>
<title>Localizing expression of ambiguity.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second Conference on Applied Natural Language Processing,</booktitle>
<pages>235--242</pages>
<contexts>
<context position="9593" citStr="Bear and Hobbs, 1988" startWordPosition="1476" endWordPosition="1479">x3) &amp; vaIue:n(x3) &amp; for(x3,x4) &amp; payment:n(x4) {pitching} (playing the position of pitcher playing:n(ei,xi,x2) &amp; position :n (x2) &amp; of(x2,x3) on a baseball team) &amp; pitchern(x3) on(ei,x4) &amp; baseball_team:n(x4) Table 2: Examples of preposition predicates encountered in the gloss. The preposition predicates always have two arguments: the first argument corresponding to the predicate of the head of the phrase to which prepositional phrase is attached, whereas the second argument corresponds to the prepositional object. This predicative treatment of prepositional attachments was first reported in (Bear and Hobbs, 1988). Table 2 shows some examples of preposition predicates. Complex nominals Many complex nominals are encoded currently in WordNet as synset entries comprising several words, known as WordNet collocations (e.g. flea market, baseball team, joint venture). Still, many compound nouns are not encoded as WordNet entries, and need to be recognized as a single nominal. The way of doing this was first devised in TACITUS (Hobbs, 1986), when the predicate nn was first introduced. Similar to conjunction predicates, the nn predicates can have a variable number of arguments, with the first one representing t</context>
</contexts>
<marker>Bear, Hobbs, 1988</marker>
<rawString>John Bear and R. Jerry Hobbs. 1988. Localizing expression of ambiguity. In Proceedings of the Second Conference on Applied Natural Language Processing, pages 235-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>L Guthrie</author>
</authors>
<title>Genus disambiguation: A study in weighted preference.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING &apos;92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="4347" citStr="Bruce and Guthrie, 1992" startWordPosition="674" endWordPosition="677">ise would be unfeasible. We have not noticed that these simplifications had any adverse effect on the TREC questions. 1.4 Related Work This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the </context>
</contexts>
<marker>Bruce, Guthrie, 1992</marker>
<rawString>R. Bruce and L. Guthrie. 1992. Genus disambiguation: A study in weighted preference. In Proceedings of COLING &apos;92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chodorow</author>
<author>R Byrd</author>
<author>G Heidorn</author>
</authors>
<title>Extracting semantic hierarchies from a large on-line dictionary.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meting of the Association for Computational Linguistics,</booktitle>
<pages>299--304</pages>
<contexts>
<context position="4299" citStr="Chodorow et al., 1985" startWordPosition="668" endWordPosition="671">nd consistent logic representation that otherwise would be unfeasible. We have not noticed that these simplifications had any adverse effect on the TREC questions. 1.4 Related Work This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and seman</context>
</contexts>
<marker>Chodorow, Byrd, Heidorn, 1985</marker>
<rawString>M. Chodorow, R. Byrd, and G. Heidorn. 1985. Extracting semantic hierarchies from a large on-line dictionary. In Proceedings of the 23rd Annual Meting of the Association for Computational Linguistics, pages 299-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Davidson</author>
</authors>
<title>The logical form of action sentences.</title>
<date>1967</date>
<booktitle>The Logic of Decision and Action,</booktitle>
<pages>81--95</pages>
<editor>In N. Rescher, editor,</editor>
<publisher>University of Pittsburgh Press.</publisher>
<contexts>
<context position="5231" citStr="Davidson, 1967" startWordPosition="813" endWordPosition="814"> Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolled in an educational institution). It will contain the predicates learner:n, enroll:v and educational_institution:n. Fix slot-allocation In the spirit of the Davidsonian treatment of the action predicates (Davidson, 1967), all verb predicates (as well as the nominalizations representing actions, events or states) have three arguments: action/state/event-predicate(e,xi,x2), where: • e represents the eventuality of the action, state or event stated by the verb to take place, • x1 represents the syntactic subject of the action, event or state, and • x2 represents the syntactic direct object of the action, event or state. For example, the LFT of (a person who backs a politician), the gloss of {supporter, protagonist, champion, admirer, booster, friend} is: [person:n(xi) &amp; back:v(ei,xi,x2) &amp; politician:n(x2) ]. Sev</context>
</contexts>
<marker>Davidson, 1967</marker>
<rawString>David Davidson. 1967. The logical form of action sentences. In N. Rescher, editor, The Logic of Decision and Action, pages 81-95. University of Pittsburgh Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>A George Miller</author>
<author>Dan I Moldovan</author>
</authors>
<title>Wordnet 2 - a morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In Proceedings of SICLEX-99,</booktitle>
<pages>1--8</pages>
<institution>University of Maryland,</institution>
<contexts>
<context position="3950" citStr="Harabagiu et al., 1999" startWordPosition="619" endWordPosition="622">ntricate syntactic explanations, and the desire for efficient deductions in favor of a simpler notation closer to English. For the logic representation of WordNet glosses we ignore: plurals and sets, verb tenses, auxiliary verbs, quantifiers and modal operators, comparatives and negation. This decision is based on our desire to provide manageable and consistent logic representation that otherwise would be unfeasible. We have not noticed that these simplifications had any adverse effect on the TREC questions. 1.4 Related Work This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus</context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>Sanda M. Harabagiu, A. George Miller, and Dan I. Moldovan. 1999. Wordnet 2 - a morphologically and semantically enhanced resource. In Proceedings of SICLEX-99, pages 1-8, University of Maryland, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Dan Moldovan</author>
<author>Marius Pasca</author>
<author>Rada Mihalcea</author>
<author>Mihai Surdeanu</author>
<author>Razvan Bunescu</author>
<author>Roxana Girju</author>
<author>Vasile Rus</author>
<author>Paul Morarescu</author>
</authors>
<title>FALCON: Boosting knowledge for answer engines.</title>
<date>2000</date>
<booktitle>In Proceedings of the Text Retrieval Conference (TREC-9),</booktitle>
<marker>Harabagiu, Moldovan, Pasca, Mihalcea, Surdeanu, Bunescu, Girju, Rus, Morarescu, 2000</marker>
<rawString>Sanda Harabagiu, Dan Moldovan, Marius Pasca, Rada Mihalcea, Mihai Surdeanu, Razvan Bunescu, Roxana Girju, Vasile Rus, and Paul Morarescu. 2000. FALCON: Boosting knowledge for answer engines. In Proceedings of the Text Retrieval Conference (TREC-9), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Overview of the tacitus project.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="3223" citStr="Hobbs, 1986" startWordPosition="509" endWordPosition="510">lied, the glosses are passed through a preprocessing phase consisting of tokenization, part-of-speech tagging and syntactic parsing. 1.3 Approach There are two criteria that guide our approach: (1) the notation be as close as possible to English, and (2) the notation be syntactically simple. Our approach is to derive the LFT directly from the output of the syntactic parser. The parser resolves the structural and syntactic ambiguities. This way, we avoid the very hard problems of logic representation of natural language. We follow closely the successful representation used by Hobbs in TACITUS (Hobbs, 1986). Hobbs explains that for many linguistic applications it is acceptable to relax ontological scruples, intricate syntactic explanations, and the desire for efficient deductions in favor of a simpler notation closer to English. For the logic representation of WordNet glosses we ignore: plurals and sets, verb tenses, auxiliary verbs, quantifiers and modal operators, comparatives and negation. This decision is based on our desire to provide manageable and consistent logic representation that otherwise would be unfeasible. We have not noticed that these simplifications had any adverse effect on th</context>
<context position="10020" citStr="Hobbs, 1986" startWordPosition="1545" endWordPosition="1546">se is attached, whereas the second argument corresponds to the prepositional object. This predicative treatment of prepositional attachments was first reported in (Bear and Hobbs, 1988). Table 2 shows some examples of preposition predicates. Complex nominals Many complex nominals are encoded currently in WordNet as synset entries comprising several words, known as WordNet collocations (e.g. flea market, baseball team, joint venture). Still, many compound nouns are not encoded as WordNet entries, and need to be recognized as a single nominal. The way of doing this was first devised in TACITUS (Hobbs, 1986), when the predicate nn was first introduced. Similar to conjunction predicates, the nn predicates can have a variable number of arguments, with the first one representing the result of the aggregation of the nouns corresponding to the rest of the arguments. Examples from Table 3 show the transformation of some complex nominals. 3 Logic Form Transformation Rules The implementation of LFTs relies on information provided by the syntactic parser. We have developed a set of transformation rules that create predicates and assign them arguments. There are two classes of rules: (1) intra-phrase and (</context>
</contexts>
<marker>Hobbs, 1986</marker>
<rawString>Jerry R. Hobbs. 1986. Overview of the tacitus project. Computational Linguistics, 12(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>ISI</author>
</authors>
<date>1998</date>
<note>http://www.isi.edu/naturallanguage/dpp/.</note>
<contexts>
<context position="4498" citStr="ISI, 1998" startWordPosition="699" endWordPosition="700">project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolled in an educational institution). It will contain the predicates learner:n, enroll:v an</context>
</contexts>
<marker>ISI, 1998</marker>
<rawString>ISI. 1998. http://www.isi.edu/naturallanguage/dpp/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<pages>38--11</pages>
<contexts>
<context position="1346" citStr="Miller, 1995" startWordPosition="217" endWordPosition="218">greed that world knowledge is necessary for many common sense reasoning problems. In this paper we argue that WordNet is an important source of world knowledge and show how this knowledge can be put to work for open-domain Question Answering systems. Consider the TREC-QA question (NIST, 2000): Q198: How did Socrates die? The answer to this question appears in the text &amp;quot;...Socrates&apos; death came when he chose to drink poisoned wine...&amp;quot;. To prove that this is a plausible answer one needs to know that drinking poisoned wine may be a cause of death. This extra knowledge is found in WordNet glosses (Miller, 1995). The gloss of concept poison:v#2 (the second sense of verb poison) contains {kill with poison} and the first sense of verb ki//74/ is {cause to die}, which collectively justify the answer. This paper presents a simple but consistent logic notation suitable for representing the English texts of the WordNet glosses. The WordNet logic forms supply us with a rich set of axioms essential for boosting the performance of a Question Answering system. 1.2 Research Goal The goal of this research project is to transform all the WordNet glosses into logic representations that enables reasoning mechanisms</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>National institute for science and technology.</title>
<date>2000</date>
<note>http://trec.nist.gov.</note>
<contexts>
<context position="1026" citStr="NIST, 2000" startWordPosition="160" endWordPosition="161">gic forms and further into axioms. The transformation of WordNet glosses into logic forms is useful for theorem proving and other applications. The paper demonstrates the utility of the WordNet axioms in a question answering system to rank and extract answers. 1 Introduction 1.1 Motivation It is well understood and agreed that world knowledge is necessary for many common sense reasoning problems. In this paper we argue that WordNet is an important source of world knowledge and show how this knowledge can be put to work for open-domain Question Answering systems. Consider the TREC-QA question (NIST, 2000): Q198: How did Socrates die? The answer to this question appears in the text &amp;quot;...Socrates&apos; death came when he chose to drink poisoned wine...&amp;quot;. To prove that this is a plausible answer one needs to know that drinking poisoned wine may be a cause of death. This extra knowledge is found in WordNet glosses (Miller, 1995). The gloss of concept poison:v#2 (the second sense of verb poison) contains {kill with poison} and the first sense of verb ki//74/ is {cause to die}, which collectively justify the answer. This paper presents a simple but consistent logic notation suitable for representing the E</context>
</contexts>
<marker>NIST, 2000</marker>
<rawString>NIST. 2000. National institute for science and technology. http://trec.nist.gov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen D Richardson</author>
<author>William B Dolan</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Mindnet: acquiring and structuring semantic information from text.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING &apos;98.</booktitle>
<contexts>
<context position="4463" citStr="Richardson et al., 1998" startWordPosition="691" endWordPosition="694">. 1.4 Related Work This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolled in an educational institution). It will contain th</context>
</contexts>
<marker>Richardson, Dolan, Vanderwende, 1998</marker>
<rawString>Stephen D. Richardson, William B. Dolan, and Lucy Vanderwende. 1998. Mindnet: acquiring and structuring semantic information from text. In Proceedings of COLING &apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Rigau</author>
<author>H Rogdriguez</author>
<author>E Agirre</author>
</authors>
<title>Building accurate semantic taxonomies from monolingual mrds.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL&apos;98,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="4485" citStr="Rigau et al., 1998" startWordPosition="695" endWordPosition="698">k is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolled in an educational institution). It will contain the predicates learner:n</context>
</contexts>
<marker>Rigau, Rogdriguez, Agirre, 1998</marker>
<rawString>G. Rigau, H. Rogdriguez, and E. Agirre. 1998. Building accurate semantic taxonomies from monolingual mrds. In Proceedings of COLING-ACL&apos;98, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
<author>B M Slator</author>
<author>L M Guthrie</author>
</authors>
<title>Electric Words- Dictionaries, Computers and Meanings.</title>
<date>1996</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="4411" citStr="Wilks et al., 1996" startWordPosition="682" endWordPosition="685">ns had any adverse effect on the TREC questions. 1.4 Related Work This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999). Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster&apos;s 2nd International Dictionary (W2). Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998). All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies. 2 LFT Definitions Predicates A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss. The name of the predicate is a concatenation of the morpheme&apos;s base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation. For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolle</context>
</contexts>
<marker>Wilks, Slator, Guthrie, 1996</marker>
<rawString>Y.A. Wilks, B.M. Slator, and L.M. Guthrie. 1996. Electric Words- Dictionaries, Computers and Meanings. The MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>