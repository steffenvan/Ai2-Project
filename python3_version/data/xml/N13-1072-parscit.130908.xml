<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018061">
<title confidence="0.991887">
Automatic Generation of English Respellings
</title>
<author confidence="0.996009">
Bradley Hauer and Grzegorz Kondrak
</author>
<affiliation confidence="0.998731">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.631668">
Edmonton, Alberta, Canada, T6G 2E8
</address>
<email confidence="0.998401">
{bmhauer,gkondrak}@ualberta.ca
</email>
<sectionHeader confidence="0.993886" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908466666667">
A respelling is an alternative spelling of a
word in the same writing system, intended to
clarify pronunciation. We introduce the task
of automatic generation of a respelling from
the word’s phonemic representation. Our ap-
proach combines machine learning with lin-
guistic constraints and electronic resources.
We evaluate our system both intrinsically
through a human judgment experiment, and
extrinsically by passing its output to a letter-
to-phoneme converter. The results show that
the respellings generated by our system are
better on average than those found on the Web,
and approach the quality of respellings de-
signed by an expert.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891660377359">
Respellings are a widely employed method of con-
veying the pronunciation of English and foreign
words, both in print and on the Web. For example,
Huatulco, the name of a Mexican resort, is respelled
as ‘wah-tool-koh’ in a travel guide (Noble, 2012).
The advantage of using respellings lies in removing
the need for a separately defined phonetic transcrip-
tion system. Since they contain only the letters of
the Latin alphabet, their phonetic interpretation re-
lies exclusively on orthographic intuitions of read-
ers. For this reason, respellings are widely used in
travel phrase books, medical compendia, and drug
name pronunciation guides, among others.
Despite their utility, good respellings are not easy
to create. Respellings found on the Web often con-
tain errors or ambiguities. For example, Henoch-
Schoenlein purpura, a skin disease, is respelled both
as ‘heh-nok shoon-line purr-puh-ruh’ and ‘hen-awk
sher-line purr-purr-ah’. Does ‘heh’ rhyme with eh
[e] or with Nineveh [a], or is it the same vowel as
in hen [e]? Clearly, if both respellings refer to the
same pronunciation, at least one of them must be
wrong. In addition, converting the pronunciation of
a foreign name to English phonemes is in itself a
non-trivial task.
In this paper, we focus on the task of generating
respellings from the intended pronunciation given as
a sequence of phonemes. We develop a stand-alone
system that combines linguistic knowledge and re-
sources with machine learning models trained on
data mined from the Web and electronic dictionar-
ies. One of our ultimate objectives is to aid writ-
ers by evaluating their respellings, improving them,
or generating new candidates. Accordingly, we en-
deavour to maintain the generation and the evalua-
tion stages as separate modules in our system.
The evaluation of respellings is a challenging
problem. Since English spelling conventions are no-
toriously inconsistent, there is no algorithm for ac-
curately predicting the pronunciation of an out-of-
vocabulary word. The current state-of-the-art letter-
to-phoneme (L2P) converters are typically reported
with 10-30% error rates on dictionary words (Bisani
and Ney, 2008). On the other hand, human read-
ers often disagree on the details of the pronunciation
implied by a respelling. In this paper, we conduct
two kinds of evaluations: an automated verification
with an independent L2P system, and an experiment
with human participants that pass judgments on dif-
ferent respellings of the same word. We interpret
the results as evidence that the output of our system
compares favourably with typical respellings found
on the Web.
</bodyText>
<page confidence="0.982408">
634
</page>
<note confidence="0.522962">
Proceedings of NAACL-HLT 2013, pages 634–643,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.883345" genericHeader="introduction">
2 Definitions and Conventions
</sectionHeader>
<bodyText confidence="0.999823857142857">
Although Chomsky and Halle (1968) characterize
English orthography as close to optimal, Kominek
and Black (2006) estimate that it is about 3 times
more complex than German, and 40 times more
complex than Spanish. This is confirmed by
lower accuracy of letter-to-phoneme systems on En-
glish (Bisani and Ney, 2008). A survey of English
spelling (Carney, 1994) devotes 120 pages to de-
scribe phoneme-to-letter correspondences, and lists
226 letter-to-phoneme rules, almost all of which ad-
mit exceptions.
There is no consensus on how to best convey the
pronunciation of an uncommon word in English.
Most dictionaries employ either the International
Phonetic Alphabet (IPA), or their own transcription
schemes that incorporate special symbols and dia-
critics. Unfortunately, many readers are unfamiliar
with phonetic transcription. Instead, respellings are
often preferred by writers in the news and on the
Web. In this section, we define the respelling task in
detail.
</bodyText>
<subsectionHeader confidence="0.988578">
2.1 Form of Respellings
</subsectionHeader>
<bodyText confidence="0.992466022222222">
A respelling is a non-standard spelling of a word,
that is intended to better convey its pronunciation.
We assume that the pronunciation is defined as a se-
quence of English phonemes, and that the respelling
contains only the 26 letters of the alphabet, with
optional hyphenation. Some transcription schemes
combine respellings with special symbols for repre-
senting certain phonemes. For example, an other-
wise purely alphabetic Wikipedia scheme employs
the symbol a for the vowel schwa. In our opin-
ion, such devices destroy the main advantage of re-
spellings, which is their universality, without attain-
ing the precision of a true phonetic transcription. In
fact, Fraser (1997) identifies the schwa symbol as
the cause of many pronunciation errors.
In our system, we consistently use hyphens to
segment multi-syllable respellings. Each syllable-
size segment contains the representation of exactly
one vowel phoneme, so that the number of segments
matches the number of syllables.1 However, the hy-
phenation need not correspond exactly to the actual
1Henceforth, we refer to “syllable-size segments” simply as
“syllables”.
syllable breaks. This approach has several advan-
tages. First, individual syllables are easier to pro-
nounce than an entire unfamiliar word. Second, hy-
phens limit the context that affects the pronuncia-
tion of a given letter (e.g. th in Beethoven ‘bayt-
hoe-ven’). Finally, hyphens indicate whether adja-
cent vowel letters, such as oe in ‘hoe’, represent one
vowel phoneme or two.
Some respellings explicitly indicate the stressed
syllable by expressing it in a different font. This is
potentially helpful because unstressed vowels tend
to be reduced, which changes their pronunciation.
However, since the vowel reduction phenomenon is
by no means universal, the readers may be unsure
whether to apply it to, e.g. the final o in ‘KWAT-
ro’. In this paper, we make no distinction between
stressed and unstressed syllables; instead, we follow
the principle that each syllable is to be pronounced
as if it was a separate word. Nonetheless, it would be
straightforward to project the stress indicators onto
the appropriate syllables in the respellings generated
by our system.
</bodyText>
<subsectionHeader confidence="0.999939">
2.2 Quality of Respellings
</subsectionHeader>
<bodyText confidence="0.9999175">
There is no clear-cut distinction between good and
bad respellings. The quality of a respelling is more
of a subjective opinion rather than a verifiable fact.
We propose to evaluate it according to the follow-
ing three criteria: ambiguity, correctness, and pref-
erence.
A respelling is ambiguous if it is perceived as
compatible with more than one pronunciation. Be-
cause most of the rules of English spelling have ex-
ceptions, it is rarely possible to demonstrate that
a respelling is completely unambiguous. How-
ever, some respellings are clearly more ambiguous
than others. For example, the digraph ee almost
always represents the vowel [i], whereas the let-
ter sequence ough can represent several different
phonemes.2 Respellings that contain highly ambigu-
ous letter-phoneme mappings can be expected to be
ambiguous themselves. Ambiguity is a property of a
respelling itself, regardless of the intended pronun-
ciation.
A respelling is correct if it accurately conveys the
intended pronunciation to the reader. Unlike the am-
</bodyText>
<footnote confidence="0.980053">
2Compare bough, cough, dough, tough, lough, through.
</footnote>
<page confidence="0.998537">
635
</page>
<bodyText confidence="0.999913777777778">
biguity, correctness can be verified objectively for
a particular reader, by comparing the intended pro-
nunciation with the pronunciation inferred by the
reader. A respelling that is judged correct with re-
spect to one pronunciation cannot be judged correct
with respect to a different pronunciation. Never-
theless, it is entirely possible that different readers
will derive different pronunciations from the same
respelling.
A respelling can be classified as unambiguous
and yet incorrect by a given reader, but it cannot
be judged as simultaneously ambiguous and cor-
rect. Indeed, an ambiguous respelling is compatible
with at least two pronunciations, only one of which
can be the intended pronunciation. Therefore, for
a given reader, unambiguity is a necessary but not
sufficient condition for correctness.
Given two unambiguous and correct respellings,
a reader may prefer one over the other, perhaps be-
cause of the ease of inferring the intended pronun-
ciation. For example, ‘rode-ease-yew’ maybe pre-
ferred to ‘roh-dee-zyoo’ because the former is en-
tirely composed of actual English words with unique
pronunciation, whereas the latter contains an un-
usual consonant cluster zy. Preference is also ex-
pressed implicitly if only one of the alternative re-
spellings is judged as unambiguous (or correct),
</bodyText>
<sectionHeader confidence="0.999956" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.99997452">
Fraser (1997) describes an experiment in which 15
human subjects were asked to pronounce uncom-
mon words after being shown a representation of
their pronunciation. The respellings designed by the
author were much more effective for that purpose
than either the IPA phonetic transcription or phone-
mic respelling (Section 4.3). However, the creation
of respellings was described as labour-intensive, and
at least one of them was found to be sub-optimal dur-
ing the experiment.
Williams and Jones (2008) propose respellings as
a way of extending pronunciation lexicons by infor-
mants who lack linguistic training. Galescu (2009)
reports that the addition of respellings of medical
terms from an on-line dictionary improves the ac-
curacy of an L2P system. The author identifies an
automatic pronunciation-to-respelling system as fu-
ture work.
Ghoshal et al. (2009) extract a large number of re-
spellings from the Web, and show that they can be
exploited to improve the accuracy of the L2P con-
version by supplementing the data in pronunciation
dictionaries. Can et al. (2009) further analyze the ef-
fect of using respellings on the accuracy of spoken-
term detection (STD) systems.
</bodyText>
<sectionHeader confidence="0.999762" genericHeader="method">
4 Direct Methods
</sectionHeader>
<bodyText confidence="0.999405666666667">
In this section, we discuss three direct methods of
generating respellings: manual design, dictionary
lookup, and phonemic respelling.
</bodyText>
<subsectionHeader confidence="0.986949">
4.1 Manual Design
</subsectionHeader>
<bodyText confidence="0.99998575">
Respellings found on the Web and in news articles
are usually ad-hoc creations of the authors of those
texts. Respellings designed by different writers for
the same word are rarely identical.3 The quality of
Web respellings vary.
The respellings found in specialized lexicons are
more likely to be designed by experts, and are of-
ten guided by a set of respelling rules. Nevertheless,
such respelling guides may also be ambiguous.4 Re-
gardless of the source, since respellings are often
used for names and foreign words, no lexicon can
be expected to provide a complete coverage.
</bodyText>
<subsectionHeader confidence="0.991536">
4.2 Dictionary Lookup
</subsectionHeader>
<bodyText confidence="0.999976866666667">
Pronunciation dictionaries can be helpful in gener-
ating respellings. Assuming that we have a method
of dividing pronunciations into syllables, a complete
respelling of an out-of-dictionary word can in some
cases be automatically derived from the list of syl-
lable pronunciations. For example, hyphy can be re-
spelled as ‘high-fee’ by following such a procedure.
If each of the syllables has a unique pronunciation,
such respellings are arguably both unambiguous and
correct.
Unfortunately, only a subset of potential phone-
mic syllables actually occur in a lexicon. Consider-
ing only the syllables of the CVC type (consonant-
vowel-consonant), there are over ten thousand dis-
tinct possibilities (e.g., [beb], [bef], etc.), of which
</bodyText>
<footnote confidence="0.9992965">
3For example, the word capoeira is represented by 99 dif-
ferent respellings in the corpus of Ghoshal et al. (2009).
4For an example of a confusing respelling guide see http:
//www.ama-assn.org/go/usan.
</footnote>
<page confidence="0.997939">
636
</page>
<bodyText confidence="0.999923">
fewer than three thousand can be found in the Com-
bilex pronunciation dictionary (Richmond et al.,
2009). While the dictionary lookup may produce
attractive respellings, it is not sufficient for a stand-
alone use.
</bodyText>
<subsectionHeader confidence="0.99921">
4.3 Phonemic Respelling
</subsectionHeader>
<bodyText confidence="0.999970033333333">
A simple method that can produce a respelling for
any word is to directly map each phoneme to a par-
ticular letter or a letter sequence that is frequently
used to represent that phoneme. Phonemes such as
[m], [d] and [f] are indeed closely associated with in-
dividual letters. This is not surprising since the Ro-
man letters were originally created to represent sin-
gle phonemes in Latin, and some of those phonemes
also exist in English. However, many phonemes, es-
pecially vowels, have no obvious orthographic rep-
resentation. One solution is to use digraphs such as
ee and aw, but a number of phonemes, such as [aU]
as in loud, have no mappings that work in all con-
texts.
The principal weakness of a phonemic respelling
is its inflexibility, which often results in counter-
intuitive respellings. For example, many readers are
baffled by respelling such as ‘gee’ for ghee or ‘john’
for Joan. Phonemic respelling tends to fail in cases
where it generates a sequence of letters that is inher-
ently ambiguous, or which pronunciation changes
because of the context. On the other hand, mappings
such as uu for [U] and ahy for [aI], which never oc-
cur in real English words, are difficult to interpret
for some readers.
In this paper, we adopt a context-free phonemic
respelling scheme as the baseline, with the mappings
from the online dictionary Dictionary.com, which
differs from the system used in Wikipedia only in
a few details.
</bodyText>
<sectionHeader confidence="0.967509" genericHeader="method">
5 Candidate Generation
</sectionHeader>
<bodyText confidence="0.9998775">
In this section, we present our syllabification ap-
proach, as well as two generation modules: a trained
phoneme-to-letter (P2L) model and a rule-based re-
speller.
</bodyText>
<subsectionHeader confidence="0.98842">
5.1 Syllabification
</subsectionHeader>
<bodyText confidence="0.9988055">
Our respelling generation process is for the most
part performed on the level of individual syllables.
</bodyText>
<figure confidence="0.562323833333333">
VOWEL ONSET LAX CODA
nt *
ndan *
bæ *
danm *
bæn
</figure>
<tableCaption confidence="0.980292">
Table 1: Examples of syllables that violate phonotactic
constraints.
</tableCaption>
<bodyText confidence="0.999795405405405">
Correct syllabification is by itself a non-trivial prob-
lem, but even if it was provided by an oracle, it might
not correspond to the optimal segmentation of a re-
spelling. For example, the word trigonal [trIganal]
is usually syllabified as tri-go-nal, but a better seg-
mentation for the purposes of respelling is trig-on-
al. We adopt an overgenerate-and-rank approach,
whereby instead of committing to a specific word
segmentation at the start of the process, we process
multiple syllabification alternatives in parallel, one
of which is ultimately selected at the respelling eval-
uation stage.
Ideally, syllabification should conform to the
phonotactic constraints of English, so that the result-
ing respellings are easy to pronounce. The conso-
nant sonority should be rising in onsets, and falling
in codas (Kenstowicz, 1994). We verify that sylla-
bles follow the sonority principle by following the
formulation of Bartlett et al. (2009). The sonor-
ity constraints are not tested at the boundaries of
the word, which are independent of the syllabifica-
tion choice. We also incorporate another important
principle of English phonotactics that asserts that
lax vowels do not occur in open syllables (Rogers,
2000).
In our implementation, each candidate syllable is
tested with respect to the following sequence of four
violable constraints, ordered from the strongest to
the weakest: (1) the syllable contains exactly one
vowel phoneme; (2) the onset satisfies the sonority
principle; (3) if the nucleus contains a lax vowel (ex-
cept a), the coda is non-empty; (4) the coda satis-
fies the sonority principle. For a syllabification to be
accepted, all its syllables must satisfy the four con-
straints. However, if this results in rejection of all
possible syllabifications, the constraints are gradu-
ally relaxed starting from the weakest.
</bodyText>
<page confidence="0.992794">
637
</page>
<bodyText confidence="0.999798833333333">
As an example, consider the word abandonment
[abændanmant], which has 18 different syllabifica-
tions satisfying the VOWEL constraint (Table 1). 8
of the 18 satisfy the ONSET constraint as well, but
only two syllabifications satisfy all four constraints:
[ab-æn-dan-mant] and [a-bæn-dan-mant].
</bodyText>
<subsectionHeader confidence="0.997365">
5.2 P2L Generator
</subsectionHeader>
<bodyText confidence="0.999986195652174">
The respelling problem can be viewed as a string
transduction problem, with the transduction occur-
ring between phonemes and letters. As such, it is di-
rectly related to the well-studied letter-to-phoneme
conversion task. The difference is that the letters
may not conform to the standard orthography of
English. If we had a sufficiently large training set
of pronunciation-respelling pairs, we could train a
machine learning algorithm to directly generate re-
spellings for any strings of English phonemes. How-
ever, such a training set is not readily available. The
respellings in the corpus collected by Ghoshal et al.
(2009) are not easily matched to the phonetic tran-
scriptions, and few of them can be found in elec-
tronic pronunciation dictionaries. In addition, the
quality of Web respellings vary greatly.
In place of a direct pronunciation-to-respelling
model, we aim to model the orthographic intuitions
of readers by deriving a phoneme-to-letter (P2L)
transduction model from an English pronunciation
dictionary. A possible criticism of such an approach
is that our model may create ambiguous respellings,
which abound in English orthography. However, we
rely on a separate evaluation module to identify and
filter ambiguous respellings at a later stage.
Our systems utilizes the DIRECTL+ program (Ji-
ampojamarn et al., 2008), which was originally de-
signed for L2P conversion. Since our basic unit is
the syllable, rather than the word, we train our P2L
model on a set of of 4215 pairs of monosyllabic
words and their pronunciations extracted from the
Combilex dictionary. We exclude syllables in multi-
syllabic words from training because their pronunci-
ation is often affected by context. This is consistent
with our expectation that the reader will pronounce
each hyphen-delimited segment of the respelling as
if it was an individual word.
Since the P2L training data consists of a relatively
small set of syllables, we ensure that the phoneme-
letter alignment is highly accurate. As a preprocess-
ing step, we replace the letter x with ks, and we con-
vert digraphs, such as ch and th, to single symbols.
The alignment is performed by M2M-ALIGNER (Ji-
ampojamarn et al., 2007), under the restriction that
each phoneme is matched to either one or two letter
symbols.
</bodyText>
<subsectionHeader confidence="0.995965">
5.3 Context-Sensitive Respeller
</subsectionHeader>
<bodyText confidence="0.999991321428572">
A hand-crafted context-sensitive respeller is in-
tended to complement the trained P2L model de-
scribed in the previous section. It is similar to to
the phonemic respelling approach described in Sec-
tion 4.3 in that it converts each phoneme to a letter
sequence. However, the mappings depend on adja-
cent phonemes, as well as on the CV pattern of the
current syllable. In addition, more than one map-
ping for a phoneme can be proposed. We designed
the mappings by analyzing their frequency and con-
sistency in pronunciation dictionaries.
The process of candidate generation involves es-
tablishing the pattern of consonants in the input syl-
lable. The consonant mappings are the same as in
the baseline, except for [g] and [9], while the vowels
yield up to three different letter sequences. For ex-
ample, [o] is mapped to oh as a default, but also to o
if both onset and coda are empty, or to o followed by
a consonant and a silent e if the coda is composed of
a single consonant. So, given the syllable [tok] as in-
put, the respeller produces two candidates: tohk and
toke.
We make no claims about the completeness or op-
timality of the mappings, but in our development
experiments we observed that the context-sensitive
respeller contributes to the robustness of our sys-
tem, and in some cases produces more attractive re-
spellings that the P2L model.
</bodyText>
<sectionHeader confidence="0.989549" genericHeader="method">
6 Candidate Selection
</sectionHeader>
<bodyText confidence="0.999944875">
We aim at developing a stand-alone method for the
assessment of respellings that could be applied re-
gardless of their origin. We consider two criteria:
correctness, which is evaluated against the intended
pronunciation, and ambiguity, which is a property of
the respelling itself. As was the case in the genera-
tion stage, the evaluation is performed at the level of
syllables.
</bodyText>
<page confidence="0.996695">
638
</page>
<subsectionHeader confidence="0.988132">
6.1 L2P Correctness Filter
</subsectionHeader>
<bodyText confidence="0.99978205882353">
The principal method of verifying the correctness
of a respelling involves the application of a letter-
to-phoneme (L2P) model trained on the word-
pronunciation pairs extracted from an English dic-
tionary. The generated pronunciation of each sylla-
ble is compared against its intended pronunciation;
if any of the syllables fail the test, the entire re-
spelling is rejected.
The L2P model is derived using the DIRECTL+
system. The main difference between the L2P model
described in this section and the P2L model from
Section 5.2 is that the input and output data are re-
versed. However, the L2P model is not simply a mir-
ror image of the P2L model. Often the phonemic
output of the composition of the two models is dif-
ferent from the initial phonemic input; e.g., [ro] —*
row —* [raU]. This is because the intermediate ortho-
graphic string may be ambiguous. Furthermore, the
L2P model is also intended to test the correctness of
respellings that were generated with other methods.
Other differences between the two models per-
tain to the preprocessing of the training data, and
the letter-to-phoneme alignment. As with the P2L
model, the training data consists of a set of mono-
syllabic words from the Combilex dictionary. How-
ever, in order to make our correctness filter more
conservative, we also remove all words that con-
tain diacritics (e.g., crêpe), non-English phonemes
(e.g., avant), or silent consonants (e.g., limn). The
alignment is restricted to matching each letter sym-
bol to at most one phoneme, and is derived with
the ALINE phonetic aligner (Kondrak, 2000), which
has been shown to outperform other 1-1 alignment
methods (Jiampojamarn and Kondrak, 2010).
</bodyText>
<subsectionHeader confidence="0.999302">
6.2 Vowel Counter
</subsectionHeader>
<bodyText confidence="0.9998184">
Syllables that contain multiple vowel groups may be
confusing to readers even if they correctly represent
the intended pronunciation. For example, readers
might be unsure whether takess represents one or
two syllables. A simple vowel counter is provided
to filter out such syllables. The vowel filter accepts
a syllable only if (a) it contains exactly one vowel
group (e.g., moe), or (b) the second vowel group
consists of a single e at the end of the syllable (e.g.,
zake).
</bodyText>
<subsectionHeader confidence="0.996221">
6.3 SVM Ambiguity Classifier
</subsectionHeader>
<bodyText confidence="0.999968782608696">
This module is designed to compute a score that re-
flects the ambiguity of an orthographic syllable. The
ambiguity score of a respelling is defined as the av-
erage of scores assigned to each of its syllables. The
score can then be used to select the best respelling
from a number of candidates generated by our sys-
tem, or to rate a respelling from another source.
Since we have no explicit ambiguity annotations
for respellings, we attempt instead to exploit ambi-
guity judgments that are implicitly made when re-
spellings are created by human authors. We ap-
proach ambiguity as a binary classification task. For
any given syllable, we wish to determine whether it
is ambiguous (a negative instance), or unambiguous
(a positive instance). Our assumption is that a sylla-
ble will not be respelled unless it is necessary due
to ambiguity. For each observed word-respelling
pair, we take all syllables from the respelling as pos-
itive instances, and all syllables in the original word
that are not preserved in the respelling as negative
instances. For example, the pair consisting of the
word cec-il-y respelled as ‘sehs-it-ee’ provides three
positive instances: sehs, il and ee; and two negative
instances: cec and y.
We extracted word-respelling pairs from the Web-
derived corpora of Ghoshal et al. (2009). The syl-
lable breaks in the respellings were mapped onto
the original words using ALINE. In order to im-
prove the quality of the data, we applied a letter-
to-phoneme model to both the original words and
their respellings, and removed pairs with divergent
pronunciations (computed as normalized edit dis-
tance &lt; 0.8). After the filtering, we were left a
set of 25067 word-respelling pairs containing 78411
training syllables, which yielded 47270 positive and
31141 negative instances.
For the classification task we utilize the SVM-
light software package (Joachims, 1999). Each in-
stance is represented by a set of binary indicator fea-
tures. The features correspond to character n-grams
(including syllable boundary markers) with the val-
ues of n ranging from 1 to 5. For example, the syl-
lable -il- turns on the following features: i, l, -i, il,
l-, -il, il-, -il-. The model learns which n-grams are
characteristic of ambiguous or unambiguous sylla-
bles. For example, it classifies both le and li as am-
</bodyText>
<page confidence="0.998314">
639
</page>
<bodyText confidence="0.998473333333333">
biguous, and lee as unambiguous. Apart from the
binary classification, the classifier also provides a
real-valued score for each syllable.
</bodyText>
<subsectionHeader confidence="0.999795">
6.4 Lexical Reviser
</subsectionHeader>
<bodyText confidence="0.999857470588235">
Since the use of familiar English letter sequences
makes the respellings easier to interpret (Fraser,
1997), we incorporate dictionary lookup (Section
4.2) into our system. When the pronunciation of a
syllable happens to correspond to the pronunciation
an actual dictionary word, the syllable may be re-
spelled using that word. This is done as the final step
in the generation process because dictionary words
often receive poor scores from the SVM classifier on
the account of their n-gram composition. The lexi-
cal reviser is restricted to optionally improving the
top-ranked word respelling candidate as determined
by the SVM classifier without altering its syllabifi-
cation. For example, the respelling ‘surr-sin-uss’ of
circinus is modified to ‘sir-sin-us’. If more than one
word can be used, we let the SVM classifier select
the least ambiguous one.
</bodyText>
<sectionHeader confidence="0.938719" genericHeader="method">
7 System Overview
</sectionHeader>
<bodyText confidence="0.9999677">
Our respelling generation system is a multi-stage
process. The input is a sequence of phonemes rep-
resenting the pronunciation of the word. We start by
identifying acceptable syllabifications of phonemes
as described in Section 5.1. For each syllable, we
take up to five respelling candidates produced by
the P2L model (Section 5.2), and between one and
three candidates proposed by the context-sensitive
respeller (Section 5.3). The next stage involves fil-
tering the candidate respellings with the L2P model
(Section 6.1), and the vowel counter (Section 6.2).
If all candidates happen to be rejected, we retain the
first output of the context-sensitive respeller as the
default. The candidate respellings are then scored
by the SVM model (Section 6.3). At this point the
syllables are combined into word respellings, which
are ranked according to their syllable score average.
Finally, the lexical reviser described in Section 6.4 is
applied to the top candidate in an attempt to further
improve the result.
</bodyText>
<sectionHeader confidence="0.978474" genericHeader="evaluation">
8 Evaluation
</sectionHeader>
<bodyText confidence="0.99996325">
In this section, after describing our test sets, we
present the results of two evaluation experiments:
direct human judgment, and indirect validation with
an L2P system.
</bodyText>
<subsectionHeader confidence="0.999926">
8.1 Test Sets
</subsectionHeader>
<bodyText confidence="0.999992666666667">
Our two test sets were defined after the development
of our system had been completed. There is no over-
lap between the test sets and any of our training sets.
The first test set consists of 27 out of 30 words com-
piled by Fraser (1997) — 3 words from the origi-
nal set were excluded because the corresponding re-
spellings assume a non-rhotic variety of English. We
refer to Fraser’s respellings as expert, and consider
them as the upper bound in terms of quality.
The second test set of 231 words (henceforth re-
ferred to as the Web set) was extracted from the
corpus of Ghoshal et al. (2009) after performing
additional data clean-up described in Section 6.3.
We identified a subset of words for which we
could find phonetic transcriptions composed of En-
glish phonemes on Wikipedia. In order to ensure
that the respellings and the corresponding transcrip-
tions reflect the same pronunciation, we adapted the
Soundex algorithm to apply to phonetic transcrip-
tions, and retained only the respelling/transcription
pairs that yielded identical Soundex codes. We re-
moved words that are found in the Combilex dic-
tionary as those could be familiar to human judges.
Since longer words are more challenging to respell,
and more likely to exhibit variation in respellings
from different sources, we retained only words con-
taining at least eight phonemes.
</bodyText>
<subsectionHeader confidence="0.999433">
8.2 Human Judgment
</subsectionHeader>
<bodyText confidence="0.999993272727273">
We conducted an experiment with human evalua-
tors using a specially developed graphical annota-
tion program with synthesized word pronunciations.
The evaluators were students enrolled in an intro-
ductory linguistic course, who were not involved in
our project. 13 out of 20 evaluators declared them-
selves as native speakers of English.
The evaluation process involves 40 randomly se-
lected words: 10 from Fraser’s set, and 30 from the
Web set. For each word, the program displays in a
random sequence three respellings, which are from
</bodyText>
<page confidence="0.993639">
640
</page>
<table confidence="0.998988">
Source Web set Fraser’s set
U U&amp;C U U&amp;C
Baseline 43.0 25.5 41.0 20.0
Web 68.0 32.6 —
Expert — 72.0 46.0
Our system 70.0 41.3 67.0 38.5
</table>
<tableCaption confidence="0.9924695">
Table 2: Human judgments on respellings in %: U -
unambiguous; U&amp;C - unambiguous &amp; correct.
</tableCaption>
<bodyText confidence="0.999971074074074">
the following sources: (1) the Baseline approach de-
scribed in Section 4.3, (2) our system, and (3) ei-
ther expert design (for Fraser’s set) or the Web (for
the Web set). In order to reduce bias, the origi-
nal spelling of the word is not shown. Each re-
spelling is judged separately with regards to ambi-
guity, and those that are judged ambiguous are re-
moved from further consideration. Next, an audio
clip synthesized from the phonemic sequence repre-
senting the intended pronunciation is played through
headphones. For each of the remaining respellings,
the evaluators decide whether it is correct with re-
spect to the recorded pronunciation. Finally, if more
than one respelling have been judged both unam-
biguous and correct, the evaluators are asked to iden-
tify the one that they prefer.
The results of the experiment are shown in Ta-
ble 2. Our system significantly outperforms both
Web respellings and the Baseline approach in terms
of unambiguity and correctness. In addition, the re-
spellings produced by our system are more likely to
be preferred over the Web respellings, and more than
twice as likely to be preferred over the baseline re-
spellings than vice versa. The results on the small
Fraser’s set are less conclusive, but suggest that in
terms of overall quality our system is much closer to
the upper bound than to the baseline.
</bodyText>
<subsectionHeader confidence="0.992867">
8.3 Automated Appraisal
</subsectionHeader>
<bodyText confidence="0.999864625">
Human evaluation is expensive and limited in terms
of the number of variant respellings. Moreover, hu-
man judgements may be biased by previously seen
respellings or by the familiarity with the standard
spelling of a word. An automated evaluation is much
less constrained, and facilitates an ablation study to
determine the relative importance of various compo-
nents of our system.
</bodyText>
<table confidence="0.997321571428571">
Source Web set Fraser’s set
WA PA WA PA
No respelling 13.0 76.2 14.8 76.3
Baseline 8.2 78.9 7.4 71.0
Web 14.3 77.9 —
Expert — 37.0 85.6
Our system 58.0 93.0 70.4 95.6
</table>
<tableCaption confidence="0.9734085">
Table 4: Word accuracy (WA) and phoneme accuracy
(PA) of eSpeak on respellings.
</tableCaption>
<table confidence="0.962017625">
Source Web set
WA PA
Full system 58.0 93.0
w/o lexical reviser 57.6 93.1
w/o context-sensitive respeller 56.7 92.8
w/o P2L generator 51.9 92.1
w/o L2P correctness filter 33.8 88.0
w/o syllable breaks 20.8 83.9
</table>
<tableCaption confidence="0.9936525">
Table 5: Accuracy of eSpeak on respellings produced by
variants of our system.
</tableCaption>
<bodyText confidence="0.999322">
eSpeak is a publicly available speech synthesizer5
that can also convert text into phonemic sequences.
The letter-to-phoneme component for English uti-
lizes about five thousand rules, and a dictionary of
about three thousand words, names, and abbrevia-
tions. In our evaluation, we treat eSpeak as a “black
box” which translates a respelling into its most likely
pronunciation. By determining if there is a match
between the output of eSpeak and the intended pro-
nunciation, we directly test the correctness of the re-
spelling, and indirectly also its ambiguity.
The results of the automated evaluation are shown
in Table 4. The accuracy on the original orthogra-
phy is low, which is unsurprising since the test sets
contain mostly rare, unusually spelled words. Nei-
ther the baseline nor the Web respellings are sig-
nificantly easier for eSpeak than the original words.
On the other hand, respellings generated by our sys-
tem make a massive difference, boosting phoneme
accuracy to well over 90% on both sets. They are
also significantly more effective than the expert re-
spellings.
Table 5 shows the results of our system on the
</bodyText>
<footnote confidence="0.967804">
5http://espeak.sourceforge.net
</footnote>
<page confidence="0.988867">
641
</page>
<table confidence="0.868209409090909">
No. Spelling IPA
1 Incirlik [intirlik]
2 Captopril [kwptapr�l]
3 Coquitlam [kokwrtlam]
4 Karolina [karOlina]
5 subluxation [sablaksefan]
6 swingle [swiUgal]
7 cockatrice [kakatrais]
8 recalesce [rikales]
9 jongleur [3Rglar]
10 ylang-ylang [ilwUilwU]
Web/HF respelling Score System respelling Score
injirlik 1/6 een-jeer-leek 4/6
kap-toh-pril 1/6 cap-tuh-prill 4/6
ko-kwit-lam 1/6 koh-quit-lumb 4/6
karo-leena 4/6 car-awl-ee-nah 1/6
sub-luck-say-shun 3/5 suh-bluck-say-shun 1/5
swing-gl 0/5 swing-gull 2/5
kok-a-trice 0/7 cock-uh-trice 4/7
ree-ka-less 1/5 re-cull-ess 3/5
jong-gler 7/9 zhahng-gler 0/9
ee-lang-ee-lang 5/5 eel-ang-eel-ang 1/5
</table>
<tableCaption confidence="0.999308">
Table 3: Examples of respellings.
</tableCaption>
<bodyText confidence="0.9998079">
Web set with various modules disabled, which pro-
vides an estimate of their importance. Neither
the context-sensitive respeller nor dictionary lookup
seem to contribute much to eSpeak’s performance.
On the other hand, disabling the P2L generator pro-
duces a significant drop in word accuracy, while re-
moving the L2P correctness filter almost doubles the
phoneme error rate. Interestingly, removing syllable
breaks from the output of the full system has an even
greater negative impact.
</bodyText>
<subsectionHeader confidence="0.983446">
8.4 Analysis
</subsectionHeader>
<bodyText confidence="0.999981655172414">
Each of 20 evaluators judged 3 variant respellings
of 40 different words. The average number of judg-
ments per word was 7.4 for the 27 words in Fraser’s
set, and 2.8 for the 212 words in the Web set (due to
random selection, 19 words from the Web set were
not judged). Table 3 shows examples of respellings
that were judged by at least five evaluators. The
score columns indicate the proportion of the evalu-
ators that judged a particular respellings as unam-
biguous and correct. The baseline respellings are
not included as their scores were rarely higher than
the scores of the other respellings for a given word.
An interesting exception is palimpsest, for which the
baseline respelling is identical to the actual spelling
of the word.
Examples 1-5 in Table 3 come from the Web set,
while examples 6-10 are from Fraser’s set. The
low scores of the first three Web respellings can be
attributed to specific letter-to-phoneme mappings:
[i]—*i, [a]—*oh, and [a]—*a. Each of the examples
3-5 indicate the evaluators’ acceptance of a partic-
ular respelling device: silent letters, multi-syllable
units, and dictionary words. In examples 6-8, the
syllables immediately after the first hyphen in Helen
Fraser’s respellings seem to be problematic. The ex-
pert respelling of jongleur is considered correct even
though the initial j suggests [t], not [3]. Finally,
the last example demonstrates that the hyphenation
choice can result in very different judgments.
</bodyText>
<sectionHeader confidence="0.997572" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999986375">
In this paper, we introduced the task of automati-
cally generating respellings from the given pronun-
ciation. We investigated the characteristics of good
respellings, and discussed three direct methods of
their creation. We proposed a system that combines
supervised and unsupervised learning with phonetic
and orthographic principles. The evaluation experi-
ment involving human participants indicates that the
respellings produced by our system are better on av-
erage than those found on the Web. The automated
verification demonstrates that they are also much
easier to interpret for a rule-based text-to-speech
converter. In the future we plan to address the re-
lated tasks of improving existing respellings, and as-
sisting writers in creating respellings without direct
access to the phonemic representations.
</bodyText>
<sectionHeader confidence="0.997513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999340833333333">
We thank Aditya Bhargava and Clarke Chomyc for
their contribution to the creation of data sets, and
Ben Tucker for advice on the complexities of the hu-
man evaluation experiment. This research was par-
tially funded by the Natural Sciences and Engineer-
ing Research Council of Canada.
</bodyText>
<page confidence="0.997798">
642
</page>
<sectionHeader confidence="0.995885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999801724137931">
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2009. On the syllabification of phonemes. In Proc.
of HLT-NAACL, pages 308–316.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.
Do˘gan Can, Erica Cooper, Arnab Ghoshal, Martin Jan-
sche, Sanjeev Khudanpur, Bhuvana Ramabhadran,
Michael Riley, Murat Saraçlar, Abhinav Sethy, Mor-
gan Ulinski, and Christopher White. 2009. Web de-
rived pronunciations for spoken term detection. In
Proc. of ACM SIGIR, pages 83–90.
Edward Carney. 1994. A Survey of English Spelling.
Routledge.
Noam Chomsky and Morris Halle. 1968. The Sound
Pattern of English. New York: Harper &amp; Row.
Helen Fraser. 1997. Dictionary pronunciation guides
for English. International Journal of Lexicography,
10(3):181–208.
Lucian Galescu. 2009. Extending pronunciation lexi-
cons via non-phonemic respellings. In Proc. of HLT-
NAACL: Short Papers, pages 129–132.
Arnab Ghoshal, Martin Jansche, Sanjeev Khudanpur,
Michael Riley, and Morgan Ulinski. 2009. Web-
derived pronunciations. In Proc. of ICASSP, pages
4289–4292.
Sittichai Jiampojamarn and Grzegorz Kondrak. 2010.
Letter-phoneme alignment: An exploration. In Proc.
of ACL, pages 780–788.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden Markov models to letter-to-phoneme con-
version. In Proc. of HLT-NAACL, pages 372–379.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Proc. of
ACL, pages 905–913.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In B. Schalkopf, C. Burges, and
A. Smola, editors, Advances in Kernel Methods - Sup-
port Vector Learning. MIT Press.
Michael Kenstowicz. 1994. Phonology in Generative
Grammar. Blackwell.
John Kominek and Alan W Black. 2006. Learning
pronunciation dictionaries: Language complexity and
word selection strategies. In Proc. of HLT-NAACL,
pages 232–239.
Grzegorz Kondrak. 2000. A new algorithm for the align-
ment of phonetic sequences. In Proc. of NAACL, pages
288–295.
John Noble. 2012. Mexico. Lonely Planet, 13th edition.
Korin Richmond, Robert Clark, and Sue Fitt. 2009. Ro-
bust LTS rules with the Combilex speech technology
lexicon. In Proc. of Interspeech, pages 1295–1298.
Henry Rogers. 2000. The Sounds of Language. Pearson.
Briony Williams and Rhys James Jones. 2008. Acquir-
ing pronunciation data for a placenames lexicon in a
less-resourced language. In Proc. of LREC.
</reference>
<page confidence="0.999169">
643
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904293">
<title confidence="0.999733">Automatic Generation of English Respellings</title>
<author confidence="0.999179">Bradley Hauer</author>
<author confidence="0.999179">Grzegorz</author>
<affiliation confidence="0.999773">Department of Computing University of</affiliation>
<address confidence="0.994294">Edmonton, Alberta, Canada, T6G</address>
<email confidence="0.993453">bmhauer@ualberta.ca</email>
<email confidence="0.993453">gkondrak@ualberta.ca</email>
<abstract confidence="0.99456125">an alternative spelling of a word in the same writing system, intended to clarify pronunciation. We introduce the task of automatic generation of a respelling from the word’s phonemic representation. Our approach combines machine learning with linguistic constraints and electronic resources. We evaluate our system both intrinsically through a human judgment experiment, and extrinsically by passing its output to a letterto-phoneme converter. The results show that the respellings generated by our system are better on average than those found on the Web, and approach the quality of respellings designed by an expert.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
<author>Grzegorz Kondrak</author>
<author>Colin Cherry</author>
</authors>
<title>On the syllabification of phonemes.</title>
<date>2009</date>
<booktitle>In Proc. of HLT-NAACL,</booktitle>
<pages>308--316</pages>
<contexts>
<context position="15092" citStr="Bartlett et al. (2009)" startWordPosition="2366" endWordPosition="2369"> trig-onal. We adopt an overgenerate-and-rank approach, whereby instead of committing to a specific word segmentation at the start of the process, we process multiple syllabification alternatives in parallel, one of which is ultimately selected at the respelling evaluation stage. Ideally, syllabification should conform to the phonotactic constraints of English, so that the resulting respellings are easy to pronounce. The consonant sonority should be rising in onsets, and falling in codas (Kenstowicz, 1994). We verify that syllables follow the sonority principle by following the formulation of Bartlett et al. (2009). The sonority constraints are not tested at the boundaries of the word, which are independent of the syllabification choice. We also incorporate another important principle of English phonotactics that asserts that lax vowels do not occur in open syllables (Rogers, 2000). In our implementation, each candidate syllable is tested with respect to the following sequence of four violable constraints, ordered from the strongest to the weakest: (1) the syllable contains exactly one vowel phoneme; (2) the onset satisfies the sonority principle; (3) if the nucleus contains a lax vowel (except a), the </context>
</contexts>
<marker>Bartlett, Kondrak, Cherry, 2009</marker>
<rawString>Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2009. On the syllabification of phonemes. In Proc. of HLT-NAACL, pages 308–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="3000" citStr="Bisani and Ney, 2008" startWordPosition="457" endWordPosition="460">tionaries. One of our ultimate objectives is to aid writers by evaluating their respellings, improving them, or generating new candidates. Accordingly, we endeavour to maintain the generation and the evaluation stages as separate modules in our system. The evaluation of respellings is a challenging problem. Since English spelling conventions are notoriously inconsistent, there is no algorithm for accurately predicting the pronunciation of an out-ofvocabulary word. The current state-of-the-art letterto-phoneme (L2P) converters are typically reported with 10-30% error rates on dictionary words (Bisani and Ney, 2008). On the other hand, human readers often disagree on the details of the pronunciation implied by a respelling. In this paper, we conduct two kinds of evaluations: an automated verification with an independent L2P system, and an experiment with human participants that pass judgments on different respellings of the same word. We interpret the results as evidence that the output of our system compares favourably with typical respellings found on the Web. 634 Proceedings of NAACL-HLT 2013, pages 634–643, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Definitio</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Do˘gan Can</author>
<author>Erica Cooper</author>
<author>Arnab Ghoshal</author>
<author>Martin Jansche</author>
<author>Sanjeev Khudanpur</author>
<author>Bhuvana Ramabhadran</author>
<author>Michael Riley</author>
<author>Murat Saraçlar</author>
<author>Abhinav Sethy</author>
<author>Morgan Ulinski</author>
<author>Christopher White</author>
</authors>
<title>Web derived pronunciations for spoken term detection.</title>
<date>2009</date>
<booktitle>In Proc. of ACM SIGIR,</booktitle>
<pages>83--90</pages>
<contexts>
<context position="10272" citStr="Can et al. (2009)" startWordPosition="1589" endWordPosition="1592">al during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. Ghoshal et al. (2009) extract a large number of respellings from the Web, and show that they can be exploited to improve the accuracy of the L2P conversion by supplementing the data in pronunciation dictionaries. Can et al. (2009) further analyze the effect of using respellings on the accuracy of spokenterm detection (STD) systems. 4 Direct Methods In this section, we discuss three direct methods of generating respellings: manual design, dictionary lookup, and phonemic respelling. 4.1 Manual Design Respellings found on the Web and in news articles are usually ad-hoc creations of the authors of those texts. Respellings designed by different writers for the same word are rarely identical.3 The quality of Web respellings vary. The respellings found in specialized lexicons are more likely to be designed by experts, and are</context>
</contexts>
<marker>Can, Cooper, Ghoshal, Jansche, Khudanpur, Ramabhadran, Riley, Saraçlar, Sethy, Ulinski, White, 2009</marker>
<rawString>Do˘gan Can, Erica Cooper, Arnab Ghoshal, Martin Jansche, Sanjeev Khudanpur, Bhuvana Ramabhadran, Michael Riley, Murat Saraçlar, Abhinav Sethy, Morgan Ulinski, and Christopher White. 2009. Web derived pronunciations for spoken term detection. In Proc. of ACM SIGIR, pages 83–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Carney</author>
</authors>
<title>A Survey of English Spelling.</title>
<date>1994</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="3975" citStr="Carney, 1994" startWordPosition="611" endWordPosition="612"> that the output of our system compares favourably with typical respellings found on the Web. 634 Proceedings of NAACL-HLT 2013, pages 634–643, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Definitions and Conventions Although Chomsky and Halle (1968) characterize English orthography as close to optimal, Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. There is no consensus on how to best convey the pronunciation of an uncommon word in English. Most dictionaries employ either the International Phonetic Alphabet (IPA), or their own transcription schemes that incorporate special symbols and diacritics. Unfortunately, many readers are unfamiliar with phonetic transcription. Instead, respellings are often preferred by writers in the news and on the Web. In this section, we define the respelling task in de</context>
</contexts>
<marker>Carney, 1994</marker>
<rawString>Edward Carney. 1994. A Survey of English Spelling. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
<author>Morris Halle</author>
</authors>
<title>The Sound Pattern of English.</title>
<date>1968</date>
<location>New York: Harper &amp; Row.</location>
<contexts>
<context position="3652" citStr="Chomsky and Halle (1968)" startWordPosition="557" endWordPosition="560">eaders often disagree on the details of the pronunciation implied by a respelling. In this paper, we conduct two kinds of evaluations: an automated verification with an independent L2P system, and an experiment with human participants that pass judgments on different respellings of the same word. We interpret the results as evidence that the output of our system compares favourably with typical respellings found on the Web. 634 Proceedings of NAACL-HLT 2013, pages 634–643, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Definitions and Conventions Although Chomsky and Halle (1968) characterize English orthography as close to optimal, Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. There is no consensus on how to best convey the pronunciation of an uncommon word in English. Most dictionaries employ either the Inte</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Noam Chomsky and Morris Halle. 1968. The Sound Pattern of English. New York: Harper &amp; Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helen Fraser</author>
</authors>
<title>Dictionary pronunciation guides for English.</title>
<date>1997</date>
<journal>International Journal of Lexicography,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="5280" citStr="Fraser (1997)" startWordPosition="812" endWordPosition="813">ended to better convey its pronunciation. We assume that the pronunciation is defined as a sequence of English phonemes, and that the respelling contains only the 26 letters of the alphabet, with optional hyphenation. Some transcription schemes combine respellings with special symbols for representing certain phonemes. For example, an otherwise purely alphabetic Wikipedia scheme employs the symbol a for the vowel schwa. In our opinion, such devices destroy the main advantage of respellings, which is their universality, without attaining the precision of a true phonetic transcription. In fact, Fraser (1997) identifies the schwa symbol as the cause of many pronunciation errors. In our system, we consistently use hyphens to segment multi-syllable respellings. Each syllablesize segment contains the representation of exactly one vowel phoneme, so that the number of segments matches the number of syllables.1 However, the hyphenation need not correspond exactly to the actual 1Henceforth, we refer to “syllable-size segments” simply as “syllables”. syllable breaks. This approach has several advantages. First, individual syllables are easier to pronounce than an entire unfamiliar word. Second, hyphens li</context>
<context position="9221" citStr="Fraser (1997)" startWordPosition="1424" endWordPosition="1425">or a given reader, unambiguity is a necessary but not sufficient condition for correctness. Given two unambiguous and correct respellings, a reader may prefer one over the other, perhaps because of the ease of inferring the intended pronunciation. For example, ‘rode-ease-yew’ maybe preferred to ‘roh-dee-zyoo’ because the former is entirely composed of actual English words with unique pronunciation, whereas the latter contains an unusual consonant cluster zy. Preference is also expressed implicitly if only one of the alternative respellings is judged as unambiguous (or correct), 3 Related Work Fraser (1997) describes an experiment in which 15 human subjects were asked to pronounce uncommon words after being shown a representation of their pronunciation. The respellings designed by the author were much more effective for that purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Gales</context>
<context position="25111" citStr="Fraser, 1997" startWordPosition="4005" endWordPosition="4006">respond to character n-grams (including syllable boundary markers) with the values of n ranging from 1 to 5. For example, the syllable -il- turns on the following features: i, l, -i, il, l-, -il, il-, -il-. The model learns which n-grams are characteristic of ambiguous or unambiguous syllables. For example, it classifies both le and li as am639 biguous, and lee as unambiguous. Apart from the binary classification, the classifier also provides a real-valued score for each syllable. 6.4 Lexical Reviser Since the use of familiar English letter sequences makes the respellings easier to interpret (Fraser, 1997), we incorporate dictionary lookup (Section 4.2) into our system. When the pronunciation of a syllable happens to correspond to the pronunciation an actual dictionary word, the syllable may be respelled using that word. This is done as the final step in the generation process because dictionary words often receive poor scores from the SVM classifier on the account of their n-gram composition. The lexical reviser is restricted to optionally improving the top-ranked word respelling candidate as determined by the SVM classifier without altering its syllabification. For example, the respelling ‘su</context>
<context position="27314" citStr="Fraser (1997)" startWordPosition="4360" endWordPosition="4361"> ranked according to their syllable score average. Finally, the lexical reviser described in Section 6.4 is applied to the top candidate in an attempt to further improve the result. 8 Evaluation In this section, after describing our test sets, we present the results of two evaluation experiments: direct human judgment, and indirect validation with an L2P system. 8.1 Test Sets Our two test sets were defined after the development of our system had been completed. There is no overlap between the test sets and any of our training sets. The first test set consists of 27 out of 30 words compiled by Fraser (1997) — 3 words from the original set were excluded because the corresponding respellings assume a non-rhotic variety of English. We refer to Fraser’s respellings as expert, and consider them as the upper bound in terms of quality. The second test set of 231 words (henceforth referred to as the Web set) was extracted from the corpus of Ghoshal et al. (2009) after performing additional data clean-up described in Section 6.3. We identified a subset of words for which we could find phonetic transcriptions composed of English phonemes on Wikipedia. In order to ensure that the respellings and the corres</context>
</contexts>
<marker>Fraser, 1997</marker>
<rawString>Helen Fraser. 1997. Dictionary pronunciation guides for English. International Journal of Lexicography, 10(3):181–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucian Galescu</author>
</authors>
<title>Extending pronunciation lexicons via non-phonemic respellings.</title>
<date>2009</date>
<booktitle>In Proc. of HLTNAACL: Short Papers,</booktitle>
<pages>129--132</pages>
<contexts>
<context position="9830" citStr="Galescu (2009)" startWordPosition="1518" endWordPosition="1519">1997) describes an experiment in which 15 human subjects were asked to pronounce uncommon words after being shown a representation of their pronunciation. The respellings designed by the author were much more effective for that purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. Ghoshal et al. (2009) extract a large number of respellings from the Web, and show that they can be exploited to improve the accuracy of the L2P conversion by supplementing the data in pronunciation dictionaries. Can et al. (2009) further analyze the effect of using respellings on the accuracy of spokenterm detection (STD) systems. 4 Direct Methods In this section, we discuss three dir</context>
</contexts>
<marker>Galescu, 2009</marker>
<rawString>Lucian Galescu. 2009. Extending pronunciation lexicons via non-phonemic respellings. In Proc. of HLTNAACL: Short Papers, pages 129–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnab Ghoshal</author>
<author>Martin Jansche</author>
<author>Sanjeev Khudanpur</author>
<author>Michael Riley</author>
<author>Morgan Ulinski</author>
</authors>
<title>Webderived pronunciations.</title>
<date>2009</date>
<booktitle>In Proc. of ICASSP,</booktitle>
<pages>4289--4292</pages>
<contexts>
<context position="10063" citStr="Ghoshal et al. (2009)" startWordPosition="1552" endWordPosition="1555">t purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. Ghoshal et al. (2009) extract a large number of respellings from the Web, and show that they can be exploited to improve the accuracy of the L2P conversion by supplementing the data in pronunciation dictionaries. Can et al. (2009) further analyze the effect of using respellings on the accuracy of spokenterm detection (STD) systems. 4 Direct Methods In this section, we discuss three direct methods of generating respellings: manual design, dictionary lookup, and phonemic respelling. 4.1 Manual Design Respellings found on the Web and in news articles are usually ad-hoc creations of the authors of those texts. Respell</context>
<context position="11985" citStr="Ghoshal et al. (2009)" startWordPosition="1859" endWordPosition="1862">omatically derived from the list of syllable pronunciations. For example, hyphy can be respelled as ‘high-fee’ by following such a procedure. If each of the syllables has a unique pronunciation, such respellings are arguably both unambiguous and correct. Unfortunately, only a subset of potential phonemic syllables actually occur in a lexicon. Considering only the syllables of the CVC type (consonantvowel-consonant), there are over ten thousand distinct possibilities (e.g., [beb], [bef], etc.), of which 3For example, the word capoeira is represented by 99 different respellings in the corpus of Ghoshal et al. (2009). 4For an example of a confusing respelling guide see http: //www.ama-assn.org/go/usan. 636 fewer than three thousand can be found in the Combilex pronunciation dictionary (Richmond et al., 2009). While the dictionary lookup may produce attractive respellings, it is not sufficient for a standalone use. 4.3 Phonemic Respelling A simple method that can produce a respelling for any word is to directly map each phoneme to a particular letter or a letter sequence that is frequently used to represent that phoneme. Phonemes such as [m], [d] and [f] are indeed closely associated with individual letter</context>
<context position="16923" citStr="Ghoshal et al. (2009)" startWordPosition="2650" endWordPosition="2653">e respelling problem can be viewed as a string transduction problem, with the transduction occurring between phonemes and letters. As such, it is directly related to the well-studied letter-to-phoneme conversion task. The difference is that the letters may not conform to the standard orthography of English. If we had a sufficiently large training set of pronunciation-respelling pairs, we could train a machine learning algorithm to directly generate respellings for any strings of English phonemes. However, such a training set is not readily available. The respellings in the corpus collected by Ghoshal et al. (2009) are not easily matched to the phonetic transcriptions, and few of them can be found in electronic pronunciation dictionaries. In addition, the quality of Web respellings vary greatly. In place of a direct pronunciation-to-respelling model, we aim to model the orthographic intuitions of readers by deriving a phoneme-to-letter (P2L) transduction model from an English pronunciation dictionary. A possible criticism of such an approach is that our model may create ambiguous respellings, which abound in English orthography. However, we rely on a separate evaluation module to identify and filter amb</context>
<context position="23845" citStr="Ghoshal et al. (2009)" startWordPosition="3797" endWordPosition="3800">negative instance), or unambiguous (a positive instance). Our assumption is that a syllable will not be respelled unless it is necessary due to ambiguity. For each observed word-respelling pair, we take all syllables from the respelling as positive instances, and all syllables in the original word that are not preserved in the respelling as negative instances. For example, the pair consisting of the word cec-il-y respelled as ‘sehs-it-ee’ provides three positive instances: sehs, il and ee; and two negative instances: cec and y. We extracted word-respelling pairs from the Webderived corpora of Ghoshal et al. (2009). The syllable breaks in the respellings were mapped onto the original words using ALINE. In order to improve the quality of the data, we applied a letterto-phoneme model to both the original words and their respellings, and removed pairs with divergent pronunciations (computed as normalized edit distance &lt; 0.8). After the filtering, we were left a set of 25067 word-respelling pairs containing 78411 training syllables, which yielded 47270 positive and 31141 negative instances. For the classification task we utilize the SVMlight software package (Joachims, 1999). Each instance is represented by</context>
<context position="27668" citStr="Ghoshal et al. (2009)" startWordPosition="4422" endWordPosition="4425">ith an L2P system. 8.1 Test Sets Our two test sets were defined after the development of our system had been completed. There is no overlap between the test sets and any of our training sets. The first test set consists of 27 out of 30 words compiled by Fraser (1997) — 3 words from the original set were excluded because the corresponding respellings assume a non-rhotic variety of English. We refer to Fraser’s respellings as expert, and consider them as the upper bound in terms of quality. The second test set of 231 words (henceforth referred to as the Web set) was extracted from the corpus of Ghoshal et al. (2009) after performing additional data clean-up described in Section 6.3. We identified a subset of words for which we could find phonetic transcriptions composed of English phonemes on Wikipedia. In order to ensure that the respellings and the corresponding transcriptions reflect the same pronunciation, we adapted the Soundex algorithm to apply to phonetic transcriptions, and retained only the respelling/transcription pairs that yielded identical Soundex codes. We removed words that are found in the Combilex dictionary as those could be familiar to human judges. Since longer words are more challen</context>
</contexts>
<marker>Ghoshal, Jansche, Khudanpur, Riley, Ulinski, 2009</marker>
<rawString>Arnab Ghoshal, Martin Jansche, Sanjeev Khudanpur, Michael Riley, and Morgan Ulinski. 2009. Webderived pronunciations. In Proc. of ICASSP, pages 4289–4292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Letter-phoneme alignment: An exploration.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>780--788</pages>
<contexts>
<context position="22024" citStr="Jiampojamarn and Kondrak, 2010" startWordPosition="3495" endWordPosition="3498">e preprocessing of the training data, and the letter-to-phoneme alignment. As with the P2L model, the training data consists of a set of monosyllabic words from the Combilex dictionary. However, in order to make our correctness filter more conservative, we also remove all words that contain diacritics (e.g., crêpe), non-English phonemes (e.g., avant), or silent consonants (e.g., limn). The alignment is restricted to matching each letter symbol to at most one phoneme, and is derived with the ALINE phonetic aligner (Kondrak, 2000), which has been shown to outperform other 1-1 alignment methods (Jiampojamarn and Kondrak, 2010). 6.2 Vowel Counter Syllables that contain multiple vowel groups may be confusing to readers even if they correctly represent the intended pronunciation. For example, readers might be unsure whether takess represents one or two syllables. A simple vowel counter is provided to filter out such syllables. The vowel filter accepts a syllable only if (a) it contains exactly one vowel group (e.g., moe), or (b) the second vowel group consists of a single e at the end of the syllable (e.g., zake). 6.3 SVM Ambiguity Classifier This module is designed to compute a score that reflects the ambiguity of an</context>
</contexts>
<marker>Jiampojamarn, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn and Grzegorz Kondrak. 2010. Letter-phoneme alignment: An exploration. In Proc. of ACL, pages 780–788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden Markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. of HLT-NAACL,</booktitle>
<pages>372--379</pages>
<contexts>
<context position="18475" citStr="Jiampojamarn et al., 2007" startWordPosition="2899" endWordPosition="2903">om the Combilex dictionary. We exclude syllables in multisyllabic words from training because their pronunciation is often affected by context. This is consistent with our expectation that the reader will pronounce each hyphen-delimited segment of the respelling as if it was an individual word. Since the P2L training data consists of a relatively small set of syllables, we ensure that the phonemeletter alignment is highly accurate. As a preprocessing step, we replace the letter x with ks, and we convert digraphs, such as ch and th, to single symbols. The alignment is performed by M2M-ALIGNER (Jiampojamarn et al., 2007), under the restriction that each phoneme is matched to either one or two letter symbols. 5.3 Context-Sensitive Respeller A hand-crafted context-sensitive respeller is intended to complement the trained P2L model described in the previous section. It is similar to to the phonemic respelling approach described in Section 4.3 in that it converts each phoneme to a letter sequence. However, the mappings depend on adjacent phonemes, as well as on the CV pattern of the current syllable. In addition, more than one mapping for a phoneme can be proposed. We designed the mappings by analyzing their freq</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden Markov models to letter-to-phoneme conversion. In Proc. of HLT-NAACL, pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>905--913</pages>
<contexts>
<context position="17629" citStr="Jiampojamarn et al., 2008" startWordPosition="2756" endWordPosition="2760">ound in electronic pronunciation dictionaries. In addition, the quality of Web respellings vary greatly. In place of a direct pronunciation-to-respelling model, we aim to model the orthographic intuitions of readers by deriving a phoneme-to-letter (P2L) transduction model from an English pronunciation dictionary. A possible criticism of such an approach is that our model may create ambiguous respellings, which abound in English orthography. However, we rely on a separate evaluation module to identify and filter ambiguous respellings at a later stage. Our systems utilizes the DIRECTL+ program (Jiampojamarn et al., 2008), which was originally designed for L2P conversion. Since our basic unit is the syllable, rather than the word, we train our P2L model on a set of of 4215 pairs of monosyllabic words and their pronunciations extracted from the Combilex dictionary. We exclude syllables in multisyllabic words from training because their pronunciation is often affected by context. This is consistent with our expectation that the reader will pronounce each hyphen-delimited segment of the respelling as if it was an individual word. Since the P2L training data consists of a relatively small set of syllables, we ensu</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proc. of ACL, pages 905–913.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning.</booktitle>
<editor>In B. Schalkopf, C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="24412" citStr="Joachims, 1999" startWordPosition="3889" endWordPosition="3890"> the Webderived corpora of Ghoshal et al. (2009). The syllable breaks in the respellings were mapped onto the original words using ALINE. In order to improve the quality of the data, we applied a letterto-phoneme model to both the original words and their respellings, and removed pairs with divergent pronunciations (computed as normalized edit distance &lt; 0.8). After the filtering, we were left a set of 25067 word-respelling pairs containing 78411 training syllables, which yielded 47270 positive and 31141 negative instances. For the classification task we utilize the SVMlight software package (Joachims, 1999). Each instance is represented by a set of binary indicator features. The features correspond to character n-grams (including syllable boundary markers) with the values of n ranging from 1 to 5. For example, the syllable -il- turns on the following features: i, l, -i, il, l-, -il, il-, -il-. The model learns which n-grams are characteristic of ambiguous or unambiguous syllables. For example, it classifies both le and li as am639 biguous, and lee as unambiguous. Apart from the binary classification, the classifier also provides a real-valued score for each syllable. 6.4 Lexical Reviser Since th</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale SVM learning practical. In B. Schalkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kenstowicz</author>
</authors>
<date>1994</date>
<booktitle>Phonology in Generative Grammar.</booktitle>
<publisher>Blackwell.</publisher>
<contexts>
<context position="14981" citStr="Kenstowicz, 1994" startWordPosition="2350" endWordPosition="2351">rIganal] is usually syllabified as tri-go-nal, but a better segmentation for the purposes of respelling is trig-onal. We adopt an overgenerate-and-rank approach, whereby instead of committing to a specific word segmentation at the start of the process, we process multiple syllabification alternatives in parallel, one of which is ultimately selected at the respelling evaluation stage. Ideally, syllabification should conform to the phonotactic constraints of English, so that the resulting respellings are easy to pronounce. The consonant sonority should be rising in onsets, and falling in codas (Kenstowicz, 1994). We verify that syllables follow the sonority principle by following the formulation of Bartlett et al. (2009). The sonority constraints are not tested at the boundaries of the word, which are independent of the syllabification choice. We also incorporate another important principle of English phonotactics that asserts that lax vowels do not occur in open syllables (Rogers, 2000). In our implementation, each candidate syllable is tested with respect to the following sequence of four violable constraints, ordered from the strongest to the weakest: (1) the syllable contains exactly one vowel ph</context>
</contexts>
<marker>Kenstowicz, 1994</marker>
<rawString>Michael Kenstowicz. 1994. Phonology in Generative Grammar. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kominek</author>
<author>Alan W Black</author>
</authors>
<title>Learning pronunciation dictionaries: Language complexity and word selection strategies.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL,</booktitle>
<pages>232--239</pages>
<contexts>
<context position="3731" citStr="Kominek and Black (2006)" startWordPosition="568" endWordPosition="571">ng. In this paper, we conduct two kinds of evaluations: an automated verification with an independent L2P system, and an experiment with human participants that pass judgments on different respellings of the same word. We interpret the results as evidence that the output of our system compares favourably with typical respellings found on the Web. 634 Proceedings of NAACL-HLT 2013, pages 634–643, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Definitions and Conventions Although Chomsky and Halle (1968) characterize English orthography as close to optimal, Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. There is no consensus on how to best convey the pronunciation of an uncommon word in English. Most dictionaries employ either the International Phonetic Alphabet (IPA), or their own transcription schemes that inco</context>
</contexts>
<marker>Kominek, Black, 2006</marker>
<rawString>John Kominek and Alan W Black. 2006. Learning pronunciation dictionaries: Language complexity and word selection strategies. In Proc. of HLT-NAACL, pages 232–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proc. of NAACL,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="21927" citStr="Kondrak, 2000" startWordPosition="3483" endWordPosition="3484">rated with other methods. Other differences between the two models pertain to the preprocessing of the training data, and the letter-to-phoneme alignment. As with the P2L model, the training data consists of a set of monosyllabic words from the Combilex dictionary. However, in order to make our correctness filter more conservative, we also remove all words that contain diacritics (e.g., crêpe), non-English phonemes (e.g., avant), or silent consonants (e.g., limn). The alignment is restricted to matching each letter symbol to at most one phoneme, and is derived with the ALINE phonetic aligner (Kondrak, 2000), which has been shown to outperform other 1-1 alignment methods (Jiampojamarn and Kondrak, 2010). 6.2 Vowel Counter Syllables that contain multiple vowel groups may be confusing to readers even if they correctly represent the intended pronunciation. For example, readers might be unsure whether takess represents one or two syllables. A simple vowel counter is provided to filter out such syllables. The vowel filter accepts a syllable only if (a) it contains exactly one vowel group (e.g., moe), or (b) the second vowel group consists of a single e at the end of the syllable (e.g., zake). 6.3 SVM </context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In Proc. of NAACL, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Noble</author>
</authors>
<date>2012</date>
<note>Lonely Planet, 13th edition.</note>
<contexts>
<context position="1107" citStr="Noble, 2012" startWordPosition="165" endWordPosition="166">electronic resources. We evaluate our system both intrinsically through a human judgment experiment, and extrinsically by passing its output to a letterto-phoneme converter. The results show that the respellings generated by our system are better on average than those found on the Web, and approach the quality of respellings designed by an expert. 1 Introduction Respellings are a widely employed method of conveying the pronunciation of English and foreign words, both in print and on the Web. For example, Huatulco, the name of a Mexican resort, is respelled as ‘wah-tool-koh’ in a travel guide (Noble, 2012). The advantage of using respellings lies in removing the need for a separately defined phonetic transcription system. Since they contain only the letters of the Latin alphabet, their phonetic interpretation relies exclusively on orthographic intuitions of readers. For this reason, respellings are widely used in travel phrase books, medical compendia, and drug name pronunciation guides, among others. Despite their utility, good respellings are not easy to create. Respellings found on the Web often contain errors or ambiguities. For example, HenochSchoenlein purpura, a skin disease, is respelle</context>
</contexts>
<marker>Noble, 2012</marker>
<rawString>John Noble. 2012. Mexico. Lonely Planet, 13th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Korin Richmond</author>
<author>Robert Clark</author>
<author>Sue Fitt</author>
</authors>
<title>Robust LTS rules with the Combilex speech technology lexicon.</title>
<date>2009</date>
<booktitle>In Proc. of Interspeech,</booktitle>
<pages>1295--1298</pages>
<contexts>
<context position="12180" citStr="Richmond et al., 2009" startWordPosition="1888" endWordPosition="1891"> such respellings are arguably both unambiguous and correct. Unfortunately, only a subset of potential phonemic syllables actually occur in a lexicon. Considering only the syllables of the CVC type (consonantvowel-consonant), there are over ten thousand distinct possibilities (e.g., [beb], [bef], etc.), of which 3For example, the word capoeira is represented by 99 different respellings in the corpus of Ghoshal et al. (2009). 4For an example of a confusing respelling guide see http: //www.ama-assn.org/go/usan. 636 fewer than three thousand can be found in the Combilex pronunciation dictionary (Richmond et al., 2009). While the dictionary lookup may produce attractive respellings, it is not sufficient for a standalone use. 4.3 Phonemic Respelling A simple method that can produce a respelling for any word is to directly map each phoneme to a particular letter or a letter sequence that is frequently used to represent that phoneme. Phonemes such as [m], [d] and [f] are indeed closely associated with individual letters. This is not surprising since the Roman letters were originally created to represent single phonemes in Latin, and some of those phonemes also exist in English. However, many phonemes, especial</context>
</contexts>
<marker>Richmond, Clark, Fitt, 2009</marker>
<rawString>Korin Richmond, Robert Clark, and Sue Fitt. 2009. Robust LTS rules with the Combilex speech technology lexicon. In Proc. of Interspeech, pages 1295–1298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Rogers</author>
</authors>
<title>The Sounds of Language.</title>
<date>2000</date>
<publisher>Pearson.</publisher>
<contexts>
<context position="15364" citStr="Rogers, 2000" startWordPosition="2411" endWordPosition="2412">Ideally, syllabification should conform to the phonotactic constraints of English, so that the resulting respellings are easy to pronounce. The consonant sonority should be rising in onsets, and falling in codas (Kenstowicz, 1994). We verify that syllables follow the sonority principle by following the formulation of Bartlett et al. (2009). The sonority constraints are not tested at the boundaries of the word, which are independent of the syllabification choice. We also incorporate another important principle of English phonotactics that asserts that lax vowels do not occur in open syllables (Rogers, 2000). In our implementation, each candidate syllable is tested with respect to the following sequence of four violable constraints, ordered from the strongest to the weakest: (1) the syllable contains exactly one vowel phoneme; (2) the onset satisfies the sonority principle; (3) if the nucleus contains a lax vowel (except a), the coda is non-empty; (4) the coda satisfies the sonority principle. For a syllabification to be accepted, all its syllables must satisfy the four constraints. However, if this results in rejection of all possible syllabifications, the constraints are gradually relaxed start</context>
</contexts>
<marker>Rogers, 2000</marker>
<rawString>Henry Rogers. 2000. The Sounds of Language. Pearson.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Briony Williams</author>
<author>Rhys James Jones</author>
</authors>
<title>Acquiring pronunciation data for a placenames lexicon in a less-resourced language. In</title>
<date>2008</date>
<booktitle>Proc. of LREC.</booktitle>
<contexts>
<context position="9706" citStr="Williams and Jones (2008)" startWordPosition="1498" endWordPosition="1501"> is also expressed implicitly if only one of the alternative respellings is judged as unambiguous (or correct), 3 Related Work Fraser (1997) describes an experiment in which 15 human subjects were asked to pronounce uncommon words after being shown a representation of their pronunciation. The respellings designed by the author were much more effective for that purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. Ghoshal et al. (2009) extract a large number of respellings from the Web, and show that they can be exploited to improve the accuracy of the L2P conversion by supplementing the data in pronunciation dictionaries. Can et al. (2009) further analyze the effect of usi</context>
</contexts>
<marker>Williams, Jones, 2008</marker>
<rawString>Briony Williams and Rhys James Jones. 2008. Acquiring pronunciation data for a placenames lexicon in a less-resourced language. In Proc. of LREC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>