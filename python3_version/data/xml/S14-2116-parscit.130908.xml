<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014883">
<title confidence="0.9985525">
ThinkMiners: Disorder Recognition using Conditional Random Fields
and Distributional Semantics
</title>
<author confidence="0.853242">
Ankur Parikh Avinesh PVS Joy Mustafi Lalit Agarwalla Ashish Mungi
</author>
<affiliation confidence="0.857268">
IBM India Pvt Ltd, IBM Software Group, Watson
</affiliation>
<email confidence="0.982382">
{anparikh,pavinesh,jmustafi,lalit.agarwalla,r1amungi}@in.ibm.com
</email>
<sectionHeader confidence="0.997204" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99496292">
In 2014, SemEval organized multiple chal-
lenges on natural language processing and
information retrieval. One of the task was
analysis of the clinical text. This challenge
is further divided into two tasks. The task
A of the challenge was to extract disor-
der mention spans in the clinical text and
the task B was to map each of the disor-
der mentions to a unique Unified Medical
Language System Concept Unique Iden-
tifier. We participated in the task A and
developed a clinical disorder recognition
system. The proposed system consists of
a Conditional Random Fields based ap-
proach to recognize disorder entities. The
SemEval challenge organizers manually
annotated disorder entities in 298 clini-
cal notes, of which 199 notes were used
for training and 99 for development. On
the test data, our system achieved the F-
measure of 0.844 for entity recognition in
relaxed and 0.689 in strict evaluation.
Keywords: medical language processing,
clinical concept extraction, conditional
random fields.
</bodyText>
<sectionHeader confidence="0.999488" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.893281">
Mining concepts from the electronic medical
records such as clinical reports, discharge sum-
maries as well as large number of doctor’s notes
has become an utmost important task for auto-
matic analysis in the medical domain. Identifica-
tion and mapping of the concepts like symptoms,
disorders, surgical procedures, body sites to a nor-
malized standards are usually the first steps to-
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
wards understanding natural language text in the
medical records.
In this paper, we describe a machine learning
based disorder recognition system for the Task 7A
of 2014 SemEval challenge. In Section 2 we give
a background of the existing solutions to tackle
the problem. Section 3 covers our approach in
detail, followed by evaluation and conclusion in
Section 4 and Section 5 respectively.
</bodyText>
<sectionHeader confidence="0.993214" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999959866666667">
In recent times, many systems have been de-
veloped to extract clinical concepts from vari-
ous types of clinical notes. The earlier nat-
ural language processing (NLP) systems were
mainly built heavily using domain knowledge
i.e. medical dictionaries. These systems in-
clude MetaMap (Aronson and Lang, 2010), Hi-
TEX (Zeng et al., 2006), KnowledgeMap (Denny
et al., 2003), MedLEE (Friedman et al., 1994),
SymText (Koehler, 1994) and Mplus (Christensen
et al., 2002). In the past couple of years, re-
searchers have been exploring the use of machine
learning algorithms in the clinical concept detec-
tion. To promote the research in this field many or-
ganizations such as ShARe/CLEF, SemEval have
organized a few clinical NLP challenges. In CLEF
2013 (Pradhan et al., 2013), the challenge was to
recognize medication-related concepts. Both rule-
based (Fan et al., 2013; Ramanan et al., 2013;
Wang and Akella, 2013) and machine learning
based methods as well as hybrid methods (Xia
et al., 2013; Osborne et al., 2013; Hervas et al.,
2013) were developed. In this shared-task sequen-
tial labeling algorithms (i.e., Conditional Random
Fields (CRF)) (Gung, 2013; Patrick et al., 2013;
Bodnari et al., 2013; Zuccon et al., 2013) and ma-
chine learning methods (i.e., Support Vector Ma-
chine (SVM)) (Cogley et al., 2013) have been
demonstrated to achieve promising performance
when provided with a large annotated corpus for
</bodyText>
<page confidence="0.980033">
652
</page>
<note confidence="0.8309865">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656,
Dublin, Ireland, August 23-24, 2014.
</note>
<figureCaption confidence="0.99972">
Figure 1: Dataset distribution
</figureCaption>
<bodyText confidence="0.75045">
training.
</bodyText>
<sectionHeader confidence="0.996833" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999794333333333">
Entity recognition has been tried in various do-
mains like news articles, Wikipedia, sports arti-
cles, financial reports and clinical texts. In clinical
text, entities can vary from medical procedures,
disorders, body site indicators etc. Clinical text
also presents with a peculiar concept of disjoint
disorders/entities. This phenomenon is common
in clinical domain compared to others and further
complicates entity extraction from clinical notes.
</bodyText>
<subsectionHeader confidence="0.996328">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999877">
The data consisted of around 298 notes from dif-
ferent clinical types including radiology reports,
discharge summaries, ECG and ECHO reports.
For each note, disorder entities were annotated
based on a pre-defined guidelines. The data set
was further divided into two, with 199 notes in the
training set and 99 notes in the development set.
The training set contains 5811 disorders where as
the development contained 5340 disorders. Figure
1 shows the distribution of the training and devel-
opment set respectively.
</bodyText>
<subsectionHeader confidence="0.999638">
3.2 Data Preprocessing
</subsectionHeader>
<bodyText confidence="0.999801777777778">
In the pre-processing step we tokenized, lemma-
tized and tagged the text with part of speech us-
ing the Apache cTAKES1 (Savova et al., 2010).
Further, section and source meta data extraction is
done for the text in the documents.
In Named Entity Recognition (NER), when
solved using machine learning, the text is typically
converted to BIO format (Beginning, Inside and
Outside the entity). BIO representation means the
</bodyText>
<footnote confidence="0.910464">
1https://ctakes.apache.org/
</footnote>
<bodyText confidence="0.999875">
words in the text are assigned one of the follow-
ing tags B - begin, I - inside and O - outside of the
entity i.e. in this case a disorder. So now the task
of NER is a sequence labeling problem to assign
the labels to the tokens. Especially in the medical
domain, the challenge is more complicated due to
the presence of disjoint disorders (&lt;10%), which
could not be solved using the traditional BIO-
notation. BIO approach works well with entities
which are consecutive. So, we took an enhanced
approach (Tang et al., 2013a) where the consec-
utive disorders are assigned traditional BIO tags
and for disjoint disorders we create two tag sets a)
D{B,I} : for disjoint entity words which are not
shared by multiple concepts; and b) H{B,I}: for
disjoint entity words which belong to more than
one disjoint concept.
The following examples show the annotations
of consecutive as well as disjoint disorders.
</bodyText>
<listItem confidence="0.9898746">
1: “The left atrium is moderately dilated.”
“The/O left/DB atrium/DI is/O moderately/O
dilated/DB ./O”
2: “The left &amp; right atrium are moderately
dilated.”
</listItem>
<construct confidence="0.384562">
“The/O left/DB &amp;/O right/DB atrium/HB are/O
moderately/O dilated/HB ./O”
</construct>
<subsectionHeader confidence="0.999902">
3.3 Sequence Labeling
</subsectionHeader>
<bodyText confidence="0.9999425">
We have used Conditional Random Fields (CRF),
a popular approach to solve sequence labeling
tasks. CRF++2 was used as an implementation of
CRF for our purpose.
</bodyText>
<footnote confidence="0.936131">
2http://crfpp.googlecode.com/svn/trunk/doc/index.html
</footnote>
<page confidence="0.99858">
653
</page>
<bodyText confidence="0.992759">
Feature set used for the learning algorithm:
</bodyText>
<listItem confidence="0.995728785714286">
• Word level features: words [-2,2], suffix and
prefix.
• Syntactic features: parts-of-speech(POS).
• Discourse features: source &amp; section. Sen-
tence containing disorder mentions usually
have similar syntactic patterns based on sec-
tions (ex: ‘Past Medical History’) and source
type (ex: discharge summary, radiology re-
port). To capture this, source and section
meta data have been provided as a feature.
• Distributional semantics: We used a con-
textual similarity based approach from the
popular concept called NC-value (Frantzi et
al., 2000).
</listItem>
<bodyText confidence="0.999199166666667">
We followed the following steps to encap-
sulate the distributional semantics into the
learning model:
– For all the disorders in the training data
we created two sets of contextual words
namely context before (CBatrain) and
context after (CAatrain). These words
belong to open class (Noun, Verb, Ad-
jective, Adverb) allocated for each sec-
tion (Sj).
– Weights are calculated for the contex-
tual words.
</bodyText>
<equation confidence="0.9891445">
Weight(btrain) = freq(disorders,b)
freq(disorders)
</equation>
<bodyText confidence="0.99810025">
– For each word in the test data we created
a similar sets of contextual words(CBa,
CAa) as above.
– Two scores are calculated for each
token based on the product of frequency
of the contextual word per section Sj
with weight calculated of that word in
the training set.
</bodyText>
<equation confidence="0.9832286">
For each section (Sj):
XNC−valueB(a) _ fa(btest)*weight(btrain)
beCBa,Sj
XNC−valueA(a) _ fa(btest)*weight(btrain)
beCAa,Sj
</equation>
<bodyText confidence="0.940536741935484">
where
a is the candidate term,
CBa is the set of context words of “a”
in a window of [-2,0],
CAa is the set of context words of “a”
in a window of [0,2],
Sj is a section like “Past Medical
History”, “Lab Reports” etc.
b is a word from CBa or CAa,
fa(btest) is the frequency of b as a term
context word of “a” in the test set,
weight(btrain) is the weight of b as term
context word of a disorder in the
training set,
NC-valueB(a) is the distributional
semantic score of contextual words
before the candidate term,
NC-valueA(a) is the distributional
semantic score of contextual words
after the candidate term.
– Further a similarity class is calculated
based on a set of thresholds on the
NC-value namely High-Sim, Med-Sim,
Low-Sim and assigned to the tokens.
Most of the features were similar to that of the pre-
vious approaches (Tang et al., 2013a; Tang et al.,
2012; Tang et al., 2013; Jiang et al., 2011) with an
addition of an innovative distributional semantics
based features (Nc-valueB, NC-valueA), which we
have tried and tested for concept mining in clinical
text.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999933833333333">
The evaluation was done in two categories a) strict
evaluation: exact match, which requires the start-
ing and ending of the concept to be the same as
the gold standard data b) relaxed evaluation: here
the concepts don’t match exactly with the start and
end of the concept but may overlap.
In the strict and relaxed evaluation, the best F-
measure among our system was 0.689, 0.844 with-
out the distributional semantics where as best Pre-
cision was 0.907, 0.749 with the distributional se-
mantics as a feature. Table 1. shows the detailed
result.
</bodyText>
<sectionHeader confidence="0.999019" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9998122">
Extraction of the concepts from the medical text
is the fundamental task in the process of analysing
patient data. In this paper we have tried a CRF
based approach to mine the disorder terms from
the clinical free text. We have tried various word
</bodyText>
<page confidence="0.998397">
654
</page>
<table confidence="0.999057333333333">
SemEval-2014 Strict Relaxed
Shared Task 7A
Precision Recall F-measure Precision Recall F-measure
Disorder Recognition 0.734 0.65 0.689 0.892 0.802 0.844
without Distributional
Semantics Feature
Disorder Recognition 0.749 0.617 0.677 0.907 0.758 0.826
with Distributional
Semantics Feature
</table>
<tableCaption confidence="0.999942">
Table 1: Results of the system on test set
</tableCaption>
<bodyText confidence="0.999831055555556">
level, syntactic, discourse and distributional se-
mantic based features as adapted to the medical
domain.
We have observed an increase (+1.5%) in pre-
cision but a drastic fall (-4.4%) in recall while
using the distributional semantic feature. Ideally
this feature has to improve the results because it
takes contextual features into consideration. In our
opinion inappropriate scaling of the feature values
might have caused the drop. Further we would
like to investigate the use of large unlabeled data,
dependency tree based context and more experi-
ments have to be carried out like threshold setting,
feature value scaling to show better results. Also
due to license issues we could not use UMLS dic-
tionary. From our survey we figured out that 2-3%
of improvement has been observed when the con-
cepts from the dictionary are used.
</bodyText>
<sectionHeader confidence="0.992556" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.966734770491804">
B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu.
2013. Recognizing clinical entities in hospital dis-
charge summaries using Structural Support Vector
Machines with word representation features. BMC
Med Inform Decis Mak, vol. 13 Suppl 1, p. S1.
M. Jiang, Y. Chen, M. Liu, S. T. Rosenbloom, S. Mani,
J. C. Denny, and H. Xu. 2011. A study of machine-
learning-based approaches to extract clinical enti-
ties and their assertions from discharge summaries.
J Am Med Inform Assoc, vol. 18, no. 5, pp. 601606.
B. Tang, Y. Wu, M. Jiang, Y. Chen, J. C. Denny, and H.
Xu. 2013. A hybrid system for temporal informa-
tion extraction from clinical text. J Am Med Inform
Assoc.
B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu. 2012.
Clinical entity recognition using structural support
vector machines with rich features. in Proceedings
of the ACM sixth international workshop on Data
and text mining in biomedical informatics, New
York, NY, USA, pp. 1320.
C. Friedman, P. O. Alderson, J. H. Austin, J. J. Cimino,
and S. B. Johnson. 1994. A general natural-
language text processorfor clinical radiology. J Am
Med Inform Assoc, vol. 1, no. 2, pp. 161174.
S. B. Koehler. 1994. SymText: a natural language un-
derstanding system for encoding free text medical
data. University of Utah.
L. M. Christensen, P. J. Haug, and M. Fiszman. 2002.
MPLUS: a probabilistic medical language under-
standing system. in Proceedings of the ACL-02
workshop on Natural language processing in the
biomedical domain - Volume 3, Stroudsburg, PA,
USA, pp. 2936.
J. C. Denny, P. R. Irani, F. H. Wehbe, J. D. Smithers,
and A. Spickard. 2003. The KnowledgeMap
Project: Development of a Concept-Based Medical
School Curriculum Database. AMIA Annu Symp
Proc, vol. 2003, pp. 195199.
G. K. Savova, J. J. Masanz, P. V. Ogren, J. Zheng,
S. Sohn, K. C. Kipper Schuler, and C. G. Chute.
2010. Mayo clinical Text Analysis and Knowledge
Extraction System (cTAKES): architecture, compo-
nent evaluation and applications. J Am Med Inform
Assoc, vol. 17, no. 5, pp. 507513.
Q. T. Zeng, S. Goryachev, S. Weiss, M. Sordo, S. N.
Murphy, and R. Lazarus. 2006. Extracting princi-
pal diagnosis, co-morbidity and smoking status for
asthma research: evaluation of a natural language
processing system. BMC Med Inform Decis Mak,
vol. 6, p. 30.
A. R. Aronson and F. M. Lang. 2010. An overview
of MetaMap: historical perspective and recent ad-
vances. J Am Med Inform Assoc, vol. 17, no. 3, pp.
229236.
. Uzuner, I. Solti, and E. Cadag. 2010. Extracting med-
ication information from clinical text. J Am Med
Inform Assoc, vol. 17, no. 5, pp. 514518.
Katerina Frantzi, Sophia Ananiadou, and Hideki Mima
2000. Automatic recognition of multi-word terms:.
the C-value/NC-value method. International Journal
on Digital Libraries 3(2):115–130.
</reference>
<page confidence="0.995136">
655
</page>
<reference confidence="0.992362670731707">
James Cogley, Nicola Stokes and Joe Carthy. 2013.
Medical Disorder Recognition with Structural Sup-
port Vector Machines. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.
Robert Leaman, Ritu Khare and Zhiyong Lu. 2013.
NCBI at 2013 ShARe/CLEF eHealth Shared Task:
Disorder Normalization in Clinical Notes with
Dnorm. Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.
James Gung. 2013. Using Relations for Identifica-
tion and Normalization of Disorders: Team CLEAR
in the ShARe/CLEF 2013 eHealth Evaluation Lab.
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.
Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jon-
nalagadda and Sunghwan Sohn. 2013. Integrated
cTAKES for Concept Mention Detection and Nor-
malization. Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.
Jon D. Patrick, Leila Safari and Ying Ou. 2013.
ShARe/CLEF eHealth 2013 Named Entity Recogni-
tion and Normalization of Disorders Challenge. On-
line Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.
Andreea Bodnari, Louise Deleger, Thomas Lavergne,
Aurelie Neveol and Pierre Zweigenbaum. 2013.
A Supervised Named-Entity Extraction System for
Medical Text. Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.
Guido Zuccon, Alexander Holloway, Bevan Koop-
man and Anthony Nguyen. 2013. Identify Disor-
ders in Health Records using Conditional Random
Fields and Metamap AEHRC at ShARe/CLEF 2013
eHealth Evaluation Lab Task 1. Online Working
Notes of the CLEF 2013 Evaluation Labs and Work-
shop, 23 - 26 September, Valencia - Spain.
Jung-wei Fan, Navdeep Sood and Yang Huang. 2013.
Disorder Concept Identification from Clinical Notes
An Experience with the ShARe/CLEF 2013 Chal-
lenge. Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.
S. V. Ramanan, Shereen Broido and P. Senthil Nathan.
2013. Performance of a multi-class biomedical tag-
ger on clinical records. Online Working Notes of
the CLEF 2013 Evaluation Labs and Workshop, 23
- 26 September, Valencia - Spain.
Chunye Wang and Ramakrishna Akella. 2013. Perfor-
mance of a multi-class biomedical tagger on clinical
records. Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.
Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan,
Sen Na, Qinan Hu and Yaohai Huang. 2013. Com-
bining MetaMap and cTAKES in Disorder Recog-
nition: THCIB at CLEF eHealth Lab 2013 Task 1.
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.
John David Osborne, Binod Gyawali and Thamar
Solorio. 2013. Evaluation of YTEX and MetaMap
for clinical concept recognition. Online Working
Notes of the CLEF 2013 Evaluation Labs and Work-
shop, 23 - 26 September, Valencia - Spain.
Lucia Hervas, Victor Martinez, Irene Sanchez and
Alberto Diaz. 2013. UCM at CLEF eHealth
2013 Shared Task1. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.
Sameer Pradhan, Noemie Elhadad, Brett R. South,
David Martinez, Lee Christensen, Amy Vogel,
Hanna Suominen, Wendy W. Chapman and Guer-
gana Savova. 2013. Task 1: ShARe/CLEF eHealth
Evaluation Lab 2013. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.
</reference>
<page confidence="0.998913">
656
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909611">
<title confidence="0.978258">ThinkMiners: Disorder Recognition using Conditional Random and Distributional Semantics</title>
<author confidence="0.991672">Ankur Parikh Avinesh PVS Joy Mustafi Lalit Agarwalla Ashish Mungi</author>
<affiliation confidence="0.99967">IBM India Pvt Ltd, IBM Software Group,</affiliation>
<abstract confidence="0.997360461538461">In 2014, SemEval organized multiple challenges on natural language processing and information retrieval. One of the task was analysis of the clinical text. This challenge is further divided into two tasks. The task A of the challenge was to extract disorder mention spans in the clinical text and the task B was to map each of the disorder mentions to a unique Unified Medical Language System Concept Unique Identifier. We participated in the task A and developed a clinical disorder recognition system. The proposed system consists of a Conditional Random Fields based approach to recognize disorder entities. The SemEval challenge organizers manually annotated disorder entities in 298 clinical notes, of which 199 notes were used for training and 99 for development. On the test data, our system achieved the Fmeasure of 0.844 for entity recognition in relaxed and 0.689 in strict evaluation. language processing, clinical concept extraction, conditional random fields.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Tang</author>
<author>H Cao</author>
<author>Y Wu</author>
<author>M Jiang</author>
<author>H Xu</author>
</authors>
<title>Recognizing clinical entities in hospital discharge summaries using Structural Support Vector Machines with word representation features.</title>
<date>2013</date>
<journal>BMC Med Inform Decis Mak,</journal>
<volume>13</volume>
<pages>1</pages>
<contexts>
<context position="5836" citStr="Tang et al., 2013" startWordPosition="906" endWordPosition="909">inning, Inside and Outside the entity). BIO representation means the 1https://ctakes.apache.org/ words in the text are assigned one of the following tags B - begin, I - inside and O - outside of the entity i.e. in this case a disorder. So now the task of NER is a sequence labeling problem to assign the labels to the tokens. Especially in the medical domain, the challenge is more complicated due to the presence of disjoint disorders (&lt;10%), which could not be solved using the traditional BIOnotation. BIO approach works well with entities which are consecutive. So, we took an enhanced approach (Tang et al., 2013a) where the consecutive disorders are assigned traditional BIO tags and for disjoint disorders we create two tag sets a) D{B,I} : for disjoint entity words which are not shared by multiple concepts; and b) H{B,I}: for disjoint entity words which belong to more than one disjoint concept. The following examples show the annotations of consecutive as well as disjoint disorders. 1: “The left atrium is moderately dilated.” “The/O left/DB atrium/DI is/O moderately/O dilated/DB ./O” 2: “The left &amp; right atrium are moderately dilated.” “The/O left/DB &amp;/O right/DB atrium/HB are/O moderately/O dilated/</context>
<context position="8961" citStr="Tang et al., 2013" startWordPosition="1404" endWordPosition="1407"> from CBa or CAa, fa(btest) is the frequency of b as a term context word of “a” in the test set, weight(btrain) is the weight of b as term context word of a disorder in the training set, NC-valueB(a) is the distributional semantic score of contextual words before the candidate term, NC-valueA(a) is the distributional semantic score of contextual words after the candidate term. – Further a similarity class is calculated based on a set of thresholds on the NC-value namely High-Sim, Med-Sim, Low-Sim and assigned to the tokens. Most of the features were similar to that of the previous approaches (Tang et al., 2013a; Tang et al., 2012; Tang et al., 2013; Jiang et al., 2011) with an addition of an innovative distributional semantics based features (Nc-valueB, NC-valueA), which we have tried and tested for concept mining in clinical text. 4 Evaluation The evaluation was done in two categories a) strict evaluation: exact match, which requires the starting and ending of the concept to be the same as the gold standard data b) relaxed evaluation: here the concepts don’t match exactly with the start and end of the concept but may overlap. In the strict and relaxed evaluation, the best Fmeasure among our system</context>
</contexts>
<marker>Tang, Cao, Wu, Jiang, Xu, 2013</marker>
<rawString>B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu. 2013. Recognizing clinical entities in hospital discharge summaries using Structural Support Vector Machines with word representation features. BMC Med Inform Decis Mak, vol. 13 Suppl 1, p. S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jiang</author>
<author>Y Chen</author>
<author>M Liu</author>
<author>S T Rosenbloom</author>
<author>S Mani</author>
<author>J C Denny</author>
<author>H Xu</author>
</authors>
<title>A study of machinelearning-based approaches to extract clinical entities and their assertions from discharge summaries.</title>
<date>2011</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>18</volume>
<pages>601606</pages>
<contexts>
<context position="9021" citStr="Jiang et al., 2011" startWordPosition="1416" endWordPosition="1419">m context word of “a” in the test set, weight(btrain) is the weight of b as term context word of a disorder in the training set, NC-valueB(a) is the distributional semantic score of contextual words before the candidate term, NC-valueA(a) is the distributional semantic score of contextual words after the candidate term. – Further a similarity class is calculated based on a set of thresholds on the NC-value namely High-Sim, Med-Sim, Low-Sim and assigned to the tokens. Most of the features were similar to that of the previous approaches (Tang et al., 2013a; Tang et al., 2012; Tang et al., 2013; Jiang et al., 2011) with an addition of an innovative distributional semantics based features (Nc-valueB, NC-valueA), which we have tried and tested for concept mining in clinical text. 4 Evaluation The evaluation was done in two categories a) strict evaluation: exact match, which requires the starting and ending of the concept to be the same as the gold standard data b) relaxed evaluation: here the concepts don’t match exactly with the start and end of the concept but may overlap. In the strict and relaxed evaluation, the best Fmeasure among our system was 0.689, 0.844 without the distributional semantics where</context>
</contexts>
<marker>Jiang, Chen, Liu, Rosenbloom, Mani, Denny, Xu, 2011</marker>
<rawString>M. Jiang, Y. Chen, M. Liu, S. T. Rosenbloom, S. Mani, J. C. Denny, and H. Xu. 2011. A study of machinelearning-based approaches to extract clinical entities and their assertions from discharge summaries. J Am Med Inform Assoc, vol. 18, no. 5, pp. 601606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tang</author>
<author>Y Wu</author>
<author>M Jiang</author>
<author>Y Chen</author>
<author>J C Denny</author>
<author>H Xu</author>
</authors>
<title>A hybrid system for temporal information extraction from clinical text.</title>
<date>2013</date>
<journal>J Am Med Inform Assoc.</journal>
<contexts>
<context position="5836" citStr="Tang et al., 2013" startWordPosition="906" endWordPosition="909">inning, Inside and Outside the entity). BIO representation means the 1https://ctakes.apache.org/ words in the text are assigned one of the following tags B - begin, I - inside and O - outside of the entity i.e. in this case a disorder. So now the task of NER is a sequence labeling problem to assign the labels to the tokens. Especially in the medical domain, the challenge is more complicated due to the presence of disjoint disorders (&lt;10%), which could not be solved using the traditional BIOnotation. BIO approach works well with entities which are consecutive. So, we took an enhanced approach (Tang et al., 2013a) where the consecutive disorders are assigned traditional BIO tags and for disjoint disorders we create two tag sets a) D{B,I} : for disjoint entity words which are not shared by multiple concepts; and b) H{B,I}: for disjoint entity words which belong to more than one disjoint concept. The following examples show the annotations of consecutive as well as disjoint disorders. 1: “The left atrium is moderately dilated.” “The/O left/DB atrium/DI is/O moderately/O dilated/DB ./O” 2: “The left &amp; right atrium are moderately dilated.” “The/O left/DB &amp;/O right/DB atrium/HB are/O moderately/O dilated/</context>
<context position="8961" citStr="Tang et al., 2013" startWordPosition="1404" endWordPosition="1407"> from CBa or CAa, fa(btest) is the frequency of b as a term context word of “a” in the test set, weight(btrain) is the weight of b as term context word of a disorder in the training set, NC-valueB(a) is the distributional semantic score of contextual words before the candidate term, NC-valueA(a) is the distributional semantic score of contextual words after the candidate term. – Further a similarity class is calculated based on a set of thresholds on the NC-value namely High-Sim, Med-Sim, Low-Sim and assigned to the tokens. Most of the features were similar to that of the previous approaches (Tang et al., 2013a; Tang et al., 2012; Tang et al., 2013; Jiang et al., 2011) with an addition of an innovative distributional semantics based features (Nc-valueB, NC-valueA), which we have tried and tested for concept mining in clinical text. 4 Evaluation The evaluation was done in two categories a) strict evaluation: exact match, which requires the starting and ending of the concept to be the same as the gold standard data b) relaxed evaluation: here the concepts don’t match exactly with the start and end of the concept but may overlap. In the strict and relaxed evaluation, the best Fmeasure among our system</context>
</contexts>
<marker>Tang, Wu, Jiang, Chen, Denny, Xu, 2013</marker>
<rawString>B. Tang, Y. Wu, M. Jiang, Y. Chen, J. C. Denny, and H. Xu. 2013. A hybrid system for temporal information extraction from clinical text. J Am Med Inform Assoc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tang</author>
<author>H Cao</author>
<author>Y Wu</author>
<author>M Jiang</author>
<author>H Xu</author>
</authors>
<title>Clinical entity recognition using structural support vector machines with rich features.</title>
<date>2012</date>
<booktitle>in Proceedings of the ACM sixth international workshop on Data and text mining in biomedical informatics,</booktitle>
<pages>1320</pages>
<location>New York, NY, USA,</location>
<contexts>
<context position="8981" citStr="Tang et al., 2012" startWordPosition="1408" endWordPosition="1411">(btest) is the frequency of b as a term context word of “a” in the test set, weight(btrain) is the weight of b as term context word of a disorder in the training set, NC-valueB(a) is the distributional semantic score of contextual words before the candidate term, NC-valueA(a) is the distributional semantic score of contextual words after the candidate term. – Further a similarity class is calculated based on a set of thresholds on the NC-value namely High-Sim, Med-Sim, Low-Sim and assigned to the tokens. Most of the features were similar to that of the previous approaches (Tang et al., 2013a; Tang et al., 2012; Tang et al., 2013; Jiang et al., 2011) with an addition of an innovative distributional semantics based features (Nc-valueB, NC-valueA), which we have tried and tested for concept mining in clinical text. 4 Evaluation The evaluation was done in two categories a) strict evaluation: exact match, which requires the starting and ending of the concept to be the same as the gold standard data b) relaxed evaluation: here the concepts don’t match exactly with the start and end of the concept but may overlap. In the strict and relaxed evaluation, the best Fmeasure among our system was 0.689, 0.844 wi</context>
</contexts>
<marker>Tang, Cao, Wu, Jiang, Xu, 2012</marker>
<rawString>B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu. 2012. Clinical entity recognition using structural support vector machines with rich features. in Proceedings of the ACM sixth international workshop on Data and text mining in biomedical informatics, New York, NY, USA, pp. 1320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>P O Alderson</author>
<author>J H Austin</author>
<author>J J Cimino</author>
<author>S B Johnson</author>
</authors>
<title>A general naturallanguage text processorfor clinical radiology.</title>
<date>1994</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>1</volume>
<pages>161174</pages>
<contexts>
<context position="2678" citStr="Friedman et al., 1994" startWordPosition="403" endWordPosition="406">challenge. In Section 2 we give a background of the existing solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al.</context>
</contexts>
<marker>Friedman, Alderson, Austin, Cimino, Johnson, 1994</marker>
<rawString>C. Friedman, P. O. Alderson, J. H. Austin, J. J. Cimino, and S. B. Johnson. 1994. A general naturallanguage text processorfor clinical radiology. J Am Med Inform Assoc, vol. 1, no. 2, pp. 161174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S B Koehler</author>
</authors>
<title>SymText: a natural language understanding system for encoding free text medical data.</title>
<date>1994</date>
<institution>University of Utah.</institution>
<contexts>
<context position="2703" citStr="Koehler, 1994" startWordPosition="408" endWordPosition="409"> background of the existing solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 20</context>
</contexts>
<marker>Koehler, 1994</marker>
<rawString>S. B. Koehler. 1994. SymText: a natural language understanding system for encoding free text medical data. University of Utah.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L M Christensen</author>
<author>P J Haug</author>
<author>M Fiszman</author>
</authors>
<title>MPLUS: a probabilistic medical language understanding system.</title>
<date>2002</date>
<booktitle>in Proceedings of the ACL-02 workshop on Natural language processing in the biomedical domain - Volume 3,</booktitle>
<pages>2936</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="2740" citStr="Christensen et al., 2002" startWordPosition="412" endWordPosition="415">g solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-ta</context>
</contexts>
<marker>Christensen, Haug, Fiszman, 2002</marker>
<rawString>L. M. Christensen, P. J. Haug, and M. Fiszman. 2002. MPLUS: a probabilistic medical language understanding system. in Proceedings of the ACL-02 workshop on Natural language processing in the biomedical domain - Volume 3, Stroudsburg, PA, USA, pp. 2936.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Denny</author>
<author>P R Irani</author>
<author>F H Wehbe</author>
<author>J D Smithers</author>
<author>A Spickard</author>
</authors>
<title>The KnowledgeMap Project: Development of a Concept-Based Medical School Curriculum Database.</title>
<date>2003</date>
<journal>AMIA Annu Symp Proc,</journal>
<volume>vol.</volume>
<pages>195199</pages>
<contexts>
<context position="2646" citStr="Denny et al., 2003" startWordPosition="398" endWordPosition="401"> the Task 7A of 2014 SemEval challenge. In Section 2 we give a background of the existing solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (</context>
</contexts>
<marker>Denny, Irani, Wehbe, Smithers, Spickard, 2003</marker>
<rawString>J. C. Denny, P. R. Irani, F. H. Wehbe, J. D. Smithers, and A. Spickard. 2003. The KnowledgeMap Project: Development of a Concept-Based Medical School Curriculum Database. AMIA Annu Symp Proc, vol. 2003, pp. 195199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Savova</author>
<author>J J Masanz</author>
<author>P V Ogren</author>
<author>J Zheng</author>
<author>S Sohn</author>
<author>K C Kipper Schuler</author>
<author>C G Chute</author>
</authors>
<title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications.</title>
<date>2010</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>17</volume>
<pages>507513</pages>
<contexts>
<context position="5008" citStr="Savova et al., 2010" startWordPosition="766" endWordPosition="769">clinical types including radiology reports, discharge summaries, ECG and ECHO reports. For each note, disorder entities were annotated based on a pre-defined guidelines. The data set was further divided into two, with 199 notes in the training set and 99 notes in the development set. The training set contains 5811 disorders where as the development contained 5340 disorders. Figure 1 shows the distribution of the training and development set respectively. 3.2 Data Preprocessing In the pre-processing step we tokenized, lemmatized and tagged the text with part of speech using the Apache cTAKES1 (Savova et al., 2010). Further, section and source meta data extraction is done for the text in the documents. In Named Entity Recognition (NER), when solved using machine learning, the text is typically converted to BIO format (Beginning, Inside and Outside the entity). BIO representation means the 1https://ctakes.apache.org/ words in the text are assigned one of the following tags B - begin, I - inside and O - outside of the entity i.e. in this case a disorder. So now the task of NER is a sequence labeling problem to assign the labels to the tokens. Especially in the medical domain, the challenge is more complic</context>
</contexts>
<marker>Savova, Masanz, Ogren, Zheng, Sohn, Schuler, Chute, 2010</marker>
<rawString>G. K. Savova, J. J. Masanz, P. V. Ogren, J. Zheng, S. Sohn, K. C. Kipper Schuler, and C. G. Chute. 2010. Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications. J Am Med Inform Assoc, vol. 17, no. 5, pp. 507513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q T Zeng</author>
<author>S Goryachev</author>
<author>S Weiss</author>
<author>M Sordo</author>
<author>S N Murphy</author>
<author>R Lazarus</author>
</authors>
<title>Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system.</title>
<date>2006</date>
<journal>BMC Med Inform Decis Mak,</journal>
<volume>6</volume>
<pages>30</pages>
<contexts>
<context position="2611" citStr="Zeng et al., 2006" startWordPosition="393" endWordPosition="396">ed disorder recognition system for the Task 7A of 2014 SemEval challenge. In Section 2 we give a background of the existing solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based </context>
</contexts>
<marker>Zeng, Goryachev, Weiss, Sordo, Murphy, Lazarus, 2006</marker>
<rawString>Q. T. Zeng, S. Goryachev, S. Weiss, M. Sordo, S. N. Murphy, and R. Lazarus. 2006. Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system. BMC Med Inform Decis Mak, vol. 6, p. 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Aronson</author>
<author>F M Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>17</volume>
<pages>229236</pages>
<contexts>
<context position="2584" citStr="Aronson and Lang, 2010" startWordPosition="387" endWordPosition="390"> describe a machine learning based disorder recognition system for the Task 7A of 2014 SemEval challenge. In Section 2 we give a background of the existing solutions to tackle the problem. Section 3 covers our approach in detail, followed by evaluation and conclusion in Section 4 and Section 5 respectively. 2 Background In recent times, many systems have been developed to extract clinical concepts from various types of clinical notes. The earlier natural language processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) </context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>A. R. Aronson and F. M. Lang. 2010. An overview of MetaMap: historical perspective and recent advances. J Am Med Inform Assoc, vol. 17, no. 3, pp. 229236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Solti Uzuner</author>
<author>E Cadag</author>
</authors>
<title>Extracting medication information from clinical text.</title>
<date>2010</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>17</volume>
<pages>514518</pages>
<marker>Uzuner, Cadag, 2010</marker>
<rawString>. Uzuner, I. Solti, and E. Cadag. 2010. Extracting medication information from clinical text. J Am Med Inform Assoc, vol. 17, no. 5, pp. 514518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina Frantzi</author>
</authors>
<title>Sophia Ananiadou, and Hideki Mima</title>
<date>2000</date>
<journal>International Journal on Digital Libraries</journal>
<volume>3</volume>
<issue>2</issue>
<marker>Frantzi, 2000</marker>
<rawString>Katerina Frantzi, Sophia Ananiadou, and Hideki Mima 2000. Automatic recognition of multi-word terms:. the C-value/NC-value method. International Journal on Digital Libraries 3(2):115–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Cogley</author>
<author>Nicola Stokes</author>
<author>Joe Carthy</author>
</authors>
<title>Medical Disorder Recognition with Structural Support Vector Machines.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3579" citStr="Cogley et al., 2013" startWordPosition="550" endWordPosition="553">al have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been tried in various domains like news articles, Wikipedia, sports articles, financial reports and clinical texts. In clinical text, entities can vary from medical procedures, disorders, body site indicators etc. Clinical text also presents with a peculiar concept of disjoint d</context>
</contexts>
<marker>Cogley, Stokes, Carthy, 2013</marker>
<rawString>James Cogley, Nicola Stokes and Joe Carthy. 2013. Medical Disorder Recognition with Structural Support Vector Machines. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Ritu Khare</author>
<author>Zhiyong Lu</author>
</authors>
<date>2013</date>
<booktitle>NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with Dnorm. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<marker>Leaman, Khare, Lu, 2013</marker>
<rawString>Robert Leaman, Ritu Khare and Zhiyong Lu. 2013. NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with Dnorm. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Gung</author>
</authors>
<title>Using Relations for Identification and Normalization of Disorders:</title>
<date>2013</date>
<booktitle>Team CLEAR in the ShARe/CLEF 2013 eHealth Evaluation Lab. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia</location>
<contexts>
<context position="3425" citStr="Gung, 2013" startWordPosition="525" endWordPosition="526">achine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been tried in various domains like news articles, Wikipedia, sports articles, financial reports and clinical texts. In clinic</context>
</contexts>
<marker>Gung, 2013</marker>
<rawString>James Gung. 2013. Using Relations for Identification and Normalization of Disorders: Team CLEAR in the ShARe/CLEF 2013 eHealth Evaluation Lab. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia -Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongfang Liu</author>
<author>Kavishwar Wagholikar</author>
</authors>
<title>Siddhartha Jonnalagadda and Sunghwan Sohn.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<marker>Liu, Wagholikar, 2013</marker>
<rawString>Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jonnalagadda and Sunghwan Sohn. 2013. Integrated cTAKES for Concept Mention Detection and Normalization. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon D Patrick</author>
<author>Leila Safari</author>
<author>Ying Ou</author>
</authors>
<date>2013</date>
<booktitle>ShARe/CLEF eHealth 2013 Named Entity Recognition and Normalization of Disorders Challenge. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia</location>
<contexts>
<context position="3447" citStr="Patrick et al., 2013" startWordPosition="527" endWordPosition="530">ing algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been tried in various domains like news articles, Wikipedia, sports articles, financial reports and clinical texts. In clinical text, entities can </context>
</contexts>
<marker>Patrick, Safari, Ou, 2013</marker>
<rawString>Jon D. Patrick, Leila Safari and Ying Ou. 2013. ShARe/CLEF eHealth 2013 Named Entity Recognition and Normalization of Disorders Challenge. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia -Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreea Bodnari</author>
<author>Louise Deleger</author>
<author>Thomas Lavergne</author>
<author>Aurelie Neveol</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>A Supervised Named-Entity Extraction System for Medical Text.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3469" citStr="Bodnari et al., 2013" startWordPosition="531" endWordPosition="534">clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been tried in various domains like news articles, Wikipedia, sports articles, financial reports and clinical texts. In clinical text, entities can vary from medical proc</context>
</contexts>
<marker>Bodnari, Deleger, Lavergne, Neveol, Zweigenbaum, 2013</marker>
<rawString>Andreea Bodnari, Louise Deleger, Thomas Lavergne, Aurelie Neveol and Pierre Zweigenbaum. 2013. A Supervised Named-Entity Extraction System for Medical Text. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Zuccon</author>
<author>Alexander Holloway</author>
<author>Bevan Koopman</author>
<author>Anthony Nguyen</author>
</authors>
<date>2013</date>
<booktitle>Identify Disorders in Health Records using Conditional Random Fields and Metamap AEHRC at ShARe/CLEF 2013 eHealth Evaluation Lab Task 1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3491" citStr="Zuccon et al., 2013" startWordPosition="535" endWordPosition="538">tion. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been tried in various domains like news articles, Wikipedia, sports articles, financial reports and clinical texts. In clinical text, entities can vary from medical procedures, disorders, bod</context>
</contexts>
<marker>Zuccon, Holloway, Koopman, Nguyen, 2013</marker>
<rawString>Guido Zuccon, Alexander Holloway, Bevan Koopman and Anthony Nguyen. 2013. Identify Disorders in Health Records using Conditional Random Fields and Metamap AEHRC at ShARe/CLEF 2013 eHealth Evaluation Lab Task 1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung-wei Fan</author>
<author>Navdeep Sood</author>
<author>Yang Huang</author>
</authors>
<title>Disorder Concept Identification from Clinical Notes An Experience with the ShARe/CLEF</title>
<date>2013</date>
<booktitle>Challenge. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3137" citStr="Fan et al., 2013" startWordPosition="477" endWordPosition="480">onaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on </context>
</contexts>
<marker>Fan, Sood, Huang, 2013</marker>
<rawString>Jung-wei Fan, Navdeep Sood and Yang Huang. 2013. Disorder Concept Identification from Clinical Notes An Experience with the ShARe/CLEF 2013 Challenge. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V Ramanan</author>
<author>Shereen Broido</author>
<author>P Senthil Nathan</author>
</authors>
<title>Performance of a multi-class biomedical tagger on clinical records.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3159" citStr="Ramanan et al., 2013" startWordPosition="481" endWordPosition="484">tems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (S</context>
</contexts>
<marker>Ramanan, Broido, Nathan, 2013</marker>
<rawString>S. V. Ramanan, Shereen Broido and P. Senthil Nathan. 2013. Performance of a multi-class biomedical tagger on clinical records. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunye Wang</author>
<author>Ramakrishna Akella</author>
</authors>
<title>Performance of a multi-class biomedical tagger on clinical records.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF</booktitle>
<contexts>
<context position="3183" citStr="Wang and Akella, 2013" startWordPosition="485" endWordPosition="488">Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–</context>
</contexts>
<marker>Wang, Akella, 2013</marker>
<rawString>Chunye Wang and Ramakrishna Akella. 2013. Performance of a multi-class biomedical tagger on clinical records. Online Working Notes of the CLEF 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evaluation Labs</author>
<author>Workshop</author>
</authors>
<date></date>
<volume>23</volume>
<pages>26</pages>
<location>Valencia -</location>
<marker>Labs, Workshop, </marker>
<rawString>Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Xiaoshi Zhong</author>
<author>Peng Liu</author>
<author>Cheng Tan</author>
<author>Sen Na</author>
<author>Qinan Hu</author>
<author>Yaohai Huang</author>
</authors>
<title>Combining MetaMap and cTAKES in Disorder Recognition:</title>
<date>2013</date>
<booktitle>THCIB at CLEF eHealth Lab 2013 Task 1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia</location>
<contexts>
<context position="3262" citStr="Xia et al., 2013" startWordPosition="499" endWordPosition="502">, MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution traini</context>
</contexts>
<marker>Xia, Zhong, Liu, Tan, Na, Hu, Huang, 2013</marker>
<rawString>Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan, Sen Na, Qinan Hu and Yaohai Huang. 2013. Combining MetaMap and cTAKES in Disorder Recognition: THCIB at CLEF eHealth Lab 2013 Task 1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia -Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John David Osborne</author>
<author>Binod Gyawali</author>
<author>Thamar Solorio</author>
</authors>
<title>Evaluation of YTEX and MetaMap for clinical concept recognition.</title>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3284" citStr="Osborne et al., 2013" startWordPosition="503" endWordPosition="506"> et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity </context>
</contexts>
<marker>Osborne, Gyawali, Solorio, 2013</marker>
<rawString>John David Osborne, Binod Gyawali and Thamar Solorio. 2013. Evaluation of YTEX and MetaMap for clinical concept recognition. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Hervas</author>
<author>Victor Martinez</author>
<author>Irene Sanchez</author>
<author>Alberto Diaz</author>
</authors>
<date>2013</date>
<booktitle>UCM at CLEF eHealth 2013 Shared Task1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3306" citStr="Hervas et al., 2013" startWordPosition="507" endWordPosition="510">t (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when provided with a large annotated corpus for 652 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656, Dublin, Ireland, August 23-24, 2014. Figure 1: Dataset distribution training. 3 Approach Entity recognition has been t</context>
</contexts>
<marker>Hervas, Martinez, Sanchez, Diaz, 2013</marker>
<rawString>Lucia Hervas, Victor Martinez, Irene Sanchez and Alberto Diaz. 2013. UCM at CLEF eHealth 2013 Shared Task1. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Noemie Elhadad</author>
<author>Brett R South</author>
<author>David Martinez</author>
<author>Lee Christensen</author>
<author>Amy Vogel</author>
<author>Hanna Suominen</author>
<author>Wendy W Chapman</author>
<author>Guergana Savova</author>
</authors>
<date>2013</date>
<booktitle>Task 1: ShARe/CLEF eHealth Evaluation Lab 2013. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September,</booktitle>
<location>Valencia -</location>
<contexts>
<context position="3043" citStr="Pradhan et al., 2013" startWordPosition="463" endWordPosition="466">nguage processing (NLP) systems were mainly built heavily using domain knowledge i.e. medical dictionaries. These systems include MetaMap (Aronson and Lang, 2010), HiTEX (Zeng et al., 2006), KnowledgeMap (Denny et al., 2003), MedLEE (Friedman et al., 1994), SymText (Koehler, 1994) and Mplus (Christensen et al., 2002). In the past couple of years, researchers have been exploring the use of machine learning algorithms in the clinical concept detection. To promote the research in this field many organizations such as ShARe/CLEF, SemEval have organized a few clinical NLP challenges. In CLEF 2013 (Pradhan et al., 2013), the challenge was to recognize medication-related concepts. Both rulebased (Fan et al., 2013; Ramanan et al., 2013; Wang and Akella, 2013) and machine learning based methods as well as hybrid methods (Xia et al., 2013; Osborne et al., 2013; Hervas et al., 2013) were developed. In this shared-task sequential labeling algorithms (i.e., Conditional Random Fields (CRF)) (Gung, 2013; Patrick et al., 2013; Bodnari et al., 2013; Zuccon et al., 2013) and machine learning methods (i.e., Support Vector Machine (SVM)) (Cogley et al., 2013) have been demonstrated to achieve promising performance when pr</context>
</contexts>
<marker>Pradhan, Elhadad, South, Martinez, Christensen, Vogel, Suominen, Chapman, Savova, 2013</marker>
<rawString>Sameer Pradhan, Noemie Elhadad, Brett R. South, David Martinez, Lee Christensen, Amy Vogel, Hanna Suominen, Wendy W. Chapman and Guergana Savova. 2013. Task 1: ShARe/CLEF eHealth Evaluation Lab 2013. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, 23 - 26 September, Valencia - Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>