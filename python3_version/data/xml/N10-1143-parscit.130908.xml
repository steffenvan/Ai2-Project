<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001569">
<title confidence="0.962789">
Evaluating Hierarchical Discourse Segmentation
</title>
<author confidence="0.854181">
Lucien Carroll
</author>
<affiliation confidence="0.408376">
Linguistics Dept.
</affiliation>
<address confidence="0.7926585">
UC San Diego
San Diego, CA 92093
</address>
<email confidence="0.999326">
lucien@ling.ucsd.edu
</email>
<sectionHeader confidence="0.99391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997143363636364">
Hierarchical discourse segmentation is a use-
ful technology, but it is difficult to eval-
uate. I propose an error measure based
on the word error rate of Beeferman et al.
(1999). I then show that this new measure
not only reliably distinguishes baseline seg-
mentations from lexically-informed hierarchi-
cal segmentations and more informed segmen-
tations from less informed segmentations, but
it also offers an improvement over previous
linear error measures.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960473684211">
Discourse segmentation is the task of identifying co-
herent clusters of sentences and the points of transi-
tion between those groupings. Discourse segmenta-
tion can be viewed as shallow parsing of discourse
structure. The segments and the relations between
them are left unlabeled, focusing instead on the
boundaries between the segments (i.e., the bracket-
ing).
Discourse segmentation is thought to facilitate
automatic summarization (Angheluta et al., 2002;
Boguraev and Neff, 2000), information retrieval
(Kaszkiel and Zobel, 1997), anaphora resolution
(Walker, 1997) and question answering (Chai and
Jin, 2004). Automatic discourse segmentation, as
shallow annotation of discourse structure, also pro-
vides a testing grounds for linguistic theories of dis-
course (Passonneau and Litman, 1997) and provides
a natural unit of measure in linguistic corpora (Biber
et al., 2004).
</bodyText>
<subsectionHeader confidence="0.999268">
1.1 The structure of discourse
</subsectionHeader>
<bodyText confidence="0.99986844">
Research in discourse structure theory (Hobbs,
1985; Grosz and Sidner, 1986; Mann and Thomp-
son, 1988; Kehler, 2002; Asher and Lascarides,
2003; Webber, 2004) and discourse parsing (Marcu,
2000; Forbes et al., 2003; Polanyi et al., 2004;
Baldridge et al., 2007) has variously defined dis-
course structure in terms of communicative inten-
tion, attention, topic/subtopic structure, coherence
relations, and cohesive devices. There is much dis-
agreement about the units and elementary relations
of discourse structure, but they agree that the struc-
tures are hierarchical, most commonly trees (Marcu,
2000), while others have argued for directed acyclic
graphs (Danlos, 2004), or general graphs (Wolf and
Gibson, 2004). In contrast, most of the segmentation
research to date has focused on linear segmentation,
in which segments are non-overlapping and sequen-
tial, and it has been argued that this sequence model
is sufficient for many purposes (Hearst, 1994). I fo-
cus here on tree discourse segmentation, in which
larger segments are composed of sequences of sub-
segments. This is potentially more informative and
more faithful to linguistic theory than linear dis-
course segmentation is, but it poses a more challeng-
ing evaluation problem.
</bodyText>
<subsectionHeader confidence="0.961662">
1.2 Hierarchical segmentation
</subsectionHeader>
<bodyText confidence="0.999881714285714">
Four studies have described hierarchical discourse
segmentation algorithms, but none of them rigor-
ously evaluated the segmentation in its hierarchi-
cal form. Yaari (1997) used a hierarchical cluster-
ing algorithm for hierarchical discourse segmenta-
tion, and to evaluate it, he linearized the tree (tak-
ing all boundaries equally) and compared the result-
</bodyText>
<page confidence="0.982614">
993
</page>
<note confidence="0.7527265">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 993–1001,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999956135135135">
ing precision and recall to contemporary linear seg-
mentation algorithms. Slaney and Ponceleon (2001)
used scale-space segmentation (an image segmen-
tation algorithm) on the discourse’s trajectory in a
Latent Semantic Indexing (LSI) space (Landauer et
al., 1998). They evaluated the algorithm by visual
comparison with the heading-subheading structure
of the text. Angheluta et al. (2002) applied a linear
discourse segmentation algorithm recursively, seg-
menting each major segment into a sequence of sub-
segments. They used the result in a summariza-
tion system, and they evaluated the summarization
system but not the segmentation itself. Eisenstein
(2009) used a Bayesian latent topic model to find
a hierarchical segmentation, and he comes the clos-
est to quantitative evaluation of the whole segmen-
tation. He evaluated it against three recursive seg-
mentation algorithms on a corpus that had just two
levels of segment depth and considers these two lev-
els as separate and equally important. While each of
these studies offers some insight into the validity of
the hierarchical segmentation, none of these evalua-
tion methods directly and quantitatively assesses the
hierarchical segmentation as a whole.
Many state-of-the-art linear discourse segmenta-
tion algorithms also use hierarchical frameworks,
making them applicable to hierarchical discourse
segmentation with only trivial modification. For ex-
ample, the C99 algorithm (Choi, 2000) applies con-
trast enhancement and divisive clustering to a ma-
trix of lexical vector cosine similarities. The CWM
algorithm (Choi et al., 2001) applies the same pro-
cedure to a similarity matrix of LSI vectors. Using
these algorithms for hierarchical discourse segmen-
tation simply requires keeping record of the bound-
ary ranking, but until now they have only been used
for linear segmentation.
</bodyText>
<subsectionHeader confidence="0.995829">
1.3 The Beeferman error measure
</subsectionHeader>
<bodyText confidence="0.999948916666667">
Studies of linear discourse segmentation have re-
vealed that discourse boundaries are inherently
fuzzy. Human annotators demonstrate frequent dis-
agreement about the number of segments and ex-
actly where the transitions between segments oc-
cur, while still demonstrating statistically significant
agreement (Passonneau and Litman, 1997). Because
of this, conventional precision and recall measures
penalize ‘near misses’ when they should be treated
much the same as complete matches. The crossing-
bracket measure (Carbone et al., 2004) is more for-
giving, but still over-penalizes near misses and fa-
vors sparse bracketings. An error measure Pk pro-
posed by Beeferman et al. (1999) compensates for
the variation in boundary locations. It considers a
moving window of width k equal to half the aver-
age segment length in the reference segmentation,
where distances are measured in words or sentences,
depending on whether word boundaries or sentence
boundaries are considered possible discourse seg-
ment boundaries. The error is the average disagree-
ment, between the reference segmentation and the
evaluated segmentation, about whether the two ends
of the window are in the same segment. Formally,
</bodyText>
<equation confidence="0.678014">
S(S(ri,ri+k),S(hi,hi+k))
</equation>
<bodyText confidence="0.999990724137931">
where N is the total number of atoms (words or sen-
tences) in the document, and k is the window width.
The arguments ri and hi are the indices of the seg-
ments that contain atom i in the reference and hy-
pothesized segmentations, respectively, and S is the
discrete delta function, evaluating to 1 if its argu-
ments are equal and to 0 otherwise. Pevzner and
Hearst (2001) proposed WindowDiff, a modification
of Pk that indicates the average disagreement about
how many boundaries lie within the window, replac-
ing the inner S functions with the count of segment
boundaries between the two atoms. It is as sensitive
to false positives as it is to false negatives, whereas
Pk is more sensitive to false negatives.
There are still a few problems with these er-
ror measures. In penalizing false negatives and
false positives equally, WindowDiff actually favors
sparse segmentations. Whereas Pk scores the base-
line strategies of no boundaries and all possible
boundaries as within a few percent of 50% error,
WindowDiff scores the all-boundaries baseline at
100% error for typical reference segmentations. Fur-
thermore, in running the summation from i = 1 to
i = N −k, both error measures count boundaries near
the edges of the text less than boundaries near the
middle of the text. A boundary that is j &lt; k atoms
from the beginning or end of the text has weight jk
relative to boundaries in the middle of the text. Fi-
nally, because of the hierarchical structure of many
</bodyText>
<equation confidence="0.9986395">
1
N−k
�
i=1
Pk =
N −k
</equation>
<page confidence="0.989229">
994
</page>
<bodyText confidence="0.999869318181818">
texts, it is quite possible that a reference segmen-
tation might not include legitimate but fairly unim-
portant boundaries that a hypothesized segmentation
does include. These unimportant boundaries should
not count against the hypothesized segmentation,
but in the linear segmentation paradigm, they nec-
essarily do. The ideal error measure should distin-
guish more-informed algorithms from less-informed
algorithms, treating equally uninformed baselines
the same, and it should treat boundary placement er-
rors according to the prominence of the boundaries,
and not according to their positions within the text.
Building on work in evaluating linear segmenta-
tion, this study considers the evaluation of tree seg-
mentations. I propose an error measure, derived
from Beeferman et al.’s Pk (1999), for evaluating the
alignment of a tree segmentation to a reference seg-
mentation. I first show that this error measure is ad-
vantageous even for evaluating linear segmentations,
and then I evaluate four hierarchical segmentation
algorithms against a gold standard derived from en-
cyclopedia articles.
</bodyText>
<sectionHeader confidence="0.852368" genericHeader="method">
2 A hierarchical measure
</sectionHeader>
<bodyText confidence="0.864749625">
The proposed error measure is based on the intu-
ition that prominent boundaries count more than less
prominent boundaries. The hierarchical atom error
rate EPk is the mean of Beeferman errors calculated
over all linearizations of the segmentation tree (see
Fig. 1). Assume a set R of reference boundaries and
a set H of hypothesized boundaries each in rank or-
der (prominent boundaries precede less prominent
</bodyText>
<figureCaption confidence="0.7419605">
Figure 1: Sequential linearizations in computing hierar-
chical word error rate. The heights of the vertical lines
represent the prominences of boundaries, and each hori-
zontal line is one linearization. In the first step, only the
highest boundary is used, producing just two segments.
Each following step includes one more boundary.
</figureCaption>
<bodyText confidence="0.927285">
ones). The error is calculated as
</bodyText>
<equation confidence="0.925184">
1
JRJ �iciPk(Ri,Hi)
</equation>
<bodyText confidence="0.737363">
where
</bodyText>
<equation confidence="0.646533">
Ri = {bj : bj E R∧ j &lt; i}
</equation>
<bodyText confidence="0.999897710526316">
The elements of Hi are chosen such that JHiJ = JRiJ
and no bn E H \ Hi is more prominent than any
bj E Hi. If the reference boundaries are completely
ordered, then ci = 1 for all ranks i, but if some ref-
erence boundaries share ranks, one Pk term is calcu-
lated for each rank level in the reference segmenta-
tion, and weighted (ci) by the number of boundaries
that were at that level. In the degenerate case of lin-
ear segmentation, all segments have the same rank,
and EPk reduces to the original Pk.
When hypothesized boundaries share ranks, each
affected term in the summation is theoretically the
average over all combinations (n boundaries at the
next rank Choose r boundaries to complete Hi). But
when the number of combinations is large, the com-
putational complexity of the calculation can be re-
duced without sacrificing much accuracy by using a
representative sampling of the combinations, as this
closely approximates the average.
When the set of hypothesized boundaries is
smaller than the set of reference boundaries, we
could simply permit Hi to be smaller than Ri for
large values of i, but that unnecessarily penalizes
the hypothesized segmentation. The set of possi-
ble boundaries (word or sentence boundaries) which
were not marked as segment boundaries can be un-
derstood to be segment boundaries of a baseline low
ranking. Adding these unmarked boundaries to H,
all at a single low rank, prevents incurring an unde-
served penalty for false negatives.
In order to avoid undercounting boundaries near
the beginning and end of the text, I consider the pos-
sibility of wrapping the window around from the be-
ginning to the end of the text. In calculating Pk, the
sum is understood to run from i = 1 to i = N, rather
than stopping at N − k, and the atom index of the
leading edge of the window (i + k) generalizes to
((i+k) mod N).
</bodyText>
<sectionHeader confidence="0.961721" genericHeader="method">
3 Hierarchical replication of Choi et al.
</sectionHeader>
<bodyText confidence="0.9990425">
As a preliminary test of the error measure, I eval-
uated two algorithms from Choi et al. (2001) on
</bodyText>
<equation confidence="0.844921">
EPk =
</equation>
<page confidence="0.97265">
995
</page>
<bodyText confidence="0.999953352941176">
the standard segmentation data set that Choi (2000)
compiled. Each file in that data is composed of
10 random portions of texts from the Brown Cor-
pus (Francis and Kucera, 1979). The following re-
sults are based on the T3_11 subset, in which text
segment lengths are uniformly distributed between
3 and 11 sentences. Since each file is composed of
a sequence of text portions, the reference segmenta-
tion is linear, not hierarchical. Nevertheless, I evalu-
ate hierarchical segmentation algorithms with the hi-
erarchical measure, to show that treating linear seg-
mentation as a special case of hierarchical segmen-
tation solves the issue of unequal treatment of false
positives and false negatives, and running the Win-
dowDiff sum to N (wrapping the window around to
the beginning) solves the problem of undercounting
the boundaries near the text edges.
</bodyText>
<subsectionHeader confidence="0.999743">
3.1 Segmentation algorithms
</subsectionHeader>
<bodyText confidence="0.999992296296296">
The C99 (Choi, 2000) and CWM (Choi et al., 2001)
algorithms were evaluated. While these were de-
signed and originally evaluated as linear segmenta-
tion algorithms, the hierarchical clustering they use
makes hierarchical segmentation a trivial matter of
retaining the order of the cluster splits. I refer to the
hierarchical versions of these algorithms as HC99
and HCWM. The HC99 implementation used here is
built directly from the C99 code which Choi released
for educational use, and the HCWM implementa-
tion is based off that. The implementation uses
a document-based LSI space built with Infomap-
NLP1 from the British National Corpus (Aston and
Burnard, 1998), whereas the original CWM used
sentence-based and paragraph-based LSI spaces de-
rived from the Brown Corpus. Because of these
differences, the implementation of HCWM reported
here differs somewhat from the implementation of
CWM reported by Choi et al. (2001).
The C99 and CWM algorithms include a criterion
for optional automatic determination of the number
of segments, but the hierarchical error measure does
not penalize a segmentation for having more seg-
ments (defined by lower ranking boundaries) than
the reference segmentation, so I used a constant
number of segments, greater than in the reference
segmentation, for the results reported here.
</bodyText>
<footnote confidence="0.676957">
1Software available at http://infomap-nlp.sourceforge.net
</footnote>
<bodyText confidence="0.999442166666667">
One baseline (BIN) was constructed by a recur-
sive bisection of segments, and another baseline
(NONE) consisted of only the implicit boundaries
at the beginning and end of the discourse, and all the
possible intermediate boundaries (sentence breaks)
are implicitly at one unmarked lower rank.
</bodyText>
<subsectionHeader confidence="0.988951">
3.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999893342857143">
The calculated EPk error rates are displayed in
Fig. 2.2 The error for HC99 in Fig. 2a (12.5%)
matches what Choi et al. (2001) reported (12%),
while the error for HCWM (12.1%) is higher than
that reported for the version with a paragraph-based
500-dimension LSI space (9%) but appears com-
parable to their sentence-based 400-dimension LSI
space. (They do not report results for the sentence-
based spaces on this T3_11 data set, but based on the
results they report for a larger data set, it would ap-
pear to be about 12% for the T3_11 set.) The result
for BIN (43.9%) is slightly lower than what Choi et
al. (2001) reported for their equal-size segment base-
line (45%). Since BIN would be an equal-segment
baseline if there were only 8 segments per text, BIN
should be similar to Choi et al’s equal-size baseline.
And the result for NONE (46.1%) agrees with Choi
et al. (2001)’s results for their NONE (46%) base-
line.
Comparison of graphs (a) and (b) in Fig. 2 shows
that continuing the sum to wrap the window around
to the beginning of the text generally lowers the
measured error, to the greatest extent for BIN and
least for HCWM. The average segment length in the
reference segmentation is 7 sentences, so the win-
dow size k is usually 3 or 4 sentences, comparable
to the minimum segment length (3). As a result,
a boundary very rarely falls within k sentences of
the text ends, and fully including these sentences in
the sum leads to a lower error for segmentations like
BIN that don’t hypothesize boundaries near the text
ends.
The EWD hierarchical error rates (calculated ac-
cording to WindowDiff) are consistently higher
(Fig. 2c, d) than the corresponding EPk. WindowDiff
</bodyText>
<footnote confidence="0.9942138">
2The error rates in this section are calculated using the word-
error rate for comparison with Choi’s results, but since the can-
didate boundaries are actually the line breaks, the line-error rate
would be more appropriate. Line error rates are 1% to 2%
higher.
</footnote>
<page confidence="0.993352">
996
</page>
<figure confidence="0.998810946428571">
0.8
p=12.5±0.9%
p=12.1±0.9%
0.6
0.4
0.0
0.2
0.8
µ=12.1±0.9%
0.6
0.4
0.2
0.0
0.8
µ=14.1±1.0%
0.6
0.4
0.2
0.0
0.8
µ=13.9±1.0%
0.6
0.4
0.2
0.0
p=43.9±0.9%
p=46.1±0.2%
µ=12.1±0.8%
●
●
● ●
●
µ=42.1±0.9%
µ=45.5±0.2%
µ=13.8±0.9%
●
●
●
●
●
µ=45.0±0.9%
µ=49.9±0.1%
µ=13.3±0.9%
● ●
● ●
µ=43.1±0.8%
µ=49.1±0.1%
●
●●
●
HC99 HCWM HCWM HCWM
HCWM BIN BIN BIN
BIN NONE NONE NONE
NONE HC99 HC99
HC99
(a) (b) (c) (d)
</figure>
<figureCaption confidence="0.99293825">
Figure 2: Distributions of EPk (a, b) and EWD (c, d) for each of the hypothesized and baseline segmentation algorithms.
The data in graphs (a) and (c) are calculated with sums that stop at N − k (when the window reaches the end of the
text), whereas (b) and (d) are calculated with sums that run to N (wrapping the window back to the beginning). The
boxes indicate the quartiles, and the means with 95% confidence intervals are written above.
</figureCaption>
<bodyText confidence="0.9998845625">
scores are never lower than Pk scores, because in or-
der to count as in agreement, the two segmentations
must agree about the number of boundaries within
the window rather than just about whether there are
boundaries within the window. But these scores are
not much higher than EPk either, even though the
original linear WindowDiff measure sometimes as-
signs much higher scores. Under the original Win-
dowDiff measure, with reference and hypothesized
boundary sets of unequal size, the NONE baseline
scores 43.8% (cf. Pk=43.5% for sum to N), while
an ALL baseline scores 99.2% (cf. Pk=51.1% for
sum to N). WindowDiff was designed to penalize
false positives even when two boundaries are close
together, a condition that Pk underpenalizes. When a
hypothesized segmentation has more segments than
the reference segmentation, the extra boundaries in-
cur false positive penalties without corresponding
false negative penalties, and WindowDiff assigns an
error rate that is higher than the Pk error rate and
sometimes even higher than the NONE baseline.
But with the hierarchical EWD error, extra bound-
aries are sampled or ignored, and so every false pos-
itive has a corresponding false negative, which limits
the divergence between EWD and EPk and keeps the
EWD error of informed segmentations below base-
line errors. As with EPk, continuing the sum to N
(Fig. 2d), has only a slight effect on the error, but
the effect is most pronounced on BIN, reflecting the
fact that BIN, like the reference segmentation sys-
tematically does not place boundaries near the text
ends.
</bodyText>
<subsectionHeader confidence="0.99497">
3.3 Conclusion
</subsectionHeader>
<bodyText confidence="0.999964166666667">
We have seen here that treating linear segmentations
as a special case of hierarchical segmentations, hav-
ing just one rank of marked boundaries but having
implicit higher ranking boundaries at the text ends
and implicit lower ranking boundaries at all ‘non-
boundaries’, resolves the outstanding issues of un-
equal sensitivity that Pk and WindowDiff have. Fur-
thermore, in sampling hypothesized boundaries to
match the number of reference boundaries, the hi-
erarchical conception of the error metric smoothly
adapts to segmentations that overestimate or under-
estimate the number of segments. A segmentation
</bodyText>
<page confidence="0.994601">
997
</page>
<bodyText confidence="0.999955764705882">
can not do much worse than 50% (at chance) just
by hypothesizing fewer or more segments than the
reference segmentation ‘knows’ about. The major
remaining strength of WindowDiff over the Pk met-
ric is that Pk still undercounts errors when there are
segments much smaller than the average size.
For these reasons, I adopt a version of EWD that
continues the sum to wrap the window around the
end of the text. In addition, when I refer to the lin-
ear error measure in the following sections, I mean
the special case of EWD in which the information in
the reference segmentation about the ranking of the
marked boundaries is ignored, but boundary ranking
information in the hypothesized segmentation (both
marked and unmarked boundaries) is still used to se-
lect as many segment boundaries as are in the refer-
ence segmentation.
</bodyText>
<sectionHeader confidence="0.996774" genericHeader="method">
4 Wiliipedia Evaluation
</sectionHeader>
<bodyText confidence="0.999931833333333">
In this section, I compare the same two algorithms
and baselines with two additional hierarchical seg-
mentation algorithms, using a hierarchical reference
segmentation. The reference segmentation corpus is
derived from encyclopedia articles, and I use the hi-
erarchical error measure developed in the previous
sections. I also constrast the hierarchical error rates
with measurements that ignore the boundary ranking
information in the hypothesized or reference seg-
mentations in order to highlight the difference be-
tween the performance on boundary position and the
performance on boundary ranking.
</bodyText>
<subsectionHeader confidence="0.997255">
4.1 Corpus and Algorithms
</subsectionHeader>
<bodyText confidence="0.9999591">
The evaluation corpus is derived from the 2006
Wikipedia CD release.3 The html pages were con-
verted to flat text, removing boilerplate, naviga-
tion, info-boxes, and image captions. Heading text
was replaced with a boundary marker, indicating the
heading depth. The subcorpus used for this evalua-
tion consists of articles with a heading depth of four
(i.e. having html elements h2 through h5), a total of
66 articles. The texts were reformatted with an au-
tomatic sentence detector4 to have one sentence per
</bodyText>
<footnote confidence="0.9746805">
3Available from http://schools-wikipedia.
org/2006/.
4From Ratnaparkhi’s ‘jmx’ (ftp://ftp.cis.upenn.
edu/pub/adwait/jmx/jmx.tar.gz).
</footnote>
<bodyText confidence="0.999407538461538">
line, and then tokenized.5
In addition to the HC99 and HCWM algorithms
used in the previous section, I use two algorithms
described by Eisenstein (2009). The HIERBAYES
algorithm (here, HBT) uses a multi-level latent topic
model to perform joint inference over the locations
and prominences of topic change boundaries. The
GREEDY-BAYES algorithm (here, GBEM) uses a
single-level latent topic model to find a linear seg-
mentation, and recursively divides each of the seg-
ments.6 Both algorithms internally decide the num-
ber of hypothesized boundaries, sometimes underes-
timating it and sometimes overestimating.?
</bodyText>
<subsectionHeader confidence="0.530924">
4.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999975791666667">
The EWD error rates for each of the hypothesized
segmentations are presented in Fig. 3. As with the
Choi data, the NONE baseline has an error rate
at chance (50%), while the lexical algorithms per-
form better than that (highly statistically signifi-
cantly (p &lt; .0001) less than 50%, according to indi-
vidual two-sided one-sample t-tests). However, they
perform much worse than they did on the Choi data.
In spite of the relatively high error rates, the dis-
criminating power of the evaluation measure is re-
vealed by comparison of the fully hierarchical er-
ror rates (Fig. 3a) with the error rates that ignore
the ranking information in the reference (Fig. 3b) or
hypothesized (Fig. 3c) segmentations. For each of
the lexical algorithms that were originally designed
as linear segmentation algorithms (HC99, HCWM,
and GBEM), the mean error is less in Fig. 3b
against the linear standard (when reference segmen-
tation boundary prominences are ignored) than in
Fig. 3a under the fully hierarchical measure (two-
tailed paired t-tests, each p &lt; .0001). In contrast,
HBT, designed as a hierarchical segmentation algo-
rithm, obtains a lower error rate under the fully hier-
archical EWD measure (though the difference does
</bodyText>
<footnote confidence="0.8589528">
5The evaluation code and corpus can be downloaded from
http://idiom.ucsd.edu/˜lucien/segmentation
6Both algorithms are part of the HBayesSeg pack-
age, available at http://people.csail.mit.edu/
jacobe/naacl09.html
?Options for HBT were set to produce 3 levels of text-
internal boundary prominence. Attempts to obtain more bound-
aries and more depth levels lead to deteriorated performance,
because the search space grows geometrically with the number
of levels (Eisenstein, p.c.)
</footnote>
<page confidence="0.991453">
998
</page>
<figure confidence="0.999872691176471">
0.8
µ=42.5±1.7%
µ=42.1±1.8%
0.6
0.4
0.2
0.0
0.8
µ=49.0±0.4%
µ=49.0±0.5%
0.6
0.4
0.2
0.0
µ=41.0±1.5%
µ=40.6±1.1%
µ=51.4±0.9%
µ=49.8±0.3%
0
0
0
0
0
0
µ=41.9±1.5%
µ=38.4±1.5%
µ=50.0±1.0%
µ=50.0±0.5%
●
●
●
●
●
µ=42.3±1.3%
µ=41.2±1.0%
µ=50.0±0.3%
µ=49.9±0.3%
●
●
●
0.8
µ=45.1±1.4%
µ=43.9±1.5%
0.6
0.4
0.2
0.0
HC99
HCWM
HBT
GBEM
BIN
NONE
HC99
HCWM
HBT
GBEM
BIN
NONE
HC99
HCWM
HBT
GBEM
BIN
NONE
(c)
(b)
(a)
</figure>
<figureCaption confidence="0.896339">
Figure 3: EWD error rates for each of the segmentation algorithms. (a) Hierarchical error (b) Linear error (ignoring
reference segmentation prominences) (c) Hierarchical error ignoring hypothesized segmentation prominences. Boxes
show quantiles and means are written above, with 95% confidence intervals.
</figureCaption>
<bodyText confidence="0.999977729166667">
not reach significance: p = 0.1, two-tailed paired
t-test). When instead the hypothesized boundary
prominences are ignored (Fig. 3c), reducing them
to linear segmentations but still evaluating against
the hierarchical standard, the error rates of all the
lexical algorithms are raised (in two-tailed paired t-
tests, each p &lt; .0001), but HBT and GBEM are only
slightly affected, whereas HC99 and HCWM are al-
most raised to chance. While HBT and GBEM hy-
pothesize about the same number of boundaries as
the reference segmentation (13 and 22 text-internal
boundaries on average, compared to 22 text-internal
boundaries in the reference corpus), the HC99 and
HCWM algorithms were made to hypothesize 54
boundaries for each text. The difference between
their error rates in (Fig. 3a) and (Fig. 3c) shows that
the HC99 and HCWM boundaries given the highest
prominences corresponded much more closely to the
reference boundaries than the hypothesized bound-
aries given the lowest prominences.
The mean scores for the BIN baseline are over
50% on the encyclopedia data. In contrast, the mean
score for BIN on the Choi standard data (Fig. 2)
was 45% for the linear measure and 43% for the
hierarchical measure. Why did BIN do so poorly
here when it performed well above chance on the
Choi data? The difference is in the distributions of
segment lengths. As seen in Fig. 4, the Choi data
segment lengths are well-defined by their mean, be-
cause they were constructed with uniform distribu-
tions of segment length. On the other hand, the dis-
tribution of segment lengths in the encyclopedia data
is more skewed, with many quite short segments and
a few quite long segments.
The error rates for both HC99 and HCWM are
much higher on the encyclopedia data than they
are on the Choi data, and the error rates for HBT
and GBEM are not much better. Choi’s evalua-
tion corpus was specifically designed to have obvi-
ous boundaries, whereas the boundaries in these dis-
course samples are much less obvious. As discussed
by Kauchak and Chen (2005), even algorithms that
obtain low error rates on newsfeed do not perform
well on more fluid discourse, and while Ji and Zha
(2003) reported quite low error on an expository text
sample (Pk = 12%), Kauchak and Chen (2005) re-
port a best error rate of Pk = 38.5% on the encyclo-
pedia corpus they used, and Malioutov and Barzi-
</bodyText>
<page confidence="0.990564">
999
</page>
<figure confidence="0.9937268">
Ratio of Segment Lengths to Mean
(a)
Ratio of Segment Lengths to Mean
(b)
0 1 2 3 4 5 6 7
Frequency
0 200 400
0 1 2 3 4 5 6 7
Frequency
0 50 150
</figure>
<figureCaption confidence="0.999998">
Figure 4: Distribution of sentences per segment for (a) Choi standard data (b) Wikipedia data
</figureCaption>
<bodyText confidence="0.999815652173913">
lay (2006) obtained Pk error rates between 30% and
40% on the lecture data they used, comparable to
human annotator pairwise Pk ranging from 24% to
42%. C99 and CWM—like the other algorithms
that make use of hierarchical representations of the
text, such as Ji and Zha (2003) and Fragkou et al.
(2004)—depend completely on lexical information.
Another strand of research, including Galley et al.
(2003) and Kauchak and Chen (2005), make use of
a wide variety of linguistic and orthographic cues.
And the discourse parsing systems take advantage
of even more linguistic cues. The ideal segmenta-
tion algorithm needs to combine the advantages of
each of these approaches, but the frameworks are not
straightforwardly compatible. The Bayesian frame-
work explored by Eisenstein and Barzilay (2008) is
a potential route to a richer model, and they found
their richer model beneficial for a meetings corpus
but not for a textbook. The HBT and GBEM al-
gorithms, which were based on that work, do not
attempt to go beyond lexical cohesion, but it does
provide a framework for hierarchical segmentation
algorithms that take advantage of other cues.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999917">
In Section 2, I introduced a modification of the er-
ror measure developed by Beeferman et al. (1999)
and Pevzner and Hearst (2001). I then showed that
this modification, directed at evaluating hierarchical
segmentations, also produces a more robust evalu-
ation of linear segmentations as well. And applied
to hierarchical segmentations, it successfully dis-
tinguishes lexically-informed segmentations from
baseline segmentations, and it distinguishes hierar-
chical segmentations from segmentations composed
of the same boundaries but without the boundary
ranking information. As a more reliable evaluation
of both linear and hierarchical segmentation algo-
rithms, this error measure will facilitate the devel-
opment of more richly informed segmentation algo-
rithms.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999864">
In this research, I have benefited from resources at
both San Diego State University and UC San Diego.
This work has been enriched by the questions and
advice of many people, including Eniko Csomay,
Rob Malouf, Lara Taylor, Rebecca Colavin, Andy
Kehler, and the NAACL anonymous reviewers. I
am also grateful to Freddy Choi and Jacob Eisen-
stein for making their code and data available, and
to Jacob for additional help running his code. All
errors are my own.
</bodyText>
<sectionHeader confidence="0.998571" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997791666666667">
Roxana Angheluta, Rik De Busser, and Marie-Francine
Moens. 2002. The use of topic segmentation for auto-
matic summarization. In DUC 2002.
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
Guy Aston and Lou Burnard. 1998. The BNC Hand-
book: Exploring the British National Corpus with
SARA. Edinburgh University Press.
Jason Baldridge, Nicholas Asher, and Julie Hunter. 2007.
Annotation for and robust parsing of discourse struc-
ture of unrestricted texts. Zeitschrift f¨ur Sprachwis-
senschaft, 26(213):239.
</reference>
<page confidence="0.74239">
1000
</page>
<reference confidence="0.999837242990655">
Doug Beeferman, Adam Berger, and John D. Lafferty.
1999. Statistical models for text segmentation. Ma-
chine Learning, 34(1-3):177–210.
Douglas Biber, Eniko Csomay, James K. Jones, and
Casey Keck. 2004. A corpus linguistic investigation
of vocabulary-based discourse units in university reg-
isters. Language and Computers, 20:53–72.
Branimir Boguraev and Mary S. Neff. 2000. Discourse
segmentation in aid of document summarization. In
33rd HICSS.
Marco Carbone, Ya’akov Gal, Stuart Shieber, and Bar-
bara Grosz. 2004. Unifying annotated discourse hi-
erarchies to create a gold standard. In Proceedings of
4th SIGDIAL Workshop on Discourse and Dialogue.
Joyce Y. Chai and Rong Jin. 2004. Discourse struc-
ture for context question answering. In HLT-NAACL
2004 Workshop on Pragmatics of Question Answering,
pages 23–30.
Freddy Choi, Peter Wiemer-Hastings, and Johanna
Moore. 2001. Latent semantic analysis for text seg-
mentation. In Proceedings of 6th EMNLP, pages 109–
117.
Freddy Choi. 2000. Advances in domain independent
linear text segmentation. In Proceedings of NAACL-
00, pages 26–33.
Laurence Danlos. 2004. Discourse dependency struc-
tures as constrained DAGs. In Proceedings of 5th SIG-
DIAL Workshop on Discourse and Dialogue, pages
127–135.
Jacob Eisenstein and Regina Barzilay. 2008. Bayesian
unsupervised topic segmentation. In Proceedings of
EMNLP 2008.
Jacob Eisenstein. 2009. Hierarchical text segmentation
from multi-scale lexical cohesion. In Proceedings of
NAACL09.
Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad,
Anoop Sarkar, Aravind Joshi, and Bonnie Webber.
2003. D-LTAG system: Discourse parsing with a lex-
icalized tree-adjoining grammar. Journal of Logic,
Language and Information, 12(3):261–279, June.
P. Fragkou, V. Petridis, and Ath. Kehagias. 2004. A dy-
namic programming algorithm for linear text segmen-
tation. Journal of Int Info Systems, 23:179–197.
W. Nelson Francis and Henry Kucera. 1979. BROWN
Corpus Manual. Brown University, third edition.
Michael Galley, Kathleen McKeown, Eric Fossler-
Lussier, and Hongyan Jing. 2003. Discourse segmen-
tation of multi-party conversation. In 41st ACL.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Com-
putational Linguistics, 12(3):175–204.
Marti Hearst. 1994. Multi-paragraph segmentation of
expository text. In 32nd ACL, pages 9 – 16, New Mex-
ico State University, Las Cruces, New Mexico.
Jerry R Hobbs. 1985. On the coherence and structure of
discourse. In CSLI 85-37.
Xiang Ji and Hongyuan Zha. 2003. Domain-independent
text segmentation using anisotropic diffusion and dy-
namic programming. In SIGIR’03.
Marcin Kaszkiel and Justin Zobel. 1997. Passage re-
trieval revisited. In Proceedings of 20th ACM SIGIR,
pages 178–185.
David Kauchak and Francine Chen. 2005. Feature-based
segmentation of narrative documents. In Proceedings
of the ACL Workshop on Feature Engineering for Ma-
chine Learning in NLP.
Andrew Kehler. 2002. Coherence, reference and the the-
ory of grammar. CSLI Publications.
Thomas K. Landauer, Peter W. Foltz, and Darrell La-
ham. 1998. An introduction to latent semantic analy-
sis. Discourse Processes, 25:259–284.
Igor Malioutov and Regina Barzilay. 2006. Minimum
cut model for spoken lecture segmentation. In Pro-
ceedings of the 21st International Conference on Com-
putational Linguistics and 44th Annual Meeting of the
ACL, pages 25–32.
William Mann and Sandra Thompson. 1988. Rhetorical
structure theory: Towards a functional theory of text
organization. Text, 8(3):243–281.
Daniel Marcu. 2000. The theory and practice of dis-
course parsing and summarization. MIT Press.
Rebecca J. Passonneau and Diane J. Litman. 1997. Dis-
course segmentation by human and automated means.
Computational Linguistics, 23(1):103–139.
Lev Pevzner and Marti Hearst. 2001. A critique and
improvement of an evaluation metric for text segmen-
tation. Computational Linguistics, 16(1).
Livia Polanyi, Chris Culy, Martin van den Berg,
Gian Lorenzo Thione, and David Ahn. 2004. A rule
based approach to discourse parsing. In Proceedings
of SIGDIAL.
Malcolm Slaney and Dulce Ponceleon. 2001. Hierar-
chical segmentation: Finding changes in a text sig-
nal. Proceedings of SIAM 2001 Text Mining Work-
shop, pages 6–13.
Marilyn A. Walker. 1997. Centering, anaphora resolu-
tion, and discourse structure. In Aravind K. Joshi Mar-
ilyn A. Walker and Ellen F. Prince, editors, Centering
in Discourse. Oxford University Press.
Bonnie Webber. 2004. D-LTAG: extending lexicalized
TAG to discourse. Cognitive Science, 28:751–779.
Florian Wolf and Edward Gibson. 2004. Representing
discourse coherence: A corpus-based analysis. In 20th
COLING.
Yaakov Yaari. 1997. Segmentation of expository texts by
hierarchical agglomerative clustering. In Proceedings
of RANLP’97.
</reference>
<page confidence="0.988103">
1001
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910323">
<title confidence="0.999968">Evaluating Hierarchical Discourse Segmentation</title>
<author confidence="0.991329">Lucien</author>
<affiliation confidence="0.984866">Linguistics UC San</affiliation>
<address confidence="0.956184">San Diego, CA</address>
<email confidence="0.999432">lucien@ling.ucsd.edu</email>
<abstract confidence="0.99896525">Hierarchical discourse segmentation is a useful technology, but it is difficult to evaluate. I propose an error measure based on the word error rate of Beeferman et al. (1999). I then show that this new measure not only reliably distinguishes baseline segmentations from lexically-informed hierarchical segmentations and more informed segmentations from less informed segmentations, but it also offers an improvement over previous linear error measures.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roxana Angheluta</author>
<author>Rik De Busser</author>
<author>Marie-Francine Moens</author>
</authors>
<title>The use of topic segmentation for automatic summarization.</title>
<date>2002</date>
<booktitle>In DUC</booktitle>
<marker>Angheluta, De Busser, Moens, 2002</marker>
<rawString>Roxana Angheluta, Rik De Busser, and Marie-Francine Moens. 2002. The use of topic segmentation for automatic summarization. In DUC 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1659" citStr="Asher and Lascarides, 2003" startWordPosition="239" endWordPosition="242">arization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segme</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Aston</author>
<author>Lou Burnard</author>
</authors>
<date>1998</date>
<booktitle>The BNC Handbook: Exploring the British National Corpus with SARA.</booktitle>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="13346" citStr="Aston and Burnard, 1998" startWordPosition="2119" endWordPosition="2122">et al., 2001) algorithms were evaluated. While these were designed and originally evaluated as linear segmentation algorithms, the hierarchical clustering they use makes hierarchical segmentation a trivial matter of retaining the order of the cluster splits. I refer to the hierarchical versions of these algorithms as HC99 and HCWM. The HC99 implementation used here is built directly from the C99 code which Choi released for educational use, and the HCWM implementation is based off that. The implementation uses a document-based LSI space built with InfomapNLP1 from the British National Corpus (Aston and Burnard, 1998), whereas the original CWM used sentence-based and paragraph-based LSI spaces derived from the Brown Corpus. Because of these differences, the implementation of HCWM reported here differs somewhat from the implementation of CWM reported by Choi et al. (2001). The C99 and CWM algorithms include a criterion for optional automatic determination of the number of segments, but the hierarchical error measure does not penalize a segmentation for having more segments (defined by lower ranking boundaries) than the reference segmentation, so I used a constant number of segments, greater than in the refe</context>
</contexts>
<marker>Aston, Burnard, 1998</marker>
<rawString>Guy Aston and Lou Burnard. 1998. The BNC Handbook: Exploring the British National Corpus with SARA. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Nicholas Asher</author>
<author>Julie Hunter</author>
</authors>
<title>Annotation for and robust parsing of discourse structure of unrestricted texts. Zeitschrift f¨ur Sprachwissenschaft,</title>
<date>2007</date>
<contexts>
<context position="1777" citStr="Baldridge et al., 2007" startWordPosition="258" endWordPosition="261">esolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear segmentation, in which segments are non-overlapping and sequential, and</context>
</contexts>
<marker>Baldridge, Asher, Hunter, 2007</marker>
<rawString>Jason Baldridge, Nicholas Asher, and Julie Hunter. 2007. Annotation for and robust parsing of discourse structure of unrestricted texts. Zeitschrift f¨ur Sprachwissenschaft, 26(213):239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John D Lafferty</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="5865" citStr="Beeferman et al. (1999)" startWordPosition="869" endWordPosition="872">aled that discourse boundaries are inherently fuzzy. Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and Litman, 1997). Because of this, conventional precision and recall measures penalize ‘near misses’ when they should be treated much the same as complete matches. The crossingbracket measure (Carbone et al., 2004) is more forgiving, but still over-penalizes near misses and favors sparse bracketings. An error measure Pk proposed by Beeferman et al. (1999) compensates for the variation in boundary locations. It considers a moving window of width k equal to half the average segment length in the reference segmentation, where distances are measured in words or sentences, depending on whether word boundaries or sentence boundaries are considered possible discourse segment boundaries. The error is the average disagreement, between the reference segmentation and the evaluated segmentation, about whether the two ends of the window are in the same segment. Formally, S(S(ri,ri+k),S(hi,hi+k)) where N is the total number of atoms (words or sentences) in </context>
<context position="28300" citStr="Beeferman et al. (1999)" startWordPosition="4563" endWordPosition="4566">e advantages of each of these approaches, but the frameworks are not straightforwardly compatible. The Bayesian framework explored by Eisenstein and Barzilay (2008) is a potential route to a richer model, and they found their richer model beneficial for a meetings corpus but not for a textbook. The HBT and GBEM algorithms, which were based on that work, do not attempt to go beyond lexical cohesion, but it does provide a framework for hierarchical segmentation algorithms that take advantage of other cues. 5 Conclusions In Section 2, I introduced a modification of the error measure developed by Beeferman et al. (1999) and Pevzner and Hearst (2001). I then showed that this modification, directed at evaluating hierarchical segmentations, also produces a more robust evaluation of linear segmentations as well. And applied to hierarchical segmentations, it successfully distinguishes lexically-informed segmentations from baseline segmentations, and it distinguishes hierarchical segmentations from segmentations composed of the same boundaries but without the boundary ranking information. As a more reliable evaluation of both linear and hierarchical segmentation algorithms, this error measure will facilitate the d</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Doug Beeferman, Adam Berger, and John D. Lafferty. 1999. Statistical models for text segmentation. Machine Learning, 34(1-3):177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
<author>Eniko Csomay</author>
<author>James K Jones</author>
<author>Casey Keck</author>
</authors>
<title>A corpus linguistic investigation of vocabulary-based discourse units in university registers.</title>
<date>2004</date>
<journal>Language and Computers,</journal>
<pages>20--53</pages>
<contexts>
<context position="1484" citStr="Biber et al., 2004" startWordPosition="212" endWordPosition="215"> them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, mo</context>
</contexts>
<marker>Biber, Csomay, Jones, Keck, 2004</marker>
<rawString>Douglas Biber, Eniko Csomay, James K. Jones, and Casey Keck. 2004. A corpus linguistic investigation of vocabulary-based discourse units in university registers. Language and Computers, 20:53–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir Boguraev</author>
<author>Mary S Neff</author>
</authors>
<title>Discourse segmentation in aid of document summarization.</title>
<date>2000</date>
<booktitle>In 33rd HICSS.</booktitle>
<contexts>
<context position="1092" citStr="Boguraev and Neff, 2000" startWordPosition="156" endWordPosition="159"> informed segmentations from less informed segmentations, but it also offers an improvement over previous linear error measures. 1 Introduction Discourse segmentation is the task of identifying coherent clusters of sentences and the points of transition between those groupings. Discourse segmentation can be viewed as shallow parsing of discourse structure. The segments and the relations between them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse par</context>
</contexts>
<marker>Boguraev, Neff, 2000</marker>
<rawString>Branimir Boguraev and Mary S. Neff. 2000. Discourse segmentation in aid of document summarization. In 33rd HICSS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Carbone</author>
<author>Ya’akov Gal</author>
<author>Stuart Shieber</author>
<author>Barbara Grosz</author>
</authors>
<title>Unifying annotated discourse hierarchies to create a gold standard.</title>
<date>2004</date>
<booktitle>In Proceedings of 4th SIGDIAL Workshop on Discourse and Dialogue.</booktitle>
<contexts>
<context position="5722" citStr="Carbone et al., 2004" startWordPosition="844" endWordPosition="847">ntil now they have only been used for linear segmentation. 1.3 The Beeferman error measure Studies of linear discourse segmentation have revealed that discourse boundaries are inherently fuzzy. Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and Litman, 1997). Because of this, conventional precision and recall measures penalize ‘near misses’ when they should be treated much the same as complete matches. The crossingbracket measure (Carbone et al., 2004) is more forgiving, but still over-penalizes near misses and favors sparse bracketings. An error measure Pk proposed by Beeferman et al. (1999) compensates for the variation in boundary locations. It considers a moving window of width k equal to half the average segment length in the reference segmentation, where distances are measured in words or sentences, depending on whether word boundaries or sentence boundaries are considered possible discourse segment boundaries. The error is the average disagreement, between the reference segmentation and the evaluated segmentation, about whether the t</context>
</contexts>
<marker>Carbone, Gal, Shieber, Grosz, 2004</marker>
<rawString>Marco Carbone, Ya’akov Gal, Stuart Shieber, and Barbara Grosz. 2004. Unifying annotated discourse hierarchies to create a gold standard. In Proceedings of 4th SIGDIAL Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joyce Y Chai</author>
<author>Rong Jin</author>
</authors>
<title>Discourse structure for context question answering.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004 Workshop on Pragmatics of Question Answering,</booktitle>
<pages>23--30</pages>
<contexts>
<context position="1222" citStr="Chai and Jin, 2004" startWordPosition="173" endWordPosition="176">oduction Discourse segmentation is the task of identifying coherent clusters of sentences and the points of transition between those groupings. Discourse segmentation can be viewed as shallow parsing of discourse structure. The segments and the relations between them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in</context>
</contexts>
<marker>Chai, Jin, 2004</marker>
<rawString>Joyce Y. Chai and Rong Jin. 2004. Discourse structure for context question answering. In HLT-NAACL 2004 Workshop on Pragmatics of Question Answering, pages 23–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freddy Choi</author>
<author>Peter Wiemer-Hastings</author>
<author>Johanna Moore</author>
</authors>
<title>Latent semantic analysis for text segmentation.</title>
<date>2001</date>
<booktitle>In Proceedings of 6th EMNLP,</booktitle>
<pages>109--117</pages>
<contexts>
<context position="4910" citStr="Choi et al., 2001" startWordPosition="724" endWordPosition="727">parate and equally important. While each of these studies offers some insight into the validity of the hierarchical segmentation, none of these evaluation methods directly and quantitatively assesses the hierarchical segmentation as a whole. Many state-of-the-art linear discourse segmentation algorithms also use hierarchical frameworks, making them applicable to hierarchical discourse segmentation with only trivial modification. For example, the C99 algorithm (Choi, 2000) applies contrast enhancement and divisive clustering to a matrix of lexical vector cosine similarities. The CWM algorithm (Choi et al., 2001) applies the same procedure to a similarity matrix of LSI vectors. Using these algorithms for hierarchical discourse segmentation simply requires keeping record of the boundary ranking, but until now they have only been used for linear segmentation. 1.3 The Beeferman error measure Studies of linear discourse segmentation have revealed that discourse boundaries are inherently fuzzy. Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and</context>
<context position="11800" citStr="Choi et al. (2001)" startWordPosition="1869" endWordPosition="1872">ed boundaries to H, all at a single low rank, prevents incurring an undeserved penalty for false negatives. In order to avoid undercounting boundaries near the beginning and end of the text, I consider the possibility of wrapping the window around from the beginning to the end of the text. In calculating Pk, the sum is understood to run from i = 1 to i = N, rather than stopping at N − k, and the atom index of the leading edge of the window (i + k) generalizes to ((i+k) mod N). 3 Hierarchical replication of Choi et al. As a preliminary test of the error measure, I evaluated two algorithms from Choi et al. (2001) on EPk = 995 the standard segmentation data set that Choi (2000) compiled. Each file in that data is composed of 10 random portions of texts from the Brown Corpus (Francis and Kucera, 1979). The following results are based on the T3_11 subset, in which text segment lengths are uniformly distributed between 3 and 11 sentences. Since each file is composed of a sequence of text portions, the reference segmentation is linear, not hierarchical. Nevertheless, I evaluate hierarchical segmentation algorithms with the hierarchical measure, to show that treating linear segmentation as a special case of</context>
<context position="13604" citStr="Choi et al. (2001)" startWordPosition="2158" endWordPosition="2161">er to the hierarchical versions of these algorithms as HC99 and HCWM. The HC99 implementation used here is built directly from the C99 code which Choi released for educational use, and the HCWM implementation is based off that. The implementation uses a document-based LSI space built with InfomapNLP1 from the British National Corpus (Aston and Burnard, 1998), whereas the original CWM used sentence-based and paragraph-based LSI spaces derived from the Brown Corpus. Because of these differences, the implementation of HCWM reported here differs somewhat from the implementation of CWM reported by Choi et al. (2001). The C99 and CWM algorithms include a criterion for optional automatic determination of the number of segments, but the hierarchical error measure does not penalize a segmentation for having more segments (defined by lower ranking boundaries) than the reference segmentation, so I used a constant number of segments, greater than in the reference segmentation, for the results reported here. 1Software available at http://infomap-nlp.sourceforge.net One baseline (BIN) was constructed by a recursive bisection of segments, and another baseline (NONE) consisted of only the implicit boundaries at the</context>
<context position="14985" citStr="Choi et al. (2001)" startWordPosition="2381" endWordPosition="2384">ussion The calculated EPk error rates are displayed in Fig. 2.2 The error for HC99 in Fig. 2a (12.5%) matches what Choi et al. (2001) reported (12%), while the error for HCWM (12.1%) is higher than that reported for the version with a paragraph-based 500-dimension LSI space (9%) but appears comparable to their sentence-based 400-dimension LSI space. (They do not report results for the sentencebased spaces on this T3_11 data set, but based on the results they report for a larger data set, it would appear to be about 12% for the T3_11 set.) The result for BIN (43.9%) is slightly lower than what Choi et al. (2001) reported for their equal-size segment baseline (45%). Since BIN would be an equal-segment baseline if there were only 8 segments per text, BIN should be similar to Choi et al’s equal-size baseline. And the result for NONE (46.1%) agrees with Choi et al. (2001)’s results for their NONE (46%) baseline. Comparison of graphs (a) and (b) in Fig. 2 shows that continuing the sum to wrap the window around to the beginning of the text generally lowers the measured error, to the greatest extent for BIN and least for HCWM. The average segment length in the reference segmentation is 7 sentences, so the w</context>
</contexts>
<marker>Choi, Wiemer-Hastings, Moore, 2001</marker>
<rawString>Freddy Choi, Peter Wiemer-Hastings, and Johanna Moore. 2001. Latent semantic analysis for text segmentation. In Proceedings of 6th EMNLP, pages 109– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freddy Choi</author>
</authors>
<title>Advances in domain independent linear text segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL00,</booktitle>
<pages>26--33</pages>
<contexts>
<context position="4768" citStr="Choi, 2000" startWordPosition="703" endWordPosition="704">inst three recursive segmentation algorithms on a corpus that had just two levels of segment depth and considers these two levels as separate and equally important. While each of these studies offers some insight into the validity of the hierarchical segmentation, none of these evaluation methods directly and quantitatively assesses the hierarchical segmentation as a whole. Many state-of-the-art linear discourse segmentation algorithms also use hierarchical frameworks, making them applicable to hierarchical discourse segmentation with only trivial modification. For example, the C99 algorithm (Choi, 2000) applies contrast enhancement and divisive clustering to a matrix of lexical vector cosine similarities. The CWM algorithm (Choi et al., 2001) applies the same procedure to a similarity matrix of LSI vectors. Using these algorithms for hierarchical discourse segmentation simply requires keeping record of the boundary ranking, but until now they have only been used for linear segmentation. 1.3 The Beeferman error measure Studies of linear discourse segmentation have revealed that discourse boundaries are inherently fuzzy. Human annotators demonstrate frequent disagreement about the number of se</context>
<context position="11865" citStr="Choi (2000)" startWordPosition="1883" endWordPosition="1884">served penalty for false negatives. In order to avoid undercounting boundaries near the beginning and end of the text, I consider the possibility of wrapping the window around from the beginning to the end of the text. In calculating Pk, the sum is understood to run from i = 1 to i = N, rather than stopping at N − k, and the atom index of the leading edge of the window (i + k) generalizes to ((i+k) mod N). 3 Hierarchical replication of Choi et al. As a preliminary test of the error measure, I evaluated two algorithms from Choi et al. (2001) on EPk = 995 the standard segmentation data set that Choi (2000) compiled. Each file in that data is composed of 10 random portions of texts from the Brown Corpus (Francis and Kucera, 1979). The following results are based on the T3_11 subset, in which text segment lengths are uniformly distributed between 3 and 11 sentences. Since each file is composed of a sequence of text portions, the reference segmentation is linear, not hierarchical. Nevertheless, I evaluate hierarchical segmentation algorithms with the hierarchical measure, to show that treating linear segmentation as a special case of hierarchical segmentation solves the issue of unequal treatment </context>
</contexts>
<marker>Choi, 2000</marker>
<rawString>Freddy Choi. 2000. Advances in domain independent linear text segmentation. In Proceedings of NAACL00, pages 26–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence Danlos</author>
</authors>
<title>Discourse dependency structures as constrained DAGs.</title>
<date>2004</date>
<booktitle>In Proceedings of 5th SIGDIAL Workshop on Discourse and Dialogue,</booktitle>
<pages>127--135</pages>
<contexts>
<context position="2184" citStr="Danlos, 2004" startWordPosition="318" endWordPosition="319">rosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear segmentation, in which segments are non-overlapping and sequential, and it has been argued that this sequence model is sufficient for many purposes (Hearst, 1994). I focus here on tree discourse segmentation, in which larger segments are composed of sequences of subsegments. This is potentially more informative and more faithful to linguistic theory than linear discourse segmentation is, but it poses a more challenging evaluation problem. 1.2 Hierarchical segmentation Four </context>
</contexts>
<marker>Danlos, 2004</marker>
<rawString>Laurence Danlos. 2004. Discourse dependency structures as constrained DAGs. In Proceedings of 5th SIGDIAL Workshop on Discourse and Dialogue, pages 127–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Bayesian unsupervised topic segmentation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="27841" citStr="Eisenstein and Barzilay (2008)" startWordPosition="4483" endWordPosition="4486">CWM—like the other algorithms that make use of hierarchical representations of the text, such as Ji and Zha (2003) and Fragkou et al. (2004)—depend completely on lexical information. Another strand of research, including Galley et al. (2003) and Kauchak and Chen (2005), make use of a wide variety of linguistic and orthographic cues. And the discourse parsing systems take advantage of even more linguistic cues. The ideal segmentation algorithm needs to combine the advantages of each of these approaches, but the frameworks are not straightforwardly compatible. The Bayesian framework explored by Eisenstein and Barzilay (2008) is a potential route to a richer model, and they found their richer model beneficial for a meetings corpus but not for a textbook. The HBT and GBEM algorithms, which were based on that work, do not attempt to go beyond lexical cohesion, but it does provide a framework for hierarchical segmentation algorithms that take advantage of other cues. 5 Conclusions In Section 2, I introduced a modification of the error measure developed by Beeferman et al. (1999) and Pevzner and Hearst (2001). I then showed that this modification, directed at evaluating hierarchical segmentations, also produces a more</context>
</contexts>
<marker>Eisenstein, Barzilay, 2008</marker>
<rawString>Jacob Eisenstein and Regina Barzilay. 2008. Bayesian unsupervised topic segmentation. In Proceedings of EMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>Hierarchical text segmentation from multi-scale lexical cohesion.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL09.</booktitle>
<contexts>
<context position="3986" citStr="Eisenstein (2009)" startWordPosition="586" endWordPosition="587">ary linear segmentation algorithms. Slaney and Ponceleon (2001) used scale-space segmentation (an image segmentation algorithm) on the discourse’s trajectory in a Latent Semantic Indexing (LSI) space (Landauer et al., 1998). They evaluated the algorithm by visual comparison with the heading-subheading structure of the text. Angheluta et al. (2002) applied a linear discourse segmentation algorithm recursively, segmenting each major segment into a sequence of subsegments. They used the result in a summarization system, and they evaluated the summarization system but not the segmentation itself. Eisenstein (2009) used a Bayesian latent topic model to find a hierarchical segmentation, and he comes the closest to quantitative evaluation of the whole segmentation. He evaluated it against three recursive segmentation algorithms on a corpus that had just two levels of segment depth and considers these two levels as separate and equally important. While each of these studies offers some insight into the validity of the hierarchical segmentation, none of these evaluation methods directly and quantitatively assesses the hierarchical segmentation as a whole. Many state-of-the-art linear discourse segmentation </context>
<context position="21595" citStr="Eisenstein (2009)" startWordPosition="3464" endWordPosition="3465">tions. Heading text was replaced with a boundary marker, indicating the heading depth. The subcorpus used for this evaluation consists of articles with a heading depth of four (i.e. having html elements h2 through h5), a total of 66 articles. The texts were reformatted with an automatic sentence detector4 to have one sentence per 3Available from http://schools-wikipedia. org/2006/. 4From Ratnaparkhi’s ‘jmx’ (ftp://ftp.cis.upenn. edu/pub/adwait/jmx/jmx.tar.gz). line, and then tokenized.5 In addition to the HC99 and HCWM algorithms used in the previous section, I use two algorithms described by Eisenstein (2009). The HIERBAYES algorithm (here, HBT) uses a multi-level latent topic model to perform joint inference over the locations and prominences of topic change boundaries. The GREEDY-BAYES algorithm (here, GBEM) uses a single-level latent topic model to find a linear segmentation, and recursively divides each of the segments.6 Both algorithms internally decide the number of hypothesized boundaries, sometimes underestimating it and sometimes overestimating.? 4.2 Results and Discussion The EWD error rates for each of the hypothesized segmentations are presented in Fig. 3. As with the Choi data, the NO</context>
</contexts>
<marker>Eisenstein, 2009</marker>
<rawString>Jacob Eisenstein. 2009. Hierarchical text segmentation from multi-scale lexical cohesion. In Proceedings of NAACL09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Forbes</author>
<author>Eleni Miltsakaki</author>
<author>Rashmi Prasad</author>
<author>Anoop Sarkar</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>D-LTAG system: Discourse parsing with a lexicalized tree-adjoining grammar.</title>
<date>2003</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1730" citStr="Forbes et al., 2003" startWordPosition="250" endWordPosition="253">eval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear segmentation, in which s</context>
</contexts>
<marker>Forbes, Miltsakaki, Prasad, Sarkar, Joshi, Webber, 2003</marker>
<rawString>Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad, Anoop Sarkar, Aravind Joshi, and Bonnie Webber. 2003. D-LTAG system: Discourse parsing with a lexicalized tree-adjoining grammar. Journal of Logic, Language and Information, 12(3):261–279, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kehagias</author>
</authors>
<title>A dynamic programming algorithm for linear text segmentation.</title>
<date>2004</date>
<journal>Journal of Int Info Systems,</journal>
<pages>23--179</pages>
<marker>Kehagias, 2004</marker>
<rawString>P. Fragkou, V. Petridis, and Ath. Kehagias. 2004. A dynamic programming algorithm for linear text segmentation. Journal of Int Info Systems, 23:179–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kucera</author>
</authors>
<date>1979</date>
<institution>BROWN Corpus Manual. Brown University,</institution>
<note>third edition.</note>
<contexts>
<context position="11990" citStr="Francis and Kucera, 1979" startWordPosition="1904" endWordPosition="1907">e text, I consider the possibility of wrapping the window around from the beginning to the end of the text. In calculating Pk, the sum is understood to run from i = 1 to i = N, rather than stopping at N − k, and the atom index of the leading edge of the window (i + k) generalizes to ((i+k) mod N). 3 Hierarchical replication of Choi et al. As a preliminary test of the error measure, I evaluated two algorithms from Choi et al. (2001) on EPk = 995 the standard segmentation data set that Choi (2000) compiled. Each file in that data is composed of 10 random portions of texts from the Brown Corpus (Francis and Kucera, 1979). The following results are based on the T3_11 subset, in which text segment lengths are uniformly distributed between 3 and 11 sentences. Since each file is composed of a sequence of text portions, the reference segmentation is linear, not hierarchical. Nevertheless, I evaluate hierarchical segmentation algorithms with the hierarchical measure, to show that treating linear segmentation as a special case of hierarchical segmentation solves the issue of unequal treatment of false positives and false negatives, and running the WindowDiff sum to N (wrapping the window around to the beginning) sol</context>
</contexts>
<marker>Francis, Kucera, 1979</marker>
<rawString>W. Nelson Francis and Henry Kucera. 1979. BROWN Corpus Manual. Brown University, third edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Galley</author>
<author>Kathleen McKeown</author>
</authors>
<title>Eric FosslerLussier, and Hongyan Jing.</title>
<date>2003</date>
<booktitle>In 41st ACL.</booktitle>
<marker>Galley, McKeown, 2003</marker>
<rawString>Michael Galley, Kathleen McKeown, Eric FosslerLussier, and Hongyan Jing. 2003. Discourse segmentation of multi-party conversation. In 41st ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1592" citStr="Grosz and Sidner, 1986" startWordPosition="228" endWordPosition="231"> Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or gen</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In 32nd ACL,</booktitle>
<volume>9</volume>
<pages>pages</pages>
<institution>New Mexico State University, Las Cruces,</institution>
<location>New Mexico.</location>
<contexts>
<context position="2468" citStr="Hearst, 1994" startWordPosition="363" endWordPosition="364">, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear segmentation, in which segments are non-overlapping and sequential, and it has been argued that this sequence model is sufficient for many purposes (Hearst, 1994). I focus here on tree discourse segmentation, in which larger segments are composed of sequences of subsegments. This is potentially more informative and more faithful to linguistic theory than linear discourse segmentation is, but it poses a more challenging evaluation problem. 1.2 Hierarchical segmentation Four studies have described hierarchical discourse segmentation algorithms, but none of them rigorously evaluated the segmentation in its hierarchical form. Yaari (1997) used a hierarchical clustering algorithm for hierarchical discourse segmentation, and to evaluate it, he linearized the</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>Marti Hearst. 1994. Multi-paragraph segmentation of expository text. In 32nd ACL, pages 9 – 16, New Mexico State University, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>On the coherence and structure of discourse.</title>
<date>1985</date>
<booktitle>In CSLI</booktitle>
<pages>85--37</pages>
<contexts>
<context position="1568" citStr="Hobbs, 1985" startWordPosition="226" endWordPosition="227"> bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graph</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry R Hobbs. 1985. On the coherence and structure of discourse. In CSLI 85-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiang Ji</author>
<author>Hongyuan Zha</author>
</authors>
<title>Domain-independent text segmentation using anisotropic diffusion and dynamic programming.</title>
<date>2003</date>
<booktitle>In SIGIR’03.</booktitle>
<contexts>
<context position="26616" citStr="Ji and Zha (2003)" startWordPosition="4266" endWordPosition="4269">ion of segment lengths in the encyclopedia data is more skewed, with many quite short segments and a few quite long segments. The error rates for both HC99 and HCWM are much higher on the encyclopedia data than they are on the Choi data, and the error rates for HBT and GBEM are not much better. Choi’s evaluation corpus was specifically designed to have obvious boundaries, whereas the boundaries in these discourse samples are much less obvious. As discussed by Kauchak and Chen (2005), even algorithms that obtain low error rates on newsfeed do not perform well on more fluid discourse, and while Ji and Zha (2003) reported quite low error on an expository text sample (Pk = 12%), Kauchak and Chen (2005) report a best error rate of Pk = 38.5% on the encyclopedia corpus they used, and Malioutov and Barzi999 Ratio of Segment Lengths to Mean (a) Ratio of Segment Lengths to Mean (b) 0 1 2 3 4 5 6 7 Frequency 0 200 400 0 1 2 3 4 5 6 7 Frequency 0 50 150 Figure 4: Distribution of sentences per segment for (a) Choi standard data (b) Wikipedia data lay (2006) obtained Pk error rates between 30% and 40% on the lecture data they used, comparable to human annotator pairwise Pk ranging from 24% to 42%. C99 and CWM—l</context>
</contexts>
<marker>Ji, Zha, 2003</marker>
<rawString>Xiang Ji and Hongyuan Zha. 2003. Domain-independent text segmentation using anisotropic diffusion and dynamic programming. In SIGIR’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Kaszkiel</author>
<author>Justin Zobel</author>
</authors>
<title>Passage retrieval revisited.</title>
<date>1997</date>
<booktitle>In Proceedings of 20th ACM SIGIR,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="1142" citStr="Kaszkiel and Zobel, 1997" startWordPosition="162" endWordPosition="165">tations, but it also offers an improvement over previous linear error measures. 1 Introduction Discourse segmentation is the task of identifying coherent clusters of sentences and the points of transition between those groupings. Discourse segmentation can be viewed as shallow parsing of discourse structure. The segments and the relations between them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et</context>
</contexts>
<marker>Kaszkiel, Zobel, 1997</marker>
<rawString>Marcin Kaszkiel and Justin Zobel. 1997. Passage retrieval revisited. In Proceedings of 20th ACM SIGIR, pages 178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
<author>Francine Chen</author>
</authors>
<title>Feature-based segmentation of narrative documents.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in NLP.</booktitle>
<contexts>
<context position="26486" citStr="Kauchak and Chen (2005)" startWordPosition="4243" endWordPosition="4246">well-defined by their mean, because they were constructed with uniform distributions of segment length. On the other hand, the distribution of segment lengths in the encyclopedia data is more skewed, with many quite short segments and a few quite long segments. The error rates for both HC99 and HCWM are much higher on the encyclopedia data than they are on the Choi data, and the error rates for HBT and GBEM are not much better. Choi’s evaluation corpus was specifically designed to have obvious boundaries, whereas the boundaries in these discourse samples are much less obvious. As discussed by Kauchak and Chen (2005), even algorithms that obtain low error rates on newsfeed do not perform well on more fluid discourse, and while Ji and Zha (2003) reported quite low error on an expository text sample (Pk = 12%), Kauchak and Chen (2005) report a best error rate of Pk = 38.5% on the encyclopedia corpus they used, and Malioutov and Barzi999 Ratio of Segment Lengths to Mean (a) Ratio of Segment Lengths to Mean (b) 0 1 2 3 4 5 6 7 Frequency 0 200 400 0 1 2 3 4 5 6 7 Frequency 0 50 150 Figure 4: Distribution of sentences per segment for (a) Choi standard data (b) Wikipedia data lay (2006) obtained Pk error rates b</context>
</contexts>
<marker>Kauchak, Chen, 2005</marker>
<rawString>David Kauchak and Francine Chen. 2005. Feature-based segmentation of narrative documents. In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
</authors>
<title>Coherence, reference and the theory of grammar.</title>
<date>2002</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="1631" citStr="Kehler, 2002" startWordPosition="237" endWordPosition="238">automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In</context>
</contexts>
<marker>Kehler, 2002</marker>
<rawString>Andrew Kehler. 2002. Coherence, reference and the theory of grammar. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--259</pages>
<contexts>
<context position="3592" citStr="Landauer et al., 1998" startWordPosition="526" endWordPosition="529">lustering algorithm for hierarchical discourse segmentation, and to evaluate it, he linearized the tree (taking all boundaries equally) and compared the result993 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 993–1001, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ing precision and recall to contemporary linear segmentation algorithms. Slaney and Ponceleon (2001) used scale-space segmentation (an image segmentation algorithm) on the discourse’s trajectory in a Latent Semantic Indexing (LSI) space (Landauer et al., 1998). They evaluated the algorithm by visual comparison with the heading-subheading structure of the text. Angheluta et al. (2002) applied a linear discourse segmentation algorithm recursively, segmenting each major segment into a sequence of subsegments. They used the result in a summarization system, and they evaluated the summarization system but not the segmentation itself. Eisenstein (2009) used a Bayesian latent topic model to find a hierarchical segmentation, and he comes the closest to quantitative evaluation of the whole segmentation. He evaluated it against three recursive segmentation a</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K. Landauer, Peter W. Foltz, and Darrell Laham. 1998. An introduction to latent semantic analysis. Discourse Processes, 25:259–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Malioutov</author>
<author>Regina Barzilay</author>
</authors>
<title>Minimum cut model for spoken lecture segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL,</booktitle>
<pages>25--32</pages>
<marker>Malioutov, Barzilay, 2006</marker>
<rawString>Igor Malioutov and Regina Barzilay. 2006. Minimum cut model for spoken lecture segmentation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
<author>Sandra Thompson</author>
</authors>
<title>Rhetorical structure theory: Towards a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="1617" citStr="Mann and Thompson, 1988" startWordPosition="232" endWordPosition="236">is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gib</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William Mann and Sandra Thompson. 1988. Rhetorical structure theory: Towards a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The theory and practice of discourse parsing and summarization.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1709" citStr="Marcu, 2000" startWordPosition="248" endWordPosition="249">rmation retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear seg</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The theory and practice of discourse parsing and summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passonneau</author>
<author>Diane J Litman</author>
</authors>
<title>Discourse segmentation by human and automated means.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="1402" citStr="Passonneau and Litman, 1997" startWordPosition="198" endWordPosition="201">be viewed as shallow parsing of discourse structure. The segments and the relations between them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relatio</context>
<context position="5524" citStr="Passonneau and Litman, 1997" startWordPosition="814" endWordPosition="817"> et al., 2001) applies the same procedure to a similarity matrix of LSI vectors. Using these algorithms for hierarchical discourse segmentation simply requires keeping record of the boundary ranking, but until now they have only been used for linear segmentation. 1.3 The Beeferman error measure Studies of linear discourse segmentation have revealed that discourse boundaries are inherently fuzzy. Human annotators demonstrate frequent disagreement about the number of segments and exactly where the transitions between segments occur, while still demonstrating statistically significant agreement (Passonneau and Litman, 1997). Because of this, conventional precision and recall measures penalize ‘near misses’ when they should be treated much the same as complete matches. The crossingbracket measure (Carbone et al., 2004) is more forgiving, but still over-penalizes near misses and favors sparse bracketings. An error measure Pk proposed by Beeferman et al. (1999) compensates for the variation in boundary locations. It considers a moving window of width k equal to half the average segment length in the reference segmentation, where distances are measured in words or sentences, depending on whether word boundaries or s</context>
</contexts>
<marker>Passonneau, Litman, 1997</marker>
<rawString>Rebecca J. Passonneau and Diane J. Litman. 1997. Discourse segmentation by human and automated means. Computational Linguistics, 23(1):103–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Pevzner</author>
<author>Marti Hearst</author>
</authors>
<title>A critique and improvement of an evaluation metric for text segmentation.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="6771" citStr="Pevzner and Hearst (2001)" startWordPosition="1018" endWordPosition="1021"> considered possible discourse segment boundaries. The error is the average disagreement, between the reference segmentation and the evaluated segmentation, about whether the two ends of the window are in the same segment. Formally, S(S(ri,ri+k),S(hi,hi+k)) where N is the total number of atoms (words or sentences) in the document, and k is the window width. The arguments ri and hi are the indices of the segments that contain atom i in the reference and hypothesized segmentations, respectively, and S is the discrete delta function, evaluating to 1 if its arguments are equal and to 0 otherwise. Pevzner and Hearst (2001) proposed WindowDiff, a modification of Pk that indicates the average disagreement about how many boundaries lie within the window, replacing the inner S functions with the count of segment boundaries between the two atoms. It is as sensitive to false positives as it is to false negatives, whereas Pk is more sensitive to false negatives. There are still a few problems with these error measures. In penalizing false negatives and false positives equally, WindowDiff actually favors sparse segmentations. Whereas Pk scores the baseline strategies of no boundaries and all possible boundaries as with</context>
<context position="28330" citStr="Pevzner and Hearst (2001)" startWordPosition="4568" endWordPosition="4571">e approaches, but the frameworks are not straightforwardly compatible. The Bayesian framework explored by Eisenstein and Barzilay (2008) is a potential route to a richer model, and they found their richer model beneficial for a meetings corpus but not for a textbook. The HBT and GBEM algorithms, which were based on that work, do not attempt to go beyond lexical cohesion, but it does provide a framework for hierarchical segmentation algorithms that take advantage of other cues. 5 Conclusions In Section 2, I introduced a modification of the error measure developed by Beeferman et al. (1999) and Pevzner and Hearst (2001). I then showed that this modification, directed at evaluating hierarchical segmentations, also produces a more robust evaluation of linear segmentations as well. And applied to hierarchical segmentations, it successfully distinguishes lexically-informed segmentations from baseline segmentations, and it distinguishes hierarchical segmentations from segmentations composed of the same boundaries but without the boundary ranking information. As a more reliable evaluation of both linear and hierarchical segmentation algorithms, this error measure will facilitate the development of more richly info</context>
</contexts>
<marker>Pevzner, Hearst, 2001</marker>
<rawString>Lev Pevzner and Marti Hearst. 2001. A critique and improvement of an evaluation metric for text segmentation. Computational Linguistics, 16(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Chris Culy</author>
<author>Martin van den Berg</author>
<author>Gian Lorenzo Thione</author>
<author>David Ahn</author>
</authors>
<title>A rule based approach to discourse parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<marker>Polanyi, Culy, van den Berg, Thione, Ahn, 2004</marker>
<rawString>Livia Polanyi, Chris Culy, Martin van den Berg, Gian Lorenzo Thione, and David Ahn. 2004. A rule based approach to discourse parsing. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malcolm Slaney</author>
<author>Dulce Ponceleon</author>
</authors>
<title>Hierarchical segmentation: Finding changes in a text signal.</title>
<date>2001</date>
<booktitle>Proceedings of SIAM 2001 Text Mining Workshop,</booktitle>
<pages>6--13</pages>
<contexts>
<context position="3432" citStr="Slaney and Ponceleon (2001)" startWordPosition="503" endWordPosition="506">d hierarchical discourse segmentation algorithms, but none of them rigorously evaluated the segmentation in its hierarchical form. Yaari (1997) used a hierarchical clustering algorithm for hierarchical discourse segmentation, and to evaluate it, he linearized the tree (taking all boundaries equally) and compared the result993 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 993–1001, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ing precision and recall to contemporary linear segmentation algorithms. Slaney and Ponceleon (2001) used scale-space segmentation (an image segmentation algorithm) on the discourse’s trajectory in a Latent Semantic Indexing (LSI) space (Landauer et al., 1998). They evaluated the algorithm by visual comparison with the heading-subheading structure of the text. Angheluta et al. (2002) applied a linear discourse segmentation algorithm recursively, segmenting each major segment into a sequence of subsegments. They used the result in a summarization system, and they evaluated the summarization system but not the segmentation itself. Eisenstein (2009) used a Bayesian latent topic model to find a </context>
</contexts>
<marker>Slaney, Ponceleon, 2001</marker>
<rawString>Malcolm Slaney and Dulce Ponceleon. 2001. Hierarchical segmentation: Finding changes in a text signal. Proceedings of SIAM 2001 Text Mining Workshop, pages 6–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Centering, anaphora resolution, and discourse structure. In Aravind</title>
<date>1997</date>
<booktitle>Centering in Discourse.</booktitle>
<editor>K. Joshi Marilyn A. Walker and Ellen F. Prince, editors,</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1178" citStr="Walker, 1997" startWordPosition="168" endWordPosition="169">previous linear error measures. 1 Introduction Discourse segmentation is the task of identifying coherent clusters of sentences and the points of transition between those groupings. Discourse segmentation can be viewed as shallow parsing of discourse structure. The segments and the relations between them are left unlabeled, focusing instead on the boundaries between the segments (i.e., the bracketing). Discourse segmentation is thought to facilitate automatic summarization (Angheluta et al., 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) </context>
</contexts>
<marker>Walker, 1997</marker>
<rawString>Marilyn A. Walker. 1997. Centering, anaphora resolution, and discourse structure. In Aravind K. Joshi Marilyn A. Walker and Ellen F. Prince, editors, Centering in Discourse. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
</authors>
<title>D-LTAG: extending lexicalized TAG to discourse.</title>
<date>2004</date>
<journal>Cognitive Science,</journal>
<pages>28--751</pages>
<contexts>
<context position="1674" citStr="Webber, 2004" startWordPosition="243" endWordPosition="244"> 2002; Boguraev and Neff, 2000), information retrieval (Kaszkiel and Zobel, 1997), anaphora resolution (Walker, 1997) and question answering (Chai and Jin, 2004). Automatic discourse segmentation, as shallow annotation of discourse structure, also provides a testing grounds for linguistic theories of discourse (Passonneau and Litman, 1997) and provides a natural unit of measure in linguistic corpora (Biber et al., 2004). 1.1 The structure of discourse Research in discourse structure theory (Hobbs, 1985; Grosz and Sidner, 1986; Mann and Thompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation researc</context>
</contexts>
<marker>Webber, 2004</marker>
<rawString>Bonnie Webber. 2004. D-LTAG: extending lexicalized TAG to discourse. Cognitive Science, 28:751–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing discourse coherence: A corpus-based analysis.</title>
<date>2004</date>
<booktitle>In 20th COLING.</booktitle>
<contexts>
<context position="2227" citStr="Wolf and Gibson, 2004" startWordPosition="323" endWordPosition="326">ompson, 1988; Kehler, 2002; Asher and Lascarides, 2003; Webber, 2004) and discourse parsing (Marcu, 2000; Forbes et al., 2003; Polanyi et al., 2004; Baldridge et al., 2007) has variously defined discourse structure in terms of communicative intention, attention, topic/subtopic structure, coherence relations, and cohesive devices. There is much disagreement about the units and elementary relations of discourse structure, but they agree that the structures are hierarchical, most commonly trees (Marcu, 2000), while others have argued for directed acyclic graphs (Danlos, 2004), or general graphs (Wolf and Gibson, 2004). In contrast, most of the segmentation research to date has focused on linear segmentation, in which segments are non-overlapping and sequential, and it has been argued that this sequence model is sufficient for many purposes (Hearst, 1994). I focus here on tree discourse segmentation, in which larger segments are composed of sequences of subsegments. This is potentially more informative and more faithful to linguistic theory than linear discourse segmentation is, but it poses a more challenging evaluation problem. 1.2 Hierarchical segmentation Four studies have described hierarchical discour</context>
</contexts>
<marker>Wolf, Gibson, 2004</marker>
<rawString>Florian Wolf and Edward Gibson. 2004. Representing discourse coherence: A corpus-based analysis. In 20th COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaakov Yaari</author>
</authors>
<title>Segmentation of expository texts by hierarchical agglomerative clustering.</title>
<date>1997</date>
<booktitle>In Proceedings of RANLP’97.</booktitle>
<contexts>
<context position="2948" citStr="Yaari (1997)" startWordPosition="435" endWordPosition="436">s are non-overlapping and sequential, and it has been argued that this sequence model is sufficient for many purposes (Hearst, 1994). I focus here on tree discourse segmentation, in which larger segments are composed of sequences of subsegments. This is potentially more informative and more faithful to linguistic theory than linear discourse segmentation is, but it poses a more challenging evaluation problem. 1.2 Hierarchical segmentation Four studies have described hierarchical discourse segmentation algorithms, but none of them rigorously evaluated the segmentation in its hierarchical form. Yaari (1997) used a hierarchical clustering algorithm for hierarchical discourse segmentation, and to evaluate it, he linearized the tree (taking all boundaries equally) and compared the result993 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 993–1001, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ing precision and recall to contemporary linear segmentation algorithms. Slaney and Ponceleon (2001) used scale-space segmentation (an image segmentation algorithm) on the discourse’s trajectory in a Latent Semantic </context>
</contexts>
<marker>Yaari, 1997</marker>
<rawString>Yaakov Yaari. 1997. Segmentation of expository texts by hierarchical agglomerative clustering. In Proceedings of RANLP’97.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>