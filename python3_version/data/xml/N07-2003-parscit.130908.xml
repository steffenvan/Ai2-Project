<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012626">
<title confidence="0.906286">
Conquest – an Open-Source Dialog System for Conferences
</title>
<author confidence="0.992919">
Dan Bohus, Sergio Grau Puerto, David Huggins-Daines, Venkatesh Keri,
Gopala Krishna, Rohit Kumar, Antoine Raux, Stefanie Tomko
</author>
<affiliation confidence="0.9922805">
School of Computer Science
Carnegie Mellon University
</affiliation>
<keyword confidence="0.38646">
{ dbohus, sgrau, dhuggins, vkeri, gopalakr, rohitk, antoine, stef }@ cs.cmu.edu
</keyword>
<sectionHeader confidence="0.984481" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999856071428572">
We describe ConQuest, an open-source,
reusable spoken dialog system that pro-
vides technical program information dur-
ing conferences. The system uses a
transparent, modular and open infrastruc-
ture, and aims to enable applied research
in spoken language interfaces. The con-
ference domain is a good platform for ap-
plied research since it permits periodical
redeployments and evaluations with a real
user-base. In this paper, we describe the
system’s functionality, overall architec-
ture, and we discuss two initial deploy-
ments.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998">
Conducting applied spoken language interface re-
search is generally a costly endeavor. Developing,
deploying and maintaining real-world spoken lan-
guage interfaces requires an existing infrastructure,
a significant amount of engineering effort, and can
greatly benefit from the availability of certain re-
sources such as transcribed in-domain data.
In an effort to enable applied research and to
lower this high cost of entry, we have developed
ConQuest (Conference Questions) an open-source
spoken dialog system that provides access to
schedule and technical program information during
conferences. We believe the conference domain
has a number of good properties for applied re-
search: it includes a number of tasks of different
complexities, it provides regular access to a real-
world user population; it permits periodical rede-
ployments and evaluations and therefore can pro-
vide a natural common evaluation task for the
spoken language interfaces community.
The ConQuest system is constructed on top of
the open, transparent and modular Olympus dialog
system framework (2007), and can be easily reused
across different conferences. To date, the system
has been deployed in two conferences: InterSpeech
2006 and IJCAI 2007. Together with corpora col-
lected from these deployments, the system is freely
available for download (Conquest, 2007).
We begin by describing the ConQuest function-
ality in the next section. Then, in section 3 we pro-
vide an overview of the system architecture and
discuss the development process. In section 4 we
briefly discuss the two deployment efforts. Finally,
in section 5 we discuss related work and draw a
number of conclusions.
</bodyText>
<sectionHeader confidence="0.989694" genericHeader="introduction">
2 Functionality
</sectionHeader>
<bodyText confidence="0.999805705882353">
As Figure 1 illustrates, ConQuest is a mixed-
initiative spoken dialog system that provides ac-
cess to schedule and technical program information
during conferences.
Users can browse the schedule and find details
about various papers or sessions of interest by pro-
viding identifying information, such as topics, ses-
sion names, special events, paper titles, author
names, specific dates and times, specific locations,
or a combination thereof (e.g. turns 2, 4, 14). Addi-
tionally, the system also allows uses to listen to
current announcements and to cast their votes for a
Best Paper Award (e.g. turns 10-17).
The interaction is mixed-initiative; at any point,
the user may switch the current focus of the con-
versation (e.g. turn 8). ConQuest employs an adap-
tive information presentation strategy that allows
</bodyText>
<page confidence="0.956171">
9
</page>
<note confidence="0.537876">
Proceedings of NAACL HLT 2007, Companion Volume, pages 9–12,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
1 S: Welcome to ConQuest [...] I can give you information about papers, sessions, special events and announcements at Inter-
Speech 2006. You can also cast a vote for the best paper award. How can I help you?
</note>
<page confidence="0.347615">
2 U. are there any papers on spoken dialog systems today
</page>
<figure confidence="0.906981888888889">
3 S: There are 23 papers on spoken dialog systems today. These papers are being presented in 3 sessions: Dialog and Discourse,
Language Modeling for Spoken Dialog Systems and Spoken Dialog Systems I. To browse this list of papers, please tell me the
author name, the paper title, the time or the venue you’re looking for. If you’re not interested in any of these papers say ‘quit’.
4 U. which ones are in the afternoon
5 S: There will be 11 papers on spoken dialog systems this afternoon. Would you like to hear information about all these papers?
6 U. yes
7 S: The list of papers on spoken dialog systems this afternoon is: Paper 1 - “Dynamic Extension of a Grammar-based Dialogue
System: Constructing an All-Recipes Knowing Robot”, Paper 2 – [...] Would you like more information about any of these?
8 U. tell me more about the third one
9 S: Paper 3 is titled “System- versus user-initiative dialog strategy for driver information systems”, and was presented yesterday at 2
pm in the poster session in Allegheny Ballroom Foyer. This paper was written by Chantal Ackermann, and Marion Libossek.
Would you like more information about any of these?
8 U. no when is the banquet
9 S: The Banquet will be held Wednesday from 7pm to 9:30 pm in the Heintz History Center. The Heinz History Center is located on
Smallman street between 12th and 13th streets. The History Center is a museum that relates and interprets 250 years of history
in the Western Pennsylvania area. Is there anything else I can do for you?
10 U. yes I’d like to cast a vote
11 S: Please tell me the title of the paper you’d like to vote for..
12 U. I don’t really know the title but I think it had Diane as one of the main authors Æ [non-understanding]
13 S: Sorry, I didn’t catch that. Please dial the first six letters from the title of the paper you would like to vote for.
14 U. I don’t know it it’s a paper by Diane Litman
15 S: There are 3 papers by Diane Litman. Paper 1 – “Discourse Structure and Speech Recognition Problems”, Paper 2 – [...], Paper
3 – [...] Would you like to vote for any of these?
16 U. Discourse Structure and Speech Recognition Problems
17 S: Okay, I’ve recorded your vote for the paper entitled “Discourse Structure and Speech Recognition Problems” What else can I do
for you?
18 U. [...I
</figure>
<figureCaption confidence="0.999961">
Figure 1. A sample interaction with ConQuest
</figureCaption>
<bodyText confidence="0.921631">
users to easily navigate the schedule (see turns 3, 5
and 15). The system uses a rich repertoire of error
recovery strategies to handle potential errors, in-
cluding several fall-back strategies (e.g. turn 13).
</bodyText>
<sectionHeader confidence="0.97322" genericHeader="method">
3 System Architecture
</sectionHeader>
<bodyText confidence="0.999916738095238">
The ConQuest system was built using RavenClaw/
Olympus (2007), an open-source framework that
facilitates research and development in task ori-
ented conversational spoken language interfaces.
Olympus consists of a collection of components
for recognition, language understanding, dialog
management, language generation, speech synthe-
sis, etc., and the corresponding communication
infrastructure. To date, Olympus has been used to
develop and deploy a number of other systems
spanning different domains and interaction types
(Bohus and Rudnicky, 2003).
A key characteristic of the Olympus framework
is a clear separation between the domain independ-
ent programs (or components) and domain specific
resources. This decoupling promotes reusability
and significantly lessens the system development
effort. In ConQuest, the authoring effort was fo-
cused on developing resources such as the lexicon,
language model, grammar, dialog task specifica-
tion, etc. Some interesting, unanticipated engineer-
ing challenges we faced during development were
dealing with foreign names and accented charac-
ters and performing text normalization on various
fields (e.g. Alex Smith and Alexander Smith are
the same author), while at the same time ensuring
consistency between these various resources. Be-
low, we briefly comment of each component and
the corresponding resources. Figure 2 provides a
top-level architectural view.
Speech Recognition. ConQuest uses a recogni-
tion server coupled to a set of parallel recognition
engines: two SPHINX-II decoders (Huang et al.,
1992) that use gender-specific acoustic models,
and a DTMF (touch-tone decoder). Each recogni-
tion engine uses class-based (e.g. paper titles, au-
thor names, etc.), state-specific trigram-language
models. We started with an initial language model
built using data collected with an early text-only
prototype. We then internally deployed a speech
based system, collected more data, transcribed it,
and used it to retrain the language models. The
</bodyText>
<page confidence="0.989289">
10
</page>
<figureCaption confidence="0.999921">
Figure 2. The Olympus dialog system reference architecture (a typical system)
</figureCaption>
<bodyText confidence="0.999729137254902">
final language models used during the InterSpeech
deployment were trained from on a corpus of 6350
utterances. The system operated with a lexicon of
4795 words, which included 659 lexicalized (con-
catenated) paper titles, and 1492 lexicalized author
names, and 78 lexicalized session names. The pro-
nunciations were generated using CMU Dictionary
and later manually corrected.
Language understanding. The system uses the
Phoenix (Ward and Issar, 1994) robust parser to
extract concepts from the recognition results. A
domain-specific shallow semantic grammar was
developed and concatenated with a domain-
independent grammar for generic expressions like
[Yes], [No], [Date], [Time], etc.
Dialog management. ConQuest uses a Raven-
Claw-based dialog manager (Bohus and Rudnicky,
2003). We developed a dialog task specification
for the conference schedule domain, expressed as a
hierarchical plan for the interaction, which the
RavenClaw engine uses to drive the dialog. In the
process, the RavenClaw engine automatically pro-
vides additional generic conversational skills such
as error recovery strategies and support for various
universal dialog mechanisms (e.g. repeat, start-
over, what-can-I-say, etc.)
Backend/Database. A backend agent looks up
schedule information from the database (stored as
a flat text file). The backend agent also performs
domain specific pre-lookup normalization (e.g.
mapping author names to their canonical forms),
and post-lookup processing of the returned records
(e.g. clustering papers by sessions). The database
file serves as starting point for constructing a
number of other system resources (e.g. language
model classes, lexicon, etc.)
Temporal reference resolution agent. Apart
from the database agent, the dialog manager also
communicates with an agent that resolves temporal
expressions (e.g. tomorrow at four p.m.) into ca-
nonical forms.
Language generation. ConQuest uses Rosetta,
a template-based language generation component.
The authoring effort at this level consisted of writ-
ing various templates for the different system ques-
tions and information presentation prompts.
Speech synthesis. ConQuest uses the Cepstral
(2005) speech synthesis engine, configured with an
open-domain unit selection voice. We manually
checked and corrected pronunciations for author
names, various technical terms and abbreviations.
</bodyText>
<sectionHeader confidence="0.994528" genericHeader="evaluation">
4 Development and Deployment
</sectionHeader>
<bodyText confidence="0.9999864375">
The first development of ConQuest system was
done for the Interspeech 2006 conference held in
Pittsburgh, PA. The iterative development process
involved regular interaction with potential users
i.e. researchers who regularly attend conferences.
Seven developers working half time participated in
this development for about three months. An esti-
mated one man-year of effort was spent. This esti-
mate does not include the effort involved in
transcribing the data collected after the conference.
Two systems were deployed at the Interspeech
2006 conference: a desktop system using a close-
talking microphone placed by the registration desk,
and a telephone-based system. Throughout the
conference we collected a corpus of 174 sessions.
We have orthographically transcribed the user ut-
</bodyText>
<page confidence="0.998187">
11
</page>
<bodyText confidence="0.999952652173913">
terances and are currently analyzing the data; we
plan to soon release it to the community, together
with detailed statistics, the full system logs as well
as the full system source code (Conquest, 2007).
Following Interspeech 2006, ConQuest was re-
deployed at IJCAI 2007 conference held in Hy-
derabad, India. The second deployment took an
estimated two man-months: three developers work-
ing half-time for over a month. The significant
parts of the second deployment involved incorpo-
rating scheduling data for the IJCAI 2007 and im-
plementing two new requirements i.e. support for
workshops and Indian English speech recognition.
The IJCAI development had fewer iterations than
the first effort. The two desktop systems set up at
the conference venue collected 129 sessions of
data. This data is currently being transcribed and
will soon be released to the community through the
Conquest website (Conquest, 2007).
Through these two deployments of ConQuest
the system specifications have been refined and we
expect the development time to asymptote to less
than a month after a few more deployments.
</bodyText>
<sectionHeader confidence="0.996713" genericHeader="conclusions">
5 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.999988212765958">
Our primary goal in developing ConQuest was to
enable research by constructing and releasing an
open-source, full-fledged dialog system, as well as
an initial corpus collected with this system. The
system is built on top of an open, transparent and
modular infrastructure that facilitates research in
spoken language interfaces (Olympus, 2007).
There have been a number of other efforts to
collect and publish dialog corpora, for instance
within the DARPA Communicator project. A more
recent project, that operates in a domain similar to
ConQuest is DiSCoH, a Dialog System for Confer-
ence Help developed by researchers at AT&amp;T,
ICSI and Edinburgh University, and deployed dur-
ing the SLT-2006 workshop (Adreani et al., 2006).
While their goals are similar, i.e. to enable re-
search, DiSCoH and ConQuest differ in a number
of dimensions. Functionality-wise, DiSCoH offers
general conference information about the venue,
accommodation options and costs, paper submis-
sion, etc., while ConQuest provides access to the
technical schedule and allows participants to vote
for a best paper award. DiSCoH is built using
AT&amp;T technology and a call-routing approach;
ConQuest relies on a plan-based dialog manage-
ment framework (RavenClaw) and an open-source
infrastructure (Olympus). Finally, the DiSCoH ef-
fort aims to develop a richly annotated dialog cor-
pus to be used for research; ConQuest’s aim is to
provide both the full system and an initial tran-
scribed and annotated corpus to the community.
The conference domain is interesting in that it
allows for frequent redeployment and in theory
provides regular access to a certain user-base. It
should therefore facilitate research and periodical
evaluations. Unfortunately, the dialog corpora col-
lected so far using DiSCoH and ConQuest have
been somewhat smaller than our initial expecta-
tions. We believe this is largely due to the fact that
the systems provide information that is already
accessible to users by other means (paper confer-
ence program, web-sites, etc.). Perhaps combining
the functionalities of these two systems, and ex-
panding into directions where the system provides
otherwise hard-to-access information (e.g. local
restaurants, transportation, etc.) would lead to in-
creased traffic.
</bodyText>
<sectionHeader confidence="0.999112" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998443478260869">
Adreani, G., Di Fabbrizio, G., Gilbert, M., Gillick, D.,
Hakkani-Tur, D., and Lemon, O., 2006 Let’s DiS-
CoH: Collecting an Annotated Open Corpus with
Dialogue Acts and Reward Signals for Natural Lan-
guage Helpdesk, in Proceedings of IEEE SLT-2006
Workshop, Aruba Beach, Aruba.
Bohus, D., and Rudnicky, A., 2003. RavenClaw: Dialog
Management Using Hierarchical Task Decomposi-
tion and an Expectation Agenda, in Proceedings of
Eurospeech 2003, Geneva, Switzerland.
Cepstral, LLC, 2005, SwiftTM: Small Footprint Text-to-
Speech Synthesizer, http://www.cepstral.com.
Conquest, 2007, http://www.conquest-dialog.org.
Huang, X., Alleva, F., Hon, H.-W., Hwang, M.-Y., Lee,
K.-F. and Rosenfeld, R., 1992. The SPHINX-II
Speech Recognition System: an overview, in Com-
puter Speech and Language, 7(2), pp 137-148, 1992.
Olympus/RavenClaw web page, as of January 2007:
http://www.ravenclaw-olympus.org/.
Ward, W., and Issar, S., 1994. Recent improvements in
the CMU spoken language understanding system, in
Proceedings of the ARPA Human Language Tech-
nology Workshop, pages 213–216, Plainsboro, NJ.
</reference>
<page confidence="0.998452">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.727609">
<title confidence="0.999858">Conquest – an Open-Source Dialog System for Conferences</title>
<author confidence="0.986303">Dan Bohus</author>
<author confidence="0.986303">Sergio Grau Puerto</author>
<author confidence="0.986303">David Huggins-Daines</author>
<author confidence="0.986303">Venkatesh Gopala Krishna</author>
<author confidence="0.986303">Rohit Kumar</author>
<author confidence="0.986303">Antoine Raux</author>
<author confidence="0.986303">Stefanie</author>
<affiliation confidence="0.9994">School of Computer Science Carnegie Mellon University</affiliation>
<email confidence="0.970192">dbohus@cs.cmu.edu</email>
<email confidence="0.970192">sgrau@cs.cmu.edu</email>
<email confidence="0.970192">dhuggins@cs.cmu.edu</email>
<email confidence="0.970192">vkeri@cs.cmu.edu</email>
<email confidence="0.970192">gopalakr@cs.cmu.edu</email>
<email confidence="0.970192">rohitk@cs.cmu.edu</email>
<email confidence="0.970192">antoine@cs.cmu.edu</email>
<email confidence="0.970192">stef@cs.cmu.edu</email>
<abstract confidence="0.9817314">We describe ConQuest, an open-source, reusable spoken dialog system that provides technical program information during conferences. The system uses a transparent, modular and open infrastructure, and aims to enable applied research in spoken language interfaces. The conference domain is a good platform for applied research since it permits periodical redeployments and evaluations with a real user-base. In this paper, we describe the system’s functionality, overall architecture, and we discuss two initial deployments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Adreani</author>
<author>G Di Fabbrizio</author>
<author>M Gilbert</author>
<author>D Gillick</author>
<author>D Hakkani-Tur</author>
<author>O Lemon</author>
</authors>
<title>Let’s DiSCoH: Collecting an Annotated Open Corpus with Dialogue Acts and Reward Signals for Natural Language Helpdesk,</title>
<date>2006</date>
<booktitle>in Proceedings of IEEE SLT-2006 Workshop,</booktitle>
<location>Aruba Beach, Aruba.</location>
<marker>Adreani, Di Fabbrizio, Gilbert, Gillick, Hakkani-Tur, Lemon, 2006</marker>
<rawString>Adreani, G., Di Fabbrizio, G., Gilbert, M., Gillick, D., Hakkani-Tur, D., and Lemon, O., 2006 Let’s DiSCoH: Collecting an Annotated Open Corpus with Dialogue Acts and Reward Signals for Natural Language Helpdesk, in Proceedings of IEEE SLT-2006 Workshop, Aruba Beach, Aruba.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bohus</author>
<author>A Rudnicky</author>
</authors>
<title>RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda,</title>
<date>2003</date>
<booktitle>in Proceedings of Eurospeech</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="6857" citStr="Bohus and Rudnicky, 2003" startWordPosition="1109" endWordPosition="1112">including several fall-back strategies (e.g. turn 13). 3 System Architecture The ConQuest system was built using RavenClaw/ Olympus (2007), an open-source framework that facilitates research and development in task oriented conversational spoken language interfaces. Olympus consists of a collection of components for recognition, language understanding, dialog management, language generation, speech synthesis, etc., and the corresponding communication infrastructure. To date, Olympus has been used to develop and deploy a number of other systems spanning different domains and interaction types (Bohus and Rudnicky, 2003). A key characteristic of the Olympus framework is a clear separation between the domain independent programs (or components) and domain specific resources. This decoupling promotes reusability and significantly lessens the system development effort. In ConQuest, the authoring effort was focused on developing resources such as the lexicon, language model, grammar, dialog task specification, etc. Some interesting, unanticipated engineering challenges we faced during development were dealing with foreign names and accented characters and performing text normalization on various fields (e.g. Alex</context>
<context position="9153" citStr="Bohus and Rudnicky, 2003" startWordPosition="1443" endWordPosition="1446">95 words, which included 659 lexicalized (concatenated) paper titles, and 1492 lexicalized author names, and 78 lexicalized session names. The pronunciations were generated using CMU Dictionary and later manually corrected. Language understanding. The system uses the Phoenix (Ward and Issar, 1994) robust parser to extract concepts from the recognition results. A domain-specific shallow semantic grammar was developed and concatenated with a domainindependent grammar for generic expressions like [Yes], [No], [Date], [Time], etc. Dialog management. ConQuest uses a RavenClaw-based dialog manager (Bohus and Rudnicky, 2003). We developed a dialog task specification for the conference schedule domain, expressed as a hierarchical plan for the interaction, which the RavenClaw engine uses to drive the dialog. In the process, the RavenClaw engine automatically provides additional generic conversational skills such as error recovery strategies and support for various universal dialog mechanisms (e.g. repeat, startover, what-can-I-say, etc.) Backend/Database. A backend agent looks up schedule information from the database (stored as a flat text file). The backend agent also performs domain specific pre-lookup normaliza</context>
</contexts>
<marker>Bohus, Rudnicky, 2003</marker>
<rawString>Bohus, D., and Rudnicky, A., 2003. RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda, in Proceedings of Eurospeech 2003, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LLC Cepstral</author>
</authors>
<title>SwiftTM: Small Footprint Text-toSpeech Synthesizer,</title>
<date>2005</date>
<pages>http://www.conquest-dialog.org.</pages>
<location>http://www.cepstral.com. Conquest,</location>
<contexts>
<context position="10536" citStr="Cepstral (2005)" startWordPosition="1640" endWordPosition="1641">rves as starting point for constructing a number of other system resources (e.g. language model classes, lexicon, etc.) Temporal reference resolution agent. Apart from the database agent, the dialog manager also communicates with an agent that resolves temporal expressions (e.g. tomorrow at four p.m.) into canonical forms. Language generation. ConQuest uses Rosetta, a template-based language generation component. The authoring effort at this level consisted of writing various templates for the different system questions and information presentation prompts. Speech synthesis. ConQuest uses the Cepstral (2005) speech synthesis engine, configured with an open-domain unit selection voice. We manually checked and corrected pronunciations for author names, various technical terms and abbreviations. 4 Development and Deployment The first development of ConQuest system was done for the Interspeech 2006 conference held in Pittsburgh, PA. The iterative development process involved regular interaction with potential users i.e. researchers who regularly attend conferences. Seven developers working half time participated in this development for about three months. An estimated one man-year of effort was spent</context>
</contexts>
<marker>Cepstral, 2005</marker>
<rawString>Cepstral, LLC, 2005, SwiftTM: Small Footprint Text-toSpeech Synthesizer, http://www.cepstral.com. Conquest, 2007, http://www.conquest-dialog.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
<author>F Alleva</author>
<author>H-W Hon</author>
<author>M-Y Hwang</author>
<author>K-F Lee</author>
<author>R Rosenfeld</author>
</authors>
<title>The SPHINX-II Speech Recognition System: an overview,</title>
<date>1992</date>
<journal>in Computer Speech and Language,</journal>
<volume>7</volume>
<issue>2</issue>
<pages>137--148</pages>
<contexts>
<context position="7858" citStr="Huang et al., 1992" startWordPosition="1255" endWordPosition="1258">cification, etc. Some interesting, unanticipated engineering challenges we faced during development were dealing with foreign names and accented characters and performing text normalization on various fields (e.g. Alex Smith and Alexander Smith are the same author), while at the same time ensuring consistency between these various resources. Below, we briefly comment of each component and the corresponding resources. Figure 2 provides a top-level architectural view. Speech Recognition. ConQuest uses a recognition server coupled to a set of parallel recognition engines: two SPHINX-II decoders (Huang et al., 1992) that use gender-specific acoustic models, and a DTMF (touch-tone decoder). Each recognition engine uses class-based (e.g. paper titles, author names, etc.), state-specific trigram-language models. We started with an initial language model built using data collected with an early text-only prototype. We then internally deployed a speech based system, collected more data, transcribed it, and used it to retrain the language models. The 10 Figure 2. The Olympus dialog system reference architecture (a typical system) final language models used during the InterSpeech deployment were trained from on</context>
</contexts>
<marker>Huang, Alleva, Hon, Hwang, Lee, Rosenfeld, 1992</marker>
<rawString>Huang, X., Alleva, F., Hon, H.-W., Hwang, M.-Y., Lee, K.-F. and Rosenfeld, R., 1992. The SPHINX-II Speech Recognition System: an overview, in Computer Speech and Language, 7(2), pp 137-148, 1992.</rawString>
</citation>
<citation valid="true">
<title>Olympus/RavenClaw web page, as of</title>
<date>2007</date>
<note>http://www.ravenclaw-olympus.org/.</note>
<contexts>
<context position="1938" citStr="(2007)" startWordPosition="283" endWordPosition="283">ions) an open-source spoken dialog system that provides access to schedule and technical program information during conferences. We believe the conference domain has a number of good properties for applied research: it includes a number of tasks of different complexities, it provides regular access to a realworld user population; it permits periodical redeployments and evaluations and therefore can provide a natural common evaluation task for the spoken language interfaces community. The ConQuest system is constructed on top of the open, transparent and modular Olympus dialog system framework (2007), and can be easily reused across different conferences. To date, the system has been deployed in two conferences: InterSpeech 2006 and IJCAI 2007. Together with corpora collected from these deployments, the system is freely available for download (Conquest, 2007). We begin by describing the ConQuest functionality in the next section. Then, in section 3 we provide an overview of the system architecture and discuss the development process. In section 4 we briefly discuss the two deployment efforts. Finally, in section 5 we discuss related work and draw a number of conclusions. 2 Functionality A</context>
<context position="6370" citStr="(2007)" startWordPosition="1047" endWordPosition="1047"> Paper 3 – [...] Would you like to vote for any of these? 16 U. Discourse Structure and Speech Recognition Problems 17 S: Okay, I’ve recorded your vote for the paper entitled “Discourse Structure and Speech Recognition Problems” What else can I do for you? 18 U. [...I Figure 1. A sample interaction with ConQuest users to easily navigate the schedule (see turns 3, 5 and 15). The system uses a rich repertoire of error recovery strategies to handle potential errors, including several fall-back strategies (e.g. turn 13). 3 System Architecture The ConQuest system was built using RavenClaw/ Olympus (2007), an open-source framework that facilitates research and development in task oriented conversational spoken language interfaces. Olympus consists of a collection of components for recognition, language understanding, dialog management, language generation, speech synthesis, etc., and the corresponding communication infrastructure. To date, Olympus has been used to develop and deploy a number of other systems spanning different domains and interaction types (Bohus and Rudnicky, 2003). A key characteristic of the Olympus framework is a clear separation between the domain independent programs (or</context>
</contexts>
<marker>2007</marker>
<rawString>Olympus/RavenClaw web page, as of January 2007: http://www.ravenclaw-olympus.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ward</author>
<author>S Issar</author>
</authors>
<title>Recent improvements in the CMU spoken language understanding system,</title>
<date>1994</date>
<booktitle>in Proceedings of the ARPA Human Language Technology Workshop,</booktitle>
<pages>213--216</pages>
<location>Plainsboro, NJ.</location>
<contexts>
<context position="8826" citStr="Ward and Issar, 1994" startWordPosition="1398" endWordPosition="1401">stem, collected more data, transcribed it, and used it to retrain the language models. The 10 Figure 2. The Olympus dialog system reference architecture (a typical system) final language models used during the InterSpeech deployment were trained from on a corpus of 6350 utterances. The system operated with a lexicon of 4795 words, which included 659 lexicalized (concatenated) paper titles, and 1492 lexicalized author names, and 78 lexicalized session names. The pronunciations were generated using CMU Dictionary and later manually corrected. Language understanding. The system uses the Phoenix (Ward and Issar, 1994) robust parser to extract concepts from the recognition results. A domain-specific shallow semantic grammar was developed and concatenated with a domainindependent grammar for generic expressions like [Yes], [No], [Date], [Time], etc. Dialog management. ConQuest uses a RavenClaw-based dialog manager (Bohus and Rudnicky, 2003). We developed a dialog task specification for the conference schedule domain, expressed as a hierarchical plan for the interaction, which the RavenClaw engine uses to drive the dialog. In the process, the RavenClaw engine automatically provides additional generic conversa</context>
</contexts>
<marker>Ward, Issar, 1994</marker>
<rawString>Ward, W., and Issar, S., 1994. Recent improvements in the CMU spoken language understanding system, in Proceedings of the ARPA Human Language Technology Workshop, pages 213–216, Plainsboro, NJ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>