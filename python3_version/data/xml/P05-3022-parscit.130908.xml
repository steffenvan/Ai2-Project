<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002638">
<title confidence="0.997191666666667">
Two diverse systems built using
generic components for spoken dialogue
(Recent Progress on TRIPS)
</title>
<author confidence="0.986726">
James Allen, George Ferguson, Mary Swift, Amanda Stent, Scott Stoness,
Lucian Galescu, Nathan Chambers, Ellen Campana, and Gregory Aist
</author>
<affiliation confidence="0.994472">
University of Rochester
Computer Science Department
</affiliation>
<address confidence="0.6570865">
UR Comp Sci RC 270226
Rochester NY 14627 USA
{james, ferguson, swift, stoness,
campana, gaist}
</address>
<email confidence="0.709813">
@cs.rochester.edu
</email>
<affiliation confidence="0.510457">
Institute for
</affiliation>
<address confidence="0.670443333333333">
Human and Machine Cognition
40 South Alcaniz St.
Pensacola FL 32502
</address>
<email confidence="0.917257">
{lgalescu,nchambers}@ihmc.us
</email>
<affiliation confidence="0.80567175">
State University of New York at
Stony Brook
1418 Computer Science
Stony Brook University
</affiliation>
<address confidence="0.783713">
Stony Brook NY 11794 USA
</address>
<email confidence="0.992731">
stent@cs.sunysb.edu
</email>
<sectionHeader confidence="0.995492" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999582857142857">
This paper describes recent progress on the
TRIPS architecture for developing spoken-lan-
guage dialogue systems. The interactive poster
session will include demonstrations of two sys-
tems built using TRIPS: a computer purchas-
ing assistant, and an object placement (and ma-
nipulation) task.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99968062962963">
Building a robust spoken dialogue system for a new
task currently requires considerable effort, includ-
ing extensive data collection, grammar develop-
ment, and building a dialogue manager that drives
the system using its &amp;quot;back-end&amp;quot; application (e.g.
database query, planning and scheduling). We de-
scribe progress in an effort to build a generic dia-
logue system that can be rapidly customized to a
wide range of different types of applications, pri-
marily by defining a domain-specific task model
and the interfaces to the back-end systems. This is
achieved by using generic components (i.e., ones
that apply in any practical domain) for all stages of
understanding and developing techniques for rapid-
ly customizing the generic components to new do-
mains (e.g. Aist, Allen, and Galescu 2004). To
achieve this goal we have made several innovations,
including (1) developing domain independent mod-
els of semantic and contextual interpretation, (2)
developing generic dialogue management compo-
nents based on an abstract model of collaborative
problem solving, and (3) extensively using an ontol-
ogy-mapping system that connects the domain inde-
pendent representations to the representations/query
languages used by the back-end applications, and
which is used to automatically optimize the perfor-
mance of the system in the specific domain.
</bodyText>
<sectionHeader confidence="0.93403" genericHeader="method">
2 Theoretical Underpinnings: The Prob-
</sectionHeader>
<subsectionHeader confidence="0.944505">
lem-Solving Model of Dialogue
</subsectionHeader>
<bodyText confidence="0.999987083333333">
While many have observed that communication
is a specialized form of joint action that happens to
involve language and that dialogue can be viewed
as collaborative problem solving, very few imple-
mented systems have been explicitly based on these
ideas. Theories of speech act interpretation as inten-
tion recognition have been developed (including ex-
tensive prior work in TRIPS&apos; predecessor, the
TRAINS project), but have been generally consid-
ered impractical for actual systems. Planning mod-
els have been more successful on the generation
side, and some systems have used the notion of exe-
cuting explicit task models to track and drive the in-
teractions (e.g., Sidner and Rich&apos;s COLLAGEN
framework). But collaborative problem solving, and
dialogue in general, is much more general than exe-
cuting tasks. In our applications, in addition to exe-
cuting tasks, we see dialogue that is used to define
the task (i.e., collaborative planning), evaluate the
task (e.g., estimating how long it will take, com-
paring options, or likely effects), debug a task
(e.g., identifying and discussing problems and how
to remedy them), learn new tasks (e.g., by demon-
stration and instruction).
</bodyText>
<page confidence="0.991694">
85
</page>
<subsubsectionHeader confidence="0.357813">
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
</subsubsectionHeader>
<bodyText confidence="0.915408">
pages 85–88, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
In the remainder of the paper, we&apos;ll first discuss
the methods we&apos;ve developed for building dialogue
systems using generic components. We&apos;ll then de-
scribe two systems implemented using the TRIPS
architecture that we will demonstrate at the interac-
tive poster session.
</bodyText>
<sectionHeader confidence="0.831794" genericHeader="method">
3 Generic Methods: Ontology Mappings
and Collaborative Problem Solving
</sectionHeader>
<bodyText confidence="0.999992290322581">
The goal of our work is to develop generic spoken
dialogue technology that can be rapidly customized
to new applications, tasks and domains. To do this,
we have developed generic domain independent rep-
resentations not only of sentence meaning but also
of the collaborative actions that are performed by
the speech acts as one engages in dialogue. Further-
more, we need to be able to easily connect these
generic representations to a wide range of different
domain specific task models and applications, rang-
ing from data base query systems to state-of-the-art
planning and scheduling systems. This paper de-
scribes the approach we have developed in the
TRIPS system. TRIPS is now being used in a wide
range of diverse applications, from interactive plan-
ning (e.g., developing evacuation plans), advice giv-
ing (e.g., a medication advisor (Ferguson et al.
2002)), controlling teams of robots, collaborative
assistance (e.g., an assistant that can help you pur-
chase a computer, as described in this paper), sup-
porting human learning, and most recently having
the computer learn (or be taught) tasks, such as
learning to perform tasks on the web. Even though
the tasks and domains differ dramatically, these ap-
plications use the same set of core understanding
components.
The key to supporting such a range of tasks and ap-
plications is the use of a general ontology-mapping
system. This allows the developer to express a set
of mapping rules that translate the generic knowl-
edge representation into the specific representations
used by the back-end applications (called the KR
representation). In order to support generic dis-
course processing, we represent these mappings as
a chain of simpler transformations. These represen-
tations are thus transformed in several stages. The
first, using the ontology mapping rules, maps the
LF representation into an intermediary representa-
tion (AKRL - the abstract KR language) that has a
generic syntax but whose content is expressed in
terms of the KR ontology. The second stage is a
syntactic transformation that occurs at the time that
calls to the back-end applications actually occur so
that interactions occur in the representations the
back-end expects. In addition to using ontology
mapping to deal with the representational issues,
TRIPS is unique in that it uses a generic model of
collaborative problem solving to drive the dialogue
itself (e.g. Allen, Blaylock, and Ferguson 2002).
This model forms the basis of a generic component
(the collaboration manager) that supports both in-
tention recognition to identify the intended speech
acts and their content, planning the system&apos;s actions
to respond to the user (or that take initiative), and
providing utterance realization goals to the genera-
tion system. To develop this, we have been develop-
ing a generic ontology of collaborative problem
solving acts, which provide the framework for man-
aging the dialogue. The collaboration manager
queries a domain-specific task component in order
to make decisions about interpretations and re-
sponses.
</bodyText>
<sectionHeader confidence="0.9330595" genericHeader="method">
4 TRIPS Spoken Dialogue Interface to
the CALO Purchasing Assistant
</sectionHeader>
<bodyText confidence="0.999936958333333">
The CALO project is a large multisite effort which
aims at building a computerized assistant that
learns how to help you with day-to-day tasks. The
overarching goal of the CALO project is to
... create cognitive software systems, that is,
systems that can reason, learn from experi-
ence, be told what to do, explain what they
are doing, reflect on their experience, and re-
spond robustly to surprise (Mark and Per-
rault 2004).
Within this broad mandate, one of our current areas
of focus is user-system dialogue regarding the task
of purchasing - including eliciting user needs, de-
scribing possibilities, and reviewing &amp; finalizing a
purchase decision. (Not necessarily as discrete
stages; these elements may be interleaved as appro-
priate for the specific item(s) and setting.) Within
the purchasing domain, we began with computer
purchasing and have branched out to other equip-
ment such as projectors.
How to help with purchasing? The family of tasks
involving purchasing items online, regardless of the
type of item, have a number of elements in com-
mon. The process of purchasing has some common
</bodyText>
<page confidence="0.992655">
86
</page>
<bodyText confidence="0.999934871794872">
dialogue elements - reporting on the range of fea-
tures available, allowing the user to specify con-
straints, and so forth. Also, regarding the goal that
must be reached at the end of the task, the eventual
item must:
Meet requirements. The item needs to meet some
sort of user expectations. This could be as arbitrary
as a specific part number, or as compositional - and
amenable to machine understanding - as a set of
physical dimensions (length, width, height, mass,
etc.)
Be approved. Either the system will have the au-
thority to approve it (cf. Amazon&apos;s one-click order-
ing system), or more commonly the user will review
and confirm the purchase. In an office environment
the approval process may extend to include review
by a supervisor, such as might happen with an item
costing over (say) $1000.
Be available. (At one time a certain electronics
store in California had the habit of leaving out floor
models of laptops beyond the point where any were
actually available for sale. (Perhaps to entice the
unwitting customer into an “upsale”, that is, buying
a similar but more expensive computer.)) On a
more serious note, computer specifications change
rapidly, and so access to online information about
available computers (provided by other research
within CALO) would be important in order to en-
sure that the user can actually order the machine he
or she has indicated a preference for.
At the interactive poster session, we will demon-
strate some of the current spoken dialogue capabili-
ty related to the CALO task of purchasing equip-
ment. We will demonstrate a number of the aspects
of the system such as initiating a conversation, dis-
cussing specific requirements, presenting possible
equipment to purchase, system-initiated reminders
to ask for supervisor approval for large purchases,
and finalizing a decision to purchase.
</bodyText>
<figureCaption confidence="0.976086">
Figure 1. Fruit carts display. 87
</figureCaption>
<bodyText confidence="0.993906666666667">
5 TRIPS Spoken Dialogue Interface to
choosing, placing, painting, rotating,
and filling (virtual) fruit carts
TRIPS is versatile in its applications, as we&apos;ve said
previously. We hope to also demonstrate an inter-
face to a system for using spoken commands to
modifying, manipulating, and placing objects on a
computer-displayed map. This system (aka “fruit
carts”) extends the TRIPS architecture into the
realm of continuous understanding. That is, when
state-of-the-art dialogue systems listen, they typi-
cally wait for the end of the utterance before decid-
ing what to do. People on the other hand do not
wait in this way – they can act on partial informa-
tion as it becomes available. A classic example
comes from M. Tanenhaus and colleagues at
Rochester: when presented with several objects of
various colors and told to “click on the yel-”, people
will already tend to be looking relatively more at the
yellow object(s) even before the word “yellow” has
been completed. To achieve this type of interactivi-
ty with a dialogue system – at least at the level of
two or three words at a time, if not parts of words –
imposes some interesting challenges. For example:
</bodyText>
<listItem confidence="0.922697777777778">
1. Information must flow asynchronously between
dialogue components, so that actions can be trig-
gered based on partial utterances even while the
understanding continues
2. There must be reasonable representations of in-
complete information – not just “incomplete sen-
tence”, but specifying what is present already
and perhaps what may potentially follow
3. Speech recognition, utterance segmentation,
</listItem>
<bodyText confidence="0.998475111111111">
parsing, interpretation, discourse reasoning, and
actions must all be able to happen in real time
The fruit carts system consists of two main compo-
nents: first, a graphical interface implemented on
Windows 2000 using the .NET framework, and
connected to a high-quality eyetracker; second, a
TRIPS-driven spoken dialogue interface implement-
ed primarily in LISP. The actions in this domain
are as follows:
</bodyText>
<listItem confidence="0.985498333333333">
1. Select an object (“take the large plain square”)
2. Move it (“move it to central park”)
3. Rotate it (“and then turn it left a bit – that&apos;s
good”)
4. Paint it (“and that one needs to be purple”)
5. Fill it (“and there&apos;s a grapefruit inside it”)
</listItem>
<bodyText confidence="0.877895571428571">
Figure 1 shows an example screenshot from the
fruit carts visual display. The natural language in-
teraction is designed to handle various ways of
speaking, including conventional definite descrip-
tions (“move the large square to central park”) and
more interactive language such as (“up towards the
flag pole – right a bit – more – um- stop there.”)
</bodyText>
<sectionHeader confidence="0.998618" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999982666666667">
In this brief paper, we have described some of
the recent progress on the TRIPS platform. In par-
ticular we have focused on two systems developed
in TRIPS: a spoken dialogue interface to a mixed-
initiative purchasing assistant, and a spoken inter-
face for exploring continuous understanding in an
object-placement task. In both cases the systems
make use of reusable components – for input and
output such as parsing and speech synthesis, and
also for dialogue functionality such as mapping be-
tween language, abstract semantics, and specific
representations for each domain.
</bodyText>
<sectionHeader confidence="0.999111" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997764851851852">
Aist, G. 2004. Speech, gaze, and mouse data from
choosing, placing, painting, rotating, and filling
(virtual) vending carts. International Committee for
Co-ordination and Standardisation of Speech
Databases (COCOSDA) 2004 Workshop, Jeju Is-
land, Korea, October 4, 2004.
Aist, G.S., Allen, J., and Galescu, L. 2004. Expanding
the linguistic coverage of a spoken dialogue system
by mining human-human dialogue for new sentences
with familiar meanings. Member Abstract, 26th An-
nual Meeting of the Cognitive Science Society,
Chicago, August 5-7, 2004.
James Allen, Nate Blaylock, and George Ferguson. A
problem-solving model for collaborative agents. In
First International Joint Conference on Autonomous
Agents and Multiagent Systems, Bologna, Italy, July
15-19 2002.
George Ferguson, James F. Allen, Nate J. Blaylock,
Donna K. Byron, Nate W. Chambers, Myrsolava O.
Dzikovska, Lucian Galescu, Xipeng Shen, Robert S.
Swier, and Mary D. Swift. The Medication Advisor
Project: Preliminary Report, Technical Report 776,
Computer Science Dept., University of Rochester,
May 2002.
Mark, B., and Perrault, R. (principal investigators).
2004. Website for Cognitive Assistant that Learns
and Organizes. http://www.ai.sri.com/project/CALO
</reference>
<page confidence="0.99937">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.025565">
<title confidence="0.931527666666667">Two diverse systems built using generic components for spoken dialogue (Recent Progress on TRIPS)</title>
<author confidence="0.99225">James Allen</author>
<author confidence="0.99225">George Ferguson</author>
<author confidence="0.99225">Mary Swift</author>
<author confidence="0.99225">Amanda Stent</author>
<author confidence="0.99225">Scott Stoness</author>
<author confidence="0.99225">Lucian Galescu</author>
<author confidence="0.99225">Nathan Chambers</author>
<author confidence="0.99225">Ellen Campana</author>
<author confidence="0.99225">Gregory Aist</author>
<affiliation confidence="0.999884">University of Rochester Computer Science Department</affiliation>
<address confidence="0.68408275">UR Comp Sci RC 270226 Rochester NY 14627 USA {james, ferguson, swift, stoness, campana, gaist}</address>
<email confidence="0.988928">@cs.rochester.edu</email>
<affiliation confidence="0.487737">Institute for Human and Machine Cognition</affiliation>
<address confidence="0.9449315">40 South Alcaniz St. Pensacola FL 32502</address>
<email confidence="0.925633">lgalescu@ihmc.us</email>
<email confidence="0.925633">nchambers@ihmc.us</email>
<affiliation confidence="0.754863">State University of New York at</affiliation>
<author confidence="0.655078">Stony Brook</author>
<affiliation confidence="0.832856">1418 Computer Science Stony Brook University</affiliation>
<address confidence="0.988878">Stony Brook NY 11794 USA</address>
<email confidence="0.999856">stent@cs.sunysb.edu</email>
<abstract confidence="0.99059925">This paper describes recent progress on the TRIPS architecture for developing spoken-language dialogue systems. The interactive poster session will include demonstrations of two systems built using TRIPS: a computer purchasing assistant, and an object placement (and manipulation) task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Aist</author>
</authors>
<title>Speech, gaze, and mouse data from choosing, placing, painting, rotating, and filling (virtual) vending carts.</title>
<date>2004</date>
<booktitle>International Committee for Co-ordination and Standardisation of Speech Databases (COCOSDA) 2004 Workshop,</booktitle>
<location>Jeju Island,</location>
<marker>Aist, 2004</marker>
<rawString>Aist, G. 2004. Speech, gaze, and mouse data from choosing, placing, painting, rotating, and filling (virtual) vending carts. International Committee for Co-ordination and Standardisation of Speech Databases (COCOSDA) 2004 Workshop, Jeju Island, Korea, October 4, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Aist</author>
<author>J Allen</author>
<author>L Galescu</author>
</authors>
<title>Expanding the linguistic coverage of a spoken dialogue system by mining human-human dialogue for new sentences with familiar meanings.</title>
<date>2004</date>
<booktitle>Member Abstract, 26th Annual Meeting of the Cognitive Science Society,</booktitle>
<location>Chicago,</location>
<marker>Aist, Allen, Galescu, 2004</marker>
<rawString>Aist, G.S., Allen, J., and Galescu, L. 2004. Expanding the linguistic coverage of a spoken dialogue system by mining human-human dialogue for new sentences with familiar meanings. Member Abstract, 26th Annual Meeting of the Cognitive Science Society, Chicago, August 5-7, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Nate Blaylock</author>
<author>George Ferguson</author>
</authors>
<title>A problem-solving model for collaborative agents.</title>
<date>2002</date>
<booktitle>In First International Joint Conference on Autonomous Agents and Multiagent Systems,</booktitle>
<location>Bologna, Italy,</location>
<marker>Allen, Blaylock, Ferguson, 2002</marker>
<rawString>James Allen, Nate Blaylock, and George Ferguson. A problem-solving model for collaborative agents. In First International Joint Conference on Autonomous Agents and Multiagent Systems, Bologna, Italy, July 15-19 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James F Allen</author>
<author>Nate J Blaylock</author>
<author>Donna K Byron</author>
<author>Nate W Chambers</author>
<author>Myrsolava O Dzikovska</author>
<author>Lucian Galescu</author>
<author>Xipeng Shen</author>
<author>Robert S Swier</author>
<author>Mary D Swift</author>
</authors>
<title>The Medication Advisor Project:</title>
<date>2002</date>
<tech>Preliminary Report, Technical Report 776,</tech>
<institution>Computer Science Dept., University of Rochester,</institution>
<contexts>
<context position="4877" citStr="Ferguson et al. 2002" startWordPosition="737" endWordPosition="740">eaning but also of the collaborative actions that are performed by the speech acts as one engages in dialogue. Furthermore, we need to be able to easily connect these generic representations to a wide range of different domain specific task models and applications, ranging from data base query systems to state-of-the-art planning and scheduling systems. This paper describes the approach we have developed in the TRIPS system. TRIPS is now being used in a wide range of diverse applications, from interactive planning (e.g., developing evacuation plans), advice giving (e.g., a medication advisor (Ferguson et al. 2002)), controlling teams of robots, collaborative assistance (e.g., an assistant that can help you purchase a computer, as described in this paper), supporting human learning, and most recently having the computer learn (or be taught) tasks, such as learning to perform tasks on the web. Even though the tasks and domains differ dramatically, these applications use the same set of core understanding components. The key to supporting such a range of tasks and applications is the use of a general ontology-mapping system. This allows the developer to express a set of mapping rules that translate the ge</context>
</contexts>
<marker>Ferguson, Allen, Blaylock, Byron, Chambers, Dzikovska, Galescu, Shen, Swier, Swift, 2002</marker>
<rawString>George Ferguson, James F. Allen, Nate J. Blaylock, Donna K. Byron, Nate W. Chambers, Myrsolava O. Dzikovska, Lucian Galescu, Xipeng Shen, Robert S. Swier, and Mary D. Swift. The Medication Advisor Project: Preliminary Report, Technical Report 776, Computer Science Dept., University of Rochester, May 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mark</author>
<author>R Perrault</author>
</authors>
<title>Website for Cognitive Assistant that Learns and Organizes.</title>
<date>2004</date>
<note>http://www.ai.sri.com/project/CALO</note>
<contexts>
<context position="7543" citStr="Mark and Perrault 2004" startWordPosition="1160" endWordPosition="1164">e. The collaboration manager queries a domain-specific task component in order to make decisions about interpretations and responses. 4 TRIPS Spoken Dialogue Interface to the CALO Purchasing Assistant The CALO project is a large multisite effort which aims at building a computerized assistant that learns how to help you with day-to-day tasks. The overarching goal of the CALO project is to ... create cognitive software systems, that is, systems that can reason, learn from experience, be told what to do, explain what they are doing, reflect on their experience, and respond robustly to surprise (Mark and Perrault 2004). Within this broad mandate, one of our current areas of focus is user-system dialogue regarding the task of purchasing - including eliciting user needs, describing possibilities, and reviewing &amp; finalizing a purchase decision. (Not necessarily as discrete stages; these elements may be interleaved as appropriate for the specific item(s) and setting.) Within the purchasing domain, we began with computer purchasing and have branched out to other equipment such as projectors. How to help with purchasing? The family of tasks involving purchasing items online, regardless of the type of item, have a</context>
</contexts>
<marker>Mark, Perrault, 2004</marker>
<rawString>Mark, B., and Perrault, R. (principal investigators). 2004. Website for Cognitive Assistant that Learns and Organizes. http://www.ai.sri.com/project/CALO</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>