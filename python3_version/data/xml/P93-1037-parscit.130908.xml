<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.067708">
<title confidence="0.9352085">
A FLEXIBLE APPROACH TO COOPERATIVE RESPONSE GENERATION
IN INFORMATION-SEEKING DIALOGUES
</title>
<author confidence="0.72034">
Liliana Ardissono, Alessandro Lombardo, Dario Sestero
</author>
<note confidence="0.5889965">
Dipartimento di Informatica - Universita&apos; di Torino
C.so Svizzera 185 - 10149 - Torino - Italy
</note>
<email confidence="0.997736">
E-Mail: liliana@di.unito.it
</email>
<sectionHeader confidence="0.99388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999816">
This paper presents a cooperative consultation system
on a restricted domain. The system builds hypotheses
on the user&apos;s plan and avoids misunderstandings (with
consequent repair dialogues) through clarification
dialogues in case of ambiguity. The role played by
constraints in the generation of the answer is charac-
terized in order to limit the cases of ambiguities re-
quiring a clarification dialogue. The answers of the
system are generated at different levels of detail, ac-
cording to the user&apos;s competence in the domain.
</bodyText>
<sectionHeader confidence="0.998755" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999902909090909">
This paper presents a plan-based consultation system
for getting information on how to achieve a goal in a
restricted domain.1 The main purpose of the system is
to recognize the user&apos;s plans and goals to build coop-
erative answers in a flexible way [Allen, 83],
[Carberry, 90]. The system is composed of two parts:
hypotheses construction and response generation.
The construction of hypotheses is based on Context
Models (CMs) [Carberry, 90]. Carberry uses default
inferences [Carberry, 90b] to select a single hypothe-
sis for building the final answer of the system and, in
case the choice is incorrect, a repair dialogue is
started. Instead, in our system, we consider all plau-
sible hypotheses and if the ambiguity among them is
relevant for the generation of the response, we try to
solve it by starting a clarification dialogue. According
to [van Beek and Cohen, 91], clarification dialogues
are simpler for the user than repair ones, because they
only involve yes/no questions on the selected ambigu-
ous plans. Furthermore, repair dialogues generally re-
quire a stronger participation of the user. Finally, if
the misunderstanding is not discovered, the system
delivers information that is not proper to the user&apos;s
case. For these reasons, it is preferable to solve the
ambiguity a priori, by asking the user information on
his intentions. In van Beek and Cohen&apos;s approach
clarification dialogues are started, even in case the
answers associated with the plausible hypotheses are
distinguished by features that could directly be
managed in the answer. We avoid this by identifying
the constraints relevant for a clarification dialogue
and those which can be mentioned in the answer. In
this way, the friendliness of the system is improved
</bodyText>
<footnote confidence="0.969521">
1The system is concerned with information about a CS
Department.
</footnote>
<bodyText confidence="0.99543048">
and the number and the length of the clarification dia-
logues are reduced.
In the perspective of generating flexible
cooperative answers, it is important to differentiate
their detail level by adapting them to the user&apos;s
competence in the domain. In our work, we want to
study how to embed information obtained from a user
model component in the system. As a fust step in this
direction, we introduce a preliminary classification of
users in three standard levels of competence
corresponding to the major users&apos; prototypes the
system is devoted to. Then, in order to produce
differentiated answers, the hypotheses are expanded
according to the user&apos;s competence level.
The knowledge about actions and plans is stored in
a plan library structured on the basis of two main hier-
archies: the Decomposition Hierarchy (DH) and the
Generalization Hierarchy (GH) [Kautz and Allen, 86].
The first one describes the plans associated with the
actions and is used for explaining how to execute a
complex action. The second one expresses the
relation among general and specific actions (the major
specificity is due to additional restrictions on
parameters). It supports an inheritance mechanism
and a top-down form of clarification dialogue.
</bodyText>
<subsectionHeader confidence="0.514817">
THE ALGORITHM
</subsectionHeader>
<bodyText confidence="0.999216">
The algorithm consists of two parts: a hypotheses
construction and a response generation phase.
</bodyText>
<listItem confidence="0.981525142857143">
• In the hypotheses construction phase the following
steps are repeated for each sentence of the user:
1- Action identification: on the basis of the user&apos;s ut-
terance, a set of candidate actions is selected.
2- Focusing: CMs built after the analysis of the pre-
vious sentences are analyzed to find a connection
with any candidate action identified in step 1 and, for
each established connection, a new CM is built. (At
the beginning of the dialogue, from each candidate
action a CM is created).
3- Upward expansion along the DH: each CM is ex-
panded (when possible) by appending it to the more
complex action having the root of the CM itself in its
decomposition. In this way we get a higher lever de-
scription of the action that the user wants to pursue.
4- Weighted expansion along the DH: for each CM,
its actions are repeatedly decomposed in more ele-
mentary ones, until all the steps of the CM are suffi-
ciently simple for the user&apos;s competence level in the
domain. In this way, the information necessary to
generate an answer suitable to the user is collected.
</listItem>
<page confidence="0.992144">
274
</page>
<bodyText confidence="0.9912858">
5- Weighted expansion backward through enable-
ment links: each CM is expanded in order to include
the actions necessary for satisfying the preconditions
which the user is supposed not to be able to plan by
himself (according to his competence level).
• In the response generation phase, the ambiguity
among the hypotheses is evaluated. If it is relevant, a
top-down clarification dialogue guided by the GH is
started up. Finally, the answer is extracted from the
CMs selected through the clarification dialogue.
</bodyText>
<sectionHeader confidence="0.996574" genericHeader="method">
THE REPRESENTATION OF GOALS,
PLANS AND ACTIONS
</sectionHeader>
<bodyText confidence="0.999980707317073">
The basic elements of representation of the domain
knowledge are goals and actions. Actions can be ele-
mentary or complex and in the second case one or
more plans (decompositions) can be associated with
them. All these plans share the same main effect.
Each action is characterized by the preconditions,
constraints, restrictions on the action parameters, ef-
fects, associated plans and position in the GH. The re-
strictions specify the relationship among the parame-
ters of the main action and those of the action sub-
steps. During the response generation phase, if the
value of some parameters is still unknown, their refer-
ent can be substituted in the answer by a linguistic de-
scription extracted from the restrictions, so avoiding
further questions to the user. For example, if the user
says that he wants to talk to the advisor for a course
plan, but he does not specify which (so it is not possi-
ble to determine the name of the advisor), still the
system may suggest: &amp;quot;talk with the advisor for the
course plan you are interested in&amp;quot;.
The GH supports an inheritance mechanism in the
plan library. Moreover, it allows to describe the de-
composition of an action by means of a more abstract
specification of some of its substeps when no specific
information is available. For example, a step of the
action of getting information on a course plan is to
talk with the curriculum advisor, that can be
specialized in different ways according to the topic of
the conversation (talking by phone and talking face to
face). If in a specific situation the actual topic is un-
known, it is not possible to select one possibility. So,
the more general action of talking is considered.
In order to support the two phases of weighted ex-
pansion, information about the difficulty degree of the
actions is embedded in the plan library by labelling
them with a weight that is a requested competence
threshold (if the user is expert for an action, it is taken
as elementary for him, otherwise its steps must be
specified). Preconditions are labelled in an analogous
way, so as to specify which users know how to plan
them by themselves and which need an explanation.
</bodyText>
<sectionHeader confidence="0.9756065" genericHeader="method">
THE CONSTRUCTION OF THE
HYPOTHESES
</sectionHeader>
<bodyText confidence="0.999838714285714">
In the action identification phase a set of actions is
selected from the plan library, each of them possibly
representing the aspect of the task on which the user&apos;s
attention is currently focused. The action identifica-
tion is accomplished by means of partially ordered
rules (a rule is more specific than another one if it im-
poses greater constraints on the structure of the log-
ical form of the user&apos;s utterance). Restrictions on the
parameters of conditions and actions are used to select
the most specific action from the plan library that is
supported by the user&apos;s utterance.
In the focusing phase the set of CMs produced by
the analysis of the previous sentences and the set of
candidate actions selected in the action identification
phase are considered. A new set of CMs is built, all of
which are obtained by expanding one of the given
CMs so as to include a candidate action. CMs for
which no links with the candidate actions have been
found are discarded. The expansion of the CMs is
similar to that of Carberry. However, because of our
approach to the response generation, when a focusing
rule fires, the expansion is tried backward through the
enablement links and along the DH and the GH, so to
find all the connections with the candidate actions
without preferring any possibility. If a heuristic rule
suggests more than one connection, a new CM is
generated for each one.
After the focusing phase, a further expansion up
through the DH is provided for each CM whose root
is part of only one higher-level plan.
In the weighted expansion along the DH, for each
CM, every action to be included in the answer is ex-
panded with its decomposition if it is not elementary
for the user&apos;s competence level. Actually, only actions
with a single decomposition are expanded2 The ex-
pansion is performed until the actions to be
mentioned in the answer are not decomposable or
they suit the user&apos;s competence level.
In the weighted expansion backward through en-
ablement links, for each CM, preconditions whose
planning is not immediate for the user are expanded
by attaching to their CMs the actions having them as
effects. When a precondition to be expanded is of the
form &amp;quot;Know(IS, x)&amp;quot; and the system knows the value
of &amp;quot;x&amp;quot;, it includes such information in the response;
so, the expansion is avoided. While in the previous
phase the expansion is performed recursively, here it
is not, because expanding along the enablement
chain extends the CM far from the current focus.
</bodyText>
<footnote confidence="0.909455444444444">
2 In the last two expansion phases we did not want to
extend the set of alternative hypotheses. In particular, in the
weighted expansion along the DH, the choice does not
reduce the generality of our approach because this kind of
ambiguity lies at a more detailed level than that of the user&apos;s
expressions. Anyway, the specificity of the actions
mentioned in the answer can be considered a matter of
trade-off between the need of being cooperative and the risk
of generating too complex answers.
</footnote>
<page confidence="0.996281">
275
</page>
<sectionHeader confidence="0.747947" genericHeader="method">
THE RESPONSE GENERATION
</sectionHeader>
<bodyText confidence="0.999997864864865">
In the relevance evaluation phase, the ambiguity
among candidate hypotheses filtered out in the focus-
ing phase is considered. The notion of relevance de-
fined by van Beek and Cohen is principally based on
the conditions (corresponding to our constraints) as-
sociated with the selected plans. We further specify
this notion in two ways, in order to avoid a clarifica-
tion dialogue when it is not necessary because a more
structured answer is sufficient for dealing with the
ambiguity. First we classify constraints into three cat-
egories: those with a value known to the system, that
are the only to be used in order to evaluate the rele-
vance of ambiguity; those that involve information
peculiar to the user (e.g. if he is a student), that can be
mentioned in the answer as assumptions for its valid-
ity; finally, those with a value unknown to both the
user and the system, but that the user can verify by
himself (e.g. the availability of books in the library).
Also constraints of the last category should be in-
cluded in the answer providing a recommendation to
check them. Second, clarification dialogues can be
avoided even when the ambiguity is relevant, but all
the selected hypotheses are invalidated by some false
constraints whose truth value does not change in the
considered situation; hence, a definitive negative an-
swer can be provided. Clarification dialogues are or-
ganized in a top-down way, along the GH.
In our approach, answers should include not only
information about the involved constraints, but also
about the specific description of how the user should
accomplish his task. For this reason, we consider a
clarification dialogue based on constraints as a first
step towards a more complex one, that takes into ac-
count the ambiguity among sequences of steps as
well. In the future work, we are going to complete the
answer generation phase by developing this part, as
well as the proper answer generation part.
</bodyText>
<sectionHeader confidence="0.953982" genericHeader="method">
AN EXAMPLE
</sectionHeader>
<bodyText confidence="0.999979185185185">
Let us suppose that a CM produced in the previous
analysis is composed by the action Get-info-on-
course-plan (one of whose steps is the Talk-prof ac-
tion) and the user asks if Prof. Smith is in his office.
The action identification phase selects the Talk-by-
phone and Meet actions, that share the constraint that
the professor is in his office. Since the two actions are
decompositions of the Talk-prof action, the focusing
phase produces two CMs from the previous one. If
the user is expert on the domain, no further expansion
of the CMs is needed for the generation of the answer,
that could be &amp;quot;Yes, he is; you can phone him to num-
ber 64 or meet him in office 42&amp;quot;. On the other hand, if
the user has a lower degree of competence, the steps
difficult for him are expanded. For example, the Talk-
by-phone action is detailed by specifying: &amp;quot;To phone
him go to the internal phone in the entrance&amp;quot;. In order
to show one of the cases that differentiate van Beek
and Cohen&apos;s approach from ours, suppose to add to
the action Meet the constraint Is-meeting-time and
that the user asks his question when the professor is
not in the office and it is not his meeting time. In this
case, the false constraint Is-meeting-time causes the
ambiguity to be relevant for van Beek and Cohen; on
the other hand, our system provides the user with a
unique negative answer, so avoiding any clarification
dialogue.
</bodyText>
<sectionHeader confidence="0.997089" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999992454545454">
The paper presented a plan-based consultation sys-
tem whose main purpose is to generate cooperative
answers on the basis of recognition of the user&apos;s plans
and goals. In the system, repair dialogues due to mis-
understandings of the user&apos;s intentions are prevented
through a possible clarification dialogue.
In order to enhance the flexibility of the system,
different detail levels have been provided for the an-
swers, according to the competence of the various
users. This has been done by specifying the difficulty
degree of the various components of the plan library
and by expanding the CMs until the information pro-
vided for the generation of an answer is suitable for
the user. Van Beek and Cohen&apos; notion of the
relevance of ambiguity has been refined on the basis
of the characteristics of the constraints present in the
plans.
In the future work, we are going to refine the notion
of relevance of ambiguity in order to deal with the
presence of different sequences of actions in the pos-
sible answers. Finally we are going to complete the
proper answer generation.
</bodyText>
<sectionHeader confidence="0.998026" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.996926333333333">
The authors are indebted to Leonardo Lesmo for
many useful discussions on the topic presented in the
paper. The authors are also grateful to the four
anonimous referees for their useful comments.
This research has been supported by CNR in the
project Pianificazione Automatica.
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999443125">
[Allen, 83] J.F.Allen. Recognizing intentions from
natural language utterances. In M. Brady and R.C.
Berwick editors, Computational Models of Discourse.
107-166. MIT Press, 1983.
[Carberry, 90] S.Carberry. Plan Recognition in
Natural Language Dialogue. ACL-MIT Press, 1990.
[Carberry 90b] S.Carberry. Incorporating Default
Inferences into Plan Recognition. Proc. 8th Conf.
AAAI, 471-478 Boston, 1990.
[Kautz and Allen, 86] H.A.Kautz, J.F.Allen.
Generalized Plan Recognition. Proc. 5th Conf AAAI,
32-37 Philadelphia, 1986.
[van Beek and Cohen, 91] P.van Beek, R.Cohen.
Resolving Plan Ambiguity for Cooperative Response
Generation. Proc. 12th Int. Joint Conf on Artificial
Intelligence, 938-94-4 Sydney, 1991.
</reference>
<page confidence="0.998464">
276
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.907142">
<title confidence="0.9981405">A FLEXIBLE APPROACH TO COOPERATIVE RESPONSE GENERATION IN INFORMATION-SEEKING DIALOGUES</title>
<author confidence="0.997757">Liliana Ardissono</author>
<author confidence="0.997757">Alessandro Lombardo</author>
<author confidence="0.997757">Dario Sestero</author>
<affiliation confidence="0.996884">Dipartimento di Informatica - Universita&apos; di Torino</affiliation>
<address confidence="0.994527">C.so Svizzera 185 - 10149 - Torino - Italy</address>
<email confidence="0.999897">E-Mail:liliana@di.unito.it</email>
<abstract confidence="0.992632909090909">This paper presents a cooperative consultation system on a restricted domain. The system builds hypotheses on the user&apos;s plan and avoids misunderstandings (with consequent repair dialogues) through clarification dialogues in case of ambiguity. The role played by constraints in the generation of the answer is characterized in order to limit the cases of ambiguities requiring a clarification dialogue. The answers of the system are generated at different levels of detail, according to the user&apos;s competence in the domain.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Recognizing intentions from natural language utterances.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse.</booktitle>
<pages>107--166</pages>
<editor>In M. Brady and R.C. Berwick editors,</editor>
<publisher>MIT Press,</publisher>
<marker>[Allen, 83]</marker>
<rawString>J.F.Allen. Recognizing intentions from natural language utterances. In M. Brady and R.C. Berwick editors, Computational Models of Discourse. 107-166. MIT Press, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Plan</author>
</authors>
<title>Recognition in Natural Language Dialogue.</title>
<date>1990</date>
<publisher>ACL-MIT Press,</publisher>
<marker>[Carberry, 90]</marker>
<rawString>S.Carberry. Plan Recognition in Natural Language Dialogue. ACL-MIT Press, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Incorporating Default Inferences into Plan Recognition.</title>
<date>1990</date>
<booktitle>Proc. 8th Conf. AAAI,</booktitle>
<pages>471--478</pages>
<location>Boston,</location>
<marker>[Carberry 90b]</marker>
<rawString>S.Carberry. Incorporating Default Inferences into Plan Recognition. Proc. 8th Conf. AAAI, 471-478 Boston, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen H A Kautz</author>
</authors>
<title>Generalized Plan Recognition.</title>
<date>1986</date>
<booktitle>Proc. 5th Conf AAAI,</booktitle>
<pages>32--37</pages>
<location>Philadelphia,</location>
<marker>[Kautz and Allen, 86]</marker>
<rawString>H.A.Kautz, J.F.Allen. Generalized Plan Recognition. Proc. 5th Conf AAAI, 32-37 Philadelphia, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cohen P van Beek</author>
</authors>
<title>Resolving Plan Ambiguity for Cooperative Response Generation.</title>
<date>1991</date>
<booktitle>Proc. 12th Int. Joint Conf on Artificial Intelligence,</booktitle>
<pages>938--94</pages>
<location>Sydney,</location>
<marker>[van Beek and Cohen, 91]</marker>
<rawString>P.van Beek, R.Cohen. Resolving Plan Ambiguity for Cooperative Response Generation. Proc. 12th Int. Joint Conf on Artificial Intelligence, 938-94-4 Sydney, 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>