<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000048">
<title confidence="0.998913">
An Integrated Approach for Arabic-English Named Entity Translation
</title>
<author confidence="0.992723">
Hany Hassan Jeffrey Sorensen
</author>
<affiliation confidence="0.737807">
IBM Cairo Technology Development Center IBM T.J. Watson Research Center
Giza - Egypt Yorktown Heights
</affiliation>
<address confidence="0.974768">
P.O. Box 166 Al-Ahram NY 10598
</address>
<email confidence="0.997821">
hanyh@eg.ibm.com sorenj@us.ibm.com
</email>
<sectionHeader confidence="0.998593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969473684211">
Translation of named entities (NEs),
such as person names, organization names
and location names is crucial for cross lin-
gual information retrieval, machine trans-
lation, and many other natural language
processing applications. Newly named en-
tities are introduced on daily basis in
newswire and this greatly complicates the
translation task. Also, while some names
can be translated, others must be transliter-
ated, and, still, others are mixed. In this
paper we introduce an integrated approach
for named entity translation deploying
phrase-based translation, word-based trans-
lation, and transliteration modules into a
single framework. While Arabic based,
the approach introduced here is a unified
approach that can be applied to NE transla-
tion for any language pair.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99898968627451">
Named Entities (NEs) translation is crucial for ef-
fective cross-language information retrieval
(CLIR) and for Machine Translation. There are
many types of NE phrases, such as: person names,
organization names, location names, temporal ex-
pressions, and names of events. In this paper we
only focus on three categories of NEs: person
names, location names and organization names,
though the approach is, in principle, general
enough to accommodate any entity type.
NE identification has been an area of significant
research interest for the last few years. NE transla-
tion, however, remains a largely unstudied prob-
lem. NEs might be phonetically transliterated (e.g.
persons names) and might also be mixed between
phonetic transliteration and semantic translation as
the case with locations and organizations names.
There are three distinct approaches that can be
applied for NE translation, namely: a
transliteration approach, a word based translation
approach and a phrase based translation approach.
The transliteration approach depends on phonetic
transliteration and is only appropriate for out of
vocabulary and completely unknown words. For
more frequently used words, transliteration does
not provide sophisticated results. A word based
approach depends upon traditional statistical
machine translation techniques such as IBM
Model1 (Brown et al., 1993) and may not always
yield satisfactory results due to its inability to
handle difficult many-to-many phrase translations.
A phrase based approach could provide a good
translation for frequently used NE phrases though
it is inefficient for less frequent words. Each of the
approaches has its advantages and disadvantages.
In this paper we introduce an integrated ap-
proach for combining phrase based NE translation,
word based NE translation, and NE transliteration
in a single framework. Our approach attempts to
harness the advantages of the three approaches
while avoiding their pitfalls. We also introduce and
evaluate a new approach for aligning NEs across
parallel corpora, a process for automatically ex-
tracting new NEs translation phrases, and a new
transliteration approach. As is typical for statistical
MT, the system requires the availability of general
parallel corpus and Named Entity identifiers for
the NEs of interest.
Our primary focus in this paper is on translating
NEs out of context (i.e. NEs are extracted and
translated without any contextual clues). Although
</bodyText>
<page confidence="0.991262">
87
</page>
<note confidence="0.8359645">
Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 87–93,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.999524">
this is a more difficult problem than translating
NEs in context, we adopt this approach because it
is more generally useful for CLIR applications.
The paper is organized as follows, section 2
presents related work, section 3 describes our inte-
grated NE translation approach, section 4 presents
the word based translation module, the phrase
based module, the transliteration module, and sys-
tem integration and decoding, section 5 provides
the experimental setup and results and finally sec-
tion 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999957119047619">
The Named Entity translation problem was previ-
ously addressed using two different approaches:
Named Entity phrase translation (which includes
word-based translation) and Named Entity translit-
eration. Recently, many NE phrase translation ap-
proaches have been proposed. Huang et al.
(Huang et al., 2003) proposed an approach to ex-
tract NE trans-lingual equivalences based on the
minimization of a linearly combined multi-feature
cost. However this approach used a bilingual dic-
tionary to extract NE pairs and deployed it itera-
tively to extract more NEs. Moore (Moore, 2003),
proposed an approach deploying a sequence of cost
models. However this approach relies on ortho-
graphic clues, such as strings repeated in the
source and target languages and capitalization,
which are only suitable for language pairs with
similar scripts and/or orthographic conventions.
Most prior work in Arabic-related translitera-
tion has been developed for the purpose of ma-
chine translation and for Arabic-English
transliteration in particular. Arbabi (Arbabi et al.,
1998) developed a hybrid neural network and
knowledge-based system to generate multiple Eng-
lish spellings for Arabic person names. Stalls and
Knight (Stalls and Knight, 1998) introduced an
approach for Arabic-English back transliteration
for names of English origin; this approach could
only back transliterate to English the names that
have an available pronunciation. Al-Onaizan and
Knight (Al-Onaizan and Knight, 2002) proposed a
spelling-based model which directly maps English
letter sequences into Arabic letter sequences. Their
model was trained on a small English Arabic
names list without the need for English pronuncia-
tions. Although this method does not require the
availability of English pronunciation, it has a seri-
ous limitation because it does not provide a mecha-
nism for inserting the omitted short vowels in
Arabic names. Therefore it does not perform well
with names of Arabic origin in which short vowels
tend to be omitted.
</bodyText>
<sectionHeader confidence="0.9770145" genericHeader="method">
3 Integrated Approach for Named Entity
Translation
</sectionHeader>
<bodyText confidence="0.9999891875">
We introduce an integrated approach for Named
Entity (NE) translation using phrase based transla-
tion, word based translation and transliteration ap-
proaches in a single framework. Our unified
approach could handle, in principle, any NE type
for any languages pair.
The level of complication in NE translation de-
pends on the NE type, the original source of the
names, the standard de facto translation for certain
named entities and the presence of acronyms. For
example persons names tend to be phonetically
transliterated, but different sources might use dif-
ferent transliteration styles depending on the origi-
nal source of the names and the idiomatic
translation that has been established. Consider the
following two names:
</bodyText>
<equation confidence="0.780763">
“ : jAk $yrAk” 4 “Jacques Chirac”
“ :jAk strw” 4 “Jack Straw”
</equation>
<bodyText confidence="0.9469165">
Although the first names in both examples are the
same in Arabic, their transliterations should be dif-
ferent. One might be able to distinguish between
the two by looking at the last names. This example
illustrates why transliteration may not be good for
frequently used named entities. Transliteration is
more appropriate for unknown NEs.
For locations and organizations, the translation
can be a mixture of translation and transliteration.
For example:
:$rkp mAykrwswft 4
Microsoft Company
: Alqds 4 Jerusalem
: mTAr Tokyw 4 Tokyo Airport
These examples highlight some of the complica-
tions of NE translation that are difficult to over-
come using any phrase based, word based or
transliteration approach independently. An ap-
proach that integrates phrase and word based trans-
lation with transliteration in a systematic and
flexible framework could provide a more complete
solution to the problem.
Our system utilizes a parallel corpus to sepa-
rately acquire the phrases for the phrase based sys-
</bodyText>
<page confidence="0.993491">
88
</page>
<bodyText confidence="0.9996535">
tem, the translation matrix for the word based sys-
tem, and training data for the transliteration sys-
tem. More details about the three systems will be
presented in the next section. Initially, the corpus
is automatically annotated with NE types in the
source and target languages using NE identifiers
similar to the systems described in (Florian et al.,
2004) for NE detection.
</bodyText>
<sectionHeader confidence="0.992256" genericHeader="method">
4 Translation and Transliteration Mod-
ules
</sectionHeader>
<subsectionHeader confidence="0.99461">
4.1 Word Based NE Translation
</subsectionHeader>
<listItem confidence="0.587564">
• Basic multi-cost NE Alignment
</listItem>
<bodyText confidence="0.998904615384616">
We introduce a novel NE alignment technique to
align NEs from a parallel corpus that has been
automatically annotated with NE types for source
and target languages. We use IBM Model1, as in-
troduced in (Brown et. al, 1993), with a modified
alignment cost. The cost function has some simi-
larity with the multi-cost aligning approach intro-
duced by Huang (Huang et al. 2003) but it is
significantly different. The cost for aligning any
source and target NE word is defined as:
C= A1p(we  |wf)+A2Ed(we,wf)+ A3Tag(we,wf)
Where: we and wf are the target and source words
respectively and A1 , A2 andA3 are the cost weight-
ing parameters.
The first term p(we  |wf) represents the transla-
tion log probability of target word ( we) given the
source word ( wf ). The second term Ed (we, wf) is
length-normalized phonetic based edit distance
between the two words. This phonetic-based edit
distance employs an Editex style (Zobel and Dart,
1996) distance measure, which groups letters that
can result in similar pronunciations, but doesn’t
require that the groups be disjoint, and can thus
reflect the correspondences between letters with
similar pronunciation more accurately. The Editex
distance (d) between two letters a and b is:
</bodyText>
<equation confidence="0.935448">
d(a,b) = 0 if both are identical
</equation>
<bodyText confidence="0.9549912">
= 1 if they are in the same group
= 2 otherwise
The Editex distance between two words is the
summation of Editex distance between their letters
and length-normalized edit distance is:
</bodyText>
<equation confidence="0.985619">
Ed (we, wf) = log(1−
we
</equation>
<bodyText confidence="0.933147575">
where d (we, wf) is the “Editex” style edit distance
and max( |we  |,  |wf |) is the maximum of the two
lengths for the source and target, normalizing the
edit distance.
The Editex edit distance is deployed between
English words and “romanized” Arabic words with
a grouping of similar consonants and a grouping of
similar vowels. This helps in identifying the corre-
spondence between rare NEs during the alignment.
For example, consider two rare NE phrases that
occur once in the training:
“wqd AstdEY wzyr AlxArjyp AlyAbAny
nwbwtAkA mA$ymwrA Alsfyr AlSyny wAnj yy”
Foreign Minister Nobutaka Machi-
mura has summoned the Chinese ambassador
Wang
Thus the task of the alignment technique is to align
:nwbwkAtA Nobutaka
mA$ymwrA Machimura
:wAng Wang
:yy Yee
If a pure Model-1 alignment was used, then the
model would have concluded that all words could
be aligned to all others with equal probability.
However, the multi-cost alignment technique could
align two named entities using a single training
sample. This approach has significant effect in cor-
rectly aligning rare NEs.
The term Tag(we,wf) in the alignment cost func-
tion is the NE type cost which increases the align-
ment cost when the source and target words are
annotated with different types and is zero other-
wise.
The parameters of the cost function
, A2 , A3) can be tuned according to the NE
category and to frequency of a NE. For example, in
the case of
names, it might be advanta-
geous to use a larger
(boosting the weight of
</bodyText>
<figure confidence="0.793596866666667">
tran
“Japanese
Yee”
:
( A1
person’s
A2
sliteration).
“
”
d (we, wf )
max(|
 |,  ||)
w f
)
</figure>
<page confidence="0.987405">
89
</page>
<listItem confidence="0.809739">
• Multi-cost Named Entity Alignment
by Content Words Elimination
</listItem>
<bodyText confidence="0.999899409090909">
In the case of organization and location names;
many content words, which are words other than
the NEs, occur in the NE phrases. These content
words might be aligned incorrectly to rare NE
words. A two-phase alignment approach is de-
ployed to overcome this problem. The first phase is
aligning the content words using a content-word-
only translation matrix. The successfully aligned
content words are removed from both the source
and target sentences. In the second phase, the re-
maining words are subsequently aligned using the
multi-cost alignment technique described in the
previous section. This two-phase approach filters
out the words that might be incorrectly aligned
using the single phase alignment techniques. Thus
the alignment accuracy is enhanced; especially for
organization names since organization names used
to contain many content words.
The following example illustrates the technique,
consider two sentences to be aligned and to avoid
language confusion let’s assume symbolic sen-
tences by denoting:
</bodyText>
<listItem confidence="0.99998725">
• Wsi: content words in the source sentence.
• NEsi: the Named Entity source words.
• Wti: the content words in the target sentence.
• NEti: the Named Entity target words.
</listItem>
<bodyText confidence="0.669224">
The source and target sentences are represented
as follows:
Source: Ws1 Ws2 NEs1 NEs2 Ws3 Ws4 Ws5
Target: Wt1 Wt2 Wt3 NEt1 NEt2 NEt3 Wt4 NEt4
After the first phase is applied, the remaining not
aligned words might look like that:
</bodyText>
<equation confidence="0.5911195">
Source: NEs1 NEs2 Ws4 Ws5
Target: Wt3 NEt1 NEt2 NEt3 NEt4
</equation>
<bodyText confidence="0.999723833333333">
The example clarify that the elimination of some
content words facilitates the task of NEs alignment
since many of the words that might lead to confu-
sion have been eliminated.
As shown in the above example, different mis-
matched identification of NEs could result from
different identifiers. The “Multi-cost Named En-
tity Alignment by Content Words Elimination”
technique helps in reducing alignment errors due to
identification errors by reducing the candidate
words for alignment and thus reducing the aligner
confusion.
</bodyText>
<subsectionHeader confidence="0.9112595">
4.2 Phrase Based Named Entity Transla-
tion
</subsectionHeader>
<bodyText confidence="0.99579445945946">
For phrase-based NE translation, we used an ap-
proach similar to that presented by Tillman (Till-
mann, 2003) for block generation with
modifications suitable for NE phrase extraction. A
block is defined to be any pair of source and target
phrases. This approach starts from a word align-
ment generated by HMM Viterbi training (Vogel
et. Al, 1996), which is done in both directions be-
tween source and target. The intersection of the
two alignments is considered a high precision
alignment and the union is considered a low preci-
sion alignment. The high precision alignments are
used to generate high precision blocks which are
further expanded using low precision alignments.
The reader is referred to (Tillmann, 2003) for de-
tailed description of the algorithm.
In our approach, for extracting NE blocks, we
limited high precision alignments to NE phrases of
the same NE types. In the expansion phase, the
multi-cost function described earlier is used. Thus
the blocks are expanded based on a cost depending
on the type matching cost, the edit distance cost
and the translation probability cost.
To explain this procedure, consider the following
sentences pair:
“wqd AstdEY wzyr AlxArjyp AlyAbAny
nwbwtAkA mA$ymwrA Alsfyr AlSyny wAnj yy”
“Japanese Foreign Minister Nobutaka Machi-
mura has summoned the Chinese ambassador
Wang Yee
The underlined words are the words that have
been identified by the NE identifiers as person
names. In the Arabic sentence, the identifier
missed the second name of the first Named En-
tity (mA$ymwrA) and did not identify the word
as person name by mistake. The high precision
block generation technique will generate the fol-
</bodyText>
<equation confidence="0.880031666666667">
lowing ✠ : two blocks:
(nwbwtAkA): Nobutaka
(wAnj yy) : Wang Yee
</equation>
<bodyText confidence="0.9561242">
The expansion technique will try to expand the
blocks on all the four possible dimensions (right
and left of the blocks in the target and source) of
each block. The result of the expansion will be:
”
</bodyText>
<page confidence="0.863013">
90
</page>
<equation confidence="0.4793775">
(nwbwtAkA mA$ymwrA) :
Nobutaka Machimura
</equation>
<bodyText confidence="0.9998615">
Therefore, the multi-cost expansion technique en-
ables expansions sensitive to the translation prob-
ability and the edit distance and providing a
mechanism to overcome NE identifiers errors.
</bodyText>
<subsectionHeader confidence="0.999286">
4.3 Named Entity Transliteration
</subsectionHeader>
<bodyText confidence="0.999234697674419">
NE transliteration is essential for translating Out
Of Vocabulary (OOV) words that are not covered
by the word or phrase based models. As mentioned
earlier, phonetic and orthographic differences be-
tween Arabic and English make NE transliteration
challenging.
We used a block based transliteration method,
which transliterates sequence of letters from the
source language to sequence of letters in the target
language. These source and target sequences con-
struct the blocks which enables the modeling of
vowels insertion. For example, consider Arabic
name “ $kry,” which is transliterated as
“Shoukry.” The system tries to model bi-grams
from the source language to n-grams in the target
language as follows:
$k shouk
kr kr
ry ry
To obtain these block translation probabilities,
we use the translation matrix, generated in section
4.1 from the word based alignment models. First,
the translation matrix is filtered out to only pre-
serve highly confident translations; translations
with probabilities less than a certain threshold are
filtered out. Secondly, the resulting high confident
translations are further refined by calculating pho-
netic based edit distance between both romanized
Arabic and English names. Name pairs with an edit
distance greater than a predefined threshold are
also filtered out. The remaining highly confident
name pairs are used to train a letter to letter transla-
tion matrix using HMM Viterbi training (Vogel et
al., 1996).
Each bi-gram of letters on the source side is
aligned to an n-gram of letters sequence on the tar-
get side, such that vowels have very low cost to be
aligned to NULL. The block probabilities are cal-
culated and refined iteratively for each source and
target sequences. Finally, for a source block s and
a target block t, the probability of s being trans-
lated as t is the ratio of their co-occurrence and
total source occurrence:
</bodyText>
<equation confidence="0.975479">
P(t  |s) = N(t, s) N(s) .
</equation>
<bodyText confidence="0.999905916666667">
The resulting block translation probabilities and
the letter to letter translation probabilities are com-
bined to construct a Weighted Finite State Trans-
ducer (WFST) for translating any source sequence
to a target sequence.
Furthermore, the constructed translation WFST
is composed with two language models (LM)
transducers namely a letter trigram model and a
word unigram model. The trigram letter based LM
acts to provide high recall results while the word
based unigram LM acts for providing high precisin
results.
</bodyText>
<subsectionHeader confidence="0.999149">
4.4 System Integration and Decoding
</subsectionHeader>
<bodyText confidence="0.999993388888889">
The three constructed models in the steps
above, namely phrase-based NE translation, word-
based translation, and transliteration, are used to
generate hypotheses for each source NE phrase.
We used a dynamic programming beam search
decoder similar to the decoder described by
Tillman (Tillmann, 2003).
We employed two language models that were built
from NE phrases extracted from monolingual tar-
get data for each NE category under consideration.
The first language model is a trigram language
model on NE phrases. The second language model
is a class based language model with a class for
unknown NEs. Every NE that do exist in the
monolingual data but out of the vocabulary of the
phrase and word translation models are considered
unknown. This helps in correctly scoring OOV
hypothesis produced by the transliteration module.
</bodyText>
<sectionHeader confidence="0.999227" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9999311">
We test our system for Arabic to English NE trans-
lation for three NE categories, namely names of
persons, organizations, and locations. The system
has been trained on a news domain parallel corpus
containing 2.8 million Arabic words and 3.4 mil-
lion words. Monolingual English data was anno-
tated with NE types and the extracted named
entities were used to train the various language
models described earlier.
We manually constructed a test set as follows:
</bodyText>
<page confidence="0.995036">
91
</page>
<table confidence="0.9251752">
Category No. of No. of
Phrases Words
Person names 803 1749
Organization names 312 867
Location names 345 614
</table>
<bodyText confidence="0.98149575">
The BLEU score (Papineni et al., 2002) with a sin-
gle reference translation was deployed for evalua-
tion. BLEU-3 which uses up to 3-grams is
deployed since three words phrase is a reasonable
length for various NE types. Table 1 reports the
results for person names; the baseline system is a
general-purpose machine translation system with
relatively good Bleu score.
</bodyText>
<table confidence="0.998006166666667">
System Bleu Score
Base line 0.2942
Word based only 0.3254
Word + Phrase 0.4620
Word + Phrase + Translitera- 0.5432
tion
</table>
<tableCaption confidence="0.6201755">
Table 1: Person Names Results
Table 2 reports the bleu score for Location cate-
gory with the same three systems presented before
with persons:
</tableCaption>
<table confidence="0.998053666666667">
System Bleu
Score
Base line 0.2445
Word based only 0.3426
Word + Phrase 0.4721
Word + Phrase + Transliteration 0.4983
</table>
<tableCaption confidence="0.76147075">
Table 2: Locations Names Results
Table 3 reports the bleu score for Organization
category with the same three systems presented
before:
</tableCaption>
<table confidence="0.998463833333333">
System Bleu Score
Base line 0.2235
Word based only 0.2541
Word + Phrase 0.3789
Word + Phrase + Translitera- 0.3876
tion
</table>
<tableCaption confidence="0.998536">
Table 3: Organizations Names Results
</tableCaption>
<figureCaption confidence="0.9780065">
Figure 1, illustrates various BLEU scores for
various categories. The results indicate that phrase
</figureCaption>
<bodyText confidence="0.999234142857143">
based translation provided enhancement for all NE
types, while transliteration proved more effective
for person names.
It is also worth mentioning that evaluating the
system using a single reference has limitations;
many good translations are considered wrong be-
cause they do not exist in the single reference.
</bodyText>
<sectionHeader confidence="0.998119" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999990411764706">
We have presented an integrated system that can
handle various NE categories and requires the
regular parallel and monolingual corpora which are
typically used in the training of any statistical ma-
chine translation system along with NEs identifier.
The proposed approach does not require any costly
special resources, lexicons or any type of annotated
data.
The system is composed of multiple translation
modules that give flexibility for different named
entities type’s translation requirements. This gives
a great flexibility that enables the system to handle
NEs of any type.
We will evaluate the effect of the system on
CLIR and MT tasks. We will also try to investigate
new approaches for deploying NE translation in
general phrase based MT system.
</bodyText>
<sectionHeader confidence="0.980235" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999858333333333">
We would like to thank Salim Roukos and Kishore
Papineni for several invaluable suggestions and
guidance. We would like also to thank Christoph
Tillmann for help with various components.
We would like also to thank Kareem Darwish for
his invaluable help in editing this paper.
</bodyText>
<figureCaption confidence="0.984396">
Figure 1: Various BLEU scores for various
categories
</figureCaption>
<page confidence="0.985337">
92
</page>
<sectionHeader confidence="0.998033" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998686">
Yaser Al-Onaizan and Kevin Knight. 2002. Machine
Transliteration of Names in Arabic Text. In Proceed-
ings of the ACL Workshop on Computational Ap-
proaches to Semitic Languages.
Peter F. Brown, Vincent J. Della Pietra, Stephen A.
Della Pietra, and Robert L. Mercer. 1993. The Mathe-
matics of Statistical Machine Translation: Parameter
Estimation. Computational Linguistics, 19(2):263–311.
Radu Florian, Hany Hassan, Abraham Ittycheriah, H.
Jing, Nanda Kambhatla, Xiaoqiang Luo, Nicolas
Nicolov, Salim Roukos: A Statistical Model for Multi-
lingual Entity Detection and Tracking. HLT-NAACL
2004: 1-8
Fei Huang, Stephan Vogel and Alex Waibel, Auto-
matic Extraction of Named Entity Translingual
Equivalence Based on Multi-feature Cost Minimiza-
tion, in the Proceedings of the 2003 Annual Confer-
ence of the Association for Computational Linguistics
(ACL’03), Workshop on Multilingual and Mixed-
language Named Entity Recognition, July, 2003
Leah Larkey, Nasreen AbdulJaleel, and Margaret
Connell, What&apos;s in a Name? Proper Names in Arabic
Cross-Language Information Retrieval. CIIR Technical
Report, IR-278,2003.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of machine translation. In Proc. of the 40th
Annual Conf. of the Association for Computational
Linguistics (ACL 02), pages 311–318, Philadelphia,
PA, July.
Bonnie G. Stalls and Kevin Knight.. Translating
Names and Technical Terms in Arabic Text. In Pro-
ceedings of the COLING/ACL Workshop on Compu-
tational Approaches to Semitic Languages. 1998.
Christoph Tillmann,. A Projection Extension Algo-
rithm for Statistical Machine Translation. In Proc of
Empirical Methods in Natural Language Processing,
2003
Stefan Vogel, Hermann Ney, and Christoph Till-
mann.. HMM Based Word Alignment in Statistical
Machine Translation. In Proc. of the 16th Int. Conf. on
Computational Linguistics (COLING), 1996
J. Zobel and P. Dart, Phonetic String Matching: Les-
sons from Information Retrieval. SIGIR Forum, special
issue:166--172, 1996
</reference>
<page confidence="0.999168">
93
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.945758">
<title confidence="0.999966">An Integrated Approach for Arabic-English Named Entity Translation</title>
<author confidence="0.999848">Hany Hassan Jeffrey Sorensen</author>
<affiliation confidence="0.990134">IBM Cairo Technology Development Center IBM T.J. Watson Research Center - Egypt Heights</affiliation>
<address confidence="0.997709">Box 166 Al-Ahram 10598</address>
<email confidence="0.99602">hanyh@eg.ibm.comsorenj@us.ibm.com</email>
<abstract confidence="0.9985237">Translation of named entities (NEs), such as person names, organization names and location names is crucial for cross lingual information retrieval, machine translation, and many other natural language processing applications. Newly named entities are introduced on daily basis in newswire and this greatly complicates the translation task. Also, while some names can be translated, others must be transliterated, and, still, others are mixed. In this paper we introduce an integrated approach for named entity translation deploying phrase-based translation, word-based translation, and transliteration modules into a single framework. While Arabic based, the approach introduced here is a unified approach that can be applied to NE translation for any language pair.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Machine Transliteration of Names in Arabic Text.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="5663" citStr="Al-Onaizan and Knight, 2002" startWordPosition="835" endWordPosition="838">ographic conventions. Most prior work in Arabic-related transliteration has been developed for the purpose of machine translation and for Arabic-English transliteration in particular. Arbabi (Arbabi et al., 1998) developed a hybrid neural network and knowledge-based system to generate multiple English spellings for Arabic person names. Stalls and Knight (Stalls and Knight, 1998) introduced an approach for Arabic-English back transliteration for names of English origin; this approach could only back transliterate to English the names that have an available pronunciation. Al-Onaizan and Knight (Al-Onaizan and Knight, 2002) proposed a spelling-based model which directly maps English letter sequences into Arabic letter sequences. Their model was trained on a small English Arabic names list without the need for English pronunciations. Although this method does not require the availability of English pronunciation, it has a serious limitation because it does not provide a mechanism for inserting the omitted short vowels in Arabic names. Therefore it does not perform well with names of Arabic origin in which short vowels tend to be omitted. 3 Integrated Approach for Named Entity Translation We introduce an integrate</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Machine Transliteration of Names in Arabic Text. In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2414" citStr="Brown et al., 1993" startWordPosition="347" endWordPosition="350"> semantic translation as the case with locations and organizations names. There are three distinct approaches that can be applied for NE translation, namely: a transliteration approach, a word based translation approach and a phrase based translation approach. The transliteration approach depends on phonetic transliteration and is only appropriate for out of vocabulary and completely unknown words. For more frequently used words, transliteration does not provide sophisticated results. A word based approach depends upon traditional statistical machine translation techniques such as IBM Model1 (Brown et al., 1993) and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations. A phrase based approach could provide a good translation for frequently used NE phrases though it is inefficient for less frequent words. Each of the approaches has its advantages and disadvantages. In this paper we introduce an integrated approach for combining phrase based NE translation, word based NE translation, and NE transliteration in a single framework. Our approach attempts to harness the advantages of the three approaches while avoiding their pitfalls. We also in</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Hany Hassan</author>
<author>Abraham Ittycheriah</author>
<author>H Jing</author>
<author>Nanda Kambhatla</author>
</authors>
<title>Xiaoqiang Luo, Nicolas Nicolov, Salim Roukos: A Statistical Model for Multilingual Entity Detection and Tracking. HLT-NAACL</title>
<date>2004</date>
<pages>1--8</pages>
<contexts>
<context position="8377" citStr="Florian et al., 2004" startWordPosition="1270" endWordPosition="1273">hat integrates phrase and word based translation with transliteration in a systematic and flexible framework could provide a more complete solution to the problem. Our system utilizes a parallel corpus to separately acquire the phrases for the phrase based sys88 tem, the translation matrix for the word based system, and training data for the transliteration system. More details about the three systems will be presented in the next section. Initially, the corpus is automatically annotated with NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al., 2004) for NE detection. 4 Translation and Transliteration Modules 4.1 Word Based NE Translation • Basic multi-cost NE Alignment We introduce a novel NE alignment technique to align NEs from a parallel corpus that has been automatically annotated with NE types for source and target languages. We use IBM Model1, as introduced in (Brown et. al, 1993), with a modified alignment cost. The cost function has some similarity with the multi-cost aligning approach introduced by Huang (Huang et al. 2003) but it is significantly different. The cost for aligning any source and target NE word is defined as: C= A</context>
</contexts>
<marker>Florian, Hassan, Ittycheriah, Jing, Kambhatla, 2004</marker>
<rawString>Radu Florian, Hany Hassan, Abraham Ittycheriah, H. Jing, Nanda Kambhatla, Xiaoqiang Luo, Nicolas Nicolov, Salim Roukos: A Statistical Model for Multilingual Entity Detection and Tracking. HLT-NAACL 2004: 1-8</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-feature Cost Minimization,</title>
<date>2003</date>
<booktitle>in the Proceedings of the 2003 Annual Conference of the Association for Computational Linguistics (ACL’03), Workshop on Multilingual and Mixedlanguage Named Entity Recognition,</booktitle>
<contexts>
<context position="4498" citStr="Huang et al., 2003" startWordPosition="663" endWordPosition="666">, section 3 describes our integrated NE translation approach, section 4 presents the word based translation module, the phrase based module, the transliteration module, and system integration and decoding, section 5 provides the experimental setup and results and finally section 6 concludes the paper. 2 Related Work The Named Entity translation problem was previously addressed using two different approaches: Named Entity phrase translation (which includes word-based translation) and Named Entity transliteration. Recently, many NE phrase translation approaches have been proposed. Huang et al. (Huang et al., 2003) proposed an approach to extract NE trans-lingual equivalences based on the minimization of a linearly combined multi-feature cost. However this approach used a bilingual dictionary to extract NE pairs and deployed it iteratively to extract more NEs. Moore (Moore, 2003), proposed an approach deploying a sequence of cost models. However this approach relies on orthographic clues, such as strings repeated in the source and target languages and capitalization, which are only suitable for language pairs with similar scripts and/or orthographic conventions. Most prior work in Arabic-related transli</context>
<context position="8870" citStr="Huang et al. 2003" startWordPosition="1353" endWordPosition="1356">h NE types in the source and target languages using NE identifiers similar to the systems described in (Florian et al., 2004) for NE detection. 4 Translation and Transliteration Modules 4.1 Word Based NE Translation • Basic multi-cost NE Alignment We introduce a novel NE alignment technique to align NEs from a parallel corpus that has been automatically annotated with NE types for source and target languages. We use IBM Model1, as introduced in (Brown et. al, 1993), with a modified alignment cost. The cost function has some similarity with the multi-cost aligning approach introduced by Huang (Huang et al. 2003) but it is significantly different. The cost for aligning any source and target NE word is defined as: C= A1p(we |wf)+A2Ed(we,wf)+ A3Tag(we,wf) Where: we and wf are the target and source words respectively and A1 , A2 andA3 are the cost weighting parameters. The first term p(we |wf) represents the translation log probability of target word ( we) given the source word ( wf ). The second term Ed (we, wf) is length-normalized phonetic based edit distance between the two words. This phonetic-based edit distance employs an Editex style (Zobel and Dart, 1996) distance measure, which groups letters t</context>
</contexts>
<marker>Huang, Vogel, Waibel, 2003</marker>
<rawString>Fei Huang, Stephan Vogel and Alex Waibel, Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-feature Cost Minimization, in the Proceedings of the 2003 Annual Conference of the Association for Computational Linguistics (ACL’03), Workshop on Multilingual and Mixedlanguage Named Entity Recognition, July, 2003</rawString>
</citation>
<citation valid="false">
<authors>
<author>Leah Larkey</author>
<author>Nasreen AbdulJaleel</author>
<author>Margaret Connell</author>
</authors>
<title>What&apos;s in a Name? Proper Names in Arabic Cross-Language Information Retrieval.</title>
<tech>CIIR Technical Report, IR-278,2003.</tech>
<marker>Larkey, AbdulJaleel, Connell, </marker>
<rawString>Leah Larkey, Nasreen AbdulJaleel, and Margaret Connell, What&apos;s in a Name? Proper Names in Arabic Cross-Language Information Retrieval. CIIR Technical Report, IR-278,2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="19723" citStr="Papineni et al., 2002" startWordPosition="3127" endWordPosition="3130">perimental Setup We test our system for Arabic to English NE translation for three NE categories, namely names of persons, organizations, and locations. The system has been trained on a news domain parallel corpus containing 2.8 million Arabic words and 3.4 million words. Monolingual English data was annotated with NE types and the extracted named entities were used to train the various language models described earlier. We manually constructed a test set as follows: 91 Category No. of No. of Phrases Words Person names 803 1749 Organization names 312 867 Location names 345 614 The BLEU score (Papineni et al., 2002) with a single reference translation was deployed for evaluation. BLEU-3 which uses up to 3-grams is deployed since three words phrase is a reasonable length for various NE types. Table 1 reports the results for person names; the baseline system is a general-purpose machine translation system with relatively good Bleu score. System Bleu Score Base line 0.2942 Word based only 0.3254 Word + Phrase 0.4620 Word + Phrase + Translitera- 0.5432 tion Table 1: Person Names Results Table 2 reports the bleu score for Location category with the same three systems presented before with persons: System Bleu</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of machine translation. In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02), pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie G Stalls</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Names and Technical Terms in Arabic Text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="5416" citStr="Stalls and Knight, 1998" startWordPosition="801" endWordPosition="804">eploying a sequence of cost models. However this approach relies on orthographic clues, such as strings repeated in the source and target languages and capitalization, which are only suitable for language pairs with similar scripts and/or orthographic conventions. Most prior work in Arabic-related transliteration has been developed for the purpose of machine translation and for Arabic-English transliteration in particular. Arbabi (Arbabi et al., 1998) developed a hybrid neural network and knowledge-based system to generate multiple English spellings for Arabic person names. Stalls and Knight (Stalls and Knight, 1998) introduced an approach for Arabic-English back transliteration for names of English origin; this approach could only back transliterate to English the names that have an available pronunciation. Al-Onaizan and Knight (Al-Onaizan and Knight, 2002) proposed a spelling-based model which directly maps English letter sequences into Arabic letter sequences. Their model was trained on a small English Arabic names list without the need for English pronunciations. Although this method does not require the availability of English pronunciation, it has a serious limitation because it does not provide a </context>
</contexts>
<marker>Stalls, Knight, 1998</marker>
<rawString>Bonnie G. Stalls and Kevin Knight.. Translating Names and Technical Terms in Arabic Text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages. 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
</authors>
<title>A Projection Extension Algorithm for Statistical Machine Translation. In</title>
<date>2003</date>
<booktitle>Proc of Empirical Methods in Natural Language Processing,</booktitle>
<contexts>
<context position="13742" citStr="Tillmann, 2003" startWordPosition="2165" endWordPosition="2167">nt words facilitates the task of NEs alignment since many of the words that might lead to confusion have been eliminated. As shown in the above example, different mismatched identification of NEs could result from different identifiers. The “Multi-cost Named Entity Alignment by Content Words Elimination” technique helps in reducing alignment errors due to identification errors by reducing the candidate words for alignment and thus reducing the aligner confusion. 4.2 Phrase Based Named Entity Translation For phrase-based NE translation, we used an approach similar to that presented by Tillman (Tillmann, 2003) for block generation with modifications suitable for NE phrase extraction. A block is defined to be any pair of source and target phrases. This approach starts from a word alignment generated by HMM Viterbi training (Vogel et. Al, 1996), which is done in both directions between source and target. The intersection of the two alignments is considered a high precision alignment and the union is considered a low precision alignment. The high precision alignments are used to generate high precision blocks which are further expanded using low precision alignments. The reader is referred to (Tillman</context>
<context position="18568" citStr="Tillmann, 2003" startWordPosition="2937" endWordPosition="2938">the constructed translation WFST is composed with two language models (LM) transducers namely a letter trigram model and a word unigram model. The trigram letter based LM acts to provide high recall results while the word based unigram LM acts for providing high precisin results. 4.4 System Integration and Decoding The three constructed models in the steps above, namely phrase-based NE translation, wordbased translation, and transliteration, are used to generate hypotheses for each source NE phrase. We used a dynamic programming beam search decoder similar to the decoder described by Tillman (Tillmann, 2003). We employed two language models that were built from NE phrases extracted from monolingual target data for each NE category under consideration. The first language model is a trigram language model on NE phrases. The second language model is a class based language model with a class for unknown NEs. Every NE that do exist in the monolingual data but out of the vocabulary of the phrase and word translation models are considered unknown. This helps in correctly scoring OOV hypothesis produced by the transliteration module. 5 Experimental Setup We test our system for Arabic to English NE transl</context>
</contexts>
<marker>Tillmann, 2003</marker>
<rawString>Christoph Tillmann,. A Projection Extension Algorithm for Statistical Machine Translation. In Proc of Empirical Methods in Natural Language Processing, 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM Based Word Alignment in Statistical Machine Translation.</title>
<date>1996</date>
<booktitle>In Proc. of the 16th Int. Conf. on Computational Linguistics (COLING),</booktitle>
<contexts>
<context position="17263" citStr="Vogel et al., 1996" startWordPosition="2722" endWordPosition="2725"> 4.1 from the word based alignment models. First, the translation matrix is filtered out to only preserve highly confident translations; translations with probabilities less than a certain threshold are filtered out. Secondly, the resulting high confident translations are further refined by calculating phonetic based edit distance between both romanized Arabic and English names. Name pairs with an edit distance greater than a predefined threshold are also filtered out. The remaining highly confident name pairs are used to train a letter to letter translation matrix using HMM Viterbi training (Vogel et al., 1996). Each bi-gram of letters on the source side is aligned to an n-gram of letters sequence on the target side, such that vowels have very low cost to be aligned to NULL. The block probabilities are calculated and refined iteratively for each source and target sequences. Finally, for a source block s and a target block t, the probability of s being translated as t is the ratio of their co-occurrence and total source occurrence: P(t |s) = N(t, s) N(s) . The resulting block translation probabilities and the letter to letter translation probabilities are combined to construct a Weighted Finite State</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stefan Vogel, Hermann Ney, and Christoph Tillmann.. HMM Based Word Alignment in Statistical Machine Translation. In Proc. of the 16th Int. Conf. on Computational Linguistics (COLING), 1996</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zobel</author>
<author>P Dart</author>
</authors>
<title>Phonetic String Matching: Lessons from Information Retrieval.</title>
<date>1996</date>
<booktitle>SIGIR Forum, special issue:166--172,</booktitle>
<contexts>
<context position="9429" citStr="Zobel and Dart, 1996" startWordPosition="1448" endWordPosition="1451">cost aligning approach introduced by Huang (Huang et al. 2003) but it is significantly different. The cost for aligning any source and target NE word is defined as: C= A1p(we |wf)+A2Ed(we,wf)+ A3Tag(we,wf) Where: we and wf are the target and source words respectively and A1 , A2 andA3 are the cost weighting parameters. The first term p(we |wf) represents the translation log probability of target word ( we) given the source word ( wf ). The second term Ed (we, wf) is length-normalized phonetic based edit distance between the two words. This phonetic-based edit distance employs an Editex style (Zobel and Dart, 1996) distance measure, which groups letters that can result in similar pronunciations, but doesn’t require that the groups be disjoint, and can thus reflect the correspondences between letters with similar pronunciation more accurately. The Editex distance (d) between two letters a and b is: d(a,b) = 0 if both are identical = 1 if they are in the same group = 2 otherwise The Editex distance between two words is the summation of Editex distance between their letters and length-normalized edit distance is: Ed (we, wf) = log(1− we where d (we, wf) is the “Editex” style edit distance and max( |we |, |</context>
</contexts>
<marker>Zobel, Dart, 1996</marker>
<rawString>J. Zobel and P. Dart, Phonetic String Matching: Lessons from Information Retrieval. SIGIR Forum, special issue:166--172, 1996</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>