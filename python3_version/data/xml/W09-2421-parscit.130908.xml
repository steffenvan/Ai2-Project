<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000176">
<title confidence="0.868099">
Relation detection between named entities: report of a shared task
</title>
<author confidence="0.698554">
Cl´audia Freitas, Diana Santos Hugo Gonc¸alo Oliveira Paula Carvalho
</author>
<table confidence="0.74346625">
Cristina Mota CISUC, DEI - FCTUC Univ. Lisbon, FCUL, XLDB
SINTEF ICT hroliv@dei.uc.pt pcc@di.fc.ul.pt
claudiafreitas@puc-rio.br
Diana.Santos@sintef.no
</table>
<email confidence="0.812084">
cmota@ist.utl.pt
</email>
<sectionHeader confidence="0.992413" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995631375">
In this paper we describe the first evalu-
ation contest (track) for Portuguese whose
goal was to detect and classify relations be-
tween named entities in running text, called
ReRelEM. Given a collection annotated with
named entities belonging to ten different se-
mantic categories, we marked all relationships
between them within each document. We used
the following fourfold relationship classifi-
cation: identity, included-in, located-in, and
other (which was later on explicitly detailed
into twenty different relations). We provide a
quantitative description of this evaluation re-
source, as well as describe the evaluation ar-
chitecture and summarize the results of the
participating systems in the track.
</bodyText>
<sectionHeader confidence="0.990019" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999413822222222">
Named entity recognition can be considered the first
step towards semantic analysis of texts and a crucial
subtask of information extraction systems. Proper
names, besides their high frequency in language, do
more than just refer – they convey additional infor-
mation as instances of general semantic categories.
But NE recognition is, as just mentioned, only the
first step for full language processing. If we want to
go beyond the detection of entities, a natural step is
establishing semantic relations between these enti-
ties, and this is what this paper is about.
There are two fairly independent communities
that focus on the task of detecting relations between
named entities: the work on anaphora resolution, il-
lustrated by (Mitkov, 2000; Collovini et al., 2007;
de Souza et al., 2008) and the work on relation de-
tection in information extraction, see e.g. (Agichtein
and Gravano, 2000; Zhao and Grishman, 2005; Cu-
lotta and Sorensen, 2004). Although both commu-
nities are doing computational semantics, the two
fields are largely non-overlapping, and one of the
merits of our work is that we tried to merge the two.
Let us briefly describe both traditions: as (Mitkov,
2000) explains, anaphora resolution is concerned
with studying the linguistic phenomenon of pointing
back to another expression in the text. The seman-
tic relations between the referents of these expres-
sions can be of different types, being co-reference a
special case when the relation is identity. The focus
of anaphora resolution is determining the antecedent
chains, although it implicitly also allows to elicit se-
mantic relations between referents. This task has a
long tradition in natural language processing (NLP)
since the early days of artificial intelligence (Web-
ber, 1978), and has from the start been considered a
key ingredient in text understanding.
A different tradition, within information extrac-
tion and ontology building, is devoted to fact ex-
traction. The detection of relations involving named
entities is seen as a step towards a more structured
model of the meaning of a text. The main concerns
here (see e.g. (Zhao and Grishman, 2005)) are the
extraction of large quantities of facts, generally cou-
pled with machine learning approaches.1
Although mentions of named entities may ex-
</bodyText>
<footnote confidence="0.797572">
1Other authors use the term relation detection in still other
ways: for example, (Roth and tau Yih, 2004) use it for the trans-
lation of any natural language sentences into “logical form”, as
in kill fx,y). This task does not concern us here.
</footnote>
<page confidence="0.939224">
129
</page>
<note confidence="0.99749">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 129–137,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.9952906875">
Relations Works
orgBased-in, Headquarters, Org-Location, Based-in RY, AG, DI, Sn, CS, ACE07, ACE04, ZG
live-in, Citizen-or-Resident RY, ACE04, ZG, ACE07,CS
Employment, Membership, Subsidiary ZG, CS, ACE04, ACE07
located(in), residence, near ACE04, ACE07,CS, ZG
work-for, Affiliate, Founder, Management, CS, ACE04, ACE07, RY, ZG
Client, Member, Staff
Associate, Grandparent, Parent, Sibling, CS, ACE04, ACE07
Spouse, Other-professional, Other-relative, Other-personal
User, Owner,Inventor, Manufacturer ACE04,ACE07, ZG, CS
DiseaseOutbreaks AG
Metonymy ACE07
identity ARE
synonym ARE
generalisation ARE
specialisation ARE
</table>
<tableCaption confidence="0.999982">
Table 1: Relations used in other works or evaluation contests.
</tableCaption>
<bodyText confidence="0.999598782608696">
press semantic relations other than identity or de-
pendency, the main focus of the first school has
been limited to co-reference. Yet, relations such
as part-of have been considered under the label
of indirect anaphora, also known as associative or
bridging anaphora.
Contrarywise, the list of relations of interest for
the second school is defined simply by world knowl-
edge (not linguistic clues), and typical are the rela-
tions between an event and its location, or an orga-
nization and its headquarters. Obviously, these rela-
tions do occur between entities that do not involve
(direct or indirect) anaphora in whatever broad un-
derstanding of the term.
Also, relation detection in the second school does
not usually cover identity (cf. ACE’s seven relation
types): identity or co-reference is often considered
an intermediate step before relation extraction (Cu-
lotta and Sorensen, 2004).
Table 1 displays a non-exhaustive overview of the
different relations found in the literature.2
In devising the ReRelEM3 pilot track, our goal
was twofold: to investigate which relations could
</bodyText>
<footnote confidence="0.9878225">
2There is overlap between ACE 2007 and 2004 types of re-
lations. In order to ease the comparison, we used the names of
subtypes for ACE relations.
3ReRelEM stands for Reconhecimento de Relac¸˜oes entre
Entidades Mencionadas, Portuguese for “recognition of rela-
tions between named entities”, see (Freitas et al., 2008).
</footnote>
<bodyText confidence="0.999958192307692">
be found between named entities in Portuguese text,
and how could a pilot task be devised that compared
the performance of different automatic systems sup-
posed to identify them. It should be emphasized that
both MUC and ACE were key inspiration sources for
ReRelEM, which stems from Linguateca’s emphasis
on evaluation.
In fact, we were conversant with MUC co-
reference track and the way it was scored, as well
as aware of two other related evaluation contests:
ACE (Doddington et al., 2004; NIST and ACE,
2007), which extended MUC by dropping the re-
quirement that entities had to be named, and ARE
(Or˘asan et al., 2008), which requested the identifi-
cation of an anaphoric relation in certain types of
pre-defined relations (identity, synonymy, general-
ization and specification), but which ignored indirect
anaphora (that may convey meronymy, or inclusion,
in a broad sense).
ReRelEM, although maintaining (or adding) the
restriction to named entitites, is, from our point of
view, an advance in the field of relation detection,
since we proposed the detection (and classification)
of all (relevant) kinds of relations between NEs in a
document, providing thus both a merge and an ex-
tension of the previous evaluation campaigns.
</bodyText>
<page confidence="0.994544">
130
</page>
<table confidence="0.968205636363636">
Category/gloss #
PESSOA/person 196
LOCAL/place 145
ORGANIZACAO/org 102
TEMPO/time 84
OBRA/title 33
VALOR/value 33
ACONTECIMENTO/event 21
ABSTRACCAO/abstraction 17
OUTRO/other 6
COISA/thing 5
</table>
<tableCaption confidence="0.998098">
Table 2: Category distribution in the golden collection
</tableCaption>
<sectionHeader confidence="0.862521" genericHeader="introduction">
2 Track description
</sectionHeader>
<bodyText confidence="0.99952875">
The purpose of ReRelEM is to assess systems that
try to recognize the most relevant relations between
named entities, even if those relations do not involve
coreference or anaphora.
</bodyText>
<subsectionHeader confidence="0.976399">
2.1 Context
</subsectionHeader>
<bodyText confidence="0.99997575">
In order for it to be feasible in the short time we
had, the track definition required that both referring
expression and their semantic referent were named
entities. Pronouns and definite descriptions were
hence excluded. Note also that ReRelEM was de-
fined in the context of the second edition of a larger
evaluation contest dealing with NE detection and
classification in Portuguese, HAREM (Santos et al.,
2008) (for a detailed description of HAREM, in Por-
tuguese, see also (Santos and Cardoso, 2007; Mota
and Santos, 2008)). HAREM required systems to
choose among ten categories (see Table 2), 43 types
and 21 subtypes, the later concerning the categories
TEMPO (time) and LOCAL (place).
So, it should be emphasized that ReRelEM fo-
cuses only on the classification and detection of
the relations, not limiting in any way the kinds of
(named) entities that can be related (as usualy done
in other detection tasks). It only enforces the kinds
of relations that must be identified.
</bodyText>
<subsectionHeader confidence="0.997361">
2.2 Relation inventory
</subsectionHeader>
<bodyText confidence="0.999376777777778">
The establishment of an inventory of the most rele-
vant relations between NEs is ultimately subjective,
depending on the kind of information that each par-
ticipant aims to extract. We have nevertheless done
an exploratory study and annotated exhaustively a
few texts to assess the most frequent and less con-
troversial (or easier to assign) relations, and came
up with just the following relation types for the task
proposal:
</bodyText>
<listItem confidence="0.999901333333333">
• identity (ident);
• inclusion (inclui (includes) or incluido
(included));
• placement (ocorre-em (occurs-in) or
sede-de (place-of));
• other (outra)
</listItem>
<bodyText confidence="0.996808">
For further description and examples see section 3.
However, during the process of building
ReRelEM’s golden collection (a subset of the
HAREM collection used as gold standard), human
annotation was felt to be more reliable – and also
more understandable – if one specified what “other”
actually meant, and so a further level of detail
(twenty new relations) was selected and marked,
see Table 3. (In any case, since this new refinement
did not belong to the initial task description, all
were mapped back to the coarser outra relation
for evaluation purposes.)
</bodyText>
<subsectionHeader confidence="0.838855">
2.3 ReRelEM features and HAREM
requirements
</subsectionHeader>
<bodyText confidence="0.999940684210526">
The annotation process began after the annotation
of HAREM’s golden collection, that is, the relations
started to be annotated after all NE had been tagged
and totally revised. For ReRelEM, we had therefore
no say in that process – again, ReRelEM was only
concerned with the relations between the classified
NEs. However, our detailed consideration of rela-
tions helped to uncover – and correct some mistakes
in the original classification.
In order to explain the task(s) at hand, let us de-
scribe shortly ReRelEM’s syntax: In ReRelEM’s
golden collection, each NE has a unique ID. A re-
lation between NE is indicated by the additional at-
tributes COREL (filled with the ID of the related en-
tity) and TIPOREL (filled with the name of the re-
lation) present in the NE that corresponds to one of
the arguments of the relation. (Actually, there’s no
difference if the relation is marked in the first or in
the second argument.)
</bodyText>
<page confidence="0.992126">
131
</page>
<bodyText confidence="0.9998685">
One referring expression can be associated with
one or more NEs through several semantic relations.
In such cases, all possible relations must be assigned
to the referring expression, in the form of a list, as
illustrated by UTAD in Figure 1.
In this example, the NE with name UTAD (and
id ex1-42) corresponds to an acronym of Univer-
sidade de Tr´as-os-Montes e Alto Douro (a univer-
sity in Portugal), maintaining with this entity an
identity relation (ident). The TIPOREL field of
ex1-42 contains another relation, inclui, which
stands for the relation of inclusion, this time with
the previously mentioned Servic¸os Administrativos
(ex1-40), a specific department of the university.
In order to minimize human labour and also to
let systems mark relations the way it would better
suit them, we have postulated from the start that, for
all purposes, it would be equivalent to annotate ev-
erything or just enough relations so that all others
can be automatically computed. So, the evaluation
programs, in an obvious extension of what was pro-
posed in (Vilain et al., 1995) for identity,
</bodyText>
<listItem confidence="0.83351975">
1. add/expand all relations with their inverses
(e.g., “A includes B” entails “B is included in
A”), and
2. apply a set of expansion rules (see examples in
</listItem>
<tableCaption confidence="0.38885">
Table 4) to compute the closure
</tableCaption>
<bodyText confidence="0.993508666666667">
As a consequence, different systems may tag the
same text in different ways, but encoding the same
knowledge.
</bodyText>
<subsectionHeader confidence="0.98015">
2.4 What is a relevant relation?
</subsectionHeader>
<bodyText confidence="0.992558571428572">
An important difference as to what we expect as rel-
evant relations should be pointed out: instead of re-
quiring explicit (linguistic) clues, as in traditional
research on anaphor, we look for all relations that
may make sense in the specific context of the whole
document. Let us provide two arguments supporting
this decision:
</bodyText>
<listItem confidence="0.992915">
• the first one is philosophical: the borders be-
tween world knowledge and contextual infer-
ence can be unclear in many cases, so it is not
easy to distinguish them, even if we did believe
in that separation in the first place;
• the second is practical: marking all possible re-
</listItem>
<bodyText confidence="0.868411958333333">
lations is a way to also deal with unpredictable
informational needs, for example for text min-
ing applications. Take a sentence like ”When I
lived in Peru, I attended a horse show and was
able to admire breeds I had known only from
pictures before, like Falabella and Paso.”. From
this sentence, few people would infer that Paso
is a Peruvian breed, but a horse specialist might
at once see the connection. The question is:
should one identify a relation between Peru and
Paso in this document? We took the affirmative
decision, assuming the existence of users inter-
ested in the topic: “relation of breeds to horse
shows: are local breeds predominant?”.
However, and since this was the first time such eval-
uation contest was run, we took the following mea-
sure: we added the attribute INDEP to the cases
where the relation was not possible to be inferred
by the text. In this way, it is possible to assess
the frequency of these cases in the texts, and one
may even filter them out before scoring the system
runs to check their weight in the ranking of the sys-
tems. Interestingly, there were very few cases (only
6) marked INDEP in the annotated collection.
</bodyText>
<sectionHeader confidence="0.994071" genericHeader="method">
3 Qualitative relation description
</sectionHeader>
<bodyText confidence="0.999068647058823">
Identity (or co-reference) does not need to be ex-
plained, although we should insist that this is not
identity of expression, but of meaning. So the same
string does not necessarily imply identity, cf.:
Os adeptos do Porto invadiram a cidade
do Porto em j´ubilo.4
Interestingly, even though organization is only the
third most frequent category, Figure 2 shows that we
found more co-reference among organizations than
among any other category.
As to inclusion (see Figure 3), it was defined be-
tween NEs of the same sort, as the folowing ex-
amples, respectively illustrating LOCAL, PESSOA,
OBRA and ORGANIZACAO, show:
Centenas de pessoas recepcionaram no
Aeroporto da Portela num clima de
enorme entusiasmo e euforia, a selecc¸˜ao
</bodyText>
<footnote confidence="0.969933">
4The (FC) Porto fans invaded the (city of) Porto, very happy
</footnote>
<page confidence="0.969802">
132
</page>
<table confidence="0.857155714285714">
&lt;EM ID=&amp;quot;ex1-39&amp;quot; CATEG=&amp;quot;PESSOA&amp;quot; TIPO=&amp;quot;INDIVIDUAL&amp;quot;&gt; Miguel Rodrigues&lt;/EM&gt;
, chefe dos &lt;EM ID=&amp;quot;ex1-40&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot;
COREL=&amp;quot;ex1-39&amp;quot; TIPOREL=&amp;quot;outra&amp;quot;&gt;Servic¸os Administrativos&lt;/EM&gt; da &lt;EM
ID=&amp;quot;ex1-41&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot; COREL=&amp;quot;ex1-40&amp;quot;
TIPOREL=&amp;quot;inclui&amp;quot;&gt; Universidade de Tr´as-os-Montes e Alto Douro&lt;/EM&gt; &lt;EM
ID=&amp;quot;ex1-42&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot; COREL=&amp;quot;ex1-41 ex1-40&amp;quot;
TIPOREL=&amp;quot;ident inclui&amp;quot;&gt;UTAD&lt;/EM&gt;
</table>
<figureCaption confidence="0.999959666666667">
Figure 1: Full example of ReRelEM syntax.
Figure 2: Distribution of NE categories for identity.
Figure 3: NE categories related by inclusion.
</figureCaption>
<bodyText confidence="0.993668857142857">
portuguesa de rˆaguebi. A boa prestac¸˜ao
global da equipa (...) n˜ao passou desperce-
bida em Portugal.5
Lewis Hamilton, colega de Alonso na
McLaren6
da assinatura do Tratado de Lisboa (...)
de ver reconhecido o valor juridicamente
vinculativo da Carta um passo “essencial
no quadro de reforma dos Tratados7
por participar na cerim´onia de
proclamac¸˜ao da Carta dos Direitos
Fundamentais da UE (...) salientou
ainda o compromisso assumido pelas trˆes
instituic¸˜oes - PE8
</bodyText>
<footnote confidence="0.90847825">
5Hundreds of people waited with enthusiasm and eupho-
ria at the Portela Airport for the Portuguese national rugby
team.(...) The team’s good performance did not go unnoticed in
Portugal
6Lewis Hamilton, Alonso’s team-mate in McLaren – Note
that, in HAREM, teams are considered groups of people, there-
fore an individual and a team have the same category PESSOA
(person), but differ in the type.
7the signing of the Lisbon Treaty (...) juridically vincula-
tive value of the Charter, a crucial step for the Treaties reform
policy
8to participate in the proclamation ceremony of the Charter
</footnote>
<bodyText confidence="0.990607384615385">
Placement is clearly skewed towards placement of
organizations (518 cases) as opposed to occurrence
of events (just 98 instances). However, if we con-
sider the relative distribution of organizations and
events (see Table 2), we can state that, relative to
their places, events have 4.8 relations in average and
organizations 5.0, which is a far more interesting re-
sult, not favouring any of the NE classes.
Examples of this relation are:
GP Brasil – N˜ao faltou emoc¸˜ao em Inter-
lagos no Circuito Jos´e Carlos Pace9
As to the refinement of outra, Table 3 presents the
relations found in the material.
</bodyText>
<subsectionHeader confidence="0.998788">
3.1 Vague categories
</subsectionHeader>
<bodyText confidence="0.999924">
It is important to stress that the basic tenets of
HAREM had to be followed or reckoned with, not
only the classification grid (see Table 2) but par-
ticularly the fact that some named entities are con-
sidered to be vague among different categories in
</bodyText>
<footnote confidence="0.96147875">
of Fundamental Rights of the EU (...) stressed the commitment
assumed by the three institutions - EP
9GP Brasil – There was no lack of excitement in Interlagos
at the Jos´e Carlos Pace Circuit.
</footnote>
<page confidence="0.990653">
133
</page>
<equation confidence="0.977189619047619">
Relation / gloss Number
vinculo-inst / inst-commitment 936
obra-de / work-of 300
participante-em / participant-in 202
ter-participacao-de / has-participant 202
relacao-familiar / family-tie 90
residencia-de / home-of 75
natural-de / born-in 47
relacao-profissional / professional-tie 46
povo-de / people-of 30
representante-de / representative-of 19
residente-de / living-in 15
personagem-de / character-of 12
periodo-vida / life-period 11
propriedade-de / owned-by 10
proprietario-de / owner-of 10
representado-por / represented-by 7
praticado-em / practised-in 7
outra-rel/other 6
nome-de-ident / name-of 4
outra-edicao / other-edition 2
</equation>
<tableCaption confidence="0.888004">
Table 3: Frequency of other relations.
</tableCaption>
<bodyText confidence="0.988235555555556">
HAREM.10
This last property, namely that named entities
could belong to more than one category, posed some
problems, since it was not straightforward whether
different relations would involve all or just some (or
one) category. So, in order to specify clearly the
relations between vague NEs, we decided to spec-
ify separate relations between facets of vague named
entities. Cf. the following example, in which vague-
ness is conveyed by a slash:
(...) a ideia de uma Europa (LO-
CAL/PESSOA) unida. (...) um dia feliz
para as cidad˜as e os cidad˜aos da Uni˜ao
Europeia (LOCAL). (...) Somos essen-
cialmente uma comunidade de valores –
s˜ao estes valores comuns que constituem
o fundamento da Uni˜ao Europeia (AB-
STRACCAO/ORG/LOCAL).11
</bodyText>
<footnote confidence="0.7878264">
10This is different from considering metonymy classes, in
that no classifications are considered more basic than others, see
(Santos, 2006) for vagueness as an intrinsic property of natural
language.
11the idea of a united Europe (...) a happy day for the citizens
</footnote>
<bodyText confidence="0.999898125">
The several relations between the three bold-faced
NEs have been found to be as follows: The LO-
CAL facet of the first NE is identical with the LO-
CAL facets of the second and third NEs, while the
ORG(ANIZACAO) facet of the third NE is located
in the LOCAL facet of the second and first NEs.
(Two kinds of relations are therefore involved here:
ident and inclui.)
</bodyText>
<sectionHeader confidence="0.913074" genericHeader="method">
4 Evaluation: architecture and measures
</sectionHeader>
<bodyText confidence="0.999646125">
Our first concern in this pilot track was to make a
clear separation between the evaluation of relations
and the evaluation of NE detection, which was the
goal of HAREM. So, ReRelEM ’s evaluation uses as
a starting point the set of alignments that correspond
to a mapping of the NE in the golden collection (GC)
to a (candidate) NE in the participation.
Evaluation has the following stages:
</bodyText>
<listItem confidence="0.992119227272727">
• Maximization: the sets of relations annotated in
both the GC and in the participation are maxi-
mized, applying the rules in Table 4;
• Selection: the alignments where the NE in the
GC is different from the corresponding one in
the participation are removed, and so are all re-
lations held between removed NEs;
• Normalization: The identifiers of the NE in the
participation are normalized in order to make it
possible to compare the relations in both sides,
given that each system uses its own identifiers.
• Translation: The alignments are translated to
triples: arg1 relation arg2, where the
arguments consist of the identifiers of the
NE together with the facet, for example x67
LOCAL sede-de ty45 ORGANIZACAO.
• Filtering: removing relations of types not be-
ing evaluated (because HAREM, and therefore
ReRelEM, allows for partial participation – and
evaluation – scenarios12).
• Individual evaluation: the triples in the GC are
compared to the triples in the participation.
</listItem>
<footnote confidence="0.8829622">
of the European Union (...) We are mainly a community of
values and these common values constitute the foundation of
the European Union.
12In other words, it is possible to select a subset of the classi-
fication hierarchy.
</footnote>
<page confidence="0.997432">
134
</page>
<bodyText confidence="0.933361">
A ident B ∧ B ident C S A ident C
A inclui B ∧ B inclui C S A inclui C
A inclui B ∧ B sede de C S A sede de C
A ident B ∧ B any rel C S A any rel C
</bodyText>
<tableCaption confidence="0.995416">
Table 4: Maximization rules
</tableCaption>
<table confidence="0.73817925">
System NE task Relations
Rembr. all all
SeRelEP only identification all but outra
SeiGeo only LOCAL detection inclusion
</table>
<tableCaption confidence="0.997286">
Table 5: Participant systems
</tableCaption>
<listItem confidence="0.943746333333333">
• Global evaluation: measures (precision, recall
and F-measure) are calculated based on the
score of each triple.
</listItem>
<bodyText confidence="0.999620857142857">
Each triple is scored as correct, missing or incor-
rect. We only considered as correct triples (and cor-
rect relations) those which linked the correct NEs
and whose relation was well classified. So, a system
doesn’t score if it correctly matches the NEs to be re-
lated, but fails to recognize the kind of relation. We
assign one point to each correct relation and none to
incorrect or missing relations, and then we compute
precision, recall and F-measure.
ReRelEM’s golden collection includes 12 texts
with 4,417 words and 573 NEs (corresponding to
642 different facets). In all we annotated 6,790 re-
lations (1436 identity; 1612 inclusion; 1232 place-
ment; 2510 other).
</bodyText>
<sectionHeader confidence="0.860738" genericHeader="evaluation">
5 Participation and results
</sectionHeader>
<bodyText confidence="0.999927769230769">
For this first edition, only three systems (totalling
nine runs) participated, namely REMBRANDT
(Cardoso, 2008), SEI-Geo (Chaves, 2008), and
SeRelEP (Bruckschen et al., 2008), whose results
are found in Figure 4. However, they did not com-
pare well: they selected different NER tasks and dif-
ferent relation types, as shown in Table 5. So, given
the little and diverse participation in ReRelEM, we
cannot do a useful state of the art, but we were def-
initely able to provide an interesting and important
resource for empirical studies and for training of fu-
ture systems, as well as a set of publicly available
programs to manipulate, evaluate and display this
</bodyText>
<figureCaption confidence="0.998128">
Figure 4: ReRelEM results: F-measure, all relations
</figureCaption>
<bodyText confidence="0.911282">
kind of semantic data13.
</bodyText>
<sectionHeader confidence="0.973382" genericHeader="conclusions">
6 Discussion and further work
</sectionHeader>
<bodyText confidence="0.999913227272727">
Although this was just a pilot, a lot of knowledge
about the task and the problems to be dealt with were
gathered for the future, and important resources
were offered to the community.
We intend to annotate further sections of the
HAREM golden collection (as well as other kinds
of texts and materials) with more relations in order
to have more quantitative empirical data for studying
the semantic fabric of Portuguese.
Although from an organization point of view it
made sense to couple ReRelEM with HAREM, one
should reflect over the consequences of inheriting a
lot of decisions taken in HAREM, somehow going
counter the intuitive and easier task of just annotat-
ing relations in a first round. However, despite initial
fears to the contrary, we found out that the consid-
erably fine-grained HAREM grid was in fact benefi-
cial to the task of specifying relations: it is, after all,
much more informative to have a relation of inclu-
sion between a COISA-MEMBROCLASSE (concrete
instance of a class of objects) and a COISA-CLASSE
(a class of objects), than just a relation of inclusion
</bodyText>
<footnote confidence="0.894965">
13http://www.linguateca.pt/HAREM/
</footnote>
<page confidence="0.997904">
135
</page>
<bodyText confidence="0.999922135135135">
tout court. In fact, in the next sentence, a kind of
specialization relation can be uncovered.
Astrˆonomos brasileiros esperam fotogra-
far os primeiros planetas fora do Sistema
Solar com a ajuda do maior telesc´opio
do mundo, o Gemini (...) os telesc´opios
Gemini tˆem capacidade cientifica...14
Likewise, an inclusion relation held between
PESSOA-GRUPOCARGO (a group of roles performed
by people) and PESSOA-INDIVIDUAL (an individ-
ual person) , as in the following example, is more
informative than a simple relation of inclusion be-
tween NEs, or even inclusion between PESSOA enti-
ties without further discrimination.
P¨ottering, S´ocrates e Barroso assinam
Carta dos Direitos Fundamentais da UE.
Depois de a Carta ser assinada pelos
Presidentes das trˆes instituic¸˜oes, ouviu-se
o hino europeu...15
Furthermore, this relation is also different from
an inclusion relation held between PESSOA-
INDIVIDUAL (an individual) and PESSOA-
GRUPOMEMBRO (a group of people):
Lobos recebidos em apoteose. (...) o
capit˜ao Vasco Uva explicou por que houve
uma empatia t˜ao grande entre... 16
Conversely, the specification of relations between
different NEs in a text may help in detecting and jus-
tifying different facets of a particular NE, i.e., mul-
tiple semantic categories that should be assigned to
it.
This illustrates the often observed case that it may
be easier for a human annotator to decide and choose
a specific issue than a too general one, and that there-
fore categories or choices should be more dependent
on ease of human interpretation than quantitative
factors (such as few categories or balanced ones).
</bodyText>
<footnote confidence="0.868895">
14Brazilian astronomers expect to take the first pictures of
planets beyond the solar system with the help of the largest
telescope in the world, Gemini (...) Gemini telescopes have
a capacity...
15P¨ottering, S´ocrates e Barroso sign the declaration... After
being signed by the Presidents of the three institutions, ...
16Lobos received apoteothically. (...) Captain Vasco Uva
explained why ...
</footnote>
<bodyText confidence="0.999941210526316">
For future work, we obviously intend to increase
the size of the annotated collection (to the whole
HAREM collection and even beyond), and investi-
gate a couple of issues that interest us: which strate-
gies are used to avoid repetition of proper names
and establish textual cohesion? How do relations
between noun phrases in general compare with re-
lations between entities?
We would also like to investigate closer rela-
tionships between different relations: for exam-
ple, is it more appropriate to also develop a hi-
erarchy of relations, reconsidering, for example,
affiliation (currently one of the other) as a
kind of inclusion?
In order to understand better what this task is
about, we would also like to investigate whether
there are interesting correlations between NE cate-
gories and relations, as well as text genre and this
sort of connectivity. Even though we only studied
and annotated in depth 12 different texts, it was at
once obvious that they had quite different properties
as far as the number and kinds of relations was con-
cerned.
From an evaluation point of view, we would like
to improve our inconsistency detection programs
and be able to reason about possible contradictions
(of the annotation or of the interpretation) as well
as experiment with different weights and evaluation
measures, taking into account criteria such as pre-
dictability of relationships between NEs.
In any case, we believe this was an important first
step to understand a number of issues and to reflect
about what computational systems should be doing
to harvest semantic knowledge. We would like to
receive feedback on whether the task design seems
sound to the rest of the community, and whether sys-
tems which would perform well in such task could
be put to good use in real world applications.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999907">
This work was done in the scope of the Linguateca
project, jointly funded by the Portuguese Govern-
ment and the European Union (FEDER and FSE)
under contract ref. POSC/339/1.3/C/NAC.
</bodyText>
<page confidence="0.998264">
136
</page>
<sectionHeader confidence="0.989947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999676881188119">
Eugene Agichtein and Luis Gravano. 2000. Snowball:
Extracting Relations from Large Plain-Text Collec-
tions. In Proc. of the 5th ACM International Con-
ference on Digital Libraries (ACM DL), pages 85–94,
San Antonio, Texas, USA, June, 2-7.
Mirian Bruckschen, Jos´e Guilherme Camargo de Souza,
Renata Vieira, and Sandro Rigo. 2008. Sistema
SeRELeP para o reconhecimento de relac¸˜oes entre en-
tidades mencionadas. In Mota and Santos (Mota and
Santos, 2008).
Nuno Cardoso. 2008. REMBRANDT - Reconhecimento
de Entidades Mencionadas Baseado em Relac¸˜oes e
AN´alise Detalhada do Texto. In Mota and Santos
(Mota and Santos, 2008).
Marcirio Chaves. 2008. Geo-ontologias e padr˜oes para
reconhecimento de locais e de suas relac¸˜oes em textos:
o SEI-Geo no Segundo HAREM. In Mota and Santos
(Mota and Santos, 2008).
Sandra Collovini, Thiago Ianez Carbonel, Ju-
liana Thiesen Fuchs, Jorge C´esar Coelho, Lucia
Helena Machado Rino, and Renata Vieira. 2007.
Summ-it: Um corpus anotado com informac¸˜oes
discursivas visando a` sumarizac¸˜ao autom´atica. In
Anais do XXVII Congresso da SBC: V Workshop em
Tecnologia da Informac¸˜ao e da Linguagem Humana
– TIL, pages 1605–1614, Rio de Janeiro, RJ, Brazil,
junho/julho.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
the 42rd Annual Meeting of the Association for Com-
putational Linguistics (ACL’04), pages 423–429. As-
sociation for Computational Linguistics, July.
Jos´e Guilherme Camargo de Souza, Patricia Nunes
Gonc¸alves, and Renata Vieira. 2008. Learning coref-
erence resolution for portuguese texts. In Ant´onio
Teixeira, Vera L´ucia Strube de Lima, Luis Caldas
de Oliveira, and Paulo Quaresma, editors, PROPOR,
volume 5190 of Lecture Notes in Computer Science,
pages 153–162. Springer.
Georde Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The automatic content extraction
(ace) programm. tasks, data and evaluation. In Pro-
ceedings of the Fourth International Conference on
Language Resources and Evaluation, pages 837–840,
Lisbon, Portugal.
Cl´audia Freitas, Diana Santos, Hugo Gonc¸alo Oliveira,
Paula Carvalho, and Cristina Mota. 2008. Relac¸˜oes
semˆanticas do ReRelEM: al´em das entidades no Se-
gundo HAREM. In Mota and Santos (Mota and San-
tos, 2008).
Ruslan Mitkov. 2000. Towards a more consistent and
comprehensive evaluation of anaphora resolution al-
gorithms and systems. In Proceedings of the Dis-
course Anaphora and Anaphora Resolution Collo-
quium (DAARC-2000), pages 96–107, Lancaster, UK.
Cristina Mota and Diana Santos, editors. 2008. Desafios
no reconhecimento de entidades mencionadas: O Se-
gundo HAREM. Linguateca.
NIST and ACE. 2007. Automatic Content Extrac-
tion 2008 Evaluation Plan (ACE08) – Assessment of
Detection and Recognition of Entities and Relations
within and across Documents. Technical report, NIST.
Constantin Or˘asan, Dan Cristea, Ruslan Mitkov, and An-
tonio Branco. 2008. Anaphora resolution exercise:
An overview. In Proceedings of the Sixth International
Language Resources and Evaluation (LREC’08), Mar-
rakech, Morocco, May, 28 - 30.
Dan Roth and Wen tau Yih. 2004. A linear programming
formulation for global inference in natural language
tasks. In Proceedings of CoNLL-2004, pages 1–8.
Diana Santos and Nuno Cardoso, editors. 2007. Re-
conhecimento de entidades mencionadas em por-
tuguˆes: Documentac¸˜ao e actas do HAREM, a primeira
avaliac¸˜ao conjunta na ´area. Linguateca, Portugal.
Diana Santos, Cl´audia Freitas, Hugo Gonc¸alo Oliveira,
and Paula Carvalho. 2008. Second HAREM: new
challenges and old wisdom. In Ant´onio Teixeira, Vera
L´ucia Strube de Lima, Luis Caldas de Oliveira, and
Paulo Quaresma, editors, Computational Processing
of the Portuguese Language, 8th International Con-
ference, Proceedings (PROPOR 2008), volume LNAI
5190, pages 212–215. Springer Verlag.
Diana Santos. 2006. What is natural language? Dif-
ferences compared to artificial languages, and conse-
quences for natural language processing, 15 May. In-
vited lecture, SBLP2006 and PROPOR’2006.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceed-
ings of the Sixth Message Understanding Conference
(MUC-6), pages 45–52. Morgan Kaufmann.
Bonnie Lynn Webber. 1978. A formal approach to dis-
course anaphora. Outstanding dissertations in linguis-
tics. Garland Publishing, New York, NY, USA.
Shubin Zhao and Ralph Grishman. 2005. Extracting re-
lations with integrated information using kernel meth-
ods. In Proceedings ofthe 43rd Annual Meeting on As-
sociation for Computational Linguistics (ACL 2005),
pages 419–426, Morristown, NJ, USA. Association for
Computational Linguistics.
</reference>
<page confidence="0.997824">
137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998796">Relation detection between named entities: report of a shared task</title>
<author confidence="0.696203">FCUL Lisbon</author>
<author confidence="0.696203">XLDB SINTEF ICT pccdi fc ul pt</author>
<email confidence="0.682995">cmota@ist.utl.pt</email>
<abstract confidence="0.991488253731344">In this paper we describe the first evaluation contest (track) for Portuguese whose goal was to detect and classify relations between named entities in running text, called ReRelEM. Given a collection annotated with named entities belonging to ten different semantic categories, we marked all relationships between them within each document. We used the following fourfold relationship classification: identity, included-in, located-in, and other (which was later on explicitly detailed into twenty different relations). We provide a quantitative description of this evaluation resource, as well as describe the evaluation architecture and summarize the results of the participating systems in the track. 1 Motivation Named entity recognition can be considered the first step towards semantic analysis of texts and a crucial subtask of information extraction systems. Proper names, besides their high frequency in language, do more than just refer – they convey additional information as instances of general semantic categories. But NE recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of these expressions can be of different types, being co-reference a special case when the relation is identity. The focus of anaphora resolution is determining the antecedent chains, although it implicitly also allows to elicit semantic relations between referents. This task has a long tradition in natural language processing (NLP) since the early days of artificial intelligence (Webber, 1978), and has from the start been considered a key ingredient in text understanding. A different tradition, within information extraction and ontology building, is devoted to fact extraction. The detection of relations involving named entities is seen as a step towards a more structured model of the meaning of a text. The main concerns here (see e.g. (Zhao and Grishman, 2005)) are the extraction of large quantities of facts, generally couwith machine learning mentions of named entities may exauthors use the term detection still other ways: for example, (Roth and tau Yih, 2004) use it for the translation of any natural language sentences into “logical form”, as This task does not concern us here.</abstract>
<note confidence="0.809236214285714">129 of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future pages 129–137, Colorado, June 2009. Association for Computational Linguistics Relations Works orgBased-in, Headquarters, Org-Location, Based-in RY, AG, DI, Sn, CS, ACE07, ACE04, ZG live-in, Citizen-or-Resident RY, ACE04, ZG, ACE07,CS Employment, Membership, Subsidiary ZG, CS, ACE04, ACE07 located(in), residence, near ACE04, ACE07,CS, ZG CS, ACE04, ACE07, RY, ZG work-for, Affiliate, Founder, Management, Client, Member, Staff Associate, Grandparent, Parent, Sibling, CS, ACE04, ACE07 Spouse, Other-professional, Other-relative, Other-personal User, Owner,Inventor, Manufacturer ACE04,ACE07, ZG, CS DiseaseOutbreaks AG Metonymy ACE07</note>
<abstract confidence="0.992404643263759">identity ARE synonym ARE generalisation ARE specialisation ARE Table 1: Relations used in other works or evaluation contests. press semantic relations other than identity or dependency, the main focus of the first school has been limited to co-reference. Yet, relations such been considered under the label of indirect anaphora, also known as associative or bridging anaphora. Contrarywise, the list of relations of interest for the second school is defined simply by world knowledge (not linguistic clues), and typical are the relations between an event and its location, or an organization and its headquarters. Obviously, these relations do occur between entities that do not involve (direct or indirect) anaphora in whatever broad understanding of the term. Also, relation detection in the second school does not usually cover identity (cf. ACE’s seven relation types): identity or co-reference is often considered an intermediate step before relation extraction (Culotta and Sorensen, 2004). Table 1 displays a non-exhaustive overview of the relations found in the devising the pilot track, our goal was twofold: to investigate which relations could is overlap between ACE 2007 and 2004 types of relations. In order to ease the comparison, we used the names of subtypes for ACE relations. stands for de entre Portuguese for “recognition of relations between named entities”, see (Freitas et al., 2008). be found between named entities in Portuguese text, and how could a pilot task be devised that compared the performance of different automatic systems supposed to identify them. It should be emphasized that both MUC and ACE were key inspiration sources for ReRelEM, which stems from Linguateca’s emphasis on evaluation. In fact, we were conversant with MUC coreference track and the way it was scored, as well as aware of two other related evaluation contests: ACE (Doddington et al., 2004; NIST and ACE, 2007), which extended MUC by dropping the requirement that entities had to be named, and ARE (Or˘asan et al., 2008), which requested the identification of an anaphoric relation in certain types of pre-defined relations (identity, synonymy, generalization and specification), but which ignored indirect anaphora (that may convey meronymy, or inclusion, in a broad sense). ReRelEM, although maintaining (or adding) the restriction to named entitites, is, from our point of view, an advance in the field of relation detection, since we proposed the detection (and classification) of all (relevant) kinds of relations between NEs in a document, providing thus both a merge and an extension of the previous evaluation campaigns. 130 Category/gloss # PESSOA/person 196 LOCAL/place 145 ORGANIZACAO/org 102 TEMPO/time 84 OBRA/title 33 VALOR/value 33 ACONTECIMENTO/event 21 ABSTRACCAO/abstraction 17 OUTRO/other 6 COISA/thing 5 Table 2: Category distribution in the golden collection 2 Track description The purpose of ReRelEM is to assess systems that try to recognize the most relevant relations between named entities, even if those relations do not involve coreference or anaphora. 2.1 Context In order for it to be feasible in the short time we had, the track definition required that both referring expression and their semantic referent were named entities. Pronouns and definite descriptions were hence excluded. Note also that ReRelEM was defined in the context of the second edition of a larger evaluation contest dealing with NE detection and classification in Portuguese, HAREM (Santos et al., 2008) (for a detailed description of HAREM, in Portuguese, see also (Santos and Cardoso, 2007; Mota and Santos, 2008)). HAREM required systems to choose among ten categories (see Table 2), 43 types and 21 subtypes, the later concerning the categories and So, it should be emphasized that ReRelEM focuses only on the classification and detection of the relations, not limiting in any way the kinds of (named) entities that can be related (as usualy done in other detection tasks). It only enforces the kinds of relations that must be identified. 2.2 Relation inventory The establishment of an inventory of the most relevant relations between NEs is ultimately subjective, depending on the kind of information that each participant aims to extract. We have nevertheless done an exploratory study and annotated exhaustively a few texts to assess the most frequent and less controversial (or easier to assign) relations, and came up with just the following relation types for the task proposal: identity inclusion or (included)); placement or other For further description and examples see section 3. However, during the process of building ReRelEM’s golden collection (a subset of the HAREM collection used as gold standard), human annotation was felt to be more reliable – and also more understandable – if one specified what “other” actually meant, and so a further level of detail (twenty new relations) was selected and marked, see Table 3. (In any case, since this new refinement did not belong to the initial task description, all mapped back to the coarser for evaluation purposes.) 2.3 ReRelEM features and HAREM requirements The annotation process began after the annotation of HAREM’s golden collection, that is, the relations started to be annotated after all NE had been tagged and totally revised. For ReRelEM, we had therefore no say in that process – again, ReRelEM was only concerned with the relations between the classified NEs. However, our detailed consideration of relations helped to uncover – and correct some mistakes in the original classification. In order to explain the task(s) at hand, let us describe shortly ReRelEM’s syntax: In ReRelEM’s golden collection, each NE has a unique ID. A relation between NE is indicated by the additional attributes COREL (filled with the ID of the related entity) and TIPOREL (filled with the name of the relation) present in the NE that corresponds to one of the arguments of the relation. (Actually, there’s no difference if the relation is marked in the first or in the second argument.) 131 One referring expression can be associated with one or more NEs through several semantic relations. In such cases, all possible relations must be assigned to the referring expression, in the form of a list, as by Figure 1. this example, the NE with name corresponds to an acronym of Univerde Tr´as-os-Montes e Alto Douro university in Portugal), maintaining with this entity an relation The TIPOREL field of another relation, which stands for the relation of inclusion, this time with previously mentioned Administrativos a specific department of the university. In order to minimize human labour and also to let systems mark relations the way it would better suit them, we have postulated from the start that, for all purposes, it would be equivalent to annotate everything or just enough relations so that all others can be automatically computed. So, the evaluation programs, in an obvious extension of what was proposed in (Vilain et al., 1995) for identity, 1. add/expand all relations with their inverses (e.g., “A includes B” entails “B is included in A”), and 2. apply a set of expansion rules (see examples in Table 4) to compute the closure As a consequence, different systems may tag the same text in different ways, but encoding the same knowledge. 2.4 What is a relevant relation? An important difference as to what we expect as relevant relations should be pointed out: instead of requiring explicit (linguistic) clues, as in traditional research on anaphor, we look for all relations that may make sense in the specific context of the whole document. Let us provide two arguments supporting this decision: • the first one is philosophical: the borders between world knowledge and contextual inference can be unclear in many cases, so it is not easy to distinguish them, even if we did believe in that separation in the first place; • the second is practical: marking all possible relations is a way to also deal with unpredictable informational needs, for example for text mining applications. Take a sentence like ”When I lived in Peru, I attended a horse show and was able to admire breeds I had known only from pictures before, like Falabella and Paso.”. From this sentence, few people would infer that Paso is a Peruvian breed, but a horse specialist might at once see the connection. The question is: should one identify a relation between Peru and Paso in this document? We took the affirmative decision, assuming the existence of users interested in the topic: “relation of breeds to horse shows: are local breeds predominant?”. However, and since this was the first time such evaluation contest was run, we took the following measure: we added the attribute INDEP to the cases where the relation was not possible to be inferred by the text. In this way, it is possible to assess the frequency of these cases in the texts, and one may even filter them out before scoring the system runs to check their weight in the ranking of the systems. Interestingly, there were very few cases (only 6) marked INDEP in the annotated collection. 3 Qualitative relation description Identity (or co-reference) does not need to be explained, although we should insist that this is not identity of expression, but of meaning. So the same string does not necessarily imply identity, cf.: adeptos do a cidade Interestingly, even though organization is only the third most frequent category, Figure 2 shows that we found more co-reference among organizations than among any other category. As to inclusion (see Figure 3), it was defined between NEs of the same sort, as the folowing exrespectively illustrating show: Centenas de pessoas recepcionaram no da Portela clima de entusiasmo e euforia, a (FC) Porto fans invaded the (city of) very happy 132 &lt;EM ID=&amp;quot;ex1-39&amp;quot; CATEG=&amp;quot;PESSOA&amp;quot; TIPO=&amp;quot;INDIVIDUAL&amp;quot;&gt; Miguel Rodrigues&lt;/EM&gt; , chefe dos &lt;EM ID=&amp;quot;ex1-40&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot; Administrativos&lt;/EM&gt; da &lt;EM ID=&amp;quot;ex1-41&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot; COREL=&amp;quot;ex1-40&amp;quot; TIPOREL=&amp;quot;inclui&amp;quot;&gt; Universidade de Tr´as-os-Montes e Alto Douro&lt;/EM&gt; &lt;EM ID=&amp;quot;ex1-42&amp;quot; CATEG=&amp;quot;ORGANIZACAO&amp;quot; TIPO=&amp;quot;INSTITUICAO&amp;quot; COREL=&amp;quot;ex1-41 ex1-40&amp;quot; TIPOREL=&amp;quot;ident inclui&amp;quot;&gt;UTAD&lt;/EM&gt; Figure 1: Full example of ReRelEM syntax. Figure 2: Distribution of NE categories for identity. Figure 3: NE categories related by inclusion. de rˆaguebi. A boa da equipa (...) passou desperceem colega de Alonso na assinatura do de Lisboa de ver reconhecido o valor juridicamente da passo “essencial quadro de reforma dos por participar na cerim´onia de da Carta dos Direitos da ainda o compromisso assumido pelas trˆes of people waited with enthusiasm and euphoat the Airport the Portuguese national rugby team.(...) The team’s good performance did not go unnoticed in Portugal Alonso’s team-mate in Note that, in HAREM, teams are considered groups of people, therean individual and a team have the same category (person), but differ in the type. signing of the Treaty juridically vinculavalue of the a crucial step for the policy participate in the proclamation ceremony of the Charter Placement is clearly skewed towards placement of organizations (518 cases) as opposed to occurrence of events (just 98 instances). However, if we consider the relative distribution of organizations and events (see Table 2), we can state that, relative to their places, events have 4.8 relations in average and organizations 5.0, which is a far more interesting result, not favouring any of the NE classes. Examples of this relation are: Brasil faltou em Interno Jos´e Carlos to the refinement of Table 3 presents the relations found in the material. 3.1 Vague categories It is important to stress that the basic tenets of HAREM had to be followed or reckoned with, not only the classification grid (see Table 2) but particularly the fact that some named entities are considered to be vague among different categories in Fundamental Rights of the stressed the commitment by the three institutions - Brasil There was no lack of excitement in Interlagos the Carlos Pace 133 Relation / gloss Number vinculo-inst / inst-commitment 936 obra-de / work-of 300 participante-em / participant-in 202 ter-participacao-de / has-participant 202 relacao-familiar / family-tie 90 residencia-de / home-of 75 natural-de / born-in 47 relacao-profissional / professional-tie 46 povo-de / people-of 30 representante-de / representative-of 19 residente-de / living-in 15 personagem-de / character-of 12 periodo-vida / life-period 11 propriedade-de / owned-by 10 proprietario-de / owner-of 10 representado-por / represented-by 7 praticado-em / practised-in 7 outra-rel/other 6 nome-de-ident / name-of 4 outra-edicao / other-edition 2 3: Frequency of This last property, namely that named entities could belong to more than one category, posed some problems, since it was not straightforward whether different relations would involve all or just some (or one) category. So, in order to specify clearly the relations between vague NEs, we decided to specify separate relations between facets of vague named entities. Cf. the following example, in which vagueness is conveyed by a slash: a ideia de uma unida. (...) um dia feliz as e os da (...) Somos essencialmente uma comunidade de valores – estes valores comuns que constituem fundamento da Europeia is different from considering metonymy classes, in that no classifications are considered more basic than others, see (Santos, 2006) for vagueness as an intrinsic property of natural language. idea of a united a happy day for the citizens The several relations between the three bold-faced have been found to be as follows: The of the first NE is identical with the LO- CAL facets of the second and third NEs, while the facet of the third NE is located the of the second and first NEs. (Two kinds of relations are therefore involved here: 4 Evaluation: architecture and measures Our first concern in this pilot track was to make a clear separation between the evaluation of relations and the evaluation of NE detection, which was the goal of HAREM. So, ReRelEM ’s evaluation uses as a starting point the set of alignments that correspond to a mapping of the NE in the golden collection (GC) to a (candidate) NE in the participation. Evaluation has the following stages: • Maximization: the sets of relations annotated in both the GC and in the participation are maximized, applying the rules in Table 4; • Selection: the alignments where the NE in the GC is different from the corresponding one in the participation are removed, and so are all relations held between removed NEs; • Normalization: The identifiers of the NE in the participation are normalized in order to make it possible to compare the relations in both sides, given that each system uses its own identifiers. • Translation: The alignments are translated to relation where the arguments consist of the identifiers of the together with the facet, for example sede-de ty45 • Filtering: removing relations of types not being evaluated (because HAREM, and therefore ReRelEM, allows for partial participation – and – • Individual evaluation: the triples in the GC are compared to the triples in the participation. the Union We are mainly a community of values and these common values constitute the foundation of other words, it is possible to select a subset of the classification hierarchy. 134 de de rel rel Table 4: Maximization rules System NE task Relations Rembr. all all SeRelEP only identification all but outra SeiGeo only LOCAL detection inclusion Table 5: Participant systems • Global evaluation: measures (precision, recall and F-measure) are calculated based on the score of each triple. Each triple is scored as correct, missing or incorrect. We only considered as correct triples (and correct relations) those which linked the correct NEs and whose relation was well classified. So, a system doesn’t score if it correctly matches the NEs to be related, but fails to recognize the kind of relation. We assign one point to each correct relation and none to incorrect or missing relations, and then we compute precision, recall and F-measure. ReRelEM’s golden collection includes 12 texts with 4,417 words and 573 NEs (corresponding to 642 different facets). In all we annotated 6,790 relations (1436 identity; 1612 inclusion; 1232 placement; 2510 other). 5 Participation and results For this first edition, only three systems (totalling nine runs) participated, namely REMBRANDT (Cardoso, 2008), SEI-Geo (Chaves, 2008), and SeRelEP (Bruckschen et al., 2008), whose results are found in Figure 4. However, they did not compare well: they selected different NER tasks and different relation types, as shown in Table 5. So, given the little and diverse participation in ReRelEM, we cannot do a useful state of the art, but we were definitely able to provide an interesting and important resource for empirical studies and for training of future systems, as well as a set of publicly available programs to manipulate, evaluate and display this Figure 4: ReRelEM results: F-measure, all relations of semantic 6 Discussion and further work Although this was just a pilot, a lot of knowledge about the task and the problems to be dealt with were gathered for the future, and important resources were offered to the community. We intend to annotate further sections of the HAREM golden collection (as well as other kinds of texts and materials) with more relations in order to have more quantitative empirical data for studying the semantic fabric of Portuguese. Although from an organization point of view it made sense to couple ReRelEM with HAREM, one should reflect over the consequences of inheriting a lot of decisions taken in HAREM, somehow going counter the intuitive and easier task of just annotating relations in a first round. However, despite initial fears to the contrary, we found out that the considerably fine-grained HAREM grid was in fact beneficial to the task of specifying relations: it is, after all, much more informative to have a relation of inclubetween a of a class of objects) and a (a class of objects), than just a relation of inclusion 135 tout court. In fact, in the next sentence, a kind of specialization relation can be uncovered. Astrˆonomos brasileiros esperam fotografar os primeiros planetas fora do Sistema Solar com a ajuda do maior telesc´opio mundo, o os telesc´opios Geminitˆem capacidade Likewise, an inclusion relation held between group of roles performed people) and individual person) , as in the following example, is more informative than a simple relation of inclusion be- NEs, or even inclusion between entities without further discrimination. Carta dos Direitos Fundamentais da UE. Depois de a Carta ser assinada pelos Presidentesdas trˆes ouviu-se hino Furthermore, this relation is also different from inclusion relation held between individual) and group of people): em apoteose. (...) o Uvaexplicou por que houve empatia grande entre... Conversely, the specification of relations between different NEs in a text may help in detecting and justifying different facets of a particular NE, i.e., multiple semantic categories that should be assigned to it. This illustrates the often observed case that it may be easier for a human annotator to decide and choose a specific issue than a too general one, and that therefore categories or choices should be more dependent on ease of human interpretation than quantitative factors (such as few categories or balanced ones). astronomers expect to take the first pictures of planets beyond the solar system with the help of the largest in the world, have a capacity... the declaration... After signed by the the three institutions, ... apoteothically. (...) Captain Uva explained why ... For future work, we obviously intend to increase the size of the annotated collection (to the whole HAREM collection and even beyond), and investigate a couple of issues that interest us: which strategies are used to avoid repetition of proper names and establish textual cohesion? How do relations between noun phrases in general compare with relations between entities? We would also like to investigate closer relationships between different relations: for example, is it more appropriate to also develop a hierarchy of relations, reconsidering, for example, one of the as a of In order to understand better what this task is about, we would also like to investigate whether there are interesting correlations between NE categories and relations, as well as text genre and this sort of connectivity. Even though we only studied and annotated in depth 12 different texts, it was at once obvious that they had quite different properties as far as the number and kinds of relations was concerned. From an evaluation point of view, we would like to improve our inconsistency detection programs and be able to reason about possible contradictions (of the annotation or of the interpretation) as well as experiment with different weights and evaluation measures, taking into account criteria such as predictability of relationships between NEs. In any case, we believe this was an important first step to understand a number of issues and to reflect about what computational systems should be doing to harvest semantic knowledge. We would like to receive feedback on whether the task design seems sound to the rest of the community, and whether systems which would perform well in such task could be put to good use in real world applications.</abstract>
<note confidence="0.854970512820513">Acknowledgments This work was done in the scope of the Linguateca project, jointly funded by the Portuguese Government and the European Union (FEDER and FSE) under contract ref. POSC/339/1.3/C/NAC. 136 References Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting Relations from Large Plain-Text Collec- In of the 5th ACM International Conon Digital Libraries (ACM pages 85–94, San Antonio, Texas, USA, June, 2-7. Mirian Bruckschen, Jos´e Guilherme Camargo de Souza, Renata Vieira, and Sandro Rigo. 2008. Sistema para o reconhecimento de entre entidades mencionadas. In Mota and Santos (Mota and Santos, 2008). Nuno Cardoso. 2008. REMBRANDT - Reconhecimento Entidades Mencionadas Baseado em e AN´alise Detalhada do Texto. In Mota and Santos (Mota and Santos, 2008). Chaves. 2008. Geo-ontologias e para de locais e de suas em textos: o SEI-Geo no Segundo HAREM. In Mota and Santos (Mota and Santos, 2008). Sandra Collovini, Thiago Ianez Carbonel, Juliana Thiesen Fuchs, Jorge C´esar Coelho, Lucia Helena Machado Rino, and Renata Vieira. 2007. Um corpus anotado com visando a` autom´atica. In Anais do XXVII Congresso da SBC: V Workshop em da e da Linguagem Humana pages 1605–1614, Rio de Janeiro, RJ, Brazil, junho/julho. Aron Culotta and Jeffrey Sorensen. 2004. Dependency kernels for relation extraction. In of the 42rd Annual Meeting of the Association for Com- Linguistics pages 423–429. Association for Computational Linguistics, July.</note>
<author confidence="0.900376">Jos´e Guilherme Camargo de_Souza</author>
<author confidence="0.900376">Patricia Nunes</author>
<affiliation confidence="0.584319">and Renata Vieira. 2008. Learning coreference resolution for portuguese texts. In Ant´onio</affiliation>
<address confidence="0.635678">Teixeira, Vera L´ucia Strube de Lima, Luis Caldas Oliveira, and Paulo Quaresma, editors,</address>
<note confidence="0.914418">5190 of Notes in Computer pages 153–162. Springer. Georde Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, and Ralph Weischedel. 2004. The automatic content extraction programm. tasks, data and evaluation. In Proceedings of the Fourth International Conference on Resources and pages 837–840,</note>
<address confidence="0.663744666666667">Lisbon, Portugal. Freitas, Diana Santos, Hugo Oliveira, Carvalho, and Cristina Mota. 2008.</address>
<abstract confidence="0.667545925925926">semˆanticas do ReRelEM: al´em das entidades no Segundo HAREM. In Mota and Santos (Mota and Santos, 2008). Ruslan Mitkov. 2000. Towards a more consistent and comprehensive evaluation of anaphora resolution aland systems. In of the Discourse Anaphora and Anaphora Resolution Collopages 96–107, Lancaster, UK. Mota and Diana Santos, editors. 2008. no reconhecimento de entidades mencionadas: O Se- Linguateca. NIST and ACE. 2007. Automatic Content Extraction 2008 Evaluation Plan (ACE08) – Assessment of Detection and Recognition of Entities and Relations within and across Documents. Technical report, NIST. Constantin Or˘asan, Dan Cristea, Ruslan Mitkov, and Antonio Branco. 2008. Anaphora resolution exercise: overview. In of the Sixth International Resources and Evaluation Marrakech, Morocco, May, 28 - 30. Dan Roth and Wen tau Yih. 2004. A linear programming formulation for global inference in natural language In of pages 1–8. Santos and Nuno Cardoso, editors. 2007. Reconhecimento de entidades mencionadas em pore actas do HAREM, a primeira conjunta na Linguateca, Portugal.</abstract>
<affiliation confidence="0.58785">Santos, Cl´audia Freitas, Hugo Oliveira,</affiliation>
<address confidence="0.403479">and Paula Carvalho. 2008. Second HAREM: new</address>
<note confidence="0.73962288">challenges and old wisdom. In Ant´onio Teixeira, Vera L´ucia Strube de Lima, Luis Caldas de Oliveira, and Quaresma, editors, Processing of the Portuguese Language, 8th International Con- Proceedings (PROPOR volume LNAI 5190, pages 212–215. Springer Verlag. Diana Santos. 2006. What is natural language? Differences compared to artificial languages, and consequences for natural language processing, 15 May. Invited lecture, SBLP2006 and PROPOR’2006. Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A modelcoreference scoring scheme. In Proceedings of the Sixth Message Understanding Conference pages 45–52. Morgan Kaufmann. Lynn Webber. 1978. formal approach to dis- Outstanding dissertations in linguistics. Garland Publishing, New York, NY, USA. Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel meth- In ofthe 43rd Annual Meeting on Asfor Computational Linguistics (ACL pages 419–426, Morristown, NJ, USA. Association for Computational Linguistics. 137</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: Extracting Relations from Large Plain-Text Collections.</title>
<date>2000</date>
<booktitle>In Proc. of the 5th ACM International Conference on Digital Libraries (ACM DL),</booktitle>
<pages>85--94</pages>
<location>San Antonio, Texas, USA,</location>
<contexts>
<context position="1922" citStr="Agichtein and Gravano, 2000" startWordPosition="283" endWordPosition="286">on as instances of general semantic categories. But NE recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of these expressions can be of different types, being co-reference a special case when the relation is identity. The focus of anaph</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting Relations from Large Plain-Text Collections. In Proc. of the 5th ACM International Conference on Digital Libraries (ACM DL), pages 85–94, San Antonio, Texas, USA, June, 2-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirian Bruckschen</author>
<author>Jos´e Guilherme Camargo de Souza</author>
<author>Renata Vieira</author>
<author>Sandro Rigo</author>
</authors>
<title>Sistema SeRELeP para o reconhecimento de relac¸˜oes entre entidades mencionadas. In Mota and Santos (Mota and Santos,</title>
<date>2008</date>
<marker>Bruckschen, de Souza, Vieira, Rigo, 2008</marker>
<rawString>Mirian Bruckschen, Jos´e Guilherme Camargo de Souza, Renata Vieira, and Sandro Rigo. 2008. Sistema SeRELeP para o reconhecimento de relac¸˜oes entre entidades mencionadas. In Mota and Santos (Mota and Santos, 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuno Cardoso</author>
</authors>
<title>REMBRANDT - Reconhecimento de Entidades Mencionadas Baseado em Relac¸˜oes e AN´alise Detalhada do Texto. In Mota and Santos (Mota and Santos,</title>
<date>2008</date>
<contexts>
<context position="22270" citStr="Cardoso, 2008" startWordPosition="3546" endWordPosition="3547"> So, a system doesn’t score if it correctly matches the NEs to be related, but fails to recognize the kind of relation. We assign one point to each correct relation and none to incorrect or missing relations, and then we compute precision, recall and F-measure. ReRelEM’s golden collection includes 12 texts with 4,417 words and 573 NEs (corresponding to 642 different facets). In all we annotated 6,790 relations (1436 identity; 1612 inclusion; 1232 placement; 2510 other). 5 Participation and results For this first edition, only three systems (totalling nine runs) participated, namely REMBRANDT (Cardoso, 2008), SEI-Geo (Chaves, 2008), and SeRelEP (Bruckschen et al., 2008), whose results are found in Figure 4. However, they did not compare well: they selected different NER tasks and different relation types, as shown in Table 5. So, given the little and diverse participation in ReRelEM, we cannot do a useful state of the art, but we were definitely able to provide an interesting and important resource for empirical studies and for training of future systems, as well as a set of publicly available programs to manipulate, evaluate and display this Figure 4: ReRelEM results: F-measure, all relations ki</context>
</contexts>
<marker>Cardoso, 2008</marker>
<rawString>Nuno Cardoso. 2008. REMBRANDT - Reconhecimento de Entidades Mencionadas Baseado em Relac¸˜oes e AN´alise Detalhada do Texto. In Mota and Santos (Mota and Santos, 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcirio Chaves</author>
</authors>
<title>Geo-ontologias e padr˜oes para reconhecimento de locais e de suas relac¸˜oes em textos: o SEI-Geo no Segundo HAREM. In Mota and Santos (Mota and Santos,</title>
<date>2008</date>
<contexts>
<context position="22294" citStr="Chaves, 2008" startWordPosition="3549" endWordPosition="3550">re if it correctly matches the NEs to be related, but fails to recognize the kind of relation. We assign one point to each correct relation and none to incorrect or missing relations, and then we compute precision, recall and F-measure. ReRelEM’s golden collection includes 12 texts with 4,417 words and 573 NEs (corresponding to 642 different facets). In all we annotated 6,790 relations (1436 identity; 1612 inclusion; 1232 placement; 2510 other). 5 Participation and results For this first edition, only three systems (totalling nine runs) participated, namely REMBRANDT (Cardoso, 2008), SEI-Geo (Chaves, 2008), and SeRelEP (Bruckschen et al., 2008), whose results are found in Figure 4. However, they did not compare well: they selected different NER tasks and different relation types, as shown in Table 5. So, given the little and diverse participation in ReRelEM, we cannot do a useful state of the art, but we were definitely able to provide an interesting and important resource for empirical studies and for training of future systems, as well as a set of publicly available programs to manipulate, evaluate and display this Figure 4: ReRelEM results: F-measure, all relations kind of semantic data13. 6</context>
</contexts>
<marker>Chaves, 2008</marker>
<rawString>Marcirio Chaves. 2008. Geo-ontologias e padr˜oes para reconhecimento de locais e de suas relac¸˜oes em textos: o SEI-Geo no Segundo HAREM. In Mota and Santos (Mota and Santos, 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Collovini</author>
<author>Thiago Ianez Carbonel</author>
<author>Juliana Thiesen Fuchs</author>
<author>Jorge C´esar Coelho</author>
<author>Lucia Helena Machado Rino</author>
<author>Renata Vieira</author>
</authors>
<title>Summ-it: Um corpus anotado com informac¸˜oes discursivas visando a` sumarizac¸˜ao autom´atica.</title>
<date>2007</date>
<booktitle>In Anais do XXVII Congresso da SBC: V Workshop em Tecnologia da Informac¸˜ao e da Linguagem Humana – TIL,</booktitle>
<pages>1605--1614</pages>
<location>Rio de Janeiro, RJ, Brazil, junho/julho.</location>
<contexts>
<context position="1798" citStr="Collovini et al., 2007" startWordPosition="262" endWordPosition="265">ems. Proper names, besides their high frequency in language, do more than just refer – they convey additional information as instances of general semantic categories. But NE recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of thes</context>
</contexts>
<marker>Collovini, Carbonel, Fuchs, Coelho, Rino, Vieira, 2007</marker>
<rawString>Sandra Collovini, Thiago Ianez Carbonel, Juliana Thiesen Fuchs, Jorge C´esar Coelho, Lucia Helena Machado Rino, and Renata Vieira. 2007. Summ-it: Um corpus anotado com informac¸˜oes discursivas visando a` sumarizac¸˜ao autom´atica. In Anais do XXVII Congresso da SBC: V Workshop em Tecnologia da Informac¸˜ao e da Linguagem Humana – TIL, pages 1605–1614, Rio de Janeiro, RJ, Brazil, junho/julho.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42rd Annual Meeting of the Association for Computational Linguistics (ACL’04),</booktitle>
<pages>423--429</pages>
<contexts>
<context position="1976" citStr="Culotta and Sorensen, 2004" startWordPosition="291" endWordPosition="295"> recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of these expressions can be of different types, being co-reference a special case when the relation is identity. The focus of anaphora resolution is determining the antecedent chains, a</context>
<context position="5322" citStr="Culotta and Sorensen, 2004" startWordPosition="795" endWordPosition="799">naphora. Contrarywise, the list of relations of interest for the second school is defined simply by world knowledge (not linguistic clues), and typical are the relations between an event and its location, or an organization and its headquarters. Obviously, these relations do occur between entities that do not involve (direct or indirect) anaphora in whatever broad understanding of the term. Also, relation detection in the second school does not usually cover identity (cf. ACE’s seven relation types): identity or co-reference is often considered an intermediate step before relation extraction (Culotta and Sorensen, 2004). Table 1 displays a non-exhaustive overview of the different relations found in the literature.2 In devising the ReRelEM3 pilot track, our goal was twofold: to investigate which relations could 2There is overlap between ACE 2007 and 2004 types of relations. In order to ease the comparison, we used the names of subtypes for ACE relations. 3ReRelEM stands for Reconhecimento de Relac¸˜oes entre Entidades Mencionadas, Portuguese for “recognition of relations between named entities”, see (Freitas et al., 2008). be found between named entities in Portuguese text, and how could a pilot task be devis</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42rd Annual Meeting of the Association for Computational Linguistics (ACL’04), pages 423–429. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Guilherme Camargo de Souza</author>
<author>Patricia Nunes Gonc¸alves</author>
<author>Renata Vieira</author>
</authors>
<title>Learning coreference resolution for portuguese texts.</title>
<date>2008</date>
<booktitle>In Ant´onio Teixeira, Vera L´ucia Strube de Lima, Luis Caldas de Oliveira, and</booktitle>
<volume>5190</volume>
<pages>153--162</pages>
<editor>Paulo Quaresma, editors, PROPOR,</editor>
<publisher>Springer.</publisher>
<marker>de Souza, Gonc¸alves, Vieira, 2008</marker>
<rawString>Jos´e Guilherme Camargo de Souza, Patricia Nunes Gonc¸alves, and Renata Vieira. 2008. Learning coreference resolution for portuguese texts. In Ant´onio Teixeira, Vera L´ucia Strube de Lima, Luis Caldas de Oliveira, and Paulo Quaresma, editors, PROPOR, volume 5190 of Lecture Notes in Computer Science, pages 153–162. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georde Doddington</author>
<author>Alexis Mitchell</author>
<author>Mark Przybocki</author>
<author>Lance Ramshaw</author>
<author>Stephanie Strassel</author>
<author>Ralph Weischedel</author>
</authors>
<title>The automatic content extraction (ace) programm. tasks, data and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation,</booktitle>
<pages>837--840</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="6324" citStr="Doddington et al., 2004" startWordPosition="957" endWordPosition="960">Relac¸˜oes entre Entidades Mencionadas, Portuguese for “recognition of relations between named entities”, see (Freitas et al., 2008). be found between named entities in Portuguese text, and how could a pilot task be devised that compared the performance of different automatic systems supposed to identify them. It should be emphasized that both MUC and ACE were key inspiration sources for ReRelEM, which stems from Linguateca’s emphasis on evaluation. In fact, we were conversant with MUC coreference track and the way it was scored, as well as aware of two other related evaluation contests: ACE (Doddington et al., 2004; NIST and ACE, 2007), which extended MUC by dropping the requirement that entities had to be named, and ARE (Or˘asan et al., 2008), which requested the identification of an anaphoric relation in certain types of pre-defined relations (identity, synonymy, generalization and specification), but which ignored indirect anaphora (that may convey meronymy, or inclusion, in a broad sense). ReRelEM, although maintaining (or adding) the restriction to named entitites, is, from our point of view, an advance in the field of relation detection, since we proposed the detection (and classification) of all </context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>Georde Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, and Ralph Weischedel. 2004. The automatic content extraction (ace) programm. tasks, data and evaluation. In Proceedings of the Fourth International Conference on Language Resources and Evaluation, pages 837–840, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cl´audia Freitas</author>
<author>Diana Santos</author>
<author>Hugo Gonc¸alo Oliveira</author>
<author>Paula Carvalho</author>
<author>Cristina Mota</author>
</authors>
<title>Relac¸˜oes semˆanticas do ReRelEM: al´em das entidades no Segundo HAREM. In Mota and Santos (Mota and Santos,</title>
<date>2008</date>
<contexts>
<context position="5833" citStr="Freitas et al., 2008" startWordPosition="875" endWordPosition="878"> co-reference is often considered an intermediate step before relation extraction (Culotta and Sorensen, 2004). Table 1 displays a non-exhaustive overview of the different relations found in the literature.2 In devising the ReRelEM3 pilot track, our goal was twofold: to investigate which relations could 2There is overlap between ACE 2007 and 2004 types of relations. In order to ease the comparison, we used the names of subtypes for ACE relations. 3ReRelEM stands for Reconhecimento de Relac¸˜oes entre Entidades Mencionadas, Portuguese for “recognition of relations between named entities”, see (Freitas et al., 2008). be found between named entities in Portuguese text, and how could a pilot task be devised that compared the performance of different automatic systems supposed to identify them. It should be emphasized that both MUC and ACE were key inspiration sources for ReRelEM, which stems from Linguateca’s emphasis on evaluation. In fact, we were conversant with MUC coreference track and the way it was scored, as well as aware of two other related evaluation contests: ACE (Doddington et al., 2004; NIST and ACE, 2007), which extended MUC by dropping the requirement that entities had to be named, and ARE </context>
</contexts>
<marker>Freitas, Santos, Oliveira, Carvalho, Mota, 2008</marker>
<rawString>Cl´audia Freitas, Diana Santos, Hugo Gonc¸alo Oliveira, Paula Carvalho, and Cristina Mota. 2008. Relac¸˜oes semˆanticas do ReRelEM: al´em das entidades no Segundo HAREM. In Mota and Santos (Mota and Santos, 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Towards a more consistent and comprehensive evaluation of anaphora resolution algorithms and systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the Discourse Anaphora and Anaphora Resolution Colloquium (DAARC-2000),</booktitle>
<pages>96--107</pages>
<location>Lancaster, UK.</location>
<contexts>
<context position="1774" citStr="Mitkov, 2000" startWordPosition="260" endWordPosition="261">xtraction systems. Proper names, besides their high frequency in language, do more than just refer – they convey additional information as instances of general semantic categories. But NE recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations betwe</context>
</contexts>
<marker>Mitkov, 2000</marker>
<rawString>Ruslan Mitkov. 2000. Towards a more consistent and comprehensive evaluation of anaphora resolution algorithms and systems. In Proceedings of the Discourse Anaphora and Anaphora Resolution Colloquium (DAARC-2000), pages 96–107, Lancaster, UK.</rawString>
</citation>
<citation valid="true">
<date>2008</date>
<booktitle>Desafios no reconhecimento de entidades mencionadas: O Segundo HAREM. Linguateca.</booktitle>
<editor>Cristina Mota and Diana Santos, editors.</editor>
<marker>2008</marker>
<rawString>Cristina Mota and Diana Santos, editors. 2008. Desafios no reconhecimento de entidades mencionadas: O Segundo HAREM. Linguateca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
<author>ACE</author>
</authors>
<title>Automatic Content Extraction</title>
<date>2007</date>
<tech>Technical report, NIST.</tech>
<contexts>
<context position="6345" citStr="NIST and ACE, 2007" startWordPosition="961" endWordPosition="964">s Mencionadas, Portuguese for “recognition of relations between named entities”, see (Freitas et al., 2008). be found between named entities in Portuguese text, and how could a pilot task be devised that compared the performance of different automatic systems supposed to identify them. It should be emphasized that both MUC and ACE were key inspiration sources for ReRelEM, which stems from Linguateca’s emphasis on evaluation. In fact, we were conversant with MUC coreference track and the way it was scored, as well as aware of two other related evaluation contests: ACE (Doddington et al., 2004; NIST and ACE, 2007), which extended MUC by dropping the requirement that entities had to be named, and ARE (Or˘asan et al., 2008), which requested the identification of an anaphoric relation in certain types of pre-defined relations (identity, synonymy, generalization and specification), but which ignored indirect anaphora (that may convey meronymy, or inclusion, in a broad sense). ReRelEM, although maintaining (or adding) the restriction to named entitites, is, from our point of view, an advance in the field of relation detection, since we proposed the detection (and classification) of all (relevant) kinds of r</context>
</contexts>
<marker>NIST, ACE, 2007</marker>
<rawString>NIST and ACE. 2007. Automatic Content Extraction 2008 Evaluation Plan (ACE08) – Assessment of Detection and Recognition of Entities and Relations within and across Documents. Technical report, NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Or˘asan</author>
<author>Dan Cristea</author>
<author>Ruslan Mitkov</author>
<author>Antonio Branco</author>
</authors>
<title>Anaphora resolution exercise: An overview.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<pages>30</pages>
<location>Marrakech, Morocco,</location>
<marker>Or˘asan, Cristea, Mitkov, Branco, 2008</marker>
<rawString>Constantin Or˘asan, Dan Cristea, Ruslan Mitkov, and Antonio Branco. 2008. Anaphora resolution exercise: An overview. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco, May, 28 - 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen tau Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL-2004,</booktitle>
<pages>1--8</pages>
<marker>Roth, Yih, 2004</marker>
<rawString>Dan Roth and Wen tau Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Proceedings of CoNLL-2004, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Santos</author>
<author>Nuno Cardoso</author>
<author>editors</author>
</authors>
<title>Reconhecimento de entidades mencionadas em portuguˆes: Documentac¸˜ao e actas do HAREM, a primeira avaliac¸˜ao conjunta na ´area.</title>
<date>2007</date>
<location>Linguateca, Portugal.</location>
<marker>Santos, Cardoso, editors, 2007</marker>
<rawString>Diana Santos and Nuno Cardoso, editors. 2007. Reconhecimento de entidades mencionadas em portuguˆes: Documentac¸˜ao e actas do HAREM, a primeira avaliac¸˜ao conjunta na ´area. Linguateca, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Santos</author>
<author>Cl´audia Freitas</author>
<author>Hugo Gonc¸alo Oliveira</author>
<author>Paula Carvalho</author>
</authors>
<title>Second HAREM: new challenges and old wisdom.</title>
<date>2008</date>
<booktitle>In Ant´onio Teixeira, Vera L´ucia Strube de Lima, Luis Caldas de Oliveira, and Paulo Quaresma, editors, Computational Processing of the Portuguese Language, 8th International Conference, Proceedings (PROPOR 2008), volume LNAI 5190,</booktitle>
<pages>212--215</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="7942" citStr="Santos et al., 2008" startWordPosition="1205" endWordPosition="1208"> description The purpose of ReRelEM is to assess systems that try to recognize the most relevant relations between named entities, even if those relations do not involve coreference or anaphora. 2.1 Context In order for it to be feasible in the short time we had, the track definition required that both referring expression and their semantic referent were named entities. Pronouns and definite descriptions were hence excluded. Note also that ReRelEM was defined in the context of the second edition of a larger evaluation contest dealing with NE detection and classification in Portuguese, HAREM (Santos et al., 2008) (for a detailed description of HAREM, in Portuguese, see also (Santos and Cardoso, 2007; Mota and Santos, 2008)). HAREM required systems to choose among ten categories (see Table 2), 43 types and 21 subtypes, the later concerning the categories TEMPO (time) and LOCAL (place). So, it should be emphasized that ReRelEM focuses only on the classification and detection of the relations, not limiting in any way the kinds of (named) entities that can be related (as usualy done in other detection tasks). It only enforces the kinds of relations that must be identified. 2.2 Relation inventory The estab</context>
</contexts>
<marker>Santos, Freitas, Oliveira, Carvalho, 2008</marker>
<rawString>Diana Santos, Cl´audia Freitas, Hugo Gonc¸alo Oliveira, and Paula Carvalho. 2008. Second HAREM: new challenges and old wisdom. In Ant´onio Teixeira, Vera L´ucia Strube de Lima, Luis Caldas de Oliveira, and Paulo Quaresma, editors, Computational Processing of the Portuguese Language, 8th International Conference, Proceedings (PROPOR 2008), volume LNAI 5190, pages 212–215. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Santos</author>
</authors>
<title>What is natural language? Differences compared to artificial languages, and consequences for natural language processing, 15 May. Invited lecture, SBLP2006 and PROPOR’2006.</title>
<date>2006</date>
<contexts>
<context position="18903" citStr="Santos, 2006" startWordPosition="2964" endWordPosition="2965">learly the relations between vague NEs, we decided to specify separate relations between facets of vague named entities. Cf. the following example, in which vagueness is conveyed by a slash: (...) a ideia de uma Europa (LOCAL/PESSOA) unida. (...) um dia feliz para as cidad˜as e os cidad˜aos da Uni˜ao Europeia (LOCAL). (...) Somos essencialmente uma comunidade de valores – s˜ao estes valores comuns que constituem o fundamento da Uni˜ao Europeia (ABSTRACCAO/ORG/LOCAL).11 10This is different from considering metonymy classes, in that no classifications are considered more basic than others, see (Santos, 2006) for vagueness as an intrinsic property of natural language. 11the idea of a united Europe (...) a happy day for the citizens The several relations between the three bold-faced NEs have been found to be as follows: The LOCAL facet of the first NE is identical with the LOCAL facets of the second and third NEs, while the ORG(ANIZACAO) facet of the third NE is located in the LOCAL facet of the second and first NEs. (Two kinds of relations are therefore involved here: ident and inclui.) 4 Evaluation: architecture and measures Our first concern in this pilot track was to make a clear separation bet</context>
</contexts>
<marker>Santos, 2006</marker>
<rawString>Diana Santos. 2006. What is natural language? Differences compared to artificial languages, and consequences for natural language processing, 15 May. Invited lecture, SBLP2006 and PROPOR’2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A modeltheoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference (MUC-6),</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="11705" citStr="Vilain et al., 1995" startWordPosition="1825" endWordPosition="1828">n (ident). The TIPOREL field of ex1-42 contains another relation, inclui, which stands for the relation of inclusion, this time with the previously mentioned Servic¸os Administrativos (ex1-40), a specific department of the university. In order to minimize human labour and also to let systems mark relations the way it would better suit them, we have postulated from the start that, for all purposes, it would be equivalent to annotate everything or just enough relations so that all others can be automatically computed. So, the evaluation programs, in an obvious extension of what was proposed in (Vilain et al., 1995) for identity, 1. add/expand all relations with their inverses (e.g., “A includes B” entails “B is included in A”), and 2. apply a set of expansion rules (see examples in Table 4) to compute the closure As a consequence, different systems may tag the same text in different ways, but encoding the same knowledge. 2.4 What is a relevant relation? An important difference as to what we expect as relevant relations should be pointed out: instead of requiring explicit (linguistic) clues, as in traditional research on anaphor, we look for all relations that may make sense in the specific context of th</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme. In Proceedings of the Sixth Message Understanding Conference (MUC-6), pages 45–52. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Lynn Webber</author>
</authors>
<title>A formal approach to discourse anaphora. Outstanding dissertations in linguistics.</title>
<date>1978</date>
<publisher>Garland Publishing,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2788" citStr="Webber, 1978" startWordPosition="420" endWordPosition="422"> both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of these expressions can be of different types, being co-reference a special case when the relation is identity. The focus of anaphora resolution is determining the antecedent chains, although it implicitly also allows to elicit semantic relations between referents. This task has a long tradition in natural language processing (NLP) since the early days of artificial intelligence (Webber, 1978), and has from the start been considered a key ingredient in text understanding. A different tradition, within information extraction and ontology building, is devoted to fact extraction. The detection of relations involving named entities is seen as a step towards a more structured model of the meaning of a text. The main concerns here (see e.g. (Zhao and Grishman, 2005)) are the extraction of large quantities of facts, generally coupled with machine learning approaches.1 Although mentions of named entities may ex1Other authors use the term relation detection in still other ways: for example,</context>
</contexts>
<marker>Webber, 1978</marker>
<rawString>Bonnie Lynn Webber. 1978. A formal approach to discourse anaphora. Outstanding dissertations in linguistics. Garland Publishing, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shubin Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings ofthe 43rd Annual Meeting on Association for Computational Linguistics (ACL</booktitle>
<pages>419--426</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1947" citStr="Zhao and Grishman, 2005" startWordPosition="287" endWordPosition="290">mantic categories. But NE recognition is, as just mentioned, only the first step for full language processing. If we want to go beyond the detection of entities, a natural step is establishing semantic relations between these entities, and this is what this paper is about. There are two fairly independent communities that focus on the task of detecting relations between named entities: the work on anaphora resolution, illustrated by (Mitkov, 2000; Collovini et al., 2007; de Souza et al., 2008) and the work on relation detection in information extraction, see e.g. (Agichtein and Gravano, 2000; Zhao and Grishman, 2005; Culotta and Sorensen, 2004). Although both communities are doing computational semantics, the two fields are largely non-overlapping, and one of the merits of our work is that we tried to merge the two. Let us briefly describe both traditions: as (Mitkov, 2000) explains, anaphora resolution is concerned with studying the linguistic phenomenon of pointing back to another expression in the text. The semantic relations between the referents of these expressions can be of different types, being co-reference a special case when the relation is identity. The focus of anaphora resolution is determi</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings ofthe 43rd Annual Meeting on Association for Computational Linguistics (ACL 2005), pages 419–426, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>