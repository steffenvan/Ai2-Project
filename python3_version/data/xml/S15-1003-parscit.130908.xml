<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009939">
<title confidence="0.995771">
A Hybrid Distributional and Knowledge-based Model of Lexical Semantics
</title>
<author confidence="0.990987">
Nikolaos Aletras
</author>
<affiliation confidence="0.990821">
Department of Computer Science,
University College London,
</affiliation>
<address confidence="0.925560666666667">
Gower Street,
London WC1E 6BT
United Kingdom
</address>
<email confidence="0.997151">
nikos.aletras@gmail.com
</email>
<author confidence="0.997147">
Mark Stevenson
</author>
<affiliation confidence="0.99742">
Department of Computer Science,
University of Sheffield,
</affiliation>
<address confidence="0.914206">
Regent Court, 211 Portobello,
Sheffield S1 4DP
United Kingdom
</address>
<email confidence="0.998804">
mark.stevenson@sheffield.ac.uk
</email>
<sectionHeader confidence="0.995636" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9991">
A range of approaches to the representa-
tion of lexical semantics have been explored
within Computational Linguistics. Two of the
most popular are distributional and knowledge-
based models. This paper proposes hybrid
models of lexical semantics that combine the
advantages of these two approaches. Our mod-
els provide robust representations of synony-
mous words derived from WordNet. We also
make use of WordNet’s hierarcy to refine the
synset vectors. The models are evaluated on
two widely explored tasks involving lexical
semantics: lexical similarity and Word Sense
Disambiguation. The hybrid models are found
to perform better than standard distributional
models and have the additional benefit of mod-
elling polysemy.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999683571428571">
The representation of lexical semantics is a core prob-
lem in Computational Linguistics and a variety of
approaches have been developed. Two of the most
widely explored have been knowledge-based and dis-
tributional semantics.
Knowledge-based approaches make use of some
external information source which defines the set of
possible meanings for each lexical item. The most
widely used information source is WordNet (Fell-
baum, 1998), although other resources, such as Ma-
chine Readable Dictionaries, thesaurii and ontologies
have also been used (see Navigli (2009)).
One advantage of these resources is that they rep-
resent the various possible meanings of lexical items
20
which makes it straightforward to identify ones that
are ambiguous. For example, these resources would
include multiple meanings for the word ball includ-
ing the ‘event’ and ‘sports equipment’ senses. How-
ever, the fact that there are multiple meanings as-
sociated with ambiguous lexical items can also be
problematic since it may not be straightforward to
identify which one is being used for an instance of an
ambiguous word in text. This issue has lead to signif-
icant exploration of the problem of Word Sense Dis-
ambiguation (Ide and V´eronis, 1998; Navigli, 2009).
More recently distributional semantics has become
a popular approach to representing lexical semantics
(Turney and Pantel, 2010; Erk, 2012). These ap-
proaches are based on the premise that the semantics
of lexical items can be modelled by their context
(Firth, 1957; Harris, 1985). Distributional seman-
tic models have the advantages of being robust and
straightforward to create from unannotated corpora.
However, problems can arise when they are used to
represent the semantics of polysemous words. Distri-
butional semantic models are generally constructed
by examining the context of lexical items in unanno-
tated corpora. But for ambiguous words, like ball,
it is not clear if a particular instance of the word in
a corpus refers to the ‘event’, ‘sports equipment’ or
another sense which can lead to the distributional se-
mantic model becoming a mixture of different mean-
ings without representing any of the meanings indi-
vidually.
This paper proposes models that merge elements
of distributional and knowledge-based approaches to
lexical semantics and combines advantages of both
techniques. A standard distributional semantic model
</bodyText>
<note confidence="0.931938">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 20–29,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.99950964">
is created from an unannotated corpus and then re-
fined using WordNet. The resulting models can be
viewed as enhanced distributional models that have
been refined using the information from WordNet
to reduce the problems caused by ambiguous terms
when models are created. Alternatively, it can be used
as a version of the WordNet hierarchy in which dis-
tributional semantic models are attached to synsets.
Thereby creating a version of WordNet for which the
appropriate synsets can be identified more easily for
ambiguous lexical items that occur in text.
We evaluate our models on two standard tasks: lex-
ical similarity and word sense disambiguation. Re-
sults show that the proposed hybrid models perform
consistently better than traditional distributional se-
mantic models.
The reminder of the paper is organised as follows.
Section 2 describes our hybrid models which com-
bine information from WordNet and a standard dis-
tributional semantic model. These models are aug-
mented using Latent Semantic Analysis and Canoni-
cal Correlation Analysis. Sections 3 and 4 describe
evaluation of the models on the word similarity and
word sense disambiguation tasks. Related work is
presented in Section 5 and conclusions in Section 6.
</bodyText>
<sectionHeader confidence="0.989043" genericHeader="method">
2 Semantic Models
</sectionHeader>
<bodyText confidence="0.995648">
First, we consider a standard distributional seman-
tic space to represent words as vectors (Section 2.1).
Then, we make use of the WordNet’s clusters of syn-
onyms and hierarchy in combination with the stan-
dard distributional space to build hybrid models (Sec-
tion 2.2) which are augmented using Latent Semantic
Analysis (Section 2.3) and Canonical Correlation
Analysis (Section 2.4).
</bodyText>
<subsectionHeader confidence="0.860761">
2.1 Distributional Model
</subsectionHeader>
<bodyText confidence="0.9999155">
We consider a semantic space D, as a word by con-
text feature matrix, L × C. Vector representations
consist of context features C in a reference corpus.
We made use of pre-computed publicly available vec-
tors1 optimised for word similarity tasks (Baroni et
al., 2014). Word co-occurrence counts are extracted
using a symmetric window of two words over a cor-
pus of 2.8 billion tokens obtained by concatenating
</bodyText>
<footnote confidence="0.9136945">
1http://clic.cimec.unitn.it/composes/
semantic-vectors.html
</footnote>
<bodyText confidence="0.9723506">
ukWaC, the English Wikipedia and the British Na-
tional Corpus. Vectors are weighted using positive
Pointwise Mutual Information and the set of context
features consists of the top 300K most frequent words
in the corpus.
</bodyText>
<subsectionHeader confidence="0.993246">
2.2 Hybrid Models
2.2.1 Synset Distributional Model
</subsectionHeader>
<bodyText confidence="0.999882428571429">
We assume that making use of information about
the structure of WordNet can reduce noise introduced
in vectors of D due to polysemy. We make use of
all noun and verb synsets (excluding numbers and
compounds) that contain at least one of the words in
L to create a vector-based synset representation, H.
Where H is a synset by context feature matrix, i.e.
5 ×C. Each synset vector is generated by computing
the centroid of its lemma vectors in 5 (i.e. the sum
of the lemma’s vectors normalised by the number of
the lemmas in the synset). For example, the vector of
the synset car.n.01 is computed as the centroid of its
lemma vectors, i.e. car, auto, automobile, machine
and motorcar (see Figure 1).
</bodyText>
<subsectionHeader confidence="0.850855">
2.2.2 Synset Rank Model
</subsectionHeader>
<bodyText confidence="0.999936333333333">
The Synset Distributional Model provides a vector
representation for each synset in WordNet which is
created using information about which lemmas share
synset membership. An advantage of this approach
is that vectors from multiple lemmas are combined to
form the synset representation. However, a disadvan-
tage is that many of these lemmas are polysemous
and their vectors represent multiple senses, not just
the one that is relevant to the synset. For example,
in WordNet the lemma machine has several possi-
ble meanings, only one of which is a member of the
synset car.n.01.
WordNet also contains information about the re-
lations between synsets, in the form of the synset
hierarchy, which can be exploited to re-weight the
importance of context features for particular synsets.
We employ a graph-based algorithm that makes use
of the WordNet is-a hierarchy. The intuition behind
this approach is that context features that are relevant
to a given synset are likely to be shared by its neigh-
bours in the hierarchy while those that are not rele-
vant (i.e. have been introduced via an irrelevant sense
of a synset member) will not be. The graph-based
algorithm increases the weight of context features
</bodyText>
<page confidence="0.999615">
21
</page>
<figureCaption confidence="0.987044">
Figure 1: In the Synset Distributional Model the vector representing a synset (white box) is computed as the
centroid of its lemma vectors (grey boxes)
</figureCaption>
<figure confidence="0.995559307692308">
motorcar
~motorcar
machine
~auto
~car
automobile�
car.n.01
+
~machine
auto
car
automobile
car.n.01
</figure>
<bodyText confidence="0.984225166666667">
that synsets share with neighbours and reduces those
that are not shared.
PageRank (Page et al., 1999) is a graph-based algo-
rithm for identifying important nodes in a graph that
has been applied to a range of NLP tasks including
word sense disambiguation (Agirre and Soroa, 2009)
and keyword extraction (Mihalcea and Tarau, 2004).
Let G = (V, E) be a graph with a set of vertices,
V , denoting synsets and a set of edges, E, denoting
links between synsets in the WordNet hierarchy. The
PageRank score (Pr) over G for a synset (Vi) can be
computed by the following equation:
</bodyText>
<equation confidence="0.977869666666667">
� 1
Pr(Vi) = d · O(Vj) Pr(Vj) + (1 − d)V (1)
Vj ∈I(Vi)
</equation>
<bodyText confidence="0.999738870967742">
where I(Vi) denotes the in-degree of the vertex Vi
and O(Vj) is the out-degree of vertex Vj. d is the
damping factor which is set to the default value of
d = 0.85 (Page et al., 1999). In standard PageRank
all elements of the vector v are the same, 1 N where
N is the number of nodes in the graph.
Personalised PageRank (PPR) (Haveliwala et al.,
2003) is a variant of the PageRank algorithm in which
extra importance is assigned to certain vertices in the
graph. This is achieved by adjusting the values of
the vector v in equation 1 to prefer certain nodes.
The values in v effectively initialises the graph and
assigning high values to nodes in v makes them more
likely to be assigned a high PPR score.
For each context feature c in C if c E LM where
LM contains all the lemma names of synsets in S,
we apply PPR to assign importance to synsets. The
score of each synset Sc in the personalisation vector
v, is set to 1
|Sc |where |Sc |is the number of synsets
that context feature i belongs. The personalisation
value of all the other sysnets is set to 0.
We apply PPR over WordNet for each context
feature using UKB (Agirre et al., 2009) and obtain
weights for each synset-context feature pair resulting
to a new semantic space Hp, S x C, where vector
elements are weighted by PageRank values. Figure 2
shows how the synset scores are computed by ap-
plying PPR over WordNet given the context feature
car. Note that we use the context features of the
distributional model D.
</bodyText>
<subsectionHeader confidence="0.999819">
2.3 Latent Semantic Analysis
</subsectionHeader>
<bodyText confidence="0.999327375">
Latent Semantic Analysis (LSA) (Deerwester et al.,
1990; Landauer and Dumais, 1997) has been used to
reduce the dimensionality of semantic spaces lead-
ing to improved performance. LSA applies Sin-
gular Value Decomposition (SVD) to a matrix X,
W x C, which represents a distributional semantic
space. This is a form of factor analysis where X is
decomposed into three other matrices:
</bodyText>
<equation confidence="0.998188">
X = UEVT (2)
</equation>
<bodyText confidence="0.999980888888889">
where U is a W x W matrix of row vectors where its
columns are eigenvectors of XXT, E is a diagonal
W x C matrix containing the singular values and V
is a C x C matrix of context feature vectors where
its columns are eigenvectors of XT X. The multi-
plication of the three component matrices results in
the original matrix, X. Any matrix can be decom-
posed perfectly if the number of singular values is
no smaller than the smallest dimension of X. When
</bodyText>
<page confidence="0.986931">
22
</page>
<figure confidence="0.996787875">
Personalisation Vector Synset Scores
.2
.03
0
.01
.2
.02
.2
...
PPR
.02
...
0
.02
.2
.03
.2
.04
car.n.01
car.n.03
car
car.n.02
car.n.04
car.n.05
</figure>
<figureCaption confidence="0.930566666666667">
Figure 2: In the Synset Rank Model, each synset (grey boxes) is assigned with a score by computing PPR
over WordNet. The personalisation vector (grey array) is initialised by assigning probabilities only to the
synsets that include the context feature as a lemma name.
</figureCaption>
<bodyText confidence="0.995595166666667">
fewer singular values are used then the matrix prod-
uct is an approximation of the original matrix. LSA
reduces the dimensionality of the SVD by deleting
coefficients in the diagonal matrix E starting with the
smallest. The approximation of matrix X retaining
the K largest singular values, ˜X, is then given by:
</bodyText>
<equation confidence="0.9989735">
X˜ ≈ UKEKV T (3)
K
</equation>
<bodyText confidence="0.9999405">
where UK is a W x K matrix of word vectors, EK
is a K x K diagonal matrix with singular values and
VK is a K x C matrix of context feature vectors.
We apply LSA on the Synset Distributional Model,
H and the Synset Rank model, Hp to obtained the
reduced semantic spaces H˜ and ˜Hp respectively.
</bodyText>
<subsectionHeader confidence="0.996231">
2.4 Joint Representation using CCA
</subsectionHeader>
<bodyText confidence="0.9999712">
Recent work has demonstrated that distributional
models can benefit from combining alternative views
of data (see Section 5). H and Hp provide two dif-
ferent views of the synsets and we incorporate evi-
dence from both to learn a joint representation using
Canonical Correlation Analysis (CCA) (Hardoon et
al., 2004). Given two multidimensional variables x
and y, CCA finds two projection vectors by max-
imising the correlations of the variables onto these
projections. The function to be maximised is:
</bodyText>
<equation confidence="0.993800666666667">
E[xy]
ρ = � (4)
E[x2]E[y2]
</equation>
<bodyText confidence="0.999941">
The dimensionality of the projection vectors is lower
or equal to the dimensionality of the original vari-
ables.
The computation of CCA directly over H and Hp
is computationally infeasible because of their high
dimensionality (300K). We apply CCA over the re-
duced spaces learned using LSA, H˜ and ˜Hp to ob-
tain two joint semantic spaces following a similar
approach to Faruqui and Dyer (2014). These are
the spaces H*, resulting from the projection of the
Synset Distributional Model ˜H, and Hp*, resulting
from the projection of the Synset Rank Model ˜Hp.
</bodyText>
<sectionHeader confidence="0.997139" genericHeader="method">
3 Word Similarity
</sectionHeader>
<subsectionHeader confidence="0.999971">
3.1 Computing Similarity
</subsectionHeader>
<bodyText confidence="0.999972333333333">
Since hybrid models represent words as synset vec-
tors, similarity between two words can be computed
following two ways. First, we compute similarity be-
tween two words as the maximum of their pairwise
synset similarity. On the other hand, similarity can be
computed as the average pairwise synset similarity
using the synsets that the two words belong. Similar-
ity is computed as the cosine of the angle between
word or synset vectors.
</bodyText>
<subsectionHeader confidence="0.989536">
3.2 Data
</subsectionHeader>
<bodyText confidence="0.991512">
We make use of six standard data sets that have been
widely used for evaluating lexical similarity and relat-
</bodyText>
<page confidence="0.991663">
23
</page>
<table confidence="0.9939585">
Max
Model WS-353 WS-Sim WS-Rel RG MC MEN
Distributional Model
D 0.62 0.70 0.59 0.79 0.72 0.72
Hybrid Models - Full
H 0.49 0.60 0.36 0.69 0.64 0.58
Hp 0.58 0.67 0.49 0.82 0.86 0.63
Hybrid Models - LSA
H˜ 0.55 0.69 0.42 0.71 0.71 0.54
˜Hp 0.58 0.68 0.46 0.85 0.86 0.55
Hybrid Models - CCA
H∗ 0.67 0.76 0.57 0.81 0.79 0.72
H∗ 0.52 0.62 0.41 0.86 0.80 0.56
p
</table>
<tableCaption confidence="0.99985">
Table 1: Spearman’s correlation on various data sets. Maximum similarity between pairs of synsets.
</tableCaption>
<bodyText confidence="0.997163153846154">
edness. First, we make use of WS-353 (Finkelstein
et al., 2001) which contains 353 pairs of words an-
notated by humans. Furthermore, we make use of
the similarity (WS-Sim) and relatedness (WS-Rel)
pairs of words created by Agirre et al. (2009) from
the original WS-353 data set.
We also made use of the RG (Rubenstein and
Goodenough, 1965) and MC (Miller and Charles,
1991) data sets which contain 65 and 30 pairs of
nouns respectively. Finally, we make use of the larger
MEN data set (Bruni et al., 2012) which contains
3,000 pairs of words that has been used as image
tags. Annotations are obtained using croudsourcing.
</bodyText>
<subsectionHeader confidence="0.999256">
3.3 Model Parameters
</subsectionHeader>
<bodyText confidence="0.997022454545455">
The parameters we need to tune are the number of
the top components in LSA spaces, H˜ and ˜Hp, and
CCA spaces, H∗ and H∗p. For the LSA spaces, we
tune the number of the top k components in RG. We
set k E {50,100,..., 1000} and select the value that
maximises performance which is k = 700 for H˜ and
k = 650 for ˜Hp. For the joint spaces learned using
CCA, we also tune the number of the top l correlated
features in RG. We set l E {10, 20,..., 650} and
select the value that maximises performance which
is l = 250 for H∗ and l = 40 for H∗p.
</bodyText>
<subsectionHeader confidence="0.899492">
3.4 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999062142857143">
Performance is measured as the correlation between
the similarity scores returned by each proposed
method and the human judgements. This is the stan-
dard approach to evaluate word and text similarity
tasks, e.g. (Budanitsky and Hirst, 2001; Agirre et
al., 2009; Agirre et al., 2012). Our experiments use
Spearman’s correlation coefficient.
</bodyText>
<sectionHeader confidence="0.862997" genericHeader="method">
3.5 Results
</sectionHeader>
<bodyText confidence="0.999060076923077">
Table 1 shows the Spearman’s correlation of simi-
larity scores generated by each model and human
judgements of similarity across various data sets by
taking the maximum pairwise similarity score of two
words’ synsets. The first row of the table shows the
results obtained by the word distributional model
of Baroni et al. (2014). The full hybrid models H
and Hp perform consistently worse than the orig-
inal distributional model D across data sets. The
main reason is that a large number of synsets contain
only one lemma name which might be polysemous.
For example, the only lemma name of the synsets
‘ball.n.01’ (‘round object that is hit or thrown or
</bodyText>
<page confidence="0.998482">
24
</page>
<table confidence="0.989981357142857">
Average
Model WS-353 WS-Sim WS-Rel RG MC MEN
Distributional Model
D 0.62 0.70 0.59 0.79 0.72 0.72
Hybrid Models - Full
H 0.61 0.71 0.52 0.72 0.65 0.64
Hp 0.65 0.73 0.56 0.79 0.81 0.58
Hybrid Models - LSA
H˜ 0.59 0.70 0.48 0.68 0.68 0.63
˜Hp 0.65 0.73 0.56 0.81 0.86 0.58
Hybrid Models - CCA
H* 0.70 0.77 0.64 0.78 0.84 0.74
H* 0.61 0.69 0.52 0.72 0.76 0.62
p
</table>
<tableCaption confidence="0.999247">
Table 2: Spearman’s correlation on various data sets. Average pairwise similarity between pairs of synsets.
</tableCaption>
<bodyText confidence="0.9959955">
kicked in games’) and ‘ball.n.04’ (‘the people as-
sembled at a lavish formal dance’) is ‘ball’. In this
case, the synset vector in H and the lemma vector in
D are identical and still polysemous. This problem
does not hold in Hp and therefore the correlations
are higher for that semantic space but still lower than
those obtained for D. Applying LSA on H and Hp
improves results but correlations are still lower than
those obtained using D2. On the other hand, the
joint space learned by applying CCA, H*, produces
consistently better similarity estimates than D while
outperforms all the other models in the majority of
the data sets. That confirms our main assumption
than incorporating information obtained from a large
corpus and a knowledge-base improves word vector
representations.
Table 2 shows the Spearman’s correlation of sim-
ilarity scores generated by each model and human
judgements of similarity across various data sets by
taking the average pairwise similarity score of two
words’ synsets. Results show that using the average
rather than the maximum system similarity improves
results for almost all data sets. For example, the best
2Note that Baroni et al. (2014) found that applying SVD to
D did not improve performance over using the full space.
hybrid model, H*, achieves correlations that are be-
tween 2% and 12% than D for the majority of data
sets, although performance is 1% lower for the RG
data set. This improved performance suggest that hu-
man judgements of word similarity are based on the
relation between all the senses of two given words
rather than just the most similar ones.
</bodyText>
<sectionHeader confidence="0.982199" genericHeader="method">
4 Word Sense Disambiguation
</sectionHeader>
<subsectionHeader confidence="0.96759">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999843166666667">
We test the efficiency of our hybrid models on the
English All Words tasks of Senseval-2 (Palmer et
al., 2001) and Senseval-3 (Snyder and Palmer, 2004),
two standard data sets for evaluating WSD. Our ex-
periments focus on the disambiguation of nouns in
these data sets.
</bodyText>
<subsectionHeader confidence="0.99536">
4.2 Word Sense Tagging
</subsectionHeader>
<bodyText confidence="0.993258">
A simple approach to all-words WSD was imple-
mented in which each sense of an ambiguous word
is compared against its context and the most similar
chosen.
For example suppose that we want to disambiguate
</bodyText>
<page confidence="0.995338">
25
</page>
<table confidence="0.999907333333333">
Nouns Senseval-2 Senseval-3
Precision Recall Precision Recall
Hybrid Models - Full
H 0.46 0.45 0.37 0.36
Hp 0.65 0.63 0.50 0.48
Hybrid Models - LSA
H˜ 0.45 0.44 0.39 0.37
˜Hp 0.60 0.58 0.46 0.45
Hybrid Models - CCA
H* 0.44 0.43 0.36 0.34
H* 0.61 0.60 0.48 0.46
p
</table>
<tableCaption confidence="0.999944">
Table 3: Results obtained by hybrid models on SenseEval-2 and SenseEval-3 data sets (nouns only).
</tableCaption>
<bodyText confidence="0.9756341875">
the word bank in the following sentence:
“Banks provide payment services.”
Assume that the word bank consists of two senses
‘bank.n.01’ and bank.n.02 defined as ‘sloping land
(especially the slope beside a body of water)’ and “a
financial institution that accepts deposits and chan-
nels the money into lending activities’ respectively.
First we consider the vectors of all the possible
noun synsets containing the word bank as a synset
name. Then for each context word (provide, payment
and service) that exists in our semantics spaces we
compute a centroid vector from its constituent senses.
Finally, we compute a context vector for the entire
context by summing up all the context word vectors.
We select the synset of the target word that its vector
has the highest cosine similarity to the context vector.
</bodyText>
<subsectionHeader confidence="0.999822">
4.3 Model Parameters
</subsectionHeader>
<bodyText confidence="0.99992675">
The parameters we need to tune are the same as for
the word similarity task and we use the best settings
obtained for that task. We also experimented with
varying the number of surrounding sentences used
as context by testing values between ±1 and ±4.
The best performance was obtained using a context
created from the sentence containing the target word
and ±1 sentences surrounding it.
</bodyText>
<subsectionHeader confidence="0.997909">
4.4 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999889333333333">
Word sense disambiguation systems are evaluated by
computing precision and recall. Precision measures
the proportion of disambiguated words that have been
correctly assigned with a sense. Recall measures the
proportion of words disambiguated correctly out of
all words available for disambiguation.
</bodyText>
<subsectionHeader confidence="0.672878">
4.5 Results
</subsectionHeader>
<bodyText confidence="0.999924789473684">
Table 3 shows the results obtained by using our hy-
brid models on the two word sense disambiguation
data sets. The full Synset Rank model Hp is consis-
tently better method in terms of precision and recall
in both data sets. On the other hand, it is somewhat
surprising that dimensionality reduction and integra-
tion of semantic spaces do not help in improving
performance. That is the ˜Hp and H*p models achieve
lower precision and recall than the fuller Hp.
The Synset Distributional models H, H˜ and H*
consistently fail to perform well. The difference in
precision and recall compared to the Synset Rank
models is between 12% and 19%. This suggests that
the knowledge-based weighting of the context fea-
tures generates less noisy vectors for sense tagging.
The pattern of results observed for the WSD task
is somewhat different to those obtained for word
similarity, where applying LSA and CCA improved
performance (see Section 3). The most likely expla-
</bodyText>
<page confidence="0.897924">
26
</page>
<bodyText confidence="0.99796614893617">
nation of this difference is that WSD requires the Dyer (2014) found that learning joint spaces from
model to represent the possible senses of each am- multilingual vector spaces using CCA improves the
biguous word. It is also important that these senses performance of standard monolingual vector spaces
correspond to the ones used in the relevant lexicon on semantic similarity. Fyshe et al. (2014) showed
(WordNet in this case). The Synset Rank model Hp that integrating textual vector space models with
does this by making use of information from Word- brain activation data when people are reading words
Net. However, these synset representations are dis- achieves better correlation to behavioural data than
rupted by LSA and CCA which compress the seman- models of one modality.
tic space by extracting general features from them. Our hybrid models are also closely related to a
This is not a problem for word similarity since there supervised method proposed by Faruqui et al. (2015).
is no need to model the senses found in the lexicon. Their method refines distributional semantic mod-
5 Related Work els using relational information from various seman-
Dealing with polysemy in distributional semantics tic lexicons, including WordNet, by making linked
is a fundamental issue since the various senses of a words in these lexicons to have similar vector repre-
word type are conflated in a single vector. Previous sentations. While our models are also based on using
work tackled the problem through vector adaptation, information from WordNet for refining vector repre-
clustering and language models (Erk, 2012). Vector sentations, they are fundamentally different. They
adaptation methods modify a traditional (i.e. poly- create synset vectors in an unsupervised fashion and
semous) target word vector by applying pointwise more importantly can be used for sense tagging.
operations such as addition or multiplication to that 6 Conclusions
and the surrounding words in a sentence (Mitchell This paper proposed hybrid models of lexical seman-
and Lapata, 2008; Erk and Pad´o, 2008; Thater et tics that combine distributional and knowledge-based
al., 2011; Van de Cruys et al., 2011). Alternatively, approaches and offer advantages of both techniques.
clustering methods have been used to cluster together A standard distributional semantic model is created
the different contexts a target word appears assum- from an unannotated corpus and then refined by (1)
ing that each cluster of contexts captures a different using WordNet synsets to create synset vectors; and
sense of the target word (Dinu and Lapata, 2010; (2) applying a graph-based technique over WordNet
Erk and Pado, 2010; Reisinger and Mooney, 2010). to reweight synset vectors. The resulting hybrid mod-
Language models have also been used to remove pol- els can be viewed as enhanced distributional models
ysemy from word vectors by predicting words that using the information from WordNet to reduce the
could replace the target word given a context (De- problems caused by ambiguous terms when models
schacht and Moens, 2009; Washtell, 2010; Moon are created. Results show that our models perform
and Erk, 2013). More recently, Polajnar and Clark better than traditional distributional models on lex-
(2014) applied context selection and normalisation ical similarity tasks. Unlike standard distributional
to improve the quality of word vectors. Our hybrid approaches the techniques proposed here also model
models are related to the vector adaptation methods polysemy and can be used to carry out word sense
since we modify the synset vectors using its lemmas’ disambiguation.
vectors to remove noise. References
Our work is also inspired by recent work on im- Eneko Agirre and Aitor Soroa. 2009. Personalizing
proving classic distributional vector representations PageRank for word sense disambiguation. In Proceed-
of words by incorporating information from different ings of the 12th Conference of the European Chapter of
modalities. For example, researchers have devel- the Association for Computational Linguistics (EACL
oped methods that make use of both visual and con- ’09), pages 33–41, Athens, Greece.
textual information to improve word vectors (Bruni Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kraval-
et al., 2011; Silberer et al., 2013; Lazaridou et al., ova, Marius Pasca, and Aitor Soroa. 2009. A study
2014). Following a similar direction, Faruqui and
27
</bodyText>
<note confidence="0.571578333333333">
on similarity and relatedness using distributional and
wordnet-based approaches. In Proceedings of Human
Language Technologies: The 2009 Annual Conference
</note>
<reference confidence="0.996422774509804">
of the North American Chapter of the Association for
Computational Linguistics (NAACL-HLT ’09), pages
19–27, Boulder, Colorado.
Eneko Agirre, Mona Diab, Daniel Cer, and Aitor
Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot
on semantic textual similarity. In Proceedings of the
First Joint Conference on Lexical and Computational
Semantics-Volume 1: Proceedings of the main confer-
ence and the shared task, and Volume 2: Proceedings
of the Sixth International Workshop on Semantic Eval-
uation, pages 385–393. Association for Computational
Linguistics.
Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski.
2014. Don’t count, predict! a systematic comparison of
context-counting vs. context-predicting semantic vec-
tors. In Proceedings of the 52nd Annual Meeting of the
Association for Computational Linguistics (Volume 1:
Long Papers), pages 238–247, Baltimore, Maryland.
Elia Bruni, Giang Binh Tran, and Marco Baroni. 2011.
Distributional semantics from text and images. In Pro-
ceedings of the Workshop on GEometrical Models of
Natural Language Semantics (GEMS ’11), pages 22–
32, Edinburgh, UK, July.
Elia Bruni, Gemma Boleda, Marco Baroni, and Nam-
Khanh Tran. 2012. Distributional semantics in techni-
color. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics: Long
Papers-Volume 1, pages 136–145, Jeju Island, Korea.
Alexander Budanitsky and Graeme Hirst. 2001. Semantic
distance in WordNet: An experimental, application-
oriented evaluation of five measures. In Proceedings of
the workshop on “WordNet and other Lexical Resources”
at the Second Annual Meeting of the North American
Association for Computational Linguistics, Pittsburgh,
PA.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41(6):391–
407.
Koen Deschacht and Marie-Francine Moens. 2009. Semi-
supervised semantic role labeling using the Latent
Words Language Model. In Proceedings of the 2009
Conference on Empirical Methods in Natural Language
Processing, pages 21–29, Singapore.
Georgiana Dinu and Mirella Lapata. 2010. Measuring
distributional similarity in context. In Proceedings of
the 2010 Conference on Empirical Methods in Natural
Language Processing, pages 1162–1172, Cambridge,
MA.
Katrin Erk and Sebastian Pad´o. 2008. A structured vector
space model for word meaning in context. In Proceed-
ings of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 897–906, Hon-
olulu, Hawaii.
Katrin Erk and Sebastian Pado. 2010. Exemplar-based
models for word meaning in context. In Proceedings of
the ACL 2010 Conference Short Papers, pages 92–97,
Uppsala, Sweden.
Katrin Erk. 2012. Vector space models of word meaning
and phrase meaning: A survey. Language and Linguis-
tics Compass, 6(10):635–653.
Manaal Faruqui and Chris Dyer. 2014. Improving vector
space word representations using multilingual correla-
tion. In Proceedings of the 14th Conference of the Eu-
ropean Chapter of the Association for Computational
Linguistics, pages 462–471, Gothenburg, Sweden.
Manaal Faruqui, Jesse Dodge, Sujay K Jauhar, Chris Dyer,
Eduard Hovy, and Noah A Smith. 2015. Retrofitting
word vectors to semantic lexicons. In Proceedings of
the 2015 Conference of NAACL, Denver, Colorado.
C. Fellbaum, editor. 1998. WordNet: An Electronic Lexi-
cal Database. The MIT Press, Cambridge, MA, Lon-
don.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud
Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin.
2001. Placing search in context: The concept revisited.
In Proceedings of the 10th international conference
on World Wide Web, pages 406–414, New York, USA.
ACM Press.
J. Firth. 1957. A synopsis of linguistic theory 1930-1955.
In Studies in Linguistic Analysis.
Alona Fyshe, Partha P. Talukdar, Brian Murphy, and
Tom M. Mitchell. 2014. Interpretable semantic vectors
from a joint model of brain- and text- based meaning.
In Proceedings of the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume 1: Long
Papers), pages 489–499, Baltimore, Maryland.
David Hardoon, Sandor Szedmak, and John Shawe-Taylor.
2004. Canonical correlation analysis: An overview
with application to learning methods. Neural computa-
tion, 16(12):2639–2664.
Z. Harris. 1985. Distributional structure. In J. Katz,
editor, The Philosophy of Linguistics, pages 26–47.
Oxford University Press, New York.
Taher Haveliwala, Sepandar Kamvar, and Glen Jeh. 2003.
An analytical comparison of approaches to personal-
izing PageRank. Technical Report 2003-35, Stanford
InfoLab.
N. Ide and J. V´eronis. 1998. Introduction to the special
issue on word sense disambiguation: The state of the
art. Computational Linguistics, 24(1):1–40.
</reference>
<page confidence="0.977019">
28
</page>
<reference confidence="0.999351325">
Thomas K Landauer and Susan T Dumais. 1997. A so-
lution to plato’s problem: The latent semantic analysis
theory of acquisition, induction, and representation of
knowledge. Psychological review, 104(2):211.
Angeliki Lazaridou, Elia Bruni, and Marco Baroni. 2014.
Is this a wampimuk? cross-modal mapping between
distributional semantics and the visual world. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 1403–1414, Baltimore, Maryland.
Rada Mihalcea and Paul Tarau. 2004. TextRank: Bring-
ing order into texts. In Proceedings of International
Conference on Empirical Methods in Natural Language
Processing (EMNLP ’04), pages 404–411, Barcelona,
Spain.
George A Miller and Walter G Charles. 1991. Contex-
tual correlates of semantic similarity. Language and
cognitive processes, 6(1):1–28.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In Proceedings of
ACL-08: HLT, pages 236–244, Columbus, Ohio.
Taesun Moon and Katrin Erk. 2013. An inference-based
model of word meaning in context as a paraphrase
distribution. ACM Transactions on Intelligent Systems
and Technology (TIST), 4(3):42.
Roberto Navigli. 2009. Word Sense Disambiguation: a
survey. ACM Computing Surveys, 41(2):1–69.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The PageRank citation ranking:
Bringing order to the web. Technical Report 1999-66,
Stanford InfoLab.
Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren
Delfs, and Hoa Trang Dang. 2001. English tasks: All-
words and verb lexical sample. In The Proceedings of
the Second International Workshop on Evaluating Word
Sense Disambiguation Systems, pages 21–24, Toulouse,
France.
Tamara Polajnar and Stephen Clark. 2014. Improving
distributional semantic vectors through context selec-
tion and normalisation. In Proceedings of the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 230–238,
Gothenburg, Sweden. Association for Computational
Linguistics.
Joseph Reisinger and Raymond J. Mooney. 2010. Multi-
prototype vector-space models of word meaning. In
Human Language Technologies: The 2010 Annual Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics, pages 109–117,
Los Angeles, California.
Herbert Rubenstein and John B Goodenough. 1965. Con-
textual correlates of synonymy. Communications of the
ACM, 8(10):627–633.
Carina Silberer, Vittorio Ferrari, and Mirella Lapata.
2013. Models of semantic representation with visual at-
tributes. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Volume
1: Long Papers), pages 572–582, Sofia, Bulgaria.
Benjamin Snyder and Martha Palmer. 2004. The en-
glish all-words task. In Senseval-3: Third International
Workshop on the Evaluation of Systems for the Semantic
Analysis of Text, pages 41–43, Barcelona, Spain.
Stefan Thater, Hagen F¨urstenau, and Manfred Pinkal.
2011. Word meaning in context: A simple and effective
vector model. In Proceedings of 5th International Joint
Conference on Natural Language Processing, pages
1134–1143, Chiang Mai, Thailand.
Peter D. Turney and Patrick Pantel. 2010. From frequency
to meaning: Vector space models of semantics. Journal
of Artificial Intelligence Research, 37:141–188.
Tim Van de Cruys, Thierry Poibeau, and Anna Korhonen.
2011. Latent vector weighting for word meaning in
context. In Proceedings of the 2011 Conferenceon
Empirical Methods in Natural Language Processing,
pages 1012–1022, Edinburgh, Scotland, UK.
Justin Washtell. 2010. Expectation vectors: A semiotics
inspired approach to geometric lexical-semantic rep-
resentation. In Proceedings of the 2010 Workshop on
GEometrical Models of Natural Language Semantics
(GEMS), pages 45–50, Uppsala, Sweden.
</reference>
<page confidence="0.999099">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.076124">
<title confidence="0.997139">A Hybrid Distributional and Knowledge-based Model of Lexical Semantics</title>
<author confidence="0.962305">Nikolaos</author>
<affiliation confidence="0.9998215">Department of Computer University College</affiliation>
<note confidence="0.639394">Gower London WC1E United</note>
<email confidence="0.965396">nikos.aletras@gmail.com</email>
<author confidence="0.996373">Mark</author>
<affiliation confidence="0.99075">Department of Computer University of</affiliation>
<note confidence="0.462281333333333">Regent Court, 211 Sheffield S1 United</note>
<email confidence="0.859679">mark.stevenson@sheffield.ac.uk</email>
<abstract confidence="0.995788111111111">A range of approaches to the representation of lexical semantics have been explored within Computational Linguistics. Two of the most popular are distributional and knowledgebased models. This paper proposes hybrid models of lexical semantics that combine the advantages of these two approaches. Our models provide robust representations of synonymous words derived from WordNet. We also make use of WordNet’s hierarcy to refine the synset vectors. The models are evaluated on two widely explored tasks involving lexical semantics: lexical similarity and Word Sense Disambiguation. The hybrid models are found to perform better than standard distributional models and have the additional benefit of modelling polysemy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date></date>
<journal>of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT</journal>
<volume>09</volume>
<pages>pages</pages>
<location>Boulder, Colorado.</location>
<marker></marker>
<rawString>of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT ’09), pages 19–27, Boulder, Colorado.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eneko Agirre</author>
<author>Mona Diab</author>
<author>Daniel Cer</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>Semeval-2012 task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation,</booktitle>
<pages>385--393</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15862" citStr="Agirre et al., 2012" startWordPosition="2651" endWordPosition="2654">nd select the value that maximises performance which is k = 700 for H˜ and k = 650 for ˜Hp. For the joint spaces learned using CCA, we also tune the number of the top l correlated features in RG. We set l E {10, 20,..., 650} and select the value that maximises performance which is l = 250 for H∗ and l = 40 for H∗p. 3.4 Evaluation Metric Performance is measured as the correlation between the similarity scores returned by each proposed method and the human judgements. This is the standard approach to evaluate word and text similarity tasks, e.g. (Budanitsky and Hirst, 2001; Agirre et al., 2009; Agirre et al., 2012). Our experiments use Spearman’s correlation coefficient. 3.5 Results Table 1 shows the Spearman’s correlation of similarity scores generated by each model and human judgements of similarity across various data sets by taking the maximum pairwise similarity score of two words’ synsets. The first row of the table shows the results obtained by the word distributional model of Baroni et al. (2014). The full hybrid models H and Hp perform consistently worse than the original distributional model D across data sets. The main reason is that a large number of synsets contain only one lemma name which</context>
</contexts>
<marker>Agirre, Diab, Cer, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Mona Diab, Daniel Cer, and Aitor Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot on semantic textual similarity. In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, pages 385–393. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Georgiana Dinu</author>
<author>Germ´an Kruszewski</author>
</authors>
<title>Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>238--247</pages>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="5541" citStr="Baroni et al., 2014" startWordPosition="843" endWordPosition="846">ic space to represent words as vectors (Section 2.1). Then, we make use of the WordNet’s clusters of synonyms and hierarchy in combination with the standard distributional space to build hybrid models (Section 2.2) which are augmented using Latent Semantic Analysis (Section 2.3) and Canonical Correlation Analysis (Section 2.4). 2.1 Distributional Model We consider a semantic space D, as a word by context feature matrix, L × C. Vector representations consist of context features C in a reference corpus. We made use of pre-computed publicly available vectors1 optimised for word similarity tasks (Baroni et al., 2014). Word co-occurrence counts are extracted using a symmetric window of two words over a corpus of 2.8 billion tokens obtained by concatenating 1http://clic.cimec.unitn.it/composes/ semantic-vectors.html ukWaC, the English Wikipedia and the British National Corpus. Vectors are weighted using positive Pointwise Mutual Information and the set of context features consists of the top 300K most frequent words in the corpus. 2.2 Hybrid Models 2.2.1 Synset Distributional Model We assume that making use of information about the structure of WordNet can reduce noise introduced in vectors of D due to poly</context>
<context position="16259" citStr="Baroni et al. (2014)" startWordPosition="2713" endWordPosition="2716">ilarity scores returned by each proposed method and the human judgements. This is the standard approach to evaluate word and text similarity tasks, e.g. (Budanitsky and Hirst, 2001; Agirre et al., 2009; Agirre et al., 2012). Our experiments use Spearman’s correlation coefficient. 3.5 Results Table 1 shows the Spearman’s correlation of similarity scores generated by each model and human judgements of similarity across various data sets by taking the maximum pairwise similarity score of two words’ synsets. The first row of the table shows the results obtained by the word distributional model of Baroni et al. (2014). The full hybrid models H and Hp perform consistently worse than the original distributional model D across data sets. The main reason is that a large number of synsets contain only one lemma name which might be polysemous. For example, the only lemma name of the synsets ‘ball.n.01’ (‘round object that is hit or thrown or 24 Average Model WS-353 WS-Sim WS-Rel RG MC MEN Distributional Model D 0.62 0.70 0.59 0.79 0.72 0.72 Hybrid Models - Full H 0.61 0.71 0.52 0.72 0.65 0.64 Hp 0.65 0.73 0.56 0.79 0.81 0.58 Hybrid Models - LSA H˜ 0.59 0.70 0.48 0.68 0.68 0.63 ˜Hp 0.65 0.73 0.56 0.81 0.86 0.58 H</context>
<context position="18233" citStr="Baroni et al. (2014)" startWordPosition="3051" endWordPosition="3054"> D while outperforms all the other models in the majority of the data sets. That confirms our main assumption than incorporating information obtained from a large corpus and a knowledge-base improves word vector representations. Table 2 shows the Spearman’s correlation of similarity scores generated by each model and human judgements of similarity across various data sets by taking the average pairwise similarity score of two words’ synsets. Results show that using the average rather than the maximum system similarity improves results for almost all data sets. For example, the best 2Note that Baroni et al. (2014) found that applying SVD to D did not improve performance over using the full space. hybrid model, H*, achieves correlations that are between 2% and 12% than D for the majority of data sets, although performance is 1% lower for the RG data set. This improved performance suggest that human judgements of word similarity are based on the relation between all the senses of two given words rather than just the most similar ones. 4 Word Sense Disambiguation 4.1 Data We test the efficiency of our hybrid models on the English All Words tasks of Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder a</context>
</contexts>
<marker>Baroni, Dinu, Kruszewski, 2014</marker>
<rawString>Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski. 2014. Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 238–247, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elia Bruni</author>
<author>Giang Binh Tran</author>
<author>Marco Baroni</author>
</authors>
<title>Distributional semantics from text and images.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on GEometrical Models of Natural Language Semantics (GEMS ’11),</booktitle>
<pages>22--32</pages>
<location>Edinburgh, UK,</location>
<marker>Bruni, Tran, Baroni, 2011</marker>
<rawString>Elia Bruni, Giang Binh Tran, and Marco Baroni. 2011. Distributional semantics from text and images. In Proceedings of the Workshop on GEometrical Models of Natural Language Semantics (GEMS ’11), pages 22– 32, Edinburgh, UK, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elia Bruni</author>
<author>Gemma Boleda</author>
<author>Marco Baroni</author>
<author>NamKhanh Tran</author>
</authors>
<title>Distributional semantics in technicolor.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>136--145</pages>
<location>Jeju Island,</location>
<contexts>
<context position="14880" citStr="Bruni et al., 2012" startWordPosition="2469" endWordPosition="2472">.86 0.80 0.56 p Table 1: Spearman’s correlation on various data sets. Maximum similarity between pairs of synsets. edness. First, we make use of WS-353 (Finkelstein et al., 2001) which contains 353 pairs of words annotated by humans. Furthermore, we make use of the similarity (WS-Sim) and relatedness (WS-Rel) pairs of words created by Agirre et al. (2009) from the original WS-353 data set. We also made use of the RG (Rubenstein and Goodenough, 1965) and MC (Miller and Charles, 1991) data sets which contain 65 and 30 pairs of nouns respectively. Finally, we make use of the larger MEN data set (Bruni et al., 2012) which contains 3,000 pairs of words that has been used as image tags. Annotations are obtained using croudsourcing. 3.3 Model Parameters The parameters we need to tune are the number of the top components in LSA spaces, H˜ and ˜Hp, and CCA spaces, H∗ and H∗p. For the LSA spaces, we tune the number of the top k components in RG. We set k E {50,100,..., 1000} and select the value that maximises performance which is k = 700 for H˜ and k = 650 for ˜Hp. For the joint spaces learned using CCA, we also tune the number of the top l correlated features in RG. We set l E {10, 20,..., 650} and select th</context>
</contexts>
<marker>Bruni, Boleda, Baroni, Tran, 2012</marker>
<rawString>Elia Bruni, Gemma Boleda, Marco Baroni, and NamKhanh Tran. 2012. Distributional semantics in technicolor. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 136–145, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Semantic distance in WordNet: An experimental, applicationoriented evaluation of five measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the workshop on “WordNet and other Lexical Resources” at the Second Annual Meeting of the North American Association for Computational Linguistics,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="15819" citStr="Budanitsky and Hirst, 2001" startWordPosition="2643" endWordPosition="2646">components in RG. We set k E {50,100,..., 1000} and select the value that maximises performance which is k = 700 for H˜ and k = 650 for ˜Hp. For the joint spaces learned using CCA, we also tune the number of the top l correlated features in RG. We set l E {10, 20,..., 650} and select the value that maximises performance which is l = 250 for H∗ and l = 40 for H∗p. 3.4 Evaluation Metric Performance is measured as the correlation between the similarity scores returned by each proposed method and the human judgements. This is the standard approach to evaluate word and text similarity tasks, e.g. (Budanitsky and Hirst, 2001; Agirre et al., 2009; Agirre et al., 2012). Our experiments use Spearman’s correlation coefficient. 3.5 Results Table 1 shows the Spearman’s correlation of similarity scores generated by each model and human judgements of similarity across various data sets by taking the maximum pairwise similarity score of two words’ synsets. The first row of the table shows the results obtained by the word distributional model of Baroni et al. (2014). The full hybrid models H and Hp perform consistently worse than the original distributional model D across data sets. The main reason is that a large number o</context>
</contexts>
<marker>Budanitsky, Hirst, 2001</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2001. Semantic distance in WordNet: An experimental, applicationoriented evaluation of five measures. In Proceedings of the workshop on “WordNet and other Lexical Resources” at the Second Annual Meeting of the North American Association for Computational Linguistics, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan T Dumais</author>
<author>George W Furnas</author>
<author>Thomas K Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<pages>407</pages>
<contexts>
<context position="10377" citStr="Deerwester et al., 1990" startWordPosition="1677" endWordPosition="1680">is the number of synsets that context feature i belongs. The personalisation value of all the other sysnets is set to 0. We apply PPR over WordNet for each context feature using UKB (Agirre et al., 2009) and obtain weights for each synset-context feature pair resulting to a new semantic space Hp, S x C, where vector elements are weighted by PageRank values. Figure 2 shows how the synset scores are computed by applying PPR over WordNet given the context feature car. Note that we use the context features of the distributional model D. 2.3 Latent Semantic Analysis Latent Semantic Analysis (LSA) (Deerwester et al., 1990; Landauer and Dumais, 1997) has been used to reduce the dimensionality of semantic spaces leading to improved performance. LSA applies Singular Value Decomposition (SVD) to a matrix X, W x C, which represents a distributional semantic space. This is a form of factor analysis where X is decomposed into three other matrices: X = UEVT (2) where U is a W x W matrix of row vectors where its columns are eigenvectors of XXT, E is a diagonal W x C matrix containing the singular values and V is a C x C matrix of context feature vectors where its columns are eigenvectors of XT X. The multiplication of </context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391– 407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Semisupervised semantic role labeling using the Latent Words Language Model.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>21--29</pages>
<marker>Deschacht, Moens, 2009</marker>
<rawString>Koen Deschacht and Marie-Francine Moens. 2009. Semisupervised semantic role labeling using the Latent Words Language Model. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 21–29, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Dinu</author>
<author>Mirella Lapata</author>
</authors>
<title>Measuring distributional similarity in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1162--1172</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="24680" citStr="Dinu and Lapata, 2010" startWordPosition="4101" endWordPosition="4104">This paper proposed hybrid models of lexical semanand Lapata, 2008; Erk and Pad´o, 2008; Thater et tics that combine distributional and knowledge-based al., 2011; Van de Cruys et al., 2011). Alternatively, approaches and offer advantages of both techniques. clustering methods have been used to cluster together A standard distributional semantic model is created the different contexts a target word appears assum- from an unannotated corpus and then refined by (1) ing that each cluster of contexts captures a different using WordNet synsets to create synset vectors; and sense of the target word (Dinu and Lapata, 2010; (2) applying a graph-based technique over WordNet Erk and Pado, 2010; Reisinger and Mooney, 2010). to reweight synset vectors. The resulting hybrid modLanguage models have also been used to remove pol- els can be viewed as enhanced distributional models ysemy from word vectors by predicting words that using the information from WordNet to reduce the could replace the target word given a context (De- problems caused by ambiguous terms when models schacht and Moens, 2009; Washtell, 2010; Moon are created. Results show that our models perform and Erk, 2013). More recently, Polajnar and Clark be</context>
</contexts>
<marker>Dinu, Lapata, 2010</marker>
<rawString>Georgiana Dinu and Mirella Lapata. 2010. Measuring distributional similarity in context. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1162–1172, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>897--906</pages>
<location>Honolulu, Hawaii.</location>
<marker>Erk, Pad´o, 2008</marker>
<rawString>Katrin Erk and Sebastian Pad´o. 2008. A structured vector space model for word meaning in context. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 897–906, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pado</author>
</authors>
<title>Exemplar-based models for word meaning in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>92--97</pages>
<location>Uppsala,</location>
<contexts>
<context position="24750" citStr="Erk and Pado, 2010" startWordPosition="4112" endWordPosition="4115">nd Pad´o, 2008; Thater et tics that combine distributional and knowledge-based al., 2011; Van de Cruys et al., 2011). Alternatively, approaches and offer advantages of both techniques. clustering methods have been used to cluster together A standard distributional semantic model is created the different contexts a target word appears assum- from an unannotated corpus and then refined by (1) ing that each cluster of contexts captures a different using WordNet synsets to create synset vectors; and sense of the target word (Dinu and Lapata, 2010; (2) applying a graph-based technique over WordNet Erk and Pado, 2010; Reisinger and Mooney, 2010). to reweight synset vectors. The resulting hybrid modLanguage models have also been used to remove pol- els can be viewed as enhanced distributional models ysemy from word vectors by predicting words that using the information from WordNet to reduce the could replace the target word given a context (De- problems caused by ambiguous terms when models schacht and Moens, 2009; Washtell, 2010; Moon are created. Results show that our models perform and Erk, 2013). More recently, Polajnar and Clark better than traditional distributional models on lex(2014) applied conte</context>
</contexts>
<marker>Erk, Pado, 2010</marker>
<rawString>Katrin Erk and Sebastian Pado. 2010. Exemplar-based models for word meaning in context. In Proceedings of the ACL 2010 Conference Short Papers, pages 92–97, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>Vector space models of word meaning and phrase meaning: A survey.</title>
<date>2012</date>
<journal>Language and Linguistics Compass,</journal>
<volume>6</volume>
<issue>10</issue>
<contexts>
<context position="2497" citStr="Erk, 2012" startWordPosition="368" endWordPosition="369">es would include multiple meanings for the word ball including the ‘event’ and ‘sports equipment’ senses. However, the fact that there are multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text. This issue has lead to significant exploration of the problem of Word Sense Disambiguation (Ide and V´eronis, 1998; Navigli, 2009). More recently distributional semantics has become a popular approach to representing lexical semantics (Turney and Pantel, 2010; Erk, 2012). These approaches are based on the premise that the semantics of lexical items can be modelled by their context (Firth, 1957; Harris, 1985). Distributional semantic models have the advantages of being robust and straightforward to create from unannotated corpora. However, problems can arise when they are used to represent the semantics of polysemous words. Distributional semantic models are generally constructed by examining the context of lexical items in unannotated corpora. But for ambiguous words, like ball, it is not clear if a particular instance of the word in a corpus refers to the ‘e</context>
<context position="23679" citStr="Erk, 2012" startWordPosition="3951" endWordPosition="3952">o model the senses found in the lexicon. Their method refines distributional semantic mod5 Related Work els using relational information from various semanDealing with polysemy in distributional semantics tic lexicons, including WordNet, by making linked is a fundamental issue since the various senses of a words in these lexicons to have similar vector repreword type are conflated in a single vector. Previous sentations. While our models are also based on using work tackled the problem through vector adaptation, information from WordNet for refining vector repreclustering and language models (Erk, 2012). Vector sentations, they are fundamentally different. They adaptation methods modify a traditional (i.e. poly- create synset vectors in an unsupervised fashion and semous) target word vector by applying pointwise more importantly can be used for sense tagging. operations such as addition or multiplication to that 6 Conclusions and the surrounding words in a sentence (Mitchell This paper proposed hybrid models of lexical semanand Lapata, 2008; Erk and Pad´o, 2008; Thater et tics that combine distributional and knowledge-based al., 2011; Van de Cruys et al., 2011). Alternatively, approaches and</context>
</contexts>
<marker>Erk, 2012</marker>
<rawString>Katrin Erk. 2012. Vector space models of word meaning and phrase meaning: A survey. Language and Linguistics Compass, 6(10):635–653.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Chris Dyer</author>
</authors>
<title>Improving vector space word representations using multilingual correlation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>462--471</pages>
<location>Gothenburg,</location>
<contexts>
<context position="13160" citStr="Faruqui and Dyer (2014)" startWordPosition="2167" endWordPosition="2170">rdoon et al., 2004). Given two multidimensional variables x and y, CCA finds two projection vectors by maximising the correlations of the variables onto these projections. The function to be maximised is: E[xy] ρ = � (4) E[x2]E[y2] The dimensionality of the projection vectors is lower or equal to the dimensionality of the original variables. The computation of CCA directly over H and Hp is computationally infeasible because of their high dimensionality (300K). We apply CCA over the reduced spaces learned using LSA, H˜ and ˜Hp to obtain two joint semantic spaces following a similar approach to Faruqui and Dyer (2014). These are the spaces H*, resulting from the projection of the Synset Distributional Model ˜H, and Hp*, resulting from the projection of the Synset Rank Model ˜Hp. 3 Word Similarity 3.1 Computing Similarity Since hybrid models represent words as synset vectors, similarity between two words can be computed following two ways. First, we compute similarity between two words as the maximum of their pairwise synset similarity. On the other hand, similarity can be computed as the average pairwise synset similarity using the synsets that the two words belong. Similarity is computed as the cosine of </context>
</contexts>
<marker>Faruqui, Dyer, 2014</marker>
<rawString>Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 462–471, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Jesse Dodge</author>
<author>Sujay K Jauhar</author>
<author>Chris Dyer</author>
<author>Eduard Hovy</author>
<author>Noah A Smith</author>
</authors>
<title>Retrofitting word vectors to semantic lexicons.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of NAACL,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="23055" citStr="Faruqui et al. (2015)" startWordPosition="3852" endWordPosition="3855">imilarity. Fyshe et al. (2014) showed (WordNet in this case). The Synset Rank model Hp that integrating textual vector space models with does this by making use of information from Word- brain activation data when people are reading words Net. However, these synset representations are dis- achieves better correlation to behavioural data than rupted by LSA and CCA which compress the seman- models of one modality. tic space by extracting general features from them. Our hybrid models are also closely related to a This is not a problem for word similarity since there supervised method proposed by Faruqui et al. (2015). is no need to model the senses found in the lexicon. Their method refines distributional semantic mod5 Related Work els using relational information from various semanDealing with polysemy in distributional semantics tic lexicons, including WordNet, by making linked is a fundamental issue since the various senses of a words in these lexicons to have similar vector repreword type are conflated in a single vector. Previous sentations. While our models are also based on using work tackled the problem through vector adaptation, information from WordNet for refining vector repreclustering and lan</context>
</contexts>
<marker>Faruqui, Dodge, Jauhar, Dyer, Hovy, Smith, 2015</marker>
<rawString>Manaal Faruqui, Jesse Dodge, Sujay K Jauhar, Chris Dyer, Eduard Hovy, and Noah A Smith. 2015. Retrofitting word vectors to semantic lexicons. In Proceedings of the 2015 Conference of NAACL, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA, London.</location>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. The MIT Press, Cambridge, MA, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eytan Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th international conference on World Wide Web,</booktitle>
<pages>406--414</pages>
<publisher>ACM Press.</publisher>
<location>New York, USA.</location>
<contexts>
<context position="14439" citStr="Finkelstein et al., 2001" startWordPosition="2391" endWordPosition="2394">make use of six standard data sets that have been widely used for evaluating lexical similarity and relat23 Max Model WS-353 WS-Sim WS-Rel RG MC MEN Distributional Model D 0.62 0.70 0.59 0.79 0.72 0.72 Hybrid Models - Full H 0.49 0.60 0.36 0.69 0.64 0.58 Hp 0.58 0.67 0.49 0.82 0.86 0.63 Hybrid Models - LSA H˜ 0.55 0.69 0.42 0.71 0.71 0.54 ˜Hp 0.58 0.68 0.46 0.85 0.86 0.55 Hybrid Models - CCA H∗ 0.67 0.76 0.57 0.81 0.79 0.72 H∗ 0.52 0.62 0.41 0.86 0.80 0.56 p Table 1: Spearman’s correlation on various data sets. Maximum similarity between pairs of synsets. edness. First, we make use of WS-353 (Finkelstein et al., 2001) which contains 353 pairs of words annotated by humans. Furthermore, we make use of the similarity (WS-Sim) and relatedness (WS-Rel) pairs of words created by Agirre et al. (2009) from the original WS-353 data set. We also made use of the RG (Rubenstein and Goodenough, 1965) and MC (Miller and Charles, 1991) data sets which contain 65 and 30 pairs of nouns respectively. Finally, we make use of the larger MEN data set (Bruni et al., 2012) which contains 3,000 pairs of words that has been used as image tags. Annotations are obtained using croudsourcing. 3.3 Model Parameters The parameters we nee</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2001. Placing search in context: The concept revisited. In Proceedings of the 10th international conference on World Wide Web, pages 406–414, New York, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930-1955.</title>
<date>1957</date>
<booktitle>In Studies in Linguistic Analysis.</booktitle>
<contexts>
<context position="2622" citStr="Firth, 1957" startWordPosition="390" endWordPosition="391">that there are multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text. This issue has lead to significant exploration of the problem of Word Sense Disambiguation (Ide and V´eronis, 1998; Navigli, 2009). More recently distributional semantics has become a popular approach to representing lexical semantics (Turney and Pantel, 2010; Erk, 2012). These approaches are based on the premise that the semantics of lexical items can be modelled by their context (Firth, 1957; Harris, 1985). Distributional semantic models have the advantages of being robust and straightforward to create from unannotated corpora. However, problems can arise when they are used to represent the semantics of polysemous words. Distributional semantic models are generally constructed by examining the context of lexical items in unannotated corpora. But for ambiguous words, like ball, it is not clear if a particular instance of the word in a corpus refers to the ‘event’, ‘sports equipment’ or another sense which can lead to the distributional semantic model becoming a mixture of differen</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>J. Firth. 1957. A synopsis of linguistic theory 1930-1955. In Studies in Linguistic Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alona Fyshe</author>
<author>Partha P Talukdar</author>
<author>Brian Murphy</author>
<author>Tom M Mitchell</author>
</authors>
<title>Interpretable semantic vectors from a joint model of brain- and text- based meaning.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>489--499</pages>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="22464" citStr="Fyshe et al. (2014)" startWordPosition="3756" endWordPosition="3759"> for sense tagging. The pattern of results observed for the WSD task is somewhat different to those obtained for word similarity, where applying LSA and CCA improved performance (see Section 3). The most likely expla26 nation of this difference is that WSD requires the Dyer (2014) found that learning joint spaces from model to represent the possible senses of each am- multilingual vector spaces using CCA improves the biguous word. It is also important that these senses performance of standard monolingual vector spaces correspond to the ones used in the relevant lexicon on semantic similarity. Fyshe et al. (2014) showed (WordNet in this case). The Synset Rank model Hp that integrating textual vector space models with does this by making use of information from Word- brain activation data when people are reading words Net. However, these synset representations are dis- achieves better correlation to behavioural data than rupted by LSA and CCA which compress the seman- models of one modality. tic space by extracting general features from them. Our hybrid models are also closely related to a This is not a problem for word similarity since there supervised method proposed by Faruqui et al. (2015). is no n</context>
</contexts>
<marker>Fyshe, Talukdar, Murphy, Mitchell, 2014</marker>
<rawString>Alona Fyshe, Partha P. Talukdar, Brian Murphy, and Tom M. Mitchell. 2014. Interpretable semantic vectors from a joint model of brain- and text- based meaning. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 489–499, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hardoon</author>
<author>Sandor Szedmak</author>
<author>John Shawe-Taylor</author>
</authors>
<title>Canonical correlation analysis: An overview with application to learning methods.</title>
<date>2004</date>
<booktitle>Neural computation,</booktitle>
<pages>16--12</pages>
<contexts>
<context position="12556" citStr="Hardoon et al., 2004" startWordPosition="2066" endWordPosition="2069">atrix of word vectors, EK is a K x K diagonal matrix with singular values and VK is a K x C matrix of context feature vectors. We apply LSA on the Synset Distributional Model, H and the Synset Rank model, Hp to obtained the reduced semantic spaces H˜ and ˜Hp respectively. 2.4 Joint Representation using CCA Recent work has demonstrated that distributional models can benefit from combining alternative views of data (see Section 5). H and Hp provide two different views of the synsets and we incorporate evidence from both to learn a joint representation using Canonical Correlation Analysis (CCA) (Hardoon et al., 2004). Given two multidimensional variables x and y, CCA finds two projection vectors by maximising the correlations of the variables onto these projections. The function to be maximised is: E[xy] ρ = � (4) E[x2]E[y2] The dimensionality of the projection vectors is lower or equal to the dimensionality of the original variables. The computation of CCA directly over H and Hp is computationally infeasible because of their high dimensionality (300K). We apply CCA over the reduced spaces learned using LSA, H˜ and ˜Hp to obtain two joint semantic spaces following a similar approach to Faruqui and Dyer (2</context>
</contexts>
<marker>Hardoon, Szedmak, Shawe-Taylor, 2004</marker>
<rawString>David Hardoon, Sandor Szedmak, and John Shawe-Taylor. 2004. Canonical correlation analysis: An overview with application to learning methods. Neural computation, 16(12):2639–2664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>Distributional structure. In</title>
<date>1985</date>
<booktitle>The Philosophy of Linguistics,</booktitle>
<pages>26--47</pages>
<editor>J. Katz, editor,</editor>
<publisher>Oxford University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="2637" citStr="Harris, 1985" startWordPosition="392" endWordPosition="393">e multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text. This issue has lead to significant exploration of the problem of Word Sense Disambiguation (Ide and V´eronis, 1998; Navigli, 2009). More recently distributional semantics has become a popular approach to representing lexical semantics (Turney and Pantel, 2010; Erk, 2012). These approaches are based on the premise that the semantics of lexical items can be modelled by their context (Firth, 1957; Harris, 1985). Distributional semantic models have the advantages of being robust and straightforward to create from unannotated corpora. However, problems can arise when they are used to represent the semantics of polysemous words. Distributional semantic models are generally constructed by examining the context of lexical items in unannotated corpora. But for ambiguous words, like ball, it is not clear if a particular instance of the word in a corpus refers to the ‘event’, ‘sports equipment’ or another sense which can lead to the distributional semantic model becoming a mixture of different meanings with</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Z. Harris. 1985. Distributional structure. In J. Katz, editor, The Philosophy of Linguistics, pages 26–47. Oxford University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher Haveliwala</author>
<author>Sepandar Kamvar</author>
<author>Glen Jeh</author>
</authors>
<title>An analytical comparison of approaches to personalizing PageRank.</title>
<date>2003</date>
<tech>Technical Report 2003-35,</tech>
<institution>Stanford InfoLab.</institution>
<contexts>
<context position="9168" citStr="Haveliwala et al., 2003" startWordPosition="1458" endWordPosition="1461">h with a set of vertices, V , denoting synsets and a set of edges, E, denoting links between synsets in the WordNet hierarchy. The PageRank score (Pr) over G for a synset (Vi) can be computed by the following equation: � 1 Pr(Vi) = d · O(Vj) Pr(Vj) + (1 − d)V (1) Vj ∈I(Vi) where I(Vi) denotes the in-degree of the vertex Vi and O(Vj) is the out-degree of vertex Vj. d is the damping factor which is set to the default value of d = 0.85 (Page et al., 1999). In standard PageRank all elements of the vector v are the same, 1 N where N is the number of nodes in the graph. Personalised PageRank (PPR) (Haveliwala et al., 2003) is a variant of the PageRank algorithm in which extra importance is assigned to certain vertices in the graph. This is achieved by adjusting the values of the vector v in equation 1 to prefer certain nodes. The values in v effectively initialises the graph and assigning high values to nodes in v makes them more likely to be assigned a high PPR score. For each context feature c in C if c E LM where LM contains all the lemma names of synsets in S, we apply PPR to assign importance to synsets. The score of each synset Sc in the personalisation vector v, is set to 1 |Sc |where |Sc |is the number </context>
</contexts>
<marker>Haveliwala, Kamvar, Jeh, 2003</marker>
<rawString>Taher Haveliwala, Sepandar Kamvar, and Glen Jeh. 2003. An analytical comparison of approaches to personalizing PageRank. Technical Report 2003-35, Stanford InfoLab.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J V´eronis</author>
</authors>
<title>Introduction to the special issue on word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Ide, V´eronis, 1998</marker>
<rawString>N. Ide and J. V´eronis. 1998. Introduction to the special issue on word sense disambiguation: The state of the art. Computational Linguistics, 24(1):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="10405" citStr="Landauer and Dumais, 1997" startWordPosition="1681" endWordPosition="1684">that context feature i belongs. The personalisation value of all the other sysnets is set to 0. We apply PPR over WordNet for each context feature using UKB (Agirre et al., 2009) and obtain weights for each synset-context feature pair resulting to a new semantic space Hp, S x C, where vector elements are weighted by PageRank values. Figure 2 shows how the synset scores are computed by applying PPR over WordNet given the context feature car. Note that we use the context features of the distributional model D. 2.3 Latent Semantic Analysis Latent Semantic Analysis (LSA) (Deerwester et al., 1990; Landauer and Dumais, 1997) has been used to reduce the dimensionality of semantic spaces leading to improved performance. LSA applies Singular Value Decomposition (SVD) to a matrix X, W x C, which represents a distributional semantic space. This is a form of factor analysis where X is decomposed into three other matrices: X = UEVT (2) where U is a W x W matrix of row vectors where its columns are eigenvectors of XXT, E is a diagonal W x C matrix containing the singular values and V is a C x C matrix of context feature vectors where its columns are eigenvectors of XT X. The multiplication of the three component matrices</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K Landauer and Susan T Dumais. 1997. A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2):211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Elia Bruni</author>
<author>Marco Baroni</author>
</authors>
<title>Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1403--1414</pages>
<location>Baltimore, Maryland.</location>
<marker>Lazaridou, Bruni, Baroni, 2014</marker>
<rawString>Angeliki Lazaridou, Elia Bruni, and Marco Baroni. 2014. Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1403–1414, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of International Conference on Empirical Methods in Natural Language Processing (EMNLP ’04),</booktitle>
<pages>404--411</pages>
<location>Barcelona,</location>
<contexts>
<context position="8518" citStr="Mihalcea and Tarau, 2004" startWordPosition="1327" endWordPosition="1330"> increases the weight of context features 21 Figure 1: In the Synset Distributional Model the vector representing a synset (white box) is computed as the centroid of its lemma vectors (grey boxes) motorcar ~motorcar machine ~auto ~car automobile� car.n.01 + ~machine auto car automobile car.n.01 that synsets share with neighbours and reduces those that are not shared. PageRank (Page et al., 1999) is a graph-based algorithm for identifying important nodes in a graph that has been applied to a range of NLP tasks including word sense disambiguation (Agirre and Soroa, 2009) and keyword extraction (Mihalcea and Tarau, 2004). Let G = (V, E) be a graph with a set of vertices, V , denoting synsets and a set of edges, E, denoting links between synsets in the WordNet hierarchy. The PageRank score (Pr) over G for a synset (Vi) can be computed by the following equation: � 1 Pr(Vi) = d · O(Vj) Pr(Vj) + (1 − d)V (1) Vj ∈I(Vi) where I(Vi) denotes the in-degree of the vertex Vi and O(Vj) is the out-degree of vertex Vj. d is the damping factor which is set to the default value of d = 0.85 (Page et al., 1999). In standard PageRank all elements of the vector v are the same, 1 N where N is the number of nodes in the graph. Per</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing order into texts. In Proceedings of International Conference on Empirical Methods in Natural Language Processing (EMNLP ’04), pages 404–411, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Walter G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity. Language and cognitive processes,</title>
<date>1991</date>
<pages>6--1</pages>
<contexts>
<context position="14748" citStr="Miller and Charles, 1991" startWordPosition="2444" endWordPosition="2447">˜ 0.55 0.69 0.42 0.71 0.71 0.54 ˜Hp 0.58 0.68 0.46 0.85 0.86 0.55 Hybrid Models - CCA H∗ 0.67 0.76 0.57 0.81 0.79 0.72 H∗ 0.52 0.62 0.41 0.86 0.80 0.56 p Table 1: Spearman’s correlation on various data sets. Maximum similarity between pairs of synsets. edness. First, we make use of WS-353 (Finkelstein et al., 2001) which contains 353 pairs of words annotated by humans. Furthermore, we make use of the similarity (WS-Sim) and relatedness (WS-Rel) pairs of words created by Agirre et al. (2009) from the original WS-353 data set. We also made use of the RG (Rubenstein and Goodenough, 1965) and MC (Miller and Charles, 1991) data sets which contain 65 and 30 pairs of nouns respectively. Finally, we make use of the larger MEN data set (Bruni et al., 2012) which contains 3,000 pairs of words that has been used as image tags. Annotations are obtained using croudsourcing. 3.3 Model Parameters The parameters we need to tune are the number of the top components in LSA spaces, H˜ and ˜Hp, and CCA spaces, H∗ and H∗p. For the LSA spaces, we tune the number of the top k components in RG. We set k E {50,100,..., 1000} and select the value that maximises performance which is k = 700 for H˜ and k = 650 for ˜Hp. For the joint </context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>George A Miller and Walter G Charles. 1991. Contextual correlates of semantic similarity. Language and cognitive processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>236--244</pages>
<location>Columbus, Ohio.</location>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. In Proceedings of ACL-08: HLT, pages 236–244, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taesun Moon</author>
<author>Katrin Erk</author>
</authors>
<title>An inference-based model of word meaning in context as a paraphrase distribution.</title>
<date>2013</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>4--3</pages>
<marker>Moon, Erk, 2013</marker>
<rawString>Taesun Moon and Katrin Erk. 2013. An inference-based model of word meaning in context as a paraphrase distribution. ACM Transactions on Intelligent Systems and Technology (TIST), 4(3):42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: a survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="1684" citStr="Navigli (2009)" startWordPosition="238" endWordPosition="239">itional benefit of modelling polysemy. 1 Introduction The representation of lexical semantics is a core problem in Computational Linguistics and a variety of approaches have been developed. Two of the most widely explored have been knowledge-based and distributional semantics. Knowledge-based approaches make use of some external information source which defines the set of possible meanings for each lexical item. The most widely used information source is WordNet (Fellbaum, 1998), although other resources, such as Machine Readable Dictionaries, thesaurii and ontologies have also been used (see Navigli (2009)). One advantage of these resources is that they represent the various possible meanings of lexical items 20 which makes it straightforward to identify ones that are ambiguous. For example, these resources would include multiple meanings for the word ball including the ‘event’ and ‘sports equipment’ senses. However, the fact that there are multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text. This issue has lead to significant exploration of the prob</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: a survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The PageRank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<tech>Technical Report 1999-66,</tech>
<institution>Stanford InfoLab.</institution>
<contexts>
<context position="8291" citStr="Page et al., 1999" startWordPosition="1290" endWordPosition="1293">to a given synset are likely to be shared by its neighbours in the hierarchy while those that are not relevant (i.e. have been introduced via an irrelevant sense of a synset member) will not be. The graph-based algorithm increases the weight of context features 21 Figure 1: In the Synset Distributional Model the vector representing a synset (white box) is computed as the centroid of its lemma vectors (grey boxes) motorcar ~motorcar machine ~auto ~car automobile� car.n.01 + ~machine auto car automobile car.n.01 that synsets share with neighbours and reduces those that are not shared. PageRank (Page et al., 1999) is a graph-based algorithm for identifying important nodes in a graph that has been applied to a range of NLP tasks including word sense disambiguation (Agirre and Soroa, 2009) and keyword extraction (Mihalcea and Tarau, 2004). Let G = (V, E) be a graph with a set of vertices, V , denoting synsets and a set of edges, E, denoting links between synsets in the WordNet hierarchy. The PageRank score (Pr) over G for a synset (Vi) can be computed by the following equation: � 1 Pr(Vi) = d · O(Vj) Pr(Vj) + (1 − d)V (1) Vj ∈I(Vi) where I(Vi) denotes the in-degree of the vertex Vi and O(Vj) is the out-d</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Christiane Fellbaum</author>
<author>Scott Cotton</author>
<author>Lauren Delfs</author>
<author>Hoa Trang Dang</author>
</authors>
<title>English tasks: Allwords and verb lexical sample.</title>
<date>2001</date>
<booktitle>In The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>21--24</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="18808" citStr="Palmer et al., 2001" startWordPosition="3153" endWordPosition="3156">ple, the best 2Note that Baroni et al. (2014) found that applying SVD to D did not improve performance over using the full space. hybrid model, H*, achieves correlations that are between 2% and 12% than D for the majority of data sets, although performance is 1% lower for the RG data set. This improved performance suggest that human judgements of word similarity are based on the relation between all the senses of two given words rather than just the most similar ones. 4 Word Sense Disambiguation 4.1 Data We test the efficiency of our hybrid models on the English All Words tasks of Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004), two standard data sets for evaluating WSD. Our experiments focus on the disambiguation of nouns in these data sets. 4.2 Word Sense Tagging A simple approach to all-words WSD was implemented in which each sense of an ambiguous word is compared against its context and the most similar chosen. For example suppose that we want to disambiguate 25 Nouns Senseval-2 Senseval-3 Precision Recall Precision Recall Hybrid Models - Full H 0.46 0.45 0.37 0.36 Hp 0.65 0.63 0.50 0.48 Hybrid Models - LSA H˜ 0.45 0.44 0.39 0.37 ˜Hp 0.60 0.58 0.46 0.45 Hybrid Models - CC</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa Trang Dang. 2001. English tasks: Allwords and verb lexical sample. In The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 21–24, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara Polajnar</author>
<author>Stephen Clark</author>
</authors>
<title>Improving distributional semantic vectors through context selection and normalisation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>230--238</pages>
<institution>Gothenburg, Sweden. Association for Computational Linguistics.</institution>
<marker>Polajnar, Clark, 2014</marker>
<rawString>Tamara Polajnar and Stephen Clark. 2014. Improving distributional semantic vectors through context selection and normalisation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 230–238, Gothenburg, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Raymond J Mooney</author>
</authors>
<title>Multiprototype vector-space models of word meaning. In</title>
<date>2010</date>
<contexts>
<context position="24779" citStr="Reisinger and Mooney, 2010" startWordPosition="4116" endWordPosition="4119">er et tics that combine distributional and knowledge-based al., 2011; Van de Cruys et al., 2011). Alternatively, approaches and offer advantages of both techniques. clustering methods have been used to cluster together A standard distributional semantic model is created the different contexts a target word appears assum- from an unannotated corpus and then refined by (1) ing that each cluster of contexts captures a different using WordNet synsets to create synset vectors; and sense of the target word (Dinu and Lapata, 2010; (2) applying a graph-based technique over WordNet Erk and Pado, 2010; Reisinger and Mooney, 2010). to reweight synset vectors. The resulting hybrid modLanguage models have also been used to remove pol- els can be viewed as enhanced distributional models ysemy from word vectors by predicting words that using the information from WordNet to reduce the could replace the target word given a context (De- problems caused by ambiguous terms when models schacht and Moens, 2009; Washtell, 2010; Moon are created. Results show that our models perform and Erk, 2013). More recently, Polajnar and Clark better than traditional distributional models on lex(2014) applied context selection and normalisatio</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>Joseph Reisinger and Raymond J. Mooney. 2010. Multiprototype vector-space models of word meaning. In</rawString>
</citation>
<citation valid="true">
<authors>
<author>Human Language</author>
</authors>
<title>Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>109--117</pages>
<location>Los Angeles, California.</location>
<marker>Language, 2010</marker>
<rawString>Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 109–117, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="14714" citStr="Rubenstein and Goodenough, 1965" startWordPosition="2438" endWordPosition="2441">0.49 0.82 0.86 0.63 Hybrid Models - LSA H˜ 0.55 0.69 0.42 0.71 0.71 0.54 ˜Hp 0.58 0.68 0.46 0.85 0.86 0.55 Hybrid Models - CCA H∗ 0.67 0.76 0.57 0.81 0.79 0.72 H∗ 0.52 0.62 0.41 0.86 0.80 0.56 p Table 1: Spearman’s correlation on various data sets. Maximum similarity between pairs of synsets. edness. First, we make use of WS-353 (Finkelstein et al., 2001) which contains 353 pairs of words annotated by humans. Furthermore, we make use of the similarity (WS-Sim) and relatedness (WS-Rel) pairs of words created by Agirre et al. (2009) from the original WS-353 data set. We also made use of the RG (Rubenstein and Goodenough, 1965) and MC (Miller and Charles, 1991) data sets which contain 65 and 30 pairs of nouns respectively. Finally, we make use of the larger MEN data set (Bruni et al., 2012) which contains 3,000 pairs of words that has been used as image tags. Annotations are obtained using croudsourcing. 3.3 Model Parameters The parameters we need to tune are the number of the top components in LSA spaces, H˜ and ˜Hp, and CCA spaces, H∗ and H∗p. For the LSA spaces, we tune the number of the top k components in RG. We set k E {50,100,..., 1000} and select the value that maximises performance which is k = 700 for H˜ a</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John B Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carina Silberer</author>
<author>Vittorio Ferrari</author>
<author>Mirella Lapata</author>
</authors>
<title>Models of semantic representation with visual attributes.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>572--582</pages>
<location>Sofia, Bulgaria.</location>
<marker>Silberer, Ferrari, Lapata, 2013</marker>
<rawString>Carina Silberer, Vittorio Ferrari, and Mirella Lapata. 2013. Models of semantic representation with visual attributes. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 572–582, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The english all-words task. In</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>41--43</pages>
<location>Barcelona,</location>
<contexts>
<context position="18849" citStr="Snyder and Palmer, 2004" startWordPosition="3159" endWordPosition="3162">. (2014) found that applying SVD to D did not improve performance over using the full space. hybrid model, H*, achieves correlations that are between 2% and 12% than D for the majority of data sets, although performance is 1% lower for the RG data set. This improved performance suggest that human judgements of word similarity are based on the relation between all the senses of two given words rather than just the most similar ones. 4 Word Sense Disambiguation 4.1 Data We test the efficiency of our hybrid models on the English All Words tasks of Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004), two standard data sets for evaluating WSD. Our experiments focus on the disambiguation of nouns in these data sets. 4.2 Word Sense Tagging A simple approach to all-words WSD was implemented in which each sense of an ambiguous word is compared against its context and the most similar chosen. For example suppose that we want to disambiguate 25 Nouns Senseval-2 Senseval-3 Precision Recall Precision Recall Hybrid Models - Full H 0.46 0.45 0.37 0.36 Hp 0.65 0.63 0.50 0.48 Hybrid Models - LSA H˜ 0.45 0.44 0.39 0.37 ˜Hp 0.60 0.58 0.46 0.45 Hybrid Models - CCA H* 0.44 0.43 0.36 0.34 H* 0.61 0.60 0.4</context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The english all-words task. In Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 41–43, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Thater</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
</authors>
<title>Word meaning in context: A simple and effective vector model.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1134--1143</pages>
<location>Chiang Mai, Thailand.</location>
<marker>Thater, F¨urstenau, Pinkal, 2011</marker>
<rawString>Stefan Thater, Hagen F¨urstenau, and Manfred Pinkal. 2011. Word meaning in context: A simple and effective vector model. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1134–1143, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141</pages>
<contexts>
<context position="2485" citStr="Turney and Pantel, 2010" startWordPosition="364" endWordPosition="367">or example, these resources would include multiple meanings for the word ball including the ‘event’ and ‘sports equipment’ senses. However, the fact that there are multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text. This issue has lead to significant exploration of the problem of Word Sense Disambiguation (Ide and V´eronis, 1998; Navigli, 2009). More recently distributional semantics has become a popular approach to representing lexical semantics (Turney and Pantel, 2010; Erk, 2012). These approaches are based on the premise that the semantics of lexical items can be modelled by their context (Firth, 1957; Harris, 1985). Distributional semantic models have the advantages of being robust and straightforward to create from unannotated corpora. However, problems can arise when they are used to represent the semantics of polysemous words. Distributional semantic models are generally constructed by examining the context of lexical items in unannotated corpora. But for ambiguous words, like ball, it is not clear if a particular instance of the word in a corpus refe</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
<author>Thierry Poibeau</author>
<author>Anna Korhonen</author>
</authors>
<title>Latent vector weighting for word meaning in context.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conferenceon Empirical Methods in Natural Language Processing,</booktitle>
<pages>1012--1022</pages>
<location>Edinburgh, Scotland, UK.</location>
<marker>Van de Cruys, Poibeau, Korhonen, 2011</marker>
<rawString>Tim Van de Cruys, Thierry Poibeau, and Anna Korhonen. 2011. Latent vector weighting for word meaning in context. In Proceedings of the 2011 Conferenceon Empirical Methods in Natural Language Processing, pages 1012–1022, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Washtell</author>
</authors>
<title>Expectation vectors: A semiotics inspired approach to geometric lexical-semantic representation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics (GEMS),</booktitle>
<pages>45--50</pages>
<location>Uppsala,</location>
<contexts>
<context position="25171" citStr="Washtell, 2010" startWordPosition="4181" endWordPosition="4182">ts captures a different using WordNet synsets to create synset vectors; and sense of the target word (Dinu and Lapata, 2010; (2) applying a graph-based technique over WordNet Erk and Pado, 2010; Reisinger and Mooney, 2010). to reweight synset vectors. The resulting hybrid modLanguage models have also been used to remove pol- els can be viewed as enhanced distributional models ysemy from word vectors by predicting words that using the information from WordNet to reduce the could replace the target word given a context (De- problems caused by ambiguous terms when models schacht and Moens, 2009; Washtell, 2010; Moon are created. Results show that our models perform and Erk, 2013). More recently, Polajnar and Clark better than traditional distributional models on lex(2014) applied context selection and normalisation ical similarity tasks. Unlike standard distributional to improve the quality of word vectors. Our hybrid approaches the techniques proposed here also model models are related to the vector adaptation methods polysemy and can be used to carry out word sense since we modify the synset vectors using its lemmas’ disambiguation. vectors to remove noise. References Our work is also inspired by</context>
</contexts>
<marker>Washtell, 2010</marker>
<rawString>Justin Washtell. 2010. Expectation vectors: A semiotics inspired approach to geometric lexical-semantic representation. In Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics (GEMS), pages 45–50, Uppsala, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>