<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.629554">
American Journal of Computational Linguistics Microfiche 50
THE FINITE STRING
</note>
<sectionHeader confidence="0.906669666666667" genericHeader="method">
NEWSLETTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
VOLUME 13 - NUMBER 5 MAY 1976
TABLE OF CONTENTS
</sectionHeader>
<bodyText confidence="0.597537">
An organization for a dictionary of word senses
Dick H. Fredericksen
Current Bibliography 24
Cahiers du groupe de travail Analyse et experimentation
dans les sciences de l&apos;homme par les methodes infor-
mathiques - E. Chouraqui and J. Virbel 93
Bibliography and subject index, current computing . . 94
Directory of university computer science 95
Privacy, security, and the information processing in-
</bodyText>
<note confidence="0.741290916666667">
dustry - Dahl A. Gerberick 96
AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published
by the Center for Applied Linguistics for the Association
for Computational Linguistics.
EDITOR: David G. Hays Professor of Linguistics, SUNY Buffalo
EDITORIAL ASSISTANT: William Benzon
EDITORIAL ADDRESS: Twin Willows, Wanakah, New York 14075
MANAGING EDITOR: A. HOOD ROBERTS Deputy Director, Center for
Applied Linguistics
MANAGEMENT ASSISTANT: hum Mminsan
PRODUCTION AND SUBSCRIPTION ADDRESS: 1611 North Kent Street,
Arlington, Virginia 22209
</note>
<copyright confidence="0.525199">
Copyright ©1976
</copyright>
<affiliation confidence="0.639759">
Association for Computational Linguistics
</affiliation>
<page confidence="0.901591">
2
</page>
<note confidence="0.712479">
American Journal of Computational Linguistics Microfiche 50 : 2
</note>
<sectionHeader confidence="0.9665245" genericHeader="method">
AN ORGANIZATION FOR A DICTIONARY OF WORD SENSES
DICK H. FREDERICKSEN
IBM THOMAS J. WATSON RESEARCH CENTER
YORKTWON &apos;HEIGHTS, NEW YORK 10598
</sectionHeader>
<bodyText confidence="0.9848126">
ABSTRACT: This paper describes a lexical organization in which &amp;quot;senses&amp;quot; are represented in their
own right, along with &amp;quot;words&amp;quot; and &amp;quot;phrases&amp;quot;, by distinct data items. The objective of the scheme is to
facilitate recognition and employment of synonyms and stock phrases by programs which process
natural la,nguage. Besides presenting the proposed organization, the paper characterizes the lexical
&amp;quot;senses&amp;quot; which result.
</bodyText>
<sectionHeader confidence="0.850096" genericHeader="method">
1. Introduction.
</sectionHeader>
<bodyText confidence="0.922268272727273">
This paper describes an internal lexical organization which is particularly designed to capture the
facts about synonymy. Besides recording the inclusion of each word in one or more synonym sets
(identified with its various &amp;quot;senses&amp;quot;), the scheme attempts to distribute attributes perspicuously
between &amp;quot;senses&amp;quot;, &amp;quot;wordings&amp;quot;, and the intersections of the two. In addition, there is proviSion to
record multi-word idioms, stock phrases, and the like, and to include these as elements in synonym
sets when appropriate.
Briefly, &amp;quot;senses&amp;quot; are represented in their own right, along with &amp;quot;words&amp;quot; and &amp;quot;phrases&amp;quot;, by distinct
data items. Each word or phrase is associated with a list of the &amp;quot;senses&amp;quot; which it can express;
conversely, each &amp;quot;sense&amp;quot; is associated with a list of &amp;quot;alternative wo lings&amp;quot; Additionally, each
word is associated with a list of phrases in which it occurs.
Grammatical category, features, selection restrictions, and the like are applicable at three different
levels: to words or phrases as such, to &amp;quot;senscs&amp;quot; as such, or to particular usages of words or phrases
(equivalently, to particular wordings of &amp;quot;senses&amp;quot;).
An Organization for a Dictionary of Word Senses 3
This lexical organization has been implemented at IBM Research, Yorktown Heights, N.Y., by a
program -- not to be described here -- which builds such dictionaries in a very compact form,
giving interactive assistance to the person making the entries. (For example, the program points
out the possibility of merging &amp;quot;senses&amp;quot; whenever their wordings overlap and their attributes are
compatible, and merges them if so directed.) There are suitable facilities for saving the results,
retrieving them in various ways, and for altering such things as schemes of classification without
scrapping previously prepared work.
The ultimate intent is that the &amp;quot;dictionary of senses&amp;quot; should serve as the lexical component in a
natural language fact-retrieval system. Pending its incorporation in that role, it will be used to
amass and organize information on the semantic relations among words and phrases.
The balance of this paper comes in two sections:
Section 2 presents the proposed lexical data structures, and suggests how they are to be used.
Included is a sketch of how various types of grammatical and semantic &amp;quot;attributes&amp;quot; fit into the
scheme.
Section 3 discusses the character of the &amp;quot;senses&amp;quot; encoded in the resulting dictionary. Reasons are
advanced for regarding lexical &amp;quot;senses&amp;quot; as something far short of semantic primitives. At the same
time, synonym sets are defended against the view that &amp;quot;true paraphrases are rare or nonexistent&amp;quot;.
An Organization for a Dictionary of Word Senses 4
2. The Internal Representation.
_
It will be our purpose in this section to say just enough about internal representation to lay bare
the organizing principles of the lexicon. The focus is on architecture and motivations; details of
field layouts, internal codes, etc. are not at issue here.
To make the discussion concrete, suppose we are interested in the senses of the word &amp;quot;change&amp;quot;
Assuming that none of the words are unfamiliar, the following should put us in mind of two senses:
change: 1. v alter;
2. n small coin.
This, of course, is just a dictionary entry in the traditional format (though with synonyms offered
in lieu of definitions).
On the other hand, we might approach the same information from a different direction: starting
with the two concepts, we might seek words to express them. It is difficult to picture this latter
situation without assigning artificial labels to the concepts. Call them concepts 1 and 2, and
suppose for a moment that there were a practical way to look the concepts up (without having
thought of either word for either concept). Then the information to be retrieved might be envi-
sioned this way:
I. v change, alter
2. n change, small coin
It is this duality of viewpoint -- that words have senses, while senses have wordings -- that our
lexical representation must reflect.
The starting point, then, is that words, phrases, and &amp;quot;senses&amp;quot; are separately represented. There are
three principal types of data item, plus a standard connector:
</bodyText>
<listItem confidence="0.864536888888889">
1. A &amp;quot;Key Data Item&amp;quot; (KDI) represents a single word.
2. A &amp;quot;Phrase Data Item&amp;quot; (PDI) represents a string of two or more words which are to
serve as a unit in some context.
An Organization for a Dictionary of Word Senses 5
3. A &amp;quot;Sense Data Item&amp;quot; (SDI) represents one distinct sense common to a set of viol-fig
and/or phrases. In general, a word or phrase may be usable in more than one sense,
while a given sense may have alternative (synonymous) wordings. Both these types of
variability are recorded making use of the next data item:
4. A &amp;quot;Sense Link Element&amp;quot; (SLE) is a connective item, to be explained shortly.
</listItem>
<bodyText confidence="0.929084">
Three principal fields will engage our attention in each type of data item. Fig. 1 summarizes the
fields for each type.
</bodyText>
<table confidence="0.9355781875">
&amp;quot;Alternative Global &amp;quot;Phrase
Senses&amp;quot; Link Attributes Involvements&amp;quot;
Link
KDI (Key Data Item)
&amp;quot;Alternative Global &amp;quot;Component
Senses&amp;quot; Link Attributes Word&amp;quot;
Links
PDI (Phrase Data Item
&amp;quot;Alternative Global &amp;quot;Sense
Wordings&amp;quot; Link Attributes Chain&amp;quot;
Link
SDI (Sense Data Item)
&amp;quot;Alternative Local &amp;quot;Alternative
Senses&amp;quot; Link Attributes Wordings&amp;quot;
Link.
SLE (Sense Link Element)
</table>
<figureCaption confidence="0.578502">
Fig. 1
</figureCaption>
<bodyText confidence="0.978133166666666">
Schematic of Data Items, with Principal Contents
Each KDI (Key Data Item) or PDI (Phrase Data Item) contains an &amp;quot;alternative senses&amp;quot; link --
pointer to the first SLE (Sense Link Element) in a chain of SLE&apos;s which represent the various
senses of the word or phrase. The SLE&apos;s are chained via their own &amp;quot;alternative senses&amp;quot; links, and
the final member points back to the KDI or PDI. Thus, we shall speak of such a chain as a ring
An Organization for a Dictionary of Word Senses 6
specifically, an &amp;quot;alternative senses ring&amp;quot;. If no senses are on record for a particular word or
phra , the &amp;quot;alternative senses&amp;quot; link in the KDI or PDI is seR referent.
Reciprocally, each SDI (Sense Data Item) contains an &amp;quot;alternative wordings&amp;quot; link. This leads to a
chain of SLErs which represent more-or-less synonymous wordings tnat express the sense. These
SLE&apos;s are chained through their own &amp;quot;alternative wording links, and again the chain is closed
into a ring — this time beginning and ending with the SDI.
The structure that is shaping up may now be seen in Fig. 2, The crucial point is that each SLE
represents the intersection between an &amp;quot;alternative senses ring and an &amp;quot;alternative wordings&amp;quot;
ring. From the standpoint of the word or phrase, it, represents a particular sense; from the
standpoint of the sense, it represents a particular wording
Starting from a KDI or PDI, one gets to the SDI for a particular sense by advancing along the
&amp;quot;alternative senses&amp;quot; ring to the relevant SLE, then detouring along the ring which connects the
latter to the SDI (as one of the SDI&apos;s &amp;quot;alternative wordings&amp;quot;). Starting from an SDI, one gets to a
particular wording by the reverse process. Since am &amp;quot;alternative senses&amp;quot; ring contains exactly
one KDI or PDI, while each &amp;quot;alternative wordings- ring contains exactly one SDI, each SLE is tied
to exactly one sense of one word or phrase. (Eankvalently, it is tied to one wording of one sense.)
The next point of interest is that &amp;quot;attribute&amp;quot; I ields are present in all four types of data item -- even
in the connectors (SLE&apos;s). The attributes which may be recorded in each, however, come from
different bags.
To begin with, the attributes found in an SDI characterize all the wordings of a given sense
whenever the wording 3 are used in that sense. In Fig. 2, for example, sense &amp;quot;1&amp;quot; should be marked
as a &amp;quot;verb&amp;quot; sense, while sense &amp;quot;2&amp;quot; is a &amp;quot;noun&amp;quot;. One would not wish to record the attribute &amp;quot;verb&amp;quot;
in the KDI for the word &amp;quot;change&amp;quot;, for the KDI represents facts about the word itself, irrespective
of sense, and &amp;quot;verb&amp;quot; does not hold for all uses of the word &amp;quot;change&amp;quot;. On the other hand, &amp;quot;verb&amp;quot;
does characterize all wordings of sense &amp;quot;1&amp;quot;, whenever they&apos;re being employed to express that
sense. It would furthermore apply to any additional wordings which we might think of, such as
&amp;quot;modify&amp;quot;, provided they are really used in a synonymous way.
As a matter of fact, it turns out that the traditional parts of speeth -- noun, verb, adjective,
preposition, etc. -- fit best in this scheme as global attributes of senses, recorded in the SDI&apos;s.
An Organization for a Dictionary of Word Senses 7
</bodyText>
<figure confidence="0.97298835">
senses of &amp;quot;alter&amp;quot;
SLE
A
y 1 (Verb)
ni &amp;quot;alter&amp;quot;
KDI I
SDI
senses of &amp;quot;change&amp;quot;
SLE
wordings of SDI 1
&amp;quot;change&amp;quot;
KDI 1
SLE y2 (Noun)
SDI
senses of &amp;quot;small coin&amp;quot;
t
SLE
wordings of SDI 2
&amp;quot;small coin&amp;quot;
PDI
</figure>
<figureCaption confidence="0.8192035">
Fig. 2
&amp;quot;Alternative Senses&amp;quot; and &amp;quot;Alternative Wordings&amp;quot; Rings
</figureCaption>
<bodyText confidence="0.991616813953488">
(The first sense has two wordings: &amp;quot;alter&amp;quot; and &amp;quot;change&amp;quot;. The second sense has wordings &amp;quot;change&amp;quot;
and &amp;quot;small coin&amp;quot;. Two senses are recorded for &amp;quot;change&amp;quot;, and one sense each for &amp;quot;alter&apos;: and
&amp;quot;small coin&amp;quot;.)
A different sort of attribute may be recorded in a KDI, as a global feature of the word itself. For
example, we may note of the word &amp;quot;change&amp;quot; that it is &amp;quot;regularly conjugated&amp;quot;. That is, when used
An Organization for a Dictionary of Word Senses 8
as a verb, it forms the third person singular by adding &amp;quot;s&amp;quot;, and both past Zand past participle by
adding &amp;quot;ed&amp;quot; To be sure, this &amp;quot;global&amp;quot; attribute applies only to the &amp;quot;verb&amp;quot; senses of &amp;quot;change&amp;quot;; but
a moment&apos;s reflection will confirm that &amp;quot;change&amp;quot; has more than one &amp;quot;verb&amp;quot; sense, and the
regularity of its conjugation is common to all of them. Thus, it is useful to note this regularity as an
attribute of the word itself. (Contrast this with the behavior of the word &amp;quot;can&amp;quot;, which is regular
when it means &amp;quot;to pack in cans&amp;quot;, but irregular when it means &amp;quot;is able to&amp;quot;.)
Various other attributes suggest themselves as global characterizers of the words themselves, to be
recorded in the ‘KIDI&apos;s. For example, one might wish to note of &amp;quot;change&amp;quot; that it drops its final &amp;quot;e&amp;quot;
when adding &amp;quot;ing&amp;quot; (this is the normal rule) but of &amp;quot;singe&amp;quot; that it doesn&apos;t.
Still other attributes are appropriate when characterizing multi-word units (in PD1&apos;s). A string of
words whose Meaning is not evident from the mere juxtaposition of its constituents (such as &amp;quot;give
up&amp;quot;) may be classified as an &amp;quot;idiom&amp;quot;. A string of words whose meaning could be figured out from
the meanings of its constituents, but which occurs with enough Frequency to warrant inclusion in
the dictionary, might be classed as a &amp;quot;stock phrase&amp;quot;. (Example: &amp;quot;drop dead&amp;quot;.) A string like
&amp;quot;perform in a subordinate role&amp;quot;, which one would not normally expect to encounter in its own
right, might be classed as a &amp;quot;definition&amp;quot; (for a certain sense of the word &amp;quot;accompany&amp;quot;, difficult to
reword except with a definition).
Perhaps the most unexpected site for recording attributes is in the connective elements (SLE&apos;s).
These are the logical place, though, to note features that apply to a specific sense of a word,
without being global to either the sense or the word. Consider the following four sentences:
On the way to the office, he stopped daydreaming.
On the way to the office, he ceased daydreaming.
On the way to the office, he ceased to daydream.
versus:
On th,e‘way to the office, he stopped to daydream.
Suppose we choose to view this as a restriction upon the (surface) object of the verb: &amp;quot;stop&amp;quot;, when
applied to an action, must take a gerund as its object; &amp;quot;cease&amp;quot; can take either a gerund or an
infinitive. (It wouldn&apos;t affect the point being made if we said that &amp;quot;stop&amp;quot; inhibits a certain
grammatical transformation en route to surface structure, while &amp;quot;cease&amp;quot; permits it.)
An Organization tor a Dictionary of Word Senses 9
Now, we wouldn&apos;t want to mark &amp;quot;gerund object only&amp;quot; as a global attribute of the sense, for we
have just shown that &amp;quot;cease&amp;quot; and &amp;quot;stop&amp;quot;, two wordings of the sense, differ with respect to this
restriction. On the other hand, it doesn&apos;t belong among the global attributes of the word &amp;quot;stop&amp;quot; as
such, for &amp;quot;stop&amp;quot; has other verb senses, even transitive ones, te which the restriction is completely
inapplicable. (Consider &amp;quot;stop a hole in the dike&amp;quot;, &amp;quot;stop a catastrophe&amp;quot;, etc.) That leaves the
alternative we are suggesting: treat the restriction as an attribute of one particular usage of the
word (equivalently, one particular wording of the sense).
</bodyText>
<figure confidence="0.672580916666667">
&amp;quot;play&amp;quot;
KDI
&amp;quot;play doWn&amp;quot;
PDI
(1)
&amp;quot;down&amp;quot;
KDI
&apos;down payment&amp;quot;
PDI
(2)
&amp;quot;payment&amp;quot;
KDI
</figure>
<figureCaption confidence="0.239044">
Fig. 3
&amp;quot;Phrase Involvement&amp;quot; Rings
</figureCaption>
<bodyText confidence="0.964293571428571">
(Where numbers are shown on connecting links, they indicate the position of the word in the
phrase which is linked to.)
An Organization for a Dictionary of Word Senses 1 0
Besides having senses, individual words are involved in phrases, and this fact is also represented in
our data structure. Fig. 3 shows the plan of attack. In the KDI for each word, there is a link
connecting it to the PDI for the first phrase in which the word is known to occur, together with a
number designating the position of the word (1st, end, 3rd, etc.) in that phrase. In the PDI itself,
there is a continuation link for each word of the phrase, together with its number in the next
phrase. In the final PDI involving a given word, the link for that word points back to the KDI.
Thus, independent of its &amp;quot;alternative senses&amp;quot; ring, each KDI may have a &amp;quot;phrase involvements&amp;quot;
ring.
This structure makes it possible to retrieve all the idioms, stock phrases, definitions, etc., in which
a given word has made its appearance, anywhere in the dictionary. As the same structure is used to
encode every multi-word unit, no occurrence of a word is ever lost sight of, and a phrase can be
looked up via any of its constituent words.
Of the fields to which Fig. 1 calls attention, we have discussed all but one. In the SDI for each
&amp;quot;sense&amp;quot;, thpre is a &amp;quot;sense chain&amp;quot; link field. This links the SDI to its successor in a global chain of
&amp;quot;senses&amp;quot;. Using this chain, it is possible to make an exhaustive, non-duplicative list of all the
&amp;quot;senses&amp;quot; recorded in the dictionary. The listing program has only to proceed down the chain,
retrieve frdm each SDI its attributes, decode them, then chase around the &amp;quot;alternative wordings&apos;
ring of the SDI and list the wordings alongside the attributes.
One more feature of the internal representation deserves mention: the data items for words occur
as &amp;quot;leaves&amp;quot; in a lexical tree (Fig. 4). That is, the KDI for a word can be looked up letter-by-letter,
following a chain of pointers that correspond to successive letters. The chain ends at a KDI after
following a substring sufficient to distinguish the word from the nearest thing like it in the
dictionary. The lexical tree has the advantage that words can be looked up either at random or in
sequence.
Recapitulating, these are the essential features of the representation:
</bodyText>
<listItem confidence="0.990309">
*1) &amp;quot;Senses&amp;quot; are represented separately from &amp;quot;wordings&amp;quot;, and the mutual connections
between them are made explicit in both directions.
*2) &amp;quot;Wordings&amp;quot; may be either single words or multi-worct pnrases. i nese are representea ty
distinct types of data item, and may be subject to distinct schemes of classification, but
they are on the same footing with regard to &amp;quot;sense&amp;quot; connections. With each word is
associated an exhaustive list of the phrases in which it occurs.
</listItem>
<bodyText confidence="0.565792">
An Organization for a Dictionary of Word Senses 11
</bodyText>
<equation confidence="0.858995571428571">
(start)
1
&amp;quot;monkey&amp;quot; t_
KDI
blank
&amp;quot;a&amp;quot;
KDI
A
&amp;quot;abate&amp;quot;
KDI
&amp;quot;above&amp;quot;
KDI
Fig. 4
Lexical Tree
</equation>
<bodyText confidence="0.92354296875">
(For a dictionary containing only the words &amp;quot;a&amp;quot;, &amp;quot;above&amp;quot;, &amp;quot;abate&amp;quot;, and &amp;quot;monkey&amp;quot;, this would be
the full tree. The path to each word is only as long as needed to distinguish it from the neighbor
with which it shares the longest leading substring.)
*3) Classifiers and features, drawn from appropriate sets, may be attributed separately to
words, to phrases, to senses, or to particular senses of words or phrases (i.e., to particu-
lar wordings of senses).
*4) The data items which represent senses are globally chained, and may be exhaustively
listed.
An Organization for a Dictionary of Word Senses 1 2
*5) The data items which represent words are accessible as &amp;quot;leaves&amp;quot; of a lexical tree; hence
they may either be retrieved by lookup (in response to presentation of the words) or
voltinteered in alphabetical order,
Given a commitment to represent a lexicon as suggested by points *1 through *5 above, various
implementations would be possible. Alternative implementations of individual points (though not
of the scheme as a whole) have in fact been described by other writers. The lexical tree (*5), for
example, is no great novelty: Sydney M Lamb and William H. Jacobsen describe implementation
details of one such tree 115j. [101 also concerns a dictionary which uses this general style of
organization for lookup. For that matter, the lexical tree is reminiscent of Feigenbaum&apos;s
&amp;quot;discrimination tree.&amp;quot; [11
More interestingly, the separate representation of senses and wordings has been incorporated in
other systems by R. F. Simmons ([11], [12]) and by Larry R. Harris [3]. This way of looking at
matters led Harris to remark some of the same points that we have been stressing: that senses have
alternative wordings just as words have alternative senses; that multi-word phrases might occur on
the same footing as individual words in the expression of a sense; and (interestingly enough) that
part-of-speech information really adheres to the &amp;quot;sense&amp;quot;, not to the &amp;quot;word&amp;quot; Similarly, Simmons
associates his &amp;quot;deep case&amp;quot; information with lexical nodes representing &amp;quot;worcisenses&amp;quot;., while words
themselves are treated as &amp;quot;print image&amp;quot; attributes of the wordsenses.
Harris&apos;s dictionary was only a minor component in a small-scale model of concept acquisition. No
great number of either words or concepts was required to illustrate the principles at stake, so
Harris programmed the dictionary as an array, with words represented by rows and &amp;quot;concepts&amp;quot; by
columns. Elements of the array were merely frequencies, indicating the strength of association
between each word and each concept.
</bodyText>
<footnote confidence="0.637972125">
Needless to say, for a full-scale vocabulary of words and concepts, such an array is mostly empty:
nobody would dream of expanding it in that form. From a programming standpoint, the only
thinkable choice is some form of list structure. Having decided in principle to use &amp;quot;some form of
list structure&amp;quot;, though, one might well ask: Why chains? Why rings? Why not just include in each
Key Data Item a full list of pointers to the corresponding Sense Data Items, and vice-versa?
The answer is simply one of convenience. It&apos;s easier to handle insertions and deletions when they
don&apos;t require the movement of expanded items to new quarters, or the provision of &amp;quot;overflow&amp;quot;
pointers. Its easier to reclaim freed storage when deleted items come in a handful of standard
</footnote>
<bodyText confidence="0.97658825">
An Organization for a Dictionary of Word Senses 13
sizes. As for &amp;quot;rings&amp;quot;, they eliminate the need for two-way pointers, since one can break into a ring
at any point and follow it to its source.
It should be noted that to make rings an attractive representation, the details of the material being
represented must cooperate, In particular, the rings must not become too long, or the processing
required to follow them becomes excessive. It happens that &amp;quot;alternative senses&amp;quot; rings and
&amp;quot;alternative wordings&amp;quot; rings are typically short rarely more than a dozen links per ring. &amp;quot;Phrase
involvement&amp;quot; rings, on the other hand, can become spectacularly long, especially for words like
&amp;quot;a&amp;quot; and &amp;quot;to&amp;quot;. In practice, it&apos;s necessary to provide these rings with short-cut links.
Any of these, programming details could be altered, however, without abandoning tile essence of
the scheme, which is given in points *I through *5 above.
An Organization for a Dictionary of Word Senses 1 4
</bodyText>
<sectionHeader confidence="0.545899" genericHeader="method">
3. The Character of Lexical Senses.
</sectionHeader>
<bodyText confidence="0.995869023474179">
Perhaps the first thing to get straight about the &amp;quot;senses&amp;quot; represented in this dictionary is what they
are not. They are not &amp;quot;concepts&amp;quot;; they are not a set of &amp;quot;primitives&amp;quot; into which human experience
an be decomposed,. No conjecture is put forward here that any such collection of discrete, atomic
concepts even exists, let alone that it might be finite.
Rather, the senses&amp;quot; of the dictionary are in the nog.ure of fuzzy equivalence sets among words.
(This is only a metaphor; we shall do more and more violence to the technical notion of an
&amp;quot;equivalence set&amp;quot; as we proceed.) Each &amp;quot;sense&amp;quot; groups a set of words which, in a set of appropri-
ate contexts: might be used more or less interchangeably. That the equivalence sets are fuzzy, one
can convince oneself with but the briefest immersion in the materials of the language -- trying to
decide whether particular words belong in particular groups or justify the creation of new groups.
Consider, for example, the following set of words and phrases:
(abandon, give up, surrender, relinquish, let go, desert, leave, forsake, abdicate)
Clearly, there is a common theme that can run through all of these, given the right circumstances.
It might be expressed as &amp;quot;reluctant parting from somebody or something&amp;quot;. This can be seen by
coupling the verbs with various possible objects:
(abandon, give up, surrender) a town to the enemy
(abandon, give up) all hope
(give up, relinquish) one&apos;s claim to an estate
(give up, let go) our entire stock at a loss
(abandon, desert, leave) one&apos;s wife and children
(desert, forsake) a friend in need
(give up, abdicate) the throne
An Organization for a Dictionary of Word Senses 15
(abandon, desert) an exhausted mine
(forsake, give up) all other, keeping thee only to her/him
(abandon, desert, leave) the area threatened by the storm
Should we, then, declare this group of words to be a &amp;quot;sense&amp;quot;? There are difficulties. The various
words carry nuances, which it may or may not be easy to ignore in a particular context.
&amp;quot;Forsake&amp;quot;, for example, can suggest that there is something reprehensible about the action. It can
also connote formal renunciation, and the above example from a marriage vow shows that the
formality can be present without the reprehensibility. Nuances get in the way of interchangeabili-
ty; it would sound strange to substitute &amp;quot;desert&amp;quot; into the marriage vow.
Besides nuances, the individual words have conventional areas of application. One does not
normally say that the doctors &amp;quot;deserted&amp;quot; all hope, or that an errant husband &amp;quot;surrendered&amp;quot; his
wife and children. The minister officiating at a wedding would be considered daft if he adjured the
bride and groom to &amp;quot;abdicate&amp;quot; all others, and a merchant would not advertize that he was
&amp;quot;relinquishing&amp;quot; his entire stock at a loss. (Somehow, the latter situation calls for more pedestrian
language.)
At the opposite extreme, overawed by this lack of interchangeability, we might decide to respect
the unique personality of each word, abolishing equivalence classes altogether. The inconvenience
of such a cop-out is obvious: we then have to introduce some other mechanism for recognizing the
equivalence of utterances that are intended synonymously, though they employ different words.
But beyond being inconvenient, the exclusion of equivalence sets is a denial of linguistic facts --
just as bad, in its own way, as the naive attribution of unconditional synonymy.
For it is a commonplace of everyone&apos;s experience that the speaker and the listener agree to ignore
the nuances of words, whenever nuances get in the way of communication. A writer who has used
the word &amp;quot;give up&amp;quot; eight times in five lines will surely cast about for some alternative ways of
saying the same thing. If &amp;quot;relinquish&amp;quot; and &amp;quot;abandon&amp;quot; would normally be too flowery, or if
&amp;quot;surrender&amp;quot; would in other circumstances call to mind an armistice ceremony in a railway wagon.
that will not deter the writer from tossing in a few occurrences of those words -- once a context
has been established that discourages the overtones. Nor will the reader understand matters any
differently. It is as if writer and reader conspired: &amp;quot;We&apos;re fed up with that word, let&apos;s hear
another,&amp;quot; Or, perhaps, the writer simply connives at jolting the reader awake with frequent
changes of idiom, maybe even an occasional incongruity. In any case, synonymy is imposed upon
An Organization for a Dictionary of Word Senses 1 6
the words, and this literary behavior merely exaggerates what people do habitually in c6mmon
speech.
Not only can words be stripped of nuances normally present; they can take an colorations
suggested by the context. The suggestion of &amp;quot;reluctance&amp;quot; conveyed by all the verbs of our example
can be inferred, in at least one case, from the setting alone; and in this case, a variety of more
neutral verbs could be used synonymously:
(part with, take leave of) our entire stock at a loss
One could even substitute the word &amp;quot;sell&amp;quot;, and it wouldn&apos;t change the meaning that was already
t ad into the utterance. But to admit context-dependent synonymy of this degree is to stretch the
equivalence sets&amp;quot; to the point of uselessness.
It comes to this: neither the grouping nor the separation of words can be fully justified. Grouping
is nearly always conditional, and separation is often so. if one could anticipate all possible contexts
in which a group of words could occur, one could perhaps enumerate all possible equivalence sets
-- one for each combination of word group with a set of contexts making the words interchangea-
ble. Anyone, however, can see the futility of that aspiration.
In the end, one settles for messy compromises. Words are grouped if a largish set of contexts in
which they are interchangeable springs readily to mind. They are separated (into perhaps overlap-
ping groups) if the imagination readily suggests contexts in which their meanings differ
&amp;quot;significantly&amp;quot; -- whatever &amp;quot;significantly&amp;quot; may mean. In doubtful cases, when words are grouped
somewhat questionably, one promises oneself to add markings some day that will prevent misuse
of the equivalence. When words are separated somewhat questionably, one promises oneself to
add a mechanism some day that will recognize their relatedness.
In the end, too, one assigns internal structure to the equivalence sets. That&apos;s the effect of assigning
local attributes to the alternative wordings (&amp;quot;animate subject&amp;quot;, &amp;quot;object a vehicle&amp;quot;, etc.): const-
raints are imposed upon the interchangeability of the wordings. More radical structuring can be
accomplished if, for example, one notes &amp;quot;government&amp;quot; as an alternative wording of the sense
&amp;quot;govern, rule, control&amp;quot;, with the attribute &amp;quot;nominalization&amp;quot;.
A trenchant discussion of such difficulties may be found in Kelly and Stone [4]. There the
emphasis is upon disambiguation: given a word in a passage of text, they seek to identify (by
selection from a fixed list of possibilities) the sense in which it is used. Building a computerized
An Organization for a Dictionary of Word Senses 1 7
dictionary for the purpose, they soon became concerned with the arbitariness and the proliferation
of target &amp;quot;senses&amp;quot;, as taken from standard desk dictionaries. They argue, with persuasive exam-
ples, that what lexicographers conventionally distinguish as separate senses of a word are often jusl
applications of the word&apos;s underlying concept to different contexts. To cover the various contexts,
the underlying concept has to be stretched a little, by a process of metaphoric extension. This
metaphoric process is beyond our present power to computerize, but for the long run looks
indispensable for successful language processing. Meanwhile, the authors advocate a dictionary
which re cords for each word as few discrete senses as practicable, combining into one sense all the
usages which can reasonably be united by a common underlying thought.
It is interesting to re-examine Kelly and Stone&apos;s argument with a different task in mind: not the
disambiguation of one word, but the recognition of synonymy between two words. A metaphorical
capability would be as useful for the one task as for the other, but in the case of synonym recogni-
tion, some of the considerations which have guided traditional lexicography remain pertinent. In
particular, it is necessary to ask not merely whether the concepts overlap, but whether the one
word may in fact be used in place of the other. As noted before, usage is restricted by conventional
domains of application; for example, an &amp;quot;alteration&amp;quot; is conceptually both a &amp;quot;change&amp;quot; and a
&amp;quot;modification&amp;quot;, but one wouldn&apos;t call it a change or a modification when painting a sign for a
tailor&apos;s shop.
The arbitrariness of the equivalence sets is not all that disqualii ies them as &amp;quot;conceptual
primitives&amp;quot;. There is a much deeper difficulty in the fact that practically all &amp;quot;senses&amp;quot; can be
paraphrased in terms of other &amp;quot;senses&amp;quot;. Take, for example, the intransitive sense of &amp;quot;change&amp;quot; (as
in &amp;quot;My, but you&apos;ve changed!&amp;quot;). Surely, one would suppose, the concept of &amp;quot;change&amp;quot; must be
primitive? Change of state is what well-nigh a third of all verbs are about.
But if &amp;quot;change&amp;quot; is a &amp;quot;primitive&amp;quot;, it&apos;s a peculiar sort of &amp;quot;primitive&amp;quot;, for it can be paraphrased in a
variety of ways:
(change, become different, cease to be the same, assume new characteristics, make a
transition into a new state)
Note that the multi-word paraphrasals are not idioms; the individual words contribute their usual
meanings to concatenated meanings which express the concept &amp;quot;change&amp;quot;.
An Organization for a Dictionary of Word Senses 1 8
But perhaps we were merely unlucky? Perhaps we chanced upon a concept which looked elemental
but actually turned out to be complex. Maybe the real primitives are &amp;quot;become&amp;quot;, &amp;quot;be&amp;quot;, &amp;quot;cease&amp;quot;,
&amp;quot;different&amp;quot;, &amp;quot;same&amp;quot;, etc. Let&apos;s dig into that possibility.
What does it mean to &amp;quot;become X&amp;quot;, where X is an adjective? The meaning can be variously
expressed:
(become X, come to be, X, get to be X, get X, turn X, grow X, assume the characteris-
tic X)
That&apos;s a discouraging number of ways for a &amp;quot;primitive&amp;quot; to be re-expressible -- though if we choose
to regard &amp;quot;come to be&amp;quot; and &amp;quot;get to be&amp;quot; as idiomatic concatenations of words, only one of the
alternatives makes use of other concepts to explain the one at hand.
As for &amp;quot;different&amp;quot;, it implies a whole underlying anecdote about somebody making a comparison,
after first making a judgment about relevant things to compare. In the combination of the two
concepts -- &amp;quot;become different&amp;quot; --, we furthermore drop mention of the objects being compared.
It&apos;s simply understood that they are certain attributes of the subject at two points in time.
It is tempting to invent ad-hoc &amp;quot;transformational&amp;quot; explanations for these phenomena. One might
conjecture, for example, that &amp;quot;The man changed.&amp;quot; is a surface realization of four underlying
sentences:
(Man be X at time m. Man be Y at time n. X not equal Y. Time n greater-than time m.)
The-trouble with explanations of this sort -- apart from the fact that they introduce growing
complexity into the understanding of straightforward utterances -- is that they assign arbitrary
primacy to some concepts at the expense of others. Why should
&amp;quot;time n greater-than time m&amp;quot;
be an assumed primitive? May we not equally well conjecture that &amp;quot;time n greater-than time m&amp;quot; is
a surface realization of these?:
(Time be m. Time change. Then time be n.)
For that matter, why not view
An Organization for a Dictionary of Word Senses 1 9
&amp;quot;Time elapsed.&amp;quot;
as a surface form of this?:
&amp;quot;At least one thing in the universe changed.&amp;quot;
After all, what is &amp;quot;time&amp;quot; but a nominalized way of talking about the presence and partitioning of
change?
The difficulty, it would seem, lies in the very notion of context-independent &amp;quot;conceptual
primitives&amp;quot;. The metaphor itself is at fault: it calls to mind a fixed set of alements, like those of
which matter is composed, out of which all ideas must be compounded. But where concepts are
concerned, primitivity is a matter of focus. Shift the perspective a little, and new elements swim
into view as fundamentals, while former simples become complex.
A more promising metaphor is the analogy to a vector space. A set of basis vectors is, in a way, a
set of &amp;quot;primitives&amp;quot; out of which all the entities in the space can be composed. These primitives
have the appealing property that they are only primitive relative to one frame of reference. Rotate
your point of view, and what used to come natural as basis vectors are now at an angle; they
become easier to express as sums of vectors that lie along new axes. That bears a resemblance to
what we have seen,in the case of lexical &amp;quot;primitives&amp;quot;.
Thus far and no further may the analogy be pushed, however. The elements which span
&amp;quot;conceptual space&amp;quot; can be no such uniform set of objects as those in a veetor space, while the
rules of composition are coextensive with grammar -- at a minimum. Composition of concepts
itself contributes to the meaning. (For that matter, it is arguable whether concepts are sufficiently
separable to model them as discrete objects at all — whether simple or composite.) Moreover as
&amp;quot;conceptual space&amp;quot; must encompass all things thinkable, the rules of composition must themselves
be part of the space. That is, the operators as much as the things operated upon lie within the space
to be spanned.
A seeming counterexample to these remarks may be found in the &amp;quot;primitive ACT&apos;s&amp;quot; of conceptual
dependency theory, as propounded by Schank, Goldman, Rieger, and Riesbeck ([2], [7], [8], [9]).
On a close reading, however, the &amp;quot;primitive ACT&apos;s&amp;quot; turn out to be verb paradigms -- powerful,
semantically motivated generalizations about large classes of verbs. The names of these paradigms
replace specific verbs as building blocks in the &amp;quot;conceptual&amp;quot; representation of an utterance. The
An Organization for a Dictionary of Word Senses 20
effect is to provide strong guidelines for the inference of unstated information, for the comparison
of related utterances, for paraphrasal, etc.
To represent a particular verb in terms of these ACT&apos;s, however, it is necessary to augment each
ACT with various substructures which detail the manner, the means, the type of actor or object,
etc. No reduced set of representatives is as yet offered for the adverbs, nouns, adjectives, etc. in
terms of which the &amp;quot;primitive ACT&apos;s&amp;quot; are qualified. If such additional condensation were
attempted, the elaboration of a gi&apos;ven utterance in terms of the full set of &amp;quot;primitives&amp;quot; might well
ramify without practical end. In other words, reduction of the set of names for nodes (and labels
for arcs) must be purchased at the expense of extending the number of them required to represent
each utterance.
In conceptual dependency representation, just as in the semantic networks&amp;quot; of Quillian [6],
Simmons ([11], [12]), Slocum, and others, reality ultimately appears as a shimmering web, every
part of which trembles when any part of it is touched upon. Taken in its totality, the system -- as
yet -- is entirely compatible with skepticism about a comprehensive set of &amp;quot;conceptual primitives&amp;quot;
In any case, the verbal &amp;quot;senses&amp;quot; proposed here lie at a far lower level of generality than the
&amp;quot;primitive ACT&apos;s&amp;quot; used in conceptual dependency theory. In terms of that theory, they come
closest to the so-called &amp;quot;CONCEXICON entries&amp;quot; used by Goldman in realizing surface expres-
sions &apos;of a concept from its conceptual representation [2]. Given a primitive ACT, Goldman
narrows it down to a particular &amp;quot;CONCEXICON&amp;quot; entry by applying the tests in a discrimination
tree to the rest of the structure in which the ACT appears.
Our lexical &amp;quot;senses&amp;quot;, therefore, are left with a humbled role. If they span anything, it might best
be thought of as &amp;quot;communication space&amp;quot;, not &amp;quot;conceptual space&amp;quot;. Even in this light, they are a
hugely redundant basis, and a not at all unique one. They form no inventory of the experiences
being communicated about; &amp;quot;meaning&amp;quot; is still a step removed, still evoked rather than embodied
by the elements of this basis.
If we persist in calling these things &amp;quot;senses&amp;quot;, it is because that is the traditional term for what is
brought to mind as the synonym sets of a given word are enumerated. The tie-in with meaning is
tenuous, but the human user is able to supply it. There is at least this much justification for the
term: synonym sets, more forcefully than words, direct attention to the points at which a tie-in
must be made between the tokens of communication and the underlying representation of &amp;quot;world
knowledge&amp;quot;
An Organization for a Dictionary of Word Senses 21
In a full-fledged system for processing natural language, then, we must envision the &amp;quot;dictionary of
senses&amp;quot; as a component stretching vertically across the &amp;quot;upper&amp;quot; layers. Its &amp;quot;sense data items&amp;quot; must
link, in some way, to the deeper-lying data structures which encode &amp;quot;knowledge of the world&amp;quot; (the
&amp;quot;pragmatic component&amp;quot;). The &amp;quot;key data items&amp;quot; and &amp;quot;phrase data items&amp;quot; register tokens to be
expected or employed in &amp;quot;surface&amp;quot; utterances. Global and local attributes recorded in the various
data items guide parsing and interpretation. V.&apos;here one takes it from there depends upon the
linguistic approach to be used.
An Organization for a Dictionary of Word Senses 22
</bodyText>
<sectionHeader confidence="0.980773" genericHeader="method">
References:
</sectionHeader>
<reference confidence="0.965984967741935">
[1] Feigenbaum. Edward A. (1963), &amp;quot;Simulation of Verbal Learning Behavior.&amp;quot;, in Computers
and Thought, eds. E. A. Feigenbaum and J. Feldman, McGraw Hill.
[2] Goldman, Neil (1975), &amp;quot;Sentence Paraphrasing from a Conceptual Base&amp;quot;, Communications of
the ACM. February, 1975, Vol. 1.8 No. 2.
[3] Harris, Larry R. (1972), &amp;quot;A Model for Adaptive Problem Solving A ppilea to Natural Language
Acquisition&amp;quot;, Cornell University, Ithaca, N.Y. PB-211 378.
[4] Kelly, Edward, and Stone, Philip (1975), &amp;quot;Computer Recognition of English Word Senses&amp;quot;,
Chapter IV, North-Holland Publishing Co, Amsterdam.
[5] Lamb, Sydney M., and Jacobsen, William H., Jr. (1966), &amp;quot;A High-Speed Large-Capacity
Dictionary System&amp;quot;, in Readings in Automatic Language Processing. ed. David G. Hays,
American Elsevier Publishing Company, New York.
[6] Quillian, M. Ross (1968), &amp;quot;Semantic Memory&amp;quot;, in Semantic Information Processing, ed.
Marvin Minsky, The MIT Press, Cambridge, Massachusetts.
1171 Schank, R., Goldman, N., Rieger, C., and Riesbeck, C. (1973), &amp;quot;Margie: Memory, Analysis,
Response Generation, and Inference on English&amp;quot;, Proceedings, Third International Joint
Conference on Artificial Intelligence. Stanford Research Institute, Stanford, California.
[8] Schank, Roger C. (1973), &amp;quot;Identification of Conceptualizations Underlying Natural
Language&amp;quot;, in Computer Models of Thought and Language, eds. R. Schank and K Colby,
W. H. Freeman &amp; Co., San Francisco.
[9] Schank, Roger C. (1973), &amp;quot;The Conceptual Analysis of Natural Lang age&amp;quot;, in Natural
Language Processing, ed. Randall Rustin, Algorithmics Press, Inc., New York.
An Organization for a Dictionary of Word Senses 23
[10] Schmidt, Charles T. (1970),. &amp;quot;A Dictionary Structure for Use with an English Language
Preprocessor to a Computerized Information Retrieval System&amp;quot;, Naval Postgraduate School,
Monterey, California. AD 710 363.
[11] Simmons, R. F., and Slocum, J. (1972), &amp;quot;Generating English Discourse from Semantic
Networks&amp;quot;, Communications of the ACM, October 1972, Vol. 15 No. 10.
[12] Simmons, R.F. (1973), &amp;quot;Semantic Networks: Their Computation and Use. for Understanding
English Sentences&amp;quot;, in Computer Models of Thought and Language. eds. R. Schank and
K. Colby, W. H. Freeman &amp; Co., San Francisco.
American Journal of Computational Linguistics Microfiche 50 : 24
</reference>
<sectionHeader confidence="0.825458" genericHeader="method">
CURRENT BIBLIOGRAPHY
</sectionHeader>
<bodyText confidence="0.935637333333334">
Despite repeated predictions to the contrary, both the
selection of material for this issue and the choice of
subject categories are tentative. The Editor and his
collaborators have found the reconstruction of intellec-
tual and mechanical systems more onerous than they had
expected.
Completeness of coverage, especially for reports circulated
privately, depends on the cooperation of authors. Summaries
or articles to be summarized should be sent to the editorial
office, Twin Willows, Wanakah, New York 14075.
Many summaries are authors&apos; abstracts, sometimes edited for
clarity, brevity, or completeness. Where possible, an infor-
</bodyText>
<table confidence="0.917024880952381">
mative summary is provided.
The Informatheque de linguistique de l&apos;Universite d&apos;Ottawa,
Dermot Ronan F. Collis, Director, provides a portion of our
entries. AJCL gratefully acknowledges the assistance of J.
Beck, B. Harris, and D. Castonguay.
See the following framefor a list of subject headings with
frame numbers.
25
SUBJECT HEADINGS
GENERAL. • • • • • 26 COMPUTATION .
Chinese . . • • . • • 35 Programming . 70
PHONETICS - PHONOLOGY 36 Languages . • 71
Recognition . • • • • 38 Pictorial Systems 72
Chinese . • • . • 43 DOCUMENTATION . • 73
WRITING • • • • • • 44 Classification • 76
Recognition 44 Retrieval . • • 76
Chinese 45 TRANSLATION . • • • • • • 76
Synthesis SOCIAL-BEHAVIORAL SCIENCE 79
Chinese • • 46 Anthropology 82
Text Input Psychology . • 83
Chinese . • • 48 Learning . • 84
Character sets HUMANITIES . 85
Chinese . 50 Concordance . 86
Chinese . . 54 Analysis . . • 86
LEXICOGRAPHY - LEXICOLOGY INSTRUCTION . 88
Statistics . 56 BRAIN THEORY • • 91
Text Handling 57 ROBOTICS
Dialectology 58
Thesauri . 58
GRAMMAR . . . 59
Generator . • 60
SEMANTICS - DISCOURSE 60
Memory 67
Question Answering • .
Text Grammar • • • • . . 67
LINGUISTICS
Methods . . 68
Mathematical . 69
GENERAL 26
Putnam and Clarke and Mind and Body
Yorick Wilkes
Artificial Intelligence Laboratory, Stanford
</table>
<subsubsectionHeader confidence="0.73054">
British Journal for the Philosophy of Science 26:213-225, September 1975 ISSN 0007-0882
</subsubsectionHeader>
<bodyText confidence="0.99946475">
Putnam argues for a satirical privacy for machines by asserting that, just as it makes no sense
to ask John how he knows that he is in pain, so it makes no sense to ask a Turing Machine
(TM) how it knows that it is in state A. When addressed to an abstract TM the question is
absurd, but not when addressed to a physically realized TM. Putnam equivocates about the
notion of state, discussing only abstract TM&apos;s when introducing the notion of state, but
making an argument which is coherent only with respect ot a physically realized TM. There
is thus, in effect, a confusion between &apos;state&apos; as of an atitomatpn and &apos;state&apos; as of a real
machine which is executing a program which realizes that automaton—any of a number of
states of the machine might correspond to one state of the automaton embodied in the
program. Thus Putmam&apos;s argument fails, Clarke&apos;s criticisms of Putnam are misguided but
instructive. A more serious notion of machine privacy can be constructed by noting that it
is impossible to inter the machine&apos;s real activitity determinattly from the content of registers.
</bodyText>
<sectionHeader confidence="0.408106" genericHeader="method">
GENERAL
</sectionHeader>
<title confidence="0.654516">
A Graphical Programming System with Speech Input
</title>
<author confidence="0.768408">
Chacko C. Neroth
</author>
<affiliation confidence="0.878842">
University of California, Berkeley
</affiliation>
<subsubsectionHeader confidence="0.900323">
Computers &amp; Graphics 1:227-231, 1975
</subsubsectionHeader>
<bodyText confidence="0.999960888888889">
The experimental problem solving environment is one of formulating specifying, debugging
and executing (algebraic) procedures interactively on a small processor. The speech
recognition system is a real time, syntax directed, limited vocabulary, highly cost effective
scheme specifically tailored to this environment. The data transformation operations of the
language are verbally specified and the control flow is specified graphically as a two-
dimensional directed graph. The semantics of the latter structure is independent of the time
sequence of its input. An input restricted (conditional input) pseudo-finite state machine
model is used for the continuous syntax checking of the input on an atomic token basis and
for directing the speech recognizer.
</bodyText>
<note confidence="0.457702">
GENERAL 27
</note>
<table confidence="0.808659166666667">
Computerized Natural Language Information System
Stewart N. T. Shen
Computer Science Department, Virginia Polytechnic Institute and State University,
Blacksburg
S. GooId, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 573-588
</table>
<bodyText confidence="0.441271777777778">
General problems in NL processing are discussed and a methodology is presented. A NL
system should consist of a supervisory module which reads and interprets certain input
sentences stated in some specific way. These sentences tell the system what kind of job is
being done. The system would have various syntactic, semantic, and pragmatic processing
modules available to. it. Technological developments may well make it practical for
individuals to have CNL1S (Computerized Natural Language Information System) terminals in
their homes. A typical user terminal may include a microcomputer an interactive TV, and
an electric typewriter. In the computerization of Chinese, a simplification of the written
characters is urged.
</bodyText>
<sectionHeader confidence="0.511088" genericHeader="method">
GENERAL
</sectionHeader>
<subsectionHeader confidence="0.650971">
Design Concepts of Chinese Language Data Processing Systems
</subsectionHeader>
<author confidence="0.907189">
Yaohan Chu, Chu
</author>
<affiliation confidence="0.942995">
Department of Computer Science, University of Maryland, College Park
</affiliation>
<subsubsectionHeader confidence="0.456735">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems,. Academia Sinica, 117-136
</subsubsectionHeader>
<bodyText confidence="0.999184333333333">
Five types of Chinese language data processing systems are discussed. 1) Accept assembly
code in English and hand-coded Chinese data and use an expanded subroutine library. 2)
Accept assembly code and data, both in Chinese, by adding a pre-assembler and translators to
the manufacturer-supplied assembler and linkage editor. 3) Accept a high-level Chinese
programming language and Chinese data. 4) Those which use the Chinese-language-oriented
postfix string as the machine language. 5) In which the high-level language itself is the
machine language (i.e. one-level language). This type of data processing system has no
intermediate language, no assembly language, no relocatable language, and no absolute
language.
</bodyText>
<figure confidence="0.365472888888889">
GENERAL 28
Design Philosophy of a Chinese-Oriented Computer
John Y. Hsu
Department of Computer Scien Statistics, California Polytechnic State Unh&apos;ersitv, San
Luis Obispo
S. Gould, Ed., Proceedings of the First International Symposium on Comprters and Chinese
Input/Output Systems, Academia Sinica, 135-150
Basic design philosophy of a Chinese-oriented computer includes consideration of the
idiosyncrasies of such a computer. The following topics are discussed: 1) Internal coding of
Chinese characters, 2) Chinese Input/Output devices, 3) Instruction Repertorie to Manipulate
Chinese Characters, and 4) Miscellaneous. The design approach toward such a Chinese-
oriented computer is also commented on.
GENERAL
Is Technology Ready for Chinese/Japanese Data Processing
8. J. Greenblott, and M. Y. Hsigo
IBM Poughkeepsie, New York
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Acadenia Sinica, 151-161
</figure>
<bodyText confidence="0.9975395">
The technology for the computer processing of Chinese characters on a large scale is almost
around the corner. The major bottleneck is the training required to key in 8,000 different
Chinese characters quickly and correctly by either a set of keyboards or some cleverly
combined coded form or keyboard design. Advances in LSI technology. mechanical or
magnetic keys, CRT, etc., will all contribute to the realization of a data processing system
capable of handling ideographic languages. An automatic pattern recognition system was not
chosen to represent the major future trend because its technical development is still beyond
the level of practical large scale implementation.
</bodyText>
<figure confidence="0.204467">
GENERAL 29
Conversation, Cognition and Learning
Gordon Pask
System Research Lid., Richmond, Surrey, England
Elsevier, Inc., Amsterdam and New York, 1975, $37.00/ WI 96.00, xii + 570 pages, ISBN 0-
444-41/93-3
</figure>
<bodyText confidence="0.9965683">
This book describes a theory of man/man or man/machine conversations and cognitive
processes (with emphasis upon the dynamics of learning and teaching at an individual level)
together with several special experimental methods and practical applications. Most of the
illustrations and data supporting the argument stern from education, course design, and
similar fields and the material is relevant to epistemology, subject matter organisation, as well
as such disciplines as pedagogy, computer aided instruction etc. Some experiments, however,
deal with laboratory learning and the acquisition of perceptual motor skills, and an attempt is
made to identify the theory and methods with many standard paradigms in social and
experimental psychology. An account of consciousness and self-reference is given in the
theory.
</bodyText>
<figure confidence="0.797019048780488">
GENERAL 30
Information Processing and Cognition: The Loyola Symposium
Robert L. Solso, editor
Loyola University of Chicago
Halsted Press Division, John Wiley &amp; Sons, New York, 1975 1SBN 0-470-81230-3 HC
$19.95
Contents
Preface xi
SECTION 1
1 MEMORY, PERCEPTION, AND DECISION IN LETTER IDENTIFICATION,
W. K. Estes 3
Introduction 3
Apparent Effects of World Context on Perception of Letters 6
Detection Procedures and Revival of the Redundancy Hypothesis 7
The Postexposure Probe Technique 9
An Interpretation of the Role of Positional Uncertainty 16
Levels of Information Processing 18
A Model for Levels of Information Processing in Letter Identification 19
Interpretations of Empirical Phenomena 22
Discussion 26
References 29
2 STUDIES OF VISUAL INFORMATION PROCESSING IN MAN, M. S. Mayzner 31
Introduction 31
Curreilt Hardware System and Associated Software Package 34
General Research Strategy 35
A Brief Review of Sequential Blanking and Displacement 36
Dynamic Visual Movement 39
Dynamic Visual Movement 39
GENERAL 31
Subjective Color Experiences Associated with Dynamic Visual Movement . • • 42
Pattern Recognition Mechanisms as Found in Overprinting Paradigms • . .... 44
Overview 52
References 53
3 ATTENTION AND COGNITIVE CONTROL,
Michael I. Posner and Charles R. R. Snyder 55
Introduction 55
Automatic Pathway Activation 56
A View of Conscious Attention 64
Strategies and Conscious Control 69
The Place of Value in a Judgment of Fact 74
Overview 81
</figure>
<sectionHeader confidence="0.843242666666666" genericHeader="method">
References 82
4 FORM, FORMATION, AND TRANSFORMATION OF INTERNAL
REPRESENTATIONS, Roger N. Shepard 87
Some Central Issues 87
Summary of Some Experimental Findings 96
Theoretical Discussion 103
Acknowledgments and Historical Note 117
References 117
SECTION 11
5 RETRIEVAL AS A MEMORY MODIFIER: AN INTERPRETATION OF
NEGATIVE RECENCY AND RELATED PHENOMENA, Robert A. Bjorl 123
Negative Recency 124
Related Phenomena 116
Conclusion 142
References 143
</sectionHeader>
<figure confidence="0.863138766666667">
GENERAL 32
6 ENCODING, STORAGE, AND REFRIEVAL OF ITEM INFORMATION, Bennet B
Murdock, Jr. and. Rita E. Anderson 145
Encoding 153
Storage 158
Retrieval 164
Retrieval at Short and Long Lags 185
References 192
7 WITHIN-INDIVIDUAL DIFFERENCES IN &amp;quot;COGNITIVE&amp;quot; PROCESSES,
William F. Battig 195
Some Questions about Current Cognitive Research Practices 197
Processing Differences within Individuals 203
Serial Learning 206
Paired-Associate Learning 211
Verbal-Discrimination Learning 219
Free-Recall Learning 220
General Conclusions 224
References 227
8 CONSCIOUSNESS: RESPECTABLE, USEFUL, AND PROBABLY NECESSARY,
George Mandler 229
The Revival of Consciousness 229
Conscious Contents and Processes 236
The Limitation of Conscious Capacity and the Flow of Consciousness 246
Conclusion 252
References 253
DISCUSSION: SECTIONS 1 AND II 255
GENERAL 33
SECTION III
9 MEMORY REPRESENTATIONS OF TEXT, Walter Kintsch 269
A Model for Episodic Memory 210
</figure>
<table confidence="0.86691924">
Some Remarks on Text Bases 272
Memory for Text 277
Answering Questions about a Text from Memory 284
Matches at Linguistic and Propositional Levels 286
Postscript: List Learning and Text Learning 291
References 293
*10 COMPUTER SIMULATION OF A LANGUAGE ACQUISTION SYSTEM:
A FIRST REPORT, John R. Anderson 295
Formal Results on Grammar Induction 296
The Role of Semantics 299
Rationale for the Research Approach 301
The Program LAS .1 302
Bracket--The Graph-Deformation Condition 317
An Example of Grammar Induction 324
Assessment of LAS.1 334
Generalizations about Noun Phrases 335
A Prediction about Language Learnability 339
Summary 344
Appendix 345
References 347
11 SEMIOTIC EXTENSION, David McNeill 351
The Study of Performance 352
Production Mechanisms 354
Ontogenesis 356
Evidence for this Argument 361
GENERAL 34
Further Evidence for the Argument 364
Other Influences on Word Order 365
Emergence of Patterned Speech 367
Semiotic Extension 372
Gestures 373
Conclusion 379
References 379
12 THE CONSTRUCTION AND USE OF REPRESENTATIONS INVOLVING
LINEAR ORDER, Tom Trabasso and Christine A. Riley 381
Problem Origins: the Development of Transitive Reasoning 382
Training Results: Serial Position Effects 385
Testing Results: Memory and Inference Correlations 386
Stochastic Retrieval Models 388
What Occurs in Training: The Serial-Position Effect 392
What Occurs in Testing&apos;? 394
Reaction-Time Experiments: Six-Term Series Problems 395
Linear Order Is Independent of Input 399
The Use of A Linear-Order Representation 400
Accessing A Linear Order: Strength or Distance? 401
Conclusions 407
References 409
DISCUSSION: SECTION 111 411
Author Index 427
Subject Index 433
</table>
<footnote confidence="0.9593815">
*This article has been abstracted under SOCIAL-BEHAVIOURAL SCIENCE: PSYCHOLOGY
on this fiche.
</footnote>
<note confidence="0.7540695">
GENERAL 35
Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems
Academia Sinica, xiii + 1331 pages
</note>
<bodyText confidence="0.942560333333333">
The Symposium was held on August 14-16, 1973 at Taipei, Taiwan, Republic of China.
Many of the papers have been abstracted elsewhere on this microfiche.
GENERAL: CHINESE
</bodyText>
<subsectionHeader confidence="0.849287">
Interactive Processing of Chinese Characters and Texts
</subsectionHeader>
<author confidence="0.466027">
3. T. Tou, J. C. Tsay, and J. K. Yoo
</author>
<affiliation confidence="0.553055">
Center for Informatics Research, University of Florida, Gainsville
</affiliation>
<author confidence="0.457745">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
</author>
<subsubsectionHeader confidence="0.394719">
Input/Output Systems, Academia Sinica 1-28
</subsubsectionHeader>
<bodyText confidence="0.999978777777778">
The system provides a tool to teach pupils how to write Chinese ideographs, how to make
proper pronunciations, and how to translate into a foreign language, and features dynamic
display of characters. The system can also perform text-editing operations. Techniques for
Chinese character representation, based on chain codes for stroke sequence, and dictionary
generation, in which each character of subcharacter is represented as a subroutine in the
dictionary, are introduced. Text-editing routines are discussed and the paper concludes with
an illustrations of text-editing operations. The final edited text can be transcribed from the
display scope for making hard copies. The system will be further developed for editing maps,
for typesetting and for use as a Chinese typewriter.
</bodyText>
<figure confidence="0.3831176">
PHONETICS-PHONOLOGY 36
A Small Computer in the Phonetics Laboratory
Claes-Christian Elert
Professor of Phonetics, Umea University, Sweden
World Papers in Phonetics, The Phonetic Society of Japan, Tokyo, 145-162, 1974
</figure>
<bodyText confidence="0.968153333333333">
With adequate programming facilities at hand the phonetician would be able to make his
table-top computer perform pratically everything that was done earlier by conventional
equipment for analysis and registration. In addition, data may be stored for automatic
processing, and sequences of events, such as qualitative or quantitative variations of
parameters or stimuli in experiments with human subjects, can be governed according to a
pre-set program, or by incoming signals of random pulses. Topics considered: 1) the nature
of available equipment, 2) programming, 3) speech analysis, 4) speech synthesis, 5) the
computer in experimental work, 6) dialectology and phonology, 7) teaching phonetics.
PHONETICS-PHONOLOGY
</bodyText>
<subsectionHeader confidence="0.726109">
A Study of Time-Domain Speech Compression by Means of a New Analog
Speech Processor
</subsectionHeader>
<author confidence="0.412258">
1. M. Bennett, and J. G. Limit&apos;
</author>
<affiliation confidence="0.423736">
Department of Electrical Engineering, Stanford University, Stanford, California 94305
Journal of the Audio Engineering Society 23:713-721, November 1975
</affiliation>
<bodyText confidence="0.9998535">
Time-domain speech compression using the SDA (sample, discard, about) procedure at
compression ratios of 0.25 to 0.75 is studied by means of a new analog speech processor and
minicomputer algorithms. Fourier transform methods have been used to establish a
correspondence between the quality of the reconstructed compressed speech waveforms and the
subjective recognition of compressed speech. The result of two psychoacoustic experiments
indicate that 1) the interruption frequency should be equal to the pitch frequency of the
voice waveform for optimum recognition of the compressed speech, and 2) smoothing of the
discontinuities with electronic techniques significantly improves the recognition of the
compressed speech. The optimum smoothing parameters, window width and characteristic
function, are also obtained from this study.
</bodyText>
<equation confidence="0.319788">
PHONETICS-PHONOLOGY 37
</equation>
<subsectionHeader confidence="0.717286666666667">
On the Characteristics of Individual Vowels and the Statistical Characteristics
of Formant Frequency Patterns in Connected Speech
Yoshtnari Kanamori
</subsectionHeader>
<note confidence="0.401836">
Research Institute of Electrical Communication, Tohoku University, Sendai 980, Japan
</note>
<subsubsectionHeader confidence="0.791718">
Systems - Computers - Controls, 6, No. 1:22-30, 1975
</subsubsectionHeader>
<bodyText confidence="0.995945928571428">
The loci of formant frequency patterns of vowels in many kinds of CVC contexts were
represented in F1-F1 space. The areas enclosing these loci were obtained for each vowel.
The positions of vowels in connected speech lie inside an area surrounded by the isolated
vowels because of the neutralization of vowels in connected speech. The faster the speaking
ra e, the more the areas tend to concentrate deeper inside. Also, the areas of individual
vowels overlap each other and the faster the speaking rate, the more the overlapping areas
increase. The overlapping areas were estimated in F1-F2 space and, to investigate the effect
of F3 in F1-F2-F3 space. The distribution of Fi is nearly approximated by the normal
density function, because the effect on imbalance or the vowel occurrence frequencies is not
clearly observed in the frequency distribution of F3. Areas reflecting the bound of
articulatory movement in the acoustic domain were obtained from the loci of formant
frequencies represented in F1-F2 and F1-F3 spaces. We conclude with a comparison of the
discussed areas and those obtained from thearticulatory model by Lindblom.
PHONETICS-PHONOLOGY
</bodyText>
<subsectionHeader confidence="0.6341205">
Epoch Extraction of Voiced Speech
T. V. Anathapadnianabha, and B. Yegnanarayana
</subsectionHeader>
<bodyText confidence="0.24032">
Department of Electrical Communication Engineering, Indian Institute of Science, Bangalore
560012, India
</bodyText>
<subsubsectionHeader confidence="0.492343">
IEEE Transactions on Acoustics, Speech, and Signal Processing 23:562-570, December 1975
</subsubsectionHeader>
<bodyText confidence="0.980930142857143">
A general theory of epoch extraction of overlapping nonidentical waveforms is presented and
applied to outputs of models of voiced speech production (model 1, impulse excitation of a
two-resonator system; model 2, glottal wave excitation of a two-resonator system) and to
actual speech data. Some typical glottal waveshapes are considered to explain their effect of
the speech output. The points of excitation of the vocal tract can be precisely identified for
continuous speech and it is possible to obtain accurate pitch information by this method even
for high-pitched sounds.
</bodyText>
<table confidence="0.281335">
PHONETICS-PHONOLOGY: RECOGNITION 38
Real-Time Digital Hardware Pitch Detector
Ronald W. Schafer
Department of Electrical Engineering, Georgia Institute of Technology, Atlanta 30332
John J. Duhnowski, and Lawrence R. Rabiner
Bell Laboratories, Murray Hill, New Jersey 07974
IEEE Transactions on Acoustics, Speech, and Signal Processing 24:2-8, February 1976
</table>
<tableCaption confidence="0.4114749">
A high-quality pitch detector has been built in digital hardware and operates in real time at a
10 kHz sampling rate. The hardware is capable of providing energy as well as pitch-period
estimates. The pitch and energy computations are performed 100 times/s once per 10
ms interval). The algorithm to estimate the pitch period uses center clipping, infinite peak
clipping, and a simplified autocorrelation analysis. The analysis is performed on a 300
sample section of speech which is both center clipped and infinite peak clipped, yielding a
three-level speech signal where the levels are -1, 0, and +1 depending on the relation of the
original speech ample to the clipping threshold. Thus computation of the autocorretation
function of the clipped speech is easily implenented in digital hardware using simple
combinatorial logic, i.e., an up-down counter can be used to compute each correlation point.
</tableCaption>
<table confidence="0.0826898">
PHONETICS-PHONOLOGY: RECOGNITION
A Comparison of Three Methods of Extracting Resonance Information from
Predictor-Coeficient Coded Speech
Randall L. Christensen
Naval Weapons Center, China- Lake, Clilifornia 93555 .
</table>
<subsectionHeader confidence="0.635192">
William J. Strong, and E. Paul Palmer
Department of Physics and Astronomy, Brigham Young University, Provo, Utah 84602
IEEE Transactions on Acoustics, Speech, and Signal Processing 24:8-14, February 1976
</subsectionHeader>
<bodyText confidence="0.999693625">
The methods: finding roots of the polynomial in the denominator of the transfer function
using Newton iteration, picking peaks in the spectrum of the transfer function, and picking
peaks in the negative of the second derivative of the spectrum. A relationship was found
between the bandwidth of a resonance and the magnitude of the second derivative peak.
Data, accumulated from a total of about two minutes of running speech from both female
and male talkers, are presented illustrating the relative effectiveness of each method in
locating resonances. The second-derivative method was shown to locate about 98 percent of
the significant resonances while the simple peak-picking method located about 85 percent
</bodyText>
<note confidence="0.652171666666667">
PHONETICS-PHONOLOGY: RECOGNITION 39
A Method for the Correctio of Garbled Words Based on the Levenshtein
Metric
</note>
<title confidence="0.134651">
Teruo Okuda
</title>
<author confidence="0.5707605">
Systems Design Section, Systems Development Department, Fujitsu Limited, Kawasaki, Japan
Eiiehi Tanaka, and Tamotsu Kasai
</author>
<affiliation confidence="0.864712">
Department of Electrical Engineering, Faculty of Engineering, University of Osaka
Prefecture, Sakai, Japan
</affiliation>
<subsectionHeader confidence="0.479749">
IEEE Transactions of Computers 25:172-178, February 1976
</subsectionHeader>
<bodyText confidence="0.9989795">
Using a method for correcting garbled words based on Levenshtein distance and weighted
Levenshtein distance we can correct substitution errors, insertion errors, and delection errors.
According to the results of computer simulation on nearly 1000 high occurrence English
words, higher error correcting rates can be achieved by this method than any other method
tried to date. Short words remain a problem; solving it will probably require utilization of
contextual information. Hardware realization of the method is possible, though complicated.
</bodyText>
<sectionHeader confidence="0.832187" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.800949">
Speaker-Identifying Features Based on Formant Tracks
</subsectionHeader>
<author confidence="0.452842">
Ursula G. Goldstein
</author>
<affiliation confidence="0.737017">
Department of Electrical Engineering and Computer Science and Researcn Laboratory of
Electronics, Massachusetts Institute of Technology, Cambridge, 02139
Journal of the Acoustic Society of America 59:176-182, January 1976
</affiliation>
<bodyText confidence="0.999663">
The formant structure of three dipthongs, four tense vowels, and three retroflex sounds was
examined in detail for possible speaker-identifying features. Formant tracks were computed
for each sound under investigation using covariance-type pitch-asynchronous linear prediction
together with a root-finding algorithm. The interspeaker variability of about 200
measurements made on these formant tracks was compared initially with intraspeaker
variability through the calculation of F ratios. Those with average F ratios greater than 60
were evaluated further with a probability-of-error criterion. Features that are potentially
most effective in identifying speakers are the minimum second-formant value in [ar], the
maximum first-formant value in [ar], the maximum second-formant values of [o], and [ 1].
and the minimum third-formant value of [1 The individual differences apparent in these
sounds presumably depend mort on speaker habits than on vocal-tract anatomy. The error
bound predicted-for a sneaker identification procedure based on these five features in 0.24%.
An identification experiment using only the best two features gave 12 errors out of 80
identifications.
</bodyText>
<note confidence="0.5892984">
PHONETICS-PHONOLOGY: RECOGNITION 40
Linear Estimation of Nonstationary Signals
Lduis A. Liporace
Institute for Defense Analysis, Communications Research Division, Princeton, New Jersey
08540
</note>
<subsectionHeader confidence="0.414583">
Journal of the Acoustic Society of America 58:1288-, December 1975
</subsectionHeader>
<bodyText confidence="0.9936894">
Implicit in the use of linear prediction is the assumption that within each analysis frame the
signal is stationary. The acoustic signal is assumed to be suitably approximated by a
recursion which describes a linear time-invariant acoustic system composed of a
concatenation of equal-length, constant-diameter nondissipative tubes. That is, assoicated
with the coefficients (c) in the recursion is a stylized articulatory configuration which
remains fixed throughout the analysis interval. If we allow the coefficients to be functions
of time rather than constants we can obtain a more realistic model in which the parameters
of the model change continuously and automatically which articulation, &apos;,rather than
discontinuously at fixed intervals. The time-varying area function can be estimated by
adapting Wakita&apos;s procedure.
</bodyText>
<note confidence="0.209349">
PHONETICS-PHONOLOGY: RECOGNITION
</note>
<title confidence="0.353078">
A Semiautomatic Pitch Detector (SAPD)
</title>
<author confidence="0.272042">
Carol A. McGonegal, Lawrence R. Rabiner, and Aaron E. Rosenberg
</author>
<affiliation confidence="0.440787">
Bell Laboratories, Murray Hill, New Jersey 07974
</affiliation>
<subsubsectionHeader confidence="0.477634">
IEEE Transactions on Acoustics, Speech, and Signal Processing 23:570-574, December 1975
</subsubsectionHeader>
<bodyText confidence="0.99931425">
The determination of an utterance&apos;s pitch contour utilizes simultaneous display (ra a 10 ms
section-by-section basis) of the low-pass filtered waveform, the autocorrelation of a 400-
point segment of the wideband recording. For each of the separate displays (i.e., waveform,
autocorrelation, and cepstrum) an independent estimate of the pitch period is made on an
interactive basis with the computer, and the final pitch period decision is made by the user
based on results of each of the measurements. Formal tests of the method were made in
which four people were asked to use the method on three different utterances, and their
results were then compared. During voiced regions, the standard deviation in the value of the
pitch period was about 0.5 samples across the four people. The standard deviation of the
location of the time at which voiced regions became unvoiced, and vice versa was on the
order of a half a section duration, or 5 ms. The major limitation of the proposed method is
that it requires about 30 min to analyze 1 s of speech.
</bodyText>
<note confidence="0.674507">
PHONETICS-PHONOLOGY: RECOGNITION 41
</note>
<title confidence="0.5342415">
A Pitch-Synchronous Digital Feature Extraction System for Phonemic
Recognition of Speech
</title>
<author confidence="0.560959">
Wolfgang J. Hess
</author>
<subsubsectionHeader confidence="0.344685">
Institut fuer Informationstecknik (Datenverarbeitung), Technische Universitaet Aluenchen
IEEE Transactions on Acoustics, Speech, and Signal Processing 24:14-25, February 1976
</subsubsectionHeader>
<bodyText confidence="0.999679714285714">
The system has three portions: pitch extraction, segmentation, formant analysis. The pitch
extractor uses an adaptive digital filter in time-domain transforming the speech signal into a
signal similar to the glottal waveform. Using the levels of the speech signal and the
differenced signal as parameters in time domain, the subsequent segmentation algorithm
derives a signal parameter which describes the speed of articulatory movement. From this,
the signal is divided into &amp;quot;stationary&amp;quot; and &amp;quot;transitional&amp;quot; segments; one stationary segment is
associated to one phoneme. For the Formant tracking procedure a subset of the pitch periods
is selected by the segmentation algorithm and is transformed into frequency domain. The
formant tracking algorithm uses a maximum detection strategy and continuity criteria for
adjacent spectra. After this step the total parameter set is offered to an adaptive universal
pattern classifier which is trained by selected material before working. For sationary
phonemes. the recognition rate is about 85 percent when training material and test material
are uttered by the same speaker. The recognition rate is increased to about 90 percent when
segmentation results are used.
</bodyText>
<sectionHeader confidence="0.942067" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.951895">
Analysis of Intonation Signals by Computer Simulation of Pitch-Perception
Behavior in Human Listeners
</subsectionHeader>
<bodyText confidence="0.507757">
Yukio Takefuta
</bodyText>
<subsubsectionHeader confidence="0.350186">
Ohio State University
S1GLASH Newsletter 8, No. &apos;1:1-8, February 1975
</subsubsectionHeader>
<bodyText confidence="0.9998291">
Pauses are used to delimit utterances into segments. Linear regression analysis of pitch
patterns allows a 4-way classification of slopes of lines: fast rising, rising, level, falling.
These are the 4 Fundamental Pattern Features (FPF). A combination of 2 or 3 (of the 4)
FPF&apos;s per segment of utterance is a pitch pattern (80 possible). An intonation pattern is a
comuination of pitch patterns. The position of the highest frequency wilue in the utterance
is important. In comparing 2 utterances. if the high point occurs in different segments the
intonations are contrastive even if the pitch patterns are the same. Of the 80 possible pitch
patterns, some must be recognized as cardinal patterns and same as cognate patterns to the
cardinal patterns. Different sets of rules must be used for the &amp;quot;high&amp;quot; segment and the final
segment of the utterance.
</bodyText>
<note confidence="0.6137525">
PHONETICS-PHONOLOGY: RECOGNITION 42
Graph-Theoretic Cluster Analysis and Its Application to Speech Recognition
</note>
<author confidence="0.550008">
Z. Chen
</author>
<affiliation confidence="0.68251">
School of Electrical Engineering, Purdue University, West Lafayette, Indiana
</affiliation>
<author confidence="0.272192">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 225-242
</author>
<bodyText confidence="0.989543555555556">
A clustering algorithm is mainly a two stage process: 1) selection of a nairwise similarity
measure between every two samples or objects in the data set, 2) the similarity measure is
used in a sorting procedure whereby groups of similar samples are extracted. In a graph-
theoretic clustering algorithm a graph is constructed for the given data and subgraphs G
satisfying certain properties are obtained. The clustering algorithm features a flexible method
of edge construction (k-nearest neighbor threshold method), N1 hich allows the grouping of
samples to be more effective, and the generalized Frisch&apos;s labelling algorithm, which detects
and removes the possible chaining effect in the data. The algorithm is applied to the
recognition of nasal consonants.
</bodyText>
<sectionHeader confidence="0.725548" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.420758">
A Comparison of Several Speech-Spectra Classification Nethods
</subsectionHeader>
<bodyText confidence="0.245211">
H. F. Silverman, and N. R. Dixon
</bodyText>
<affiliation confidence="0.9351385">
Speech Processing Group, Computer Sciences Department, IBM Thomas J. Watson Research
Center, Yorktown Heights, New York
</affiliation>
<subsubsectionHeader confidence="0.339095">
1 BM Research Report 5584, 18 August 1975
</subsubsectionHeader>
<bodyText confidence="0.9888734">
Two measures of performance of speech spectra classification--accuracy and stability--were
derived through the use of an automatic performance evaluation system. Over 3000 hand-
labelled spectra were used. The most successful classification method involved a linearly-
mean-corrected minimum distance measure. on a 40-point spectral representation with a
square (or cube) norm. Straight minimum distance is the worst performer. The question of
appropriate point representation is really one of adequate information retention. The 80-
point representation contains too many components above 3kHz while 20- and 10-point
representations contain insufficient information relative to the classes to be discriminated.
The value of the norm exponent primarily relates to the weight given extrema in the norm
kernel; a heavier weighting (2 or 3) should be placed on extrema.
</bodyText>
<note confidence="0.5374165">
PHONETICS-PHONOLOGY: RECOGNITION: CHINESE 43
Speech Recognition and Chinese Voice Input for Computer
Kung-Pu Li
TRW Systems Group, One Space Park, Redondo Beach, California
</note>
<author confidence="0.6897725">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 211-223
</author>
<bodyText confidence="0.999720111111111">
The machine recognition of Mandarin mono-syllables seems to be feasible at the present. An
integrated recognition procedure of monosyllable utterances has also been suggested, and some
results are described. The basic syllable structure contains three major parts: initial, tone, and
final. The initial contains only consonantal phonemes of four different categories: sonorant,
plosive, fricative, aspirate. There are four tonemes in Mandarin Chinese; the pitch contours
cover only the final part of the syllable. In the vowel part of a syllable, although seven
phonemes are sufficient to describe all possible vowels, the final can also contain dipthongs
and tripthongs composed of more than one vowel phoneme. An itegrated recognition
procedure of monosyllable utterances has been suggested, and some results are reported.
</bodyText>
<sectionHeader confidence="0.975647" genericHeader="method">
PHONETICS-PHONOLOGY: CHINESE
</sectionHeader>
<subsectionHeader confidence="0.984985">
Chinese Phonemes Analysis and Synthesis
</subsectionHeader>
<author confidence="0.337458">
T. Y. Chou, and K. C. Huang
</author>
<affiliation confidence="0.503832">
National Chiao Tung University, Hsinchu, Taiwan, Republic of China
</affiliation>
<author confidence="0.369599">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 1227-1241
</author>
<bodyText confidence="0.999766083333333">
The system for producing consonants is a noise generator followed by a pole-zero resonator,
while that for producing vowels is a quasi-periodic pulse generator with variable period
followed by a resonator with three variable poles called formant frequencies, ranging from 0
to 3 KHz. The results of analyzing, by means of sonagrams obtained from ten male voices,
show that the 16 vowel phonemes can be classified into two classes as single and compounded
vowel sounds. Some of the synthesized single vowels are very monotonic and can be
recognized. Others, with third formant frequency slightly greater than 3 KHz are not as
clear, due to the fast decaying of high frequency components in the generated pulses. The
compounded vowels are also synthesized by a step variation of formant frequency derived
from its components. The result is also well recognizable. The sonogram analysis of a
continuous Chinese speech shows that every word and its spelling phonemes are quite
independent and separable, and are therfore very different from English speech.
</bodyText>
<note confidence="0.925672">
WRITING 44
Graphemic Synthesis: The Ultimate Solution to the Chinese Input/Output
Problem
</note>
<author confidence="0.642972">
Carl Leban
</author>
<affiliation confidence="0.72089">
The University of Kansas, Lawrence
</affiliation>
<author confidence="0.654449">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 533-552
</author>
<bodyText confidence="0.9999616875">
In design of 10 systems for human graphics it is necessary to simulate the activity of writing
and not the graphic result of that activity. Orthographic rules. are essentially sets of criteria
for determining proper serial order of graphic signs, upon which further subsets of phonetic,
semantic, graphic and other conventions are imposed. Chinese orthography is of the
polyalternating polyvariable type in which a number of undefined subsets of graphic signs
combine with each other in any of several possible juxtapositional modes according to rules
not yet fully elucidated. But if the loi.:,,ography is not converted to an invariable series it
cannot be input to, manipulated in, or output from a digital computer. The temporal series
in which elements are composed into logog.rapM is variably serial, and therefore computer
compatible. Graphemic synthesis is a procedure by which logographs are mechanically
produced in a manner simulating the normal writing procedure. Since logographs are
synthesized from a small finite set of component elements, there is no need to prestore
logographs, but only the small grapheme set. Output in normal logogr,iphy is achieved as
needed only at the output end by reversal of the synthesizing process. It is possible to
achieve a synthesis at somewhat less than the ideal level, pseudographemic synthesis, and this
has been implemented in the SINCO system.
</bodyText>
<sectionHeader confidence="0.584415" genericHeader="method">
WRITING: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.386549">
Feature Extraction on a Finite Set of Binary Patterns
</subsectionHeader>
<author confidence="0.232716">
Paul P. Wang, and William S. Hodgkiss, Jr.
</author>
<affiliation confidence="0.657429">
Department of Electrical Engineering, Duke University, Durham, North Carolina
</affiliation>
<author confidence="0.340002">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 183-194
</author>
<bodyText confidence="0.9901405">
A &amp;quot;best&amp;quot; subset of mutually orthogonal features which are minimum in mumber but sufficient
to discriminate a finite set of patterns is chosen from a much larger set of available features
in a systematic and deterministic manner by a heuristic program based on the criterion of
maximum separability. The unique code words for the finite set of binary patterns are
established through a learning procedure derived from a theorem on necessary and sufficient
conditions for mutual independence of these vectors over a binary field.
</bodyText>
<note confidence="0.329171666666667">
WRITING: RECOGNITION: CHINESE 45
An Experimental System for the Recognition of Handwritten Chinese
Characters
</note>
<author confidence="0.326828">
Shi-Kuo Chang
</author>
<affiliation confidence="0.646223">
Institute of Mathematics, Academic Sinica, Nankang, Taipei, Republic of China
</affiliation>
<author confidence="0.940902">
Der Her Lo
</author>
<affiliation confidence="0.5762545">
Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan, Republic
of China
S. Gould, Ed., Proceedings of the First Internatiocal Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 257-267,
</affiliation>
<bodyText confidence="0.999518090909091">
A Chinese character can be thought of as composed from a set of straight line segments. A
stroke is ideally a line segment or a concatenation °I several straight line segments. Each
straight line segment has its starting point, direction and length. There is also a specified
sequence among these segments. The specified sequence of line segments for a character is
the same as the seqbence of their starting points. Therefore, when a character is drawn on
the tablet of the digitizer, the output paper tape containing the (x,y) coordinates of sampling
points of each of its line segments presents these points in the proper order. The
preprocessor produces a sequence of simplified straight line segments, each with a direction
code and length, from the paper tape input, and sends the results to the classifier which
constructs a dictionary of characters which it then uses in the recognition process. The
program achieved 95% recognition for a test sample of 300 Chinese characters.
</bodyText>
<sectionHeader confidence="0.89366" genericHeader="method">
WRITING: RECOGNITION: CHINESE
</sectionHeader>
<subsectionHeader confidence="0.961279">
Computer-Aided Chinese Character Recognition by Forward Markovian
Dynamic Programming
</subsectionHeader>
<author confidence="0.76868">
Yung-Lung Ma
</author>
<affiliation confidence="0.845325">
Department of Electrical Engineering, National Taiwan University, Taipei, Republic of China
</affiliation>
<reference confidence="0.25375405">
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 269-286
A Chinese character may be called a kind of block picture. Each stroke seems to be a
hieroglyph. Curves formed by several strokes or by a continous stroke do not happen very
often. Some characters only differ by a single stroke. If the Markovian processes mentioned
in this paper are used, detailed recognition for each row and column is available and even a
single stroke would not be missed absolutely, so the increasing the degree of correct
recognition is by no means a problem. A plane block picture may be divided tnto plane
blocks while a solid one can be discussed by divi,ding it into solid blocks. The greater the
number of layers, the higher the degree of correct recognition. The input, pattern is divided
into 20 layers for individual recognition. If every layer satisfied the condition, then
recognition is complete. If one of the layers has a great difference, then the pattern should
be another picture.
WRITING: RECOGNITION: CHINESE 46
The Topological Analysis, Classification, and Encoding of Chinese Characters
for Digital Computer Interfacing—Part I
Paul P. Wang
Department of Electrical Engineering, Duke University, Durham, North Carolina
S. Gould, Ed., Proceedings of the First&apos; International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 417-439
</reference>
<bodyText confidence="0.94759425">
A set of features believed to be useful in classification and recognition and which is deduced
from topological properties and heuristic properties is proposed. An encoding scheme offers
a unique code word for each character (signature) of a dictionary of about 6,000 items. A
three-stage machine recognition system, based upon the optimal multiple category
classification principle, has been proposed to solve the problem of automatic reading of
Chinese characters. A by product of this research is the development of a topologically based
lexicographical ordering for a useful Chinese dictionary. Finally, some recommendations
concerning machine recognition of printed Chinese ideographs are made.
</bodyText>
<sectionHeader confidence="0.734742" genericHeader="method">
WRITING: SYNTHESIS: CHINESE
</sectionHeader>
<reference confidence="0.662998">
Software Method in kanji Information Processing
Teiji Kakinuma
Fujitsu Limited, Minato-ku, Tokyo, Japan
Kenmi Tsukatani
PET)&apos; Limited, Chiyoda-ku, Tokyo, Japan
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 983-998
</reference>
<bodyText confidence="0.983873090909091">
En the FCL (FACOM Composition Language) System, information is punched on paper tape
with a Kanji keyboard. The layout data turns out the forms of final printed matter as
parameters, punched with an alphanumeric keyboard, and these are applied to the FCL as an
input together with the text data. The results of the editing by the FCL are output to a
cassette magnetic tape, transferred to the photo type-autosetter, and are printed on film. At
this stage a print for correction is completed and this print is placed in the correctio.n
processing cycle. The correction processing generates the corrected data concerning errors in
the test and layout data and this corrected data is again input to the FCL. The FCL saved
file is utilized as the objective of the correction processing. The FRAME program is the
portion of the layout control system which defines paragraph groups which have the same
character and shape.
</bodyText>
<note confidence="0.624292">
WRITING: SYNTHESIS: CHINESE 47
</note>
<reference confidence="0.8531156">
Photo-Electrostatic Kanji Printer
Atsushi Ishi, Yoichi Hagiwara, Woshimitsu&apos;Masui, and Yoshiyuki Aida
Fujitsu Ltd., Minato-Ru, Tokyo, Japan
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 969-981
</reference>
<bodyText confidence="0.995043714285714">
This Kanji printer consists of a character generator and a printer. The character generator
has a small rotating image disc with 5,376 Gharacters printed on it, and the character patterns
are converted into video signals by a vidicon. The printer has an optical fiber tube and a
photo-electrostatic recording element. Reproduced character patterns on the surface of the
optical fiber tube are recorded on the dielectric coated paper by a photo-electrostatic element.
This Kanji printer is capable of printing 100 characters a second, and is usable for any
application of printing in Kanji.
</bodyText>
<sectionHeader confidence="0.730009" genericHeader="method">
WRITING: SYNTHESIS: CHINESE
</sectionHeader>
<reference confidence="0.6207306">
Designing Storage/Output Units. for Chinese Input/Output Digital Computers
Kai Huang
Department of Electrical Engineering, University of Miami, Coral Gables, Florida
S.Gould., Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 931-942
</reference>
<bodyText confidence="0.998321">
The storage unit (SU) provides a permanent filing cabinet for storing Chinese characters in
any predetermined binary-coded form. The stored information is addressable and readable
from external control. The SU contains a large-scale cellular array of Read-Only Memories
(ROM) with the associated address decoder, control logic, memory address/data registers and
sense amplifier to enable readability, The output unit is used for printing or displaying
decoded Chinese in ideographic form. It consists of a k2-segment character decoder, two
buffer registers, and auxiliary display terminals (DT). The DT may take many forms, such as
a multiple-head printer, D/A converter and storage CRT monitor or a graphical display
console make with an array of light emitting devices (LED).
</bodyText>
<reference confidence="0.783376714285714">
WRITING: SYNTHESIS: CHINESE 48
Computer-Aided Design of Chinese Character Patterns
Hideo Hirahara, Kiyoshi Kibuchi, and Masamitsu Satou
Informations Systems Research Laboratory, Toshiba Research and Development Center,
Kawasaki-City, Japan
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/OUtput Systems, Ac r :mia Sinica, 909-930
</reference>
<bodyText confidence="0.792598666666667">
The System generates dot patterns from any original design plttern or handwritten items.
The source patterns are scanned with a vidicon camera and recurded on magnetic tape. The
following procedures are used: 1) Noise elimination and smoothing of scanned patterns, 2)
Line enhancement, 3) Matrix size compression, 4) Interactive refinement, 5) Automatic
generation of Chinese charackr read only memory (ROM) patterns. The obtained dot
patterns are then translated into a paper tape for a numerical controller which in turn drives
the wiring system for the read only memory. Chinese character line printers, CRT displays,
and other Chinese character output devices can be implemented by this Chinese character read
only memory.
</bodyText>
<sectionHeader confidence="0.394412" genericHeader="method">
WRITING: TEXT INPUT: CHINESE
</sectionHeader>
<reference confidence="0.971378833333333">
A;System Design for the Input of Chinese Characters through the Use of
Phonetic and Orthographic Symbols.
H. C. Li, S. P. Hu, C. L. Jen, H. Chou, S. Shan, and E. T. Chen
Department of Economics, Bryant College, Smithfield, R.I.
S. Gould, Ed., h-oceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 501-511
</reference>
<bodyText confidence="0.936417916666667">
The following principles have been observed in system design: 1) Easy to Learn and Use, 2)
Inexpensive to Implement, 3) Higher input Rate, 4) Unique Code for Dictionary Search, 5)
Facilitate Other Related Applications. The input of Chinese characters is through thc use of
phonetic and orthographical symbols. The total number of symbols needed to transcribe a
single Chinese character varies from a lower limit of three to a maximum of eight. A single
Chinese character require a maximum. of three phonetic symbols and one intonation notation
to indicate pronunciation. By coupling one to four of fifteen orthographical symbols with
the pronunication symbols, each Chinese character can be uniquely transcribed into a set of
symbols which indicates the pronunciation as well as the orthographical structure of the
ideography. No new hardware is required for implementation. With some minor
modifications, the keypunch machines and other typewriter-like input peripherals now
available on the market can be used immediately.
</bodyText>
<reference confidence="0.717550285714286">
WRITING: TEXT INPUT: CHINESE 49
A New Approach to a Chinese (Tele) Typewriter, Which Can be Used as a
Telex, Data Terminal and Computer Input/Output Device
Ye-San Liu
Directorate General of Telecommunications, Taipei, Republic of China
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 489-499
</reference>
<bodyText confidence="0.9997539">
A typing Keyboard is proposed which is arranged like an English teletypewriter, using an 8-
unit code as in an ASCII code with even parity Switching a lever key, you will be able to
type Chinese or English. When you type Chinese, you need only to push a key three times at
most to complete the selection of a character. Then the character will come out by pushing
the space bar once. If it is so arranged as to push a key three times for all characters, we
shall be able to save the process of pushing the space bar for every character. The rules of
decomposing Chinese characters are studied. The key layout of the keyboard is so arranged
as to make recognition of key position easy. Four simple typing rules have been determined.
There are only 21, out of the 3,000 characters which often appear in current newspapers, that
share the same 3 keyed codes, and so they have been treated as exceptions.
</bodyText>
<sectionHeader confidence="0.61978" genericHeader="method">
WRITING: TEXT INPUT: CHINESE
</sectionHeader>
<reference confidence="0.918365666666667">
PEACE--A Phonetic Encoding and Chinese Editing System
Shi-Kuo Chang, Chi-Shion Chiu, Ming-Hwei Yang, and Bao-Shuh Lin
Computation Laboratory, Institute of Mathematics, Academia Sin/ca, Nankang, Republic of
China
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sin/ca, 29-47
</reference>
<bodyText confidence="0.996066444444444">
Different Chinese characjers may have the same phonetic transcription (using Chinese
National Phonetic Symbols), requiring methods to disambiguate homonyms. If however, the
Chinese text is coded into phrases separated by delimiters, then the phrases can often be
decoded unambiguously to obtain the corresponding string of Chinese characters. The file
structure for the PEACE system consists of a character file and a phrase file. Chinese
characters are stored in the form of a composition rule. The phonetic encoding method has
also proved to be quite satisfactory, especially for the generation and editing of Chinese texts,
where more than 60% of the characters are embeded in phrases. Character encoding rates of
the order of 30 characters per minute can be attained with this system.
</bodyText>
<note confidence="0.591124">
WRITING: CHARACTER SETS: CHINESE 50
</note>
<title confidence="0.503669">
A New Alphameric Code for Chinese Ideographs
</title>
<author confidence="0.331193">
Nelson Ling-Sun Chou
</author>
<reference confidence="0.96308965">
East Asia Library, Rutgers University
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 471-488
The Following are assumed: 1) All Chinese ideographs are composed of one or more
components, and thus may be classified by the pattern of these components. 2) Each of the
comaonents is in turn composed of one or more graphic elements. The total number of
graptic elements is fairly limited. Ideographs may be divided into four major patterns:
Horizontal, Vertical, Bordered, and Independent. After identification of an ideograph&apos;s
pattern, a component&apos;s structure, and the basic elements, one can then perform the coding by
following rules for: 1) Ideograph as a whole, 2) Components, 3) Elements, 4) Relationship or
separation signs, 5) Coding sequence, 6) Component of bordered pattern, 7) Independent
ideographs of components.
WRITING: CHARACTER SETS: CHINESE
Chinese Input-Output with Standard IBM Selectric Typewriter Terminal
Ching C. Tsao
IBM Corporation, Armonk, New York
Emerson W. Pugh
IBM T.J. Watson Research Center, Yorktown Heights, New Yor,
S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese
Input/Output Systems, Academia Sinica, 459-469
</reference>
<bodyText confidence="0.854741142857143">
A multicorner indexing system has been developed for entering Chinese characters, using the
numeric keys of a standard computer terminal. Each character is uniquely coded with a
sequence of one to nine digits in a nine-corner extension of Wang&apos;s Four Corner System. A
20- by 21- dot array output code has been programmed in APL for use on the IBM 2741
Standard Selectric* Terminal with the fine-plot printing element. These two techniques can
be combined to provide an easily learned Chinese input-output system for use on standard
computer hardware.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.669796">Journal of Computational Linguistics 50</note>
<title confidence="0.9383408">THE FINITE STRING NEWSLETTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS VOLUME 13 - NUMBER 5 MAY TABLE OF CONTENTS An organization for a dictionary of word senses</title>
<author confidence="0.8860945">Dick H Fredericksen Current Bibliography</author>
<abstract confidence="0.914495444444444">Cahiers du groupe de travail Analyse et experimentation les sciences de l&apos;homme par les methodes informathiques - E. Chouraqui and J. Virbel 93 Bibliography and subject index, current computing . . 94 Directory of university computer science 95 security, and the information processing industry - Dahl A. Gerberick 96 AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published by the Center for Applied Linguistics for the Association</abstract>
<note confidence="0.689340230769231">for Computational Linguistics. G. Hays of Linguistics, SUNY Buffalo EDITORIAL ASSISTANT: William Benzon ADDRESS: Willows, Wanakah, New York 14075 EDITOR: A. ROBERTS Director, Center for Applied Linguistics MANAGEMENT ASSISTANT: hum Mminsan AND SUBSCRIPTION ADDRESS: North Kent Arlington, Virginia 22209 Copyright ©1976 Association for Computational Linguistics 2 Journal of Computational Linguistics 50 : 2</note>
<title confidence="0.985492">AN ORGANIZATION FOR A DICTIONARY OF WORD SENSES</title>
<author confidence="0.999962">DICK H FREDERICKSEN</author>
<affiliation confidence="0.998267">IBM THOMAS J. WATSON RESEARCH CENTER</affiliation>
<address confidence="0.955587">YORKTWON &apos;HEIGHTS, NEW YORK 10598</address>
<abstract confidence="0.987180521126761">This paper describes a lexical organization in which &amp;quot;senses&amp;quot; are represented in their own right, along with &amp;quot;words&amp;quot; and &amp;quot;phrases&amp;quot;, by distinct data items. The objective of the scheme is to facilitate recognition and employment of synonyms and stock phrases by programs which process natural la,nguage. Besides presenting the proposed organization, the paper characterizes the lexical &amp;quot;senses&amp;quot; which result. This paper describes an internal lexical organization which is particularly designed to capture the facts about synonymy. Besides recording the inclusion of each word in one or more synonym sets (identified with its various &amp;quot;senses&amp;quot;), the scheme attempts to distribute attributes perspicuously between &amp;quot;senses&amp;quot;, &amp;quot;wordings&amp;quot;, and the intersections of the two. In addition, there is proviSion to record multi-word idioms, stock phrases, and the like, and to include these as elements in synonym sets when appropriate. Briefly, &amp;quot;senses&amp;quot; are represented in their own right, along with &amp;quot;words&amp;quot; and &amp;quot;phrases&amp;quot;, by distinct data items. Each word or phrase is associated with a list of the &amp;quot;senses&amp;quot; which it can express; conversely, each &amp;quot;sense&amp;quot; is associated with a list of &amp;quot;alternative wo lings&amp;quot; Additionally, each word is associated with a list of phrases in which it occurs. Grammatical category, features, selection restrictions, and the like are applicable at three different levels: to words or phrases as such, to &amp;quot;senscs&amp;quot; as such, or to particular usages of words or phrases (equivalently, to particular wordings of &amp;quot;senses&amp;quot;). An Organization for a Dictionary of Word Senses 3 lexical organization has been implemented at Yorktown Heights, N.Y., by a program -not to be described here -which builds such dictionaries in a very compact form, giving interactive assistance to the person making the entries. (For example, the program points out the possibility of merging &amp;quot;senses&amp;quot; whenever their wordings overlap and their attributes are compatible, and merges them if so directed.) There are suitable facilities for saving the results, retrieving them in various ways, and for altering such things as schemes of classification without scrapping previously prepared work. The ultimate intent is that the &amp;quot;dictionary of senses&amp;quot; should serve as the lexical component in a natural language fact-retrieval system. Pending its incorporation in that role, it will be used to amass and organize information on the semantic relations among words and phrases. The balance of this paper comes in two sections: Section 2 presents the proposed lexical data structures, and suggests how they are to be used. Included is a sketch of how various types of grammatical and semantic &amp;quot;attributes&amp;quot; fit into the scheme. Section 3 discusses the character of the &amp;quot;senses&amp;quot; encoded in the resulting dictionary. Reasons are advanced for regarding lexical &amp;quot;senses&amp;quot; as something far short of semantic primitives. At the same time, synonym sets are defended against the view that &amp;quot;true paraphrases are rare or nonexistent&amp;quot;. Organization for a Dictionary of Word The Representation. _ It will be our purpose in this section to say just enough about internal representation to lay bare the organizing principles of the lexicon. The focus is on architecture and motivations; details of field layouts, internal codes, etc. are not at issue here. make the discussion concrete, suppose we are interested in the senses of the word Assuming that none of the words are unfamiliar, the following should put us in mind of two senses: change: 1. v alter; coin. This, of course, is just a dictionary entry in the traditional format (though with synonyms offered in lieu of definitions). On the other hand, we might approach the same information from a different direction: starting with the two concepts, we might seek words to express them. It is difficult to picture this latter situation without assigning artificial labels to the concepts. Call them concepts 1 and 2, and for a moment that there were a practical way to look the concepts up thought of either word for either concept). Then the information to be retrieved might be envisioned this way: change, alter small coin It is this duality of viewpoint -that words have senses, while senses have wordings -that our lexical representation must reflect. The starting point, then, is that words, phrases, and &amp;quot;senses&amp;quot; are separately represented. There are three principal types of data item, plus a standard connector: A Data Item&amp;quot; represents a single word. A Data Item&amp;quot; represents a string of two or more words which to serve as a unit in some context. Organization for a Dictionary of Word Senses A Data Item&amp;quot; represents one distinct sense common to a set of and/or phrases. In general, a word or phrase may be usable in more than one sense, while a given sense may have alternative (synonymous) wordings. Both these types of variability are recorded making use of the next data item: A Link Element&amp;quot; is a connective item, to be explained shortly. Three principal fields will engage our attention in each type of data item. Fig. 1 summarizes the fields for each type.</abstract>
<title confidence="0.90550225">Senses&amp;quot; Link Attributes Link Data Item) Senses&amp;quot; Link Attributes Links PDI (Phrase Data Item</title>
<author confidence="0.762029">Wordings Link Attributes Link</author>
<note confidence="0.6234724">SDI (Sense Data Item) Senses&amp;quot; Link Local Link. Attributes SLE (Sense Link Element) Fig. 1</note>
<title confidence="0.914523">Schematic of Data Items, with Principal Contents</title>
<author confidence="0.790939">Each KDI or PDI contains an alternative senses link</author>
<abstract confidence="0.997673552693209">pointer to the first SLE (Sense Link Element) in a chain of SLE&apos;s which represent the various senses of the word or phrase. The SLE&apos;s are chained via their own &amp;quot;alternative senses&amp;quot; links, and the final member points back to the KDI or PDI. Thus, we shall speak of such a chain as a ring Organization for a Dictionary of Word Senses specifically, an &amp;quot;alternative senses ring&amp;quot;. If no senses are on record for a particular word or , the &amp;quot;alternative senses&amp;quot; link in the seR referent. each Data Item) contains an &amp;quot;alternative wordings&amp;quot; link. This leads to a of which represent more-or-less synonymous wordings tnat express These SLE&apos;s are chained through their own &amp;quot;alternative wording links, and again the chain is closed a ring — this time beginning and ending with the structure that is shaping up may now be seen in Fig. crucial point is that each SLE represents the intersection between an &amp;quot;alternative senses ring and an &amp;quot;alternative wordings&amp;quot; the standpoint of the word or phrase, it, represents a particular sense; from the standpoint of the sense, it represents a particular wording from a PDI, one gets to the SDI for a particular sense by advancing along the &amp;quot;alternative senses&amp;quot; ring to the relevant SLE, then detouring along the ring which connects the to the one of the SDI&apos;s &amp;quot;alternative wordings&amp;quot;). Starting from an SDI, one gets to a particular wording by the reverse process. Since am &amp;quot;alternative senses&amp;quot; ring contains exactly KDI or each &amp;quot;alternative wordingsring contains exactly one SDI, each SLE is tied to exactly one sense of one word or phrase. (Eankvalently, it is tied to one wording of one sense.) The next point of interest is that &amp;quot;attribute&amp;quot; I ields are present in all four types of data item -even in the connectors (SLE&apos;s). The attributes which may be recorded in each, however, come from different bags. To begin with, the attributes found in an SDI characterize all the wordings of a given sense whenever the wording 3 are used in that sense. In Fig. 2, for example, sense &amp;quot;1&amp;quot; should be marked as a &amp;quot;verb&amp;quot; sense, while sense &amp;quot;2&amp;quot; is a &amp;quot;noun&amp;quot;. One would not wish to record the attribute &amp;quot;verb&amp;quot; in the KDI for the word &amp;quot;change&amp;quot;, for the KDI represents facts about the word itself, irrespective of sense, and &amp;quot;verb&amp;quot; does not hold for all uses of the word &amp;quot;change&amp;quot;. On the other hand, &amp;quot;verb&amp;quot; does characterize all wordings of sense &amp;quot;1&amp;quot;, whenever they&apos;re being employed to express that sense. It would furthermore apply to any additional wordings which we might think of, such as &amp;quot;modify&amp;quot;, provided they are really used in a synonymous way. As a matter of fact, it turns out that the traditional parts of speeth -noun, verb, adjective, preposition, etc. -fit best in this scheme as global attributes of senses, recorded in the SDI&apos;s. Organization for a Dictionary of Word Senses senses of &amp;quot;alter&amp;quot; SLE A (Verb) &amp;quot;alter&amp;quot; I SDI senses of &amp;quot;change&amp;quot; SLE wordings of SDI 1 &amp;quot;change&amp;quot; KDI 1 SDI senses of &amp;quot;small coin&amp;quot; t SLE wordings of SDI 2 &amp;quot;small coin&amp;quot; PDI Fig. 2 &amp;quot;Alternative Senses&amp;quot; and &amp;quot;Alternative Wordings&amp;quot; Rings (The first sense has two wordings: &amp;quot;alter&amp;quot; and &amp;quot;change&amp;quot;. The second sense has wordings &amp;quot;change&amp;quot; and &amp;quot;small coin&amp;quot;. Two senses are recorded for &amp;quot;change&amp;quot;, and one sense each for &amp;quot;alter&apos;: and &amp;quot;small coin&amp;quot;.) A different sort of attribute may be recorded in a KDI, as a global feature of the word itself. For example, we may note of the word &amp;quot;change&amp;quot; that it is &amp;quot;regularly conjugated&amp;quot;. That is, when used Organization for a Dictionary of Word Senses as a verb, it forms the third person singular by adding &amp;quot;s&amp;quot;, and both past Zand past participle by adding &amp;quot;ed&amp;quot; To be sure, this &amp;quot;global&amp;quot; attribute applies only to the &amp;quot;verb&amp;quot; senses of &amp;quot;change&amp;quot;; but a moment&apos;s reflection will confirm that &amp;quot;change&amp;quot; has more than one &amp;quot;verb&amp;quot; sense, and the regularity of its conjugation is common to all of them. Thus, it is useful to note this regularity as an attribute of the word itself. (Contrast this with the behavior of the word &amp;quot;can&amp;quot;, which is regular when it means &amp;quot;to pack in cans&amp;quot;, but irregular when it means &amp;quot;is able to&amp;quot;.) Various other attributes suggest themselves as global characterizers of the words themselves, to be recorded in the ‘KIDI&apos;s. For example, one might wish to note of &amp;quot;change&amp;quot; that it drops its final &amp;quot;e&amp;quot; when adding &amp;quot;ing&amp;quot; (this is the normal rule) but of &amp;quot;singe&amp;quot; that it doesn&apos;t. Still other attributes are appropriate when characterizing multi-word units (in PD1&apos;s). A string of words whose Meaning is not evident from the mere juxtaposition of its constituents (such as &amp;quot;give up&amp;quot;) may be classified as an &amp;quot;idiom&amp;quot;. A string of words whose meaning could be figured out from the meanings of its constituents, but which occurs with enough Frequency to warrant inclusion in the dictionary, might be classed as a &amp;quot;stock phrase&amp;quot;. (Example: &amp;quot;drop dead&amp;quot;.) A string like &amp;quot;perform in a subordinate role&amp;quot;, which one would not normally expect to encounter in its own right, might be classed as a &amp;quot;definition&amp;quot; (for a certain sense of the word &amp;quot;accompany&amp;quot;, difficult to reword except with a definition). Perhaps the most unexpected site for recording attributes is in the connective elements (SLE&apos;s). These are the logical place, though, to note features that apply to a specific sense of a word, without being global to either the sense or the word. Consider the following four sentences: On the way to the office, he stopped daydreaming. On the way to the office, he ceased daydreaming. On the way to the office, he ceased to daydream. versus: On th,e‘way to the office, he stopped to daydream. Suppose we choose to view this as a restriction upon the (surface) object of the verb: &amp;quot;stop&amp;quot;, when applied to an action, must take a gerund as its object; &amp;quot;cease&amp;quot; can take either a gerund or an infinitive. (It wouldn&apos;t affect the point being made if we said that &amp;quot;stop&amp;quot; inhibits a certain grammatical transformation en route to surface structure, while &amp;quot;cease&amp;quot; permits it.) Organization tor a Dictionary of Word Senses Now, we wouldn&apos;t want to mark &amp;quot;gerund object only&amp;quot; as a global attribute of the sense, for we have just shown that &amp;quot;cease&amp;quot; and &amp;quot;stop&amp;quot;, two wordings of the sense, differ with respect to this On the other hand, it doesn&apos;t belong among attributes of the word &amp;quot;stop&amp;quot; as such, for &amp;quot;stop&amp;quot; has other verb senses, even transitive ones, te which the restriction is completely inapplicable. (Consider &amp;quot;stop a hole in the dike&amp;quot;, &amp;quot;stop a catastrophe&amp;quot;, etc.) That leaves the alternative we are suggesting: treat the restriction as an attribute of one particular usage of the word (equivalently, one particular wording of the sense). &amp;quot;play&amp;quot; KDI &amp;quot;play doWn&amp;quot; PDI (1) (2) &amp;quot;down&amp;quot; KDI &apos;down payment&amp;quot; PDI (2) &amp;quot;payment&amp;quot; KDI Fig. 3 &amp;quot;Phrase Involvement&amp;quot; Rings (Where numbers are shown on connecting links, they indicate the position of the word in the phrase which is linked to.) An Organization for a Dictionary of Word Senses 1 0 Besides having senses, individual words are involved in phrases, and this fact is also represented in our data structure. Fig. 3 shows the plan of attack. In the KDI for each word, there is a link it to the the first phrase in which the word is known to occur, together with a number designating the position of the word (1st, end, 3rd, etc.) in that phrase. In the PDI itself, there is a continuation link for each word of the phrase, together with its number in the next In the final PDI involving a given word, the link for that word points back to the independent of its &amp;quot;alternative senses&amp;quot; ring, each have a &amp;quot;phrase involvements&amp;quot; ring. This structure makes it possible to retrieve all the idioms, stock phrases, definitions, etc., in which a given word has made its appearance, anywhere in the dictionary. As the same structure is used to encode every multi-word unit, no occurrence of a word is ever lost sight of, and a phrase can be looked up via any of its constituent words. Of the fields to which Fig. 1 calls attention, we have discussed all but one. In the SDI for each &amp;quot;sense&amp;quot;, thpre is a &amp;quot;sense chain&amp;quot; link field. This links the SDI to its successor in a global chain of &amp;quot;senses&amp;quot;. Using this chain, it is possible to make an exhaustive, non-duplicative list of all the &amp;quot;senses&amp;quot; recorded in the dictionary. The listing program has only to proceed down the chain, retrieve frdm each SDI its attributes, decode them, then chase around the &amp;quot;alternative wordings&apos; ring of the SDI and list the wordings alongside the attributes. One more feature of the internal representation deserves mention: the data items for words occur as &amp;quot;leaves&amp;quot; in a lexical tree (Fig. 4). That is, the KDI for a word can be looked up letter-by-letter, following a chain of pointers that correspond to successive letters. The chain ends at a KDI after following a substring sufficient to distinguish the word from the nearest thing like it in the dictionary. The lexical tree has the advantage that words can be looked up either at random or in sequence. Recapitulating, these are the essential features of the representation: *1) &amp;quot;Senses&amp;quot; are represented separately from &amp;quot;wordings&amp;quot;, and the mutual connections between them are made explicit in both directions. *2) &amp;quot;Wordings&amp;quot; may be either single words or multi-worct pnrases. i nese are representea ty distinct types of data item, and may be subject to distinct schemes of classification, but they are on the same footing with regard to &amp;quot;sense&amp;quot; connections. With each word is associated an exhaustive list of the phrases in which it occurs. Organization for a Dictionary of Word (start) 1 &amp;quot;monkey&amp;quot; t_ KDI blank &amp;quot;a&amp;quot; KDI A &amp;quot;abate&amp;quot; KDI &amp;quot;above&amp;quot; KDI Fig. 4 Lexical Tree (For a dictionary containing only the words &amp;quot;a&amp;quot;, &amp;quot;above&amp;quot;, &amp;quot;abate&amp;quot;, and &amp;quot;monkey&amp;quot;, this would be the full tree. The path to each word is only as long as needed to distinguish it from the neighbor with which it shares the longest leading substring.) *3) Classifiers and features, drawn from appropriate sets, may be attributed separately to words, to phrases, to senses, or to particular senses of words or phrases (i.e., to particular wordings of senses). *4) The data items which represent senses are globally chained, and may be exhaustively listed. Organization for a Dictionary of Word Senses 1 *5) The data items which represent words are accessible as &amp;quot;leaves&amp;quot; of a lexical tree; hence they may either be retrieved by lookup (in response to presentation of the words) or voltinteered in alphabetical order, Given a commitment to represent a lexicon as suggested by points *1 through *5 above, various implementations would be possible. Alternative implementations of individual points (though not of the scheme as a whole) have in fact been described by other writers. The lexical tree (*5), for is no great novelty: Sydney and William H. Jacobsen describe implementation of one such tree 115j.[101 also concerns a dictionary which uses this general style of organization for lookup. For that matter, the lexical tree is reminiscent of Feigenbaum&apos;s &amp;quot;discrimination tree.&amp;quot; [11 More interestingly, the separate representation of senses and wordings has been incorporated in systems by Simmons ([11], [12]) and by Larry R. Harris [3]. This way of looking at matters led Harris to remark some of the same points that we have been stressing: that senses have alternative wordings just as words have alternative senses; that multi-word phrases might occur on the same footing as individual words in the expression of a sense; and (interestingly enough) that part-of-speech information really adheres to the &amp;quot;sense&amp;quot;, not to the &amp;quot;word&amp;quot; Similarly, Simmons associates his &amp;quot;deep case&amp;quot; information with lexical nodes representing &amp;quot;worcisenses&amp;quot;., while words themselves are treated as &amp;quot;print image&amp;quot; attributes of the wordsenses. Harris&apos;s dictionary was only a minor component in a small-scale model of concept acquisition. No great number of either words or concepts was required to illustrate the principles at stake, so Harris programmed the dictionary as an array, with words represented by rows and &amp;quot;concepts&amp;quot; by columns. Elements of the array were merely frequencies, indicating the strength of association between each word and each concept. Needless to say, for a full-scale vocabulary of words and concepts, such an array is mostly empty: nobody would dream of expanding it in that form. From a programming standpoint, the only thinkable choice is some form of list structure. Having decided in principle to use &amp;quot;some form of list structure&amp;quot;, though, one might well ask: Why chains? Why rings? Why not just include in each Key Data Item a full list of pointers to the corresponding Sense Data Items, and vice-versa? The answer is simply one of convenience. It&apos;s easier to handle insertions and deletions when they don&apos;t require the movement of expanded items to new quarters, or the provision of &amp;quot;overflow&amp;quot; pointers. Its easier to reclaim freed storage when deleted items come in a handful of standard Organization for a Dictionary of Word Senses sizes. As for &amp;quot;rings&amp;quot;, they eliminate the need for two-way pointers, since one can break into a ring at any point and follow it to its source. It should be noted that to make rings an attractive representation, the details of the material being must cooperate, In particular, the rings must not become too long, or the to follow them becomes excessive. It happens that &amp;quot;alternative rings &amp;quot;alternative wordings&amp;quot; rings are typically short rarely more than a dozen links per ring. &amp;quot;Phrase involvement&amp;quot; rings, on the other hand, can become spectacularly long, especially for words like &amp;quot;a&amp;quot; and &amp;quot;to&amp;quot;. In practice, it&apos;s necessary to provide these rings with short-cut links. of these, programming details could be altered, however, without abandoning tile the scheme, which is given in points *I through *5 above. Organization for a Dictionary of Word Senses 4 The Characterof Senses. Perhaps the first thing to get straight about the &amp;quot;senses&amp;quot; represented in this dictionary is what they are not &amp;quot;concepts&amp;quot;; they are not a set of &amp;quot;primitives&amp;quot; into which human experience an be decomposed,. No conjecture is put forward here that any such collection of discrete, atomic concepts even exists, let alone that it might be finite. Rather, the senses&amp;quot; of the dictionary are in the nog.ure of fuzzy equivalence sets among words. (This is only a metaphor; we shall do more and more violence to the technical notion of an &amp;quot;equivalence set&amp;quot; as we proceed.) Each &amp;quot;sense&amp;quot; groups a set of words which, in a set of appropriate contexts: might be used more or less interchangeably. That the equivalence sets are fuzzy, one can convince oneself with but the briefest immersion in the materials of the language -trying to decide whether particular words belong in particular groups or justify the creation of new groups. Consider, for example, the following set of words and phrases: (abandon, give up, surrender, relinquish, let go, desert, leave, forsake, abdicate) Clearly, there is a common theme that can run through all of these, given the right circumstances. It might be expressed as &amp;quot;reluctant parting from somebody or something&amp;quot;. This can be seen by coupling the verbs with various possible objects: (abandon, give up, surrender) a town to the enemy (abandon, give up) all hope (give up, relinquish) one&apos;s claim to an estate (give up, let go) our entire stock at a loss (abandon, desert, leave) one&apos;s wife and children (desert, forsake) a friend in need (give up, abdicate) the throne Organization for a Dictionary of Word Senses (abandon, desert) an exhausted mine (forsake, give up) all other, keeping thee only to her/him (abandon, desert, leave) the area threatened by the storm Should we, then, declare this group of words to be a &amp;quot;sense&amp;quot;? There are difficulties. The various words carry nuances, which it may or may not be easy to ignore in a particular context. &amp;quot;Forsake&amp;quot;, for example, can suggest that there is something reprehensible about the action. It can also connote formal renunciation, and the above example from a marriage vow shows that the formality can be present without the reprehensibility. Nuances get in the way of interchangeability; it would sound strange to substitute &amp;quot;desert&amp;quot; into the marriage vow. Besides nuances, the individual words have conventional areas of application. One does not normally say that the doctors &amp;quot;deserted&amp;quot; all hope, or that an errant husband &amp;quot;surrendered&amp;quot; his wife and children. The minister officiating at a wedding would be considered daft if he adjured the bride and groom to &amp;quot;abdicate&amp;quot; all others, and a merchant would not advertize that he was &amp;quot;relinquishing&amp;quot; his entire stock at a loss. (Somehow, the latter situation calls for more pedestrian language.) At the opposite extreme, overawed by this lack of interchangeability, we might decide to respect the unique personality of each word, abolishing equivalence classes altogether. The inconvenience such a cop-out is obvious: we then have to introduce some for recognizing the equivalence of utterances that are intended synonymously, though they employ different words. But beyond being inconvenient, the exclusion of equivalence sets is a denial of linguistic facts -just as bad, in its own way, as the naive attribution of unconditional synonymy. For it is a commonplace of everyone&apos;s experience that the speaker and the listener agree to ignore the nuances of words, whenever nuances get in the way of communication. A writer who has used the word &amp;quot;give up&amp;quot; eight times in five lines will surely cast about for some alternative ways of saying the same thing. If &amp;quot;relinquish&amp;quot; and &amp;quot;abandon&amp;quot; would normally be too flowery, or if &amp;quot;surrender&amp;quot; would in other circumstances call to mind an armistice ceremony in a railway wagon. that will not deter the writer from tossing in a few occurrences of those words -once a context has been established that discourages the overtones. Nor will the reader understand matters any It is as if writer and reader conspired: &amp;quot;We&apos;re fed up with let&apos;s hear another,&amp;quot; Or, perhaps, the writer simply connives at jolting the reader awake with frequent changes of idiom, maybe even an occasional incongruity. In any case, synonymy is imposed upon Organization for a Dictionary of Word Senses 1 the words, and this literary behavior merely exaggerates what people do habitually in c6mmon speech. only can words be stripped of nuances normally present; they can an suggested by the context. The suggestion of &amp;quot;reluctance&amp;quot; conveyed by all the verbs of our example can be inferred, in at least one case, from the setting alone; and in this case, a variety of more neutral verbs could be used synonymously: (part with, take leave of) our entire stock at a loss One could even substitute the word &amp;quot;sell&amp;quot;, and it wouldn&apos;t change the meaning that was already t ad into the utterance. But to admit context-dependent synonymy of this degree is to stretch the equivalence sets&amp;quot; to the point of uselessness. It comes to this: neither the grouping nor the separation of words can be fully justified. Grouping is nearly always conditional, and separation is often so. if one could anticipate all possible contexts in which a group of words could occur, one could perhaps enumerate all possible equivalence sets -one for each combination of word group with a set of contexts making the words interchangeable. Anyone, however, can see the futility of that aspiration. In the end, one settles for messy compromises. Words are grouped if a largish set of contexts in which they are interchangeable springs readily to mind. They are separated (into perhaps overlapping groups) if the imagination readily suggests contexts in which their meanings differ &amp;quot;significantly&amp;quot; -whatever &amp;quot;significantly&amp;quot; may mean. In doubtful cases, when words are grouped somewhat questionably, one promises oneself to add markings some day that will prevent misuse of the equivalence. When words are separated somewhat questionably, one promises oneself to add a mechanism some day that will recognize their relatedness. In the end, too, one assigns internal structure to the equivalence sets. That&apos;s the effect of assigning local attributes to the alternative wordings (&amp;quot;animate subject&amp;quot;, &amp;quot;object a vehicle&amp;quot;, etc.): constraints are imposed upon the interchangeability of the wordings. More radical structuring can be accomplished if, for example, one notes &amp;quot;government&amp;quot; as an alternative wording of the sense &amp;quot;govern, rule, control&amp;quot;, with the attribute &amp;quot;nominalization&amp;quot;. A trenchant discussion of such difficulties may be found in Kelly and Stone [4]. There the emphasis is upon disambiguation: given a word in a passage of text, they seek to identify (by selection from a fixed list of possibilities) the sense in which it is used. Building a computerized Organization for a Dictionary of Word Senses 1 dictionary for the purpose, they soon became concerned with the arbitariness and the proliferation of target &amp;quot;senses&amp;quot;, as taken from standard desk dictionaries. They argue, with persuasive examples, that what lexicographers conventionally distinguish as separate senses of a word are often jusl applications of the word&apos;s underlying concept to different contexts. To cover the various contexts, the underlying concept has to be stretched a little, by a process of metaphoric extension. This metaphoric process is beyond our present power to computerize, but for the long run looks indispensable for successful language processing. Meanwhile, the authors advocate a dictionary which re cords for each word as few discrete senses as practicable, combining into one sense all the usages which can reasonably be united by a common underlying thought. It is interesting to re-examine Kelly and Stone&apos;s argument with a different task in mind: not the of one word, but of synonymy between two words. A metaphorical capability would be as useful for the one task as for the other, but in the case of synonym recognition, some of the considerations which have guided traditional lexicography remain pertinent. In particular, it is necessary to ask not merely whether the concepts overlap, but whether the one word may in fact be used in place of the other. As noted before, usage is restricted by conventional domains of application; for example, an &amp;quot;alteration&amp;quot; is conceptually both a &amp;quot;change&amp;quot; and a but one wouldn&apos;t a change or a modification when painting a sign for a tailor&apos;s shop. The arbitrariness of the equivalence sets is not all that disqualii ies them as &amp;quot;conceptual primitives&amp;quot;. There is a much deeper difficulty in the fact that practically all &amp;quot;senses&amp;quot; can be paraphrased in terms of other &amp;quot;senses&amp;quot;. Take, for example, the intransitive sense of &amp;quot;change&amp;quot; (as in &amp;quot;My, but you&apos;ve changed!&amp;quot;). Surely, one would suppose, the concept of &amp;quot;change&amp;quot; must be primitive? Change of state is what well-nigh a third of all verbs are about. But if &amp;quot;change&amp;quot; is a &amp;quot;primitive&amp;quot;, it&apos;s a peculiar sort of &amp;quot;primitive&amp;quot;, for it can be paraphrased in a variety of ways: (change, become different, cease to be the same, assume new characteristics, make a transition into a new state) Note that the multi-word paraphrasals are not idioms; the individual words contribute their usual meanings to concatenated meanings which express the concept &amp;quot;change&amp;quot;. Organization for a Dictionary of Word Senses 1 But perhaps we were merely unlucky? Perhaps we chanced upon a concept which looked elemental but actually turned out to be complex. Maybe the real primitives are &amp;quot;become&amp;quot;, &amp;quot;be&amp;quot;, &amp;quot;cease&amp;quot;, &amp;quot;different&amp;quot;, &amp;quot;same&amp;quot;, etc. Let&apos;s dig into that possibility. What does it mean to &amp;quot;become X&amp;quot;, where X is an adjective? The meaning can be variously expressed: to be, X, get to be X, get X, turn X, grow X, assume the characteristic X) That&apos;s a discouraging number of ways for a &amp;quot;primitive&amp;quot; to be re-expressible -though if we choose to regard &amp;quot;come to be&amp;quot; and &amp;quot;get to be&amp;quot; as idiomatic concatenations of words, only one of the alternatives makes use of other concepts to explain the one at hand. As for &amp;quot;different&amp;quot;, it implies a whole underlying anecdote about somebody making a comparison, after first making a judgment about relevant things to compare. In the combination of the two concepts -- &amp;quot;become different&amp;quot; --, we furthermore drop mention of the objects being compared. It&apos;s simply understood that they are certain attributes of the subject at two points in time. It is tempting to invent ad-hoc &amp;quot;transformational&amp;quot; explanations for these phenomena. One might conjecture, for example, that &amp;quot;The man changed.&amp;quot; is a surface realization of four underlying sentences: (Man be X at time m. Man be Y at time n. X not equal Y. Time n greater-than time m.) The-trouble with explanations of this sort -apart from the fact that they introduce growing complexity into the understanding of straightforward utterances -is that they assign arbitrary primacy to some concepts at the expense of others. Why should &amp;quot;time n greater-than time m&amp;quot; be an assumed primitive? May we not equally well conjecture that &amp;quot;time n greater-than time m&amp;quot; is a surface realization of these?: (Time be m. Time change. Then time be n.) For that matter, why not view Organization for a Dictionary of Word Senses 1 &amp;quot;Time elapsed.&amp;quot; surface form of this?: &amp;quot;At least one thing in the universe changed.&amp;quot; After all, what is &amp;quot;time&amp;quot; but a nominalized way of talking about the presence and partitioning of change? The difficulty, it would seem, lies in the very notion of context-independent &amp;quot;conceptual primitives&amp;quot;. The metaphor itself is at fault: it calls to mind a fixed set of alements, like those of which matter is composed, out of which all ideas must be compounded. But where concepts are concerned, primitivity is a matter of focus. Shift the perspective a little, and new elements swim into view as fundamentals, while former simples become complex. A more promising metaphor is the analogy to a vector space. A set of basis vectors is, in a way, a set of &amp;quot;primitives&amp;quot; out of which all the entities in the space can be composed. These primitives have the appealing property that they are only primitive relative to one frame of reference. Rotate your point of view, and what used to come natural as basis vectors are now at an angle; they become easier to express as sums of vectors that lie along new axes. That bears a resemblance to what we have seen,in the case of lexical &amp;quot;primitives&amp;quot;. Thus far and no further may the analogy be pushed, however. The elements which span &amp;quot;conceptual space&amp;quot; can be no such uniform set of objects as those in a veetor space, while the rules of composition are coextensive with grammar -at a minimum. Composition of concepts itself contributes to the meaning. (For that matter, it is arguable whether concepts are sufficiently separable to model them as discrete objects at all — whether simple or composite.) Moreover as &amp;quot;conceptual space&amp;quot; must encompass all things thinkable, the rules of composition must themselves be part of the space. That is, the operators as much as the things operated upon lie within the space to be spanned. A seeming counterexample to these remarks may be found in the &amp;quot;primitive ACT&apos;s&amp;quot; of conceptual dependency theory, as propounded by Schank, Goldman, Rieger, and Riesbeck ([2], [7], [8], [9]). a close reading, however, the &amp;quot;primitive ACT&apos;s&amp;quot; turn out to be paradigms -motivated large classes of verbs. The names of these paradigms replace specific verbs as building blocks in the &amp;quot;conceptual&amp;quot; representation of an utterance. The Organization for a Dictionary of Word Senses effect is to provide strong guidelines for the inference of unstated information, for the comparison of related utterances, for paraphrasal, etc. represent a particular verb in terms of these ACT&apos;s, however, it is necessary to augment ACT with various substructures which detail the manner, the means, the type of actor or object, etc. No reduced set of representatives is as yet offered for the adverbs, nouns, adjectives, etc. in terms of which the &amp;quot;primitive ACT&apos;s&amp;quot; are qualified. If such additional condensation were the elaboration of a gi&apos;ven utterance in terms of the of &amp;quot;primitives&amp;quot; might well ramify without practical end. In other words, reduction of the set of names for nodes (and labels for arcs) must be purchased at the expense of extending the number of them required to represent each utterance. In conceptual dependency representation, just as in the semantic networks&amp;quot; of Quillian [6], Simmons ([11], [12]), Slocum, and others, reality ultimately appears as a shimmering web, every part of which trembles when any part of it is touched upon. Taken in its totality, the system -as -is entirely compatible with skepticism about a of &amp;quot;conceptual primitives&amp;quot; In any case, the verbal &amp;quot;senses&amp;quot; proposed here lie at a far lower level of generality than the &amp;quot;primitive ACT&apos;s&amp;quot; used in conceptual dependency theory. In terms of that theory, they come closest to the so-called &amp;quot;CONCEXICON entries&amp;quot; used by Goldman in realizing surface expressions &apos;of a concept from its conceptual representation [2]. Given a primitive ACT, Goldman narrows it down to a particular &amp;quot;CONCEXICON&amp;quot; entry by applying the tests in a discrimination tree to the rest of the structure in which the ACT appears. Our lexical &amp;quot;senses&amp;quot;, therefore, are left with a humbled role. If they span anything, it might best be thought of as &amp;quot;communication space&amp;quot;, not &amp;quot;conceptual space&amp;quot;. Even in this light, they are a hugely redundant basis, and a not at all unique one. They form no inventory of the experiences being communicated about; &amp;quot;meaning&amp;quot; is still a step removed, still evoked rather than embodied by the elements of this basis. If we persist in calling these things &amp;quot;senses&amp;quot;, it is because that is the traditional term for what is to mind the synonym sets of a given word are enumerated. The tie-in with meaning is tenuous, but the human user is able to supply it. There is at least this much justification for the term: synonym sets, more forcefully than words, direct attention to the points at which a tie-in must be made between the tokens of communication and the underlying representation of &amp;quot;world knowledge&amp;quot; Organization for a Dictionary of Word Senses In a full-fledged system for processing natural language, then, we must envision the &amp;quot;dictionary of senses&amp;quot; as a component stretching vertically across the &amp;quot;upper&amp;quot; layers. Its &amp;quot;sense data items&amp;quot; must link, in some way, to the deeper-lying data structures which encode &amp;quot;knowledge of the world&amp;quot; (the &amp;quot;pragmatic component&amp;quot;). The &amp;quot;key data items&amp;quot; and &amp;quot;phrase data items&amp;quot; register tokens to be expected or employed in &amp;quot;surface&amp;quot; utterances. Global and local attributes recorded in the various data items guide parsing and interpretation. V.&apos;here one takes it from there depends upon the approach to</abstract>
<title confidence="0.75423">Organization for a Dictionary of Word Senses References:</title>
<author confidence="0.634713">Simulation of Verbal Learning Behavior</author>
<author confidence="0.634713">in</author>
<affiliation confidence="0.605048">Thought, E. A. Feigenbaum and J. Feldman, McGraw Hill.</affiliation>
<address confidence="0.621431">Goldman, Neil (1975), &amp;quot;Sentence Paraphrasing from a Conceptual Base&amp;quot;, of</address>
<note confidence="0.968551678571429">ACM. 1975, Vol. 1.8 No. 2. Harris, Larry R. (1972), &amp;quot;A Model for Adaptive Problem Solving to Natural Language Acquisition&amp;quot;, Cornell University, Ithaca, N.Y. PB-211 378. [4] Kelly, Edward, and Stone, Philip (1975), &amp;quot;Computer Recognition of English Word Senses&amp;quot;, Chapter IV, North-Holland Publishing Co, Amsterdam. [5] Lamb, Sydney M., and Jacobsen, William H., Jr. (1966), &amp;quot;A High-Speed Large-Capacity System&amp;quot;, in in Automatic Language Processing. David G. Hays, American Elsevier Publishing Company, New York. Quillian, M. Ross (1968), &amp;quot;Semantic Memory&amp;quot;, in Information Processing, Marvin Minsky, The MIT Press, Cambridge, Massachusetts. Schank, N., Rieger, C., and Riesbeck, C. (1973), &amp;quot;Margie: Memory, Analysis, Generation, and Inference on English&amp;quot;, Third International Joint on Artificial Intelligence. Research Institute, Stanford, California. [8] Schank, Roger C. (1973), &amp;quot;Identification of Conceptualizations Underlying Natural in Models of Thought and Language, R. Schank and K Colby, W. H. Freeman &amp; Co., San Francisco. Schank, Roger C. (1973), &amp;quot;The Conceptual Analysis of Natural Lang age&amp;quot;, in Processing, Randall Rustin, Algorithmics Press, Inc., New York. Organization for a Dictionary of Word Senses [10] Schmidt, Charles T. (1970),. &amp;quot;A Dictionary Structure for Use with an English Language Preprocessor to a Computerized Information Retrieval System&amp;quot;, Naval Postgraduate School, Monterey, California. AD 710 363. Simmons, R. F., and Slocum, &amp;quot;Generating English Discourse from Semantic of the ACM, 1972, Vol. 15 No. 10. Simmons, R.F. (1973), &amp;quot;Semantic Networks: Their Computation and for Understanding Sentences&amp;quot;, in Models of Thought and Language. R. Schank and Colby, W. &amp; Co., San Francisco. Journal of Computational Linguistics 50 : 24</note>
<abstract confidence="0.9559418">CURRENT BIBLIOGRAPHY predictions to the both the selection of material for this issue and the choice of subject categories are tentative. The Editor and his have found of intellectual and mechanical systems more onerous than they had expected. especially for reports circulated privately, depends on the cooperation of authors. Summaries articles to be summarized should be the editorial Twin Willows, New York 14075. Many summaries are authors&apos; abstracts, sometimes edited for brevity, or completeness. Where possible, an informative summary is provided. The Informatheque de linguistique de l&apos;Universite d&apos;Ottawa, Ronan F. Collis, Director, a of our entries. AJCL gratefully acknowledges the assistance of J. Beck, B. Harris, and D. Castonguay. See the following framefor a list of subject headings with frame numbers.</abstract>
<note confidence="0.897749903225806">25 SUBJECT HEADINGS GENERAL. • • • • • 26 COMPUTATION . Chinese . . • • . • • 35 Programming . 70 PHONETICS - PHONOLOGY 36 . 71 Recognition . • • • • 38 Pictorial Systems 72 Chinese . • • . • 43 . 73 WRITING • • • • • • 44 76 Recognition 44 . 76 Chinese 45 . • • • 76 Synthesis SCIENCE 79 Chinese • • 46 Anthropology 82 Text Input . 83 Chinese . • • 48 . 84 HUMANITIES . 85 Chinese . 50 Concordance . 86 Chinese . . 54 . . 86 LEXICOGRAPHY - LEXICOLOGY INSTRUCTION . 88 Statistics . 56 BRAIN THEORY • • 91 Text Handling 57 ROBOTICS Dialectology 58 Thesauri . 58 GRAMMAR . . . 59 . 60 SEMANTICS - DISCOURSE 60 Memory 67 Answering Text Grammar • • • • . . 67 LINGUISTICS . 68 Mathematical . 69</note>
<title confidence="0.444341">Putnam and Clarke and Mind and Body</title>
<author confidence="0.910908">Yorick Wilkes</author>
<affiliation confidence="0.963154">Artificial Intelligence Laboratory, Stanford</affiliation>
<address confidence="0.903896">British Journal for the Philosophy of Science 26:213-225, September 1975 ISSN 0007-0882</address>
<abstract confidence="0.968810666666667">Putnam argues for a satirical privacy for machines by asserting that, just as it makes no sense to ask John how he knows that he is in pain, so it makes no sense to ask a Turing Machine how it knows that it is in state addressed to an abstract TM the question is absurd, but not when addressed to a physically realized TM. Putnam equivocates about the notion of state, discussing only abstract TM&apos;s when introducing the notion of state, but making an argument which is coherent only with respect ot a physically realized TM. There is thus, in effect, a confusion between &apos;state&apos; as of an atitomatpn and &apos;state&apos; as of a real machine which is executing a program which realizes that automaton—any of a number of states of the machine might correspond to one state of the automaton embodied in the program. Thus Putmam&apos;s argument fails, Clarke&apos;s criticisms of Putnam are misguided but instructive. A more serious notion of machine privacy can be constructed by noting that it is impossible to inter the machine&apos;s real activitity determinattly from the content of registers.</abstract>
<title confidence="0.9070245">GENERAL A Graphical Programming System with Speech Input</title>
<author confidence="0.997929">Chacko C Neroth</author>
<affiliation confidence="0.998153">University of California, Berkeley</affiliation>
<address confidence="0.453724">Computers &amp; Graphics 1:227-231, 1975</address>
<abstract confidence="0.995740777777778">The experimental problem solving environment is one of formulating specifying, debugging and executing (algebraic) procedures interactively on a small processor. The speech recognition system is a real time, syntax directed, limited vocabulary, highly cost effective scheme specifically tailored to this environment. The data transformation operations of the language are verbally specified and the control flow is specified graphically as a twodimensional directed graph. The semantics of the latter structure is independent of the time sequence of its input. An input restricted (conditional input) pseudo-finite state machine model is used for the continuous syntax checking of the input on an atomic token basis and the speech recognizer.</abstract>
<title confidence="0.980797">Computerized Natural Language Information System</title>
<author confidence="0.99997">Stewart N T Shen</author>
<affiliation confidence="0.99999">Computer Science Department, Virginia Polytechnic Institute and State University,</affiliation>
<address confidence="0.930162">Blacksburg</address>
<abstract confidence="0.836435727272727">S. GooId, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 573-588 General problems in NL processing are discussed and a methodology is presented. A NL system should consist of a supervisory module which reads and interprets certain input sentences stated in some specific way. These sentences tell the system what kind of job is being done. The system would have various syntactic, semantic, and pragmatic processing modules available to. it. Technological developments may well make it practical for individuals to have CNL1S (Computerized Natural Language Information System) terminals in their homes. A typical user terminal may include a microcomputer an interactive TV, and an electric typewriter. In the computerization of Chinese, a simplification of the written characters is urged.</abstract>
<title confidence="0.905452">GENERAL Design Concepts of Chinese Language Data Processing Systems</title>
<author confidence="0.993609">Yaohan Chu</author>
<author confidence="0.993609">Chu</author>
<affiliation confidence="0.947581">Department of Computer Science, University of Maryland, College Park</affiliation>
<note confidence="0.53755475">S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems,. Academia Sinica, 117-136 Five types of Chinese language data processing systems are discussed. 1) Accept assembly code in English and hand-coded Chinese data and use an expanded subroutine library. 2</note>
<abstract confidence="0.829853125">Accept assembly code and data, both in Chinese, by adding a pre-assembler and translators to the manufacturer-supplied assembler and linkage editor. 3) Accept a high-level Chinese programming language and Chinese data. 4) Those which use the Chinese-language-oriented postfix string as the machine language. 5) In which the high-level language itself is the language (i.e. one-level language). This type of data processing system has intermediate language, no assembly language, no relocatable language, and no absolute language. GENERAL 28</abstract>
<title confidence="0.994176">Design Philosophy of a Chinese-Oriented Computer</title>
<author confidence="0.999978">John Y Hsu</author>
<affiliation confidence="0.997918">Department of Computer Scien Statistics, California Polytechnic State Unh&apos;ersitv,</affiliation>
<author confidence="0.901491">Luis Obispo</author>
<note confidence="0.672671">S. Gould, Ed., Proceedings of the First International Symposium on Comprters and Chinese Input/Output Systems, Academia Sinica, 135-150 Basic design philosophy of a Chinese-oriented computer includes consideration of the idiosyncrasies of such a computer. The following topics are discussed: 1) Internal coding of Chinese characters, 2) Chinese Input/Output devices, 3) Instruction Repertorie to Manipulate Chinese Characters, and 4) Miscellaneous. The design approach toward such a Chineseoriented computer is also commented on. GENERAL Is Technology Ready for Chinese/Japanese Data Processing Greenblott, and M. Y. Hsigo IBM Poughkeepsie, New York S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Acadenia Sinica, 151-161</note>
<abstract confidence="0.975723875">technology for the computer processing of Chinese characters on a large scale is around the corner. The major bottleneck is the training required to key in 8,000 different Chinese characters quickly and correctly by either a set of keyboards or some cleverly coded form or keyboard design. Advances in LSI technology. mechanical magnetic keys, CRT, etc., will all contribute to the realization of a data processing system capable of handling ideographic languages. An automatic pattern recognition system was not chosen to represent the major future trend because its technical development is still beyond the level of practical large scale implementation.</abstract>
<title confidence="0.962403">Conversation, Cognition and Learning</title>
<author confidence="0.965255">Gordon Pask</author>
<affiliation confidence="0.822653">System Research Lid., Richmond, Surrey, England</affiliation>
<address confidence="0.812864">Inc., Amsterdam and New York, 1975, $37.00/ WI 96.00, xii + 570 0-</address>
<phone confidence="0.515556">444-41/93-3</phone>
<abstract confidence="0.9971187">describes a theory of man/man or man/machine conversations and cognitive processes (with emphasis upon the dynamics of learning and teaching at an individual level) together with several special experimental methods and practical applications. Most of the illustrations and data supporting the argument stern from education, course design, and similar fields and the material is relevant to epistemology, subject matter organisation, as well as such disciplines as pedagogy, computer aided instruction etc. Some experiments, however, deal with laboratory learning and the acquisition of perceptual motor skills, and an attempt is made to identify the theory and methods with many standard paradigms in social and experimental psychology. An account of consciousness and self-reference is given in the theory.</abstract>
<title confidence="0.979511">Information Processing and Cognition: The Loyola Symposium</title>
<author confidence="0.998684">Robert L Solso</author>
<author confidence="0.998684">editor</author>
<affiliation confidence="0.983526">Loyola University of Chicago</affiliation>
<note confidence="0.867225857142857">Halsted Press Division, John Wiley &amp; Sons, New York, 1975 1SBN 0-470-81230-3 HC $19.95 Contents Preface xi SECTION 1 1 MEMORY, PERCEPTION, AND DECISION IN LETTER IDENTIFICATION, W. K. Estes 3</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Edward</author>
</authors>
<title>Simulation of Verbal Learning Behavior.&amp;quot;,</title>
<date>1963</date>
<booktitle>in Computers and Thought,</booktitle>
<editor>eds. E. A. Feigenbaum and J. Feldman,</editor>
<publisher>McGraw Hill.</publisher>
<marker>Edward, 1963</marker>
<rawString>[1] Feigenbaum. Edward A. (1963), &amp;quot;Simulation of Verbal Learning Behavior.&amp;quot;, in Computers and Thought, eds. E. A. Feigenbaum and J. Feldman, McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil Goldman</author>
</authors>
<title>Sentence Paraphrasing from a Conceptual Base&amp;quot;,</title>
<date>1975</date>
<journal>Communications of the ACM. February,</journal>
<volume>1</volume>
<marker>Goldman, 1975</marker>
<rawString>[2] Goldman, Neil (1975), &amp;quot;Sentence Paraphrasing from a Conceptual Base&amp;quot;, Communications of the ACM. February, 1975, Vol. 1.8 No. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry R Harris</author>
</authors>
<title>A Model for Adaptive Problem Solving A ppilea to Natural Language Acquisition&amp;quot;,</title>
<date>1972</date>
<pages>211--378</pages>
<institution>Cornell University,</institution>
<location>Ithaca, N.Y.</location>
<marker>Harris, 1972</marker>
<rawString>[3] Harris, Larry R. (1972), &amp;quot;A Model for Adaptive Problem Solving A ppilea to Natural Language Acquisition&amp;quot;, Cornell University, Ithaca, N.Y. PB-211 378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Kelly</author>
<author>Philip Stone</author>
</authors>
<title>Computer Recognition of English Word Senses&amp;quot;, Chapter IV,</title>
<date>1975</date>
<publisher>North-Holland Publishing Co,</publisher>
<location>Amsterdam.</location>
<marker>Kelly, Stone, 1975</marker>
<rawString>[4] Kelly, Edward, and Stone, Philip (1975), &amp;quot;Computer Recognition of English Word Senses&amp;quot;, Chapter IV, North-Holland Publishing Co, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sydney M Lamb</author>
<author>William H Jacobsen</author>
</authors>
<title>A High-Speed Large-Capacity Dictionary System&amp;quot;,</title>
<date>1966</date>
<booktitle>in Readings in Automatic Language Processing.</booktitle>
<editor>ed. David G. Hays,</editor>
<publisher>American Elsevier Publishing Company,</publisher>
<location>New York.</location>
<marker>Lamb, Jacobsen, 1966</marker>
<rawString>[5] Lamb, Sydney M., and Jacobsen, William H., Jr. (1966), &amp;quot;A High-Speed Large-Capacity Dictionary System&amp;quot;, in Readings in Automatic Language Processing. ed. David G. Hays, American Elsevier Publishing Company, New York.</rawString>
</citation>
<citation valid="true">
<title>Semantic Memory&amp;quot;,</title>
<date>1968</date>
<booktitle>in Semantic Information Processing,</booktitle>
<editor>[6] Quillian, M. Ross</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>1968</marker>
<rawString>[6] Quillian, M. Ross (1968), &amp;quot;Semantic Memory&amp;quot;, in Semantic Information Processing, ed. Marvin Minsky, The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>N Goldman</author>
<author>C Rieger</author>
<author>C Riesbeck</author>
</authors>
<title>Margie: Memory, Analysis, Response Generation, and Inference on English&amp;quot;,</title>
<date>1973</date>
<booktitle>Proceedings, Third International Joint Conference on Artificial Intelligence. Stanford Research Institute,</booktitle>
<location>Stanford, California.</location>
<marker>Schank, Goldman, Rieger, Riesbeck, 1973</marker>
<rawString>1171 Schank, R., Goldman, N., Rieger, C., and Riesbeck, C. (1973), &amp;quot;Margie: Memory, Analysis, Response Generation, and Inference on English&amp;quot;, Proceedings, Third International Joint Conference on Artificial Intelligence. Stanford Research Institute, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
</authors>
<title>Identification of Conceptualizations Underlying Natural Language&amp;quot;,</title>
<date>1973</date>
<booktitle>in Computer Models of Thought and Language,</booktitle>
<editor>eds. R. Schank and K Colby, W. H. Freeman &amp; Co.,</editor>
<location>San Francisco.</location>
<marker>Schank, 1973</marker>
<rawString>[8] Schank, Roger C. (1973), &amp;quot;Identification of Conceptualizations Underlying Natural Language&amp;quot;, in Computer Models of Thought and Language, eds. R. Schank and K Colby, W. H. Freeman &amp; Co., San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
</authors>
<title>The Conceptual Analysis of Natural Lang age&amp;quot;,</title>
<date>1973</date>
<journal>Senses</journal>
<booktitle>in Natural Language Processing,</booktitle>
<volume>23</volume>
<editor>ed. Randall Rustin,</editor>
<publisher>Algorithmics Press, Inc.,</publisher>
<location>New York.</location>
<marker>Schank, 1973</marker>
<rawString>[9] Schank, Roger C. (1973), &amp;quot;The Conceptual Analysis of Natural Lang age&amp;quot;, in Natural Language Processing, ed. Randall Rustin, Algorithmics Press, Inc., New York. An Organization for a Dictionary of Word Senses 23</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles T Schmidt</author>
</authors>
<title>A Dictionary Structure for Use with an English Language Preprocessor to a Computerized Information Retrieval System&amp;quot;,</title>
<date>1970</date>
<journal>AD</journal>
<volume>710</volume>
<pages>363</pages>
<location>Naval Postgraduate School, Monterey, California.</location>
<marker>Schmidt, 1970</marker>
<rawString>[10] Schmidt, Charles T. (1970),. &amp;quot;A Dictionary Structure for Use with an English Language Preprocessor to a Computerized Information Retrieval System&amp;quot;, Naval Postgraduate School, Monterey, California. AD 710 363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
<author>J Slocum</author>
</authors>
<title>Generating English Discourse from Semantic Networks&amp;quot;,</title>
<date>1972</date>
<journal>Communications of the ACM,</journal>
<volume>15</volume>
<marker>Simmons, Slocum, 1972</marker>
<rawString>[11] Simmons, R. F., and Slocum, J. (1972), &amp;quot;Generating English Discourse from Semantic Networks&amp;quot;, Communications of the ACM, October 1972, Vol. 15 No. 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
</authors>
<title>Semantic Networks: Their Computation and Use. for Understanding English Sentences&amp;quot;,</title>
<date>1973</date>
<booktitle>in Computer Models of Thought and Language.</booktitle>
<editor>eds. R. Schank and K. Colby, W. H. Freeman &amp; Co.,</editor>
<location>San Francisco.</location>
<marker>Simmons, 1973</marker>
<rawString>[12] Simmons, R.F. (1973), &amp;quot;Semantic Networks: Their Computation and Use. for Understanding English Sentences&amp;quot;, in Computer Models of Thought and Language. eds. R. Schank and K. Colby, W. H. Freeman &amp; Co., San Francisco.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<journal>American Journal of Computational Linguistics Microfiche</journal>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<volume>50</volume>
<pages>269--286</pages>
<marker>Gould, Ed, </marker>
<rawString>American Journal of Computational Linguistics Microfiche 50 : 24 S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 269-286</rawString>
</citation>
<citation valid="false">
<title>A Chinese character may be called a kind of block picture. Each stroke seems to be a hieroglyph. Curves formed by several strokes or by a continous stroke do not happen very often. Some characters only differ by a single stroke. If the Markovian processes mentioned in this paper are used, detailed recognition for each row and column is available and even a single stroke would not be missed absolutely, so the increasing the degree of correct recognition is by no means a problem. A plane block picture may be divided tnto plane blocks while a solid one can be discussed by divi,ding it into solid blocks. The greater the number of layers, the higher the degree of correct recognition. The input, pattern is divided into 20 layers for individual recognition. If every layer satisfied the condition, then recognition is complete. If one of the layers has a great difference, then the pattern should be another picture.</title>
<marker></marker>
<rawString>A Chinese character may be called a kind of block picture. Each stroke seems to be a hieroglyph. Curves formed by several strokes or by a continous stroke do not happen very often. Some characters only differ by a single stroke. If the Markovian processes mentioned in this paper are used, detailed recognition for each row and column is available and even a single stroke would not be missed absolutely, so the increasing the degree of correct recognition is by no means a problem. A plane block picture may be divided tnto plane blocks while a solid one can be discussed by divi,ding it into solid blocks. The greater the number of layers, the higher the degree of correct recognition. The input, pattern is divided into 20 layers for individual recognition. If every layer satisfied the condition, then recognition is complete. If one of the layers has a great difference, then the pattern should be another picture.</rawString>
</citation>
<citation valid="false">
<authors>
<author>WRITING RECOGNITION</author>
</authors>
<title>CHINESE 46 The Topological Analysis, Classification, and Encoding of Chinese Characters for Digital Computer Interfacing—Part I</title>
<marker>RECOGNITION, </marker>
<rawString>WRITING: RECOGNITION: CHINESE 46 The Topological Analysis, Classification, and Encoding of Chinese Characters for Digital Computer Interfacing—Part I</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Paul</author>
</authors>
<title>Wang Department of Electrical Engineering,</title>
<booktitle>Proceedings of the First&apos; International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>417--439</pages>
<institution>Duke University,</institution>
<location>Durham, North Carolina</location>
<marker>Paul, </marker>
<rawString>Paul P. Wang Department of Electrical Engineering, Duke University, Durham, North Carolina S. Gould, Ed., Proceedings of the First&apos; International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 417-439</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<title>Software Method in kanji Information Processing Teiji Kakinuma Fujitsu Limited,</title>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>983--998</pages>
<location>Minato-ku, Tokyo, Japan Kenmi Tsukatani PET)&apos; Limited, Chiyoda-ku, Tokyo, Japan</location>
<marker>Gould, Ed, </marker>
<rawString>Software Method in kanji Information Processing Teiji Kakinuma Fujitsu Limited, Minato-ku, Tokyo, Japan Kenmi Tsukatani PET)&apos; Limited, Chiyoda-ku, Tokyo, Japan S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 983-998</rawString>
</citation>
<citation valid="false">
<institution>Photo-Electrostatic Kanji Printer Atsushi Ishi, Yoichi Hagiwara, Woshimitsu&apos;Masui, and Yoshiyuki Aida Fujitsu Ltd.,</institution>
<location>Minato-Ru, Tokyo, Japan</location>
<marker></marker>
<rawString>Photo-Electrostatic Kanji Printer Atsushi Ishi, Yoichi Hagiwara, Woshimitsu&apos;Masui, and Yoshiyuki Aida Fujitsu Ltd., Minato-Ru, Tokyo, Japan</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>969--981</pages>
<marker>Gould, Ed, </marker>
<rawString>S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 969-981</rawString>
</citation>
<citation valid="false">
<booktitle>S.Gould., Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>931--942</pages>
<institution>Designing Storage/Output Units. for Chinese Input/Output Digital Computers Kai Huang Department of Electrical Engineering, University of Miami, Coral Gables, Florida</institution>
<marker></marker>
<rawString>Designing Storage/Output Units. for Chinese Input/Output Digital Computers Kai Huang Department of Electrical Engineering, University of Miami, Coral Gables, Florida S.Gould., Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 931-942</rawString>
</citation>
<citation valid="false">
<booktitle>WRITING: SYNTHESIS: CHINESE 48 Computer-Aided Design of Chinese Character Patterns Hideo Hirahara, Kiyoshi Kibuchi, and Masamitsu Satou Informations Systems Research Laboratory, Toshiba Research and Development</booktitle>
<location>Center, Kawasaki-City, Japan</location>
<marker></marker>
<rawString>WRITING: SYNTHESIS: CHINESE 48 Computer-Aided Design of Chinese Character Patterns Hideo Hirahara, Kiyoshi Kibuchi, and Masamitsu Satou Informations Systems Research Laboratory, Toshiba Research and Development Center, Kawasaki-City, Japan</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/OUtput Systems, Ac r :mia Sinica,</booktitle>
<pages>909--930</pages>
<marker>Gould, Ed, </marker>
<rawString>S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/OUtput Systems, Ac r :mia Sinica, 909-930</rawString>
</citation>
<citation valid="false">
<title>A;System Design for the Input of Chinese Characters through the Use of Phonetic and Orthographic Symbols.</title>
<marker></marker>
<rawString>A;System Design for the Input of Chinese Characters through the Use of Phonetic and Orthographic Symbols.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H C Li</author>
<author>S P Hu</author>
<author>C L Jen</author>
<author>H Chou</author>
<author>S Shan</author>
<author>E T</author>
</authors>
<booktitle>Ed., h-oceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>501--511</pages>
<institution>Chen Department of Economics, Bryant College,</institution>
<location>Smithfield, R.I.</location>
<marker>Li, Hu, Jen, Chou, Shan, T, </marker>
<rawString>H. C. Li, S. P. Hu, C. L. Jen, H. Chou, S. Shan, and E. T. Chen Department of Economics, Bryant College, Smithfield, R.I. S. Gould, Ed., h-oceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 501-511</rawString>
</citation>
<citation valid="false">
<authors>
<author>WRITING TEXT</author>
</authors>
<title>INPUT: CHINESE 49 A New Approach to a Chinese (Tele) Typewriter, Which Can be Used as a Telex, Data Terminal and Computer Input/Output Device</title>
<marker>TEXT, </marker>
<rawString>WRITING: TEXT INPUT: CHINESE 49 A New Approach to a Chinese (Tele) Typewriter, Which Can be Used as a Telex, Data Terminal and Computer Input/Output Device</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ye-San Liu</author>
</authors>
<title>Directorate General of Telecommunications,</title>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>489--499</pages>
<location>Taipei, Republic of</location>
<marker>Liu, </marker>
<rawString>Ye-San Liu Directorate General of Telecommunications, Taipei, Republic of China S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 489-499</rawString>
</citation>
<citation valid="false">
<authors>
<author>PEACE--A Phonetic</author>
</authors>
<title>Encoding and Chinese Editing System Shi-Kuo Chang, Chi-Shion Chiu, Ming-Hwei Yang,</title>
<institution>and Bao-Shuh Lin Computation Laboratory, Institute of Mathematics, Academia Sin/ca, Nankang, Republic of China</institution>
<marker>Phonetic, </marker>
<rawString>PEACE--A Phonetic Encoding and Chinese Editing System Shi-Kuo Chang, Chi-Shion Chiu, Ming-Hwei Yang, and Bao-Shuh Lin Computation Laboratory, Institute of Mathematics, Academia Sin/ca, Nankang, Republic of China</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sin/ca,</booktitle>
<pages>29--47</pages>
<marker>Gould, Ed, </marker>
<rawString>S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sin/ca, 29-47</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Gould</author>
<author>Ed</author>
</authors>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>471--488</pages>
<institution>East Asia Library, Rutgers University</institution>
<marker>Gould, Ed, </marker>
<rawString>East Asia Library, Rutgers University S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 471-488</rawString>
</citation>
<citation valid="false">
<title>The Following are assumed: 1) All Chinese ideographs are composed of one or more components, and thus may be classified by the pattern of these components. 2) Each of the comaonents is in turn composed of one or more graphic elements. The total number of graptic elements is fairly limited. Ideographs may be divided into four major patterns: Horizontal, Vertical, Bordered, and Independent. After identification of an ideograph&apos;s pattern, a component&apos;s structure, and the basic elements, one can then perform the coding by following rules for: 1) Ideograph as a whole, 2) Components, 3) Elements, 4) Relationship or separation signs, 5) Coding sequence, 6) Component of bordered pattern, 7) Independent ideographs of components.</title>
<marker></marker>
<rawString>The Following are assumed: 1) All Chinese ideographs are composed of one or more components, and thus may be classified by the pattern of these components. 2) Each of the comaonents is in turn composed of one or more graphic elements. The total number of graptic elements is fairly limited. Ideographs may be divided into four major patterns: Horizontal, Vertical, Bordered, and Independent. After identification of an ideograph&apos;s pattern, a component&apos;s structure, and the basic elements, one can then perform the coding by following rules for: 1) Ideograph as a whole, 2) Components, 3) Elements, 4) Relationship or separation signs, 5) Coding sequence, 6) Component of bordered pattern, 7) Independent ideographs of components.</rawString>
</citation>
<citation valid="false">
<authors>
<author>WRITING CHARACTER</author>
</authors>
<title>SETS: CHINESE Chinese Input-Output with Standard IBM Selectric Typewriter Terminal</title>
<marker>CHARACTER, </marker>
<rawString>WRITING: CHARACTER SETS: CHINESE Chinese Input-Output with Standard IBM Selectric Typewriter Terminal</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Ching</author>
</authors>
<title>Tsao IBM Corporation,</title>
<location>Armonk, New York</location>
<marker>Ching, </marker>
<rawString>Ching C. Tsao IBM Corporation, Armonk, New York</rawString>
</citation>
<citation valid="false">
<authors>
<author>Emerson W Pugh IBM T J Watson Research Center</author>
</authors>
<booktitle>Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica,</booktitle>
<pages>459--469</pages>
<location>Yorktown Heights, New Yor,</location>
<marker>Center, </marker>
<rawString>Emerson W. Pugh IBM T.J. Watson Research Center, Yorktown Heights, New Yor, S. Gould, Ed., Proceedings of the First International Symposium on Computers and Chinese Input/Output Systems, Academia Sinica, 459-469</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>