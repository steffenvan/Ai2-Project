<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000137">
<title confidence="0.985658">
“I Object!” Modeling Latent Pragmatic Effects in Courtroom Dialogues
</title>
<author confidence="0.997843">
Dan Goldwasser
</author>
<affiliation confidence="0.9991355">
University of Maryland
Institute for Advanced Computer Studies
</affiliation>
<address confidence="0.883942">
College Park, MD , USA
</address>
<email confidence="0.997959">
goldwas1@umiacs.edu
</email>
<author confidence="0.994807">
Hal Daum´e III
</author>
<affiliation confidence="0.9980045">
Department of Computer Science
University of Maryland
</affiliation>
<address confidence="0.884874">
College Park, MD , USA
</address>
<email confidence="0.99922">
hal@cs.umd.edu
</email>
<sectionHeader confidence="0.997395" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999781428571429">
Understanding the actionable outcomes of
a dialogue requires effectively modeling
situational roles of dialogue participants,
the structure of the dialogue and the rele-
vance of each utterance to an eventual ac-
tion. We develop a latent-variable model
that can capture these notions and apply
it in the context of courtroom dialogues,
in which the objection speech act is used
as binary supervision to drive the learning
process. We demonstrate quantitatively
and qualitatively that our model is able to
uncover natural discourse structure from
this distant supervision.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948178571429">
Many dialogues lead to decisions and actions. The
participants in such dialogues each come with
their own goals and agendas, their own perspec-
tives on dialogue topics, and their own ways of
interacting with others. Understanding the action-
able results of a dialogue requires accurately mod-
eling both the content of dialogue utterances, as
well as the relevant features of its participants.
In this work, we devise a discriminative latent
variable model that is able to capture the overall
structure of a dialogue as relevant to specific acts
that occur as a result of that dialogue. We aim to
model both the relevance of preceding dialogue to
particular action, as well as a binary structured re-
lationship among utterances, while taking into ac-
count the pragmatic effect introduced by the dif-
ferent speakers’ perspectives.
We focus on a particular domain of dialogue:
courtroom transcripts. This domain has the advan-
tage that while its range of topics can be broad, the
roles of participants are relatively well-defined.
Courtroom dialogues also contain a specialized
speech act: the objection.
In real court settings (as opposed to fictional-
ized courts), an objection is a decision made by the
party opposing the side holding the floor, to inter-
rupt the flow of the courtroom discussion. While
motivation behind taking this decision can stem
from different reasons, it is typically an indication
that a particular pragmatic rule has been broken.
The key insight is that objections are sustained
when a nuanced rule of court is being violated: for
instance, the argumentative objection is “raised in
response to a question which prompts a witness to
draw inferences from facts of the case”1, as op-
posed to the witness stating concrete facts.
The objectionable aspects of the preceding di-
alogue can be identified by a well-trained person;
however these aspects are quite subtle to a com-
putational model. In this work we take a first step
toward addressing this problem computationally,
and focus on identifying the key properties of dia-
logue interactions relevant for learning to identify
and classify courtroom objections.
Our technical goal is to drive latent learning of
dialogue structure based on a combination of raw
input and pragmatic binary supervision. The bi-
nary supervision we use is derived from objection
speech acts appearing in the dialogue (described
in Section 2.1).
We are primarily interested in constructing a
representation suitable for learning the challeng-
ing task of identifying objections in courtroom
proceedings (Figure 1 provides an example).
In order to make classifications reliably, a
deeper representation of the dialogue is required.
</bodyText>
<note confidence="0.670706">
1Source: Wikipedia, July 2011, http://en.wikipedia.
org/wiki/Argumentative.
</note>
<page confidence="0.964326">
655
</page>
<note confidence="0.9989225">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 655–663,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.994735">
Figure 1: Moving from raw text to a meaningful rep-
</figureCaption>
<bodyText confidence="0.994566954545455">
resentation. The raw textual representation hides complex
interactions, relevant for understanding the dialogue flow and
making decisions over it. We break the text into dialogue
turns, each associated with a speaker, explicitly annotated
with their role and side in the court case. Judgements of the
relevance of each dialogue component for the classification
task, produce a more accurate representation of the dialogue
which is easier to learn. These judgments can be over indi-
vidual sentences ( 1 ) or over pairs of sentences across dif-
ferent turns ( 2 ), which represent relevant information flow.
The parameters required for making these judgements are ob-
tained via interaction with the learning process. We explain
these consideration and the construction stages in Section 2.
Our model makes use of three conceptually differ-
ent components capturing linguistic and pragmatic
considerations and their relevance in the context of
the dialogue structure.
Our linguistic model focuses on enriching a
lexical representation of the dialogue utterances
using linguistic resources capturing biased lan-
guage use, such as subjective speech, expressions
of sentiment, intensifiers and hedges. For exam-
ple, the phrase “So he was driving negligently?”
is an argumentative expression, as it requires the
witness to draw inferences, rather than describe
facts. Identifying the use of biased language in this
phrase can help capture this objectionable aspect.
In addition, we use a named entity recognizer, as
we observe that relevant entity mentions provide
a good indication of the dialogue focus. We refer
the reader to Section 2.2 for further explanations.
The surface representation of dialogue turns
hides the complex interactions between its partici-
pants. These interactions are driven by their agen-
das and roles in the trial. Understanding the lexical
cues in this context requires situating the dialogue
in the context of the court case. We condition the
lexical representation of a turn on its speaker, the
speaker’s role and side in the trial, thus allowing
the model to capture the relevant pragmatic influ-
ences introduced by the different speakers.
Next, a discriminative latent variable model
learns a structured representation of the dia-
logue that is useful in making high-level seman-
</bodyText>
<table confidence="0.999724875">
Notation Explanation
x Input dialogue
xSit Situated dialogue
h Latent structure variables
t Dialogue turn
t.speaker.{name,role,side} Speaker information
t.text Text in a dialogue turn
t.si.{text,type,subj,entities} Sentence level information
</table>
<tableCaption confidence="0.832182333333333">
Table 1: Notation Summary
tic/pragmatic predictions (section 2.3). The latent
variable model consists of two types of variables.
</tableCaption>
<bodyText confidence="0.999908771428571">
The first type of latent variable aims to identify
content relevant for the objection identification de-
cision. To this end, it determines the relevance of
individual sentences to the classification decision,
based on properties such as the lexical items ap-
pearing in the sentence, the sentence type, and ex-
pressions of subjectivity. The second latent vari-
able type focuses on the information flow between
speakers. It identifies relevant dialogue relations
between turns. This decision is made by construct-
ing a joint representation of two sentences, across
different dialogue turns, capturing responses to
questions and joining lexical items appearing in
factual sentences across different turns.
Both dialogue aspects are formalized as latent
variables, trained jointly with the final classifica-
tion task using automatically extracted supervi-
sion. In Sec. 3 we describe the learning process.
We evaluate our approach over short dialogue
snippets extracted from the O.J. Simpson murder
trial. Our experiments evaluate the contribution of
the different aspects of our system, showing that
the dialogue representation determined by our la-
tent model results in considerable improvements.
Our evaluation process considers several differ-
ent views of the extracted data. Interestingly, de-
spite the formal definitions of objections, the ma-
jority of objections are raised without justification
(and are subsequently overruled), typically for the
purpose of interrupting the opposing side when
controversial topics are touched upon. Our exper-
iments analyze the differences between sustained
and overruled objections and show that sustained
objections are easier to detect. We describe our
experiments in section 4.
</bodyText>
<sectionHeader confidence="0.970223" genericHeader="method">
2 Dialogue Structure Modeling
</sectionHeader>
<bodyText confidence="0.986614333333333">
Making predictions in such a complex domain re-
quires a rich representation, capturing the interac-
tions between different participants, the tone of
</bodyText>
<figure confidence="0.998289904761905">
MR. COCHRAN
Attorney
Defense
Det. LANGE
Witness
Prosecution
1
MR. COCHRAN And then she filed the case, right?
DETECTIVE LANGE That’s correct
MS. CLARKE Objection your honor.
MR. COCHRAN And before you submitted this case you had
heard or seen Miss Clarke on Television saying
this was a sole murderer case; isn’t that
correct? you had heard that, hadn’t you?
THE COURT Hearsay. Sustained
1
2
1
RELEVANCE
Dialogue Input
Label
</figure>
<page confidence="0.998116">
656
</page>
<bodyText confidence="0.999956205882353">
conversation, understanding of controversial is-
sues presented during the trial, and their different
interpretations by either side in the trial. Obtaining
this information manually is a labor intensive task,
furthermore, its subjective nature allows for many
different interpretations of the interactions leading
to the objection.
Our approach, therefore, tries to avoid this diffi-
culty by using a data-driven approach to learn the
correct representation for the input, jointly with
learning to classify correctly. Our representation
transforms the raw input, dialogue snippets ex-
tracted automatically from court proceedings, into
meaningful interactions between dialogue partic-
ipants using a set of variables to determine the
relevant parts of the dialogue and the relations
between them. We inform these decisions using
generic resources providing linguistic knowledge
and pragmatic information, situating the dialogue
in the context of the trial.
In this section we explain this process, starting
from the automatic process of extracting examples
(Section 2.1), the linguistic knowledge resources
and pragmatic information used (Section 2.2), we
summarize the notation used to describe the dia-
logue and its properties in Table 1. We formulate
the inference process, identifying the meaning-
ful interactions for prediction as an Integer Linear
Programming (ILP) optimization problem (Sec-
tion 2.3). The objective function used when solv-
ing this optimization problem is learned from data,
by treating these decisions as latent variables dur-
ing learning. We explain the learning process and
its interaction with inference in Section 3.
</bodyText>
<subsectionHeader confidence="0.998624">
2.1 Mining Courtroom Proceedings
</subsectionHeader>
<bodyText confidence="0.999432473684211">
The first step in forming our dataset consists of
collecting a large set of relevant courtroom dia-
logue snippets. First, we look for textual occur-
rences of objections in the trial transcript by look-
ing for sustain or overrule word lemma patterns,
attributed to the judge. We treat the judge ruling
turn and the one preceding it as sources of super-
vision, from which an indication of an objection,
its type and sustained/overruled ruling, can be ex-
tracted. 2
We treat the preceding dialogue as the cause for
the objection, which could appear in any of the
previous turns (or sequence of several turns inter-
vening).We consider the previous n=6 turns as the
2In 4 we provide details about the extracted dataset and its
distribution according to types.
context potentially relevant for the decision and let
the latent variable model learn which aspects of
the context are actually relevant.
</bodyText>
<subsectionHeader confidence="0.941714">
2.2 Linguistic and Pragmatic Information
</subsectionHeader>
<bodyText confidence="0.99771155319149">
Objection decisions often rely on semantic and
pragmatic patterns which are not explicitly en-
coded. Rather than annotating these manually, we
use generic resources to enrich our representation.
We make a conceptual distinction between two
types of resources. The first, an array of linguis-
tic resources, which provides us an indication of
structure, topics of controversy, and the sentiment
and tone of language used in the dialogue.
The second captures pragmatic considerations
by situating the dialogue utterances in the context
of the courtroom. Each utterance is attributed to
a speaker, thus capturing meaningful patterns spe-
cific to individual speakers.
Linguistic Resources (1) Named Entities pro-
vide strong indications of the topics discussed in
the dialogue and help uncover relevant utterances,
such as ones making claims associating individu-
als with locations. We use the Named Entity Rec-
ognizer (NER) described in (Finkel et al., 2005) to
identify this information.
(2) Subjective and Biased Language Equally im-
portant to understanding the topics of conversation
is the way they are discussed. Expressions of sub-
jectivity and sentiment are useful linguistic tools
for changing the tone of the dialogue and are likely
to attract opposition. We use several resources
to capture this information. We use a lexicon of
subjective and positive/negative sentiment expres-
sions (Riloff and Wiebe, 2003). This resource can
help identify subjective statements attempting to
bias the discussion (e.g., “So he was driving neg-
ligently?”)
We use a list of hedges and boosters (Hyland,
2005). This resource can potentially allow the
model to identify evasive (“I might have seen
him”) and (overly) confident responses (“I am ab-
solutely sure that I have seen him”).
We use a lexicon of biased language provided
by (Recasens et al., 2013), this lexicon extracted
from Wikipedia edits consists of words indicative
of bias, for example in an attempt to frame the
facts raised in the discussion according to one of
the viewpoints (“The death of Nicolle Simposon”
vs. “The murder of Nicolle Simposon”).
Finally we use a Patient Polarity Verbs lexi-
con (Goyal et al., 2010). This lexicon consists
</bodyText>
<page confidence="0.992192">
657
</page>
<bodyText confidence="0.985589">
of verbs in which the agent performs an action
with a positive (“He donated money to the foun-
dation”) or negative (“He stole money from the
foundation”) consequence to the patient.
(3) Sentence Segmentation Many turns discuss
multiple topics, some more relevant than others.
In order to accommodate a finer-grained analysis,
we segment each turn into its sentences. Each sen-
tence is associated with a label, taken from a small
set of generic labels. Labels include FORMALITY (e.g.,
a witness being sworn in), QUESTION, RESPONSE (which
could be either POSITIVE or NEGATIVE) and a general
STATEMENT3.
Capturing Pragmatic Effects We observe that
in the context of a courtroom discussion, utterance
interpretation (and subsequent dialogue actions) is
conditioned to a large extent on the speaker’s mo-
tivation and goals rather than in isolation. We cap-
ture this information by explicitly associating rele-
vant characteristics of the speakers involved in the
dialogue with their utterances. We use the list of
actors which appear in the trial transcripts, and as-
sociate each turn with a speaker, their role in the
trial and the side they represent. We augment the
lexical turn representation with this information
(see Sec. 2.3.4).
</bodyText>
<subsectionHeader confidence="0.997697">
2.3 Identifying Relevant Interactions using
Constrained Optimization
</subsectionHeader>
<bodyText confidence="0.999949444444444">
In this section we take the next step towards a
meaningful representation by trying to identify di-
alogue content and information flow relevant for
objection identification. Since this information
is not pre-annotated, we allow it to be learned
as latent variables. These latent variables act as
boolean indicator variables, which determine how
each dialogue input example will be represented.
This process consists of two conceptual stages,
corresponding to two types of boolean variables:
(1) relevant utterances are identified; (2) mean-
ingful connections between them, across dialogue
turns, are identified. This information is exempli-
fied as 1 and 2 in Figure 1. These decisions
are taken jointly by formalizing this process as an
optimization problem over the space of possible
binary relations between dialogue turns and sen-
tences.
</bodyText>
<footnote confidence="0.9837795">
3Determined by lexical information (question marks,
dis/agreement indications and sentence length)
</footnote>
<subsectionHeader confidence="0.41278">
2.3.1 Relevance Decisions
</subsectionHeader>
<bodyText confidence="0.995621125">
Our raw representation allows as many as six pre-
vious turns to be relevant to the classification de-
cision, however not all turns are indeed relevant,
and even relevant turns may consist only of a
handful of relevant sentences. Given a dialogue
consisting of (t1, .., tn) turns, each consisting of
(ti.s1, .., ti.sk) sentences, we associate with each
sentence.
</bodyText>
<listItem confidence="0.969976666666666">
• Relevance variables, denoted by hri,j, indi-
cating the relevance of the j-th sentence in the
i-th turn, for the classification decision.
• Irrelevance variables, denoted by hi i,j, indi-
cating that the j-th sentence in the i-th turn is
not relevant for the classification decision.
• Variable pair activation constraints Given
a sentence the activation of these variables
should be mutually exclusive. We encode this
fact by constraining the decision with a linear
constraint.
∀i, j, hri,j + hii,j = 1 (1)
</listItem>
<subsectionHeader confidence="0.84099">
2.3.2 Dialogue Structure Decisions
</subsectionHeader>
<bodyText confidence="0.996127375">
In many cases the information required to make
the classification is not contained in a single dia-
logue turn, but rather is the product of the infor-
mation flow between dialogue participants. Given
a dialogue consisting of (t1, .., tn) turns, each con-
sisting of (ti.s1, .., ti.sk) sentences, we associate
with every two sentences, sj E ti, sk E tl, such
that (i =� l):
</bodyText>
<listItem confidence="0.917329285714286">
• Sentences-Connected variables, denoted by
hc(i,j),(k,l), indicating that the combination of
the two sentences is relevant for the classifi-
cation decision.
• Sentences-not-Connected variables, de-
noted by hn(i,j),(k,l), indicating that the
combination of the two sentences is not
relevant for the classification decision.
• Variable pair activation constraints Given
a sentence pair the activation of these vari-
ables should be mutually exclusive. We en-
code this fact by constraining the decision
with a linear constraint.
∀i, j, k, l hc(i,j),(k,l) + hn(i,j),(k,l) = 1 (2)
</listItem>
<page confidence="0.902204">
658
</page>
<listItem confidence="0.843172571428571">
• Decision Consistency constraints Given a
sentence pair, the activation of the variable
indicating the relevance of the sentence pair
entails the activation of the variables indicat-
ing the relevance of the individual sentences.
Vi, j, k,l, (hc(i,j),(k,l)) =� (hri,j ∧ hrk,l)
(3)
</listItem>
<subsubsectionHeader confidence="0.40416">
2.3.3 Overall Optimization Function
</subsubsectionHeader>
<bodyText confidence="0.999734153846154">
The boolean variables described in the previous
section define a space of competing dialogue rep-
resentations, each representation considers differ-
ent parts of the dialogue as relevant for the objec-
tion classification decision. When making this de-
cision a single representation is selected, by quan-
tifying the decisions and looking for the optimal
set of decisions maximizing the overall sum of de-
cision scores. We construct this objective function
by associating each decision with a feature vector,
obtained using a feature function φ (described in
Section 2.3.4), mapping the relevant part of the in-
put to a feature set.
More formally, given an input x, we denote the
space of all possible dialogue entities (i.e., sen-
tences and sentence pairs) as Γ(x). Assuming that
Γ(x) is of size N, we denote latent representation
decisions as h E {0,1}N, a set of indicator vari-
ables, that selects a subset of the possible dialogue
entities that constitute the dialogue representation.
For a given dialogue input x and a dialog entity
s E Γ(x), we denote φs(x) as the feature vector
of s. Given a fixed weight vector w that scores
intermediate representations for the final classifi-
cation task, our decision function (for predicting
“objectionable or not”) becomes:
</bodyText>
<figure confidence="0.834206466666667">
Biased-Language:{(w, resourceContains(w), t.speaker.*)
|Vw E t.s.text} 6
Irrelevance (hi) :
SentType: (t.s.type)
ContainsNamedEntity (t.s.entities =� ∅)
Sentences-(not)-Connected (hc,hn) :
SentTypes: (ti.sj.type, tk.sl.type)
QA pair: (ti.sj.type = Question) n (tk.sl.type =
Response)
x {qa|Vw E ti.sj.text, qa = (w, tk.sl.type)}
FactPair: (ti.sj.type = Statement) n (tk.sl.type =
Statement)
x {qa|Vw E ti.sj.text, qa = (w, tk.sl.type)}
SpeakerPair: (ti.speaker.*, tk.speaker.*)
3 Learning and Inference
</figure>
<bodyText confidence="0.993917909090909">
Unlike the traditional classification settings, in
which learning is done over a fixed representation
of the input, we define the learning process over
a set of latent variables. The process of choos-
ing a good representation is formalized as an op-
timization problem that selects the elements and
associated features that best contribute to success-
ful classification. In the rest of this section we ex-
plain the learning process for the parameters of the
model needed both for the representation decision
and the final classification decision.
</bodyText>
<subsectionHeader confidence="0.994879">
3.1 Learning
</subsectionHeader>
<bodyText confidence="0.9997318">
Similar to the traditional formalization of support
vector machines (Boser et al., 1992), learning is
formulated as the following margin-based opti-
mization problem, where λ is a regularization pa-
rameter, and ` is the squared-hinge loss function:
</bodyText>
<equation confidence="0.9393586">
X hswT φs(x) min λ X ` (−yifw(xi)) (5)
fw(x) = max w 2 11w112 +
h i
s
subject to (1)-(3); Vs; hs E {0,1}(4)
</equation>
<bodyText confidence="0.996878">
In our experiments, we formalize Eq. (4) as an
ILP instance, which we solve using the highly op-
timized Gurobi toolkit4.
</bodyText>
<sectionHeader confidence="0.795126" genericHeader="method">
2.3.4 Features
</sectionHeader>
<bodyText confidence="0.9997405">
In this section we describe the features used in
each of the different decision types.
</bodyText>
<equation confidence="0.486028">
Relevance (hr) :
Bag-of-words: {(w, t.speaker. * 5)|Vw E t.s.text}
</equation>
<footnote confidence="0.974033">
4http://www.gurobi.com/
5“*” denotes all properties
</footnote>
<bodyText confidence="0.9994816">
Unlike standard support vector machines, our de-
cision function fw(xi) is defined over a set of la-
tent variables. We substitute Eq. (4) into Eq.(5),
and obtain the following formulation for a latent
structure classifier:
</bodyText>
<equation confidence="0.930944">
⎛ ⎞
`⎝−yi max ⎠
wT Xhsφs (xi
)
h∈C
s∈Γ(x)
(6)
</equation>
<footnote confidence="0.9835925">
6refers to all linguistic resources used. We also included a
+/-1 word window around words appearing in these resources
</footnote>
<equation confidence="0.9892848">
λ X
2 11w112+
i
min
w
</equation>
<page confidence="0.993961">
659
</page>
<bodyText confidence="0.999963">
This formulation is not a convex optimization
problem and care must be taken to find a good op-
timum. In our experiments, we use the algorithm
presented in (Chang et al., 2010) to solve this
problem. The algorithm solves this non-convex
optimization function iteratively, decreasing the
value of the objective in each iteration until con-
vergence. In each iteration, the algorithm deter-
mines the values of the latent variables of positive
examples, and optimizes the modified objective
function using a cutting plane algorithm. This al-
gorithmic approach is conceptually (and algorith-
mically) related to the algorithm suggested by (Yu
and Joachims, 2009).
As standard, we classify x as positive iff
fw(x) &gt; 0. In Eq. (4), wT os(x) is the score
associated with the substructure s, and fw(x) is
the score for the entire intermediate representa-
tion. Therefore, our decision function fw(x) &gt; 0
makes use of the intermediate representation and
its score to classify the input.
</bodyText>
<sectionHeader confidence="0.992474" genericHeader="method">
4 Empirical Study
</sectionHeader>
<bodyText confidence="0.999986636363636">
Our experiments were designed with two objec-
tives in mind. Since this work is the first to tackle
the challenging task of objection prediction, we
are interested in understanding the scope and fea-
sibility of finding learning-based solutions.
Our second goal is to examine the individual as-
pects of our model and how they impact the over-
all decision and the latent structure it imposes. In
particular, we are interested in understanding the
effect that modeling the situated context (pragmat-
ics) of the dialogue has on objection prediction.
</bodyText>
<subsectionHeader confidence="0.97884">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999195933333333">
Evaluated Systems In order to understand the
different components of our system, we construct
several variations, which differ according to the re-
sources used during learning (see Section 2.2 for
details), and the latent variable formulation used
(see Section 2.3). We compare our latent model
with and without using pragmatic information (de-
noted DIAL(XS;t) and DIAL(X), respectively). We also
compare two baseline systems, which do not use
the latent variable formulation, these systems are
trained, using linear SVM, directly over all the fea-
tures activated by the hr decisions for all the turns
in the dialogue. Again, we consider two varia-
tions, with and without pragmatic information (de-
noted ALL(XS;t) and ALL(X), respectively).
</bodyText>
<subsectionHeader confidence="0.917047">
4.2 Datasets
</subsectionHeader>
<bodyText confidence="0.99941075">
Our dataset consists of dialogue snippets collected
from the transcripts of the famous O.J. Simpson
murder trial7, collected between January of 1995
to September of that year. We also extracted from
the same resource a list of all trial participants,
their roles in the murder case. Section 2.1 de-
scribes the technical details concerned with min-
ing these examples. The collected dataset consists
of 4981 dialogue snippets resulting in an objection
being raised, out of which 2153 were sustained. In
addition, we also mined the trial transcript for neg-
ative examples, collecting 6269 of those examples.
Negative examples are dialogue snippets which do
not result in an objection. To ensure fair evalua-
tion, we mined negative examples from each hear-
ing, proportionally to the number of positive ex-
amples identified in the same hearing. These ex-
amples were mined randomly, by selecting dia-
logue snippets that were not followed by an ob-
jection in any of the three subsequent turns.
We constructed several datasets, each capturing
different characteristics of courtroom interaction.
All Objections Our first dataset consists of all
the objections (both sustained and overruled). The
objection might not be justified, but the corre-
sponding dialogue either has the characteristics of
a justified objection, or it touches upon points of
controversy. In order to simulate this scenario,
we use all the examples, treating all examples re-
sulting in an objection as positive examples. We
randomly select 20% as test data. We refer to
this dataset as ALLOBJ. In addition, to examine
the different properties of sustained and overruled
objections we create two additional dataset, con-
sisting only of sustained/overruled objections and
negative examples. We denote the dataset con-
sisting only of sustained/overruled objections as
SUSTAINEDOBJ and OVERRULEDOBJ, respectively.
Objections by Type Our final dataset breaks the
objections down by type. Unfortunately, most ob-
jections are not raised with an explanation of their
type. We therefore can only use subsets of the
larger ALLOBJ dataset. We use the occurrences of
each objection type as the test dataset and match it
with negative examples, proportional to the size of
the typed dataset. For training, we use all the pos-
itive examples marked with an UNKNOWN type. The
size of each typed dataset appears in Table 3.
</bodyText>
<footnote confidence="0.988315">
7http://en.wikipedia.org/wiki/O._J._Simpson_
murder_case
</footnote>
<page confidence="0.981412">
660
</page>
<table confidence="0.99986975">
Objection Type #Pos/#Neg DIAL(xSit) DIAL(x) ALL(xSit) ALL(x)
CALLS FOR SPECULATION 304 / 364 59.4 58.6 58 58
IRRELEVANT 275 / 330 58.5 58.6 55.2 56.6
LACK OF FOUNDATION 238 / 285 60.6 55 57 52.1
HEARSAY 164 / 196 60.3 57.2 60 55
ARGUMENTATIVE 153 / 183 68.8 65.8 64.8 64.8
FACTS NOT IN EVIDENCE 120 / 144 64.7 65.5 59.8 59.4
LEADING QUESTION 116 / 139 56.7 58.4 56.8 58
</table>
<tableCaption confidence="0.983376">
Table 3: Accuracy results by objection type. Note that the dataset size varies according to the objection type.
</tableCaption>
<table confidence="0.9999548">
System ALLOBJ OVERRULEDOBJ SUSTAINEDOBJ
ALL(x) 64.9 63.7 66.9
ALL(xSit) 65.1 63.7 67.9
DIAL(x) 65.4 65.1 66.7
DIAL(xSit) 69.1 66.3 70.2
</table>
<tableCaption confidence="0.994105666666667">
Table 2: Overall Accuracy results. Results show consider-
able improvement when using our latent learning framework
with pragmatic information.
</tableCaption>
<subsectionHeader confidence="0.99921">
4.3 Empirical Analysis
</subsectionHeader>
<bodyText confidence="0.999816716417911">
Overall results We begin our discussion with
the experiments conducted over the three larger
datasets (ALLOBJ, SUSTAINEDOBJ, OVERRULEDOBJ). Table 2
summarizes the results obtained by the different
variations of our systems over these datasets.
The most striking observation emerging from
these results is the combined contribution of cap-
turing relevant dialogue content and interaction
(using latent variables), combined with pragmatic
information. For example in the ALLOBJ, when used
in conjunction, their joint contribution pushed per-
formance to 69.1 accuracy, a considerable im-
provement over using each one in isolation - 65.1
for the deterministic system using pragmatic infor-
mation, and 65.4 of the latent-variable formulation
which does not use this information. These results
are consistent in all of our experiments.
We also observe that sustained objections are
easier to predict than overruled objections. This
is not surprising since objections raised for unjus-
tified reasons are harder to detect.
Pragmatic Considerations Pragmatic informa-
tion in our system is modeled by using the xSit
representation, which conditions all decisions on
the speaker identity and role. The results in Ta-
ble 2 show that this information typically results
in better quality predictions.
An interesting side effect of using pragmatic
information is its impact on the dialogue struc-
ture predictions learned as latent variables dur-
ing learning. We can quantify the effect by look-
ing at the number of latent variables activated
for each model. When pragmatic information is
used, 5.6 relevance variables are used on average
(per dialogue snipped). In contrast, when prag-
matic information is not used, this number rises to
6.38. In addition, the average number of sentence-
connection variables active when pragmatic infor-
mation is used is 3.44. This number drops to 2.53
when it is not. These scores suggest that infor-
mation about the dialogue pragmatics allows the
model to take advantage of the dialogue structure
at the level of the latent information, focusing the
learner of higher level information, such as the re-
lation between turns, and less on low level, lexi-
cal information. The effect of using the pragmatic
information can be observed qualitatively as ex-
emplified in Figure 2, where the latent decisions,
when pragmatic information is available, construct
a more topically centered representation of the di-
alogue for the classification decision.
Typed Objections The results over the different
objection types are summarized in Table 3. These
results provide some intuition on which of the ob-
jection types are harder to predict, and the contri-
bution of each aspect of our system for that ob-
jection type.9 We can see that across the objec-
tion types, using latent variables modeling typi-
cally results in a considerable improvement in per-
formance. The most striking example of the im-
portance of using pragmatic information is the LACK
OF FOUNDATION objection type. This objection defini-
tion as “the evidence lacks testimony as to its au-
thenticity or source.”10 can explain this fact, as
information about the side in the trial introducing
specific evidence in testimony is very likely to im-
pact the objection decision.
</bodyText>
<sectionHeader confidence="0.999916" genericHeader="conclusions">
5 Related Work and Discussion
</sectionHeader>
<bodyText confidence="0.999107">
Our work applies latent variable learning to the
problem of uncovering pragmatic effects in court-
</bodyText>
<footnote confidence="0.9905602">
8The average number of sentences per dialogue is 8.6
9Since these datasets vary in size, their results are neither
directly comparable to each other nor to the results in Table 2.
10http://en.wikipedia.org/wiki/Foundation_
(evidence)
</footnote>
<page confidence="0.99056">
661
</page>
<figureCaption confidence="0.8286724">
Figure 2: Example of the pragmatic effect on latent
dialogue structure. Constructing the latent dialogue struc-
ture over situated text marks unrelated sentences as irrele-
vant, while marking topically related sentences and identi-
fying the connection between the question-answer pair (de-
cisions marked in solid blue lines). When trained without
situated information, the latent output structure marks topi-
cally unrelated sentences as relevant for objection classifica-
tion. Note that in this case all the edge variables are turned
off (marked with dashed red lines).
</figureCaption>
<bodyText confidence="0.992190829545455">
room dialogues. We adopted the structured latent
variable model defined in (Chang et al., 2010), and
use ILP to solve the structure prediction inference
problem (Roth and Yih, 2007).
Our prediction task, identifying the actionable
result of a dialogue, requires capturing the dia-
logue and discourse relations. While we view
these relations as latent variables in the context
of action prediction, studying these relations in-
dependently has been the focus of significant re-
search efforts, such as discourse relations (Prasad
et al., 2008), rhetorical structure (Marcu, 1997)
and dialogue act modeling (Stolcke et al., 2000).
Fully supervised approaches for learning to pre-
dict dialogue and discourse relations (such as
(Baldridge and Lascarides, 2005)) typically re-
quires heavy supervision and has been applied
only to limited domains.
Moving away from full supervision, the work of
(Golland et al., 2010) uses a game-theoretic model
to explicitly model the roles of dialogue partic-
ipants. In the context of dialogue and situated
language understanding, the work of (Artzi and
Zettlemoyer, 2011) shows how to derive supervi-
sion for dialogue processing from its structure.
Discriminative latent variables models have
seen a surge of interest in recent years, both in the
machine learning community (Yu and Joachims,
2009; Quattoni et al., 2007) as well as various ap-
plication domains such as NLP (T¨ackstr¨om and
McDonald, 2011) and computer vision (Felzen-
szwalb et al., 2010). In NLP, one of the most well-
known applications of discriminative latent struc-
tured classification is to the Textual Entailment
(TE) task (Chang et al., 2010; Wang and Manning,
2010). The TE task bears some resemblances ours,
as both tasks require making a binary decision
on the basis of a complex input object (i.e., the
history of dialogue, pairs of paragraphs), creating
the need for a learning framework that is flexible
enough to model the complex latent structure that
exists in the input. Another popular application
domain is sentiment analysis (Yessenalina et al.,
2010; T¨ackstr¨om and McDonald, 2011; Trivedi
and Eisenstein, 2013). The latent variable model
allows the learner to identify finer grained senti-
ment expression than annotated in the data.
A related area of work with different motiva-
tions and different technical approaches has fo-
cused on attempting to understand narrative struc-
ture. For instance, Chambers and Jurafsky (Cham-
bers and Jurafsky, 2008; Chambers and Juraf-
sky, 2009) model narrative flow in the style of
Schankian scripts (Schank and Abelson, 1977).
Their focus is on common sequences of actions,
not specifically related to dialogue. Somewhat
more related is recent work (Goyal et al., 2010)
that aimed to build a computational model of
Lehnert’s Plot Units (Lehnert, 1981) model. That
work focused primarily on actions and not on di-
alogue: in fact, their results showed that the lack
of dialogue understanding was a significant detri-
ment to their ability to model plot structure.
Instead of focusing on actions, like the above
work, we focus on dialogue content and relation-
ships between utterances. Furthermore, unlike
most of the relevant work in NLP, our approach
requires only very lightweight annotation coming
for “free” in the form of courtroom objections,
and use a latent variable model to provide judge-
ments of relevant linguistic and dialogue relations,
rather than annotating it manually. We enhance
this model using pragmatic information, captur-
ing speakers’ identity and role in the dialogue, and
show empirically the relevance of this information
when making predictions.
It is important to recognize that courtroom ob-
jections are not the only actionable result of di-
alogues. Many discussions that occur on online
forums, in social media, and by email result in
measurable real-world outcomes. We have shown
that one particular type of outcome, realized as a
speech-act, can drive dialogue interpretation; the
field is wide open to investigate others.
MS. KESTLER I don&apos;t recal if there was that day or not.
I know at some point, we had a meeting as to
what evidence we had and what was going to
be tested and who was going to test it.
</bodyText>
<figure confidence="0.989957076923077">
MR. DARDEN Your Honor, this is hearsay
THE COURT Overruled
MR. NEUFELD
MR. NEUFELD
MS. KESTLER
...
...
On the very next day, June 16th, did you
participate in another meeting about this case?
Do you recal being at a meeting with Erin
Reily, Colin Yamauchi and Dennis Fung and
Greg Matheson about this case on June 16th?
I don&apos;t recal.
</figure>
<page confidence="0.978455">
662
</page>
<sectionHeader confidence="0.997165" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909314606741">
Adam Vogel and Christopher Potts and Dan Jurafsky.
2011. Implicatures and Nested Beliefs in Approxi-
mate Decentralized-POMDPs. In EMNLP.
Yoav Artzi and Luke S. Zettlemoyer. 2011. Boot-
strapping semantic parsers from conversations. In
EMNLP.
Jason Baldridge and Alex Lascarides. 2005. Proba-
bilistic head-driven parsing for discourse structure.
In CoNLL.
B. E. Boser, I. M. Guyon, and V. N. Vapnik. 1992.
A training algorithm for optimal margin classifiers.
In Proc. 5th Annu. Workshop on Comput. Learning
Theory, pages 144–152.
Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT, June.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In ACL/IJCNLP, pages 602–610.
Ming-Wei Chang, Dan Goldwasser, Dan Roth, and
Vivek Srikumar. 2010. Discriminative learning over
constrained latent representations. In NAACL.
Pedro F. Felzenszwalb, Ross B. Girshick, David A.
McAllester, and Deva Ramanan. 2010. Object
detection with discriminatively trained part-based
models. IEEE Trans. Pattern Anal. Mach. Intell.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In ACL.
Dave Golland, Percy Liang, and Dan Klein. 2010.
A game-theoretic approach to generating spatial de-
scriptions. In EMNLP.
Amit Goyal, Ellen Riloff, and Hal Daum´e III. 2010.
Automatically producing plot unit representations
for narrative text. In Empirical Methods in Natural
Language Processing (EMNLP).
K. Hyland. 2005. Metadiscourse: Exploring inter-
action in writing. In Continuum, London and New
York.
W. G. Lehnert. 1981. Plot units and narrative summa-
rization. In Cognitive Science.
Daniel Marcu. 1997. The rhetorical parsing of natural
language texts. In ACL.
R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki,
L Robaldo, A. Joshi, and B. Webber. 2008. The
penn discourse treebank 2.0. In LREC.
Ariadna Quattoni, Sybor Wang, L-P Morency, Michael
Collins, and Trevor Darrell. 2007. Hidden condi-
tional random fields. Pattern Analysis and Machine
Intelligence, IEEE Transactions on.
Marta Recasens, Cristian Danescu-Niculescu-Mizil,
and Dan Jurafsky. 2013. Linguistic models for an-
alyzing and detecting biased language. In Proceed-
ings of ACL.
E. Riloff and J. Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In NAACL.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In Lise Getoor and Ben Taskar, editors,
Introduction to Statistical Relational Learning. MIT
Press.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
plans, goals and understanding. In ACL/IJCNLP.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliz-
abeth Shriberg, Rebecca Bates, Daniel Jurafsky,
Paul Taylor, Rachel Martin, Carol Van Ess-Dykema,
and Marie Meteer. 2000. Dialogue act modeling
for automatic tagging and recognition of conversa-
tional speech. COMPUTATIONAL LINGUISTICS,
26:339–373.
Oscar T¨ackstr¨om and Ryan T. McDonald. 2011. Dis-
covering fine-grained sentiment with latent variable
structured prediction models. In ECIR.
Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse
connectors for latent subjectivity in sentiment anal-
ysis. classification. In NAACL.
Mengqiu Wang and Christopher D. Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question an-
swering. In Proceedings of the 23rd International
Conference on Computational Linguistics (COLING
2010).
Ainur Yessenalina, Yisong Yue, and Claire Cardie.
2010. Multi-level structured models for document-
level sentiment classification. In EMNLP.
C. Yu and T. Joachims. 2009. Learning structural svms
with latent variables. In Proc. of the International
Conference on Machine Learning (ICML).
</reference>
<page confidence="0.998889">
663
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.362473">
<title confidence="0.999987">Object!” Latent Pragmatic Effects in Courtroom Dialogues</title>
<author confidence="0.997068">Dan</author>
<affiliation confidence="0.9979435">University of Institute for Advanced Computer</affiliation>
<address confidence="0.596633">College Park, MD ,</address>
<email confidence="0.999084">goldwas1@umiacs.edu</email>
<author confidence="0.998118">Hal Daum´e</author>
<affiliation confidence="0.9999355">Department of Computer University of</affiliation>
<address confidence="0.6175">College Park, MD ,</address>
<email confidence="0.999676">hal@cs.umd.edu</email>
<abstract confidence="0.999379733333333">Understanding the actionable outcomes of a dialogue requires effectively modeling situational roles of dialogue participants, the structure of the dialogue and the relevance of each utterance to an eventual action. We develop a latent-variable model that can capture these notions and apply it in the context of courtroom dialogues, which the act is used as binary supervision to drive the learning process. We demonstrate quantitatively and qualitatively that our model is able to uncover natural discourse structure from this distant supervision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Christopher Potts</author>
<author>Dan Jurafsky</author>
</authors>
<title>Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<marker>Vogel, Potts, Jurafsky, 2011</marker>
<rawString>Adam Vogel and Christopher Potts and Dan Jurafsky. 2011. Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke S Zettlemoyer</author>
</authors>
<title>Bootstrapping semantic parsers from conversations.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="32231" citStr="Artzi and Zettlemoyer, 2011" startWordPosition="4999" endWordPosition="5002">ant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Yoav Artzi and Luke S. Zettlemoyer. 2011. Bootstrapping semantic parsers from conversations. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Alex Lascarides</author>
</authors>
<title>Probabilistic head-driven parsing for discourse structure. In CoNLL.</title>
<date>2005</date>
<contexts>
<context position="31887" citStr="Baldridge and Lascarides, 2005" startWordPosition="4945" endWordPosition="4948">he structure prediction inference problem (Roth and Yih, 2007). Our prediction task, identifying the actionable result of a dialogue, requires capturing the dialogue and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well</context>
</contexts>
<marker>Baldridge, Lascarides, 2005</marker>
<rawString>Jason Baldridge and Alex Lascarides. 2005. Probabilistic head-driven parsing for discourse structure. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B E Boser</author>
<author>I M Guyon</author>
<author>V N Vapnik</author>
</authors>
<title>A training algorithm for optimal margin classifiers.</title>
<date>1992</date>
<booktitle>In Proc. 5th Annu. Workshop on Comput. Learning Theory,</booktitle>
<pages>144--152</pages>
<contexts>
<context position="20476" citStr="Boser et al., 1992" startWordPosition="3138" endWordPosition="3141">lassification settings, in which learning is done over a fixed representation of the input, we define the learning process over a set of latent variables. The process of choosing a good representation is formalized as an optimization problem that selects the elements and associated features that best contribute to successful classification. In the rest of this section we explain the learning process for the parameters of the model needed both for the representation decision and the final classification decision. 3.1 Learning Similar to the traditional formalization of support vector machines (Boser et al., 1992), learning is formulated as the following margin-based optimization problem, where λ is a regularization parameter, and ` is the squared-hinge loss function: X hswT φs(x) min λ X ` (−yifw(xi)) (5) fw(x) = max w 2 11w112 + h i s subject to (1)-(3); Vs; hs E {0,1}(4) In our experiments, we formalize Eq. (4) as an ILP instance, which we solve using the highly optimized Gurobi toolkit4. 2.3.4 Features In this section we describe the features used in each of the different decision types. Relevance (hr) : Bag-of-words: {(w, t.speaker. * 5)|Vw E t.s.text} 4http://www.gurobi.com/ 5“*” denotes all prop</context>
</contexts>
<marker>Boser, Guyon, Vapnik, 1992</marker>
<rawString>B. E. Boser, I. M. Guyon, and V. N. Vapnik. 1992. A training algorithm for optimal margin classifiers. In Proc. 5th Annu. Workshop on Comput. Learning Theory, pages 144–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative event chains.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<contexts>
<context position="33586" citStr="Chambers and Jurafsky, 2008" startWordPosition="5213" endWordPosition="5217">rs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewhat more related is recent work (Goyal et al., 2010) that aimed to build a computational model of Lehnert’s Plot Units (Lehnert, 1981) model. That work focused primarily on actions and not on dialogue: in fact, their results showed that the lack of dialogue understanding was a significant detriment to their ability to model plot structure. Instead of focusing on actions, like the above work, w</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised learning of narrative event chains. In Proceedings of ACL-08: HLT, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In ACL/IJCNLP,</booktitle>
<pages>602--610</pages>
<contexts>
<context position="33616" citStr="Chambers and Jurafsky, 2009" startWordPosition="5218" endWordPosition="5222">he need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewhat more related is recent work (Goyal et al., 2010) that aimed to build a computational model of Lehnert’s Plot Units (Lehnert, 1981) model. That work focused primarily on actions and not on dialogue: in fact, their results showed that the lack of dialogue understanding was a significant detriment to their ability to model plot structure. Instead of focusing on actions, like the above work, we focus on dialogue content an</context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In ACL/IJCNLP, pages 602–610.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
<author>Vivek Srikumar</author>
</authors>
<title>Discriminative learning over constrained latent representations.</title>
<date>2010</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="21670" citStr="Chang et al., 2010" startWordPosition="3347" endWordPosition="3350">om/ 5“*” denotes all properties Unlike standard support vector machines, our decision function fw(xi) is defined over a set of latent variables. We substitute Eq. (4) into Eq.(5), and obtain the following formulation for a latent structure classifier: ⎛ ⎞ `⎝−yi max ⎠ wT Xhsφs (xi ) h∈C s∈Γ(x) (6) 6refers to all linguistic resources used. We also included a +/-1 word window around words appearing in these resources λ X 2 11w112+ i min w 659 This formulation is not a convex optimization problem and care must be taken to find a good optimum. In our experiments, we use the algorithm presented in (Chang et al., 2010) to solve this problem. The algorithm solves this non-convex optimization function iteratively, decreasing the value of the objective in each iteration until convergence. In each iteration, the algorithm determines the values of the latent variables of positive examples, and optimizes the modified objective function using a cutting plane algorithm. This algorithmic approach is conceptually (and algorithmically) related to the algorithm suggested by (Yu and Joachims, 2009). As standard, we classify x as positive iff fw(x) &gt; 0. In Eq. (4), wT os(x) is the score associated with the substructure s</context>
<context position="31232" citStr="Chang et al., 2010" startWordPosition="4847" endWordPosition="4850">ct on latent dialogue structure. Constructing the latent dialogue structure over situated text marks unrelated sentences as irrelevant, while marking topically related sentences and identifying the connection between the question-answer pair (decisions marked in solid blue lines). When trained without situated information, the latent output structure marks topically unrelated sentences as relevant for objection classification. Note that in this case all the edge variables are turned off (marked with dashed red lines). room dialogues. We adopted the structured latent variable model defined in (Chang et al., 2010), and use ILP to solve the structure prediction inference problem (Roth and Yih, 2007). Our prediction task, identifying the actionable result of a dialogue, requires capturing the dialogue and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discou</context>
<context position="32769" citStr="Chang et al., 2010" startWordPosition="5086" endWordPosition="5089">e and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>Ming-Wei Chang, Dan Goldwasser, Dan Roth, and Vivek Srikumar. 2010. Discriminative learning over constrained latent representations. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro F Felzenszwalb</author>
<author>Ross B Girshick</author>
<author>David A McAllester</author>
<author>Deva Ramanan</author>
</authors>
<title>Object detection with discriminatively trained part-based models.</title>
<date>2010</date>
<journal>IEEE Trans. Pattern Anal. Mach. Intell.</journal>
<contexts>
<context position="32611" citStr="Felzenszwalb et al., 2010" startWordPosition="5059" endWordPosition="5063">rom full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and Mc</context>
</contexts>
<marker>Felzenszwalb, Girshick, McAllester, Ramanan, 2010</marker>
<rawString>Pedro F. Felzenszwalb, Ross B. Girshick, David A. McAllester, and Deva Ramanan. 2010. Object detection with discriminatively trained part-based models. IEEE Trans. Pattern Anal. Mach. Intell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="12414" citStr="Finkel et al., 2005" startWordPosition="1881" endWordPosition="1884">dication of structure, topics of controversy, and the sentiment and tone of language used in the dialogue. The second captures pragmatic considerations by situating the dialogue utterances in the context of the courtroom. Each utterance is attributed to a speaker, thus capturing meaningful patterns specific to individual speakers. Linguistic Resources (1) Named Entities provide strong indications of the topics discussed in the dialogue and help uncover relevant utterances, such as ones making claims associating individuals with locations. We use the Named Entity Recognizer (NER) described in (Finkel et al., 2005) to identify this information. (2) Subjective and Biased Language Equally important to understanding the topics of conversation is the way they are discussed. Expressions of subjectivity and sentiment are useful linguistic tools for changing the tone of the dialogue and are likely to attract opposition. We use several resources to capture this information. We use a lexicon of subjective and positive/negative sentiment expressions (Riloff and Wiebe, 2003). This resource can help identify subjective statements attempting to bias the discussion (e.g., “So he was driving negligently?”) We use a li</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dave Golland</author>
<author>Percy Liang</author>
<author>Dan Klein</author>
</authors>
<title>A game-theoretic approach to generating spatial descriptions.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="32041" citStr="Golland et al., 2010" startWordPosition="4970" endWordPosition="4973">e and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most well</context>
</contexts>
<marker>Golland, Liang, Klein, 2010</marker>
<rawString>Dave Golland, Percy Liang, and Dan Klein. 2010. A game-theoretic approach to generating spatial descriptions. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Goyal</author>
<author>Ellen Riloff</author>
<author>Hal Daum´e</author>
</authors>
<title>Automatically producing plot unit representations for narrative text.</title>
<date>2010</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<marker>Goyal, Riloff, Daum´e, 2010</marker>
<rawString>Amit Goyal, Ellen Riloff, and Hal Daum´e III. 2010. Automatically producing plot unit representations for narrative text. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hyland</author>
</authors>
<title>Metadiscourse: Exploring interaction in writing.</title>
<date>2005</date>
<booktitle>In Continuum, London and</booktitle>
<location>New York.</location>
<contexts>
<context position="13054" citStr="Hyland, 2005" startWordPosition="1982" endWordPosition="1983">on. (2) Subjective and Biased Language Equally important to understanding the topics of conversation is the way they are discussed. Expressions of subjectivity and sentiment are useful linguistic tools for changing the tone of the dialogue and are likely to attract opposition. We use several resources to capture this information. We use a lexicon of subjective and positive/negative sentiment expressions (Riloff and Wiebe, 2003). This resource can help identify subjective statements attempting to bias the discussion (e.g., “So he was driving negligently?”) We use a list of hedges and boosters (Hyland, 2005). This resource can potentially allow the model to identify evasive (“I might have seen him”) and (overly) confident responses (“I am absolutely sure that I have seen him”). We use a lexicon of biased language provided by (Recasens et al., 2013), this lexicon extracted from Wikipedia edits consists of words indicative of bias, for example in an attempt to frame the facts raised in the discussion according to one of the viewpoints (“The death of Nicolle Simposon” vs. “The murder of Nicolle Simposon”). Finally we use a Patient Polarity Verbs lexicon (Goyal et al., 2010). This lexicon consists 65</context>
</contexts>
<marker>Hyland, 2005</marker>
<rawString>K. Hyland. 2005. Metadiscourse: Exploring interaction in writing. In Continuum, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Lehnert</author>
</authors>
<title>Plot units and narrative summarization.</title>
<date>1981</date>
<journal>In Cognitive Science.</journal>
<contexts>
<context position="33924" citStr="Lehnert, 1981" startWordPosition="5270" endWordPosition="5271">fy finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewhat more related is recent work (Goyal et al., 2010) that aimed to build a computational model of Lehnert’s Plot Units (Lehnert, 1981) model. That work focused primarily on actions and not on dialogue: in fact, their results showed that the lack of dialogue understanding was a significant detriment to their ability to model plot structure. Instead of focusing on actions, like the above work, we focus on dialogue content and relationships between utterances. Furthermore, unlike most of the relevant work in NLP, our approach requires only very lightweight annotation coming for “free” in the form of courtroom objections, and use a latent variable model to provide judgements of relevant linguistic and dialogue relations, rather </context>
</contexts>
<marker>Lehnert, 1981</marker>
<rawString>W. G. Lehnert. 1981. Plot units and narrative summarization. In Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The rhetorical parsing of natural language texts.</title>
<date>1997</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="31710" citStr="Marcu, 1997" startWordPosition="4921" endWordPosition="4922">ed off (marked with dashed red lines). room dialogues. We adopted the structured latent variable model defined in (Chang et al., 2010), and use ILP to solve the structure prediction inference problem (Roth and Yih, 2007). Our prediction task, identifying the actionable result of a dialogue, requires capturing the dialogue and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Di</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. The rhetorical parsing of natural language texts. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Prasad</author>
<author>N Dinesh</author>
<author>A Lee</author>
<author>E Miltsakaki</author>
<author>L Robaldo</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>The penn discourse treebank 2.0. In LREC.</title>
<date>2008</date>
<contexts>
<context position="31674" citStr="Prasad et al., 2008" startWordPosition="4915" endWordPosition="4918">in this case all the edge variables are turned off (marked with dashed red lines). room dialogues. We adopted the structured latent variable model defined in (Chang et al., 2010), and use ILP to solve the structure prediction inference problem (Roth and Yih, 2007). Our prediction task, identifying the actionable result of a dialogue, requires capturing the dialogue and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialog</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L Robaldo, A. Joshi, and B. Webber. 2008. The penn discourse treebank 2.0. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariadna Quattoni</author>
<author>Sybor Wang</author>
<author>L-P Morency</author>
<author>Michael Collins</author>
<author>Trevor Darrell</author>
</authors>
<title>Hidden conditional random fields. Pattern Analysis and Machine Intelligence,</title>
<date>2007</date>
<journal>IEEE Transactions on.</journal>
<contexts>
<context position="32479" citStr="Quattoni et al., 2007" startWordPosition="5038" endWordPosition="5041">aldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent struct</context>
</contexts>
<marker>Quattoni, Wang, Morency, Collins, Darrell, 2007</marker>
<rawString>Ariadna Quattoni, Sybor Wang, L-P Morency, Michael Collins, and Trevor Darrell. 2007. Hidden conditional random fields. Pattern Analysis and Machine Intelligence, IEEE Transactions on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Dan Jurafsky</author>
</authors>
<title>Linguistic models for analyzing and detecting biased language.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="13299" citStr="Recasens et al., 2013" startWordPosition="2022" endWordPosition="2025">gue and are likely to attract opposition. We use several resources to capture this information. We use a lexicon of subjective and positive/negative sentiment expressions (Riloff and Wiebe, 2003). This resource can help identify subjective statements attempting to bias the discussion (e.g., “So he was driving negligently?”) We use a list of hedges and boosters (Hyland, 2005). This resource can potentially allow the model to identify evasive (“I might have seen him”) and (overly) confident responses (“I am absolutely sure that I have seen him”). We use a lexicon of biased language provided by (Recasens et al., 2013), this lexicon extracted from Wikipedia edits consists of words indicative of bias, for example in an attempt to frame the facts raised in the discussion according to one of the viewpoints (“The death of Nicolle Simposon” vs. “The murder of Nicolle Simposon”). Finally we use a Patient Polarity Verbs lexicon (Goyal et al., 2010). This lexicon consists 657 of verbs in which the agent performs an action with a positive (“He donated money to the foundation”) or negative (“He stole money from the foundation”) consequence to the patient. (3) Sentence Segmentation Many turns discuss multiple topics, </context>
</contexts>
<marker>Recasens, Danescu-Niculescu-Mizil, Jurafsky, 2013</marker>
<rawString>Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic models for analyzing and detecting biased language. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="12872" citStr="Riloff and Wiebe, 2003" startWordPosition="1951" endWordPosition="1954">r relevant utterances, such as ones making claims associating individuals with locations. We use the Named Entity Recognizer (NER) described in (Finkel et al., 2005) to identify this information. (2) Subjective and Biased Language Equally important to understanding the topics of conversation is the way they are discussed. Expressions of subjectivity and sentiment are useful linguistic tools for changing the tone of the dialogue and are likely to attract opposition. We use several resources to capture this information. We use a lexicon of subjective and positive/negative sentiment expressions (Riloff and Wiebe, 2003). This resource can help identify subjective statements attempting to bias the discussion (e.g., “So he was driving negligently?”) We use a list of hedges and boosters (Hyland, 2005). This resource can potentially allow the model to identify evasive (“I might have seen him”) and (overly) confident responses (“I am absolutely sure that I have seen him”). We use a lexicon of biased language provided by (Recasens et al., 2013), this lexicon extracted from Wikipedia edits consists of words indicative of bias, for example in an attempt to frame the facts raised in the discussion according to one of</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>E. Riloff and J. Wiebe. 2003. Learning extraction patterns for subjective expressions. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation.</title>
<date>2007</date>
<booktitle>In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="31318" citStr="Roth and Yih, 2007" startWordPosition="4861" endWordPosition="4864">ted text marks unrelated sentences as irrelevant, while marking topically related sentences and identifying the connection between the question-answer pair (decisions marked in solid blue lines). When trained without situated information, the latent output structure marks topically unrelated sentences as relevant for objection classification. Note that in this case all the edge variables are turned off (marked with dashed red lines). room dialogues. We adopted the structured latent variable model defined in (Chang et al., 2010), and use ILP to solve the structure prediction inference problem (Roth and Yih, 2007). Our prediction task, identifying the actionable result of a dialogue, requires capturing the dialogue and discourse relations. While we view these relations as latent variables in the context of action prediction, studying these relations independently has been the focus of significant research efforts, such as discourse relations (Prasad et al., 2008), rhetorical structure (Marcu, 1997) and dialogue act modeling (Stolcke et al., 2000). Fully supervised approaches for learning to predict dialogue and discourse relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supe</context>
</contexts>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
<author>Robert P Abelson</author>
</authors>
<title>Scripts, plans, goals and understanding.</title>
<date>1977</date>
<booktitle>In ACL/IJCNLP.</booktitle>
<contexts>
<context position="33698" citStr="Schank and Abelson, 1977" startWordPosition="5232" endWordPosition="5235">structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewhat more related is recent work (Goyal et al., 2010) that aimed to build a computational model of Lehnert’s Plot Units (Lehnert, 1981) model. That work focused primarily on actions and not on dialogue: in fact, their results showed that the lack of dialogue understanding was a significant detriment to their ability to model plot structure. Instead of focusing on actions, like the above work, we focus on dialogue content and relationships between utterances. Furthermore, unlike most of the relevant work </context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Roger C. Schank and Robert P. Abelson. 1977. Scripts, plans, goals and understanding. In ACL/IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Klaus Ries</author>
<author>Noah Coccaro</author>
<author>Elizabeth Shriberg</author>
<author>Rebecca Bates</author>
<author>Daniel Jurafsky</author>
<author>Paul Taylor</author>
<author>Rachel Martin</author>
<author>Carol Van Ess-Dykema</author>
<author>Marie Meteer</author>
</authors>
<title>Dialogue act modeling for automatic tagging and recognition of conversational speech.</title>
<date>2000</date>
<journal>COMPUTATIONAL LINGUISTICS,</journal>
<pages>26--339</pages>
<marker>Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky, Taylor, Martin, Van Ess-Dykema, Meteer, 2000</marker>
<rawString>Andreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul Taylor, Rachel Martin, Carol Van Ess-Dykema, and Marie Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. COMPUTATIONAL LINGUISTICS, 26:339–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan T McDonald</author>
</authors>
<title>Discovering fine-grained sentiment with latent variable structured prediction models.</title>
<date>2011</date>
<booktitle>In ECIR.</booktitle>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan T. McDonald. 2011. Discovering fine-grained sentiment with latent variable structured prediction models. In ECIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rakshit Trivedi</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Discourse connectors for latent subjectivity in sentiment analysis. classification.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="33254" citStr="Trivedi and Eisenstein, 2013" startWordPosition="5162" endWordPosition="5165">of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewhat more related is recent work (Goyal et al., 2010) that aimed </context>
</contexts>
<marker>Trivedi, Eisenstein, 2013</marker>
<rawString>Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse connectors for latent subjectivity in sentiment analysis. classification. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Probabilistic tree-edit models with structured latent variables for textual entailment and question answering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="32794" citStr="Wang and Manning, 2010" startWordPosition="5090" endWordPosition="5093">age understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of </context>
</contexts>
<marker>Wang, Manning, 2010</marker>
<rawString>Mengqiu Wang and Christopher D. Manning. 2010. Probabilistic tree-edit models with structured latent variables for textual entailment and question answering. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Yisong Yue</author>
<author>Claire Cardie</author>
</authors>
<title>Multi-level structured models for documentlevel sentiment classification.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="33191" citStr="Yessenalina et al., 2010" startWordPosition="5154" endWordPosition="5157"> computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model the complex latent structure that exists in the input. Another popular application domain is sentiment analysis (Yessenalina et al., 2010; T¨ackstr¨om and McDonald, 2011; Trivedi and Eisenstein, 2013). The latent variable model allows the learner to identify finer grained sentiment expression than annotated in the data. A related area of work with different motivations and different technical approaches has focused on attempting to understand narrative structure. For instance, Chambers and Jurafsky (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009) model narrative flow in the style of Schankian scripts (Schank and Abelson, 1977). Their focus is on common sequences of actions, not specifically related to dialogue. Somewh</context>
</contexts>
<marker>Yessenalina, Yue, Cardie, 2010</marker>
<rawString>Ainur Yessenalina, Yisong Yue, and Claire Cardie. 2010. Multi-level structured models for documentlevel sentiment classification. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Yu</author>
<author>T Joachims</author>
</authors>
<title>Learning structural svms with latent variables.</title>
<date>2009</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="22146" citStr="Yu and Joachims, 2009" startWordPosition="3417" endWordPosition="3420">vex optimization problem and care must be taken to find a good optimum. In our experiments, we use the algorithm presented in (Chang et al., 2010) to solve this problem. The algorithm solves this non-convex optimization function iteratively, decreasing the value of the objective in each iteration until convergence. In each iteration, the algorithm determines the values of the latent variables of positive examples, and optimizes the modified objective function using a cutting plane algorithm. This algorithmic approach is conceptually (and algorithmically) related to the algorithm suggested by (Yu and Joachims, 2009). As standard, we classify x as positive iff fw(x) &gt; 0. In Eq. (4), wT os(x) is the score associated with the substructure s, and fw(x) is the score for the entire intermediate representation. Therefore, our decision function fw(x) &gt; 0 makes use of the intermediate representation and its score to classify the input. 4 Empirical Study Our experiments were designed with two objectives in mind. Since this work is the first to tackle the challenging task of objection prediction, we are interested in understanding the scope and feasibility of finding learning-based solutions. Our second goal is to </context>
<context position="32455" citStr="Yu and Joachims, 2009" startWordPosition="5034" endWordPosition="5037">e relations (such as (Baldridge and Lascarides, 2005)) typically requires heavy supervision and has been applied only to limited domains. Moving away from full supervision, the work of (Golland et al., 2010) uses a game-theoretic model to explicitly model the roles of dialogue participants. In the context of dialogue and situated language understanding, the work of (Artzi and Zettlemoyer, 2011) shows how to derive supervision for dialogue processing from its structure. Discriminative latent variables models have seen a surge of interest in recent years, both in the machine learning community (Yu and Joachims, 2009; Quattoni et al., 2007) as well as various application domains such as NLP (T¨ackstr¨om and McDonald, 2011) and computer vision (Felzenszwalb et al., 2010). In NLP, one of the most wellknown applications of discriminative latent structured classification is to the Textual Entailment (TE) task (Chang et al., 2010; Wang and Manning, 2010). The TE task bears some resemblances ours, as both tasks require making a binary decision on the basis of a complex input object (i.e., the history of dialogue, pairs of paragraphs), creating the need for a learning framework that is flexible enough to model t</context>
</contexts>
<marker>Yu, Joachims, 2009</marker>
<rawString>C. Yu and T. Joachims. 2009. Learning structural svms with latent variables. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>