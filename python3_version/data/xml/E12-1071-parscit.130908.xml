<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000560">
<title confidence="0.976595">
Unsupervised Detection of Downward-Entailing Operators By
Maximizing Classification Certainty
</title>
<author confidence="0.951132">
Jackie CK Cheung and Gerald Penn
</author>
<affiliation confidence="0.9983995">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.984617">
Toronto, ON, M5S 3G4, Canada
</address>
<email confidence="0.999393">
{jcheung,gpenn}@cs.toronto.edu
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999923444444445">
We propose an unsupervised, iterative
method for detecting downward-entailing
operators (DEOs), which are important for
deducing entailment relations between sen-
tences. Like the distillation algorithm of
Danescu-Niculescu-Mizil et al. (2009), the
initialization of our method depends on the
correlation between DEOs and negative po-
larity items (NPIs). However, our method
trusts the initialization more and aggres-
sively separates likely DEOs from spuri-
ous distractors and other words, unlike dis-
tillation, which we show to be equivalent
to one iteration of EM prior re-estimation.
Our method is also amenable to a bootstrap-
ping method that co-learns DEOs and NPIs,
and achieves the best results in identifying
DEOs in two corpora.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.946847130434783">
Reasoning about text has been a long-standing
challenge in NLP, and there has been consider-
able debate both on what constitutes inference and
what techniques should be used to support infer-
ence. One task involving inference that has re-
cently received much attention is that of recog-
nizing textual entailment (RTE), in which the goal
is to determine whether a hypothesis sentence can
be entailed from a piece of source text (Bentivogli
et al., 2010, for example).
An important consideration in RTE is whether
a sentence or context produces an entailment re-
lation for events that are a superset or subset of
the original sentence (MacCartney and Manning,
2008). By default, contexts are upward-entailing,
allowing reasoning from a set of events to a su-
perset of events as seen in (1). In the scope of
a downward-entailing operator (DEO), however,
this entailment relation is reversed, such as in
the scope of the classical DEO not (2). There
are also operators which are neither upward- nor
downward entailing, such as the expression ex-
actly three (3).
</bodyText>
<listItem confidence="0.981409142857143">
(1) She sang in French. ⇒ She sang.
(upward-entailing)
(2) She did not sing in French. ⇐ She did not
sing. (downward-entailing)
(3) Exactly three students sang. ⇔� Exactly
three students sang in French. (neither
upward- nor downward-entailing)
</listItem>
<bodyText confidence="0.997770318181818">
Danescu-Niculescu-Mizil et al. (2009) (hence-
forth DLD09) proposed the first computational
methods for detecting DEOs from a corpus. They
proposed two unsupervised algorithms which rely
on the correlation between DEOs and negative
polarity items (NPIs), which by the definition of
Ladusaw (1980) must appear in the context of
DEOs. An example of an NPI is yet, as in the
sentence This project is not complete yet. The
first baseline method proposed by DLD09 sim-
ply calculates a ratio of the relative frequencies
of a word in NPI contexts versus in a general
corpus, and the second is a distillation method
which appears to refine the baseline ratios using a
task-specific heuristic. Danescu-Niculescu-Mizil
and Lee (2010) (henceforth DL10) extend this ap-
proach to Romanian, where a comprehensive list
of NPIs is not available, by proposing a bootstrap-
ping approach to co-learn DEOs and NPIs.
DLD09 are to be commended for having iden-
tified a crucial component of inference that nev-
ertheless lends itself to a classification-based ap-
</bodyText>
<page confidence="0.981328">
696
</page>
<note confidence="0.976627">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 696–705,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999973193548387">
proach, as we will show. However, as noted
by DL10, the performance of the distillation
method is mixed across languages and in the
semi-supervised bootstrapping setting, and there
is no mathematical grounding of the heuristic to
explain why it works and whether the approach
can be refined or extended. This paper supplies
the missing mathematical basis for distillation and
shows that, while its intentions are fundamentally
sound, the formulation of distillation neglects an
important requirement that the method not be
easily distracted by other word co-occurrences
in NPI contexts. We call our alternative cer-
tainty, which uses an unusual posterior classifica-
tion confidence score (based on the max function)
to favour single, definite assignments of DEO-
hood within every NPI context. DLD09 actually
speculated on the use of max as an alternative,
but within the context of an EM-like optimization
procedure that throws away its initial parameter
settings too willingly. Certainty iteratively and
directly boosts the scores of the currently best-
ranked DEO candidates relative to the alternatives
in a Naive Bayes model, which thus pays more re-
spect to the initial weights, constructively build-
ing on top of what the model already knows. This
method proves to perform better on two corpora
than distillation, and is more amenable to the co-
learning of NPIs and DEOs. In fact, the best
results are obtained by co-learning the NPIs and
DEOs in conjunction with our method.
</bodyText>
<sectionHeader confidence="0.999896" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999647666666667">
There is a large body of literature in linguis-
tic theory on downward entailment and polar-
ity items1, of which we will only mention the
most relevant work here. The connection between
downward-entailing contexts and negative polar-
ity items was noticed by Ladusaw (1980), who
stated the hypothesis that NPIs must be gram-
matically licensed by a DEO. However, DEOs
are not the sole licensors of NPIs, as NPIs can
also be found in the scope of questions, certain
numeric expressions (i.e., non-monotone quanti-
fiers), comparatives, and conditionals, among oth-
ers. Giannakidou (2002) proposes that the prop-
erty shared by these constructions and downward
entailment is non-veridicality. If F is a propo-
</bodyText>
<footnote confidence="0.967616">
1See van der Wouden (1997) for a comprehensive refer-
ence.
</footnote>
<bodyText confidence="0.9997696">
sitional operator for proposition p, then an oper-
ator is non-veridical if Fp ⇒6 p. Positive opera-
tors such as past tense adverbials are veridical (4),
whereas questions, negation and other DEOs are
non-veridical (5, 6).
</bodyText>
<listItem confidence="0.999698333333333">
(4) She sang yesterday. ⇒ She sang.
(5) She denied singing. ⇒6 She sang.
(6) Did she sing? ⇒6 She sang.
</listItem>
<bodyText confidence="0.999842117647058">
While Ladusaw’s hypothesis is thus accepted
to be insufficient from a linguistic perspective, it
is nevertheless a useful starting point for compu-
tational methods for detecting NPIs and DEOs,
and has inspired successful techniques to detect
DEOs, like the work by DLD09, DL10, and also
this work. In addition to this hypothesis, we fur-
ther assume that there should only be one plausi-
ble DEO candidate per NPI context. While there
are counterexamples, this assumption is in prac-
tice very robust, and is a useful constraint for our
learning algorithm. An analogy can be drawn to
the one sense per discourse assumption in word
sense disambiguation (Gale et al., 1992).
The related—and as we will argue, more
difficult—problem of detecting NPIs has also
been studied, and in fact predates the work on
DEO detection. Hoeksema (1997) performed the
first corpus-based study of NPIs, predominantly
for Dutch, and there has also been work on de-
tecting NPIs in German which assumes linguistic
knowledge of licensing contexts for NPIs (Lichte
and Soehn, 2007). Richter et al. (2010) make
this assumption as well as use syntactic structure
to extract NPIs that are multi-word expressions.
Parse information is an especially important con-
sideration in freer-word-order languages like Ger-
man where a MWE may not appear as a contigu-
ous string. In this paper, we explicitly do not as-
sume detailed linguistic knowledge about licens-
ing contexts for NPIs and do not assume that a
parser is available, since neither of these are guar-
anteed when extending this technique to resource-
poor languages.
</bodyText>
<sectionHeader confidence="0.958949" genericHeader="method">
3 Distillation as EM Prior Re-estimation
</sectionHeader>
<bodyText confidence="0.999798">
Let us first review the baseline and distillation
methods proposed by DLD09, then show that dis-
tillation is equivalent to one iteration of EM prior
</bodyText>
<page confidence="0.997186">
697
</page>
<bodyText confidence="0.990392285714286">
re-estimation in a Naive Bayes generative proba-
bilistic model up to constant rescaling. The base-
line method assigns a score to each word-type
based on the ratio of its relative frequency within
NPI contexts to its relative frequency within a
general corpus. Suppose we are given a corpus C
with extracted NPI contexts N and they contain
tokens(C) and tokens(N) tokens respectively.
Let y be a candidate DEO, countC(y) be the uni-
gram frequency of y in a corpus, and countN(y)
be the unigram frequency of y in N. Then, we
define S(y) to be the ratio between the relative
frequencies of y within NPI contexts and in the
entire corpus2:
</bodyText>
<equation confidence="0.996378">
countN(y)/tokens(N)
S(y) = countC(y)/tokens(C) .(7)
</equation>
<bodyText confidence="0.999850142857143">
The scores are then used as a ranking to de-
termine word-types that are likely to be DEOs.
This method approximately captures Ladusaw’s
hypothesis by highly ranking words that appear
in NPI contexts more often than would be ex-
pected by chance. However, the problem with
this approach is that DEOs are not the only words
that co-occur with NPIs. In particular, there exist
many piggybackers, which, as defined by DLD09,
collocate with DEOs due to semantic relatedness
or chance, and would thus incorrectly receive a
high S(y) score.
Examples of piggybackers found by DLD09 in-
clude the proper noun Milken, and the adverb vig-
orously, which collocate with DEOs like deny in
the corpus they used. DLD09’s solution to the
piggybacker problem is a method that they term
distillation. Let Ny be the NPI contexts that con-
tain word y; i.e., Ny = {c E N|c D y}. In dis-
tillation, each word-type is given a distilled score
according to the following equation:
</bodyText>
<equation confidence="0.9996075">
1 �
Sd(y) = |Ny |p∈Ny
</equation>
<bodyText confidence="0.9982475">
where p indexes the set of NPI contexts which
contain y3, and the denominator is the number of
</bodyText>
<footnote confidence="0.9912165">
2DLD09 actually use the number of NPI contexts con-
taining y rather than countN (y), but we find that using the
raw count works better in our experiments.
3In DLD09, the corresponding equation does not indicate
that p should be the contexts that include y, but it is clear
from the surrounding text that our version is the intended
meaning. If all the NPI contexts were included in the sum-
mation, Sd(y) would reduce to inverse relative frequency.
</footnote>
<figureCaption confidence="0.999546">
Figure 1: Naive Bayes formulation of DEO detection.
</figureCaption>
<bodyText confidence="0.999376827586207">
NPI contexts which contain y.
DLD09 find that distillation seems to improve
the performance of DEO detection in BLLIP.
Later work by DL10, however, shows that distil-
lation does not seem to improve performance over
the baseline method in Romanian, and the authors
also note that distillation does not improve perfor-
mance in their experiments on co-learning NPIs
and DEOs via bootstrapping.
A better mathematical grounding of the distilla-
tion method’s apparent heuristic in terms of exist-
ing probabilistic models sheds light on the mixed
performance of distillation across languages and
experimental settings. In particular, it turns out
that the distillation method of DLD09 is equiva-
lent to one iteration of EM prior re-estimation in
a Naive Bayes model. Given a lexicon L of L
words, let each NPI context be one sample gen-
erated by the model. One sample consists of a
latent categorical (i.e., a multinomial with one
trial) variable Y whose values range over L, cor-
responding to the DEO that licenses the context,
and observed Bernoulli variables X� = Xi=1...L
which indicate whether a word appears in the NPI
context (Figure 1). This method does not attempt
to model the order of the observed words, nor the
number of times each word appears. Formally, a
Naive Bayes model is given by the following ex-
pression:
</bodyText>
<equation confidence="0.997292666666667">
L
P( X,Y ) = P(Xi|Y )P(Y ). (9)
i=1
</equation>
<bodyText confidence="0.754826">
The probability of a DEO given a particular
NPI context is
</bodyText>
<equation confidence="0.8098128">
L
P(Y  |X) a P(Xi|Y )P(Y ). (10)
i=1
DEO
Context words
Y
X
L
S(y) (8)
Ey′∈p S(y′
</equation>
<page confidence="0.98158">
698
</page>
<bodyText confidence="0.9941333">
The probability of a set of observed NPI con-
texts N is the product of the probabilities for each
sample:
We first instantiate the baseline method of
DLD09 by initializing the parameters to the
model, P(XZ = 1|y) and P(Y = y), such that
P(Y = y) is proportional to S(y). Recall that this
initialization utilizes domain knowledge about the
correlation between NPIs and DEOs, inspired by
Ladusaw’s hypothesis:
</bodyText>
<equation confidence="0.997117833333333">
P(Y = y) = S(y)/ � S(y′) (13)
y′
r 1 if XZ corresponds to y
P(XZ = 1|y) =
0.5 otherwise.
(14)
</equation>
<bodyText confidence="0.9999256">
This initialization of P(XZ = 1|y) ensures that
the the value of y corresponds to one of the words
in the NPI context, and the initialization of P(Y )
is simply a normalization of S(y).
Since we are working in an unsupervised set-
ting, there are no labels for Y available. A com-
mon and reasonable assumption about learning
the parameter settings in this case is to find the pa-
rameters that maximize the likelihood of the ob-
served training data; i.e., the NPI contexts:
</bodyText>
<equation confidence="0.9298485">
θ� = argmax
θ P(N; θ). (15)
</equation>
<bodyText confidence="0.9510965">
The EM algorithm is a well-known iterative al-
gorithm for performing this optimization. Assum-
ing that the prior P(Y = y) is a categorical distri-
bution, the M-step estimate of these parameters
after one iteration through the corpus is as fol-
lows:
We do not re-estimate P(XZ = 1|y) because
their role is simply to ensure that the DEO re-
sponsible for an NPI context exists in the context.
Estimating these parameters would exacerbate the
problems with EM for this task which we will dis-
cuss shortly.
P(Y ) gives a prior probability that a certain
word-type y is a DEO in an NPI context, without
normalizing for the frequency of y in NPI con-
texts. Since we are interested in estimating the
context-independent probability that y is a DEO,
we must calculate the probability that a word is
a DEO given that it appears in an NPI context.
Let Xy be the observed variable corresponding to
y. Then, the expression we are interested in is
P(y|Xy = 1). We now show that P(y|Xy =
1) = P(y)/P(Xy = 1), and that this expression
is equivalent to (8).
</bodyText>
<equation confidence="0.999923">
P (y, Xy = 1)
P(y|Xy = 1) = P(Xy = 1) (17)
</equation>
<bodyText confidence="0.904852">
Recall that P(y, Xy = 0) = 0 because of the
assumption that a DEO appears in the NPI context
that it generates. Thus,
</bodyText>
<equation confidence="0.9894925">
P(y, Xy = 1) = P(y, Xy = 1) + P(y, Xy = 0)
= P(y) (18)
</equation>
<bodyText confidence="0.999554172413793">
One iteration of EM to calculate this proba-
bility is equivalent to the distillation method of
DLD09. In particular, the numerator of (17),
which we just showed to be equal to the estimate
of P(Y ) given by (16), is exactly the sum of the
responsibilities for a particular y, and is propor-
tional to the summation in (8) modulo normaliza-
tion, because P( ~X|y) is constant for all y in the
context. The denominator P(Xy = 1) is simply
the proportion of contexts containing y, which is
proportional to |Ny|. Since both the numerator
and denominator are equivalent up to a constant
factor, an identical ranking is produced by distil-
lation and EM prior re-estimation.
Unfortunately, the EM algorithm does not pro-
vide good results on this task. In fact, as more
iterations of EM are run, the performance drops
drastically, even though the corpus likelihood
is increasing. The reason is that unsupervised
EM learning is not constrained or biased towards
learning a good set of DEOs. Rather, a higher data
likelihood can be achieved simply by assigning
high prior probabilities to frequent word-types.
This can be seen qualitatively by consider-
ing the top-ranking DEOs after several itera-
tions of EM/distillation (Figure 2). The top-
ranking words are simply function words or other
words common in the corpus, which have noth-
ing to do with downward entailment. In effect,
</bodyText>
<equation confidence="0.9278340625">
�
Pt+1(Y = y) =
XEN
Pt(
′
y′|
Ey
Pt(y|~X) (16)
X)
P(N) = rl P( ~X) (11)
XEN
P( � P(~X, y). (12)
~X) =
yEG
699
1 iteration 2 iterations
</equation>
<bodyText confidence="0.97775">
denies
denied
unaware
longest
hardly
lacking
deny
nobody
opposes
highest
</bodyText>
<figureCaption confidence="0.982562">
Figure 2: Top 10 DEOs after iterations of EM on
BLLIP.
</figureCaption>
<bodyText confidence="0.9997732">
EM/distillation overrides the initialization based
on Ladusaw’s hypothesis and finds another solu-
tion with a higher data likelihood. We will also
provide a quantitative analysis of the effects of
EM/distillation in Section 5.
</bodyText>
<sectionHeader confidence="0.919622" genericHeader="method">
4 Alternative to EM: Maximizing the
Posterior Classification Certainty
</sectionHeader>
<bodyText confidence="0.999586357142857">
We have seen that in trying to solve the piggy-
backer problem, EM/distillation too readily aban-
dons the initialization based on Ladusaw’s hy-
pothesis, leading to an incorrect solution. Instead
of optimizing the data likelihood, what we need is
a measure of the number of plausible DEO candi-
dates there are in an NPI context, and a method
that refines the scores towards having only one
such plausible candidate per context. To this end,
we define the classification certainty to be the
product of the maximum posterior classification
probabilities over the DEO candidates. For a set
of hidden variables yN for NPI contexts N, this
is the expression:
</bodyText>
<equation confidence="0.970544333333333">
�
Certainty(yN|N) =
~XEN
</equation>
<bodyText confidence="0.999985875">
To increase this certainty score, we propose
a novel iterative heuristic method for refining
the baseline initializations of P(Y ). Unlike
EM/distillation, our method biases learning to-
wards trusting the initialization, but refines the
scores towards having only one plausible DEO
per context in the training corpus. This is accom-
plished by treating the problem as a DEO classi-
fication problem, and then maximizing an objec-
tive ratio that favours one DEO per context. Our
method is not guaranteed to increase classification
certainty between iterations, but we will show that
it does increase certainty very quickly in practice.
The key observation that allows us to resolve
the tension between trusting the initialization and
enforcing one DEO per NPI context is that the
distributions of words that co-occur with DEOs
and piggybackers are different, and that this dif-
ference follows from Ladusaw’s hypothesis. In
particular, while DEOs may appear with or with-
out piggybackers in NPI contexts, piggybackers
do not appear without DEOs in NPI contexts, be-
cause Ladusaw’s hypothesis stipulates that a DEO
is required to license the NPI in the first place.
Thus, the presence of a high-scoring DEO candi-
date among otherwise low-scoring words is strong
evidence that the high-scoring word is not a pig-
gybacker and its high score from the initialization
is deserved. Conversely, a DEO candidate which
always appears in the presence of other strong
DEO candidates is likely a piggybacker whose
initial high score should be discounted.
We now describe our heuristic method that is
based on this intuition. For clarity, we use scores
rather than probabilities in the following explana-
tion, though it is equally applicable to either. As
in EM/distillation, the method is initialized with
the baseline S(y) scores. One iteration of the
method proceeds as follows. Let the score of the
strongest DEO candidate in an NPI context p be:
</bodyText>
<equation confidence="0.9842035">
M(p) = max
yEp St h(y), (20)
</equation>
<bodyText confidence="0.998085538461538">
where Sth(y) is the score of candidate y at the tth
iteration according to this heuristic method.
Then, for each word-type y in each context p,
we compare the current score of y to the scores of
the other words in p. If y is currently the strongest
DEO candidate in p, then we give y credit equal
to the proportional change to M(p) if y were re-
moved (Context p without y is denoted p \ y). A
large change means that y is the only plausible
DEO candidate in p, while a small change means
that there are other plausible DEO candidates. If
y is not currently the strongest DEO candidate, it
receives no credit:
</bodyText>
<equation confidence="0.494477333333333">
� cred M(P��(P\y) if Sth(y) = M(p)
�&apos; y) 0 otherwise.
(21)
</equation>
<figure confidence="0.980656">
3 iterations
the
to
denied
than
that
if
has
denies
and
but
the
to
that
than
and
has
if
of
denied
denies
max
y
X). (19)
P(y|
700
unlikely to be a DEO according to the initializa-
tion.
NPI contexts
ABC,BC,BC,DC
Original scores
</figure>
<equation confidence="0.9375175">
S(A) = 5, S(B) = 4, S(C) = 1, S(D) = 2
Updated scores
Sh(A) = 5 x (5 − 4)/5 = 1
Sh(B) = 4 x (0 + 2 x (4 − 1)/4)/3 = 2
Sh(C) = 1 x (0 + 0 + 0) = 0
Sh(D) = 2 x (2 − 1)/2 = 1
</equation>
<figureCaption confidence="0.98077">
Figure 3: Example of one iteration of the certainty-
based heuristic on four NPI contexts with four words
in the lexicon.
</figureCaption>
<bodyText confidence="0.9886142">
Then, the average credit received by each y is
a measure of how much we should trust the cur-
rent score for y. The updated score for each DEO
candidate is the original score multiplied by this
average:
</bodyText>
<equation confidence="0.988246454545454">
�
St+1
h (y) = Sth(y) x
|Ny |pENy
The probability Pt+1(Y = y) is then simply
St+1
h (y) normalized:
Pt+1(Y = y) = St+1
h (1( y (23)
sh ( )
y′EG
</equation>
<bodyText confidence="0.999857111111111">
We iteratively reduce the scores in this fashion
to get better estimates of the relative suitability of
word-types as DEOs.
An example of this method and how it solves
the piggybacker problem is given in Figure 3. In
this example, we would like to learn that B and
D are DEOs, A is a piggybacker, and C is a fre-
quent word-type, such as a stop word. Using the
original scores, piggybacker A would appear to
be the most likely word to be a DEO. However,
by noticing that it never occurs on its own with
words that are unlikely to be DEOs (in the exam-
ple, word C), our heuristic penalizes A more than
B, and ranks B higher after one iteration. EM
prior re-estimation would not correctly solve this
example, as it would converge on a solution where
C receives all of the probability mass because it
appears in all of the contexts, even though it is
</bodyText>
<sectionHeader confidence="0.999412" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99999485">
We evaluate the performance of these methods on
the BLLIP corpus (-30M words) and the AFP
portion of the Gigaword corpus (-338M words).
Following DLD09, we define an NPI context to
be all the words to the left of an NPI, up to the
closest comma or semi-colon, and removed NPI
contexts which contain the most common DEOs
like not. We further removed all empty NPI con-
texts or those which only contain other punctua-
tion. After this filtering, there were 26696 NPI
contexts in BLLIP and 211041 NPI contexts in
AFP, using the same list of 26 NPIs defined by
DLD09.
We first define an automatic measure of per-
formance that is common in information retrieval.
We use average precision to quantify how well a
system separates DEOs from non-DEOs. Given a
list of known DEOs, G, and non-DEOs, the aver-
age precision of a ranked list of items, X, is de-
fined by the following equation:
</bodyText>
<equation confidence="0.997029666666667">
�n k=1 P(X1...k) x 1(xk E G)
AP(X) =
(24)
</equation>
<bodyText confidence="0.999979590909091">
where P(X1...k) is the precision of the first k
items and 1(xk E G) is an indicator function
which is 1 if x is in the gold standard list of DEOs
and 0 otherwise.
DLD09 simply evaluated the top 150 output
DEO candidates by their systems, and qualita-
tively judged the precision of the top-k candidates
at various values of k up to 150. Average preci-
sion can be seen as a generalization of this evalu-
ation procedure that is sensitive to the ranking of
DEOs and non-DEOs. For development purposes,
we use the list of 150 annotations by DLD09. Of
these, 90 were DEOs, 30 were not, and 30 were
classified as “other” (they were either difficult to
classify, or were other types of non-veridical oper-
ators like comparatives or conditionals). We dis-
carded the 30 “other” items and ignored all items
not in the remaining 120 items when evaluating a
ranked list of DEO candidates. We call this mea-
sure AP120.
In addition, we annotated DEO candidates from
the top-150 rankings produced by our certainty-
</bodyText>
<equation confidence="0.9822935">
cred(p, y). (22)
|G |,
</equation>
<page confidence="0.985679">
701
</page>
<bodyText confidence="0.9992961">
absolve, abstain, banish, bereft, boycott, cau-
tion, clear, coy, delay, denial, desist, devoid,
disavow, discount, dispel, disqualify, down-
play, exempt, exonerate, foil, forbid, forego,
impossible, inconceivable, irrespective, limit,
mitigate, nip, noone, omit, outweigh, pre-
condition, pre-empt, prerequisite, refute, re-
move5, repel, repulse, scarcely, scotch, scuttle,
seldom, sensitive, shy, sidestep, snuff, thwart,
waive, zero-tolerance
</bodyText>
<figureCaption confidence="0.9988695">
Figure 4: Lemmata of DEOs identified in this work not
found by DLD09.
</figureCaption>
<bodyText confidence="0.999838870967742">
based heuristic on BLLIP and also by the dis-
tillation and heuristic methods on AFP, in order
to better evaluate the final output of the meth-
ods. This produced an additional 68 DEOs (nar-
rowly defined) (Figure 4), 58 non-DEOs, and 31
“other” items4. Adding the DEOs and non-DEOs
we found to the 120 items from above, we have
an expanded list of 246 items to rank, and a corre-
sponding average precision which we call AP246.
We employ the frequency cut-offs used by
DLD09 for sparsity reasons. A word-type must
appear at least 10 times in an NPI context and
150 times in the corpus overall to be considered.
We treat BLLIP as a development corpus and use
AP120 on AFP to determine the number of itera-
tions to run our heuristic (5 iterations for BLLIP
and 13 iterations for AFP). We run EM/distillation
for one iteration in development and testing, be-
cause more iterations hurt performance, as ex-
plained in Section 3.
We first report the AP120 results of our ex-
periments on the BLLIP corpus (Table 1 sec-
ond column). Our method outperforms both
EM/distillation and the baseline method. These
results are replicated on the final test set from
AFP using the full set of annotations AP246 (Ta-
ble 1 third column). Note that the scores are lower
when using all the annotations because there are
more non-DEOs relative to DEOs in this list, mak-
ing the ranking task more challenging.
A better understanding of the algorithms can
</bodyText>
<footnote confidence="0.998007">
4The complete list will be made publicly available.
5We disagree with DLD09 that remove is not downward-
</footnote>
<figureCaption confidence="0.4469075">
entailing; e.g., The detergent removed stains from his cloth-
ing. =:&gt;. The detergent removed stains from his shirts.
</figureCaption>
<table confidence="0.8428805">
BLLIP AP120 AFP AP246
Baseline
Distillation
This work
</table>
<tableCaption confidence="0.988022">
Table 1: Average precision results on the BLLIP and
AFP corpora.
</tableCaption>
<bodyText confidence="0.999961818181818">
be obtained by examining the data likelihood and
the classification certainty at each iteration of the
algorithms (Figure 5). Whereas EM/distillation
maximizes the former expression, the certainty-
based heuristic method actually decreases data
likelihood for the first couple of iterations before
increasing it again. In terms of classification cer-
tainty, EM/distillation converges to a lower classi-
fication certainty score compared to our heuristic
method. Thus, our method better captures the as-
sumption of one DEO per NPI context.
</bodyText>
<sectionHeader confidence="0.9722615" genericHeader="method">
6 Bootstrapping to Co-Learn NPIs and
DEOs
</sectionHeader>
<bodyText confidence="0.9998895">
The above experiments show that the heuristic
method outperforms the EM/distillation method
given a list of NPIs. We would like to extend
this result to novel domains, corpora, and lan-
guages. DLD09 and DL10 proposed the follow-
ing bootstrapping algorithm for co-learning NPIs
and DEOs given a much smaller list of NPIs as a
seed set.
</bodyText>
<listItem confidence="0.998565333333333">
1. Begin with a small set of seed NPIs
2. Iterate:
(a) Use the current list of NPIs to learn a
list of DEOs
(b) Use the current list of DEOs to learn a
list of NPIs
</listItem>
<bodyText confidence="0.9996774">
Interestingly, DL10 report that while this
method works in Romanian data, it does not work
in the English BLLIP corpus. They speculate that
the reason might be due to the nature of the En-
glish DEO any, which can occur in all classes of
DE contexts according to an analysis by Haspel-
math (1997). Further, they find that in Romanian,
distillation does not perform better than the base-
line method during Step (2a). While this linguis-
tic explanation may certainly be a factor, we raise
</bodyText>
<figure confidence="0.99353825">
Method
.879
.946
.955
.734
.785
.809
702
Log probability
Log probability
Iterations
(a) Data log likelihood.
x 10
0
-0.5
-1
-1.5
-2
-2.5
0 1 2 3 4 5 6 7 8 9 10
Iterations
(b) Log classification certainty probabilities.
x 10
0
6
-0.5
-1
-1.5
-2
-2.5
0 1 2 3 4 5 6 7 8 9 10
5
</figure>
<figureCaption confidence="0.9836735">
Figure 5: Log likelihood and classification certainty probabilities of NPI contexts in two corpora. Thinner lines
near the top are for BLLIP; thicker lines for AFP. Blue dotted: baseline; red dashed: distillation; green solid:
our certainty-based heuristic method. P( X|y) probabilities are not included since they would only result in a
constant offset in the log domain.
</figureCaption>
<bodyText confidence="0.999787153846154">
a second possibility that the distillation algorithm
itself may be responsible for these results. As ev-
idence, we show that the heuristic algorithm is
able to work in English with just the single seed
NPI any, and in fact the bootstrapping approach in
conjunction with our heuristic even outperforms
the above approaches when using a static list of
NPIs.
In particular, we use the methods described in
the previous sections for Step (2a), and the follow-
ing ratio to rank NPI candidates in Step (2b), cor-
responding to the baseline method to detect DEOs
in reverse:
</bodyText>
<equation confidence="0.994837">
countD(x)/tokens(D)
T(x) = countC(x)/tokens(C) . (25)
</equation>
<bodyText confidence="0.999969315789474">
Here, countD(x) refers to the number of oc-
currences of NPI candidate x in DEO contexts
D, defined to be the words to the right of a DEO
operator up to a comma or semi-colon. We do
not use the EM/distillation or heuristic methods in
Step (2b). Learning NPIs from DEOs is a much
harder problem than learning DEOs from NPIs.
Because DEOs (and other non-veridical opera-
tors) license NPIs, the majority of occurrences of
NPIs will be in the context of a DEO, modulo am-
biguity of DEOs such as the free-choice any and
other spurious correlations such as piggybackers
as discussed earlier. In the other direction, it is
not the case that DEOs always or nearly always
appear in the context of an NPI. Rather, the most
common collocations of DEOs are the selectional
preferences of the DEO, such as common argu-
ments to verbal DEOs, prepositions that are part
of the subcategorization of the DEO, and words
that together with the surface form of the DEO
comprise an idiomatic expression or multi-word
expression. Further, NPIs are more likely to be
composed of multiple words, while many DEOs
are single words, possibly with PP subcategoriza-
tion requirements which can be filled in post hoc.
Because of these issues, we cannot trust the ini-
tialization to learn NPIs nearly as much as with
DEOs, and cannot use the distillation or certainty
methods for this step. Rather, the hope is that
learning a noisy list of “pseudo-NPIs”, which of-
ten occur in negative contexts but may not actu-
ally be NPIs, can still improve the performance of
DEO detection.
There are a number of parameters to the method
which we tuned to the BLLIP corpus using
AP120. At the end of Step (2a), we use the cur-
rent top 25 DEOs plus 5 per iteration as the DEO
list for the next step. To the initial seed NPI of
</bodyText>
<page confidence="0.995744">
703
</page>
<table confidence="0.9992855">
Method BLLIP AP120 AFP AP246
Baseline .889 (+.010) .739 (−.005)
Distillation .930 (−.016) .804 (+.019)
This work .962 (+.007) .821 (+.012)
</table>
<tableCaption confidence="0.8697105">
Table 2: Average precision results with bootstrapping
on the BLLIP and AFP corpora. Absolute gain in av-
erage precision compared to using a fixed list of NPIs
given in brackets.
</tableCaption>
<bodyText confidence="0.94693275">
anymore, anything, anytime, avail, bother,
bothered, budge, budged, countenance, faze,
fazed, inkling, iota, jibe, mince, nor, whatso-
ever, whit
</bodyText>
<figureCaption confidence="0.9983475">
Figure 6: Probable NPIs found by bootstrapping using
the certainty-based heuristic method.
</figureCaption>
<bodyText confidence="0.999962">
any, we add the top 5 ranking NPI candidates at
the end of Step (2b) in each subsequent iteration.
We ran the bootstrapping algorithm for 11 itera-
tions for all three algorithms. The final evaluation
was done on AFP using AP246.
The results show that bootstrapping can indeed
improve performance, even in English (Table 2).
Using bootstrapping to co-learn NPIs and DEOs
actually results in better performance than spec-
ifying a static list of NPIs. The certainty-based
heuristic in particular achieves gains with boot-
strapping in both corpora, in contrast to the base-
line and distillation methods. Another factor that
we found to be important is to add a sufficient
number of NPIs to the NPI list each iteration, as
adding too few NPIs results in only a small change
in the NPI contexts available for DEO detection.
DL10 only added one NPI per iteration, which
may explain why they did not find any improve-
ment with bootstrapping in English. It also ap-
pears that learning the pseudo-NPIs does not hurt
performance in detecting DEO, and further, that
a number of true NPIs are learned by our method
(Figure 6).
</bodyText>
<sectionHeader confidence="0.999584" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999991214285714">
We have proposed a novel unsupervised method
for discovering downward-entailing operators
from raw text based on their co-occurrence with
negative polarity items. Unlike the distilla-
tion method of DLD09, which we show to
be an instance of EM prior re-estimation, our
method directly addresses the issue of piggyback-
ers which spuriously correlate with NPIs but are
not downward-entailing. This is achieved by
maximizing the posterior classification certainty
of the corpus in a way that respects the initializa-
tion, rather than maximizing the data likelihood
as in EM/distillation. Our method outperforms
distillation and a baseline method on two corpora
as well as in a bootstrapping setting where NPIs
and DEOs are jointly learned. It achieves the best
performance in the bootstrapping setting, rather
than when using a fixed list of NPIs. The perfor-
mance of our algorithm suggests that it is suitable
for other corpora and languages.
Interesting future research directions include
detecting DEOs of more than one word as well as
distinguishing the particular word sense and sub-
categorization that is downward-entailing. An-
other problem that should be addressed is the
scope of the downward entailment, generalizing
work being done in detecting the scope of nega-
tion (Councill et al., 2010, for example).
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998404">
We would like to thank Cristian Danescu-
Niculescu-Mizil for his help with replicating his
results on the BLLIP corpus. This project was
supported by the Natural Sciences and Engineer-
ing Research Council of Canada.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993321">
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa T.
Dang, and Danilo Giampiccolo. 2010. The sixth
pascal recognizing textual entailment challenge. In
The Text Analysis Conference (TAC 2010).
Isaac G. Councill, Ryan McDonald, and Leonid Ve-
likovich. 2010. What’s great and what’s not:
Learning to classify the scope of negation for im-
proved sentiment analysis. In Proceedings of the
Workshop on Negation and Speculation in Natural
Language Processing, pages 51–59. Association for
Computational Linguistics.
Cristian Danescu-Niculescu-Mizil and Lillian Lee.
2010. Don’t ‘have a clue’?: Unsupervised co-
learning of downward-entailing operators. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 247–252. Association for Computational Lin-
guistics.
Cristian Danescu-Niculescu-Mizil, Lillian Lee, and
Richard Ducott. 2009. Without a ‘doubt’?: Un-
supervised discovery of downward-entailing oper-
</reference>
<page confidence="0.985342">
704
</page>
<reference confidence="0.999588894736842">
ators. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics.
William A. Gale, Kenneth W. Church, and David
Yarowsky. 1992. One sense per discourse. In Pro-
ceedings of the Workshop on Speech and Natural
Language, pages 233–237. Association for Compu-
tational Linguistics.
Anastasia Giannakidou. 2002. Licensing and sensitiv-
ity in polarity items: from downward entailment to
nonveridicality. CLS, 38:29–53.
Martin Haspelmath. 1997. Indefinite pronouns. Ox-
ford University Press.
Jack Hoeksema. 1997. Corpus study of negative po-
larity items. IV-V Jornades de corpus linguistics
1996–1997.
William A. Ladusaw. 1980. On the notion ‘affective’
in the analysis of negative-polarity items. Journal
ofLinguistic Research, 1(2):1–16.
Timm Lichte and Jan-Philipp Soehn. 2007. The re-
trieval and classification of negative polarity items
using statistical profiles. Roots: Linguistics in
Search ofIts Evidential Base, pages 249–266.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Proceedings of the
22nd International Conference on Computational
Linguistics.
Frank Richter, Fabienne Fritzinger, and Marion Weller.
2010. Who can see the forest for the trees? ex-
tracting multiword negative polarity items from
dependency-parsed text. Journal for Language
Technology and Computational Linguistics, 25:83–
110.
Ton van der Wouden. 1997. Negative Contexts: Col-
location, Polarity and Multiple Negation. Rout-
ledge.
</reference>
<page confidence="0.998545">
705
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921620">
<title confidence="0.9948045">Unsupervised Detection of Downward-Entailing Operators Maximizing Classification Certainty</title>
<author confidence="0.999096">Jackie CK Cheung</author>
<author confidence="0.999096">Gerald</author>
<affiliation confidence="0.999743">Department of Computer University of</affiliation>
<address confidence="0.968898">Toronto, ON, M5S 3G4,</address>
<abstract confidence="0.997977052631579">We propose an unsupervised, iterative method for detecting downward-entailing operators (DEOs), which are important for deducing entailment relations between sentences. Like the distillation algorithm of Danescu-Niculescu-Mizil et al. (2009), the initialization of our method depends on the correlation between DEOs and negative polarity items (NPIs). However, our method trusts the initialization more and aggressively separates likely DEOs from spurious distractors and other words, unlike distillation, which we show to be equivalent to one iteration of EM prior re-estimation. Our method is also amenable to a bootstrapping method that co-learns DEOs and NPIs, and achieves the best results in identifying DEOs in two corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa T Dang</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>The sixth pascal recognizing textual entailment challenge.</title>
<date>2010</date>
<booktitle>In The Text Analysis Conference (TAC</booktitle>
<contexts>
<context position="1442" citStr="Bentivogli et al., 2010" startWordPosition="211" endWordPosition="214">stimation. Our method is also amenable to a bootstrapping method that co-learns DEOs and NPIs, and achieves the best results in identifying DEOs in two corpora. 1 Introduction Reasoning about text has been a long-standing challenge in NLP, and there has been considerable debate both on what constitutes inference and what techniques should be used to support inference. One task involving inference that has recently received much attention is that of recognizing textual entailment (RTE), in which the goal is to determine whether a hypothesis sentence can be entailed from a piece of source text (Bentivogli et al., 2010, for example). An important consideration in RTE is whether a sentence or context produces an entailment relation for events that are a superset or subset of the original sentence (MacCartney and Manning, 2008). By default, contexts are upward-entailing, allowing reasoning from a set of events to a superset of events as seen in (1). In the scope of a downward-entailing operator (DEO), however, this entailment relation is reversed, such as in the scope of the classical DEO not (2). There are also operators which are neither upward- nor downward entailing, such as the expression exactly three (</context>
</contexts>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2010</marker>
<rawString>Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa T. Dang, and Danilo Giampiccolo. 2010. The sixth pascal recognizing textual entailment challenge. In The Text Analysis Conference (TAC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac G Councill</author>
<author>Ryan McDonald</author>
<author>Leonid Velikovich</author>
</authors>
<title>What’s great and what’s not: Learning to classify the scope of negation for improved sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>51--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Councill, McDonald, Velikovich, 2010</marker>
<rawString>Isaac G. Councill, Ryan McDonald, and Leonid Velikovich. 2010. What’s great and what’s not: Learning to classify the scope of negation for improved sentiment analysis. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 51–59. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Lillian Lee</author>
</authors>
<title>Don’t ‘have a clue’?: Unsupervised colearning of downward-entailing operators.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>247--252</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3010" citStr="Danescu-Niculescu-Mizil and Lee (2010)" startWordPosition="464" endWordPosition="467">ational methods for detecting DEOs from a corpus. They proposed two unsupervised algorithms which rely on the correlation between DEOs and negative polarity items (NPIs), which by the definition of Ladusaw (1980) must appear in the context of DEOs. An example of an NPI is yet, as in the sentence This project is not complete yet. The first baseline method proposed by DLD09 simply calculates a ratio of the relative frequencies of a word in NPI contexts versus in a general corpus, and the second is a distillation method which appears to refine the baseline ratios using a task-specific heuristic. Danescu-Niculescu-Mizil and Lee (2010) (henceforth DL10) extend this approach to Romanian, where a comprehensive list of NPIs is not available, by proposing a bootstrapping approach to co-learn DEOs and NPIs. DLD09 are to be commended for having identified a crucial component of inference that nevertheless lends itself to a classification-based ap696 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 696–705, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics proach, as we will show. However, as noted by DL10, the performance of the </context>
</contexts>
<marker>Danescu-Niculescu-Mizil, Lee, 2010</marker>
<rawString>Cristian Danescu-Niculescu-Mizil and Lillian Lee. 2010. Don’t ‘have a clue’?: Unsupervised colearning of downward-entailing operators. In Proceedings of the ACL 2010 Conference Short Papers, pages 247–252. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Lillian Lee</author>
<author>Richard Ducott</author>
</authors>
<title>Without a ‘doubt’?: Unsupervised discovery of downward-entailing operators.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2327" citStr="Danescu-Niculescu-Mizil et al. (2009)" startWordPosition="353" endWordPosition="356">ailing, allowing reasoning from a set of events to a superset of events as seen in (1). In the scope of a downward-entailing operator (DEO), however, this entailment relation is reversed, such as in the scope of the classical DEO not (2). There are also operators which are neither upward- nor downward entailing, such as the expression exactly three (3). (1) She sang in French. ⇒ She sang. (upward-entailing) (2) She did not sing in French. ⇐ She did not sing. (downward-entailing) (3) Exactly three students sang. ⇔� Exactly three students sang in French. (neither upward- nor downward-entailing) Danescu-Niculescu-Mizil et al. (2009) (henceforth DLD09) proposed the first computational methods for detecting DEOs from a corpus. They proposed two unsupervised algorithms which rely on the correlation between DEOs and negative polarity items (NPIs), which by the definition of Ladusaw (1980) must appear in the context of DEOs. An example of an NPI is yet, as in the sentence This project is not complete yet. The first baseline method proposed by DLD09 simply calculates a ratio of the relative frequencies of a word in NPI contexts versus in a general corpus, and the second is a distillation method which appears to refine the base</context>
</contexts>
<marker>Danescu-Niculescu-Mizil, Lee, Ducott, 2009</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Lillian Lee, and Richard Ducott. 2009. Without a ‘doubt’?: Unsupervised discovery of downward-entailing operators. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the Workshop on Speech and Natural Language,</booktitle>
<pages>233--237</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6764" citStr="Gale et al., 1992" startWordPosition="1072" endWordPosition="1075"> be insufficient from a linguistic perspective, it is nevertheless a useful starting point for computational methods for detecting NPIs and DEOs, and has inspired successful techniques to detect DEOs, like the work by DLD09, DL10, and also this work. In addition to this hypothesis, we further assume that there should only be one plausible DEO candidate per NPI context. While there are counterexamples, this assumption is in practice very robust, and is a useful constraint for our learning algorithm. An analogy can be drawn to the one sense per discourse assumption in word sense disambiguation (Gale et al., 1992). The related—and as we will argue, more difficult—problem of detecting NPIs has also been studied, and in fact predates the work on DEO detection. Hoeksema (1997) performed the first corpus-based study of NPIs, predominantly for Dutch, and there has also been work on detecting NPIs in German which assumes linguistic knowledge of licensing contexts for NPIs (Lichte and Soehn, 2007). Richter et al. (2010) make this assumption as well as use syntactic structure to extract NPIs that are multi-word expressions. Parse information is an especially important consideration in freer-word-order language</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. 1992. One sense per discourse. In Proceedings of the Workshop on Speech and Natural Language, pages 233–237. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anastasia Giannakidou</author>
</authors>
<title>Licensing and sensitivity in polarity items: from downward entailment to nonveridicality.</title>
<date>2002</date>
<journal>CLS,</journal>
<pages>38--29</pages>
<contexts>
<context position="5600" citStr="Giannakidou (2002)" startWordPosition="878" endWordPosition="879">njunction with our method. 2 Related work There is a large body of literature in linguistic theory on downward entailment and polarity items1, of which we will only mention the most relevant work here. The connection between downward-entailing contexts and negative polarity items was noticed by Ladusaw (1980), who stated the hypothesis that NPIs must be grammatically licensed by a DEO. However, DEOs are not the sole licensors of NPIs, as NPIs can also be found in the scope of questions, certain numeric expressions (i.e., non-monotone quantifiers), comparatives, and conditionals, among others. Giannakidou (2002) proposes that the property shared by these constructions and downward entailment is non-veridicality. If F is a propo1See van der Wouden (1997) for a comprehensive reference. sitional operator for proposition p, then an operator is non-veridical if Fp ⇒6 p. Positive operators such as past tense adverbials are veridical (4), whereas questions, negation and other DEOs are non-veridical (5, 6). (4) She sang yesterday. ⇒ She sang. (5) She denied singing. ⇒6 She sang. (6) Did she sing? ⇒6 She sang. While Ladusaw’s hypothesis is thus accepted to be insufficient from a linguistic perspective, it is </context>
</contexts>
<marker>Giannakidou, 2002</marker>
<rawString>Anastasia Giannakidou. 2002. Licensing and sensitivity in polarity items: from downward entailment to nonveridicality. CLS, 38:29–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
</authors>
<title>Indefinite pronouns.</title>
<date>1997</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="26353" citStr="Haspelmath (1997)" startWordPosition="4519" endWordPosition="4521">a, and languages. DLD09 and DL10 proposed the following bootstrapping algorithm for co-learning NPIs and DEOs given a much smaller list of NPIs as a seed set. 1. Begin with a small set of seed NPIs 2. Iterate: (a) Use the current list of NPIs to learn a list of DEOs (b) Use the current list of DEOs to learn a list of NPIs Interestingly, DL10 report that while this method works in Romanian data, it does not work in the English BLLIP corpus. They speculate that the reason might be due to the nature of the English DEO any, which can occur in all classes of DE contexts according to an analysis by Haspelmath (1997). Further, they find that in Romanian, distillation does not perform better than the baseline method during Step (2a). While this linguistic explanation may certainly be a factor, we raise Method .879 .946 .955 .734 .785 .809 702 Log probability Log probability Iterations (a) Data log likelihood. x 10 0 -0.5 -1 -1.5 -2 -2.5 0 1 2 3 4 5 6 7 8 9 10 Iterations (b) Log classification certainty probabilities. x 10 0 6 -0.5 -1 -1.5 -2 -2.5 0 1 2 3 4 5 6 7 8 9 10 5 Figure 5: Log likelihood and classification certainty probabilities of NPI contexts in two corpora. Thinner lines near the top are for BL</context>
</contexts>
<marker>Haspelmath, 1997</marker>
<rawString>Martin Haspelmath. 1997. Indefinite pronouns. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Hoeksema</author>
</authors>
<title>Corpus study of negative polarity items. IV-V Jornades de corpus linguistics 1996–1997.</title>
<date>1997</date>
<contexts>
<context position="6927" citStr="Hoeksema (1997)" startWordPosition="1100" endWordPosition="1101">cessful techniques to detect DEOs, like the work by DLD09, DL10, and also this work. In addition to this hypothesis, we further assume that there should only be one plausible DEO candidate per NPI context. While there are counterexamples, this assumption is in practice very robust, and is a useful constraint for our learning algorithm. An analogy can be drawn to the one sense per discourse assumption in word sense disambiguation (Gale et al., 1992). The related—and as we will argue, more difficult—problem of detecting NPIs has also been studied, and in fact predates the work on DEO detection. Hoeksema (1997) performed the first corpus-based study of NPIs, predominantly for Dutch, and there has also been work on detecting NPIs in German which assumes linguistic knowledge of licensing contexts for NPIs (Lichte and Soehn, 2007). Richter et al. (2010) make this assumption as well as use syntactic structure to extract NPIs that are multi-word expressions. Parse information is an especially important consideration in freer-word-order languages like German where a MWE may not appear as a contiguous string. In this paper, we explicitly do not assume detailed linguistic knowledge about licensing contexts </context>
</contexts>
<marker>Hoeksema, 1997</marker>
<rawString>Jack Hoeksema. 1997. Corpus study of negative polarity items. IV-V Jornades de corpus linguistics 1996–1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Ladusaw</author>
</authors>
<title>On the notion ‘affective’ in the analysis of negative-polarity items.</title>
<date>1980</date>
<journal>Journal ofLinguistic Research,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="2584" citStr="Ladusaw (1980)" startWordPosition="393" endWordPosition="394">r upward- nor downward entailing, such as the expression exactly three (3). (1) She sang in French. ⇒ She sang. (upward-entailing) (2) She did not sing in French. ⇐ She did not sing. (downward-entailing) (3) Exactly three students sang. ⇔� Exactly three students sang in French. (neither upward- nor downward-entailing) Danescu-Niculescu-Mizil et al. (2009) (henceforth DLD09) proposed the first computational methods for detecting DEOs from a corpus. They proposed two unsupervised algorithms which rely on the correlation between DEOs and negative polarity items (NPIs), which by the definition of Ladusaw (1980) must appear in the context of DEOs. An example of an NPI is yet, as in the sentence This project is not complete yet. The first baseline method proposed by DLD09 simply calculates a ratio of the relative frequencies of a word in NPI contexts versus in a general corpus, and the second is a distillation method which appears to refine the baseline ratios using a task-specific heuristic. Danescu-Niculescu-Mizil and Lee (2010) (henceforth DL10) extend this approach to Romanian, where a comprehensive list of NPIs is not available, by proposing a bootstrapping approach to co-learn DEOs and NPIs. DLD</context>
<context position="5292" citStr="Ladusaw (1980)" startWordPosition="829" endWordPosition="830">re respect to the initial weights, constructively building on top of what the model already knows. This method proves to perform better on two corpora than distillation, and is more amenable to the colearning of NPIs and DEOs. In fact, the best results are obtained by co-learning the NPIs and DEOs in conjunction with our method. 2 Related work There is a large body of literature in linguistic theory on downward entailment and polarity items1, of which we will only mention the most relevant work here. The connection between downward-entailing contexts and negative polarity items was noticed by Ladusaw (1980), who stated the hypothesis that NPIs must be grammatically licensed by a DEO. However, DEOs are not the sole licensors of NPIs, as NPIs can also be found in the scope of questions, certain numeric expressions (i.e., non-monotone quantifiers), comparatives, and conditionals, among others. Giannakidou (2002) proposes that the property shared by these constructions and downward entailment is non-veridicality. If F is a propo1See van der Wouden (1997) for a comprehensive reference. sitional operator for proposition p, then an operator is non-veridical if Fp ⇒6 p. Positive operators such as past t</context>
</contexts>
<marker>Ladusaw, 1980</marker>
<rawString>William A. Ladusaw. 1980. On the notion ‘affective’ in the analysis of negative-polarity items. Journal ofLinguistic Research, 1(2):1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timm Lichte</author>
<author>Jan-Philipp Soehn</author>
</authors>
<title>The retrieval and classification of negative polarity items using statistical profiles. Roots: Linguistics in Search ofIts Evidential Base,</title>
<date>2007</date>
<pages>249--266</pages>
<contexts>
<context position="7148" citStr="Lichte and Soehn, 2007" startWordPosition="1133" endWordPosition="1136">here are counterexamples, this assumption is in practice very robust, and is a useful constraint for our learning algorithm. An analogy can be drawn to the one sense per discourse assumption in word sense disambiguation (Gale et al., 1992). The related—and as we will argue, more difficult—problem of detecting NPIs has also been studied, and in fact predates the work on DEO detection. Hoeksema (1997) performed the first corpus-based study of NPIs, predominantly for Dutch, and there has also been work on detecting NPIs in German which assumes linguistic knowledge of licensing contexts for NPIs (Lichte and Soehn, 2007). Richter et al. (2010) make this assumption as well as use syntactic structure to extract NPIs that are multi-word expressions. Parse information is an especially important consideration in freer-word-order languages like German where a MWE may not appear as a contiguous string. In this paper, we explicitly do not assume detailed linguistic knowledge about licensing contexts for NPIs and do not assume that a parser is available, since neither of these are guaranteed when extending this technique to resourcepoor languages. 3 Distillation as EM Prior Re-estimation Let us first review the baseli</context>
</contexts>
<marker>Lichte, Soehn, 2007</marker>
<rawString>Timm Lichte and Jan-Philipp Soehn. 2007. The retrieval and classification of negative polarity items using statistical profiles. Roots: Linguistics in Search ofIts Evidential Base, pages 249–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Modeling semantic containment and exclusion in natural language inference.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1653" citStr="MacCartney and Manning, 2008" startWordPosition="245" endWordPosition="248"> a long-standing challenge in NLP, and there has been considerable debate both on what constitutes inference and what techniques should be used to support inference. One task involving inference that has recently received much attention is that of recognizing textual entailment (RTE), in which the goal is to determine whether a hypothesis sentence can be entailed from a piece of source text (Bentivogli et al., 2010, for example). An important consideration in RTE is whether a sentence or context produces an entailment relation for events that are a superset or subset of the original sentence (MacCartney and Manning, 2008). By default, contexts are upward-entailing, allowing reasoning from a set of events to a superset of events as seen in (1). In the scope of a downward-entailing operator (DEO), however, this entailment relation is reversed, such as in the scope of the classical DEO not (2). There are also operators which are neither upward- nor downward entailing, such as the expression exactly three (3). (1) She sang in French. ⇒ She sang. (upward-entailing) (2) She did not sing in French. ⇐ She did not sing. (downward-entailing) (3) Exactly three students sang. ⇔� Exactly three students sang in French. (nei</context>
</contexts>
<marker>MacCartney, Manning, 2008</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2008. Modeling semantic containment and exclusion in natural language inference. In Proceedings of the 22nd International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Richter</author>
<author>Fabienne Fritzinger</author>
<author>Marion Weller</author>
</authors>
<title>Who can see the forest for the trees? extracting multiword negative polarity items from dependency-parsed text.</title>
<date>2010</date>
<booktitle>Journal for Language Technology and Computational Linguistics,</booktitle>
<pages>25--83</pages>
<contexts>
<context position="7171" citStr="Richter et al. (2010)" startWordPosition="1137" endWordPosition="1140"> this assumption is in practice very robust, and is a useful constraint for our learning algorithm. An analogy can be drawn to the one sense per discourse assumption in word sense disambiguation (Gale et al., 1992). The related—and as we will argue, more difficult—problem of detecting NPIs has also been studied, and in fact predates the work on DEO detection. Hoeksema (1997) performed the first corpus-based study of NPIs, predominantly for Dutch, and there has also been work on detecting NPIs in German which assumes linguistic knowledge of licensing contexts for NPIs (Lichte and Soehn, 2007). Richter et al. (2010) make this assumption as well as use syntactic structure to extract NPIs that are multi-word expressions. Parse information is an especially important consideration in freer-word-order languages like German where a MWE may not appear as a contiguous string. In this paper, we explicitly do not assume detailed linguistic knowledge about licensing contexts for NPIs and do not assume that a parser is available, since neither of these are guaranteed when extending this technique to resourcepoor languages. 3 Distillation as EM Prior Re-estimation Let us first review the baseline and distillation met</context>
</contexts>
<marker>Richter, Fritzinger, Weller, 2010</marker>
<rawString>Frank Richter, Fabienne Fritzinger, and Marion Weller. 2010. Who can see the forest for the trees? extracting multiword negative polarity items from dependency-parsed text. Journal for Language Technology and Computational Linguistics, 25:83– 110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ton van der Wouden</author>
</authors>
<title>Negative Contexts: Collocation, Polarity and Multiple Negation.</title>
<date>1997</date>
<publisher>Routledge.</publisher>
<marker>van der Wouden, 1997</marker>
<rawString>Ton van der Wouden. 1997. Negative Contexts: Collocation, Polarity and Multiple Negation. Routledge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>