<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.4993295">
PROCESSING DICTIONARY DEFINITIONS WITH PHRASAL PATTERN
HIERARCHIES
</title>
<author confidence="0.707165">
Hiyan Alshawi
</author>
<affiliation confidence="0.812139">
University of Cambridge Computer Laboratory
Corn Exchange Street, Cambridge CB2 3QG, England*
</affiliation>
<bodyText confidence="0.998661846153846">
This paper shows how dictionary word sense definitions can be analysed by applying a hierarchy of
phrasal patterns. An experimental system embodying this mechanism has been implemented for
processing definitions from the Longman Dictionary of Contemporary English. A property of this
dictionary, exploited by the system, is that it uses a restricted vocabulary in its word sense definitions.
The structures generated by the experimental system are intended to be used for the classification of new
word senses in terms of the senses of words in the restricted vocabulary. Examples illustrating the output
generated are presented, and some qualitative performance results and problems that were encountered
are discussed. The analysis process applies successively more specific phrasal analysis rules as
determined by a hierarchy of patterns in which less specific patterns dominate more specific ones. This
ensures that reasonable incomplete analyses of the definitions are produced when more complete
analyses are not possible, resulting in a relatively robust analysis mechanism. Thus the work reported
addresses two robustness problems faced by current experimental natural language processing systems:
coping with an incomplete lexicon and with incomplete knowledge of phrasal constructions.
</bodyText>
<sectionHeader confidence="0.997656" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999970052631579">
A major factor contributing to the lack of robustness of
experimental natural language understanding systems is
the small number of words in the experimental semantic
dictionaries used by these systems. For example
&amp;quot;missing vocabulary&amp;quot; is cited as the most frequent
cause of errors for the FRUMP system (DeJong 1979),
a system designed to achieve a high degree of robust-
ness. The problem does not disappear when dealing
with limited discourse domains of the type encountered
in database query and expert system interfaces. This is
because of the large number of synonyms and special-
ized words that can occur, and because of the difficulty
of delimiting discourse domains exactly.
A different problem faced by designers of natural
language understanding systems is how to provide for
graceful failure of sentence analysis. There is thus the
need to produce reasonable incomplete interpretations
of sentences when complete analyses are not possible.
This situation can occur because of gaps in the gram-
</bodyText>
<footnote confidence="0.370888666666667">
*Author&apos;s present address: SRI International, Cambridge Computer
Science Research Centre, Millers Yard, Mill Lane, Cambridge CB2
1RQ, England.
</footnote>
<bodyText confidence="0.9999302">
matical knowledge of the system or because the system
is faced with extragrammatical input. This paper shows
how a possible solution to this partial analysis problem
can be applied to the vocabulary problem in the context
of large machine readable dictionaries.
More specifically, we will see how word sense defi-
nitions from the Longman Dictionary of Contemporary
English (Procter, 1978 — henceforth LDOCE) are proc-
essed by a phrasal analyser that applies successively
more specific phrasal analysis rules. The aim of this
analysis is to provide sufficient semantic information to
enable a system carrying out a language processing
application to cope with occurrences of unknown
words.
Both the problem of coping with new words and the
problem of robust phrasal analysis can be thought of as
instances of a more general natural language interpreta-
tion problem. This is the problem of coping with incom-
plete knowledge of language use; lexical knowledge in
the first case and knowledge of phrasal structure in the
second. The unavoidable incompleteness of the knowl-
edge of language use available to a language processing
system means that trying to achieve robust natural
language processing involves developing effective
mechanisms for dealing with this problem. The research
</bodyText>
<footnote confidence="0.84763725">
Copyright 1987 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided
that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To
copy otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/ 87 /030195-202$03.00
</footnote>
<note confidence="0.6238425">
Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 195
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
</note>
<bodyText confidence="0.999616769230769">
reported in this paper is intended to be a contribution to
this development effort.
The next two sections will discuss the kind of output
that may be produced from processing dictionary defi-
nitions and give examples of the results of processing
LDOCE definitions produced by an implemented defi-
nition analyser. Some problems that were encountered
are then discussed. Later sections motivate and explain
the basic analysis algorithm, and then describe and
illustrate details of analysis and structure building rules.
Finally some remarks are made about the performance
of the current implementation and necessary further
research.
</bodyText>
<sectionHeader confidence="0.991758" genericHeader="method">
DEFINITION ANALYSIS
</sectionHeader>
<bodyText confidence="0.999601821782178">
There are various possibilities for the kind of structures
useful for language understanding that may be derived
from dictionary definitions. These include meaning pos-
tulates (Carnap, 1952) expressed in some logic; con-
straints or &apos;semantic formulae&apos; based on semantic prim-
itives (Katz and Fodor, 1963, Wilks, 1975); and
structures carrying information enabling the classifica-
tion of the new word sense with respect to an existing
classification of entities in a discourse domain. The
structures produced by the implemented definition
analyser belong to this last type, and examples of these
structures are given later.
The dictionary being used in this work, LDOCE, has
features that make it particularly suitable for definition
analysis. Thus many LDOCE word sense entries con-
tain additional semantic information that could be com-
bined, or used in conjunction with, the structures pro-
duced from processing word sense definition texts. This
information is available as &apos;box codes&apos; that give selec-
tional restrictions, and &apos;subject codes&apos; that indicate
typical discourse domain usage of word senses (these
codes occur in the machine-readable version of the
dictionary, but not in the printed form). The suitability
of LDOCE for work in computational linguistics has
been analysed in detail by Michiels (1982). For the
purpose of the work reported here, the most important
property of LDOCE is the use of a restricted definition
vocabulary of around 2000 words. Further, an impor-
tant restriction imposed on LDOCE lexicographers is
that only the &apos;central&apos; senses of these words should
occur in definition texts. Some ways in which the
definitions diverge from a strict interpretation of this
rule are discussed later. It should be remarked here that
the LDOCE restricted definition vocabulary has more in
common with a &apos;basic English&apos; vocabulary than a set of
semantic primitives. (A list of the words in the restricted
definition vocabulary is given in an appendix to the
published version (Procter, 1978) of the dictionary.)
If the output of processing LDOCE definitions was in
the form of meaning postulates, then the logic expres-
sions produced would have a new symbol for the word
sense being defined along with symbols corresponding
to the senses of words in the definition vocabulary.
Similarly, producing semantic primitive formulae would
involve building new formulae by putting together for-
mulae corresponding to the word senses of the defini-
tion vocabulary.
For the third possible form of output listed earlier,
we need a (hand-coded) classification of the central
senses of the definition vocabulary together with a
classification of concepts in the particular domain of
discourse in terms of these word senses. The descrip-
tions of implementations by Bobrow and Webber
(1980), Mark (1981), and Alshawi (1987), show how
such a classification can be organized and used during
text processing. The LDOCE definition for a new word
sense is processed using the mechanism described in
this paper in order to extract sufficient information for
including the new word sense in such a classification. A
natural language processing application that depended
on a classification of concepts in the discourse domain
should then be able to carry out its application task
despite the occurrence of a new word in an input
sentence.
Extracting the information necessary for classifica-
tion will of course include locating superordinates in the
definitions (which define the so called &amp;quot;ISA&amp;quot; relation)
as is done in the work reported by Amsler (1981) and
Calzolari (1984). However, this previous work suggests
that achieving further semantic precision in a classifica-
tion process requires making use of other information
present in the definition (such as modifiers and predica-
tions). Examples of extracting this sort of information
are presented in the next section.
This way of dealing with unknown words in language
processing applications still requires good solutions to
the problem of choosing between alternative possible
word senses (Walker and Amsler (1986) have used the
LDOCE subject codes for this purpose) and to the
problems involved in the classification process (see
Schmolze and Lipkis, 1983). Nonetheless, providing a
mechanism, as described in this paper, for extracting
the information required by the classification process is
a necessary first step for this approach to handling
unknown words.
Dictionaries vary in the level of detail provided by
their semantic definitions, and, in general, producing a
meaning postulate for understanding a sentence, or
incorporating a word sense into a discourse domain
classification, can often be done without making use of
all the detail provided by the dictionary definition. Even
only being able to locate the &apos;semantic head&apos; (i.e. the
main superordinate term) of a definition can be useful to
a language processing application. This is fortunate
since providing complete analyses of arbitrary dictio-
nary definitions is beyond the current state of the art in
computational linguistics. It is therefore reasonable to
derive and make use of partial analyses of dictionary
definitions when complete analyses are not possible.
This is the approach taken in the implemented analysis
system. (For certain text processing systems, for exam-
</bodyText>
<page confidence="0.973924">
196 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987
</page>
<bodyText confidence="0.801219">
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
pie precision information retrieval systems, such an
approach may not be acceptable.)
</bodyText>
<sectionHeader confidence="0.777816" genericHeader="method">
ANALYSIS EXAMPLES
</sectionHeader>
<bodyText confidence="0.99474715">
I will refer to the information derived for classifying
word senses simply as &apos;semantic structures&apos;; this rather
vague term being chosen because these structures are
not viewed as having formal semantic status, but only as
data structures containing information relevant to the
classification process (or perhaps some other semantic
process). Roughly speaking, these structures have some
properties of a linguistic analysis of definition texts and
some properties of a semantic definition of word sense
concepts; their gross syntactic form is that of nested
feature lists.
The semantic structures are derived from various
types of modifiers and relative clauses present in word
sense definitions as well as the semantic head of the
definition, if this is substantive. The syntactic category
under which senses are grouped in the dictionary is
important, in particular, for locating the semantic head
of a definition and, more generally, for determining
which analysis rules are applicable to the definition. The
details of the analysis process are explained in a later
section. Illustrative examples of the structures pro-
duced from analysing the main categories of definitions
currently handled by the implemented system — noun,
verb, adjective and adverb definitions — are now given.
Oddities in the semantic structures are often due to
peculiarities of the current analysis grammar and output
format, and I would not wish to argue for their correct-
ness, especially in view of the problems discussed later.
The following are examples of noun sense definitions
together with the semantic structures derived from
them. The words under which these examples occur in
the dictionary are shown underlined. (The analysis
system retrieves definitions from a lispified&apos; version of
the LDOCE type-setting tape, for example items pre-
ceded by an asterisk are Lisp atoms corresponding to
font control characters present on the type-setting tape
(see Alshawi, Boguraev, and Briscoe, 1985).)
(launch)
(a large usu. motor-driven boat used for carrying
people on rivers, lakes, harbours, etc.)
</bodyText>
<equation confidence="0.3732088">
((CLASS BOAT) (PROPERTIES (LARGE))
(PURPOSE
(PREDICATION (CLASS CARRY) (OBJECT
PEOPLE))))
(mug)
</equation>
<bodyText confidence="0.907828">
(*46 BrE infml *44 a foolish person who is easily
deceived *44 *63 see also *CA MUG&apos;S GAME)
</bodyText>
<sectionHeader confidence="0.724242" genericHeader="method">
((CLASS PERSON) (PROPERTIES (FOOLISH))
(PREDICATION (OBJECT-OF ((CLASS
DECEIVE)))))
</sectionHeader>
<bodyText confidence="0.925081192307692">
(hornbeam
(a type of small tree with hard wood, sometimes used
in *CA HEDGE *CB *46 s)
((CLASS TREE) (COLLECTIVE TYPE) (PROPER-
TIES (SMALL))
(HAS-PART ((CLASS WOOD) (PROPERTIES
(HARD)))))
The semantic heads of these definitions are boat, per-
son, and tree respectively, this being different in the last
case from the syntactic head (&amp;quot;type&amp;quot;) of the definition.
The other information in these structures is derived
from adjectives, prepositional phrases, and relative
clauses. Not all the information present in the defini-
tions is captured, for example the information conveyed
by the phrase sometimes used in HEDGEs, in which
HEDGE is capitalised because it is not part of the
restricted definition vocabulary (but is defined in terms
of this vocabulary elsewhere).
Verb sense definitions are, in general, infinitive verb
phrases with adverbials (often prepositional phrases)
and additional restrictions on the semantic class of
agents and objects. These are some examples of deriv-
ing structures from verb sense definitions.
(launch)
(to send (a modern weapon or instrument) into the sky
or space by means of scientific explosive apparatus)
</bodyText>
<figure confidence="0.789223666666667">
((CLASS SEND)
(OBJECT
((CLASS INSTRUMENT) (OTHER-CLASSES
(WEAPON))
(PROPERTIES (MODERN))))
(ADVERBIAL ((CASE INTO) (FILLER (CLASS
SKY))))
(mug)
(to rob with violence, as in a dark street)
((CLASS ROB)
(ADVERBIAL ((CASE WITH) (FILLER (CLASS
VIOLENCE)))))
(club)
(to beat or strike with a heavy stick (*CA CLUB *CB))
((CLASS STRIKE) (OTHER-CLASSES ((BEAT)))
</figure>
<sectionHeader confidence="0.61094425" genericHeader="method">
(ADVERBIAL
((CASE WITH)
(FILLER (CLASS STICK) (PROPERTIES
(HEAVY))))))
</sectionHeader>
<bodyText confidence="0.917128222222222">
Similarly, adjective sense definitions tend to have ad-
jectival or verbal predicates as their heads, and they
often include restrictions on the class of objects to
which the property corresponding to the adjective can
Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 197
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
apply. The adverbial phrases used to define adverbs are
often prepositional phrases. Examples of adjective and
adverb definitions are the following.
</bodyText>
<figure confidence="0.7565605625">
(bushy)
((of hair) growing thickly: *46 a bushy beard / tail)
(CLASS PROPERTY)
(PREDICATION (CLASS GROW) (MANNER
THICKLY))
(RESTRICTED-TO ((CLASS HAIR))))
(undomesticated)
((of an animal) not serving man; not *CA TAME)
((CLASS PROPERTY)
(PREDICATION (NOT (CLASS SERVE)
(OBJECT MAN)))
(RESTRICTED-TO ((CLASS ANIMAL))))
(overland)
(across or by land and not by sea or air)
((MANNER ((CASE ACROSS) (FILLER ((CLASS
LAND))))))
</figure>
<bodyText confidence="0.971002714285714">
LDOCE definitions for lexicalized compound noun and
phrasal verbs are handled in exactly the same way as
noun and verb definitions. Two examples of structures
generated for such definitions are given below.
(roller coaster)
(a kind of small railway with sharp slopes and curves,
popular in amusement parks)
</bodyText>
<figure confidence="0.689354846153846">
((CLASS RAILWAY) (COLLECTIVE KIND)
(PROPERTIES (SMALL)))
(bring out)
(*46 becoming rare *44 to introduce (usu. a young
lady) into the social life of a great city *63 see also
*CA COME OUT *CB (7))
((CLASS INTRODUCE)
(OBJECT ((CLASS LADY) (PROPERTIES
(YOUNG))))
(ADVERBIAL
((CASE INTO)
(FILLER (CLASS LIFE) (PROPERTIES
(SOCIAL))))))
</figure>
<sectionHeader confidence="0.671502" genericHeader="method">
SOME PROBLEMS
</sectionHeader>
<bodyText confidence="0.977434930232558">
The current implementation is able to locate the correct
semantic heads of dictionary definitions in most cases,
although the examples above are untypical in the
amount of additional information they recover from the
definitions. Some quantitative remarks about the per-
formance of the system are given later. This section
briefly discusses a number of problems that were en-
countered while testing the implemented system.
In some respects the information conveyed by the
output structures, being too closely tied to the surface
definitions, only provides constraints for further seman-
tic analysis. Perhaps the most important case of this is
that the relationships implicit in compound nouns and
certain prepositional phrase adverbials cannot, in gen-
eral, be made more explicit without further interpreta-
tion apparatus (see e.g. Alshawi, 1987) beyond that
available to the definition analyser. The phrasal context
can, however, sometimes allow further specification of
relationships implicit in prepositions, for instance deri-
vation of PURPOSE from for in cases exemplified by
the noun sense of launch (although, of course, errors
can result from attempting to make relationships more
explicit in this way). The actual words appearing in the
semantic structures are, on the other hand, further
disambiguated than might be assumed given the high
degree of polysemy of many of the words in the re-
stricted vocabulary. This is because the analysis proc-
ess identifies the syntactic category of these words and
because of the LDOCE rule that only the most central
senses of words from the restricted vocabulary should
appear in definitions (but see the remarks below on
phrasal verbs).
The fact that definition texts are often not analysed
completely means that information that is central to a
definition is sometimes not taken into account, as
illustrated by the following example. In this case the
usual &apos;purpose&apos; of nails is not recovered.
(nail)
(a thin piece of metal with a point at one end and a flat
head at the other for hammering into a piece of wood,
usu. to fasten the wood to something else)
((CLASS PIECE) (MATERIAL METAL) (PROPER-
TIES (THIN))
</bodyText>
<sectionHeader confidence="0.751755" genericHeader="method">
(HAS-PART ((CLASS POINT))))
</sectionHeader>
<bodyText confidence="0.974880666666667">
Although the base forms of all the words in the
restricted vocabulary and simple morphological vari-
ants of these are handled by the analysis process, there
are many cases of derivational morphology which are
not currently handled. Difficulties are also caused by the
liberal use in LDOCE definitions of phrasal verbs made
up from verbs and particles taken from the restricted
vocabulary. The idiomatic nature of phrasal verbs
means that the rule of using only the central senses of
words in the definition vocabulary is violated in many
cases in which phrasal verbs are used to implicitly
increase the size of the defining vocabulary. An exam-
ple is the occurrence of look after and bring up causing
an error in the analysis of the following sense definition
for foster:
(foster)
(to look after or bring up (a child or young animal) as
one&apos;s own . . .)
</bodyText>
<page confidence="0.937996">
198 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987
</page>
<note confidence="0.5745245">
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
((CLASS LOOK)).
</note>
<bodyText confidence="0.98519565625">
Another problem encountered in LDOCE entries is
that word senses are sometimes defined in terms of
previous senses of the same homograph. For example
immediately after the definition of the sense of horn-
beam given earlier, the following dependent word sense
definition is present, for which the system produces a
structure containing the special symbol &amp;quot;&apos;previous-
sense*&apos;.
(the wood of this tree)
((CLASS WOOD) (RELATED-TO
*PREVIOUS-SENSE*))
A problem related to the one just mentioned is that only
the simplest forms of cross references to words not
included in the definition vocabulary are handled at
present. However, given the compositional nature of
nested feature lists, and the fact that definitional cross
references are intended to be non-circular in LDOCE, it
should be feasible to use semantic structures for the
referenced words (and previous senses as in the horn-
beam example) in building other semantic structures.
The use of a restricted vocabulary in LDOCE defi-
nitions means that the lexicographers have already
engaged in a substantial amount of semantic analysis of
word senses that is potentially useful for automatic
natural language processing. However, as observed by
Michiels (1982), there is a tradeoff between the size of
the definition vocabulary and the syntactic complexity
of definitions. This implies that in order to take full
advantage of the potential of LDOCE entries for lan-
guage processing we need to pay special attention to the
design of the definition analyser; this is the issue ad-
dressed in the rest of this paper.
</bodyText>
<sectionHeader confidence="0.90565" genericHeader="method">
PHRASAL ANALYSIS HIERARCHIES
</sectionHeader>
<bodyText confidence="0.999926508196722">
The analysis mechanism has the flavour of a pattern-
based phrasal analyser. It was designed to overcome
some of the more obvious difficulties of applying a
simple pattern matching approach to robust phrasal
analysis. In particular it was required that the mecha-
nism should have the means to specify which compo-
nents of a phrase are more important, and to index
analysis rules so that the mechanism would be reason-
ably efficient.
Pattern matching has played an important role in
several previous parsing systems, for example those of
Wilks (1975), Parkinson et al (1977), Wilensky and
Arens (1980), and Hayes and Mouradian (1981). A
characteristic of the mechanism used here is that it
depends on a hierarchy of phrasal analysis patterns in
which more specific patterns are dominated by less
specific ones.
The basic analysis algorithm that applies the hierar-
chy of patterns is as follows. Starting at the top of the
hierarchy, a pattern is matched against the input defini-
tion, If the match with this pattern succeeds then a
match is attempted with each of its daughter patterns
(i.e. the more specific forms of this pattern placed
immediately below it in the hierarchy). This procedure
is repeated recursively so that we end up with the most
specific matches against the input definition. This pars-
ing technique is different in kind from the more common
approach to robust parsing in which exact grammar
rules are tried first before being relaxed by the parser
(see e.g. Weischedel and Black, 1980, Kwasny and
Sondheimer, 1981, and Pulman, 1984).
The hierarchy provides a natural solution to the
indexing problem mentioned above since it restricts the
application of patterns to those that are more likely to
succeed, enabling efficient phrasal analysis. It also
provides a solution to the problem of specifying the
more important components of phrases since less spe-
cific patterns tend to be concerned with more important
components only. This ensures that reasonable incom-
plete analyses can be produced when more detailed
analyses are not possible.
Each analysis rule consists of a rule identifier, a
phrasal pattern, and a list of rule identifiers for daughter
patterns. It is written in the following form:
(rule identifier phrasal pattern daughter identifiers).
The rule identifier also appears in a semantic struc-
ture building rule. These two types of rule are kept
separate in order to allow different kinds of output
structures to be generated for the same analysis gram-
mar. Building semantic structures is basically a simple
process of fleshing out templates provided by the se-
mantic structure building rules using variable bindings
generated by the matching algorithm.
The following section gives some examples of anal-
ysis and structure building rules, explaining the notation
in which the phrasal patterns are written. The notation
currently provides a limited number of facilities, but it
should be clear that these facilities could be extended in
various ways while remaining within the the overall
framework of applying a hierarchy of phrasal patterns
as discussed above.
</bodyText>
<sectionHeader confidence="0.614468" genericHeader="method">
ANALYSIS RULES
</sectionHeader>
<bodyText confidence="0.998918428571429">
A typical analysis rule, n-100, for noun definitions, and
two of its descendants, n-110 and n-135, are shown
below. n-110 is a daughter of n-100, and n-135 is a
daughter of n-130 (not shown). More mnemonic identi-
fiers for these rules might be &amp;quot;Noun-phrase&amp;quot;, &amp;quot;Simple-
NP&amp;quot;, and &amp;quot;NP-with-relative&amp;quot; instead of n-100, n-110,
and n-135 respectively.
</bodyText>
<footnote confidence="0.9814448">
(n-100 (n &amp;&amp; +Odet &amp;&amp; &amp;Oadj &amp;noun &amp;&amp;) n-110 n-120
n-130 n-140)
(n-110 (n +Odet +Ointens &amp;Oadj &amp;noun *Opp-mod &amp;&amp;))
(n-135 (n +Odet &amp;Oadj &amp;Onoun +nounl +that-which
*verb-pred &amp;&amp;))
</footnote>
<note confidence="0.3344635">
Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 199
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
</note>
<bodyText confidence="0.999419865384615">
In the phrasal pattern part of these rules, the initial
&amp;quot;n&amp;quot; restricts the pattern to matching definitions for
senses with lexical category &amp;quot;n&amp;quot;, i.e. nouns. The other
pattern elements match zero or more items in the input
depending on the type of the element (indicated by its
first one or two characters) and restrictions in terms of
lexical features. Digits at the end of pattern elements
simply distinguish different occurrences of elements
with the same properties. Examples of pattern elements
and what they can match are the following.
for the word for
+noun exactly one noun
+Odet zero or one determiner
&amp;noun one or more nouns
&amp;Oadj zero or more adjectives
&amp;&amp; an arbitrary segment of input words
*Opp mod zero or one prepositional phrase
modifier
*verb-pred a segment that matches a verb
phrase pattern
The last element is an example of an element with
subsidiary patterns (in this case for verb phrases) which
use the same kinds of element as above. There are thus
associated with this element a list of rules including
`(passive-pred (be +vtrans))&apos;. Here &apos;passive-pred&apos; is
just the name of the subsidiary pattern `(be +vtrans)&apos;.
Similarly, one subsidiary pattern of `*Opp-mod&apos; is &apos;(for-
pp (+Oused for +noun-verb)&apos;. The use of elements with
such subsidiary patterns allows for recursion and a
more compact set of patterns, in much the same way as
for conventional context free phrase structure gram-
mars.
Given this interpretation of pattern elements, it
should be clear that the phrasal patterns of rules n-110
and n-135 will match subsets of the set of definitions
matched by the phrasal pattern of rule n-100. The noun
sense definition examples given earlier for launch and
mug matched n-110 and n-135 respectively. (There is an
initial morphological analysis phase which discards
items like usu. which it does not recognize.) The
analysis algorithm outlined in the previous section en-
sures that n-110 and n-135 are tried only if n-100
succeeds.
The structure building rule associated with an analy-
sis rule is applied when none of the immediate descen-
dants of the analysis rule succeed. Thus the structure
building rule for n-100 is applied when none of n-110,
n-120, n-130, or n-140 succeed, ensuring that a semantic
structure is built according to the analysis provided by
n-100 if no more specific version of this analysis is
possible. The structure building rules for n-100 and
n-135 are given below.
</bodyText>
<equation confidence="0.697559666666667">
(n-100 ((compound-class &amp;noun) (properties &amp;Oadj)))
(n-135 ((class + noun 1) (noun-mods &amp;Onoun)
(properties &amp;Oadj) (predication *verb-pred)))
</equation>
<bodyText confidence="0.99975444117647">
The semantic structure given earlier for the definition a
foolish person who is easily deceived . . . (a British
English sense of mug) was generated using the rule just
given above. Applying the rule involves replacing the
variables with bindings generated by the matching proc-
ess; splicing-out substructures associated with unin-
stantiated optional pattern elements; and recursively
applying this process to the structure building rule
associated with the appropriate (i.e. successfully match-
ing) subsidiary pattern for the element `*verb-pred&apos;.
This last step results in building the substructure
&amp;quot;(predication (object-of ((class deceive)))&amp;quot; using a rule
associated with the subsidiary pattern &apos;passive-pred&apos;
that was mentioned earlier. There is also an optional
further stage of the structure building process which
applies transformations specified as attached proce-
dures associated with items in the structure building
rules, for example the item &apos;predication&apos;. This phase
gives greater freedom than would be possible by the use
of structure building templates alone, for example it
allows moving items (such as those indicating negation)
&apos;upwards&apos; out of substructures.
The analysis algorithm follows all paths from suc-
cessful matches. This does not lead to inefficiency
because it is rare for several deep, but disjoint, paths to
be followed successfully down the pattern hierarchy,
and because the implementation maintains a well-
formed substring table to avoid a certain amount of
redundant computation. Alternative semantic struc-
tures can result from processing a definition when there
is more than one most specific successful analysis rule.
At present one such analysis is chosen by an over
simplistic heuristic that basically prefers analyses ac-
counting for more words of the input definition.
</bodyText>
<sectionHeader confidence="0.670032" genericHeader="evaluation">
PERFORMANCE REMARKS
</sectionHeader>
<bodyText confidence="0.999842105263158">
Although some of the difficulties mentioned in the
section on problems are not easy to accommodate in the
present system, most of the errors in identifying seman-
tic heads of definitions were not due to these. Instead
these errors appear to be caused mainly by failure on
the part of the rudimentary morphological analysis
performed, and the inadequate coverage of the present
set of phrasal patterns.
In order to evaluate the performance of the system, it
was tested against a sample of 500 definitions chosen at
random using a facility for automatic random selection
of entries provided by the dictionary access system.
Only a few of these definitions will have coincided with
those processed during the development of the system
and its analysis rules. The selection process ignored
definitions for idioms and those with complex cross
references, so these are not taken into account in the
figures given below.
The results of the test were as follows. The semantic
</bodyText>
<page confidence="0.861089">
200 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987
</page>
<note confidence="0.471784">
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
</note>
<bodyText confidence="0.999931777777778">
head was identified correctly for 387 definitions (77%).
Additional information was recovered for 236 (61%) of
these definitions, and this additional information was
judged to be correct for 207 (88%) of these cases.
Thus only identifying the head is much more typical
than might be suggested by the examples given earlier
for illustrative purposes, and in fact the present set of
rules rarely takes into account all the words appearing
in a definition. There are altogether some 90 phrasal
patterns in the hierarchy, including subsidiary patterns.
It should be emphasized that this grammar of definitions
was written as a feasibility test, and I believe it is
reasonable to expect that the number of patterns in the
hierarchy could be enlarged to 400, say, before the
problem of diminishing returns becomes a serious one.
The current implementation of the definition analyser
takes around half a second to access the dictionary and
process a definition. This is the elapsed time on a lightly
loaded GEC-63 (a 32 bit mini-computer); the definition
analyser was implemented in Cambridge Lisp and low
level dictionary access in the language C. Finally,
perhaps it is worth mentioning that the development
effort was only a few man months for each of the
program and grammar, which, compared with other
natural language processing systems we have developed
recently at Cambridge, represents a relatively small
effort.
</bodyText>
<sectionHeader confidence="0.851164" genericHeader="conclusions">
FURTHER RESEARCH
</sectionHeader>
<bodyText confidence="0.999979444444444">
The work carried out so far seems to suggest that
dictionary definitions can be analysed with a reasonable
degree of success using hierarchies of phrasal patterns,
but it still remains to be demonstrated that this tech-
nique can enable an actual natural language application
system to cope effectively with unknown words.
Although dictionary definitions exhibit a rich variety
of forms, these are mostly variations on a manageably
small number of basic forms, and it is this property of
definitions that makes phrasal pattern hierarchies par-
ticularly appropriate for analysing them. It seems likely
however that the analysis technique developed here
would be useful for the same reason in other language
processing applications, for example specialized inter-
active applications.
One direction in which it is hoped to extend the work
reported in this paper is in enhancing the capabilities of
natural language processing systems for coping with
idioms. Intuitively, some sort of pattern matching
seems to be appropriate for analysing idioms (see e.g.
Wilensky and Arens, 1980). In the context of a parsing
system using an analysis hierarchy the patterns for
idioms would be placed as most specialized patterns
(i.e. leaves). LDOCE entries contain a wealth of infor-
mation on idiomatic uses of words, and the meanings of
idioms are expressed using the restricted definition
vocabulary. It is hoped to extend the definition analysis
system so that it would attempt to generate appropriate
phrasal patterns when it encountered a definition for an
idiomatic use of a word. It may then be possible to use
the generated pattern and the definition of the idiom to
produce a paraphrase of an input sentence before fur-
ther processing takes place. In any case, a comprehen-
sive treatment of dictionary entry analysis for language
understanding systems clearly needs to take account of
idiomatic word usage.
</bodyText>
<sectionHeader confidence="0.994017" genericHeader="acknowledgments">
ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.999839666666667">
I am very grateful to the Longman Group for making
this work possible by granting me access to the LDOCE
tape for research purposes. I would also like to thank
Bran Boguraev, Ted Briscoe, and two anonymous Com-
putational Linguistics referees for many helpful com-
ments that improved earlier drafts of this paper.
</bodyText>
<sectionHeader confidence="0.995885" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999485">
Alshawi, H. 1987 Memory and Context Mechanisms for Language
Interpretation. Cambridge University Press, Cambridge, England.
Alshawi, H.; Boguraev, B.; and Briscoe, E. 1985 Towards a Dictio-
nary Support Environment for Real Time Parsing. In Proceedings
of the Second Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, Geneva: 171-178.
Amsler, R. 1981 A Taxonomy for English Nouns and Verbs. In
Proceedings of the 19th Annual Meeting of the Association for
Computational Linguistics, Stanford, California: 133-138.
Bobrow, R.J.; and Webber, B.L. 1980 Knowledge Representation for
Syntactic/Semantic Processing. In Proceedings of the First AAAI
Conference, Stanford, California: 316-323.
Calzolari, N. 1984 Detecting Patterns in A Lexical Database. In
Proceedings of the 10th International Conference on Computa-
tional Linguistics, Stanford, California: 170-173.
Carnap, R. 1952 Meaning Postulates. Philosophical Studies 3: 65-73.
DeJong, G. 1979 Prediction and Substantiation: A New Approach to
Natural Language Processing. Cognitive Science 3: 251-273.
Hayes, P.J.; and Mouradian, G.V. 1981 Flexible Parsing. American
Journal of Computational Linguistics 7(4): 232-242.
Katz, J.J.; and Fodor J.A. 1963 The Structure of a Semantic Theory.
Language 39: 170-210.
Kwasny, S.C.; and Sondheimer, N.K. 1981 Relaxation Techniques
for Parsing Grammatically Ill-Formed Input in Natural Language
Understanding Systems. American Journal of Computatiohal Lin-
guistics 7(2): 99-108.
Mark, W. 1981 Representation and Inference in the Consul System. In
Proceedings of the Seventh International Joint Conference on
Artificial Intelligence, Vancouver, British Columbia: 375-381.
Michiels, A. 1982 Exploiting a Large Dictionary Database. Ph.D.
thesis, Universite de Liege, Liege.
Parkinson, R.C.; Colby, K. M.; and Faught, W. S. 1977 Conversa-
tional Language Comprehension Using Integrated Pattern-
Matching and Parsing. Artificial Intelligence 9: 111-134.
Procter, P., Ed., 1978 Longman Dictionary of Contemporary English.
Longman Group Limited, Harlow and London.
Pulman, S.G. 1984 Limited Domain Systems for Language Teaching.
In Proceedings of the 10th International Conference on Compu-
tational Linguistics, Stanford, California: 84-87.
Schmolze, J.G.; and Lipkis, T.A. 1983 Classification in the KL-ONE
Knowledge Representation System. In Proceedings of Eighth
International Joint Conference on Artificial Intelligence, Karls-
ruhe: 330-332.
Walker, D.; and Amsler, R. 1986 The Use of Machine Readable
Dictionaries in Sublanguage Analysis. In Analyzing Language in
Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 201
Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies
Restricted Domains, edited by Ralph Grishman and Richard
Kittredge. Lawrence Erlbaum Associates, Hillsdale, New Jersey:
69-83.
Weischedel, R.M.; and Black, J.E. 1980 Responding Intelligently to
Unparsable Inputs. American Journal of Computational Linguis-
tics 6(2): 97-109.
Wilensky, R.; and Arens, Y. 1980 PHRAN — A Phrasal Natural
Language Understander. In Proceedings of the 18th Annual Meet-
ing of the Association for Computational Linguistics, Philadel-
phia, Pennsylvania: 117-121.
Wilks, Y. 1975 An Intelligent Analyser and Understander of English.
Communications of the ACM 18: 264-274.
</reference>
<page confidence="0.959436">
202 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.646916">
<title confidence="0.998461">PROCESSING DICTIONARY DEFINITIONS WITH PHRASAL HIERARCHIES</title>
<author confidence="0.997166">Hiyan Alshawi</author>
<affiliation confidence="0.997892">University of Cambridge Computer</affiliation>
<address confidence="0.883564">Corn Exchange Street, Cambridge CB2 3QG, England*</address>
<abstract confidence="0.976459384615385">This paper shows how dictionary word sense definitions can be analysed by applying a hierarchy of phrasal patterns. An experimental system embodying this mechanism has been implemented for definitions from the Dictionary of Contemporary English. property of this dictionary, exploited by the system, is that it uses a restricted vocabulary in its word sense definitions. The structures generated by the experimental system are intended to be used for the classification of new word senses in terms of the senses of words in the restricted vocabulary. Examples illustrating the output generated are presented, and some qualitative performance results and problems that were encountered are discussed. The analysis process applies successively more specific phrasal analysis rules as determined by a hierarchy of patterns in which less specific patterns dominate more specific ones. This ensures that reasonable incomplete analyses of the definitions are produced when more complete analyses are not possible, resulting in a relatively robust analysis mechanism. Thus the work reported addresses two robustness problems faced by current experimental natural language processing systems: coping with an incomplete lexicon and with incomplete knowledge of phrasal constructions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>Memory and Context Mechanisms for Language Interpretation.</title>
<date>1987</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="7919" citStr="Alshawi (1987)" startWordPosition="1195" endWordPosition="1196">along with symbols corresponding to the senses of words in the definition vocabulary. Similarly, producing semantic primitive formulae would involve building new formulae by putting together formulae corresponding to the word senses of the definition vocabulary. For the third possible form of output listed earlier, we need a (hand-coded) classification of the central senses of the definition vocabulary together with a classification of concepts in the particular domain of discourse in terms of these word senses. The descriptions of implementations by Bobrow and Webber (1980), Mark (1981), and Alshawi (1987), show how such a classification can be organized and used during text processing. The LDOCE definition for a new word sense is processed using the mechanism described in this paper in order to extract sufficient information for including the new word sense in such a classification. A natural language processing application that depended on a classification of concepts in the discourse domain should then be able to carry out its application task despite the occurrence of a new word in an input sentence. Extracting the information necessary for classification will of course include locating sup</context>
<context position="16998" citStr="Alshawi, 1987" startWordPosition="2551" endWordPosition="2552">s. Some quantitative remarks about the performance of the system are given later. This section briefly discusses a number of problems that were encountered while testing the implemented system. In some respects the information conveyed by the output structures, being too closely tied to the surface definitions, only provides constraints for further semantic analysis. Perhaps the most important case of this is that the relationships implicit in compound nouns and certain prepositional phrase adverbials cannot, in general, be made more explicit without further interpretation apparatus (see e.g. Alshawi, 1987) beyond that available to the definition analyser. The phrasal context can, however, sometimes allow further specification of relationships implicit in prepositions, for instance derivation of PURPOSE from for in cases exemplified by the noun sense of launch (although, of course, errors can result from attempting to make relationships more explicit in this way). The actual words appearing in the semantic structures are, on the other hand, further disambiguated than might be assumed given the high degree of polysemy of many of the words in the restricted vocabulary. This is because the analysis</context>
</contexts>
<marker>Alshawi, 1987</marker>
<rawString>Alshawi, H. 1987 Memory and Context Mechanisms for Language Interpretation. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>B Boguraev</author>
<author>E Briscoe</author>
</authors>
<title>Towards a Dictionary Support Environment for Real Time Parsing.</title>
<date>1985</date>
<booktitle>In Proceedings of the Second Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>171--178</pages>
<location>Geneva:</location>
<contexts>
<context position="12620" citStr="Alshawi, Boguraev, and Briscoe, 1985" startWordPosition="1906" endWordPosition="1910">peculiarities of the current analysis grammar and output format, and I would not wish to argue for their correctness, especially in view of the problems discussed later. The following are examples of noun sense definitions together with the semantic structures derived from them. The words under which these examples occur in the dictionary are shown underlined. (The analysis system retrieves definitions from a lispified&apos; version of the LDOCE type-setting tape, for example items preceded by an asterisk are Lisp atoms corresponding to font control characters present on the type-setting tape (see Alshawi, Boguraev, and Briscoe, 1985).) (launch) (a large usu. motor-driven boat used for carrying people on rivers, lakes, harbours, etc.) ((CLASS BOAT) (PROPERTIES (LARGE)) (PURPOSE (PREDICATION (CLASS CARRY) (OBJECT PEOPLE)))) (mug) (*46 BrE infml *44 a foolish person who is easily deceived *44 *63 see also *CA MUG&apos;S GAME) ((CLASS PERSON) (PROPERTIES (FOOLISH)) (PREDICATION (OBJECT-OF ((CLASS DECEIVE))))) (hornbeam (a type of small tree with hard wood, sometimes used in *CA HEDGE *CB *46 s) ((CLASS TREE) (COLLECTIVE TYPE) (PROPERTIES (SMALL)) (HAS-PART ((CLASS WOOD) (PROPERTIES (HARD))))) The semantic heads of these definitio</context>
</contexts>
<marker>Alshawi, Boguraev, Briscoe, 1985</marker>
<rawString>Alshawi, H.; Boguraev, B.; and Briscoe, E. 1985 Towards a Dictionary Support Environment for Real Time Parsing. In Proceedings of the Second Conference of the European Chapter of the Association for Computational Linguistics, Geneva: 171-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Amsler</author>
</authors>
<title>A Taxonomy for English Nouns and Verbs.</title>
<date>1981</date>
<booktitle>In Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>Stanford, California:</location>
<contexts>
<context position="8642" citStr="Amsler (1981)" startWordPosition="1311" endWordPosition="1312">new word sense is processed using the mechanism described in this paper in order to extract sufficient information for including the new word sense in such a classification. A natural language processing application that depended on a classification of concepts in the discourse domain should then be able to carry out its application task despite the occurrence of a new word in an input sentence. Extracting the information necessary for classification will of course include locating superordinates in the definitions (which define the so called &amp;quot;ISA&amp;quot; relation) as is done in the work reported by Amsler (1981) and Calzolari (1984). However, this previous work suggests that achieving further semantic precision in a classification process requires making use of other information present in the definition (such as modifiers and predications). Examples of extracting this sort of information are presented in the next section. This way of dealing with unknown words in language processing applications still requires good solutions to the problem of choosing between alternative possible word senses (Walker and Amsler (1986) have used the LDOCE subject codes for this purpose) and to the problems involved in</context>
</contexts>
<marker>Amsler, 1981</marker>
<rawString>Amsler, R. 1981 A Taxonomy for English Nouns and Verbs. In Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics, Stanford, California: 133-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Bobrow</author>
<author>B L Webber</author>
</authors>
<title>Knowledge Representation for Syntactic/Semantic Processing.</title>
<date>1980</date>
<booktitle>In Proceedings of the First AAAI Conference,</booktitle>
<pages>316--323</pages>
<location>Stanford, California:</location>
<contexts>
<context position="7886" citStr="Bobrow and Webber (1980)" startWordPosition="1188" endWordPosition="1191">ew symbol for the word sense being defined along with symbols corresponding to the senses of words in the definition vocabulary. Similarly, producing semantic primitive formulae would involve building new formulae by putting together formulae corresponding to the word senses of the definition vocabulary. For the third possible form of output listed earlier, we need a (hand-coded) classification of the central senses of the definition vocabulary together with a classification of concepts in the particular domain of discourse in terms of these word senses. The descriptions of implementations by Bobrow and Webber (1980), Mark (1981), and Alshawi (1987), show how such a classification can be organized and used during text processing. The LDOCE definition for a new word sense is processed using the mechanism described in this paper in order to extract sufficient information for including the new word sense in such a classification. A natural language processing application that depended on a classification of concepts in the discourse domain should then be able to carry out its application task despite the occurrence of a new word in an input sentence. Extracting the information necessary for classification wi</context>
</contexts>
<marker>Bobrow, Webber, 1980</marker>
<rawString>Bobrow, R.J.; and Webber, B.L. 1980 Knowledge Representation for Syntactic/Semantic Processing. In Proceedings of the First AAAI Conference, Stanford, California: 316-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Calzolari</author>
</authors>
<title>Detecting Patterns in A Lexical Database.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics,</booktitle>
<pages>170--173</pages>
<location>Stanford, California:</location>
<contexts>
<context position="8663" citStr="Calzolari (1984)" startWordPosition="1314" endWordPosition="1315">processed using the mechanism described in this paper in order to extract sufficient information for including the new word sense in such a classification. A natural language processing application that depended on a classification of concepts in the discourse domain should then be able to carry out its application task despite the occurrence of a new word in an input sentence. Extracting the information necessary for classification will of course include locating superordinates in the definitions (which define the so called &amp;quot;ISA&amp;quot; relation) as is done in the work reported by Amsler (1981) and Calzolari (1984). However, this previous work suggests that achieving further semantic precision in a classification process requires making use of other information present in the definition (such as modifiers and predications). Examples of extracting this sort of information are presented in the next section. This way of dealing with unknown words in language processing applications still requires good solutions to the problem of choosing between alternative possible word senses (Walker and Amsler (1986) have used the LDOCE subject codes for this purpose) and to the problems involved in the classification p</context>
</contexts>
<marker>Calzolari, 1984</marker>
<rawString>Calzolari, N. 1984 Detecting Patterns in A Lexical Database. In Proceedings of the 10th International Conference on Computational Linguistics, Stanford, California: 170-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Carnap</author>
</authors>
<title>Meaning Postulates.</title>
<date>1952</date>
<journal>Philosophical Studies</journal>
<volume>3</volume>
<pages>65--73</pages>
<location>DeJong, G.</location>
<contexts>
<context position="5293" citStr="Carnap, 1952" startWordPosition="783" endWordPosition="784">ults of processing LDOCE definitions produced by an implemented definition analyser. Some problems that were encountered are then discussed. Later sections motivate and explain the basic analysis algorithm, and then describe and illustrate details of analysis and structure building rules. Finally some remarks are made about the performance of the current implementation and necessary further research. DEFINITION ANALYSIS There are various possibilities for the kind of structures useful for language understanding that may be derived from dictionary definitions. These include meaning postulates (Carnap, 1952) expressed in some logic; constraints or &apos;semantic formulae&apos; based on semantic primitives (Katz and Fodor, 1963, Wilks, 1975); and structures carrying information enabling the classification of the new word sense with respect to an existing classification of entities in a discourse domain. The structures produced by the implemented definition analyser belong to this last type, and examples of these structures are given later. The dictionary being used in this work, LDOCE, has features that make it particularly suitable for definition analysis. Thus many LDOCE word sense entries contain additio</context>
</contexts>
<marker>Carnap, 1952</marker>
<rawString>Carnap, R. 1952 Meaning Postulates. Philosophical Studies 3: 65-73. DeJong, G. 1979 Prediction and Substantiation: A New Approach to Natural Language Processing. Cognitive Science 3: 251-273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
<author>G V Mouradian</author>
</authors>
<title>Flexible Parsing.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>7</volume>
<issue>4</issue>
<pages>232--242</pages>
<contexts>
<context position="21570" citStr="Hayes and Mouradian (1981)" startWordPosition="3288" endWordPosition="3291">he analysis mechanism has the flavour of a patternbased phrasal analyser. It was designed to overcome some of the more obvious difficulties of applying a simple pattern matching approach to robust phrasal analysis. In particular it was required that the mechanism should have the means to specify which components of a phrase are more important, and to index analysis rules so that the mechanism would be reasonably efficient. Pattern matching has played an important role in several previous parsing systems, for example those of Wilks (1975), Parkinson et al (1977), Wilensky and Arens (1980), and Hayes and Mouradian (1981). A characteristic of the mechanism used here is that it depends on a hierarchy of phrasal analysis patterns in which more specific patterns are dominated by less specific ones. The basic analysis algorithm that applies the hierarchy of patterns is as follows. Starting at the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy). This procedure is repeated recursively so that we end up</context>
</contexts>
<marker>Hayes, Mouradian, 1981</marker>
<rawString>Hayes, P.J.; and Mouradian, G.V. 1981 Flexible Parsing. American Journal of Computational Linguistics 7(4): 232-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Katz</author>
<author>J A Fodor</author>
</authors>
<title>The Structure of a Semantic Theory.</title>
<date>1963</date>
<journal>Language</journal>
<volume>39</volume>
<pages>170--210</pages>
<contexts>
<context position="5404" citStr="Katz and Fodor, 1963" startWordPosition="799" endWordPosition="802">were encountered are then discussed. Later sections motivate and explain the basic analysis algorithm, and then describe and illustrate details of analysis and structure building rules. Finally some remarks are made about the performance of the current implementation and necessary further research. DEFINITION ANALYSIS There are various possibilities for the kind of structures useful for language understanding that may be derived from dictionary definitions. These include meaning postulates (Carnap, 1952) expressed in some logic; constraints or &apos;semantic formulae&apos; based on semantic primitives (Katz and Fodor, 1963, Wilks, 1975); and structures carrying information enabling the classification of the new word sense with respect to an existing classification of entities in a discourse domain. The structures produced by the implemented definition analyser belong to this last type, and examples of these structures are given later. The dictionary being used in this work, LDOCE, has features that make it particularly suitable for definition analysis. Thus many LDOCE word sense entries contain additional semantic information that could be combined, or used in conjunction with, the structures produced from proc</context>
</contexts>
<marker>Katz, Fodor, 1963</marker>
<rawString>Katz, J.J.; and Fodor J.A. 1963 The Structure of a Semantic Theory. Language 39: 170-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
<author>N K Sondheimer</author>
</authors>
<title>Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems.</title>
<date>1981</date>
<journal>American Journal of Computatiohal Linguistics</journal>
<volume>7</volume>
<issue>2</issue>
<pages>99--108</pages>
<contexts>
<context position="22469" citStr="Kwasny and Sondheimer, 1981" startWordPosition="3439" endWordPosition="3442"> the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy). This procedure is repeated recursively so that we end up with the most specific matches against the input definition. This parsing technique is different in kind from the more common approach to robust parsing in which exact grammar rules are tried first before being relaxed by the parser (see e.g. Weischedel and Black, 1980, Kwasny and Sondheimer, 1981, and Pulman, 1984). The hierarchy provides a natural solution to the indexing problem mentioned above since it restricts the application of patterns to those that are more likely to succeed, enabling efficient phrasal analysis. It also provides a solution to the problem of specifying the more important components of phrases since less specific patterns tend to be concerned with more important components only. This ensures that reasonable incomplete analyses can be produced when more detailed analyses are not possible. Each analysis rule consists of a rule identifier, a phrasal pattern, and a </context>
</contexts>
<marker>Kwasny, Sondheimer, 1981</marker>
<rawString>Kwasny, S.C.; and Sondheimer, N.K. 1981 Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems. American Journal of Computatiohal Linguistics 7(2): 99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mark</author>
</authors>
<title>Representation and Inference in the Consul System.</title>
<date>1981</date>
<booktitle>In Proceedings of the Seventh International Joint Conference on Artificial Intelligence,</booktitle>
<pages>375--381</pages>
<location>Vancouver, British Columbia:</location>
<contexts>
<context position="7899" citStr="Mark (1981)" startWordPosition="1192" endWordPosition="1193">se being defined along with symbols corresponding to the senses of words in the definition vocabulary. Similarly, producing semantic primitive formulae would involve building new formulae by putting together formulae corresponding to the word senses of the definition vocabulary. For the third possible form of output listed earlier, we need a (hand-coded) classification of the central senses of the definition vocabulary together with a classification of concepts in the particular domain of discourse in terms of these word senses. The descriptions of implementations by Bobrow and Webber (1980), Mark (1981), and Alshawi (1987), show how such a classification can be organized and used during text processing. The LDOCE definition for a new word sense is processed using the mechanism described in this paper in order to extract sufficient information for including the new word sense in such a classification. A natural language processing application that depended on a classification of concepts in the discourse domain should then be able to carry out its application task despite the occurrence of a new word in an input sentence. Extracting the information necessary for classification will of course </context>
</contexts>
<marker>Mark, 1981</marker>
<rawString>Mark, W. 1981 Representation and Inference in the Consul System. In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, Vancouver, British Columbia: 375-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Michiels</author>
</authors>
<title>Exploiting a Large Dictionary Database.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>Universite de Liege, Liege.</institution>
<contexts>
<context position="6410" citStr="Michiels (1982)" startWordPosition="955" endWordPosition="956"> particularly suitable for definition analysis. Thus many LDOCE word sense entries contain additional semantic information that could be combined, or used in conjunction with, the structures produced from processing word sense definition texts. This information is available as &apos;box codes&apos; that give selectional restrictions, and &apos;subject codes&apos; that indicate typical discourse domain usage of word senses (these codes occur in the machine-readable version of the dictionary, but not in the printed form). The suitability of LDOCE for work in computational linguistics has been analysed in detail by Michiels (1982). For the purpose of the work reported here, the most important property of LDOCE is the use of a restricted definition vocabulary of around 2000 words. Further, an important restriction imposed on LDOCE lexicographers is that only the &apos;central&apos; senses of these words should occur in definition texts. Some ways in which the definitions diverge from a strict interpretation of this rule are discussed later. It should be remarked here that the LDOCE restricted definition vocabulary has more in common with a &apos;basic English&apos; vocabulary than a set of semantic primitives. (A list of the words in the r</context>
<context position="20563" citStr="Michiels (1982)" startWordPosition="3123" endWordPosition="3124">e handled at present. However, given the compositional nature of nested feature lists, and the fact that definitional cross references are intended to be non-circular in LDOCE, it should be feasible to use semantic structures for the referenced words (and previous senses as in the hornbeam example) in building other semantic structures. The use of a restricted vocabulary in LDOCE definitions means that the lexicographers have already engaged in a substantial amount of semantic analysis of word senses that is potentially useful for automatic natural language processing. However, as observed by Michiels (1982), there is a tradeoff between the size of the definition vocabulary and the syntactic complexity of definitions. This implies that in order to take full advantage of the potential of LDOCE entries for language processing we need to pay special attention to the design of the definition analyser; this is the issue addressed in the rest of this paper. PHRASAL ANALYSIS HIERARCHIES The analysis mechanism has the flavour of a patternbased phrasal analyser. It was designed to overcome some of the more obvious difficulties of applying a simple pattern matching approach to robust phrasal analysis. In p</context>
</contexts>
<marker>Michiels, 1982</marker>
<rawString>Michiels, A. 1982 Exploiting a Large Dictionary Database. Ph.D. thesis, Universite de Liege, Liege.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Parkinson</author>
<author>K M Colby</author>
<author>W S Faught</author>
</authors>
<title>Conversational Language Comprehension Using Integrated PatternMatching and Parsing.</title>
<date>1977</date>
<journal>Artificial Intelligence</journal>
<volume>9</volume>
<pages>111--134</pages>
<contexts>
<context position="21511" citStr="Parkinson et al (1977)" startWordPosition="3279" endWordPosition="3282"> the rest of this paper. PHRASAL ANALYSIS HIERARCHIES The analysis mechanism has the flavour of a patternbased phrasal analyser. It was designed to overcome some of the more obvious difficulties of applying a simple pattern matching approach to robust phrasal analysis. In particular it was required that the mechanism should have the means to specify which components of a phrase are more important, and to index analysis rules so that the mechanism would be reasonably efficient. Pattern matching has played an important role in several previous parsing systems, for example those of Wilks (1975), Parkinson et al (1977), Wilensky and Arens (1980), and Hayes and Mouradian (1981). A characteristic of the mechanism used here is that it depends on a hierarchy of phrasal analysis patterns in which more specific patterns are dominated by less specific ones. The basic analysis algorithm that applies the hierarchy of patterns is as follows. Starting at the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy</context>
</contexts>
<marker>Parkinson, Colby, Faught, 1977</marker>
<rawString>Parkinson, R.C.; Colby, K. M.; and Faught, W. S. 1977 Conversational Language Comprehension Using Integrated PatternMatching and Parsing. Artificial Intelligence 9: 111-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Procter</author>
<author>Ed</author>
</authors>
<date>1978</date>
<institution>Longman Dictionary of Contemporary English. Longman Group Limited, Harlow and London.</institution>
<marker>Procter, Ed, 1978</marker>
<rawString>Procter, P., Ed., 1978 Longman Dictionary of Contemporary English. Longman Group Limited, Harlow and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Pulman</author>
</authors>
<title>Limited Domain Systems for Language Teaching.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics,</booktitle>
<pages>84--87</pages>
<location>Stanford, California:</location>
<contexts>
<context position="22488" citStr="Pulman, 1984" startWordPosition="3444" endWordPosition="3445">ern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy). This procedure is repeated recursively so that we end up with the most specific matches against the input definition. This parsing technique is different in kind from the more common approach to robust parsing in which exact grammar rules are tried first before being relaxed by the parser (see e.g. Weischedel and Black, 1980, Kwasny and Sondheimer, 1981, and Pulman, 1984). The hierarchy provides a natural solution to the indexing problem mentioned above since it restricts the application of patterns to those that are more likely to succeed, enabling efficient phrasal analysis. It also provides a solution to the problem of specifying the more important components of phrases since less specific patterns tend to be concerned with more important components only. This ensures that reasonable incomplete analyses can be produced when more detailed analyses are not possible. Each analysis rule consists of a rule identifier, a phrasal pattern, and a list of rule identi</context>
</contexts>
<marker>Pulman, 1984</marker>
<rawString>Pulman, S.G. 1984 Limited Domain Systems for Language Teaching. In Proceedings of the 10th International Conference on Computational Linguistics, Stanford, California: 84-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Schmolze</author>
<author>T A Lipkis</author>
</authors>
<title>Classification in the KL-ONE Knowledge Representation System.</title>
<date>1983</date>
<booktitle>In Proceedings of Eighth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>330--332</pages>
<location>Karlsruhe:</location>
<contexts>
<context position="9301" citStr="Schmolze and Lipkis, 1983" startWordPosition="1408" endWordPosition="1411">his previous work suggests that achieving further semantic precision in a classification process requires making use of other information present in the definition (such as modifiers and predications). Examples of extracting this sort of information are presented in the next section. This way of dealing with unknown words in language processing applications still requires good solutions to the problem of choosing between alternative possible word senses (Walker and Amsler (1986) have used the LDOCE subject codes for this purpose) and to the problems involved in the classification process (see Schmolze and Lipkis, 1983). Nonetheless, providing a mechanism, as described in this paper, for extracting the information required by the classification process is a necessary first step for this approach to handling unknown words. Dictionaries vary in the level of detail provided by their semantic definitions, and, in general, producing a meaning postulate for understanding a sentence, or incorporating a word sense into a discourse domain classification, can often be done without making use of all the detail provided by the dictionary definition. Even only being able to locate the &apos;semantic head&apos; (i.e. the main super</context>
</contexts>
<marker>Schmolze, Lipkis, 1983</marker>
<rawString>Schmolze, J.G.; and Lipkis, T.A. 1983 Classification in the KL-ONE Knowledge Representation System. In Proceedings of Eighth International Joint Conference on Artificial Intelligence, Karlsruhe: 330-332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Walker</author>
<author>R Amsler</author>
</authors>
<title>The Use of Machine Readable Dictionaries in Sublanguage Analysis.</title>
<date>1986</date>
<booktitle>In Analyzing Language in Computational Linguistics, Volume 13,</booktitle>
<pages>201</pages>
<location>Numbers</location>
<contexts>
<context position="9158" citStr="Walker and Amsler (1986)" startWordPosition="1385" endWordPosition="1388">the definitions (which define the so called &amp;quot;ISA&amp;quot; relation) as is done in the work reported by Amsler (1981) and Calzolari (1984). However, this previous work suggests that achieving further semantic precision in a classification process requires making use of other information present in the definition (such as modifiers and predications). Examples of extracting this sort of information are presented in the next section. This way of dealing with unknown words in language processing applications still requires good solutions to the problem of choosing between alternative possible word senses (Walker and Amsler (1986) have used the LDOCE subject codes for this purpose) and to the problems involved in the classification process (see Schmolze and Lipkis, 1983). Nonetheless, providing a mechanism, as described in this paper, for extracting the information required by the classification process is a necessary first step for this approach to handling unknown words. Dictionaries vary in the level of detail provided by their semantic definitions, and, in general, producing a meaning postulate for understanding a sentence, or incorporating a word sense into a discourse domain classification, can often be done with</context>
</contexts>
<marker>Walker, Amsler, 1986</marker>
<rawString>Walker, D.; and Amsler, R. 1986 The Use of Machine Readable Dictionaries in Sublanguage Analysis. In Analyzing Language in Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 201</rawString>
</citation>
<citation valid="false">
<title>Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies Restricted Domains, edited by Ralph Grishman and Richard Kittredge. Lawrence Erlbaum Associates,</title>
<pages>69--83</pages>
<location>Hillsdale, New Jersey:</location>
<marker></marker>
<rawString>Hiyan Alshawi Processing Dictionary Definitions with Phrasal Pattern Hierarchies Restricted Domains, edited by Ralph Grishman and Richard Kittredge. Lawrence Erlbaum Associates, Hillsdale, New Jersey: 69-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Weischedel</author>
<author>J E Black</author>
</authors>
<title>Responding Intelligently to Unparsable Inputs.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>6</volume>
<issue>2</issue>
<pages>97--109</pages>
<contexts>
<context position="22440" citStr="Weischedel and Black, 1980" startWordPosition="3435" endWordPosition="3438">s is as follows. Starting at the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy). This procedure is repeated recursively so that we end up with the most specific matches against the input definition. This parsing technique is different in kind from the more common approach to robust parsing in which exact grammar rules are tried first before being relaxed by the parser (see e.g. Weischedel and Black, 1980, Kwasny and Sondheimer, 1981, and Pulman, 1984). The hierarchy provides a natural solution to the indexing problem mentioned above since it restricts the application of patterns to those that are more likely to succeed, enabling efficient phrasal analysis. It also provides a solution to the problem of specifying the more important components of phrases since less specific patterns tend to be concerned with more important components only. This ensures that reasonable incomplete analyses can be produced when more detailed analyses are not possible. Each analysis rule consists of a rule identifi</context>
</contexts>
<marker>Weischedel, Black, 1980</marker>
<rawString>Weischedel, R.M.; and Black, J.E. 1980 Responding Intelligently to Unparsable Inputs. American Journal of Computational Linguistics 6(2): 97-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
<author>Y Arens</author>
</authors>
<title>PHRAN — A Phrasal Natural Language Understander.</title>
<date>1980</date>
<booktitle>In Proceedings of the 18th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>117--121</pages>
<location>Philadelphia, Pennsylvania:</location>
<contexts>
<context position="21538" citStr="Wilensky and Arens (1980)" startWordPosition="3283" endWordPosition="3286"> PHRASAL ANALYSIS HIERARCHIES The analysis mechanism has the flavour of a patternbased phrasal analyser. It was designed to overcome some of the more obvious difficulties of applying a simple pattern matching approach to robust phrasal analysis. In particular it was required that the mechanism should have the means to specify which components of a phrase are more important, and to index analysis rules so that the mechanism would be reasonably efficient. Pattern matching has played an important role in several previous parsing systems, for example those of Wilks (1975), Parkinson et al (1977), Wilensky and Arens (1980), and Hayes and Mouradian (1981). A characteristic of the mechanism used here is that it depends on a hierarchy of phrasal analysis patterns in which more specific patterns are dominated by less specific ones. The basic analysis algorithm that applies the hierarchy of patterns is as follows. Starting at the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately below it in the hierarchy). This procedure is repeat</context>
<context position="32728" citStr="Wilensky and Arens, 1980" startWordPosition="5041" endWordPosition="5044">ic forms, and it is this property of definitions that makes phrasal pattern hierarchies particularly appropriate for analysing them. It seems likely however that the analysis technique developed here would be useful for the same reason in other language processing applications, for example specialized interactive applications. One direction in which it is hoped to extend the work reported in this paper is in enhancing the capabilities of natural language processing systems for coping with idioms. Intuitively, some sort of pattern matching seems to be appropriate for analysing idioms (see e.g. Wilensky and Arens, 1980). In the context of a parsing system using an analysis hierarchy the patterns for idioms would be placed as most specialized patterns (i.e. leaves). LDOCE entries contain a wealth of information on idiomatic uses of words, and the meanings of idioms are expressed using the restricted definition vocabulary. It is hoped to extend the definition analysis system so that it would attempt to generate appropriate phrasal patterns when it encountered a definition for an idiomatic use of a word. It may then be possible to use the generated pattern and the definition of the idiom to produce a paraphrase</context>
</contexts>
<marker>Wilensky, Arens, 1980</marker>
<rawString>Wilensky, R.; and Arens, Y. 1980 PHRAN — A Phrasal Natural Language Understander. In Proceedings of the 18th Annual Meeting of the Association for Computational Linguistics, Philadelphia, Pennsylvania: 117-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>An Intelligent Analyser and Understander of English.</title>
<date>1975</date>
<journal>Communications of the ACM</journal>
<volume>18</volume>
<pages>264--274</pages>
<contexts>
<context position="5418" citStr="Wilks, 1975" startWordPosition="803" endWordPosition="804">hen discussed. Later sections motivate and explain the basic analysis algorithm, and then describe and illustrate details of analysis and structure building rules. Finally some remarks are made about the performance of the current implementation and necessary further research. DEFINITION ANALYSIS There are various possibilities for the kind of structures useful for language understanding that may be derived from dictionary definitions. These include meaning postulates (Carnap, 1952) expressed in some logic; constraints or &apos;semantic formulae&apos; based on semantic primitives (Katz and Fodor, 1963, Wilks, 1975); and structures carrying information enabling the classification of the new word sense with respect to an existing classification of entities in a discourse domain. The structures produced by the implemented definition analyser belong to this last type, and examples of these structures are given later. The dictionary being used in this work, LDOCE, has features that make it particularly suitable for definition analysis. Thus many LDOCE word sense entries contain additional semantic information that could be combined, or used in conjunction with, the structures produced from processing word se</context>
<context position="21487" citStr="Wilks (1975)" startWordPosition="3277" endWordPosition="3278">e addressed in the rest of this paper. PHRASAL ANALYSIS HIERARCHIES The analysis mechanism has the flavour of a patternbased phrasal analyser. It was designed to overcome some of the more obvious difficulties of applying a simple pattern matching approach to robust phrasal analysis. In particular it was required that the mechanism should have the means to specify which components of a phrase are more important, and to index analysis rules so that the mechanism would be reasonably efficient. Pattern matching has played an important role in several previous parsing systems, for example those of Wilks (1975), Parkinson et al (1977), Wilensky and Arens (1980), and Hayes and Mouradian (1981). A characteristic of the mechanism used here is that it depends on a hierarchy of phrasal analysis patterns in which more specific patterns are dominated by less specific ones. The basic analysis algorithm that applies the hierarchy of patterns is as follows. Starting at the top of the hierarchy, a pattern is matched against the input definition, If the match with this pattern succeeds then a match is attempted with each of its daughter patterns (i.e. the more specific forms of this pattern placed immediately b</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks, Y. 1975 An Intelligent Analyser and Understander of English. Communications of the ACM 18: 264-274.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>