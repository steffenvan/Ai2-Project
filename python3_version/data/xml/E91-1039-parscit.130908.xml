<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001220">
<sectionHeader confidence="0.4857265" genericHeader="method">
AUTOMATIC SEMANTIC CLASSIFICATION OF VERBS FROM THEIR
SYNTACTIC CONTEXTS: AN IMPLEMENTED CLASSIFIER FOR STATIVITY
</sectionHeader>
<author confidence="0.6403685">
Michael R. Brent
MIT Al Lab
</author>
<affiliation confidence="0.457701">
545 Technology Square
</affiliation>
<address confidence="0.788929">
Cambridge, Massachusetts 02139
</address>
<email confidence="0.999108">
michael@ai.mit.edu
</email>
<sectionHeader confidence="0.99551" genericHeader="method">
Abstract
</sectionHeader>
<bodyText confidence="0.9999565">
This paper discusses an implemented
program that automatically classifies
verbs into those that describe only
states of the world, such as to know, and
those that describe events, such as Lo
look. It works by exploiting the con-
straint between the syntactic environ-
ments in which a verb can occur and
its meaning. The only input is on-line
text. This demonstrates an important
new technique for the automatic gener-
ation of lexical databases.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="method">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99706">
Young children and natural language process-
ing programs face a common problem: everyone
else knows a lot more about words. Children, it is
hypothesized, catch up by observing the linguis-
tic and non-linguistic contexts in which words are
used. This paper focuses on the value and acces-
sibility of the linguistic context. It argues that
linguistic context by itself can provide useful cues
about verb meaning to an artificial learner. This is
demonstrated by a program that exploits two par-
ticular cues from the linguistic context to classify
verbs automatically into those whose sole sense is
qne describing a state, and those that have a sense
describing an event.i The approach described here
accounts for a certain degree of noise in the input
due both to mis-apprehension of input sentences
and to their occasional mal-formation. This work
shows that the two cues are available and are re-
liable given the statistical methods applied.
Language users, whether natural or artificial,
need detailed semantic and syntactic classifica-
tions of words. Ultimately, any artificial language
&apos;The input sentences are those compiled in the Lan-
caster/Oslo/Bergen (LOB) Corpus, a balanced corpus
of one million words of British English. The LOB con-
sists primarily of edited prose.
user must be able to add new words to its lexicon,
if only to accommodate the many neologisms it
will encounter. And our lexicographic needs grow
with our understanding of language. A number
of current approaches to satisfying the lexical re-
quirements for artificial devices do not involve un-
supervised learning from examples. Boguraev and
Briscoe (1987) discusses interpreting the informa-
tion published in on-line dictionaries, while Zernik
and Dyer (1987) discuss tutored learning in a con-
trolled environment. But any method that re-
quires explicit human intervention — be it that of
lexicographers, knowledge engineers, or &amp;quot;tutors&amp;quot;
— will lag behind both the growth of vocabu-
lary and the growth of linguistics, and even with
the lag their maintenance will be expensive. By
contrast, dictionaries constructed by automated
learners from real sentences will not lag behind
vocabulary growth; examples of current language
use are free and nearly infinite. These observa-
tions have led Several researchers, including Hindle
(1990) and Smadja and McKeown (1990), to begin
investigating automatic acquisition of semantics.
Hindle and Smadja and McKeown rely purely on
the ability of one particular word to statistically
predict the occurrence of another in a particular
position. In contrast, the approach described here
is targeted at particular semantic classes that are
revealed by specific linguistic constructions.
</bodyText>
<sectionHeader confidence="0.964349" genericHeader="method">
2 The Questions
</sectionHeader>
<bodyText confidence="0.9752568">
This section discusses work on two linguis-
tic cues that reveal the availability of non-stative
senses for verbs. This work attempts to determine
the difficulty of using the cues to classify verbs
into those describing states and those describing
events. To that end, it focuses on two questions:
1. Is it possible to reliably detect the two cues
using only a simple syntactic mechanism and
minimal syntactic knowledge? How simple
can the syntax be? (The less knowledge re-
quired to learn using a given technique, the
- 222 -
more useful the technique will be.)
2. Assuming minimal syntactic power, how re-
liable are our two cues in real text, which
is subject to performance limitations? Are
there learning strategies under which their re-
liability is adequate?
Section 2.1 describes syntactic constructions stud-
ied and demonstrates their relation to the stative
semantic class. Sections 2.2 answers questions 1
in the affirmative. Section 2.4 answers question 2
in the affirmative, discusses the statistical method
used for noise reduction, and demonstrates the
program that learns the state-event distinction.
</bodyText>
<subsectionHeader confidence="0.994803">
2.1 Revealing Constructions
</subsectionHeader>
<bodyText confidence="0.999929666666667">
The differences between verbs describing
states (statives) and those describing events (non-
statives) has been studied by linguists at least
since Lakoff (1965). (For a more precise seman-
tic characterization of statives see Dowty, 1979.)
Classic examples of stative verbs are know, believe,
desire, and love. A number of syntactic tests have
been proposed to distinguish between statives and
non-statives (again see Dowty, 1979). For exam-
ple, stative verbs are anomalous when used in the
progressive aspect and when modified by rate ad-
verbs such as quickly and slowly:
</bodyText>
<listItem confidence="0.997881">
(1) a. * Jon is knowing calculus
b. * Jon knows calculus quickly
</listItem>
<bodyText confidence="0.842254333333333">
Perception verbs like see and hear share with sta-
tives a strong resistance to the progressive aspect,
but not to rate adverbs:
</bodyText>
<listItem confidence="0.998141">
(2) a. * Jon is seeing the car
b. OK Jon quickly saw the car
</listItem>
<bodyText confidence="0.99486">
Agentive verbs describing attempts to gain per-
ceptions, like look and listen, do not share either
property:
</bodyText>
<listItem confidence="0.9992605">
(3) a. OK Jon is looking at a car
b. OK Jon quickly looked at his watch
</listItem>
<bodyText confidence="0.999646666666667">
The classification program relies primarily on the
progressive cue, but uses evidence from the rate
adverb cue when it is available.
</bodyText>
<subsectionHeader confidence="0.9936815">
2.2 Syntactic Requirements for Cue
Detection
</subsectionHeader>
<bodyText confidence="0.952880777777777">
Consider first how much syntactic analysis is
needed to detect the progressive and rate adverb
constructions. Initially, suppose that the availabil-
ity of a non-stative sense is an intrinsic property of
a verb not affected by its syntactic context.2 To
detect progressives one need only parse a trivial
part of the auxiliary system, which is known to
2This is not true in general, as shown by the fact
that think that.., is stative while think about... is not.
be finite-state. Detecting the rate adverb cue re-
quires determining what the adverb modifies, and
that can be trickier. For example, adverbs may
appear after the direct object, (4a), and this must
not be confused with the case where they appear
after the subject of an embedded clause, (4b).
(4) a. Jon fixed the robot quickly
b. Jon knew his hostess rapidly lost inter-
est in such things
Using simple, finite-state machinery one would be
forced to deal with (4b) by recognizing the po-
sition of the adverb as ambiguous and rejecting
the example. Or one could deploy more sophisti-
cated syntax to try determining the boundaries of
embedded sentences. But even the best syntactic
parser will fail on truly ambiguous cases like the
following:
(5) a. Jon fixed the robot that had spoken
slowly
b. Jon believed the robot that had spoken
slowly
The data on rate adverbs were collected using
the parsing approach, which required a substantial
amount of machinery, but a finite-state approach
might do almost as well. (See Brent and Berwick,
1991, for automatic lexical acquisition using sim-
ple finite-state parsing.)
</bodyText>
<subsectionHeader confidence="0.998917">
2.3 Data on Cues from the Corpus
</subsectionHeader>
<bodyText confidence="0.999395296296296">
To test the power of the two proposed cues,
the LOB corpus was automatically processed to
determine what percentage of each verb&apos;s occur-
rences were in the progressive, and what percent-
age were modified by rate adverbs. Sampling error
was handled by calculating the probability distri-
bution of the true percentage for each verb assum-
ing that the sentences in the corpus were drawn
at random froth some infinitely large corpus. The
overall frequency of the progressive construction
was substantially higher than that of the rate ad-
verb construction and so provided more significant
data. Figure 1 shows a histogram constructed by
summing these distributions of true frequency in
the progressive over each of the 38 most common
verbs in the corpus.3 Figure 1 shows that, at least
for these most common verbs, there are three and
perhaps four distinct populations. In other words,
these verbs do not vary continuously in their fre-
quency of occurrence in the progressive, but rather
show a marked tendency to cluster around certain
values. As will be shown in the next section, the
3Histograms that include less frequent verbs have
the same general character, but the second local maxi-
mum gets somewhat blurred by the many verbs whose
true frequency in the progressive is poorly localized
due to insufficient sample size.
</bodyText>
<table confidence="0.995866833333333">
- 223 -
al 0.02 200 :scale IOU) 1 0.1 0.11 0.12 0.13 0.14 11.13 0.16 0.17 SAO I I
(print-hi 375 :nax-Index 0.116 SAY 0.00 0.09 0.19 0.2
NIL 0.03 0.04 0.03
0.0 0.01
nsmic Lis. Listener 1
</table>
<figureCaption confidence="0.9920135">
Figure 1: A histogram constructed by summing the probability distributions of true frequency
in the progressive over each of the 38 most common verbs in the corpus
</figureCaption>
<bodyText confidence="0.999615">
stative verbs fall in the first population, to the left
of the slight discontinuity at 1.35% of occurrence
in the progressive.
</bodyText>
<subsectionHeader confidence="0.995105">
2.4 The Classification Program
</subsectionHeader>
<bodyText confidence="0.99988372972973">
I implemented a program that attempts to
classify verbs into those with event senses, and
those whose only meaning describes a state rather
than an event. It does this by first detecting oc-
currences of the progressive and rate adverb con-
structions in the LOB corpus, and then computing
confidence intervals on the true frequency of occur-
rence of each verb in an arbitrarily large corpus
of the same composition. The program classifies
the verbs according to bounds, which are for the
moment supplied by the researcher, on the confi-
dence intervals. For example, on the run shown
in Figure 2, the program classifies verbs which oc-
cur at least .1% of the time either in the progres-
sive or modified by a rate adverb, as having an
event (non-stative) sense. The classifier acts on
.1% bound only if the sample-size is large enough
to guarantee the bound with 95% confidence. Ac-
curacy in ascribing non-stative senses according
with this technique is excellent — no purely sta-
tive verbs are mis-classified as having non-stative
senses. In fact, this result is not very sensitive to
raising the minimum progressive frequency from
.1% to as high as .6% or .7%, since most verbs
with non-stative senses yield observed frequencies
of at least two or three percent.
Now consider the other side of the problem,
classifying verbs as purely stative. Here the pro-
gram takes verbs that fail the test for having a
non-stative sense, and in addition whose true fre-
quency in the progressive falls below a given upper
bound with sufficient confidence. The rate-adverb
construction is not used, except insofar as the
verbs must fail the .1% lower bound, because this
construction turns out to be so rare that only a
few of the most frequent verbs provide sufficiently
tight bounds. The results for identifying pure sta-
</bodyText>
<table confidence="0.997309739130435">
- 224 -
• (c1ass1fy-stotlye-non-statIve :max-proor-for-stative .0135
sw1n-rot5-for-non-stat1ve .091
;min- -for-non-stative .991)
LRCKS-NON-STATIVE-SENSE:
KNOW SEEM LIKE BELIEVE RANT REMAIN MEAN HERR REQUIRE UNDERSTAND AGREE
HRS-NON-STRTIVE-SENSE:
REAR WRIT 00 TALK GROW CO STAY TRY VISIT LISTEN LIE SIT PREPARE FAIL SEEK YONDER FIGHT WORK STORY
BEGIN DRIVE MATCH DEAL ACT ENJOY SETTLE SMILE PLAY DIE LIVE RUN MOVE STAND HAPPEN WALK CREATE PROVE
CRUSE BREAK DROP LOOK CARRY FACE ATTEND EXPECT FALL ENO DEVELOP OFFER EAT UNITE READ CLOSE BECOME I
(PINT DRAM RETURN RISE BUILD CHANCE RIM CONE LEARN PUBLISH PICK ASSOCIATE GET PRODUCE REPLY PAY LEAD
INTRODUCE COMPLETE REFUSE SAVE NOTICE PULL AVOID RECEIVE SERVE PRESENT STOP OPEN ENTER SET SPEND NUN
FORGET NOTE ASSUME PLACE INCREASE OCCUR COMPARE CONSIDER SUGGEST COVER DISCOVER SELL THINK REGARD CFTC
CT KEEP HOLD FOLLOW PUT MEET ACCEPT SENO HELP REVEAL BRING RAISE APPEAR PROVIDE TAKE REMEMBER SPECK
FINISH TURN ASK. REACH LET TELL MAKE FELL ANSWER FIND LEAVE ACHIEVE FEEL COLL SHOW USE EXPLAIN Gm
OBTAIN DECIDE SAY SEE
INDETERMINRTE:
THROW REFER BASE CHOOSE CATCH ARRIVE MANAGE SUPPORT EXIST BELONG ARISE BEAR NEED CUT INTEND IMAGINE C
LAIR FORM BUY NE STATE KILL APPLY REMOVE REALISE HOPE MAINTAIN JOIN MENTION FILL ADMIT DEPEND REPORT
ALLOW MARRY ESTABLISH INDICATE LAY LOOSE SPEAK SUPPOSE REDUCE REPRESENT LOVE INVOLVE CONTAIN ADO START
BR INCLUDE CONCERN CONTINUE DESCRIBE
NIL
Dynamic Lisp Listener 1
</table>
<figureCaption confidence="0.847952">
Figure 2: One run of the stative/non-stative classification program on verbs occurring at least
100 times in the LOB corpus
</figureCaption>
<bodyText confidence="0.997560448275862">
Lives are also quite good, although more sensitive
to the precise bounds than were the results for
identifying non-statives. If the upper bound on
progressive frequency is set at 1.35%, as in Fig-
ure 2, then eleven verbs are identified as purely
stative, of the 204 distinct verbs occurring at least
100 times each in the corpus. Two of these, hear
and agree, have relatively rare non-stative senses,
meaning to imagine one hears (&amp;quot;I am hearing a
ringing in my ears&amp;quot;) and to communicate agree-
ment (&amp;quot;Rachel was already agreeing when Jon in-
terrupted her with yet another tirade&amp;quot;). If the up-
per bound on progressive frequency is tightened to
1.20% then hear and agree drop into the &amp;quot;indeter-
minate&amp;quot; category of verbs that pass neither test.
So, too, do three pure statives, mean, require, and
understand.
It is worth noting the importance of using
some sort of noise reduction technique, such as
the confidence intervals used here. There are two
sources of noise in the linguistic input. First
speakers do utter anomalous sentences. For ex-
ample, the stative verb mean occurred one time
out of 450 in the progressive. The sentence, &amp;quot;It&apos;s
a stroke, that was what he was meaning&amp;quot; is clearly
anomalous. The second source of noise is failure
of the learner to detect the cue accurately. The
accuracy of our automatic cue detection detection
is described in the following section.
</bodyText>
<subsectionHeader confidence="0.999934">
2.5 Accuracy of Cue Detection
</subsectionHeader>
<bodyText confidence="0.936204170731707">
Section 2.2 discussed how much structure must
be imposed on sentences if the progressive and
rate-adverb constructions are to be detected. Sec-
tion 2.3 showed that the progressive and rate-
adverb constructions are indeed reliable cues for
the availability of a non-stative sense. This sec-
tion discusses the accuracy with which these cues
can be detected.
It is not practical to check manually every
verb occurrence that our program judged tp be
progressive. Instead, I checked 300 such sentences
- 225 -
selected at random from among the most com-
monly occurring verbs. This check revealed only
one sentence that did not truly describe a progres-
sive event. That sentence is shown in (6a).
(6) a. go: What that means in this case is go-
ing back to the war years...
b. see: The task was solely to see how
speedily it could be met...
c. compare: ...the purchasing power of the
underdeveloped countries in the com-
monwealth will rise slowly compared
with that of Europe.
It is not clear how to automatically determine
that (6a) does not deseribe an event of going in
progress. Rate adverbs are infrequent enough that
it was possible to verify manually all 281 cases the
program found. In four of those cases the rate ad-
verb actually modified a verb other than the one
that the program chose. Three of these four cases
had the structure of (6b), where a wh- relative
is not recognized as signaling the beginning of a
new clause. This reflects an oversight in the gram-
mar that should be easily correctable. The one re-
maining case of a mis-attributed rate adverb, (6c),
would again require some work, and perhaps sub-
stantial syntactic knowledge, to correct. The rate
of false positives in cue detection, then can be esti-
mated at about one serious hazard in 300 for both
&apos;tests.
</bodyText>
<sectionHeader confidence="0.999617" genericHeader="conclusions">
3 Conclusions
</sectionHeader>
<bodyText confidence="0.999982681818182">
This work demonstrates a promising ap-
proach to automatic semantic classification of
verbs based only on their immediate linguistic con-
texts. Some sort of statistical smoothing is essen-
tial to avoid being permanently mislead by anoma-
lous and misunderstood utterances, and this work
demonstrated the sufficiency of an-approach based
on binomial confidence-intervals. These meth-
ods, in combination with pure collocational meth-
ods like those of [Hindle, 1990] and [Smadja and
McKeown, 1990], may eventually yield substan-
tial progress toward automatic acquisition of word
meaning, or some aspects thereof, by language us-
ing devices.
The initial results described here suggest
many more experiments, some of which are al-
ready underway (see Brent and Berwick, 1991).
These include attempting to take into account the
ability of local syntactic context to influence a
verb&apos;s meaning as well as to reveal it. For exam-
ple, think that is stative while think about and think
of are not. Separating these two senses automati-
cally could add substantial power to our classifier.
Next, there are many more linguistic cues to verb
meaning to be detected and exploited. For exam-
ple, the ability to take both a direct object and a
propositional complement, as in &amp;quot;tell him that he&apos;s
a fool&amp;quot;, reveal verbs of communication. While the
progressive cue is not available in Romance lan-
guages, the ability to take a direct object and a
propositional complement seems to be diagnostic
of communication verbs in Romance as well as in
English. It would be valuable to demonstrate cues
like this on non-English text. It would also be
valuable to apply these techniques to a greater va-
riety of input sentences, including transcriptions
of mother&apos;s speech to their children. Finally, sub-
stantially larger corpora should be used in order
to enlarge the number of verbs classified. All of
these planned extensions serve the goal of auto-
matically classifying thousands of verbs by dozens
of different syntactic criteria, and thereby yielding
a valuable, adaptable lexicon for natural language
processing and artificial intelligence.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985294060606061">
[Boguraev and Briscoe, 1987] B. Boguraev and
T. Briscoe. Large Lexicons for Natural Lan-
guage Processing: Utilising the Grammar Cod-
ing System of LDOCE. Comp. Ling., 13(3),
1987.
[Brent and Berwick, 1991] M. Brent and
R. Berwick, Automatic Acquisition of Subcate-
gorization Frames From Free Text Corpora. In
Proceedings of the .4th Darpa Speech and Natu-
ral Language Workshop. Defense Advanced Re-
search Projects Agency, Arlington, VA, USA,
1991.
[Dowty, 1979] D. Dowty. Word Meaning and
Montague Grammar. Synthese Language Li-
brary. D. Reidel, Boston, 1979.
[Hindle, 1990] D. Hindle. Noun classification from
predicate argument structures. In Proceedings
of the 28th Annual Meeting of the ACL, pages
268-275. ACL, 1990.
[Lakoff, 19651 G. Lakoff. On the Nature of Syntac-
tic Irregularity. PhD thesis, Indiana University,
1965. Published by Holt, Rinhard, and Winston
as Irregularity in Syntax, 1970.
[Smadja and McKeown, 1990]
F. Smadja and K. McKeown. Automatically
extracting and representing collocations for lan-
guage generation. In 28th Annual Meeting of
the Association for Comp. Ling., pages 252-259.
ACL, 1990.
[Zernik and Dyer, 1987] U. Zernik and M. Dyer.
The self-extending phrasal lexicon. Comp.
Ling., 13(3), 1987.
- 226 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.936929">
<title confidence="0.9915455">AUTOMATIC SEMANTIC CLASSIFICATION OF VERBS FROM THEIR SYNTACTIC CONTEXTS: AN IMPLEMENTED CLASSIFIER FOR STATIVITY</title>
<author confidence="0.999993">Michael R Brent</author>
<affiliation confidence="0.972273">MIT Al Lab</affiliation>
<address confidence="0.9975375">545 Technology Square Cambridge, Massachusetts 02139</address>
<email confidence="0.999883">michael@ai.mit.edu</email>
<abstract confidence="0.998780923076923">This paper discusses an implemented program that automatically classifies verbs into those that describe only of the world, such as know, that describe events, such as works by exploiting the constraint between the syntactic environments in which a verb can occur and its meaning. The only input is on-line text. This demonstrates an important new technique for the automatic generation of lexical databases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Large Lexicons for Natural Language Processing: Utilising the Grammar Coding System of LDOCE.</title>
<date>1987</date>
<journal>Comp. Ling.,</journal>
<volume>13</volume>
<issue>3</issue>
<contexts>
<context position="2302" citStr="(1987)" startWordPosition="361" endWordPosition="361">tic classifications of words. Ultimately, any artificial language &apos;The input sentences are those compiled in the Lancaster/Oslo/Bergen (LOB) Corpus, a balanced corpus of one million words of British English. The LOB consists primarily of edited prose. user must be able to add new words to its lexicon, if only to accommodate the many neologisms it will encounter. And our lexicographic needs grow with our understanding of language. A number of current approaches to satisfying the lexical requirements for artificial devices do not involve unsupervised learning from examples. Boguraev and Briscoe (1987) discusses interpreting the information published in on-line dictionaries, while Zernik and Dyer (1987) discuss tutored learning in a controlled environment. But any method that requires explicit human intervention — be it that of lexicographers, knowledge engineers, or &amp;quot;tutors&amp;quot; — will lag behind both the growth of vocabulary and the growth of linguistics, and even with the lag their maintenance will be expensive. By contrast, dictionaries constructed by automated learners from real sentences will not lag behind vocabulary growth; examples of current language use are free and nearly infinite. </context>
</contexts>
<marker>1987</marker>
<rawString>[Boguraev and Briscoe, 1987] B. Boguraev and T. Briscoe. Large Lexicons for Natural Language Processing: Utilising the Grammar Coding System of LDOCE. Comp. Ling., 13(3), 1987.</rawString>
</citation>
<citation valid="true">
<title>Automatic Acquisition of Subcategorization Frames From Free Text Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the .4th Darpa Speech and Natural Language Workshop. Defense Advanced Research Projects Agency,</booktitle>
<location>Arlington, VA, USA,</location>
<marker>1991</marker>
<rawString>[Brent and Berwick, 1991] M. Brent and R. Berwick, Automatic Acquisition of Subcategorization Frames From Free Text Corpora. In Proceedings of the .4th Darpa Speech and Natural Language Workshop. Defense Advanced Research Projects Agency, Arlington, VA, USA, 1991.</rawString>
</citation>
<citation valid="true">
<title>Word Meaning and Montague Grammar. Synthese Language Library.</title>
<date>1979</date>
<location>D. Reidel, Boston,</location>
<marker>1979</marker>
<rawString>[Dowty, 1979] D. Dowty. Word Meaning and Montague Grammar. Synthese Language Library. D. Reidel, Boston, 1979.</rawString>
</citation>
<citation valid="true">
<title>Noun classification from predicate argument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the ACL,</booktitle>
<pages>268--275</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="2974" citStr="(1990)" startWordPosition="463" endWordPosition="463">onaries, while Zernik and Dyer (1987) discuss tutored learning in a controlled environment. But any method that requires explicit human intervention — be it that of lexicographers, knowledge engineers, or &amp;quot;tutors&amp;quot; — will lag behind both the growth of vocabulary and the growth of linguistics, and even with the lag their maintenance will be expensive. By contrast, dictionaries constructed by automated learners from real sentences will not lag behind vocabulary growth; examples of current language use are free and nearly infinite. These observations have led Several researchers, including Hindle (1990) and Smadja and McKeown (1990), to begin investigating automatic acquisition of semantics. Hindle and Smadja and McKeown rely purely on the ability of one particular word to statistically predict the occurrence of another in a particular position. In contrast, the approach described here is targeted at particular semantic classes that are revealed by specific linguistic constructions. 2 The Questions This section discusses work on two linguistic cues that reveal the availability of non-stative senses for verbs. This work attempts to determine the difficulty of using the cues to classify verbs </context>
</contexts>
<marker>1990</marker>
<rawString>[Hindle, 1990] D. Hindle. Noun classification from predicate argument structures. In Proceedings of the 28th Annual Meeting of the ACL, pages 268-275. ACL, 1990.</rawString>
</citation>
<citation valid="true">
<title>On the Nature of Syntactic Irregularity.</title>
<date>1965</date>
<tech>PhD thesis,</tech>
<institution>Indiana University,</institution>
<note>Published by</note>
<contexts>
<context position="4674" citStr="(1965)" startWordPosition="724" endWordPosition="724">there learning strategies under which their reliability is adequate? Section 2.1 describes syntactic constructions studied and demonstrates their relation to the stative semantic class. Sections 2.2 answers questions 1 in the affirmative. Section 2.4 answers question 2 in the affirmative, discusses the statistical method used for noise reduction, and demonstrates the program that learns the state-event distinction. 2.1 Revealing Constructions The differences between verbs describing states (statives) and those describing events (nonstatives) has been studied by linguists at least since Lakoff (1965). (For a more precise semantic characterization of statives see Dowty, 1979.) Classic examples of stative verbs are know, believe, desire, and love. A number of syntactic tests have been proposed to distinguish between statives and non-statives (again see Dowty, 1979). For example, stative verbs are anomalous when used in the progressive aspect and when modified by rate adverbs such as quickly and slowly: (1) a. * Jon is knowing calculus b. * Jon knows calculus quickly Perception verbs like see and hear share with statives a strong resistance to the progressive aspect, but not to rate adverbs:</context>
</contexts>
<marker>1965</marker>
<rawString>[Lakoff, 19651 G. Lakoff. On the Nature of Syntactic Irregularity. PhD thesis, Indiana University, 1965. Published by Holt, Rinhard, and Winston as Irregularity in Syntax, 1970.</rawString>
</citation>
<citation valid="true">
<title>Automatically extracting and representing collocations for language generation.</title>
<date>1990</date>
<booktitle>In 28th Annual Meeting of the Association for Comp. Ling.,</booktitle>
<pages>252--259</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="2974" citStr="(1990)" startWordPosition="463" endWordPosition="463">onaries, while Zernik and Dyer (1987) discuss tutored learning in a controlled environment. But any method that requires explicit human intervention — be it that of lexicographers, knowledge engineers, or &amp;quot;tutors&amp;quot; — will lag behind both the growth of vocabulary and the growth of linguistics, and even with the lag their maintenance will be expensive. By contrast, dictionaries constructed by automated learners from real sentences will not lag behind vocabulary growth; examples of current language use are free and nearly infinite. These observations have led Several researchers, including Hindle (1990) and Smadja and McKeown (1990), to begin investigating automatic acquisition of semantics. Hindle and Smadja and McKeown rely purely on the ability of one particular word to statistically predict the occurrence of another in a particular position. In contrast, the approach described here is targeted at particular semantic classes that are revealed by specific linguistic constructions. 2 The Questions This section discusses work on two linguistic cues that reveal the availability of non-stative senses for verbs. This work attempts to determine the difficulty of using the cues to classify verbs </context>
</contexts>
<marker>1990</marker>
<rawString>[Smadja and McKeown, 1990] F. Smadja and K. McKeown. Automatically extracting and representing collocations for language generation. In 28th Annual Meeting of the Association for Comp. Ling., pages 252-259. ACL, 1990.</rawString>
</citation>
<citation valid="true">
<title>The self-extending phrasal lexicon.</title>
<date>1987</date>
<journal>Comp. Ling.,</journal>
<volume>13</volume>
<issue>3</issue>
<contexts>
<context position="2302" citStr="(1987)" startWordPosition="361" endWordPosition="361">tic classifications of words. Ultimately, any artificial language &apos;The input sentences are those compiled in the Lancaster/Oslo/Bergen (LOB) Corpus, a balanced corpus of one million words of British English. The LOB consists primarily of edited prose. user must be able to add new words to its lexicon, if only to accommodate the many neologisms it will encounter. And our lexicographic needs grow with our understanding of language. A number of current approaches to satisfying the lexical requirements for artificial devices do not involve unsupervised learning from examples. Boguraev and Briscoe (1987) discusses interpreting the information published in on-line dictionaries, while Zernik and Dyer (1987) discuss tutored learning in a controlled environment. But any method that requires explicit human intervention — be it that of lexicographers, knowledge engineers, or &amp;quot;tutors&amp;quot; — will lag behind both the growth of vocabulary and the growth of linguistics, and even with the lag their maintenance will be expensive. By contrast, dictionaries constructed by automated learners from real sentences will not lag behind vocabulary growth; examples of current language use are free and nearly infinite. </context>
</contexts>
<marker>1987</marker>
<rawString>[Zernik and Dyer, 1987] U. Zernik and M. Dyer. The self-extending phrasal lexicon. Comp. Ling., 13(3), 1987.</rawString>
</citation>
<citation valid="false">
<pages>226</pages>
<marker></marker>
<rawString>- 226 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>