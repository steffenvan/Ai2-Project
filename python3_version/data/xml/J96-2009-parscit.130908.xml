<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.4490175">
Briefly Noted
Language and Learning for Robots
</title>
<bodyText confidence="0.99389070967742">
Colleen Crangle and Patrick Suppes
(Stanford University)
Stanford, CA: Center for the Study of
Learning and Information (CSLI lecture
notes 41), 1994, xxi+276 pp; distributed by
the University of Chicago Press; hardbound,
ISBN 1-881526-20-8, $49.95, £39.95;
paperbound, ISBN 1-881526-19-4, $21.95,
£17.50
In a career spanning five decades, Patrick
Suppes has pursued a unique approach to
the problems of language and learning. This
book, with Colleen Crangle, is a reprise of
much of the work on the philosophy of lan-
guage. As the title indicates, the underlying
model is of a robot that is to receive instruc-
tions (and later also instruction) in ordinary
language. The philosophizing is made con-
crete through software simulations and some
simple experiments with a physical robot. Al-
though much of the material has appeared
before, it is reworked into a cohesive whole.
Any attempt to deal with such deep issues
will involve simplifications, and it is instruc-
tive to follow the unfolding of complications.
The starting point is quite conventional; at-
tribute grammar with a semantics based on
formal logic. But the demands of the robot
domain quickly require the introduction of
functional semantics for perception and ac-
tion, which are not analyzed further, and
for control primitives. Task requirements also
push the authors to abandon the autonomy
of syntax and to give a major role to inten-
tionality, contextual readings, and the shared
perceptions of speaker and hearer. Thus they
are led to many of the core concerns of cog-
nitive semantics and this becomes explicit in
a chapter on geometry and spatial preposi-
tions. Traditional issues concerning negation
get extended in intriguing ways in the chap-
ter that considers what it means to ask a
robot to stop.
The work on learning is mostly recent, al-
though the theme goes back to Suppes&apos;s orig-
inal work in mathematical psychology. The
model has the robot choose parameters of ac-
tions (distance, etc.) from probability distri-
butions that get modified by verbal feedback.
The final chapter describes on-going work
on the learning of natural language from ex-
amples in the robot domain. By postulating
pre-existing internal structures for each ut-
terance, the problem is reduced to statisti-
cally associating surface forms with internal
constructs. This problem is analyzed theoret-
ically and on a small corpus. As in the rest
of the book, the work is idiosyncratic. But
anyone with a deep interest in the philoso-
phy of language can benefit from following
the progression of ideas on some of its most
fundamental issues.—Jerome A. Feldman, Inter-
</bodyText>
<note confidence="0.275731">
national Computer Science Institute, Berkeley
</note>
<title confidence="0.441121">
Semantics: Defining the Discipline
</title>
<author confidence="0.421713">
Robert A. Hipkiss
</author>
<affiliation confidence="0.650002">
(California State University Long Beach)
Mahwah, NJ: Lawrence Erlbaum Associates,
</affiliation>
<bodyText confidence="0.960757212121212">
1995, xvii+123 pp; hardbound, ISBN
0-8058-2026-4, $29.95; paperbound, ISBN
0-8058-1593-7, $17.50
This short book is meant to introduce the dis-
cipline of semantics, which Hipkiss believes
ought to be recognized as sui generis and
not a component of linguistics, philosophy,
psychology, or anything else. Nevertheless,
he reveals a linguistic bias by defining se-
mantics as &amp;quot;the study of word meanings&amp;quot;
(p. 107). To create an insightful, usable intro-
ductory semantics text of a mere 130 pages
(introduction and 10 chapters) would be a
masterstroke. It is very difficult to write an
introductory text of any length for a wide-
ranging topic like semantics (in contrast with
set theory or predicate calculus). The book
begins with gusto, and moves from Plato
to Wittgenstein within three pages, touches
some aspects of linguistic semantics, and
ends with a paean to Korzybski&apos;s general
semantics—an ideological position on mean-
ing in language that current theoretical se-
mantics largely (and properly) ignores. There
are too many significant gaps and factual er-
rors for this book to be acceptable; I felt I
was reading an essay by an enthusiastic un-
dergraduate with many flashes of common
sense but too little learning.
Some examples of naive and misleading or
incorrect statements, and failure to discuss
important matters arising will ground these
criticisms:
</bodyText>
<listItem confidence="0.978694">
• Chapter 8 asks &amp;quot;Is there a semantics
for Al?&amp;quot; and answers &amp;quot;Al is showing that
the computer is far more than a mechanical
</listItem>
<page confidence="0.987726">
277
</page>
<note confidence="0.418975">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.994460285714286">
memory. It can learn and conceptualize. It
can relate those concepts to language. It can,
then, give semantic content to the words in
its memory. This is a limited semantics, how-
ever, for it has, at best, a limited intentional-
ity&amp;quot; (p. 96). I wish my computer could con-
ceptualize!
</bodyText>
<listItem confidence="0.885180211764706">
• &amp;quot;[F]eature analysis selection [is] the fa-
vorite subject of Fillmore and other case-
grammarians&amp;quot; (p. xv). (?!)
• &amp;quot;Kripke (1980) sees the Morning and
Evening Star as the same, contra Russell and
Frege, but that is because he looks at the ob-
ject by itself as though continually observed,
not at it in its contexts in different manifes-
tations&amp;quot; (p. 30).
• Hipkiss espouses Wittgenstein&apos;s mean-
ing-as-use theory without discussing its ram-
ifications, and implies that a semanticist re-
quires no special training: &amp;quot;Ultimately we are
forced to do what the lexicographers do, lis-
ten, read, and learn how words are actually
used, in order to know what they mean to
different people. The more we read and listen
and practice different modes of discourse at
various levels of abstraction the more finely
tuned we become to the possible meanings
of different words in different contexts. There
is no substitute for that experience, although
our dictionaries, to some extent, abridge that
experience for us&amp;quot; (p. 107).
• Common sense leads Hipkiss astray:
&amp;quot;Normally, we would not run through all the
dictionary meanings of verb and noun when
we see a word, for we have already been lim-
ited in our search by the context of the sen-
tence&amp;quot; (p. 69). In fact, all senses are activated
and then inappropriate ones suppressed—
see Gernsbacher (1990) and references cited
there.
• The claim that &amp;quot;propositions are, by defi-
nition, true statements&amp;quot; (p. xiii) needs discus-
sion in an introductory textbook; at worst it
makes a mockery of propositional logic, and
at best should lead to discussion of what is
meant by a true versus a false statement.
• It is incorrect that around 1970 Jerrold
Katz &amp;quot;developed in his generative semantics
a system of semantic marking that explained,
to some degree, the mental process of se-
lecting various words and word order as we
speak and read&amp;quot; (p. xiv). Katz was never a
generative semanticist and although he once
believed he was defining semantic compe-
tence in Chomsky&apos;s sense, and later the se-
mantics of an abstract system, he specifically
eschewed performance and processing mod-
els (see Katz 1966, 1972, 1981).
• Erroneous is: &amp;quot;Wierzbicka (1991) created
a pragmatics dictionary of English verbs&amp;quot;
(p. 39). The correct reference is Wierzbicka
1987, and it presents the senses of speech act
verbs, rather than their pragmatics.
• Chapters 1-3 discuss conceptualization,
subjective awareness, and relative truth,
while dismissing &amp;quot;logic&amp;quot; as a means of ac-
counting for these important aspects of se-
mantics. Although Hipkiss writes &amp;quot;words ...
are symbols for concepts arrived at through
experience&amp;quot; (p. 2), there is no discussion of
cognitive or conceptual semantics.
• An insufficient grasp of logic seems to lie
behind a number of statements in this book—
for example, the discussion of quantification
and the definite article (p. 16), and &amp;quot;were
truth-conditional semantics to incorporate
the possible and the probable, it would not
have been such a narrow incursion into the
worlds of language and thought&amp;quot; (p. 26).
Hipkiss claims that possible-worlds seman-
tics is needed, but contrasts it with truth-con-
ditional semantics, thus ignoring its truth-
conditional basis. Nowhere is model-theoret-
ic semantics so much as mentioned.
• There is far too little discussion or ex-
planation in this book. For example, cases
(thematic roles) are listed without exposition
(p. 63). Chapter 9 lists titles of papers in Etc.,
the flagship journal of general semantics, but
there is almost no discussion of them, nor
any comparison of general semantics with
theories of semantic structure and relations.
</listItem>
<bodyText confidence="0.994487166666667">
Such infelicities are just a sample. This is a
book that should be approached with caution
by anyone with a limited (or no) knowledge
of semantics. True, no book is perfect, but too
much of this one is either misleading or just
plain wrong.—Keith Allan, Monash University
</bodyText>
<sectionHeader confidence="0.980439" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.9529523">
Gernsbacher, Morton Ann. 1990. Language
Comprehension as Structure Building.
Hillsdale, NJ: Lawrence Erlbaum.
Katz, Jerrold J. 1966. The Philosophy of
Language. New York: Harper and Row.
Katz, Jerrold J. 1972. Semantic Theory. New
York: Harper and Row.
Katz, Jerrold J. 1981. Language and Other
Abstract Objects. Totowa: Rowman and
Littlefield.
</reference>
<page confidence="0.995623">
278
</page>
<bodyText confidence="0.401493333333333">
Briefly Noted
Kripke, Saul. 1980. Naming and Necessity.
Oxford: Blackwell.
</bodyText>
<listItem confidence="0.312859166666667">
Wierzbicka, Anna. 1987. English Speech Act
Verbs: A Semantic Dictionary. Sydney:
Academic Press.
Wierzbicka, Anna. 1991. Cross-cultural
Pragmatics: The Semantics of Human
Interaction. Berlin: Mouton de Gruyter.
</listItem>
<subsectionHeader confidence="0.461468">
Reasoning about Knowledge
</subsectionHeader>
<bodyText confidence="0.951924364864865">
Ronald Fagin, Joseph Y. Halpern, Yoram
Moses, and Moshe &apos;Y. Vardi
(IBM Almaden Research Center, IBM Almaden
Research Center, Weizmann Institute of Sci-
ence, and Rice University)
Cambridge, MA: The MIT Press, 1995,
xiii+477 pp; hardbound, ISBN 0-262-06162-7,
$45.00
Reasoning about knowledge is concerned
with answering questions like: &amp;quot;What do I /
you / we know?&amp;quot;, &amp;quot;What do I / you / we not
know?&amp;quot;, and &amp;quot;Do I / you / we know enough
to....&amp;quot; Reasoning about knowledge under-
lies all of human communication, as commu-
nication is an attempt to make someone else
know (or believe) something. Further, com-
munication depends on what the participants
know about each other&apos;s knowledge. Rea-
soning about knowledge is also of interest
in cryptography, theory of economics, game
theory, philosophy, and general artificial in-
telligence.
The book Reasoning about Knowledge ana-
lyzes reasoning about knowledge held by
groups of agents. (The book uses this
currently-overused term, so I will too.) The
authors are among the foremost experts in
the area and are responsible for many of the
recent advances in reasoning about knowl-
edge.
Reasoning about Knowledge emphasizes per-
fect reasoning, which is not appropriate for
actual human linguistic systems, but an un-
derstanding of the simpler, perfect reasoning
case is needed, in my opinion, as a precur-
sor to the more complex, limited or imper-
fect reasoning case, and the book does de-
vote considerable space to some formal mod-
els of the limited or imperfect reasoning case.
(Whether formal treatments of the more com-
plex case are appropriate is a separate matter;
even if you think such formal methods are
garbage, it is generally a good idea to know
something about rival camps.)
The book presents the formal underpin-
nings of reasoning about knowledge. It cov-
ers the defining of several varieties of multi-
agent systems, which are systems composed
of several agents that perform actions and
use reasoning about knowledge or, perhaps,
just act like they do or can profitably be an-
alyzed as such. The book discusses common
knowledge and its relationship to agreement,
including the paradox that common knowl-
edge is needed for agreement but is essen-
tially impossible to achieve. The book men-
tions some of the problems with logical om-
niscience and presents some formal systems
that are not logically omniscient.
There are many examples in the book that
make its content much easier to understand.
The book is primarily written for use in
courses, but would be useful for anyone with
an interest in reasoning about knowledge
and with some background in formal logic.
It contains many exercises suitable for class-
room use or self-study.
In summary, this is an extremely well-
written book that covers a subject that is im-
portant to computational linguistics. I rec-
ommend it for anyone interested in situa-
tions that occur when one agent must rea-
son about the knowledge of another.—Peter
F. Patel-Schneider, AT&amp;T Research
</bodyText>
<sectionHeader confidence="0.972154" genericHeader="keywords">
Empirical Methods for Artificial Intel-
ligence
</sectionHeader>
<subsectionHeader confidence="0.875986">
Paul R. Cohen
</subsectionHeader>
<bodyText confidence="0.975042176470588">
(University of Massachusetts)
Cambridge, MA: The MIT Press, 1995,
xvi+405 pp; hardbound, ISBN 0-262-03225-2,
$55.00
Paul Cohen has written a remarkable and
valuable guidebook for those doing empiri-
cal research in artificial intelligence and other
computational fields. This book differs in fla-
vor from those devoted to experimental de-
sign or statistical methods in that all tech-
niques are set firmly within motivated, com-
pelling discussions of the scientific method
and how it can be properly applied when
the object of study is a complex computer
program.
The book is organized as a progres-
sion through the experimental process, and
</bodyText>
<page confidence="0.986235">
279
</page>
<note confidence="0.614454">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.985291450980392">
brings together, in clear, approachable prose,
discussions of research methodology, ex-
ploratory data analysis, experimental de-
sign, hypothesis-testing tools (traditional and
computer-intensive), causal modeling of sys-
tem behavior, and techniques for generaliz-
ing from data and analyses. Examples and
case studies are abundant, drawing most
heavily from real experiments in compu-
tational linguistics, machine learning, and
planning.
Throughout the book, strategies for how
to design and understand the experimental
tasks are foremost; statistics are treated as
tools for achieving these ends. For example,
topics such as analysis of variance and fac-
torial design, which are chapter headings in
many texts, are discussed here in the context
of how to explain system performance.
Computational linguists should be aware
that despite its title, this book contains little
discussion of probability, multidimensional
scaling, learning algorithms, and other topics
that are important for corpus-based language
analysis but not necessarily for experimen-
tal design. Additionally, readers not familiar
with Al should be warned that the book con-
tains some AI-centric examples whose moti-
vation is not well-explained, as well as fre-
quent references to debates within Al on
how to conduct and evaluate experiments.
Another potential drawback, if one wishes
to use this book as an instructional text, is
the lack of practice problems. However, one
could exercise the concepts learned by hav-
ing students attempt to apply them to pub-
lished research papers. The book begins at an
introductory level, assuming no background
in statistics, and although it develops many
advanced techniques, once this material is
mastered, supplementary references may be
required (and Cohen usually supplies rele-
vant pointers).
One could argue that there is no need for
such a book, given the legions of existing ex-
positions on scientific methodology and ex-
perimental design. However, Empirical Meth-
ods for Artificial Intelligence is useful not only
because it is targeted at a computational au-
dience, whose training so frequently and un-
fortunately does not include basic research
methodology, but also because it presents the
material in a clear, useful, modern, and invit-
ing manner.—Marti A. Hearst, Xerox Palo Alto
Research Center
Applied Logic: How, What and Why.
Logical Approaches to Natural Lan-
guage
Laszlo Polos and Michael Masuch (editors)
(Centre for Computer Science in Organiza-
tion and Management, University of Amster-
dam)
Dordrecht: Kluwer Academic Publishers
(Synthese Library, edited by Jaakko
Hintikka, volume 247), 1995, viii+392 pp;
hardbound, ISBN 0-7923-3432-9, $115.00,
£74.00, Dfl 175.00
This book arises from the first Conferencel on
Applied Logic organized in December 1992
in Amsterdam by the Centre for Computer
Science in Organization and Management
and the Institute for Logic, Language, and In-
formation. The collection contains 13 papers
that were classified by the program commit-
tee as belonging to the area of &amp;quot;Applications
of logic to the study of natural language.&amp;quot;2
The editorial preface is extremely brief. No
overview, comparative summary, or evalua-
tion of the contribution of the individual pa-
pers is provided.
I would call the papers thin on data and
heavy on theory. Only a few briefly ad-
dress computability. The authors appear to
be much more concerned and familiar with
logic than with natural language. Two pa-
pers, &amp;quot;Optimization of deduction for multi-
modal logics&amp;quot; by Olivier Gasquet and &amp;quot;Im-
plicit and explicit definability in modal and
temporal logics&amp;quot; by Larisa Maksimova, do
not discuss any data and do not contain any
discussion about natural language whatso-
ever. Only one paper, &amp;quot;Dynamic aspect trees&amp;quot;
by Jerry Seligman and Alice ter Meulen, dis-
cusses some real-looking data (although its
source is not indicated), including a multi-
paragraph text.
Reading and understanding such ex-
tremely formal, long papers (all but one be-
tween 20 and 40 pages), is not an easy task,
even for one accustomed to formal theories.
The papers are journal-like—many report on
mature research—but they do not appear to
</bodyText>
<footnote confidence="0.94285">
1 The editors also use the term workshop when
referring to this meeting.
2 The other two topic areas were &amp;quot;Computer
science applications of logic&amp;quot; and &amp;quot;Algebraic
applications.&amp;quot;
</footnote>
<page confidence="0.995765">
280
</page>
<bodyText confidence="0.996588538461539">
Briefly Noted
have undergone a rigorous journal-like re-
view.
The reader is often left wondering whether
the ideas presented are new or whether they
were reported elsewhere. Sometimes simple-
to-fix stylistic problems, such as claims
buried toward the end of the paper, signif-
icantly obscure the presentation. The omis-
sion of some very relevant references is often
apparent, with few references to the work
outside Europe.3 For example, the paper
&amp;quot;Are types needed for natural language?&amp;quot;
by Fairouz Kamareddine, surprisingly does
not reference Keenan and Faltz (1985). Many
papers discuss dynamic characteristics of
their formalisms. The word dynamic here
refers to step-by-step text interpretation ac-
companied by appropriate updates of in-
formation obtained from the text seen thus
far. It would be interesting to know how
these dynamic logics differ from some exist-
ing formal frameworks for processing nat-
ural language that view understanding of
natural language as the process of knowl-
edge update. It would also be interesting to
know how these dynamic logics differ from
the knowledge representation formalisms,
including belief-revision systems, that have
been proposed over the last decade in artifi-
cial intelligence.
While I liked fragments of many papers,
I was generally not convinced by the argu-
ments in support of the claimed advantages
of the formalisms and even less so about
their relevance or criticality for processing
natural language.
My recommendations are as follows. I
would not recommend this book to the gen-
eral computational linguistics audience. Re-
searchers who are concerned with handling
large volumes of real linguistic data are
highly unlikely to benefit from theories mo-
tivated by such artificial, toy examples as
those discussed in this book. More-formally
inclined researchers will probably find only
selected papers to be of interest. I would rec-
ommend this book to those unfamiliar with
European research on applied logic; 14 out of
18 authors are affiliated with European insti-
tutions and their research provides a good
sample. I would also recommend this book
</bodyText>
<footnote confidence="0.937944333333333">
3 It is only fair to note that many American
researchers are similarly guilty of largely
ignoring European results.
</footnote>
<bodyText confidence="0.999922636363636">
as a source of logical formalisms with some
relevance to natural language. While one&apos;s
chances of learning about results of immedi-
ate interest are small, there is a great oppor-
tunity to extend one&apos;s horizon. For example,
this book has greatly improved my limited
knowledge of Situation Theory.4 Similarly, re-
searchers not familiar with the theory of pro-
gramming languages can learn some com-
mon themes in the semantics of program-
ming and natural languages.—Lucja
</bodyText>
<affiliation confidence="0.471861">
Wayne State University
</affiliation>
<reference confidence="0.607293">
Reference
Keenan, Edward L. and Leonard M. Faltz.
1985. Boolean Semantics for Natural Language.
Dordrecht: D. Reidel.
</reference>
<sectionHeader confidence="0.4518765" genericHeader="method">
HORATIO: A Middle-sized NLP Appli-
cation in Prolog
</sectionHeader>
<bodyText confidence="0.925347733333333">
Archibal Michiels
(Universite de Liege)
Liege: Department of English, Universite de
Liege, 198 pp and diskette; paperbound,
ISBN 2-87233-0154, BEF 700
[Available from: L3, Dept of English,
Universite de Liege, place Cockerill 3,
B-4000, Liege, Belgium, fax +32-41-665721;
add BEF 50 for postage outside Belgium.]
HORATIO is a moderately-wide-coverage En-
glish parser developed in Arity Prolog on
a PC and based on Michael McCord&apos;s slot
grammars. Its output includes explicit gram-
matical relations such as subject and ob-
ject, and some lexical disambiguation is per-
formed by using argument properties such
as human and abstract. Performance is re-
spectable; on my 66-MHz 486, each sentence
in the test suite took no more than a few
seconds, including complex sentences such
as Devito manages a programmer Abrams inter-
viewed and Browne hired.
Noteworthy features of HORATIO include a
lexicon derived (by the awk program) from
an on-line version of the Longman Dictionary
of Contemporary English; a parsing technique
4 Which is not to say that I like this theory. It
appears to offer very little for representing
meaning of natural language sentences
involving general negation.
</bodyText>
<page confidence="0.986604">
281
</page>
<note confidence="0.688014">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.999122736842105">
that avoids looping on coordinate structures;
provisions for idioms with different degrees
of syntactic opacity; a mechanism to handle
word-order variation; and a generation facil-
ity.
The book documents HORATIO in detail:
&amp;quot;No pseudo-code is given. No piece of code
is presented in a simplified form. Cited code
always corresponds exactly to the runnable
code to be found on the companion disk&amp;quot;
(p. 5).&apos;
The diskette does indeed contain the
source code, executables, and test suite, en-
tire. The user can verity that HORATIO works
as advertised, give it additional sentences to
parse, and use it as the basis of further work
(taking due note of the copyright, of course).
Porting from Arity Prolog to other im-
plementations should be straightforward.—
</bodyText>
<affiliation confidence="0.569084">
Michael A. Covington, University of Georgia
</affiliation>
<sectionHeader confidence="0.850363" genericHeader="method">
Language Industries Atlas
</sectionHeader>
<bodyText confidence="0.981178807692308">
Paul M. Hearn and Diana F. Button
(editors)
(INK-Belgium)
Amsterdam: IOS Press, 1994, xviii+406 pp;
hardbound, ISBN 90-5199-148-7, no price
listed
&amp;quot;The aim of our study has been to de-
scribe the activities of the many organisa-
tions, both public and private, that create
the infrastructure within which languages
are able to develop and interact on equal
terms in multilingual Europe. Although de-
velopments in the United States and Japan
have been mentioned, we have been inter-
ested primarily in describing activities in the
European Community....
&amp;quot;The Language Industries Atlas will be of in-
terest to a broad spectrum of language pro-
fessionals including translators, interpreters,
terminologists, teachers, computational lin-
guists, researchers and public and private or-
ganisations, and indeed to anyone interested
in languages, from a planning, standards, in-
frastructural or technological perspective.
&amp;quot;The Atlas contains more than 1,000 de-
scriptions of activities which play a role in
</bodyText>
<footnote confidence="0.6691625">
1 The code may also be downloaded free of
charge from http://engdepl.philo.ulg.ac.be.
</footnote>
<bodyText confidence="0.99690775">
shaping the language industries, whether
from a user or provider perspective.... [It]
has been compiled from a questionnaire and
telephone survey carried out over the past
12 months.... Where information was not
provided from our survey, we have supple-
mented this from our own records.&amp;quot;—From
the introduction
</bodyText>
<sectionHeader confidence="0.620557" genericHeader="method">
Text Encoding Initiative: Background
and Context
</sectionHeader>
<reference confidence="0.929952272727273">
Nancy Ide and Jean Veronis (editors)
(Vassar College and CNRS and Universitd de
Provence)
[Reprinted from Computers and the
Humanities, volume 29, numbers 1, 2, and 3,
1995.]
Dordrecht: Kluwer Academic Publishers,
1995, vi+242 pp; hardbound, ISBN
0-7923-3689-5, $99.00, £60.00, Dfl 145.00
&amp;quot;The Text Encoding Initiative Guidelines for
Electronic Text Encoding and Interchange.
</reference>
<bodyText confidence="0.999041612903226">
known familiarly as TEl P3 , appeared in
May 1994. The Guidelines are the result of
over six years&apos; work by dozens of scholars
from all over the world who were involved
in TEl working groups, providing their con-
clusions concerning the optimal way to con-
sistently and comprehensively encode a vast
range of text types and features. As such,
TEl P3 represents a pioneer effort in an area
where only occasional and isolated attempts
had been made before, and will certainly
serve as the primary basis for encoding texts
in electronic form for the foreseeable future.
&amp;quot;There is a compelling reason for collect-
ing this series of papers. The TEl is a pio-
neering effort; the TEl working groups were
the first to comprehensively address the sub-
stantial intellectual problem of representing
textual data in electronic form. They were
faced with a vast array of new problems: it
became immediately apparent that the devel-
opment of a text encoding scheme demanded
much more than assigning tag names to fea-
tures, and included looking at the concep-
tual structure of texts and determining the
commonalities across different text types. It
also demanded finding the most consistent
and effective ways to encode texts using
the Standard Generalized Markup Language
(SGML), which provides only the fundamen-
tal machinery for marking texts and provides
</bodyText>
<page confidence="0.987493">
282
</page>
<bodyText confidence="0.977871866666667">
Briefly Noted
for many alternative means to encode texts.
Therefore, the work of participants in the TEl
not only involved consideration of problems
of text encoding that are likely to be with
us for decades to come, but also required the
development of a methodology, from scratch,
for approaching these problems. These pio-
neering efforts, while likely to be refined and
extended, should not be lost; they provide
the intellectual basis upon which text encod-
ing practices will build in the future. This
collection is therefore also an attempt to doc-
ument the course of these efforts.&amp;quot;—From the
publisher&apos;s announcement
</bodyText>
<sectionHeader confidence="0.9408635" genericHeader="method">
Elements of Acoustic Phonetics (second
edition)
</sectionHeader>
<subsectionHeader confidence="0.924299">
Peter Ladefoged
</subsectionHeader>
<bodyText confidence="0.99275196875">
(University of California, Los Angeles)
Chicago: The University of Chicago Press,
1996, viii+216 pp; hardbound, ISBN
0-226-46763-5, $39.95, 01.95; paperbound,
ISBN 0-226-46764-3, $14.95, £11.95
&amp;quot;This revised and expanded edition of a clas-
sic [1962] textbook provides a concise intro-
duction to basic concepts of acoustics and
digital speech processing that are important
to linguists, phoneticians, and speech scien-
tists. The second edition includes four new
chapters that cover new experimental tech-
niques in acoustic phonetics made possible
by the use of computers. Assuming no back-
ground in physics or mathematics, Lade-
foged explains concepts that must be under-
stood in using modern laboratory techniques
for acoustic analysis, including resonances of
the vocal tract and the relation of formants
to different cavities; digital speech process-
ing and computer storage of sound waves;
and Fourier analysis and Linear Predictive
Coding, the equations used most frequently
in the analysis of speech sounds. Incorporat-
ing recent developments in our knowledge
of the nature of speech, Ladefoged also up-
dates the original edition&apos;s discussion of the
basic properties of sound waves; variations
in loudness, pitch, and quality of speech
sounds; wave analysis; and the hearing and
production of speech.&amp;quot;—From the publisher&apos;s
announcement
</bodyText>
<page confidence="0.997934">
283
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.234739">
<title confidence="0.998074">Briefly Noted Language and Learning for Robots</title>
<author confidence="0.951816">Colleen Crangle</author>
<author confidence="0.951816">Patrick Suppes</author>
<affiliation confidence="0.987804">(Stanford University)</affiliation>
<address confidence="0.739423">Stanford, CA: Center for the Study of</address>
<abstract confidence="0.904477708333333">Learning and Information (CSLI lecture notes 41), 1994, xxi+276 pp; distributed by the University of Chicago Press; hardbound, ISBN 1-881526-20-8, $49.95, £39.95; paperbound, ISBN 1-881526-19-4, $21.95, £17.50 In a career spanning five decades, Patrick Suppes has pursued a unique approach to the problems of language and learning. This book, with Colleen Crangle, is a reprise of much of the work on the philosophy of language. As the title indicates, the underlying model is of a robot that is to receive instructions (and later also instruction) in ordinary language. The philosophizing is made concrete through software simulations and some simple experiments with a physical robot. Although much of the material has appeared before, it is reworked into a cohesive whole. Any attempt to deal with such deep issues will involve simplifications, and it is instructive to follow the unfolding of complications. The starting point is quite conventional; attribute grammar with a semantics based on</abstract>
<intro confidence="0.557969">formal logic. But the demands of the robot</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Morton Ann Gernsbacher</author>
</authors>
<title>Language Comprehension as Structure Building.</title>
<date>1990</date>
<location>Hillsdale, NJ: Lawrence Erlbaum.</location>
<contexts>
<context position="5950" citStr="Gernsbacher (1990)" startWordPosition="968" endWordPosition="969">ctice different modes of discourse at various levels of abstraction the more finely tuned we become to the possible meanings of different words in different contexts. There is no substitute for that experience, although our dictionaries, to some extent, abridge that experience for us&amp;quot; (p. 107). • Common sense leads Hipkiss astray: &amp;quot;Normally, we would not run through all the dictionary meanings of verb and noun when we see a word, for we have already been limited in our search by the context of the sentence&amp;quot; (p. 69). In fact, all senses are activated and then inappropriate ones suppressed— see Gernsbacher (1990) and references cited there. • The claim that &amp;quot;propositions are, by definition, true statements&amp;quot; (p. xiii) needs discussion in an introductory textbook; at worst it makes a mockery of propositional logic, and at best should lead to discussion of what is meant by a true versus a false statement. • It is incorrect that around 1970 Jerrold Katz &amp;quot;developed in his generative semantics a system of semantic marking that explained, to some degree, the mental process of selecting various words and word order as we speak and read&amp;quot; (p. xiv). Katz was never a generative semanticist and although he once be</context>
</contexts>
<marker>Gernsbacher, 1990</marker>
<rawString>Gernsbacher, Morton Ann. 1990. Language Comprehension as Structure Building. Hillsdale, NJ: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
</authors>
<title>The Philosophy of Language.</title>
<date>1966</date>
<location>New York: Harper and Row.</location>
<contexts>
<context position="6733" citStr="Katz 1966" startWordPosition="1101" endWordPosition="1102">ockery of propositional logic, and at best should lead to discussion of what is meant by a true versus a false statement. • It is incorrect that around 1970 Jerrold Katz &amp;quot;developed in his generative semantics a system of semantic marking that explained, to some degree, the mental process of selecting various words and word order as we speak and read&amp;quot; (p. xiv). Katz was never a generative semanticist and although he once believed he was defining semantic competence in Chomsky&apos;s sense, and later the semantics of an abstract system, he specifically eschewed performance and processing models (see Katz 1966, 1972, 1981). • Erroneous is: &amp;quot;Wierzbicka (1991) created a pragmatics dictionary of English verbs&amp;quot; (p. 39). The correct reference is Wierzbicka 1987, and it presents the senses of speech act verbs, rather than their pragmatics. • Chapters 1-3 discuss conceptualization, subjective awareness, and relative truth, while dismissing &amp;quot;logic&amp;quot; as a means of accounting for these important aspects of semantics. Although Hipkiss writes &amp;quot;words ... are symbols for concepts arrived at through experience&amp;quot; (p. 2), there is no discussion of cognitive or conceptual semantics. • An insufficient grasp of logic se</context>
</contexts>
<marker>Katz, 1966</marker>
<rawString>Katz, Jerrold J. 1966. The Philosophy of Language. New York: Harper and Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
</authors>
<title>Semantic Theory.</title>
<date>1972</date>
<location>New York: Harper and Row.</location>
<marker>Katz, 1972</marker>
<rawString>Katz, Jerrold J. 1972. Semantic Theory. New York: Harper and Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
</authors>
<title>Language and Other Abstract Objects.</title>
<date>1981</date>
<location>Totowa: Rowman and Littlefield.</location>
<marker>Katz, 1981</marker>
<rawString>Katz, Jerrold J. 1981. Language and Other Abstract Objects. Totowa: Rowman and Littlefield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward L Keenan</author>
<author>Leonard M Faltz</author>
</authors>
<title>Boolean Semantics for Natural Language.</title>
<date>1985</date>
<location>Dordrecht: D. Reidel.</location>
<marker>Keenan, Faltz, 1985</marker>
<rawString>Keenan, Edward L. and Leonard M. Faltz. 1985. Boolean Semantics for Natural Language. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="false">
<booktitle>College and CNRS and Universitd de Provence</booktitle>
<editor>Nancy Ide and Jean Veronis (editors) (Vassar</editor>
<marker></marker>
<rawString>Nancy Ide and Jean Veronis (editors) (Vassar College and CNRS and Universitd de Provence)</rawString>
</citation>
<citation valid="true">
<date>1995</date>
<booktitle>Reprinted from Computers and the Humanities,</booktitle>
<volume>29</volume>
<marker>1995</marker>
<rawString>[Reprinted from Computers and the Humanities, volume 29, numbers 1, 2, and 3, 1995.]</rawString>
</citation>
<citation valid="false">
<date>1995</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht:</location>
<note>vi+242 pp; hardbound, ISBN 0-7923-3689-5, $99.00, £60.00, Dfl 145.00</note>
<marker>1995</marker>
<rawString>Dordrecht: Kluwer Academic Publishers, 1995, vi+242 pp; hardbound, ISBN 0-7923-3689-5, $99.00, £60.00, Dfl 145.00</rawString>
</citation>
<citation valid="false">
<title>The Text Encoding Initiative Guidelines for Electronic Text Encoding and Interchange.</title>
<marker></marker>
<rawString>&amp;quot;The Text Encoding Initiative Guidelines for Electronic Text Encoding and Interchange.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>