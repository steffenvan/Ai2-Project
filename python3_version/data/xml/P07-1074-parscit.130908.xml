<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.999744">
A Seed-driven Bottom-up Machine Learning Framework
for Extracting Relations of Various Complexity
</title>
<author confidence="0.991329">
Feiyu Xu, Hans Uszkoreit and Hong Li
</author>
<affiliation confidence="0.979923">
Language Technology Lab, DFKI GmbH
</affiliation>
<address confidence="0.956565">
Stuhlsatzenhausweg 3, D-66123 Saarbruecken
</address>
<email confidence="0.999131">
{feiyu,uszkoreit,hongli}@dfki.de
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999944">
A minimally supervised machine learning
framework is described for extracting rela-
tions of various complexity. Bootstrapping
starts from a small set of n-ary relation in-
stances as “seeds”, in order to automati-
cally learn pattern rules from parsed data,
which then can extract new instances of the
relation and its projections. We propose a
novel rule representation enabling the
composition of n-ary relation rules on top
of the rules for projections of the relation.
The compositional approach to rule con-
struction is supported by a bottom-up pat-
tern extraction method. In comparison to
other automatic approaches, our rules can-
not only localize relation arguments but
also assign their exact target argument
roles. The method is evaluated in two
tasks: the extraction of Nobel Prize awards
and management succession events. Perfor-
mance for the new Nobel Prize task is
strong. For the management succession
task the results compare favorably with
those of existing pattern acquisition ap-
proaches.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999732833333333">
Information extraction (IE) has the task to discover
n-tuples of relevant items (entities) belonging to an
n-ary relation in natural language documents. One
of the central goals of the ACE program1 is to de-
velop a more systematically grounded approach to
IE starting from elementary entities, binary rela-
</bodyText>
<footnote confidence="0.84043">
1 http://projects.ldc.upenn.edu/ace/
</footnote>
<bodyText confidence="0.999710269230769">
tions to n-ary relations such as events. Current
semi- or unsupervised approaches to automatic
pattern acquisition are either limited to a certain
linguistic representation (e.g., subject-verb-object),
or only deal with binary relations, or cannot assign
slot filler roles to the extracted arguments, or do
not have good selection and filtering methods to
handle the large number of tree patterns (Riloff,
1996; Agichtein and Gravano, 2000; Yangarber,
2003; Sudo et al., 2003; Greenwood and Stevenson,
2006; Stevenson and Greenwood, 2006). Most of
these approaches do not consider the linguistic in-
teraction between relations and their projections on
k dimensional subspaces where 1≤k&lt;n, which is
important for scalability and reusability of rules.
Stevenson and Greenwood (2006) present a sys-
tematic investigation of the pattern representation
models and point out that substructures of the lin-
guistic representation and the access to the embed-
ded structures are important for obtaining a good
coverage of the pattern acquisition. However, all
considered representation models (subject-verb-
object, chain model, linked chain model and sub-
tree model) are verb-centered. Relations embedded
in non-verb constructions such as a compound
noun cannot be discovered:
</bodyText>
<listItem confidence="0.7368765">
(1) the 2005 Nobel Peace Prize
(1) describes a ternary relation referring to three
</listItem>
<bodyText confidence="0.987866888888889">
properties of a prize: year, area and prize name.
We also observe that the automatically acquired
patterns in Riloff (1996), Yangarber (2003), Sudo
et al. (2003), Greenwood and Stevenson (2006)
cannot be directly used as relation extraction rules
because the relation-specific argument role infor-
mation is missing. E.g., in the management succes-
sion domain that concerns the identification of job
changing events, a person can either move into a
</bodyText>
<page confidence="0.976496">
584
</page>
<note confidence="0.9164">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 584–591,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.863961666666667">
job (called Person_In) or leave a job (called Per-
son_Out). (2) is a simplified example of patterns
extracted by these systems:
</bodyText>
<listItem confidence="0.630145">
(2) &lt;subject: person&gt; verb &lt;object:organisation&gt;
</listItem>
<bodyText confidence="0.999931905660378">
In (2), there is no further specification of whether
the person entity in the subject position is Per-
son_In or Person_Out.
The ambitious goal of our approach is to provide
a general framework for the extraction of relations
and events with various complexity. Within this
framework, the IE system learns extraction pat-
terns automatically and induces rules of various
complexity systematically, starting from sample
relation instances as seeds. The arity of the seed
determines the complexity of extracted relations.
The seed helps us to identify the explicit linguistic
expressions containing mentionings of relation in-
stances or instances of their k-ary projections
where 1≤k&lt;n. Because our seed samples are not
linguistic patterns, the learning system is not re-
stricted to a particular linguistic representation and
is therefore suitable for various linguistic analysis
methods and representation formats. The pattern
discovery is bottom-up and compositional, i.e.,
complex patterns can build on top of simple pat-
terns for projections.
We propose a rule representation that supports
this strategy. Therefore, our learning approach is
seed-driven and bottom-up. Here we use depend-
ency trees as input for pattern extraction. We con-
sider only trees or their subtrees containing seed
arguments. Therefore, our method is much more
efficient than the subtree model of Sudo et al.,
(2003), where all subtrees containing verbs are
taken into account. Our pattern rule ranking and
filtering method considers two aspects of a pattern:
its domain relevance and the trustworthiness of its
origin. We tested our framework in two domains:
Nobel Prize awards and management succession.
Evaluations have been conducted to investigate the
performance with respect to the seed parameters:
the number of seeds and the influence of data size
and its redundancy property. The whole system
has been evaluated for the two domains consider-
ing precision and recall. We utilize the evaluation
strategy “Ideal Matrix” of Agichtein and Gravano
(2000) to deal with unannotated test data.
The remainder of the paper is organised as fol-
lows: Section 2 provides an overview of the system
architecture. Section 3 discusses the rule represen-
tation. In Section 4, a detailed description of the
seed-driven bottom-up pattern acquisition is pre-
sented. Section 5 describes our experiments with
pattern ranking, filtering and rule induction. Sec-
tion 6 presents the experiments and evaluations for
the two application domains. Section 7 provides a
conclusion and an outline of future work.
</bodyText>
<sectionHeader confidence="0.92833" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.99714">
Given the framework, our system architecture
can be depicted as follows:
</bodyText>
<figureCaption confidence="0.99792">
Figure 1. Architecture
</figureCaption>
<bodyText confidence="0.999752346153846">
This architecture has been inspired by several
existing seed-oriented minimally supervised ma-
chine learning systems, in particular by Snowball
(Agichtein and Gravano, 2000) and ExDisco
(Yangarber et al., 2000). We call our system
DARE, standing for “Domain Adaptive Relation
Extraction based on Seeds”. DARE contains four
major components: linguistic annotation, classifier,
rule learning and relation extraction. The first com-
ponent only applies once, while the last three com-
ponents are integrated in a bootstrapping loop. At
each iteration, rules will be learned based on the
seed and then new relation instances will be ex-
tracted by applying the learned rules. The new re-
lation instances are then used as seeds for the next
iteration of the learning cycle. The cycle termi-
nates when no new relations can be acquired.
The linguistic annotation is responsible for en-
riching the natural language texts with linguistic
information such as named entities and depend-
ency structures. In our framework, the depth of the
linguistic annotation can be varied depending on
the domain and the available resources.
The classifier has the task to deliver relevant
paragraphs and sentences that contain seed ele-
ments. It has three subcomponents: document re-
</bodyText>
<page confidence="0.997554">
585
</page>
<bodyText confidence="0.999974592592593">
trieval, paragraph retrieval and sentence retrieval.
The document retrieval component utilizes the
open source IR-system Lucene2. A translation step
is built in to convert the seed into the proper IR
query format. As explained in Xu et al. (2006), we
generate all possible lexical variants of the seed
arguments to boost the retrieval coverage and for-
mulate a boolean query where the arguments are
connected via conjunction and the lexical variants
are associated via disjunction. However, the trans-
lation could be modified. The task of paragraph
retrieval is to find text snippets from the relevant
documents where the seed relation arguments co-
occur. Given the paragraphs, a sentence containing
at least two arguments of a seed relation will be
regarded as relevant.
As mentioned above, the rule learning compo-
nent constitutes the core of our system. It identifies
patterns from the annotated documents inducing
extraction rules from the patterns, and validates
them. In section 4, we will give a detailed expla-
nation of this component.
The relation extraction component applies the
newly learned rules to the relevant documents and
extracts relation instances. The validated relation
instances will then be used as new seeds for the
next iteration.
</bodyText>
<sectionHeader confidence="0.995567" genericHeader="method">
3 DARE Rule Representation
</sectionHeader>
<bodyText confidence="0.999502230769231">
Our rule representation is designed to specify the
location and the role of the arguments w.r.t. the
target relation in a linguistic construction. In our
framework, the rules should not be restricted to a
particular linguistic representation and should be
adaptable to various NLP tools on demand. A
DARE rule is allowed to call further DARE rules
that extract a subset of the arguments. Let us step
through some example rules for the prize award
domain. One of the target relations in the domain is
about a person who obtains a special prize in a cer-
tain area in a certain year, namely, a quaternary
tuple, see (3). (4) is a domain relevant sentence.
</bodyText>
<listItem confidence="0.997065666666667">
(3) &lt;recipient, prize, area, year&gt;
(4) Mohamed ElBaradei won the 2005 Nobel
Peace Prize on Friday for his efforts to limit the
spread of atomic weapons.
(5) is a rule that extracts a ternary projection in-
stance &lt;prize, area, year&gt; from a noun phrase
</listItem>
<footnote confidence="0.586924">
2 http://www.lucene.de
</footnote>
<bodyText confidence="0.897449428571428">
compound, while (6) is a rule which triggers (5) in
its object argument and extracts all four arguments.
(5) and (6) are useful rules for extracting argu-
ments from (4).
(5)
Next we provide a definition of a DARE rule:
A DARE rule has three components
</bodyText>
<listItem confidence="0.9992394">
1. rule name: rZ;
2. output: a set A containing the n arguments
of the n-ary relation, labelled with their ar-
gument roles;
3. rule body in AVM format containing:
</listItem>
<bodyText confidence="0.980747714285714">
- specific linguistic labels or attributes
(e.g., subject, object, head, mod), de-
rived from the linguistic analysis, e.g.,
dependency structures and the named en-
tity information
- rule: its value is a DARE rule which ex-
tracts a subset of arguments of A
The rule in (6) is a typical DARE rule. Its sub-
ject and object descriptions call appropriate DARE
rules that extract a subset of the output relation
arguments. The advantages of this rule representa-
tion strategy are that (1) it supports the bottom-up
rule composition; (2) it is expressive enough for
the representation of rules of various complexity;
(3) it reflects the precise linguistic relationship
among the relation arguments and reduces the
template merging task in the later phase; (4) the
rules for the subset of arguments may be reused for
other relation extraction tasks.
The rule representation models for automatic or
unsupervised pattern rule extraction discussed by
</bodyText>
<equation confidence="0.473142">
(6)
</equation>
<page confidence="0.989952">
586
</page>
<bodyText confidence="0.9965495">
Stevenson and Greenwood (2006) do not account
for these considerations.
</bodyText>
<sectionHeader confidence="0.952801" genericHeader="method">
4 Seed-driven Bottom-up Rule Learning
</sectionHeader>
<bodyText confidence="0.999985342857142">
Two main approaches to seed construction have
been discussed in the literature: pattern-oriented
(e.g., ExDisco) and semantics-oriented (e.g.,
Snowball) strategies. The pattern-oriented method
suffers from poor coverage because it makes the IE
task too dependent on one linguistic representation
construction (e.g., subject-verb-object) and has
moreover ignored the fact that semantic relations
and events could be dispersed over different sub-
structures of the linguistic representation. In prac-
tice, several tuples extracted by different patterns
can contribute to one complex relation instance.
The semantics-oriented method uses relation in-
stances as seeds. It can easily be adapted to all re-
lation/event instances. The complexity of the target
relation is not restricted by the expressiveness of
the seed pattern representation. In Brin (1998) and
Agichtein and Gravano (2000), the semantics-
oriented methods have proved to be effective in
learning patterns for some general binary relations
such as booktitle-author and company-headquarter
relations. In Xu et al. (2006), the authors show that
at least for the investigated task it is more effective
to start with the most complex relation instance,
namely, with an n-ary sample for the target n-ary
relation as seed, because the seed arguments are
often centred in a relevant textual snippet where
the relation is mentioned. Given the bottom-up
extracted patterns, the task of the rule induction is
to cluster and generalize the patterns. In compari-
son to the bottom-up rule induction strategy (Califf
and Mooney, 2004), our method works also in a
compositional way. For reasons of space this part
of the work will be reported in Xu and Uszkoreit
(forthcoming).
</bodyText>
<subsectionHeader confidence="0.981222">
4.1 Pattern Extraction
</subsectionHeader>
<bodyText confidence="0.999652833333333">
Pattern extraction in DARE aims to find linguistic
patterns which do not only trigger the relations but
also locate the relation arguments. In DARE, the
patterns can be extracted from a phrase, a clause or
a sentence, depending on the location and the dis-
tribution of the seed relation arguments.
</bodyText>
<figureCaption confidence="0.955633666666667">
Figure 2. Pattern extraction step 1
Figure 3. Pattern extraction step 2
Figures 2 and 3 depict the general steps of bot-
tom-up pattern extraction from a dependency tree t
where three seed arguments arg1, arg2 and arg3 are
located. All arguments are assigned their relation
roles r1, r2 and r3. The pattern-relevant subtrees are
trees in which seed arguments are embedded: t1, t2
and t3. Their root nodes are n1, n2 and n3. Figure 2
</figureCaption>
<bodyText confidence="0.876665">
shows the extraction of a unary pattern n2_r3_i,
while Figure 3 illustrates the further extraction and
construction of a binary pattern n1_r1_r2_j and a
ternary pattern n3_r1_r2_r3_k. In practice, not all
branches in the subtrees will be kept. In the follow-
ing, we give a general definition of our seed-driven
bottom-up pattern extraction algorithm:
input: (i) relation = &lt;r1, r2, ..., rn&gt;: the target rela-
tion tuple with n argument roles.
T: a set of linguistic analysis trees anno-
tated with i seed relation arguments (1&lt;i&lt;n)
output: P: a set of pattern instances which can ex-
tract i or a subset of i arguments.
</bodyText>
<subsectionHeader confidence="0.184276">
Pattern extraction:
</subsectionHeader>
<bodyText confidence="0.606036">
for each tree t ∈T
</bodyText>
<page confidence="0.98442">
587
</page>
<tableCaption confidence="0.427927">
Step 1: (depicted in Figure 2)
</tableCaption>
<listItem confidence="0.984370541666667">
1. replace all terminal nodes that are instanti-
ated with the seed arguments by new
nodes. Label these new nodes with the
seed argument roles and possibly the cor-
responding entity classes;
2. identify the set of the lowest nonterminal
nodes N1 in t that dominate only one ar-
gument (possibly among other nodes).
3. substitute N1 by nodes labelled with the
seed argument roles and their entity classes
4. prune the subtrees dominated by N1 from t
and add these subtrees into P. These sub-
trees are assigned the argument role infor-
mation and a unique id.
Step2: For i=2 to n: (depicted in Figure 3)
1. find the set of the lowest nodes N1 in t that
dominate in addition to other children only
i seed arguments;
2. substitute N1 by nodes labelled with the i
seed argument role combination informa-
tion (e.g., ri_rj) and with a unique id.
3. prune the subtrees Ti dominated by Ni in t;
4. add Ti to P together with the argument role
combination information and the unique id
</listItem>
<bodyText confidence="0.988663">
With this approach, we can learn rules like (6) in
a straightforward way.
</bodyText>
<subsectionHeader confidence="0.98229">
4.2 Rule Validation: Ranking and Filtering
</subsectionHeader>
<bodyText confidence="0.99993075">
Our ranking strategy has incorporated the ideas
proposed by Riloff (1996), Agichtein and Gravano
(2000), Yangarber (2003) and Sudo et al. (2003).
We take two properties of a pattern into account:
</bodyText>
<listItem confidence="0.9981612">
• domain relevance: its distribution in the rele-
vant documents and irrelevant documents
(documents in other domains);
• trustworthiness of its origin: the relevance
score of the seeds from which it is extracted.
</listItem>
<bodyText confidence="0.940042777777778">
In Riloff (1996) and Sudo et al. (2003), the rele-
vance of a pattern is mainly dependent on its oc-
currences in the relevant documents vs. the whole
corpus. Relevant patterns with lower frequencies
cannot float to the top. It is known that some com-
plex patterns are relevant even if they have low
occurrence rates. We propose a new method for
calculating the domain relevance of a pattern. We
assume that the domain relevance of a pattern is
dependent on the relevance of the lexical terms
(words or collocations) constructing the pattern,
e.g., the domain relevance of (5) and (6) are de-
pendent on the terms “prize” and “win” respec-
tively. Given n different domains, the domain rele-
vance score (DR) of a term t in a domain di is:
DR(t, di)=
0, if df(t, di) =0;
where
</bodyText>
<listItem confidence="0.9998945">
• df(t, di): is the document frequency of a
term t in the domain di
• D: the number of the documents in di
• N: the total number of the terms in di
</listItem>
<bodyText confidence="0.9999160625">
Here the domain relevance of a term is dependent
both on its document frequency and its document
frequency distribution in other domains. Terms
mentioned by more documents within the domain
than outside are more relevant (Xu et al., 2002).
In the case of n=3 such different domains might
be, e.g., management succession, book review or
biomedical texts. Every domain corpus should ide-
ally have the same number of documents and simi-
lar average document size. In the calculation of the
trustworthiness of the origin, we follow Agichtein
and Gravano (2000) and Yangarber (2003). Thus,
the relevance of a pattern is dependent on the rele-
vance of its terms and the score value of the most
trustworthy seed from which it origins. Finally, the
score of a pattern p is calculated as follows:
</bodyText>
<equation confidence="0.995521">
score(p)= ∑ DR(ti ) × max{ ( ) :
score s s Seeds
∈ }
0
</equation>
<bodyText confidence="0.998835">
where |T|&gt; 0 and ti ∈ T
</bodyText>
<listItem confidence="0.9998535">
• T: is the set of the terms occur in p;
• Seeds: a set of seeds from which the pat-
tern is extracted;
• score(s): is the score of the seed s;
</listItem>
<bodyText confidence="0.999777833333333">
This relevance score is not dependent on the distri-
bution frequency of a pattern in the domain corpus.
Therefore, patterns with lower frequency, in par-
ticular, some complex patterns, can be ranked
higher when they contain relevant domain terms or
come from reliable seeds.
</bodyText>
<equation confidence="0.938873818181818">
T
df(t,di)
N×D
×LOG(
n× df(t,di)
), otherwise
n
∑df(t,dj)
j=1
i
=
</equation>
<page confidence="0.990885">
588
</page>
<bodyText confidence="0.99997275">
The extracted instances can be used as potential
seeds for the further pattern extraction iteration,
when their scores are validated. The initial seeds
obtain 1 as their score.
</bodyText>
<sectionHeader confidence="0.998175" genericHeader="evaluation">
6 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.98814275">
We apply our framework to two application do-
mains: Nobel Prize awards and management suc-
cession events. Table 1 gives an overview of our
test data sets.
</bodyText>
<table confidence="0.999014">
Data Set Name Doc Number Data Amount
Nobel Prize A (1999-2005) 2296 12,6 MB
Nobel Prize B (1981-1998) 1032 5,8 MB
MUC-6 199 1 MB
</table>
<tableCaption confidence="0.940556">
Table1. Overview of Test Data Sets.
</tableCaption>
<bodyText confidence="0.9777973125">
For the Nobel Prize award scenario, we use two
test data sets with different sizes: Nobel Prize A
and Nobel Prize B. They are Nobel Prize related
articles from New York Times, online BBC and
CNN news reports. The target relation for the ex-
periment is a quaternary relation as mentioned in
(3), repeated here again:
&lt;recipient, prize, area, year&gt;
Our test data is not annotated with target rela-
tion instances. However, the entire list of Nobel
Prize award events is available for the evaluation
from the Nobel Prize official website3. We use it as
our reference relation database for building our
Ideal table (Agichtein and Gravano, 2000).
For the management succession scenario, we use
the test data from MUC-6 (MUC-6, 1995) and de-
</bodyText>
<footnote confidence="0.754706">
3 http://nobelprize.org/
</footnote>
<bodyText confidence="0.9684105">
fine a simpler relation structure than the MUC-6
scenario template with four arguments:
</bodyText>
<subsubsectionHeader confidence="0.834864">
&lt;Person_In, Person_Out, Position, Organisation&gt;
</subsubsectionHeader>
<bodyText confidence="0.999478">
In the following tables, we use PI for Person_In,
PO for Person_Out, POS for Position and ORG for
Organisation. In our experiments, we attempt to
investigate the influence of the size of the seed and
the size of the test data on the performance. All
these documents are processed by named entity
recognition (Drozdzynski et al., 2004) and depend-
ency parser MINIPAR (Lin, 1998).
</bodyText>
<subsectionHeader confidence="0.998075">
6.1 Nobel Prize Domain Evaluation
</subsectionHeader>
<bodyText confidence="0.999942576923077">
For this domain, three test runs have been evalu-
ated, initialized by one randomly selected relation
instance as seed each time. In the first run, we use
the largest test data set Nobel Prize A. In the sec-
ond and third runs, we have compared two random
selected seed samples with 50% of the data each,
namely Nobel Prize B. For data sets in this do-
main, we are faced with an evaluation challenge
pointed out by DIPRE (Brin, 1998) and Snowball
(Agichtein and Gravano, 2000), because there is no
gold-standard evaluation corpus available. We
have adapted the evaluation method suggested by
Agichtein and Gravano, i.e., our system is success-
ful if we capture one mentioning of a Nobel Prize
winner event through one instance of the relation
tuple or its projections. We constructed two tables
(named Ideal) reflecting an approximation of the
maximal detectable relation instances: one for No-
bel Prize A and another for Nobel Prize B. The
Ideal tables contain the Nobel Prize winners that
co-occur with the word “Nobel” in the test corpus.
Then precision is the correctness of the extracted
relation instances, while recall is the coverage of
the extracted tuples that match with the Ideal table.
In Table 2 we show the precision and recall of the
three runs and their random seed sample:
</bodyText>
<table confidence="0.999556666666667">
Data Seed Preci- Recall
Set sion
total time interval
Nobel [Zewail, Ahmed H], 71,6% 50,7% 70,9%
Prize A nobel, chemistry,1999 (1999-2005)
Nobel [Sen, Amartya], no- 87,3% 31% 43%
Prize B bel, economics, 1998 (1981-1998)
Nobel [Arias, Oscar], 83,8% 32% 45%
Prize B nobel, peace, 1987 (1981-1998)
</table>
<tableCaption confidence="0.999834">
Table 2. Precision, Recall against the Ideal Table
</tableCaption>
<bodyText confidence="0.964691375">
The first experiment with the full test data has
achieved much higher recall than the two experi-
ments with the set Nobel Prize B. The two experi-
ments with the Nobel Prize B corpus show similar
5 Top down Rule Application
After the acquisition of pattern rules, the DARE
system applies these rules to the linguistically an-
notated corpus. The rule selection strategy moves
from complex to simple. It first matches the most
complex pattern to the analyzed sentence in order
to extract the maximal number of relation argu-
ments. According to the duality principle (Yangar-
ber 2001), the score of the new extracted relation
instance S is dependent on the patterns from which
it origins. Our score method is a simplified version
of that defined by Agichtein and Gravano (2000):
</bodyText>
<equation confidence="0.9504615">
P
score(S)=1− (1− score(Pi )
∏ )
i=0
</equation>
<bodyText confidence="0.546944">
where P={Pi} is the set of patterns that extract S.
</bodyText>
<page confidence="0.996037">
589
</page>
<figureCaption confidence="0.958857">
Figure 6. Experiment with Nobel Prize A
</figureCaption>
<subsectionHeader confidence="0.997169">
6.2 Management Succession Domain
</subsectionHeader>
<bodyText confidence="0.999120555555555">
The MUC-6 corpus is much smaller than the Nobel
Prize corpus. Since the gold standard of the target
relations is available, we use the standard IE preci-
sion and recall method. The total gold standard
table contains 256 event instances, from which we
randomly select seeds for our experiments. Table 3
gives an overview of performance of the experi-
ments. Our tests vary between one seed, 20 seeds
and 55 seeds.
</bodyText>
<table confidence="0.9994968">
Initial Seed Nr. Precision Recall
1 A 12.6% 7.0%
B 15.1% 21.8%
20 48.4% 34.2%
55 62.0% 48.0%
</table>
<tableCaption confidence="0.997965">
Table 3. Results for various initial seed sets
</tableCaption>
<bodyText confidence="0.997305375">
The first two one-seed tests achieved poor per-
formance. With 55 seeds, we can extract additional
67 instances to obtain the half size of the instances
occurring in the corpus. Table 4 show evaluations
of the single arguments. B works a little better be-
cause the randomly selected single seed appears a
better sample for finding the pattern for extracting
PI argument.
</bodyText>
<table confidence="0.9926115">
Arg precision precision Recall Recall
(A) (B) (A) (B)
PI 10.9% 15.1% 8.6% 34.4%
PO 28.6% - 2.3% 2.3%
ORG 25.6% 100% 2.6% 2.6%
POS 11.2% 11.2% 5.5% 5.5%
</table>
<tableCaption confidence="0.999884">
Table 4. Evaluation of one-seed tests (A and B)
</tableCaption>
<bodyText confidence="0.97712875">
Table 5 shows the performance with 20 and 55
seeds respectively. Both of them are better than the
one-seed tests, while 55 seeds deliver the best per-
formance in average, in particular, the recall value.
</bodyText>
<table confidence="0.994981">
arg precision precision recall recall
(20) (55) (20) (55)
PI 84% 62.8% 27.9% 56.1%
PO 41.2% 59% 34.2% 31.2%
ORG 82.4% 58.2% 7.4% 20.2%
POS 42% 64.8% 25.6% 30.6%
</table>
<tableCaption confidence="0.999807">
Table 5. Evaluation of 20 and 55 seeds tests
</tableCaption>
<bodyText confidence="0.999955">
Our result with 20 seeds (precision of 48.4% and
recall of 34.2%) is comparable with the best result
reported by Greenwood and Stevenson (2006) with
the linked chain model (precision of 0.434 and re-
call of 0.265). Since the latter model uses patterns
as seeds, applying a similarity measure for pattern
ranking, a fair comparison is not possible. Our re-
sult is not restricted to binary relations and our
model also assigns the exact argument role to the
Person role, i.e. Person_In or Person_Out.
We have also evaluated the top 100 event-
independent binary relations such as Person-
Organisation and Position-Organisation. The preci-
sion of these by-product relations of our IE system
is above 98%.
</bodyText>
<sectionHeader confidence="0.996312" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999952833333333">
Several parameters are relevant for the success
of a seed-based bootstrapping approach to relation
extraction. One of these is the arity of the relation.
Another one is the locality of the relation instance
in an average mentioning. A third one is the types
of the relation arguments: Are they named entities
in the classical sense? Are they lexically marked?
Are there several arguments of the same type?
Both tasks we explored involved extracting quater-
nary relations. The Nobel Prize domain shows bet-
ter lexical marking because of the prize name. The
management succession domain has two slots of
the same NE type, i.e., persons. These differences
are relevant for any relation extraction approach.
The success of the bootstrapping approach cru-
cially depends on the nature of the training data
base. One of the most relevant properties of this
data base is the ratio of documents to relation in-
stances. Several independent reports of an instance
usually yield a higher number of patterns.
The two tasks we used to investigate our method
drastically differ in this respect. The Nobel Prize
performance. All three experiments have better
recalls when taking only the relation instances dur-
ing the report years into account, because there are
more mentionings during these years in the corpus.
Figure (6) depicts the pattern learning and new
seed extracting behavior during the iterations for
the first experiment. Similar behaviours are ob-
served in the other two experiments.
</bodyText>
<page confidence="0.986185">
590
</page>
<bodyText confidence="0.999969365853659">
domain we selected as a learning domain for gen-
eral award events since it exhibits a high degree of
redundancy in reporting. A Nobel Prize triggers
more news reports than most other prizes. The
achieved results met our expectations. With one
randomly selected seed, we could finally extract
most relevant events in some covered time interval.
However, it turns out that it is not just the aver-
age number of reports per events that matters but
also the distribution of reportings to events. Since
the Nobel prizes data exhibit a certain type of
skewed distribution, the graph exhibits properties
of scale-free graphs. The distances between events
are shortened to a few steps. Therefore, we can
reach most events in a few iterations. The situation
is different for the management succession task
where the reports came from a single newspaper.
The ratio of events to reports is close to one. This
lack of informational redundancy requires a higher
number of seeds. When we started the bootstrap-
ping with a single event, the results were rather
poor. Going up to twenty seeds, we still did not
get the performance we obtain in the Nobel Prize
task but our results compare favorably to the per-
formance of existing bootstrapping methods.
The conclusion, we draw from the observed dif-
ference between the two tasks is simple: We shall
always try to find a highly redundant training data
set. If at all possible, the training data should ex-
hibit a skewed distribution of reports to events.
Actually, such training data may be the only realis-
tic chance for reaching a large number of rare pat-
terns. In future work we will try to exploit the web
as training resource for acquiring patterns while
using the parsed domain data as the source for ob-
taining new seeds in bootstrapping the rules before
applying these to any other nonredundant docu-
ment base. This is possible because our seed tu-
ples can be translated into simple IR queries and
further linguistic processing is limited to the re-
trieved candidate documents.
</bodyText>
<sectionHeader confidence="0.985223" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999882666666667">
The presented research was partially supported by a
grant from the German Federal Ministry of Education
and Research to the project Hylap (FKZ: 01IWF02) and
EU–funding for the project RASCALLI. Our special
thanks go to Doug Appelt and an anonymous reviewer
for their thorough and highly valuable comments.
</bodyText>
<sectionHeader confidence="0.998444" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99976706">
E. Agichtein and L. Gravano. 2000. Snowball: extract-
ing relations from large plain-text collections. In
ACM 2000, pages 85–94, Texas, USA.
S. Brin. Extracting patterns and relations from the
World-Wide Web. In Proc. 1998 Int&apos;l Workshop on
the Web and Databases (WebDB &apos;98), March 1998.
M. E. Califf and R. J. Mooney. 2004. Bottom-Up Rela-
tional Learning of Pattern Matching Rules for Infor-
mation Extraction. Journal of Machine Learning Re-
search, MIT Press.
W. Drozdzynski, H.-U.Krieger, J. Piskorski; U. Schä-
fer, and F. Xu. 2004. Shallow Processing with Unifi-
cation and Typed Feature Structures — Foundations
and Applications. Künstliche Intelligenz 1:17—23.
M. A. Greenwood and M. Stevenson. 2006. Improving
Semi-supervised Acquisition of Relation Extraction
Patterns. In Proc. of the Workshop on Information
Extraction Beyond the Document, Australia.
D. Lin. 1998. Dependency-based evaluation of MINI-
PAR. In Workshop on the Evaluation of Parsing Sys-
tems, Granada, Spain.
MUC. 1995. Proceedings of the Sixth Message Under-
standing Conference (MUC-6), Morgan Kaufmann.
E. Riloff. 1996. Automatically Generating Extraction
Patterns from Untagged Text. In Proc. of the Thir-
teenth National Conference on Articial Intelligence,
pages 1044–1049, Portland, OR, August.
M. Stevenson and Mark A. Greenwood. 2006. Compar-
ing Information Extraction Pattern Models. In Proc.
of the Workshop on Information Extraction Beyond
the Document, Sydney, Australia.
K. Sudo, S. Sekine, and R. Grishman. 2003. An Im-
proved Extraction Pattern Representation Model for
Automatic IE Pattern Acquisition. In Proc. of ACL-
03, pages 224–231, Sapporo, Japan.
R. Yangarber, R. Grishman, P. Tapanainen, and S. Hut-
tunen. 2000. Automatic Acquisition of Domain
Knowledge for Information Extraction. In Proc. of
COLING 2000, Saarbrücken, Germany.
R. Yangarber. 2003. Counter-training in the Discovery
of Semantic Patterns. In Proceedings of ACL-03,
pages 343–350, Sapporo, Japan.
F. Xu, D. Kurz, J. Piskorski and S. Schmeier. 2002. A
Domain Adaptive Approach to Automatic Acquisition
of Domain Relevant Terms and their Relations with
Bootstrapping. In Proc. of LREC 2002, May 2002.
F. Xu, H. Uszkoreit and H. Li. 2006. Automatic Event
and Relation Detection with Seeds of Varying Com-
plexity. In Proceedings of AAAI 2006 Workshop
Event Extraction and Synthesis, Boston, July, 2006.
</reference>
<page confidence="0.998107">
591
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.775884">
<title confidence="0.9983365">A Seed-driven Bottom-up Machine Learning Framework for Extracting Relations of Various Complexity</title>
<author confidence="0.995977">Feiyu Xu</author>
<author confidence="0.995977">Hans Uszkoreit</author>
<author confidence="0.995977">Hong Li</author>
<affiliation confidence="0.995845">Language Technology Lab, DFKI GmbH</affiliation>
<address confidence="0.930165">Stuhlsatzenhausweg 3, D-66123 Saarbruecken</address>
<email confidence="0.988038">feiyu@dfki.de</email>
<email confidence="0.988038">uszkoreit@dfki.de</email>
<email confidence="0.988038">hongli@dfki.de</email>
<abstract confidence="0.994085461538461">A minimally supervised machine learning framework is described for extracting relations of various complexity. Bootstrapping starts from a small set of n-ary relation instances as “seeds”, in order to automatically learn pattern rules from parsed data, which then can extract new instances of the relation and its projections. We propose a novel rule representation enabling the composition of n-ary relation rules on top of the rules for projections of the relation. The compositional approach to rule construction is supported by a bottom-up pattern extraction method. In comparison to other automatic approaches, our rules cannot only localize relation arguments but also assign their exact target argument roles. The method is evaluated in two tasks: the extraction of Nobel Prize awards and management succession events. Performance for the new Nobel Prize task is strong. For the management succession task the results compare favorably with those of existing pattern acquisition approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In ACM 2000,</booktitle>
<pages>85--94</pages>
<location>Texas, USA.</location>
<contexts>
<context position="2048" citStr="Agichtein and Gravano, 2000" startWordPosition="299" endWordPosition="302">One of the central goals of the ACE program1 is to develop a more systematically grounded approach to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the pattern acquisition. However</context>
<context position="5789" citStr="Agichtein and Gravano (2000)" startWordPosition="861" endWordPosition="864">ubtrees containing verbs are taken into account. Our pattern rule ranking and filtering method considers two aspects of a pattern: its domain relevance and the trustworthiness of its origin. We tested our framework in two domains: Nobel Prize awards and management succession. Evaluations have been conducted to investigate the performance with respect to the seed parameters: the number of seeds and the influence of data size and its redundancy property. The whole system has been evaluated for the two domains considering precision and recall. We utilize the evaluation strategy “Ideal Matrix” of Agichtein and Gravano (2000) to deal with unannotated test data. The remainder of the paper is organised as follows: Section 2 provides an overview of the system architecture. Section 3 discusses the rule representation. In Section 4, a detailed description of the seed-driven bottom-up pattern acquisition is presented. Section 5 describes our experiments with pattern ranking, filtering and rule induction. Section 6 presents the experiments and evaluations for the two application domains. Section 7 provides a conclusion and an outline of future work. 2 System Architecture Given the framework, our system architecture can b</context>
<context position="12234" citStr="Agichtein and Gravano (2000)" startWordPosition="1885" endWordPosition="1888"> dependent on one linguistic representation construction (e.g., subject-verb-object) and has moreover ignored the fact that semantic relations and events could be dispersed over different substructures of the linguistic representation. In practice, several tuples extracted by different patterns can contribute to one complex relation instance. The semantics-oriented method uses relation instances as seeds. It can easily be adapted to all relation/event instances. The complexity of the target relation is not restricted by the expressiveness of the seed pattern representation. In Brin (1998) and Agichtein and Gravano (2000), the semanticsoriented methods have proved to be effective in learning patterns for some general binary relations such as booktitle-author and company-headquarter relations. In Xu et al. (2006), the authors show that at least for the investigated task it is more effective to start with the most complex relation instance, namely, with an n-ary sample for the target n-ary relation as seed, because the seed arguments are often centred in a relevant textual snippet where the relation is mentioned. Given the bottom-up extracted patterns, the task of the rule induction is to cluster and generalize </context>
<context position="15695" citStr="Agichtein and Gravano (2000)" startWordPosition="2478" endWordPosition="2481">or i=2 to n: (depicted in Figure 3) 1. find the set of the lowest nodes N1 in t that dominate in addition to other children only i seed arguments; 2. substitute N1 by nodes labelled with the i seed argument role combination information (e.g., ri_rj) and with a unique id. 3. prune the subtrees Ti dominated by Ni in t; 4. add Ti to P together with the argument role combination information and the unique id With this approach, we can learn rules like (6) in a straightforward way. 4.2 Rule Validation: Ranking and Filtering Our ranking strategy has incorporated the ideas proposed by Riloff (1996), Agichtein and Gravano (2000), Yangarber (2003) and Sudo et al. (2003). We take two properties of a pattern into account: • domain relevance: its distribution in the relevant documents and irrelevant documents (documents in other domains); • trustworthiness of its origin: the relevance score of the seeds from which it is extracted. In Riloff (1996) and Sudo et al. (2003), the relevance of a pattern is mainly dependent on its occurrences in the relevant documents vs. the whole corpus. Relevant patterns with lower frequencies cannot float to the top. It is known that some complex patterns are relevant even if they have low </context>
<context position="17467" citStr="Agichtein and Gravano (2000)" startWordPosition="2790" endWordPosition="2793">the number of the documents in di • N: the total number of the terms in di Here the domain relevance of a term is dependent both on its document frequency and its document frequency distribution in other domains. Terms mentioned by more documents within the domain than outside are more relevant (Xu et al., 2002). In the case of n=3 such different domains might be, e.g., management succession, book review or biomedical texts. Every domain corpus should ideally have the same number of documents and similar average document size. In the calculation of the trustworthiness of the origin, we follow Agichtein and Gravano (2000) and Yangarber (2003). Thus, the relevance of a pattern is dependent on the relevance of its terms and the score value of the most trustworthy seed from which it origins. Finally, the score of a pattern p is calculated as follows: score(p)= ∑ DR(ti ) × max{ ( ) : score s s Seeds ∈ } 0 where |T|&gt; 0 and ti ∈ T • T: is the set of the terms occur in p; • Seeds: a set of seeds from which the pattern is extracted; • score(s): is the score of the seed s; This relevance score is not dependent on the distribution frequency of a pattern in the domain corpus. Therefore, patterns with lower frequency, in </context>
<context position="19423" citStr="Agichtein and Gravano, 2000" startWordPosition="3144" endWordPosition="3147">obel Prize award scenario, we use two test data sets with different sizes: Nobel Prize A and Nobel Prize B. They are Nobel Prize related articles from New York Times, online BBC and CNN news reports. The target relation for the experiment is a quaternary relation as mentioned in (3), repeated here again: &lt;recipient, prize, area, year&gt; Our test data is not annotated with target relation instances. However, the entire list of Nobel Prize award events is available for the evaluation from the Nobel Prize official website3. We use it as our reference relation database for building our Ideal table (Agichtein and Gravano, 2000). For the management succession scenario, we use the test data from MUC-6 (MUC-6, 1995) and de3 http://nobelprize.org/ fine a simpler relation structure than the MUC-6 scenario template with four arguments: &lt;Person_In, Person_Out, Position, Organisation&gt; In the following tables, we use PI for Person_In, PO for Person_Out, POS for Position and ORG for Organisation. In our experiments, we attempt to investigate the influence of the size of the seed and the size of the test data on the performance. All these documents are processed by named entity recognition (Drozdzynski et al., 2004) and depend</context>
<context position="22487" citStr="Agichtein and Gravano (2000)" startWordPosition="3653" endWordPosition="3656">periments with the Nobel Prize B corpus show similar 5 Top down Rule Application After the acquisition of pattern rules, the DARE system applies these rules to the linguistically annotated corpus. The rule selection strategy moves from complex to simple. It first matches the most complex pattern to the analyzed sentence in order to extract the maximal number of relation arguments. According to the duality principle (Yangarber 2001), the score of the new extracted relation instance S is dependent on the patterns from which it origins. Our score method is a simplified version of that defined by Agichtein and Gravano (2000): P score(S)=1− (1− score(Pi ) ∏ ) i=0 where P={Pi} is the set of patterns that extract S. 589 Figure 6. Experiment with Nobel Prize A 6.2 Management Succession Domain The MUC-6 corpus is much smaller than the Nobel Prize corpus. Since the gold standard of the target relations is available, we use the standard IE precision and recall method. The total gold standard table contains 256 event instances, from which we randomly select seeds for our experiments. Table 3 gives an overview of performance of the experiments. Our tests vary between one seed, 20 seeds and 55 seeds. Initial Seed Nr. Preci</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>E. Agichtein and L. Gravano. 2000. Snowball: extracting relations from large plain-text collections. In ACM 2000, pages 85–94, Texas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
</authors>
<title>Extracting patterns and relations from the World-Wide Web. In</title>
<date>1998</date>
<booktitle>Proc. 1998 Int&apos;l Workshop on the Web and Databases (WebDB &apos;98),</booktitle>
<contexts>
<context position="12201" citStr="Brin (1998)" startWordPosition="1882" endWordPosition="1883"> the IE task too dependent on one linguistic representation construction (e.g., subject-verb-object) and has moreover ignored the fact that semantic relations and events could be dispersed over different substructures of the linguistic representation. In practice, several tuples extracted by different patterns can contribute to one complex relation instance. The semantics-oriented method uses relation instances as seeds. It can easily be adapted to all relation/event instances. The complexity of the target relation is not restricted by the expressiveness of the seed pattern representation. In Brin (1998) and Agichtein and Gravano (2000), the semanticsoriented methods have proved to be effective in learning patterns for some general binary relations such as booktitle-author and company-headquarter relations. In Xu et al. (2006), the authors show that at least for the investigated task it is more effective to start with the most complex relation instance, namely, with an n-ary sample for the target n-ary relation as seed, because the seed arguments are often centred in a relevant textual snippet where the relation is mentioned. Given the bottom-up extracted patterns, the task of the rule induct</context>
<context position="20518" citStr="Brin, 1998" startWordPosition="3330" endWordPosition="3331">the performance. All these documents are processed by named entity recognition (Drozdzynski et al., 2004) and dependency parser MINIPAR (Lin, 1998). 6.1 Nobel Prize Domain Evaluation For this domain, three test runs have been evaluated, initialized by one randomly selected relation instance as seed each time. In the first run, we use the largest test data set Nobel Prize A. In the second and third runs, we have compared two random selected seed samples with 50% of the data each, namely Nobel Prize B. For data sets in this domain, we are faced with an evaluation challenge pointed out by DIPRE (Brin, 1998) and Snowball (Agichtein and Gravano, 2000), because there is no gold-standard evaluation corpus available. We have adapted the evaluation method suggested by Agichtein and Gravano, i.e., our system is successful if we capture one mentioning of a Nobel Prize winner event through one instance of the relation tuple or its projections. We constructed two tables (named Ideal) reflecting an approximation of the maximal detectable relation instances: one for Nobel Prize A and another for Nobel Prize B. The Ideal tables contain the Nobel Prize winners that co-occur with the word “Nobel” in the test c</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>S. Brin. Extracting patterns and relations from the World-Wide Web. In Proc. 1998 Int&apos;l Workshop on the Web and Databases (WebDB &apos;98), March 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Califf</author>
<author>R J Mooney</author>
</authors>
<title>Bottom-Up Relational Learning of Pattern Matching Rules for Information Extraction.</title>
<date>2004</date>
<journal>Journal of Machine Learning Research,</journal>
<publisher>MIT Press.</publisher>
<contexts>
<context position="12928" citStr="Califf and Mooney, 2004" startWordPosition="1995" endWordPosition="1998">g patterns for some general binary relations such as booktitle-author and company-headquarter relations. In Xu et al. (2006), the authors show that at least for the investigated task it is more effective to start with the most complex relation instance, namely, with an n-ary sample for the target n-ary relation as seed, because the seed arguments are often centred in a relevant textual snippet where the relation is mentioned. Given the bottom-up extracted patterns, the task of the rule induction is to cluster and generalize the patterns. In comparison to the bottom-up rule induction strategy (Califf and Mooney, 2004), our method works also in a compositional way. For reasons of space this part of the work will be reported in Xu and Uszkoreit (forthcoming). 4.1 Pattern Extraction Pattern extraction in DARE aims to find linguistic patterns which do not only trigger the relations but also locate the relation arguments. In DARE, the patterns can be extracted from a phrase, a clause or a sentence, depending on the location and the distribution of the seed relation arguments. Figure 2. Pattern extraction step 1 Figure 3. Pattern extraction step 2 Figures 2 and 3 depict the general steps of bottom-up pattern ext</context>
</contexts>
<marker>Califf, Mooney, 2004</marker>
<rawString>M. E. Califf and R. J. Mooney. 2004. Bottom-Up Relational Learning of Pattern Matching Rules for Information Extraction. Journal of Machine Learning Research, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Drozdzynski</author>
<author>J Piskorski H-U Krieger</author>
<author>U Schä-fer</author>
<author>F Xu</author>
</authors>
<date>2004</date>
<booktitle>Shallow Processing with Unification and Typed Feature Structures — Foundations and Applications. Künstliche Intelligenz</booktitle>
<pages>1--17</pages>
<contexts>
<context position="20012" citStr="Drozdzynski et al., 2004" startWordPosition="3236" endWordPosition="3239"> table (Agichtein and Gravano, 2000). For the management succession scenario, we use the test data from MUC-6 (MUC-6, 1995) and de3 http://nobelprize.org/ fine a simpler relation structure than the MUC-6 scenario template with four arguments: &lt;Person_In, Person_Out, Position, Organisation&gt; In the following tables, we use PI for Person_In, PO for Person_Out, POS for Position and ORG for Organisation. In our experiments, we attempt to investigate the influence of the size of the seed and the size of the test data on the performance. All these documents are processed by named entity recognition (Drozdzynski et al., 2004) and dependency parser MINIPAR (Lin, 1998). 6.1 Nobel Prize Domain Evaluation For this domain, three test runs have been evaluated, initialized by one randomly selected relation instance as seed each time. In the first run, we use the largest test data set Nobel Prize A. In the second and third runs, we have compared two random selected seed samples with 50% of the data each, namely Nobel Prize B. For data sets in this domain, we are faced with an evaluation challenge pointed out by DIPRE (Brin, 1998) and Snowball (Agichtein and Gravano, 2000), because there is no gold-standard evaluation corp</context>
</contexts>
<marker>Drozdzynski, Krieger, Schä-fer, Xu, 2004</marker>
<rawString>W. Drozdzynski, H.-U.Krieger, J. Piskorski; U. Schä-fer, and F. Xu. 2004. Shallow Processing with Unification and Typed Feature Structures — Foundations and Applications. Künstliche Intelligenz 1:17—23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Greenwood</author>
<author>M Stevenson</author>
</authors>
<title>Improving Semi-supervised Acquisition of Relation Extraction Patterns.</title>
<date>2006</date>
<booktitle>In Proc. of the Workshop on Information Extraction Beyond the Document,</booktitle>
<location>Australia.</location>
<contexts>
<context position="2115" citStr="Greenwood and Stevenson, 2006" startWordPosition="309" endWordPosition="312"> systematically grounded approach to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the pattern acquisition. However, all considered representation models (subject-verbobject, chain m</context>
<context position="24325" citStr="Greenwood and Stevenson (2006)" startWordPosition="3977" endWordPosition="3980">.6% POS 11.2% 11.2% 5.5% 5.5% Table 4. Evaluation of one-seed tests (A and B) Table 5 shows the performance with 20 and 55 seeds respectively. Both of them are better than the one-seed tests, while 55 seeds deliver the best performance in average, in particular, the recall value. arg precision precision recall recall (20) (55) (20) (55) PI 84% 62.8% 27.9% 56.1% PO 41.2% 59% 34.2% 31.2% ORG 82.4% 58.2% 7.4% 20.2% POS 42% 64.8% 25.6% 30.6% Table 5. Evaluation of 20 and 55 seeds tests Our result with 20 seeds (precision of 48.4% and recall of 34.2%) is comparable with the best result reported by Greenwood and Stevenson (2006) with the linked chain model (precision of 0.434 and recall of 0.265). Since the latter model uses patterns as seeds, applying a similarity measure for pattern ranking, a fair comparison is not possible. Our result is not restricted to binary relations and our model also assigns the exact argument role to the Person role, i.e. Person_In or Person_Out. We have also evaluated the top 100 eventindependent binary relations such as PersonOrganisation and Position-Organisation. The precision of these by-product relations of our IE system is above 98%. 7 Conclusion and Future Work Several parameters </context>
</contexts>
<marker>Greenwood, Stevenson, 2006</marker>
<rawString>M. A. Greenwood and M. Stevenson. 2006. Improving Semi-supervised Acquisition of Relation Extraction Patterns. In Proc. of the Workshop on Information Extraction Beyond the Document, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR.</title>
<date>1998</date>
<booktitle>In Workshop on the Evaluation of Parsing Systems,</booktitle>
<location>Granada,</location>
<contexts>
<context position="20054" citStr="Lin, 1998" startWordPosition="3245" endWordPosition="3246">succession scenario, we use the test data from MUC-6 (MUC-6, 1995) and de3 http://nobelprize.org/ fine a simpler relation structure than the MUC-6 scenario template with four arguments: &lt;Person_In, Person_Out, Position, Organisation&gt; In the following tables, we use PI for Person_In, PO for Person_Out, POS for Position and ORG for Organisation. In our experiments, we attempt to investigate the influence of the size of the seed and the size of the test data on the performance. All these documents are processed by named entity recognition (Drozdzynski et al., 2004) and dependency parser MINIPAR (Lin, 1998). 6.1 Nobel Prize Domain Evaluation For this domain, three test runs have been evaluated, initialized by one randomly selected relation instance as seed each time. In the first run, we use the largest test data set Nobel Prize A. In the second and third runs, we have compared two random selected seed samples with 50% of the data each, namely Nobel Prize B. For data sets in this domain, we are faced with an evaluation challenge pointed out by DIPRE (Brin, 1998) and Snowball (Agichtein and Gravano, 2000), because there is no gold-standard evaluation corpus available. We have adapted the evaluati</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Dependency-based evaluation of MINIPAR. In Workshop on the Evaluation of Parsing Systems, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MUC</author>
</authors>
<date>1995</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference (MUC-6),</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<marker>MUC, 1995</marker>
<rawString>MUC. 1995. Proceedings of the Sixth Message Understanding Conference (MUC-6), Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text.</title>
<date>1996</date>
<booktitle>In Proc. of the Thirteenth National Conference on Articial Intelligence,</booktitle>
<pages>1044--1049</pages>
<location>Portland, OR,</location>
<contexts>
<context position="2019" citStr="Riloff, 1996" startWordPosition="297" endWordPosition="298">ge documents. One of the central goals of the ACE program1 is to develop a more systematically grounded approach to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the</context>
<context position="15665" citStr="Riloff (1996)" startWordPosition="2476" endWordPosition="2477">ue id. Step2: For i=2 to n: (depicted in Figure 3) 1. find the set of the lowest nodes N1 in t that dominate in addition to other children only i seed arguments; 2. substitute N1 by nodes labelled with the i seed argument role combination information (e.g., ri_rj) and with a unique id. 3. prune the subtrees Ti dominated by Ni in t; 4. add Ti to P together with the argument role combination information and the unique id With this approach, we can learn rules like (6) in a straightforward way. 4.2 Rule Validation: Ranking and Filtering Our ranking strategy has incorporated the ideas proposed by Riloff (1996), Agichtein and Gravano (2000), Yangarber (2003) and Sudo et al. (2003). We take two properties of a pattern into account: • domain relevance: its distribution in the relevant documents and irrelevant documents (documents in other domains); • trustworthiness of its origin: the relevance score of the seeds from which it is extracted. In Riloff (1996) and Sudo et al. (2003), the relevance of a pattern is mainly dependent on its occurrences in the relevant documents vs. the whole corpus. Relevant patterns with lower frequencies cannot float to the top. It is known that some complex patterns are r</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>E. Riloff. 1996. Automatically Generating Extraction Patterns from Untagged Text. In Proc. of the Thirteenth National Conference on Articial Intelligence, pages 1044–1049, Portland, OR, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>Mark A Greenwood</author>
</authors>
<title>Comparing Information Extraction Pattern Models.</title>
<date>2006</date>
<booktitle>In Proc. of the Workshop on Information Extraction Beyond the Document,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2147" citStr="Stevenson and Greenwood, 2006" startWordPosition="313" endWordPosition="316">ch to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the pattern acquisition. However, all considered representation models (subject-verbobject, chain model, linked chain model and sub</context>
<context position="11274" citStr="Stevenson and Greenwood (2006)" startWordPosition="1750" endWordPosition="1753">te DARE rules that extract a subset of the output relation arguments. The advantages of this rule representation strategy are that (1) it supports the bottom-up rule composition; (2) it is expressive enough for the representation of rules of various complexity; (3) it reflects the precise linguistic relationship among the relation arguments and reduces the template merging task in the later phase; (4) the rules for the subset of arguments may be reused for other relation extraction tasks. The rule representation models for automatic or unsupervised pattern rule extraction discussed by (6) 586 Stevenson and Greenwood (2006) do not account for these considerations. 4 Seed-driven Bottom-up Rule Learning Two main approaches to seed construction have been discussed in the literature: pattern-oriented (e.g., ExDisco) and semantics-oriented (e.g., Snowball) strategies. The pattern-oriented method suffers from poor coverage because it makes the IE task too dependent on one linguistic representation construction (e.g., subject-verb-object) and has moreover ignored the fact that semantic relations and events could be dispersed over different substructures of the linguistic representation. In practice, several tuples extr</context>
</contexts>
<marker>Stevenson, Greenwood, 2006</marker>
<rawString>M. Stevenson and Mark A. Greenwood. 2006. Comparing Information Extraction Pattern Models. In Proc. of the Workshop on Information Extraction Beyond the Document, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sudo</author>
<author>S Sekine</author>
<author>R Grishman</author>
</authors>
<title>An Improved Extraction Pattern Representation Model for Automatic IE Pattern Acquisition.</title>
<date>2003</date>
<booktitle>In Proc. of ACL03,</booktitle>
<pages>224--231</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2084" citStr="Sudo et al., 2003" startWordPosition="305" endWordPosition="308">s to develop a more systematically grounded approach to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the pattern acquisition. However, all considered representation mode</context>
<context position="5148" citStr="Sudo et al., (2003)" startWordPosition="762" endWordPosition="765">tricted to a particular linguistic representation and is therefore suitable for various linguistic analysis methods and representation formats. The pattern discovery is bottom-up and compositional, i.e., complex patterns can build on top of simple patterns for projections. We propose a rule representation that supports this strategy. Therefore, our learning approach is seed-driven and bottom-up. Here we use dependency trees as input for pattern extraction. We consider only trees or their subtrees containing seed arguments. Therefore, our method is much more efficient than the subtree model of Sudo et al., (2003), where all subtrees containing verbs are taken into account. Our pattern rule ranking and filtering method considers two aspects of a pattern: its domain relevance and the trustworthiness of its origin. We tested our framework in two domains: Nobel Prize awards and management succession. Evaluations have been conducted to investigate the performance with respect to the seed parameters: the number of seeds and the influence of data size and its redundancy property. The whole system has been evaluated for the two domains considering precision and recall. We utilize the evaluation strategy “Idea</context>
<context position="15736" citStr="Sudo et al. (2003)" startWordPosition="2485" endWordPosition="2488"> of the lowest nodes N1 in t that dominate in addition to other children only i seed arguments; 2. substitute N1 by nodes labelled with the i seed argument role combination information (e.g., ri_rj) and with a unique id. 3. prune the subtrees Ti dominated by Ni in t; 4. add Ti to P together with the argument role combination information and the unique id With this approach, we can learn rules like (6) in a straightforward way. 4.2 Rule Validation: Ranking and Filtering Our ranking strategy has incorporated the ideas proposed by Riloff (1996), Agichtein and Gravano (2000), Yangarber (2003) and Sudo et al. (2003). We take two properties of a pattern into account: • domain relevance: its distribution in the relevant documents and irrelevant documents (documents in other domains); • trustworthiness of its origin: the relevance score of the seeds from which it is extracted. In Riloff (1996) and Sudo et al. (2003), the relevance of a pattern is mainly dependent on its occurrences in the relevant documents vs. the whole corpus. Relevant patterns with lower frequencies cannot float to the top. It is known that some complex patterns are relevant even if they have low occurrence rates. We propose a new method</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>K. Sudo, S. Sekine, and R. Grishman. 2003. An Improved Extraction Pattern Representation Model for Automatic IE Pattern Acquisition. In Proc. of ACL03, pages 224–231, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Yangarber</author>
<author>R Grishman</author>
<author>P Tapanainen</author>
<author>S Huttunen</author>
</authors>
<title>Automatic Acquisition of Domain Knowledge for Information Extraction.</title>
<date>2000</date>
<booktitle>In Proc. of COLING</booktitle>
<location>Saarbrücken, Germany.</location>
<contexts>
<context position="6644" citStr="Yangarber et al., 2000" startWordPosition="990" endWordPosition="993"> the seed-driven bottom-up pattern acquisition is presented. Section 5 describes our experiments with pattern ranking, filtering and rule induction. Section 6 presents the experiments and evaluations for the two application domains. Section 7 provides a conclusion and an outline of future work. 2 System Architecture Given the framework, our system architecture can be depicted as follows: Figure 1. Architecture This architecture has been inspired by several existing seed-oriented minimally supervised machine learning systems, in particular by Snowball (Agichtein and Gravano, 2000) and ExDisco (Yangarber et al., 2000). We call our system DARE, standing for “Domain Adaptive Relation Extraction based on Seeds”. DARE contains four major components: linguistic annotation, classifier, rule learning and relation extraction. The first component only applies once, while the last three components are integrated in a bootstrapping loop. At each iteration, rules will be learned based on the seed and then new relation instances will be extracted by applying the learned rules. The new relation instances are then used as seeds for the next iteration of the learning cycle. The cycle terminates when no new relations can b</context>
</contexts>
<marker>Yangarber, Grishman, Tapanainen, Huttunen, 2000</marker>
<rawString>R. Yangarber, R. Grishman, P. Tapanainen, and S. Huttunen. 2000. Automatic Acquisition of Domain Knowledge for Information Extraction. In Proc. of COLING 2000, Saarbrücken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Yangarber</author>
</authors>
<title>Counter-training in the Discovery of Semantic Patterns.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL-03,</booktitle>
<pages>343--350</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2065" citStr="Yangarber, 2003" startWordPosition="303" endWordPosition="304">he ACE program1 is to develop a more systematically grounded approach to IE starting from elementary entities, binary rela1 http://projects.ldc.upenn.edu/ace/ tions to n-ary relations such as events. Current semi- or unsupervised approaches to automatic pattern acquisition are either limited to a certain linguistic representation (e.g., subject-verb-object), or only deal with binary relations, or cannot assign slot filler roles to the extracted arguments, or do not have good selection and filtering methods to handle the large number of tree patterns (Riloff, 1996; Agichtein and Gravano, 2000; Yangarber, 2003; Sudo et al., 2003; Greenwood and Stevenson, 2006; Stevenson and Greenwood, 2006). Most of these approaches do not consider the linguistic interaction between relations and their projections on k dimensional subspaces where 1≤k&lt;n, which is important for scalability and reusability of rules. Stevenson and Greenwood (2006) present a systematic investigation of the pattern representation models and point out that substructures of the linguistic representation and the access to the embedded structures are important for obtaining a good coverage of the pattern acquisition. However, all considered </context>
<context position="15713" citStr="Yangarber (2003)" startWordPosition="2482" endWordPosition="2483">re 3) 1. find the set of the lowest nodes N1 in t that dominate in addition to other children only i seed arguments; 2. substitute N1 by nodes labelled with the i seed argument role combination information (e.g., ri_rj) and with a unique id. 3. prune the subtrees Ti dominated by Ni in t; 4. add Ti to P together with the argument role combination information and the unique id With this approach, we can learn rules like (6) in a straightforward way. 4.2 Rule Validation: Ranking and Filtering Our ranking strategy has incorporated the ideas proposed by Riloff (1996), Agichtein and Gravano (2000), Yangarber (2003) and Sudo et al. (2003). We take two properties of a pattern into account: • domain relevance: its distribution in the relevant documents and irrelevant documents (documents in other domains); • trustworthiness of its origin: the relevance score of the seeds from which it is extracted. In Riloff (1996) and Sudo et al. (2003), the relevance of a pattern is mainly dependent on its occurrences in the relevant documents vs. the whole corpus. Relevant patterns with lower frequencies cannot float to the top. It is known that some complex patterns are relevant even if they have low occurrence rates. </context>
<context position="17488" citStr="Yangarber (2003)" startWordPosition="2795" endWordPosition="2796"> • N: the total number of the terms in di Here the domain relevance of a term is dependent both on its document frequency and its document frequency distribution in other domains. Terms mentioned by more documents within the domain than outside are more relevant (Xu et al., 2002). In the case of n=3 such different domains might be, e.g., management succession, book review or biomedical texts. Every domain corpus should ideally have the same number of documents and similar average document size. In the calculation of the trustworthiness of the origin, we follow Agichtein and Gravano (2000) and Yangarber (2003). Thus, the relevance of a pattern is dependent on the relevance of its terms and the score value of the most trustworthy seed from which it origins. Finally, the score of a pattern p is calculated as follows: score(p)= ∑ DR(ti ) × max{ ( ) : score s s Seeds ∈ } 0 where |T|&gt; 0 and ti ∈ T • T: is the set of the terms occur in p; • Seeds: a set of seeds from which the pattern is extracted; • score(s): is the score of the seed s; This relevance score is not dependent on the distribution frequency of a pattern in the domain corpus. Therefore, patterns with lower frequency, in particular, some comp</context>
</contexts>
<marker>Yangarber, 2003</marker>
<rawString>R. Yangarber. 2003. Counter-training in the Discovery of Semantic Patterns. In Proceedings of ACL-03, pages 343–350, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xu</author>
<author>D Kurz</author>
<author>J Piskorski</author>
<author>S Schmeier</author>
</authors>
<title>A Domain Adaptive Approach to Automatic Acquisition of Domain Relevant Terms and their Relations with Bootstrapping.</title>
<date>2002</date>
<booktitle>In Proc. of LREC</booktitle>
<contexts>
<context position="17152" citStr="Xu et al., 2002" startWordPosition="2739" endWordPosition="2742">, e.g., the domain relevance of (5) and (6) are dependent on the terms “prize” and “win” respectively. Given n different domains, the domain relevance score (DR) of a term t in a domain di is: DR(t, di)= 0, if df(t, di) =0; where • df(t, di): is the document frequency of a term t in the domain di • D: the number of the documents in di • N: the total number of the terms in di Here the domain relevance of a term is dependent both on its document frequency and its document frequency distribution in other domains. Terms mentioned by more documents within the domain than outside are more relevant (Xu et al., 2002). In the case of n=3 such different domains might be, e.g., management succession, book review or biomedical texts. Every domain corpus should ideally have the same number of documents and similar average document size. In the calculation of the trustworthiness of the origin, we follow Agichtein and Gravano (2000) and Yangarber (2003). Thus, the relevance of a pattern is dependent on the relevance of its terms and the score value of the most trustworthy seed from which it origins. Finally, the score of a pattern p is calculated as follows: score(p)= ∑ DR(ti ) × max{ ( ) : score s s Seeds ∈ } 0</context>
</contexts>
<marker>Xu, Kurz, Piskorski, Schmeier, 2002</marker>
<rawString>F. Xu, D. Kurz, J. Piskorski and S. Schmeier. 2002. A Domain Adaptive Approach to Automatic Acquisition of Domain Relevant Terms and their Relations with Bootstrapping. In Proc. of LREC 2002, May 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xu</author>
<author>H Uszkoreit</author>
<author>H Li</author>
</authors>
<title>Automatic Event and Relation Detection with Seeds of Varying Complexity.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI 2006 Workshop Event Extraction and Synthesis,</booktitle>
<location>Boston,</location>
<contexts>
<context position="7930" citStr="Xu et al. (2006)" startWordPosition="1195" endWordPosition="1198"> natural language texts with linguistic information such as named entities and dependency structures. In our framework, the depth of the linguistic annotation can be varied depending on the domain and the available resources. The classifier has the task to deliver relevant paragraphs and sentences that contain seed elements. It has three subcomponents: document re585 trieval, paragraph retrieval and sentence retrieval. The document retrieval component utilizes the open source IR-system Lucene2. A translation step is built in to convert the seed into the proper IR query format. As explained in Xu et al. (2006), we generate all possible lexical variants of the seed arguments to boost the retrieval coverage and formulate a boolean query where the arguments are connected via conjunction and the lexical variants are associated via disjunction. However, the translation could be modified. The task of paragraph retrieval is to find text snippets from the relevant documents where the seed relation arguments cooccur. Given the paragraphs, a sentence containing at least two arguments of a seed relation will be regarded as relevant. As mentioned above, the rule learning component constitutes the core of our s</context>
<context position="12428" citStr="Xu et al. (2006)" startWordPosition="1913" endWordPosition="1916">he linguistic representation. In practice, several tuples extracted by different patterns can contribute to one complex relation instance. The semantics-oriented method uses relation instances as seeds. It can easily be adapted to all relation/event instances. The complexity of the target relation is not restricted by the expressiveness of the seed pattern representation. In Brin (1998) and Agichtein and Gravano (2000), the semanticsoriented methods have proved to be effective in learning patterns for some general binary relations such as booktitle-author and company-headquarter relations. In Xu et al. (2006), the authors show that at least for the investigated task it is more effective to start with the most complex relation instance, namely, with an n-ary sample for the target n-ary relation as seed, because the seed arguments are often centred in a relevant textual snippet where the relation is mentioned. Given the bottom-up extracted patterns, the task of the rule induction is to cluster and generalize the patterns. In comparison to the bottom-up rule induction strategy (Califf and Mooney, 2004), our method works also in a compositional way. For reasons of space this part of the work will be r</context>
</contexts>
<marker>Xu, Uszkoreit, Li, 2006</marker>
<rawString>F. Xu, H. Uszkoreit and H. Li. 2006. Automatic Event and Relation Detection with Seeds of Varying Complexity. In Proceedings of AAAI 2006 Workshop Event Extraction and Synthesis, Boston, July, 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>