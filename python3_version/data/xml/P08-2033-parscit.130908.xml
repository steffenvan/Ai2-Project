<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006345">
<title confidence="0.998396">
In-Browser Summarisation: Generating Elaborative Summaries Biased
Towards the Reading Context
</title>
<author confidence="0.987735">
Stephen Wan and C´ecile Paris
</author>
<affiliation confidence="0.6979645">
ICT Centre*
CSIRO
</affiliation>
<address confidence="0.8478555">
Locked Bag 17, North Ryde, Sydney
NSW 1670, Australia
</address>
<email confidence="0.996792">
Firstname.Lastname@csiro.au
</email>
<sectionHeader confidence="0.995589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99970755">
We investigate elaborative summarisation,
where the aim is to identify supplementary in-
formation that expands upon a key fact. We
envisage such summaries being useful when
browsing certain kinds of (hyper-)linked doc-
ument sets, such as Wikipedia articles or
repositories of publications linked by cita-
tions. For these collections, an elaborative
summary is intended to provide additional in-
formation on the linking anchor text. Our con-
tribution in this paper focuses on identifying
and exploring a real task in which summarisa-
tion is situated, realised as an In-Browser tool.
We also introduce a neighbourhood scoring
heuristic as a means of scoring matches to rel-
evant passages of the document. In a prelim-
inary evaluation using this method, our sum-
marisation system scores above our baselines
and achieves a recall of 57% annotated gold
standard sentences.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986018022727272">
It has long been held that a summary is useful, par-
ticularly if it supports the underlying task of the user
— for an overview of summarisation scenarios see
Spark Jones (1998). For example, generic (that is,
not query-specific) summaries, which are often in-
dicative, providing just the gist of a document, are
only useful if they happen to address the underlying
need of the user.
In a push to make summaries more responsive
to user needs, the field of summarisation has ex-
plored the overlap with complex question-answering
&apos;Information and Communication Technologies Centre
research to produce query-focused summaries. Such
work includes the recent DUC challenges on query-
focused summarisation,1 in which the user needs are
represented by short paragraphs of text written by
human judges. These are then used as input to the
summarisation process. However, modelling user
needs is a difficult task. DUC descriptions of in-
formation needs are only an artificial stipulation of a
user’s interest.
In this work, we propose a tool built into an inter-
net browser that makes use of a very simple heuris-
tic for determining user interest.2 The basic premise
of the heuristic is that the text currently being read
provides an approximation of the current user inter-
est. Specifically, as a user reads a sentence, it po-
tentially represents a fine-grained information need.
We identify the sentence of interest without com-
plex methods, relying instead on the user to move
the mouse over the anchor text link to request a sum-
mary of the linked document, thus identifying to the
browser plug-in which sentence is now in focus.
To generate the summary, the whole document,
specifically the linking sentence that contains the an-
chor text, serves as the reading context, a potential
indicator of the user interest. An example of the cur-
rent output on Wikipedia text is presented in Figure
1. It shows an elaborative summary of a document
about the Space Shuttle Discovery expanding on the
content of the linking sentence. In this case, it gives
further information about a space walk in which the
shuttle was repaired inflight.
Our summarisation tool, the In-Browser Elabora-
</bodyText>
<footnote confidence="0.999715">
1http://duc.nist.gov/guidelines/2006.html
2We currently work with the Firefox browser.
</footnote>
<page confidence="0.951324">
129
</page>
<reference confidence="0.2040505">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 129–132,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<figureCaption confidence="0.998509">
Figure 1: A summary generated when moving the mouse
over the link “Discovery’s” (mouse pointer omitted).
</figureCaption>
<bodyText confidence="0.999934083333333">
tive Summariser (IBES), complements generic sum-
maries in providing additional information about a
particular aspect of a page.3 Generic summaries
themselves are easy to generate due to rules enforced
by the Wikipedia style-guide, which dictates that all
titles be noun phrases describing an entity, thus serv-
ing as a short generic summary. Furthermore, the
first sentence of the article should contain the title
in subject position, which tends to create sentences
that define the main entity of the article.
For the elaborative summarisation scenario de-
scribed, we are interested in exploring ways in
which the reading context can be leveraged to pro-
duce the elaborative summary. One method ex-
plored in this paper attempts to map the content of
the linked document into the semantic space of the
reading context, as defined in vector-space. We use
Singular Value Decomposition (SVD), the underly-
ing method behind Latent Semantic Analysis (Deer-
wester et al., 1990), as a means of identifying latent
topics in the reading context, against which we com-
pare the linked document. We present our system
and the results from our preliminary investigation in
the remainder of this paper.
</bodyText>
<footnote confidence="0.810122">
3http://www.ict.csiro.au/staff/stephen.wan/ibes/
</footnote>
<sectionHeader confidence="0.996335" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999693041666667">
Using link text for summarisation has been explored
previously by Amitay and Paris (2000). They identi-
fied situations when it was possible to generate sum-
maries of web-pages by recycling human-authored
descriptions of links from anchor text. In our work,
we use the anchor text as the reading context to pro-
vide an elaborative summary for the linked docu-
ment.
Our work is similar in domain to that of the 2007
CLEF WiQA shared task.4 However, in contrast to
our application scenario, the end goal of the shared
task focuses on suggesting editing updates for a
particular document and not on elaborating on the
user’s reading context.
A related task was explored at the Document Un-
derstanding Conference (DUC) in 2007.5 Here the
goal was to find new information with respect to a
previously seen set of documents. This is similar to
the elaborative goal of our summary in the sense that
one could answer the question: “What else can I say
about topic X (that hasn’t already been mentioned
in the reading context)”. However, whereas DUC
focused on unlinked news wire text, we explore a
different genre of text.
</bodyText>
<sectionHeader confidence="0.998734" genericHeader="method">
3 Algorithm
</sectionHeader>
<bodyText confidence="0.999550555555556">
Our approach is designed to select justification sen-
tences and expand upon them by finding elaborative
material. The first stage identifies those sentences
in the linked document that support the semantic
content of the anchor text. We call those sentences
justification material. The second stage finds mate-
rial that is supplementary yet relevant for the user.
In this paper, we report on the first of these tasks,
though ultimately both are required for elaborative
summaries.
To locate justification material, we implemented
two known summarisation techniques. The first
compares word overlap between the anchor text and
the linked document. The second approach attempts
to discover a semantic space, as defined by the read-
ing context. The linked document is then mapped
into this semantic space. These are referred to as the
Simple Link method and the SVD method, where
</bodyText>
<footnote confidence="0.99995">
4http://ilps.science.uva.nl/WiQA/
5http://duc.nist.gov/guidelines/2007.html
</footnote>
<page confidence="0.994047">
130
</page>
<bodyText confidence="0.99699">
the latter divides further into two variants: SVD-
Link and SVD-topic.
</bodyText>
<subsectionHeader confidence="0.995745">
3.1 Simple Link Method
</subsectionHeader>
<bodyText confidence="0.999970444444444">
The first strategy, Simple Link, makes use of stan-
dard vector space approaches from Information Re-
trieval. A vector of word frequencies, omitting stop-
words, is used to represent each sentence in the read-
ing context and in the linked document. The vec-
tor for the anchor sentence is compared with vectors
for each linked document sentence, using the cosine
similarity metric. The highest scoring sentences are
then retrieved as the summary.
</bodyText>
<sectionHeader confidence="0.6626665" genericHeader="method">
3.2 Two Singular Value Decomposition (SVD)
Methods
</sectionHeader>
<bodyText confidence="0.999817666666667">
In these approaches, the semantic space of the linked
document is mapped into that of the reading context.
Intuitively, only those sentences that map well into
the reading context space and are similar to the link-
ing sentence would be good justification material.
To begin with, the reading context document is
represented as a term-by-sentence matrix, A, where
stop words are omitted and frequencies are weighted
using inverse document frequency. A Singular Value
Decomposition (SVD) analysis is performed (using
the JAMA package6) on this matrix which provides
three resulting matrices: A = U5Vtr.
The S-matrix defines the themes of the reading
context. The U-matrix relates the reading context
vocabulary to the discovered themes. Finally, the
V-matrix relates the original sentences to each of the
themes. The point of the SVD analysis is to discover
these themes based on co-variance between the word
frequencies. If words occur together, they are se-
mantically related and the co-variance is marked as
a theme, allowing one to capture fuzzy matches be-
tween related words. Crucially, each sentence can
now be represented with a vector of membership
scores to each theme.
The first of the semantic space mapping methods,
SVD-link, finds the theme that the anchor text be-
longs to best. This is done by consulting the V-
matrix of the SVD analysis to find the highest scor-
ing theme for that sentence, which we call the link-
ing theme. Each sentence in the linked document,
</bodyText>
<footnote confidence="0.836269">
6http://math.nist.gov/javanumerics/jama/
</footnote>
<bodyText confidence="0.999764727272727">
after mapping it to the SVD-derived vector space, is
then examined. The highest scoring sentences that
belong to the linking theme are then extracted.
The second method, SVD-topic, makes a differ-
ent assumption about the nature of the reading con-
text. Instead of taking the anchor text as an indicator
of the user’s information need, it assumes that the
top n themes of the reading context document rep-
resent the user’s interest. Of the linked document
sentences, for each of those top n reading context
themes, the best scoring sentence is extracted.
</bodyText>
<sectionHeader confidence="0.996526" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.996267111111111">
In lieu of a user-centered experiment, our prelimi-
nary experiments evaluated the effectiveness of the
tool in terms of finding justification material for an
elaborative summary. We evaluated the three sys-
tems described in Section 3. Each system selected
5 sentences. We tested against two baselines. The
first simply returns the first 5 sentences. The second
produces a generic summary based on Gong and Liu
(2001), independently of the reading context.
</bodyText>
<subsectionHeader confidence="0.992352">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999970818181818">
The data used is a collection of Wikipedia articles
obtained automatically from the web. The snap-
shot of the corpus was collected in 2007. Of these,
links from about 600 randomly chosen documents
were filtered with a heuristic that enforced a sen-
tence length of at least 10 words such that the link in
the anchor text occurred after this minimum length.
This heuristic was used as an approximate means
of filtering out sentences where the linking sentence
was simply a definition of the entity linked. In these
cases, the justification material is usually trivially
identified as the first sentence of the linked docu-
ment. This leaves us with links that potentially re-
quire more complicated summarisation methods.
Of these cases, 125 cases were randomly selected
and the linked documents annotated for varying de-
grees of relevancy. This resulted in 50 relevant doc-
ument links, which we further annotated, selecting
sentences supporting the anchor sentence, with a
Cohen’s Kappa of 0.55. The intersection of the se-
lected sentences was then used as a gold standard for
each test case.
</bodyText>
<page confidence="0.993618">
131
</page>
<table confidence="0.9993488">
System Recall Precision
generic 0.13 0.05
SVD-topic 0.14 0.06
SVD-link 0.22 0.09
simple-link 0.28 0.11
</table>
<tableCaption confidence="0.947769">
Table 1: Recall and Precision figures for all summarisers
without the first 5 sentences.
</tableCaption>
<sectionHeader confidence="0.764901" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999932189189189">
It is difficult to beat the first-5 baseline, which attains
the best recall of 0.52 and a precision of 0.2, with all
other strategies falling behind. However, we believe
that this may be due to the presence of some types
of Wikipedia articles that are narrow in scope and
centered on specific events. For such articles, we
would naturally advocate using the first N sentences
as a summary.
To examine the performance of the summarisa-
tion strategies on sentences beyond the top-N, we
filtered the gold standard sets to remove sentences
occurring in positions 1-5 in the linked document,
and tested recall and precision on the remaining
sentences. This reduces our test set by 10 cases.
Since documents may be lengthy (more than 100
sentences), selecting justification material is a dif-
ficult task. The results are shown in Table 1 and in-
dicate that systems using reading context do better
than a generic summariser.
Thinking ahead to the second expansion step in
which we find elaborative material, good candidates
for such sentences may be found in the immedi-
ate vicinity of justification sentences. If so, near
matches for justification sentences may still be use-
ful in indicating that, at least, the right portion of
the document was identified. Thus, to test for near
matches, we scored a match if the gold sentence
occurred on either side of the system-selected sen-
tence. We refer to this as the neighbourhood heuris-
tic.
Table 2 shows the effect on recall and preci-
sion if we treat each selected sentence as defining a
neighbourhood of relevance in the linked document.
Again, performance on the first 5 sentences were ig-
nored. Recall improved by up to 10% with only a
small drop in precision (6%). When the neighbour-
hood heuristic is run on the original gold sentence
</bodyText>
<table confidence="0.9354568">
System Recall Precision
generic 0.27 0.04
SVD-topic 0.27 0.04
SVD-link 0.30 0.05
simple-link 0.38 0.06
</table>
<tableCaption confidence="0.970315">
Table 2: Recall and Precision figures using the neigh-
bourhood heuristic (without the first 5 sentences).
</tableCaption>
<bodyText confidence="0.99869">
set (with the first 5 sentences), recall reaches 0.57,
which lies above an amended 0.55 baseline.
</bodyText>
<sectionHeader confidence="0.998082" genericHeader="discussions">
5 Future Work and Conclusions
</sectionHeader>
<bodyText confidence="0.999968733333333">
We introduced the concept of a user-biased elabo-
rative summarisation, using the reading context as
an indicator of the information need. Our paper
presents a scenario in which elaborative summari-
sation may be useful and explored simple summari-
sation strategies to perform this role. Results are
encouraging and our preliminary evaluation shows
that reading context is helpful, achieving a recall
of 57% when identifying sentences that justify con-
tent in the linking sentence of the reading context.
In future work, we intend to explore other latent
topic methods to improve recall and precision per-
formance. Further development of elaborative sum-
marisation strategies and a user-centered evaluation
are also planned.
</bodyText>
<sectionHeader confidence="0.998834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990682941176471">
Einat Amitay and C´ecile Paris. 2000. Automatically
summarising web sites: is there a way around it? In
Proceedings of the 9th international conference on In-
formation and knowledge management, NY, USA.
Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by Latent Semantic Analysis. Jour-
nal of the American Society of Information Science,
41(6):391–407.
Yihong Gong and Xin Liu. 2001. Generic text summa-
rization using relevance measure and latent semantic
analysis. In Proceedings of the 24th ACM SIGIR con-
ference. New Orleans, USA.
Karen Spark Jones. 1998. Automatic summarizing:
factors and directions. In I. Mani and M. May-
bury (ed.), Advances in Automatic Text Summarisa-
tion. MIT Press, Cambridge MA.
</reference>
<page confidence="0.997719">
132
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.665851">
<title confidence="0.9950665">In-Browser Summarisation: Generating Elaborative Summaries Biased Towards the Reading Context</title>
<author confidence="0.952767">Stephen Wan</author>
<author confidence="0.952767">C´ecile Paris</author>
<affiliation confidence="0.804994">CSIRO</affiliation>
<address confidence="0.869774">Locked Bag 17, North Ryde, Sydney NSW 1670, Australia</address>
<email confidence="0.95863">Firstname.Lastname@csiro.au</email>
<abstract confidence="0.999382">investigate where the aim is to identify supplementary information that expands upon a key fact. We envisage such summaries being useful when browsing certain kinds of (hyper-)linked document sets, such as Wikipedia articles or repositories of publications linked by citations. For these collections, an elaborative summary is intended to provide additional information on the linking anchor text. Our contribution in this paper focuses on identifying and exploring a real task in which summarisais situated, realised as an also introduce a heuristic as a means of scoring matches to relevant passages of the document. In a preliminary evaluation using this method, our summarisation system scores above our baselines and achieves a recall of 57% annotated gold standard sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>129--132</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 129–132,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Amitay</author>
<author>C´ecile Paris</author>
</authors>
<title>Automatically summarising web sites: is there a way around it?</title>
<date>2000</date>
<booktitle>In Proceedings of the 9th international conference on Information and knowledge management,</booktitle>
<location>NY, USA.</location>
<marker>Amitay, Paris, 2000</marker>
<rawString>Einat Amitay and C´ecile Paris. 2000. Automatically summarising web sites: is there a way around it? In Proceedings of the 9th international conference on Information and knowledge management, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by Latent Semantic Analysis. Journal of the American Society of Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th ACM SIGIR conference.</booktitle>
<location>New Orleans, USA.</location>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proceedings of the 24th ACM SIGIR conference. New Orleans, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Spark Jones</author>
</authors>
<title>Automatic summarizing: factors and directions.</title>
<date>1998</date>
<booktitle>Advances in Automatic Text Summarisation.</booktitle>
<editor>In I. Mani and M. Maybury (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge MA.</location>
<contexts>
<context position="1282" citStr="Jones (1998)" startWordPosition="196" endWordPosition="197">ibution in this paper focuses on identifying and exploring a real task in which summarisation is situated, realised as an In-Browser tool. We also introduce a neighbourhood scoring heuristic as a means of scoring matches to relevant passages of the document. In a preliminary evaluation using this method, our summarisation system scores above our baselines and achieves a recall of 57% annotated gold standard sentences. 1 Introduction It has long been held that a summary is useful, particularly if it supports the underlying task of the user — for an overview of summarisation scenarios see Spark Jones (1998). For example, generic (that is, not query-specific) summaries, which are often indicative, providing just the gist of a document, are only useful if they happen to address the underlying need of the user. In a push to make summaries more responsive to user needs, the field of summarisation has explored the overlap with complex question-answering &apos;Information and Communication Technologies Centre research to produce query-focused summaries. Such work includes the recent DUC challenges on queryfocused summarisation,1 in which the user needs are represented by short paragraphs of text written by</context>
</contexts>
<marker>Jones, 1998</marker>
<rawString>Karen Spark Jones. 1998. Automatic summarizing: factors and directions. In I. Mani and M. Maybury (ed.), Advances in Automatic Text Summarisation. MIT Press, Cambridge MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>