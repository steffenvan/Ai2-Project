<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000922">
<title confidence="0.979106">
Using lexical and relational similarity to classify semantic relations
</title>
<author confidence="0.903951">
Diarmuid O´ S´eaghdha
</author>
<affiliation confidence="0.956072">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.963647666666667">
15 JJ Thomson Avenue
Cambridge CB3 0FD
United Kingdom
</address>
<email confidence="0.998367">
do242@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993863" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988725">
Many methods are available for comput-
ing semantic similarity between individ-
ual words, but certain NLP tasks require
the comparison of word pairs. This pa-
per presents a kernel-based framework for
application to relational reasoning tasks of
this kind. The model presented here com-
bines information about two distinct types
of word pair similarity: lexical similarity
and relational similarity. We present an
efficient and flexible technique for imple-
menting relational similarity and show the
effectiveness of combining lexical and re-
lational models by demonstrating state-of-
the-art results on a compound noun inter-
pretation task.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891809523809">
The problem of modelling semantic similarity be-
tween words has long attracted the interest of re-
searchers in Natural Language Processing and has
been shown to be important for numerous applica-
tions. For some tasks, however, it is more appro-
priate to consider the problem of modelling sim-
ilarity between pairs of words. This is the case
when dealing with tasks involving relational or
analogical reasoning. In such tasks, the chal-
lenge is to compare pairs of words on the basis of
the semantic relation(s) holding between the mem-
bers of each pair. For example, the noun pairs
(steel,knife) and (paper,cup) are similar because
in both cases the relation N2 is made of N1 fre-
quently holds between their members. Analogi-
cal tasks are distinct from (but not unrelated to)
other kinds of “relation extraction” tasks where
each data item is tied to a specific sentence con-
text (e.g., Gir u et al. (2007)).
One such relational reasoning task is the prob-
lem of compound noun interpretation, which
</bodyText>
<note confidence="0.659459833333333">
Ann Copestake
Computer Laboratory
University of Cambridge
15 JJ Thomson Avenue
Cambridge CB3 0FD
United Kingdom
</note>
<email confidence="0.975749">
aac10@cl.cam.ac.uk
</email>
<bodyText confidence="0.99989787804878">
has received a great deal of attention in recent
years (Gir u et al., 2005; Turney, 2006; But-
nariu and Veale, 2008). In English (and other
languages), the process of producing new lexical
items through compounding is very frequent and
very productive. Furthermore, the noun-noun re-
lation expressed by a given compound is not ex-
plicit in its surface form: a steel knife may be a
knife made from steel but a kitchen knife is most
likely to be a knife used in a kitchen, not a knife
made from a kitchen. The assumption made by
similarity-based interpretation methods is that the
likely meaning of a novel compound can be pre-
dicted by comparing it to previously seen com-
pounds whose meanings are known. This is a
natural framework for computational techniques;
there is also empirical evidence for similarity-
based interpretation in human compound process-
ing (Ryder, 1994; Devereux and Costello, 2007).
This paper presents an approach to relational
reasoning based on combining information about
two kinds of similarity between word pairs: lex-
ical similarity and relational similarity. The as-
sumptions underlying these two models of similar-
ity are sketched in Section 2. In Section 3 we de-
scribe how these models can be implemented for
statistical machine learning with kernel methods.
We present a new flexible and efficient kernel-
based framework for classification with relational
similarity. In Sections 4 and 5 we apply our
methods to a compound interpretation task and
demonstrate that combining models of lexical and
relational similarity can give state-of-the-art re-
sults on a compound noun interpretation task, sur-
passing the performance attained by either model
taken alone. We then discuss previous research
on relational similarity, and show that some previ-
ously proposed models can be implemented in our
framework as special cases. Given the good per-
formance achieved for compound interpretation, it
seems likely that the methods presented in this pa-
</bodyText>
<note confidence="0.923055">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 621–629,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997956">
621
</page>
<bodyText confidence="0.982795666666667">
per can also be applied successfully to other rela-
tional reasoning tasks; we suggest some directions
for future research in Section 7.
2 Two models of word pair similarity
While there is a long tradition of NLP research
on methods for calculating semantic similarity be-
tween words, calculating similarity between pairs
(or n-tuples) of words is a less well-understood
problem. In fact, the problem has rarely been
stated explicitly, though it is implicitly addressed
by most work on compound noun interpretation
and semantic relation extraction. This section de-
scribes two complementary approaches for using
distributional information extracted from corpora
to calculate noun pair similarity.
The first model of pair similarity is based on
standard methods for computing semantic similar-
ity between individual words. According to this
lexical similarity model, word pairs (w1, w2) and
(w3, w4) are judged similar if w1 is similar to w3
and w2 is similar to w4. Given a measure wsim
of word-word similarity, a measure of pair simi-
larity psim can be derived as a linear combination
of pairwise lexical similarities:
</bodyText>
<equation confidence="0.9979195">
psim((w1, w2), (w3, w4)) _ (1)
a[wsim(w1, w3)] + Q[wsim(w2, w4)]
</equation>
<bodyText confidence="0.999943648648649">
A great number of methods for lexical semantic
similarity have been proposed in the NLP liter-
ature. The most common paradigm for corpus-
based methods, and the one adopted here, is based
on the distributional hypothesis: that two words
are semantically similar if they have similar pat-
terns of co-occurrence with other words in some
set of contexts. Curran (2004) gives a comprehen-
sive overview of distributional methods.
The second model of pair similarity rests on the
assumption that when the members of a word pair
are mentioned in the same context, that context
is likely to yield information about the relations
holding between the words’ referents. For exam-
ple, the members of the pair (bear, forest) may
tend to co-occur in contexts containing patterns
such as w1 lives in the w2 and in the w2,... a w1,
suggesting that a LOCATED IN or LIVES IN re-
lation frequently holds between bears and forests.
If the contexts in which fish and reef co-occur are
similar to those found for bear and forest, this is
evidence that the same semantic relation tends to
hold between the members of each pair. A re-
lational distributional hypothesis therefore states
that two word pairs are semantically similar if their
members appear together in similar contexts.
The distinction between lexical and relational
similarity for word pair comparison is recognised
by Turney (2006) (he calls the former attributional
similarity), though the methods he presents focus
on relational similarity. O´ S´eaghdha and Copes-
take’s (2007) classification of information sources
for noun compound interpretation also includes a
description of lexical and relational similarity. Ap-
proaches to compound noun interpretation have
tended to use either lexical or relational similarity,
though rarely both (see Section 6 below).
</bodyText>
<sectionHeader confidence="0.999712" genericHeader="method">
3 Kernel methods for pair similarity
</sectionHeader>
<subsectionHeader confidence="0.689321">
3.1 Kernel methods
</subsectionHeader>
<bodyText confidence="0.9999495">
The kernel framework for machine learning is a
natural choice for similarity-based classification
(Shawe-Taylor and Cristianini, 2004). The cen-
tral concept in this framework is the kernel func-
tion, which can be viewed as a measure of simi-
larity between data items. Valid kernels must sat-
isfy the mathematical condition of positive semi-
definiteness; this is equivalent to requiring that the
kernel function equate to an inner product in some
vector space. The kernel can be expressed in terms
of a mapping function 0 from the input space X to
a feature space F:
</bodyText>
<equation confidence="0.890971">
k(Xi, X9) _ h0(Xi), 0(X9)i,7 (2)
</equation>
<bodyText confidence="0.999975894736842">
where h·, ·i,7 is the inner product associated with
F. X and F need not have the same dimension-
ality or be of the same type. F is by definition an
inner product space, but the elements of X need
not even be vectorial, so long as a suitable map-
ping function 0 can be found. Furthermore, it is
often possible to calculate kernel values without
explicitly representing the elements of F; this al-
lows the use of implicit feature spaces with a very
high or even infinite dimensionality.
Kernel functions have received significant at-
tention in recent years, most notably due to the
successful application of Support Vector Machines
(Cortes and Vapnik, 1995) to many problems. The
SVM algorithm learns a decision boundary be-
tween two data classes that maximises the mini-
mum distance or margin from the training points
in each class to the boundary. The geometry of the
space in which this boundary is set depends on the
</bodyText>
<page confidence="0.997552">
622
</page>
<bodyText confidence="0.999925235294118">
kernel function used to compare data items. By
tailoring the choice of kernel to the task at hand,
the user can use prior knowledge and intuition to
improve classification performance.
One useful property of kernels is that any sum
or linear combination of kernel functions is itself
a valid kernel. Theoretical analyses (Cristianini
et al., 2001; Joachims et al., 2001) and empiri-
cal investigations (e.g., Gliozzo et al. (2005)) have
shown that combining kernels in this way can have
a beneficial effect when the component kernels
capture different “views” of the data while indi-
vidually attaining similar levels of discriminative
performance. In the experiments described below,
we make use of this insight to integrate lexical and
relational information for semantic classification
of compound nouns.
</bodyText>
<subsectionHeader confidence="0.999508">
3.2 Lexical kernels
</subsectionHeader>
<bodyText confidence="0.999619357142857">
O´ S´eaghdha and Copestake (2008) demonstrate
how standard techniques for distributional similar-
ity can be implemented in a kernel framework. In
particular, kernels for comparing probability dis-
tributions can be derived from standard probabilis-
tic distance measures through simple transforma-
tions. These distributional kernels are suited to a
data representation where each word w is identi-
fied with the a vector of conditional probabilities
(P(c1|w), ... , P(c|C||w)) that defines a distribu-
tion over other terms c co-occurring with w. For
example, the following positive semi-definite ker-
nel between words can be derived from the well-
known Jensen-Shannon divergence:
</bodyText>
<equation confidence="0.9999072">
kjsd(w1, w2) =
[P(c|w1)lo92( P(c|w1) )
P(c |w1) + P(c |w2)
+ P(c|w2)lo92( P(c|w2) )] (3)
P(c|w1) + P(c|w2)
</equation>
<bodyText confidence="0.999980181818182">
A straightforward method of extending this model
to word pairs is to represent each pair (w1, w2) as
the concatenation of the co-occurrence probability
vectors for w1 and w2. Taking kjsd as a measure of
word similarity and introducing parameters α and
β to scale the contributions of w1 and w2 respec-
tively, we retrieve the lexical model of pair similar-
ity defined above in (1). Without prior knowledge
of the relative importance of each pair constituent,
it is natural to set both scaling parameters to 0.5,
and this is done in the experiments below.
</bodyText>
<subsectionHeader confidence="0.998934">
3.3 String embedding functions
</subsectionHeader>
<bodyText confidence="0.99885373076923">
The necessary starting point for our implementa-
tion of relational similarity is a means of compar-
ing contexts. Contexts can be represented in a va-
riety of ways, from unordered bags of words to
rich syntactic structures. The context representa-
tion adopted here is based on strings, which pre-
serve useful information about the order of words
in the context yet can be processed and compared
quite efficiently. String kernels are a family of ker-
nels that compare strings s, t by mapping them
into feature vectors φstring(s), φstring(t) whose
non-zero elements index the subsequences con-
tained in each string.
A string is defined as a finite sequence s =
(s1, ... , sl) of symbols belonging to an alphabet
E. El is the set of all strings of length l, and E* is
set of all strings or the language. A subsequence
u of s is defined by a sequence of indices i =
(i1, ... , i|u|) such that 1 &lt; i1 &lt; · · · &lt; i|u |&lt; |s|,
where |s |is the length of s. len(i) = i|u |− i1 + 1
is the length of the subsequence in s. An embed-
ding φstring : E* —* R|Σ|l is a function that maps
a string s onto a vector of positive “counts” that
correspond to subsequences contained in s.
One example of an embedding function is a
gap-weighted embedding, defined as
</bodyText>
<equation confidence="0.7914385">
1: φgapl(s) = [ λlen(i)]uEΣl (4)
i:s[i]=u
</equation>
<bodyText confidence="0.99871945">
λ is a decay parameter between 0 and 1; the
smaller its value, the more the influence of a dis-
continuous subsequence is reduced. When l = 1
this corresponds to a “bag-of-words” embedding.
Gap-weighted string kernels implicitly compute
the similarity between two strings s, t as an inner
product (φ(s), φ(t)). Lodhi et al. (2002) present
an efficient dynamic programming algorithm that
evaluates this kernel in O(l|s||t|) time without ex-
plicitly representing the feature vectors φ(s), φ(t).
An alternative embedding is that used by Turney
(2008) in his PairClass system (see Section 6). For
the PairClass embedding φPC, an n-word context
[0−1 words] N1|2 [0−3 words] N1|2 [0−1 words]
containing target words N1, N2 is mapped onto
the 2n−2 patterns produced by substituting zero
or more of the context words with a wildcard *.
Unlike the patterns used by the gap-weighted em-
bedding these are not truly discontinuous, as each
wildcard must match exactly one word.
</bodyText>
<equation confidence="0.3998285">
1: −
�
</equation>
<page confidence="0.990844">
623
</page>
<subsectionHeader confidence="0.994062">
3.4 Kernels on sets
</subsectionHeader>
<bodyText confidence="0.999782769230769">
String kernels afford a way of comparing individ-
ual contexts. In order to compute the relational
similarity of two pairs, however, we do not want to
associate each pair with a single context but rather
with the set of contexts in which they appear to-
gether. In this section, we use string embeddings
to define kernels on sets of strings.
One natural way of defining a kernel over sets
is to take the average of the pairwise basic kernel
values between members of the two sets A and B.
Let k0 be a kernel on a set X, and let A, B C_ X
be sets of cardinality |A |and |B |respectively. The
averaged kernel is defined as
</bodyText>
<equation confidence="0.986522">
1 kave(A, B) = |A ||B |Y-
a∈A
</equation>
<bodyText confidence="0.999815052631579">
This kernel was introduced by G¨artner et
al. (2002) in the context of multiple instance learn-
ing. It was first used for computing relational sim-
ilarity by O´ S´eaghdha and Copestake (2007). The
efficiency of the kernel computation is dominated
by the |A |x |B |basic kernel calculations. When
each basic kernel calculation k0(a, b) has signifi-
cant complexity, as is the case with string kernels,
calculating kave can be slow.
A second perspective views each set as corre-
sponding to a probability distribution, and takes
the members of that set as observed samples from
that distribution. In this way a kernel on distribu-
tions can be cast as a kernel on sets. In the case of
sets whose members are strings, a string embed-
ding Ostring can be used to estimate a probability
distribution over subsequences for each set by tak-
ing the normalised sum of the feature mappings of
its members:
</bodyText>
<equation confidence="0.864154">
�
set (A) = 1
Z
S∈A
</equation>
<bodyText confidence="0.979867581818182">
where Z is a normalisation factor. Different
choices of Ostring yield different relational simi-
larity models. In this paper we primarily use the
gap-weighted embedding Ogapl; we also discuss
the PairClass embedding OPC for comparison.
Once the embedding Oset has been calculated,
any suitable inner product can be applied to the
resulting vectors, e.g. the linear kernel (dot prod-
uct) or the Jensen-Shannon kernel defined in (3).
In the latter case, which we term kjsd below, the
natural choice for normalisation is the sum of the
entries in ES∈A Ostring(s), ensuring that Oset(A)
has unit L1 norm and defines a probability dis-
tribution. Furthermore, scaling Oset(A) by 1
|A|,
applying L2 vector normalisation and applying
the linear kernel retrieves the averaged set kernel
kave(A, B) as a special case of the distributional
framework for sets of strings.
Instead of requiring |A||B |basic kernel evalua-
tions for each pair of sets, distributional set kernels
only require the embedding Oset(A) to be com-
puted once for each set and then a single vector
inner product for each pair of sets. This is gen-
erally far more efficient than the kernel averaging
method. The significant drawback is that repre-
senting the feature vector for each set demands
a large amount of memory; for the gap-weighted
embedding with subsequence length l, each vec-
tor potentially contains up to |A|(|S�a�|) entries,
�
where smax is the longest string in A. In practice,
however, the vector length will be lower due to
subsequences occurring more than once and many
strings being shorter than smax.
One way to reduce the memory load is to re-
duce the lengths of the strings used, either by re-
taining just the part of each string expected to be
informative or by discarding all strings longer than
an acceptable maximum. The PairClass embed-
ding function implicitly restricts the contexts con-
sidered by only applying to strings where no more
than three words occur between the targets, and by
ignoring all non-intervening words except single
ones adjacent to the targets. A further technique
is to trade off time efficiency for space efficiency
by computing the set kernel matrix in a blockwise
fashion. To do this, the input data is divided into
blocks of roughly equal size – the size that is rele-
vant here is the sum of the cardinalities of the sets
in a given block. Larger block sizes b therefore
allow faster computation, but they require more
memory. In the experiments described below, b
was set to 5,000 for embeddings of length l = 1
and l = 2, and to 3,000 for l = 3.
</bodyText>
<sectionHeader confidence="0.992324" genericHeader="method">
4 Experimental setup for compound
noun interpretation
</sectionHeader>
<subsectionHeader confidence="0.987915">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.998095">
The dataset used in our experiments is O´ S´eaghdha
and Copestake’s (2007) set of 1,443 compound
nouns extracted from the British National Corpus
(BNC).1 Each compound is annotated with one of
</bodyText>
<footnote confidence="0.9722415">
1The data are available from http://www.cl.cam.
ac.uk/˜do242/resources.html.
</footnote>
<equation confidence="0.995731666666667">
� k0(a,b) (5)
b∈B
Ostring(s) (6)
</equation>
<page confidence="0.985186">
624
</page>
<bodyText confidence="0.999854222222222">
six semantic relations: BE, HAVE, IN, AGENT, IN-
STRUMENT and ABOUT. For example, air disas-
ter is labelled IN (a disaster in the air) and freight
train is labelled INSTRUMENT (a train that car-
ries freight). The best previous classification result
on this dataset was reported by O´ S´eaghdha and
Copestake (2008), who achieved 61.0% accuracy
and 58.8% F-score with a purely lexical model of
compound similarity.
</bodyText>
<subsectionHeader confidence="0.956409">
4.2 General Methodology
</subsectionHeader>
<bodyText confidence="0.9999838">
All experiments were run using the LIBSVM Sup-
port Vector Machine library.2 The one-versus-all
method was used to decompose the multiclass task
into six binary classification tasks. Performance
was evaluated using five-fold cross-validation. For
each fold the SVM cost parameter was optimised
in the range (2−6, 2−4, ... , 212) through cross-
validation on the training set.
All kernel matrices were precomputed on near-
identical machines with 2.4 Ghz 64-bit processors
and 8Gb of memory. The kernel matrix compu-
tation is trivial to parallelise, as each cell is inde-
pendent. Spreading the computational load across
multiple processors is a simple way to reduce the
real time cost of the procedure.
</bodyText>
<subsectionHeader confidence="0.998193">
4.3 Lexical features
</subsectionHeader>
<bodyText confidence="0.999953727272727">
Our implementation of the lexical similarity
model uses the same feature set as O´ S´eaghdha
and Copestake (2008). Two corpora were used
to extract co-occurrence information: the writ-
ten component of the BNC (Burnard, 1995) and
the Google Web 1T 5-Gram Corpus (Brants and
Franz, 2006). For each noun appearing as a com-
pound constituent in the dataset, we estimate a co-
occurrence distribution based on the nouns in co-
ordinative constructions. Conjunctions are identi-
fied in the BNC by first parsing the corpus with
RASP (Briscoe et al., 2006) and extracting in-
stances of the conj grammatical relation. As the
5-Gram corpus does not contain full sentences it
cannot be parsed, so regular expressions were used
to extract coordinations. In each corpus, the set of
co-occurring terms is restricted to the 10,000 most
frequent conjuncts in that corpus so that each con-
stituent distribution is represented with a 10,000-
dimensional vector. The probability vector for the
compound is created by appending the two con-
stituent vectors, each scaled by 0.5 to weight both
</bodyText>
<footnote confidence="0.9624685">
2http://www.csie.ntu.edu.tw/˜cjlin/
libsvm
</footnote>
<bodyText confidence="0.999860666666667">
constituents equally and ensure that the new vec-
tor sums to 1. To perform classification with these
features we use the Jensen-Shannon kernel (3).3
</bodyText>
<subsectionHeader confidence="0.97835">
4.4 Relational features
</subsectionHeader>
<bodyText confidence="0.993725425531915">
To extract data for computing relational similarity,
we searched a large corpus for sentences in which
both constituents of a compound co-occur. The
corpora used here are the written BNC, contain-
ing 90 million words of British English balanced
across genre and text type, and the English Giga-
word Corpus, 2nd Edition (Graff et al., 2005), con-
taining 2.3 billion words of newswire text. Extrac-
tion from the Gigaword Corpus was performed at
the paragraph level as the corpus is not annotated
for sentence boundaries, and a dictionary of plural
forms and American English variants was used to
expand the coverage of the corpus trawl.
The extracted contexts were split into sentences,
tagged and lemmatised with RASP. Duplicate sen-
tences were discarded, as were sentences in which
the compound head and modifier were more than
10 words apart. Punctuation and tokens containing
non-alphanumeric characters were removed. The
compound modifier and head were replaced with
placeholder tokens M:n and H:n in each sentence
to ensure that the classifier would learn from re-
lational information only and not from lexical in-
formation about the constituents. Finally, all to-
kens more than five words to the left of the left-
most constituent or more than five words to the
right of the rightmost constituent were discarded;
this has the effect of speeding up the kernel com-
putations and should also focus the classifier on
the most informative parts of the context sen-
tences. Examples of the context strings extracted
for the modifier-head pair (history,book) are the:a
1957:m pulitizer:n prize-winning:j H:n describe:v
event:n in:i american:j M:n when:c elect:v of-
ficial:n take:v principle:v and he:p read:v con-
stantly:r usually:r H:n about:i american:j M:n
or:c biography:n.
This extraction procedure resulted in a corpus
of 1,472,798 strings. There was significant varia-
tion in the number of context strings extracted for
each compound: 288 compounds were associated
with 1,000 or more sentences, while 191 were as-
3 O´ S´eaghdha and Copestake (2008) achieve their single
best result with a different kernel (the Jensen-Shannon RBF
kernel), but the kernel used here (the Jensen-Shannon lin-
ear kernel) generally achieves equivalent performance and
presents one fewer parameter to optimise.
</bodyText>
<page confidence="0.997918">
625
</page>
<table confidence="0.999700777777778">
kjsd kave
Length Acc F Acc F
1 47.9 45.8 43.6 40.4
2 51.7 49.5 49.7 48.3
3 50.7 48.4 50.1 48.6
Σ12 51.5 49.6 48.3 46.8
Σ23 52.1 49.9 50.9 49.5
Σ123 51.3 49.0 50.5 49.1
OPC 44.9 43.3 40.9 40.0
</table>
<tableCaption confidence="0.9940685">
Table 1: Results for combinations of embedding
functions and set kernels
</tableCaption>
<bodyText confidence="0.998106233333333">
sociated with 10 or fewer and no sentences were
found for 45 constituent pairs. The largest context
sets were predominantly associated with political
or economic topics (e.g., government official, oil
price), reflecting the journalistic sources of the Gi-
gaword sentences.
Our implementation of relational similarity ap-
plies the two set kernels kave and kjsd defined in
Section 3.4 to these context sets. For each kernel
we tested gap-weighted embedding functions with
subsequence length values l in the range 1, 2, 3,
as well as summed kernels for all combinations
of values in this range. The decay parameter A
for the subsequence feature embedding was set to
0.5 throughout, in line with previous recommen-
dations (e.g., Cancedda et al. (2003)). To inves-
tigate the effects of varying set sizes, we ran ex-
periments with context sets of maximal cardinality
q E 150,250, 1000}. These sets were randomly
sampled for each compound; for compounds asso-
ciated with fewer strings than the maximal cardi-
nality, all associated strings were used. For q = 50
we average results over five runs in order to re-
duce sampling variation. We also report some
results with the PairClass embedding OPC. The
restricted representative power of this embedding
brings greater efficiency and we were able to use
q = 5, 000; for all but 22 compounds, this allowed
the use of all contexts for which the OPC embed-
ding was defined.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999871448275862">
Table 1 presents results for classification with re-
lational set kernels, using q = 1, 000 for the gap-
weighted embedding. In general, there is little dif-
ference between the performance of kjsd and kave
with Ogapl; the only statistically significant differ-
ences (at p &lt; 0.05, using paired t-tests) are be-
tween the kernels kl=1 with subsequence length
l = 1 and the summed kernels kE12 = kl=1+kl=2.
The best performance of 52.1% accuracy, 49.9%
F-score is obtained with the Jensen-Shannon ker-
nel kjsd computed on the summed feature embed-
dings of length 2 and 3. This is significantly lower
than the performance achieved by O´ S´eaghdha
and Copestake (2008) with their lexical similar-
ity model, but it is well above the majority class
baseline (21.3%). Results for the PairClass em-
bedding are much lower than for the gap-weighted
embedding; the superiority of Ogapl is statistically
significant in all cases except l = 1.
Results for combinations of lexical co-
occurrence kernels and (gap-weighted) relational
set kernels are given in Table 2. With the excep-
tion of some combinations of the length-1 set
kernel, these results are clearly better than the
best results obtained with either the lexical or
the relational model taken alone. The best result
is obtained by the combining the lexical kernel
computed on BNC conjunction features with the
summed Jensen-Shannon set kernel kE23; this
combination achieves 63.1% accuracy and 61.6%
F-score, a statistically significant improvement (at
the p &lt; 0.01 level) over the lexical kernel alone
and the best result yet reported for this dataset.
Also, the benefit of combining set kernels of
different subsequence lengths l is evident; of the
12 combinations presented Table 2 that include
summed set kernels, nine lead to statistically
significant improvements over the corresponding
lexical kernels taken alone (the remaining three
are also close to significance).
Our experiments also show that the distribu-
tional implementation of set kernels (6) is much
more efficient than the averaging implementation
(5). The time behaviour of the two methods
with increasing set cardinality q and subsequence
length l is illustrated in Figure 1. At the largest
tested values of q and l (1,000 and 3, respectively),
the averaging method takes over 33 days of CPU
time, while the distributional method takes just
over one day. In theory, kave scales quadratically
as q increases; this was not observed because for
many constituent pairs there are not enough con-
text strings available to keep adding as q grows
large, but the dependence is certainly superlinear.
The time taken by kjsd is theoretically linear in q,
but again scales less dramatically in practice. On
the other hand kave is linear in l, while kjsd scales
exponentially. This exponential dependence may
</bodyText>
<page confidence="0.997632">
626
</page>
<table confidence="0.9997568">
kjsd kave
BNC 5-Gram BNC 5-Gram
Length Acc F Acc F Acc F Acc F
1 60.6 58.6 60.3 58.1 59.5 57.6 59.1 56.5
2 61.9* 60.4* 62.6 60.8 62.0 60.5* 61.3 59.1
3 62.5* 60.8* 61.7 59.9 62.8* 61.2** 62.3** 60.8**
Σ12 62.6* 61.0** 62.3* 60.6* 62.0* 60.3* 61.5 59.2
Σ23 63.1** 61.6** 62.3* 60.5* 62.2* 60.7* 62.0 60.3
Σ123 62.9** 61.3** 62.6 60.8* 61.9* 60.4* 62.4* 60.6*
No Set 59.9 57.8 60.2 58.1 59.9 57.8 60.2 58.1
</table>
<tableCaption confidence="0.917258">
Table 2: Results for set kernel and lexical kernel combination. */** indicate significant improvement at
the 0.05/0.01 level over the corresponding lexical kernel alone, estimated by paired t-tests.
</tableCaption>
<figure confidence="0.999265151515151">
q
(a) l = 1
Q
(b) l = 2
time/s
108
106
104
102
100
50 250 1000
time/s
108
106
104
102
100
50 250 1000
kave
kjsd
time/s
kave
kjsd
108
kave
106 kjsd
104
102
100
50 250
1000
Q
(c) l = 3
</figure>
<figureCaption confidence="0.999973">
Figure 1: Timing results (in seconds, log-scaled) for averaged and Jensen-Shannon set kernels
</figureCaption>
<bodyText confidence="0.99952375">
seem worrying, but in practice only short subse-
quence lengths are used with string kernels. In
situations where set sizes are small but long sub-
sequence features are desired, the averaging ap-
proach may be more appropriate. However, it
seems likely that many applications will be sim-
ilar to the task considered here, where short sub-
sequences are sufficient and it is desirable to use
as much data as possible to represent each set.
We note that calculating the PairClass embedding,
which counts far fewer patterns, took just 1h21m.
For optimal efficiency, it seems best to use a gap-
weighted embedding with small set cardinality;
averaged across five runs kjsd with q = 50 and
l = Σ123 took 26m to calculate and still achieved
47.6% Accuracy, 45.1% F-score.
</bodyText>
<sectionHeader confidence="0.999908" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999659941176471">
Turney et al. (2003) suggest combining various in-
formation sources for solving SAT analogy prob-
lems. However, previous work on compound in-
terpretation has generally used either lexical simi-
larity or relational similarity but not both in com-
bination. Previously proposed lexical models in-
clude the WordNet-based methods of Kim and
Baldwin (2005) and Girju et al. (2005), and the
distributional model of O´ S´eaghdha and Copes-
take (2008). The idea of using relational similar-
ity to understand compounds goes back at least as
far as Lebowitz’ (1988) RESEARCHER system,
which processed patent abstracts in an incremental
fashion and associated an unseen compound with
the relation expressed in a context where the con-
stituents previously occurred.
Turney (2006) describes a method (Latent Rela-
tional Analysis) that extracts subsequence patterns
for noun pairs from a large corpus, using query
expansion to increase the recall of the search and
feature selection and dimensionality reduction to
reduce the complexity of the feature space. LRA
performs well on analogical tasks including com-
pound interpretation, but has very substantial re-
source requirements. Turney (2008) has recently
proposed a simpler SVM-based algorithm for ana-
logical classification called PairClass. While it
does not adopt a set-based or distributional model
of relational similarity, we have noted above that
PairClass implicitly uses a feature representation
similar to the one presented above as (6) by ex-
tracting subsequence patterns from observed co-
occurrences of word pair members. Indeed, Pair-
Class can be viewed as a special case of our frame-
</bodyText>
<page confidence="0.994649">
627
</page>
<bodyText confidence="0.999960979591837">
work; the differences from the model we have
used consist in the use of a different embedding
function Opc and a more restricted notion of con-
text, a frequency cutoff to eliminate less common
subsequences and the Gaussian kernel to compare
vectors. While we cannot compare methods di-
rectly as we do not possess the large corpus of
5 x 1010 words used by Turney, we have tested
the impact of each of these modifications on our
model.4 None improve performance with our set
kernels, but the only statistically significant effect
is that of changing the embedding model as re-
ported in section Section 5. Implementing the full
PairClass algorithm on our corpus yields 46.2%
accuracy, 44.9% F-score, which is again signifi-
cantly worse than all results for the gap-weighted
model with l &gt; 1.
In NLP, there has not been widespread use of
set representations for data items, and hence set
classification techniques have received little at-
tention. Notable exceptions include Rosario and
Hearst (2005) and Bunescu and Mooney (2007),
who tackle relation classification and extraction
tasks by considering the set of contexts in which
the members of a candidate relation argument pair
co-occur. While this gives a set representation for
each pair, both sets of authors apply classifica-
tion methods at the level of individual set mem-
bers rather than directly comparing sets. There
is also a close connection between the multino-
mial probability model we have proposed and the
pervasive bag of words (or bag of n-grams) repre-
sentation. Distributional kernels based on a gap-
weighted feature embedding extend these models
by using bags of discontinuous n-grams and down-
weighting gappy subsequences.
A number of set kernels other than those dis-
cussed here have been proposed in the machine
learning literature, though none of these propos-
als have explicitly addressed the problem of com-
paring sets of strings or other structured objects,
and many are suitable only for comparing sets of
small cardinality. Kondor and Jebara (2003) take a
distributional approach similar to ours, fitting mul-
tivariate normal distributions to the feature space
mappings of sets A and B and comparing the map-
pings with the Bhattacharrya vector inner product.
The model described above in (6) implicitly fits
multinomial distributions in the feature space F;
</bodyText>
<footnote confidence="0.6247325">
4Turney (p.c.) reports that the full PairClass model
achieves 50.0% accuracy, 49.3% F-score.
</footnote>
<bodyText confidence="0.99959625">
this seems more intuitive for string kernel embed-
dings that map strings onto vectors of positive-
valued “counts”. Experiments with Kondor and
Jebara’s Bhattacharrya kernel indicate that it can
in fact come close to the performances reported
in Section 5 but has significantly greater compu-
tational requirements due to the need to perform
costly matrix manipulations.
</bodyText>
<sectionHeader confidence="0.964885" genericHeader="conclusions">
7 Conclusion and future directions
</sectionHeader>
<bodyText confidence="0.999585625">
In this paper we have presented a combined model
of lexical and relational similarity for relational
reasoning tasks. We have developed an efficient
and flexible kernel-based framework for compar-
ing sets of contexts using the feature embedding
associated with a string kernel.5 By choosing a
particular embedding function and a particular in-
ner product on subsequence vectors, the previ-
ously proposed set-averaging and PairClass algo-
rithms for relational similarity can be retrieved as
special cases. Applying our methods to the task
of compound noun interpretation, we have shown
that combining lexical and relational similarity is a
very effective approach that surpasses either simi-
larity model taken individually.
Turney (2008) argues that many NLP tasks can
be formulated in terms of analogical reasoning,
and he applies his PairClass algorithm to a number
of problems including SAT verbal analogy tests,
synonym/antonym classification and distinction
between semantically similar and semantically as-
sociated words. Our future research plans include
investigating the application of our combined sim-
ilarity model to analogical tasks other than com-
pound noun interpretation. A second promising
direction is to investigate relational models for un-
supervised semantic analysis of noun compounds.
The range of semantic relations that can be ex-
pressed by compounds is the subject of some con-
troversy (Ryder, 1994), and unsupervised learning
methods offer a data-driven means of discovering
relational classes.
</bodyText>
<sectionHeader confidence="0.996514" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9973115">
We are grateful to Peter Turney, Andreas Vla-
chos and the anonymous EACL reviewers for their
helpful comments. This work was supported in
part by EPSRC grant EP/C010035/1.
</bodyText>
<footnote confidence="0.8999285">
5The treatment presented here has used a string represen-
tation of context, but the method could be extended to other
structural representations for which substructure embeddings
exist, such as syntactic trees (Collins and Duffy, 2001).
</footnote>
<page confidence="0.9956">
628
</page>
<sectionHeader confidence="0.995774" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884097345133">
Thorsten Brants and Alex Franz, 2006. Web 1T 5-gram
Corpus Version 1.1. Linguistic Data Consortium.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the RASP system. In Pro-
ceedings of the ACL-06 Interactive Presentation
Sessions.
Razvan C. Bunescu and Raymond J. Mooney. 2007.
Learning to extract relations from the Web using
minimal supervision. In Proceedings of the 45th An-
nual Meeting of the Association for Computational
Linguistics (ACL-07).
Lou Burnard, 1995. Users’ Guide for the British Na-
tional Corpus. British National Corpus Consortium.
Cristina Butnariu and Tony Veale. 2008. A concept-
centered approach to noun-compound interpretation.
In Proceedings of the 22nd International Conference
on Computational Linguistics (COLING-08).
Nicola Cancedda, Eric Gaussier, Cyril Goutte, and
Jean-Michel Renders. 2003. Word-sequence ker-
nels. Journal of Machine Learning Research,
3:1059–1082.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Proceedings of the
15th Conference on Neural Information Processing
Systems (NIPS-01).
Corinna Cortes and Vladimir Vapnik. 1995. Support
vector networks. Machine Learning, 20(3):273–
297.
Nello Cristianini, Jaz Kandola, Andre Elisseeff, and
John Shawe-Taylor. 2001. On kernel target align-
ment. Technical Report NC-TR-01-087, Neuro-
COLT.
James Curran. 2004. From Distributional to Seman-
tic Similarity. Ph.D. thesis, School of Informatics,
University of Edinburgh.
Barry Devereux and Fintan Costello. 2007. Learning
to interpret novel noun-noun compounds: Evidence
from a category learning experiment. In Proceed-
ings of the ACL-07 Workshop on Cognitive Aspects
of Computational Language Acquisition.
Thomas G¨artner, Peter A. Flach, Adam Kowalczyk,
and Alex J. Smola. 2002. Multi-instance kernels.
In Proceedings of the 19th International Conference
on Machine Learning (ICML-02).
Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel
Antohe. 2005. On the semantics of noun
compounds. Computer Speech and Language,
19(4):479–496.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
SemEval-2007 Task 04: Classification of seman-
tic relations between nominals. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations (SemEval-07).
Alfio Gliozzo, Claudio Giuliano, and Carlo Strappar-
ava. 2005. Domain kernels for word sense disam-
biguation. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL-05).
David Graff, Junbo Kong, Ke Chen, and Kazuaki
Maeda, 2005. English Gigaword Corpus, 2nd Edi-
tion. Linguistic Data Consortium.
Thorsten Joachims, Nello Cristianini, and John Shawe-
Taylor. 2001. Composite kernels for hypertext cate-
gorisation. In Proceedings of the 18th International
Conference on Machine Learning (ICML-01).
Su Nam Kim and Timothy Baldwin. 2005. Automatic
interpretation of noun compounds using WordNet
similarity. In Proceedings of the 2nd International
Joint Conference on Natural Language Processing
(IJCNLP-05).
Risi Kondor and Tony Jebara. 2003. A kernel between
sets of vectors. In Proceedings of the 20th Interna-
tional Conference on Machine Learning (ICML-03).
Michael Lebowitz. 1988. The use of memory in
text processing. Communications of the ACM,
31(12):1483–1502.
Huma Lodhi, Craig Saunders, John Shawe-Taylor,
Nello Cristianini, and Christopher J. C. H. Watkins.
2002. Text classification using string kernels. Jour-
nal of Machine Learning Research, 2:419–444.
Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Co-
occurrence contexts for noun compound interpreta-
tion. In Proceedings of the ACL-07 Workshop on A
Broader Perspective on Multiword Expressions.
Diarmuid O´ S´eaghdha and Ann Copestake. 2008. Se-
mantic classification with distributional kernels. In
Proceedings of the 22nd International Conference
on Computational Linguistics (COLING-08).
Barbara Rosario and Marti A. Hearst. 2005. Multi-
way relation classification: Application to protein-
protein interactions. In Proceedings of the 2005
Human Language Technology Conference and Con-
ference on Empirical Methods in Natural Language
Processing (HLT-EMNLP-05).
Mary Ellen Ryder. 1994. Ordered Chaos: The Inter-
pretation of English Noun-Noun Compounds. Uni-
versity of California Press, Berkeley, CA.
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press, Cambridge.
Peter D. Turney, Michael L. Littman, Jeffrey Bigham,
and Victor Shnayder. 2003. Combining indepen-
dent modules to solve multiple-choice synonym and
analogy problems. In Proceedings of the 2003 Inter-
national Conference on Recent Advances in Natural
Language Processing (RANLP-03).
Peter D. Turney. 2006. Similarity of semantic rela-
tions. Computational Linguistics, 32(3):379–416.
Peter D. Turney. 2008. A uniform approach to analo-
gies, synonyms, antonyms, and associations. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics (COLING-08).
</reference>
<page confidence="0.99888">
629
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.528472">
<title confidence="0.998784">Using lexical and relational similarity to classify semantic relations</title>
<author confidence="0.702539">O´S´eaghdha</author>
<affiliation confidence="0.999987">Computer Laboratory University of Cambridge</affiliation>
<address confidence="0.930652666666667">15 JJ Thomson Avenue Cambridge CB3 0FD United Kingdom</address>
<email confidence="0.985159">do242@cl.cam.ac.uk</email>
<abstract confidence="0.996787235294118">Many methods are available for computing semantic similarity between individual words, but certain NLP tasks require the comparison of word pairs. This paper presents a kernel-based framework for application to relational reasoning tasks of this kind. The model presented here combines information about two distinct types of word pair similarity: lexical similarity and relational similarity. We present an efficient and flexible technique for implementing relational similarity and show the effectiveness of combining lexical and relational models by demonstrating state-ofthe-art results on a compound noun interpretation task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram Corpus Version 1.1. Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="19017" citStr="Brants and Franz, 2006" startWordPosition="3150" endWordPosition="3153">kernel matrices were precomputed on nearidentical machines with 2.4 Ghz 64-bit processors and 8Gb of memory. The kernel matrix computation is trivial to parallelise, as each cell is independent. Spreading the computational load across multiple processors is a simple way to reduce the real time cost of the procedure. 4.3 Lexical features Our implementation of the lexical similarity model uses the same feature set as O´ S´eaghdha and Copestake (2008). Two corpora were used to extract co-occurrence information: the written component of the BNC (Burnard, 1995) and the Google Web 1T 5-Gram Corpus (Brants and Franz, 2006). For each noun appearing as a compound constituent in the dataset, we estimate a cooccurrence distribution based on the nouns in coordinative constructions. Conjunctions are identified in the BNC by first parsing the corpus with RASP (Briscoe et al., 2006) and extracting instances of the conj grammatical relation. As the 5-Gram corpus does not contain full sentences it cannot be parsed, so regular expressions were used to extract coordinations. In each corpus, the set of co-occurring terms is restricted to the 10,000 most frequent conjuncts in that corpus so that each constituent distribution</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz, 2006. Web 1T 5-gram Corpus Version 1.1. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL-06 Interactive Presentation Sessions.</booktitle>
<contexts>
<context position="19274" citStr="Briscoe et al., 2006" startWordPosition="3194" endWordPosition="3197"> simple way to reduce the real time cost of the procedure. 4.3 Lexical features Our implementation of the lexical similarity model uses the same feature set as O´ S´eaghdha and Copestake (2008). Two corpora were used to extract co-occurrence information: the written component of the BNC (Burnard, 1995) and the Google Web 1T 5-Gram Corpus (Brants and Franz, 2006). For each noun appearing as a compound constituent in the dataset, we estimate a cooccurrence distribution based on the nouns in coordinative constructions. Conjunctions are identified in the BNC by first parsing the corpus with RASP (Briscoe et al., 2006) and extracting instances of the conj grammatical relation. As the 5-Gram corpus does not contain full sentences it cannot be parsed, so regular expressions were used to extract coordinations. In each corpus, the set of co-occurring terms is restricted to the 10,000 most frequent conjuncts in that corpus so that each constituent distribution is represented with a 10,000- dimensional vector. The probability vector for the compound is created by appending the two constituent vectors, each scaled by 0.5 to weight both 2http://www.csie.ntu.edu.tw/˜cjlin/ libsvm constituents equally and ensure that</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the RASP system. In Proceedings of the ACL-06 Interactive Presentation Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to extract relations from the Web using minimal supervision.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07).</booktitle>
<contexts>
<context position="31064" citStr="Bunescu and Mooney (2007)" startWordPosition="5132" endWordPosition="5135">of these modifications on our model.4 None improve performance with our set kernels, but the only statistically significant effect is that of changing the embedding model as reported in section Section 5. Implementing the full PairClass algorithm on our corpus yields 46.2% accuracy, 44.9% F-score, which is again significantly worse than all results for the gap-weighted model with l &gt; 1. In NLP, there has not been widespread use of set representations for data items, and hence set classification techniques have received little attention. Notable exceptions include Rosario and Hearst (2005) and Bunescu and Mooney (2007), who tackle relation classification and extraction tasks by considering the set of contexts in which the members of a candidate relation argument pair co-occur. While this gives a set representation for each pair, both sets of authors apply classification methods at the level of individual set members rather than directly comparing sets. There is also a close connection between the multinomial probability model we have proposed and the pervasive bag of words (or bag of n-grams) representation. Distributional kernels based on a gapweighted feature embedding extend these models by using bags of</context>
</contexts>
<marker>Bunescu, Mooney, 2007</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2007. Learning to extract relations from the Web using minimal supervision. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Users’ Guide for the British National Corpus. British National Corpus Consortium.</title>
<date>1995</date>
<contexts>
<context position="18956" citStr="Burnard, 1995" startWordPosition="3141" endWordPosition="3142">2) through crossvalidation on the training set. All kernel matrices were precomputed on nearidentical machines with 2.4 Ghz 64-bit processors and 8Gb of memory. The kernel matrix computation is trivial to parallelise, as each cell is independent. Spreading the computational load across multiple processors is a simple way to reduce the real time cost of the procedure. 4.3 Lexical features Our implementation of the lexical similarity model uses the same feature set as O´ S´eaghdha and Copestake (2008). Two corpora were used to extract co-occurrence information: the written component of the BNC (Burnard, 1995) and the Google Web 1T 5-Gram Corpus (Brants and Franz, 2006). For each noun appearing as a compound constituent in the dataset, we estimate a cooccurrence distribution based on the nouns in coordinative constructions. Conjunctions are identified in the BNC by first parsing the corpus with RASP (Briscoe et al., 2006) and extracting instances of the conj grammatical relation. As the 5-Gram corpus does not contain full sentences it cannot be parsed, so regular expressions were used to extract coordinations. In each corpus, the set of co-occurring terms is restricted to the 10,000 most frequent c</context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>Lou Burnard, 1995. Users’ Guide for the British National Corpus. British National Corpus Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Butnariu</author>
<author>Tony Veale</author>
</authors>
<title>A conceptcentered approach to noun-compound interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</booktitle>
<contexts>
<context position="2099" citStr="Butnariu and Veale, 2008" startWordPosition="326" endWordPosition="330">similar because in both cases the relation N2 is made of N1 frequently holds between their members. Analogical tasks are distinct from (but not unrelated to) other kinds of “relation extraction” tasks where each data item is tied to a specific sentence context (e.g., Gir u et al. (2007)). One such relational reasoning task is the problem of compound noun interpretation, which Ann Copestake Computer Laboratory University of Cambridge 15 JJ Thomson Avenue Cambridge CB3 0FD United Kingdom aac10@cl.cam.ac.uk has received a great deal of attention in recent years (Gir u et al., 2005; Turney, 2006; Butnariu and Veale, 2008). In English (and other languages), the process of producing new lexical items through compounding is very frequent and very productive. Furthermore, the noun-noun relation expressed by a given compound is not explicit in its surface form: a steel knife may be a knife made from steel but a kitchen knife is most likely to be a knife used in a kitchen, not a knife made from a kitchen. The assumption made by similarity-based interpretation methods is that the likely meaning of a novel compound can be predicted by comparing it to previously seen compounds whose meanings are known. This is a natura</context>
</contexts>
<marker>Butnariu, Veale, 2008</marker>
<rawString>Cristina Butnariu and Tony Veale. 2008. A conceptcentered approach to noun-compound interpretation. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Cancedda</author>
</authors>
<title>Eric Gaussier, Cyril Goutte, and Jean-Michel Renders.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1059</pages>
<marker>Cancedda, 2003</marker>
<rawString>Nicola Cancedda, Eric Gaussier, Cyril Goutte, and Jean-Michel Renders. 2003. Word-sequence kernels. Journal of Machine Learning Research, 3:1059–1082.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<booktitle>In Proceedings of the 15th Conference on Neural Information Processing Systems (NIPS-01).</booktitle>
<marker>Collins, Duffy, 2001</marker>
<rawString>Michael Collins and Nigel Duffy. 2001. Convolution kernels for natural language. In Proceedings of the 15th Conference on Neural Information Processing Systems (NIPS-01).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support vector networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<volume>20</volume>
<issue>3</issue>
<pages>297</pages>
<contexts>
<context position="8396" citStr="Cortes and Vapnik, 1995" startWordPosition="1346" endWordPosition="1349"> product associated with F. X and F need not have the same dimensionality or be of the same type. F is by definition an inner product space, but the elements of X need not even be vectorial, so long as a suitable mapping function 0 can be found. Furthermore, it is often possible to calculate kernel values without explicitly representing the elements of F; this allows the use of implicit feature spaces with a very high or even infinite dimensionality. Kernel functions have received significant attention in recent years, most notably due to the successful application of Support Vector Machines (Cortes and Vapnik, 1995) to many problems. The SVM algorithm learns a decision boundary between two data classes that maximises the minimum distance or margin from the training points in each class to the boundary. The geometry of the space in which this boundary is set depends on the 622 kernel function used to compare data items. By tailoring the choice of kernel to the task at hand, the user can use prior knowledge and intuition to improve classification performance. One useful property of kernels is that any sum or linear combination of kernel functions is itself a valid kernel. Theoretical analyses (Cristianini </context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Support vector networks. Machine Learning, 20(3):273– 297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>Jaz Kandola</author>
<author>Andre Elisseeff</author>
<author>John Shawe-Taylor</author>
</authors>
<title>On kernel target alignment.</title>
<date>2001</date>
<tech>Technical Report NC-TR-01-087, NeuroCOLT.</tech>
<contexts>
<context position="9008" citStr="Cristianini et al., 2001" startWordPosition="1450" endWordPosition="1453">apnik, 1995) to many problems. The SVM algorithm learns a decision boundary between two data classes that maximises the minimum distance or margin from the training points in each class to the boundary. The geometry of the space in which this boundary is set depends on the 622 kernel function used to compare data items. By tailoring the choice of kernel to the task at hand, the user can use prior knowledge and intuition to improve classification performance. One useful property of kernels is that any sum or linear combination of kernel functions is itself a valid kernel. Theoretical analyses (Cristianini et al., 2001; Joachims et al., 2001) and empirical investigations (e.g., Gliozzo et al. (2005)) have shown that combining kernels in this way can have a beneficial effect when the component kernels capture different “views” of the data while individually attaining similar levels of discriminative performance. In the experiments described below, we make use of this insight to integrate lexical and relational information for semantic classification of compound nouns. 3.2 Lexical kernels O´ S´eaghdha and Copestake (2008) demonstrate how standard techniques for distributional similarity can be implemented in </context>
</contexts>
<marker>Cristianini, Kandola, Elisseeff, Shawe-Taylor, 2001</marker>
<rawString>Nello Cristianini, Jaz Kandola, Andre Elisseeff, and John Shawe-Taylor. 2001. On kernel target alignment. Technical Report NC-TR-01-087, NeuroCOLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
</authors>
<title>From Distributional to Semantic Similarity.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="5661" citStr="Curran (2004)" startWordPosition="898" endWordPosition="899">ar to w3 and w2 is similar to w4. Given a measure wsim of word-word similarity, a measure of pair similarity psim can be derived as a linear combination of pairwise lexical similarities: psim((w1, w2), (w3, w4)) _ (1) a[wsim(w1, w3)] + Q[wsim(w2, w4)] A great number of methods for lexical semantic similarity have been proposed in the NLP literature. The most common paradigm for corpusbased methods, and the one adopted here, is based on the distributional hypothesis: that two words are semantically similar if they have similar patterns of co-occurrence with other words in some set of contexts. Curran (2004) gives a comprehensive overview of distributional methods. The second model of pair similarity rests on the assumption that when the members of a word pair are mentioned in the same context, that context is likely to yield information about the relations holding between the words’ referents. For example, the members of the pair (bear, forest) may tend to co-occur in contexts containing patterns such as w1 lives in the w2 and in the w2,... a w1, suggesting that a LOCATED IN or LIVES IN relation frequently holds between bears and forests. If the contexts in which fish and reef co-occur are simil</context>
</contexts>
<marker>Curran, 2004</marker>
<rawString>James Curran. 2004. From Distributional to Semantic Similarity. Ph.D. thesis, School of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Devereux</author>
<author>Fintan Costello</author>
</authors>
<title>Learning to interpret novel noun-noun compounds: Evidence from a category learning experiment.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-07 Workshop on Cognitive Aspects of Computational Language Acquisition.</booktitle>
<contexts>
<context position="2880" citStr="Devereux and Costello, 2007" startWordPosition="457" endWordPosition="460"> noun-noun relation expressed by a given compound is not explicit in its surface form: a steel knife may be a knife made from steel but a kitchen knife is most likely to be a knife used in a kitchen, not a knife made from a kitchen. The assumption made by similarity-based interpretation methods is that the likely meaning of a novel compound can be predicted by comparing it to previously seen compounds whose meanings are known. This is a natural framework for computational techniques; there is also empirical evidence for similaritybased interpretation in human compound processing (Ryder, 1994; Devereux and Costello, 2007). This paper presents an approach to relational reasoning based on combining information about two kinds of similarity between word pairs: lexical similarity and relational similarity. The assumptions underlying these two models of similarity are sketched in Section 2. In Section 3 we describe how these models can be implemented for statistical machine learning with kernel methods. We present a new flexible and efficient kernelbased framework for classification with relational similarity. In Sections 4 and 5 we apply our methods to a compound interpretation task and demonstrate that combining </context>
</contexts>
<marker>Devereux, Costello, 2007</marker>
<rawString>Barry Devereux and Fintan Costello. 2007. Learning to interpret novel noun-noun compounds: Evidence from a category learning experiment. In Proceedings of the ACL-07 Workshop on Cognitive Aspects of Computational Language Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G¨artner</author>
<author>Peter A Flach</author>
<author>Adam Kowalczyk</author>
<author>Alex J Smola</author>
</authors>
<title>Multi-instance kernels.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Machine Learning (ICML-02).</booktitle>
<marker>G¨artner, Flach, Kowalczyk, Smola, 2002</marker>
<rawString>Thomas G¨artner, Peter A. Flach, Adam Kowalczyk, and Alex J. Smola. 2002. Multi-instance kernels. In Proceedings of the 19th International Conference on Machine Learning (ICML-02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Dan Moldovan</author>
<author>Marta Tatu</author>
<author>Daniel Antohe</author>
</authors>
<title>On the semantics of noun compounds.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="28787" citStr="Girju et al. (2005)" startWordPosition="4768" endWordPosition="4771">ust 1h21m. For optimal efficiency, it seems best to use a gapweighted embedding with small set cardinality; averaged across five runs kjsd with q = 50 and l = Σ123 took 26m to calculate and still achieved 47.6% Accuracy, 45.1% F-score. 6 Related work Turney et al. (2003) suggest combining various information sources for solving SAT analogy problems. However, previous work on compound interpretation has generally used either lexical similarity or relational similarity but not both in combination. Previously proposed lexical models include the WordNet-based methods of Kim and Baldwin (2005) and Girju et al. (2005), and the distributional model of O´ S´eaghdha and Copestake (2008). The idea of using relational similarity to understand compounds goes back at least as far as Lebowitz’ (1988) RESEARCHER system, which processed patent abstracts in an incremental fashion and associated an unseen compound with the relation expressed in a context where the constituents previously occurred. Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimens</context>
</contexts>
<marker>Girju, Moldovan, Tatu, Antohe, 2005</marker>
<rawString>Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel Antohe. 2005. On the semantics of noun compounds. Computer Speech and Language, 19(4):479–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Preslav Nakov</author>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
<author>Peter Turney</author>
<author>Deniz Yuret</author>
</authors>
<title>SemEval-2007 Task 04: Classification of semantic relations between nominals.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-07).</booktitle>
<marker>Girju, Nakov, Nastase, Szpakowicz, Turney, Yuret, 2007</marker>
<rawString>Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Szpakowicz, Peter Turney, and Deniz Yuret. 2007. SemEval-2007 Task 04: Classification of semantic relations between nominals. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfio Gliozzo</author>
<author>Claudio Giuliano</author>
<author>Carlo Strapparava</author>
</authors>
<title>Domain kernels for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05).</booktitle>
<contexts>
<context position="9090" citStr="Gliozzo et al. (2005)" startWordPosition="1463" endWordPosition="1466">wo data classes that maximises the minimum distance or margin from the training points in each class to the boundary. The geometry of the space in which this boundary is set depends on the 622 kernel function used to compare data items. By tailoring the choice of kernel to the task at hand, the user can use prior knowledge and intuition to improve classification performance. One useful property of kernels is that any sum or linear combination of kernel functions is itself a valid kernel. Theoretical analyses (Cristianini et al., 2001; Joachims et al., 2001) and empirical investigations (e.g., Gliozzo et al. (2005)) have shown that combining kernels in this way can have a beneficial effect when the component kernels capture different “views” of the data while individually attaining similar levels of discriminative performance. In the experiments described below, we make use of this insight to integrate lexical and relational information for semantic classification of compound nouns. 3.2 Lexical kernels O´ S´eaghdha and Copestake (2008) demonstrate how standard techniques for distributional similarity can be implemented in a kernel framework. In particular, kernels for comparing probability distributions</context>
</contexts>
<marker>Gliozzo, Giuliano, Strapparava, 2005</marker>
<rawString>Alfio Gliozzo, Claudio Giuliano, and Carlo Strapparava. 2005. Domain kernels for word sense disambiguation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2005</date>
<booktitle>English Gigaword Corpus, 2nd Edition. Linguistic Data Consortium.</booktitle>
<contexts>
<context position="20347" citStr="Graff et al., 2005" startWordPosition="3363" endWordPosition="3366">ing the two constituent vectors, each scaled by 0.5 to weight both 2http://www.csie.ntu.edu.tw/˜cjlin/ libsvm constituents equally and ensure that the new vector sums to 1. To perform classification with these features we use the Jensen-Shannon kernel (3).3 4.4 Relational features To extract data for computing relational similarity, we searched a large corpus for sentences in which both constituents of a compound co-occur. The corpora used here are the written BNC, containing 90 million words of British English balanced across genre and text type, and the English Gigaword Corpus, 2nd Edition (Graff et al., 2005), containing 2.3 billion words of newswire text. Extraction from the Gigaword Corpus was performed at the paragraph level as the corpus is not annotated for sentence boundaries, and a dictionary of plural forms and American English variants was used to expand the coverage of the corpus trawl. The extracted contexts were split into sentences, tagged and lemmatised with RASP. Duplicate sentences were discarded, as were sentences in which the compound head and modifier were more than 10 words apart. Punctuation and tokens containing non-alphanumeric characters were removed. The compound modifier </context>
</contexts>
<marker>Graff, Kong, Chen, Maeda, 2005</marker>
<rawString>David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda, 2005. English Gigaword Corpus, 2nd Edition. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
<author>Nello Cristianini</author>
<author>John ShaweTaylor</author>
</authors>
<title>Composite kernels for hypertext categorisation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML-01).</booktitle>
<contexts>
<context position="9032" citStr="Joachims et al., 2001" startWordPosition="1454" endWordPosition="1457">ems. The SVM algorithm learns a decision boundary between two data classes that maximises the minimum distance or margin from the training points in each class to the boundary. The geometry of the space in which this boundary is set depends on the 622 kernel function used to compare data items. By tailoring the choice of kernel to the task at hand, the user can use prior knowledge and intuition to improve classification performance. One useful property of kernels is that any sum or linear combination of kernel functions is itself a valid kernel. Theoretical analyses (Cristianini et al., 2001; Joachims et al., 2001) and empirical investigations (e.g., Gliozzo et al. (2005)) have shown that combining kernels in this way can have a beneficial effect when the component kernels capture different “views” of the data while individually attaining similar levels of discriminative performance. In the experiments described below, we make use of this insight to integrate lexical and relational information for semantic classification of compound nouns. 3.2 Lexical kernels O´ S´eaghdha and Copestake (2008) demonstrate how standard techniques for distributional similarity can be implemented in a kernel framework. In p</context>
</contexts>
<marker>Joachims, Cristianini, ShaweTaylor, 2001</marker>
<rawString>Thorsten Joachims, Nello Cristianini, and John ShaweTaylor. 2001. Composite kernels for hypertext categorisation. In Proceedings of the 18th International Conference on Machine Learning (ICML-01).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using WordNet similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05).</booktitle>
<contexts>
<context position="28763" citStr="Kim and Baldwin (2005)" startWordPosition="4763" endWordPosition="4766"> far fewer patterns, took just 1h21m. For optimal efficiency, it seems best to use a gapweighted embedding with small set cardinality; averaged across five runs kjsd with q = 50 and l = Σ123 took 26m to calculate and still achieved 47.6% Accuracy, 45.1% F-score. 6 Related work Turney et al. (2003) suggest combining various information sources for solving SAT analogy problems. However, previous work on compound interpretation has generally used either lexical similarity or relational similarity but not both in combination. Previously proposed lexical models include the WordNet-based methods of Kim and Baldwin (2005) and Girju et al. (2005), and the distributional model of O´ S´eaghdha and Copestake (2008). The idea of using relational similarity to understand compounds goes back at least as far as Lebowitz’ (1988) RESEARCHER system, which processed patent abstracts in an incremental fashion and associated an unseen compound with the relation expressed in a context where the constituents previously occurred. Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feat</context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2005. Automatic interpretation of noun compounds using WordNet similarity. In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Risi Kondor</author>
<author>Tony Jebara</author>
</authors>
<title>A kernel between sets of vectors.</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th International Conference on Machine Learning (ICML-03).</booktitle>
<contexts>
<context position="32055" citStr="Kondor and Jebara (2003)" startWordPosition="5291" endWordPosition="5294">ection between the multinomial probability model we have proposed and the pervasive bag of words (or bag of n-grams) representation. Distributional kernels based on a gapweighted feature embedding extend these models by using bags of discontinuous n-grams and downweighting gappy subsequences. A number of set kernels other than those discussed here have been proposed in the machine learning literature, though none of these proposals have explicitly addressed the problem of comparing sets of strings or other structured objects, and many are suitable only for comparing sets of small cardinality. Kondor and Jebara (2003) take a distributional approach similar to ours, fitting multivariate normal distributions to the feature space mappings of sets A and B and comparing the mappings with the Bhattacharrya vector inner product. The model described above in (6) implicitly fits multinomial distributions in the feature space F; 4Turney (p.c.) reports that the full PairClass model achieves 50.0% accuracy, 49.3% F-score. this seems more intuitive for string kernel embeddings that map strings onto vectors of positivevalued “counts”. Experiments with Kondor and Jebara’s Bhattacharrya kernel indicate that it can in fact</context>
</contexts>
<marker>Kondor, Jebara, 2003</marker>
<rawString>Risi Kondor and Tony Jebara. 2003. A kernel between sets of vectors. In Proceedings of the 20th International Conference on Machine Learning (ICML-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lebowitz</author>
</authors>
<title>The use of memory in text processing.</title>
<date>1988</date>
<journal>Communications of the ACM,</journal>
<volume>31</volume>
<issue>12</issue>
<marker>Lebowitz, 1988</marker>
<rawString>Michael Lebowitz. 1988. The use of memory in text processing. Communications of the ACM, 31(12):1483–1502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huma Lodhi</author>
<author>Craig Saunders</author>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
<author>Christopher J C H Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--419</pages>
<contexts>
<context position="12447" citStr="Lodhi et al. (2002)" startWordPosition="2036" endWordPosition="2039"> subsequence in s. An embedding φstring : E* —* R|Σ|l is a function that maps a string s onto a vector of positive “counts” that correspond to subsequences contained in s. One example of an embedding function is a gap-weighted embedding, defined as 1: φgapl(s) = [ λlen(i)]uEΣl (4) i:s[i]=u λ is a decay parameter between 0 and 1; the smaller its value, the more the influence of a discontinuous subsequence is reduced. When l = 1 this corresponds to a “bag-of-words” embedding. Gap-weighted string kernels implicitly compute the similarity between two strings s, t as an inner product (φ(s), φ(t)). Lodhi et al. (2002) present an efficient dynamic programming algorithm that evaluates this kernel in O(l|s||t|) time without explicitly representing the feature vectors φ(s), φ(t). An alternative embedding is that used by Turney (2008) in his PairClass system (see Section 6). For the PairClass embedding φPC, an n-word context [0−1 words] N1|2 [0−3 words] N1|2 [0−1 words] containing target words N1, N2 is mapped onto the 2n−2 patterns produced by substituting zero or more of the context words with a wildcard *. Unlike the patterns used by the gap-weighted embedding these are not truly discontinuous, as each wildc</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Christopher J. C. H. Watkins. 2002. Text classification using string kernels. Journal of Machine Learning Research, 2:419–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Cooccurrence contexts for noun compound interpretation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-07 Workshop on A Broader Perspective on Multiword Expressions.</booktitle>
<marker>S´eaghdha, Copestake, 2007</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Cooccurrence contexts for noun compound interpretation. In Proceedings of the ACL-07 Workshop on A Broader Perspective on Multiword Expressions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Semantic classification with distributional kernels.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</booktitle>
<marker>S´eaghdha, Copestake, 2008</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. 2008. Semantic classification with distributional kernels. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti A Hearst</author>
</authors>
<title>Multiway relation classification: Application to proteinprotein interactions.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT-EMNLP-05).</booktitle>
<contexts>
<context position="31034" citStr="Rosario and Hearst (2005)" startWordPosition="5127" endWordPosition="5130">ave tested the impact of each of these modifications on our model.4 None improve performance with our set kernels, but the only statistically significant effect is that of changing the embedding model as reported in section Section 5. Implementing the full PairClass algorithm on our corpus yields 46.2% accuracy, 44.9% F-score, which is again significantly worse than all results for the gap-weighted model with l &gt; 1. In NLP, there has not been widespread use of set representations for data items, and hence set classification techniques have received little attention. Notable exceptions include Rosario and Hearst (2005) and Bunescu and Mooney (2007), who tackle relation classification and extraction tasks by considering the set of contexts in which the members of a candidate relation argument pair co-occur. While this gives a set representation for each pair, both sets of authors apply classification methods at the level of individual set members rather than directly comparing sets. There is also a close connection between the multinomial probability model we have proposed and the pervasive bag of words (or bag of n-grams) representation. Distributional kernels based on a gapweighted feature embedding extend</context>
</contexts>
<marker>Rosario, Hearst, 2005</marker>
<rawString>Barbara Rosario and Marti A. Hearst. 2005. Multiway relation classification: Application to proteinprotein interactions. In Proceedings of the 2005 Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT-EMNLP-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Ryder</author>
</authors>
<title>Ordered Chaos: The Interpretation of English Noun-Noun Compounds.</title>
<date>1994</date>
<publisher>University of California Press,</publisher>
<location>Berkeley, CA.</location>
<contexts>
<context position="2850" citStr="Ryder, 1994" startWordPosition="455" endWordPosition="456">thermore, the noun-noun relation expressed by a given compound is not explicit in its surface form: a steel knife may be a knife made from steel but a kitchen knife is most likely to be a knife used in a kitchen, not a knife made from a kitchen. The assumption made by similarity-based interpretation methods is that the likely meaning of a novel compound can be predicted by comparing it to previously seen compounds whose meanings are known. This is a natural framework for computational techniques; there is also empirical evidence for similaritybased interpretation in human compound processing (Ryder, 1994; Devereux and Costello, 2007). This paper presents an approach to relational reasoning based on combining information about two kinds of similarity between word pairs: lexical similarity and relational similarity. The assumptions underlying these two models of similarity are sketched in Section 2. In Section 3 we describe how these models can be implemented for statistical machine learning with kernel methods. We present a new flexible and efficient kernelbased framework for classification with relational similarity. In Sections 4 and 5 we apply our methods to a compound interpretation task a</context>
</contexts>
<marker>Ryder, 1994</marker>
<rawString>Mary Ellen Ryder. 1994. Ordered Chaos: The Interpretation of English Noun-Noun Compounds. University of California Press, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="7285" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="1149" endWordPosition="1152">y Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. O´ S´eaghdha and Copestake’s (2007) classification of information sources for noun compound interpretation also includes a description of lexical and relational similarity. Approaches to compound noun interpretation have tended to use either lexical or relational similarity, though rarely both (see Section 6 below). 3 Kernel methods for pair similarity 3.1 Kernel methods The kernel framework for machine learning is a natural choice for similarity-based classification (Shawe-Taylor and Cristianini, 2004). The central concept in this framework is the kernel function, which can be viewed as a measure of similarity between data items. Valid kernels must satisfy the mathematical condition of positive semidefiniteness; this is equivalent to requiring that the kernel function equate to an inner product in some vector space. The kernel can be expressed in terms of a mapping function 0 from the input space X to a feature space F: k(Xi, X9) _ h0(Xi), 0(X9)i,7 (2) where h·, ·i,7 is the inner product associated with F. X and F need not have the same dimensionality or be of the same type. F is by definit</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
<author>Jeffrey Bigham</author>
<author>Victor Shnayder</author>
</authors>
<title>Combining independent modules to solve multiple-choice synonym and analogy problems.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 International Conference on Recent Advances in Natural Language Processing (RANLP-03).</booktitle>
<contexts>
<context position="28439" citStr="Turney et al. (2003)" startWordPosition="4714" endWordPosition="4717">ed, the averaging approach may be more appropriate. However, it seems likely that many applications will be similar to the task considered here, where short subsequences are sufficient and it is desirable to use as much data as possible to represent each set. We note that calculating the PairClass embedding, which counts far fewer patterns, took just 1h21m. For optimal efficiency, it seems best to use a gapweighted embedding with small set cardinality; averaged across five runs kjsd with q = 50 and l = Σ123 took 26m to calculate and still achieved 47.6% Accuracy, 45.1% F-score. 6 Related work Turney et al. (2003) suggest combining various information sources for solving SAT analogy problems. However, previous work on compound interpretation has generally used either lexical similarity or relational similarity but not both in combination. Previously proposed lexical models include the WordNet-based methods of Kim and Baldwin (2005) and Girju et al. (2005), and the distributional model of O´ S´eaghdha and Copestake (2008). The idea of using relational similarity to understand compounds goes back at least as far as Lebowitz’ (1988) RESEARCHER system, which processed patent abstracts in an incremental fas</context>
</contexts>
<marker>Turney, Littman, Bigham, Shnayder, 2003</marker>
<rawString>Peter D. Turney, Michael L. Littman, Jeffrey Bigham, and Victor Shnayder. 2003. Combining independent modules to solve multiple-choice synonym and analogy problems. In Proceedings of the 2003 International Conference on Recent Advances in Natural Language Processing (RANLP-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Similarity of semantic relations.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>3</issue>
<contexts>
<context position="2072" citStr="Turney, 2006" startWordPosition="324" endWordPosition="325">aper,cup) are similar because in both cases the relation N2 is made of N1 frequently holds between their members. Analogical tasks are distinct from (but not unrelated to) other kinds of “relation extraction” tasks where each data item is tied to a specific sentence context (e.g., Gir u et al. (2007)). One such relational reasoning task is the problem of compound noun interpretation, which Ann Copestake Computer Laboratory University of Cambridge 15 JJ Thomson Avenue Cambridge CB3 0FD United Kingdom aac10@cl.cam.ac.uk has received a great deal of attention in recent years (Gir u et al., 2005; Turney, 2006; Butnariu and Veale, 2008). In English (and other languages), the process of producing new lexical items through compounding is very frequent and very productive. Furthermore, the noun-noun relation expressed by a given compound is not explicit in its surface form: a steel knife may be a knife made from steel but a kitchen knife is most likely to be a knife used in a kitchen, not a knife made from a kitchen. The assumption made by similarity-based interpretation methods is that the likely meaning of a novel compound can be predicted by comparing it to previously seen compounds whose meanings </context>
<context position="6665" citStr="Turney (2006)" startWordPosition="1065" endWordPosition="1066">tterns such as w1 lives in the w2 and in the w2,... a w1, suggesting that a LOCATED IN or LIVES IN relation frequently holds between bears and forests. If the contexts in which fish and reef co-occur are similar to those found for bear and forest, this is evidence that the same semantic relation tends to hold between the members of each pair. A relational distributional hypothesis therefore states that two word pairs are semantically similar if their members appear together in similar contexts. The distinction between lexical and relational similarity for word pair comparison is recognised by Turney (2006) (he calls the former attributional similarity), though the methods he presents focus on relational similarity. O´ S´eaghdha and Copestake’s (2007) classification of information sources for noun compound interpretation also includes a description of lexical and relational similarity. Approaches to compound noun interpretation have tended to use either lexical or relational similarity, though rarely both (see Section 6 below). 3 Kernel methods for pair similarity 3.1 Kernel methods The kernel framework for machine learning is a natural choice for similarity-based classification (Shawe-Taylor an</context>
<context position="29176" citStr="Turney (2006)" startWordPosition="4830" endWordPosition="4831">tation has generally used either lexical similarity or relational similarity but not both in combination. Previously proposed lexical models include the WordNet-based methods of Kim and Baldwin (2005) and Girju et al. (2005), and the distributional model of O´ S´eaghdha and Copestake (2008). The idea of using relational similarity to understand compounds goes back at least as far as Lebowitz’ (1988) RESEARCHER system, which processed patent abstracts in an incremental fashion and associated an unseen compound with the relation expressed in a context where the constituents previously occurred. Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. LRA performs well on analogical tasks including compound interpretation, but has very substantial resource requirements. Turney (2008) has recently proposed a simpler SVM-based algorithm for analogical classification called PairClass. While it does not adopt a set-based or distributional model of relational similarity, we</context>
</contexts>
<marker>Turney, 2006</marker>
<rawString>Peter D. Turney. 2006. Similarity of semantic relations. Computational Linguistics, 32(3):379–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>A uniform approach to analogies, synonyms, antonyms, and associations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</booktitle>
<contexts>
<context position="12663" citStr="Turney (2008)" startWordPosition="2069" endWordPosition="2070">hted embedding, defined as 1: φgapl(s) = [ λlen(i)]uEΣl (4) i:s[i]=u λ is a decay parameter between 0 and 1; the smaller its value, the more the influence of a discontinuous subsequence is reduced. When l = 1 this corresponds to a “bag-of-words” embedding. Gap-weighted string kernels implicitly compute the similarity between two strings s, t as an inner product (φ(s), φ(t)). Lodhi et al. (2002) present an efficient dynamic programming algorithm that evaluates this kernel in O(l|s||t|) time without explicitly representing the feature vectors φ(s), φ(t). An alternative embedding is that used by Turney (2008) in his PairClass system (see Section 6). For the PairClass embedding φPC, an n-word context [0−1 words] N1|2 [0−3 words] N1|2 [0−1 words] containing target words N1, N2 is mapped onto the 2n−2 patterns produced by substituting zero or more of the context words with a wildcard *. Unlike the patterns used by the gap-weighted embedding these are not truly discontinuous, as each wildcard must match exactly one word. 1: − � 623 3.4 Kernels on sets String kernels afford a way of comparing individual contexts. In order to compute the relational similarity of two pairs, however, we do not want to ass</context>
<context position="29587" citStr="Turney (2008)" startWordPosition="4891" endWordPosition="4892">ER system, which processed patent abstracts in an incremental fashion and associated an unseen compound with the relation expressed in a context where the constituents previously occurred. Turney (2006) describes a method (Latent Relational Analysis) that extracts subsequence patterns for noun pairs from a large corpus, using query expansion to increase the recall of the search and feature selection and dimensionality reduction to reduce the complexity of the feature space. LRA performs well on analogical tasks including compound interpretation, but has very substantial resource requirements. Turney (2008) has recently proposed a simpler SVM-based algorithm for analogical classification called PairClass. While it does not adopt a set-based or distributional model of relational similarity, we have noted above that PairClass implicitly uses a feature representation similar to the one presented above as (6) by extracting subsequence patterns from observed cooccurrences of word pair members. Indeed, PairClass can be viewed as a special case of our frame627 work; the differences from the model we have used consist in the use of a different embedding function Opc and a more restricted notion of conte</context>
<context position="33588" citStr="Turney (2008)" startWordPosition="5524" endWordPosition="5525">We have developed an efficient and flexible kernel-based framework for comparing sets of contexts using the feature embedding associated with a string kernel.5 By choosing a particular embedding function and a particular inner product on subsequence vectors, the previously proposed set-averaging and PairClass algorithms for relational similarity can be retrieved as special cases. Applying our methods to the task of compound noun interpretation, we have shown that combining lexical and relational similarity is a very effective approach that surpasses either similarity model taken individually. Turney (2008) argues that many NLP tasks can be formulated in terms of analogical reasoning, and he applies his PairClass algorithm to a number of problems including SAT verbal analogy tests, synonym/antonym classification and distinction between semantically similar and semantically associated words. Our future research plans include investigating the application of our combined similarity model to analogical tasks other than compound noun interpretation. A second promising direction is to investigate relational models for unsupervised semantic analysis of noun compounds. The range of semantic relations t</context>
</contexts>
<marker>Turney, 2008</marker>
<rawString>Peter D. Turney. 2008. A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>