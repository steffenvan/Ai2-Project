<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.686033">
Proceedings of EACL &apos;99
</note>
<title confidence="0.844828">
Selective Magic HPSG Parsing
</title>
<author confidence="0.986174">
Guido Minnen*
</author>
<affiliation confidence="0.963771">
Cognitive and Computing Sciences, University of Sussex
</affiliation>
<address confidence="0.9229395">
Falmer, Brighton BN1 9QH
United Kingdom
</address>
<email confidence="0.582512">
Guido.MinnenOcogs.susx.ac.uk
</email>
<note confidence="0.311217">
www.cogs.susx.ac.uk/lab/n1p/minnen/minnen.html
</note>
<sectionHeader confidence="0.992314" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998816">
We propose a parser for constraint-
logic grammars implementing HPSG
that combines the advantages of dy-
namic bottom-up and advanced top-
down control. The parser allows the
user to apply magic compilation to spe-
cific constraints in a grammar which as
a result can be processed dynamically
in a bottom-up and goal-directed fash-
ion. State of the art top-down process-
ing techniques are used to deal with the
remaining constraints. We discuss vari-
ous aspects concerning the implementa-
tion of the parser as part of a grammar
development system.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999418396551724">
In case of large grammars the space requirements
of dynamic parsing often outweigh the benefit of
not duplicating sub-computations. We propose a
parser that avoids this drawback through combin-
ing the advantages of dynamic bottom-up and ad-
vanced top-down contro1.1 The underlying idea is
to achieve faster parsing by avoiding tabling on
sub-computations which are not expensive. The
so-called selective magic parser allows the user to
apply magic compilation to specific constraints in
a grammar which as a result can be processed dy-
namically in a bottom-up and goal-directed fash-
ion. State of the art top-down processing tech-
niques are used to deal with the remaining con-
straints.
Magic is a compilation technique originally de-
veloped for goal-directed bottom-up processing of
logic programs. See, among others, (Ramakrish-
nan et al. 1992). As shown in (Minnen, 1996)
•The presented research was carried out at the Uni-
versity of Tubingen, Germany, as part of the Sonder-
forschungsbereich 340.
I A more detailed discussion of various aspects of
the proposed parser can be found in (Minnen, 1998).
magic is an interesting technique with respect to
natural language processing as it incorporates fil-
tering into the logic underlying the grammar and
enables elegant control independent filtering im-
provements. In this paper we investigate the se-
lective application of magic to typed feature gram-
mars a type of constraint-logic grammar based on
Typed Feature Logic (T r; G6tz, 1995). Typed
feature grammars can be used as the basis for
implementations of Head-driven Phrase Structure
Grammar (HPSG; Pollard and Sag, 1994) as dis-
cussed in (Gotz and Meurers, 1997a) and (Meur-
ers and Minnen, 1997). Typed feature grammar
constraints that are inexpensive to resolve are
dealt with using the top-down interpreter of the
ConTroll grammar development system (GOtz and
Meurers, 1997b) which uses an advanced search
function, an advanced selection function and in-
corporates a coroutining mechanism which sup-
ports delayed interpretation.
The proposed parser is related to the so-called
Lemma Table deduction system (Johnson and
D6rre, 1995) which allows the user to specify
whether top-down sub-computations are to be
tabled. In contrast to Johnson and D6rre&apos;s deduc-
tion system, though, the selective magic parsing
approach combines top-down and bottom-up con-
trol strategies. As such it resembles the parser
of the grammar development system Attribute
Language Engine (ALE) of (Carpenter and Penn,
1994). Unlike the ALE parser, though, the selec-
tive magic parser does not presuppose a phrase
structure backbone and is more flexible as to
which sub-computations are tabled/filtered.
</bodyText>
<sectionHeader confidence="0.986939" genericHeader="method">
2 Bottom-up Interpretation of
Magic-compiled Typed Feature
Grammars
</sectionHeader>
<bodyText confidence="0.999935666666667">
We describe typed feature grammars and discuss
their use in implementing HPSG grammars. Sub-
sequently we present magic compilation of typed
</bodyText>
<page confidence="0.996791">
165
</page>
<bodyText confidence="0.9159854">
Proceedings of EACL &apos;99
feature grammars on the basis of an example and
introduce a dynamic bottom-up interpreter that
can be used for goal-directed interpretation of
magic-compiled typed feature grammars.
</bodyText>
<subsectionHeader confidence="0.983129">
2.1 Typed Feature Grammars
</subsectionHeader>
<bodyText confidence="0.999444125">
A typed feature grammar consists of a signa-
ture and a set of definite clauses over the con-
straint language of equations of TIT (Gotz, 1995)
terms (Haleld and Smolka, 1988) which we will
refer to as TFL definite clauses. Equations over
TIT terms can be solved using (graph) unifica-
tion provided they are in normal form. (Gotz,
1994) describes a normal form for TIT terms,
where typed feature structures are interpreted as
satisfiable normal form TIT terms.2 The signa-
ture consists of a type hierarchy and a set of ap-
propriateness conditions.
Example 1 The signature specified in figure 1
and 2 and the TIT definite clauses in figure 3
constitute an example of a typed feature gram-
mar. We write TIT terms in normal form, i. e.,
</bodyText>
<equation confidence="0.7920395">
relation
constituentERG1 sig3
</equation>
<figureCaption confidence="0.9765315">
Figure 2: Example of a typed feature grammar
signature (part 2)
</figureCaption>
<bodyText confidence="0.9985151875">
as typed feature structures. In addition, uninfor-
mative feature specifications are ignored and typ-
ing is left implicit when immaterial to the example
at hand. Equations between typed feature struc-
tures are removed by simple substitution or tags
indicating structure sharing. Notice that we also
use non-numerical tags such as Xs and XsYs . In
general all boxed items indicate structure sharing.
For expository reasons we represent the ARG n
features of the append relation as separate argu-
ments.
Typed feature grammars can be used as the
basis for implementations of Head-driven Phrase
Structure Grammar (Pollard and Sag, 1994).3
(Meurers and Minnen, 1997) propose a compi-
lation of lexical rules into TIT definite clauses
</bodyText>
<footnote confidence="0.926502">
2This view of typed feature structures differs from
the perspective on typed feature structures as mod-
eling partial information as in (Carpenter, 1992).
Typed feature structures as normal form TFC terms
are merely syntactic objects.
&apos;See (King, 1994) for a discussion of the appro-
priateness of TIG for HPSG and a comparison with
other feature logic approaches designed for HPSG.
</footnote>
<equation confidence="0.904759368421053">
[
CAT $
(1) Constituent( PHON 1 ):-
I
SEM _
_...
appendE a
CAT
(2) constituent( I PHON
AGR.
SEM
CAT
PHON
constituent(
AGR
SEM
append(0,
append(0 I
append(
</equation>
<figureCaption confidence="0.99918">
Figure 3: Example of a set of TIT definite clauses
</figureCaption>
<bodyText confidence="0.9999139">
which are used to restrict lexical entries. (Graz
and Meurers, 1997b) describe a method for com-
piling implicational constraints into typed feature
grammars and interleaving them with relational
constraints.4 Because of space limitations we have
to refrain from an example. The ConTroll gram-
mar development system as described in (Gotz
and Meurers, 1997b) implements the above men-
tioned techniques for compiling an HPSG theory
into typed feature grammars.
</bodyText>
<subsectionHeader confidence="0.999199">
2.2 Magic Compilation
</subsectionHeader>
<bodyText confidence="0.970040666666667">
Magic is a compilation technique for goal-directed
bottom-up processing of logic programs. See,
among others, (Ramakrishnan et al. 1992). Be-
cause magic compilation does not refer to the spe-
cific constraint language adopted, its application
is not limited to logic programs/grammars: It can
be applied to relational extensions of other con-
straint languages such as typed feature grammars
without further adaptions.
Due to space limitations we discuss magic com-
pilation by example only. The interested reader
is referred to (Nilsson and Maluszynski, 1995) for
an introduction.
Example 2 We illustrate magic compilation of
typed feature grammars with respect to definite
4(Gotz, 1995) proves that this compilation method
is sound in the general case and defines the large class
of type constraints for which it is complete.
</bodyText>
<figure confidence="0.998369787878788">
CAT
constituent( [
PHON
constituent(
SEM
AGR.
SEM
CAT
PHON
AGR
np 1),
2
4
6
3 [SUB.!
4
5
append ARG3 list
LRG1 /is]
ARG2 list
5
Ys
Ys )•
), Ys , (Ec I XsYs )):-
Xs Ys XsYs )-
)•
fly
( marl )
third-sing
mary_lf
(sleeps)
third-sing 1.
sleep
</figure>
<page confidence="0.540127">
166
</page>
<figureCaption confidence="0.746691">
Proceedings of EACL &apos;99
Figure 1: Example of a typed feature grammar signature (part 1)
</figureCaption>
<figure confidence="0.999295242424242">
CAT cat
PHON list
AGR agr
SEM sem
string
mary sleeps relation
s np v
elist agr sem
/
1
T
list third-sing
mary_lf sleep EUBJ sent
clause 1 in figure 3. Consider the T.T.0 definite magic_constituent( CAT s ).
clause in figure 4. As a result of magic compi- PHON (mom sleeps)
SEM sem
CAT s )
SEM 1
5
[CAT
constituent( magic PHON
magic_constituent(
magic )
al,
PHON 2
constituent( AGR 4
[
SEM 6
constituent( CAT
PEON 3
AGR. 4
append (ft , SEM 5 [SUBJ 6
El )-
</figure>
<figureCaption confidence="0.9372645">
Figure 4: Magic variant of definite clause 1 in fig-
ure 3
</figureCaption>
<bodyText confidence="0.999945066666667">
lation a magic literal is added to the right-hand
side of the original definite clause. Intuitively un-
derstood, this magic literal &amp;quot;guards&amp;quot; the applica-
tion of the definite clause. The clause is applied
only when there exists a fact that unifies with this
magic literal.&apos; The resulting definite clause is also
referred to as the magic variant of the original def-
inite clause.
The definite clause in figure 5 is the so-called
seed which is used to make the bindings as pro-
vided by the initial goal available for bottom-up
processing. In this case the seed corresponds to
the initial goal of parsing the string `mary sleeps&apos;.
Intuitively understood, the seed makes available
the bindings of the initial goal to the magic van-
</bodyText>
<footnote confidence="0.67014475">
5A fact can be a unit clause, i. e., a TFC definite
clause without right-hand side literals, from the gram-
mar or derived using the rules in the grammar. In the
latter case one also speaks of a passive edge.
</footnote>
<figureCaption confidence="0.959006">
Figure 5: Seed corresponding to the initial goal of
parsing the string `mary sleeps&apos;
</figureCaption>
<bodyText confidence="0.9999380625">
ants of the definite clauses defining a particular
initial goal; in this case the magic variant of the
definite clause defining a constituent of category
&apos;s&apos;. Only when their magic literal unifies with the
seed are these clauses applied.&apos;
The so-called magic rules in figure 6 are derived
in order to be able to use the bindings provided by
the seed to derive new facts that provide the bind-
ings which allow for a goal-directed application of
the definite clauses in the grammar not directly
defining the initial goal. Definite clause 3, for
example, can be used to derive a magic_app end
fact which percolates the relevant bindings of the
seed/initial goal to restrict the application of the
magic variant of definite clauses 4 and 5 in figure 3
(which are not displayed).
</bodyText>
<subsectionHeader confidence="0.999556">
2.3 Semi-naive Bottom-up Interpretation
</subsectionHeader>
<bodyText confidence="0.984188333333333">
Magic-compiled logic programs/grammars can be
interpreted in a bottom-up fashion without losing
any of the goal-directedness normally associated
with top-down interpretation using a so-called
semi-naive bottom-up interpreter: A dynamic in-
terpreter that tables only complete intermediate
results, i. e., facts or passive edges, and uses
an agenda to avoid redundant sub-computations.
The Prolog predicates in figure 7 implement a
&apos;The creation of the seed can be postponed until
run time, such that the grammar does not need to be
compiled for every possible initial goal.
</bodyText>
<page confidence="0.958897">
167
</page>
<table confidence="0.635039409090909">
Proceedings of EACL &apos;99
CAT up
(1) magic_constituent( PHON list.:-
)
AGR w
SEM semi
[ CAT s
magic_constituent( PHON list ).
SEM sem
(2) magic_append( [ ):- $
magic_constituent( CAT CAT 1
PHON 5
SEM
PHON 2
constituent( AGR 4
[
SEM 6
CAT
constituent( PHON 3 [SUBJ 6 11
[
SEMAGR 4
5
</table>
<figureCaption confidence="0.883152">
Figure 6: Magic rules resulting from applying
magic compilation to definite clause 1 in figure 3
</figureCaption>
<bodyText confidence="0.901162678571429">
semi-naive bottom-up interpreter.7 In this inter-
preter both the table and the agenda are repre-
sented using lists.8 The agenda keeps track of the
facts that have not yet been used to update the
table. It is important to notice that in order to
use the interpreter for typed feature grammars it
has to be adapted to perform graph unification.9
We refrain from making the necessary adaptions
to the code for expository reasons.
The table is initialized with the facts from the
grammar. Facts are combined using a operation
called match. The match operation unifies all but
one of the right-hand side literals of a definite
clause in the grammar with facts in the table. The
7Definite clauses serving as data are en-
coded using the predicate de f init e_c 1 ause/1:
def inite_clause( (Us : - Rhs) ) . , where Rhs is a
(possibly empty) list of literals.
8There are various other—more efficient—ways to
implement a dynamic control strategy in Prolog. See,
for example, (Shieber et al., 1995).
°A term encoding of typed feature structures would
enable the use of term unification instead. See, for
example, (Gerdemann, 1995).
remaining right-hand side literal is unified with a
newly derived fact, i. e., a fact from the agenda.
By doing this, repeated derivation of facts from
the same earlier derived facts is avoided.
</bodyText>
<table confidence="0.996033857142857">
semi_naive_int erpret (Goal) : -
init ializat ion (Agenda , Table° ) ,
updat e_t able (Agenda , Table0 , Table) ,
member (edge (Goal , [] ) , Table ) .
updat e_t able ( , Table , Table ) .
update_t able ( [Edge I Agenda0] , Table0 , Table ) : -
update_table_w_edge (Edge , Edges ,
Table0 , Table 1 ) ,
append (Edges , Agenda° , Agenda) ,
updat e_t able (Agenda , Table 1 , Table ) .
updat e_table_w_edge (Edge , Edges , Table° ,Table) -
f indall ( NewEdge ,
match (Edge ,NewEdge , Table° )
Edges) ,
store (Edges , Table° , Table ) .
store([] , Table , Table) : -
store ( [Edge I Edges] , Table° , Table ) : -
member (GenEdge , Tabl e 0 )
\+ subsumes (GenEdge , Edge )
store (Edges , [Edge I Table()] , Table ) .
st ore ( LI Edges] , Table0 , Table )
store (Edges , Table0 , Table) .
init ializat ion (Edges , Edges ) : -
f indall ( edge (Head ,0),
def inite_clause ( (Head : - ) ) ,
Edges ) .
complet ion (Edge , edge (Goal, [] ) , Table) : -
def init e_clause ( (Goal : - Body)),
Edge = edge (F , [] ) ,
select(F,Body,R),
edges (R , Table) .
edges ( [] -)
edges ( [Lit IL its] , Table ) : -
member (edge (Lit, ) , Table )
edges (Lits , Table ) .
</table>
<figureCaption confidence="0.939893">
Figure 7: Semi-naive bottom-up interpreter
</figureCaption>
<sectionHeader confidence="0.96596" genericHeader="method">
3 Selective Magic IIPS(3, Parsing
</sectionHeader>
<bodyText confidence="0.999926818181818">
In case of large grammars the huge space require-
ments of dynamic processing often nullify the ben-
efit of tabling intermediate results. By combin-
ing control strategies and allowing the user to
specify how to process particular constraints in
the grammar the selective magic parser avoids
this problem. This solution is based on the ob-
servation that there are sub-computations that
are relatively cheap and as a result do not need
tabling (Johnson and Done, 1995; van Noord,
1997).
</bodyText>
<subsectionHeader confidence="0.986033">
3.1 Parse Type Specification
</subsectionHeader>
<bodyText confidence="0.999213">
Combining control strategies depends on a way
to differentiate between types of constraints. For
</bodyText>
<figure confidence="0.9973419">
AGR 4 ),
CAT np
PHON list
constituent(
6
SEM
[ CAT u
PHON list
(3) magic_constituent( AGR
SEM 5
{S1J131
CAT ),
SEM rI
magic_constituent( PHON list 5-1
s
[
4
6
):-
).
</figure>
<page confidence="0.921552">
168
</page>
<bodyText confidence="0.986770555555556">
Proceedings of EACL &apos;99
example, the ALE parser (Carpenter and Penn,
1994) presupposes a phrase structure backbone
which can be used to determine whether a con-
straint is to be interpreted bottom-up or top-
down. In the case of selective magic parsing we
use so-called parse types which allow the user to
specify how constraints in the grammar are to be
interpreted. A literal (goal) is considered a parse
type literal (goal) if it has as its single argument
a typed feature structure of a type specified as a
parse type.1°
All types in the type hierarchy can be used
as parse types. This way parse type specifica-
tion supports a flexible filtering component which
allows us to experiment with the role of filter-
ing. However, in the remainder we will concen-
trate on a specific class of parse types: We as-
sume the specification of type sign and its sub-
types as parse types.&amp;quot; This choice is based on
the observation that the constraints on type sign
and its sub-types play an important guiding role
in the parsing process and are best interpreted
bottom-up given the lexical orientation of HPSG.
The parsing process corresponding to such a parse
type specification is represented schematically in
figure 8. Starting from the lexical entries, i. e.,
</bodyText>
<figure confidence="0.712440571428571">
.........
..........
..........
sta
non-parse type
goals
word word
</figure>
<figureCaption confidence="0.9813225">
Figure 8: Schematic representation of the selective
magic parsing process
</figureCaption>
<bodyText confidence="0.997668">
the T.FL definite clauses that specify the word
objects in the grammar, phrases are built bottom-
up by matching the parse type literals of the def-
inite clauses in the grammar against the edges in
the table. The non-parse type literals are pro-
cessed according to the top-down control strategy
10The notion of a parse type literal is closely related
to that of a memo literal as in (Johnson and Dorre,
1995).
&apos;When a type is specified as a parse type, all its
sub-types are considered as parse types as well. This is
necessary as otherwise there may exist magic variants
of definite clauses defining a parse type goal for which
no magic facts can be derived which means that the
magic literal of these clauses can be interpreted nei-
ther top-down nor bottom-up.
described in section 3.3.
</bodyText>
<subsectionHeader confidence="0.999145">
3.2 Selective Magic Compilation
</subsectionHeader>
<bodyText confidence="0.999976692307692">
In order to process parse type goals according to a
semi-naive magic control strategy, we apply magic
compilation selectively. Only the T.T.0 definite
clauses in a typed feature grammar which define
parse type goals are subject to magic compilation.
The compilation applied to these clauses is iden-
tical to the magic compilation illustrated in sec-
tion 2.1 except that we derive magic rules only for
the right-hand side literals in a clause which are of
a parse type. The definite clauses in the grammar
defining non-parse type goals are not compiled as
they will be processed using the top-down inter-
preter described in the next section.
</bodyText>
<subsectionHeader confidence="0.999144">
3.3 Advanced Top-down Control
</subsectionHeader>
<bodyText confidence="0.940292125">
Non-parse type goals are interpreted using the
standard interpreter of the ConTroll grammar de-
velopment system (G8tz and Meurers, 1997b) as
developed and implemented by Thilo Gotz. This
advanced top-down interpreter uses a search func-
tion that allows the user to specify the information
on which the definite clauses in the grammar are
indexed. An important advantage of deep multi-
ple indexing is that the linguist does not have to
take into account of processing criteria with re-
spect to the organization of her/his data as is the
case with a standard Prolog search function which
indexes on the functor of the first argument.
Another important feature of the top-down in-
terpreter is its use of a selection function that
interprets deterministic goals, i. e., goals which
unify with the left-hand side literal of exactly
one definite clause in the grammar, prior to non-
deterministic goals. This is often referred to as
incorporating deterministic closure (DOrre, 1993).
Deterministic closure accomplishes a reduction of
the number of choice points that need to be set
during processing to a minimum. Furthermore, it
leads to earlier failure detection.
Finally, the used top-down interpreter imple-
ments a powerful coroutining mechanism:12 At
run time the processing of a goal is postponed
in case it is insufficiently instantiated. Whether
or not a goal is sufficiently instantiated is deter-
mined on the basis of so-called delay patterns.13
These are specifications provided by the user that
12Coroutining appears under many different guises,
like for example, suspension, residuation, (goal) freez-
ing, and blocking. See also (Colmerauer, 1982; Naish,
1986).
&amp;quot;In the literature delay patterns are sometimes also
referred to as wait declarations or block statements.
sk.
non-parse type
goals
</bodyText>
<page confidence="0.979084">
169
</page>
<bodyText confidence="0.888347666666667">
Proceedings of EACL &apos;99
indicate which restricting information has to be
available before a goal is processed.
</bodyText>
<subsectionHeader confidence="0.9770275">
3.4 Adapted Semi-naive Bottom-up
Interpretation
</subsectionHeader>
<bodyText confidence="0.960576214285714">
The definite clauses resulting from selective magic
transformation are interpreted using a semi-naive
bottom-up interpreter that is adapted in two re-
spects. It ensures that non-parse type goals are
interpreted using the advanced top-down inter-
preter, and it allows non-parse type goals that
remain delayed locally to be passed in and out
of sub-computations in a similar fashion as pro-
posed by (Johnson and Dorre, 1995). In order
to accommodate these changes the adapted semi-
naive interpreter enables the use of edges which
specify delayed goals.
Figure 9 illustrates the adapted match op-
eration. The first defining clause of match/3
</bodyText>
<equation confidence="0.4979652">
match(Edge,edge(Goal,Delayed),Table):-
definite_clause((Goal :- Body)),
select(Lit,Body,Lits),
parse_type(Lit),
Edge = edge(Lit,Delayed0),
edges(Lit,Table,Delayed0,TopDown),
advancecLtd_interpret(TopDown,Delayed).
match(Edge,edge(Goal,Delayed),Table):-
definite_clause((Goal TopDown)),
advancecLtd_interpret(TopDown,Delayed).
</equation>
<figureCaption confidence="0.9970145">
Figure 9: Adapted definition of mat ch/3
passes delayed and non-parse type goals of the
</figureCaption>
<bodyText confidence="0.979253966666667">
definite clause under consideration to the ad-
vanced top-down interpreter via the call to
advanced_td_interpret/2 as the list of goals
TopDown.14 The second defining clause of mat ch/3
is added to ensure all right-hand side literals are
directly passed to the advanced top-down inter-
preter if none of them are of a parse type.
Allowing edges which specify delayed goals
necessitates the adaption of the definition of
edges/3. When a parse type literal is matched
against an edge in the table, the delayed goals
specified by that edge need to be passed to the
top-down interpreter. Consider the definition of
the predicate edges in figure 11. The third argu-
ment of the definition of edges/4 is used to collect
delayed goals. When there are no more parse type
literals in the right-hand side of the definite clause
under consideration, the second defining clause
of edges/4 appends the collected delayed goals
&amp;quot;The definition of match/3 assumes that there ex-
ists a strict ordering of the right-hand side literals in
the definite clauses in the grammar, i. e., parse type
literals always preced e non-parse type literals.
edges([LitILits],Table,Delayed0,TopDown):-
parse_type(Lit),
member(edge(Lit,Delayed1),Table),
append(DelayedO,Delayedl,Delayed).
edges(Lit,Table,Delayed,TopDown).
edges(0,_,Delayed,TopDown):-
append(Delayed,Lit,TopDown).
</bodyText>
<figureCaption confidence="0.997415">
Figure 11: Adapted definition of edges/4
</figureCaption>
<bodyText confidence="0.970010333333333">
to the remaining non-parse type literals. Subse-
quently, the resulting list of literals is passed up
again for advanced top-down interpretation.
</bodyText>
<sectionHeader confidence="0.996071" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.989113075">
The described parser was implemented as part of
the ConTroll grammar development system (Gi5tz
and Meurers, 1997b). Figure 10 shows the over-
all setup of the ConTroll magic component. The
Controll magic component presupposes a parse
type specification and a set of delay patterns to
determine when non-parse type constraints are to
be interpreted. At run-time the goal-directedness
of the selective magic parser is further increased
by means of using the phonology of the natural
language expression to be parsed as specified by
the initial goal to restrict the number of facts that
are added to the table during initialization. Only
those facts in the grammar corresponding to lex-
ical entries that have a value for their phonology
feature that appears as part of the input string
are used to initialize the table.
The ConTroll magic component was tested with
a larger (&gt; 5000 lines) HPSG grammar of a size-
able fragment of German. This grammar provides
an analysis for simple and complex verb-second,
verb-first and verb-last sentences with scrambling
in the mittelfeld, extraposition phenomena, wh-
movement and topicalization, integrated verb-first
parentheticals, and an interface to an illocution
theory, as well as the three kinds of infinitive con-
structions, nominal phrases, and adverbials (Hin-
richs et al., 1997).
As the test grammar combines sub-strings in a
non-concatenative fashion, a preprocessor is used
that chunks the input string into linearization do-
mains. This way the standard ConTroll inter-
preter (as described in section 3.3) achieves pars-
ing times of around 1-5 seconds for 5 word sen-
tences and 10-60 seconds for 12 word sentences.15
The use of magic compilation on all grammar
constraints, i.e., tabling of all sub-computations,
&apos;Parsing with such a grammar is difficult in any
system as it does neither have nor allow the extraction
of a phrase structure backbone.
</bodyText>
<page confidence="0.980968">
170
</page>
<figure confidence="0.519451">
Proceedings of EACL &apos;99
</figure>
<figureCaption confidence="0.7053062">
extended semi-naive
bottom-up interpretation
of parse type clauses
combined with advanced
top-does interpretation
</figureCaption>
<figure confidence="0.995777909090909">
parse type
specification
initial goal
input: typed feature grammar
preselection
of relevant
lexical entries
magic compilation
on parse type
clauses
output:
</figure>
<figureCaption confidence="0.999781">
Figure 10: Setup of the Con Troll magic component
</figureCaption>
<bodyText confidence="0.999138392857143">
leads to an vast increase of parsing times. The
selective magic HPSG parser, however, exhibits a
significant speedup in many cases. For example,
parsing with the module of the grammar imple-
menting the analysis of nominal phrases is up to
nine times faster. At the same time though se-
lective magic HPSG parsing is sometimes signifi-
cantly slower. For example, parsing of particular
sentences exhibiting adverbial subordinate clauses
and long extraction is sometimes more than nine
times slower. We conjecture that these ambigu-
ous results are due to the use of coroutining: As
the test grammar was implemented using the stan-
dard ConTroll interpreter, the delay patterns used
presuppose a data-flow corresponding to advanced
top-down control and are not fine-tuned with re-
spect to the data-flow corresponding to the selec-
tive magic parser.
Coroutining is a flexible and powerful facility
used in many grammar development systems and
it will probably remain indispensable in dealing
with many control problems despite its various
disadvantages.&apos; The test results discussed above
indicate that the comparison of parsing strategies
can be seriously hampered by fine-tuning parsing
using delay patterns. We believe therefore that
further research into the systematics underlying
coroutining would be desirable.
</bodyText>
<sectionHeader confidence="0.986915" genericHeader="conclusions">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999867">
We described a selective magic parser for typed
feature grammars implementing HPSG that com-
bines the advantages of dynamic bottom-up and
advanced top-down control. As a result the parser
avoids the efficiency problems resulting from the
huge space requirements of storing intermediate
results in parsing with large grammars. The
parser allows the user to apply magic compilation
to specific constraints in a grammar which as a
</bodyText>
<footnote confidence="0.634360833333333">
16Coroutining has a significant run-time overhead
caused by the necessity to check the instantiation sta-
tus of a literal/goal. In addition, it demands the pro-
cedural annotation of an otherwise declarative gram-
mar. Finally, coroutining presupposes that a grammar
writer possesses substantial processing expertise.
</footnote>
<page confidence="0.993552">
171
</page>
<bodyText confidence="0.9621715">
Proceedings of EACL &apos;99
result can be processed dynamically in a bottom-
up and goal-directed fashion. State of the art
top-down processing techniques are used to deal
with the remaining constraints. We discussed var-
ious aspects concerning the implementation of the
parser which was developed as part of the gram-
mar development system ConTroll.
</bodyText>
<sectionHeader confidence="0.998168" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999877416666667">
The author gratefully acknowledges the support
of the SFB 340 project B4 &amp;quot;From Constraints to
Rules: Efficient Compilation of HPSG&amp;quot; funded by
the German Science Foundation and the project
&amp;quot;PSET: Practical Simplification of English Text&amp;quot;,
a three-year project funded by the UK Engi-
neering and Physical Sciences Research Council
(GR/L53175), and Apple Computer Inc.. The au-
thor wishes to thank Dale Gerdemann and Erhard
Hinrichs and the anonymous reviewers for com-
ments and discussion. Of course, the author is
responsible for all remaining errors.
</bodyText>
<sectionHeader confidence="0.998244" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998775395348837">
Bob Carpenter and Gerald Penn. 1994. ALE —
The Attribute Logic Engine, User&apos;s guide, ver-
sion 2.0.2. Technical report, Carnegie Mellon
University, Pittsburgh, Pennsylvania, USA.
Bob Carpenter. 1992. The Logic of Typed Fea-
ture Structures - With Applications to Unifica-
tion Grammars, Logic Programs and Constraint
Resolution. Cambridge University Press, New
York, USA.
Alain Colmerauer. 1982. PrologII: Manuel de
reference et modele theorique. Technical re-
port, Groupe d&apos;Intelligence Artificielle, Faculte
de Sciences de Luminy, Marseille, France.
Jochen Dorre. 1993. Generalizing Earley Deduc-
tion for Constraint-based Grammars. In Jochen
DOrre and Michael Dorna (eds.), 1993. Compu-
tational Aspects of Constraint-Based Linguistic
Description I. DYANA-2, Deliverable R1 .2.A.
Dale Gerdemann. 1995. Term Encoding of
Typed Feature Structures. In Proceedings of
the Fourth International Workshop on Parsing
Technologies, Prague, Czech Republic.
Thilo Gotz and Detmar Meurers. 1997a. In-
terleaving Universal Principles and Relational
Constraints over Typed Feature Logic. In
ACL/EACL Proceedings, Madrid, Spain.
Thilo Graz and Detmar Meurers. 1997b. The
ConTroll System as Large Grammar Develop-
ment Platform. In Proceedings of the ACL
Workshop on Computational Environments for
Grammar Development and Linguistic Engi-
neering, Madrid, Spain.
Thilo Gotz. 1994. A Normal Form for Typed
Feature Structures. Technical report SFB 340
nr. 40, University of Tubingen, Germany.
Thilo GOtz. 1995. Compiling HPSG Constraint
Grammars into Logic Programs. In Proceedings
of the Workshop on Computational Logic for
Natural Language Processing, Edinburgh, UK.
Erhard Hinrichs, Detmar Meurers, Frank Richter,
Manfred Sailer, and Heike Winhart. 1997. Ein
HPSG-fragment des Deutschen, Teil 1: Theo-
re. Technical report SFB 340 95, University of
Tubingen, Germany.
Markus Hafeld and Gert Smolka. 1988. Definite
Relations over Constraint Languages. Technical
Report 53, IBM, Germany.
Mark Johnson and Jochen DOrre. 1995. Memo-
ization of Coroutined Constraints. In A CL Pro-
ceedings, Cambridge, Massachusetts, USA.
Paul King. 1994. Typed Feature Structures as
Descriptions. In Proceedings of of the 15th Con-
ference on Computational Linguistics, Kyoto,
Japan.
Detmar Meurers and Guido Minnen. 1997. A
Computational Treatment of Lexical Rules in
HPSG as Covariation in Lexical Entries. Com-
putational Linguistics, 23(4).
Guido Minnen. 1996. Magic for Filter Optimiza-
tion in Dynamic Bottom-up Processing. In ACL
Proceedings, Santa Cruz, California, USA.
Guido Minnen. 1998. Off-line Compilation for Ef-
ficient Processing with Constraint-logic Gram-
mars. Ph.D. thesis, University of Tubingen,
Germany. Technical report SFB 340 nr. 130.
Lee Naish. 1986. Negation and Control in Prolog.
Springer-Verlag, Berlin, Germany.
Ulf Nilsson and Jan Maluszynski. 1995. Logic,
Programming and Prolog. John Wiley &amp; Sons,
Chichester, UK, 2nd edition.
Carl Pollard and Ivan Sag. 1994. Head-Driven
Phrase Structure Grammar. University of
Chicago Press, Chicago, Illinois, USA.
Raghu Ramakrishnan, Divesh Srivastava, and
S. Sudarshan. 1992. Efficient Bottom-up
Evaluation of Logic Programs. In Joos Van-
dewalle (ed.), 1992. The State of the Art in
Computer Systems and Software Engineering.
Kluwer Academic Publishers.
Stuart Shieber, Yves Schabes, and Fernando
Pereira. 1995. Principles and Implementation
of Deductive Parsing. Journal of Logic Pro-
gramming, 24(1-2).
Gertjan van Noord. 1997. An Efficient Imple-
mentation of the Head-corner Parser. Compu-
tational Linguistics, 23(3).
</reference>
<page confidence="0.997872">
172
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.459530">
<note confidence="0.757604">Proceedings of EACL &apos;99</note>
<title confidence="0.99838">Selective Magic HPSG Parsing</title>
<author confidence="0.997326">Guido Minnen</author>
<affiliation confidence="0.986045">Cognitive and Computing Sciences, University of Sussex</affiliation>
<address confidence="0.898965">Falmer, Brighton BN1 9QH United Kingdom</address>
<email confidence="0.8375245">Guido.MinnenOcogs.susx.ac.ukwww.cogs.susx.ac.uk/lab/n1p/minnen/minnen.html</email>
<abstract confidence="0.99844125">We propose a parser for constraintlogic grammars implementing HPSG that combines the advantages of dynamic bottom-up and advanced topdown control. The parser allows the user to apply magic compilation to specific constraints in a grammar which as a result can be processed dynamically in a bottom-up and goal-directed fashion. State of the art top-down processing techniques are used to deal with the remaining constraints. We discuss various aspects concerning the implementation of the parser as part of a grammar development system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Gerald Penn</author>
</authors>
<title>ALE — The Attribute Logic Engine, User&apos;s guide, version 2.0.2.</title>
<date>1994</date>
<tech>Technical report,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, Pennsylvania, USA.</location>
<contexts>
<context position="3283" citStr="Carpenter and Penn, 1994" startWordPosition="500" endWordPosition="503">, 1997b) which uses an advanced search function, an advanced selection function and incorporates a coroutining mechanism which supports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and D6rre&apos;s deduction system, though, the selective magic parsing approach combines top-down and bottom-up control strategies. As such it resembles the parser of the grammar development system Attribute Language Engine (ALE) of (Carpenter and Penn, 1994). Unlike the ALE parser, though, the selective magic parser does not presuppose a phrase structure backbone and is more flexible as to which sub-computations are tabled/filtered. 2 Bottom-up Interpretation of Magic-compiled Typed Feature Grammars We describe typed feature grammars and discuss their use in implementing HPSG grammars. Subsequently we present magic compilation of typed 165 Proceedings of EACL &apos;99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goal-directed interpretation of magic-compiled typed feature grammars. 2.1 </context>
<context position="14341" citStr="Carpenter and Penn, 1994" startWordPosition="2429" endWordPosition="2432"> constraints in the grammar the selective magic parser avoids this problem. This solution is based on the observation that there are sub-computations that are relatively cheap and as a result do not need tabling (Johnson and Done, 1995; van Noord, 1997). 3.1 Parse Type Specification Combining control strategies depends on a way to differentiate between types of constraints. For AGR 4 ), CAT np PHON list constituent( 6 SEM [ CAT u PHON list (3) magic_constituent( AGR SEM 5 {S1J131 CAT ), SEM rI magic_constituent( PHON list 5-1 s [ 4 6 ):- ). 168 Proceedings of EACL &apos;99 example, the ALE parser (Carpenter and Penn, 1994) presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottom-up or topdown. In the case of selective magic parsing we use so-called parse types which allow the user to specify how constraints in the grammar are to be interpreted. A literal (goal) is considered a parse type literal (goal) if it has as its single argument a typed feature structure of a type specified as a parse type.1° All types in the type hierarchy can be used as parse types. This way parse type specification supports a flexible filtering component which allows us to </context>
</contexts>
<marker>Carpenter, Penn, 1994</marker>
<rawString>Bob Carpenter and Gerald Penn. 1994. ALE — The Attribute Logic Engine, User&apos;s guide, version 2.0.2. Technical report, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures - With Applications to Unification Grammars, Logic Programs and Constraint Resolution.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="5599" citStr="Carpenter, 1992" startWordPosition="873" endWordPosition="874">tructure sharing. Notice that we also use non-numerical tags such as Xs and XsYs . In general all boxed items indicate structure sharing. For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994).3 (Meurers and Minnen, 1997) propose a compilation of lexical rules into TIT definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in (Carpenter, 1992). Typed feature structures as normal form TFC terms are merely syntactic objects. &apos;See (King, 1994) for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM append(0, append(0 I append( Figure 3: Example of a set of TIT definite clauses which are used to restrict lexical entries. (Graz and Meurers, 1997b) describe a method for compiling implicational constraints into typed feature grammars and interl</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. The Logic of Typed Feature Structures - With Applications to Unification Grammars, Logic Programs and Constraint Resolution. Cambridge University Press, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>PrologII: Manuel de reference et modele theorique.</title>
<date>1982</date>
<booktitle>Groupe d&apos;Intelligence Artificielle, Faculte de Sciences de Luminy,</booktitle>
<tech>Technical report,</tech>
<location>Marseille, France.</location>
<contexts>
<context position="18778" citStr="Colmerauer, 1982" startWordPosition="3162" endWordPosition="3163">mber of choice points that need to be set during processing to a minimum. Furthermore, it leads to earlier failure detection. Finally, the used top-down interpreter implements a powerful coroutining mechanism:12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is determined on the basis of so-called delay patterns.13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking. See also (Colmerauer, 1982; Naish, 1986). &amp;quot;In the literature delay patterns are sometimes also referred to as wait declarations or block statements. sk. non-parse type goals 169 Proceedings of EACL &apos;99 indicate which restricting information has to be available before a goal is processed. 3.4 Adapted Semi-naive Bottom-up Interpretation The definite clauses resulting from selective magic transformation are interpreted using a semi-naive bottom-up interpreter that is adapted in two respects. It ensures that non-parse type goals are interpreted using the advanced top-down interpreter, and it allows non-parse type goals tha</context>
</contexts>
<marker>Colmerauer, 1982</marker>
<rawString>Alain Colmerauer. 1982. PrologII: Manuel de reference et modele theorique. Technical report, Groupe d&apos;Intelligence Artificielle, Faculte de Sciences de Luminy, Marseille, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Dorre</author>
</authors>
<title>Generalizing Earley Deduction for Constraint-based Grammars.</title>
<date>1993</date>
<booktitle>In Jochen DOrre and Michael Dorna (eds.), 1993. Computational Aspects of Constraint-Based Linguistic Description I. DYANA-2, Deliverable R1 .2.A.</booktitle>
<marker>Dorre, 1993</marker>
<rawString>Jochen Dorre. 1993. Generalizing Earley Deduction for Constraint-based Grammars. In Jochen DOrre and Michael Dorna (eds.), 1993. Computational Aspects of Constraint-Based Linguistic Description I. DYANA-2, Deliverable R1 .2.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale Gerdemann</author>
</authors>
<title>Term Encoding of Typed Feature Structures.</title>
<date>1995</date>
<booktitle>In Proceedings of the Fourth International Workshop on Parsing Technologies,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="12070" citStr="Gerdemann, 1995" startWordPosition="1982" endWordPosition="1983">d using a operation called match. The match operation unifies all but one of the right-hand side literals of a definite clause in the grammar with facts in the table. The 7Definite clauses serving as data are encoded using the predicate de f init e_c 1 ause/1: def inite_clause( (Us : - Rhs) ) . , where Rhs is a (possibly empty) list of literals. 8There are various other—more efficient—ways to implement a dynamic control strategy in Prolog. See, for example, (Shieber et al., 1995). °A term encoding of typed feature structures would enable the use of term unification instead. See, for example, (Gerdemann, 1995). remaining right-hand side literal is unified with a newly derived fact, i. e., a fact from the agenda. By doing this, repeated derivation of facts from the same earlier derived facts is avoided. semi_naive_int erpret (Goal) : - init ializat ion (Agenda , Table° ) , updat e_t able (Agenda , Table0 , Table) , member (edge (Goal , [] ) , Table ) . updat e_t able ( , Table , Table ) . update_t able ( [Edge I Agenda0] , Table0 , Table ) : - update_table_w_edge (Edge , Edges , Table0 , Table 1 ) , append (Edges , Agenda° , Agenda) , updat e_t able (Agenda , Table 1 , Table ) . updat e_table_w_edge</context>
</contexts>
<marker>Gerdemann, 1995</marker>
<rawString>Dale Gerdemann. 1995. Term Encoding of Typed Feature Structures. In Proceedings of the Fourth International Workshop on Parsing Technologies, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thilo Gotz</author>
<author>Detmar Meurers</author>
</authors>
<title>Interleaving Universal Principles and Relational Constraints over Typed Feature Logic.</title>
<date>1997</date>
<booktitle>In ACL/EACL Proceedings,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="2451" citStr="Gotz and Meurers, 1997" startWordPosition="376" endWordPosition="379">aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as discussed in (Gotz and Meurers, 1997a) and (Meurers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GOtz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and incorporates a coroutining mechanism which supports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and D6rre&apos;s deduction </context>
<context position="6385" citStr="Gotz and Meurers, 1997" startWordPosition="1001" endWordPosition="1004">mparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM append(0, append(0 I append( Figure 3: Example of a set of TIT definite clauses which are used to restrict lexical entries. (Graz and Meurers, 1997b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an example. The ConTroll grammar development system as described in (Gotz and Meurers, 1997b) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars. 2.2 Magic Compilation Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). Because magic compilation does not refer to the specific constraint language adopted, its application is not limited to logic programs/grammars: It can be applied to relational extensions of other constraint languages such as typed feature grammars without further adaptions. Due to space limitations we discuss magic compilation by exam</context>
</contexts>
<marker>Gotz, Meurers, 1997</marker>
<rawString>Thilo Gotz and Detmar Meurers. 1997a. Interleaving Universal Principles and Relational Constraints over Typed Feature Logic. In ACL/EACL Proceedings, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thilo Graz</author>
<author>Detmar Meurers</author>
</authors>
<title>The ConTroll System as Large Grammar Development Platform.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Computational Environments for Grammar Development and Linguistic Engineering,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="6100" citStr="Graz and Meurers, 1997" startWordPosition="959" endWordPosition="962">ructures differs from the perspective on typed feature structures as modeling partial information as in (Carpenter, 1992). Typed feature structures as normal form TFC terms are merely syntactic objects. &apos;See (King, 1994) for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM append(0, append(0 I append( Figure 3: Example of a set of TIT definite clauses which are used to restrict lexical entries. (Graz and Meurers, 1997b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an example. The ConTroll grammar development system as described in (Gotz and Meurers, 1997b) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars. 2.2 Magic Compilation Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). Because magic compilation does not refer to the spec</context>
</contexts>
<marker>Graz, Meurers, 1997</marker>
<rawString>Thilo Graz and Detmar Meurers. 1997b. The ConTroll System as Large Grammar Development Platform. In Proceedings of the ACL Workshop on Computational Environments for Grammar Development and Linguistic Engineering, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thilo Gotz</author>
</authors>
<title>A Normal Form for Typed Feature Structures.</title>
<date>1994</date>
<tech>Technical report SFB 340 nr. 40,</tech>
<institution>University of Tubingen,</institution>
<contexts>
<context position="4237" citStr="Gotz, 1994" startWordPosition="652" endWordPosition="653">ntly we present magic compilation of typed 165 Proceedings of EACL &apos;99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goal-directed interpretation of magic-compiled typed feature grammars. 2.1 Typed Feature Grammars A typed feature grammar consists of a signature and a set of definite clauses over the constraint language of equations of TIT (Gotz, 1995) terms (Haleld and Smolka, 1988) which we will refer to as TFL definite clauses. Equations over TIT terms can be solved using (graph) unification provided they are in normal form. (Gotz, 1994) describes a normal form for TIT terms, where typed feature structures are interpreted as satisfiable normal form TIT terms.2 The signature consists of a type hierarchy and a set of appropriateness conditions. Example 1 The signature specified in figure 1 and 2 and the TIT definite clauses in figure 3 constitute an example of a typed feature grammar. We write TIT terms in normal form, i. e., relation constituentERG1 sig3 Figure 2: Example of a typed feature grammar signature (part 2) as typed feature structures. In addition, uninformative feature specifications are ignored and typing is left i</context>
</contexts>
<marker>Gotz, 1994</marker>
<rawString>Thilo Gotz. 1994. A Normal Form for Typed Feature Structures. Technical report SFB 340 nr. 40, University of Tubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thilo GOtz</author>
</authors>
<title>Compiling HPSG Constraint Grammars into Logic Programs.</title>
<date>1995</date>
<booktitle>In Proceedings of the Workshop on Computational Logic for Natural Language Processing,</booktitle>
<location>Edinburgh, UK.</location>
<marker>GOtz, 1995</marker>
<rawString>Thilo GOtz. 1995. Compiling HPSG Constraint Grammars into Logic Programs. In Proceedings of the Workshop on Computational Logic for Natural Language Processing, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard Hinrichs</author>
<author>Detmar Meurers</author>
<author>Frank Richter</author>
<author>Manfred Sailer</author>
<author>Heike Winhart</author>
</authors>
<date>1997</date>
<booktitle>Ein HPSG-fragment des Deutschen, Teil 1: Theore. Technical report SFB 340 95,</booktitle>
<institution>University of Tubingen,</institution>
<contexts>
<context position="22995" citStr="Hinrichs et al., 1997" startWordPosition="3763" endWordPosition="3767">at have a value for their phonology feature that appears as part of the input string are used to initialize the table. The ConTroll magic component was tested with a larger (&gt; 5000 lines) HPSG grammar of a sizeable fragment of German. This grammar provides an analysis for simple and complex verb-second, verb-first and verb-last sentences with scrambling in the mittelfeld, extraposition phenomena, whmovement and topicalization, integrated verb-first parentheticals, and an interface to an illocution theory, as well as the three kinds of infinitive constructions, nominal phrases, and adverbials (Hinrichs et al., 1997). As the test grammar combines sub-strings in a non-concatenative fashion, a preprocessor is used that chunks the input string into linearization domains. This way the standard ConTroll interpreter (as described in section 3.3) achieves parsing times of around 1-5 seconds for 5 word sentences and 10-60 seconds for 12 word sentences.15 The use of magic compilation on all grammar constraints, i.e., tabling of all sub-computations, &apos;Parsing with such a grammar is difficult in any system as it does neither have nor allow the extraction of a phrase structure backbone. 170 Proceedings of EACL &apos;99 ex</context>
</contexts>
<marker>Hinrichs, Meurers, Richter, Sailer, Winhart, 1997</marker>
<rawString>Erhard Hinrichs, Detmar Meurers, Frank Richter, Manfred Sailer, and Heike Winhart. 1997. Ein HPSG-fragment des Deutschen, Teil 1: Theore. Technical report SFB 340 95, University of Tubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Hafeld</author>
<author>Gert Smolka</author>
</authors>
<title>Definite Relations over Constraint Languages.</title>
<date>1988</date>
<tech>Technical Report 53, IBM,</tech>
<marker>Hafeld, Smolka, 1988</marker>
<rawString>Markus Hafeld and Gert Smolka. 1988. Definite Relations over Constraint Languages. Technical Report 53, IBM, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Jochen DOrre</author>
</authors>
<title>Memoization of Coroutined Constraints.</title>
<date>1995</date>
<booktitle>In A CL Proceedings,</booktitle>
<location>Cambridge, Massachusetts, USA.</location>
<marker>Johnson, DOrre, 1995</marker>
<rawString>Mark Johnson and Jochen DOrre. 1995. Memoization of Coroutined Constraints. In A CL Proceedings, Cambridge, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul King</author>
</authors>
<title>Typed Feature Structures as Descriptions.</title>
<date>1994</date>
<booktitle>In Proceedings of of the 15th Conference on Computational Linguistics, Kyoto,</booktitle>
<contexts>
<context position="5698" citStr="King, 1994" startWordPosition="888" endWordPosition="889">items indicate structure sharing. For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994).3 (Meurers and Minnen, 1997) propose a compilation of lexical rules into TIT definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in (Carpenter, 1992). Typed feature structures as normal form TFC terms are merely syntactic objects. &apos;See (King, 1994) for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM append(0, append(0 I append( Figure 3: Example of a set of TIT definite clauses which are used to restrict lexical entries. (Graz and Meurers, 1997b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an e</context>
</contexts>
<marker>King, 1994</marker>
<rawString>Paul King. 1994. Typed Feature Structures as Descriptions. In Proceedings of of the 15th Conference on Computational Linguistics, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Detmar Meurers</author>
<author>Guido Minnen</author>
</authors>
<date>1997</date>
<booktitle>A Computational Treatment of Lexical Rules in HPSG as Covariation in Lexical Entries. Computational Linguistics,</booktitle>
<volume>23</volume>
<issue>4</issue>
<contexts>
<context position="2484" citStr="Meurers and Minnen, 1997" startWordPosition="381" endWordPosition="385"> can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as discussed in (Gotz and Meurers, 1997a) and (Meurers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GOtz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and incorporates a coroutining mechanism which supports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and D6rre&apos;s deduction system, though, the selective mag</context>
<context position="5382" citStr="Meurers and Minnen, 1997" startWordPosition="837" endWordPosition="840"> addition, uninformative feature specifications are ignored and typing is left implicit when immaterial to the example at hand. Equations between typed feature structures are removed by simple substitution or tags indicating structure sharing. Notice that we also use non-numerical tags such as Xs and XsYs . In general all boxed items indicate structure sharing. For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994).3 (Meurers and Minnen, 1997) propose a compilation of lexical rules into TIT definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in (Carpenter, 1992). Typed feature structures as normal form TFC terms are merely syntactic objects. &apos;See (King, 1994) for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM append(0, append(0 I append( </context>
</contexts>
<marker>Meurers, Minnen, 1997</marker>
<rawString>Detmar Meurers and Guido Minnen. 1997. A Computational Treatment of Lexical Rules in HPSG as Covariation in Lexical Entries. Computational Linguistics, 23(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
</authors>
<title>Magic for Filter Optimization in Dynamic Bottom-up Processing.</title>
<date>1996</date>
<booktitle>In ACL Proceedings,</booktitle>
<location>Santa Cruz, California, USA.</location>
<contexts>
<context position="1664" citStr="Minnen, 1996" startWordPosition="251" endWordPosition="252"> contro1.1 The underlying idea is to achieve faster parsing by avoiding tabling on sub-computations which are not expensive. The so-called selective magic parser allows the user to apply magic compilation to specific constraints in a grammar which as a result can be processed dynamically in a bottom-up and goal-directed fashion. State of the art top-down processing techniques are used to deal with the remaining constraints. Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). As shown in (Minnen, 1996) •The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. I A more detailed discussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (T r; G6t</context>
</contexts>
<marker>Minnen, 1996</marker>
<rawString>Guido Minnen. 1996. Magic for Filter Optimization in Dynamic Bottom-up Processing. In ACL Proceedings, Santa Cruz, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
</authors>
<title>Off-line Compilation for Efficient Processing with Constraint-logic Grammars.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<pages>130</pages>
<institution>University of Tubingen, Germany.</institution>
<contexts>
<context position="1890" citStr="Minnen, 1998" startWordPosition="289" endWordPosition="290">ts in a grammar which as a result can be processed dynamically in a bottom-up and goal-directed fashion. State of the art top-down processing techniques are used to deal with the remaining constraints. Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). As shown in (Minnen, 1996) •The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. I A more detailed discussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as discussed in (Gotz and Meurers, 1997a) and (Meurers and Minnen, 1997). Type</context>
</contexts>
<marker>Minnen, 1998</marker>
<rawString>Guido Minnen. 1998. Off-line Compilation for Efficient Processing with Constraint-logic Grammars. Ph.D. thesis, University of Tubingen, Germany. Technical report SFB 340 nr. 130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee Naish</author>
</authors>
<date>1986</date>
<booktitle>Negation and Control in Prolog.</booktitle>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="18792" citStr="Naish, 1986" startWordPosition="3164" endWordPosition="3165">nts that need to be set during processing to a minimum. Furthermore, it leads to earlier failure detection. Finally, the used top-down interpreter implements a powerful coroutining mechanism:12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is determined on the basis of so-called delay patterns.13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking. See also (Colmerauer, 1982; Naish, 1986). &amp;quot;In the literature delay patterns are sometimes also referred to as wait declarations or block statements. sk. non-parse type goals 169 Proceedings of EACL &apos;99 indicate which restricting information has to be available before a goal is processed. 3.4 Adapted Semi-naive Bottom-up Interpretation The definite clauses resulting from selective magic transformation are interpreted using a semi-naive bottom-up interpreter that is adapted in two respects. It ensures that non-parse type goals are interpreted using the advanced top-down interpreter, and it allows non-parse type goals that remain delay</context>
</contexts>
<marker>Naish, 1986</marker>
<rawString>Lee Naish. 1986. Negation and Control in Prolog. Springer-Verlag, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Nilsson</author>
<author>Jan Maluszynski</author>
</authors>
<title>Logic, Programming and Prolog.</title>
<date>1995</date>
<publisher>John Wiley &amp; Sons,</publisher>
<location>Chichester, UK,</location>
<note>2nd edition.</note>
<contexts>
<context position="7063" citStr="Nilsson and Maluszynski, 1995" startWordPosition="1102" endWordPosition="1105"> compiling an HPSG theory into typed feature grammars. 2.2 Magic Compilation Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). Because magic compilation does not refer to the specific constraint language adopted, its application is not limited to logic programs/grammars: It can be applied to relational extensions of other constraint languages such as typed feature grammars without further adaptions. Due to space limitations we discuss magic compilation by example only. The interested reader is referred to (Nilsson and Maluszynski, 1995) for an introduction. Example 2 We illustrate magic compilation of typed feature grammars with respect to definite 4(Gotz, 1995) proves that this compilation method is sound in the general case and defines the large class of type constraints for which it is complete. CAT constituent( [ PHON constituent( SEM AGR. SEM CAT PHON AGR np 1), 2 4 6 3 [SUB.! 4 5 append ARG3 list LRG1 /is] ARG2 list 5 Ys Ys )• ), Ys , (Ec I XsYs )):- Xs Ys XsYs )- )• fly ( marl ) third-sing mary_lf (sleeps) third-sing 1. sleep 166 Proceedings of EACL &apos;99 Figure 1: Example of a typed feature grammar signature (part 1) C</context>
</contexts>
<marker>Nilsson, Maluszynski, 1995</marker>
<rawString>Ulf Nilsson and Jan Maluszynski. 1995. Logic, Programming and Prolog. John Wiley &amp; Sons, Chichester, UK, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, Illinois, USA.</location>
<contexts>
<context position="2411" citStr="Pollard and Sag, 1994" startWordPosition="368" endWordPosition="371">I A more detailed discussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as discussed in (Gotz and Meurers, 1997a) and (Meurers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GOtz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and incorporates a coroutining mechanism which supports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In co</context>
<context position="5353" citStr="Pollard and Sag, 1994" startWordPosition="833" endWordPosition="836">ped feature structures. In addition, uninformative feature specifications are ignored and typing is left implicit when immaterial to the example at hand. Equations between typed feature structures are removed by simple substitution or tags indicating structure sharing. Notice that we also use non-numerical tags such as Xs and XsYs . In general all boxed items indicate structure sharing. For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994).3 (Meurers and Minnen, 1997) propose a compilation of lexical rules into TIT definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in (Carpenter, 1992). Typed feature structures as normal form TFC terms are merely syntactic objects. &apos;See (King, 1994) for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG. [ CAT $ (1) Constituent( PHON 1 ):- I SEM _ _... appendE a CAT (2) constituent( I PHON AGR. SEM CAT PHON constituent( AGR SEM </context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, Illinois, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghu Ramakrishnan</author>
<author>Divesh Srivastava</author>
<author>S Sudarshan</author>
</authors>
<title>Efficient Bottom-up Evaluation of Logic Programs.</title>
<date>1992</date>
<booktitle>The State of the Art in Computer Systems and Software Engineering.</booktitle>
<editor>In Joos Vandewalle (ed.),</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1636" citStr="Ramakrishnan et al. 1992" startWordPosition="243" endWordPosition="247"> dynamic bottom-up and advanced top-down contro1.1 The underlying idea is to achieve faster parsing by avoiding tabling on sub-computations which are not expensive. The so-called selective magic parser allows the user to apply magic compilation to specific constraints in a grammar which as a result can be processed dynamically in a bottom-up and goal-directed fashion. State of the art top-down processing techniques are used to deal with the remaining constraints. Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). As shown in (Minnen, 1996) •The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. I A more detailed discussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on T</context>
<context position="6646" citStr="Ramakrishnan et al. 1992" startWordPosition="1038" endWordPosition="1041">ite clauses which are used to restrict lexical entries. (Graz and Meurers, 1997b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an example. The ConTroll grammar development system as described in (Gotz and Meurers, 1997b) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars. 2.2 Magic Compilation Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al. 1992). Because magic compilation does not refer to the specific constraint language adopted, its application is not limited to logic programs/grammars: It can be applied to relational extensions of other constraint languages such as typed feature grammars without further adaptions. Due to space limitations we discuss magic compilation by example only. The interested reader is referred to (Nilsson and Maluszynski, 1995) for an introduction. Example 2 We illustrate magic compilation of typed feature grammars with respect to definite 4(Gotz, 1995) proves that this compilation method is sound in the ge</context>
</contexts>
<marker>Ramakrishnan, Srivastava, Sudarshan, 1992</marker>
<rawString>Raghu Ramakrishnan, Divesh Srivastava, and S. Sudarshan. 1992. Efficient Bottom-up Evaluation of Logic Programs. In Joos Vandewalle (ed.), 1992. The State of the Art in Computer Systems and Software Engineering. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
<author>Fernando Pereira</author>
</authors>
<title>Principles and Implementation of Deductive Parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<pages>24--1</pages>
<contexts>
<context position="11938" citStr="Shieber et al., 1995" startWordPosition="1960" endWordPosition="1963">g the necessary adaptions to the code for expository reasons. The table is initialized with the facts from the grammar. Facts are combined using a operation called match. The match operation unifies all but one of the right-hand side literals of a definite clause in the grammar with facts in the table. The 7Definite clauses serving as data are encoded using the predicate de f init e_c 1 ause/1: def inite_clause( (Us : - Rhs) ) . , where Rhs is a (possibly empty) list of literals. 8There are various other—more efficient—ways to implement a dynamic control strategy in Prolog. See, for example, (Shieber et al., 1995). °A term encoding of typed feature structures would enable the use of term unification instead. See, for example, (Gerdemann, 1995). remaining right-hand side literal is unified with a newly derived fact, i. e., a fact from the agenda. By doing this, repeated derivation of facts from the same earlier derived facts is avoided. semi_naive_int erpret (Goal) : - init ializat ion (Agenda , Table° ) , updat e_t able (Agenda , Table0 , Table) , member (edge (Goal , [] ) , Table ) . updat e_t able ( , Table , Table ) . update_t able ( [Edge I Agenda0] , Table0 , Table ) : - update_table_w_edge (Edge </context>
</contexts>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Stuart Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and Implementation of Deductive Parsing. Journal of Logic Programming, 24(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>An Efficient Implementation of the Head-corner Parser.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<marker>van Noord, 1997</marker>
<rawString>Gertjan van Noord. 1997. An Efficient Implementation of the Head-corner Parser. Computational Linguistics, 23(3).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>