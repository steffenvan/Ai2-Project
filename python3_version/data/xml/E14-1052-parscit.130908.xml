<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000265">
<title confidence="0.999312">
A Latent Variable Model for
Discourse-aware Concept and Entity Disambiguation
</title>
<author confidence="0.98081">
Angela Fahrni and Michael Strube
</author>
<affiliation confidence="0.965152">
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.92928">
Schloss-Wolfsbrunnenweg 35
69118 Heidelberg, Germany
</address>
<email confidence="0.913519">
(angela.fahrni|michael.strube)@h-its.org
</email>
<sectionHeader confidence="0.991613" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999264">
This paper takes a discourse-oriented per-
spective for disambiguating common and
proper noun mentions with respect to
Wikipedia. Our novel approach mod-
els the relationship between disambigua-
tion and aspects of cohesion using Markov
Logic Networks with latent variables.
Considering cohesive aspects consistently
improves the disambiguation results on
various commonly used data sets.
</bodyText>
<sectionHeader confidence="0.998789" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999877036363637">
“I have to review a paper”, the super-
visor moaned from the office. “Please
don’t disturb me until I’m done with the
review.” His student nodded, went to
the cafeteria, sat down in the sunshine
and started to read yesterday’s paper.
This text snippet illustrates two aspects that have
been neglected by previous disambiguation ap-
proaches. (1) The interpretation of different men-
tions, i.e. common and proper nouns, is deter-
mined by different notions of context: some men-
tions depend more on a local sentence-level con-
text (paper in read yesterday’s paper; the global
context is misleading), some more on a global one
(review in I’m done with the review; the local con-
text is not discriminative), some on both global
and local context (paper in review a paper). (2)
The context relevant to disambiguate a mention
depends on how it is embedded into discourse and
is not bound to the surface form of a mention (pa-
per in the first sentence vs. paper in the last one).
Starting from this observation, we argue that the
context relevant to disambiguate a mention cor-
relates with its cohesive scope, i.e. the text span
within which a mention establishes cohesive re-
lations. Therefore, we propose to disambiguate
mentions differently depending on their cohesive
scopes (Section 2). We distinguish between three
different cohesive scopes of mentions and model
them as latent variables using Markov Logic Net-
works (Section 3). The use of latent variables al-
lows us to learn and predict the cohesive scope
and the disambiguation of a mention jointly. This
comes with the advantage that the learning of the
scope assignment does not need annotated data by
itself but is guided by the annotations available for
the target prediction task, i.e. the disambiguation.
In this paper, we focus on concept and entity
disambiguation1 with respect to an inventory de-
rived from Wikipedia and compare (1) to a state-
of-the-art approach that treats all mentions alike
and uses the same features for disambiguation,
(2) to a pipeline-based approach, and (3) to other
state-of-the-art approaches (Section 4).
While early work disambiguated concepts us-
ing the local context (Csomai and Mihalcea,
2008), current research focuses on exploiting the
global document context (Milne and Witten, 2008;
Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni
and Strube, 2012; Cheng and Roth, 2013). Al-
though such global approaches try to balance be-
tween local and global context, they treat all men-
tions alike, i.e., they apply the same model and the
same weighting of local and global context fea-
tures for disambiguating all mentions (Section 5).
</bodyText>
<sectionHeader confidence="0.991203" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999581285714286">
Halliday and Hasan (1976) define cohesion as “re-
lations of meaning that exist within the text, and
that define it as a text” (p. 4). A tie is one instance
of such a cohesive relation between two items. Co-
hesive ties occur on various linguistic levels, such
as on the entity level (e.g. coreference and bridg-
ing relations) or on the concept level (e.g. lexical
</bodyText>
<footnote confidence="0.999873">
1In the following, we use concept to refer to concepts and
what is usually called entities (e.g. Ji et al. (2011)).
</footnote>
<page confidence="0.938381">
491
</page>
<note confidence="0.993293">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 491–500,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999906177777778">
chains). In this paper, we focus on concept-level
cohesion and assume that each concept referred to
by a mention can exhibit cohesive ties with con-
cepts from other lexical units. The cohesive scope
of a mention is the text span within which a con-
cept referred to by a mention shows such cohesive
ties. We distinguish three broad categories of co-
hesive scopes: (1) Mentions with local cohesive
scope exhibit cohesive ties with lexical units in
the same sentence; (2) mentions with intermedi-
ate cohesive scope show cohesive ties both within
the sentence and beyond; (3) mentions with global
cohesive scope form cohesive ties with mentions
across sentence boundaries.
The notion of scope is a means to define the ap-
propriate context to disambiguate a mention. A
mention of local scope does not exhibit relations
with lexical units outside its sentence. Hence, the
global context does not help to disambiguate it or
can even lead to the wrong disambiguation. For
a mention with global scope, the global context is
crucial, while the local context is not discrimina-
tive or even misleading. For a mention with in-
termediate scope both local and global context are
relevant. Hence, while the scope influences the ap-
propriate disambiguation context, the disambigua-
tion of a mention influences its scope. In the ex-
ample (Section 1), paper in read yesterday’s pa-
per refers to the concept NEWSPAPER. Its scope
is local, as it lacks some cohesive ties with men-
tions in other sentences. If it had been disam-
biguated to SCHOLARLY PAPER, its scope would
be global. This reciprocal relationship between
discourse structure and meaning has also been dis-
cussed by Asher and Lascarides (1995). They
use rhetorical relations for structuring discourse
while we rely on the notion of lexical cohesion
and model scope assignment and disambiguation
jointly.
Our notion of scope is related to work on
lexical chains (Morris and Hirst, 1991; Nelken
and Shieber, 2006; Mihalcea, 2006) and to work
in content modeling, e.g. Haghighi and Vander-
wende (2009) distinguish content vocabulary and
document-specific vocabulary.
</bodyText>
<sectionHeader confidence="0.996285" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999774838709677">
Given a set of features for disambiguation, we
aim to weight them differently depending on the
scope. To model the reciprocal relationship be-
tween scope assignment and disambiguation, we
propose a latent variables based approach using
Markov Logic Networks that allows us to learn
the parameters for the scope assignment and the
disambiguation tasks jointly and enables us to per-
form joint inference.
Our approach is joint as we assign the scope s
and predict the concept c for a mention m simulta-
neously. As during learning training data is avail-
able for the disambiguation task but not for the
scope assignment task, we face a problem with
latent variables. Latent variables represent miss-
ing information in the input or a part of the out-
put which is not relevant except for supporting the
prediction of the target (Smith, 2011). In our ap-
proach, the different cohesive scopes are modeled
by latent variables. Each mention to be disam-
biguated is assigned a scope s. All feature weights
are parametrized by scope s. The parameters for
the disambiguation and scope assignment tasks are
learned jointly and are guided by the annotations
available for the disambiguation task.
Markov Logic Networks can be represented as
log-linear models, when grounded, and are there-
fore straightforward to extend with latent variables
(Smith, 2011; Poon and Domingos, 2008). In ad-
dition, global features can be conveniently inte-
grated.
</bodyText>
<subsectionHeader confidence="0.999278">
3.1 Markov Logic Networks
</subsectionHeader>
<bodyText confidence="0.997311588235294">
Markov Logic (ML) incorporates first-order logic
and probabilities (Domingos and Lowd, 2009).
A Markov Logic Network (MLN) is a first-order
knowledge base and consists of a set of pairs
(Fi, wi), where Fi is a first-order formula and
wi ∈ ][R is the weight of formula Fi. It is a tem-
plate for constructing a Markov Network. This
Markov Network has a binary node for each pos-
sible grounding for each predicate of the MLN. If
the grounding of the predicate is true, the binary
node’s value is set to 1, otherwise to 0. Further-
more, it contains one feature2 for each ground for-
mula Fi. If a ground formula is true, its feature’s
value is set to 1, otherwise to 0. The feature’s
weight is provided by wi.
The probability distribution in the ground
Markov Network is given by
</bodyText>
<equation confidence="0.9581065">
P(X = x) = Z exp (� wini(x) I
i
</equation>
<footnote confidence="0.949859">
2In this section feature is used differently than in the rest
of the paper.
</footnote>
<page confidence="0.998225">
492
</page>
<bodyText confidence="0.999862">
where ni(x) is the number of true groundings of
Fi in x. The normalization factor Z is the partition
function.
To perform MAP inference we use thebeast3
which transforms the inference problem into an
Integer Linear Program and solves it using cutting
plane inference (Riedel, 2008).
</bodyText>
<subsectionHeader confidence="0.950341">
3.1.1 Weight Learning with Latent Variables
</subsectionHeader>
<bodyText confidence="0.991569666666667">
Since no annotations are available for the scope
distinction, we face a latent variable learning prob-
lem. For learning weights in this situation we fol-
low Poon and Domingos (2008). We split our hid-
den predicates into two parts: V are the ones for
which the ground truth is known (concepts) and
U are the ones for which there is no annotation
(scopes). Let O be the observed predicates. Let
o and v be the values of O and V in the train-
ing data. u denotes values assigned to U. Weight
learning finds a w that maximizes the conditional
log-likelihood
</bodyText>
<equation confidence="0.997625333333333">
L.(o, v) = log P.(V = vJO = o)
�= log P.(V = v, U = uJO = o),
u
</equation>
<bodyText confidence="0.998969">
where the sum is over all possible values of U.
Although Lw(o, v) is not convex, a local opti-
mum can be found via gradient descent by itera-
tively solving
</bodyText>
<equation confidence="0.993882">
wt+1 = wt + ηV.L.(o, v),
</equation>
<bodyText confidence="0.999855">
where the gradient ∇wLw(o, v) is given by
Ew denotes the expectation according to Pw
and ni(o, v, u) is the number of true ground-
ings of formula Fi under the assignment spec-
ified by (o, v, u). We use a voted perceptron
(Lowd and Domingos, 2007) which approximates
the expectations via computing the MAP solution
with (o, v) fixed (Ew[ni(o, v, U)]) and (o) fixed
(Ew[ni(o,V, U)]) respectively.
</bodyText>
<subsectionHeader confidence="0.94115">
3.1.2 Scope-aware Concept Disambiguation
</subsectionHeader>
<bodyText confidence="0.989985333333333">
Both the scope assignment and the disambiguation
task are performed jointly using Markov Logic
Networks.
</bodyText>
<footnote confidence="0.7128">
3http://code.google.com/p/thebeast.
</footnote>
<bodyText confidence="0.999538891304348">
Table 1 shows the core of our proposed ap-
proach in terms of predicates and first-order logic
formulas. We build upon our previous approach
for joint concept disambiguation and clustering
(Fahrni and Strube, 2012). For brevity, we only
discuss the scope-aware extension of the disam-
biguation part. The extension for clustering is
done analogously.
The purpose of assigning a scope to each
mention m is to learn scope-specific weights
for disambiguation to account for heteroge-
nous scopes of mentions. The learned weights
are parametrized by scopes. We indicate this
parametrization of learned weights by w(s) (cf.
Table 1, f8, f9).
For each relation to predict, a hidden predicate
is defined. We are interested in predicting two
relations: a relation between a mention m and a
concept c (p1: hasConcept(m, c)) and a relation
between a mention m and a scope s (p3: hasS-
cope(m, s)). To bridge between the disambigua-
tion and the scope assignment task a third hid-
den predicate relatesScopeToConcept(m, c, s) (p2)
models a relation between a mention m, a concept
c and a scope s. This predicate together with For-
mulas f4 − f7 garantuees that the scope assign-
ment and the selection of a concept for a mention
influence each other and that the ground hidden
predicates are in accordance.4 Hard cardinality
constraints (f1, f2, f3) enforce that each mention
m is assigned exactly one scope s and at most one
concept c.
The hidden predicates and formulas form the
core. Features for the disambiguation and the
scope assignment tasks are incorporated using lo-
cal and global formulas with learned weights. The
features are described in Section 3.2. Table 1 gives
formula templates for both tasks (please note that
these are templates not formulas (Section 3.2)):
(1) a template for formulas that add information
for scope assignment (f8) and (2) a template for
formulas that add information for disambigua-
tion (f9). All formulas with scope-parametrized
weights that are relevant for the concept prediction
task are defined for the predicate relatesScopeTo-
Concept. This enables us to activate the relevant
</bodyText>
<construct confidence="0.651743833333333">
4We also run experiments with just two hidden predi-
cates, i.e. hasConcept(m, c) and hasScope(m, s). All for-
mulas with learned weight were then defined in the fol-
lowing, less efficient way: `dm E M, c E C, s E S :
featureDisambiguation(m, c, q) --+ hasConcept(m, c) n
hasScope(m, s). q is a score (Table 1).
</construct>
<equation confidence="0.9580595">
∂ L.(o, v) = E.[ni(o, v, U)] − E.[ni(o, V, U)].
∂wi
</equation>
<page confidence="0.823487">
493
</page>
<subsectionHeader confidence="0.627877">
Predicates
</subsectionHeader>
<bodyText confidence="0.626614">
Hidden predicates
</bodyText>
<equation confidence="0.946757086956522">
p1 hasConcept(m, c)
p2 relatesScopeToConcept(m, c, s)
p3 hasScope(m, s)
Predicate template for disambiguation features
p4 featureDisambiguation(m, c, q)
Predicate template for scope assignment features
p5 featureScope(m, q)
Formulas
Hard cardinality constraints
f1 `dm E M : {c E C : hasConcept(m, c)J &lt; 1
f2 `dm E M : {c E C, s E S : relatesScopeToConcept(m, c, s)j &lt; 1
f3 `dm E M : {s E S : hasScope(m, s)J = 1
Hard constraints
f4 `dm E M, c E C, s E S : relatesScopeToConcept(m, c, s) --+ hasConcept(m, c)
f5 `dm E M, c E C, s E S : relatesScopeToConcept(m, c, s) --+ hasScope(m, s)
f6 `dm E M, c E C, s E S : hasConcept(m, c) n hasScope(m, s)
--+ relatesScopeToConcept(m, c, s)
f7 `dm E M, c E C : hasConcept(m, c) --+ ( {s E S : relatesScopeToConcept(m, c, s)1 = 1)
Formula template with learned weights for scope assignment
f8 q · w(s) `dm E M, s E S : featureScope(m, q) --+ hasScope(m, s)
Formula template with learned weights for disambiguation
f9 q · w(s) `dm E M, c E C, s E S : featureDisambiguation(m, c, q)
--+ relatesScopeToConcept(m, c, s)
</equation>
<tableCaption confidence="0.6395525">
Table 1: Predicates and formulas used for scope distinction and disambiguation (m represents a mention,
M sets of mentions, c a concept, C sets of concepts, s a scope, S sets of scopes, q scores, w weights and
</tableCaption>
<bodyText confidence="0.948719">
w(s) a weight which is parametrized by s). The two template predicates and formulas are generalized
patterns to integrate the features for the scope assignment and disambiguation task (Section 3.2).
scope-specific weights w(s) which depend on the
chosen scope s. The final weight for a formula
can also include a score q defined by the observed
predicate.
</bodyText>
<subsectionHeader confidence="0.987038">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.999916">
For disambiguation and clustering we build upon
our previous work (Fahrni and Strube, 2012). We
use the same features and formulas and adopt the
latter to learn scope-specific weights. Given for
example the local context similarity feature (pred-
icate hasContextSimilarity(m, c, q) where q is the
similarity score) and the corresponding formula
</bodyText>
<construct confidence="0.903979125">
`dm E M, c E CM : hasContextSimilarity(m, c, q)
--+ hasConcept(m, c)
with weight (q · w) we adopt it in the following
way (cf. Table 1, template f9):
`dm E M, s E S, c E CM :
hasContextSimilarity(m, c, q)
--+ relatesScopeToConcept(m, c, s)
with weight (q · w(s)).
</construct>
<bodyText confidence="0.99915225">
In order to distinguish between the three pro-
posed scopes, we use the features described in Ta-
ble 2. The first column shows the predicate which
can be used for template f8 in Table 1.
</bodyText>
<sectionHeader confidence="0.999254" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999972333333333">
We compare our novel scope-aware approach to
our previous scope-ignorant approach (Fahrni and
Strube, 2012) – which has achieved good results
in the English monolingual and Chinese and Span-
ish cross-lingual entity linking tasks at TAC 2012
and 2013 (Fahrni et al., 2014) – and a scope-aware
pipeline-based approach using the same features
and preprocessing to ensure a fair comparison.
This allows us to identify the differences in the
results that are due to scope-awareness and differ-
ences in the results that are due to different learn-
ing strategies (joint vs. pipeline-based). In addi-
tion, we compare our joint scope-aware approach
to state-of-the-art approaches using various data
sets.
</bodyText>
<subsectionHeader confidence="0.988995">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999777375">
Table 3 summarizes our test sets (ACE 2005, ACE
2004, MSNBC and TAC 2011) and our train-
ing and development sets derived from Wikipedia
(WP Training, WP Dev). For each data set we re-
port the total number of annotated mentions, the
number of mentions with a corresponding concept
in Wikipedia (non-NILs) and the number of NILs
(i.e. mentions that do not refer to a Wikipedia con-
</bodyText>
<page confidence="0.995568">
494
</page>
<table confidence="0.919219">
Predicates Description
Mention-based Features
idfHead(m, q) The more frequent a mention is, the more likely it is to exert a local scope. This is inspired by
work on indexing for IR. We use the idf score of the head of a mention according the English
Gigaword Corpus (Parker et al., 2011).
propernoun(m) Proper nouns are usually more prominent than common nouns and are more likely to have an
intermediate or global scope than common nouns.
singlewordNoun(m) Single word NPs are often less prominent than multi-word NPs and are more likely to be of local
scope.
abbrev(m) Abbreviations with a terminal dot such as Mr. or Ltd. tend to have a local scope as they are usually
local modifiers or specifications.
</table>
<subsectionHeader confidence="0.921695">
Features Based on Modification
</subsectionHeader>
<bodyText confidence="0.97533475">
isPreModified(m) If a mention is pre-modified, it tends to be more prominent than unmodified mentions. If a mention
headOfRelClause(m) is more prominent, it is more likely to have a larger scope.
Mentions that are the head of a relative clause are usually more prominent and are more likely to
have an intermediate or global scope.
</bodyText>
<subsectionHeader confidence="0.912156">
Features Based on the Text Structure
</subsectionHeader>
<bodyText confidence="0.997647210526316">
Mentions in theme position, which is in English often the subject, tend to pick up what has already
been mentioned before (Daneˇs, 1974). Since this is not just the case on the reference-level, but
also on the concept-level, the mention in theme position tends to be related to other mentions in
the text and tends to have an intermediate or global scope.
The earlier a mention appears in the sentence in English, the more thematic it is, and the more
likely it has an intermediate or global scope.
Focusing adverbs in the text pattern &lt;focusing adverb&gt; &lt;mention&gt; – e.g. “particularly Jack” –
indicate that the mention is thematic and therefore has larger scope.
A premodifier of a verbal argument is usually more likely to be of local scope.
A passive construction – e.g. “the thief was catched by the police” – is a way to reduce the
prominency of the agent (e.g. police). The agent tends to be of local scope.
Conjunctions are often used for exemplifications. Therefore mentions in conjunctions are often
less prominent.
In NPs with prepositional or genitive modifiers usually at most one part – either the modifying NP
or the head – has intermediate or global scope.
The more frequent the head of a mention appears in the text – also as a derivation, e.g. a verb,
according to CatVar (Habash and Dorr, 2003) –, the more prominent it is.
The earlier a mention appears in text, the more likely it is to exhibit global cohesive scope (cf. the
hard-to-be-beat lead baseline in summarization (Radev et al., 2003)).
</bodyText>
<equation confidence="0.9944052">
inSubjPosition(m)
posInSentence(m, q)
focusingAdverb(m)
modifiesArgument(m)
passiveBy(m)
inConjunction(m)
inDepRelPP(m1, m2)
inDepRelGen(m1, m2)
morphoTiesHead(m, q)
positionInText(m, q)
</equation>
<tableCaption confidence="0.6397035">
Table 2: Features for cohesive scope distinction. m, m1, m2 denote mentions, q a score. The predicates
are plugged in the template formula f8 in Table 1.
</tableCaption>
<table confidence="0.999934444444444">
Data set No. of Non- NILs Avg.
Men- NILs Ambi-
tions guity
WP Training 56,372 53,097 3,275 2.31
WP Dev 9,992 9,375 617 2.28
ACE 2005 29,300 27,184 2,116 6.52
ACE 2004 306 257 49 5.04
TAC 2011 2,250 1,124 1,126 6.32
MSNBC 756 629 127 5.29
</table>
<tableCaption confidence="0.997394">
Table 3: Statistics for data sets.
</tableCaption>
<bodyText confidence="0.9999113">
cept). The average ambiguity of mentions is given
by our lexicon (see Section 4.2).
Our system is exclusively trained on the internal
hyperlinks in Wikipedia with the advantage that no
manual annotation effort is needed. We use 500 ar-
ticles for training and 100 articles for development
(Fahrni and Strube, 2012). Each internal hyper-
link is considered as an annotated mention. The
pointer to the Wikipedia article serves as the cor-
rect concept for this mention and all other candi-
date concepts we obtain from our lexicon as wrong
concepts for this mention.
For the detailed analysis of our approach, we
use a version of the ACE 2005 corpus which con-
tains Wikipedia link annotations (Bentivogli et al.,
2010). All ACE mentions, both common and
proper nouns, are annotated with one or more links
to the English Wikipedia or as NILs. If a men-
tion is annotated with more than one link, we con-
sider it as correctly disambiguated if one of the an-
notated concepts has been chosen by our system.
ACE 2005 consists of 597 texts from newswire re-
ports, broadcast news, internet sources and tran-
scribed audio data and contains more annotations
than the other data sets we use for comparison.
While ACE 2005 and ACE 2004 (Ratinov et
al., 2011) fit our target scenario most (both com-
mon and proper nouns are annotated), MSNBC
(Cucerzan, 2007) and TAC 2011 (Ji et al., 2011)
are only annotated for proper nouns.
</bodyText>
<page confidence="0.995939">
495
</page>
<subsectionHeader confidence="0.966733">
4.2 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999953">
The training, development and testing data are all
preprocessed in the same way. We perform POS
tagging, syntactic parsing and named entity recog-
nition using the Stanford CoreNLP pipeline5. For
identifying mentions we extract all noun phrases
(excluding discontinuous phrases and determin-
ers) and look them up in our lexicon. Our lex-
icon and also all other information we obtained
from Wikipedia are extracted from the same En-
glish Wikipedia dump.6 The lexicon consists of
anchor texts, article titles and redirects.
</bodyText>
<subsectionHeader confidence="0.997199">
4.3 Settings
</subsectionHeader>
<bodyText confidence="0.975321066666667">
Upper bound: The upper bound shows the maxi-
mum performance we can reach given our lexicon
and preprocessing. If the correct concept is among
the candidate concepts of a mention, it is consid-
ered as correct.
First Concept: The first concept baseline is a
strong baseline in disambiguation. It chooses for
each mention its most frequent concept.
Scope-ignorant (Disambig.): Our previous
MLN-based approach for concept disambiguation
(Fahrni and Strube, 2012).
Scope-ignorant (Disambig. &amp; Clust.): Our pre-
vious MLN-based approach for joint disambigua-
tion and clustering of concepts (Fahrni and Strube,
2012).
</bodyText>
<subsectionHeader confidence="0.821155">
Pipeline-based Scope-aware (Disambig.): We
</subsectionHeader>
<bodyText confidence="0.997440944444444">
compare our joint approach to a pipeline-based
one in which the assignment of the cohesive scope
is done before disambiguation. The features for
the scope assignment and the disambiguation task
are exactly the same as in the joint setting and
implemented in Markov Logic. The weights for
the scope assignment and disambiguation task are
learned in a cascaded way. In contrast to the
joint approach, the hasScope(m, s) predicate is ob-
served during disambiguation.
Joint Scope-aware (Disambig.): This is our ap-
proach as described in Section 3 for concept dis-
ambiguation. As only local optimization is possi-
ble, initialization is crucial. We use the same ini-
tialization strategy as for the cascaded approach.
Joint Scope-aware (Disambig. &amp; Clust.): This is
our approach as described in Section 3 for disam-
biguation and clustering of concepts.
</bodyText>
<footnote confidence="0.994303666666667">
5http://nlp.stanford.edu/software/
corenlp.shtml
6We use the English Wikipedia dump from Jan. 4, 2012.
</footnote>
<note confidence="0.751712">
4.4 Analysis of Scope-awareness on
ACE 2005
</note>
<bodyText confidence="0.999964734693878">
In Table 4 we report precision (P), recall (R) and
F-measure (F) for non-NILs and NILs for the ACE
2005 data. We also report overall accuracy (Acc)
(aka micro-average) and calculate significance us-
ing a paired t-test.
Differences in the results can be exclusively
traced back to differences in the modeling (scope-
ignorant vs. scope-aware) and learning (pipeline-
based vs. joint). Learning scope-specific models
(pipeline-based or joint) significantly improves the
result with p &lt; 0.01 while using the same features
for disambiguation. Scope-aware joint approaches
significantly outperform the other corresponding
approaches (pipeline-based and scope-ignorant)
that use the same features for disambiguation (and
clustering) with p &lt; 0.01. While the pipeline-
based approach suffers from error propagation,
the joint approach also benefits from the learn-
ing strategy: learning weights for scope distinction
can be guided by the training data available for
the disambiguation task. Joint disambiguation and
clustering of mentions improves the disambigua-
tion results for both the scope-ignorant (Fahrni and
Strube, 2012) and the scope-aware approach.
As Table 4 indicates, the gain of the joint scope-
aware approach with respect to non-NILs is sub-
stantial in both precision and recall. For NILs
the recall improves while the precision decreases.
This leads to a slightly worse F-Measure for the
NILs. As NILs are much rarer than non-NILs in
the corpus, the overall accurracy for which we op-
timize is significantly higher for the scope-aware
approaches.
As no gold annotations for cohesive scopes are
available, we present statistics on the distribution
of induced scopes. Table 5 shows the distribu-
tion of the mentions across induced scopes. Men-
tions with local scope are more frequent than men-
tions with intermediate scope followed by men-
tions with global scope. Table 5 compares the
overall accurracy of the scope-ignorant joint dis-
ambiguation and clustering approach (Fahrni and
Strube, 2012) with the accurracy of the corre-
sponding joint scope-aware approach. The joint
scope-aware approach improves the disambigua-
tion results for mentions of all three scopes. The
biggest gain (2.79) is achieved for mentions with
induced global scope. The gain for mentions with
local and intermediate scope is 1.27 and 0.3 re-
</bodyText>
<page confidence="0.998158">
496
</page>
<table confidence="0.999826666666667">
Non-NILs P NILs F Acc
P R F R
Upper bound 94.8 91.8 93.3 71.3 100.0 83.3 92.4
First Concept 68.6 70.0 69.3 55.3 40.3 46.6 67.9
Scope-ignorant (Disambig.) (Fahrni &amp; Strube 2012) 77.3 76.0 76.6 44.7 54.2 49.0 74.4
Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Strube 2012) 76.8 76.9 76.9 50.2 50.0 50.1 74.9
Pipeline-based Scope-aware (Disambig.) 80.1 75.8 77.9 37.3 63.4 47.0 74.9
Joint Scope-aware (Disambig.) 80.1 76.6 78.3 39.2 61.5 47.9 75.5
Joint Scope-aware (Disambig. &amp; Clust.) 80.3 77.1 78.6 40.8 62.1 49.3 76.0
</table>
<tableCaption confidence="0.999258">
Table 4: Evaluation on ACE 2005 data
</tableCaption>
<table confidence="0.999913285714286">
Scope-ignorant Approach Joint Scope-aware Approach Scope Distribution (%)
(Disambig. &amp; Clust.) (Disambig. &amp; Clust.) (Acc)
(Fahrni &amp; Strube 2012) (Acc)
Global Scope 73.20 75.99 8.54
Intermediate Scope 76.34 76.64 31.05
Local Scope 75.57 76.84 60.40
Total 75.61 76.71 100.00
</table>
<tableCaption confidence="0.8159075">
Table 5: Evaluation on ACE 2005 data across induced scopes. The accurracy of the two compared
systems is slightly higher than in Table 4 as we consider here only mentions that have been recognized by
our mention identification strategy. In the evaluation in Table 4 mentions that have not been recognized
are considered as wrong.
</tableCaption>
<bodyText confidence="0.999820534883721">
spectively. A comparison of the learned weights
for the different scope-specific models shows that
for mentions with local scope the local context has
relatively more weight than for mentions with in-
termediate scope. For mentions with global scope,
it is striking that candidiate concepts that are not
related to the global context are relatively higher
punished than in the other two models.
To obtain some insights on the behaviour of the
joint scope-aware approach, we investigate some
examples. In a text on the 2004 US elections, the
mention Kerry in “Kerry was the clear winner, but
victory was snatched from him” is wrongly disam-
biguated to KERRY GAA, a branch of the Gaelic
football association, by the scope-ignorant ap-
proach, because the local context strongly prefers
an interpretation in the domain of sports. In
the joint scope-aware approach, Kerry is assigned
global scope, and it is correctly disambiguated
to JOHN KERRY, an American politician, as the
global relatedness overrules the local context in
this model. In another text on U.S. troops in
Iraq, the scope-ignorant approach disambiguates
south in “Monday’s advances came one day af-
ter British forces in the south made their deepest
push into Iraq’s second largest city” to SOUTHERN
UNITED STATES as concepts related to the USA
are quite prominent in the text. In the scope-aware
approach south is considered as being of local
scope and is correctly disambiguated as SOUTH.
In “we happen to be at a very nice spot by the
beach where this is a chance for people to get
away from cnn coverage” spot is disambiguated
as SPOT (SATELLITE) in the scope-ignorant ap-
proach (misled by CNN), while it has been cor-
rectly recognized as NIL by the scope-aware ap-
proach in which it is considered as being of inter-
mediate scope. The remaining disambiguation er-
rors can be traced back to (1) scope assignment er-
rors and (2) disambiguation errors (e.g. Palmisano
(global scope) is disambiguated as SAMUEL J.
PALMISANO, but the text refers to a different un-
known Palmisano).
</bodyText>
<subsectionHeader confidence="0.993068">
4.5 Comparison to State-of-the-art
Approaches
</subsectionHeader>
<bodyText confidence="0.99989425">
Compared to the state-of-the-art for concept and
entity disambiguation our approach performs fa-
vorably (Table 6). On ACE 2004 (Ratinov et
al., 2011) – which contains annotations for com-
mon and proper nouns and fits our target scenario
most – our scope-aware approach outperforms re-
cent state-of-the-art approaches for concept and
entity disambiguation, i.e. Ratinov et al. (2011)
and Cheng and Roth (2013). We also ran Rati-
nov et al.’s (2011) sytem on ACE 2005, but it
seems that its mention recognition is not designed
for ACE 2005.
We also evaluate our system on the task of en-
tity linking, i.e. the disambiguation of (selected)
proper nouns (MSNBC and TAC 2011). Our
system fails to beat the best systems, but still
</bodyText>
<page confidence="0.995456">
497
</page>
<table confidence="0.977887142857143">
System ACE 2004 MSNBC TAC 2011
BOC BOC Acc B3 P B3 R B3 F1
Ratinov et al. 2011; Cogcomp 77.3 74.9 78.7 75.7 76.5 76.1
Cheng &amp; Roth 2013 85.3 81.2 86.1 82.9 84.5 83.7
Monahan et al. 2011 (Best System at TAC 2011) 86.1 84.4 84.7 84.6
Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Strube 2012) 83.4 76.5 84.8 82.5 83.0 82.8
Joint Scope-aware (Disambig. &amp; Clust.) 86.3 79.0 85.5 83.6 82.7 83.1
</table>
<tableCaption confidence="0.993156">
Table 6: Evaluation on various data sets using the respective standard evaluation metrics. BOC stands
</tableCaption>
<bodyText confidence="0.981739125">
for Bag-of-Concepts. We use the code of Ratinov et al. (2011) to evaluate on ACE 2004 and MSNBC.
For TAC 2011, we use the offical evaluation script and report the micro-average (Acc) and B3 scores.
Note that for TAC we use three additional disambiguation features – they measure the similarity of the
article name to the context – both in the scope-ignorant and the scope-aware approach.
achieves competitive performance without train-
ing on TAC data. On all data sets, the joint
scope-aware approach consistently outperforms
the scope-ignorant approach ceteris paribus.
</bodyText>
<sectionHeader confidence="0.999888" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999107244897959">
Joint approaches have been successful in the past
in NLP (e.g. Meza-Ruiz and Riedel (2009)). The
idea of augmenting a model with additional latent
variables to increase its expressiveness is known as
hidden or latent variable learning (Smith, 2011)
and is a promising research direction with success-
ful applications in e.g. syntactic parsing (Petrov
et al., 2006), statistical machine translation (Blun-
som et al., 2008) and sentiment analysis (Yesse-
nalina et al., 2010; Trivedi and Eisenstein, 2013).
For latent variable learning generative approaches
(Petrov et al., 2006), large margin methods (Smith,
2011) and conditional log-linear models have been
proposed. We focus here on conditional log-linear
models due to their flexibility and their previous
success for many tasks. Blunsom et al. (2008)
for instance use latent variables in the context of
discriminative machine translation and model the
derivation as a latent variable. Chang et al. (2010)
is close to our approach, as their latent variable ap-
proach also uses ILP. Poon and Domingos (2008)
also use latent variables with Markov Logic, al-
though with a completely different aim, i.e. for un-
supervised coreference resolution.
Most approaches that use Wikipedia as a re-
source for disambiguation focus on named enti-
ties (Bunescu and Pas¸ca, 2006; Cucerzan, 2007;
Dredze et al., 2010; Ji and Grishman, 2011;
Hachey et al., 2013; Hoffart et al., 2011), while
only a few disambiguate common and proper
nouns like us (Csomai and Mihalcea, 2008; Milne
and Witten, 2008; Zhou et al., 2010; Ratinov et al.,
2011; Cheng and Roth, 2013). We build upon our
previous Markov Logic based approach for joint
concept disambiguation and clustering (Fahrni and
Strube, 2012). In contrast to us, most approaches
for lexical disambiguation use either one model
for all mentions (Milne and Witten, 2008; Rati-
nov et al., 2011) or a separate model for each men-
tion or concept which requires a lot of training data
(e.g. Bryl et al. (2010)). Only a few approaches try
to learn specific models for groups of mentions,
although none of them is discourse-motivated as
ours: Mihalcea and Csomai (2005) learn a specific
model for each POS, Ando (2006) uses alternating
structure optimization to simultantanously learn a
number of WSD problems and Dhillon and Ungar
(2009) improve feature selection for WSD by in-
tegrating knowledge from similar words.
</bodyText>
<sectionHeader confidence="0.997383" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999861">
In this paper, we discuss the relationship between
cohesion and concept disambiguation and pro-
pose a cohesive scope-aware disambiguation ap-
proach. We distinguish between three different co-
hesive scopes (local, intermediate and global) and
model the scope assignment and the disambigua-
tion jointly using latent variables in the framework
of MLN. The joint scope-aware approach signifi-
cantly improves over both a state-of-the-art and a
pipeline-based approach using the same features
for the disambiguation task.
For future work, we are planning to investigate
the relation between discourse structure and co-
hesive scope more deeply and to integrate scope-
specific disambiguation features.
</bodyText>
<sectionHeader confidence="0.998293" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996598">
We would like to thank Sebastian Martschat for his
valuable comments. This work has been partially
funded by the Klaus Tschira Foundation.
</bodyText>
<page confidence="0.997655">
498
</page>
<sectionHeader confidence="0.850497" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.983071063636364">
Rie Kubota Ando. 2006. Applying alternating struc-
ture optimization to word sense disambiguation. In
Proceedings of the 10th Conference on Computa-
tional Natural Language Learning, New York, N.Y.,
USA, 8–9 June 2006, pages 77–84.
Nicholas Asher and Alex Lascarides. 1995. Lexical
disambiguation in a discourse context. Journal of
Semantics, 12(1):69–108.
Luisa Bentivogli, Pamela Forner, Claudio Giu-
liano, Alessandro Marchetti, Emanuele Pianta, and
Kateryna Tymoshenko. 2010. Extending English
ACE 2005 corpus annotation with ground-truth links
to Wikipedia. In Proceedings of the 2nd Work-
shop on The People’s Web: Colloboratively Con-
structed Semantic Resources, Beijing, China, 28 Au-
gust 2010, pages 19–27.
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A discriminative latent variable model for statisti-
cal machine translation. In Proceedings of the 46th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
Columbus, Ohio, 15–20 June 2008, pages 200–208.
Volha Bryl, Claudio Giuliano, Luciano Serafini, and
Kateryna Tymoshenko. 2010. Supporting natu-
ral language processing with background knowl-
edge: Coreference resolution case. In Proceedings
of the 9th International Semantic Web Conference,
Revised Selected Papers, Part I, Shanghai, China, 7-
11 November 2010, pages 80–95.
Razvan Bunescu and Marius Pas¸ca. 2006. Using en-
cyclopedic knowledge for named entity disambigua-
tion. In Proceedings of the 11th Conference of the
European Chapter of the Association for Compu-
tational Linguistics, Trento, Italy, 3–7 April 2006,
pages 9–16.
Ming-Wei Chang, Vivek Srikumar, Dan Goldwasser,
and Dan Roth. 2010. Structured output learning
with indirect supervision. In Proceedings of the
27th International Conference on Machine Learn-
ing, Haifa, Israel, 21–24 June 2010, pages 199–206.
Xiao Cheng and Dan Roth. 2013. Relational infer-
ence for Wikification. In Proceedings of the 2013
Conference on Empirical Methods in Natural Lan-
guage Processing, Seattle, Wash., 18–21 October
2013, pages 1787–1796.
Andras Csomai and Rada Mihalcea. 2008. Linking
documents to encyclopedic knowledge. IEEE Intel-
ligent Systems, 23(5):34–41.
Silviu Cucerzan. 2007. Large-scale named entity
disambiguation based on Wikipedia data. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Language Learning, Prague, Czech Re-
public, 28–30 June 2007, pages 708–716.
Frantiˇsek Daneˇs. 1974. Functional sentence perspec-
tive and the organization of the text. In F. Daneˇs,
editor, Papers on Functional Sentence Perspective,
pages 106–128. Prague: Academia.
Paramveer S. Dhillon and Lyle H. Ungar. 2009. Trans-
fer learning, feature selection and word sense dis-
ambguation. In Proceedings of the ACL-IJCNLP
2009 Conference Short Papers, Singapore, 2–7 Au-
gust 2009, pages 257–260.
Pedro Domingos and Daniel Lowd. 2009. Markov
Logic: An Interface Layer for Artificial Intelligence.
Morgan Claypool Publishers.
Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-
ber, and Tim Finin. 2010. Entity disambigua-
tion for knowledge base population. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, Beijing, China, 23–27 Au-
gust 2010, pages 277–285.
Angela Fahrni and Michael Strube. 2012. Jointly
disambiguating and clustering concepts and entities
with Markov logic. In Proceedings of the 24th Inter-
national Conference on Computational Linguistics,
Mumbai, India, 8–15 December 2012, pages 815–
832.
Angela Fahrni, Benjamin Heinzerling, Thierry G¨ockel,
and Michael Strube. 2014. HITS’ monolin-
gual and cross-lingual entity linking system at TAC
2013. In Proceedings of the Text Analysis Confer-
ence, National Institute of Standards and Technol-
ogy, Gaithersburg, Maryland, USA, 18–19 Novem-
ber 2013.
Nizar Habash and Bonnie Dorr. 2003. A catego-
rial variation database for English. In Proceed-
ings of the Human Language Technology Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics, Edmonton, Al-
berta, Canada, 27 May –1 June 2003, pages 17–23.
Ben Hachey, Will Radford, Joel Nothman, Matthew
Honnibal, and James R. Curran. 2013. Evaluat-
ing entity linking with Wikipedia. Artificial Intel-
ligence, 194:130–150.
Aria Haghighi and Lucy Vanderwende. 2009. Explor-
ing content models for multi-document summariza-
tion. In Proceedings of Human Language Technolo-
gies 2009: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics, Boulder, Col., 31 May – 5 June 2009, pages
362–370.
M. A. K. Halliday and Ruqaiya Hasan. 1976. Cohe-
sion in English. London, U.K.: Longman.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the 2011 Con-
ference on Empirical Methods in Natural Language
</reference>
<page confidence="0.989489">
499
</page>
<reference confidence="0.999914232142857">
Processing, Edinburgh, Scotland, U.K., 27–29 July
2011, pages 782–792.
Heng Ji and Ralph Grishman. 2011. Knowledge base
population: Successful approaches and challenges.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics, Portland,
Oreg., 19–24 June 2011, pages 1148–1158.
Heng Ji, Ralph Grishman, and Hoa Dang. 2011.
Overview of the TAC 2011 knowledge base popula-
tion track. In Proceedings of the Text Analysis Con-
ference, National Institute of Standards and Technol-
ogy, Gaithersburg, Maryland, USA, 14–15 Novem-
ber 2011.
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective anno-
tation of Wikipedia entities in web text. In Pro-
ceedings of the 15th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, Paris,
France, 28 June – 1 July 2009, pages 457–466.
Daniel Lowd and Pedro Domingos. 2007. Efficient
weight learning for Markov logic networks. In
Proceedings of the 11th European Conference on
Principles and Practices of Knowledge Discovery
in Databases, Warsaw, Poland, 17–21 September
2007, pages 200–211.
Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly
identifying predicates, arguments and senses using
Markov logic. In Proceedings of Human Language
Technologies 2009: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, Boulder, Col., 31 May – 5 June
2009, pages 155–163.
Rada Mihalcea and Andras Csomai. 2005. Sense-
Learner: Word sense disambiguation for all words in
unrestricted text. In Proceedings of the Interactive
Poster and Demonstrations Sessions at the 43rd An-
nual Meeting of the Association for Computational
Linguistics, Ann Arbor, Mich., 25–30 June 2005,
pages 53–56.
Rada Mihalcea. 2006. Knowledge-based methods
for WSD. In E. Agirre and P.G. Edmonds, editors,
Word Sense Disambiguation: Algorithms and Appli-
cations, pages 107–131. Springer, Heidelberg, Ger-
many.
David Milne and Ian H. Witten. 2008. Learning to link
with Wikipedia. In Proceedings of the ACM 17th
Conference on Information and Knowledge Man-
agement (CIKM 2008), Napa Valley, Cal., USA, 26–
30 October 2008, pages 1046–1055.
Jane Morris and Graeme Hirst. 1991. Lexical cohe-
sion computed by thesaural relations as an indicator
of the structure of text. Computational Linguistics,
17(1):21–48.
Rani Nelken and Stuart Shieber. 2006. Lexical chain-
ing and word-sense-disambiguation. Technical Re-
port TR-06-07, Computer Science Group, Harvard
University, Cambridge, Mass.
Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword Fifth Edi-
tion. LDC2011T07.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associ-
ation for Computational Linguistics, Sydney, Aus-
tralia, 17–21 July 2006, pages 433–440.
Hoifung Poon and Pedro Domingos. 2008. Joint unsu-
pervised coreference resolution with Markov Logic.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, Waikiki,
Honolulu, Hawaii, 25–27 October 2008, pages 650–
659.
Dragomir R. Radev, Simone Teufel, Horacio Saggion,
Wai Lam, John Blitzer, Hong Qi, Arda Celebi,
Danyu Liu, and Elliott Drabek. 2003. Evaluation
challenges in large-scale document summarization.
In Proceedings of the 41st Annual Meeting of the As-
sociation for Computational Linguistics, Sapporo,
Japan, 7–12 July 2003, pages 375–382.
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to Wikipedia. In Proceedings of the
49th Annual Meeting of the Association for Com-
putational Linguistics, Portland, Oreg., 19–24 June
2011, pages 1375–1384.
Sebastian Riedel. 2008. Improving the accuracy and
efficiency of MAP inference for Markov logic. In
Proceedings of the 24th Conference on Uncertainty
in Artificial Intelligence, Helsinki, Finland, 9–12
July 2008, pages 468–475.
Noah A. Smith. 2011. Linguistic Structure Prediction.
Morgan &amp; Claypool Publishers.
Rakshit Trivedi and Jacob Eisenstein. 2013. Dis-
course connectors for latent subjectivity in sentiment
analysis. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Atlanta, Georgia, 9–14 June 2013, pages
808–813.
Ainur Yessenalina, Yejin Choi, and Claire Cardie.
2010. Automatically generating annotator rationales
to improve sentiment classification. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, Uppsala, Sweden, 11–
16 July 2010, pages 336–341.
Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Flavian
Vasile, and Scott Gaffney. 2010. Resolving sur-
face forms to Wikipedia topics. In Proceedings
of the 23rd International Conference on Compu-
tational Linguistics, Beijing, China, 23–27 August
2010, pages 1335–1343.
</reference>
<page confidence="0.995609">
500
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.575624">
<title confidence="0.9991225">A Latent Variable Model Discourse-aware Concept and Entity Disambiguation</title>
<author confidence="0.995339">Angela Fahrni</author>
<author confidence="0.995339">Michael</author>
<affiliation confidence="0.790553">Heidelberg Institute for Theoretical Studies Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.99984">69118 Heidelberg, Germany</address>
<email confidence="0.999103">(angela.fahrni|michael.strube)@h-its.org</email>
<abstract confidence="0.999048545454545">This paper takes a discourse-oriented perspective for disambiguating common and proper noun mentions with respect to Wikipedia. Our novel approach models the relationship between disambiguation and aspects of cohesion using Markov Logic Networks with latent variables. Considering cohesive aspects consistently improves the disambiguation results on various commonly used data sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rie Kubota Ando</author>
</authors>
<title>Applying alternating structure optimization to word sense disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning,</booktitle>
<pages>77--84</pages>
<location>New York, N.Y., USA, 8–9</location>
<contexts>
<context position="32456" citStr="Ando (2006)" startWordPosition="5367" endWordPosition="5368">and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) uses alternating structure optimization to simultantanously learn a number of WSD problems and Dhillon and Ungar (2009) improve feature selection for WSD by integrating knowledge from similar words. 6 Conclusions In this paper, we discuss the relationship between cohesion and concept disambiguation and propose a cohesive scope-aware disambiguation approach. We distinguish between three different cohesive scopes (local, intermediate and global) and model the scope assignment and the disambiguation jointly using latent variables in the framework of MLN. The joint scope-aware approach significan</context>
</contexts>
<marker>Ando, 2006</marker>
<rawString>Rie Kubota Ando. 2006. Applying alternating structure optimization to word sense disambiguation. In Proceedings of the 10th Conference on Computational Natural Language Learning, New York, N.Y., USA, 8–9 June 2006, pages 77–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Lexical disambiguation in a discourse context.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="5646" citStr="Asher and Lascarides (1995)" startWordPosition="904" endWordPosition="907"> not discriminative or even misleading. For a mention with intermediate scope both local and global context are relevant. Hence, while the scope influences the appropriate disambiguation context, the disambiguation of a mention influences its scope. In the example (Section 1), paper in read yesterday’s paper refers to the concept NEWSPAPER. Its scope is local, as it lacks some cohesive ties with mentions in other sentences. If it had been disambiguated to SCHOLARLY PAPER, its scope would be global. This reciprocal relationship between discourse structure and meaning has also been discussed by Asher and Lascarides (1995). They use rhetorical relations for structuring discourse while we rely on the notion of lexical cohesion and model scope assignment and disambiguation jointly. Our notion of scope is related to work on lexical chains (Morris and Hirst, 1991; Nelken and Shieber, 2006; Mihalcea, 2006) and to work in content modeling, e.g. Haghighi and Vanderwende (2009) distinguish content vocabulary and document-specific vocabulary. 3 Approach Given a set of features for disambiguation, we aim to weight them differently depending on the scope. To model the reciprocal relationship between scope assignment and d</context>
</contexts>
<marker>Asher, Lascarides, 1995</marker>
<rawString>Nicholas Asher and Alex Lascarides. 1995. Lexical disambiguation in a discourse context. Journal of Semantics, 12(1):69–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Pamela Forner</author>
<author>Claudio Giuliano</author>
<author>Alessandro Marchetti</author>
<author>Emanuele Pianta</author>
<author>Kateryna Tymoshenko</author>
</authors>
<title>corpus annotation with ground-truth links to Wikipedia.</title>
<date>2010</date>
<journal>Extending English ACE</journal>
<booktitle>In Proceedings of the 2nd Workshop on The People’s Web: Colloboratively Constructed Semantic Resources,</booktitle>
<pages>pages</pages>
<location>Beijing,</location>
<contexts>
<context position="20048" citStr="Bentivogli et al., 2010" startWordPosition="3364" endWordPosition="3367"> Our system is exclusively trained on the internal hyperlinks in Wikipedia with the advantage that no manual annotation effort is needed. We use 500 articles for training and 100 articles for development (Fahrni and Strube, 2012). Each internal hyperlink is considered as an annotated mention. The pointer to the Wikipedia article serves as the correct concept for this mention and all other candidate concepts we obtain from our lexicon as wrong concepts for this mention. For the detailed analysis of our approach, we use a version of the ACE 2005 corpus which contains Wikipedia link annotations (Bentivogli et al., 2010). All ACE mentions, both common and proper nouns, are annotated with one or more links to the English Wikipedia or as NILs. If a mention is annotated with more than one link, we consider it as correctly disambiguated if one of the annotated concepts has been chosen by our system. ACE 2005 consists of 597 texts from newswire reports, broadcast news, internet sources and transcribed audio data and contains more annotations than the other data sets we use for comparison. While ACE 2005 and ACE 2004 (Ratinov et al., 2011) fit our target scenario most (both common and proper nouns are annotated), M</context>
</contexts>
<marker>Bentivogli, Forner, Giuliano, Marchetti, Pianta, Tymoshenko, 2010</marker>
<rawString>Luisa Bentivogli, Pamela Forner, Claudio Giuliano, Alessandro Marchetti, Emanuele Pianta, and Kateryna Tymoshenko. 2010. Extending English ACE 2005 corpus annotation with ground-truth links to Wikipedia. In Proceedings of the 2nd Workshop on The People’s Web: Colloboratively Constructed Semantic Resources, Beijing, China, 28 August 2010, pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Miles Osborne</author>
</authors>
<title>A discriminative latent variable model for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>200--208</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="30692" citStr="Blunsom et al., 2008" startWordPosition="5077" endWordPosition="5081">ach. achieves competitive performance without training on TAC data. On all data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also</context>
</contexts>
<marker>Blunsom, Cohn, Osborne, 2008</marker>
<rawString>Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008. A discriminative latent variable model for statistical machine translation. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Columbus, Ohio, 15–20 June 2008, pages 200–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Volha Bryl</author>
<author>Claudio Giuliano</author>
<author>Luciano Serafini</author>
<author>Kateryna Tymoshenko</author>
</authors>
<title>Supporting natural language processing with background knowledge: Coreference resolution case.</title>
<date>2010</date>
<booktitle>In Proceedings of the 9th International Semantic Web Conference, Revised Selected Papers, Part I,</booktitle>
<pages>80--95</pages>
<location>Shanghai,</location>
<contexts>
<context position="32249" citStr="Bryl et al. (2010)" startWordPosition="5331" endWordPosition="5334">n, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) uses alternating structure optimization to simultantanously learn a number of WSD problems and Dhillon and Ungar (2009) improve feature selection for WSD by integrating knowledge from similar words. 6 Conclusions In this paper, we discuss the relationship between cohesion and concept disambiguation and propose a cohesive scope-aware disambiguation approach. We distinguish between three dif</context>
</contexts>
<marker>Bryl, Giuliano, Serafini, Tymoshenko, 2010</marker>
<rawString>Volha Bryl, Claudio Giuliano, Luciano Serafini, and Kateryna Tymoshenko. 2010. Supporting natural language processing with background knowledge: Coreference resolution case. In Proceedings of the 9th International Semantic Web Conference, Revised Selected Papers, Part I, Shanghai, China, 7-11 November 2010, pages 80–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Marius Pas¸ca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>9--16</pages>
<location>Trento,</location>
<marker>Bunescu, Pas¸ca, 2006</marker>
<rawString>Razvan Bunescu and Marius Pas¸ca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Trento, Italy, 3–7 April 2006, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Vivek Srikumar</author>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
</authors>
<title>Structured output learning with indirect supervision.</title>
<date>2010</date>
<booktitle>In Proceedings of the 27th International Conference on Machine Learning,</booktitle>
<pages>199--206</pages>
<location>Haifa,</location>
<contexts>
<context position="31227" citStr="Chang et al. (2010)" startWordPosition="5158" endWordPosition="5161">arsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et</context>
</contexts>
<marker>Chang, Srikumar, Goldwasser, Roth, 2010</marker>
<rawString>Ming-Wei Chang, Vivek Srikumar, Dan Goldwasser, and Dan Roth. 2010. Structured output learning with indirect supervision. In Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 21–24 June 2010, pages 199–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Cheng</author>
<author>Dan Roth</author>
</authors>
<title>Relational inference for Wikification.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1787--1796</pages>
<location>Seattle, Wash.,</location>
<contexts>
<context position="3019" citStr="Cheng and Roth, 2013" startWordPosition="466" endWordPosition="469">isambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the entity level (e.g. coreference and bridging relations) or on the conc</context>
<context position="28878" citStr="Cheng and Roth (2013)" startWordPosition="4772" endWordPosition="4775">nment errors and (2) disambiguation errors (e.g. Palmisano (global scope) is disambiguated as SAMUEL J. PALMISANO, but the text refers to a different unknown Palmisano). 4.5 Comparison to State-of-the-art Approaches Compared to the state-of-the-art for concept and entity disambiguation our approach performs favorably (Table 6). On ACE 2004 (Ratinov et al., 2011) – which contains annotations for common and proper nouns and fits our target scenario most – our scope-aware approach outperforms recent state-of-the-art approaches for concept and entity disambiguation, i.e. Ratinov et al. (2011) and Cheng and Roth (2013). We also ran Ratinov et al.’s (2011) sytem on ACE 2005, but it seems that its mention recognition is not designed for ACE 2005. We also evaluate our system on the task of entity linking, i.e. the disambiguation of (selected) proper nouns (MSNBC and TAC 2011). Our system fails to beat the best systems, but still 497 System ACE 2004 MSNBC TAC 2011 BOC BOC Acc B3 P B3 R B3 F1 Ratinov et al. 2011; Cogcomp 77.3 74.9 78.7 75.7 76.5 76.1 Cheng &amp; Roth 2013 85.3 81.2 86.1 82.9 84.5 83.7 Monahan et al. 2011 (Best System at TAC 2011) 86.1 84.4 84.7 84.6 Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Stru</context>
<context position="31860" citStr="Cheng and Roth, 2013" startWordPosition="5265" endWordPosition="5268"> our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) use</context>
<context position="29331" citStr="Cheng &amp; Roth 2013" startWordPosition="4861" endWordPosition="4864"> our scope-aware approach outperforms recent state-of-the-art approaches for concept and entity disambiguation, i.e. Ratinov et al. (2011) and Cheng and Roth (2013). We also ran Ratinov et al.’s (2011) sytem on ACE 2005, but it seems that its mention recognition is not designed for ACE 2005. We also evaluate our system on the task of entity linking, i.e. the disambiguation of (selected) proper nouns (MSNBC and TAC 2011). Our system fails to beat the best systems, but still 497 System ACE 2004 MSNBC TAC 2011 BOC BOC Acc B3 P B3 R B3 F1 Ratinov et al. 2011; Cogcomp 77.3 74.9 78.7 75.7 76.5 76.1 Cheng &amp; Roth 2013 85.3 81.2 86.1 82.9 84.5 83.7 Monahan et al. 2011 (Best System at TAC 2011) 86.1 84.4 84.7 84.6 Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Strube 2012) 83.4 76.5 84.8 82.5 83.0 82.8 Joint Scope-aware (Disambig. &amp; Clust.) 86.3 79.0 85.5 83.6 82.7 83.1 Table 6: Evaluation on various data sets using the respective standard evaluation metrics. BOC stands for Bag-of-Concepts. We use the code of Ratinov et al. (2011) to evaluate on ACE 2004 and MSNBC. For TAC 2011, we use the offical evaluation script and report the micro-average (Acc) and B3 scores. Note that for TAC we use three additional dis</context>
</contexts>
<marker>Cheng, Roth, 2013</marker>
<rawString>Xiao Cheng and Dan Roth. 2013. Relational inference for Wikification. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Wash., 18–21 October 2013, pages 1787–1796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andras Csomai</author>
<author>Rada Mihalcea</author>
</authors>
<title>Linking documents to encyclopedic knowledge.</title>
<date>2008</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>23</volume>
<issue>5</issue>
<contexts>
<context position="2834" citStr="Csomai and Mihalcea, 2008" startWordPosition="437" endWordPosition="440">omes with the advantage that the learning of the scope assignment does not need annotated data by itself but is guided by the annotations available for the target prediction task, i.e. the disambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one insta</context>
<context position="31772" citStr="Csomai and Mihalcea, 2008" startWordPosition="5249" endWordPosition="5252">e translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated </context>
</contexts>
<marker>Csomai, Mihalcea, 2008</marker>
<rawString>Andras Csomai and Rada Mihalcea. 2008. Linking documents to encyclopedic knowledge. IEEE Intelligent Systems, 23(5):34–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning,</booktitle>
<pages>708--716</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="20669" citStr="Cucerzan, 2007" startWordPosition="3477" endWordPosition="3478">ACE mentions, both common and proper nouns, are annotated with one or more links to the English Wikipedia or as NILs. If a mention is annotated with more than one link, we consider it as correctly disambiguated if one of the annotated concepts has been chosen by our system. ACE 2005 consists of 597 texts from newswire reports, broadcast news, internet sources and transcribed audio data and contains more annotations than the other data sets we use for comparison. While ACE 2005 and ACE 2004 (Ratinov et al., 2011) fit our target scenario most (both common and proper nouns are annotated), MSNBC (Cucerzan, 2007) and TAC 2011 (Ji et al., 2011) are only annotated for proper nouns. 495 4.2 Preprocessing The training, development and testing data are all preprocessed in the same way. We perform POS tagging, syntactic parsing and named entity recognition using the Stanford CoreNLP pipeline5. For identifying mentions we extract all noun phrases (excluding discontinuous phrases and determiners) and look them up in our lexicon. Our lexicon and also all other information we obtained from Wikipedia are extracted from the same English Wikipedia dump.6 The lexicon consists of anchor texts, article titles and red</context>
<context position="31594" citStr="Cucerzan, 2007" startWordPosition="5220" endWordPosition="5221">els due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which r</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning, Prague, Czech Republic, 28–30 June 2007, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frantiˇsek Daneˇs</author>
</authors>
<title>Functional sentence perspective and the organization of the text.</title>
<date>1974</date>
<booktitle>Papers on Functional Sentence Perspective,</booktitle>
<pages>106--128</pages>
<editor>In F. Daneˇs, editor,</editor>
<publisher>Academia.</publisher>
<location>Prague:</location>
<marker>Daneˇs, 1974</marker>
<rawString>Frantiˇsek Daneˇs. 1974. Functional sentence perspective and the organization of the text. In F. Daneˇs, editor, Papers on Functional Sentence Perspective, pages 106–128. Prague: Academia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramveer S Dhillon</author>
<author>Lyle H Ungar</author>
</authors>
<title>Transfer learning, feature selection and word sense disambguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>257--260</pages>
<contexts>
<context position="32576" citStr="Dhillon and Ungar (2009)" startWordPosition="5382" endWordPosition="5385">d clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) uses alternating structure optimization to simultantanously learn a number of WSD problems and Dhillon and Ungar (2009) improve feature selection for WSD by integrating knowledge from similar words. 6 Conclusions In this paper, we discuss the relationship between cohesion and concept disambiguation and propose a cohesive scope-aware disambiguation approach. We distinguish between three different cohesive scopes (local, intermediate and global) and model the scope assignment and the disambiguation jointly using latent variables in the framework of MLN. The joint scope-aware approach significantly improves over both a state-of-the-art and a pipeline-based approach using the same features for the disambiguation t</context>
</contexts>
<marker>Dhillon, Ungar, 2009</marker>
<rawString>Paramveer S. Dhillon and Lyle H. Ungar. 2009. Transfer learning, feature selection and word sense disambguation. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, Singapore, 2–7 August 2009, pages 257–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro Domingos</author>
<author>Daniel Lowd</author>
</authors>
<title>Markov Logic: An Interface Layer for Artificial Intelligence.</title>
<date>2009</date>
<publisher>Morgan Claypool Publishers.</publisher>
<contexts>
<context position="7615" citStr="Domingos and Lowd, 2009" startWordPosition="1216" endWordPosition="1219">ch mention to be disambiguated is assigned a scope s. All feature weights are parametrized by scope s. The parameters for the disambiguation and scope assignment tasks are learned jointly and are guided by the annotations available for the disambiguation task. Markov Logic Networks can be represented as log-linear models, when grounded, and are therefore straightforward to extend with latent variables (Smith, 2011; Poon and Domingos, 2008). In addition, global features can be conveniently integrated. 3.1 Markov Logic Networks Markov Logic (ML) incorporates first-order logic and probabilities (Domingos and Lowd, 2009). A Markov Logic Network (MLN) is a first-order knowledge base and consists of a set of pairs (Fi, wi), where Fi is a first-order formula and wi ∈ ][R is the weight of formula Fi. It is a template for constructing a Markov Network. This Markov Network has a binary node for each possible grounding for each predicate of the MLN. If the grounding of the predicate is true, the binary node’s value is set to 1, otherwise to 0. Furthermore, it contains one feature2 for each ground formula Fi. If a ground formula is true, its feature’s value is set to 1, otherwise to 0. The feature’s weight is provide</context>
</contexts>
<marker>Domingos, Lowd, 2009</marker>
<rawString>Pedro Domingos and Daniel Lowd. 2009. Markov Logic: An Interface Layer for Artificial Intelligence. Morgan Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Paul McNamee</author>
<author>Delip Rao</author>
<author>Adam Gerber</author>
<author>Tim Finin</author>
</authors>
<title>Entity disambiguation for knowledge base population.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>277--285</pages>
<location>Beijing, China, 23–27</location>
<contexts>
<context position="31615" citStr="Dredze et al., 2010" startWordPosition="5222" endWordPosition="5225"> flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of trai</context>
</contexts>
<marker>Dredze, McNamee, Rao, Gerber, Finin, 2010</marker>
<rawString>Mark Dredze, Paul McNamee, Delip Rao, Adam Gerber, and Tim Finin. 2010. Entity disambiguation for knowledge base population. In Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, 23–27 August 2010, pages 277–285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Michael Strube</author>
</authors>
<title>Jointly disambiguating and clustering concepts and entities with Markov logic.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics,</booktitle>
<pages>815--832</pages>
<location>Mumbai,</location>
<contexts>
<context position="2996" citStr="Fahrni and Strube, 2012" startWordPosition="462" endWordPosition="465">ediction task, i.e. the disambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the entity level (e.g. coreference and bridging re</context>
<context position="10312" citStr="Fahrni and Strube, 2012" startWordPosition="1701" endWordPosition="1704">nment specified by (o, v, u). We use a voted perceptron (Lowd and Domingos, 2007) which approximates the expectations via computing the MAP solution with (o, v) fixed (Ew[ni(o, v, U)]) and (o) fixed (Ew[ni(o,V, U)]) respectively. 3.1.2 Scope-aware Concept Disambiguation Both the scope assignment and the disambiguation task are performed jointly using Markov Logic Networks. 3http://code.google.com/p/thebeast. Table 1 shows the core of our proposed approach in terms of predicates and first-order logic formulas. We build upon our previous approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). For brevity, we only discuss the scope-aware extension of the disambiguation part. The extension for clustering is done analogously. The purpose of assigning a scope to each mention m is to learn scope-specific weights for disambiguation to account for heterogenous scopes of mentions. The learned weights are parametrized by scopes. We indicate this parametrization of learned weights by w(s) (cf. Table 1, f8, f9). For each relation to predict, a hidden predicate is defined. We are interested in predicting two relations: a relation between a mention m and a concept c (p1: hasConcept(m, c)) and</context>
<context position="14311" citStr="Fahrni and Strube, 2012" startWordPosition="2398" endWordPosition="2401">e distinction and disambiguation (m represents a mention, M sets of mentions, c a concept, C sets of concepts, s a scope, S sets of scopes, q scores, w weights and w(s) a weight which is parametrized by s). The two template predicates and formulas are generalized patterns to integrate the features for the scope assignment and disambiguation task (Section 3.2). scope-specific weights w(s) which depend on the chosen scope s. The final weight for a formula can also include a score q defined by the observed predicate. 3.2 Features For disambiguation and clustering we build upon our previous work (Fahrni and Strube, 2012). We use the same features and formulas and adopt the latter to learn scope-specific weights. Given for example the local context similarity feature (predicate hasContextSimilarity(m, c, q) where q is the similarity score) and the corresponding formula `dm E M, c E CM : hasContextSimilarity(m, c, q) --+ hasConcept(m, c) with weight (q · w) we adopt it in the following way (cf. Table 1, template f9): `dm E M, s E S, c E CM : hasContextSimilarity(m, c, q) --+ relatesScopeToConcept(m, c, s) with weight (q · w(s)). In order to distinguish between the three proposed scopes, we use the features desc</context>
<context position="19653" citStr="Fahrni and Strube, 2012" startWordPosition="3296" endWordPosition="3299">d in the template formula f8 in Table 1. Data set No. of Non- NILs Avg. Men- NILs Ambitions guity WP Training 56,372 53,097 3,275 2.31 WP Dev 9,992 9,375 617 2.28 ACE 2005 29,300 27,184 2,116 6.52 ACE 2004 306 257 49 5.04 TAC 2011 2,250 1,124 1,126 6.32 MSNBC 756 629 127 5.29 Table 3: Statistics for data sets. cept). The average ambiguity of mentions is given by our lexicon (see Section 4.2). Our system is exclusively trained on the internal hyperlinks in Wikipedia with the advantage that no manual annotation effort is needed. We use 500 articles for training and 100 articles for development (Fahrni and Strube, 2012). Each internal hyperlink is considered as an annotated mention. The pointer to the Wikipedia article serves as the correct concept for this mention and all other candidate concepts we obtain from our lexicon as wrong concepts for this mention. For the detailed analysis of our approach, we use a version of the ACE 2005 corpus which contains Wikipedia link annotations (Bentivogli et al., 2010). All ACE mentions, both common and proper nouns, are annotated with one or more links to the English Wikipedia or as NILs. If a mention is annotated with more than one link, we consider it as correctly di</context>
<context position="21746" citStr="Fahrni and Strube, 2012" startWordPosition="3644" endWordPosition="3647">mation we obtained from Wikipedia are extracted from the same English Wikipedia dump.6 The lexicon consists of anchor texts, article titles and redirects. 4.3 Settings Upper bound: The upper bound shows the maximum performance we can reach given our lexicon and preprocessing. If the correct concept is among the candidate concepts of a mention, it is considered as correct. First Concept: The first concept baseline is a strong baseline in disambiguation. It chooses for each mention its most frequent concept. Scope-ignorant (Disambig.): Our previous MLN-based approach for concept disambiguation (Fahrni and Strube, 2012). Scope-ignorant (Disambig. &amp; Clust.): Our previous MLN-based approach for joint disambiguation and clustering of concepts (Fahrni and Strube, 2012). Pipeline-based Scope-aware (Disambig.): We compare our joint approach to a pipeline-based one in which the assignment of the cohesive scope is done before disambiguation. The features for the scope assignment and the disambiguation task are exactly the same as in the joint setting and implemented in Markov Logic. The weights for the scope assignment and disambiguation task are learned in a cascaded way. In contrast to the joint approach, the hasS</context>
<context position="24039" citStr="Fahrni and Strube, 2012" startWordPosition="3984" endWordPosition="3987"> using the same features for disambiguation. Scope-aware joint approaches significantly outperform the other corresponding approaches (pipeline-based and scope-ignorant) that use the same features for disambiguation (and clustering) with p &lt; 0.01. While the pipelinebased approach suffers from error propagation, the joint approach also benefits from the learning strategy: learning weights for scope distinction can be guided by the training data available for the disambiguation task. Joint disambiguation and clustering of mentions improves the disambiguation results for both the scope-ignorant (Fahrni and Strube, 2012) and the scope-aware approach. As Table 4 indicates, the gain of the joint scopeaware approach with respect to non-NILs is substantial in both precision and recall. For NILs the recall improves while the precision decreases. This leads to a slightly worse F-Measure for the NILs. As NILs are much rarer than non-NILs in the corpus, the overall accurracy for which we optimize is significantly higher for the scope-aware approaches. As no gold annotations for cohesive scopes are available, we present statistics on the distribution of induced scopes. Table 5 shows the distribution of the mentions ac</context>
<context position="31990" citStr="Fahrni and Strube, 2012" startWordPosition="5284" endWordPosition="5287">Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) uses alternating structure optimization to simultantanously learn a number of WSD problems and Dhillon and Ungar (2009) improve featu</context>
<context position="25413" citStr="Fahrni &amp; Strube 2012" startWordPosition="4211" endWordPosition="4214">mpares the overall accurracy of the scope-ignorant joint disambiguation and clustering approach (Fahrni and Strube, 2012) with the accurracy of the corresponding joint scope-aware approach. The joint scope-aware approach improves the disambiguation results for mentions of all three scopes. The biggest gain (2.79) is achieved for mentions with induced global scope. The gain for mentions with local and intermediate scope is 1.27 and 0.3 re496 Non-NILs P NILs F Acc P R F R Upper bound 94.8 91.8 93.3 71.3 100.0 83.3 92.4 First Concept 68.6 70.0 69.3 55.3 40.3 46.6 67.9 Scope-ignorant (Disambig.) (Fahrni &amp; Strube 2012) 77.3 76.0 76.6 44.7 54.2 49.0 74.4 Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Strube 2012) 76.8 76.9 76.9 50.2 50.0 50.1 74.9 Pipeline-based Scope-aware (Disambig.) 80.1 75.8 77.9 37.3 63.4 47.0 74.9 Joint Scope-aware (Disambig.) 80.1 76.6 78.3 39.2 61.5 47.9 75.5 Joint Scope-aware (Disambig. &amp; Clust.) 80.3 77.1 78.6 40.8 62.1 49.3 76.0 Table 4: Evaluation on ACE 2005 data Scope-ignorant Approach Joint Scope-aware Approach Scope Distribution (%) (Disambig. &amp; Clust.) (Disambig. &amp; Clust.) (Acc) (Fahrni &amp; Strube 2012) (Acc) Global Scope 73.20 75.99 8.54 Intermediate Scope 76.34 76.64 31.05 Lo</context>
<context position="29486" citStr="Fahrni &amp; Strube 2012" startWordPosition="4888" endWordPosition="4891">d Roth (2013). We also ran Ratinov et al.’s (2011) sytem on ACE 2005, but it seems that its mention recognition is not designed for ACE 2005. We also evaluate our system on the task of entity linking, i.e. the disambiguation of (selected) proper nouns (MSNBC and TAC 2011). Our system fails to beat the best systems, but still 497 System ACE 2004 MSNBC TAC 2011 BOC BOC Acc B3 P B3 R B3 F1 Ratinov et al. 2011; Cogcomp 77.3 74.9 78.7 75.7 76.5 76.1 Cheng &amp; Roth 2013 85.3 81.2 86.1 82.9 84.5 83.7 Monahan et al. 2011 (Best System at TAC 2011) 86.1 84.4 84.7 84.6 Scope-ignorant (Disambig. &amp; Clust.) (Fahrni &amp; Strube 2012) 83.4 76.5 84.8 82.5 83.0 82.8 Joint Scope-aware (Disambig. &amp; Clust.) 86.3 79.0 85.5 83.6 82.7 83.1 Table 6: Evaluation on various data sets using the respective standard evaluation metrics. BOC stands for Bag-of-Concepts. We use the code of Ratinov et al. (2011) to evaluate on ACE 2004 and MSNBC. For TAC 2011, we use the offical evaluation script and report the micro-average (Acc) and B3 scores. Note that for TAC we use three additional disambiguation features – they measure the similarity of the article name to the context – both in the scope-ignorant and the scope-aware approach. achieves c</context>
</contexts>
<marker>Fahrni, Strube, 2012</marker>
<rawString>Angela Fahrni and Michael Strube. 2012. Jointly disambiguating and clustering concepts and entities with Markov logic. In Proceedings of the 24th International Conference on Computational Linguistics, Mumbai, India, 8–15 December 2012, pages 815– 832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Benjamin Heinzerling</author>
<author>Thierry G¨ockel</author>
<author>Michael Strube</author>
</authors>
<title>HITS’ monolingual and cross-lingual entity linking system at TAC</title>
<date>2014</date>
<booktitle>In Proceedings of the Text Analysis Conference, National Institute of Standards and Technology,</booktitle>
<location>Gaithersburg, Maryland, USA,</location>
<marker>Fahrni, Heinzerling, G¨ockel, Strube, 2014</marker>
<rawString>Angela Fahrni, Benjamin Heinzerling, Thierry G¨ockel, and Michael Strube. 2014. HITS’ monolingual and cross-lingual entity linking system at TAC 2013. In Proceedings of the Text Analysis Conference, National Institute of Standards and Technology, Gaithersburg, Maryland, USA, 18–19 November 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Bonnie Dorr</author>
</authors>
<title>A categorial variation database for English.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>17--23</pages>
<location>Edmonton, Alberta,</location>
<contexts>
<context position="18526" citStr="Habash and Dorr, 2003" startWordPosition="3116" endWordPosition="3119">argument is usually more likely to be of local scope. A passive construction – e.g. “the thief was catched by the police” – is a way to reduce the prominency of the agent (e.g. police). The agent tends to be of local scope. Conjunctions are often used for exemplifications. Therefore mentions in conjunctions are often less prominent. In NPs with prepositional or genitive modifiers usually at most one part – either the modifying NP or the head – has intermediate or global scope. The more frequent the head of a mention appears in the text – also as a derivation, e.g. a verb, according to CatVar (Habash and Dorr, 2003) –, the more prominent it is. The earlier a mention appears in text, the more likely it is to exhibit global cohesive scope (cf. the hard-to-be-beat lead baseline in summarization (Radev et al., 2003)). inSubjPosition(m) posInSentence(m, q) focusingAdverb(m) modifiesArgument(m) passiveBy(m) inConjunction(m) inDepRelPP(m1, m2) inDepRelGen(m1, m2) morphoTiesHead(m, q) positionInText(m, q) Table 2: Features for cohesive scope distinction. m, m1, m2 denote mentions, q a score. The predicates are plugged in the template formula f8 in Table 1. Data set No. of Non- NILs Avg. Men- NILs Ambitions guity</context>
</contexts>
<marker>Habash, Dorr, 2003</marker>
<rawString>Nizar Habash and Bonnie Dorr. 2003. A categorial variation database for English. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Edmonton, Alberta, Canada, 27 May –1 June 2003, pages 17–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hachey</author>
<author>Will Radford</author>
<author>Joel Nothman</author>
<author>Matthew Honnibal</author>
<author>James R Curran</author>
</authors>
<title>Evaluating entity linking with Wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--130</pages>
<contexts>
<context position="31659" citStr="Hachey et al., 2013" startWordPosition="5230" endWordPosition="5233">many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a </context>
</contexts>
<marker>Hachey, Radford, Nothman, Honnibal, Curran, 2013</marker>
<rawString>Ben Hachey, Will Radford, Joel Nothman, Matthew Honnibal, and James R. Curran. 2013. Evaluating entity linking with Wikipedia. Artificial Intelligence, 194:130–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Exploring content models for multi-document summarization.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5</booktitle>
<pages>362--370</pages>
<contexts>
<context position="6000" citStr="Haghighi and Vanderwende (2009)" startWordPosition="959" endWordPosition="963">pe is local, as it lacks some cohesive ties with mentions in other sentences. If it had been disambiguated to SCHOLARLY PAPER, its scope would be global. This reciprocal relationship between discourse structure and meaning has also been discussed by Asher and Lascarides (1995). They use rhetorical relations for structuring discourse while we rely on the notion of lexical cohesion and model scope assignment and disambiguation jointly. Our notion of scope is related to work on lexical chains (Morris and Hirst, 1991; Nelken and Shieber, 2006; Mihalcea, 2006) and to work in content modeling, e.g. Haghighi and Vanderwende (2009) distinguish content vocabulary and document-specific vocabulary. 3 Approach Given a set of features for disambiguation, we aim to weight them differently depending on the scope. To model the reciprocal relationship between scope assignment and disambiguation, we propose a latent variables based approach using Markov Logic Networks that allows us to learn the parameters for the scope assignment and the disambiguation tasks jointly and enables us to perform joint inference. Our approach is joint as we assign the scope s and predict the concept c for a mention m simultaneously. As during learnin</context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Aria Haghighi and Lucy Vanderwende. 2009. Exploring content models for multi-document summarization. In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5 June 2009, pages 362–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>Ruqaiya Hasan</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English.</booktitle>
<publisher>Longman.</publisher>
<location>London, U.K.:</location>
<contexts>
<context position="3308" citStr="Halliday and Hasan (1976)" startWordPosition="515" endWordPosition="518">, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the entity level (e.g. coreference and bridging relations) or on the concept level (e.g. lexical 1In the following, we use concept to refer to concepts and what is usually called entities (e.g. Ji et al. (2011)). 491 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 491–500, Gothenburg, Sweden, A</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>M. A. K. Halliday and Ruqaiya Hasan. 1976. Cohesion in English. London, U.K.: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>27--29</pages>
<location>Edinburgh, Scotland, U.K.,</location>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, Scotland, U.K., 27–29 July 2011, pages 782–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Knowledge base population: Successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1148--1158</pages>
<location>Portland, Oreg.,</location>
<contexts>
<context position="31638" citStr="Ji and Grishman, 2011" startWordPosition="5226" endWordPosition="5229">r previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Ralph Grishman. 2011. Knowledge base population: Successful approaches and challenges. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, Oreg., 19–24 June 2011, pages 1148–1158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Dang</author>
</authors>
<title>Overview of the TAC 2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference, National Institute of Standards and Technology,</booktitle>
<pages>14--15</pages>
<location>Gaithersburg, Maryland, USA,</location>
<contexts>
<context position="3756" citStr="Ji et al. (2011)" startWordPosition="597" endWordPosition="600">hey apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the entity level (e.g. coreference and bridging relations) or on the concept level (e.g. lexical 1In the following, we use concept to refer to concepts and what is usually called entities (e.g. Ji et al. (2011)). 491 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 491–500, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics chains). In this paper, we focus on concept-level cohesion and assume that each concept referred to by a mention can exhibit cohesive ties with concepts from other lexical units. The cohesive scope of a mention is the text span within which a concept referred to by a mention shows such cohesive ties. We distinguish three broad categories of cohesive scopes: (1) Mentions with loca</context>
<context position="20700" citStr="Ji et al., 2011" startWordPosition="3482" endWordPosition="3485">proper nouns, are annotated with one or more links to the English Wikipedia or as NILs. If a mention is annotated with more than one link, we consider it as correctly disambiguated if one of the annotated concepts has been chosen by our system. ACE 2005 consists of 597 texts from newswire reports, broadcast news, internet sources and transcribed audio data and contains more annotations than the other data sets we use for comparison. While ACE 2005 and ACE 2004 (Ratinov et al., 2011) fit our target scenario most (both common and proper nouns are annotated), MSNBC (Cucerzan, 2007) and TAC 2011 (Ji et al., 2011) are only annotated for proper nouns. 495 4.2 Preprocessing The training, development and testing data are all preprocessed in the same way. We perform POS tagging, syntactic parsing and named entity recognition using the Stanford CoreNLP pipeline5. For identifying mentions we extract all noun phrases (excluding discontinuous phrases and determiners) and look them up in our lexicon. Our lexicon and also all other information we obtained from Wikipedia are extracted from the same English Wikipedia dump.6 The lexicon consists of anchor texts, article titles and redirects. 4.3 Settings Upper boun</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Dang. 2011. Overview of the TAC 2011 knowledge base population track. In Proceedings of the Text Analysis Conference, National Institute of Standards and Technology, Gaithersburg, Maryland, USA, 14–15 November 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayali Kulkarni</author>
<author>Amit Singh</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Collective annotation of Wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<volume>1</volume>
<pages>457--466</pages>
<location>Paris,</location>
<contexts>
<context position="2949" citStr="Kulkarni et al., 2009" startWordPosition="454" endWordPosition="457">y the annotations available for the target prediction task, i.e. the disambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the</context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti. 2009. Collective annotation of Wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Paris, France, 28 June – 1 July 2009, pages 457–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Lowd</author>
<author>Pedro Domingos</author>
</authors>
<title>Efficient weight learning for Markov logic networks.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th European Conference on Principles and Practices of Knowledge Discovery in Databases,</booktitle>
<pages>200--211</pages>
<location>Warsaw,</location>
<contexts>
<context position="9769" citStr="Lowd and Domingos, 2007" startWordPosition="1625" endWordPosition="1628">of O and V in the training data. u denotes values assigned to U. Weight learning finds a w that maximizes the conditional log-likelihood L.(o, v) = log P.(V = vJO = o) �= log P.(V = v, U = uJO = o), u where the sum is over all possible values of U. Although Lw(o, v) is not convex, a local optimum can be found via gradient descent by iteratively solving wt+1 = wt + ηV.L.(o, v), where the gradient ∇wLw(o, v) is given by Ew denotes the expectation according to Pw and ni(o, v, u) is the number of true groundings of formula Fi under the assignment specified by (o, v, u). We use a voted perceptron (Lowd and Domingos, 2007) which approximates the expectations via computing the MAP solution with (o, v) fixed (Ew[ni(o, v, U)]) and (o) fixed (Ew[ni(o,V, U)]) respectively. 3.1.2 Scope-aware Concept Disambiguation Both the scope assignment and the disambiguation task are performed jointly using Markov Logic Networks. 3http://code.google.com/p/thebeast. Table 1 shows the core of our proposed approach in terms of predicates and first-order logic formulas. We build upon our previous approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). For brevity, we only discuss the scope-aware extension </context>
</contexts>
<marker>Lowd, Domingos, 2007</marker>
<rawString>Daniel Lowd and Pedro Domingos. 2007. Efficient weight learning for Markov logic networks. In Proceedings of the 11th European Conference on Principles and Practices of Knowledge Discovery in Databases, Warsaw, Poland, 17–21 September 2007, pages 200–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Jointly identifying predicates, arguments and senses using Markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5</booktitle>
<pages>155--163</pages>
<contexts>
<context position="30363" citStr="Meza-Ruiz and Riedel (2009)" startWordPosition="5028" endWordPosition="5031">et al. (2011) to evaluate on ACE 2004 and MSNBC. For TAC 2011, we use the offical evaluation script and report the micro-average (Acc) and B3 scores. Note that for TAC we use three additional disambiguation features – they measure the similarity of the article name to the context – both in the scope-ignorant and the scope-aware approach. achieves competitive performance without training on TAC data. On all data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on condition</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly identifying predicates, arguments and senses using Markov logic. In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5 June 2009, pages 155–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>SenseLearner: Word sense disambiguation for all words in unrestricted text.</title>
<date>2005</date>
<booktitle>In Proceedings of the Interactive Poster and Demonstrations Sessions at the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>53--56</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="32407" citStr="Mihalcea and Csomai (2005)" startWordPosition="5356" endWordPosition="5359">nd Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for each POS, Ando (2006) uses alternating structure optimization to simultantanously learn a number of WSD problems and Dhillon and Ungar (2009) improve feature selection for WSD by integrating knowledge from similar words. 6 Conclusions In this paper, we discuss the relationship between cohesion and concept disambiguation and propose a cohesive scope-aware disambiguation approach. We distinguish between three different cohesive scopes (local, intermediate and global) and model the scope assignment and the disambiguation jointly using latent variables in the framework </context>
</contexts>
<marker>Mihalcea, Csomai, 2005</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2005. SenseLearner: Word sense disambiguation for all words in unrestricted text. In Proceedings of the Interactive Poster and Demonstrations Sessions at the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 25–30 June 2005, pages 53–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Knowledge-based methods for WSD.</title>
<date>2006</date>
<booktitle>Word Sense Disambiguation: Algorithms and Applications,</booktitle>
<pages>107--131</pages>
<editor>In E. Agirre and P.G. Edmonds, editors,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg, Germany.</location>
<contexts>
<context position="5930" citStr="Mihalcea, 2006" startWordPosition="950" endWordPosition="951">erday’s paper refers to the concept NEWSPAPER. Its scope is local, as it lacks some cohesive ties with mentions in other sentences. If it had been disambiguated to SCHOLARLY PAPER, its scope would be global. This reciprocal relationship between discourse structure and meaning has also been discussed by Asher and Lascarides (1995). They use rhetorical relations for structuring discourse while we rely on the notion of lexical cohesion and model scope assignment and disambiguation jointly. Our notion of scope is related to work on lexical chains (Morris and Hirst, 1991; Nelken and Shieber, 2006; Mihalcea, 2006) and to work in content modeling, e.g. Haghighi and Vanderwende (2009) distinguish content vocabulary and document-specific vocabulary. 3 Approach Given a set of features for disambiguation, we aim to weight them differently depending on the scope. To model the reciprocal relationship between scope assignment and disambiguation, we propose a latent variables based approach using Markov Logic Networks that allows us to learn the parameters for the scope assignment and the disambiguation tasks jointly and enables us to perform joint inference. Our approach is joint as we assign the scope s and p</context>
</contexts>
<marker>Mihalcea, 2006</marker>
<rawString>Rada Mihalcea. 2006. Knowledge-based methods for WSD. In E. Agirre and P.G. Edmonds, editors, Word Sense Disambiguation: Algorithms and Applications, pages 107–131. Springer, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with Wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACM 17th Conference on Information and Knowledge Management (CIKM 2008),</booktitle>
<pages>1046--1055</pages>
<location>Napa Valley, Cal., USA,</location>
<contexts>
<context position="2926" citStr="Milne and Witten, 2008" startWordPosition="450" endWordPosition="453">y itself but is guided by the annotations available for the target prediction task, i.e. the disambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic</context>
<context position="31796" citStr="Milne and Witten, 2008" startWordPosition="5253" endWordPosition="5256"> derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Cs</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008. Learning to link with Wikipedia. In Proceedings of the ACM 17th Conference on Information and Knowledge Management (CIKM 2008), Napa Valley, Cal., USA, 26– 30 October 2008, pages 1046–1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="5887" citStr="Morris and Hirst, 1991" startWordPosition="942" endWordPosition="945">pe. In the example (Section 1), paper in read yesterday’s paper refers to the concept NEWSPAPER. Its scope is local, as it lacks some cohesive ties with mentions in other sentences. If it had been disambiguated to SCHOLARLY PAPER, its scope would be global. This reciprocal relationship between discourse structure and meaning has also been discussed by Asher and Lascarides (1995). They use rhetorical relations for structuring discourse while we rely on the notion of lexical cohesion and model scope assignment and disambiguation jointly. Our notion of scope is related to work on lexical chains (Morris and Hirst, 1991; Nelken and Shieber, 2006; Mihalcea, 2006) and to work in content modeling, e.g. Haghighi and Vanderwende (2009) distinguish content vocabulary and document-specific vocabulary. 3 Approach Given a set of features for disambiguation, we aim to weight them differently depending on the scope. To model the reciprocal relationship between scope assignment and disambiguation, we propose a latent variables based approach using Markov Logic Networks that allows us to learn the parameters for the scope assignment and the disambiguation tasks jointly and enables us to perform joint inference. Our appro</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Jane Morris and Graeme Hirst. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1):21–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart Shieber</author>
</authors>
<title>Lexical chaining and word-sense-disambiguation.</title>
<date>2006</date>
<tech>Technical Report TR-06-07,</tech>
<institution>Computer Science Group, Harvard University,</institution>
<location>Cambridge, Mass.</location>
<contexts>
<context position="5913" citStr="Nelken and Shieber, 2006" startWordPosition="946" endWordPosition="949">ion 1), paper in read yesterday’s paper refers to the concept NEWSPAPER. Its scope is local, as it lacks some cohesive ties with mentions in other sentences. If it had been disambiguated to SCHOLARLY PAPER, its scope would be global. This reciprocal relationship between discourse structure and meaning has also been discussed by Asher and Lascarides (1995). They use rhetorical relations for structuring discourse while we rely on the notion of lexical cohesion and model scope assignment and disambiguation jointly. Our notion of scope is related to work on lexical chains (Morris and Hirst, 1991; Nelken and Shieber, 2006; Mihalcea, 2006) and to work in content modeling, e.g. Haghighi and Vanderwende (2009) distinguish content vocabulary and document-specific vocabulary. 3 Approach Given a set of features for disambiguation, we aim to weight them differently depending on the scope. To model the reciprocal relationship between scope assignment and disambiguation, we propose a latent variables based approach using Markov Logic Networks that allows us to learn the parameters for the scope assignment and the disambiguation tasks jointly and enables us to perform joint inference. Our approach is joint as we assign </context>
</contexts>
<marker>Nelken, Shieber, 2006</marker>
<rawString>Rani Nelken and Stuart Shieber. 2006. Lexical chaining and word-sense-disambiguation. Technical Report TR-06-07, Computer Science Group, Harvard University, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<title>English Gigaword Fifth Edition.</title>
<date>2011</date>
<contexts>
<context position="16395" citStr="Parker et al., 2011" startWordPosition="2754" endWordPosition="2757">2004, MSNBC and TAC 2011) and our training and development sets derived from Wikipedia (WP Training, WP Dev). For each data set we report the total number of annotated mentions, the number of mentions with a corresponding concept in Wikipedia (non-NILs) and the number of NILs (i.e. mentions that do not refer to a Wikipedia con494 Predicates Description Mention-based Features idfHead(m, q) The more frequent a mention is, the more likely it is to exert a local scope. This is inspired by work on indexing for IR. We use the idf score of the head of a mention according the English Gigaword Corpus (Parker et al., 2011). propernoun(m) Proper nouns are usually more prominent than common nouns and are more likely to have an intermediate or global scope than common nouns. singlewordNoun(m) Single word NPs are often less prominent than multi-word NPs and are more likely to be of local scope. abbrev(m) Abbreviations with a terminal dot such as Mr. or Ltd. tend to have a local scope as they are usually local modifiers or specifications. Features Based on Modification isPreModified(m) If a mention is pre-modified, it tends to be more prominent than unmodified mentions. If a mention headOfRelClause(m) is more promin</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edition. LDC2011T07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="30636" citStr="Petrov et al., 2006" startWordPosition="5070" endWordPosition="5073"> – both in the scope-ignorant and the scope-aware approach. achieves competitive performance without training on TAC data. On all data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, 17–21 July 2006, pages 433–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov Logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>650--659</pages>
<location>Waikiki, Honolulu, Hawaii,</location>
<contexts>
<context position="7434" citStr="Poon and Domingos, 2008" startWordPosition="1190" endWordPosition="1193">the output which is not relevant except for supporting the prediction of the target (Smith, 2011). In our approach, the different cohesive scopes are modeled by latent variables. Each mention to be disambiguated is assigned a scope s. All feature weights are parametrized by scope s. The parameters for the disambiguation and scope assignment tasks are learned jointly and are guided by the annotations available for the disambiguation task. Markov Logic Networks can be represented as log-linear models, when grounded, and are therefore straightforward to extend with latent variables (Smith, 2011; Poon and Domingos, 2008). In addition, global features can be conveniently integrated. 3.1 Markov Logic Networks Markov Logic (ML) incorporates first-order logic and probabilities (Domingos and Lowd, 2009). A Markov Logic Network (MLN) is a first-order knowledge base and consists of a set of pairs (Fi, wi), where Fi is a first-order formula and wi ∈ ][R is the weight of formula Fi. It is a template for constructing a Markov Network. This Markov Network has a binary node for each possible grounding for each predicate of the MLN. If the grounding of the predicate is true, the binary node’s value is set to 1, otherwise </context>
<context position="8912" citStr="Poon and Domingos (2008)" startWordPosition="1451" endWordPosition="1454">en by P(X = x) = Z exp (� wini(x) I i 2In this section feature is used differently than in the rest of the paper. 492 where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. To perform MAP inference we use thebeast3 which transforms the inference problem into an Integer Linear Program and solves it using cutting plane inference (Riedel, 2008). 3.1.1 Weight Learning with Latent Variables Since no annotations are available for the scope distinction, we face a latent variable learning problem. For learning weights in this situation we follow Poon and Domingos (2008). We split our hidden predicates into two parts: V are the ones for which the ground truth is known (concepts) and U are the ones for which there is no annotation (scopes). Let O be the observed predicates. Let o and v be the values of O and V in the training data. u denotes values assigned to U. Weight learning finds a w that maximizes the conditional log-likelihood L.(o, v) = log P.(V = vJO = o) �= log P.(V = v, U = uJO = o), u where the sum is over all possible values of U. Although Lw(o, v) is not convex, a local optimum can be found via gradient descent by iteratively solving wt+1 = wt + </context>
<context position="31327" citStr="Poon and Domingos (2008)" startWordPosition="5176" endWordPosition="5179">ent analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint </context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Waikiki, Honolulu, Hawaii, 25–27 October 2008, pages 650– 659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Simone Teufel</author>
<author>Horacio Saggion</author>
<author>Wai Lam</author>
<author>John Blitzer</author>
<author>Hong Qi</author>
<author>Arda Celebi</author>
<author>Danyu Liu</author>
<author>Elliott Drabek</author>
</authors>
<title>Evaluation challenges in large-scale document summarization.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>375--382</pages>
<location>Sapporo,</location>
<contexts>
<context position="18726" citStr="Radev et al., 2003" startWordPosition="3150" endWordPosition="3153">o be of local scope. Conjunctions are often used for exemplifications. Therefore mentions in conjunctions are often less prominent. In NPs with prepositional or genitive modifiers usually at most one part – either the modifying NP or the head – has intermediate or global scope. The more frequent the head of a mention appears in the text – also as a derivation, e.g. a verb, according to CatVar (Habash and Dorr, 2003) –, the more prominent it is. The earlier a mention appears in text, the more likely it is to exhibit global cohesive scope (cf. the hard-to-be-beat lead baseline in summarization (Radev et al., 2003)). inSubjPosition(m) posInSentence(m, q) focusingAdverb(m) modifiesArgument(m) passiveBy(m) inConjunction(m) inDepRelPP(m1, m2) inDepRelGen(m1, m2) morphoTiesHead(m, q) positionInText(m, q) Table 2: Features for cohesive scope distinction. m, m1, m2 denote mentions, q a score. The predicates are plugged in the template formula f8 in Table 1. Data set No. of Non- NILs Avg. Men- NILs Ambitions guity WP Training 56,372 53,097 3,275 2.31 WP Dev 9,992 9,375 617 2.28 ACE 2005 29,300 27,184 2,116 6.52 ACE 2004 306 257 49 5.04 TAC 2011 2,250 1,124 1,126 6.32 MSNBC 756 629 127 5.29 Table 3: Statistics </context>
</contexts>
<marker>Radev, Teufel, Saggion, Lam, Blitzer, Qi, Celebi, Liu, Drabek, 2003</marker>
<rawString>Dragomir R. Radev, Simone Teufel, Horacio Saggion, Wai Lam, John Blitzer, Hong Qi, Arda Celebi, Danyu Liu, and Elliott Drabek. 2003. Evaluation challenges in large-scale document summarization. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan, 7–12 July 2003, pages 375–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to Wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1375--1384</pages>
<location>Portland, Oreg.,</location>
<contexts>
<context position="2971" citStr="Ratinov et al., 2011" startWordPosition="458" endWordPosition="461">able for the target prediction task, i.e. the disambiguation. In this paper, we focus on concept and entity disambiguation1 with respect to an inventory derived from Wikipedia and compare (1) to a stateof-the-art approach that treats all mentions alike and uses the same features for disambiguation, (2) to a pipeline-based approach, and (3) to other state-of-the-art approaches (Section 4). While early work disambiguated concepts using the local context (Csomai and Mihalcea, 2008), current research focuses on exploiting the global document context (Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Fahrni and Strube, 2012; Cheng and Roth, 2013). Although such global approaches try to balance between local and global context, they treat all mentions alike, i.e., they apply the same model and the same weighting of local and global context features for disambiguating all mentions (Section 5). 2 Motivation Halliday and Hasan (1976) define cohesion as “relations of meaning that exist within the text, and that define it as a text” (p. 4). A tie is one instance of such a cohesive relation between two items. Cohesive ties occur on various linguistic levels, such as on the entity level (e.g. co</context>
<context position="20571" citStr="Ratinov et al., 2011" startWordPosition="3459" endWordPosition="3462">version of the ACE 2005 corpus which contains Wikipedia link annotations (Bentivogli et al., 2010). All ACE mentions, both common and proper nouns, are annotated with one or more links to the English Wikipedia or as NILs. If a mention is annotated with more than one link, we consider it as correctly disambiguated if one of the annotated concepts has been chosen by our system. ACE 2005 consists of 597 texts from newswire reports, broadcast news, internet sources and transcribed audio data and contains more annotations than the other data sets we use for comparison. While ACE 2005 and ACE 2004 (Ratinov et al., 2011) fit our target scenario most (both common and proper nouns are annotated), MSNBC (Cucerzan, 2007) and TAC 2011 (Ji et al., 2011) are only annotated for proper nouns. 495 4.2 Preprocessing The training, development and testing data are all preprocessed in the same way. We perform POS tagging, syntactic parsing and named entity recognition using the Stanford CoreNLP pipeline5. For identifying mentions we extract all noun phrases (excluding discontinuous phrases and determiners) and look them up in our lexicon. Our lexicon and also all other information we obtained from Wikipedia are extracted f</context>
<context position="28621" citStr="Ratinov et al., 2011" startWordPosition="4732" endWordPosition="4735">TE) in the scope-ignorant approach (misled by CNN), while it has been correctly recognized as NIL by the scope-aware approach in which it is considered as being of intermediate scope. The remaining disambiguation errors can be traced back to (1) scope assignment errors and (2) disambiguation errors (e.g. Palmisano (global scope) is disambiguated as SAMUEL J. PALMISANO, but the text refers to a different unknown Palmisano). 4.5 Comparison to State-of-the-art Approaches Compared to the state-of-the-art for concept and entity disambiguation our approach performs favorably (Table 6). On ACE 2004 (Ratinov et al., 2011) – which contains annotations for common and proper nouns and fits our target scenario most – our scope-aware approach outperforms recent state-of-the-art approaches for concept and entity disambiguation, i.e. Ratinov et al. (2011) and Cheng and Roth (2013). We also ran Ratinov et al.’s (2011) sytem on ACE 2005, but it seems that its mention recognition is not designed for ACE 2005. We also evaluate our system on the task of entity linking, i.e. the disambiguation of (selected) proper nouns (MSNBC and TAC 2011). Our system fails to beat the best systems, but still 497 System ACE 2004 MSNBC TAC</context>
<context position="31837" citStr="Ratinov et al., 2011" startWordPosition="5261" endWordPosition="5264">al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a specific model for ea</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to Wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, Oreg., 19–24 June 2011, pages 1375–1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
</authors>
<title>Improving the accuracy and efficiency of MAP inference for Markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>468--475</pages>
<location>Helsinki,</location>
<contexts>
<context position="8687" citStr="Riedel, 2008" startWordPosition="1417" endWordPosition="1418">re2 for each ground formula Fi. If a ground formula is true, its feature’s value is set to 1, otherwise to 0. The feature’s weight is provided by wi. The probability distribution in the ground Markov Network is given by P(X = x) = Z exp (� wini(x) I i 2In this section feature is used differently than in the rest of the paper. 492 where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. To perform MAP inference we use thebeast3 which transforms the inference problem into an Integer Linear Program and solves it using cutting plane inference (Riedel, 2008). 3.1.1 Weight Learning with Latent Variables Since no annotations are available for the scope distinction, we face a latent variable learning problem. For learning weights in this situation we follow Poon and Domingos (2008). We split our hidden predicates into two parts: V are the ones for which the ground truth is known (concepts) and U are the ones for which there is no annotation (scopes). Let O be the observed predicates. Let o and v be the values of O and V in the training data. u denotes values assigned to U. Weight learning finds a w that maximizes the conditional log-likelihood L.(o,</context>
</contexts>
<marker>Riedel, 2008</marker>
<rawString>Sebastian Riedel. 2008. Improving the accuracy and efficiency of MAP inference for Markov logic. In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, Helsinki, Finland, 9–12 July 2008, pages 468–475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
</authors>
<title>Linguistic Structure Prediction.</title>
<date>2011</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="6907" citStr="Smith, 2011" startWordPosition="1110" endWordPosition="1111">d approach using Markov Logic Networks that allows us to learn the parameters for the scope assignment and the disambiguation tasks jointly and enables us to perform joint inference. Our approach is joint as we assign the scope s and predict the concept c for a mention m simultaneously. As during learning training data is available for the disambiguation task but not for the scope assignment task, we face a problem with latent variables. Latent variables represent missing information in the input or a part of the output which is not relevant except for supporting the prediction of the target (Smith, 2011). In our approach, the different cohesive scopes are modeled by latent variables. Each mention to be disambiguated is assigned a scope s. All feature weights are parametrized by scope s. The parameters for the disambiguation and scope assignment tasks are learned jointly and are guided by the annotations available for the disambiguation task. Markov Logic Networks can be represented as log-linear models, when grounded, and are therefore straightforward to extend with latent variables (Smith, 2011; Poon and Domingos, 2008). In addition, global features can be conveniently integrated. 3.1 Markov</context>
<context position="30521" citStr="Smith, 2011" startWordPosition="5054" endWordPosition="5055">e three additional disambiguation features – they measure the similarity of the article name to the context – both in the scope-ignorant and the scope-aware approach. achieves competitive performance without training on TAC data. On all data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the contex</context>
</contexts>
<marker>Smith, 2011</marker>
<rawString>Noah A. Smith. 2011. Linguistic Structure Prediction. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rakshit Trivedi</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Discourse connectors for latent subjectivity in sentiment analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>808--813</pages>
<location>Atlanta, Georgia, 9–14</location>
<contexts>
<context position="30772" citStr="Trivedi and Eisenstein, 2013" startWordPosition="5090" endWordPosition="5093">ll data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic,</context>
</contexts>
<marker>Trivedi, Eisenstein, 2013</marker>
<rawString>Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse connectors for latent subjectivity in sentiment analysis. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Atlanta, Georgia, 9–14 June 2013, pages 808–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Automatically generating annotator rationales to improve sentiment classification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>11</volume>
<pages>336--341</pages>
<location>Uppsala,</location>
<contexts>
<context position="30741" citStr="Yessenalina et al., 2010" startWordPosition="5085" endWordPosition="5089">training on TAC data. On all data sets, the joint scope-aware approach consistently outperforms the scope-ignorant approach ceteris paribus. 5 Related Work Joint approaches have been successful in the past in NLP (e.g. Meza-Ruiz and Riedel (2009)). The idea of augmenting a model with additional latent variables to increase its expressiveness is known as hidden or latent variable learning (Smith, 2011) and is a promising research direction with successful applications in e.g. syntactic parsing (Petrov et al., 2006), statistical machine translation (Blunsom et al., 2008) and sentiment analysis (Yessenalina et al., 2010; Trivedi and Eisenstein, 2013). For latent variable learning generative approaches (Petrov et al., 2006), large margin methods (Smith, 2011) and conditional log-linear models have been proposed. We focus here on conditional log-linear models due to their flexibility and their previous success for many tasks. Blunsom et al. (2008) for instance use latent variables in the context of discriminative machine translation and model the derivation as a latent variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use late</context>
</contexts>
<marker>Yessenalina, Choi, Cardie, 2010</marker>
<rawString>Ainur Yessenalina, Yejin Choi, and Claire Cardie. 2010. Automatically generating annotator rationales to improve sentiment classification. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 11– 16 July 2010, pages 336–341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiping Zhou</author>
<author>Lan Nie</author>
<author>Omid Rouhani-Kalleh</author>
<author>Flavian Vasile</author>
<author>Scott Gaffney</author>
</authors>
<title>Resolving surface forms to Wikipedia topics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>1335--1343</pages>
<location>Beijing, China, 23–27</location>
<contexts>
<context position="31815" citStr="Zhou et al., 2010" startWordPosition="5257" endWordPosition="5260">variable. Chang et al. (2010) is close to our approach, as their latent variable approach also uses ILP. Poon and Domingos (2008) also use latent variables with Markov Logic, although with a completely different aim, i.e. for unsupervised coreference resolution. Most approaches that use Wikipedia as a resource for disambiguation focus on named entities (Bunescu and Pas¸ca, 2006; Cucerzan, 2007; Dredze et al., 2010; Ji and Grishman, 2011; Hachey et al., 2013; Hoffart et al., 2011), while only a few disambiguate common and proper nouns like us (Csomai and Mihalcea, 2008; Milne and Witten, 2008; Zhou et al., 2010; Ratinov et al., 2011; Cheng and Roth, 2013). We build upon our previous Markov Logic based approach for joint concept disambiguation and clustering (Fahrni and Strube, 2012). In contrast to us, most approaches for lexical disambiguation use either one model for all mentions (Milne and Witten, 2008; Ratinov et al., 2011) or a separate model for each mention or concept which requires a lot of training data (e.g. Bryl et al. (2010)). Only a few approaches try to learn specific models for groups of mentions, although none of them is discourse-motivated as ours: Mihalcea and Csomai (2005) learn a</context>
</contexts>
<marker>Zhou, Nie, Rouhani-Kalleh, Vasile, Gaffney, 2010</marker>
<rawString>Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Flavian Vasile, and Scott Gaffney. 2010. Resolving surface forms to Wikipedia topics. In Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, 23–27 August 2010, pages 1335–1343.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>