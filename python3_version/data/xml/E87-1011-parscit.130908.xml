<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013910">
<title confidence="0.98447">
A Multi-Purpose Interface to an On-line Dictionary
</title>
<author confidence="0.918581">
Branimir Boguraev and David Carter
</author>
<affiliation confidence="0.9699445">
University of Cambridge, Computer Laboratory
Corn Exchange Street, Cambridge CB2 3QG, England
Ted Briscoe
Department of Linguistics, University of Lancaster
</affiliation>
<address confidence="0.479284">
Bailrigg, Lancaster LA1 4YT, England
</address>
<sectionHeader confidence="0.965822" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999881764705882">
We argue that there are two qualitatively different
modes of using a machine-readable dictionary in the
context of research in computational linguistics: batch
processing of the source with the purpose of collating
information for subsequent use by a natural language
application, and placing the dictionary on-line in an
environment which supports fast interactive access to
data selected on the basis of a number of linguistic
constraints. While it is the former mode of dictionary
use which is characteristic of most computational lin-
guistics work to date, it is the latter which has the
potential of making maximal use of the information
typically found in a machine-readable dictionary. We
describe the mounting of the machine-readable source
of the Longman Dictionary of Contemporary English
on a single user workstation to make it available as a
development tool for a number of research projects.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935636363637">
A growing mass of work at present, both within the
narrower field of computational linguistics and in the
wider context of building knowledge-based systems,
is focussed on making use of the lexical resources to
be found in a number of (monolingual) dictionaries of
the style exemplified by e.g. The Longman Dictionary
of Contemporary English, The Collins English Dictio-
nary, or Webster&apos;s Seventh New Collegiate Dictionary.
These contain a wealth of information relevant to a
wide range of natural language processing functions
— a fact which is hardly surprising, given that such
sources typically (and almost by definition) contain
the results of substantial efforts to collate and analyse
data about real language, to elicit collocational and
distributional properties of words and to apply com-
mon principles of defining their meaning.
The availability of dictionary sources on-line, in
the form of machine-readable dictionaries (henceforth
MRDs) and encyclopaedias, makes it possible to view
these as repositories of large amounts of information,
linguistic and extra-linguistic, which can be brought to
bear at various points of the natural language under-
standing process. Developments in hardware, as well
as research in computational linguistics, offer the tech-
nology both to process lexical resources and to extract
from them what is relevant to computer programs con-
cerned with various natural language processing ac-
tivities. A number of recent projects have extracted
data from publishers&apos; tapes and subsequently used it
to support activities such as syntactic parsing, speech
synthesis, lexical disambiguation, semantic interpreta-
tion in context, spelling correction and machine trans-
lation. The common denominator in these projects is
that the end product incorporates in some form appro-
priate fragments derived from the machine-readable
source.
There are essentially two different modes in which
MRDs can be used (see Boguraev, 1987, for more de-
tails). The predominant technique to date involves an
arbitrary amount of pre-processing, typically in batch,
of the on-line source. Those parts of the dictionary
entries which contain useful data for the task at hand
are extracted and suitably represented in a form di-
rectly usable by a client program. Such a model of
dictionary use does not in any way rely on the original
source being available at the time the language pro-
cessing application is active, and thus a batch deriva-
tion of the appropriate information is a suitable way
of transforming the raw data into a usable repository
of lexical knowledge.
But the reality of trying to adapt information,
originally packaged according to lexicographic and ty-
pographic conventions for visual presentation and not
at all intended for automated natural language pro-
cessing, suggests a different model of dictionary use.
The non-trivial task of developing suitable procedures
for pre-processing of the machine-readable source typ-
ically requires careful analysis of the properties of the
particular MRD, and is best aided by having fast in-
teractive access to appropriate fragments of it.
In addition, many research projects of a more ex-
perimental nature focus on investigating the ways in
which the availability of an MRD can aid the devel-
opment of particular natural language processing sys-
tems. The assumption is that an analysis of the accu-
mulated data in the dictionary will reveal regularities
which can then be exploited for the task at hand. Just
one example, from a number of projects currently un-
der way in Cambridge, illustrating this point is the
work of Alshawi (1987), who has analysed definition
texts across an entire dictionary to produce a &amp;quot;defini-
tion grammar&amp;quot; together with an associated technique
for parsing the natural language descriptions of words
into semantic structures.
Such projects depend critically not only on the
availability of a machine-readable equivalent of a pub-
lished dictionary, but also on a software system ca-
pable of providing fast interactive access into the on-
line source through various access routes. Operational
natural language processing systems clearly will have
well-defined requirements as far as their lexicons are
concerned, and once the format of lexical resources has
been settled, retrieval of individual entries can be im-
plemented fairly efficiently using standard computa-
tional and linguistic techniques (see e.g. Russell et al.,
1986). The placing of a dictionary on-line, however,
with the intention of making it available to a number
of different research projects which need to locate and
</bodyText>
<page confidence="0.999016">
63
</page>
<bodyText confidence="0.995540567307693">
collate dictionary samples satisfying a wide range of
constraints, requires an efficient and flexible system
for management and retrieval of linguistic data.
This is not the computationally straightforward is-
sue it appears to be, as conventional database man-
agement systems (DBMS) are not well suited for on-
line dictionary support, particularly when the entire
dictionary is viewed as a lexical knowledge base, more
complex in structure and facing more taxing demands
in a natural language research environment. This pa-
per addresses the problem in greater detail, by placing
it into the wider context of research into computa-
tional linguistics and highlighting those issues which
pose a challenge for the current DBMS wisdom. We
propose a solution adequate to handle most of the lex-
ical requirements of current systems, which is general-
isable to a range of MRDs, and describe a particular
implementation for single user workstations used in a
number of on-going research projects at the universi-
ties of Cambridge and Lancaster.
2 The nature of the problem
Several factors put the task of mounting a machine-
readable dictionary as a proper development tool be-
yond the scope of current DBMS practice and make
its conversion into a database of e.g. a standard rela-
tional kind quite difficult.
Firstly, there is the nature of the data in a dictio-
nary: typically, it contains far too much free text (def-
initions, examples, cross-reference pointers, glosses on
usage and so forth) to fit easily into the concept of
structured data. On the other hand, the highly struc-
tured and formalised encoding of other types of in-
formation (found in e.g. the part of speech, syllab-
ification or pronunciation fields) makes a dictionary
equally unsuitable for on-line access by information
retrieval methods.
The second factor is due to the nature of the only
source of machine-readable dictionaries so fax available
— namely the publishers&apos; typesetting tapes, originally
constructed for the production of a printed version.
The organisation of data there, aimed at visual pre-
sentation, carries virtually no explicit structure; a tape
is simply a character stream containing an arbitrary
mixture of typesetting commands and real data. This
not only introduces the difficult problem of &amp;quot;parsing&amp;quot;
a dictionary entry (addressed in detail by e.g. Kaz-
man, 1986), but also raises the issue of devising a suit-
able representation for the potentially huge amount of
linguistic data; one which does not limit in any way
the language processing functions that could be sup-
ported or constrain the complexity of the computa-
tional counterpart of a dictionary entry.
Finally, there is the nature of the data structures
themselves. A text processing application, typically
written in Lisp or Prolog, requires that its lexical data
is represented in a compatible form, say Lisp s-expres-
sions of arbitrary complexity. Therefore, even if we
choose to remain neutral with respect to representa-
tion details, we still face the problem of interfacing
to a vast number of symbolic s-expressions, held in
secondary storage. This problem arises from the un-
suitability of conventional data models for handling
the complex data structures underlying any sophisti-
cated symbolic processing. Partly, this is due to the
inherent restrictions such models impose on the class
of data structure they can represent easily — namely
records of fixed format. But more importantly, con-
ventional database systems make strong assumptions
about the status and use of data they have to hold:
databases are taken to consist of a large number of
data records taken from a small number of rigidly-
defined classes. It is not clear that a lexical &amp;quot;knowl-
edge base&amp;quot;, derived from a dictionary and intended to
support a wide range of language processing applica-
tions, fits this model well.
Some solutions to these problems will no doubt
be offered by dedicated efforts to develop special pur-
pose data models, capable of computationally repre-
senting a dictionary and amenable to flexible and effi-
cient DBMS support. The work, at the University of
Waterloo, on computerising the Oxford English Dictio-
nary (Tompa, 1986) is a good example here; similarly,
the desire to be able to mount computerised dictio-
naries on-line for in-house research motivates Byrd&apos;s
work on a general purpose dictionary access method
(Byrd et al., 1986). In the short run, alternative
approaches reduce the complexity of the problem by
limiting themselves to applying the machine readable
source of a dictionary to a small class of similar tasks,
and building customised interfaces offering relatively
narrow access channels into the on-line data. Thus
IBM&apos;s WordSmith system (Byrd and Chodorow, 1985)
is concerned primarily with providing a browsing func-
tionality which supports retrieval of words &amp;quot;close&amp;quot; to
a given word along the dimensions of spelling, mean-
ing and sound, while a group at Bell Labs has sev-
eral large dictionaries on-line used only for research
on stress assignment (Church, 1985). Alshawi et al.
(1985) have used a machine-readable source directly
for syntactic analysis of texts; however, the approach
taken there — namely that of simple pre-indexing by
orthography — does not generalise easily for applica-
tions which require the rapid locating and retrieval of
entries satisfying more than one selection criterion.
</bodyText>
<sectionHeader confidence="0.974665" genericHeader="method">
3 System functionality
</sectionHeader>
<bodyText confidence="0.99971372">
The motivation for the design described here is di-
vided equally between the diverse nature of MRD-
based projects in Cambridge and Lancaster and the
unique properties of the particular dictionary that they
use. The suitability of the Longman Dictionary of Con-
temporary English (LDOCE) for research into compu-
tational linguistics has been discussed at length else-
where (see, in particular, Michiels, 1982); below we
will outline several projects undertaken in Cambridge
as a context for highlighting its particularly useful
characteristics insofar as they are relevant to this pa-
per.
LDOCE carries special lexical and linguistic infor-
mation which is useful for a number of natural lan-
guage processing tasks.
1. The dictionary is unique in tagging word senses
with grammar codes which provide very elabo-
rate syntactic subcategorisation information; a
procedure has been developed for mapping the
grammar codes into feature clusters (in the style
of e.g. Generalised Phrase Structure Grammar),
subsequently to be used by a syntactic parser
(Boguraev and Briscoe, 1987, describe this in
detail). The transformation program is about
to be integrated in a software system for gram-
</bodyText>
<page confidence="0.996608">
64
</page>
<bodyText confidence="0.987985875">
mar support and development, both as a lexicon
generator and as a tool for grammar debugging
(Boguraev and Ritchie, 1987).
2. The pronunciation information in LDOCE has
provided the basis for a study, in the larger con-
text of speech recognition, of the implications
of the phonetic structure of the English lexicon
for different methods for lexical access (Carter,
1986). Again in the context of speech recog-
nition, we intend to tackle the problem of word
identification from a lattice of phonemes by con-
structing a parser that uses information about
both phoneme collocations and syntactic pre-
dictions derived from independent analyses of
the phonetic and grammar coding fields in the
dictionary.
</bodyText>
<listItem confidence="0.80995475">
3. Furthermore, LDOCE carries special tags, known
as subject and box codes, which encode semantic
notions like the overall context in which a word
sense is likely to appear (e.g. politics, religion,
language) and selectional restrictions on verbs,
nouns and compound phrases; we intend to use
this information for further guidance during the
word recognition process. Independently, an al-
gorithm has been developed for analysing the se-
mantic content proper of the dictionary entries
by converting the definition texts in LDOCE
into fragments of semantic networks (Alshawi,
1987); this opens opportunities for building a
comprehensive and robust semantic component
which could then be incorporated into any of
the projects mentioned above.
</listItem>
<bodyText confidence="0.99995675">
It is clear that in order to make full use of the com-
puterised LDOCE, we need a dictionary access system
with proper DBMS functionality, capable of efficient
retrieval of entries satisfying selection criteria applying
at various levels of linguistic description. The design
of the system described here allows precisely such het-
erogeneous requests. What we offer is a software envi-
ronment buffering the user from the typically baroque
and idiosyncratic format of the raw dictionary source
and allowing, via a carefully crafted interface, multi-
ple entry points and arbitrarily complex access paths
into the on-line lexical knowledge base.
</bodyText>
<sectionHeader confidence="0.8309755" genericHeader="method">
4 Requirements for the dictionary
database
</sectionHeader>
<bodyText confidence="0.999993324675325">
Three main requirements can be identified if the data-
base is to perform the functions intended for it.
Firstly, the source tape of the dictionary must be
converted into a format to which fast access can be
coupled. This involves, at the very least, overall seg-
mentation of the original character stream into records
corresponding to gross lexical categories such as head
word, pronunciation and part of speech. This may be a
highly complex task, as in Kazman&apos;s (1986) project to
restructure the text of the OED, or it may be concep-
tually fairly straightforward, as in the case of LDOCE
where considerable segmentation is already present.
But in either case, given that the on-line dictionary is
intended to support more than one application, a more
elaborate structuring of the entries&apos; individual records
might turn out to be unsuitable for further unforeseen
use. Fortunately, it is clear from work with comput-
erised dictionaries in general that once an application
has located the relevant fragment of a dictionary en-
try, local &amp;quot;parsing&amp;quot; into whatever format is needed
can be fast and reliable, and can therefore be done
&amp;quot;on the fly&amp;quot; by functions which manipulate individual
entries on demand and have no permanent effect on
the underlying source. Thus we should aim at incorpo-
rating the segmented version of the source intact into
the database, to serve directly as its &amp;quot;bottom layer&amp;quot;
in the sense that all access paths ultimately point to
complete dictionary entries, which are then returned
as the results of queries.
Secondly, it should be possible to execute queries
involving information of as many different types as
possible. Even if the machine-readable source used
is a comparatively structured one such as LDOCE,
the creation of access paths will involve, for at least
some types of information, the non-trivial (but fast)
construction of an intermediate and temporary repre-
sentation by means of the local parsing already men-
tioned. For example, subcategorisation information is
often specified in a rather elliptical form in LDOCE,
for the sake of human readability; this must be made
explicit by a parsing process, as described in Boguraev
and Briscoe (1987). Also, it is desirable to impose a
phonologically motivated structure on pronunciations,
which are typically given as a string of phonemes and
stress markers. This will allow the user to specify a
constraint on, say, &amp;quot;the onset of the second syllable of
the word&apos;, whose position in the phoneme string will
not be the same for all words. The straight indexing
approach used by e.g. Boguraev and Briscoe (1987)
for headword-based access cannot in general provide
sufficiently flexible access routes.
Thirdly, the user or client program should be free
to specify different types of constraint in any combina-
tion. We cannot assume in advance that information
of a given type will always be present in great enough
quantities to allow efficient retrieval. For example,
if the system is being used by an automatic speech
recogniser, then at one point in the signal significant
information on pronunciation may be available, but
few syntactic or semantic constraints may be present;
at another point, the situation may be reversed, with
the speech signal itself yielding little phonological in-
formation but with an expectation-driven parser pro-
viding quite specific higher-level constraints. In each
case, the stronger, more specific constraints must be
used for access, and the weaker ones only for check-
ing the entries retrieved. To achieve this, the sys-
tem must clearly be able to estimate in advance what
the most efficient search strategy will be. This abil-
ity to perform maximally efficient searches given many
different kinds of constraint will also be important if
the database is being used interactively to investigate
properties of the language. If the system&apos;s claim to be
interactive is to be justified, it must be able to tell the
user in advance roughly how long a prospective query
would take to evaluate, and roughly how many entries
would be returned as a result.
</bodyText>
<sectionHeader confidence="0.991976" genericHeader="method">
5 Design and implementation
</sectionHeader>
<bodyText confidence="0.9994398">
The design and implementation of the database sys-
tem described here reflects the three requirements just
identified.
The machine-readable source of LDOCE serves as
the bottom layer of the database after undergoing a
</bodyText>
<page confidence="0.998229">
65
</page>
<bodyText confidence="0.9999097">
&amp;quot;lispification&amp;quot; process described in detail in Boguraev
and Briscoe (1987). This process preserves all the in-
formation, lexical and typographic, on the tape, and
involves little restructuring, serving primarily to re-
format the source in a bracketed form in which it can
be much more easily read by Lisp programs. The link
between the user or client program and the lispified
dictionary is provided by a pointer file and a constraint
file whose nature and motivation will be described be-
low.
</bodyText>
<subsectionHeader confidence="0.999801">
5.1 Analysing dictionary entries
</subsectionHeader>
<bodyText confidence="0.997034013157895">
Information of six different types is analysed for the
construction of access paths: semantic features clas-
sifying the meanings of words and their dependents;
semantic subject area; grammatical part of speech;
grammatical subcategorisation; British English pro-
nunciations; and definition texts. All these types can
be mixed together in constructing search queries. En-
tries can also be accessed by spelling patterns.
The codes used for the first three of these types
of information have a fairly simple structure, and are
hence trivial to extract. The fourth, subcategorisa-
tion, is indicated by a complex and highly discrimina-
tory set of codes; the extraction of these codes from
the elliptical form in which they occur in LDOCE is
described in Boguraev and Briscoe (1987). We will
therefore discuss here only the structuring of pronun-
ciations and the treatment of definition texts.
Pronunciations are represented in the dictionary
as strings of phonemes and primary and secondary
stress markers. Syllable boundaries are not reliably
indicated. Therefore, in order to allow the syllable-
based access that a speech recogniser would probably
require, pronunciation fields are parsed into syllables
and, within a syllable, into onset, peak and coda, using
the phonotactic constraints given in Gimson (1980)
and employing a maximal onset principle (Selkirk, 1978)
where these yield ambiguous syllable boundaries. Thus
for example the internal syllable boundary in the pro-
nunciation of &amp;quot;constraint&amp;quot; is placed before the &amp;quot;s&amp;quot;.
The parser used for analysing pronunciations is
a special-purpose one whose (very simple) grammar
is incorporated into its code. This allows pronun-
ciations to be parsed many times faster than by a
general-purpose parser with a declarative grammar.
It also allows constraints on relationships between syl-
lable constituents to be relaxed when necessary. For
example, the LDOCE pronunciation of &amp;quot;bedouin&amp;quot; is
&apos;beduin, which violates the constraint that a syllable
whose peak is u (as in &amp;quot;put&amp;quot;) cannot have a null coda;
this constraint is therefore relaxed to obtain a parse.
The strategy used for indexing entries according to
the words their definition texts was designed to reflect
the fact that it is the semantic content of these words
that is likely to be of interest to the user. This has
two main consequences:
(1) It is more appropriate to take root forms of
words as keys than to treat inflectional variants dif-
ferently, because it is the root that holds most of the
semantic content. Indeed, the inflection used with a
particular word often depends on the largely arbitrary
choice of syntactic constructions used in the definition.
Thus for example, entries whose definitions contain
any of the words &amp;quot;film&amp;quot;, &amp;quot;films&amp;quot; and &amp;quot;filmed&amp;quot; should
all be indexed under &amp;quot;film&amp;quot;.
(2) Closed class words are unlikely to be useful
as keys because their semantic content is limited and
often highly context-dependent. In addition, many of
them occur too often to be sufficiently discriminating
for efficient lookup. Therefore only open class words
are made available as keys.
The task of deriving root forms of words is made
much easier by the fact that LDOCE&apos;s definition texts
are constructed largely from a set of two thousand
basic words. When other words are used, they (or, in
the case of inflectional variants, their root forms) are
shown in a special font. Accurate root extraction for
words not so marked can therefore be accomplished
simply by stripping off affixes (which are themselves
in the basic word list) and applying a few simple rules
for spelling changes until a basic word is found. All
irregular forms of basic words are stored explicitly.
Distinguishing open and closed class words is also
straightforward; a list of closed class words was de-
rived by performing a database lookup using those
grammar codes and categories that represent closed
classes.
</bodyText>
<subsectionHeader confidence="0.999671">
5.2 Constructing access paths
</subsectionHeader>
<bodyText confidence="0.999995954545455">
Once the relevant information has been extracted from
an entry, constructing acess paths is straightforward
in the grammatical, semantic and definition text cases:
a list of entry pointers is constructed for every code
and every suitable definition word found in the dictio-
nary. Pronunciations, however, are treated differently.
To achieve flexibility and efficiency, a pointer list is
formed for every distinct syllable in every position in
which it occurs (e.g. second syllable in a three-syllable
word).
When the whole dictionary has been analysed, a
pointer file is created containing all the entry pointer
lists and, just before each list, its length. As described
below, this allows the system to estimate the work
involved in evaluating a query without actually having
to read the (sometimes very long) list itself.
The next stage is to construct the constraint file.
This file takes the form of a discrimination net which
links every possible constraint on an entry (e.g. a sub-
ject area, a grammar code or a constituent of a sylla-
ble) to one or, in the pronunciation case, several lists
in the pointer file.
</bodyText>
<subsectionHeader confidence="0.9997">
5.3 Constructing search queries
</subsectionHeader>
<bodyText confidence="0.999771444444444">
A menu-driven graphical interface is provided by means
of which the user can construct a search query in the
form of a tree whose terminal nodes are constraint val-
ues, disjunctions of them, or wild cards. The menus
are derived automatically from the constraint file, so
that only queries with some chance of being satisfied
can be constructed. For example, if the user is con-
structing a specification of a syllable, the tree at one
point may be as in Figure 1.
</bodyText>
<page confidence="0.954876">
66
</page>
<figureCaption confidence="0.985191">
Figure 1
</figureCaption>
<bodyText confidence="0.9952225">
If the user selects the CODA node, the resulting
menu, shown in Figure 2, allows him to specify the
coda &amp;quot;pst&amp;quot;, but not, for example &amp;quot;psm&amp;quot;. (In this
menu, and in terminal nodes of the PRONUNCIA-
TION subtree of Figure 1, &amp;quot;*&amp;quot; matches any sequence
of symbols; &amp;quot;7 matches any single symbol; and all
other symbols have the phonetic values defined for
them in LDOCE).
</bodyText>
<figureCaption confidence="0.653201">
Figure 2
</figureCaption>
<bodyText confidence="0.999965688888889">
A tree can be constructed either from a WORD
node alone, or by instructing the system to build a tree
from the entry for a specified word, and then editing
it. Once the tree is built, either a partial search (to
gather statistics) or a full search (to retrieve entries)
can be requested.
In a partial search, the system follows each con-
straint to the pointer list(s) it leads to, and sums
the lengths of these lists (as recorded explicitly in
the pointer file) to display the approximate number
of dictionary entries that satisfy it. It also indicates
which constraints it would use to look up candidate
entries in a full search, which ones it would merely
apply as tests to those candidates, and, to allow the
user to decide whether or not to order a full search,
about how long the process would take. It makes the
lookup/test choice using figures for the expected time
taken to read (a) a pointer from the constraint file
and (b) a complete entry from the dictionary. The
most efficient search strategy involves using the most
specific few constraints as lookup keys (more specific
keys ultimately yielding fewer entries). The optimal
number of constraints to use is found by balancing the
number of pointers that will have to be read, which
increases with the number of lookup keys, against the
expected number of entries that will have to be read,
which decreases. ( kn entry will only be read if there
is a pointer to it in every pointer list. Therefore if n
lookup keys are used, returning pointer lists of lengths
Li, L2, ... L., then the expected number of entries
to be read, assuming statistical independence between
lists, is Li L2...L.1 , where D is the number of en-
tries in the dictionary. This decreases with n because
Li cannot exceed D, and is in fact normally very much
smaller).
In a full search, these statistics and choices are not
only displayed but are also acted on. The pointer lists
for the lookup constraints are intersected, the number
of pointers resulting is displayed and, at the user&apos;s
option, the corresponding entries are read from the
dictionary, the test constraints are applied to them,
and the surviving entries are displayed. Applying tests
to a dictionary entry involves reanalysing the relevant
parts of it in the same way as when the database is
constructed.
</bodyText>
<sectionHeader confidence="0.912805" genericHeader="method">
6 An example
</sectionHeader>
<bodyText confidence="0.999950857142857">
As an example, suppose the user wishes to see all
entries for three-syllable nouns which describe mov-
able solid objects, whose second syllable has a schwa
as peak, and whose third syllable has a coda that is a
voiced stop. He constructs the tree in Figure 3 over-
leaf, and selects the &amp;quot;partial search&amp;quot; option. This re-
turns the information shown in Figure 4.
</bodyText>
<table confidence="0.973194">
Would look up on these constraints:
(*CODA* (OR b d g) / 3 3)
.-). 502 items
Would test on these ones:
(*PEAK&amp;quot; E / 2 3) (-&gt; 3629 items)
(a5 5 J) (-&gt; 5179 items)
(*NSYLLS* 3) (-&gt; 10468 items)
(faC n) (-) 23835 items)
Estimated pointer+entry reading time:
12.5+85.3=97.8 seconds (502 entrie)
</table>
<figureCaption confidence="0.97215">
Figure 4
</figureCaption>
<figure confidence="0.979798478260869">
WORD
PRONUNCIATION
SYLLABLE
rt•--
ONCET PEAK CODA
AND
.lo w -round
STRESS
67
WORD
SEMANTICS GRAMMAR, PRONUNCIATION
SYLLABLE SYLLABLE
/
STRESS ONSET PEAK CODA
SYLLABLE
\
STRESS ONSET PEAK CODA
BOX CATEGORY
5 .3
OR
/
01\
b d g
</figure>
<figureCaption confidence="0.973463">
Figure 3
</figureCaption>
<bodyText confidence="0.986594428571429">
Because of the expected large number of entries
in the result and the time that would be taken to
read them, the user decides to look only at the en-
tries for such words whose definitions contain the word
&amp;quot;camera&amp;quot;. He adds the relevant constraint to the
tree (the system checking, as he does so, that &amp;quot;cam-
era&amp;quot; is a valid key) and orders another partial search.
This time, the statistics are more manageable. A full
search is therefore ordered, in which the definition
word &amp;quot;camera&amp;quot; is used as the only lookup key, and
the other constraints are this time all used as tests.
This returns the entries for the words &amp;quot;clapperboard&amp;quot;
and &amp;quot;Polaroid&amp;quot;, shown in Figure 5.
Figure 5
</bodyText>
<sectionHeader confidence="0.99803" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99616758490566">
We have sketched the requirements for, and the design
of, a flexible interface to an on-line dictionary, capable
of supporting the lexical requirements of a number of
active research projects and adaptable to a range of
applications. The programs have been developed in
Lisp, and make heavy use of the interactive graphic ca-
pabilities of Xerox&apos;s Lisp workstations. Nothing, how-
ever, depends critically on this; the Interlisp-D inter-
active graphics simply make the task of constructing
search specifications very easy for the end user. The
design is sufficiently modular to allow easy modifica-
tion, and the system would be capable of functioning
on a conventional minicomputer or mainframe (as long
as it supported random access to files) just as well as
it does on a single user workstation.
In order to make the lexical knowledge base avail-
able to all the projects requiring access to it, the sys-
tem had to be adapted to fit into the local environ-
ment of networked workstations. The database man-
ager was easily repackaged to reflect the model of one
server catering for several clients over a network; the
Remote Procedure Call Protocol (XSIS, 1981) pro-
vided the necessary functionality to incorporate the
manager into a dictionary server node (of the kind
discussed by Kay, 1984) — this bypassed the need for
costly fileservers and proved the integrity of the de-
sign. We also plan to develop a version of the system
running in Franz Lisp under UNIX and accessing the
MRC dictionary database (Coltheart, 1981).
While the system implements in effect a linguisti-
cally motivated DBMS constructed round a suitable
machine-readable source, it stops short of full brows-
ing capability (even though such a capability could
easily be added by fully integrating Alshawi&apos;s defini-
tions analysis program into the overall design). In this
sense the lexical knowledge base discussed here differs
Entry window
clap.per.hoard Pkleepabo:d I -arbord/
(subj MP--, box (when starting to
film a scene for the cinema) a board on
which the details of the scene to be
filmed are written, held up in front of
the camera
Po.lar.oid tdtnk 1(U)
subj st--, box ---- a material with
which glass is treated in order to make
light shine less brightly through it, used
in making ZUNGLAZZes,car windows,
etc, 2 IC] subj box also (
mi) Polaroid cam.e.ra / ,••• &apos;••• —
a type of camera that produces a
finished photograph only seconds after
the picture has been taken
</bodyText>
<page confidence="0.997924">
68
</page>
<bodyText confidence="0.999951857142857">
from the concept of a lexical database as described in
Calzolari (1986), or underlying Miller&apos;s WORDNET
(1985). Nonetheless, the methodology described here
is sufficiently flexible and powerful to satisfy a sub-
stantial proportion of the needs of the computational
linguistics community till a proper mix of database
and browsing capabilities becomes available.
</bodyText>
<sectionHeader confidence="0.998422" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999728714285714">
This work was supported by a research grant (Number
GR/D/4217.7) from the UK Science and Engineering
Research Council. We are grateful to the Longman
Group Limited for kindly allowing us access to the
LDOCE typesetting tape for research purposes. We
thank Graham Titmus for his assistance in bringing
the dictionary server up.
</bodyText>
<sectionHeader confidence="0.998703" genericHeader="references">
9 References
</sectionHeader>
<reference confidence="0.984275337499999">
Alshawi, H.; Boguraev, B.K. and Briscoe, E.J.(1985)
&apos;A dictionary support environment for real-time
parsing&apos;, Proceedings of the Second Conference of
the European Chapter of the ACL, Geneva, pp.171-
178
Alshawi, H.A.(1987,forthcoming) &apos;Processing dictio-
nary definitions with phrasal pattern hierarchies&apos;,
Computational Linguistics
Boguraev, B.K.(1987,forthcoming) &apos;Machine-readable
dictionaries and computational linguistics research&apos;
in Walker, D. and Zampolli, A. (eds.), Automating
the lexicon: theory and practice in a multilingual
environment, Cambridge University Press, Cam-
bridge
Boguraev, B.K. and Briscoe, E.J.(1987,forthcoming)
&apos;Large lexicons for natural language processing:
utilising the grammar coding system of LDOCE&apos;,
Computational Linguistics, vol.13
Boguraev, B.K.; Ritchie, G.D. et al.(1987,forthcoming)
&apos;The lexical component of a natural language tool-
kit&apos; in Walker, D. and Zampolli, A. (eds.), Au-
tomating the lexicon: theory and practice in a mul-
tilingual environment, Cambridge University Press,
Cambridge
Byrd, R.J. and Chodorow, M.S.(1985) &apos;Using an on-
line dictionary to find rhyming words and pro-
nunciations for unknown words&apos;, Proceedings of the
25th Annual Meeting of the ACL, Chicago, Illinois,
pp.277-284
Byrd, R.J.; Neumann, G. and Andersson, K.S.B.(1986)
DAM — a dictionary access method, IBM research
report, in preparation
Calzolari, N.(1986,forthcoming) &apos;Machine-readable dic-
tionaries, lexical data bases and the lexical system&apos;
in Walker, D. and Zampolli, A. (eds.), Automating
the lexicon: theory and practice in a multilingual
environment, Cambridge University Press, Cam-
bridge
Carter, D.M.(1986) An information-theoretic analysis
of phonetic dictionary access, Computer Labora-
tory, University of Cambridge (submitted to Com-
puter Speech and Language).
Church, K.(1985) &apos;Stress assignment in letter-to-sound
rules for speech synthesis&apos;, Proceedings of the 25th
Annual Meeting of the ACL, Chicago, IL, pp.246-
254
Coltheart, M.(1981) &apos;The MRC Psycholinguistic Data-
base&apos;, Quarterly Journal of Experimental Psychol-
ogy, vol.33A, 497-505
Gimson, A.C.(1980) An introduction to the pronuncia-
tion of English (3rd edition), Edward Arnold, Lon-
don
Kay, M.(1984) &apos;The dictionary server&apos;, Proceedings of
the 10th International Congress of Computational
Linguistics, Stanford, California, pp.461-462
Kazman, R.(1986) Structuring the text of the Oxford
English Dictionary through finite state transduction,
Technical Report TR-86-20, Department of Com-
puter Science, University of Waterloo, Waterloo,
Ontario
Michiels, A.(1982) Exploiting a large dictionary database,
Ph.D. Thesis, Universite de Liege, Belgium
Miller, G.(1985) WORDNET: a dictionary browser, In
Proceedings of the First International Conference
on Information in Data, University of Waterloo
centre for the New OED, Waterloo, Ontario
Russell, G.J. et al.(1986) &apos;A dictionary and morpho-
logical analyser for English&apos;, Proceedings of the 11th
International Congress on Computational Linguis-
tics, Bonn, pp.277-279
Selkirk, E.0.(1978) On prosodic structure and its rela-
tion to syntactic structure, Indiana University Lin-
guistics Club, Bloomington, Indiana
Tompa, F.(1986) Database design for a dictionary of
the future, Preliminary report, Centre for the New
Oxford English Dictionary, University of Water-
loo, Waterloo, Ontario
XSIS 038112(1981) Courier: the Remote Procedure Call
protocol, Xerox Systems Integration Standard, Xe-
rox Corporation, Stamford, Connecticut
</reference>
<page confidence="0.999317">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.972434">
<title confidence="0.999828">A Multi-Purpose Interface to an On-line Dictionary</title>
<author confidence="0.998586">Branimir Boguraev</author>
<author confidence="0.998586">David Carter</author>
<affiliation confidence="0.999998">University of Cambridge, Computer Laboratory</affiliation>
<address confidence="0.979956">Corn Exchange Street, Cambridge CB2 3QG, England</address>
<author confidence="0.998768">Ted Briscoe</author>
<affiliation confidence="0.99999">Department of Linguistics, University of Lancaster</affiliation>
<address confidence="0.999751">Bailrigg, Lancaster LA1 4YT, England</address>
<abstract confidence="0.999732833333333">We argue that there are two qualitatively different modes of using a machine-readable dictionary in the context of research in computational linguistics: batch processing of the source with the purpose of collating information for subsequent use by a natural language application, and placing the dictionary on-line in an environment which supports fast interactive access to data selected on the basis of a number of linguistic constraints. While it is the former mode of dictionary use which is characteristic of most computational linguistics work to date, it is the latter which has the potential of making maximal use of the information typically found in a machine-readable dictionary. We describe the mounting of the machine-readable source the Dictionary of Contemporary English on a single user workstation to make it available as a development tool for a number of research projects.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>H Alshawi</author>
<author>B K Boguraev</author>
<author>Briscoe</author>
</authors>
<title>E.J.(1985) &apos;A dictionary support environment for real-time parsing&apos;,</title>
<booktitle>Proceedings of the Second Conference of the European Chapter of the ACL, Geneva,</booktitle>
<pages>171--178</pages>
<marker>Alshawi, Boguraev, Briscoe, </marker>
<rawString>Alshawi, H.; Boguraev, B.K. and Briscoe, E.J.(1985) &apos;A dictionary support environment for real-time parsing&apos;, Proceedings of the Second Conference of the European Chapter of the ACL, Geneva, pp.171-178</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alshawi</author>
</authors>
<title>Processing dictionary definitions with phrasal pattern hierarchies&apos;,</title>
<date>1987</date>
<journal>Computational Linguistics</journal>
<contexts>
<context position="4795" citStr="Alshawi (1987)" startWordPosition="739" endWordPosition="740">the properties of the particular MRD, and is best aided by having fast interactive access to appropriate fragments of it. In addition, many research projects of a more experimental nature focus on investigating the ways in which the availability of an MRD can aid the development of particular natural language processing systems. The assumption is that an analysis of the accumulated data in the dictionary will reveal regularities which can then be exploited for the task at hand. Just one example, from a number of projects currently under way in Cambridge, illustrating this point is the work of Alshawi (1987), who has analysed definition texts across an entire dictionary to produce a &amp;quot;definition grammar&amp;quot; together with an associated technique for parsing the natural language descriptions of words into semantic structures. Such projects depend critically not only on the availability of a machine-readable equivalent of a published dictionary, but also on a software system capable of providing fast interactive access into the online source through various access routes. Operational natural language processing systems clearly will have well-defined requirements as far as their lexicons are concerned, a</context>
<context position="13580" citStr="Alshawi, 1987" startWordPosition="2126" endWordPosition="2127">ar coding fields in the dictionary. 3. Furthermore, LDOCE carries special tags, known as subject and box codes, which encode semantic notions like the overall context in which a word sense is likely to appear (e.g. politics, religion, language) and selectional restrictions on verbs, nouns and compound phrases; we intend to use this information for further guidance during the word recognition process. Independently, an algorithm has been developed for analysing the semantic content proper of the dictionary entries by converting the definition texts in LDOCE into fragments of semantic networks (Alshawi, 1987); this opens opportunities for building a comprehensive and robust semantic component which could then be incorporated into any of the projects mentioned above. It is clear that in order to make full use of the computerised LDOCE, we need a dictionary access system with proper DBMS functionality, capable of efficient retrieval of entries satisfying selection criteria applying at various levels of linguistic description. The design of the system described here allows precisely such heterogeneous requests. What we offer is a software environment buffering the user from the typically baroque and </context>
</contexts>
<marker>Alshawi, 1987</marker>
<rawString>Alshawi, H.A.(1987,forthcoming) &apos;Processing dictionary definitions with phrasal pattern hierarchies&apos;, Computational Linguistics</rawString>
</citation>
<citation valid="false">
<authors>
<author>B K Boguraev</author>
</authors>
<title>Machine-readable dictionaries and computational linguistics research&apos;</title>
<editor>in Walker, D. and Zampolli, A. (eds.),</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge</location>
<marker>Boguraev, </marker>
<rawString>Boguraev, B.K.(1987,forthcoming) &apos;Machine-readable dictionaries and computational linguistics research&apos; in Walker, D. and Zampolli, A. (eds.), Automating the lexicon: theory and practice in a multilingual environment, Cambridge University Press, Cambridge</rawString>
</citation>
<citation valid="false">
<authors>
<author>B K Boguraev</author>
<author>Briscoe</author>
</authors>
<title>E.J.(1987,forthcoming) &apos;Large lexicons for natural language processing: utilising the grammar coding system of LDOCE&apos;,</title>
<journal>Computational Linguistics,</journal>
<volume>13</volume>
<marker>Boguraev, Briscoe, </marker>
<rawString>Boguraev, B.K. and Briscoe, E.J.(1987,forthcoming) &apos;Large lexicons for natural language processing: utilising the grammar coding system of LDOCE&apos;, Computational Linguistics, vol.13</rawString>
</citation>
<citation valid="false">
<authors>
<author>B K Boguraev</author>
<author>G D Ritchie</author>
</authors>
<title>et al.(1987,forthcoming) &apos;The lexical component of a natural language toolkit&apos;</title>
<editor>in Walker, D. and Zampolli, A. (eds.),</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge</location>
<marker>Boguraev, Ritchie, </marker>
<rawString>Boguraev, B.K.; Ritchie, G.D. et al.(1987,forthcoming) &apos;The lexical component of a natural language toolkit&apos; in Walker, D. and Zampolli, A. (eds.), Automating the lexicon: theory and practice in a multilingual environment, Cambridge University Press, Cambridge</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Byrd</author>
<author>Chodorow</author>
</authors>
<title>Using an online dictionary to find rhyming words and pronunciations for unknown words&apos;,</title>
<date>1985</date>
<booktitle>Proceedings of the 25th Annual Meeting of the ACL,</booktitle>
<pages>277--284</pages>
<location>Chicago, Illinois,</location>
<contexts>
<context position="10469" citStr="Byrd and Chodorow, 1985" startWordPosition="1638" endWordPosition="1641">rloo, on computerising the Oxford English Dictionary (Tompa, 1986) is a good example here; similarly, the desire to be able to mount computerised dictionaries on-line for in-house research motivates Byrd&apos;s work on a general purpose dictionary access method (Byrd et al., 1986). In the short run, alternative approaches reduce the complexity of the problem by limiting themselves to applying the machine readable source of a dictionary to a small class of similar tasks, and building customised interfaces offering relatively narrow access channels into the on-line data. Thus IBM&apos;s WordSmith system (Byrd and Chodorow, 1985) is concerned primarily with providing a browsing functionality which supports retrieval of words &amp;quot;close&amp;quot; to a given word along the dimensions of spelling, meaning and sound, while a group at Bell Labs has several large dictionaries on-line used only for research on stress assignment (Church, 1985). Alshawi et al. (1985) have used a machine-readable source directly for syntactic analysis of texts; however, the approach taken there — namely that of simple pre-indexing by orthography — does not generalise easily for applications which require the rapid locating and retrieval of entries satisfyin</context>
</contexts>
<marker>Byrd, Chodorow, 1985</marker>
<rawString>Byrd, R.J. and Chodorow, M.S.(1985) &apos;Using an online dictionary to find rhyming words and pronunciations for unknown words&apos;, Proceedings of the 25th Annual Meeting of the ACL, Chicago, Illinois, pp.277-284</rawString>
</citation>
<citation valid="false">
<authors>
<author>R J Byrd</author>
<author>G Neumann</author>
<author>Andersson</author>
</authors>
<booktitle>K.S.B.(1986) DAM — a dictionary access method, IBM</booktitle>
<note>research report, in preparation</note>
<marker>Byrd, Neumann, Andersson, </marker>
<rawString>Byrd, R.J.; Neumann, G. and Andersson, K.S.B.(1986) DAM — a dictionary access method, IBM research report, in preparation</rawString>
</citation>
<citation valid="true">
<authors>
<author>Calzolari</author>
</authors>
<title>Machine-readable dictionaries, lexical data bases and the lexical system&apos;</title>
<date>1986</date>
<editor>in Walker, D. and Zampolli, A. (eds.),</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge</location>
<contexts>
<context position="31540" citStr="Calzolari (1986)" startWordPosition="5106" endWordPosition="5107">ndow clap.per.hoard Pkleepabo:d I -arbord/ (subj MP--, box (when starting to film a scene for the cinema) a board on which the details of the scene to be filmed are written, held up in front of the camera Po.lar.oid tdtnk 1(U) subj st--, box ---- a material with which glass is treated in order to make light shine less brightly through it, used in making ZUNGLAZZes,car windows, etc, 2 IC] subj box also ( mi) Polaroid cam.e.ra / ,••• &apos;••• — a type of camera that produces a finished photograph only seconds after the picture has been taken 68 from the concept of a lexical database as described in Calzolari (1986), or underlying Miller&apos;s WORDNET (1985). Nonetheless, the methodology described here is sufficiently flexible and powerful to satisfy a substantial proportion of the needs of the computational linguistics community till a proper mix of database and browsing capabilities becomes available. 8 Acknowledgements This work was supported by a research grant (Number GR/D/4217.7) from the UK Science and Engineering Research Council. We are grateful to the Longman Group Limited for kindly allowing us access to the LDOCE typesetting tape for research purposes. We thank Graham Titmus for his assistance in</context>
</contexts>
<marker>Calzolari, 1986</marker>
<rawString>Calzolari, N.(1986,forthcoming) &apos;Machine-readable dictionaries, lexical data bases and the lexical system&apos; in Walker, D. and Zampolli, A. (eds.), Automating the lexicon: theory and practice in a multilingual environment, Cambridge University Press, Cambridge</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carter</author>
</authors>
<title>An information-theoretic analysis of phonetic dictionary access,</title>
<date>1986</date>
<institution>Computer Laboratory, University of Cambridge</institution>
<note>(submitted to Computer Speech and Language).</note>
<contexts>
<context position="12674" citStr="Carter, 1986" startWordPosition="1986" endWordPosition="1987">the style of e.g. Generalised Phrase Structure Grammar), subsequently to be used by a syntactic parser (Boguraev and Briscoe, 1987, describe this in detail). The transformation program is about to be integrated in a software system for gram64 mar support and development, both as a lexicon generator and as a tool for grammar debugging (Boguraev and Ritchie, 1987). 2. The pronunciation information in LDOCE has provided the basis for a study, in the larger context of speech recognition, of the implications of the phonetic structure of the English lexicon for different methods for lexical access (Carter, 1986). Again in the context of speech recognition, we intend to tackle the problem of word identification from a lattice of phonemes by constructing a parser that uses information about both phoneme collocations and syntactic predictions derived from independent analyses of the phonetic and grammar coding fields in the dictionary. 3. Furthermore, LDOCE carries special tags, known as subject and box codes, which encode semantic notions like the overall context in which a word sense is likely to appear (e.g. politics, religion, language) and selectional restrictions on verbs, nouns and compound phras</context>
</contexts>
<marker>Carter, 1986</marker>
<rawString>Carter, D.M.(1986) An information-theoretic analysis of phonetic dictionary access, Computer Laboratory, University of Cambridge (submitted to Computer Speech and Language).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Church</author>
</authors>
<title>Stress assignment in letter-to-sound rules for speech synthesis&apos;,</title>
<date>1985</date>
<booktitle>Proceedings of the 25th Annual Meeting of the ACL,</booktitle>
<pages>246--254</pages>
<location>Chicago, IL,</location>
<contexts>
<context position="10768" citStr="Church, 1985" startWordPosition="1689" endWordPosition="1690">proaches reduce the complexity of the problem by limiting themselves to applying the machine readable source of a dictionary to a small class of similar tasks, and building customised interfaces offering relatively narrow access channels into the on-line data. Thus IBM&apos;s WordSmith system (Byrd and Chodorow, 1985) is concerned primarily with providing a browsing functionality which supports retrieval of words &amp;quot;close&amp;quot; to a given word along the dimensions of spelling, meaning and sound, while a group at Bell Labs has several large dictionaries on-line used only for research on stress assignment (Church, 1985). Alshawi et al. (1985) have used a machine-readable source directly for syntactic analysis of texts; however, the approach taken there — namely that of simple pre-indexing by orthography — does not generalise easily for applications which require the rapid locating and retrieval of entries satisfying more than one selection criterion. 3 System functionality The motivation for the design described here is divided equally between the diverse nature of MRDbased projects in Cambridge and Lancaster and the unique properties of the particular dictionary that they use. The suitability of the Longman</context>
</contexts>
<marker>Church, 1985</marker>
<rawString>Church, K.(1985) &apos;Stress assignment in letter-to-sound rules for speech synthesis&apos;, Proceedings of the 25th Annual Meeting of the ACL, Chicago, IL, pp.246-254</rawString>
</citation>
<citation valid="true">
<authors>
<author>Coltheart</author>
</authors>
<title>The MRC Psycholinguistic Database&apos;,</title>
<date>1981</date>
<journal>Quarterly Journal of Experimental Psychology,</journal>
<volume>33</volume>
<pages>497--505</pages>
<contexts>
<context position="30544" citStr="Coltheart, 1981" startWordPosition="4938" endWordPosition="4939">system had to be adapted to fit into the local environment of networked workstations. The database manager was easily repackaged to reflect the model of one server catering for several clients over a network; the Remote Procedure Call Protocol (XSIS, 1981) provided the necessary functionality to incorporate the manager into a dictionary server node (of the kind discussed by Kay, 1984) — this bypassed the need for costly fileservers and proved the integrity of the design. We also plan to develop a version of the system running in Franz Lisp under UNIX and accessing the MRC dictionary database (Coltheart, 1981). While the system implements in effect a linguistically motivated DBMS constructed round a suitable machine-readable source, it stops short of full browsing capability (even though such a capability could easily be added by fully integrating Alshawi&apos;s definitions analysis program into the overall design). In this sense the lexical knowledge base discussed here differs Entry window clap.per.hoard Pkleepabo:d I -arbord/ (subj MP--, box (when starting to film a scene for the cinema) a board on which the details of the scene to be filmed are written, held up in front of the camera Po.lar.oid tdtn</context>
</contexts>
<marker>Coltheart, 1981</marker>
<rawString>Coltheart, M.(1981) &apos;The MRC Psycholinguistic Database&apos;, Quarterly Journal of Experimental Psychology, vol.33A, 497-505</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gimson</author>
</authors>
<title>An introduction to the pronunciation of English (3rd edition),</title>
<date>1980</date>
<location>Edward Arnold, London</location>
<contexts>
<context position="20545" citStr="Gimson (1980)" startWordPosition="3236" endWordPosition="3237">tical form in which they occur in LDOCE is described in Boguraev and Briscoe (1987). We will therefore discuss here only the structuring of pronunciations and the treatment of definition texts. Pronunciations are represented in the dictionary as strings of phonemes and primary and secondary stress markers. Syllable boundaries are not reliably indicated. Therefore, in order to allow the syllablebased access that a speech recogniser would probably require, pronunciation fields are parsed into syllables and, within a syllable, into onset, peak and coda, using the phonotactic constraints given in Gimson (1980) and employing a maximal onset principle (Selkirk, 1978) where these yield ambiguous syllable boundaries. Thus for example the internal syllable boundary in the pronunciation of &amp;quot;constraint&amp;quot; is placed before the &amp;quot;s&amp;quot;. The parser used for analysing pronunciations is a special-purpose one whose (very simple) grammar is incorporated into its code. This allows pronunciations to be parsed many times faster than by a general-purpose parser with a declarative grammar. It also allows constraints on relationships between syllable constituents to be relaxed when necessary. For example, the LDOCE pronunci</context>
</contexts>
<marker>Gimson, 1980</marker>
<rawString>Gimson, A.C.(1980) An introduction to the pronunciation of English (3rd edition), Edward Arnold, London</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kay</author>
</authors>
<title>The dictionary server&apos;,</title>
<date>1984</date>
<booktitle>Proceedings of the 10th International Congress of Computational Linguistics,</booktitle>
<pages>461--462</pages>
<location>Stanford, California,</location>
<contexts>
<context position="30315" citStr="Kay, 1984" startWordPosition="4898" endWordPosition="4899">uter or mainframe (as long as it supported random access to files) just as well as it does on a single user workstation. In order to make the lexical knowledge base available to all the projects requiring access to it, the system had to be adapted to fit into the local environment of networked workstations. The database manager was easily repackaged to reflect the model of one server catering for several clients over a network; the Remote Procedure Call Protocol (XSIS, 1981) provided the necessary functionality to incorporate the manager into a dictionary server node (of the kind discussed by Kay, 1984) — this bypassed the need for costly fileservers and proved the integrity of the design. We also plan to develop a version of the system running in Franz Lisp under UNIX and accessing the MRC dictionary database (Coltheart, 1981). While the system implements in effect a linguistically motivated DBMS constructed round a suitable machine-readable source, it stops short of full browsing capability (even though such a capability could easily be added by fully integrating Alshawi&apos;s definitions analysis program into the overall design). In this sense the lexical knowledge base discussed here differs</context>
</contexts>
<marker>Kay, 1984</marker>
<rawString>Kay, M.(1984) &apos;The dictionary server&apos;, Proceedings of the 10th International Congress of Computational Linguistics, Stanford, California, pp.461-462</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazman</author>
</authors>
<title>Structuring the text of the Oxford English Dictionary through finite state transduction,</title>
<date>1986</date>
<tech>Technical Report TR-86-20,</tech>
<institution>Department of Computer Science, University of Waterloo,</institution>
<location>Waterloo, Ontario</location>
<contexts>
<context position="8104" citStr="Kazman, 1986" startWordPosition="1260" endWordPosition="1262">y unsuitable for on-line access by information retrieval methods. The second factor is due to the nature of the only source of machine-readable dictionaries so fax available — namely the publishers&apos; typesetting tapes, originally constructed for the production of a printed version. The organisation of data there, aimed at visual presentation, carries virtually no explicit structure; a tape is simply a character stream containing an arbitrary mixture of typesetting commands and real data. This not only introduces the difficult problem of &amp;quot;parsing&amp;quot; a dictionary entry (addressed in detail by e.g. Kazman, 1986), but also raises the issue of devising a suitable representation for the potentially huge amount of linguistic data; one which does not limit in any way the language processing functions that could be supported or constrain the complexity of the computational counterpart of a dictionary entry. Finally, there is the nature of the data structures themselves. A text processing application, typically written in Lisp or Prolog, requires that its lexical data is represented in a compatible form, say Lisp s-expressions of arbitrary complexity. Therefore, even if we choose to remain neutral with resp</context>
</contexts>
<marker>Kazman, 1986</marker>
<rawString>Kazman, R.(1986) Structuring the text of the Oxford English Dictionary through finite state transduction, Technical Report TR-86-20, Department of Computer Science, University of Waterloo, Waterloo, Ontario</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michiels</author>
</authors>
<title>Exploiting a large dictionary database,</title>
<date>1982</date>
<tech>Ph.D. Thesis,</tech>
<institution>Universite de Liege, Belgium</institution>
<contexts>
<context position="11531" citStr="Michiels, 1982" startWordPosition="1806" endWordPosition="1807">t of simple pre-indexing by orthography — does not generalise easily for applications which require the rapid locating and retrieval of entries satisfying more than one selection criterion. 3 System functionality The motivation for the design described here is divided equally between the diverse nature of MRDbased projects in Cambridge and Lancaster and the unique properties of the particular dictionary that they use. The suitability of the Longman Dictionary of Contemporary English (LDOCE) for research into computational linguistics has been discussed at length elsewhere (see, in particular, Michiels, 1982); below we will outline several projects undertaken in Cambridge as a context for highlighting its particularly useful characteristics insofar as they are relevant to this paper. LDOCE carries special lexical and linguistic information which is useful for a number of natural language processing tasks. 1. The dictionary is unique in tagging word senses with grammar codes which provide very elaborate syntactic subcategorisation information; a procedure has been developed for mapping the grammar codes into feature clusters (in the style of e.g. Generalised Phrase Structure Grammar), subsequently </context>
</contexts>
<marker>Michiels, 1982</marker>
<rawString>Michiels, A.(1982) Exploiting a large dictionary database, Ph.D. Thesis, Universite de Liege, Belgium</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miller</author>
</authors>
<title>WORDNET: a dictionary browser,</title>
<date>1985</date>
<booktitle>In Proceedings of the First International Conference on Information in Data, University of Waterloo centre for the</booktitle>
<location>New OED, Waterloo, Ontario</location>
<marker>Miller, 1985</marker>
<rawString>Miller, G.(1985) WORDNET: a dictionary browser, In Proceedings of the First International Conference on Information in Data, University of Waterloo centre for the New OED, Waterloo, Ontario</rawString>
</citation>
<citation valid="false">
<authors>
<author>G J Russell</author>
</authors>
<title>et al.(1986) &apos;A dictionary and morphological analyser for English&apos;,</title>
<booktitle>Proceedings of the 11th International Congress on Computational Linguistics,</booktitle>
<pages>277--279</pages>
<location>Bonn,</location>
<marker>Russell, </marker>
<rawString>Russell, G.J. et al.(1986) &apos;A dictionary and morphological analyser for English&apos;, Proceedings of the 11th International Congress on Computational Linguistics, Bonn, pp.277-279</rawString>
</citation>
<citation valid="true">
<authors>
<author>Selkirk</author>
</authors>
<title>On prosodic structure and its relation to syntactic structure,</title>
<date>1978</date>
<institution>Indiana University Linguistics Club,</institution>
<location>Bloomington, Indiana</location>
<contexts>
<context position="20601" citStr="Selkirk, 1978" startWordPosition="3244" endWordPosition="3245"> Boguraev and Briscoe (1987). We will therefore discuss here only the structuring of pronunciations and the treatment of definition texts. Pronunciations are represented in the dictionary as strings of phonemes and primary and secondary stress markers. Syllable boundaries are not reliably indicated. Therefore, in order to allow the syllablebased access that a speech recogniser would probably require, pronunciation fields are parsed into syllables and, within a syllable, into onset, peak and coda, using the phonotactic constraints given in Gimson (1980) and employing a maximal onset principle (Selkirk, 1978) where these yield ambiguous syllable boundaries. Thus for example the internal syllable boundary in the pronunciation of &amp;quot;constraint&amp;quot; is placed before the &amp;quot;s&amp;quot;. The parser used for analysing pronunciations is a special-purpose one whose (very simple) grammar is incorporated into its code. This allows pronunciations to be parsed many times faster than by a general-purpose parser with a declarative grammar. It also allows constraints on relationships between syllable constituents to be relaxed when necessary. For example, the LDOCE pronunciation of &amp;quot;bedouin&amp;quot; is &apos;beduin, which violates the constr</context>
</contexts>
<marker>Selkirk, 1978</marker>
<rawString>Selkirk, E.0.(1978) On prosodic structure and its relation to syntactic structure, Indiana University Linguistics Club, Bloomington, Indiana</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tompa</author>
</authors>
<title>Database design for a dictionary of the future,</title>
<date>1986</date>
<tech>Preliminary report,</tech>
<institution>Centre for the New Oxford English Dictionary, University of Waterloo,</institution>
<location>Waterloo, Ontario</location>
<contexts>
<context position="9911" citStr="Tompa, 1986" startWordPosition="1554" endWordPosition="1555">abases are taken to consist of a large number of data records taken from a small number of rigidlydefined classes. It is not clear that a lexical &amp;quot;knowledge base&amp;quot;, derived from a dictionary and intended to support a wide range of language processing applications, fits this model well. Some solutions to these problems will no doubt be offered by dedicated efforts to develop special purpose data models, capable of computationally representing a dictionary and amenable to flexible and efficient DBMS support. The work, at the University of Waterloo, on computerising the Oxford English Dictionary (Tompa, 1986) is a good example here; similarly, the desire to be able to mount computerised dictionaries on-line for in-house research motivates Byrd&apos;s work on a general purpose dictionary access method (Byrd et al., 1986). In the short run, alternative approaches reduce the complexity of the problem by limiting themselves to applying the machine readable source of a dictionary to a small class of similar tasks, and building customised interfaces offering relatively narrow access channels into the on-line data. Thus IBM&apos;s WordSmith system (Byrd and Chodorow, 1985) is concerned primarily with providing a b</context>
</contexts>
<marker>Tompa, 1986</marker>
<rawString>Tompa, F.(1986) Database design for a dictionary of the future, Preliminary report, Centre for the New Oxford English Dictionary, University of Waterloo, Waterloo, Ontario</rawString>
</citation>
<citation valid="false">
<booktitle>XSIS 038112(1981) Courier: the Remote Procedure Call protocol, Xerox Systems Integration Standard, Xerox Corporation,</booktitle>
<location>Stamford, Connecticut</location>
<marker></marker>
<rawString>XSIS 038112(1981) Courier: the Remote Procedure Call protocol, Xerox Systems Integration Standard, Xerox Corporation, Stamford, Connecticut</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>