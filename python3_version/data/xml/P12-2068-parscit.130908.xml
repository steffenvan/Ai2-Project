<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000868">
<title confidence="0.994308">
Sentence Compression with Semantic Role Constraints
</title>
<author confidence="0.9744">
Katsumasa Yoshikawa
</author>
<affiliation confidence="0.958259333333333">
Precision and Intelligence Laboratory,
Tokyo Institute of Technology, Japan
IBM Research-Tokyo, IBM Japan, Ltd.
</affiliation>
<email confidence="0.937581">
katsumasay@gmail.com
</email>
<author confidence="0.945986">
Tsutomu Hirao
</author>
<affiliation confidence="0.737122">
NTT Communication Science Laboratories,
NTT Corporation, Japan
</affiliation>
<email confidence="0.994903">
hirao.tsutomu@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.998583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999665166666667">
For sentence compression, we propose new se-
mantic constraints to directly capture the relations
between a predicate and its arguments, whereas
the existing approaches have focused on relatively
shallow linguistic properties, such as lexical and
syntactic information. These constraints are based
on semantic roles and superior to the constraints
of syntactic dependencies. Our empirical eval-
uation on the Written News Compression Cor-
pus (Clarke and Lapata, 2008) demonstrates that
our system achieves results comparable to other
state-of-the-art techniques.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999831333333333">
Recent work in document summarization do not
only extract sentences but also compress sentences.
Sentence compression enables summarizers to re-
duce the redundancy in sentences and generate in-
formative summaries beyond the extractive summa-
rization systems (Knight and Marcu, 2002). Con-
ventional approaches to sentence compression ex-
ploit various linguistic properties based on lexical
information and syntactic dependencies (McDonald,
2006; Clarke and Lapata, 2008; Cohn and Lapata,
2008; Galanis and Androutsopoulos, 2010).
In contrast, our approach utilizes another property
based on semantic roles (SRs) which improves weak-
nesses of syntactic dependencies. Syntactic depen-
dencies are not sufficient to compress some complex
sentences with coordination, with passive voice, and
with an auxiliary verb. Figure 1 shows an example
with a coordination structure. &apos;
</bodyText>
<footnote confidence="0.8008025">
&apos;This example is from Written News Compression Cor-
pus(http://jamesclarke.net/research/resources).
</footnote>
<author confidence="0.703576">
Ryu Iida
</author>
<affiliation confidence="0.9759755">
Department of Computer Science,
Tokyo Institute of Technology, Japan
</affiliation>
<email confidence="0.927883">
ryu-i@cl.cs.titech.ac.jp
</email>
<author confidence="0.89088">
Manabu Okumura
</author>
<affiliation confidence="0.9909885">
Precision and Intelligence Laboratory,
Tokyo Institute of Technology, Japan
</affiliation>
<email confidence="0.949642">
oku@lr.pi.titech.ac.jp
</email>
<figureCaption confidence="0.990278">
Figure 1: Semantic Role vs. Dependency Relation
</figureCaption>
<bodyText confidence="0.999117434782609">
In this example, a SR labeler annotated that Harari
is an A0 argument of left and an A1 argument of
became. Harari is syntactically dependent on left –
SBJ(left-2, Harari-1). However, Harari is not depen-
dent on became and we are hence unable to utilize a
dependency relation between Harari and became di-
rectly. SRs allow us to model the relations between
a predicate and its arguments in a direct fashion.
SR constraints are also advantageous in that we
can compress sentences with semantic information.
In Figure 1, became has three arguments, Harari as
A1, businessman as A2, and shortly afterward as
AM-TMP. As shown in this example, shortly after-
word can be omitted (shaded boxes). In general,
modifier arguments like AM-TMP or AM-LOC are
more likely to be reduced than complement cases
like A0-A4. We can implement such properties by
SR constraints.
Liu and Gildea (2010) suggests that SR features
contribute to generating more readable sentence in
machine translation. We expect that SR features also
help our system to improve readability in sentence
compression and summarization.
</bodyText>
<sectionHeader confidence="0.690188" genericHeader="method">
2 Why are Semantic Roles Useful for Com-
pressing Sentences?
</sectionHeader>
<bodyText confidence="0.986344">
Before describing our system, we show the statis-
tics in terms of predicates, arguments and their rela-
</bodyText>
<page confidence="0.992846">
349
</page>
<note confidence="0.8149395">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 349–353,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.995261208333333">
Label
A0
A1
A2
AM-TMP
AM-LOC
AM-ADV
AM-DIS
In Compression / Total
1454 / 1607
1916 / 2208
427 / 490
261 / 488
134 / 214
115 / 213
8 / 85
Ratio
0.905
0.868
0.871
0.535
0.626
0.544
0.094
</figure>
<tableCaption confidence="0.982887">
Table 1: Statistics of Arguments in Compression
</tableCaption>
<bodyText confidence="0.99991944">
tions in the Written News Compression (WNC) Cor-
pus. It has 82 documents (1,629 sentences). We di-
vided them into three: 55 documents are used for
training (1106 sentences); 10 for development (184
sentences); 17 for testing (339 sentences).
Our investigation was held in training data. There
are 3137 verbal predicates and 7852 unique argu-
ments. We performed SR labeling by LTH (Johans-
son and Nugues, 2008), an SR labeler for CoNLL-
2008 shared task. Based on the SR labels annotated
by LTH, we investigated that, for all predicates in
compression, how many their arguments were also
in. Table 1 shows the survival ratio of main argu-
ments in compression. Labels A0, A1, and A2 are
complement case roles and over 85% of them survive
with their predicates. On the other hand, for modifier
arguments (AM-X), survival ratios are down to lower
than 65%. Our SR constraints implement the differ-
ence of survival ratios by SR labels. Note that de-
pendency labels SBJ and OBJ generally correspond
to SR labels A0 and A1, respectively. But their total
numbers are 777 / 919 (SBJ) and 918 / 1211 (OBJ)
and much fewer than A0 and A1 labels. Thus, SR la-
bels can connect much more arguments to their pred-
icates.
</bodyText>
<sectionHeader confidence="0.99471" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999939454545455">
This section describes our new approach to sen-
tence compression. In order to introduce rich syn-
tactic and semantic constraints to a sentence com-
pression model, we employ Markov Logic (Richard-
son and Domingos, 2006). Since Markov Logic sup-
ports both soft and hard constraints, we can imple-
ment our SR constraints in simple and direct fash-
ion. Moreover, implementations of learning and
inference methods are already provided in existing
Markov Logic interpreters such as Alchemy 2 and
Markov thebeast. 3 Thus, we can focus our effort
</bodyText>
<footnote confidence="0.999516">
2http://alchemy.cs.washington.edu/
3http://code.google.com/p/thebeast/
</footnote>
<bodyText confidence="0.997661">
on building a set of formulae called Markov Logic
Network (MLN). So, in this section, we describe our
proposed MLN in detail.
</bodyText>
<subsectionHeader confidence="0.999304">
3.1 Proposed Markov Logic Network
</subsectionHeader>
<bodyText confidence="0.999917181818182">
First, let us define our MLN predicates. We sum-
marize the MLN predicates in Table 2. We have only
one hidden MLN predicate, inComp(i) which mod-
els the decision we need to make: whether a token i
is in compression or not. The other MLN predicates
are called observed which provide features. With our
MLN predicates defined, we can now go on to in-
corporate our intuition about the task using weighted
first-order logic formulae. We define SR constraints
and the other formulae in Sections 3.1.1 and 3.1.2,
respectively.
</bodyText>
<subsectionHeader confidence="0.787682">
3.1.1 Semantic Role Constraints
</subsectionHeader>
<bodyText confidence="0.998083625">
Semantic role labeling generally includes the three
subtasks: predicate identification; argument role la-
beling; sense disambiguation. Our model exploits
the results of predicate identification and argument
role labeling. 4 pred(i) and role(i, j, r) indicate the
results of predicate identification and role labeling,
respectively.
First, the formula describing a local property of a
predicate is
pred(i) =� inComp(i) (1)
which denotes that, if token i is a predicate then i is
in compression. A formula with exact one hidden
predicate is called local formula.
A predicate is not always in compression. The for-
mula reducing some predicates is
pred(i) n height(i, +n) =� -,inComp(i) (2)
which implies that a predicate i is not in compression
with n height in a dependency tree. Note the + nota-
tion indicates that the MLN contains one instance of
the rule, with a separate weight, for each assignment
of the variables with a plus sign.
As mentioned earlier, our SR constraints model
the difference of the survival rate of role labels in
compression. Such SR constraints are encoded as:
</bodyText>
<equation confidence="0.945397">
role(i, j, +r) n inComp(i) =� inComp(j) (3)
role(i, j, +r) n -,inComp(i) =� -,inComp(j) (4)
</equation>
<bodyText confidence="0.949998">
which represent that, if a predicate i is (not) in com-
pression, then its argument j is (not) also in with
</bodyText>
<footnote confidence="0.998933">
4Sense information is too sparse because the size of the
WNC Corpus is not big enough.
</footnote>
<page confidence="0.988727">
350
</page>
<tableCaption confidence="0.733804">
predicate definition
Table 2: MLN Predicates
</tableCaption>
<bodyText confidence="0.947828058823529">
role r. These formulae are called global formulae
because they have more than two hidden MLN pred-
icates. With global formulae, our model makes two
decisions at a time. When considering the example
in Figure 1, Formula (3) will be grounded as:
role(9,1, A0) n inComp(9) =&gt; inComp(1) (5)
role(9, 7, AM-TMP) n inComp(9) =&gt; inComp(7). (6)
In fact, Formula (5) gains a higher weight than For-
mula (6) by learning on training data. As a re-
sult, our system gives “1-Harari” more chance to
survive in compression. We also add some exten-
sions of Formula (3) combined with dep(i, j, +d) and
path(i, j, +l) which enhance SR constraints. Note, all
our SR constraints are “predicate-driven” (only =&gt;
nota as in Formula (13)). Because an argument is
usually related to multiple predicates, it is difficult to
model “argument-driven” formula.
</bodyText>
<subsectionHeader confidence="0.67737">
3.1.2 Lexical and Syntactic Features
</subsectionHeader>
<bodyText confidence="0.999269090909091">
For lexical and syntactic features, we mainly refer
to the previous work (McDonald, 2006; Clarke and
Lapata, 2008). The first two formulae in this sec-
tion capture the relation of the tokens with their lexi-
cal and syntactic properties. The formula describing
such a local property of a word form is
word(i, +w) =&gt; inComp(i) (7)
which implies that a token i is in compression with a
weight that depends on the word form.
For part-of-speech (POS), we add unigram and bi-
gram features with the formulae,
</bodyText>
<equation confidence="0.916619">
pos(i, +p) =&gt; inComp(i) (8)
</equation>
<bodyText confidence="0.948487555555555">
pos(i, +p1) n pos(i + 1, +p2) =&gt; inComp(i). (9)
POS features are often more reasonable than word
form features to combine with the other properties.
The formula,
pos(i, +p) n height(i, +n) =&gt; inComp(i). (10)
is a combination of POS features and a height in a
dependency tree.
The next formula combines POS bigram features
with dependency relations.
</bodyText>
<equation confidence="0.822427833333333">
pos(i, +p1) n pos(j, +p2) n
dep(i, j, +d) =&gt; inComp(i). (11)
Moreover, our model includes the following
global formulae,
dep(i, j, +d) n inComp(i) =&gt; inComp(j) (12)
dep(i, j, +d) n inComp(i) a inComp(j) (13)
</equation>
<bodyText confidence="0.999668727272727">
which enforce the consistencies between head and
modifier tokens. Formula (12) represents that if
we include a head token in compression then its
modifier must also be included. Formula (13) en-
sures that head and modifier words must be simul-
taneously kept in compression or dropped. Though
Clarke and Lapata (2008) implemented these depen-
dency constraints by ILP, we implement them by
soft constraints of MLN. Note that Formula (12) ex-
presses the same properties as Formula (3) replacing
dep(i, j, +d) by role(i, j, +r).
</bodyText>
<sectionHeader confidence="0.999181" genericHeader="evaluation">
4 Experiment and Result
</sectionHeader>
<subsectionHeader confidence="0.998273">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999968105263158">
Our experimental setting follows previous
work (Clarke and Lapata, 2008). As stated in
Section 2, we employed the WNC Corpus. For
preprocessing, we performed POS tagging by
stanford-tagger. 5 and dependency parsing by
MST-parser (McDonald et al., 2005). In addition,
LTH 6 was exploited to perform both dependency
parsing and SR labeling. We implemented our
model by Markov Thebeast with Gurobi optimizer. 7
Our evaluation consists of two types of automatic
evaluations. The first evaluation is dependency based
evaluation same as Riezler et al. (2003). We per-
formed dependency parsing on gold data and system
outputs by RASP. 8 Then we calculated precision, re-
call, and F1 for the set of label(head, modifier).
In order to demonstrate how well our SR con-
straints keep correct predicate-argument structures
in compression, we propose SRL based evalua-
tion. We performed SR labeling on gold data
</bodyText>
<footnote confidence="0.997505">
5http://nlp.stanford.edu/software/tagger.shtml
6http://nlp.cs.lth.se/software/semantic_
parsing:_propbank_nombank_frames
7http://www.gurobi.com/
8http://www.informatics.susx.ac.uk/research/
</footnote>
<equation confidence="0.968644363636364">
groups/nlp/rasp/
inComp(i)
Token i is in compression
pred(i)
role(i, j, r)
word(i, w)
pos(i, p)
dep(i, j, d)
path(i, j, l)
height(i, n)
Token i is a predicate
</equation>
<bodyText confidence="0.990661857142857">
Token i has an argument j with role r
Token i has word w
Token i has Pos tag p
Token i is dependent on token j with
dependency label d
Tokens i and j has syntactic path l
Token i has height n in dependency tree
</bodyText>
<page confidence="0.993929">
351
</page>
<table confidence="0.989121857142857">
Original [A0 They] [pred say] [A1 the refugees will enhance productivity and economic growth].
MLN with SRL [A0 They] [pred say] [A1 the refugees will enhance growth].
Gold Standard [A1. the refugees will enhance productivity and growth].
Original [A0 A Ł16.1m dam] [AM−MOD will] [pred hold] back [A1 a 2.6-mile-long artificial lake to be
known as the Roadford Reservoir].
MLN with SRL [A0 A dam] will [pred hold] back [A1 a artificial lake to be known as the Roadford Reservoir].
Gold Standard [A0 A Ł16.1m dam] [AM−MOD will] [pred hold back [A1 a 2.6-mile-long Roadford Reservoir].
</table>
<tableCaption confidence="0.947847">
Table 4: Analysis of Errors
</tableCaption>
<table confidence="0.9999086">
Model CompR F1-Dep F1-SRL
McDonald 73.6% 38.4% 49.9%
MLN w/o SRL 68.3% 51.3% 57.2%
MLN with SRL 73.1% 58.9% 64.1%
Gold Standard 73.3% – –
</table>
<tableCaption confidence="0.999913">
Table 3: Results of Sentence Compression
</tableCaption>
<bodyText confidence="0.9996695">
and system outputs by LTH. Then we calculated
precision, recall, and F1 value for the set of
role(predicate, argument).
The training time of our MLN model are approx-
imately 8 minutes on all training data, with 3.1GHz
Intel Core i3 CPU and 4G memory. While the pre-
diction can be done within 20 seconds on the test
data.
</bodyText>
<subsectionHeader confidence="0.795852">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.980202756756757">
Table 3 shows the results of our compression
models by compression rate (CompR), dependency-
based F1 (F1-Dep), and SRL-based F1 (F1-SRL). In
our experiment, we have three models. McDonald
is a re-implementation of McDonald (2006). Clarke
and Lapata (2008) also re-implemented McDonald’s
model with an ILP solver and experimented it on the
WNC Corpus. 9 MLN with SRL and MLN w/o
SRL are our Markov Logic models with and with-
out SR Constraints, respectively.
Note our three models have no constraint for the
length of compression. Therefore, we think the com-
pression rate of the better system should get closer to
that of human compression. In comparison between
MLN models and McDonald, the former models out-
perform the latter model on both F1-Dep and F1-
SRL. Because MLN models have global constraints
and can generate syntactically correct sentences.
Our concern is how a model with SR constraints
is superior to a model without them. MLN with
SRL outperforms MLN without SRL with a 7.6
points margin (F1-Dep). The compression rate of
MLN with SRL goes up to 73.1% and gets close
9Clarke’s re-implementation got 60.1% for CompR and
36.0%pt for F1-Dep
to that of gold standard. SRL-based evaluation also
shows that SR constraints actually help extract cor-
rect predicate-argument structures. These results are
promising to improve readability.
It is difficult to directly compare our results with
those of state-of-the-art systems (Cohn and Lapata,
2009; Clarke and Lapata, 2010; Galanis and An-
droutsopoulos, 2010) since they have different test-
ing sets and the results with different compression
rates. However, though our MLN model with SR
constraints utilizes no large-scale data, it is the only
model which achieves close on 60% in F1-Dep.
</bodyText>
<subsectionHeader confidence="0.984933">
4.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999956857142857">
Table 4 indicates two critical examples which our
SR constraints failed to compress correctly. For the
first example, our model leaves an argument with its
predicate because our SR constraints are “predicate-
driven”. In addition, “say” is the main verb in this
sentence and hard to be deleted due to the syntactic
significance.
The second example in Table 4 requires to iden-
tify a coreference relation between artificial lake and
Roadford Reservour. We consider that discourse
constraints (Clarke and Lapata, 2010) help our model
handle these cases. Discourse and coreference infor-
mation enable our model to select important argu-
ments and their predicates.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999830363636364">
In this paper, we proposed new semantic con-
straints for sentence compression. Our model with
global constraints of semantic roles selected correct
predicate-argument structures and successfully im-
proved performance of sentence compression.
As future work, we will compare our model with
the other state-of-the-art systems. We will also inves-
tigate the correlation between readability and SRL-
based score by manual evaluations. Furthermore, we
would like to combine discourse constraints with SR
constraints.
</bodyText>
<page confidence="0.996247">
352
</page>
<sectionHeader confidence="0.983144" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994043879310345">
James Clarke and Mirella Lapata. 2008. Global infer-
ence for sentence compression: An integer linear pro-
gramming approach. Journal of Artificial Intelligence
Research, 31(1):399–429.
James Clarke and Mirella Lapata. 2010. Discourse con-
straints for document compression. Computational
Linguistics, 36(3):411–441.
Trevor Cohn and Mirella Lapata. 2008. Sentence com-
pression beyond word deletion. In Proceedings of
the 22nd International Conference on Computational
Linguistics-Volume 1, pages 137–144. Association for
Computational Linguistics.
Trevor Cohn and Mirella Lapata. 2009. Sentence com-
pression as tree transduction. Journal of Artificial In-
telligence Research, 34:637–674.
Dimitrios Galanis and Ion Androutsopoulos. 2010. An
extractive supervised two-stage method for sentence
compression. In Human Language Technologies: The
2010 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
HLT ’10, pages 885–893, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic-semantic analysis
with propbank and nombank. In Proceedings of
the Twelfth Conference on Computational Natural
Language Learning, pages 183–187. Association for
Computational Linguistics.
Kevin Knight and Daniel Marcu. 2002. Summariza-
tion beyond sentence extraction: A probabilistic ap-
proach to sentence compression. Artificial Intelligence,
139(1):91–107.
Ding Liu and Daniel Gildea. 2010. Semantic role fea-
tures for machine translation. In Proceedings of the
23rd International Conference on Computational Lin-
guistics (Coling 2010), pages 716–724, Beijing, China,
August. Coling 2010 Organizing Committee.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan
Hajiˇc. 2005. Non-projective dependency parsing us-
ing spanning tree algorithms. In Proceedings of the
conference on Human Language Technology and Em-
pirical Methods in Natural Language Processing, HLT
’05, pages 523–530, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Ryan McDonald. 2006. Discriminative sentence com-
pression with soft syntactic evidence. In Proceedings
of EACL, pages 297–304.
Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine Learning, 62(1-
2):107–136.
Stefan Riezler, Tracy H. King, Richard Crouch, and An-
nie Zaenen. 2003. Statistical sentence condensation
using ambiguity packing and stochastic disambigua-
tion methods for lexical-functional grammar. In Pro-
ceedings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology-Volume 1, pages
118–125. Association for Computational Linguistics.
</reference>
<page confidence="0.999347">
353
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.318729">
<title confidence="0.999571">Sentence Compression with Semantic Role Constraints</title>
<author confidence="0.546442">Katsumasa</author>
<affiliation confidence="0.866384333333333">Precision and Intelligence Tokyo Institute of Technology, IBM Research-Tokyo, IBM Japan,</affiliation>
<email confidence="0.999685">katsumasay@gmail.com</email>
<author confidence="0.698869">Tsutomu</author>
<affiliation confidence="0.9932005">NTT Communication Science NTT Corporation,</affiliation>
<email confidence="0.920928">hirao.tsutomu@lab.ntt.co.jp</email>
<abstract confidence="0.999223846153846">For sentence compression, we propose new semantic constraints to directly capture the relations between a predicate and its arguments, whereas the existing approaches have focused on relatively shallow linguistic properties, such as lexical and syntactic information. These constraints are based on semantic roles and superior to the constraints of syntactic dependencies. Our empirical evaluation on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="781" citStr="Clarke and Lapata, 2008" startWordPosition="97" endWordPosition="100">rch-Tokyo, IBM Japan, Ltd. katsumasay@gmail.com Tsutomu Hirao NTT Communication Science Laboratories, NTT Corporation, Japan hirao.tsutomu@lab.ntt.co.jp Abstract For sentence compression, we propose new semantic constraints to directly capture the relations between a predicate and its arguments, whereas the existing approaches have focused on relatively shallow linguistic properties, such as lexical and syntactic information. These constraints are based on semantic roles and superior to the constraints of syntactic dependencies. Our empirical evaluation on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques. 1 Introduction Recent work in document summarization do not only extract sentences but also compress sentences. Sentence compression enables summarizers to reduce the redundancy in sentences and generate informative summaries beyond the extractive summarization systems (Knight and Marcu, 2002). Conventional approaches to sentence compression exploit various linguistic properties based on lexical information and syntactic dependencies (McDonald, 2006; Clarke and Lapata, 2008; Cohn and Lapata, 2008; G</context>
<context position="8710" citStr="Clarke and Lapata, 2008" startWordPosition="1369" endWordPosition="1372">) gains a higher weight than Formula (6) by learning on training data. As a result, our system gives “1-Harari” more chance to survive in compression. We also add some extensions of Formula (3) combined with dep(i, j, +d) and path(i, j, +l) which enhance SR constraints. Note, all our SR constraints are “predicate-driven” (only =&gt; nota as in Formula (13)). Because an argument is usually related to multiple predicates, it is difficult to model “argument-driven” formula. 3.1.2 Lexical and Syntactic Features For lexical and syntactic features, we mainly refer to the previous work (McDonald, 2006; Clarke and Lapata, 2008). The first two formulae in this section capture the relation of the tokens with their lexical and syntactic properties. The formula describing such a local property of a word form is word(i, +w) =&gt; inComp(i) (7) which implies that a token i is in compression with a weight that depends on the word form. For part-of-speech (POS), we add unigram and bigram features with the formulae, pos(i, +p) =&gt; inComp(i) (8) pos(i, +p1) n pos(i + 1, +p2) =&gt; inComp(i). (9) POS features are often more reasonable than word form features to combine with the other properties. The formula, pos(i, +p) n height(i, +n</context>
<context position="9994" citStr="Clarke and Lapata (2008)" startWordPosition="1589" endWordPosition="1592">height in a dependency tree. The next formula combines POS bigram features with dependency relations. pos(i, +p1) n pos(j, +p2) n dep(i, j, +d) =&gt; inComp(i). (11) Moreover, our model includes the following global formulae, dep(i, j, +d) n inComp(i) =&gt; inComp(j) (12) dep(i, j, +d) n inComp(i) a inComp(j) (13) which enforce the consistencies between head and modifier tokens. Formula (12) represents that if we include a head token in compression then its modifier must also be included. Formula (13) ensures that head and modifier words must be simultaneously kept in compression or dropped. Though Clarke and Lapata (2008) implemented these dependency constraints by ILP, we implement them by soft constraints of MLN. Note that Formula (12) expresses the same properties as Formula (3) replacing dep(i, j, +d) by role(i, j, +r). 4 Experiment and Result 4.1 Experimental Setup Our experimental setting follows previous work (Clarke and Lapata, 2008). As stated in Section 2, we employed the WNC Corpus. For preprocessing, we performed POS tagging by stanford-tagger. 5 and dependency parsing by MST-parser (McDonald et al., 2005). In addition, LTH 6 was exploited to perform both dependency parsing and SR labeling. We impl</context>
<context position="13082" citStr="Clarke and Lapata (2008)" startWordPosition="2085" endWordPosition="2088">ble 3: Results of Sentence Compression and system outputs by LTH. Then we calculated precision, recall, and F1 value for the set of role(predicate, argument). The training time of our MLN model are approximately 8 minutes on all training data, with 3.1GHz Intel Core i3 CPU and 4G memory. While the prediction can be done within 20 seconds on the test data. 4.2 Results Table 3 shows the results of our compression models by compression rate (CompR), dependencybased F1 (F1-Dep), and SRL-based F1 (F1-SRL). In our experiment, we have three models. McDonald is a re-implementation of McDonald (2006). Clarke and Lapata (2008) also re-implemented McDonald’s model with an ILP solver and experimented it on the WNC Corpus. 9 MLN with SRL and MLN w/o SRL are our Markov Logic models with and without SR Constraints, respectively. Note our three models have no constraint for the length of compression. Therefore, we think the compression rate of the better system should get closer to that of human compression. In comparison between MLN models and McDonald, the former models outperform the latter model on both F1-Dep and F1- SRL. Because MLN models have global constraints and can generate syntactically correct sentences. Ou</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31(1):399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Discourse constraints for document compression.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="14305" citStr="Clarke and Lapata, 2010" startWordPosition="2284" endWordPosition="2287">r concern is how a model with SR constraints is superior to a model without them. MLN with SRL outperforms MLN without SRL with a 7.6 points margin (F1-Dep). The compression rate of MLN with SRL goes up to 73.1% and gets close 9Clarke’s re-implementation got 60.1% for CompR and 36.0%pt for F1-Dep to that of gold standard. SRL-based evaluation also shows that SR constraints actually help extract correct predicate-argument structures. These results are promising to improve readability. It is difficult to directly compare our results with those of state-of-the-art systems (Cohn and Lapata, 2009; Clarke and Lapata, 2010; Galanis and Androutsopoulos, 2010) since they have different testing sets and the results with different compression rates. However, though our MLN model with SR constraints utilizes no large-scale data, it is the only model which achieves close on 60% in F1-Dep. 4.3 Error Analysis Table 4 indicates two critical examples which our SR constraints failed to compress correctly. For the first example, our model leaves an argument with its predicate because our SR constraints are “predicatedriven”. In addition, “say” is the main verb in this sentence and hard to be deleted due to the syntactic si</context>
</contexts>
<marker>Clarke, Lapata, 2010</marker>
<rawString>James Clarke and Mirella Lapata. 2010. Discourse constraints for document compression. Computational Linguistics, 36(3):411–441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression beyond word deletion.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1,</booktitle>
<pages>137--144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1378" citStr="Cohn and Lapata, 2008" startWordPosition="178" endWordPosition="181">Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques. 1 Introduction Recent work in document summarization do not only extract sentences but also compress sentences. Sentence compression enables summarizers to reduce the redundancy in sentences and generate informative summaries beyond the extractive summarization systems (Knight and Marcu, 2002). Conventional approaches to sentence compression exploit various linguistic properties based on lexical information and syntactic dependencies (McDonald, 2006; Clarke and Lapata, 2008; Cohn and Lapata, 2008; Galanis and Androutsopoulos, 2010). In contrast, our approach utilizes another property based on semantic roles (SRs) which improves weaknesses of syntactic dependencies. Syntactic dependencies are not sufficient to compress some complex sentences with coordination, with passive voice, and with an auxiliary verb. Figure 1 shows an example with a coordination structure. &apos; &apos;This example is from Written News Compression Corpus(http://jamesclarke.net/research/resources). Ryu Iida Department of Computer Science, Tokyo Institute of Technology, Japan ryu-i@cl.cs.titech.ac.jp Manabu Okumura Precisio</context>
</contexts>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2008. Sentence compression beyond word deletion. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 137–144. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression as tree transduction.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>34--637</pages>
<contexts>
<context position="14280" citStr="Cohn and Lapata, 2009" startWordPosition="2280" endWordPosition="2283">y correct sentences. Our concern is how a model with SR constraints is superior to a model without them. MLN with SRL outperforms MLN without SRL with a 7.6 points margin (F1-Dep). The compression rate of MLN with SRL goes up to 73.1% and gets close 9Clarke’s re-implementation got 60.1% for CompR and 36.0%pt for F1-Dep to that of gold standard. SRL-based evaluation also shows that SR constraints actually help extract correct predicate-argument structures. These results are promising to improve readability. It is difficult to directly compare our results with those of state-of-the-art systems (Cohn and Lapata, 2009; Clarke and Lapata, 2010; Galanis and Androutsopoulos, 2010) since they have different testing sets and the results with different compression rates. However, though our MLN model with SR constraints utilizes no large-scale data, it is the only model which achieves close on 60% in F1-Dep. 4.3 Error Analysis Table 4 indicates two critical examples which our SR constraints failed to compress correctly. For the first example, our model leaves an argument with its predicate because our SR constraints are “predicatedriven”. In addition, “say” is the main verb in this sentence and hard to be delete</context>
</contexts>
<marker>Cohn, Lapata, 2009</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2009. Sentence compression as tree transduction. Journal of Artificial Intelligence Research, 34:637–674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitrios Galanis</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>An extractive supervised two-stage method for sentence compression. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>885--893</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1414" citStr="Galanis and Androutsopoulos, 2010" startWordPosition="182" endWordPosition="185">) demonstrates that our system achieves results comparable to other state-of-the-art techniques. 1 Introduction Recent work in document summarization do not only extract sentences but also compress sentences. Sentence compression enables summarizers to reduce the redundancy in sentences and generate informative summaries beyond the extractive summarization systems (Knight and Marcu, 2002). Conventional approaches to sentence compression exploit various linguistic properties based on lexical information and syntactic dependencies (McDonald, 2006; Clarke and Lapata, 2008; Cohn and Lapata, 2008; Galanis and Androutsopoulos, 2010). In contrast, our approach utilizes another property based on semantic roles (SRs) which improves weaknesses of syntactic dependencies. Syntactic dependencies are not sufficient to compress some complex sentences with coordination, with passive voice, and with an auxiliary verb. Figure 1 shows an example with a coordination structure. &apos; &apos;This example is from Written News Compression Corpus(http://jamesclarke.net/research/resources). Ryu Iida Department of Computer Science, Tokyo Institute of Technology, Japan ryu-i@cl.cs.titech.ac.jp Manabu Okumura Precision and Intelligence Laboratory, Tokyo</context>
<context position="14341" citStr="Galanis and Androutsopoulos, 2010" startWordPosition="2288" endWordPosition="2292">with SR constraints is superior to a model without them. MLN with SRL outperforms MLN without SRL with a 7.6 points margin (F1-Dep). The compression rate of MLN with SRL goes up to 73.1% and gets close 9Clarke’s re-implementation got 60.1% for CompR and 36.0%pt for F1-Dep to that of gold standard. SRL-based evaluation also shows that SR constraints actually help extract correct predicate-argument structures. These results are promising to improve readability. It is difficult to directly compare our results with those of state-of-the-art systems (Cohn and Lapata, 2009; Clarke and Lapata, 2010; Galanis and Androutsopoulos, 2010) since they have different testing sets and the results with different compression rates. However, though our MLN model with SR constraints utilizes no large-scale data, it is the only model which achieves close on 60% in F1-Dep. 4.3 Error Analysis Table 4 indicates two critical examples which our SR constraints failed to compress correctly. For the first example, our model leaves an argument with its predicate because our SR constraints are “predicatedriven”. In addition, “say” is the main verb in this sentence and hard to be deleted due to the syntactic significance. The second example in Ta</context>
</contexts>
<marker>Galanis, Androutsopoulos, 2010</marker>
<rawString>Dimitrios Galanis and Ion Androutsopoulos. 2010. An extractive supervised two-stage method for sentence compression. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 885–893, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic-semantic analysis with propbank and nombank.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>183--187</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4202" citStr="Johansson and Nugues, 2008" startWordPosition="617" endWordPosition="621"> A2 AM-TMP AM-LOC AM-ADV AM-DIS In Compression / Total 1454 / 1607 1916 / 2208 427 / 490 261 / 488 134 / 214 115 / 213 8 / 85 Ratio 0.905 0.868 0.871 0.535 0.626 0.544 0.094 Table 1: Statistics of Arguments in Compression tions in the Written News Compression (WNC) Corpus. It has 82 documents (1,629 sentences). We divided them into three: 55 documents are used for training (1106 sentences); 10 for development (184 sentences); 17 for testing (339 sentences). Our investigation was held in training data. There are 3137 verbal predicates and 7852 unique arguments. We performed SR labeling by LTH (Johansson and Nugues, 2008), an SR labeler for CoNLL2008 shared task. Based on the SR labels annotated by LTH, we investigated that, for all predicates in compression, how many their arguments were also in. Table 1 shows the survival ratio of main arguments in compression. Labels A0, A1, and A2 are complement case roles and over 85% of them survive with their predicates. On the other hand, for modifier arguments (AM-X), survival ratios are down to lower than 65%. Our SR constraints implement the difference of survival ratios by SR labels. Note that dependency labels SBJ and OBJ generally correspond to SR labels A0 and A</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic-semantic analysis with propbank and nombank. In Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 183–187. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="1171" citStr="Knight and Marcu, 2002" startWordPosition="150" endWordPosition="153"> as lexical and syntactic information. These constraints are based on semantic roles and superior to the constraints of syntactic dependencies. Our empirical evaluation on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques. 1 Introduction Recent work in document summarization do not only extract sentences but also compress sentences. Sentence compression enables summarizers to reduce the redundancy in sentences and generate informative summaries beyond the extractive summarization systems (Knight and Marcu, 2002). Conventional approaches to sentence compression exploit various linguistic properties based on lexical information and syntactic dependencies (McDonald, 2006; Clarke and Lapata, 2008; Cohn and Lapata, 2008; Galanis and Androutsopoulos, 2010). In contrast, our approach utilizes another property based on semantic roles (SRs) which improves weaknesses of syntactic dependencies. Syntactic dependencies are not sufficient to compress some complex sentences with coordination, with passive voice, and with an auxiliary verb. Figure 1 shows an example with a coordination structure. &apos; &apos;This example is </context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Kevin Knight and Daniel Marcu. 2002. Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>716--724</pages>
<location>Beijing, China,</location>
<contexts>
<context position="2993" citStr="Liu and Gildea (2010)" startWordPosition="419" endWordPosition="422">dependency relation between Harari and became directly. SRs allow us to model the relations between a predicate and its arguments in a direct fashion. SR constraints are also advantageous in that we can compress sentences with semantic information. In Figure 1, became has three arguments, Harari as A1, businessman as A2, and shortly afterward as AM-TMP. As shown in this example, shortly afterword can be omitted (shaded boxes). In general, modifier arguments like AM-TMP or AM-LOC are more likely to be reduced than complement cases like A0-A4. We can implement such properties by SR constraints. Liu and Gildea (2010) suggests that SR features contribute to generating more readable sentence in machine translation. We expect that SR features also help our system to improve readability in sentence compression and summarization. 2 Why are Semantic Roles Useful for Compressing Sentences? Before describing our system, we show the statistics in terms of predicates, arguments and their rela349 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 349–353, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Label A0 A1 A2 AM-TMP AM-LOC </context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic role features for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 716–724, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 523–530, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative sentence compression with soft syntactic evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>297--304</pages>
<contexts>
<context position="1330" citStr="McDonald, 2006" startWordPosition="172" endWordPosition="173"> on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques. 1 Introduction Recent work in document summarization do not only extract sentences but also compress sentences. Sentence compression enables summarizers to reduce the redundancy in sentences and generate informative summaries beyond the extractive summarization systems (Knight and Marcu, 2002). Conventional approaches to sentence compression exploit various linguistic properties based on lexical information and syntactic dependencies (McDonald, 2006; Clarke and Lapata, 2008; Cohn and Lapata, 2008; Galanis and Androutsopoulos, 2010). In contrast, our approach utilizes another property based on semantic roles (SRs) which improves weaknesses of syntactic dependencies. Syntactic dependencies are not sufficient to compress some complex sentences with coordination, with passive voice, and with an auxiliary verb. Figure 1 shows an example with a coordination structure. &apos; &apos;This example is from Written News Compression Corpus(http://jamesclarke.net/research/resources). Ryu Iida Department of Computer Science, Tokyo Institute of Technology, Japan </context>
<context position="8684" citStr="McDonald, 2006" startWordPosition="1367" endWordPosition="1368">fact, Formula (5) gains a higher weight than Formula (6) by learning on training data. As a result, our system gives “1-Harari” more chance to survive in compression. We also add some extensions of Formula (3) combined with dep(i, j, +d) and path(i, j, +l) which enhance SR constraints. Note, all our SR constraints are “predicate-driven” (only =&gt; nota as in Formula (13)). Because an argument is usually related to multiple predicates, it is difficult to model “argument-driven” formula. 3.1.2 Lexical and Syntactic Features For lexical and syntactic features, we mainly refer to the previous work (McDonald, 2006; Clarke and Lapata, 2008). The first two formulae in this section capture the relation of the tokens with their lexical and syntactic properties. The formula describing such a local property of a word form is word(i, +w) =&gt; inComp(i) (7) which implies that a token i is in compression with a weight that depends on the word form. For part-of-speech (POS), we add unigram and bigram features with the formulae, pos(i, +p) =&gt; inComp(i) (8) pos(i, +p1) n pos(i + 1, +p2) =&gt; inComp(i). (9) POS features are often more reasonable than word form features to combine with the other properties. The formula,</context>
<context position="13056" citStr="McDonald (2006)" startWordPosition="2083" endWordPosition="2084">dard 73.3% – – Table 3: Results of Sentence Compression and system outputs by LTH. Then we calculated precision, recall, and F1 value for the set of role(predicate, argument). The training time of our MLN model are approximately 8 minutes on all training data, with 3.1GHz Intel Core i3 CPU and 4G memory. While the prediction can be done within 20 seconds on the test data. 4.2 Results Table 3 shows the results of our compression models by compression rate (CompR), dependencybased F1 (F1-Dep), and SRL-based F1 (F1-SRL). In our experiment, we have three models. McDonald is a re-implementation of McDonald (2006). Clarke and Lapata (2008) also re-implemented McDonald’s model with an ILP solver and experimented it on the WNC Corpus. 9 MLN with SRL and MLN w/o SRL are our Markov Logic models with and without SR Constraints, respectively. Note our three models have no constraint for the length of compression. Therefore, we think the compression rate of the better system should get closer to that of human compression. In comparison between MLN models and McDonald, the former models outperform the latter model on both F1-Dep and F1- SRL. Because MLN models have global constraints and can generate syntactic</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative sentence compression with soft syntactic evidence. In Proceedings of EACL, pages 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine Learning,</booktitle>
<pages>62--1</pages>
<contexts>
<context position="5216" citStr="Richardson and Domingos, 2006" startWordPosition="796" endWordPosition="800">ents (AM-X), survival ratios are down to lower than 65%. Our SR constraints implement the difference of survival ratios by SR labels. Note that dependency labels SBJ and OBJ generally correspond to SR labels A0 and A1, respectively. But their total numbers are 777 / 919 (SBJ) and 918 / 1211 (OBJ) and much fewer than A0 and A1 labels. Thus, SR labels can connect much more arguments to their predicates. 3 Approach This section describes our new approach to sentence compression. In order to introduce rich syntactic and semantic constraints to a sentence compression model, we employ Markov Logic (Richardson and Domingos, 2006). Since Markov Logic supports both soft and hard constraints, we can implement our SR constraints in simple and direct fashion. Moreover, implementations of learning and inference methods are already provided in existing Markov Logic interpreters such as Alchemy 2 and Markov thebeast. 3 Thus, we can focus our effort 2http://alchemy.cs.washington.edu/ 3http://code.google.com/p/thebeast/ on building a set of formulae called Markov Logic Network (MLN). So, in this section, we describe our proposed MLN in detail. 3.1 Proposed Markov Logic Network First, let us define our MLN predicates. We summari</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62(1-2):107–136.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Annie Zaenen</author>
</authors>
<title>Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical-functional grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume</booktitle>
<volume>1</volume>
<pages>118--125</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10800" citStr="Riezler et al. (2003)" startWordPosition="1716" endWordPosition="1719">d) by role(i, j, +r). 4 Experiment and Result 4.1 Experimental Setup Our experimental setting follows previous work (Clarke and Lapata, 2008). As stated in Section 2, we employed the WNC Corpus. For preprocessing, we performed POS tagging by stanford-tagger. 5 and dependency parsing by MST-parser (McDonald et al., 2005). In addition, LTH 6 was exploited to perform both dependency parsing and SR labeling. We implemented our model by Markov Thebeast with Gurobi optimizer. 7 Our evaluation consists of two types of automatic evaluations. The first evaluation is dependency based evaluation same as Riezler et al. (2003). We performed dependency parsing on gold data and system outputs by RASP. 8 Then we calculated precision, recall, and F1 for the set of label(head, modifier). In order to demonstrate how well our SR constraints keep correct predicate-argument structures in compression, we propose SRL based evaluation. We performed SR labeling on gold data 5http://nlp.stanford.edu/software/tagger.shtml 6http://nlp.cs.lth.se/software/semantic_ parsing:_propbank_nombank_frames 7http://www.gurobi.com/ 8http://www.informatics.susx.ac.uk/research/ groups/nlp/rasp/ inComp(i) Token i is in compression pred(i) role(i,</context>
</contexts>
<marker>Riezler, King, Crouch, Zaenen, 2003</marker>
<rawString>Stefan Riezler, Tracy H. King, Richard Crouch, and Annie Zaenen. 2003. Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical-functional grammar. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 118–125. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>