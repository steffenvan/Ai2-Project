<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.601351" genericHeader="abstract">
BIDIRECTIONAL PARSING OF
LEXICALIZED TREE ADJOINING GRAMMARS*
</sectionHeader>
<bodyText confidence="0.473949333333333">
Alberto LaveIli and Giorgio Satta
Istituto per la Ricerca Scientifica e Tecnologica
I - 38050 Povo TN, Italy
</bodyText>
<email confidence="0.83069">
e-mail: lavelli/satta@irst.it
</email>
<sectionHeader confidence="0.986791" genericHeader="introduction">
Abstract
</sectionHeader>
<bodyText confidence="0.999734">
In this paper a bidirectional parser for Lexicalized
Tree Adjoining Grammars will be presented. The
algorithm takes advantage of a peculiar characteristic
of Lexicalized TAGs, i.e. that each elementary tree is
associated with a lexical item, called its anchor. The
algorithm employs a mixed strategy: it works bot-
tom-up from the lexical anchors and then expands
(partial) analyses making top-down predictions. Even
if such an algorithm does not improve the worst-case
time bounds of already known TAGs parsing meth-
ods, it could be relevant from the perspective of
linguistic information processing, because it em-
ploys lexical information in a more direct way.
</bodyText>
<sectionHeader confidence="0.99145" genericHeader="method">
1. Introduction
</sectionHeader>
<bodyText confidence="0.990121160714286">
Tree Adjoining Grammars (TAGs) are a formal-
ism for expressing grammatical knowledge that ex-
tends the domain of locality of context-free gram-
mars (CFGs). TAGs are tree rewriting systems spec-
ified by a finite set of elementary trees (for a detailed
description of TAGs, see (Joshi, 1985)). TAGs can
cope with various kinds of unbounded dependencies
in a direct way because of their extended domain of
locality; in fact, the elementary trees of TAGs are
the appropriate domains for characterizing such de-
pendencies. In (ICroch and Joshi, 1985) a detailed dis-
cussion of the linguistic relevance of TAGs can be
found.
Lexicalized Tree Adjoining Grammars (Schabes et
al., 1988) are a refinement of TAGs such that each
elementary tree is associated with a lexical item,
called the anchor of the tree. Therefore, Lexicalized
TAGs conform to a common tendency in modem
theories of grammar, namely the attempt to embed
grammatical information within lexical items.
Notably, the association between elementary trees
and anchors improves also parsing performance, as
will be discussed below.
Various parsing algorithms for TAGs have been
proposed in the literature: the worst-case time com-
plexity varies from 0(n4 log n) (Harbusch, 1990) to
0(n6) (Vijay-Shanker and Joshi, 1985, Lang, 1990,
Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988).
`Part of this work was done while Giorgio Satta was
completing his Doctoral Dissertation at the
University of Padova (Italy). We would like to thank
Yves Schabes for his valuable comments. We would
also like to thank Anne AbelIle. All errors are of
course our own.
As for Lexicalized TAGs, in (Schabes et al., 1988) a
two step algorithm has been presented: during the
first step the trees corresponding to the input string
are selected and in the second step the input string is
parsed with respect to this set of trees. Another paper
by Schabes and Joshi (1989) shows how parsing
strategies can take advantage of lexicalization in
order to improve parsers&apos; performance. Two major
advantages have been discussed in the cited work:
grammar filtering (the parser can use only a subset
of the entire grammar) and bottom-up information
(further constraints are imposed on the way trees can
be combined). Given these premises and starting
from an already known method for bidirectional CF
language recognition (Satta and Stock, 1989), it
seems quite natural to propose an anchor-driven bidi-
rectional parser for Lexicalized TAGs that tries to
make more direct use of the information contained
within the anchor&apos;s. The algorithm employs a mixed
strategy: it work&apos;s bottom-up from the lexical an-
chors and then expands (partial) analyses making
top-down predictions.
</bodyText>
<sectionHeader confidence="0.797116" genericHeader="method">
2. Overview of the Algorithm
</sectionHeader>
<bodyText confidence="0.999755576923077">
The algorithm that will be presented is a recog-
nizer for Tree Adjoining Languages: a parser can be
obtained from such a recognizer by additional pro-
cessing (see final section). As an introduction to the
next section, an informal description of the studied
algorithm is here presented. We assume the follow-
ing definition of TAGs.
Definition 1 A Tree Adjoining Grammar (TAG)
is a 5-tuple G=(VN, VE, S. I, A), where VN is a
finite set of non-terminal symbols, VE is a finite set
of terminal symbols, SE VN is the start symbol,!
and A are two finite sets of trees, called initial trees
and auxiliary trees respectively. The trees in the set
luA are called elementary trees.
We assume that the reader is familiar with the
definitions of adjoining operation and foot node (see
(Joshi, 1985)).
The proposed algorithm is a tabular method that
accepts a TAG G and a string w as input, and decides
whether wE L(G). This is done by recovering
(partial) analyses for substrings of w and by combin-
ing them. More precisely, the algorithm factorizes
analyses of derived trees by employing a specific
structure called state. Each state retains a pointer to a
node n in some tree aE RA, along with two addi-
tional pointers (called !dot and rdot) to n itself or to
</bodyText>
<equation confidence="0.494101">
- 27 -
</equation>
<bodyText confidence="0.999894023255814">
its children in a. Let an be a tree obtained from the
maximal subtree of a with root n, by means of
some adjoining operations. Informally speaking and
with a little bit of simplification, the two following
cases are possible. First, if Idot, rdot*n, state s indi-
cates that the part of an dominated by the nodes
between ldot and rdot has already been analyzed by
the algorithm. Second, if Idot=rdot=n, state s indi-
cates that the whole of an has already been analyzed,
including possible adjunctions to its root n.
Each state s will be inserted into a recognition
matrix T, which is a square matrix indexed from 0 to
nw, where nw is the length of w. If state s belongs
to the component ti j of T, the partial analysis (the
part of an) represented by s subsumes the substring
of w that starts from position i and ends at position
j, except for the items dominated by a possible foot
node in an (this is explicitly indicated within s).
The algorithm performs the analysis of w start-
ing from the anchor node of every tree in G whose
category is the same as an item in w. Then it tries to
extend each partial analysis so obtained, by climbing
each tree along the path that connects the anchor
node to the root node; in doing this, the algorithm
recognizes all possible adjunctions that are present in
w. Most important, every subtree yof a tree derived
from a€ luA, such that y dOes not contain the an-
chor node of a, is predicted and analyzed by the algo-
rithm in a top-down fashion, from right to left (left
to right) if it is located to the left (right) of the path
that connects the anchor node to the root node in a.
The combinations of partial analyses (states) and
the introduction of top-down prediction states is car-
ried out by means of the application of six proce-
dures that will be defined below. Each procedure ap-
plies to some states, trying to &amp;quot;move&amp;quot; outward one
of the two additional pointers within each state.
The algorithm stops when no state in T can be
further expanded. If some state has been obtained that
subsumes the input string and that represents a com-
plete analysis for some tree with the root node of
category S. the algorithm succeeds in the recogni-
tion.
</bodyText>
<sectionHeader confidence="0.957366" genericHeader="method">
3. The Algorithm
</sectionHeader>
<bodyText confidence="0.9996439">
In the following any (elementary or derived) tree
will be denoted by a pair (N, E), where N is a finite
set of nodes and E is a set of ordered pairs of nodes,
called arcs. For every tree o(N, E), we define five
functions of N into Nu (I) called father, leftmost-
child, rightmost-child, left-sibling, and right-sibling
(with the obvious meanings). For every tree ct(N,
E) and every node n€ N, a function domaina is de-
fined such that domaina(n)=I3, where /3 is the maxi-
mal subtree in a whose root is n.
</bodyText>
<subsectionHeader confidence="0.916952">
&apos;The symbol &amp;quot;1&amp;quot; denotes here the undefined element.
</subsectionHeader>
<bodyText confidence="0.969107833333333">
For any TAG G and for every node n in some
tree in G, we will write cat(n)=X, XE VNUVE•
whenever X is the symbol associated to n in G. For
every node n in some tree in G, such that
cat(n)e VN, the set Adjoin(n) contains all root nodes
of auxiliary trees that can be adjoined to n in G.
Furthermore, a function 2&apos; is defined such that, for
every tree ae /uA, it holds that r(a)=n, where n
indicates the anchor node of a. In the following we
assume that the anchor nodes in G are not labelled
by the null (syntactic) category symbol e. The set of
all nodes that dominate the anchor node of some tree
in /uA will be called Middle-nodes (anchor nodes
included); for every tree o(N, E), the nodes neN in
Middle-nodes divide a in two (possibly empty) left
and right portions. The set Left-nodes (Right-nodes)
is defined as the set of all nodes in the left (right)
portion of some tree in /uA. Note that the three sets
Middle-nodes, Left-nodes and Right-nodes constitute
a partition of the set of all nodes of trees in /uA.
The set of all foot nodes in the trees in A will be
called Foot-nodes.
Let w=al an„„ nw?.1, be a symbol string; we
will say that nw is the length of w.
Definition 2 A state is defined to be any 8-tuple
En, Ido:, lpos, rdot, rpos.fj f, m] such that:
n, Mot, rdot are nodes in some tree cze ILA;
Ipos,rpose (left, right);
Air are either the symbol &amp;quot;-&amp;quot; or indices in the
input string such that far;
</bodyText>
<subsectionHeader confidence="0.395937">
ME (-, rm,
</subsectionHeader>
<bodyText confidence="0.929390522727273">
The first component in a state s indicates a node
n in some tree a, such that s represents some partial
analysis for the subtree domaina(n). The second
component ado° may be n or one of its children in
a: if Ipos=left, domainaadot) is included in the par-
tial analysis represented by s, otherwise it is not.
The components rdot and rpos have a symmetrical
interpretation. The pair 11, fr represents the part of
the input string that is subsumed by the possible
foot node in domaina(n). A binary operator indicated
with the symbol ED is defined to combine the com-
ponents ft. Jr in different states; such an operator is
defined as follows: of equals f iff= -, it equals f if
fr= -, and it is undefined otherwise. Finally, the com-
ponent m is a marker that will be used to block ex-
pansion at one side for a state that has already been
subsumed at the other one. This particular technique
is called subsumption test and is discussed in (Satta
and Stock, 1989). The subsumption test has the
main purpose of blocking analysis proliferation due
to the bidirectional behaviour of the method.
Let 1s be the set of all possible states; we will
use a particular equivalence relation Q-C_ Is&gt;ds de-
fined as follows. For any pair of states s, s&apos;, sQs&apos;
holds if and only if every component in s but the
last one (the m component) equals the corresponding
- 28 -
component in s&apos;.
The algorithm that will be presented employs the
following function.
Definition 3 A function F is defined as follows:2
F: VE P(Is)
F(a) = (s I s=1father(n), n, left, n, right, -, -],
cat(n)=a and T(a)=n for some tree
ae /vA )
The details of the algorithm are as follows.
Algorithm 1
Let G=(VN, VE, S. I, A) be a TAG and let w=a1
anw, n?_1, be any string in VE* . Let T be a recogni-
tion matrix of size (nw+1)x(nw+1) whose compo-
nents tij are indexed from 0 to nw for both sides.
Develop matrix T in the following way (a new state
s is added to some entry in T only if sQsq does not
hold for any state sq already present in that entry).
</bodyText>
<listItem confidence="0.979555">
1. For every state SE F(ad, 15i5.nw, add s to
2. Process each state s added to some entry in T by
</listItem>
<bodyText confidence="0.757449">
means of the following procedures (in any order):
</bodyText>
<construct confidence="0.7650695">
Left-expander(s), Right-expander(s),
Move-dot-left(s), Move-dot-right(s),
Completer(s), Adjoiner(s);
until no state can be further added.
</construct>
<listItem confidence="0.886826">
3. if s=[n, n, left, n, right, -, -JE 10,nw for some
node n such that cat(n)=S and n is the root of a
tree in I, then output(true), else output (false).
</listItem>
<bodyText confidence="0.9882605">
The six procedures mentioned above are defined
in the following.
</bodyText>
<table confidence="0.4033165">
Procedure 1 Left-expander
Input A state s=[n, ldot, lpos, rdot, rpos,
in
Precondition m#Im, ldomn and lpos—right.
Description
Case 1: 1dOtEVN, Idote Foot-nodes.
</table>
<tableCaption confidence="0.494974">
Step 1: For every state s&amp;quot;=[Idot, Idot, left, Idol,
</tableCaption>
<bodyText confidence="0.961822">
right, fi&amp;quot;, fr&amp;quot;, -] in tr,i, add state s&apos;=[n,
ldot, left, rdot, rpos, frOir&amp;quot;, -] to to;
set m=rm in s if left-expansion is successful;
Step 2: Add state s&apos;.[Idot, ldot, right, ldot, right,
-] to ti,j. For every state s&amp;quot;=[n&amp;quot;, n&amp;quot;, left,
n&amp;quot;, right, fr, fr&amp;quot;, -] in tr,i, i&apos;&lt; I,
n&amp;quot;EAdjoin(Idot), add state s&apos;=[ldot, !dot, right,
Idol, right, -, -] to If,&amp;quot; fr&amp;quot;.
</bodyText>
<sectionHeader confidence="0.69692" genericHeader="method">
Case 2: IdOlEVE.3
</sectionHeader>
<bodyText confidence="0.98286">
If ai=cat(Idot), add state s&apos;=[n, Idol, left, rdot,
rpos, fr, -] to ti.ii (if tat(ldot)=e, i.e. the null
category symbol, add state s&apos; to V; set m=rm
in s if left-expansion is successful.
</bodyText>
<footnote confidence="0.7406926">
Case 3: IdotE Foot-nodes.
Add state s&apos;=[n, ldot, left, rdot, rpos, -Ito
2Given a generic set A, the symbol T(14) denotes the
set of all the subsets of A (the power set of A).
3We assume that al) is undefined.
</footnote>
<table confidence="0.607022428571429">
for every and set m=rm in s.
Procedure 2 Right-expander
Input A state s=[n, Idol, lpos, rdot, rpos, ft, fr, m]
in
Precondition nmrm, rdott-n and rpos=left.
Description
Case 1: rdotE VN, rdote Foot-nodes.
</table>
<tableCaption confidence="0.284854">
Step 1: For every state s&amp;quot;=[rdot, rdot, left, rdot,
right, fi&amp;quot;, fr&amp;quot;, -] in tjJ., j5.1, add state s&apos;=[n,
</tableCaption>
<bodyText confidence="0.488302875">
!dot, lpos, rdot, right, fieft-, -] to
tii•; set m = /m in s if left-expansion is
successful;
Step 2: Add state s&apos;-[rdot, rdot, left, rdot, left, -,
-Ito tjj. For every state s&amp;quot;=[n&amp;quot;, n&amp;quot;, left,
n&amp;quot;, right, fi&amp;quot;, fr&amp;quot;, -] in tjJ,, j&lt; j&apos;,
n&amp;quot;EAdjoin(rdot), add state s&apos;=[rdot, rdot, left,
rdot, left,-,-,-Ito ifr&amp;quot;,fr&apos;&apos;.
</bodyText>
<equation confidence="0.242283">
Case 2: rdotEVz.4
</equation>
<bodyText confidence="0.52769075">
If aki_i=cat(rdot), add state s&apos;=[n, Idol, lpos, rdot,
right, AA., -] to tij+1 (if cat(rdot)=e, i.e. the
null category symbol, add state s&apos; to tii); set
m=bn in s if right-expansion is successful.
</bodyText>
<figure confidence="0.699817227272727">
Case 3: rdotEFoot-nodes.
Add state s&apos;=[n, ldot, lpos, rdot, right, j, j&apos;, -] to
tij,, for every j5...r, and set m=im in s. ci
Procedure 3 Move-dot-left
Input A state s=[n, Idol, lpos, rdot, rpos, fi. fr, m]
in
Precondition m#Im, and Idot*n, Ipos=left, or
Idot=n, Ipos=right.
Description
Case 1: Ipos=right.
Add state s&apos;=[n, rightmost-child(n), right, rdot,
rpos, fr, -Ito ti J; set m=rm ins;
Case 2: Ipos=left, left-sibling(n)*1.
Add state s&apos;=[n, left-sibling(ldot), right, rdot,
rpos, fj, fr. -] to tii; set m=rm in s.
Case 3: Ipos=left, left-sibling(Idot)=1.
Add state s&apos;=[n, n, left, rdot, rpos, fj, fr, -Ito tiJ
and set m=rm in s.
Procedure 4 Move-dot-right
Input A state s=[n, Idol, lpos, rdot, rpos, fr, m]
in t
Precondition m*rm, and rdomn, rpos=right, or
rdot=n,rpos=left.
Description
Case 1: rpos=left.
Add state s&apos;=[n, &apos;dot, lpos, leftmost-child(n), left,
fb fr, -] to ti.j; set m=lm in s;
Case 2: rpos=rtght,right-sibling(n)*.L.
Add state s&apos;=[n, Idol, lpos, right-sibling(rdot),
left, fr, -] to tiJ; set m=lm in s.
Case 3: rpos=right, right-sibling(ldot)=.1.
Add state s&apos;=[n, &apos;dot, lpos, n, right, kJ&apos;, -] to
and set nt=lm in s.
4See note 3.
- 29 -
Procedure 5 Completer
Input A state s=[n, n, left, n, right, fr, m] in tij.
Precondition n is not the root of an auxiliary tree.
Description
Case 1: nE Middle-nodes.
Add state s&apos;.(father(n), n, left, n, right, fr, -]
to tij.
Case 2: neLeft-nodes.
For every state s&amp;quot;=[n&amp;quot;, &apos;dot&amp;quot;, right, rdot, rpos,
</figure>
<construct confidence="0.5139517">
fr&amp;quot;, in tjx, f&gt;j, such that ldor=n and
m&amp;quot;*/m, add state s&apos;=[n&amp;quot;, ldot&amp;quot;, left, rdot, rpos,
Mph&amp;quot;. frefr&amp;quot;, -1 in ticr; if left-expansion is
successful for state s&amp;quot;, set m&amp;quot;=rm in s&amp;quot;.
Case 3: neRight-nodes.
For every state s&amp;quot;=[n&amp;quot;, Idol, lpos, rdot&amp;quot;, left, f&amp;quot;,
fr&amp;quot;, m&amp;quot;] in to, i&apos;&lt;i, such that rdot&amp;quot;=n and
m&apos;Wm, add state s&apos;=-[n&amp;quot;, &apos;dot, lpos, rdot&amp;quot;, right,
PM&amp;quot;, frefr&amp;quot;, -] in to; if right-expansion is
successful for state s&amp;quot;, set m&amp;quot;=/m in s&amp;quot;.
</construct>
<figure confidence="0.96137375">
Procedure 6 Adjoiner
Input A state s=[n, n, left, right, fr, m] in tij.
Precondition Void.
Description
</figure>
<figureCaption confidence="0.751508">
Case 1: apply always.
</figureCaption>
<construct confidence="0.836887428571429">
For every state s&amp;quot;=[n&amp;quot;, n&amp;quot;, left, n&amp;quot;, right, i, j, -1
in to% i&apos;5.i, j&apos;?4, n&amp;quot;eAdjoin(n), add state s&apos;=En,
n, left, n, right, fr, -}to /iv.
Case 2: n is the root of an auxiliary tree.
Step 1: For every state s&amp;quot;=[n&amp;quot;, n&amp;quot;, left, n&amp;quot;,
right, Ii&amp;quot;. fr&amp;quot;, -1 in /far, such that
ne Adjoin(n&amp;quot;), add state s&apos;=In&amp;quot;, n&amp;quot;, left, n&amp;quot;,
right, fi&amp;quot;, fr&amp;quot;, -Ito tij.
Step 2: For every state s&amp;quot;—[n&amp;quot;, Idot&amp;quot;, right, rdot,
rpos, fr&amp;quot;, m&amp;quot;] in tjx, I&gt;j, such that
Adjoin(ldot&amp;quot;) and m&amp;quot;Thn, add state
s&apos;=[Idot&amp;quot;, Idol&amp;quot;, right, ldot&amp;quot;, right, -, -Ito
tfrjr.
Step 3: For every state s&amp;quot;=[n&amp;quot;, &apos;dot, lpos, rdot&amp;quot;,
</construct>
<bodyText confidence="0.902603666666667">
left, fi&amp;quot;, fr&amp;quot;, m&amp;quot;1 in i&apos;&lt;i, such that
ne Adjoin(rdot&amp;quot;) and m&amp;quot;#rm, add state
s&apos;=[rdot&amp;quot;, rdot&amp;quot;, left, rdot&amp;quot;, left, -, -] to
</bodyText>
<sectionHeader confidence="0.994353" genericHeader="method">
4. Formal Results
</sectionHeader>
<bodyText confidence="0.989679555555556">
Some definitions will be introduced in the fol-
lowing, in order to present some interesting proper-
ties of Algorithm 1. Formal proofs of the statements
below can be found in (Satta, 1990).
Let n be a node in some tree aE/uA. Each state
s=[n, Idol, lpos, rdot, rpos, f, fr, m] in Is identifies
a tree forest 0(s) composed of all maximal subtrees
in a whose roots are &amp;quot;spanned&amp;quot; by the two positions
ldot and rdot. If ldomn, we assume that the maximal
subtree in a whose root is Idol is included in 0(s) if
and only if /pos=left (the mirror case holds w.r.t.
rdot). We define the subsumption relation 5. on Is as
follows: iff state s has the same first component
as state s&apos; and 0(s) is included in 0(s&apos;). We also say
that a forest O(s) derives a forest ty (0(s) 4 tv)
whenever iy can be obtained from (/)(s) by means of
some adjoining operations. Finally, E denotes the
immediate dominance relation on nodes of aeluA,
and iga) denotes the foot node of a (if oce A). The
following statement characterizes the set of all states
inserted in T by Algorithm 1.
Theorem 1 Let n be a node in aE luA and let n&apos;
be the lowest node in a such that n&apos;e Middle-nodes
and (n, 06E4; let also s=[n, ldot, lpos, rdot, rpos,
m] be a state in I. Algorithm 1 inserts a state
s&apos;, s5s&apos;, in ti_hij+h,, hi,h2?_0, if and only if one of
the following conditions is met:
</bodyText>
<figureCaption confidence="0.8516265">
(i) ne Middle-nodes (n&apos;=n) and (P(s) ty, where v/
spans ai.+1 ... di (with the exception of string
afr if ir(a) is included in 0(s)) (see
Figure 1);
</figureCaption>
<bodyText confidence="0.957485">
(ii) ne Left-nodes, s=s&apos; , h1=h2=0 and 0(s) 4
where yi spans ai+i ... di (with the exception of
string afi+i ... at; if It(a) is included in 0(s)).
Moreover, n&apos; is the root of a (maximal) subtree
in a such that 1&apos; 1//, ty strictly includes tp&apos; and
every tree /3E A that has been adjoined to some
node in the path from n&apos; to n spans a string that
is included in al ai (see Figure 2);
(iii) the symmetrical case of (ii).
</bodyText>
<figureCaption confidence="0.561249">
Figure 2.
In order to present the computational complexity
of Algorithm 1, some norms for TAGs are here in-
troduced. Let A be a set of nodes in some trees of a
TAG G; we define
</figureCaption>
<figure confidence="0.6983174">
= Ichildren(n)lk
nE
, The following result refers to the Random Access
Machine model of computation.
a i ••• aft X a f
</figure>
<figureCaption confidence="0.930694">
Figure 1.
</figureCaption>
<figure confidence="0.929149714285714">
a&apos;
a
included in
ar- a.
4)(0
4.r.a af r+i
- 30 -
</figure>
<bodyText confidence="0.902929428571429">
Theorem 2 If some auxiliary structures (vector of
lists) are used by Algorithm I for the bookkeeping
of all states that correspond to completely analyzed
auxiliary trees, a string can be recognized in
0(n6-1Al.max(IGI*x1+IGIx2)) time, where Af
=Middle-nodes and N denotes the set of all nodes in
the trees of G.
</bodyText>
<sectionHeader confidence="0.914715" genericHeader="method">
5. A Linguistic Example
</sectionHeader>
<bodyText confidence="0.997687666666667">
In order to gain a better understanding of
Algorithm 1 and to emphasize the linguistic rele-
vance of TAGs, we present a running example. In
the following we assume the formal framework of
X-bar Theory (Jackendoff, 1977). Given the sen-
tence:
</bodyText>
<listItem confidence="0.533064166666667">
(1) Gianni incontra Maria per caso
lit. Gianni meets Maria by chance
we will propose here the following analysis (see
Figure 4):
(2) [c. [ip [NI, Gianni] 4. incontra i [vp. [vp
[Np Maria]]] 6 per casoth]]]
</listItem>
<bodyText confidence="0.999396052631579">
Note that the Verb incontra has been moved to the
Inflection position. Therefore, the PP adjunction
stretches the dependency between the Verb incontra
and its Direct Object Maria. These cases may raise
some difficulties in a context-free framework, be-
cause the lack of the head within its constituent
makes the task of predicting the object(s) rather inef-
ficient.
Assume a TAG G.(VN, VE, S. I, A), where
VN= (IP, I&apos;, VP, V&apos;, NP), VE= (Gianni, Maria,
incontra, PP), I=(a) and A= (/3) (see Figure 3; each
node has been paired with an integer which will be
used as its address). In order to simplify the compu-
tation, we have somewhat reduced the initial tree a
and we have considered the constituent PP as a ter-
minal symbol. In Figure 4 the whole analysis tree
corresponding to (2) is reported.
Let z(a)=5, &apos;4/3)=13; from Definition 3 it fol-
lows that:
</bodyText>
<equation confidence="0.799054">
F(5). ( [4, 5, left, 5, right, -, -]),
F(13)=([11, 13, left, 11, right, -, -]).
</equation>
<bodyText confidence="0.984880222222222">
A run of Algorithm 1 on sentence (1) is simpli-
fied in the following steps (only relevant steps are
reported).
First of all, the two anchors are recognized:
1) s1=[4, 5, left, 5, right, -] is inserted in 11.2
and s2=[11, 13, left, 13, right, -, -] is
inserted in 13,4, by line 1 of the algorithm.
Then, auxiliary tree fi is recognized in the following
steps:
</bodyText>
<listItem confidence="0.974922416666667">
2) s3=[11, 12, right, 13, right, -, -] is inserted
in /3,4 and m is set to rm in state s2, by Case
2 of the move-dot-left procedure;
3) s4=[11, 12, left, 13, right, 2, 3, -] is inserted
in t2.4 and m is set to rm in state s3, by Case
3 of the left-expander procedure;
4) s5=[11, 11, left, 13, right, 2, 3, -] is inserted
in &apos;2,4 and m is set to rm in state s4, by Case
3 of the move-dot-left procedure;
5) s6=[11, 11, left, 11, right, 2, 3, -1 is inserted
in t24 and m is set to lm in state s5, by Case
3 of the move-dot-right procedure.
</listItem>
<equation confidence="0.514785125">
a: IP (i)
(2) NP 1. (4)
(3) Gianni incontra (5) VP (6)
V&apos; (7)
(8) el NP (9)
Maria (10)
VP (11)
(12) VP PP (13)
</equation>
<figureCaption confidence="0.838484">
per caso
Figure 3.
</figureCaption>
<figure confidence="0.996467875">
IP
NP
I
Gianni incontra VP
VP PP
per caso
V.
C1 NP
</figure>
<figureCaption confidence="0.834532">
Maria
Figure 4.
</figureCaption>
<bodyText confidence="0.9999165">
After the insertion of state s7=[4, 5, left, 6, left, -,
-] in t1,2 by Case 2 of the move-dot-right procedure,
the VP node (6) is hypothesized by Case 1 (Step 2,
via state s6) of the right-expander procedure with the
insertion of state s8=[6, 6, left, 6, left, -] in 12,2.
The whole recognition of node (6) takes place with
the insertion of state s9=[6, 6, left, 6, right, -, -]
in:t2.3. Then we have the following step:
</bodyText>
<equation confidence="0.742438">
6) s10=[6, 6, left, 6, right, -, -1 is inserted in
- 31 -
</equation>
<bodyText confidence="0.807065">
t24, by the adjoiner procedure.
The analysis proceeds working on tree a and reach-
ing a final configuration in which state s11=[1, 1,
left, 1, right, -] belongs to tm.
</bodyText>
<sectionHeader confidence="0.998739" genericHeader="conclusions">
6. Discussion
</sectionHeader>
<bodyText confidence="0.999996196428572">
Within the perspective of Lexicalized TAGs,
known methods for TAGs recognition/parsing pre-
sent some limitations: these methods behave in a
left-to-right fashion (Schabes and Joshi, 1988) or
they are purely bottom-up (Vijay-Shanker and Joshi,
1985, Harbusch, 1990), hence they cannot take ad-
vantage of anchor information in a direct way. The
presented algorithm directly exploits both the advan-
tages of lexicalization mentioned in the paper by
Schabes and Joshi (1989), i.e. grammar filtering and
bottom-up information. In fact, such an algorithm
starts partial analyses from the anchor elements, di-
rectly selecting the relevant trees in the grammar,
and then it proceeds in both directions, climbing to
the roots of these trees and predicting the rest of the
structures in a top-down fashion. These capabilities
make the algorithm attractive from the perspective of
linguistic information processing, even if it does not
improve the worst-case time bounds of already
known TAGs parsers.
The studied algorithm recognizes auxiliary trees
without considering the substring dominated by the
foot node, as is the case of the CYK-like algorithm
in Vijay-Shanker and Joshi (1985). More precisely,
Case 3 in the procedure Left-expander nondeterminis-
tically jumps over such a substring. Note that the
alternative solution, which consists in waiting for
possible analyses subsumed by the foot node, would
prevent the algorithm from recognizing particular
configurations, due to the bidirectional behaviour of
the method (examples are left to the reader). On the
contrary, Earley-like parsers for TAGs (Lang, 1990,
Schabes, 1990) do care about substrings dominated
by the foot node. However, these algorithms are
forced to start at each foot node the recognition of all
possible subtre,es of the elementary trees whose roots
can be the locus of an adjunction.
In this work, we have discussed a theoretical
schema for the parser, in order to study its formal
properties. In practical cases, such an algorithm
could be considerably improved. For example, the
above mentioned guess in Case 3 of the procedure
Left-expander could take advantage of look-ahead
techniques. So far, we have not addressed topics such
as substitution or on-line recognition. Our algorithm
can be easily modified in these directions, adopting
the same proposals advanced in (Schabes and Joshi,
1988).
Finally, a parser for Lexicalized TAGs can be
obtained from Algorithm 1. To this purpose, it suf-
fices to store elements in Is into the recognition
matrix T along with a list of pointers to those en-
tries that caused such elements to be placed in the
matrix. Using this additional information, it is not
difficult to exhibit an algorithm for the construction
of the desired parser(s).
</bodyText>
<sectionHeader confidence="0.998192" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993161157894737">
Harbusch, Karin, 1990. An Efficient Parsing
Algorithm for TAGs. In Proceedings of the 28th
Annual Meeting of the Association for Computational
Linguistics. Pittsburgh, PA.
Jackendoff, Ray, 1977. X-bar Syntax: A Study of
Phrase Structure. The MIT Press, Cambridge, MA.
Joshi, Aravind K., 1985. Tree Adjoining
Grammars: How Much Context-Sensitivity Is Required
to Provide Reasonable Structural Descriptions?. In: D.
Dowty et al. (eds). Natural Language Parsing:
Psychological, Computational and Theoretical
Perspectives. Cambridge University Press, New York,
NY.
Kroch, Anthony S. and Joshi, Aravind K., 1985.
Linguistic Relevance of Tree Adjoining Grammars.
Technical Report MS-CIS-85-18, Department of
Computer and Information Science, University of
Pennsylv ani a.
Lang. Bernard, 1990. The Systematic Construction
of Earley Parsers: Application to the Production of
0(n6) Earley Parsers for Tree Adjoining Grammars. In
Proceedings of the 1st International Workshop on
Tree Adjoining Grammars. Dagstuhl Castle, F.R.G..
Satta, Giorgio, 1990. Aspetti computazionali della
Teoria della Reggenza e del Legamento. Doctoral
Dissertation, University of Padova, Italy.
Satta, Giorgio and Stock, Olivier°, 1989. Head-
Driven Bidirectional Parsing: A Tabular Method. In
Proceedings of the 1st International Workshop on
Parsing Technologies. Pittsburgh, PA.
Schabes, Yves, 1990. Mathematical and
Computational Aspects of Lexicalized Grammars. PhD
Thesis, Department of Computer and Information
Science, University of Pennsylvania.
Schabes, Yves; Abeille, Anne and Joshi, Aravind
K., 1988. Parsing Strategies for &apos;Lexicalized&apos;
Grammars: Application to Tree Adjoining Grammars.
In Proceedings of the 12th International Conference
on Computational Linguistics. Budapest, Hungary.
Schabes, Yves and Joshi, Aravind K., 1988. An
Earley-Type Parsing Algorithm for Tree Adjoining
Grammars. In Proceedings of the 26th Annual
Meeting of the Association for Computational
Linguistics. Buffalo, NY.
Schabes, Yves and Joshi, Aravind K., 1989. The
Relevance of Lexicalization to Parsing. In
Proceedings of the 1st International Workshop on
Parsing Technologies. Pittsburgh, PA. To also appear
under the title: Parsing with Lexicalized Tree
Adjoining Grammar. In: M. Tomita (ed.). Current
Issues in Parsing Technologies. The MIT Press.
Vijay-Shanker, K. and Joshi, Aravind K., 1985.
Some Computational Properties of Tree Adjoining
Grammars. In Proceedings of the 23rd Annual
Meeting of the Association for Computational
Linguistics. Chicago, IL.
- 32 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.658668">
<title confidence="0.9983845">BIDIRECTIONAL PARSING OF LEXICALIZED TREE ADJOINING GRAMMARS*</title>
<author confidence="0.998867">Alberto LaveIli</author>
<author confidence="0.998867">Giorgio Satta</author>
<affiliation confidence="0.884637">Istituto per la Ricerca Scientifica e Tecnologica</affiliation>
<address confidence="0.99722">I - 38050 Povo TN, Italy</address>
<email confidence="0.999828">e-mail:lavelli/satta@irst.it</email>
<abstract confidence="0.995248202702703">In this paper a bidirectional parser for Lexicalized Tree Adjoining Grammars will be presented. The algorithm takes advantage of a peculiar characteristic of Lexicalized TAGs, i.e. that each elementary tree is with a lexical item, called its algorithm employs a mixed strategy: it works bottom-up from the lexical anchors and then expands (partial) analyses making top-down predictions. Even if such an algorithm does not improve the worst-case time bounds of already known TAGs parsing methods, it could be relevant from the perspective of linguistic information processing, because it employs lexical information in a more direct way. Tree Adjoining Grammars (TAGs) are a formalism for expressing grammatical knowledge that extends the domain of locality of context-free grammars (CFGs). TAGs are tree rewriting systems specby a finite set of trees a detailed description of TAGs, see (Joshi, 1985)). TAGs can cope with various kinds of unbounded dependencies in a direct way because of their extended domain of locality; in fact, the elementary trees of TAGs are the appropriate domains for characterizing such de- (ICroch and Joshi, 1985) a detailed disthe linguistic relevance of TAGs can be found. Tree Adjoining Grammars are a refinement of TAGs such that each elementary tree is associated with a lexical item, the the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time comvaries from log (Harbusch, 1990) to and Joshi, 1985, Lang, 1990, 1990) and and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank for his valuable comments. also like to thank Anne AbelIle. All errors are of course our own. for Lexicalized TAGs, in (Schabes al., a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper by Schabes and Joshi (1989) shows how parsing strategies can take advantage of lexicalization in order to improve parsers&apos; performance. Two major advantages have been discussed in the cited work: grammar filtering (the parser can use only a subset of the entire grammar) and bottom-up information (further constraints are imposed on the way trees can be combined). Given these premises and starting from an already known method for bidirectional CF language recognition (Satta and Stock, 1989), it quite natural to propose an bidirectional parser for Lexicalized TAGs that tries to make more direct use of the information contained within the anchor&apos;s. The algorithm employs a mixed strategy: it work&apos;s bottom-up from the lexical anchors and then expands (partial) analyses making top-down predictions. 2. Overview of the Algorithm The algorithm that will be presented is a recognizer for Tree Adjoining Languages: a parser can be obtained from such a recognizer by additional pro-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Karin Harbusch</author>
</authors>
<title>An Efficient Parsing Algorithm for TAGs.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="2111" citStr="Harbusch, 1990" startWordPosition="324" endWordPosition="325">d. Lexicalized Tree Adjoining Grammars (Schabes et al., 1988) are a refinement of TAGs such that each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time complexity varies from 0(n4 log n) (Harbusch, 1990) to 0(n6) (Vijay-Shanker and Joshi, 1985, Lang, 1990, Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank Yves Schabes for his valuable comments. We would also like to thank Anne AbelIle. All errors are of course our own. As for Lexicalized TAGs, in (Schabes et al., 1988) a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with res</context>
<context position="22065" citStr="Harbusch, 1990" startWordPosition="3954" endWordPosition="3955">akes place with the insertion of state s9=[6, 6, left, 6, right, -, -] in:t2.3. Then we have the following step: 6) s10=[6, 6, left, 6, right, -, -1 is inserted in - 31 - t24, by the adjoiner procedure. The analysis proceeds working on tree a and reaching a final configuration in which state s11=[1, 1, left, 1, right, -] belongs to tm. 6. Discussion Within the perspective of Lexicalized TAGs, known methods for TAGs recognition/parsing present some limitations: these methods behave in a left-to-right fashion (Schabes and Joshi, 1988) or they are purely bottom-up (Vijay-Shanker and Joshi, 1985, Harbusch, 1990), hence they cannot take advantage of anchor information in a direct way. The presented algorithm directly exploits both the advantages of lexicalization mentioned in the paper by Schabes and Joshi (1989), i.e. grammar filtering and bottom-up information. In fact, such an algorithm starts partial analyses from the anchor elements, directly selecting the relevant trees in the grammar, and then it proceeds in both directions, climbing to the roots of these trees and predicting the rest of the structures in a top-down fashion. These capabilities make the algorithm attractive from the perspective </context>
</contexts>
<marker>Harbusch, 1990</marker>
<rawString>Harbusch, Karin, 1990. An Efficient Parsing Algorithm for TAGs. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>X-bar Syntax: A Study of Phrase Structure.</title>
<date>1977</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="18892" citStr="Jackendoff, 1977" startWordPosition="3357" endWordPosition="3358">a f Figure 1. a&apos; a included in ar- a. 4)(0 4.r.a af r+i - 30 - Theorem 2 If some auxiliary structures (vector of lists) are used by Algorithm I for the bookkeeping of all states that correspond to completely analyzed auxiliary trees, a string can be recognized in 0(n6-1Al.max(IGI*x1+IGIx2)) time, where Af =Middle-nodes and N denotes the set of all nodes in the trees of G. 5. A Linguistic Example In order to gain a better understanding of Algorithm 1 and to emphasize the linguistic relevance of TAGs, we present a running example. In the following we assume the formal framework of X-bar Theory (Jackendoff, 1977). Given the sentence: (1) Gianni incontra Maria per caso lit. Gianni meets Maria by chance we will propose here the following analysis (see Figure 4): (2) [c. [ip [NI, Gianni] 4. incontra i [vp. [vp [Np Maria]]] 6 per casoth]]] Note that the Verb incontra has been moved to the Inflection position. Therefore, the PP adjunction stretches the dependency between the Verb incontra and its Direct Object Maria. These cases may raise some difficulties in a context-free framework, because the lack of the head within its constituent makes the task of predicting the object(s) rather inefficient. Assume a</context>
</contexts>
<marker>Jackendoff, 1977</marker>
<rawString>Jackendoff, Ray, 1977. X-bar Syntax: A Study of Phrase Structure. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree Adjoining Grammars: How Much Context-Sensitivity Is Required to Provide Reasonable Structural Descriptions?. In:</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="1171" citStr="Joshi, 1985" startWordPosition="177" endWordPosition="178">then expands (partial) analyses making top-down predictions. Even if such an algorithm does not improve the worst-case time bounds of already known TAGs parsing methods, it could be relevant from the perspective of linguistic information processing, because it employs lexical information in a more direct way. 1. Introduction Tree Adjoining Grammars (TAGs) are a formalism for expressing grammatical knowledge that extends the domain of locality of context-free grammars (CFGs). TAGs are tree rewriting systems specified by a finite set of elementary trees (for a detailed description of TAGs, see (Joshi, 1985)). TAGs can cope with various kinds of unbounded dependencies in a direct way because of their extended domain of locality; in fact, the elementary trees of TAGs are the appropriate domains for characterizing such dependencies. In (ICroch and Joshi, 1985) a detailed discussion of the linguistic relevance of TAGs can be found. Lexicalized Tree Adjoining Grammars (Schabes et al., 1988) are a refinement of TAGs such that each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, name</context>
<context position="4388" citStr="Joshi, 1985" startWordPosition="702" endWordPosition="703">on). As an introduction to the next section, an informal description of the studied algorithm is here presented. We assume the following definition of TAGs. Definition 1 A Tree Adjoining Grammar (TAG) is a 5-tuple G=(VN, VE, S. I, A), where VN is a finite set of non-terminal symbols, VE is a finite set of terminal symbols, SE VN is the start symbol,! and A are two finite sets of trees, called initial trees and auxiliary trees respectively. The trees in the set luA are called elementary trees. We assume that the reader is familiar with the definitions of adjoining operation and foot node (see (Joshi, 1985)). The proposed algorithm is a tabular method that accepts a TAG G and a string w as input, and decides whether wE L(G). This is done by recovering (partial) analyses for substrings of w and by combining them. More precisely, the algorithm factorizes analyses of derived trees by employing a specific structure called state. Each state retains a pointer to a node n in some tree aE RA, along with two additional pointers (called !dot and rdot) to n itself or to - 27 - its children in a. Let an be a tree obtained from the maximal subtree of a with root n, by means of some adjoining operations. Info</context>
<context position="22048" citStr="Joshi, 1985" startWordPosition="3952" endWordPosition="3953">of node (6) takes place with the insertion of state s9=[6, 6, left, 6, right, -, -] in:t2.3. Then we have the following step: 6) s10=[6, 6, left, 6, right, -, -1 is inserted in - 31 - t24, by the adjoiner procedure. The analysis proceeds working on tree a and reaching a final configuration in which state s11=[1, 1, left, 1, right, -] belongs to tm. 6. Discussion Within the perspective of Lexicalized TAGs, known methods for TAGs recognition/parsing present some limitations: these methods behave in a left-to-right fashion (Schabes and Joshi, 1988) or they are purely bottom-up (Vijay-Shanker and Joshi, 1985, Harbusch, 1990), hence they cannot take advantage of anchor information in a direct way. The presented algorithm directly exploits both the advantages of lexicalization mentioned in the paper by Schabes and Joshi (1989), i.e. grammar filtering and bottom-up information. In fact, such an algorithm starts partial analyses from the anchor elements, directly selecting the relevant trees in the grammar, and then it proceeds in both directions, climbing to the roots of these trees and predicting the rest of the structures in a top-down fashion. These capabilities make the algorithm attractive from</context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Joshi, Aravind K., 1985. Tree Adjoining Grammars: How Much Context-Sensitivity Is Required to Provide Reasonable Structural Descriptions?. In: D. Dowty et al. (eds). Natural Language Parsing: Psychological, Computational and Theoretical Perspectives. Cambridge University Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony S Kroch</author>
<author>Aravind K Joshi</author>
</authors>
<title>Linguistic Relevance of Tree Adjoining Grammars.</title>
<date>1985</date>
<tech>Technical Report MS-CIS-85-18,</tech>
<institution>Department of Computer and Information Science, University of Pennsylv</institution>
<note>ani a.</note>
<marker>Kroch, Joshi, 1985</marker>
<rawString>Kroch, Anthony S. and Joshi, Aravind K., 1985. Linguistic Relevance of Tree Adjoining Grammars. Technical Report MS-CIS-85-18, Department of Computer and Information Science, University of Pennsylv ani a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard</author>
</authors>
<title>The Systematic Construction of Earley Parsers: Application to the Production of 0(n6) Earley Parsers for Tree Adjoining Grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 1st International Workshop on Tree Adjoining Grammars. Dagstuhl</booktitle>
<location>Castle, F.R.G..</location>
<marker>Bernard, 1990</marker>
<rawString>Lang. Bernard, 1990. The Systematic Construction of Earley Parsers: Application to the Production of 0(n6) Earley Parsers for Tree Adjoining Grammars. In Proceedings of the 1st International Workshop on Tree Adjoining Grammars. Dagstuhl Castle, F.R.G..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Aspetti computazionali della Teoria della Reggenza e del Legamento. Doctoral Dissertation,</title>
<date>1990</date>
<institution>University of Padova, Italy.</institution>
<contexts>
<context position="16261" citStr="Satta, 1990" startWordPosition="2854" endWordPosition="2855"> state s&apos;=In&amp;quot;, n&amp;quot;, left, n&amp;quot;, right, fi&amp;quot;, fr&amp;quot;, -Ito tij. Step 2: For every state s&amp;quot;—[n&amp;quot;, Idot&amp;quot;, right, rdot, rpos, fr&amp;quot;, m&amp;quot;] in tjx, I&gt;j, such that Adjoin(ldot&amp;quot;) and m&amp;quot;Thn, add state s&apos;=[Idot&amp;quot;, Idol&amp;quot;, right, ldot&amp;quot;, right, -, -Ito tfrjr. Step 3: For every state s&amp;quot;=[n&amp;quot;, &apos;dot, lpos, rdot&amp;quot;, left, fi&amp;quot;, fr&amp;quot;, m&amp;quot;1 in i&apos;&lt;i, such that ne Adjoin(rdot&amp;quot;) and m&amp;quot;#rm, add state s&apos;=[rdot&amp;quot;, rdot&amp;quot;, left, rdot&amp;quot;, left, -, -] to 4. Formal Results Some definitions will be introduced in the following, in order to present some interesting properties of Algorithm 1. Formal proofs of the statements below can be found in (Satta, 1990). Let n be a node in some tree aE/uA. Each state s=[n, Idol, lpos, rdot, rpos, f, fr, m] in Is identifies a tree forest 0(s) composed of all maximal subtrees in a whose roots are &amp;quot;spanned&amp;quot; by the two positions ldot and rdot. If ldomn, we assume that the maximal subtree in a whose root is Idol is included in 0(s) if and only if /pos=left (the mirror case holds w.r.t. rdot). We define the subsumption relation 5. on Is as follows: iff state s has the same first component as state s&apos; and 0(s) is included in 0(s&apos;). We also say that a forest O(s) derives a forest ty (0(s) 4 tv) whenever iy can be ob</context>
</contexts>
<marker>Satta, 1990</marker>
<rawString>Satta, Giorgio, 1990. Aspetti computazionali della Teoria della Reggenza e del Legamento. Doctoral Dissertation, University of Padova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Olivier° Stock</author>
</authors>
<title>HeadDriven Bidirectional Parsing: A Tabular Method.</title>
<date>1989</date>
<booktitle>In Proceedings of the 1st International Workshop on Parsing Technologies.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="3245" citStr="Satta and Stock, 1989" startWordPosition="508" endWordPosition="511">the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper by Schabes and Joshi (1989) shows how parsing strategies can take advantage of lexicalization in order to improve parsers&apos; performance. Two major advantages have been discussed in the cited work: grammar filtering (the parser can use only a subset of the entire grammar) and bottom-up information (further constraints are imposed on the way trees can be combined). Given these premises and starting from an already known method for bidirectional CF language recognition (Satta and Stock, 1989), it seems quite natural to propose an anchor-driven bidirectional parser for Lexicalized TAGs that tries to make more direct use of the information contained within the anchor&apos;s. The algorithm employs a mixed strategy: it work&apos;s bottom-up from the lexical anchors and then expands (partial) analyses making top-down predictions. 2. Overview of the Algorithm The algorithm that will be presented is a recognizer for Tree Adjoining Languages: a parser can be obtained from such a recognizer by additional processing (see final section). As an introduction to the next section, an informal description </context>
<context position="9979" citStr="Satta and Stock, 1989" startWordPosition="1747" endWordPosition="1750">rpos have a symmetrical interpretation. The pair 11, fr represents the part of the input string that is subsumed by the possible foot node in domaina(n). A binary operator indicated with the symbol ED is defined to combine the components ft. Jr in different states; such an operator is defined as follows: of equals f iff= -, it equals f if fr= -, and it is undefined otherwise. Finally, the component m is a marker that will be used to block expansion at one side for a state that has already been subsumed at the other one. This particular technique is called subsumption test and is discussed in (Satta and Stock, 1989). The subsumption test has the main purpose of blocking analysis proliferation due to the bidirectional behaviour of the method. Let 1s be the set of all possible states; we will use a particular equivalence relation Q-C_ Is&gt;ds defined as follows. For any pair of states s, s&apos;, sQs&apos; holds if and only if every component in s but the last one (the m component) equals the corresponding - 28 - component in s&apos;. The algorithm that will be presented employs the following function. Definition 3 A function F is defined as follows:2 F: VE P(Is) F(a) = (s I s=1father(n), n, left, n, right, -, -], cat(n)=a</context>
</contexts>
<marker>Satta, Stock, 1989</marker>
<rawString>Satta, Giorgio and Stock, Olivier°, 1989. HeadDriven Bidirectional Parsing: A Tabular Method. In Proceedings of the 1st International Workshop on Parsing Technologies. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Mathematical and Computational Aspects of Lexicalized Grammars.</title>
<date>1990</date>
<tech>PhD Thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="2179" citStr="Schabes, 1990" startWordPosition="334" endWordPosition="335">efinement of TAGs such that each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time complexity varies from 0(n4 log n) (Harbusch, 1990) to 0(n6) (Vijay-Shanker and Joshi, 1985, Lang, 1990, Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank Yves Schabes for his valuable comments. We would also like to thank Anne AbelIle. All errors are of course our own. As for Lexicalized TAGs, in (Schabes et al., 1988) a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper by Schabes and Joshi (1989)</context>
<context position="23420" citStr="Schabes, 1990" startWordPosition="4160" endWordPosition="4161">ithm recognizes auxiliary trees without considering the substring dominated by the foot node, as is the case of the CYK-like algorithm in Vijay-Shanker and Joshi (1985). More precisely, Case 3 in the procedure Left-expander nondeterministically jumps over such a substring. Note that the alternative solution, which consists in waiting for possible analyses subsumed by the foot node, would prevent the algorithm from recognizing particular configurations, due to the bidirectional behaviour of the method (examples are left to the reader). On the contrary, Earley-like parsers for TAGs (Lang, 1990, Schabes, 1990) do care about substrings dominated by the foot node. However, these algorithms are forced to start at each foot node the recognition of all possible subtre,es of the elementary trees whose roots can be the locus of an adjunction. In this work, we have discussed a theoretical schema for the parser, in order to study its formal properties. In practical cases, such an algorithm could be considerably improved. For example, the above mentioned guess in Case 3 of the procedure Left-expander could take advantage of look-ahead techniques. So far, we have not addressed topics such as substitution or o</context>
</contexts>
<marker>Schabes, 1990</marker>
<rawString>Schabes, Yves, 1990. Mathematical and Computational Aspects of Lexicalized Grammars. PhD Thesis, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Anne Abeille</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing Strategies for &apos;Lexicalized&apos; Grammars: Application to Tree Adjoining Grammars.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics.</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1557" citStr="Schabes et al., 1988" startWordPosition="237" endWordPosition="240"> expressing grammatical knowledge that extends the domain of locality of context-free grammars (CFGs). TAGs are tree rewriting systems specified by a finite set of elementary trees (for a detailed description of TAGs, see (Joshi, 1985)). TAGs can cope with various kinds of unbounded dependencies in a direct way because of their extended domain of locality; in fact, the elementary trees of TAGs are the appropriate domains for characterizing such dependencies. In (ICroch and Joshi, 1985) a detailed discussion of the linguistic relevance of TAGs can be found. Lexicalized Tree Adjoining Grammars (Schabes et al., 1988) are a refinement of TAGs such that each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time complexity varies from 0(n4 log n) (Harbusch, 1990) to 0(n6) (Vijay-Shanker and Joshi, 1985, Lang</context>
</contexts>
<marker>Schabes, Abeille, Joshi, 1988</marker>
<rawString>Schabes, Yves; Abeille, Anne and Joshi, Aravind K., 1988. Parsing Strategies for &apos;Lexicalized&apos; Grammars: Application to Tree Adjoining Grammars. In Proceedings of the 12th International Conference on Computational Linguistics. Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>An Earley-Type Parsing Algorithm for Tree Adjoining Grammars.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Buffalo, NY.</location>
<contexts>
<context position="2215" citStr="Schabes and Joshi, 1988" startWordPosition="338" endWordPosition="341">t each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time complexity varies from 0(n4 log n) (Harbusch, 1990) to 0(n6) (Vijay-Shanker and Joshi, 1985, Lang, 1990, Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank Yves Schabes for his valuable comments. We would also like to thank Anne AbelIle. All errors are of course our own. As for Lexicalized TAGs, in (Schabes et al., 1988) a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper by Schabes and Joshi (1989) shows how parsing strategies can ta</context>
<context position="21988" citStr="Schabes and Joshi, 1988" startWordPosition="3941" endWordPosition="3944">tion of state s8=[6, 6, left, 6, left, -] in 12,2. The whole recognition of node (6) takes place with the insertion of state s9=[6, 6, left, 6, right, -, -] in:t2.3. Then we have the following step: 6) s10=[6, 6, left, 6, right, -, -1 is inserted in - 31 - t24, by the adjoiner procedure. The analysis proceeds working on tree a and reaching a final configuration in which state s11=[1, 1, left, 1, right, -] belongs to tm. 6. Discussion Within the perspective of Lexicalized TAGs, known methods for TAGs recognition/parsing present some limitations: these methods behave in a left-to-right fashion (Schabes and Joshi, 1988) or they are purely bottom-up (Vijay-Shanker and Joshi, 1985, Harbusch, 1990), hence they cannot take advantage of anchor information in a direct way. The presented algorithm directly exploits both the advantages of lexicalization mentioned in the paper by Schabes and Joshi (1989), i.e. grammar filtering and bottom-up information. In fact, such an algorithm starts partial analyses from the anchor elements, directly selecting the relevant trees in the grammar, and then it proceeds in both directions, climbing to the roots of these trees and predicting the rest of the structures in a top-down fa</context>
</contexts>
<marker>Schabes, Joshi, 1988</marker>
<rawString>Schabes, Yves and Joshi, Aravind K., 1988. An Earley-Type Parsing Algorithm for Tree Adjoining Grammars. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics. Buffalo, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>The Relevance of Lexicalization to Parsing.</title>
<date>1989</date>
<booktitle>In Proceedings of the 1st International Workshop on Parsing Technologies.</booktitle>
<editor>In: M. Tomita (ed.).</editor>
<publisher>The MIT Press.</publisher>
<location>Pittsburgh, PA.</location>
<note>To also appear under</note>
<contexts>
<context position="2779" citStr="Schabes and Joshi (1989)" startWordPosition="437" endWordPosition="440">ng, 1990, Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank Yves Schabes for his valuable comments. We would also like to thank Anne AbelIle. All errors are of course our own. As for Lexicalized TAGs, in (Schabes et al., 1988) a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper by Schabes and Joshi (1989) shows how parsing strategies can take advantage of lexicalization in order to improve parsers&apos; performance. Two major advantages have been discussed in the cited work: grammar filtering (the parser can use only a subset of the entire grammar) and bottom-up information (further constraints are imposed on the way trees can be combined). Given these premises and starting from an already known method for bidirectional CF language recognition (Satta and Stock, 1989), it seems quite natural to propose an anchor-driven bidirectional parser for Lexicalized TAGs that tries to make more direct use of t</context>
<context position="22269" citStr="Schabes and Joshi (1989)" startWordPosition="3985" endWordPosition="3988">cedure. The analysis proceeds working on tree a and reaching a final configuration in which state s11=[1, 1, left, 1, right, -] belongs to tm. 6. Discussion Within the perspective of Lexicalized TAGs, known methods for TAGs recognition/parsing present some limitations: these methods behave in a left-to-right fashion (Schabes and Joshi, 1988) or they are purely bottom-up (Vijay-Shanker and Joshi, 1985, Harbusch, 1990), hence they cannot take advantage of anchor information in a direct way. The presented algorithm directly exploits both the advantages of lexicalization mentioned in the paper by Schabes and Joshi (1989), i.e. grammar filtering and bottom-up information. In fact, such an algorithm starts partial analyses from the anchor elements, directly selecting the relevant trees in the grammar, and then it proceeds in both directions, climbing to the roots of these trees and predicting the rest of the structures in a top-down fashion. These capabilities make the algorithm attractive from the perspective of linguistic information processing, even if it does not improve the worst-case time bounds of already known TAGs parsers. The studied algorithm recognizes auxiliary trees without considering the substri</context>
</contexts>
<marker>Schabes, Joshi, 1989</marker>
<rawString>Schabes, Yves and Joshi, Aravind K., 1989. The Relevance of Lexicalization to Parsing. In Proceedings of the 1st International Workshop on Parsing Technologies. Pittsburgh, PA. To also appear under the title: Parsing with Lexicalized Tree Adjoining Grammar. In: M. Tomita (ed.). Current Issues in Parsing Technologies. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>Aravind K Joshi</author>
</authors>
<title>Some Computational Properties of Tree Adjoining Grammars.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Chicago, IL.</location>
<contexts>
<context position="2151" citStr="Vijay-Shanker and Joshi, 1985" startWordPosition="328" endWordPosition="331">ing Grammars (Schabes et al., 1988) are a refinement of TAGs such that each elementary tree is associated with a lexical item, called the anchor of the tree. Therefore, Lexicalized TAGs conform to a common tendency in modem theories of grammar, namely the attempt to embed grammatical information within lexical items. Notably, the association between elementary trees and anchors improves also parsing performance, as will be discussed below. Various parsing algorithms for TAGs have been proposed in the literature: the worst-case time complexity varies from 0(n4 log n) (Harbusch, 1990) to 0(n6) (Vijay-Shanker and Joshi, 1985, Lang, 1990, Schabes, 1990) and 0(n9) (Schabes and Joshi, 1988). `Part of this work was done while Giorgio Satta was completing his Doctoral Dissertation at the University of Padova (Italy). We would like to thank Yves Schabes for his valuable comments. We would also like to thank Anne AbelIle. All errors are of course our own. As for Lexicalized TAGs, in (Schabes et al., 1988) a two step algorithm has been presented: during the first step the trees corresponding to the input string are selected and in the second step the input string is parsed with respect to this set of trees. Another paper</context>
<context position="22048" citStr="Vijay-Shanker and Joshi, 1985" startWordPosition="3950" endWordPosition="3953">whole recognition of node (6) takes place with the insertion of state s9=[6, 6, left, 6, right, -, -] in:t2.3. Then we have the following step: 6) s10=[6, 6, left, 6, right, -, -1 is inserted in - 31 - t24, by the adjoiner procedure. The analysis proceeds working on tree a and reaching a final configuration in which state s11=[1, 1, left, 1, right, -] belongs to tm. 6. Discussion Within the perspective of Lexicalized TAGs, known methods for TAGs recognition/parsing present some limitations: these methods behave in a left-to-right fashion (Schabes and Joshi, 1988) or they are purely bottom-up (Vijay-Shanker and Joshi, 1985, Harbusch, 1990), hence they cannot take advantage of anchor information in a direct way. The presented algorithm directly exploits both the advantages of lexicalization mentioned in the paper by Schabes and Joshi (1989), i.e. grammar filtering and bottom-up information. In fact, such an algorithm starts partial analyses from the anchor elements, directly selecting the relevant trees in the grammar, and then it proceeds in both directions, climbing to the roots of these trees and predicting the rest of the structures in a top-down fashion. These capabilities make the algorithm attractive from</context>
</contexts>
<marker>Vijay-Shanker, Joshi, 1985</marker>
<rawString>Vijay-Shanker, K. and Joshi, Aravind K., 1985. Some Computational Properties of Tree Adjoining Grammars. In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics. Chicago, IL.</rawString>
</citation>
<citation valid="false">
<pages>32</pages>
<marker></marker>
<rawString>- 32 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>