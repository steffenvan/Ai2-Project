<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001984">
<title confidence="0.744714">
Epiphenomenal Grammar Acquisition with GSG
</title>
<note confidence="0.70441925">
Marsal GayaIda
Interactive Systems, Inc.
1900 Murray Ave. Suite 203
Pittsburgh, PA 15217, U.S.A.
</note>
<email confidence="0.948437">
marsal@interactivesys. corn
</email>
<sectionHeader confidence="0.976269" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999018">
As a step toward conversational systems that al-
low for a more natural human-computer interac-
tion, we repOrton GsG, a system that, while pro-
viding a natural-language interface to a variety of
applications, engages in clarification dialogues with
the end user through which new semantic mappings
are dynamically acquired. GSG exploits task- and
language-dependent information but is fully task-
and language-independent in its architecture and
strategies.
</bodyText>
<sectionHeader confidence="0.995513" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970825">
As conversational systems move from the realm of
science fiction and research labs into people&apos;s every-
day life, and as they evolve from the plain, system-
directed interactions a la press or say one of so-
called interactive voice response systems based on
isolated-word recognizers and fixed-menu naviga-
tion, to the more open, mixed-initiative dialogues
carried out in spoken dialogue systems based on
large-vocabulary continuous speech recognizers and
flexible dialogue managers (see, e.g., (Allen et al.,
1996; Denecke, 1997; Walker et al., 1998; Rudnicky
et al., 1999; Zue et al., 2000)), the overall experien-
tial quality of the human-computer interaction be-
comes increasingly important. That is, beyond the
obvious factors of speech recognition accuracy and
speech synthesis naturalness, the most critical chal-
lenge is that of providing conversational interactions
that feel natural to human users (cf. (Glass, 1999)).
This, we believe, mainly translates into building sys-
tems that possess some degree of linguistic, reason-
ing, and learning abilities.
In this paper we report on GSG, a conversational
system that partially addresses these issues by being
able to dynamically extend its linguistic knowledge
through simple, natural-language only interactions
with non-expert users: On a purely on-need basis,
i.e., when the system does not understand what the
user means, GSG makes educated guesses, poses con-
firmation and clarification questions, and learns new
semantic mappings from the answers given by the
users, as well as from other linguistic information
that they may volunteer. GSG provides, therefore,
an extremely robust interface, and, at the same time,
significantly reduces grammar development time be-
cause the original grammar, while complete with
respect to the semantic representation of the do-
main at hand, need only cover a small portion of
the surface variability, since it will be automatically
extended as an epiprienomenon of engaging in clari-
fication dialogues with end users.
</bodyText>
<sectionHeader confidence="0.940021" genericHeader="method">
2 Brief System Description
</sectionHeader>
<bodyText confidence="0.999492103448276">
As sketched in Figure 1, GSG is a conversational&apos;
system built around the Sour parser (GayaIda,
2000).
GSG&apos;s principal (and possibly sole) knowledge
source is a task-dependent, semantic context-free
grammar (the Kernel Grammar). At run-time, the
Grammar is initialized as the union of the Kernel
Grammar and, possibly, the User Grammar (user-
dependent rules learned in previous sessions). The
Grammar gives rise to the Ontology and to a parse-
bank (collection of parse trees), which, together
with a possible Kernel Parsebank, becomes the Parse-
bank, from which the statistical Prediction Models
are trained. The Ontology is a directed acyclic
graph automatically derived from the Grammar in
which the nodes correspond to grammar nontermi-
nals (NTs) and the arcs record immediate domi-
nance relation, i.e., the presence of, say, NTi in a
right-hand side (RHS) alternative of NT, will re-
sult in an arc from NZ to NT,. Nodes are an-
notated as being &amp;quot;Principal&amp;quot; vs. &amp;quot;Auxiliary&amp;quot; (via
naming convention), &amp;quot;Top-level&amp;quot; vs. &amp;quot;Non-top level&amp;quot;
(i.e., whether they are starting symbols of the gram-
mar), and with having &amp;quot;Only NT daughters&amp;quot; vs.
&amp;quot;Only T daughters&amp;quot; vs. &amp;quot;Mixed&amp;quot;; arcs are anno-
tated as being &amp;quot;Is-a&amp;quot; (estimated from being the
only non-optional NT in a RHS alternative) vs.
&amp;quot;Expresses&amp;quot; links, &amp;quot;Always-required&amp;quot; vs. &amp;quot;Always-
optional&amp;quot; vs. &amp;quot;Mixed,&amp;quot; and &amp;quot;Never-repeatable&amp;quot; vs.
</bodyText>
<footnote confidence="0.94841125">
11n the work reported here, Gsa&apos;s interactions are text-
based (keyboard as input, text window as output), but GSG
is being integrated with both a speech recognizer and a speech
synthesizer.
</footnote>
<page confidence="0.995947">
36
</page>
<figure confidence="0.9998814">
Parse Tree
Builder
SOUP
Parser
i&amp;quot; Memel
&apos;....persebank
User
Gramm arA../
020
Back.end Application
Manager
lnteraction
History
User
Interface
</figure>
<figureCaption confidence="0.997918">
Figure 1: GSG&apos;S system diagram. Ovals enclose knowledge sources, rectangles modules, and arrows indicate
information flow. Dashed components are optional.
</figureCaption>
<table confidence="0.999456833333333">
Strategy Knowledge Source
All-top Parsing Grammar
Anchor Mother Predictions Prediction Models
Required/Is-a/... Daughters Search Ontology
Verbal Head Search POS Tagger, Ontology
Parser Predictions Grammar
</table>
<tableCaption confidence="0.999822">
Table 1: List of GsG&apos;s main prediction and learning strategies.
</tableCaption>
<bodyText confidence="0.972643785714286">
&amp;quot;Always-repeatable&amp;quot; vs. &amp;quot;Mixed&amp;quot;. Also, a topo-
logical sort2 on the nodes is computed to derive a
general-to-specific partial order of the NTs.
A full system description is beyond the scope of
this paper, but, very briefly, the User Interface me-
diates all interactions with the end-user, the stack-
based Dialogue Manager keeps track of current and
past utterances and ensuing clarification dialogues,
and, together with the History Interaction, ensures
that no answered question is asked again. The GSG
Engine manages the core of the systems&apos; &amp;quot;intelli-
gence,&amp;quot; namely hypothesizing interpretations (to-
gether with the Parse Tree Builder) and on-line learn-
ing of semantic mappings.
</bodyText>
<sectionHeader confidence="0.994429" genericHeader="method">
3 Example Dialogue
</sectionHeader>
<bodyText confidence="0.9995526">
To illustrate the workings of Gsc, let&apos;s analyze an
example interaction in an e-mail client task. Figure 2
shows the example dialogue, Figure 3 presents a rel-
evant fragment of the semantic context-free gram-
mar3 used to analyze the input, and Table 1 above
</bodyText>
<footnote confidence="0.320635666666667">
2 Requires that the grammar be acyclic.
3Containing, approximately, 300 NTs, 500 Ts, and 800
RHS alternatives, out of which about 55% is dedicated to
</footnote>
<bodyText confidence="0.99935905">
lists the main prediction and learning strategies em-
ployed.
The user inputs (U1) and, as it turns out, nei-
ther retrieve, nor bob, nor christmas are in the gram-
mar and no full parse of (U1) can be found. Rather
than responding with a I don&apos;t understand — please
rephrase, G SG sets its predictive machinery in mo-
tion with the goal of constructing a full interpreta-
tion for (U1).4
The first step is to reparse (U1) in a mode in
which all NTs are considered top-level, i.e., able to
stand at the root of a parse tree. This produces
a set of still unparsed words, such as retrieve, and
parse subtrees, such as from bob being parsed under
SENDER (via grammar rules (R6) to (R10)) and, am-
biguously, under CsourceFoider] as well (via gram-
mar rules (R11) and (R12)). All of it (i.e., the full
content of the chart) is taken as evidence by the
Prediction Models to postulate the overall meaning
of the original utterance. In this case (see (U2)
</bodyText>
<footnote confidence="0.854566">
cover temporal and numeric expressions, and digits and let-
ters.
4The hypothesized interpretation assumes that a single
parse tree will cover the entire problematic sentence.
</footnote>
<page confidence="0.996378">
37
</page>
<listItem confidence="0.992179666666667">
(151) U: retrieve all messages from bob that were sent after christmas
(U2) S: I don&apos;t understand right away what you mean but let me guess...
&amp;quot;retrieve all messages from bob that were sent after christmas&amp;quot; is a way to express:
1. send mail
2. reply mail
3. read mail
0. None of the above
(U3) LT: none
(U4) S: &amp;quot;retrieve all messages from bob that were sent after christmas&amp;quot; is a way to express:
1. move mail
2. list mail
0. None of the above
(115) U: list
(U6) 5: By &amp;quot;from bob&amp;quot; do you mean:
1. source folder
2. sender
(U7) U: sender
(118) S =&amp;quot;christraas&amp;quot; is a way to express:
</listItem>
<table confidence="0.8132323">
-1: yesterday (date relative yesterday)
2. tomorrow (date relative tomorrow)
3. today (date relative today)
0. None of the above
U: by christmas i&apos;m referring to december twenty fifth
S: Thanks for teaching me the meaning of &amp;quot;christmas&amp;quot;!
Thanks for teaching me the meaning of &amp;quot;retrieve all messages from bob that were sent after christmas&amp;quot;!
I understand &amp;quot;retrieve all messages from bob that were sent after december twenty fifth&amp;quot;
U: retrieve last email to mary before christmas
(1112) S: understand &amp;quot;retrieve last email to mary before december twenty fifth&amp;quot;
</table>
<figureCaption confidence="0.993514">
Figure 2: Example dialogue between a user (U) and the system (S) on an e-mail client task.
</figureCaption>
<bodyText confidence="0.999944761904762">
to (U5)5) the suggestions of the Prediction Models
are not particularly accurate (the correct choice is
presented only in fifth place), but, considering that
the head verb (retrieve) is not even in the grammar,
such a response to (U1) is definitely better than giv-
ing up. The effect of (U5) is to select [listMail]
as (U1)&apos;s &amp;quot;anchor mother&amp;quot; (logical root of the over-
all interpretation). But to complete the parse tree
a few details still need to be filled in. To that ef-
fect (06) is generated to disambiguate from bob and
(U8) to find the right mapping for christmas. The
reasoning behind the rather puzzling choices offered
by (U8) comes from applying the Parser Predictions
strategy: given the context in which an unparsed se-
quence (in this case, single word) christmas appears,
i.e., the subtree DATE_AFTER2RE covering after (via
(R14)), the grammar is traversed to find likely con-
tinuations of the context (left context only in this
case). Since DATE_AFTER_PRE can be immediately
followed by [dateAfter] (see (R13)) that makes
CdateAfterl a candidate to cover the unparsed se-
</bodyText>
<footnote confidence="0.973500714285714">
5The options presented in (152) and (U4) are generated
at the same time, the only reason why they are split is to
prevent overwhelming the end user, who may be hearing the
choices spoken over the telephone. Also, note that in (U3)
the user could have also said zero, or none of the above and
achieve the same result — or, alternatively, they could have
volunteered information as in (119).
</footnote>
<bodyText confidence="0.999809611111111">
quence christmas. However, since, according to the
Ontology, [dateAfter] does not allow terminals as
immediate daughters, a search is performed to find
NTs under [clateAtted that permit it. In this case
(via (R15) to (R19)) it suggests yesterday, tomorrow,
etc.6 The user, though, realizing that the system
does not directly understand christmas, volunteers
(U9)7, from which the mapping (M2) in Figure 4 is
learned.
At this point one may wonder about the fate of the
unparsed word retrieve, since no question was asked
about it. The answer is that Gs@ need not ask about
every single prediction, if the confidence value is high
enough. In this case, as soon as E1istMan] was
established (in (U5)) as the anchor mother, a Verbal
Head Search strategy was launched to see whether,
among the unparsed words, a verb was found that
could be placed in a mostly-verb NT8 directly under
</bodyText>
<footnote confidence="0.9736312">
5In fact it suggests EDATE_RELATIVE:yesterdayi,
DATE_RELATIVE: t morrow] , etc, but it presents an ex-
ample automatically generated from such NTs.
?Obviously &amp;quot;the meaning of Christmas&amp;quot; (cf. cheerful
(1510)) may be much more profound than a shorthand for
December 25 — but, alas, conveying that is well beyond the
simple grammar presented here.
8A &amp;quot;verbness&amp;quot; ratio is automatically computed for each
candidate NT. by running the POS tagger on automatically
generated sentences from the NTs in question. (We used a
</footnote>
<page confidence="0.997409">
38
</page>
<table confidence="0.992319578947368">
[listMail] 4-- *VERB_DESIRE LIST *TO_FORAE +MAIL_ARGUMENTS
[moveMail] 4-- *VERB_DESIRE MOVE *+MAIL_ARGIJMENTS +[sourceFolder] klestinationFolder]
LIST 4-- list I get
MOVE 4-- move
MAIL_ARGUMENTS SENDER I RECIPIENT I SUBJECT I DATE I MESSAGE_IDI
(116) SENDER 4-- *SENDER_PRE [sender]
SENDER_PRE E-- from I by
[sender] 4-- [flame; STRING] I [emailAddress:STRING1
[name:STRING] 4-- PERSON_OR_INSTITUTION_NAME I MAILING_LIST_NAME
PERSON_OR_INSTITUTION_NAME E-- +WILDCARD
[sourceFolder] 4-- from [folderName:STRING] *FOLDER
[f olderName : STRING] 4--- WILDCARD
[dateRange] (DATE_AFTER_PRE [dateAfter]) I (DATE_BEFORE_FRE [dateBeforel)
DATE_AFTER_PFtE after I from I since
[dateAfter] 4-- [datePoint :DATE]
[datePoint :DATE] +DATE_POINT_ARGUMENT
DATE_POINT_ARGUMENT 4-- [datePoint:DATE_RELATIVE] I [datePoint:DATE_FIXEDI
[datePoint:DATE_RELATIVE] 4-- [DATE_RKLATIVE:yesterday] I [DATE_RELATIVE:tomorroid] I ...
[DATE:RELATIVE: yesterday] 4-- yesterday
</table>
<figureCaption confidence="0.782623">
Figure 3: Grammar fragment for an e-mail client task. 4.&apos; indicates optiohality of adjacent token, +&apos;
repeatability, and `I&apos; separates RHS alternatives. Terminals are italicized. WILDCARD is a special NT that
matches any out-of-vocabulary word or any in-vocabulary word present in a list for that purpose.
[listMail] . The result was highly positive and led
to the acquisition of the RHS alternative (M1).
</figureCaption>
<bodyText confidence="0.999856615384615">
It is worth mentioning here that there are two
kinds of mappings that GSG learns: RHS alterna-
tives and subtree mappings. Learning new RHS al-
ternatives is the preferred way because the knowl-
edge can be incorporated into the Parsebank (and, in
turn, into the Prediction Models). That is the effect
of adding (M1) to the Grammar: Since the Parsebank
and the Prediction Models are updated on-line, the
presence of the word retrieve in subsequent utter-
ances becomes a strong indicator of LIST and, asso-
ciatively, of ClistMail3. However, when the source
expression can not be mapped into the desired target
structure via grammar rules, as in (M2), the only so-
lution is to remember the equivalence. This kind of
learning, although definitely useful since the mean-
ing of the source expression will be henceforth re-
membered, cannot be incorporated into the Predic-
tion Models.
Right after (U9), (U1) is considered fully un-
derstood and the interpretation is automatically
mapped into the feature structure (FS1)9 in Fig-
ure 5, which is then shipped to the Back-end Ap-
plication Manager.
Finally, when (U11) comes in, a correct analysis is
produced thanks to the mappings just learned from
(U1),&apos;° and (FS2) in is generated.
</bodyText>
<footnote confidence="0.9411945">
modified version of Brill&apos;s tagger (Brill 1994).)
9The mapping is simply a removal of auxiliary NTs from
the parse tree, plus value extraction of dates, numbers and
strings from certain subtrees, e.g., subtree in (M2) becomes
the substructure under datePoint in (FS1).
101400 that rule [].istMail] 4— LIST +MAIL_AAGIIMENTS
</footnote>
<sectionHeader confidence="0.98084" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.995916190476191">
The example above illustrates the philosophy of
GSG,11 namely, to exploit task and linguistic knowl-
edge to pose clarification questions in the face of
incomplete analyses,u build correct interpretations,
and acquire new semantic mappings. Thus, a contri-
bution of GsG, is the demonstration that from a sim-
ple context-free grammar, with a very lightweight
formalism, one can extract enough information (On-
tology, Parsebank, Parser Predictions strategy) to
conduct meaningful clarification dialogues. Note,
moreover, that such dialogues occur entirely within
GSG, with the Back-end Application Manager receiv-
ing only finalized feature structures.&apos;3
Another advantage is the ease with which natural-
language interfaces can be constructed for new do-
mains: Since all the task and linguistic knowledge
is extracted from the grammar,&amp;quot; one need only de-
velop a Kernel Grammar that models the domain at
(extracted from the final interpretation of (U1)) would have
been learned too, but its subsumption by existing rule (B1)
was automatically detected.
</bodyText>
<footnote confidence="0.816587461538462">
1&apos;Based on the pioneering work of (Lehman, 1989).
1 2Detected by a lack of interpretation, excessively frag-
mented interpretation, or by being told by the end user that
the automatically generated paraphrase of their input is not
what they meant.
130f course, prediction accuracy can improve if the Back-
end Application Manager can be incorporated as a knowledge
source to, for example, contribute in the ranking of hypothe-
ses, but the point is that it is not necessary and that, as long
as the capabilities of the back-end application are adequately
modeled by the Grammar, the construction of the correct in-
terpretation can be performed within GSG alone.
14Except for the POS Tagger and the Syntactic Grammar.
</footnote>
<page confidence="0.998464">
39
</page>
<figure confidence="0.998686578947369">
retrieve
LIST
DATE_POINT_ARCUMENT
MONTH
MONTH_VAL
[nionth:12]
decembor
DAY_OF_MONTH
(day0fMonth:INTEOER]
ORD/NAL-NUMBER-0-99
CARDINAL-NUMBER-TENS
(INTEGER-CARDINAL: 20]
hventy
ORDINAL-NUMBER-UNITS
[INTEGER-ORDINAL: 5]
fifth
(MI)
(M2)
christmas
</figure>
<figureCaption confidence="0.999782">
Figure 4: Mappings learned from the dialogue in Figure 2.
</figureCaption>
<table confidence="0.990453">
listMail listMail
messageIdx: all messageIdx:- East
sender recipient
name: bob name: mary
dateRange dateRange
dateAfter dateBefore
datePoint datePoint
month: 12 month: 12
day0fMonth: 25 day0fMonth: 25
(FST) (FS2)
</table>
<figureCaption confidence="0.994286">
Figure 5: Feature structures sent to the Back-end Application Manager after (1J10) and (U12) in Figure 2.
</figureCaption>
<bodyText confidence="0.963229">
hand via its NTs15 but need not provide a high cov-
erage of the utterances possible in the domain (data
which may not be available anyway). Also, reuse of
existing grammar modules for, e.g., dates and num-
bers, is straightforward.
However, a fear of letting the end user (indirectly)
modify a grammar is that the grammar may grow
untamed and become filled with new rules that dis-
rupt the Kernel Grammar. To prevent that, besides
the careful construction of interpretations via the
strategies described above, GSG employs two safety
mechanisms: before a rule is added to the gram-
mar, it is checked whether it introduces ambiguity
to the grammar,&amp;quot; and whether it disrupts existing
&amp;quot;Knowledge of, e.g., how the Ontology is computed helps,
but it coincides with the most natural way of writing well-
structured, context-free semantic grammars.
I6Accomplished by using the SOUP parser in yet another
mode: parsing of RHSs (expanded to RHS paths) instead of
terminals. In this case, existence of a parse tree covering an
entire RHS path indicates ambiguity. Note that if all RHS
paths of the new rule can be parsed under the current RHS of
the new rule&apos;s left-hand side, then the new rule is subsumed
by the existing RHS and can therefore be discarded (cf. note
10).
(correct) interpretations.17 In this way, some of the
new rules may have to be discarded, but at least the
health of the grammar is preserved.&amp;quot;
Another concern may be that the new mappings
end up generating feature structures that are not un-
derstood by the Back-end Application Manager. To
avoid that, GSG only allows a principal NT to be
dominated by another principal NT if such domi-
nance relation is licensed by the Kernel Grammar.
This guarantees that all resulting feature structures
be structurally correct (although they may contain
unexpected atomic values).
A current limitation of GSG lies in the difficulty of
segmenting long sequences of unparsed words: GsG
uses POS tagging followed by noun-phrase bracket-
ing (via parsing with a shallow Syntactic Grammar),
which represents an improvement over the Single
Segment Assumption (cf. (Lehman, 1989)), but is
still far from perfect and can disrupt the ensuing
clarification dialogue. Also, the number of questions
that the system can pose as it builds an interpre-
</bodyText>
<footnote confidence="0.99534">
I7Achieved by reparsing (a subset of) the Parsebank. Note
that SOUP can typically parse in the order of 100 utterances
per second (cf. (Gayala, 2000)).
18Assuming minimally cooperative and consistent users.
</footnote>
<page confidence="0.998551">
40
</page>
<bodyText confidence="0.9984105">
tation, may, in occasion, exceed the patience of the
end user (but the command cancel is always under-
stood).
The hardest problem we have encountered so far is
typical of natural-language interfaces but is exacer-
bated in GSG (as it treats every unparsable sentence
as an opportunity to learn), and that is the difficulty
of identifiying in-domain end-user sentences that go
beyond the capabilities of the end application, or, in
other words, are not expressible in the grammar.
Finally, as GSG becomes fully integrated with a
speech recognizer, it remains to be seen how an op-
timal point in the tradeoff between the wide cover-
age but relatively low word recognition accuracy ob-
tained with a loose dictation grammar, and the nar-
row coverage but high word accuracy achieved with
a tight, task-dependent grammar, can be found, and
how the degradation. of the input is going to affect
GSG&apos;s behavior.
Overall, however, we believe that GSG, by virtue
of its built-in robustness, minimal initial knowledge
requirements, and learning abilities, begins to em-
body the kind of qualities that are necessary for con-
versational systems, if they are to provide, without
exorbitant development effort, an interaction thay
feels truly natural to humans.
</bodyText>
<sectionHeader confidence="0.996918" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999582290322581">
Allen, James, et al. (1996). Robust Understanding
in a Dialogue System. In Proceedings of ACL-
1996.
Brill, Eric. (1994). Some Advances in Part of Speech
Tagging. In Proceedings of AAAI-1994
Denecke, Matthias. (1997). An Information-
based Approach for Guiding Multi-modal Human-
Computer Interaction. In Proceedings of IJCAI-
1997.
Gavaldà, Marsal. (2000. SOUP: A Parser for Real-
world Spontaneous Speech. In Proceedings of the
Sixth International Workshop on Parsing Tech-
nologies (IWPT-2000).
Glass, James. (1999). Challenges for Spoken Dia-
logue Systems. In Proceedings of the 1999 IEEE
ASRU Workshop.
Lehman, Jill. (1989). Adaptive Parsing: Self-
extending Natural Language Interfaces. Ph.D. dis-
sertation, School of Computer Science, Carnegie
Mellon University.
Rudnicky, Alex, et al. (1999). Creating Natural
Dialogs in the Carnegie Mellon COMMUNICATOR
System. In Proceedings of Eurospeech-1999.
Walker, Marilyn, et al. (1998). Learning Optimal
Dialogue Strategies: A Case Study of a Spo-
ken Dialogue Agent for Email. In Proceedings .of
COLING/ACL-1998.
Zue, Victor, et al. (2000). JUPITER: A Telephone-
Based Conversational Interface for Weather Infor-
mation. In IEEE Transactions on Speech and Au-
dio Processing, Vol. 8 , No. 1.
</reference>
<page confidence="0.99944">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254669">
<title confidence="0.944702">Epiphenomenal Grammar Acquisition with GSG</title>
<author confidence="0.678351">Marsal</author>
<affiliation confidence="0.953644">Interactive Systems,</affiliation>
<address confidence="0.996389">1900 Murray Ave. Suite Pittsburgh, PA 15217,</address>
<author confidence="0.404821">corn</author>
<abstract confidence="0.994389">As a step toward conversational systems that allow for a more natural human-computer interacwe GsG, system that, while providing a natural-language interface to a variety of applications, engages in clarification dialogues with the end user through which new semantic mappings dynamically acquired. taskand language-dependent information but is fully taskand language-independent in its architecture and strategies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Robust Understanding in a Dialogue System. In</title>
<date>1996</date>
<booktitle>Proceedings of ACL1996.</booktitle>
<marker>Allen, 1996</marker>
<rawString>Allen, James, et al. (1996). Robust Understanding in a Dialogue System. In Proceedings of ACL1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some Advances in Part of Speech Tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of AAAI-1994</booktitle>
<contexts>
<context position="13704" citStr="Brill 1994" startWordPosition="2158" endWordPosition="2159">nly solution is to remember the equivalence. This kind of learning, although definitely useful since the meaning of the source expression will be henceforth remembered, cannot be incorporated into the Prediction Models. Right after (U9), (U1) is considered fully understood and the interpretation is automatically mapped into the feature structure (FS1)9 in Figure 5, which is then shipped to the Back-end Application Manager. Finally, when (U11) comes in, a correct analysis is produced thanks to the mappings just learned from (U1),&apos;° and (FS2) in is generated. modified version of Brill&apos;s tagger (Brill 1994).) 9The mapping is simply a removal of auxiliary NTs from the parse tree, plus value extraction of dates, numbers and strings from certain subtrees, e.g., subtree in (M2) becomes the substructure under datePoint in (FS1). 101400 that rule [].istMail] 4— LIST +MAIL_AAGIIMENTS 4 Discussion The example above illustrates the philosophy of GSG,11 namely, to exploit task and linguistic knowledge to pose clarification questions in the face of incomplete analyses,u build correct interpretations, and acquire new semantic mappings. Thus, a contribution of GsG, is the demonstration that from a simple con</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, Eric. (1994). Some Advances in Part of Speech Tagging. In Proceedings of AAAI-1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Denecke</author>
</authors>
<title>An Informationbased Approach for Guiding Multi-modal HumanComputer Interaction.</title>
<date>1997</date>
<booktitle>In Proceedings of IJCAI1997.</booktitle>
<contexts>
<context position="1167" citStr="Denecke, 1997" startWordPosition="167" endWordPosition="168"> is fully taskand language-independent in its architecture and strategies. 1 Introduction As conversational systems move from the realm of science fiction and research labs into people&apos;s everyday life, and as they evolve from the plain, systemdirected interactions a la press or say one of socalled interactive voice response systems based on isolated-word recognizers and fixed-menu navigation, to the more open, mixed-initiative dialogues carried out in spoken dialogue systems based on large-vocabulary continuous speech recognizers and flexible dialogue managers (see, e.g., (Allen et al., 1996; Denecke, 1997; Walker et al., 1998; Rudnicky et al., 1999; Zue et al., 2000)), the overall experiential quality of the human-computer interaction becomes increasingly important. That is, beyond the obvious factors of speech recognition accuracy and speech synthesis naturalness, the most critical challenge is that of providing conversational interactions that feel natural to human users (cf. (Glass, 1999)). This, we believe, mainly translates into building systems that possess some degree of linguistic, reasoning, and learning abilities. In this paper we report on GSG, a conversational system that partially</context>
</contexts>
<marker>Denecke, 1997</marker>
<rawString>Denecke, Matthias. (1997). An Informationbased Approach for Guiding Multi-modal HumanComputer Interaction. In Proceedings of IJCAI1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marsal Gavaldà</author>
</authors>
<title>SOUP: A Parser for Realworld Spontaneous Speech.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT-2000).</booktitle>
<marker>Gavaldà, 2000</marker>
<rawString>Gavaldà, Marsal. (2000. SOUP: A Parser for Realworld Spontaneous Speech. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT-2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Glass</author>
</authors>
<title>Challenges for Spoken Dialogue Systems.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 IEEE ASRU Workshop.</booktitle>
<contexts>
<context position="1561" citStr="Glass, 1999" startWordPosition="226" endWordPosition="227"> to the more open, mixed-initiative dialogues carried out in spoken dialogue systems based on large-vocabulary continuous speech recognizers and flexible dialogue managers (see, e.g., (Allen et al., 1996; Denecke, 1997; Walker et al., 1998; Rudnicky et al., 1999; Zue et al., 2000)), the overall experiential quality of the human-computer interaction becomes increasingly important. That is, beyond the obvious factors of speech recognition accuracy and speech synthesis naturalness, the most critical challenge is that of providing conversational interactions that feel natural to human users (cf. (Glass, 1999)). This, we believe, mainly translates into building systems that possess some degree of linguistic, reasoning, and learning abilities. In this paper we report on GSG, a conversational system that partially addresses these issues by being able to dynamically extend its linguistic knowledge through simple, natural-language only interactions with non-expert users: On a purely on-need basis, i.e., when the system does not understand what the user means, GSG makes educated guesses, poses confirmation and clarification questions, and learns new semantic mappings from the answers given by the users,</context>
</contexts>
<marker>Glass, 1999</marker>
<rawString>Glass, James. (1999). Challenges for Spoken Dialogue Systems. In Proceedings of the 1999 IEEE ASRU Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Lehman</author>
</authors>
<title>Adaptive Parsing: Selfextending Natural Language Interfaces.</title>
<date>1989</date>
<institution>School of Computer Science, Carnegie Mellon University.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="15081" citStr="Lehman, 1989" startWordPosition="2365" endWordPosition="2366">arification dialogues. Note, moreover, that such dialogues occur entirely within GSG, with the Back-end Application Manager receiving only finalized feature structures.&apos;3 Another advantage is the ease with which naturallanguage interfaces can be constructed for new domains: Since all the task and linguistic knowledge is extracted from the grammar,&amp;quot; one need only develop a Kernel Grammar that models the domain at (extracted from the final interpretation of (U1)) would have been learned too, but its subsumption by existing rule (B1) was automatically detected. 1&apos;Based on the pioneering work of (Lehman, 1989). 1 2Detected by a lack of interpretation, excessively fragmented interpretation, or by being told by the end user that the automatically generated paraphrase of their input is not what they meant. 130f course, prediction accuracy can improve if the Backend Application Manager can be incorporated as a knowledge source to, for example, contribute in the ranking of hypotheses, but the point is that it is not necessary and that, as long as the capabilities of the back-end application are adequately modeled by the Grammar, the construction of the correct interpretation can be performed within GSG </context>
<context position="18480" citStr="Lehman, 1989" startWordPosition="2901" endWordPosition="2902">rstood by the Back-end Application Manager. To avoid that, GSG only allows a principal NT to be dominated by another principal NT if such dominance relation is licensed by the Kernel Grammar. This guarantees that all resulting feature structures be structurally correct (although they may contain unexpected atomic values). A current limitation of GSG lies in the difficulty of segmenting long sequences of unparsed words: GsG uses POS tagging followed by noun-phrase bracketing (via parsing with a shallow Syntactic Grammar), which represents an improvement over the Single Segment Assumption (cf. (Lehman, 1989)), but is still far from perfect and can disrupt the ensuing clarification dialogue. Also, the number of questions that the system can pose as it builds an interpreI7Achieved by reparsing (a subset of) the Parsebank. Note that SOUP can typically parse in the order of 100 utterances per second (cf. (Gayala, 2000)). 18Assuming minimally cooperative and consistent users. 40 tation, may, in occasion, exceed the patience of the end user (but the command cancel is always understood). The hardest problem we have encountered so far is typical of natural-language interfaces but is exacerbated in GSG (a</context>
</contexts>
<marker>Lehman, 1989</marker>
<rawString>Lehman, Jill. (1989). Adaptive Parsing: Selfextending Natural Language Interfaces. Ph.D. dissertation, School of Computer Science, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Rudnicky</author>
</authors>
<title>Creating Natural Dialogs in the Carnegie Mellon COMMUNICATOR System. In</title>
<date>1999</date>
<booktitle>Proceedings of Eurospeech-1999.</booktitle>
<marker>Rudnicky, 1999</marker>
<rawString>Rudnicky, Alex, et al. (1999). Creating Natural Dialogs in the Carnegie Mellon COMMUNICATOR System. In Proceedings of Eurospeech-1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
</authors>
<title>Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email.</title>
<date>1998</date>
<booktitle>In Proceedings .of COLING/ACL-1998.</booktitle>
<marker>Walker, 1998</marker>
<rawString>Walker, Marilyn, et al. (1998). Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email. In Proceedings .of COLING/ACL-1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Zue</author>
</authors>
<title>JUPITER: A TelephoneBased Conversational Interface for Weather Information.</title>
<date>2000</date>
<booktitle>In IEEE Transactions on Speech and Audio Processing,</booktitle>
<volume>8</volume>
<marker>Zue, 2000</marker>
<rawString>Zue, Victor, et al. (2000). JUPITER: A TelephoneBased Conversational Interface for Weather Information. In IEEE Transactions on Speech and Audio Processing, Vol. 8 , No. 1.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>