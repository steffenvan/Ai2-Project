<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.852237">
Unified Expectation Maximization
</title>
<author confidence="0.975683">
Rajhans Samdani Ming-Wei Chang Dan Roth
</author>
<affiliation confidence="0.993221">
University of Illinois Microsoft Research University of Illinois
</affiliation>
<email confidence="0.985563">
rsamdan2@illinois.edu minchang@microsoft.com danr@illinois.edu
</email>
<sectionHeader confidence="0.821549" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.758697208333333">
We present a general framework containing a
graded spectrum of Expectation Maximization
(EM) algorithms called Unified Expectation
Maximization (UEM.) UEM is parameterized
by a single parameter and covers existing al-
gorithms like standard EM and hard EM, con-
strained versions of EM such as Constraint-
Driven Learning (Chang et al., 2007) and Pos-
terior Regularization (Ganchev et al., 2010),
along with a range of new EM algorithms.
For the constrained inference step in UEM we
present an efficient dual projected gradient as-
cent algorithm which generalizes several dual
decomposition and Lagrange relaxation algo-
rithms popularized recently in the NLP litera-
ture (Ganchev et al., 2008; Koo et al., 2010;
Rush and Collins, 2011). UEM is as efficient
and easy to implement as standard EM. Fur-
thermore, experiments on POS tagging, infor-
mation extraction, and word-alignment show
that often the best performing algorithm in the
UEM family is a new algorithm that wasn’t
available earlier, exhibiting the benefits of the
UEM framework.
</bodyText>
<sectionHeader confidence="0.992169" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999507611111111">
Expectation Maximization (EM) (Dempster et al.,
1977) is inarguably the most widely used algo-
rithm for unsupervised and semi-supervised learn-
ing. Many successful applications of unsupervised
and semi-supervised learning in NLP use EM in-
cluding text classification (McCallum et al., 1998;
Nigam et al., 2000), machine translation (Brown et
al., 1993), and parsing (Klein and Manning, 2004).
Recently, EM algorithms which incorporate con-
straints on structured output spaces have been pro-
posed (Chang et al., 2007; Ganchev et al., 2010).
Several variations of EM (e.g. hard EM) exist in
the literature and choosing a suitable variation is of-
ten very task-specific. Some works have shown that
for certain tasks, hard EM is more suitable than reg-
ular EM (Spitkovsky et al., 2010). The same issue
continues in the presence of constraints where Poste-
rior Regularization (PR) (Ganchev et al., 2010) cor-
responds to EM while Constraint-Driven Learning
(CoDL)1 (Chang et al., 2007) corresponds to hard
EM. The problem of choosing between EM and hard
EM (or between PR and CoDL) remains elusive,
along with the possibility of simple and better alter-
natives, to practitioners. Unfortunately, little study
has been done to understand the relationships be-
tween these variations in the NLP community.
In this paper, we approach various EM-based
techniques from a novel perspective. We believe that
“EM or Hard-EM?” and “PR or CoDL?” are not the
right questions to ask. Instead, we present a unified
framework for EM, Unified EM (UEM), that covers
many EM variations including the constrained cases
along with a continuum of new ones. UEM allows us
to compare and investigate the properties of EM in a
systematic way and helps find better alternatives.
The contributions of this paper are as follows:
</bodyText>
<listItem confidence="0.979641272727273">
1. We propose a general framework called Uni-
fied Expectation Maximization (UEM) that
presents a continuous spectrum of EM algo-
rithms parameterized by a simple temperature-
like tuning parameter. The framework covers
both constrained and unconstrained EM algo-
rithms. UEM thus connects EM, hard EM, PR,
and CoDL so that the relation between differ-
ent algorithms can be better understood. It also
enables us to find new EM algorithms.
2. To solve UEM (with constraints), we propose
</listItem>
<note confidence="0.786664714285714">
1To be more precise, (Chang et al., 2007) mentioned using
hard constraints as well as soft constraints in EM. In this paper,
we refer to CoDL only as the EM framework with hard con-
straints.
688
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688–698,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9474525">
a dual projected subgradient ascent algorithm
that generalizes several dual decomposition
and Lagrange relaxation algorithms (Bertsekas,
1999) introduced recently in NLP (Ganchev et
al., 2008; Rush and Collins, 2011).
3. We provide a way to implement a family of
EM algorithms and choose the appropriate one,
given the data and problem setting, rather than
a single EM variation. We conduct experi-
ments on unsupervised POS tagging, unsuper-
vised word-alignment, and semi-supervised in-
formation extraction and show that choosing
the right UEM variation outperforms existing
EM algorithms by a significant margin.
</bodyText>
<sectionHeader confidence="0.981647" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999835866666667">
Let x denote an input or observed features and h be
a discrete output variable to be predicted from a fi-
nite set of possible outputs x(x). Let PO(x, h) be
a probability distribution over (x, h) parameterized
by 0. Let PO(h|x) refer to the conditional probabil-
ity of h given x. For instance, in part-of-speech tag-
ging, x is a sentence, h the corresponding POS tags,
and 0 could be an HMM model; in word-alignment,
x can be an English-French sentence pair, h the
word alignment between the sentences, and 0 the
probabilistic alignment model. Let S(h = h&apos;) be
the Kronecker-Delta distribution centered at h&apos;, i.e.,
it puts a probability of 1 at h&apos; and 0 elsewhere.
In the rest of this section, we review EM and
constraints-based learning with EM.
</bodyText>
<subsectionHeader confidence="0.896019">
2.1 EM Algorithm
</subsectionHeader>
<bodyText confidence="0.9998935">
To obtain the parameter 0 in an unsupervised way,
one maximizes log-likelihood of the observed data:
</bodyText>
<equation confidence="0.998481">
L(0) = log PO(x) = log � PO(x, h) . (1)
hEW(x)
</equation>
<bodyText confidence="0.977683">
EM (Dempster et al., 1977) is the most common
technique for learning 0, which maximizes a tight
lower bound on L(0). While there are a few different
styles of expressing EM, following the style of (Neal
and Hinton, 1998), we define
</bodyText>
<equation confidence="0.989819">
F(0, q) = L(0) − KL(q, PO(h|x)), (2)
</equation>
<bodyText confidence="0.995861857142857">
where q is a posterior distribution over x(x) and
KL(p1, p2) is the KL divergence between two dis-
tributions p1 and p2. Given this formulation, EM can
be shown to maximize F via block coordinate ascent
alternating over q (E-step) and 0 (M-step) (Neal and
Hinton, 1998). In particular, the E-step for EM can
be written as
</bodyText>
<equation confidence="0.9846835">
q = arg min
Q&apos;EQ KL(q&apos;, PO(h|x)) , (3)
</equation>
<bodyText confidence="0.999739666666667">
where 2 is the space of all distributions. While EM
produces a distribution in the E-step, hard EM is
thought of as producing a single output given by
</bodyText>
<equation confidence="0.9983775">
h* = arg max PO(h|x) . (4)
hEW(x)
</equation>
<bodyText confidence="0.9877124">
However, one can also think of hard EM as pro-
ducing a distribution given by q = S(h = h*). In
this paper, we pursue this distributional view of both
EM and hard EM and show its benefits.
EM for Discriminative Models EM-like algo-
rithms can also be used in discriminative set-
tings (Bellare et al., 2009; Ganchev et al., 2010)
specifically for semi-supervised learning (SSL.)
Given some labeled and unlabeled data, such algo-
rithms maximize a modified F(0, q) function:
</bodyText>
<equation confidence="0.989692">
F(0, q) = L,(0) − c1110112 − c2KL(q, PO(h|x)) , (5)
</equation>
<bodyText confidence="0.999749">
where, q, as before, is a probability distribution over
x(x), L,(0) is the conditional log-likelihood of the
labels given the features for the labeled data, and c1
and c2 are constants specified by the user; the KL
divergence is measured only over the unlabeled data.
The EM algorithm in this case has the same E-step
as unsupervised EM, but the M-step is different. The
M-step is similar to supervised learning as it finds 0
by maximizing a regularized conditional likelihood
of the data w.r.t. the labels — true labels are used for
labeled data and “soft” pseudo labels based on q are
used for unlabeled data.
</bodyText>
<subsectionHeader confidence="0.998562">
2.2 Constraints in EM
</subsectionHeader>
<bodyText confidence="0.999980888888889">
It has become a common practice in the NLP com-
munity to use constraints on output variables to
guide inference. Few of many examples include
type constraints between relations and entities (Roth
and Yih, 2004), sentential and modifier constraints
during sentence compression (Clarke and Lapata,
2006), and agreement constraints between word-
alignment directions (Ganchev et al., 2008) or var-
ious parsing models (Koo et al., 2010). In the con-
</bodyText>
<page confidence="0.915546">
689
</page>
<bodyText confidence="0.958705045454545">
text of EM, constraints can be imposed on the pos-
terior probabilities, q, to guide the learning proce-
dure (Chang et al., 2007; Ganchev et al., 2010).
In this paper, we focus on linear constraints over
h (potentially non-linear over x.) This is a very gen-
eral formulation as it is known that all Boolean con-
straints can be transformed into sets of linear con-
straints over binary variables (Roth and Yih, 2007).
Assume that we have m linear constraints on out-
puts where the kth constraint can be written as
ukTh ≤ bk .
Defining a matrix U as UT = [u1T . . . uMT]
and a vector b as bT = [b1, ... , bm], we write down
the set of all feasible2 structures as
{h  |h ∈ H(x), Uh ≤ b} .
Constraint-Driven Learning (CoDL) (Chang et
al., 2007) augments the E-step of hard EM (4) by
imposing these constraints on the outputs.
Constraints on structures can be relaxed to expec-
tation constraints by requiring the distribution q to
satisfy them only in expectation. Define expecta-
tion w.r.t. a distribution q over H(x) as EQ[Uh] =
</bodyText>
<equation confidence="0.959571142857143">
E
hEW(x) q(h)Uh. In the expectation constraints
setting, q is required to satisfy:
EQ[Uh] ≤ b .
The space of distributions Q can be modified as:
Q = {q  |q(h) ≥ 0,EQ[Uh] ≤ b, � q(h) = 1}.
hEW(x)
</equation>
<bodyText confidence="0.999824666666667">
Augmenting these constraints into the E-step of
EM (3), gives the Posterior Regularization (PR)
framework (Ganchev et al., 2010). In this paper, we
adopt the expectation constraint setting. Later, we
show that UEM naturally includes and generalizes
both PR and CoDL.
</bodyText>
<sectionHeader confidence="0.973092" genericHeader="method">
3 Unified Expectation Maximization
</sectionHeader>
<bodyText confidence="0.712877625">
We now present the Unified Expectation Maximiza-
tion (UEM) framework which captures a continuum
of (constrained and unconstrained) EM algorithms
2Note that this set is a finite set of discrete variables not to
be confused with a polytope. Polytopes are also specified as
{z|Az &lt; d} but are over real variables whereas h is discrete.
Algorithm 1 The UEM algorithm for both the genera-
tive (G) and discriminative (D) cases.
</bodyText>
<equation confidence="0.988211571428571">
Initialize 01
fort = 0,...,T do
UEM E-step:
qt+1 ← arg min9EQ KL(q, Pet(h|x); y)
UEM M-step:
G: 0t+1 = arg maxe E9t+1 [log Pe(x, h)]
D: 0t+1 = arg maxe E9t+1 [log Pe(h|x)] − c1k0k&apos;
</equation>
<subsectionHeader confidence="0.650843">
end for
</subsectionHeader>
<bodyText confidence="0.999856842105263">
including EM and hard EM by modulating the en-
tropy of the posterior. A key observation underlying
the development of UEM is that hard EM (or CoDL)
finds a distribution with zero entropy while EM (or
PR) finds a distribution with the same entropy as PB
(or close to it). Specifically, we modify the objective
of the E-step of EM (3) as
In other words, UEM projects PB(h|x) on the
space of feasible distributions Q w.r.t. a metric3
KL(·, ·;y) to obtain the posterior q. By simply vary-
ing y, UEM changes the metric of projection and ob-
tains different variations of EM including EM (PR,
in the presence of constraints) and hard EM (CoDL.)
The M-step for UEM is exactly the same as EM (or
discriminative EM.)
The UEM Algorithm: Alg. 1 shows the UEM al-
gorithm for both the generative (G) and the discrimi-
native (D) case. We refer to the UEM algorithm with
parameter y as UEM.y.
</bodyText>
<subsectionHeader confidence="0.9641975">
3.1 Relationship between UEM and Other EM
Algorithms
</subsectionHeader>
<bodyText confidence="0.942749777777778">
The relation between unconstrained versions of EM
has been mentioned before (Ueda and Nakano,
1998; Smith and Eisner, 2004). We show that the
relationship takes novel aspects in the presence of
constraints. In order to better understand different
UEM variations, we write the UEM E-step (6) ex-
plicitly as an optimization problem:
3The term ‘metric’ is used very loosely. KL����� -y) does
not satisfy the mathematical properties of a metric.
</bodyText>
<equation confidence="0.9927526">
q = arg min KL(q&apos;,PB(h|x);y) , (6)
Q&apos;EQ
where KL(q, p; y) is a modified KL divergence:
KL(q,p;y) = � yq(h) log q(h)−q(h) logp(h). (7)
h0i(x)
</equation>
<page confidence="0.369362">
690
</page>
<table confidence="0.7578234">
Framework γ = −oo γ = 0 γ E (0, 1) γ = 1 γ = oo --+ 1
Constrained Hard EM Hard EM (NEW) UEM, Standard EM Deterministic
Annealing EM
Unconstrained CoDL (Chang et (NEW) EM (NEW) constrained PR (Ganchev et al.,
al., 2007) with Lin. Prog. UEM, 2010)
</table>
<tableCaption confidence="0.998972">
Table 1: Summary of different UEM algorithms. The entries marked with “(NEW)” have not been proposed before.
</tableCaption>
<equation confidence="0.998729428571429">
Eq. (8) is the objective function for all the EM frameworks listed in this table. Note that, in the absence of constraints,
-y E (−oc, 0] corresponds to hard EM (Sec. 3.1.1.) Please see Sec. 3.1 for a detailed explanation.
-yq(h) log q(h) − q(h) log Pθ(h|x)(8)
s.t. Eq[Uh] &lt; b,
q(h) &gt; 0, Vh E H(x),
E
hEH(x) q(h) = 1 .
</equation>
<bodyText confidence="0.998831">
We discuss below, both the constrained and the
unconstrained cases. Tab. 1 summarizes different
EM algorithms in the UEM family.
</bodyText>
<subsectionHeader confidence="0.832422">
3.1.1 UEM Without Constraints
</subsectionHeader>
<bodyText confidence="0.9995932">
The E-step in this case, computes a q obeying
only the simplex constraints: EhEH(x) q(h) = 1.
For -y = 1, UEM minimizes KL(q, Pθ(h|x); 1)
which is the same as minimizing KL(q, Pθ(h|x))
as in the standard EM (3). For -y = 0, UEM
</bodyText>
<equation confidence="0.638836">
E
</equation>
<bodyText confidence="0.9944176">
is solving arg minqEQ hEH(x) −q(h) log Pθ(h|x)
which is a linear programming (LP) problem. Due to
the unimodularity of the simplex constraints (Schri-
jver, 1986), this LP outputs an integral q =
( )
S h = arg maxhEH(x) Pθ(h|x) which is the same
as hard EM (4). It has already been noted in the liter-
ature (Kearns et al., 1997; Smith and Eisner, 2004;
Hofmann, 2001) that this formulation (correspond-
ing to our -y = 0) is the same as hard EM. In fact,
for -y &lt; 0, UEM stays the same as hard EM be-
cause of negative penalty on the entropy. The range
-y E (0, 1) has not been discussed in the literature,
to the best of our knowledge. In Sec. 5, we show
the impact of using UEMγfor -y E 10, 11. Lastly,
the range of -y from oc to 1 has been used in deter-
ministic annealing for EM (Rose, 1998; Ueda and
Nakano, 1998; Hofmann, 2001). However, the focus
of deterministic annealing is solely to solve the stan-
dard EM while avoiding local maxima problems.
</bodyText>
<subsectionHeader confidence="0.939786">
3.1.2 UEM With Constraints
</subsectionHeader>
<bodyText confidence="0.997032625">
UEM and Posterior Regularization (-y = 1) For
-y = 1, UEM solves arg minqEQ KL (q, Pθ(h|x))
which is the same as Posterior Regulariza-
tion (Ganchev et al., 2010).
UEM and CoDL (-y = −oc) When -y —* −oc
then due to an infinite penalty on the entropy of the
posterior, the entropy must become zero. Thus, now
the E-step, as expressed by Eq. (8), can be written as
</bodyText>
<equation confidence="0.879936">
q = S(h = h*) where h* is obtained as
arg max log Pθ(h|x) (9)
hEH(x)
s.t. Uh &lt; b ,
</equation>
<bodyText confidence="0.99977075">
which is the same as CoDL. This combinatorial
maximization can be solved using the Viterbi algo-
rithm in some cases or, in general, using Integer Lin-
ear Programming (ILP.)
</bodyText>
<subsectionHeader confidence="0.711038">
3.2 UEM with -y E [0, 1]
</subsectionHeader>
<bodyText confidence="0.99998425">
Tab. 1 lists different EM variations and their associ-
ated values -y. This paper focuses on values of -y be-
tween 0 and 1 for the following reasons. First, the E-
step (8) is non-convex for -y &lt; 0 and hence compu-
tationally expensive; e.g., hard EM (i.e. -y = −oc)
requires ILP inference. For -y &gt; 0, (8) is a convex
optimization problem which can be solved exactly
and efficiently. Second, for -y = 0, the E-step solves
</bodyText>
<equation confidence="0.978974333333333">
max
q E hEH(x) q(h) log Pθ(h|x) (10)
s.t. Eq[Uh] &lt; b,
q(h) &gt; 0, Vh E H(x),
E
hEH(x) q(h) = 1 ,
</equation>
<bodyText confidence="0.97965925">
which is an LP-relaxation of hard EM (Eq. (4)
and (9)). LP relaxations often provide a decent
proxy to ILP (Roth and Yih, 2004; Martins et al.,
2009). Third, -y E [0, 1] covers standard EM/PR.
</bodyText>
<subsectionHeader confidence="0.539754">
3.2.1 Discussion: Role of -y
</subsectionHeader>
<bodyText confidence="0.9823015">
The modified KL divergence can be related to
standard KL divergence as KL(q, Pθ(h|x); -y) =
</bodyText>
<equation confidence="0.948854333333333">
min
q
E
hEH(x)
691
KL(q, Pe(yJx)) + (1 − -y)H(q) — UEM (6) mini-
</equation>
<bodyText confidence="0.998383894736842">
mizes the former during the E-step, while Standard
EM (3) minimizes the latter. The additional term
(1 − -y)H(q) is essentially an entropic prior on the
posterior distribution q which can be used to regu-
larize the entropy as desired.
For -y &lt; 1, the regularization term penalizes the
entropy of the posterior thus reducing the probability
mass on the tail of the distribution. This is signifi-
cant, for instance, in unsupervised structured predic-
tion where the tail can carry a substantial amount of
probability mass as the output space is massive. This
notion aligns with the observation of (Spitkovsky
et al., 2010) who criticize EM for frittering away
too much probability mass on unimportant outputs
while showing that hard EM does much better in
PCFG parsing. In particular, they empirically show
that when initialized with a “good” set of parame-
ters obtained by supervised learning, EM drifts away
(thus losing accuracy) much farther than hard-EM.
</bodyText>
<sectionHeader confidence="0.941018" genericHeader="method">
4 Solving Constrained E-step with
Lagrangian Dual
</sectionHeader>
<bodyText confidence="0.998357428571429">
In this section, we discuss how to solve the E-
step (8) for UEM. It is a non-convex problem for
-y &lt; 0; however, for -y = −oc (CoDL) one can use
ILP solvers. We focus here on solving the E-step for
-y &gt; 0 for which it is a convex optimization problem,
and use a Lagrange relaxation algorithm (Bertsekas,
1999). Our contributions are two fold:
</bodyText>
<listItem confidence="0.883473">
• We describe an algorithm for UEM with con-
straints that is as easy to implement as PR or
CoDL. Existing code for constrained EM (PR
or CoDL) can be easily extended to run UEM.
• We solve the E-step (8) using a Lagrangian
dual-based algorithm which performs projected
</listItem>
<bodyText confidence="0.897981416666667">
subgradient-ascent on dual variables. Our al-
gorithm covers Lagrange relaxation and dual
decomposition techniques (Bertsekas, 1999)
which were recently popularized in NLP (Rush
and Collins, 2011; Rush et al., 2010; Koo et al.,
2010). Not only do we extend the algorithmic
framework to a continuum of algorithms, we
also allow, unlike the aforementioned works,
general inequality constraints over the output
variables. Furthermore, we establish new and
interesting connections between existing con-
strained inference techniques.
</bodyText>
<subsectionHeader confidence="0.8362295">
4.1 Projected Subgradient Ascent with
Lagrangian Dual
</subsectionHeader>
<bodyText confidence="0.999811833333333">
We provide below a high-level view of our algo-
rithm, omitting the technical derivations due to lack
of space. To solve the E-step (8), we introduce dual
variables A — one for each expectation constraint in
Q. The subgradient OA of the dual of Eq. (8) w.r.t.
A is given by
</bodyText>
<equation confidence="0.5582824">
OA a EQ[Uh] − b . (11)
For -y &gt; 0, the primal variable q can be written in
terms of A as
1 aTUh
q(h) a Pet(hJx) rye 7 . (12)
</equation>
<bodyText confidence="0.993277666666667">
For -y = 0, the q above is not well defined and so
we take the limit -y —* 0 in (12) and since h, norm
approaches the max-norm as p —* oc, this yields
</bodyText>
<equation confidence="0.992617625">
q(h) = S(h = argmax Pe(h&apos;Jx)e−aT Uh&apos;). (13)
h&apos;EW(x)
We combine both the ideas by setting q(h) =
G(h, Pet(·Jx), A&apos;U, -y) where
G(h, P, v, 7) =
S(h= arg max P(h&apos;)e−°h0) 7 = 0 .
h0EN(x)
(14)
</equation>
<bodyText confidence="0.999927944444444">
Alg. 2 shows the overall optimization scheme.
The dual variables for inequality constraints are re-
stricted to be positive and hence after a gradient up-
date, negative dual variables are projected to 0.
Note that for -y = 0, our algorithm is a Lagrange
relaxation algorithm for approximately solving the
E-step for CoDL (which uses exact arg max infer-
ence). Lagrange relaxation has been recently shown
to provide exact and optimal results in a large num-
ber of cases (Rush and Collins, 2011). This shows
that our range of algorithms is very broad — it in-
cludes PR and a good approximation to CoDL.
Overall, the required optimization (8) can be
solved efficiently if the expected value computation
in the dual gradient (Eq. (11)) w.r.t. the posterior q
in the primal (Eq (14)) can be performed efficiently.
In cases where we can enumerate the possible out-
puts h efficiently, e.g. multi-class classification, we
</bodyText>
<figure confidence="0.9882552">
I
−
vh
7
1
P(h)7 e
1
7 e
7 &gt; 0 ,
vh0
7
E
h0 P(h0)
692
Algorithm 2 Solving E-step of UEMγ for γ ≥ 0.
</figure>
<listItem confidence="0.845251">
1: Initialize and normalize q; initialize λ = 0.
2: for t = 0, ... , R or until convergence do
3: λ ← max (λ + ηt (Eq[Uh] − b) , 0)
4: q(h) = G(h, Pet(·|x), λTU, γ)
5: end for
</listItem>
<bodyText confidence="0.999867142857143">
can compute the posterior probability q explicitly
using the dual variables. In cases where the out-
put space is structured and exponential in size, e.g.
word alignment, we can optimize (8) efficiently if
the constraints and the model Pθ(h|x) decompose
in the same way. To elucidate, we give a more con-
crete example in the next section.
</bodyText>
<subsectionHeader confidence="0.9036735">
4.2 Projected Subgradient based Dual
Decomposition Algorithm
</subsectionHeader>
<bodyText confidence="0.999681545454546">
Solving the inference (8) using Lagrangian dual can
often help us decompose the problem into compo-
nents and handle complex constraints in the dual
space as we show in this section. Suppose our
task is to predict two output variables h1 and h2
coupled via linear constraints. Specifically, they
obey Ueh1 = Ueh2 (agreement constraints) and
Uih1 ≤ Uih2 (inequality constraints)4 for given
matrices Ue and Ui. Let their respective probabilis-
tic models be P1θ1 and P2θ2. The E-step (8) can be
written as
</bodyText>
<equation confidence="0.864686333333333">
arg min A(q1,q2;γ) (15)
q1,q2
s.t. Eq1[Ueh1] = Eq2[Ueh2]
Eq1[Uih1] ≤ Eq2[Uih2] ,
where A(q1, q2;γ) = KL(q1(h1), P1θ1(h1|x);γ) +
KL(q2(h2), P2θ2(h2|x); γ).
</equation>
<bodyText confidence="0.9998652">
The application of Alg. 2 results in a dual decom-
position scheme which is described in Alg. 3.
Note that in the absence of inequality constraints
and for γ = 0, our algorithm reduces to a simpler
dual decomposition algorithm with agreement con-
straints described in (Rush et al., 2010; Koo et al.,
2010). For γ = 1 with agreement constraints, our
algorithm specializes to an earlier proposed tech-
nique by (Ganchev et al., 2008). Thus our algo-
rithm puts these dual decomposition techniques with
</bodyText>
<footnote confidence="0.908097">
4The analysis remains the same for a more general formu-
lation with a constant offset vector on the R.H.S. and different
</footnote>
<table confidence="0.804409">
matrices for h1 and h2.
Algorithm 3 Projected Subgradient-based Lagrange
Relaxation Algorithm that optimizes Eq. (15)
</table>
<listItem confidence="0.467522384615385">
1: Input: Two distributions P1e1 and P2e2.
2: Output: Output distributions q1 and q2 in (15)
3: Define λT = [ T]
λe T λiT] and UT = [Ue T Ui
4: λ ← 0
5: for t = 0, ... , R or until convergence do
6: q1(h1) ← G(h1, P1e1(·|x), λT U, γ)
7: q2(h2) ← G(h2, P2e2(·|x), −λTU, γ)
8: λe ← λe + ηt(−Eq1[Ueh1] + Eq2[Ueh2])
9: λi ← λi + ηt(−Eq1[Uih1] + Eq2[Uih2])
10: λi ← max(λi, 0) {Projection step}
11: end for
12: return (q1, q2)
</listItem>
<bodyText confidence="0.99789780952381">
agreement constraints on the same spectrum. More-
over, dual-decomposition is just a special case of
Lagrangian dual-based techniques. Hence Alg. 2
is more broadly applicable (see Sec. 5). Lines 6-9
show that the required computation is decomposed
over each sub-component.
Thus if computing the posterior and expected val-
ues of linear functions over each subcomponent is
easy, then the algorithm works efficiently. Con-
sider the case when constraints decompose linearly
over h and each component is modeled as an HMM
with θS as the initial state distribution, θE as em-
mision probabilities, and θT as transition probabil-
ities. An instance of this is word alignment over
language pair (S, T) modeled using an HMM aug-
mented with agreement constraints which constrain
alignment probabilities in one direction (Pθ1: from
S to T) to agree with the alignment probabilities in
the other direction (Pθ2: from T to S.) The agree-
ment constraints are linear over the alignments, h.
Now, the HMM probability is given by
</bodyText>
<equation confidence="0.921115">
Pθ(h|x) = θS(h0) Hi θE(xi|hi)θT(hi+1|hi)
</equation>
<bodyText confidence="0.999922333333333">
where vi denotes the ith component of a vector v.
For γ &gt; 0, the resulting q (14) can be expressed
using a vector µ =+/-λT U (see lines 6-7) as
</bodyText>
<equation confidence="0.9969325">
q(h) ∝ θS(h0) �
i /θE(xi|hi)θT (hi+1|hi)
�∝ θS(h0)1γ (θE(xi|hi)eµihi)1γ θT(hi+1|hi)γ1 .
i
</equation>
<bodyText confidence="0.999068333333333">
The dual variables-based term can be folded into
the emission probabilities, OE. Now, the resulting q
can be expressed as an HMM by raising θS, θE, and
</bodyText>
<figure confidence="0.704233333333333">
1
γ r-i µihi
e γ
</figure>
<page confidence="0.605092">
693
</page>
<bodyText confidence="0.999738285714286">
BT to the power 1/y and normalizing. For y = 0, q
can be computed as the most probable output. The
required computations in lines 6-9 can be performed
using the forward-backward algorithm or the Viterbi
algorithm. Note that we can efficiently compute ev-
ery step because the linear constraints decompose
nicely along the probability model.
</bodyText>
<sectionHeader confidence="0.998635" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.996949815789474">
Our experiments are designed to explore tuning y
in the UEM framework as a way to obtain gains
over EM and hard EM in the constrained and uncon-
strained cases. We conduct experiments on POS-
tagging, word-alignment, and information extrac-
tion; we inject constraints in the latter two. In all the
cases we use our unified inference step to implement
general UEM and the special cases of existing EM
algorithms. Since both of our constrained problems
involve large scale constrained inference during the
E-step, we use UEM0 (with a Lagrange relaxation
based E-step) as a proxy for ILP-based CoDL .
As we vary y over [0, 1], we circumvent much of
the debate over EM vs hard EM (Spitkovsky et al.,
2010) by exploring the space of EM algorithms in a
“continuous” way. Furthermore, we also study the
relation between quality of model initialization and
the value of y in the case of POS tagging. This is
inspired by a general “research wisdom” that hard
EM is a better choice than EM with a good initial-
ization point whereas the opposite is true with an
“uninformed” initialization.
Unsupervised POS Tagging We conduct exper-
iments on unsupervised POS learning experiment
with the tagging dictionary assumption. We use a
standard subset of Penn Treebank containing 24,115
tokens (Ravi and Knight, 2009) with the tagging dic-
tionary derived from the entire Penn Treebank. We
run UEM with a first order (bigram) HMM model5.
We consider initialization points of varying quality
and observe the performance for y E [0, 1].
Different initialization points are constructed as
follows. The “posterior uniform” initialization is
created by spreading the probability uniformly over
all possible tags for each token. Our EM model on
5(Ravi and Knight, 2009) showed that a first order HMM
model performs much better than a second order HMM model
on unsupervised POS tagging
</bodyText>
<figure confidence="0.986467166666667">
0.05
0
-0.05
-0.1
-0.15
1.0
</figure>
<figureCaption confidence="0.999604">
Figure 1: POS Experiments showing the relation between
</figureCaption>
<bodyText confidence="0.983985105263158">
initial model parameters and y. We report the relative per-
formance compared to EM (see Eq. (16)). The posterior
uniform initialization does not use any labeled examples.
As the no. of labeled examples used to create the initial
HMM model increases, the quality of the initial model
improves. The results show that the value of the best y is
sensitive to the initialization point and EM (y = 1) and
hard EM (y = 0) are often not the best choice.
this dataset obtains 84.9% accuracy on all tokens
and 72.3% accuracy on ambiguous tokens, which
is competitive with results reported in (Ravi and
Knight, 2009). To construct better initialization
points, we train a supervised HMM tagger on hold-
out labeled data. The quality of the initialization
points is varied by varying the size of the labeled
data over 15, 10, 20, 40, 801. Those initialization
points are then fed into different UEM algorithms.
Results For a particular y, we report the perfor-
mance of UEMy w.r.t. EM (y = 1.0) as given by
</bodyText>
<equation confidence="0.987191666666667">
Acc(UEMy) − Acc(UEMy=1.0)
rel(y) = (16)
Acc(UEMy=1.0)
</equation>
<bodyText confidence="0.999858083333333">
where Acc represents the accuracy as evaluated on
the ambiguous words of the given data. Note that
rel(y) &lt; 0, implies performance better or worse
than EM. The results are summarized in Figure 1.
Note that when we use the “posterior uniform”
initialization, EM wins by a significant margin. Sur-
prisingly, with the initialization point constructed
with merely 5 or 10 examples, EM is not the best
algorithm anymore. The best result for most cases is
obtained at y somewhere between 0 (hard EM) and 1
(EM). Furthermore, the results not only indicate that
a measure of “hardness” of EM i.e. the best value
</bodyText>
<page confidence="0.861572">
694
</page>
<bodyText confidence="0.993828914893617">
of -y, is closely related to the quality of the ini-
tialization point but also elicit a more fine-grained
relationship between initialization and UEM.
This experiment agrees with (Merialdo, 1994),
which shows that EM performs poorly in the semi-
supervised setting. In (Spitkovsky et al., 2010), the
authors show that hard EM (Viterbi EM) works bet-
ter than standard EM. We extend these results by
showing that this issue can be overcome with the
UEM framework by picking appropriate -y based on
the amount of available labeled data.
Semi-Supervised Entity-Relation Extraction
We conduct semi-supervised learning (SSL) ex-
periments on entity and relation type prediction
assuming that we are given mention boundaries.
We borrow the data and the setting from (Roth and
Yih, 2004). The dataset has 1437 sentences; four
entity types: PER, ORG, LOC, OTHERS and;
five relation types LIVE IN, KILL, ORG BASED IN,
WORKS FOR, LOCATED IN. We consider relations
between all within-sentence pairs of entities. We
add a relation type NONE indicating no relation
exists between a given pair of entities.
We train two log linear models for entity type and
relation type prediction, respectively via discrimina-
tive UEM. We work in a discriminative setting in
order to use several informative features which we
borrow from (Roth and Small, 2009). Using these
features, we obtain 56% average F1 for relations and
88% average F1 for entities in a fully supervised set-
ting with an 80-20 split which is competitive with
the reported results on this data (Roth and Yih, 2004;
Roth and Small, 2009). For our SSL experiments,
we use 20% of data for testing, a small amount, n%,
as labeled training data (we vary n), and the remain-
ing as unlabeled training data. We initialize with a
classifier trained on the given labeled data.
We use the following constraints on the posterior.
1) Type constraints: For two entities e1 and e2, the
relation type p(e1, e2) between them dictates a par-
ticular entity type (or in general, a set of entity types)
for both e1 and e2. These type constraints can be
expressed as simple logical rules which can be con-
verted into linear constraints. E.g. if the pair (e1, e2)
has relation type LOCATED IN then e2 must have en-
tity type LOC. This yields a logical rule which is
converted into a linear constraint as
</bodyText>
<figureCaption confidence="0.99378425">
Figure 2: Average F1 for relation prediction for varying
sizes of labeled data comparing the supervised baseline,
PR, CoDL, and UEM. UEM is statistically significantly
better than supervised baseline and PR in all the cases.
</figureCaption>
<bodyText confidence="0.9494488">
(p(e1, e2) == LOCATED IN) —* (e2 == LOC)
==&gt;. q (LOCATED IN; e1, e2) &lt; q (LOC; e2) .
Refer to (Roth and Yih, 2004) for more statistics on
this data and a list of all the type constraints used.
2) Expected count constraints: Since most entity
pairs are not covered by the given relation types, the
presence of a large number of NONE relations can
overwhelm SSL. To guide learning in the right direc-
tion, we use corpus-wide expected count constraints
for each non-NONE relation type. These constraints
are very similar to the label regularization technique
mentioned in (Mann and McCallum, 2010). Let Dr
be the set of entity pairs as candidate relations in the
entire corpus. For each non-NONE relation type p,
we impose the constraints
</bodyText>
<equation confidence="0.8611145">
Lp &lt; � q(p; e1, e2) &lt; Up ,
(e1,e2)ED,
</equation>
<bodyText confidence="0.999934692307692">
where Lp and Up are lower and upper bound on the
expected number of p relations in the entire corpus.
Assuming that the labeled and the unlabeled data are
drawn from the same distribution, we obtain these
bounds using the fractional counts of p over the la-
beled data and then perturbing it by +/- 20%.
Results We use Alg. 2 for solving the constrained
E-step. We report results averaged over 10 random
splits of the data and measure statistical significance
using paired t-test with p = 0.05. The results for
relation prediction are shown in Fig. 2. For each
trial, we split the labeled data into half to tune the
value of -y. For n = 5%, 10%, and 20%, the average
</bodyText>
<figure confidence="0.9623100625">
Avg. F1 for relations
0.48
0.46
0.44
0.42
0.38
0.36
0.34
0.32
0.4
0.3
Sup. Bas. PR
CoDL UEM
10 20
% of labeled data
695
</figure>
<bodyText confidence="0.999873680851064">
value of gamma is 0.52, 0.6, and 0.57, respectively;
the median values are 0.5, 0.6, and 0.5, respectively.
For relation extraction, UEM is always statistically
significantly better than the baseline and PR. The
difference between UEM and CoDL is small which
is not very surprising because hard EM approaches
like CoDL are known to work very well for discrim-
inative SSL. We omit the graph for entity predic-
tion because EM-based approaches do not outper-
form the supervised baseline there. However, no-
tably, for entities, for n = 10%, UEM outperforms
CoDL and PR and for 20%, the supervised baseline
outperforms PR statistically significantly.
Word Alignment Statistical word alignment is a
well known structured output application of unsu-
pervised learning and is a key step towards ma-
chine translation from a source language 5 to a tar-
get language T. We experiment with two language-
pairs: English-French and English-Spanish. We
use Hansards corpus for French-English trans-
lation (Och and Ney, 2000) and Europarl cor-
pus (Koehn, 2002) for Spanish-English translation
with EPPS (Lambert et al., 2005) annotation.
We use an HMM-based model for word-
alignment (Vogel et al., 1996) and add agreement
constraints (Liang et al., 2008; Ganchev et al., 2008)
to constrain alignment probabilities in one direction
(Po,: from 5 to T) to agree with the alignment prob-
abilities in the other direction (P02: from T to 5.)
We use a small development set of size 50 to tune
the model. Note that the amount of labeled data we
use is much smaller than the supervised approaches
reported in (Taskar et al., 2005; Moore et al., 2006)
and unsupervised approaches mentioned in (Liang et
al., 2008; Ganchev et al., 2008) and hence our results
are not directly comparable. For the E-step, we use
Alg. 3 with R=5 and picky from 10.0, 0.1, ... ,1.0},
tuning it over the development set.
During testing, instead of running HMM mod-
els for each direction separately, we obtain posterior
probabilities by performing agreement constraints-
based inference as in Alg. 3. This results in a
posterior probability distribution over all possible
alignments. To obtain final alignments, follow-
ing (Ganchev et al., 2008) we use minimum Bayes
risk decoding: we align all word pairs with poste-
rior marginal alignment probability above a certain
</bodyText>
<table confidence="0.998676888888889">
Size EM PR CoDL UEM EM PR CoDL UEM
En-Fr Fr-En
10k 23.54 10.63 14.76 9.10 19.63 10.71 14.68 9.21
50k 18.02 8.30 10.08 7.34 16.17 8.40 10.09 7.40
100k 16.31 8.16 9.17 7.05 15.03 8.09 8.93 6.87
En-Es Es-En
10k 33.92 22.24 28.19 20.80 31.94 22.00 28.13 20.83
50k 25.31 19.84 22.99 18.93 24.46 20.08 23.01 18.95
100k 24.48 19.49 21.62 18.75 23.78 19.70 21.60 18.64
</table>
<tableCaption confidence="0.992828">
Table 2: AER (Alignment Error Rate) comparisons
</tableCaption>
<bodyText confidence="0.925869545454546">
for French-English (above) and Spanish-English (below)
alignment for various data sizes. For French-English set-
ting, tuned y for all data-sizes is either 0.5 or 0.6. For
Spanish-English, tuned y for all data-sizes is 0.7.
threshold, tuned over the development set.
Results We compare UEM with EM, PR, and
CoDL on the basis of Alignment Error Rate (AER)
for different sizes of unlabeled data (See Tab. 2.)
See (Och and Ney, 2003) for the definition of AER.
UEM consistently outperforms EM, PR, and CoDL
with a wide margin.
</bodyText>
<sectionHeader confidence="0.998212" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998440541666667">
We proposed a continuum of EM algorithms
parameterized by a single parameter. Our frame-
work naturally incorporates constraints on output
variables and generalizes existing constrained and
unconstrained EM algorithms like standard and
hard EM, PR, and CoDL. We provided an efficient
Lagrange relaxation algorithm for inference with
constraints in the E-step and empirically showed
how important it is to choose the right EM version.
Our technique is amenable to be combined with
many existing variations of EM (Berg-Kirkpatrick
et al., 2010). We leave this as future work.
Acknowledgments: We thank Jo˜ao Grac¸a for provid-
ing the code and data for alignment with agreement. This
research is sponsored by the Army Research Laboratory
(ARL) under agreement W911NF-09-2-0053, Defense
Advanced Research Projects Agency (DARPA) Machine
Reading Program under Air Force Research Laboratory
(AFRL) prime contract no. FA8750-09-C-018, and an
ONR Award on Guiding Learning and Decision Making
in the Presence of Multiple Forms of Information. Any
opinions, findings, conclusions or recommendations are
those of the authors and do not necessarily reflect the
views of the funding agencies.
</bodyText>
<page confidence="0.920683">
696
</page>
<sectionHeader confidence="0.992822" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999965398058252">
K. Bellare, G. Druck, and A. McCallum. 2009. Alter-
nating projections for learning with expectation con-
straints. In UAI.
T. Berg-Kirkpatrick, A. Bouchard-Cˆot´e, J. DeNero, and
D. Klein. 2010. Painless unsupervised learning with
features. In ACL, HLT ’10.
D. P. Bertsekas. 1999. Nonlinear Programming. Athena
Scientific, 2nd edition.
P. Brown, S. D. Pietra, V. D. Pietra, and R. Mercer. 1993.
The mathematics of statistical machine translation: pa-
rameter estimation. Computational Linguistics.
M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-
supervision with constraint-driven learning. In ACL.
J. Clarke and M. Lapata. 2006. Constraint-based
sentence compression: An integer programming ap-
proach. In ACL.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum likelihood from incomplete data via the EM
algorithm. Journal of the Royal Statistical Society.
K. Ganchev, J. Graca, and B. Taskar. 2008. Better align-
ments = better translations. In ACL.
K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar.
2010. Posterior regularization for structured latent
variable models. Journal of Machine Learning Re-
search.
T. Hofmann. 2001. Unsupervised learning by probabilis-
tic latent semantic analysis. MlJ.
M. Kearns, Y. Mansour, and A. Y. Ng. 1997. An
information-theoretic analysis of hard and soft assign-
ment methods for clustering. In ICML.
D. Klein and C. D. Manning. 2004. Corpus-based induc-
tion of syntactic structure: models of dependency and
constituency. In ACL.
P. Koehn. 2002. Europarl: A multilingual corpus for
evaluation of machine translation.
T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Son-
tag. 2010. Dual decomposition for parsing with non-
projective head automata. In EMNLP.
P. Lambert, A. De Gispert, R. Banchs, and J. Marino.
2005. Guidelines for word alignment evaluation and
manual alignment. Language Resources and Evalua-
tion.
P. Liang, D. Klein, and M. I. Jordan. 2008. Agreement-
based learning. In NIPS.
G. S. Mann and A. McCallum. 2010. Generalized
expectation criteria for semi-supervised learning with
weakly labeled data. JMLR, 11.
A. Martins, N. A. Smith, and E. Xing. 2009. Concise
integer linear programming formulations for depen-
dency parsing. In ACL.
A. K. McCallum, R. Rosenfeld, T. M. Mitchell, and A. Y.
Ng. 1998. Improving text classification by shrinkage
in a hierarchy of classes. In ICML.
B. Merialdo. 1994. Tagging text with a probabilistic
model. Computational Linguistics.
R. C. Moore, W. Yih, and A. Bode. 2006. Improved
discriminative bilingual word alignment. In ACL.
R. M. Neal and G. E. Hinton. 1998. A new view of
the EM algorithm that justifies incremental, sparse and
other variants. In M. I. Jordan, editor, Learning in
Graphical Models.
K. Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell.
2000. Text classification from labeled and unlabeled
documents using EM. Machine Learning.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. In ACL.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. CL, 29.
S. Ravi and K. Knight. 2009. Minimized models for
unsupervised part-of-speech tagging. ACL, 1(August).
K. Rose. 1998. Deterministic annealing for clustering,
compression, classification, regression, and related op-
timization problems. In IEEE, pages 2210–2239.
D. Roth and K. Small. 2009. Interactive feature space
construction using semantic information. In Proc.
of the Annual Conference on Computational Natural
Language Learning (CoNLL).
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks. In
H. T. Ng and E. Riloff, editors, CoNLL.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In L. Getoor and B. Taskar, editors, In-
troduction to Statistical Relational Learning.
A. M. Rush and M. Collins. 2011. Exact decoding of
syntactic translation models through lagrangian relax-
ation. In ACL.
A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On dual decomposition and linear program-
ming relaxations for natural language processing. In
EMNLP.
A. Schrijver. 1986. Theory of linear and integer pro-
gramming. John Wiley &amp; Sons, Inc.
N. A. Smith and J. Eisner. 2004. Annealing techniques
for unsupervised statistical language learning. In ACL.
V. I. Spitkovsky, H. Alshawi, D. Jurafsky, and C. D. Man-
ning. 2010. Viterbi training improves unsupervised
dependency parsing. In CoNLL.
B. Taskar, S. Lacoste-Julien, and D. Klein. 2005. A dis-
criminative matching approach to word alignment. In
HLT-EMNLP.
N. Ueda and R. Nakano. 1998. Deterministic annealing
em algorithm. Neural Network.
</reference>
<page confidence="0.504204">
697
</page>
<reference confidence="0.905958">
S. Vogel, H. Ney, and C. Tillmann. 1996. Hmm-based
word alignment in statistical translation. In COLING.
</reference>
<page confidence="0.882332">
698
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.805982">
<title confidence="0.999718">Unified Expectation Maximization</title>
<author confidence="0.999769">Rajhans Samdani Ming-Wei Chang Dan Roth</author>
<affiliation confidence="0.999954">University of Illinois Microsoft Research University of Illinois</affiliation>
<email confidence="0.99713">rsamdan2@illinois.eduminchang@microsoft.comdanr@illinois.edu</email>
<abstract confidence="0.98805732">We present a general framework containing a graded spectrum of Expectation Maximization (EM) algorithms called Unified Expectation Maximization (UEM.) UEM is parameterized by a single parameter and covers existing algorithms like standard EM and hard EM, constrained versions of EM such as Constraint- Driven Learning (Chang et al., 2007) and Posterior Regularization (Ganchev et al., 2010), along with a range of new EM algorithms. For the constrained inference step in UEM we present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Bellare</author>
<author>G Druck</author>
<author>A McCallum</author>
</authors>
<title>Alternating projections for learning with expectation constraints.</title>
<date>2009</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="6582" citStr="Bellare et al., 2009" startWordPosition="1071" endWordPosition="1074">tep) and 0 (M-step) (Neal and Hinton, 1998). In particular, the E-step for EM can be written as q = arg min Q&apos;EQ KL(q&apos;, PO(h|x)) , (3) where 2 is the space of all distributions. While EM produces a distribution in the E-step, hard EM is thought of as producing a single output given by h* = arg max PO(h|x) . (4) hEW(x) However, one can also think of hard EM as producing a distribution given by q = S(h = h*). In this paper, we pursue this distributional view of both EM and hard EM and show its benefits. EM for Discriminative Models EM-like algorithms can also be used in discriminative settings (Bellare et al., 2009; Ganchev et al., 2010) specifically for semi-supervised learning (SSL.) Given some labeled and unlabeled data, such algorithms maximize a modified F(0, q) function: F(0, q) = L,(0) − c1110112 − c2KL(q, PO(h|x)) , (5) where, q, as before, is a probability distribution over x(x), L,(0) is the conditional log-likelihood of the labels given the features for the labeled data, and c1 and c2 are constants specified by the user; the KL divergence is measured only over the unlabeled data. The EM algorithm in this case has the same E-step as unsupervised EM, but the M-step is different. The M-step is s</context>
</contexts>
<marker>Bellare, Druck, McCallum, 2009</marker>
<rawString>K. Bellare, G. Druck, and A. McCallum. 2009. Alternating projections for learning with expectation constraints. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Berg-Kirkpatrick</author>
<author>A Bouchard-Cˆot´e</author>
<author>J DeNero</author>
<author>D Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In ACL, HLT ’10.</booktitle>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>T. Berg-Kirkpatrick, A. Bouchard-Cˆot´e, J. DeNero, and D. Klein. 2010. Painless unsupervised learning with features. In ACL, HLT ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P Bertsekas</author>
</authors>
<title>Nonlinear Programming. Athena Scientific, 2nd edition.</title>
<date>1999</date>
<contexts>
<context position="4075" citStr="Bertsekas, 1999" startWordPosition="626" endWordPosition="627">orithms. 2. To solve UEM (with constraints), we propose 1To be more precise, (Chang et al., 2007) mentioned using hard constraints as well as soft constraints in EM. In this paper, we refer to CoDL only as the EM framework with hard constraints. 688 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688–698, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics a dual projected subgradient ascent algorithm that generalizes several dual decomposition and Lagrange relaxation algorithms (Bertsekas, 1999) introduced recently in NLP (Ganchev et al., 2008; Rush and Collins, 2011). 3. We provide a way to implement a family of EM algorithms and choose the appropriate one, given the data and problem setting, rather than a single EM variation. We conduct experiments on unsupervised POS tagging, unsupervised word-alignment, and semi-supervised information extraction and show that choosing the right UEM variation outperforms existing EM algorithms by a significant margin. 2 Preliminaries Let x denote an input or observed features and h be a discrete output variable to be predicted from a finite set of</context>
<context position="16384" citStr="Bertsekas, 1999" startWordPosition="2848" endWordPosition="2849">outputs while showing that hard EM does much better in PCFG parsing. In particular, they empirically show that when initialized with a “good” set of parameters obtained by supervised learning, EM drifts away (thus losing accuracy) much farther than hard-EM. 4 Solving Constrained E-step with Lagrangian Dual In this section, we discuss how to solve the Estep (8) for UEM. It is a non-convex problem for -y &lt; 0; however, for -y = −oc (CoDL) one can use ILP solvers. We focus here on solving the E-step for -y &gt; 0 for which it is a convex optimization problem, and use a Lagrange relaxation algorithm (Bertsekas, 1999). Our contributions are two fold: • We describe an algorithm for UEM with constraints that is as easy to implement as PR or CoDL. Existing code for constrained EM (PR or CoDL) can be easily extended to run UEM. • We solve the E-step (8) using a Lagrangian dual-based algorithm which performs projected subgradient-ascent on dual variables. Our algorithm covers Lagrange relaxation and dual decomposition techniques (Bertsekas, 1999) which were recently popularized in NLP (Rush and Collins, 2011; Rush et al., 2010; Koo et al., 2010). Not only do we extend the algorithmic framework to a continuum of</context>
</contexts>
<marker>Bertsekas, 1999</marker>
<rawString>D. P. Bertsekas. 1999. Nonlinear Programming. Athena Scientific, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S D Pietra</author>
<author>V D Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation. Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="1603" citStr="Brown et al., 1993" startWordPosition="231" endWordPosition="234">andard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2010) corresponds to EM while Constraint-Driven Learning (CoDL)1</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. D. Pietra, V. D. Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semisupervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1764" citStr="Chang et al., 2007" startWordPosition="256" endWordPosition="259">a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2010) corresponds to EM while Constraint-Driven Learning (CoDL)1 (Chang et al., 2007) corresponds to hard EM. The problem of choosing between EM and hard EM (or between PR and CoDL) remains elusive, along with the possibility</context>
<context position="3556" citStr="Chang et al., 2007" startWordPosition="551" endWordPosition="554">a systematic way and helps find better alternatives. The contributions of this paper are as follows: 1. We propose a general framework called Unified Expectation Maximization (UEM) that presents a continuous spectrum of EM algorithms parameterized by a simple temperaturelike tuning parameter. The framework covers both constrained and unconstrained EM algorithms. UEM thus connects EM, hard EM, PR, and CoDL so that the relation between different algorithms can be better understood. It also enables us to find new EM algorithms. 2. To solve UEM (with constraints), we propose 1To be more precise, (Chang et al., 2007) mentioned using hard constraints as well as soft constraints in EM. In this paper, we refer to CoDL only as the EM framework with hard constraints. 688 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688–698, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics a dual projected subgradient ascent algorithm that generalizes several dual decomposition and Lagrange relaxation algorithms (Bertsekas, 1999) introduced recently in NLP (Ganchev et al., 2008; Rush and Collins, 2011). 3. We</context>
<context position="8003" citStr="Chang et al., 2007" startWordPosition="1309" endWordPosition="1312">e used for unlabeled data. 2.2 Constraints in EM It has become a common practice in the NLP community to use constraints on output variables to guide inference. Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints over binary variables (Roth and Yih, 2007). Assume that we have m linear constraints on outputs where the kth constraint can be written as ukTh ≤ bk . Defining a matrix U as UT = [u1T . . . uMT] and a vector b as bT = [b1, ... , bm], we write down the set of all feasible2 structures as {h |h ∈ H(x), Uh ≤ b} . Constraint-Driven Learning (CoDL) (Chang et al.,</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semisupervision with constraint-driven learning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Constraint-based sentence compression: An integer programming approach.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7734" citStr="Clarke and Lapata, 2006" startWordPosition="1262" endWordPosition="1265"> E-step as unsupervised EM, but the M-step is different. The M-step is similar to supervised learning as it finds 0 by maximizing a regularized conditional likelihood of the data w.r.t. the labels — true labels are used for labeled data and “soft” pseudo labels based on q are used for unlabeled data. 2.2 Constraints in EM It has become a common practice in the NLP community to use constraints on output variables to guide inference. Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints over binary variables (Roth and Yih, 2007). Assume that we have m linear constraints on ou</context>
</contexts>
<marker>Clarke, Lapata, 2006</marker>
<rawString>J. Clarke and M. Lapata. 2006. Constraint-based sentence compression: An integer programming approach. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society.</journal>
<contexts>
<context position="1307" citStr="Dempster et al., 1977" startWordPosition="187" endWordPosition="190"> present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-s</context>
<context position="5495" citStr="Dempster et al., 1977" startWordPosition="868" endWordPosition="871">ing, x is a sentence, h the corresponding POS tags, and 0 could be an HMM model; in word-alignment, x can be an English-French sentence pair, h the word alignment between the sentences, and 0 the probabilistic alignment model. Let S(h = h&apos;) be the Kronecker-Delta distribution centered at h&apos;, i.e., it puts a probability of 1 at h&apos; and 0 elsewhere. In the rest of this section, we review EM and constraints-based learning with EM. 2.1 EM Algorithm To obtain the parameter 0 in an unsupervised way, one maximizes log-likelihood of the observed data: L(0) = log PO(x) = log � PO(x, h) . (1) hEW(x) EM (Dempster et al., 1977) is the most common technique for learning 0, which maximizes a tight lower bound on L(0). While there are a few different styles of expressing EM, following the style of (Neal and Hinton, 1998), we define F(0, q) = L(0) − KL(q, PO(h|x)), (2) where q is a posterior distribution over x(x) and KL(p1, p2) is the KL divergence between two distributions p1 and p2. Given this formulation, EM can be shown to maximize F via block coordinate ascent alternating over q (E-step) and 0 (M-step) (Neal and Hinton, 1998). In particular, the E-step for EM can be written as q = arg min Q&apos;EQ KL(q&apos;, PO(h|x)) , (3</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Graca</author>
<author>B Taskar</author>
</authors>
<title>Better alignments = better translations.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="892" citStr="Ganchev et al., 2008" startWordPosition="122" endWordPosition="125"> Expectation Maximization (EM) algorithms called Unified Expectation Maximization (UEM.) UEM is parameterized by a single parameter and covers existing algorithms like standard EM and hard EM, constrained versions of EM such as ConstraintDriven Learning (Chang et al., 2007) and Posterior Regularization (Ganchev et al., 2010), along with a range of new EM algorithms. For the constrained inference step in UEM we present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM incl</context>
<context position="4124" citStr="Ganchev et al., 2008" startWordPosition="632" endWordPosition="635">we propose 1To be more precise, (Chang et al., 2007) mentioned using hard constraints as well as soft constraints in EM. In this paper, we refer to CoDL only as the EM framework with hard constraints. 688 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688–698, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics a dual projected subgradient ascent algorithm that generalizes several dual decomposition and Lagrange relaxation algorithms (Bertsekas, 1999) introduced recently in NLP (Ganchev et al., 2008; Rush and Collins, 2011). 3. We provide a way to implement a family of EM algorithms and choose the appropriate one, given the data and problem setting, rather than a single EM variation. We conduct experiments on unsupervised POS tagging, unsupervised word-alignment, and semi-supervised information extraction and show that choosing the right UEM variation outperforms existing EM algorithms by a significant margin. 2 Preliminaries Let x denote an input or observed features and h be a discrete output variable to be predicted from a finite set of possible outputs x(x). Let PO(x, h) be a probabi</context>
<context position="7817" citStr="Ganchev et al., 2008" startWordPosition="1273" endWordPosition="1276">rvised learning as it finds 0 by maximizing a regularized conditional likelihood of the data w.r.t. the labels — true labels are used for labeled data and “soft” pseudo labels based on q are used for unlabeled data. 2.2 Constraints in EM It has become a common practice in the NLP community to use constraints on output variables to guide inference. Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints over binary variables (Roth and Yih, 2007). Assume that we have m linear constraints on outputs where the kth constraint can be written as ukTh ≤ bk . Defining a matrix U as</context>
<context position="20663" citStr="Ganchev et al., 2008" startWordPosition="3609" endWordPosition="3612"> P2θ2. The E-step (8) can be written as arg min A(q1,q2;γ) (15) q1,q2 s.t. Eq1[Ueh1] = Eq2[Ueh2] Eq1[Uih1] ≤ Eq2[Uih2] , where A(q1, q2;γ) = KL(q1(h1), P1θ1(h1|x);γ) + KL(q2(h2), P2θ2(h2|x); γ). The application of Alg. 2 results in a dual decomposition scheme which is described in Alg. 3. Note that in the absence of inequality constraints and for γ = 0, our algorithm reduces to a simpler dual decomposition algorithm with agreement constraints described in (Rush et al., 2010; Koo et al., 2010). For γ = 1 with agreement constraints, our algorithm specializes to an earlier proposed technique by (Ganchev et al., 2008). Thus our algorithm puts these dual decomposition techniques with 4The analysis remains the same for a more general formulation with a constant offset vector on the R.H.S. and different matrices for h1 and h2. Algorithm 3 Projected Subgradient-based Lagrange Relaxation Algorithm that optimizes Eq. (15) 1: Input: Two distributions P1e1 and P2e2. 2: Output: Output distributions q1 and q2 in (15) 3: Define λT = [ T] λe T λiT] and UT = [Ue T Ui 4: λ ← 0 5: for t = 0, ... , R or until convergence do 6: q1(h1) ← G(h1, P1e1(·|x), λT U, γ) 7: q2(h2) ← G(h2, P2e2(·|x), −λTU, γ) 8: λe ← λe + ηt(−Eq1[Ue</context>
<context position="32121" citStr="Ganchev et al., 2008" startWordPosition="5576" endWordPosition="5579">y significantly. Word Alignment Statistical word alignment is a well known structured output application of unsupervised learning and is a key step towards machine translation from a source language 5 to a target language T. We experiment with two languagepairs: English-French and English-Spanish. We use Hansards corpus for French-English translation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised approaches mentioned in (Liang et al., 2008; Ganchev et al., 2008) and hence our results are not directly comparable. For the E-step, we use Alg. 3 with R=5 and picky from 10.0, 0.1, ... ,1.0}, tuning it over the devel</context>
</contexts>
<marker>Ganchev, Graca, Taskar, 2008</marker>
<rawString>K. Ganchev, J. Graca, and B. Taskar. 2008. Better alignments = better translations. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Grac¸a</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research.</journal>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Unsupervised learning by probabilistic latent semantic analysis.</title>
<date>2001</date>
<journal>MlJ.</journal>
<contexts>
<context position="12936" citStr="Hofmann, 2001" startWordPosition="2203" endWordPosition="2204">Without Constraints The E-step in this case, computes a q obeying only the simplex constraints: EhEH(x) q(h) = 1. For -y = 1, UEM minimizes KL(q, Pθ(h|x); 1) which is the same as minimizing KL(q, Pθ(h|x)) as in the standard EM (3). For -y = 0, UEM E is solving arg minqEQ hEH(x) −q(h) log Pθ(h|x) which is a linear programming (LP) problem. Due to the unimodularity of the simplex constraints (Schrijver, 1986), this LP outputs an integral q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic annealing for EM (Rose, 1998; Ueda and Nakano, 1998; Hofmann, 2001). However, the focus of deterministic annealing is solely to solve the standard EM while avoiding local maxima problems. 3.1.2 UEM With Con</context>
</contexts>
<marker>Hofmann, 2001</marker>
<rawString>T. Hofmann. 2001. Unsupervised learning by probabilistic latent semantic analysis. MlJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kearns</author>
<author>Y Mansour</author>
<author>A Y Ng</author>
</authors>
<title>An information-theoretic analysis of hard and soft assignment methods for clustering.</title>
<date>1997</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="12896" citStr="Kearns et al., 1997" startWordPosition="2195" endWordPosition="2198">t EM algorithms in the UEM family. 3.1.1 UEM Without Constraints The E-step in this case, computes a q obeying only the simplex constraints: EhEH(x) q(h) = 1. For -y = 1, UEM minimizes KL(q, Pθ(h|x); 1) which is the same as minimizing KL(q, Pθ(h|x)) as in the standard EM (3). For -y = 0, UEM E is solving arg minqEQ hEH(x) −q(h) log Pθ(h|x) which is a linear programming (LP) problem. Due to the unimodularity of the simplex constraints (Schrijver, 1986), this LP outputs an integral q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic annealing for EM (Rose, 1998; Ueda and Nakano, 1998; Hofmann, 2001). However, the focus of deterministic annealing is solely to solve the standard EM while avoiding l</context>
</contexts>
<marker>Kearns, Mansour, Ng, 1997</marker>
<rawString>M. Kearns, Y. Mansour, and A. Y. Ng. 1997. An information-theoretic analysis of hard and soft assignment methods for clustering. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1642" citStr="Klein and Manning, 2004" startWordPosition="237" endWordPosition="240">s on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2010) corresponds to EM while Constraint-Driven Learning (CoDL)1 (Chang et al., 2007) corresponds to ha</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>D. Klein and C. D. Manning. 2004. Corpus-based induction of syntactic structure: models of dependency and constituency. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A multilingual corpus for evaluation of machine translation.</title>
<date>2002</date>
<contexts>
<context position="31906" citStr="Koehn, 2002" startWordPosition="5544" endWordPosition="5545">EM-based approaches do not outperform the supervised baseline there. However, notably, for entities, for n = 10%, UEM outperforms CoDL and PR and for 20%, the supervised baseline outperforms PR statistically significantly. Word Alignment Statistical word alignment is a well known structured output application of unsupervised learning and is a key step towards machine translation from a source language 5 to a target language T. We experiment with two languagepairs: English-French and English-Spanish. We use Hansards corpus for French-English translation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised app</context>
</contexts>
<marker>Koehn, 2002</marker>
<rawString>P. Koehn. 2002. Europarl: A multilingual corpus for evaluation of machine translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>A M Rush</author>
<author>M Collins</author>
<author>T Jaakkola</author>
<author>D Sontag</author>
</authors>
<title>Dual decomposition for parsing with nonprojective head automata.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="910" citStr="Koo et al., 2010" startWordPosition="126" endWordPosition="129">ion (EM) algorithms called Unified Expectation Maximization (UEM.) UEM is parameterized by a single parameter and covers existing algorithms like standard EM and hard EM, constrained versions of EM such as ConstraintDriven Learning (Chang et al., 2007) and Posterior Regularization (Ganchev et al., 2010), along with a range of new EM algorithms. For the constrained inference step in UEM we present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classif</context>
<context position="7862" citStr="Koo et al., 2010" startWordPosition="1282" endWordPosition="1285">ularized conditional likelihood of the data w.r.t. the labels — true labels are used for labeled data and “soft” pseudo labels based on q are used for unlabeled data. 2.2 Constraints in EM It has become a common practice in the NLP community to use constraints on output variables to guide inference. Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints over binary variables (Roth and Yih, 2007). Assume that we have m linear constraints on outputs where the kth constraint can be written as ukTh ≤ bk . Defining a matrix U as UT = [u1T . . . uMT] and a vector b as bT = </context>
<context position="16917" citStr="Koo et al., 2010" startWordPosition="2934" endWordPosition="2937">nvex optimization problem, and use a Lagrange relaxation algorithm (Bertsekas, 1999). Our contributions are two fold: • We describe an algorithm for UEM with constraints that is as easy to implement as PR or CoDL. Existing code for constrained EM (PR or CoDL) can be easily extended to run UEM. • We solve the E-step (8) using a Lagrangian dual-based algorithm which performs projected subgradient-ascent on dual variables. Our algorithm covers Lagrange relaxation and dual decomposition techniques (Bertsekas, 1999) which were recently popularized in NLP (Rush and Collins, 2011; Rush et al., 2010; Koo et al., 2010). Not only do we extend the algorithmic framework to a continuum of algorithms, we also allow, unlike the aforementioned works, general inequality constraints over the output variables. Furthermore, we establish new and interesting connections between existing constrained inference techniques. 4.1 Projected Subgradient Ascent with Lagrangian Dual We provide below a high-level view of our algorithm, omitting the technical derivations due to lack of space. To solve the E-step (8), we introduce dual variables A — one for each expectation constraint in Q. The subgradient OA of the dual of Eq. (8) </context>
<context position="20539" citStr="Koo et al., 2010" startWordPosition="3588" endWordPosition="3591">ih1 ≤ Uih2 (inequality constraints)4 for given matrices Ue and Ui. Let their respective probabilistic models be P1θ1 and P2θ2. The E-step (8) can be written as arg min A(q1,q2;γ) (15) q1,q2 s.t. Eq1[Ueh1] = Eq2[Ueh2] Eq1[Uih1] ≤ Eq2[Uih2] , where A(q1, q2;γ) = KL(q1(h1), P1θ1(h1|x);γ) + KL(q2(h2), P2θ2(h2|x); γ). The application of Alg. 2 results in a dual decomposition scheme which is described in Alg. 3. Note that in the absence of inequality constraints and for γ = 0, our algorithm reduces to a simpler dual decomposition algorithm with agreement constraints described in (Rush et al., 2010; Koo et al., 2010). For γ = 1 with agreement constraints, our algorithm specializes to an earlier proposed technique by (Ganchev et al., 2008). Thus our algorithm puts these dual decomposition techniques with 4The analysis remains the same for a more general formulation with a constant offset vector on the R.H.S. and different matrices for h1 and h2. Algorithm 3 Projected Subgradient-based Lagrange Relaxation Algorithm that optimizes Eq. (15) 1: Input: Two distributions P1e1 and P2e2. 2: Output: Output distributions q1 and q2 in (15) 3: Define λT = [ T] λe T λiT] and UT = [Ue T Ui 4: λ ← 0 5: for t = 0, ... , R</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Sontag. 2010. Dual decomposition for parsing with nonprojective head automata. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lambert</author>
<author>A De Gispert</author>
<author>R Banchs</author>
<author>J Marino</author>
</authors>
<title>Guidelines for word alignment evaluation and manual alignment. Language Resources and Evaluation.</title>
<date>2005</date>
<marker>Lambert, De Gispert, Banchs, Marino, 2005</marker>
<rawString>P. Lambert, A. De Gispert, R. Banchs, and J. Marino. 2005. Guidelines for word alignment evaluation and manual alignment. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>D Klein</author>
<author>M I Jordan</author>
</authors>
<title>Agreementbased learning.</title>
<date>2008</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="32098" citStr="Liang et al., 2008" startWordPosition="5572" endWordPosition="5575">orms PR statistically significantly. Word Alignment Statistical word alignment is a well known structured output application of unsupervised learning and is a key step towards machine translation from a source language 5 to a target language T. We experiment with two languagepairs: English-French and English-Spanish. We use Hansards corpus for French-English translation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised approaches mentioned in (Liang et al., 2008; Ganchev et al., 2008) and hence our results are not directly comparable. For the E-step, we use Alg. 3 with R=5 and picky from 10.0, 0.1, ... ,1.0}, t</context>
</contexts>
<marker>Liang, Klein, Jordan, 2008</marker>
<rawString>P. Liang, D. Klein, and M. I. Jordan. 2008. Agreementbased learning. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Mann</author>
<author>A McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning with weakly labeled data.</title>
<date>2010</date>
<journal>JMLR,</journal>
<volume>11</volume>
<contexts>
<context position="29910" citStr="Mann and McCallum, 2010" startWordPosition="5191" endWordPosition="5194">eline and PR in all the cases. (p(e1, e2) == LOCATED IN) —* (e2 == LOC) ==&gt;. q (LOCATED IN; e1, e2) &lt; q (LOC; e2) . Refer to (Roth and Yih, 2004) for more statistics on this data and a list of all the type constraints used. 2) Expected count constraints: Since most entity pairs are not covered by the given relation types, the presence of a large number of NONE relations can overwhelm SSL. To guide learning in the right direction, we use corpus-wide expected count constraints for each non-NONE relation type. These constraints are very similar to the label regularization technique mentioned in (Mann and McCallum, 2010). Let Dr be the set of entity pairs as candidate relations in the entire corpus. For each non-NONE relation type p, we impose the constraints Lp &lt; � q(p; e1, e2) &lt; Up , (e1,e2)ED, where Lp and Up are lower and upper bound on the expected number of p relations in the entire corpus. Assuming that the labeled and the unlabeled data are drawn from the same distribution, we obtain these bounds using the fractional counts of p over the labeled data and then perturbing it by +/- 20%. Results We use Alg. 2 for solving the constrained E-step. We report results averaged over 10 random splits of the data</context>
</contexts>
<marker>Mann, McCallum, 2010</marker>
<rawString>G. S. Mann and A. McCallum. 2010. Generalized expectation criteria for semi-supervised learning with weakly labeled data. JMLR, 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martins</author>
<author>N A Smith</author>
<author>E Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="14845" citStr="Martins et al., 2009" startWordPosition="2578" endWordPosition="2581">d their associated values -y. This paper focuses on values of -y between 0 and 1 for the following reasons. First, the Estep (8) is non-convex for -y &lt; 0 and hence computationally expensive; e.g., hard EM (i.e. -y = −oc) requires ILP inference. For -y &gt; 0, (8) is a convex optimization problem which can be solved exactly and efficiently. Second, for -y = 0, the E-step solves max q E hEH(x) q(h) log Pθ(h|x) (10) s.t. Eq[Uh] &lt; b, q(h) &gt; 0, Vh E H(x), E hEH(x) q(h) = 1 , which is an LP-relaxation of hard EM (Eq. (4) and (9)). LP relaxations often provide a decent proxy to ILP (Roth and Yih, 2004; Martins et al., 2009). Third, -y E [0, 1] covers standard EM/PR. 3.2.1 Discussion: Role of -y The modified KL divergence can be related to standard KL divergence as KL(q, Pθ(h|x); -y) = min q E hEH(x) 691 KL(q, Pe(yJx)) + (1 − -y)H(q) — UEM (6) minimizes the former during the E-step, while Standard EM (3) minimizes the latter. The additional term (1 − -y)H(q) is essentially an entropic prior on the posterior distribution q which can be used to regularize the entropy as desired. For -y &lt; 1, the regularization term penalizes the entropy of the posterior thus reducing the probability mass on the tail of the distribut</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>A. Martins, N. A. Smith, and E. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K McCallum</author>
<author>R Rosenfeld</author>
<author>T M Mitchell</author>
<author>A Y Ng</author>
</authors>
<title>Improving text classification by shrinkage in a hierarchy of classes.</title>
<date>1998</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="1540" citStr="McCallum et al., 1998" startWordPosition="221" endWordPosition="224">d Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2</context>
</contexts>
<marker>McCallum, Rosenfeld, Mitchell, Ng, 1998</marker>
<rawString>A. K. McCallum, R. Rosenfeld, T. M. Mitchell, and A. Y. Ng. 1998. Improving text classification by shrinkage in a hierarchy of classes. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Merialdo</author>
</authors>
<title>Tagging text with a probabilistic model. Computational Linguistics.</title>
<date>1994</date>
<contexts>
<context position="26975" citStr="Merialdo, 1994" startWordPosition="4693" endWordPosition="4694">Figure 1. Note that when we use the “posterior uniform” initialization, EM wins by a significant margin. Surprisingly, with the initialization point constructed with merely 5 or 10 examples, EM is not the best algorithm anymore. The best result for most cases is obtained at y somewhere between 0 (hard EM) and 1 (EM). Furthermore, the results not only indicate that a measure of “hardness” of EM i.e. the best value 694 of -y, is closely related to the quality of the initialization point but also elicit a more fine-grained relationship between initialization and UEM. This experiment agrees with (Merialdo, 1994), which shows that EM performs poorly in the semisupervised setting. In (Spitkovsky et al., 2010), the authors show that hard EM (Viterbi EM) works better than standard EM. We extend these results by showing that this issue can be overcome with the UEM framework by picking appropriate -y based on the amount of available labeled data. Semi-Supervised Entity-Relation Extraction We conduct semi-supervised learning (SSL) experiments on entity and relation type prediction assuming that we are given mention boundaries. We borrow the data and the setting from (Roth and Yih, 2004). The dataset has 143</context>
</contexts>
<marker>Merialdo, 1994</marker>
<rawString>B. Merialdo. 1994. Tagging text with a probabilistic model. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
<author>W Yih</author>
<author>A Bode</author>
</authors>
<title>Improved discriminative bilingual word alignment.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32485" citStr="Moore et al., 2006" startWordPosition="5643" endWordPosition="5646"> 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised approaches mentioned in (Liang et al., 2008; Ganchev et al., 2008) and hence our results are not directly comparable. For the E-step, we use Alg. 3 with R=5 and picky from 10.0, 0.1, ... ,1.0}, tuning it over the development set. During testing, instead of running HMM models for each direction separately, we obtain posterior probabilities by performing agreement constraintsbased inference as in Alg. 3. This results in a posterior probability distribution over all possible alignments. To obtain final alignments, following (Ganchev et al., 2008) we use minimum Bayes risk decodi</context>
</contexts>
<marker>Moore, Yih, Bode, 2006</marker>
<rawString>R. C. Moore, W. Yih, and A. Bode. 2006. Improved discriminative bilingual word alignment. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Neal</author>
<author>G E Hinton</author>
</authors>
<title>A new view of the EM algorithm that justifies incremental, sparse and other variants.</title>
<date>1998</date>
<booktitle>Learning in Graphical Models.</booktitle>
<editor>In M. I. Jordan, editor,</editor>
<contexts>
<context position="5689" citStr="Neal and Hinton, 1998" startWordPosition="902" endWordPosition="905">e probabilistic alignment model. Let S(h = h&apos;) be the Kronecker-Delta distribution centered at h&apos;, i.e., it puts a probability of 1 at h&apos; and 0 elsewhere. In the rest of this section, we review EM and constraints-based learning with EM. 2.1 EM Algorithm To obtain the parameter 0 in an unsupervised way, one maximizes log-likelihood of the observed data: L(0) = log PO(x) = log � PO(x, h) . (1) hEW(x) EM (Dempster et al., 1977) is the most common technique for learning 0, which maximizes a tight lower bound on L(0). While there are a few different styles of expressing EM, following the style of (Neal and Hinton, 1998), we define F(0, q) = L(0) − KL(q, PO(h|x)), (2) where q is a posterior distribution over x(x) and KL(p1, p2) is the KL divergence between two distributions p1 and p2. Given this formulation, EM can be shown to maximize F via block coordinate ascent alternating over q (E-step) and 0 (M-step) (Neal and Hinton, 1998). In particular, the E-step for EM can be written as q = arg min Q&apos;EQ KL(q&apos;, PO(h|x)) , (3) where 2 is the space of all distributions. While EM produces a distribution in the E-step, hard EM is thought of as producing a single output given by h* = arg max PO(h|x) . (4) hEW(x) However</context>
</contexts>
<marker>Neal, Hinton, 1998</marker>
<rawString>R. M. Neal and G. E. Hinton. 1998. A new view of the EM algorithm that justifies incremental, sparse and other variants. In M. I. Jordan, editor, Learning in Graphical Models.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>A K Mccallum</author>
<author>S Thrun</author>
<author>T Mitchell</author>
</authors>
<title>Text classification from labeled and unlabeled documents using EM.</title>
<date>2000</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="1561" citStr="Nigam et al., 2000" startWordPosition="225" endWordPosition="228">s as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2010) corresponds to E</context>
</contexts>
<marker>Nigam, Mccallum, Thrun, Mitchell, 2000</marker>
<rawString>K. Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell. 2000. Text classification from labeled and unlabeled documents using EM. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="31872" citStr="Och and Ney, 2000" startWordPosition="5536" endWordPosition="5539">the graph for entity prediction because EM-based approaches do not outperform the supervised baseline there. However, notably, for entities, for n = 10%, UEM outperforms CoDL and PR and for 20%, the supervised baseline outperforms PR statistically significantly. Word Alignment Statistical word alignment is a well known structured output application of unsupervised learning and is a key step towards machine translation from a source language 5 to a target language T. We experiment with two languagepairs: English-French and English-Spanish. We use Hansards corpus for French-English translation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>CL,</journal>
<volume>29</volume>
<contexts>
<context position="34012" citStr="Och and Ney, 2003" startWordPosition="5898" endWordPosition="5901"> 28.19 20.80 31.94 22.00 28.13 20.83 50k 25.31 19.84 22.99 18.93 24.46 20.08 23.01 18.95 100k 24.48 19.49 21.62 18.75 23.78 19.70 21.60 18.64 Table 2: AER (Alignment Error Rate) comparisons for French-English (above) and Spanish-English (below) alignment for various data sizes. For French-English setting, tuned y for all data-sizes is either 0.5 or 0.6. For Spanish-English, tuned y for all data-sizes is 0.7. threshold, tuned over the development set. Results We compare UEM with EM, PR, and CoDL on the basis of Alignment Error Rate (AER) for different sizes of unlabeled data (See Tab. 2.) See (Och and Ney, 2003) for the definition of AER. UEM consistently outperforms EM, PR, and CoDL with a wide margin. 6 Conclusion We proposed a continuum of EM algorithms parameterized by a single parameter. Our framework naturally incorporates constraints on output variables and generalizes existing constrained and unconstrained EM algorithms like standard and hard EM, PR, and CoDL. We provided an efficient Lagrange relaxation algorithm for inference with constraints in the E-step and empirically showed how important it is to choose the right EM version. Our technique is amenable to be combined with many existing v</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. CL, 29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ravi</author>
<author>K Knight</author>
</authors>
<title>Minimized models for unsupervised part-of-speech tagging.</title>
<date>2009</date>
<pages>1</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="24487" citStr="Ravi and Knight, 2009" startWordPosition="4271" endWordPosition="4274"> (Spitkovsky et al., 2010) by exploring the space of EM algorithms in a “continuous” way. Furthermore, we also study the relation between quality of model initialization and the value of y in the case of POS tagging. This is inspired by a general “research wisdom” that hard EM is a better choice than EM with a good initialization point whereas the opposite is true with an “uninformed” initialization. Unsupervised POS Tagging We conduct experiments on unsupervised POS learning experiment with the tagging dictionary assumption. We use a standard subset of Penn Treebank containing 24,115 tokens (Ravi and Knight, 2009) with the tagging dictionary derived from the entire Penn Treebank. We run UEM with a first order (bigram) HMM model5. We consider initialization points of varying quality and observe the performance for y E [0, 1]. Different initialization points are constructed as follows. The “posterior uniform” initialization is created by spreading the probability uniformly over all possible tags for each token. Our EM model on 5(Ravi and Knight, 2009) showed that a first order HMM model performs much better than a second order HMM model on unsupervised POS tagging 0.05 0 -0.05 -0.1 -0.15 1.0 Figure 1: PO</context>
<context position="25734" citStr="Ravi and Knight, 2009" startWordPosition="4481" endWordPosition="4484"> relation between initial model parameters and y. We report the relative performance compared to EM (see Eq. (16)). The posterior uniform initialization does not use any labeled examples. As the no. of labeled examples used to create the initial HMM model increases, the quality of the initial model improves. The results show that the value of the best y is sensitive to the initialization point and EM (y = 1) and hard EM (y = 0) are often not the best choice. this dataset obtains 84.9% accuracy on all tokens and 72.3% accuracy on ambiguous tokens, which is competitive with results reported in (Ravi and Knight, 2009). To construct better initialization points, we train a supervised HMM tagger on holdout labeled data. The quality of the initialization points is varied by varying the size of the labeled data over 15, 10, 20, 40, 801. Those initialization points are then fed into different UEM algorithms. Results For a particular y, we report the performance of UEMy w.r.t. EM (y = 1.0) as given by Acc(UEMy) − Acc(UEMy=1.0) rel(y) = (16) Acc(UEMy=1.0) where Acc represents the accuracy as evaluated on the ambiguous words of the given data. Note that rel(y) &lt; 0, implies performance better or worse than EM. The </context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>S. Ravi and K. Knight. 2009. Minimized models for unsupervised part-of-speech tagging. ACL, 1(August).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rose</author>
</authors>
<title>Deterministic annealing for clustering, compression, classification, regression, and related optimization problems.</title>
<date>1998</date>
<booktitle>In IEEE,</booktitle>
<pages>2210--2239</pages>
<contexts>
<context position="13358" citStr="Rose, 1998" startWordPosition="2293" endWordPosition="2294">s an integral q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic annealing for EM (Rose, 1998; Ueda and Nakano, 1998; Hofmann, 2001). However, the focus of deterministic annealing is solely to solve the standard EM while avoiding local maxima problems. 3.1.2 UEM With Constraints UEM and Posterior Regularization (-y = 1) For -y = 1, UEM solves arg minqEQ KL (q, Pθ(h|x)) which is the same as Posterior Regularization (Ganchev et al., 2010). UEM and CoDL (-y = −oc) When -y —* −oc then due to an infinite penalty on the entropy of the posterior, the entropy must become zero. Thus, now the E-step, as expressed by Eq. (8), can be written as q = S(h = h*) where h* is obtained as arg max log Pθ</context>
</contexts>
<marker>Rose, 1998</marker>
<rawString>K. Rose. 1998. Deterministic annealing for clustering, compression, classification, regression, and related optimization problems. In IEEE, pages 2210–2239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>K Small</author>
</authors>
<title>Interactive feature space construction using semantic information.</title>
<date>2009</date>
<booktitle>In Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="28105" citStr="Roth and Small, 2009" startWordPosition="4874" endWordPosition="4877">undaries. We borrow the data and the setting from (Roth and Yih, 2004). The dataset has 1437 sentences; four entity types: PER, ORG, LOC, OTHERS and; five relation types LIVE IN, KILL, ORG BASED IN, WORKS FOR, LOCATED IN. We consider relations between all within-sentence pairs of entities. We add a relation type NONE indicating no relation exists between a given pair of entities. We train two log linear models for entity type and relation type prediction, respectively via discriminative UEM. We work in a discriminative setting in order to use several informative features which we borrow from (Roth and Small, 2009). Using these features, we obtain 56% average F1 for relations and 88% average F1 for entities in a fully supervised setting with an 80-20 split which is competitive with the reported results on this data (Roth and Yih, 2004; Roth and Small, 2009). For our SSL experiments, we use 20% of data for testing, a small amount, n%, as labeled training data (we vary n), and the remaining as unlabeled training data. We initialize with a classifier trained on the given labeled data. We use the following constraints on the posterior. 1) Type constraints: For two entities e1 and e2, the relation type p(e1,</context>
</contexts>
<marker>Roth, Small, 2009</marker>
<rawString>D. Roth and K. Small. 2009. Interactive feature space construction using semantic information. In Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<editor>In H. T. Ng and E. Riloff, editors, CoNLL.</editor>
<contexts>
<context position="7643" citStr="Roth and Yih, 2004" startWordPosition="1251" endWordPosition="1254">e is measured only over the unlabeled data. The EM algorithm in this case has the same E-step as unsupervised EM, but the M-step is different. The M-step is similar to supervised learning as it finds 0 by maximizing a regularized conditional likelihood of the data w.r.t. the labels — true labels are used for labeled data and “soft” pseudo labels based on q are used for unlabeled data. 2.2 Constraints in EM It has become a common practice in the NLP community to use constraints on output variables to guide inference. Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints</context>
<context position="14822" citStr="Roth and Yih, 2004" startWordPosition="2574" endWordPosition="2577">ent EM variations and their associated values -y. This paper focuses on values of -y between 0 and 1 for the following reasons. First, the Estep (8) is non-convex for -y &lt; 0 and hence computationally expensive; e.g., hard EM (i.e. -y = −oc) requires ILP inference. For -y &gt; 0, (8) is a convex optimization problem which can be solved exactly and efficiently. Second, for -y = 0, the E-step solves max q E hEH(x) q(h) log Pθ(h|x) (10) s.t. Eq[Uh] &lt; b, q(h) &gt; 0, Vh E H(x), E hEH(x) q(h) = 1 , which is an LP-relaxation of hard EM (Eq. (4) and (9)). LP relaxations often provide a decent proxy to ILP (Roth and Yih, 2004; Martins et al., 2009). Third, -y E [0, 1] covers standard EM/PR. 3.2.1 Discussion: Role of -y The modified KL divergence can be related to standard KL divergence as KL(q, Pθ(h|x); -y) = min q E hEH(x) 691 KL(q, Pe(yJx)) + (1 − -y)H(q) — UEM (6) minimizes the former during the E-step, while Standard EM (3) minimizes the latter. The additional term (1 − -y)H(q) is essentially an entropic prior on the posterior distribution q which can be used to regularize the entropy as desired. For -y &lt; 1, the regularization term penalizes the entropy of the posterior thus reducing the probability mass on th</context>
<context position="27554" citStr="Roth and Yih, 2004" startWordPosition="4784" endWordPosition="4787"> experiment agrees with (Merialdo, 1994), which shows that EM performs poorly in the semisupervised setting. In (Spitkovsky et al., 2010), the authors show that hard EM (Viterbi EM) works better than standard EM. We extend these results by showing that this issue can be overcome with the UEM framework by picking appropriate -y based on the amount of available labeled data. Semi-Supervised Entity-Relation Extraction We conduct semi-supervised learning (SSL) experiments on entity and relation type prediction assuming that we are given mention boundaries. We borrow the data and the setting from (Roth and Yih, 2004). The dataset has 1437 sentences; four entity types: PER, ORG, LOC, OTHERS and; five relation types LIVE IN, KILL, ORG BASED IN, WORKS FOR, LOCATED IN. We consider relations between all within-sentence pairs of entities. We add a relation type NONE indicating no relation exists between a given pair of entities. We train two log linear models for entity type and relation type prediction, respectively via discriminative UEM. We work in a discriminative setting in order to use several informative features which we borrow from (Roth and Small, 2009). Using these features, we obtain 56% average F1 </context>
<context position="29431" citStr="Roth and Yih, 2004" startWordPosition="5113" endWordPosition="5116">e2. These type constraints can be expressed as simple logical rules which can be converted into linear constraints. E.g. if the pair (e1, e2) has relation type LOCATED IN then e2 must have entity type LOC. This yields a logical rule which is converted into a linear constraint as Figure 2: Average F1 for relation prediction for varying sizes of labeled data comparing the supervised baseline, PR, CoDL, and UEM. UEM is statistically significantly better than supervised baseline and PR in all the cases. (p(e1, e2) == LOCATED IN) —* (e2 == LOC) ==&gt;. q (LOCATED IN; e1, e2) &lt; q (LOC; e2) . Refer to (Roth and Yih, 2004) for more statistics on this data and a list of all the type constraints used. 2) Expected count constraints: Since most entity pairs are not covered by the given relation types, the presence of a large number of NONE relations can overwhelm SSL. To guide learning in the right direction, we use corpus-wide expected count constraints for each non-NONE relation type. These constraints are very similar to the label regularization technique mentioned in (Mann and McCallum, 2010). Let Dr be the set of entity pairs as candidate relations in the entire corpus. For each non-NONE relation type p, we im</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In H. T. Ng and E. Riloff, editors, CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation.</title>
<date>2007</date>
<booktitle>Introduction to Statistical Relational Learning.</booktitle>
<editor>In L. Getoor and B. Taskar, editors,</editor>
<contexts>
<context position="8286" citStr="Roth and Yih, 2007" startWordPosition="1359" endWordPosition="1362">r constraints during sentence compression (Clarke and Lapata, 2006), and agreement constraints between wordalignment directions (Ganchev et al., 2008) or various parsing models (Koo et al., 2010). In the con689 text of EM, constraints can be imposed on the posterior probabilities, q, to guide the learning procedure (Chang et al., 2007; Ganchev et al., 2010). In this paper, we focus on linear constraints over h (potentially non-linear over x.) This is a very general formulation as it is known that all Boolean constraints can be transformed into sets of linear constraints over binary variables (Roth and Yih, 2007). Assume that we have m linear constraints on outputs where the kth constraint can be written as ukTh ≤ bk . Defining a matrix U as UT = [u1T . . . uMT] and a vector b as bT = [b1, ... , bm], we write down the set of all feasible2 structures as {h |h ∈ H(x), Uh ≤ b} . Constraint-Driven Learning (CoDL) (Chang et al., 2007) augments the E-step of hard EM (4) by imposing these constraints on the outputs. Constraints on structures can be relaxed to expectation constraints by requiring the distribution q to satisfy them only in expectation. Define expectation w.r.t. a distribution q over H(x) as EQ</context>
</contexts>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. In L. Getoor and B. Taskar, editors, Introduction to Statistical Relational Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Rush</author>
<author>M Collins</author>
</authors>
<title>Exact decoding of syntactic translation models through lagrangian relaxation.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="935" citStr="Rush and Collins, 2011" startWordPosition="130" endWordPosition="133">s called Unified Expectation Maximization (UEM.) UEM is parameterized by a single parameter and covers existing algorithms like standard EM and hard EM, constrained versions of EM such as ConstraintDriven Learning (Chang et al., 2007) and Posterior Regularization (Ganchev et al., 2010), along with a range of new EM algorithms. For the constrained inference step in UEM we present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011). UEM is as efficient and easy to implement as standard EM. Furthermore, experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is a new algorithm that wasn’t available earlier, exhibiting the benefits of the UEM framework. 1 Introduction Expectation Maximization (EM) (Dempster et al., 1977) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning. Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al.,</context>
<context position="4149" citStr="Rush and Collins, 2011" startWordPosition="636" endWordPosition="639"> precise, (Chang et al., 2007) mentioned using hard constraints as well as soft constraints in EM. In this paper, we refer to CoDL only as the EM framework with hard constraints. 688 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688–698, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics a dual projected subgradient ascent algorithm that generalizes several dual decomposition and Lagrange relaxation algorithms (Bertsekas, 1999) introduced recently in NLP (Ganchev et al., 2008; Rush and Collins, 2011). 3. We provide a way to implement a family of EM algorithms and choose the appropriate one, given the data and problem setting, rather than a single EM variation. We conduct experiments on unsupervised POS tagging, unsupervised word-alignment, and semi-supervised information extraction and show that choosing the right UEM variation outperforms existing EM algorithms by a significant margin. 2 Preliminaries Let x denote an input or observed features and h be a discrete output variable to be predicted from a finite set of possible outputs x(x). Let PO(x, h) be a probability distribution over (x</context>
<context position="16879" citStr="Rush and Collins, 2011" startWordPosition="2926" endWordPosition="2929"> the E-step for -y &gt; 0 for which it is a convex optimization problem, and use a Lagrange relaxation algorithm (Bertsekas, 1999). Our contributions are two fold: • We describe an algorithm for UEM with constraints that is as easy to implement as PR or CoDL. Existing code for constrained EM (PR or CoDL) can be easily extended to run UEM. • We solve the E-step (8) using a Lagrangian dual-based algorithm which performs projected subgradient-ascent on dual variables. Our algorithm covers Lagrange relaxation and dual decomposition techniques (Bertsekas, 1999) which were recently popularized in NLP (Rush and Collins, 2011; Rush et al., 2010; Koo et al., 2010). Not only do we extend the algorithmic framework to a continuum of algorithms, we also allow, unlike the aforementioned works, general inequality constraints over the output variables. Furthermore, we establish new and interesting connections between existing constrained inference techniques. 4.1 Projected Subgradient Ascent with Lagrangian Dual We provide below a high-level view of our algorithm, omitting the technical derivations due to lack of space. To solve the E-step (8), we introduce dual variables A — one for each expectation constraint in Q. The </context>
<context position="18490" citStr="Rush and Collins, 2011" startWordPosition="3220" endWordPosition="3223">e combine both the ideas by setting q(h) = G(h, Pet(·Jx), A&apos;U, -y) where G(h, P, v, 7) = S(h= arg max P(h&apos;)e−°h0) 7 = 0 . h0EN(x) (14) Alg. 2 shows the overall optimization scheme. The dual variables for inequality constraints are restricted to be positive and hence after a gradient update, negative dual variables are projected to 0. Note that for -y = 0, our algorithm is a Lagrange relaxation algorithm for approximately solving the E-step for CoDL (which uses exact arg max inference). Lagrange relaxation has been recently shown to provide exact and optimal results in a large number of cases (Rush and Collins, 2011). This shows that our range of algorithms is very broad — it includes PR and a good approximation to CoDL. Overall, the required optimization (8) can be solved efficiently if the expected value computation in the dual gradient (Eq. (11)) w.r.t. the posterior q in the primal (Eq (14)) can be performed efficiently. In cases where we can enumerate the possible outputs h efficiently, e.g. multi-class classification, we I − vh 7 1 P(h)7 e 1 7 e 7 &gt; 0 , vh0 7 E h0 P(h0) 692 Algorithm 2 Solving E-step of UEMγ for γ ≥ 0. 1: Initialize and normalize q; initialize λ = 0. 2: for t = 0, ... , R or until c</context>
</contexts>
<marker>Rush, Collins, 2011</marker>
<rawString>A. M. Rush and M. Collins. 2011. Exact decoding of syntactic translation models through lagrangian relaxation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Rush</author>
<author>D Sontag</author>
<author>M Collins</author>
<author>T Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="16898" citStr="Rush et al., 2010" startWordPosition="2930" endWordPosition="2933">or which it is a convex optimization problem, and use a Lagrange relaxation algorithm (Bertsekas, 1999). Our contributions are two fold: • We describe an algorithm for UEM with constraints that is as easy to implement as PR or CoDL. Existing code for constrained EM (PR or CoDL) can be easily extended to run UEM. • We solve the E-step (8) using a Lagrangian dual-based algorithm which performs projected subgradient-ascent on dual variables. Our algorithm covers Lagrange relaxation and dual decomposition techniques (Bertsekas, 1999) which were recently popularized in NLP (Rush and Collins, 2011; Rush et al., 2010; Koo et al., 2010). Not only do we extend the algorithmic framework to a continuum of algorithms, we also allow, unlike the aforementioned works, general inequality constraints over the output variables. Furthermore, we establish new and interesting connections between existing constrained inference techniques. 4.1 Projected Subgradient Ascent with Lagrangian Dual We provide below a high-level view of our algorithm, omitting the technical derivations due to lack of space. To solve the E-step (8), we introduce dual variables A — one for each expectation constraint in Q. The subgradient OA of t</context>
<context position="20520" citStr="Rush et al., 2010" startWordPosition="3584" endWordPosition="3587"> constraints) and Uih1 ≤ Uih2 (inequality constraints)4 for given matrices Ue and Ui. Let their respective probabilistic models be P1θ1 and P2θ2. The E-step (8) can be written as arg min A(q1,q2;γ) (15) q1,q2 s.t. Eq1[Ueh1] = Eq2[Ueh2] Eq1[Uih1] ≤ Eq2[Uih2] , where A(q1, q2;γ) = KL(q1(h1), P1θ1(h1|x);γ) + KL(q2(h2), P2θ2(h2|x); γ). The application of Alg. 2 results in a dual decomposition scheme which is described in Alg. 3. Note that in the absence of inequality constraints and for γ = 0, our algorithm reduces to a simpler dual decomposition algorithm with agreement constraints described in (Rush et al., 2010; Koo et al., 2010). For γ = 1 with agreement constraints, our algorithm specializes to an earlier proposed technique by (Ganchev et al., 2008). Thus our algorithm puts these dual decomposition techniques with 4The analysis remains the same for a more general formulation with a constant offset vector on the R.H.S. and different matrices for h1 and h2. Algorithm 3 Projected Subgradient-based Lagrange Relaxation Algorithm that optimizes Eq. (15) 1: Input: Two distributions P1e1 and P2e2. 2: Output: Output distributions q1 and q2 in (15) 3: Define λT = [ T] λe T λiT] and UT = [Ue T Ui 4: λ ← 0 5:</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schrijver</author>
</authors>
<title>Theory of linear and integer programming.</title>
<date>1986</date>
<publisher>John Wiley &amp; Sons, Inc.</publisher>
<contexts>
<context position="12732" citStr="Schrijver, 1986" startWordPosition="2160" endWordPosition="2162">(h|x)(8) s.t. Eq[Uh] &lt; b, q(h) &gt; 0, Vh E H(x), E hEH(x) q(h) = 1 . We discuss below, both the constrained and the unconstrained cases. Tab. 1 summarizes different EM algorithms in the UEM family. 3.1.1 UEM Without Constraints The E-step in this case, computes a q obeying only the simplex constraints: EhEH(x) q(h) = 1. For -y = 1, UEM minimizes KL(q, Pθ(h|x); 1) which is the same as minimizing KL(q, Pθ(h|x)) as in the standard EM (3). For -y = 0, UEM E is solving arg minqEQ hEH(x) −q(h) log Pθ(h|x) which is a linear programming (LP) problem. Due to the unimodularity of the simplex constraints (Schrijver, 1986), this LP outputs an integral q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic an</context>
</contexts>
<marker>Schrijver, 1986</marker>
<rawString>A. Schrijver. 1986. Theory of linear and integer programming. John Wiley &amp; Sons, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Annealing techniques for unsupervised statistical language learning.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="11046" citStr="Smith and Eisner, 2004" startWordPosition="1855" endWordPosition="1858">ric3 KL(·, ·;y) to obtain the posterior q. By simply varying y, UEM changes the metric of projection and obtains different variations of EM including EM (PR, in the presence of constraints) and hard EM (CoDL.) The M-step for UEM is exactly the same as EM (or discriminative EM.) The UEM Algorithm: Alg. 1 shows the UEM algorithm for both the generative (G) and the discriminative (D) case. We refer to the UEM algorithm with parameter y as UEM.y. 3.1 Relationship between UEM and Other EM Algorithms The relation between unconstrained versions of EM has been mentioned before (Ueda and Nakano, 1998; Smith and Eisner, 2004). We show that the relationship takes novel aspects in the presence of constraints. In order to better understand different UEM variations, we write the UEM E-step (6) explicitly as an optimization problem: 3The term ‘metric’ is used very loosely. KL����� -y) does not satisfy the mathematical properties of a metric. q = arg min KL(q&apos;,PB(h|x);y) , (6) Q&apos;EQ where KL(q, p; y) is a modified KL divergence: KL(q,p;y) = � yq(h) log q(h)−q(h) logp(h). (7) h0i(x) 690 Framework γ = −oo γ = 0 γ E (0, 1) γ = 1 γ = oo --+ 1 Constrained Hard EM Hard EM (NEW) UEM, Standard EM Deterministic Annealing EM Uncon</context>
<context position="12920" citStr="Smith and Eisner, 2004" startWordPosition="2199" endWordPosition="2202">e UEM family. 3.1.1 UEM Without Constraints The E-step in this case, computes a q obeying only the simplex constraints: EhEH(x) q(h) = 1. For -y = 1, UEM minimizes KL(q, Pθ(h|x); 1) which is the same as minimizing KL(q, Pθ(h|x)) as in the standard EM (3). For -y = 0, UEM E is solving arg minqEQ hEH(x) −q(h) log Pθ(h|x) which is a linear programming (LP) problem. Due to the unimodularity of the simplex constraints (Schrijver, 1986), this LP outputs an integral q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic annealing for EM (Rose, 1998; Ueda and Nakano, 1998; Hofmann, 2001). However, the focus of deterministic annealing is solely to solve the standard EM while avoiding local maxima problems. 3.</context>
</contexts>
<marker>Smith, Eisner, 2004</marker>
<rawString>N. A. Smith and J. Eisner. 2004. Annealing techniques for unsupervised statistical language learning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Spitkovsky</author>
<author>H Alshawi</author>
<author>D Jurafsky</author>
<author>C D Manning</author>
</authors>
<title>Viterbi training improves unsupervised dependency parsing.</title>
<date>2010</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="2028" citStr="Spitkovsky et al., 2010" startWordPosition="302" endWordPosition="305"> successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification (McCallum et al., 1998; Nigam et al., 2000), machine translation (Brown et al., 1993), and parsing (Klein and Manning, 2004). Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (Chang et al., 2007; Ganchev et al., 2010). Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific. Some works have shown that for certain tasks, hard EM is more suitable than regular EM (Spitkovsky et al., 2010). The same issue continues in the presence of constraints where Posterior Regularization (PR) (Ganchev et al., 2010) corresponds to EM while Constraint-Driven Learning (CoDL)1 (Chang et al., 2007) corresponds to hard EM. The problem of choosing between EM and hard EM (or between PR and CoDL) remains elusive, along with the possibility of simple and better alternatives, to practitioners. Unfortunately, little study has been done to understand the relationships between these variations in the NLP community. In this paper, we approach various EM-based techniques from a novel perspective. We belie</context>
<context position="15689" citStr="Spitkovsky et al., 2010" startWordPosition="2725" endWordPosition="2728">(6) minimizes the former during the E-step, while Standard EM (3) minimizes the latter. The additional term (1 − -y)H(q) is essentially an entropic prior on the posterior distribution q which can be used to regularize the entropy as desired. For -y &lt; 1, the regularization term penalizes the entropy of the posterior thus reducing the probability mass on the tail of the distribution. This is significant, for instance, in unsupervised structured prediction where the tail can carry a substantial amount of probability mass as the output space is massive. This notion aligns with the observation of (Spitkovsky et al., 2010) who criticize EM for frittering away too much probability mass on unimportant outputs while showing that hard EM does much better in PCFG parsing. In particular, they empirically show that when initialized with a “good” set of parameters obtained by supervised learning, EM drifts away (thus losing accuracy) much farther than hard-EM. 4 Solving Constrained E-step with Lagrangian Dual In this section, we discuss how to solve the Estep (8) for UEM. It is a non-convex problem for -y &lt; 0; however, for -y = −oc (CoDL) one can use ILP solvers. We focus here on solving the E-step for -y &gt; 0 for which</context>
<context position="23891" citStr="Spitkovsky et al., 2010" startWordPosition="4174" endWordPosition="4177"> a way to obtain gains over EM and hard EM in the constrained and unconstrained cases. We conduct experiments on POStagging, word-alignment, and information extraction; we inject constraints in the latter two. In all the cases we use our unified inference step to implement general UEM and the special cases of existing EM algorithms. Since both of our constrained problems involve large scale constrained inference during the E-step, we use UEM0 (with a Lagrange relaxation based E-step) as a proxy for ILP-based CoDL . As we vary y over [0, 1], we circumvent much of the debate over EM vs hard EM (Spitkovsky et al., 2010) by exploring the space of EM algorithms in a “continuous” way. Furthermore, we also study the relation between quality of model initialization and the value of y in the case of POS tagging. This is inspired by a general “research wisdom” that hard EM is a better choice than EM with a good initialization point whereas the opposite is true with an “uninformed” initialization. Unsupervised POS Tagging We conduct experiments on unsupervised POS learning experiment with the tagging dictionary assumption. We use a standard subset of Penn Treebank containing 24,115 tokens (Ravi and Knight, 2009) wit</context>
<context position="27072" citStr="Spitkovsky et al., 2010" startWordPosition="4707" endWordPosition="4710">nificant margin. Surprisingly, with the initialization point constructed with merely 5 or 10 examples, EM is not the best algorithm anymore. The best result for most cases is obtained at y somewhere between 0 (hard EM) and 1 (EM). Furthermore, the results not only indicate that a measure of “hardness” of EM i.e. the best value 694 of -y, is closely related to the quality of the initialization point but also elicit a more fine-grained relationship between initialization and UEM. This experiment agrees with (Merialdo, 1994), which shows that EM performs poorly in the semisupervised setting. In (Spitkovsky et al., 2010), the authors show that hard EM (Viterbi EM) works better than standard EM. We extend these results by showing that this issue can be overcome with the UEM framework by picking appropriate -y based on the amount of available labeled data. Semi-Supervised Entity-Relation Extraction We conduct semi-supervised learning (SSL) experiments on entity and relation type prediction assuming that we are given mention boundaries. We borrow the data and the setting from (Roth and Yih, 2004). The dataset has 1437 sentences; four entity types: PER, ORG, LOC, OTHERS and; five relation types LIVE IN, KILL, ORG</context>
</contexts>
<marker>Spitkovsky, Alshawi, Jurafsky, Manning, 2010</marker>
<rawString>V. I. Spitkovsky, H. Alshawi, D. Jurafsky, and C. D. Manning. 2010. Viterbi training improves unsupervised dependency parsing. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>S Lacoste-Julien</author>
<author>D Klein</author>
</authors>
<title>A discriminative matching approach to word alignment.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP.</booktitle>
<contexts>
<context position="32464" citStr="Taskar et al., 2005" startWordPosition="5639" endWordPosition="5642">slation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised approaches mentioned in (Liang et al., 2008; Ganchev et al., 2008) and hence our results are not directly comparable. For the E-step, we use Alg. 3 with R=5 and picky from 10.0, 0.1, ... ,1.0}, tuning it over the development set. During testing, instead of running HMM models for each direction separately, we obtain posterior probabilities by performing agreement constraintsbased inference as in Alg. 3. This results in a posterior probability distribution over all possible alignments. To obtain final alignments, following (Ganchev et al., 2008) we use mini</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>B. Taskar, S. Lacoste-Julien, and D. Klein. 2005. A discriminative matching approach to word alignment. In HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueda</author>
<author>R Nakano</author>
</authors>
<title>Deterministic annealing em algorithm.</title>
<date>1998</date>
<journal>Neural Network.</journal>
<contexts>
<context position="11021" citStr="Ueda and Nakano, 1998" startWordPosition="1851" endWordPosition="1854">ibutions Q w.r.t. a metric3 KL(·, ·;y) to obtain the posterior q. By simply varying y, UEM changes the metric of projection and obtains different variations of EM including EM (PR, in the presence of constraints) and hard EM (CoDL.) The M-step for UEM is exactly the same as EM (or discriminative EM.) The UEM Algorithm: Alg. 1 shows the UEM algorithm for both the generative (G) and the discriminative (D) case. We refer to the UEM algorithm with parameter y as UEM.y. 3.1 Relationship between UEM and Other EM Algorithms The relation between unconstrained versions of EM has been mentioned before (Ueda and Nakano, 1998; Smith and Eisner, 2004). We show that the relationship takes novel aspects in the presence of constraints. In order to better understand different UEM variations, we write the UEM E-step (6) explicitly as an optimization problem: 3The term ‘metric’ is used very loosely. KL����� -y) does not satisfy the mathematical properties of a metric. q = arg min KL(q&apos;,PB(h|x);y) , (6) Q&apos;EQ where KL(q, p; y) is a modified KL divergence: KL(q,p;y) = � yq(h) log q(h)−q(h) logp(h). (7) h0i(x) 690 Framework γ = −oo γ = 0 γ E (0, 1) γ = 1 γ = oo --+ 1 Constrained Hard EM Hard EM (NEW) UEM, Standard EM Determi</context>
<context position="13381" citStr="Ueda and Nakano, 1998" startWordPosition="2295" endWordPosition="2298">l q = ( ) S h = arg maxhEH(x) Pθ(h|x) which is the same as hard EM (4). It has already been noted in the literature (Kearns et al., 1997; Smith and Eisner, 2004; Hofmann, 2001) that this formulation (corresponding to our -y = 0) is the same as hard EM. In fact, for -y &lt; 0, UEM stays the same as hard EM because of negative penalty on the entropy. The range -y E (0, 1) has not been discussed in the literature, to the best of our knowledge. In Sec. 5, we show the impact of using UEMγfor -y E 10, 11. Lastly, the range of -y from oc to 1 has been used in deterministic annealing for EM (Rose, 1998; Ueda and Nakano, 1998; Hofmann, 2001). However, the focus of deterministic annealing is solely to solve the standard EM while avoiding local maxima problems. 3.1.2 UEM With Constraints UEM and Posterior Regularization (-y = 1) For -y = 1, UEM solves arg minqEQ KL (q, Pθ(h|x)) which is the same as Posterior Regularization (Ganchev et al., 2010). UEM and CoDL (-y = −oc) When -y —* −oc then due to an infinite penalty on the entropy of the posterior, the entropy must become zero. Thus, now the E-step, as expressed by Eq. (8), can be written as q = S(h = h*) where h* is obtained as arg max log Pθ(h|x) (9) hEH(x) s.t. U</context>
</contexts>
<marker>Ueda, Nakano, 1998</marker>
<rawString>N. Ueda and R. Nakano. 1998. Deterministic annealing em algorithm. Neural Network.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>Hmm-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="32048" citStr="Vogel et al., 1996" startWordPosition="5564" endWordPosition="5567">and PR and for 20%, the supervised baseline outperforms PR statistically significantly. Word Alignment Statistical word alignment is a well known structured output application of unsupervised learning and is a key step towards machine translation from a source language 5 to a target language T. We experiment with two languagepairs: English-French and English-Spanish. We use Hansards corpus for French-English translation (Och and Ney, 2000) and Europarl corpus (Koehn, 2002) for Spanish-English translation with EPPS (Lambert et al., 2005) annotation. We use an HMM-based model for wordalignment (Vogel et al., 1996) and add agreement constraints (Liang et al., 2008; Ganchev et al., 2008) to constrain alignment probabilities in one direction (Po,: from 5 to T) to agree with the alignment probabilities in the other direction (P02: from T to 5.) We use a small development set of size 50 to tune the model. Note that the amount of labeled data we use is much smaller than the supervised approaches reported in (Taskar et al., 2005; Moore et al., 2006) and unsupervised approaches mentioned in (Liang et al., 2008; Ganchev et al., 2008) and hence our results are not directly comparable. For the E-step, we use Alg.</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. Hmm-based word alignment in statistical translation. In COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>