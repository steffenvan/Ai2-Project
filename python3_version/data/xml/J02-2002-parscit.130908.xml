<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.982183">
The Combinatory Morphemic Lexicon
</title>
<author confidence="0.961885">
Cem Bozsahin∗
</author>
<affiliation confidence="0.919016">
Middle East Technical University
</affiliation>
<bodyText confidence="0.989968833333333">
Grammars that expect words from the lexicon may be at odds with the transparent projection of
syntactic and semantic scope relations of smaller units. We propose a morphosyntactic framework
based on Combinatory Categorial Grammar that provides flexible constituency, flexible category
consistency, and lexical projection of morphosyntactic properties and attachment to grammar in
order to establish a morphemic grammar-lexicon. These mechanisms provide enough expressive
power in the lexicon to formulate semantically transparent specifications without the necessity
to confine structure forming to words and phrases. For instance, bound morphemes as lexical
items can have phrasal scope or word scope, independent of their attachment characteristics but
consistent with their semantics. The controls can be attuned in the lexicon to language-particular
properties. The result is a transparent interface of inflectional morphology, syntax, and semantics.
We present a computational system and show the application of the framework to English and
Turkish.
</bodyText>
<sectionHeader confidence="0.997031" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999876666666667">
The study presented in this article is concerned with the integrated representation and
processing of inflectional morphology, syntax, and semantics in a unified grammar ar-
chitecture. An important issue in such integration is mismatches in morphological,
syntactic, and semantic bracketings. The problem was first noted in derivational mor-
phology. Williams (1981) provided examples from English; the semantic bracketings
in (1a–2a) are in conflict with the morphological bracketings in (1b–2b).
If the problem were confined to derivational morphology, we could avoid it by
making derivational morphology part of the lexicon that does not interact with gram-
mar. But this is not the case. Mismatches in morphosyntactic and semantic bracketing
</bodyText>
<note confidence="0.729419">
∗ Computer Engineering and Cognitive Science, Middle East Technical University, 06531 Ankara, Turkey.
</note>
<email confidence="0.938734">
E-mail: bozsahin@metu.edu.tr.
</email>
<figure confidence="0.869264555555555">
(1) a.
-ing b. G¨odel
G¨odel number number -ing
(1) a.
hydro electric
-ity b. hydro
electric -ity
© 2002 Association for Computational Linguistics
Computational Linguistics Volume 28, Number 2
</figure>
<bodyText confidence="0.99710475">
also abound. This article addresses such problems and their resolution in a computa-
tional system.1
M¨uller (1999, page 401) exemplifies the scope problem in German prefixes. (3a) is
in conflict with the bracketing required for the semantics of the conjunct (3b).
</bodyText>
<listItem confidence="0.895178">
(3) a. Wenn [Ihr Lust] und [noch nichts anderes vor-]habt,
</listItem>
<bodyText confidence="0.9191226">
if you pleasure and yet nothing else intend
k¨onnen wir sie ja vom Flughafen abholen
can we them PARTICLE from.the airport pick up
’If you feel like it and have nothing else planned, we can pick them
up at the airport.’
b. Ihr Lust habt UND noch nichts anderes vorhabt
Similar problems can be observed in Turkish inflectional suffixes. In the coordi-
nation of tensed clauses, the tense attaches to the verb of the rightmost conjunct (4a)
but applies to all conjuncts (4b). Delayed affixation appears to apply to all nominal
inflections (4c–e).
</bodyText>
<listItem confidence="0.936105">
(4) a. Zorunlu deprem sigortasa [y¨ur¨url¨u ˘ge girmi¸s] ama
</listItem>
<bodyText confidence="0.6442906">
mandatory earthquake insurance effect enter-ASP but
[tam anlamayla uygulanamama¸s]-ta
exactly apply-NEG-ASP-TENSE
’Mandatory earthquake insurance had gone into effect, but it had not
been enforced properly.’
</bodyText>
<listItem confidence="0.9699276">
b. y¨ur¨url¨u ˘ge girmi¸s-ti ama tam anlamayla uygulanamama¸s-ta
c. Adam-an [araba ve ev]-i
man-GEN car and house-POSS
’the man’s house and car’
d. Araba-ya [adam ve ¸cocuk]-lar-a g¨oster-di-m
Car-ACC man and child-PLU-DAT show-TENSE-PERS1
’(I) showed the car to the men and the children.’
e. Araba-ya sen-in [dost ve tanadak]-lar-an-a g¨oster-di-m
Car-ACC you-GEN friend and acq.-PLU-POSS-DAT showed
’(I) showed the car to the your friends and acquaintances.’
</listItem>
<footnote confidence="0.98946925">
1 Our use of the term morphosyntax needs some clarification. Some authors, (e.g., Jackendoff 1997),
take it to mean the syntax of words, in contrast to the syntax of phrases. By morphosyntax we mean
those aspects of morphology and syntax that collectively contribute to grammatical meaning
composition. This is more in line with the inflectional-morphology-is-syntax view. In this respect, we
will not address problems related to derivational morphology; its semantics is notoriously
noncompositional and does not interact with grammatical meaning. Moreover, without a semantically
powerful lexicon such as Pustejovsky’s (1991), even the most productive fragment of derivational
morphology is hard to deal with (Sehitoglu and Bozsahin 1999).
</footnote>
<page confidence="0.992895">
146
</page>
<note confidence="0.626061">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<bodyText confidence="0.9996347">
Phrasal scope of inflection can be seen in subordination and relativization as well.
In (5a), the entire nominalized clause marked with the accusative case is the object
of want. In (5b), the relative participle applies to the relative clause, which lacks an
object. The object’s case is governed by the subordinate verb, whose case requirements
might differ from that of the matrix verb (5c). As we show later in this section, the
coindexing mechanisms in word-based unification accounts of unbounded extraction
face a conflict between the local and the nonlocal behavior of the relativized noun,
mainly due to applying the relative participle -di˘g-i to the verbal stem ver rather than
the entire relative clause. A lexical entry for -di˘g-i would resolve the conflict and
capture the fact that it applies to nonsubjects uniformly.
</bodyText>
<figure confidence="0.777413">
(5) a. Can [Ay¸se’nin kitab-ı oku-ma-sı]-nı iste-di
C.NOM A.-GEN book-ACC read-INF-AGR-ACC want-TENSE
’Can wanted Ay¸se to read the book.’
lit. ’Can wanted Ay¸se’s-reading-the-book.’
b. Ben [Mehmet’in ¸cocu˘g-a/*-u ver]-di˘g-i kitab-ı oku-du-m
I.NOM M-GEN child-DAT/*ACC give-REL.OP book-ACC read-TENSE-PERS1
’I read the book that Mehmet gave to the child.’
c. Ben [Mehmet’in kitab-ı ver]-di˘g-i ¸cocu˘g-u/*-a g¨or-d¨u-m
I.NOM M-GEN book-ACC give-REL.OP child-ACC/*DAT see-TENSE-PERS1
’I saw the child to whom Mehmet gave the book.’
</figure>
<bodyText confidence="0.999820592592593">
The morphological/phrasal scope conflict of affixes is not particular to morpho-
logically rich languages. Semantic composition of affixes in morphologically simpler
languages poses problems with word (narrow) scope of inflections. For instance, fake
trucks needs the semantics (plu(faketruck)), which corresponds to the surface brack-
eting [fake truck]-s, because it denotes the nonempty nonsingleton sets of things that
are not trucks but fake trucks (Carpenter 1997). Four trucks, on the other hand, has the
semantics (four(plu truck)), which corresponds to four [truck]-s, because it denotes the
subset of nonempty nonsingleton sets of trucks with four members.
The status of inflectional morphology among theories of grammar is far from
settled, but, starting with Chomsky (1970), there seems to be an agreement that deriva-
tional morphology is internal to the lexicon. Lexical Functional Grammar (LFG)
(Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson
1982) consider inflectional morphology to be part of syntax, but it has been del-
egated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard
and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195).
The representational status of the morpheme is even less clear. Parallel develop-
ments in computational studies of HPSG propose lexical rules to model inflectional
morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988)
and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal re-
garding inflectional morphology. Finally, morphosyntactic aspects have always
been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty
1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock
1988), but the issues of constraining the morphosyntactic derivations and re-
solving the apparent mismatches have been relatively untouched in computational
studies.
We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal
CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with
</bodyText>
<page confidence="0.994158">
147
</page>
<note confidence="0.88227">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.983239367346939">
the issues raised so far. For convenience, we call a grammar that expects words from
the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic
grammar. A lexemic PSG provides a lexical interface for inflected words (X0s) such
that a regular grammar subcomponent handles lexical insertion at X0.2 In (4d), the
right conjunct ¸cocuk-lar-a is analyzed as N0 → ¸cocuk-PLU-DAT (or N0 → N0, -DAT,
N0, → N0,, -PLU, N0,, → Stem, as a regular grammar). Assuming a syncategorematic
coordination schema, that is, X → X and X, the N0 in the left and right conjuncts
of this example would not be of the same type. Revising the coordination schema
such that only the root features coordinate would not be a solution either. In (4e),
the relation of possession that is marked on the right conjunct must be carried over
to the left conjunct as well. What is required for these examples is that the syntac-
tic constituent X in the schema be analyzed as X-PLU(-POSS)-DAT, after N0 and N0
coordination.
What we need then is not a lexemic but a morphemic organization in which brack-
eting of free and bound morphemes is regulated in syntax. The lexicon, of course,
must now supply the ingredients of a morphosyntactic calculus. This leads to a the-
ory in which semantic composition parallels morphosyntactic combination by virtue
of bound morphemes’ being able to pick their domains just like words (above X0,
if needed). A comparison of English and Turkish in this regard is noteworthy. The
English relative pronouns that/whom and the Turkish relative participle -di˘g-i would
have exactly the same semantics when the latter is granted a representational status
in the lexicon (see Section 6).
Furthermore, rule-based PSGs project a rigid notion of surface constituency. Steed-
man (2000) argued, however, that syntactic processes such as identical element dele-
tion under coordination call for flexible constituency, such as SO (subject-object) in
the SVO &amp; SO gapping pattern of English and SV (subject-verb) constituency in
the OSV &amp; SV pattern of Turkish. Nontraditional constituents are also needed in
specifying semantically transparent constituency of words, affixes, clitics, and
phrases.
Constraint-based PSGs such as HPSG appeal to coindexation and feature passing
via unification, rather than movement, to deal with such processes. HPSG also makes
the commitment that inflectional morphology is internal to the lexicon, handled either
by lexical rules (Pollard and Sag 1994) or by lexical inheritance (Miller and Sag 1997).
We look at (5c) to highlight a problem with the stem-and-inflections view. As words en-
ter syntax fully inflected, the sign of the verb ver-di˘g-i in the relative clause (5c) would
be as in (6a), in which the SUBCAT list of the verb stem is, as specified in the lexi-
cal entry for ver, unsaturated. The participle adds coindexation in MODJ · · · JINDEX.
The HPSG analysis of this example would be as in Figure 1. Although passing the
agreement features of the head separately (Sehitoglu 1996) solves the case problem
alluded to in (5c), however, structure sharing of the NPdat with the SLASH, INDEX,
and CONTENT features of ver-di˘g-i is needed for semantics (GIVEE), but this conflicts
with the head features of the topmost NPacc in the tree. The relative participle as a
lexical entry (e.g., (6b)) would resolve the problem with subcategorization because its
SUBCAT list is empty (like the relative pronoun that in English), hence there would be
no indirect dependence of the nonlocal SLASH feature and the local SUBCAT feature
via semantics (CONTENT). Such morphemic alternatives are not considered in HPSG,
however, and require a significant revision in the theory. Furthermore, HPSG’s lexical
2 But see Creider, Hankamer, and Wood (1995), which argues that the morphotactics of human languages
is not regular but linear context free.
</bodyText>
<page confidence="0.991706">
148
</page>
<note confidence="0.622781">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<bodyText confidence="0.9964515">
assignment for trace introduces phonologically null elements into the lexicon, which,
as we show later, is not necessary.
</bodyText>
<figure confidence="0.979657740740741">
(6) a. ver-di˘g-i := �
�
� � �PERSON thin
HEAD AGR [NUMBER sing
CAT CASE dat
�
SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt;
LOCAL MOD  |MODSYN  |LOCAL  |CONT  |INDEX 1
� �
RELNgive
GIVER 3
CONTENT � �
GIVEE 1
GIFT 2
NONLOCAL  |TO-BIND  |SLASH { 1 }
1
1
�
� � � � � � � � � � � � � � �
b. -di˘g-i := �
�
� CAT f HEAD noun [acc or dat]l
LOCAL LSUBCAT &lt;&gt; J
CONTENT npro[INDEX 1 ]
NONLOCAL  |INHER  |SLASH { 1 }
1
1
</figure>
<bodyText confidence="0.998067333333333">
MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different
modes of combination in the grammar. In addition to binary modes such as wrapping
and commutative operations, unary modalities provide finer control over the cate-
gories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyn-
tactic features such as case, number, and person for economy in lexical assignments.
For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for
case and declension. Underspecification is dealt with in the grammar using inclusion
postulates (e.g., (7)). The interaction of different modalities is regulated by distribution
postulates.
</bodyText>
<equation confidence="0.5935815">
(7) ✷caser F_ X ✷caser F_ X
✷nomr F_ X ✷accr F_ X
</equation>
<bodyText confidence="0.9998599375">
Lexical assignments to inflected words carry unary modalities: boys has the type
✷plN, in contrast to ✷sgN for boy. Although such regulation of inflectional features
successfully mediates, for example, subject-verb agreement or NP-internal case agree-
ment (as in German), it is essentially word-based, because type assignments are to
inflected forms; morphemes do not carry types. This reliance on word types neces-
sitates a lexical rule–based approach to some morphosyntactic processes that create
indefinitely long words, such as ki-relativization in Turkish (see Section 6.5). But lexical
rules for such processes risk nontermination (Sehitoglu and Bozsahin 1999). Our main
point of departure from MCG accounts is the morphemic versus lexemic nature of the
lexicon: The morphosyntactic and attachment modalities originate from the lexicon;
they are not properties of the grammar (we elaborate more on this later). This paves
the way to the morphemic lexicon by licensing type assignments to units smaller than
words.
Besides problems with lexical rules, the automata-theoretic power of MCGs is
problematic: Unrestricted use of structural modalities and postulates leads to Tur-
ing completeness (Carpenter 1999). Indeed, one of the identifiable fragments of Mul-
</bodyText>
<page confidence="0.996321">
149
</page>
<note confidence="0.636086">
Computational Linguistics Volume 28, Number 2
</note>
<figureCaption confidence="0.983299">
Figure 1
</figureCaption>
<bodyText confidence="0.977049444444444">
HPSG analysis of (5c).
timodal languages that is computationally tractable is Combinatory Categorial lan-
guages (Kruijff and Baldridge 2000), which we adopt as the basis for the framework
presented here. We propose a morphosyntactic Combinatory Categorial Grammar
(CCG) in which the grammar and the morphemic lexicon refer to morphosyntactic
types rather than syntactic types. We first introduce the syntactic CCG in Section 2.
Morphosyntactic CCG is described in Section 3. In Section 4, we look at the compu-
tational aspects of the framework. We then show its realization for some aspects of
English (Section 5) and Turkish (Section 6).
</bodyText>
<page confidence="0.995648">
150
</page>
<note confidence="0.750456">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<sectionHeader confidence="0.929896" genericHeader="keywords">
2. Syntactic Types
</sectionHeader>
<bodyText confidence="0.900558333333333">
CG is a theory of grammar in which the form-meaning relation is conceived as a
transparent correspondence between the surface-syntactic and semantic combinatorics
(Jacobson 1996). A CCG sign can be represented as a triplet π − σ: µ, where π is the
prosodic element, σ is its syntactic type, and µ its semantic type. For instance, the
lexical assignment for read is (8).3
(8) read := read − (S\NP)/NP: λx.λy.read xy
</bodyText>
<sectionHeader confidence="0.441244" genericHeader="introduction">
Definition (Syntactic Types)
</sectionHeader>
<listItem confidence="0.898178">
• The set of basic syntactic categories: As = {N,NP,S,S−t,S+t}
• The set of complex syntactic categories: Bs
— As C Bs
— If X E Bs and Y E Bs, thenX\Y and X/Y E Bs
</listItem>
<bodyText confidence="0.96057925">
The classical Ajdukiewicz/Bar-Hillel (AB) CG is weakly equivalent to Context-
Free Grammars (Bar-Hillel, Gaifman, and Shamir 1960). It has function application
rules, defined originally in a nondirectional fashion. The directional variants and their
associated semantics are as follows:
</bodyText>
<listItem confidence="0.860579">
(9) Forward Application (&gt;):4 X/Y: f Y: a X: fa
Backward Application (&lt;): Y: a X\Y: f X: fa
</listItem>
<bodyText confidence="0.918589333333333">
CCG (Steedman 1985, 1987, 1988; Szabolcsi 1983, 1987) is an extended version of
AB that includes function composition (10), substitution, and type raising (11). These
extensions make CCGs mildly context sensitive.
</bodyText>
<listItem confidence="0.987172333333333">
(10) Forward Composition (&gt;B): X/Y: f Y/Z: g X/Z: λx.f (gx)
Backward Composition (&lt;B): Y\Z:g X\Y: f X\Z: λx.f (gx)
(11) Forward Type Raising (&gt;T):5 X: a T/(T\X): λf .f [a]
</listItem>
<subsubsectionHeader confidence="0.433367">
Backward Type Raising (&lt;T): X: a T\(T/X): λf .f [a]
</subsubsectionHeader>
<bodyText confidence="0.6925785">
Type raising is an order-preserving operation. For instance, Lambek’s (1958) cat-
egory S/(S\NP) is a positional encoding of the grammatical subject as a function
</bodyText>
<footnote confidence="0.979756818181818">
3 We take π to be the surface string for simplicity. We use the “result-first” convention for CG. For
instance, transitive verbs of English are written as (S\NP)/NP, which translates to (NP\S)/NP in the
“result-on-top” convention.
4 We omit the prosodic element for ease of exposition. For instance, the complete definition of forward
application is s1 − X/Y: f s2 − Y: a ⇒ s1 • s2 − X: fa, where • is prosodic combination and fa is the
application of f to a. The • will play a crucial role in the lexicalization of attachment later on.
5 The lambda term f [a] denotes internal one-step β-reduction of f on a. In parsing, we achieve the same
effect by partial execution (Pereira and Shieber 1987). Af .f [a] is encoded as (a&amp;quot;F)&amp;quot;F in Prolog, where ˆ
is lambda abstraction. We opted for the explicit f [a] notation mainly for ease of exposition (cf. the
semantics of raising verbs, relative participles, etc. in Section 6). Moreover, as Pereira and Shieber
noted, (a&amp;quot;F)&amp;quot;F is not a lambda term in the strict sense because a is not a variable.
</footnote>
<page confidence="0.983363">
151
</page>
<note confidence="0.440032">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.999212142857143">
looking for a VP (= S\NP) to the right to become S. The reversal of directionality such
as topicalization (e.g., This book, I recommend) requires another schema. The reversal
is with respect to the position of the verb, which we shall call contraposition and
formulate as in (12).6 (&lt;XP) is leftward extraction of a right constituent, and (&gt;XP)
is rightward extraction of a left constituent, both of which are marked constructions.
Directionally insensitive types such as T|(T|X) cause the collapse of directionality in
surface grammar (Moortgat 1988a).
</bodyText>
<figure confidence="0.46970075">
(12) Leftward Contraposition (&lt;XP): X: a S+t/(S/X): λf .f [a]
S+t/(S+t/X): λf.f [a]
Rightward Contraposition (&gt;XP): X: a S−t\(S\X): λf .f [a]
S−t\(S−t\X): λf.f [a]
</figure>
<bodyText confidence="0.999584538461538">
The semantics of contraposition depends on discourse properties as well. We leave
this issue aside by (1) noting that it is related to type raising in changing the function-
argument relation and (2) categorizing the sentence as S+t (topicalized) or S−t (detopi-
calized), which are not discourse equivalent to S. Syntactic characterization as such
also helps a discourse component do its work on syntactic derivations.
CCG’s notion of interpretation is represented in the Predicate-Argument Structure
(PAS). Its organization is crucial for our purposes, since the bracketing in the PAS is
the arbitrator for reconciling the bracketings in morphology and syntax via proper
lexical type assignments. It is the sole level of representation in CCG (Steedman 1996,
page 89).7 It is the level at which the conditions on objects of interpretation, such as
binding and control, are formulated. For instance, Steedman (1996) defines c-command
and binding conditions A, B, and C over the PAS. The PAS also reflects the obliqueness
order of the arguments:
</bodyText>
<subsubsectionHeader confidence="0.783615">
Predicate ... Tertiary-Term Secondary-Term Primary-Term
</subsubsectionHeader>
<bodyText confidence="0.9999415">
Assuming left associativity for juxtaposition, this representation yields the brack-
eting in (13) for the PAS. Having the primary argument as the outermost term is
motivated by the observations on binding asymmetries between subjects and comple-
ments in many languages (e.g., *Himself saw John, *heself).
</bodyText>
<equation confidence="0.731858">
(13)
</equation>
<sectionHeader confidence="0.943665" genericHeader="method">
3. Morphosyntactic Types
</sectionHeader>
<bodyText confidence="0.9927975">
A syntactic type such as N does not discriminate morphosyntactically. A finer dis-
tinction can be made as singular nouns, plural nouns, case-marked nouns, etc. For
</bodyText>
<footnote confidence="0.993583">
6 In fact, topicalization of nonperipheral arguments (This book, I would give to Mary) requires that (12) be
finitely schematized over valencies, such as S, S/NP, S/PP (Steedman 1985).
7 We will not elaborate on the theoretical consequences of having this level of representation; see, for
instance, Dowty (1991) and Steedman (1996).
</footnote>
<page confidence="0.993816">
152
</page>
<figure confidence="0.999629702702703">
Bozsahin The Combinatory Morphemic Lexicon
free (f)
(t)
(n)
n-num
s-tense
(v)
n-base (b) s-base
s-base (v)
(r)
n-relbase n-root
(l)
s-caus
(u)
s-reflex (x) s-recip
(a)
s-person
s-modal
(m)
n-comp (m) n-poss
(a)
(o)
(g)
(i)
(p)
n-num
(n)
n-case (c)
n-base (b)
s-tense
s-abil
s-neg
s-imp
s-pass
(b)
(c)
free (f)
</figure>
<figureCaption confidence="0.98401">
Figure 2
</figureCaption>
<bodyText confidence="0.97721035">
The lattice of diacritics for (a) Turkish and (b) English.
instance, the set of number-marked nouns can be represented as n✶N, where ✶ is a
morphosyntactic modality (“equals”) and n is a diacritic (for number). Books is of type
n✶N, but book is not. The type for books can be obtained morphosyntactically by as-
signing -s (-PLU) the functor type n✶ N\ b✶ N, where b stands for base. A syntactic type
such as N\N overgenerates.
Another modality, &lt; (“up to and equals”), allows wider domains in morphosyn-
tactic typing. For instance, n
&lt; N represents the set of nouns marked on number or
any other diacritic that is lower than number in a partial order (e.g., Figure 2). The
inflectional paradigm of a language can be represented as a partial ordering us-
ing the modalities.8 For instance, if the paradigm is Base-Number-Case, we have
υ( &lt; b N) C υ( &lt; n N) C υ( &lt;c N), where υ(τ) is the valuation function from the mor-
phosyntactic type τ to the set of strings that have the type τ. The ✶ modality is more
strict than &lt; to provide finer control; although υ( &lt;n N) C υ(&lt;c N), υ(n ✶ N) Cz υ(c✶ N),
because a noun can be number marked but not case marked or vice versa. Also,
υ( ✶i N) C υ(&lt;i N) for any diacritic i since, for instance, the set of nouns marked up to
and including case includes case-marked, number-marked, and unmarked nouns.
The lattice consistency condition is imposed on the set of diacritics to ensure
category unity.9 In other words, the syntactic type X can be viewed as an abbreviation
</bodyText>
<equation confidence="0.534333">
T
</equation>
<bodyText confidence="0.969418">
for the morphosyntactic type &lt; X where T is the universal upper bound. It is the
</bodyText>
<footnote confidence="0.960294666666667">
8 See Heylen (1997) on use of unary modalities for a similar purpose in lexemic MCG.
9 In a lattice L, x ≤ y (morphosyntactically, x &lt; y) is equivalent to the consistency properties x ∧ y = x
and x ∨ y = y. We use the join operator for this check, thus it suffices to have a join semilattice.
</footnote>
<page confidence="0.991894">
153
</page>
<note confidence="0.432977">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.9475865">
most underspecified category of X which subsumes all morphosyntactically decorated
versions of X. Figure 2 shows the lattice for English and Turkish.
</bodyText>
<sectionHeader confidence="0.341257" genericHeader="method">
Definition (Morphosyntactic Types)
</sectionHeader>
<listItem confidence="0.999046">
• D = finite set of diacritics
• Join semilattice L = (D, &lt;, =)
• The set of basic morphosyntactic types: Ams.
</listItem>
<equation confidence="0.9364685">
— &lt; X E Ams and ✶i X E Ams if i E D and X E As (see definition of
i
</equation>
<bodyText confidence="0.788995">
syntactic types for As)
</bodyText>
<listItem confidence="0.8597282">
— (✶ corresponds to lattice condition =)
— (&lt; corresponds to lattice condition &lt;)
• The set of complex morphosyntactic types: Bms
— Ams C Bms
— If X E Bms and Y E Bms, then X\Y and X/Y E Bms
</listItem>
<bodyText confidence="0.851614833333333">
For instance, the infinitive marker -ma in (14a) can be lexically specified to look
a
for untensed VPs—functions onto &lt; S—to yield a complex noun base (14b), which, as
a consequence of nominalization (result type N), receives case to become an argument
of the matrix verb. The adjective in fake trucks can be restricted to modify unmarked
Ns to get the bracketing [fake truck]-s (14c).
</bodyText>
<figure confidence="0.696701375">
(14) a. Mehmet [[kitab-ı oku]-ma]-yı istiyor
M.NOM book-ACC read-INF-ACC wants
’Mehmet wants to read the book.’
b f
b. -INF := ma − &lt; N\( &lt; a S\ &lt; NPnom): λf .f
c. fake :=fake − &lt; N/ b
b
&lt; N: λx.fakex
</figure>
<bodyText confidence="0.9986299">
Different attachment characteristics of words, affixes, and clitics must be factored
into the prosodic domain as a counterpart of refining the morphosyntactic description.
In Montague Grammar, every syntactic rule is associated with a certain mode of at-
tachment, and this tradition is followed in MCG; attachment types are related with the
slash (e.g., /w for wrapping), which is a grammatical modality.10 In the present frame-
work, however, attachment is projected from the lexicon to the grammar as a prosodic
property of the lexical items.11 The grammar is unimodal in the sense that / and \
simply indicate the function-argument distinction in adjacent prosodic elements. The
lexical projection of attachment further complements the notion of morphemic lexicon
so that bound morphemes are no longer parasitic on words but have an independent
</bodyText>
<footnote confidence="0.903382142857143">
10 See Dowty (1996) and Steedman (1996) for a discussion of bringing nonconcatenative combination into
grammar.
11 There is a precedent of associating attachment characteristics with the prosodic element rather than the
slash in CG (Hoeksema and Janda 1988). In Hoeksema and Janda’s notation, arguments can be
constrained on phonological properties and attachment. For instance, the English article a has its NP/N
category spelled out as &lt;/CX/N,NP,Pref&gt;, indicating a consonantal first segment for the noun
argument and concatenation to the left.
</footnote>
<page confidence="0.999215">
154
</page>
<note confidence="0.355588">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<tableCaption confidence="0.6694535">
Table 1
Attachment properties of some Turkish morphemes.
</tableCaption>
<equation confidence="0.843920733333333">
uzun (long) := o uzun − &lt; N/ &lt; N uzun yol
long road
’long road’
s v f f
oku (read) := ◦oku − � S\ � NPnom\ � NPacc adam kitab-ı oku-du
man book-ACC read-TENSE
’the man read the book.’
-EMPH := ◦c de − X\X Ben de yaz-ar-ım
I too write-TENSE-PERS
’I write too.’
� N\ o
-LOC := ◦a de − c � N Ben-de kalem var
I-LOC pen exist
’I have a pen.’
i
</equation>
<bodyText confidence="0.986081166666667">
representational status of their own. We write ◦s to denote the attachment modality
i (affixation, syntactic concatenation, cliticization) of the prosodic elements.
Table 1 shows some lexical assignments for Turkish (e.g., the sign ◦a s − X\Y: µ
characterizes a suffix). The morphosyntactic calculus of CCG is defined with the ad-
dition of morphosyntactic types and attachment modalities as follows (similarly, for
other combinatory rules):
</bodyText>
<listItem confidence="0.874849">
(15) Forward Application (&gt;): o s1 − X/ o; Y: f o s2− 02 Y: a
</listItem>
<equation confidence="0.926428411764706">
&gt;
◦k (s1 •k s2) − X: fa
if α2❑1α1 in lattice L, for: ❑1, ❑2 ∈ {M, &lt;},
α1, α2 ∈ D in L,
i, j, k ∈ {a, s, c},
i j k
◦ ◦�a ◦
Forward Composition (&gt; B): o s1 − X/ o; Y: f o s2 − 02 Y/Z: g
&gt;B
◦k (s1 •k s2) − X/Z: Ax.f (gx)
if α2❑1α1 in lattice L, for: ❑1, ❑2 ∈ {M, &lt;},
α1, α2 ∈ D in L,
i, j, k ∈ {a, s, c},
i j k
◦ ◦�a ◦
The main functor’s argument specification (❑1 of α1
✷1 Y in (15)) determines the
</equation>
<bodyText confidence="0.981075">
lattice condition in derivations.12 Hence the morphosyntactic decoration in lexical as-
signments propagates its lattice condition to grammar as in α2❑1α1 (cf. Heylen [1997],
in which the grammar rule imposes a fixed partial order, e.g., X/Y combines with Z if
</bodyText>
<footnote confidence="0.886921666666667">
12 This coincides with Steedman’s (1991b) observation that directionality of the main functor’s slash is
also a property of the same argument. The main functor is the one whose result type determines the
overall result type (i.e., X/Y in (15)).
</footnote>
<page confidence="0.990447">
155
</page>
<note confidence="0.43241">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.956349571428572">
Z ≤ Y). This is another prerequisite that must be fulfilled for the morphemic lexicon
to project the lexical specification of scope.
The grammar is not fixed on the attachment modality either (unlike a lexemic
grammar, which is fixed on combination of words). Hence another requirement is the
propagation of attachment to grammar. This is facilitated by the lexical types m◦ s−u: µ,
i j
where m is an attachment type. The attachment calculus ◦◦�a ◦k in (15), which reads
“attachment types i and j yield type k,” relates attachment to prosodic combination in
the grammar.13 It can be attuned to language-particular properties.
We can specify some prosodic properties of the attachment calculus for Turkish as
follows (i indicates stress on the prosodic element x):
syntactic concatenation x�•s y� = .xy
affixation x� •a y = xy
cliticization x�•c y = .xy
</bodyText>
<sectionHeader confidence="0.991451" genericHeader="method">
4. Morpheme-Based Parsing
</sectionHeader>
<bodyText confidence="0.9996035">
To contrast lexemic and morphemic processing, consider the Turkish example in (16a).
We show some stages of the derivation to highlight prosodic combination (•) as well.
Every item in the top row is a lexical entry. Allomorphs, such as that of tense, have the
same category in the lexicon (16b). Vowel harmony, voicing, and other phonological
restrictions are handled as constraints on the prosodic element. Constraint checking
can be switched off during parsing to obtain purely morphosyntactic derivations.
</bodyText>
<figure confidence="0.99575993939394">
(16) a. Can Ay¸se nin kitab ı oku ması nı iste di
C.NOM -GEN(agr) book -ACC read -SUB1G -ACC want -TENSE
f
a NP)
a
a S\
a
.4 S\
\
f
a NPacc \(
f
.4NPnom) \(
b
aN
b
aN
c
a NPgen\
o
aN
b
aN
c
a Nacc\
o
aN
v
a S\
f
a NPnom
o
a N\
f
a NPgen
c
a N\
o t
aN TV (aS\
f
a NP)
.
.
.
a
iste • di−
t f
a S\ a NPnom
a s v f f
kitab • ı • oku− � S\ � NPnom \ � NPacc
a s a o f
(kitab • ı • oku) • ması− a N\ a NPgen
.
.
.
((ay¸se a s a s a a t f t f f
• nin) • (kitab • ı • oku) • ması) • nı−( .4 S\ a NPnom)/( a S\ a NPnom\ a NPacc)
.
.
.
s
can • (ay¸se
: want(read book ay¸se)can
’Can wanted Ay¸se to read the book.’
f f
b. -TENSE := ◦a dı|di|du|d¨u|tı|ti|tu|t¨u − (� t S\ � NP)\( � a S\ � NP): Af f
</figure>
<bodyText confidence="0.978986125">
13 Clearly, much more needs to be done to incorporate intonation into the system. The motive for
attachment types is to provide the representational ingredients on behalf of the morphemic lexicon. As
one reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomous
prosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b). The present
proposal for attachment modality is computationally compatible with both accounts: Combinatory
prosody can match prosodic types with morphosyntactic types. Prosodic features are associated with
the basic categories of a syntactic type in the latter formulation, hence they become part of the featural
inference that goes along with the matching of categories in the application of combinatory rules.
</bodyText>
<figure confidence="0.895037">
a s a s a a s a t
• nin • kitab • ı • oku • ması • nı) • (iste • di)− a S
</figure>
<page confidence="0.867572">
156
</page>
<bodyText confidence="0.8617315">
Bozsahin The Combinatory Morphemic Lexicon
The lexicalization of attachment modality helps to determine the prosodic domain
of postconditions. For instance, for Turkish, vowel harmony does not apply over word
boundaries, which can be enforced by applying it when the modality is ◦a and ◦c , but
</bodyText>
<subsubsectionHeader confidence="0.59616">
s
</subsubsectionHeader>
<bodyText confidence="0.998840666666667">
not ◦. Voicing applies to ◦a and ◦s, but not to ◦c .
The basic categories N, NP, S, S+t, and S−t carry agreement features of fixed arity
(e.g., tense and person for S, S+t, and S−t, and case, number, person, and gender for N
and NP). Positional encoding of such information as in Pulman (1996) allows efficient
term unification for the propagation of these features.14 Term unification also handles
the matching of complex categories in the CCG schema. For instance, α1
</bodyText>
<equation confidence="0.975517">
✷1 A/(o22B \ o; C)
combines with β2
✷4B\ β3
</equation>
<bodyText confidence="0.996609666666667">
✷5C via (&gt;) for B, C E As, if β2 ❑2 α2, β3 ❑3 α3 (❑i E {&lt;, M}). Apart
from the matching of syntactic types and agreement, unification does no linguistic
work in this framework, in contrast to structure-sharing in HPSG and slash passing
in Unification CG (Calder, Klein, and Zeevat 1988).
CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993). This re-
sult depends on the finite schematization of type raising and bounded composition.
Assuming a maximum valence of four in the lexicon (Steedman 2000a), composition
(Bn) is bounded by n ≤ 3. The refinement of the type raising schema (11) for finite
schematization is shown in (17).
</bodyText>
<listItem confidence="0.7608805">
(17) a. Revised Forward Type Raising (&gt;T): NP: a T/(T\NP): Af .f [a]
b. Revised Backward Type Raising (&lt;T): NP: a T\(T/NP): Af .f [a]
</listItem>
<equation confidence="0.914234">
T E {S,S\NP, S\NP\NP, S\NP\NP\NP}.
</equation>
<bodyText confidence="0.995056148148148">
The finite schematization of type raising suggests that it can be delegated to the
lexicon, for example, by a lexical rule that value-raises all functions onto NP to their
type-raised variety, such as NP/N to (S/(S\NP))/N. But this move presupposes the
presence of such functions in the lexicon, that is, a language with determiners. To be
transparent with respect to the lexicon, we make type raising and other unary schema
(contraposition) available in the grammar. Since both are finite schemas in the revised
formulation, the complexity result of Vijay-Shanker and Weir still holds. Checking the
lattice condition as in (15) incurs a constant factor with a finite lattice.
Type raising and composition cause the so-called spurious-ambiguity problem
(Wittenburg 1987): Multiple analyses of semantically equivalent derivations are pos-
sible in parsing. This is shown to be desirable from the perspective of prosody; for
example, different bracketings are needed to match intonational phrasing with syn-
tactic structure (Steedman 1991). From the parsing perspective, the redundancy of
analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking
the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the proces-
sor parsimonious on using long-distance compositions (Pareschi and Steedman 1987),
or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989;
K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of com-
positions in O(1) time via tags in the grammar, before derivations are licensed. There
is a switch that can be turned off during parsing to obtain all surface bracketings.
14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important
consequences on underspecification, the domain of agreement, and the notion of “like categories” in
coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000).
Rather than providing an elaborate agreement system, we note that Pulman’s techniques provide the
mechanism for implementing agreement as atomic unification, subsumption hierarchies represented as
lattices, or set-valued features. The categorial ingredient of phrase-internal agreement can be provided
by endotypic functors when necessary (see Sections 5 and 6).
</bodyText>
<page confidence="0.969572">
157
</page>
<note confidence="0.422763">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.999970892857143">
There is also a switch for checking the PAS equivalence, with the warning that the
equivalence of two lambda expressions is undecidable.
The parser is an adaptation of the Cocke-Kasami-Younger (CKY) algorithm (Aho
and Ullman 1972, page 315), modified to handle unary rules as well: In the kth iteration
of the CKY algorithm to build constituents of length k, the unary rules apply to the CKY
table entries T[αi, αi+k ], i = 0,1, ... , n − k; that is, k-length results of binary rules are
input to potential unary constituents of length k. In practice, this allows, for instance,
a nominalized clause to be type-raised after it is derived as a category of type N.
The remaining combinatory schema is already in Chomsky Normal Form, as required
by CKY. The finite schematization of CCG rules and constant costs incurred by the
normal form and lattice checking provide a straightforward extension of CKY-style
context-free parsing for CCG. Komagata (1997) claims that the average complexity of
CCG parsing is O(n3) even without the finite schematization of type raising (based on
the parsing of 22 sentences consisting of around 20 words, with a lexicon of 200 entries
and no derivation of semantics in the grammar; a morphological analyzer provided
five analyses per second to the parser). Statistical techniques developed for lexicalized
grammars (e.g., Collins 1997), readily apply to CCG to improve the average parsing
performance in large-scale practical applications (Hockenmaier, Bierner, and Baldridge
2000). Both Collins and Hockenmeier, Bierner, and Baldridge used section 02-21 of the
Wall Street Journal Corpus of Penn Treebank for training, which contains 40,886 words
(70,151 lexical entries). A recent initiative (Oflazer, et al. 2001) aims to provide such a
resource of around one million words for Turkish. It encodes in the Treebank surface-
syntactic relations and the morphological breakdown of words. The latter is invaluable
for training morphemic grammars and lexicons.
In morpheme-based parsing, lattice conditions help eliminate the permutation
problem in endotypic categories. Such categories are typical of inflectional morphemes.
For instance, assume that three morphemes m1, m2, and m3 have endotypic categories
(say N\N), that they can appear only in this order, and that they are all optional. The
</bodyText>
<equation confidence="0.80104775">
κi
&lt; N such that κi &lt;� κi for all i, and κ� j−1 &lt; κj for j = 1, 2, 3
allows omissions (18a–b) but rules out the permutations (18c–d).15
(18) a. stem m1 m2 m3
categorization of mi as
&lt; κ� i N\
κ2
&lt; N
κ1
&lt; N
κ0
&lt; N
κ3
&lt; N
κ&apos;
&lt;1N\
κ3
&lt; N\
κ�
&lt;2 N\
κ&apos;
&lt; 1N because κ0 &lt; κ1
κ&apos;
&lt; N because κ�
2 1 &lt; κ2
κ&apos;
&lt; N because κ�
3 2 &lt;
κ3
b. stem m3
κ&apos;
&lt; 3N because κ0 &lt; κ3
</equation>
<page confidence="0.6110095">
15 Three asterisks in the line indicate that the derivation is not licensed.
158
</page>
<bodyText confidence="0.258967">
Bozsahin The Combinatory Morphemic Lexicon
</bodyText>
<equation confidence="0.7845712">
c. *stem m2 m1 m3
κ&apos;
&lt;2 N because κ0 &lt; κ2
*** κ�2 &lt;9 κ1 because κ1 &lt; κi &lt; κ2 &lt; κZ
d. *stem m1 m3 m2
κ&apos;
&lt; 1N because κ0 &lt; κ1
κ3
N because κi &lt; κ3
*** κ3 &lt;9 κ2 because κ2 &lt; κ&apos;2 &lt; κ3 &lt; κ3
</equation>
<bodyText confidence="0.998959666666667">
The lattice and its consistency condition on derivability offer varying degrees of
flexibility. A lattice with only T and the relation &lt; would undo all the effects of
parameterization; it would be equivalent to a syntactic grammar in which every basic
</bodyText>
<equation confidence="0.989432">
T
category X stands for &lt; X. To enforce a completely lexemic syntax, a lattice with T
</equation>
<bodyText confidence="0.999501875">
and free would define all functional categories as functions over free forms.
Morphological processing seems inevitable for languages like Turkish, and mor-
phological and lexical ambiguity such as that shown in (19) must be passed on to
syntax irrespective of how inflectional morphology is processed (isolated from or in-
tegrated with syntax). For the verbal paradigm, Jurafsky and Martin (2000) reports
Oflazer’s estimation that inflectional suffixes alone create around 40,000 word forms
per root. In the nominal paradigm, iterative processes such as ki-relativization (Sec-
tion 6.5) can create millions of word forms per nominal root (Hankamer 1989).
</bodyText>
<listItem confidence="0.698876833333333">
(19) a. kazma-ları
pickaxe-POSS3p
’their pickaxe’
b. kazma-lar-ı
pickaxe-PLU-POSS3p
’their pickaxes’
c. kazma-lar-ı
pickaxe-PLU-POSS3s
’his/her pickaxes’
d. kaz-ma-ları
dig-SUB-AGR
’their digging’
</listItem>
<bodyText confidence="0.92828075">
The questions that need to be answered related to processing are (1) What should a
(super)linear fragment of processing for morphology deliver to (morpho)syntax? and
(2) Is the syntax lexemic or morphemic? The problems with lexemic syntax, which
stem from mismatches with semantics, were highlighted in the introduction. In other
</bodyText>
<page confidence="0.972588">
159
</page>
<figure confidence="0.997588139534884">
Computational Linguistics Volume 28, Number 2
root lexicon morphological syntax and
parsing interpretation
kazma PF−LF
kaz
kazma−POSS3p pairs
kazma−PLU−POSS3p
kazma−PLU−POSS3s
kaz−SUB−AGR
(a) Lexemic syntax and lexicon
kazma
kaz
root lexicon
affix lexicon
morphological
parsing
morpheme−
semantics
matching
syntax and
interpretation
kazma−POSS3p
kazma−PLU−POSS3p
kazma−PLU−POSS3s
kaz−SUB−AGR
PF−LF
pairs
−ma
−lar
−i
−lari
(b) Morphemic syntax and split lexicon
Phonological Form (PF)
Logical Form (LF)
root and affix syntax and
lexicon interpretation
kaz PF−LF
kazma pairs
−lar
−i
−lari
−ma
(c) Morphemic syntax and lexicon
</figure>
<figureCaption confidence="0.903506">
Figure 3
</figureCaption>
<bodyText confidence="0.988200291666667">
The processing of kazmaları in three different architectures (see Example (19) for glosses).
words, a lexemic grammar (e.g., Figure 3a) is computationally nontransparent when
interpretation is a component of an NLP system.
Regarding the first question, let us consider two architectures from the perspective
of the lexicon for the purpose of morphology, morphemic syntax, and semantics inter-
face. The architecture in Figure 3b incorporates the current proposal as an interpretive
front end to a morphological analyzer such as Oflazer’s (1994), which delivers the anal-
yses of words as a stream of morphemes out of which the bound morphemes have to
be matched with their semantics from the affix lexicon to be interpretable in grammar.
The advantage of this model is its efficiency; morphological parsing of words is—in
principle—linear context free; hence, finite-state techniques and their computational
advantages readily apply. But the uninterpretable surface forms of bound morphemes
must match with those of the affix lexicon, and this is not necessarily a one-to-one
mapping because of multiple lexical assignments for capturing syntactic–semantic dis-
tinctions (e.g., dative case as a direct object, indirect object, or adjunct marker or -i
as a possessive and/or compound marker). Surface form–semantics pairing is not a
trivial task, particularly in the case of lexically composite affixes, which require se-
mantic composition as well as tokenization. The matching process needs to be aware
of all the syntactic contexts in which certain affix sequences act as a unit, for exam-
ple, relative participles and agreement markers (-di˘g-i relative participle as -OP-POSS
or -OP-AGR), possessive and compound markers, etc., for Turkish. The factorization
of syntactic issues into a morphological analyzer would also make the separate mor-
phological component nonmodular or expand its number of states to factor in these
concerns (e.g., treating the -OP-POSS sequence as a state different from -OP followed
</bodyText>
<page confidence="0.983014">
160
</page>
<note confidence="0.373282">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<tableCaption confidence="0.994205">
Table 2
</tableCaption>
<table confidence="0.966260833333334">
Parsing performance.
Average number
Sample text Number of items of parses/grammatical Average CPU time
type in text input per test (milliseconds)
Normal Normal
PAS form PAS form
tests words morphs check parse Unrestr. check parse
Word order and 58 216 384 1.26 3.68 39 39 30
case
Subordination 14 70 137 3.00 5.09 267 270 180
Relativization 23 130 232 2.04 2.32 796 783 266
Control verbs 33 147 291 1.42 3.34 166 163 137
Possessives and 26 109 200 1.23 2.47 137 135 98
compounds
Adjuncts 14 57 100 1.12 4.87 89 88 72
-ki relatives 24 66 179 1.07 1.54 36 36 35
Note: CPU times are for a Sun UltraSparc-4 running SICStus Prolog; lexical items include stems and inflec-
tional affixes.
</table>
<bodyText confidence="0.975510111111112">
by -POSS, in which -POSS is not interpreted with the semantics of possession but that
of agreement marking). Not knowing how many of the syntactic distinctions are han-
dled by the morphological analyzer, a subsequent interpreter may need to reconsult
the grammar if scoping problems arise.
The architecture in Figure 3c describes the current implementation of the pro-
posal. Bound morphemes are fed to the parser along with their interpretation. This
model is preferred over that presented in Figure 3b for its simplicity in design and
extendibility.16 The price is lesser efficiency due to context-free processing of inflec-
tional morphology. By one estimate (Oflazer, Gocmen, and Bozsahin 1994), Turkish
has 59 inflectional morphemes out of a total of 166 bound morphemes, and Oflazer
(personal communication) notes that the average number of bound morphemes per
word in unrestricted corpora is around 2.8, including derivational affixes. In a news
corpus of 850,000 words, the average number of inflections per word is less than two
(Oflazer et al. 2001). This is tolerable for sentences of moderate length in terms of the
extra burden it puts on the context-free parser. Table 2 shows the results of our tests
with a Prolog implementation of the system on different kinds of constructions. The
test cases included 10 lexical items on average, with an average parsing time of 0.32
seconds per sentence. A relatively long sentence (12 words, 21 morphemes) took 2.9
seconds to parse. The longest sentence (20 words, 37 morphemes) took 40 seconds.
The lexicon for the experiment included 700 entries; 139 were free morphemes and
561 were bound morphemes compiled out of 105 allomorphic representations (includ-
ing all the ambiguous interpretations of bound morphemes and the results of lexical
rules). For a rough comparison with an existing NLP system with no disambiguation
16 The morphological analyzer would be in no better position to handle morpheme–semantics pairing if
the architecture in Figure 3b were implemented with an integrated lexicon of roots and affixes. For
instance, -POSS would still require distinct states because of the difference in the semantics of
possession and agreement marking coming from the lexicon.
</bodyText>
<page confidence="0.986418">
161
</page>
<note confidence="0.635565">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.999837952380952">
aids, G¨ung¨ordu¨ and Oflazer (1995) reported average parsing times of around 10 sec-
onds per sentence for a lexicon of 24,000 free morphemes, and their morphological
analyzer delivered around two analyses per second to a lexemic grammar. Oflazer’s
later (1996) morphological analyzer contained an abstract morphotactic component of
around 50 states for inflections, which resulted in compilation to 30,000 states and
100,000 transitions when the morphophonemic rules were added to the system.
In conclusion, we note that the current proposal for a morphemic lexicon and
grammar is compatible with both a separate morphological component (Figure 3b) and
syntax-integrated inflectional morphology (Figure 3c). The architecture in Figure 3b
may in fact be more suitable for inflecting languages (e.g., Russian) in which the
surface forms of bound morphemes are difficult to isolate (e.g., m´este, locative singular
of m´esto) but can be delivered as a sequence of morpheme labels by a morphological
analyzer (e.g. m´esto-SING-LOC) to be matched with the lexical type assignments to
-SING and -LOC for grammatical interpretation.
It might be argued that in computational models of the type in Figure 3b, the lattice
is not necessary, because the morphological analyzer embodies the tactical component.
But not only tactical problems (cf. Example (18) and its discussion) but also transparent
scoping in syntax and semantics is regulated by the use of lattice in type assignments,
and that is our main concern. We show examples of such cases in the remainder of the
article. Thus the nonredundant role of the lattice decouples the morphemic grammar–
lexicon from the kind of morphological analysis performed in the back end.
</bodyText>
<sectionHeader confidence="0.710345" genericHeader="method">
5. Case Study: The English Plural
</sectionHeader>
<bodyText confidence="0.9999374">
In this section, we present a morphosyntactic treatment of the English plural mor-
pheme. The lattice for English is shown in Figure 2b. We follow Carpenter (1997) in
categorizing numerical modifiers and intersective adjectives as plural noun modifiers:
four boys is interpreted as four(plu boy) and green boxes as green(plu box). This bracketing
reflects the “set of sets” interpretation of the plural noun; four(plu boy) denotes the set
of nonempty nonsingleton sets of boys with four members. The type assignments in
(20) correctly interpret the interaction of the plural and these modifiers (cf. 21a–b).
The endotypic category of the plural also allows phrase-internal number agreement
for languages that require it; the agreement can be regulated over the category N
before the specifier is applied to the noun group to obtain NP.
</bodyText>
<equation confidence="0.824030333333333">
(20) -PLU := ◦a s − &lt;n N\ &lt;b N: λx.plu x
four := ◦s four − &lt;n N/ n✶N: λx.four x
green := s &lt; N/ n
◦ green − n
&lt; N: λx.green x
(21) a. four boy -s
&lt; N/ n
n ✶N &lt;b N &lt;nN\ &lt;bN
n
&lt; N: plu boy
n
&lt; N : four(plu boy)
</equation>
<page confidence="0.949994">
162
</page>
<table confidence="0.9448971">
Bozsahin The Combinatory Morphemic Lexicon
b. four boy -s
***
&lt; N\b
n
&lt; N
n
&lt; N: four boy
because n-base # n-num
***
</table>
<equation confidence="0.5598905">
n
&lt; N:* plu(four boy)
</equation>
<bodyText confidence="0.998296444444444">
Carpenter (1997) points out that nonintersective adjectives (e.g, toy, fake, alleged) are
unlike numerical modifiers and intersective adjectives in that their semantics requires
phrasal (wide) scope for -PLU, corresponding to the “set of things” interpretation
of the plural noun. Thus, toy guns is interpreted as plu(toygun) because the plural
outscopes the modification. It denotes a nonempty nonsingleton set of things that are
not really guns but toy guns. *toy(plu gun) would interpret plu over guns. The situation
is precisely the opposite of (21); we need the second derivational pattern to go through
and the first one to fail. The following category for nonintersective adjectives derives
the wide scope for -PLU but not the narrow scope:
</bodyText>
<listItem confidence="0.5280655">
(22) toy := ◦s toy − &lt;b N/ &lt;b N: Ax.toy x
(23) a. toy gun -s
</listItem>
<figure confidence="0.939002538461538">
&lt; N/ b
b &lt; N &lt; n N: plu gun
***
n
&lt; N : *toy(plu gun)
because n-num ≤~ n-base
b. toy gun -s
&lt; N/b
b &lt;N &lt;b N &lt;nN\ &lt;bN
b
&lt; N:toygun
n
&lt; N : plu(toy gun)
</figure>
<bodyText confidence="0.9979165">
Carpenter (1997) avoided rebracketing because of the plural through lexical type
assignments to plural nouns and a phonologically null lexical entry to obtain differ-
ent semantic effects of the plural. In our formulation, there is no lexical entry for
inflected forms and no phonologically null type assignment to account for the dis-
tinction in different types of plural modification; there is only one (phonologically
realized) category for -PLU.17 The modifiers differ only in the kind and degree of mor-
phosyntactic control. Strict control (✶) on four disallows four boy, and flexible control
(&lt;) on green also handles green box. Fourgreen boxes is interpreted as four(green(plu box)),
</bodyText>
<footnote confidence="0.954779">
17 This is not to say that there is only one model-theoretic interpretation of plu. “Sets of sets” and “set of
individuals” valuations of plu can be carried over the PAS.
</footnote>
<page confidence="0.989111">
163
</page>
<note confidence="0.638267">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.999784666666667">
not as *four(plu(green box)), and four toy guns is interpreted as four(plu(toygun)), not as
*plu(four(toygun)). These derivations preserve the domain of the modifiers and the
plural without rebracketing.
</bodyText>
<sectionHeader confidence="0.910846" genericHeader="method">
6. Case Study: Turkish Morphosyntax
</sectionHeader>
<bodyText confidence="0.999649923076923">
There have been several computational studies to model morphology–syntax inter-
action in Turkish. These unification-based approaches represent varying degrees of
integration. G¨ung¨ordu¨ and Oflazer (1995) isolates morphology from syntax by having
separate modules (a finite-state transducer for the former, and an LFG component for
the latter), that is, the syntax is lexemic. The morphological component is expected to
handle all aspects of morphology, including inflections and derivations. In Sehitoglu
and Bozsahin (1999), lexical rules implement inflectional morphology, and derivations
are assumed to take place in the lexicon. Hoffman’s (1995) categorial analysis of Turk-
ish is also lexemic; all lexical entries are fully inflected. Interpretive components of
these systems face the aforementioned difficulties because of their commitment to lex-
emic syntax. Inflectional morphology is incorporated into syntax in another categorial
approach (Bozsahin and G¨o¸cmen 1995), but morphotactic constraints are modeled with
nonmonotonic unification, such as nonexistence checks for features and overrides. The
system cannot make finer distinctions in morphosyntactic types either. The result is an
overgenerating and nontransparent integration of morphology and syntax because of
the possibility of rebracketing and the unresolved representational basis of the lexicon.
In this section, we outline the application of the proposed framework to Turkish.
We analyze a large fragment of the language, without any claims for a comprehensive
grammar. The phenomena modeled here exhibit particular morphosyntactic problems
described in the preceding sections. We assume the binding theory in Steedman (1996),
which is predicated over the PAS. In each section, we provide a brief empirical observa-
tion about the phenomenon, propose lexical type assignments, exemplify derivations
of the parser, and briefly discuss the constraints imposed by morphosyntactic types.
Because of space considerations, we sometimes use abbreviated forms in derivations
such as the genitive affix’s (N/(N\N))\N category for (&lt;o N/(o✶ Npn\ o✶ Npn))\ &lt;o Npn,
but the parser operates on full morphosyntactic representations.
</bodyText>
<subsectionHeader confidence="0.99991">
6.1 Case Marking and Word Order
</subsectionHeader>
<bodyText confidence="0.99980975">
Turkish is regarded as a free constituent order language; all permutations of the
predicate and its arguments are grammatical in main clauses, being subject to con-
straints on discourse and semantic properties such as definiteness and referentiality
of the argument and topic–focus distinctions. The mapping of surface functions to
grammatical relations is mediated by case marking. Word order variation has lesser
functionality in embedded clauses because embedded arguments are less accessible
to surface discourse functions like topic and focus. Embedded clauses are verb fi-
nal.
</bodyText>
<subsubsectionHeader confidence="0.429121">
6.1.1 Lexical Types. We start with the lexical type assignments for the verbs. We use
</subsubsectionHeader>
<bodyText confidence="0.96533375">
the abbreviations in (24a) when no confusion arises about the arguments’ case or mor-
phosyntactic type. Verb-final orders are regarded as basic, which suggests the category
S\NP\NP for transitive verbs. But Janeway (1990) argued that such underspecification
for verb-peripheral languages causes undesirable ambiguity. Grammatical relations of
</bodyText>
<page confidence="0.976933">
164
</page>
<figure confidence="0.917531647058824">
Bozsahin The Combinatory Morphemic Lexicon
the arguments are determined not by directionality but by case in such languages. The
category S\NPnom\NPacc resolves the ambiguity (24b–c).
(24) a. IV = S\NP
TV = S\NP\NP
DV = S\NP\NP\NP
f f
b. sev (like) := ◦s sev − &lt; v S\ &lt; NPnom\ &lt; NPacc: λx.λy.like xy
f f f
c. ver (give) := ◦s ver − &lt; v S\ &lt; NPnom\ &lt; NPdat\ &lt; NPacc: λx.λy.λz.giveyxz
v f f
d. &lt; S\ &lt; NPnom\ &lt; NPacc : λx.λy.like xy ⇒
v f f
&lt; S\ &lt; NP+ref
acc \ &lt; NPnom : λy.λx.like xy
e. -ACC := a◦ i|ı|u|¨u|yi|yı|yu|y¨u − &lt;c Nacc\ &lt;o N: λf .f
f. -LOC := ◦a de|da|te|ta − ( &lt;α S/ &lt;α S)\ &lt;o N: λx.λf.at fx
</figure>
<bodyText confidence="0.999025">
Gapping behavior seems to indicate that Turkish is verb final, not just SOV. SO
and OS syntactic types must be distinguished to account for SO &amp; SOV, OS &amp; OSV,
*SO &amp; OSV and *OS &amp; SOV. The OS &amp; OSV pattern requires the lexical category
S\NPacc\NPnom for the verb (Bozsahin 2000b). SOV and OSV base orders can be cap-
tured uniquely in the lexicon in set-CCG notation as S\{NPacc,NPnom}. Set-CCG is
strongly equivalent to CCG (Baldridge 1999). We distinguish SOV and OSV lexically,
however, because OSV requires referential objects (25a–b). OSV is generated from SOV
by a lexical rule (24d). This is genuine lexical ambiguity, because the two related entries
differ in semantics (referentiality).
</bodyText>
<figure confidence="0.4313236">
(25) a. Kitab-ı adam oku-du
Book-ACC man.NOM read-TENSE
’The man read the book.’
b. *Kitap adam oku-du
Book man.NOM read-TENSE
</figure>
<bodyText confidence="0.970856142857143">
Regarding the relationship between case and the specifiers, it is questionable
whether Turkish has a discernible syntactic category for determiners. There is no lex-
ical functor that takes an N and yields an NP. The only article, the indefinite bir (’a’),
makes a distinction in discourse properties (26). Specifying case as a determiner (e.g.,
NP\N) does not alleviate the problem, either. Ignoring the problem of case stacking
for a moment, zero marking of the surface subject and the indefinite object takes us
back to where we started.
</bodyText>
<listItem confidence="0.457184">
(26) ¸Cocuk ye¸sil bir elma/elma/elma-yı ye-mi¸s
</listItem>
<bodyText confidence="0.962007">
child.NOM green an apple/apple/apple-ACC eat-TENSE
’The child ate a green apple.’ (indefinite but referential apple)
’The child ate green apple.’ (indefinite and nonreferential apple)
’The child ate the green apple.’ (definite and referential apple)
</bodyText>
<page confidence="0.990327">
165
</page>
<note confidence="0.635628">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.997918666666667">
Making the nouns lexically ambiguous (N or NP) would also require that all func-
tions onto nouns be ambiguous (N\N and NP\NP for inflections, N/N and NP/NP for
adjectives, etc.). Redundancy of this kind in the lexicon is not desirable, since it is in-
troduced purely for formal reasons with no distinction in meaning. We accommodate
these concerns by positing a special case of type raising for Turkish (27). Similarly,
contraposition turns Ns into functors looking for NPs.
</bodyText>
<figure confidence="0.88294005">
(27) Type Raising for Turkish: N.: a T/(T\ &lt;
ag, NPagr): λf .f [a]
f
⇒T\(T/ &lt; NPagr):λf.f[a]
T E {S,S\NP,S\NP\NP, S\NP\NP\NP}
The noun that is type raised can be a syntactically derived noun (28). SO (and OS)
constituency required for gapping is provided by &gt;T and &gt;B.
(28) Mehmet k¨u¸c¨uk ye¸sil kitab-ı, ¸cocuk da yeni gelen dergi-yi oku-du
M.NOM little green book-ACC child-COORD new come mag.-ACC read-TENSE
Nnom Nacc Nnom Nacc S\NPnom\NPacc
&gt;T &gt;T
S/(S\NPnom) (S\NP)
/(S\NP\NPacc)
...
&gt;B &gt;B
S/(S\NPnom\NPacc) S/(S\NPnom\NPacc)
&amp;
S/(S\NPnom\NPacc)
&gt;
S
</figure>
<bodyText confidence="0.973833285714286">
’Mehmet read the little green book, and the child, the newly arrived magazine’.
Our lexical type assignment to case morphemes (24e–f) departs from other CCG
analyses of case (e.g., Steedman 1985, 1991a, Bozsahin 1998). These studies correlate
morphological case with type raising of arguments, in the case of Bozsahin (1998), via
a value-raised category assignment to case morphemes. Evidence from NP-internal
case agreement and case stacking (Kracht 1999) challenges the type-raising approach.
Agreement phenomena require that case (which can be marked on articles, adjectives,
and nouns) be regulated as an agreement feature within the category N before the
case-marked argument looks for the verb via type raising. Kracht observes that, in
case stacking, there may be other morphemes between two case morphemes. Thus,
treating the two cases as composite affixes for the purpose of type raising is not
feasible. If the first case type-raises the noun to say, T/(T\NP), the second case would
require a category, (T/(T\NP))\(T/(T\NP)); that is, it is endotypic. Hence, an endotypic
category for case (like other inflections in the paradigm) subsumes the type-raising
analysis of case provided that type raising is available in the grammar, not necessarily
anchored to case.
We analyze case as an endotypic functor of type N\N (24e)—hence allow for
phrase-internal agreement for languages that require it and provide type raising in
grammar as in (27). Abandoning the type-raising analysis of case does not necessitate
taking liberties in the directionality of the categories, such as the use of nondirectional
slash (|) in multiset-CCG (Hoffman 1995). Contraposition and type raising in grammar
</bodyText>
<page confidence="0.979713">
166
</page>
<bodyText confidence="0.920607111111111">
Bozsahin The Combinatory Morphemic Lexicon
can account for free word order and gapping facts with fully directional syntactic types
(Bozsahin 2000a).
6.1.2 Derivations. The wide scope of case is captured by treating its argument type as
non-case-marked N (&lt;o N) and the type of noun modifiers as functions onto non-case-
marked nouns of a particular domain, for example, &lt; N for nonintersective adjectives
and &lt;n N for intersective adjectives (29a). The same strategy in type assignments to
other nominal inflections allows them to outscope nominal modification, for exam-
ple, (29b).
</bodyText>
<figure confidence="0.973465764705882">
(29) a. Mehmet [ [ oyuncak araba ] -lar] -ı sev-er
M.NOM toy car -PLU -ACC like-TENSE
&lt;B
b f
&lt; N/ &lt; b N &lt; b N &lt; n N\ &lt; b N &lt; c Nacc\ &lt; o N &lt; t S\ &lt; NPnom
b
&lt; Nnom
f
: mehmet : λx.toy x : car : λx.plu x : λf .f \
&gt;T
f
S/(S\&lt; NPnom) : λx.λy.like xy
: λf.f [mehmet]
&gt;
b
&lt; N: toy car
&lt;
n
&lt; N: plu(toycar)
&lt;
c
&lt; Nacc: plu(toy car)
&gt;T
f
(S\NP)/(S\NP\ &lt; NPacc): λg.g[plu(toy car)]
&gt;
tf
&lt; S\ &lt; NPnom: λy.like(plu(toy car))y
&gt;
S: like(plu(toy car))mehmet
’Mehmet likes toy cars.’
b. Adam-ın [k¨u¸c¨uk kırmızı araba]-sı
Man-GEN little red car-POSS
’the man’s little red car’ = poss(little(redcar))man
</figure>
<bodyText confidence="0.999206166666667">
A word-based alternative for reconciling the semantic (wide) scope of inflections
and their morphological (narrow) attachment to stems runs into difficulties even if
we assume that morphemes carry type assignments—and hence have representational
status—but that they always combine with stems first. We use syntactic types to show
the problem. If -PLU and -ACC in (29a) combine with the stem first, only the narrow-
scope reading of the plural and case is possible (30a). Plu(toycar) is not derivable with
</bodyText>
<figure confidence="0.542427333333333">
&lt; NPacc
167
Computational Linguistics Volume 28, Number 2
</figure>
<figureCaption confidence="0.530507">
word-based modification. The morphosyntactic categories, however, are transparent
to the scope of nominal modification (cf. (29a) and (30b)).
</figureCaption>
<figure confidence="0.373267608695652">
(30) a. oyuncak [[araba] -lar] -ı
toy car -PLU -ACC
N/N N N\N Nacc\N
: λx.toyx : car : λx.plu x : λf .f
&lt;
N: plu car
&lt;
Nacc: plu car
&gt;
N: ∗ toy(plu car)
b. [ye¸sil [araba] -lar] -ı
green car -PLU -ACC
&lt; N/ n
n &lt; N &lt;bN &lt;nN\&lt;bN &lt;cNacc\&lt;oN
: λx.green x : car : λx.plu x
n
&lt; N: plu car
&gt;
n
&lt; N: green(plu car)
&lt;
c
&lt; Nacc: green(plu car)
</figure>
<figureCaption confidence="0.161101">
Surface case annotations on categories enable the grammar to capture the correct
PAS in all permutations of S, O, and V while maintaining the discourse-relevant dis-
tinctions (31). Verb-final subordinate clauses are enforced by the directionality of the
subordination morphemes in the lexicon.
</figureCaption>
<figure confidence="0.974928265306123">
(31) a. S O V
&gt;T &gt;T
f f
S/(S\ &lt; NPnom) (S\NP)/(S\NP\ &lt; NPacc) S\NPnom\NPacc
&gt;
S\NPnom
&gt;
S
b. O S V
&gt;T &gt;T
f f
S/(S\ &lt; NPacc) (S\NP)/(S\NP\ &lt; NPnom) S\NPacc\NPnom
S\NPacc
&gt;
S
: λf .f
&lt;
168
Bozsahin The Combinatory Morphemic Lexicon
c. O V S
&gt;T &gt;XP
f
(S\NP)/(S\NP\ &lt; NPacc) S\NPnom\NPacc S−t\(S\NPnom)
&gt;
S\NPnom
&lt;
S−t
d. S V O
&gt;T &gt;XP
f
(S\NP)/(S\NP\ &lt; NPnom) S\NPacc\NPnom S−t\(S\NPacc)
&gt;
S\NPacc
&lt;
S−t
e. V S O
&gt;XP &gt;XP
S\NPnom\NPacc S−t\(S\NPnom) S−t\(S−t\NPacc)
&lt;B
S−t\NPacc
&lt;
S−t
f. V O S
&gt;XP &gt;XP
S\NPacc\NPnom S−t\(S\NPacc) S−t\(S−t\NPnom)
&lt;B
S−t\NPnom
&lt;
S−t
</figure>
<subsectionHeader confidence="0.998414">
6.2 Subordination
</subsectionHeader>
<bodyText confidence="0.998529">
Subordinate clauses can be classified as unmarked clauses (32a), infinitival clauses
(32b), verbal nouns (32c), and nominalizations (32d). The latter two types require a
genitive embedded subject, which agrees with the subordinate verb.
</bodyText>
<listItem confidence="0.822020888888889">
(32) a. Mehmet [ ¸cocuk ev-e git-ti ] san-dı
M.NOM child.NOM house-DAT go-TENSE assume-TENSE
’Mehmet assumed that the child went home.’
b. ¸Cocuk [ kız-a kalem-i ver-me ] -yi unut-tu
child.NOM girl-DAT pen-ACC give-SUB1i -ACC forget-TENSE
’The child forgot to give the pen to the girl.’
c. [ ¸Cocu˘g-un araba-da uyu-ma-sı] Mehmet’i kız-dır-dı
child-GEN car-LOC sleep-SUB1g-POSS M-ACC anger-CAUS-TENSE
’Child’s sleeping in the car made Mehmet angry.’
</listItem>
<page confidence="0.990242">
169
</page>
<figure confidence="0.987308714285714">
Computational Linguistics Volume 28, Number 2
d. Deniz [ ¸cocu˘g-un uyu-du˘g-u] -na inan-m-ıyor
D.NOM child-GEN sleep-SUB2g-POSS -DAT believe-NEG-TENSE
’Deniz does not believe the child’s sleeping.’
(33) a. Denizi [kendisi-nini uyu-ma-dı˘g-ı]-nı s¨oyle-di
D.NOM self-GEN sleep-NEG-SUB2g-POSS-ACC2 say-TENSE
’Denizi said that hei did not sleep.’
b. *kendisii [Deniz’ini uyu-ma-dı˘g-ı]-nı s¨oyle-di
c. Denizi adam-ıj [ kendii/j arkada¸s-ı-nın g¨or-d¨u ˘g-¨u ]-ne inan-ıyor
D.NOM man-ACC self friend-POSS see-SUB2g-POSS-DAT2 believe-TENSE
’Denizi believes that hisi/j friend saw the manj.’
d. Denizi adam-aj [ kendii/∗j kitab-ı-nı oku-du˘g-u ]-nu s¨oyle-di
D.NOM man-DAT self book-POSS-ACC2 read-SUB2g-POSS-ACC2 say-TENSE
’Denizi told the manj that he read hisi/∗j book.’
</figure>
<figureCaption confidence="0.42388">
6.2.1 Lexical Types. The asymmetries in (33) show that the obliqueness order in bind-
ing relations is preserved in subordination. This suggests the following bracketing, in
which the embedded clause’s position in the PAS of the matrix predicate is determined
by its grammatical function.
</figureCaption>
<figure confidence="0.7046735">
Matrix-Pred ... Matrix-Argument ... Embedded-Clause ... Matrix-Argument
a b f
(34) -SUB1i (-ma) := ◦ma − &lt; N\( &lt; a S\ &lt; NPnom): λf .f
(infinitive)
a o f f
-SUB1g (-ması) := ◦ması − &lt; N\ &lt; NPagr\( &lt; a S\ &lt; NPnom): λf .f
(verbal noun)
f f
</figure>
<equation confidence="0.8016455">
-SUB2g (-dı˘gı) := a ◦dı˘gı − � o Ncase=obl\ � NPagr\( � a S\ � NPnom): Af f
(nominalization)
</equation>
<bodyText confidence="0.866011461538462">
The wide scope of case markers on subordinate clauses implies that the subor-
dinate markers themselves must have phrasal scope as well. Since case is a nominal
inflection, the category of a subordinate marker must be a function onto N. Its ar-
gument is IV for infinitives and NPagr\IV for others, which require genitive subjects
(34). This yields two families of functors for subordination. The verb-final characteris-
tics of the embedded clauses is ensured by the backward-looking main functor of the
subordinate marker.
For morphosyntactic modality, the resulting nominalized predicate can receive
o
only case, hence it has &lt; N control. Verbal nouns refer to actions, and nominaliza-
tions refer to facts. Subordinate markers for the former are tenseless. A subordinate
a
marker replaces the tense of the subordinate verb in nominalizations, yielding &lt; S
</bodyText>
<page confidence="0.967726">
170
</page>
<bodyText confidence="0.974566714285714">
Bozsahin The Combinatory Morphemic Lexicon
control on the verb. For subject raising, the result may undergo any nominal inflection
(&lt; b N).
Word order variation within the subordinate clause is constrained by the subject
on the left and the verb on the right. This constraint is achieved by categorizing the
embedded subjects as NPagr and having a result category of N for all subordinate mark-
ers. If there were any contraposed element NP in the embedded clause, the category
of the clause would be S\NP, and the clause could not combine with the contraposed
category such as S−t\(S\NP) on the right because the extraction category combines
with a subordinate marker first, which is onto N, not S\NP, hence composition (&lt;B)
could not take place.
6.2.2 Derivations. Example (35a) is the derivation of subject raising (we use Nr as
an abbreviation for a type-raised N when space is limited). We use Steedman’s (1996)
ana function to denote the binding of the embedded subject. Infinitive -SUB1i has
phrasal scope in this example; the DV must be reduced to an IV before the infinitive
can apply. Hence the subordination of intransitive clauses is only a special case in
which the morphological scope of the infinitive works without rebracketing. Subject
raising and coindexation with the matrix subject are made explicit in the raising cate-
gory of unut. The systematic relationship between the raised and nonraised category
of such verbs can be captured by a lexical rule, for example, TV: λx.λy.forgetxy ⇒
TV: λf .λy.forget(f [ana y])y.
(35b–c) contrast subject and nonsubject nominalizations. The difference is cap-
tured with the case distinction of the result type (&lt;o N) for -SUB1g and -SUB2g. These
examples also show the possibility of affix composition in the lexicon. For instance,
we write -ması in (35b), which marks subordination and agreement together, instead
of -ma-sı. Otherwise, -ma (SUB1g) would have to look to the right as a functor to
enforce agreement, and the verb-final property of subordination could not be as-
sured.
</bodyText>
<figure confidence="0.838055789473684">
(35) a. ¸Cocuk kız-a kalem-i ver -me -yi unut-tu
child.NOM girl-DAT pen-ACC give -SUB1i -ACC forgot
&gt;T &gt;T &gt;T &lt;B
Nnom Ndat N.c DV &lt; N\( &lt; S\ &lt; NPnom) &lt; Nacc\ &lt; N TV
: λf.f [child] : λg.g[girl] : λh.h[pen] : λx.λy.λz. : λf.f : λf.f : λf.λx.
give yxz forget
(f [ana x])x
&gt;
vf f
&lt; S\ &lt; NPnom\ &lt; NPdat
&gt;
v f
&lt; S\ &lt; NPnom
&lt;
b
&lt; N
&lt;
c
&lt; Nacc
</figure>
<equation confidence="0.869180555555556">
&gt;T
f
(S\NP)/(S\NP\ &lt; NPacc)
&gt;
t f
&lt; S\&lt; NPnom
&gt;
t
&lt; S: forget(give girl pen(ana child))child
</equation>
<bodyText confidence="0.5584">
’The child forgot to give the pen to the girl.’
</bodyText>
<page confidence="0.980933">
171
</page>
<figure confidence="0.987543066666667">
Computational Linguistics Volume 28, Number 2
b. ¸Cocu˘g-un uyu -masa Mehmet’i kazdar-da
child-GEN sleep -SUB1g M-ACC anger-TENSE
&gt;T &gt;T &lt;B
NPagr IV N\NPagr\IV IV/TV TV
&lt; &gt;
N\NPagr IV
&lt;
&gt;T
S/IV
&gt;
S: anger(sleep child)mehmet
’The child’s sleeping angered Mehmet.’
c. *¸Cocu˘g-un uyu-du˘gu Mehmet’i kazdar-da
sleep-SUB2g
</figure>
<subsectionHeader confidence="0.994336">
6.3 The Morphosyntax of Control
</subsectionHeader>
<bodyText confidence="0.999856666666667">
The control verb’s controlled argument is marked by the infinitive -ma, and the re-
sulting nominalized embedded clause can undergo nominal inflections (36a–b). The
infinitive -ma has the lexical type in (34). A potential conflict between an object con-
trol verb’s subcategorization and PAS is resolved by case decoration: zorla ’force’ and
tavsiye et ’recommend’ differ in their case requirements and what is controlled (36b–c).
tavsiye et’s infinitive complement is accusative, whereas zorla’s is dative.
</bodyText>
<figure confidence="0.45865375">
(36) a. ¸Cocuk [kitab-a oku-ma]-ya ¸cala¸s-ta
child.NOM book-ACC read-SUB1i-DAT try-TENSE
’The childi tried [to i read the book].’
b. Mehmet ¸cocu˘g-u [kitab-a oku-ma]-ya zorla-da
</figure>
<bodyText confidence="0.8372358">
M.NOM child-ACC book-ACC read-SUB1i-DAT force-TENSE
’Mehmetj forced the childi [to i/∗j read the book].’
c. Mehmet ¸cocu˘g-a/*-u [kitab-a oku-ma]-ya/*-ya tavsiye et-ti
M.NOM child-DAT/ACC book-ACC read-SUB1i-ACC/DAT recommend-TENSE
’Mehmet recommended the childi [to i read the book].’
</bodyText>
<subsubsectionHeader confidence="0.284021">
6.3.1 Lexical Types. Subject control verbs (e.g., ¸cala¸s ’try’; s¨oz ver ’promise’) and object
</subsubsectionHeader>
<bodyText confidence="0.607868">
control verbs (e.g., zorla; tavsiye et) have the control property indicated in their PAS
(37). The nonraising variety of these verbs is obtained via a lexical rule.
</bodyText>
<equation confidence="0.965780428571429">
s
(37) ¸calı¸s := ◦¸cala¸s − TV:Aq.Az.try(q[anaz])z
s¨oz ver := s◦ s¨oz ver − DV: Aq.Az.Aw.promisez(q[ana w])w
s
zorla := ◦zorla − DV: Az.Aq.Aw.force(q[anaz])zw
tavsiye et := ◦s tavsiye et − DV:AzAqAw.recommend(q[anaz])zw
N
</equation>
<page confidence="0.993014">
172
</page>
<note confidence="0.479796">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<bodyText confidence="0.959559111111111">
6.3.2 Derivations. The types in (37), coupled with the raising category of the infinitive,
yield the derivations in (38). These examples compose the infinitive complement before
a case can be applied on the nominalized predicate. This is possible because of the
phrasal scope of -ma and the case markers. (38b) shows that although there may be two
accusative-marked NPs, the arguments of the infinitive complement are identifiable;
the IV scope of -ma implies that any (di)transitive subordinate verb must find its
nonsubject arguments before the matrix verb gets its arguments. This type assignment
strategy handles word order variations inside the infinitive complement and the matrix
clause transparently.
</bodyText>
<figure confidence="0.888777242424242">
(38) a. ¸Cocuk kitab-ı oku -ma -ya ¸calı¸s-tı
child.NOM book-ACC read -SUB -DAT try-TENSE
&gt;T &gt;T &lt;B
S/IV IV/TV TV N\IV Ndat\N TV
&gt;
IV
&lt;
N
&lt;
Ndat
&gt;T
IV/TV
&gt;
IV
&gt;
S: try(read book(ana child))child
’The child tried to read the book.’
b. Mehmet ¸cocu˘g-u kitab-ı oku -ma -ya zorla-dı
M.NOM child-ACC book-ACC read -SUB -DAT force-TENSE
&gt;T &gt;T &gt;T &lt;B
S/IV IV/TV IV/TV TV N\IV Ndat\N DV
&gt;
IV
&lt;
N
&lt;
Ndat
&gt;T
TV/DV
&gt;
TV
&gt;
&gt;
</figure>
<bodyText confidence="0.666911">
S: force(read book(ana child))child mehmet
’Mehmet forced the child to read the book.’
</bodyText>
<page confidence="0.877251">
IV
173
</page>
<note confidence="0.722833">
Computational Linguistics Volume 28, Number 2
</note>
<subsectionHeader confidence="0.983613">
6.4 Relativization
</subsectionHeader>
<bodyText confidence="0.9969984">
There are two strategies for forming relative clauses: the subject participle strategy
(SP) and the nonsubject participle strategy (OP). SP is realized by the affixes -(y)An,
-(y)AcAk, and -mI¸s, and OP by -dIk- and -(y)AcAk-. OP triggers agreement similar to
that of possessive constructions between the subject and the predicate of the relative
clause (39b).
</bodyText>
<listItem confidence="0.795647833333333">
(39) a. kitab-ı oku-yan adam
book-ACC read-SP man
’the man that read/reads the book’
b. adam-ın oku-du˘g-u kitap
man-GEN(AGR) read-OP-POSS(AGR) book
’the book that the man read’
</listItem>
<subsubsectionHeader confidence="0.49709">
6.4.1 Lexical Types. The categories in (40) make explicit the unbounded nature of
</subsubsectionHeader>
<bodyText confidence="0.5384455">
relativization; type raising and composition can combine an indefinitely large sequence
of constituents onto S\NP.
</bodyText>
<equation confidence="0.606582714285714">
a f f
(40) -SP := ◦yan − (N↑/ &lt; N)\( &lt; a S\ &lt; NPnom)
: λP.λx.λQ.and(Q[x])(P[x])
-OP.AGR := ◦a dı˘gı − (N ↑/ &lt; N)\( &lt; S\ &lt; NPcase=obl)
(argument) :λP.λx.λQ.and(Q[x])(P[x])
-OP.AGR := ◦a dı˘gı − (N ↑/ &lt; N)\ &lt; S
(adjunct) :λP.λx.λQ.and(Q[x])(at(P[x])x)
</equation>
<bodyText confidence="0.9660795">
We present a formulation of relativization without any use of empty categories,
traces, or movement. We follow the Montagovian treatment of relative clauses as noun
restrictors of the semantic type λP.λQ.and(Q[x])(P[x]), where P is the semantics of the
relative clause and Q is the semantics of the predicate taking the relativized noun
(x) as the argument. Montagovian analysis assumes a generalized quantifier (GQ)
category for the determiner; that is, NP is the functor and VP is the argument. The
determiner takes the relativized noun (and its semantically type-raised category) as an
argument as well. In a language with determiners, the functor category of the overall
NP can be made explicit by lexically value-raising the determiner with GQ semantics
from, for example, NP/N to (S/(S\NP))/N = (S/VP)/N. To achieve the same effect in
a language that lacks determiners, we make NP the functor by lexically value-raising
the relative participle from (N/N)\(S\NP) to (N↑/N)\(S\NP), in which N↑/N denotes
a value-raised noun, since N↑ is a type-raised category. The category of the relative
participle unfolds to ((S/(S\NP))/N)\(S\NP) and (((S\NP)/(S\NP\NP))/N)\(S\NP).
Relativization is strictly head final in Turkish. This implies that all relative par-
ticiples are backward-looking functors that differ only in case requirements (cf. En-
glish relatives, which require different directionality, e.g., (N\N)/(S\NP) for subjects
and (N\N)/(S/NP) for nonsubjects). For morphosyntactic modality, the head noun has
</bodyText>
<page confidence="0.991299">
174
</page>
<figure confidence="0.8209645">
Bozsahin The Combinatory Morphemic Lexicon
f
flexible control (&lt; N), because any further grammatical marking on the head must be
shared (41).
(41) Adam-ın g¨or-d¨u ˘g-¨u ¸cocuk-lar uyu-du
man-GEN see-OP-POSS child-PLU sleep-TENSE
’The children that the man saw slept.’ = and(sleep(plu child))(see(plu child)man)
#*and(sleep(plu child))(seechild man)
</figure>
<bodyText confidence="0.99918">
Morphologically, the agreement marker -POSS in OP strategy is a function over
the -OP morpheme, but syntactically, the -OP morpheme triggers the agreement in
the relative clause. Hence -OP-POSS can be treated as a lexically composite affix and
glossed as -OP.AGR. This also ensures the verb-final property of the relativized clause
by not positing a rightward-looking functor for -OP. As for attachment modality, rel-
ative participles are bound morphemes that are affixed to the predicate.
6.4.2 Derivations. (42a–d) show example derivations for subject, object, indirect object,
and adjunct relativization. All nonsubject arguments are handled by a single -OP type
(42b–c). Relativizing the specifier of an argument uses the same strategy as the argu-
ment. This phenomenon calls for another well-regulated lexical assignment schema,
for example, (N↑/N)\(N\N)\IV for the relativized specifier of the subject. (42e) is an ex-
ample of relativizing the subject’s specifier. Configurationality within the noun group
is maintained by backward directionality of the categories.
</bodyText>
<figure confidence="0.941782151515152">
(42) a. kitab-ı oku -yan adam uyu-du
book-ACC read -SP man sleep-TENSE
&gt;T &lt;B
IV/TV TV (N↑/N)\IV N IV
: Af .f [book] : Ax.Ay.read xy : AP.Ax.AQ.and(Q[x])(P[x]) :man : Ax.sleep x
&gt;
IV: Ay.read booky
&lt;
N↑/N: Ax.AQ.and(Q[x])(read book x)
&gt;
N↑=S/(S\NP): AQ.and(Q[man])(read book man)
&gt;
S: and(sleep man)(read book man)
’The man who read the book slept.’
b. adam-ın g¨or -d¨u ˘g¨u ¸cocuk uyu-du
man-GEN read -OP.AGR child sleep-TENSE
&lt; &lt;B
NPagr TV (N↑/N)\IVagr N IV
&lt;
&lt;
N↑/N
&lt;
N↑=S/IV
&gt;
S: and(sleep child)(see child man)
’The child whom the man saw slept.’
IVagr
175
Computational Linguistics Volume 28, Number 2
c. ¸cocu˘g-un kitab-ı ver -di˘gi adam uyu-du
child-GEN book-ACC give -OP.AGR man sleep-TENSE
&lt; &gt;T &lt;B
NPagr TV/DV DV (N↑/N)\IVagr N IV
TV
&lt;
IVagr
&lt;
N↑/N
&gt;
N↑=S\IV
&gt;
S: and(sleep man)(give man book child)
’The man to whom the child gave the book slept.’
d. ¸cocu˘g-un uyu -du˘gu araba bozul-du
child-GEN sleep -OP.AGR car break-TENSE
&lt; &lt;B
NPagr IV (N↑/N)\S N IV
S
N↑/N
&gt;
N↑=S/IV
&gt;
S: and(break car)(at(sleep child)car)
’The car that the child slept in broke.’
e. ¸cocu˘g -u uyu -yan adam kız-dı
child -POSS sleep -SP man anger-TENSE
&lt;B
N N\N\N IV (N↑/N)\(N\N)\IV N IV
N\N (N↑/N)\(N\N)
&lt;
N↑/N
&gt;
N↑=S/IV
&gt;
S: and(sleep(poss child man))(anger man)
’The man whose child slept got angry.’
</figure>
<bodyText confidence="0.941464666666667">
As these examples indicate, -SP and -OP do not range over the verb stem in
semantic scope; they cover the entire relative clause. The wide scope of -SP and -OP
resolves the inconsistency pointed out in the introduction (5b–c), which was mainly
due to coindexation in unification accounts and the lexemic nature of the lexicon.
Isolating the relative participle inflections in a morphological component undermines
the transparency of derivations. Note also that -OP is categorially transparent to the
arity of the verb; a DV must be reduced to an IV before -OP applies to the verb
complex (42c). This is possible only when -OP has phrasal scope.
&lt;
</bodyText>
<page confidence="0.955762">
176
</page>
<note confidence="0.496289">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<subsectionHeader confidence="0.975476">
6.5 Ki-relativization
</subsectionHeader>
<bodyText confidence="0.999952">
Ki-relativization is a morphosyntactic process that can generate indefinitely long words
of relative pronouns and relative adjectives. -ki can be attached to case-marked nouns
whose case relation is one of possession, time, or place (i.e., the genitive and the
locative). Its effect is to create a nominal stem on which all inflections can start again
(43a–b). It produces relative pronouns (43c) and relative adjectives (43d) with the
locative and relative pronouns with the genitive.
</bodyText>
<equation confidence="0.913064333333333">
(43) a. araba-da-ki
car-LOC-REL
’the one in the car’
b. ¸cocu˘g-un ev-i-nde-ki-ler-in-ki
child-GEN house-POSS-LOC2-REL-PLU-GEN-REL
lit. ’The one that belongs to the ones that are in the child’s house’
</equation>
<listItem confidence="0.5926075">
c. Ben ev-de-ki-ni hi¸c kullan-ma-dı-m
I.NOM house-LOC-REL-ACC2 never use-NEG-TENSE-PERS.1s
’I never used the one at home.’
d. ev-de-ki hediye
house-LOC-REL present
’the presenti, the onei at home’
</listItem>
<subsectionHeader confidence="0.486786">
6.5.1 Lexical Types.
</subsectionHeader>
<bodyText confidence="0.693952578947368">
(44) a. -PROki := a◦ ki− ✶l N\c✶Nloc:λx.λf.and(atPROx)(f[PRO])
(locative) := a ki − ( ✶l N/ n
-ADJki ◦&lt; N)\ c✶ Nloc: λx.λy.λf.and(atxy)(f [y])
-PROki := a◦ ki− ✶l N\N↑gen:λx.λf.and(possPROx)(f[PRO])
(genitive)
sabahki := ◦s sabahki − ✶l N/ &lt;n N: λx.λf.and(at morning x)(f[x])
ki (that) := ◦c ki − (N ↑\ &lt; N)/( &lt; S\ &lt; NPnom)
: λP.λx.λQ.and(Q[x])(P[x])
N↑gen is a shorthand for the N/(N\N) category of a type-raised genitive. In (43c),
pronominal one (PRO) cannot be bound to ev (44a). Adjectival interpretation (43d)
associates the relative adjective with the relativized noun (44b). For morphosyntac-
tic modality, ki-marked nouns behave like possessive-marked nouns in case marking,
which requires strict control over the possessive (o✶ N). This presents a dilemma: Mor-
phologically, -ki creates a nominal stem that can undergo all nominal inflections again,
but, as (45a) indicates, the stem does not take the CASE (ACC, DAT, etc.) that is com-
mon to nouns unmarked on the possessive. Thus CASE2 in (45c) must refer to another
diacritic (n-relbase, or ✶l) to eliminate (45b). This diacritic controls the result category
of -ki. The value-raised varieties of (44a–c) are assigned a type similar to the type of
relative participles. Inherently temporal nouns such as sabah (’morning’) can take -ki
</bodyText>
<page confidence="0.989229">
177
</page>
<note confidence="0.617737">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.695464">
without the locative. They can be lexicalized without overgeneration with the help of
the morphosyntactic modality ✶l (44d).
</bodyText>
<listItem confidence="0.483327">
(45) a. *ev-de-ki-yi b. *ev-ni
house-LOC-REL-ACC house-ACC2
c. ev-de-ki-ni d. ev-i
house-LOC-REL-ACC2 house-ACC
6.5.2 Derivations. -ki ranges over the case-marked noun, which, as (46a–b) indicate,
can be lexical or phrasal. In a lexemic analysis, the entire ki-marked noun would have
to be rebracketed before the adjective k¨u¸c¨uk can apply to its right scope (which is ev,
not ¸cocuk).
(46) a. ev -de -ki
</listItem>
<figure confidence="0.97439732">
house -LOC -PROki
&lt; N\ o
c &lt; N ✶l N\ ✶ c Nloc
&lt;
c
&lt; Nloc
&lt;
✶l N: Af.and(at PRO house)(f[PRO])
’the one that is in the house’
b. k¨u¸c¨uk ev -de -ki ¸cocuk
little house -LOC -ADJki child
b
&lt; N
b b
&lt; N/ &lt; b N &lt; b N &lt; c N\ &lt; o N ( ✶l N/ &lt; n N)\ ✶ c Nloc &lt; N
&gt;
b
&lt; N
&lt;
c
&lt; Nloc
&lt;
✶l N/ &lt;n N
&gt;
✶l N: Af.and(at(little house)child)(f [child])
</figure>
<bodyText confidence="0.893306">
’the childi, the onei at the little house’
There is another ki in Turkish that forms nonrestrictive relative clauses as post-
modifiers. It is a Persian borrowing and follows the Indo-European pattern of relative
clause formation (47). It can be distinguished from the bound morpheme -ki lexically.
Its attachment characteristic is also different than that of -ki (44e).
</bodyText>
<listItem confidence="0.567518">
(47) Adam ki hep uyur
</listItem>
<bodyText confidence="0.5228875">
man that always sleep-TENSE
’the man, who always sleeps’
</bodyText>
<page confidence="0.989611">
178
</page>
<note confidence="0.454005">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<subsectionHeader confidence="0.996483">
6.6 Possessive Constructions and Syntactic Compounds
</subsectionHeader>
<bodyText confidence="0.93678925">
The grammatical marking of possession is realized through the genitive case on the
possessor (Ngen) and the possessive marker on the possessee (Nposs). Ngen and Nposs must
agree in person and number (48a), and the resulting noun group is configurational.
Possessives can be nested (48c).
</bodyText>
<figure confidence="0.7140965">
(48) a. ev-in kapı-sı b. * ev-in kapı / *ev-in kapı-lar (door-PLU)
house-GEN3 door-POSS3s
’the door of the house’
c. ben-im arkada¸s-ım-ın ev-i-nin kapı-lar-ı
I-GEN1 friend-POSS1s-GEN3 house-POSS3s door-PLU-POSS3s
’my friend’s house’s doors’
d. ben-im arkada¸s-ım-ıni dost-u-nunj kendisi∗i/j
I-GEN1 friend-POSS1s-GEN3 buddy-POSS3s-GEN3 self
’my friend’s buddy himself’
e. Her ¸calı¸san-ın bazı hak-lar-ı vardır
every worker-GEN3 some right-PLU-POSS3s exists
∀x∃y((worker(x) ∧ right(y)) → has(x,y))
but not ∃y∀x(right(y) ∧ (worker(x) → has(x,y)))
6.6.1 Lexical Types for Possessives. Type assignments for the genitive and the pos-
sessive can be schematized over person (p) and number (n) features, as in (49).
(49) -GENpn := ◦a s − ( &lt; o N/( o ✶ Npn\ o ✶ Npn))\ &lt; o Npn: λx.λy.poss yx
a
-POSSpn := ◦s −(o ✶ Npn\o ✶ Npn)\&lt; n Npn:λf .f
</figure>
<bodyText confidence="0.951634818181818">
The possessive marker’s result category is a functor because it enforces agreement
with the type raised specifier.18 (48d–e) indicate that the genitive marker is a type
raiser; the possessor scopes over the possessee. For morphosyntactic modality, the
genitive marker can be attached to nouns that are inflected up to and including a
possessive marker (&lt;o N). Moreover, nesting in possessives implies that the specifier
o
may be a genitive. Hence, the stem’s category must be &lt; N.
But there is a finer control over the possessee argument’s category, because it must
be inflected with the possessive marker to signify relation of possession (cf. (48a–b)).
Semantically, the possessive must outscope nominal modification. For instance, (50a)
has the PAS as indicated, hence both markers must range over a noun group, not just
</bodyText>
<footnote confidence="0.573387333333333">
18 An “inert” category such as N may be motivated by the prodrop phenomenon, in which the specifier
may be dropped under pragmatically conditioned circumstances. But this analysis disregards the point
that binding relations (hence semantics) still require the coindexation of the specifier with some overt
referent, which can be inferred from the discourse. Such an interface phenomenon seems to be better
suited for handling by interactions in the components of a multidimensional grammar, rather than as a
purely syntactic phenomenon.
</footnote>
<page confidence="0.990336">
179
</page>
<figure confidence="0.930361170731708">
Computational Linguistics Volume 28, Number 2
the stem. Binding relations require an organization of the type (poss possee possessor)
(50b–c).
(50) a. ya¸sli adam-in k¨u¸c¨uk kiz-i
old man-GEN3little daughter-POSS3s
’old man’s little daughter’ = poss(little daughter)(old man)
b. adami-in kendii-si
man-GEN self-POSS
’the man himself’
c. *kendii adami-i
6.6.2 Derivation of Possessive Constructions. Example (51) shows the wide scope of
the genitive (51a) and nested genitives (51b).
(51) a. ya¸sli adam -in k¨u¸c¨uk kiz -i
old man -GEN little daughter -POSS
&lt; N/ b
b &lt; N &lt; b N &lt; o N/( o ✶ N\ o ✶ N)\ &lt; o N &lt; b N/ &lt; b N &lt; b N o ✶ N\ o ✶ N\ &lt; n N
&gt; &gt;
b b
&lt; N &lt; N
&lt; &lt;
&lt; N/( o
o ✶ N\o ✶ N) ✶ N\ o
o ✶ N
&gt;
o
&lt; N: poss(little daughter)(old man)
’old man’s little daughter’
b. ben -im arkada¸s -im -in ev -i
I -GEN friend -POSS -GEN house -POSS
N N/(N\N)\N N N\N\N N/(N\N)\N N N\N\N
&lt; &lt; &lt;
N/(N\N) N\N N\N
&gt;
&lt;
N/(N\N)
&gt;
N: poss house(poss friend i)
’my friend’s house’
N
180
Bozsahin The Combinatory Morphemic Lexicon
</figure>
<subsubsectionHeader confidence="0.728294">
6.6.3 Lexical Types for Compounds. Syntactic compounds exhibit syntactic patterns
</subsubsectionHeader>
<bodyText confidence="0.9996785">
similar to possessive constructions, but they signify semantic relations of a different
kind. In what follows, we use the function comp to signify that the arguments in the
PAS form a compound but say nothing about the range of productivity of this function.
The lexical semantics of the arguments and a qualia structure (Pustejovsky 1991) may
indicate the function’s range of applicability. Lexical type assignments for compound
markers are as in (52).
</bodyText>
<figure confidence="0.370618">
(52) -COMP := o s − A N\ &lt; N\ A N: Ax.Ay.comp xy
-COMP2 :=o s− AN\ AN\ &lt; N\ A N: Ax.Ay.Az.comp(compxy)z
(nested comp)
</figure>
<bodyText confidence="0.992112142857143">
Syntactic compounds are formed by means of compound markers that are attached
to the head of the compound. For morphosyntactic modality, nonreferentiality of the
head implies no inflection (AN) or modification (53a–b). The left component can be
a noun group (53c) in which there is ambiguity in the scope of modification. This
is regulated by typing, for example, the intersective adjectives ambiguous as noun
modifiers ( &lt;n N/ &lt;n N) and compound modifiers (m� N/ m�N).19 The overall compound
may be inflected only for case (see, e.g., (53d) and (53e)).
</bodyText>
<figure confidence="0.910481076923077">
(53) a.otob¨us bilet-i
bus ticket-COMP
’bus ticket’
c.ye¸sil otob¨us bilet-i
green bus ticket-COMP
green(comp ticket bus)
or comp(ticket(green bus))
d.otob¨us bilet-i-ni
ticket-COMP-ACC2
b.*otob¨us ye¸sil bilet-i
green
e.*otob¨us bilet-i-si
ticket-COMP-POSS
</figure>
<bodyText confidence="0.994825444444444">
Compound markers serve the dual function of compounding and agreement in
possessive constructions; double marking of the possessive is suppressed (cf. 54a–b).
The -COMP2 type assignment in (52) handles nested compounds.
(54) a.banka-nın faiz oran-ı b.*banka-nın faiz oran-ı-sı
bank-GEN interest rate-COMP.POSS rate-COMP-POSS
’interest rate of the bank’
We claim that plural compounds are lexically composite functions in a similar
vein. This claim has some empirical support from the lexicalization of -leri as a
third person plural possessive marker; see (55b–c). It follows that -leri has the lexi-
</bodyText>
<page confidence="0.8956735">
19 I am grateful to the anonymous reviewer who proposed this alternative.
181
</page>
<figure confidence="0.929219777777778">
Computational Linguistics Volume 28, Number 2
cal types of -COMP and -COMP2 with plural and possessive composition: λx.λy.plu
(comp xy).
(55) a.otob¨us bilet-leri b.onlar-ın ev-leri
bus ticket-COMP.PLU they-GEN3 house-POSS3p
’bus tickets’ ’their house’
c.onlar-ın ev-ler-i
they-GEN3 house-PLU-POSS3s
’their houses’
</figure>
<figureCaption confidence="0.8741176">
6.6.4 Derivation of Compounds. (56) exemplifies derivations with the type assign-
ments in (52). (56a–b) show that both the narrow and the wide scope of the modifier
can be accounted for. (56c–d) show that the compound marker interacts with the pos-
sessive. Hence, it must carry both poss and comp in possessive constructions involving
compounds. (56e–f) are examples of nested compounds. (56f–g) show the effect of
</figureCaption>
<figure confidence="0.9621936">
strict control (b✶N) over the compound’s head.
(56) a. ye¸sil otob¨us bilet -i
green bus ticket -COMP
&lt; N/ n
n &lt; N &lt;bN &lt;bN m ✶ N\&lt;nN\b✶N
&gt; &lt;
n&lt; N AN\&lt; N
&lt;
m✶ N: comp ticket(green bus)
b. ye¸sil otob¨us bilet -i
&lt;
✶ N/ m
m ✶ N &lt;b N m✶N\ &lt;n N
&lt;
m✶N
&gt;
m ✶N: green(compticket bus)
c. banka -nın faiz oran -ı
bank -GEN interest rate -COMP.POSS
N N/(N\N)\N N N N\N\N\N
&gt; &lt;
N/(N\N) N\N\N
&lt;
N\N
&gt;
</figure>
<bodyText confidence="0.551713">
N: poss(comp rate interest)bank
’interest rate of the bank’
</bodyText>
<page confidence="0.884893">
182
</page>
<figure confidence="0.960378083333333">
Bozsahin The Combinatory Morphemic Lexicon
d. banka -nan faiz oran -lara
bank -GEN interest rate -COMP.POSS.PLU
N N/(N\N)\N N N N\N\N\N
&gt; &lt;
N/(N\N) N\N\N
&lt;
N\N
&gt;
N: poss(plu(comp rate interest))bank
’interest rates of the bank’
e. kredi kart -a faiz oran -a
credit card -COMP interest rate -COMP2
N N N\N\N N N N\N\N\N
&lt; &lt;
N\N N\N\N
&lt; &lt;
N N\N
&lt;
N: comp(comp rate interest)(comp card credit)
’credit card interest rate’
f.kredi kart-a yallak faiz oran-a g.*kredi kart-a faiz yallak oran-a
annual
’credit card annual interest rate’
</figure>
<sectionHeader confidence="0.914167" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.999914523809524">
Theoretical and computational commitment to word-based grammar—and to regard
inflectional morphology as a word-internal process—puts artificial limits on specify-
ing the syntactic and semantic domains of all meaning-bearing elements and on the
transparent projection of scope from the lexicon. Designating words as minimal units
of the lexicon is too constraining for many languages. This traditional notion is also
challenged in current linguistic theorizing (e.g., Jackendoff 1997 and Keenan and Sta-
bler 1997). Marslen-Wilson (1999) argues on psycholinguistic grounds that the lexicon
must be morphemic even for morphologically simpler languages such as English.
We have argued in this article that the key to the integration of inflectional mor-
phology and syntax is granting representational status to morphemes, which, in a
computational system, requires certain precautions. What we propose is enriching the
expressive power of the combinatory morphemic lexicon to factor in morphosyntactic
types and attachment modalities. Coupled with flexible constituency in the grammar
and directionality information coming from the lexicon, these extensions provide the
grammar with the information it requires to compute the transparent semantics of
morphosyntactic phenomena. This flexibility causes neither inefficiency in parsing nor
uncontrolled expressivity. The extensions do not affect the polynomial worst-case com-
plexity results, and category unity is preserved by lattice consistency. The result is a
morphemic grammar–lexicon with computationally desirable features such as mod-
ularity and transparency. The system is available at ftp://ftp.lcsl.metu.edu.tr/pub/
tools/msccg.
</bodyText>
<page confidence="0.997177">
183
</page>
<note confidence="0.762938">
Computational Linguistics Volume 28, Number 2
</note>
<sectionHeader confidence="0.967819" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.8215443">
I am very grateful to four anonymous CL
reviewers for extensive commentary and
suggestions. Thanks to Wolf K¨onig and
Stefan M¨uller for the data; and to Jason
Baldridge, Gann Bierner, Aysenur Birt¨urk,
Ruken ¸Cakici, Nissim Francez, Stasinos
Konstantopoulos, Markus Kracht, Geert-Jan
Kruijff, Alan Libert, Mark Steedman, ¨Umit
Turan and Deniz Zeyrek for comments,
advice, and criticism.
</reference>
<sectionHeader confidence="0.82113" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999672259615384">
Aho, Alfred V. and Jeffrey D. Ullman. 1972.
The Theory of Parsing, Translation, and
Compiling. Vol. 1. Prentice-Hall.
Anderson, Stephen R. 1982. Where’s
morphology? Linguistic Inquiry,
13(4):571–612.
Bach, Emmon. 1983. On the relationship
between word-grammar and
phrase-grammar. Natural Language and
Linguistic Theory, 1:65–89.
Baldridge, Jason. 1999. Strong equivalence
of CCG and Set-CCG. Unpublished
manuscript, University of Edinburgh.
Bar-Hillel, Yehoshua, Chaim Gaifman, and
Eliyahu Shamir. 1960. On categorial and
phrase structure grammars. Bulletin of the
Research Council of Israel, 9F:1–16.
Bozsahin, Cem. 1998. Deriving the
Predicate-Argument structure for a free
word order language. In Proceedings of
COLING-ACL 1998, Montreal,
pages 167–173.
Bozsahin, Cem. 2000a. Directionality and
the lexicon: Evidence from gapping.
Unpublished manuscript, Middle East
Technical University, Ankara.
Bozsahin, Cem. 2000b. Gapping and word
order in Turkish. In Proceedings of the 10th
International Conference on Turkish
Linguistics, Istanbul.
Bozsahin, Cem and Elvan G¨o¸cmen. 1995. A
categorial framework for composition in
multiple linguistic domains. In Proceedings
of the 4th International Conference on
Cognitive Science of NLP, Dublin.
Bresnan, Joan. 1995. Lexical–Functional
syntax. Course notes. Seventh European
Summer School in Logic, Language, and
Information, Barcelona.
Calder, Jonathan, Ewan Klein, and Henk
Zeevat. 1988. Unification categorial
grammar. In Proceedings of the 12th
International Conference on Computational
Linguistics, Budapest, pages 83–86.
Carpenter, Bob. 1992. Categorial Grammar,
lexical rules, and the English predicative.
In R. Levine, editor, Formal Grammar:
Theory and Application. Oxford University
Press, pages 168–242.
Carpenter, Bob. 1997. Type-Logical Semantics.
MIT Press.
Carpenter, Bob. 1999. The
Turing-completeness of Multimodal
Categorial Grammars. In Papers Presented
to Johan van Benthem in Honor of his 50th
Birthday. ESSLLI, Utrecht.
Carpenter, Bob and Gerald Penn. 1994. The
Attribute Logic Engine User’s Guide, Version
2.0. Carnegie Mellon University.
Chomsky, Noam. 1970. Remarks on
nominalization. In R. Jacobs and
P. Rosenbaum, editors, Readings in English
Transformational Grammar. Ginn, Waltham,
MA, pages 184–221.
Chomsky, Noam. 1995. The Minimalist
Program. MIT Press.
Collins, Michael. 1997. Three generative,
lexicalised models for statistical parsing.
In Proceedings of the 35th Annual Meeting of
the ACL.
Creider, Chet, Jorge Hankamer, and Derick
Wood. 1995. Preset two-head automata
and natural language morphology.
International Journal of Computer
Mathematics, 58:1–18.
Dalrymple, Mary and Ronald M. Kaplan.
2000. Feature indeterminacy and feature
resolution. Language, 76:759–798.
Dowty, David. 1979. Word Meaning and
Montague Grammar. Kluwer, Dordrecht.
Dowty, David. 1991. Toward a minimalist
theory of syntactic structure. In Tilburg
Conference on Discontinuous Constituency,
January 1989.
Dowty, David. 1996. Non-constituent
coordination, wrapping, and Multimodal
Categorial Grammars. In International
Congress of Logic, Methodology, and
Philosophy, Florence, August.
Eisner, Jason. 1996. Efficient normal-form
parsing for Combinatory Categorial
Grammar. In Proceedings of the 34th Annual
Meeting of the ACL, pages 79–86.
Fong, Sandiway. 1991. Computational
Properties of Principle-Based Grammatical
Theories. Ph.D. dissertation, MIT.
G¨ung¨ord¨u, Zelal and Kemal Oflazer. 1995.
Parsing Turkish using the
Lexical-Functional Grammar formalism.
Machine Translation, 10:293–319.
Hankamer, Jorge. 1989. Morphological
parsing and the lexicon. In W.
Marslen-Wilson, editor, Lexical
Representation and Process. MIT Press.
</reference>
<page confidence="0.980513">
184
</page>
<note confidence="0.295598">
Bozsahin The Combinatory Morphemic Lexicon
</note>
<reference confidence="0.99985556557377">
Hepple, Mark. 1990a. The Grammar and
Processing of Order and Dependency: A
Categorial Approach. Ph.D. dissertation,
University of Edinburgh.
Hepple, Mark. 1990b. Normal form theorem
proving for the Lambek Calculus. In
Proceedings of COLING 1990.
Hepple, Mark and Glyn Morrill. 1989.
Parsing and derivational equivalence. In
Proceedings of the 4th EACL, Manchester.
Heylen, Dirk. 1997. Underspecification in
Type-Logical Grammars. In Logical Aspects
of Computational Linguistics (LACL), Nancy.
Heylen, Dirk. 1999. Types and Sorts: Resource
Logic for Feature Checking. Ph.D.
dissertation, Utrecht University.
Hockenmaier, Julia, Gann Bierner, and Jason
Baldridge. 2000. Providing robustness for
a CCG system. Unpublished manuscript,
University of Edinburgh.
Hoeksema, Jack. 1985. Categorial Morphology.
Garland, New York.
Hoeksema, Jack and Richard D. Janda. 1988.
Implications of process-morphology for
Categorial Grammar. In Richard T.
Oehrle, Emmon Bach, and Deirdre
Wheeler, editors, Categorial Grammars and
Natural Language Structures. D. Reidel,
Dordrecht, pages 199–247.
Hoffman, Beryl. 1995. The Computational
Analysis of the Syntax and Interpretation of
“Free” Word Order in Turkish. Ph.D.
dissertation, University of Pennsylvania.
Jackendoff, Ray. 1997. The Architecture of the
Language Faculty. MIT Press.
Jacobson, Pauline. 1996. The syntax/
semantics interface in Categorial
Grammar. In Shalom Lappin, editor, The
Handbook of Contemporary Semantic Theory.
Blackwell, 89–116.
Janeway, Roger. 1990. Unacceptable
ambiguity in Categorial Grammar. In
Proceedings of the Ninth West Coast
Conference on Formal Linguistics, pages
305–316.
Johnson, Mark. 1988. Deductive parsing
with multiple levels of representation. In
Proceedings of the 26th Annual Meeting of the
ACL, pages 241–248.
Johnson, Mark and Sam Bayer. 1995.
Features and agreement in Lambek
Categorial Grammar. In Proceedings of the
1995 ESSLLI Formal Grammar Workshop,
pages 123–137.
Jurafsky, Daniel and James H. Martin. 2000.
Speech and Language Processing.
Prentice-Hall.
Karttunen, Lauri. 1989. Radical lexicalism.
In Mark Baltin and Anthony Kroch,
editors, Alternative Conceptions of Phrase
Structure. University of Chicago Press,
pages 43–65.
Keenan, Edward L. and Edward Stabler.
1997. Bare grammar. Course notes, Ninth
European Summer School on Logic,
Language, and Information,
Aix-en-Provence.
Komagata, Nobo. 1997. Efficient parsing for
CCGs with generalized type-raised
categories. In Proceedings of the Fifth Int.
Workshop on Parsing Technologies, pages
135–146.
K¨onig, Esther. 1989. Parsing as natural
deduction. In Proceedings of the 27th Annual
Meeting of the ACL, pages 272–279.
Kracht, Markus. 1999. Referent systems,
argument structure, and syntax. ESSLLI
lecture notes, Utrecht.
Kruijff, Geert-Jan M. and Jason M.
Baldridge. 2000. Relating categorial type
logics and CCG through simulation.
Unpublished manuscript, University of
Edinburgh.
Lambek, Joachim. 1958. The mathematics of
sentence structure. American Mathematical
Monthly, 65:154–170.
Marslen-Wilson, William. 1999. Abstractness
and combination: The morphemic lexicon.
In Simon Garrod and Martin J. Pickering,
editors, Language Processing. Psychology
Press, East Sussex, UK, pages 101–119.
Miller, Philip H. and Ivan A. Sag. 1997.
French clitic movement without clitics or
movement. Natural Language and Linguistic
Theory, 15:573–639.
Moortgat, Michael. 1988a. Categorial
Investigations: Logical and Linguistic Aspects
of the Lambek Calculus. Foris, Dordrecht.
Moortgat, Michael. 1988b. Mixed
composition and discontinuous
dependencies. In Richard T. Oehrle,
Emmon Bach, and Deirdre Wheeler,
editors, Categorial Grammars and Natural
Language Structures. D. Reidel, Dordrecht,
pages 319–348.
Moortgat, Michael and Richard T. Oehrle.
1994. Adjacency, dependency and order.
In Proceedings of the Ninth Amsterdam
Colloquium.
Morrill, Glyn V. 1994. Type Logical Grammar:
Categorial Logic of Signs. Kluwer.
Morrill, Glyn V. 1999. Geometry of
lexico-syntactic interaction. In Proceedings
of the Ninth EACL, Bergen.
M¨uller, Stefan. 1999. Deutsche Syntax
deklarativ. Head-Driven Phrase Structure
Grammar f¨ur das Deutsche. Linguistische
Arbeiten 394. Max Niemeyer Verlag,
T¨ubingen.
Oflazer, Kemal. 1994. Two-level description
of Turkish morphology. Literary and
Linguistic Computing, 9(2).
</reference>
<page confidence="0.970654">
185
</page>
<note confidence="0.363023">
Computational Linguistics Volume 28, Number 2
</note>
<reference confidence="0.999759619565218">
Oflazer, Kemal. 1996. Error-tolerant
finite-state recognition with applications
to morphological analysis and spelling
correction. Computational Linguistics,
22:73–89.
Oflazer, Kemal, Elvan G¨o¸cmen, and Cem
Bozsahin. 1994. An outline of Turkish
morphology. Report to NATO Science
Division SfS III (TU-LANGUAGE),
Brussels.
Oflazer, Kemal, Bilge Say, Dilek Zeynep
Hakkani-T¨ur, and G¨okhan T¨ur. 2001.
Building a Turkish treebank. In Anne
Abeille, editor, Building and Exploiting
Syntactically-Annotated Corpora. Kluwer.
Pareschi, Remo and Mark Steedman. 1987.
A lazy way to chart-parse with Categorial
Grammars. In Proceedings of the 25th
Annual Meeting of the ACL, pages 81–88.
Pereira, Fernando C. N. and Stuart M.
Shieber. 1987. Prolog and Natural-Language
Analysis. CSLI, Stanford, CA.
Pollard, Carl and Ivan A. Sag. 1994.
Head-Driven Phrase Structure Grammar.
University of Chicago Press.
Pulman, Stephen G. 1996. Unification
encodings of grammatical notations.
Computational Linguistics, 22:295–327.
Pustejovsky, James. 1991. The generative
lexicon. Computational Linguistics,
17(4):409–441.
Sehitoglu, Onur. 1996. A sign-based phrase
structure grammar for Turkish. Master’s
thesis, Middle East Technical University.
Sehitoglu, Onur and Cem Bozsahin. 1999.
Lexical rules and lexical organization:
Productivity in the lexicon. In Evelyne
Viegas, editor, Breadth and Depth of
Semantic Lexicons. Kluwer, pages 39–57.
Steedman, Mark. 1985. Dependency and
co¨ordination in the grammar of Dutch
and English. Language, 61(3):523–568.
Steedman, Mark. 1987. Combinatory
grammars and parasitic gaps. Natural
Language and Linguistic Theory, 5:403–439.
Steedman, Mark. 1988. Combinators and
grammars. In Richard T. Oehrle, Emmon
Bach, and Deirdre Wheeler, editors,
Categorial Grammars and Natural Language
Structures. D. Reidel, Dordrecht, pages
417–442.
Steedman, Mark. 1991a. Structure and
intonation. Language, 67:260–298.
Steedman, Mark. 1991b. Type raising and
directionality in Combinatory Grammar.
In Proceedings of the 29th Annual Meeting of
the ACL, pages 71–78.
Steedman, Mark. 1996. Surface Structure and
Interpretation. MIT Press.
Steedman, Mark. 2000a. The Syntactic
Process. MIT Press.
Steedman, Mark. 2000b. Information
structure and the syntax-phonology
interface. Linguistic Inquiry, 31(4): 649–689.
Szabolcsi, Anna. 1983. ECP in categorial
grammar. Unpublished manuscript,
Max-Planck Institute.
Szabolcsi, Anna. 1987. Bound variables in
syntax: Are there any? In Proceedings of the
6th Amsterdam Colloquium, pages 331–350.
Tomita, Masaru. 1988. The Generalized LR
Parser/Compiler. Technical report, Center
for Machine Translation, Carnegie Mellon
University.
Vijay-Shanker, K. and David J. Weir. 1993.
Parsing some constrained grammar
formalisms. Computational Linguistics,
19:591–636.
Wechsler, Stephen and Larisa Zlati´c. 2000. A
theory of agreement and its application to
Serbo-Croatian. Language, 76:799–832.
Whitelock, Pete J. 1988. A feature-based
categorial morpho-syntax for Japanese. In
Uwe Reyle and C. Rohrer, editors, Natural
Language Parsing and Linguistic Theories. D.
Reidel, pages 230–261.
Williams, Edwin. 1981. On the notions
“lexically related” and “head of a word.”
Linguistic Inquiry, 12(2):245–274.
Wittenburg, Kent. 1987. Predictive
combinators. In Proceedings of the 25th
Annual Meeting of the ACL, pages 73–79.
</reference>
<page confidence="0.998772">
186
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.233361">
<title confidence="0.7912985">The Combinatory Morphemic Lexicon Middle East Technical University</title>
<abstract confidence="0.986077090909091">Grammars that expect words from the lexicon may be at odds with the transparent projection of syntactic and semantic scope relations of smaller units. We propose a morphosyntactic framework based on Combinatory Categorial Grammar that provides flexible constituency, flexible category consistency, and lexical projection of morphosyntactic properties and attachment to grammar in order to establish a morphemic grammar-lexicon. These mechanisms provide enough expressive power in the lexicon to formulate semantically transparent specifications without the necessity to confine structure forming to words and phrases. For instance, bound morphemes as lexical items can have phrasal scope or word scope, independent of their attachment characteristics but consistent with their semantics. The controls can be attuned in the lexicon to language-particular properties. The result is a transparent interface of inflectional morphology, syntax, and semantics. We present a computational system and show the application of the framework to English and</abstract>
<intro confidence="0.463488">Turkish.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>I am very grateful to four anonymous CL reviewers for extensive commentary and suggestions. Thanks to Wolf K¨onig and Stefan M¨uller for the data; and to Jason Baldridge, Gann Bierner, Aysenur Birt¨urk, Ruken ¸Cakici, Nissim Francez, Stasinos Konstantopoulos, Markus Kracht, Geert-Jan Kruijff, Alan Libert, Mark Steedman, ¨Umit Turan and Deniz Zeyrek for comments, advice, and criticism.</title>
<marker></marker>
<rawString>I am very grateful to four anonymous CL reviewers for extensive commentary and suggestions. Thanks to Wolf K¨onig and Stefan M¨uller for the data; and to Jason Baldridge, Gann Bierner, Aysenur Birt¨urk, Ruken ¸Cakici, Nissim Francez, Stasinos Konstantopoulos, Markus Kracht, Geert-Jan Kruijff, Alan Libert, Mark Steedman, ¨Umit Turan and Deniz Zeyrek for comments, advice, and criticism.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>The Theory of Parsing,</title>
<date>1972</date>
<journal>Translation, and Compiling.</journal>
<volume>1</volume>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="34516" citStr="Aho and Ullman 1972" startWordPosition="5654" endWordPosition="5657">n elaborate agreement system, we note that Pulman’s techniques provide the mechanism for implementing agreement as atomic unification, subsumption hierarchies represented as lattices, or set-valued features. The categorial ingredient of phrase-internal agreement can be provided by endotypic functors when necessary (see Sections 5 and 6). 157 Computational Linguistics Volume 28, Number 2 There is also a switch for checking the PAS equivalence, with the warning that the equivalence of two lambda expressions is undecidable. The parser is an adaptation of the Cocke-Kasami-Younger (CKY) algorithm (Aho and Ullman 1972, page 315), modified to handle unary rules as well: In the kth iteration of the CKY algorithm to build constituents of length k, the unary rules apply to the CKY table entries T[αi, αi+k ], i = 0,1, ... , n − k; that is, k-length results of binary rules are input to potential unary constituents of length k. In practice, this allows, for instance, a nominalized clause to be type-raised after it is derived as a category of type N. The remaining combinatory schema is already in Chomsky Normal Form, as required by CKY. The finite schematization of CCG rules and constant costs incurred by the norm</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Aho, Alfred V. and Jeffrey D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Vol. 1. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen R Anderson</author>
</authors>
<title>Where’s morphology? Linguistic Inquiry,</title>
<date>1982</date>
<contexts>
<context position="6958" citStr="Anderson 1982" startWordPosition="1012" endWordPosition="1013">e nonempty nonsingleton sets of things that are not trucks but fake trucks (Carpenter 1997). Four trucks, on the other hand, has the semantics (four(plu truck)), which corresponds to four [truck]-s, because it denotes the subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morpho</context>
</contexts>
<marker>Anderson, 1982</marker>
<rawString>Anderson, Stephen R. 1982. Where’s morphology? Linguistic Inquiry, 13(4):571–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmon Bach</author>
</authors>
<title>On the relationship between word-grammar and phrase-grammar.</title>
<date>1983</date>
<booktitle>Natural Language and Linguistic Theory,</booktitle>
<pages>1--65</pages>
<contexts>
<context position="7646" citStr="Bach 1983" startWordPosition="1117" endWordPosition="1118">ed to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar tha</context>
</contexts>
<marker>Bach, 1983</marker>
<rawString>Bach, Emmon. 1983. On the relationship between word-grammar and phrase-grammar. Natural Language and Linguistic Theory, 1:65–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>Strong equivalence of CCG and Set-CCG.</title>
<date>1999</date>
<institution>University of Edinburgh.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="53778" citStr="Baldridge 1999" startWordPosition="8773" endWordPosition="8774"> xy ⇒ v f f &lt; S\ &lt; NP+ref acc \ &lt; NPnom : λy.λx.like xy e. -ACC := a◦ i|ı|u|¨u|yi|yı|yu|y¨u − &lt;c Nacc\ &lt;o N: λf .f f. -LOC := ◦a de|da|te|ta − ( &lt;α S/ &lt;α S)\ &lt;o N: λx.λf.at fx Gapping behavior seems to indicate that Turkish is verb final, not just SOV. SO and OS syntactic types must be distinguished to account for SO &amp; SOV, OS &amp; OSV, *SO &amp; OSV and *OS &amp; SOV. The OS &amp; OSV pattern requires the lexical category S\NPacc\NPnom for the verb (Bozsahin 2000b). SOV and OSV base orders can be captured uniquely in the lexicon in set-CCG notation as S\{NPacc,NPnom}. Set-CCG is strongly equivalent to CCG (Baldridge 1999). We distinguish SOV and OSV lexically, however, because OSV requires referential objects (25a–b). OSV is generated from SOV by a lexical rule (24d). This is genuine lexical ambiguity, because the two related entries differ in semantics (referentiality). (25) a. Kitab-ı adam oku-du Book-ACC man.NOM read-TENSE ’The man read the book.’ b. *Kitap adam oku-du Book man.NOM read-TENSE Regarding the relationship between case and the specifiers, it is questionable whether Turkish has a discernible syntactic category for determiners. There is no lexical functor that takes an N and yields an NP. The onl</context>
</contexts>
<marker>Baldridge, 1999</marker>
<rawString>Baldridge, Jason. 1999. Strong equivalence of CCG and Set-CCG. Unpublished manuscript, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
<author>Chaim Gaifman</author>
<author>Eliyahu Shamir</author>
</authors>
<title>On categorial and phrase structure grammars.</title>
<date>1960</date>
<journal>Bulletin of the Research Council of Israel,</journal>
<pages>9--1</pages>
<marker>Bar-Hillel, Gaifman, Shamir, 1960</marker>
<rawString>Bar-Hillel, Yehoshua, Chaim Gaifman, and Eliyahu Shamir. 1960. On categorial and phrase structure grammars. Bulletin of the Research Council of Israel, 9F:1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Bozsahin</author>
</authors>
<title>Deriving the Predicate-Argument structure for a free word order language.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<pages>167--173</pages>
<location>Montreal,</location>
<contexts>
<context position="56293" citStr="Bozsahin 1998" startWordPosition="9163" endWordPosition="9164"> be a syntactically derived noun (28). SO (and OS) constituency required for gapping is provided by &gt;T and &gt;B. (28) Mehmet k¨u¸c¨uk ye¸sil kitab-ı, ¸cocuk da yeni gelen dergi-yi oku-du M.NOM little green book-ACC child-COORD new come mag.-ACC read-TENSE Nnom Nacc Nnom Nacc S\NPnom\NPacc &gt;T &gt;T S/(S\NPnom) (S\NP) /(S\NP\NPacc) ... &gt;B &gt;B S/(S\NPnom\NPacc) S/(S\NPnom\NPacc) &amp; S/(S\NPnom\NPacc) &gt; S ’Mehmet read the little green book, and the child, the newly arrived magazine’. Our lexical type assignment to case morphemes (24e–f) departs from other CCG analyses of case (e.g., Steedman 1985, 1991a, Bozsahin 1998). These studies correlate morphological case with type raising of arguments, in the case of Bozsahin (1998), via a value-raised category assignment to case morphemes. Evidence from NP-internal case agreement and case stacking (Kracht 1999) challenges the type-raising approach. Agreement phenomena require that case (which can be marked on articles, adjectives, and nouns) be regulated as an agreement feature within the category N before the case-marked argument looks for the verb via type raising. Kracht observes that, in case stacking, there may be other morphemes between two case morphemes. Th</context>
</contexts>
<marker>Bozsahin, 1998</marker>
<rawString>Bozsahin, Cem. 1998. Deriving the Predicate-Argument structure for a free word order language. In Proceedings of COLING-ACL 1998, Montreal, pages 167–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Bozsahin</author>
</authors>
<title>Directionality and the lexicon: Evidence from gapping.</title>
<date>2000</date>
<institution>Middle East Technical University,</institution>
<location>Ankara.</location>
<note>Unpublished manuscript,</note>
<contexts>
<context position="53616" citStr="Bozsahin 2000" startWordPosition="8747" endWordPosition="8748">\ &lt; NPnom\ &lt; NPacc: λx.λy.like xy f f f c. ver (give) := ◦s ver − &lt; v S\ &lt; NPnom\ &lt; NPdat\ &lt; NPacc: λx.λy.λz.giveyxz v f f d. &lt; S\ &lt; NPnom\ &lt; NPacc : λx.λy.like xy ⇒ v f f &lt; S\ &lt; NP+ref acc \ &lt; NPnom : λy.λx.like xy e. -ACC := a◦ i|ı|u|¨u|yi|yı|yu|y¨u − &lt;c Nacc\ &lt;o N: λf .f f. -LOC := ◦a de|da|te|ta − ( &lt;α S/ &lt;α S)\ &lt;o N: λx.λf.at fx Gapping behavior seems to indicate that Turkish is verb final, not just SOV. SO and OS syntactic types must be distinguished to account for SO &amp; SOV, OS &amp; OSV, *SO &amp; OSV and *OS &amp; SOV. The OS &amp; OSV pattern requires the lexical category S\NPacc\NPnom for the verb (Bozsahin 2000b). SOV and OSV base orders can be captured uniquely in the lexicon in set-CCG notation as S\{NPacc,NPnom}. Set-CCG is strongly equivalent to CCG (Baldridge 1999). We distinguish SOV and OSV lexically, however, because OSV requires referential objects (25a–b). OSV is generated from SOV by a lexical rule (24d). This is genuine lexical ambiguity, because the two related entries differ in semantics (referentiality). (25) a. Kitab-ı adam oku-du Book-ACC man.NOM read-TENSE ’The man read the book.’ b. *Kitap adam oku-du Book man.NOM read-TENSE Regarding the relationship between case and the specifie</context>
<context position="57921" citStr="Bozsahin 2000" startWordPosition="9409" endWordPosition="9410">rammar, not necessarily anchored to case. We analyze case as an endotypic functor of type N\N (24e)—hence allow for phrase-internal agreement for languages that require it and provide type raising in grammar as in (27). Abandoning the type-raising analysis of case does not necessitate taking liberties in the directionality of the categories, such as the use of nondirectional slash (|) in multiset-CCG (Hoffman 1995). Contraposition and type raising in grammar 166 Bozsahin The Combinatory Morphemic Lexicon can account for free word order and gapping facts with fully directional syntactic types (Bozsahin 2000a). 6.1.2 Derivations. The wide scope of case is captured by treating its argument type as non-case-marked N (&lt;o N) and the type of noun modifiers as functions onto non-casemarked nouns of a particular domain, for example, &lt; N for nonintersective adjectives and &lt;n N for intersective adjectives (29a). The same strategy in type assignments to other nominal inflections allows them to outscope nominal modification, for example, (29b). (29) a. Mehmet [ [ oyuncak araba ] -lar] -ı sev-er M.NOM toy car -PLU -ACC like-TENSE &lt;B b f &lt; N/ &lt; b N &lt; b N &lt; n N\ &lt; b N &lt; c Nacc\ &lt; o N &lt; t S\ &lt; NPnom b &lt; Nnom f </context>
</contexts>
<marker>Bozsahin, 2000</marker>
<rawString>Bozsahin, Cem. 2000a. Directionality and the lexicon: Evidence from gapping. Unpublished manuscript, Middle East Technical University, Ankara.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Bozsahin</author>
</authors>
<title>Gapping and word order in Turkish.</title>
<date>2000</date>
<booktitle>In Proceedings of the 10th International Conference on Turkish Linguistics,</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="53616" citStr="Bozsahin 2000" startWordPosition="8747" endWordPosition="8748">\ &lt; NPnom\ &lt; NPacc: λx.λy.like xy f f f c. ver (give) := ◦s ver − &lt; v S\ &lt; NPnom\ &lt; NPdat\ &lt; NPacc: λx.λy.λz.giveyxz v f f d. &lt; S\ &lt; NPnom\ &lt; NPacc : λx.λy.like xy ⇒ v f f &lt; S\ &lt; NP+ref acc \ &lt; NPnom : λy.λx.like xy e. -ACC := a◦ i|ı|u|¨u|yi|yı|yu|y¨u − &lt;c Nacc\ &lt;o N: λf .f f. -LOC := ◦a de|da|te|ta − ( &lt;α S/ &lt;α S)\ &lt;o N: λx.λf.at fx Gapping behavior seems to indicate that Turkish is verb final, not just SOV. SO and OS syntactic types must be distinguished to account for SO &amp; SOV, OS &amp; OSV, *SO &amp; OSV and *OS &amp; SOV. The OS &amp; OSV pattern requires the lexical category S\NPacc\NPnom for the verb (Bozsahin 2000b). SOV and OSV base orders can be captured uniquely in the lexicon in set-CCG notation as S\{NPacc,NPnom}. Set-CCG is strongly equivalent to CCG (Baldridge 1999). We distinguish SOV and OSV lexically, however, because OSV requires referential objects (25a–b). OSV is generated from SOV by a lexical rule (24d). This is genuine lexical ambiguity, because the two related entries differ in semantics (referentiality). (25) a. Kitab-ı adam oku-du Book-ACC man.NOM read-TENSE ’The man read the book.’ b. *Kitap adam oku-du Book man.NOM read-TENSE Regarding the relationship between case and the specifie</context>
<context position="57921" citStr="Bozsahin 2000" startWordPosition="9409" endWordPosition="9410">rammar, not necessarily anchored to case. We analyze case as an endotypic functor of type N\N (24e)—hence allow for phrase-internal agreement for languages that require it and provide type raising in grammar as in (27). Abandoning the type-raising analysis of case does not necessitate taking liberties in the directionality of the categories, such as the use of nondirectional slash (|) in multiset-CCG (Hoffman 1995). Contraposition and type raising in grammar 166 Bozsahin The Combinatory Morphemic Lexicon can account for free word order and gapping facts with fully directional syntactic types (Bozsahin 2000a). 6.1.2 Derivations. The wide scope of case is captured by treating its argument type as non-case-marked N (&lt;o N) and the type of noun modifiers as functions onto non-casemarked nouns of a particular domain, for example, &lt; N for nonintersective adjectives and &lt;n N for intersective adjectives (29a). The same strategy in type assignments to other nominal inflections allows them to outscope nominal modification, for example, (29b). (29) a. Mehmet [ [ oyuncak araba ] -lar] -ı sev-er M.NOM toy car -PLU -ACC like-TENSE &lt;B b f &lt; N/ &lt; b N &lt; b N &lt; n N\ &lt; b N &lt; c Nacc\ &lt; o N &lt; t S\ &lt; NPnom b &lt; Nnom f </context>
</contexts>
<marker>Bozsahin, 2000</marker>
<rawString>Bozsahin, Cem. 2000b. Gapping and word order in Turkish. In Proceedings of the 10th International Conference on Turkish Linguistics, Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Bozsahin</author>
<author>Elvan G¨o¸cmen</author>
</authors>
<title>A categorial framework for composition in multiple linguistic domains.</title>
<date>1995</date>
<booktitle>In Proceedings of the 4th International Conference on Cognitive Science of NLP,</booktitle>
<location>Dublin.</location>
<marker>Bozsahin, G¨o¸cmen, 1995</marker>
<rawString>Bozsahin, Cem and Elvan G¨o¸cmen. 1995. A categorial framework for composition in multiple linguistic domains. In Proceedings of the 4th International Conference on Cognitive Science of NLP, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Lexical–Functional syntax. Course notes.</title>
<date>1995</date>
<booktitle>Seventh European Summer School in Logic, Language, and Information,</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="6887" citStr="Bresnan 1995" startWordPosition="1002" endWordPosition="1003">sponds to the surface bracketing [fake truck]-s, because it denotes the nonempty nonsingleton sets of things that are not trucks but fake trucks (Carpenter 1997). Four trucks, on the other hand, has the semantics (four(plu truck)), which corresponds to four [truck]-s, because it denotes the subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, ha</context>
</contexts>
<marker>Bresnan, 1995</marker>
<rawString>Bresnan, Joan. 1995. Lexical–Functional syntax. Course notes. Seventh European Summer School in Logic, Language, and Information, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Calder</author>
<author>Ewan Klein</author>
<author>Henk Zeevat</author>
</authors>
<title>Unification categorial grammar.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics, Budapest,</booktitle>
<pages>83--86</pages>
<marker>Calder, Klein, Zeevat, 1988</marker>
<rawString>Calder, Jonathan, Ewan Klein, and Henk Zeevat. 1988. Unification categorial grammar. In Proceedings of the 12th International Conference on Computational Linguistics, Budapest, pages 83–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Categorial Grammar, lexical rules, and the English predicative. In</title>
<date>1992</date>
<pages>168--242</pages>
<editor>R. Levine, editor, Formal</editor>
<publisher>Oxford University Press,</publisher>
<contexts>
<context position="7662" citStr="Carpenter 1992" startWordPosition="1119" endWordPosition="1120">exicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphe</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Carpenter, Bob. 1992. Categorial Grammar, lexical rules, and the English predicative. In R. Levine, editor, Formal Grammar: Theory and Application. Oxford University Press, pages 168–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Type-Logical Semantics.</title>
<date>1997</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6435" citStr="Carpenter 1997" startWordPosition="933" endWordPosition="934">ver]-di˘g-i ¸cocu˘g-u/*-a g¨or-d¨u-m I.NOM M-GEN book-ACC give-REL.OP child-ACC/*DAT see-TENSE-PERS1 ’I saw the child to whom Mehmet gave the book.’ The morphological/phrasal scope conflict of affixes is not particular to morphologically rich languages. Semantic composition of affixes in morphologically simpler languages poses problems with word (narrow) scope of inflections. For instance, fake trucks needs the semantics (plu(faketruck)), which corresponds to the surface bracketing [fake truck]-s, because it denotes the nonempty nonsingleton sets of things that are not trucks but fake trucks (Carpenter 1997). Four trucks, on the other hand, has the semantics (four(plu truck)), which corresponds to four [truck]-s, because it denotes the subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been deleg</context>
<context position="46367" citStr="Carpenter (1997)" startWordPosition="7559" endWordPosition="7560">ut not only tactical problems (cf. Example (18) and its discussion) but also transparent scoping in syntax and semantics is regulated by the use of lattice in type assignments, and that is our main concern. We show examples of such cases in the remainder of the article. Thus the nonredundant role of the lattice decouples the morphemic grammar– lexicon from the kind of morphological analysis performed in the back end. 5. Case Study: The English Plural In this section, we present a morphosyntactic treatment of the English plural morpheme. The lattice for English is shown in Figure 2b. We follow Carpenter (1997) in categorizing numerical modifiers and intersective adjectives as plural noun modifiers: four boys is interpreted as four(plu boy) and green boxes as green(plu box). This bracketing reflects the “set of sets” interpretation of the plural noun; four(plu boy) denotes the set of nonempty nonsingleton sets of boys with four members. The type assignments in (20) correctly interpret the interaction of the plural and these modifiers (cf. 21a–b). The endotypic category of the plural also allows phrase-internal number agreement for languages that require it; the agreement can be regulated over the ca</context>
<context position="48368" citStr="Carpenter (1997)" startWordPosition="7932" endWordPosition="7933">odification. It denotes a nonempty nonsingleton set of things that are not really guns but toy guns. *toy(plu gun) would interpret plu over guns. The situation is precisely the opposite of (21); we need the second derivational pattern to go through and the first one to fail. The following category for nonintersective adjectives derives the wide scope for -PLU but not the narrow scope: (22) toy := ◦s toy − &lt;b N/ &lt;b N: Ax.toy x (23) a. toy gun -s &lt; N/ b b &lt; N &lt; n N: plu gun *** n &lt; N : *toy(plu gun) because n-num ≤~ n-base b. toy gun -s &lt; N/b b &lt;N &lt;b N &lt;nN\ &lt;bN b &lt; N:toygun n &lt; N : plu(toy gun) Carpenter (1997) avoided rebracketing because of the plural through lexical type assignments to plural nouns and a phonologically null lexical entry to obtain different semantic effects of the plural. In our formulation, there is no lexical entry for inflected forms and no phonologically null type assignment to account for the distinction in different types of plural modification; there is only one (phonologically realized) category for -PLU.17 The modifiers differ only in the kind and degree of morphosyntactic control. Strict control (✶) on four disallows four boy, and flexible control (&lt;) on green also hand</context>
</contexts>
<marker>Carpenter, 1997</marker>
<rawString>Carpenter, Bob. 1997. Type-Logical Semantics. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Turing-completeness of Multimodal Categorial Grammars.</title>
<date>1999</date>
<booktitle>In Papers Presented to Johan van Benthem in Honor of his 50th Birthday. ESSLLI,</booktitle>
<location>Utrecht.</location>
<contexts>
<context position="14493" citStr="Carpenter 1999" startWordPosition="2219" endWordPosition="2220"> for such processes risk nontermination (Sehitoglu and Bozsahin 1999). Our main point of departure from MCG accounts is the morphemic versus lexemic nature of the lexicon: The morphosyntactic and attachment modalities originate from the lexicon; they are not properties of the grammar (we elaborate more on this later). This paves the way to the morphemic lexicon by licensing type assignments to units smaller than words. Besides problems with lexical rules, the automata-theoretic power of MCGs is problematic: Unrestricted use of structural modalities and postulates leads to Turing completeness (Carpenter 1999). Indeed, one of the identifiable fragments of Mul149 Computational Linguistics Volume 28, Number 2 Figure 1 HPSG analysis of (5c). timodal languages that is computationally tractable is Combinatory Categorial languages (Kruijff and Baldridge 2000), which we adopt as the basis for the framework presented here. We propose a morphosyntactic Combinatory Categorial Grammar (CCG) in which the grammar and the morphemic lexicon refer to morphosyntactic types rather than syntactic types. We first introduce the syntactic CCG in Section 2. Morphosyntactic CCG is described in Section 3. In Section 4, we </context>
</contexts>
<marker>Carpenter, 1999</marker>
<rawString>Carpenter, Bob. 1999. The Turing-completeness of Multimodal Categorial Grammars. In Papers Presented to Johan van Benthem in Honor of his 50th Birthday. ESSLLI, Utrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Gerald Penn</author>
</authors>
<title>The Attribute Logic Engine User’s Guide, Version 2.0.</title>
<date>1994</date>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="7388" citStr="Carpenter and Penn 1994" startWordPosition="1077" endWordPosition="1080">to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs</context>
</contexts>
<marker>Carpenter, Penn, 1994</marker>
<rawString>Carpenter, Bob and Gerald Penn. 1994. The Attribute Logic Engine User’s Guide, Version 2.0. Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Remarks on nominalization.</title>
<date>1970</date>
<booktitle>Readings in English Transformational Grammar. Ginn,</booktitle>
<pages>184--221</pages>
<editor>In R. Jacobs and P. Rosenbaum, editors,</editor>
<location>Waltham, MA,</location>
<contexts>
<context position="6750" citStr="Chomsky (1970)" startWordPosition="981" endWordPosition="982">guages poses problems with word (narrow) scope of inflections. For instance, fake trucks needs the semantics (plu(faketruck)), which corresponds to the surface bracketing [fake truck]-s, because it denotes the nonempty nonsingleton sets of things that are not trucks but fake trucks (Carpenter 1997). Four trucks, on the other hand, has the semantics (four(plu truck)), which corresponds to four [truck]-s, because it denotes the subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectiona</context>
</contexts>
<marker>Chomsky, 1970</marker>
<rawString>Chomsky, Noam. 1970. Remarks on nominalization. In R. Jacobs and P. Rosenbaum, editors, Readings in English Transformational Grammar. Ginn, Waltham, MA, pages 184–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>The Minimalist Program.</title>
<date>1995</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7176" citStr="Chomsky 1995" startWordPosition="1048" endWordPosition="1049">e subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of const</context>
</contexts>
<marker>Chomsky, 1995</marker>
<rawString>Chomsky, Noam. 1995. The Minimalist Program. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="35653" citStr="Collins 1997" startWordPosition="5844" endWordPosition="5845">e finite schematization of CCG rules and constant costs incurred by the normal form and lattice checking provide a straightforward extension of CKY-style context-free parsing for CCG. Komagata (1997) claims that the average complexity of CCG parsing is O(n3) even without the finite schematization of type raising (based on the parsing of 22 sentences consisting of around 20 words, with a lexicon of 200 entries and no derivation of semantics in the grammar; a morphological analyzer provided five analyses per second to the parser). Statistical techniques developed for lexicalized grammars (e.g., Collins 1997), readily apply to CCG to improve the average parsing performance in large-scale practical applications (Hockenmaier, Bierner, and Baldridge 2000). Both Collins and Hockenmeier, Bierner, and Baldridge used section 02-21 of the Wall Street Journal Corpus of Penn Treebank for training, which contains 40,886 words (70,151 lexical entries). A recent initiative (Oflazer, et al. 2001) aims to provide such a resource of around one million words for Turkish. It encodes in the Treebank surfacesyntactic relations and the morphological breakdown of words. The latter is invaluable for training morphemic g</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Collins, Michael. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the 35th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chet Creider</author>
<author>Jorge Hankamer</author>
<author>Derick Wood</author>
</authors>
<title>Preset two-head automata and natural language morphology.</title>
<date>1995</date>
<journal>International Journal of Computer Mathematics,</journal>
<pages>58--1</pages>
<marker>Creider, Hankamer, Wood, 1995</marker>
<rawString>Creider, Chet, Jorge Hankamer, and Derick Wood. 1995. Preset two-head automata and natural language morphology. International Journal of Computer Mathematics, 58:1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<title>Feature indeterminacy and feature resolution.</title>
<date>2000</date>
<journal>Language,</journal>
<pages>76--759</pages>
<contexts>
<context position="33844" citStr="Dalrymple and Kaplan 2000" startWordPosition="5559" endWordPosition="5562">Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providing an elaborate agreement system, we note that Pulman’s techniques provide the mechanism for implementing agreement as atomic unification, subsumption hierarchies represented as lattices, or set-valued features. The categorial ingredient of phrase-internal agreement can be provided by endotypic functors when necessary (see Sections 5 and 6). 157 Computational Linguistics Volume 28, Number 2 There is also a switch for checking the PAS equivalence, with the warning that the equivalence of two lambda expressions is undecidable. The parser is an ada</context>
</contexts>
<marker>Dalrymple, Kaplan, 2000</marker>
<rawString>Dalrymple, Mary and Ronald M. Kaplan. 2000. Feature indeterminacy and feature resolution. Language, 76:759–798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Word Meaning and Montague Grammar.</title>
<date>1979</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="7674" citStr="Dowty 1979" startWordPosition="1121" endWordPosition="1122">riven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphe</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>Dowty, David. 1979. Word Meaning and Montague Grammar. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Toward a minimalist theory of syntactic structure.</title>
<date>1991</date>
<booktitle>In Tilburg Conference on Discontinuous Constituency,</booktitle>
<contexts>
<context position="20603" citStr="Dowty (1991)" startWordPosition="3205" endWordPosition="3206">binding asymmetries between subjects and complements in many languages (e.g., *Himself saw John, *heself). (13) 3. Morphosyntactic Types A syntactic type such as N does not discriminate morphosyntactically. A finer distinction can be made as singular nouns, plural nouns, case-marked nouns, etc. For 6 In fact, topicalization of nonperipheral arguments (This book, I would give to Mary) requires that (12) be finitely schematized over valencies, such as S, S/NP, S/PP (Steedman 1985). 7 We will not elaborate on the theoretical consequences of having this level of representation; see, for instance, Dowty (1991) and Steedman (1996). 152 Bozsahin The Combinatory Morphemic Lexicon free (f) (t) (n) n-num s-tense (v) n-base (b) s-base s-base (v) (r) n-relbase n-root (l) s-caus (u) s-reflex (x) s-recip (a) s-person s-modal (m) n-comp (m) n-poss (a) (o) (g) (i) (p) n-num (n) n-case (c) n-base (b) s-tense s-abil s-neg s-imp s-pass (b) (c) free (f) Figure 2 The lattice of diacritics for (a) Turkish and (b) English. instance, the set of number-marked nouns can be represented as n✶N, where ✶ is a morphosyntactic modality (“equals”) and n is a diacritic (for number). Books is of type n✶N, but book is not. The t</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>Dowty, David. 1991. Toward a minimalist theory of syntactic structure. In Tilburg Conference on Discontinuous Constituency, January 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Non-constituent coordination, wrapping, and Multimodal Categorial Grammars.</title>
<date>1996</date>
<booktitle>In International Congress of Logic, Methodology, and Philosophy,</booktitle>
<location>Florence,</location>
<contexts>
<context position="24904" citStr="Dowty (1996)" startWordPosition="3983" endWordPosition="3984">ttachment, and this tradition is followed in MCG; attachment types are related with the slash (e.g., /w for wrapping), which is a grammatical modality.10 In the present framework, however, attachment is projected from the lexicon to the grammar as a prosodic property of the lexical items.11 The grammar is unimodal in the sense that / and \ simply indicate the function-argument distinction in adjacent prosodic elements. The lexical projection of attachment further complements the notion of morphemic lexicon so that bound morphemes are no longer parasitic on words but have an independent 10 See Dowty (1996) and Steedman (1996) for a discussion of bringing nonconcatenative combination into grammar. 11 There is a precedent of associating attachment characteristics with the prosodic element rather than the slash in CG (Hoeksema and Janda 1988). In Hoeksema and Janda’s notation, arguments can be constrained on phonological properties and attachment. For instance, the English article a has its NP/N category spelled out as &lt;/CX/N,NP,Pref&gt;, indicating a consonantal first segment for the noun argument and concatenation to the left. 154 Bozsahin The Combinatory Morphemic Lexicon Table 1 Attachment proper</context>
</contexts>
<marker>Dowty, 1996</marker>
<rawString>Dowty, David. 1996. Non-constituent coordination, wrapping, and Multimodal Categorial Grammars. In International Congress of Logic, Methodology, and Philosophy, Florence, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient normal-form parsing for Combinatory Categorial Grammar.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the ACL,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="33280" citStr="Eisner 1996" startWordPosition="5477" endWordPosition="5478">): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Eisner, Jason. 1996. Efficient normal-form parsing for Combinatory Categorial Grammar. In Proceedings of the 34th Annual Meeting of the ACL, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandiway Fong</author>
</authors>
<title>Computational Properties of Principle-Based Grammatical Theories.</title>
<date>1991</date>
<note>Ph.D. dissertation, MIT.</note>
<contexts>
<context position="7464" citStr="Fong 1991" startWordPosition="1091" endWordPosition="1092">onal Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with </context>
</contexts>
<marker>Fong, 1991</marker>
<rawString>Fong, Sandiway. 1991. Computational Properties of Principle-Based Grammatical Theories. Ph.D. dissertation, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelal G¨ung¨ord¨u</author>
<author>Kemal Oflazer</author>
</authors>
<title>Parsing Turkish using the Lexical-Functional Grammar formalism.</title>
<date>1995</date>
<booktitle>Machine Translation,</booktitle>
<pages>10--293</pages>
<marker>G¨ung¨ord¨u, Oflazer, 1995</marker>
<rawString>G¨ung¨ord¨u, Zelal and Kemal Oflazer. 1995. Parsing Turkish using the Lexical-Functional Grammar formalism. Machine Translation, 10:293–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Hankamer</author>
</authors>
<title>Morphological parsing and the lexicon.</title>
<date>1989</date>
<booktitle>Lexical Representation and Process.</booktitle>
<editor>In W. Marslen-Wilson, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="38266" citStr="Hankamer 1989" startWordPosition="6313" endWordPosition="6314"> categories as functions over free forms. Morphological processing seems inevitable for languages like Turkish, and morphological and lexical ambiguity such as that shown in (19) must be passed on to syntax irrespective of how inflectional morphology is processed (isolated from or integrated with syntax). For the verbal paradigm, Jurafsky and Martin (2000) reports Oflazer’s estimation that inflectional suffixes alone create around 40,000 word forms per root. In the nominal paradigm, iterative processes such as ki-relativization (Section 6.5) can create millions of word forms per nominal root (Hankamer 1989). (19) a. kazma-ları pickaxe-POSS3p ’their pickaxe’ b. kazma-lar-ı pickaxe-PLU-POSS3p ’their pickaxes’ c. kazma-lar-ı pickaxe-PLU-POSS3s ’his/her pickaxes’ d. kaz-ma-ları dig-SUB-AGR ’their digging’ The questions that need to be answered related to processing are (1) What should a (super)linear fragment of processing for morphology deliver to (morpho)syntax? and (2) Is the syntax lexemic or morphemic? The problems with lexemic syntax, which stem from mismatches with semantics, were highlighted in the introduction. In other 159 Computational Linguistics Volume 28, Number 2 root lexicon morpholo</context>
</contexts>
<marker>Hankamer, 1989</marker>
<rawString>Hankamer, Jorge. 1989. Morphological parsing and the lexicon. In W. Marslen-Wilson, editor, Lexical Representation and Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>The Grammar and Processing of Order and Dependency: A Categorial Approach.</title>
<date>1990</date>
<institution>University of Edinburgh.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="12568" citStr="Hepple 1990" startWordPosition="1934" endWordPosition="1935">but linear context free. 148 Bozsahin The Combinatory Morphemic Lexicon assignment for trace introduces phonologically null elements into the lexicon, which, as we show later, is not necessary. (6) a. ver-di˘g-i := � � � � �PERSON thin HEAD AGR [NUMBER sing CAT CASE dat � SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt; LOCAL MOD |MODSYN |LOCAL |CONT |INDEX 1 � � RELNgive GIVER 3 CONTENT � � GIVEE 1 GIFT 2 NONLOCAL |TO-BIND |SLASH { 1 } 1 1 � � � � � � � � � � � � � � � � b. -di˘g-i := � � � CAT f HEAD noun [acc or dat]l LOCAL LSUBCAT &lt;&gt; J CONTENT npro[INDEX 1 ] NONLOCAL |INHER |SLASH { 1 } 1 1 MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different modes of combination in the grammar. In addition to binary modes such as wrapping and commutative operations, unary modalities provide finer control over the categories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyntactic features such as case, number, and person for economy in lexical assignments. For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for case and declension. Underspecification is dealt with in the grammar using inclusion postulates (e.g., (7)). The interaction </context>
<context position="33293" citStr="Hepple 1990" startWordPosition="5479" endWordPosition="5480">nalyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providi</context>
</contexts>
<marker>Hepple, 1990</marker>
<rawString>Hepple, Mark. 1990a. The Grammar and Processing of Order and Dependency: A Categorial Approach. Ph.D. dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>Normal form theorem proving for the Lambek Calculus.</title>
<date>1990</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="12568" citStr="Hepple 1990" startWordPosition="1934" endWordPosition="1935">but linear context free. 148 Bozsahin The Combinatory Morphemic Lexicon assignment for trace introduces phonologically null elements into the lexicon, which, as we show later, is not necessary. (6) a. ver-di˘g-i := � � � � �PERSON thin HEAD AGR [NUMBER sing CAT CASE dat � SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt; LOCAL MOD |MODSYN |LOCAL |CONT |INDEX 1 � � RELNgive GIVER 3 CONTENT � � GIVEE 1 GIFT 2 NONLOCAL |TO-BIND |SLASH { 1 } 1 1 � � � � � � � � � � � � � � � � b. -di˘g-i := � � � CAT f HEAD noun [acc or dat]l LOCAL LSUBCAT &lt;&gt; J CONTENT npro[INDEX 1 ] NONLOCAL |INHER |SLASH { 1 } 1 1 MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different modes of combination in the grammar. In addition to binary modes such as wrapping and commutative operations, unary modalities provide finer control over the categories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyntactic features such as case, number, and person for economy in lexical assignments. For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for case and declension. Underspecification is dealt with in the grammar using inclusion postulates (e.g., (7)). The interaction </context>
<context position="33293" citStr="Hepple 1990" startWordPosition="5479" endWordPosition="5480">nalyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providi</context>
</contexts>
<marker>Hepple, 1990</marker>
<rawString>Hepple, Mark. 1990b. Normal form theorem proving for the Lambek Calculus. In Proceedings of COLING 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
<author>Glyn Morrill</author>
</authors>
<title>Parsing and derivational equivalence.</title>
<date>1989</date>
<booktitle>In Proceedings of the 4th EACL,</booktitle>
<location>Manchester.</location>
<contexts>
<context position="33319" citStr="Hepple and Morrill 1989" startWordPosition="5481" endWordPosition="5484">antically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providing an elaborate agreement </context>
</contexts>
<marker>Hepple, Morrill, 1989</marker>
<rawString>Hepple, Mark and Glyn Morrill. 1989. Parsing and derivational equivalence. In Proceedings of the 4th EACL, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Heylen</author>
</authors>
<title>Underspecification in Type-Logical Grammars.</title>
<date>1997</date>
<booktitle>In Logical Aspects of Computational Linguistics (LACL),</booktitle>
<location>Nancy.</location>
<contexts>
<context position="7687" citStr="Heylen 1997" startWordPosition="1123" endWordPosition="1124">Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. </context>
<context position="12809" citStr="Heylen (1997" startWordPosition="1970" endWordPosition="1971"> AGR [NUMBER sing CAT CASE dat � SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt; LOCAL MOD |MODSYN |LOCAL |CONT |INDEX 1 � � RELNgive GIVER 3 CONTENT � � GIVEE 1 GIFT 2 NONLOCAL |TO-BIND |SLASH { 1 } 1 1 � � � � � � � � � � � � � � � � b. -di˘g-i := � � � CAT f HEAD noun [acc or dat]l LOCAL LSUBCAT &lt;&gt; J CONTENT npro[INDEX 1 ] NONLOCAL |INHER |SLASH { 1 } 1 1 MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different modes of combination in the grammar. In addition to binary modes such as wrapping and commutative operations, unary modalities provide finer control over the categories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyntactic features such as case, number, and person for economy in lexical assignments. For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for case and declension. Underspecification is dealt with in the grammar using inclusion postulates (e.g., (7)). The interaction of different modalities is regulated by distribution postulates. (7) ✷caser F_ X ✷caser F_ X ✷nomr F_ X ✷accr F_ X Lexical assignments to inflected words carry unary modalities: boys has the type ✷plN, in contrast to ✷sgN for boy. Although s</context>
<context position="22550" citStr="Heylen (1997)" startWordPosition="3562" endWordPosition="3563">ty is more strict than &lt; to provide finer control; although υ( &lt;n N) C υ(&lt;c N), υ(n ✶ N) Cz υ(c✶ N), because a noun can be number marked but not case marked or vice versa. Also, υ( ✶i N) C υ(&lt;i N) for any diacritic i since, for instance, the set of nouns marked up to and including case includes case-marked, number-marked, and unmarked nouns. The lattice consistency condition is imposed on the set of diacritics to ensure category unity.9 In other words, the syntactic type X can be viewed as an abbreviation T for the morphosyntactic type &lt; X where T is the universal upper bound. It is the 8 See Heylen (1997) on use of unary modalities for a similar purpose in lexemic MCG. 9 In a lattice L, x ≤ y (morphosyntactically, x &lt; y) is equivalent to the consistency properties x ∧ y = x and x ∨ y = y. We use the join operator for this check, thus it suffices to have a join semilattice. 153 Computational Linguistics Volume 28, Number 2 most underspecified category of X which subsumes all morphosyntactically decorated versions of X. Figure 2 shows the lattice for English and Turkish. Definition (Morphosyntactic Types) • D = finite set of diacritics • Join semilattice L = (D, &lt;, =) • The set of basic morphosy</context>
</contexts>
<marker>Heylen, 1997</marker>
<rawString>Heylen, Dirk. 1997. Underspecification in Type-Logical Grammars. In Logical Aspects of Computational Linguistics (LACL), Nancy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Heylen</author>
</authors>
<title>Types and Sorts: Resource Logic for Feature Checking.</title>
<date>1999</date>
<institution>Utrecht University.</institution>
<note>Ph.D. dissertation,</note>
<marker>Heylen, 1999</marker>
<rawString>Heylen, Dirk. 1999. Types and Sorts: Resource Logic for Feature Checking. Ph.D. dissertation, Utrecht University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Gann Bierner</author>
<author>Jason Baldridge</author>
</authors>
<title>Providing robustness for a CCG system.</title>
<date>2000</date>
<institution>University of Edinburgh.</institution>
<note>Unpublished manuscript,</note>
<marker>Hockenmaier, Bierner, Baldridge, 2000</marker>
<rawString>Hockenmaier, Julia, Gann Bierner, and Jason Baldridge. 2000. Providing robustness for a CCG system. Unpublished manuscript, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Hoeksema</author>
</authors>
<title>Categorial Morphology.</title>
<date>1985</date>
<publisher>Garland,</publisher>
<location>New York.</location>
<contexts>
<context position="7702" citStr="Hoeksema 1985" startWordPosition="1125" endWordPosition="1126">mmar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. A lexemic PSG p</context>
</contexts>
<marker>Hoeksema, 1985</marker>
<rawString>Hoeksema, Jack. 1985. Categorial Morphology. Garland, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Hoeksema</author>
<author>Richard D Janda</author>
</authors>
<title>Implications of process-morphology for Categorial Grammar.</title>
<date>1988</date>
<booktitle>Categorial Grammars and Natural Language Structures.</booktitle>
<pages>199--247</pages>
<editor>In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors,</editor>
<location>Dordrecht,</location>
<contexts>
<context position="25142" citStr="Hoeksema and Janda 1988" startWordPosition="4016" endWordPosition="4019">con to the grammar as a prosodic property of the lexical items.11 The grammar is unimodal in the sense that / and \ simply indicate the function-argument distinction in adjacent prosodic elements. The lexical projection of attachment further complements the notion of morphemic lexicon so that bound morphemes are no longer parasitic on words but have an independent 10 See Dowty (1996) and Steedman (1996) for a discussion of bringing nonconcatenative combination into grammar. 11 There is a precedent of associating attachment characteristics with the prosodic element rather than the slash in CG (Hoeksema and Janda 1988). In Hoeksema and Janda’s notation, arguments can be constrained on phonological properties and attachment. For instance, the English article a has its NP/N category spelled out as &lt;/CX/N,NP,Pref&gt;, indicating a consonantal first segment for the noun argument and concatenation to the left. 154 Bozsahin The Combinatory Morphemic Lexicon Table 1 Attachment properties of some Turkish morphemes. uzun (long) := o uzun − &lt; N/ &lt; N uzun yol long road ’long road’ s v f f oku (read) := ◦oku − � S\ � NPnom\ � NPacc adam kitab-ı oku-du man book-ACC read-TENSE ’the man read the book.’ -EMPH := ◦c de − X\X B</context>
</contexts>
<marker>Hoeksema, Janda, 1988</marker>
<rawString>Hoeksema, Jack and Richard D. Janda. 1988. Implications of process-morphology for Categorial Grammar. In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors, Categorial Grammars and Natural Language Structures. D. Reidel, Dordrecht, pages 199–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beryl Hoffman</author>
</authors>
<title>The Computational Analysis of the Syntax and Interpretation of “Free” Word Order in Turkish.</title>
<date>1995</date>
<institution>University of Pennsylvania.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="57726" citStr="Hoffman 1995" startWordPosition="9381" endWordPosition="9382">hat is, it is endotypic. Hence, an endotypic category for case (like other inflections in the paradigm) subsumes the type-raising analysis of case provided that type raising is available in the grammar, not necessarily anchored to case. We analyze case as an endotypic functor of type N\N (24e)—hence allow for phrase-internal agreement for languages that require it and provide type raising in grammar as in (27). Abandoning the type-raising analysis of case does not necessitate taking liberties in the directionality of the categories, such as the use of nondirectional slash (|) in multiset-CCG (Hoffman 1995). Contraposition and type raising in grammar 166 Bozsahin The Combinatory Morphemic Lexicon can account for free word order and gapping facts with fully directional syntactic types (Bozsahin 2000a). 6.1.2 Derivations. The wide scope of case is captured by treating its argument type as non-case-marked N (&lt;o N) and the type of noun modifiers as functions onto non-casemarked nouns of a particular domain, for example, &lt; N for nonintersective adjectives and &lt;n N for intersective adjectives (29a). The same strategy in type assignments to other nominal inflections allows them to outscope nominal modi</context>
</contexts>
<marker>Hoffman, 1995</marker>
<rawString>Hoffman, Beryl. 1995. The Computational Analysis of the Syntax and Interpretation of “Free” Word Order in Turkish. Ph.D. dissertation, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The Architecture of the Language Faculty.</title>
<date>1997</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3911" citStr="Jackendoff 1997" startWordPosition="568" endWordPosition="569">one into effect, but it had not been enforced properly.’ b. y¨ur¨url¨u ˘ge girmi¸s-ti ama tam anlamayla uygulanamama¸s-ta c. Adam-an [araba ve ev]-i man-GEN car and house-POSS ’the man’s house and car’ d. Araba-ya [adam ve ¸cocuk]-lar-a g¨oster-di-m Car-ACC man and child-PLU-DAT show-TENSE-PERS1 ’(I) showed the car to the men and the children.’ e. Araba-ya sen-in [dost ve tanadak]-lar-an-a g¨oster-di-m Car-ACC you-GEN friend and acq.-PLU-POSS-DAT showed ’(I) showed the car to the your friends and acquaintances.’ 1 Our use of the term morphosyntax needs some clarification. Some authors, (e.g., Jackendoff 1997), take it to mean the syntax of words, in contrast to the syntax of phrases. By morphosyntax we mean those aspects of morphology and syntax that collectively contribute to grammatical meaning composition. This is more in line with the inflectional-morphology-is-syntax view. In this respect, we will not address problems related to derivational morphology; its semantics is notoriously noncompositional and does not interact with grammatical meaning. Moreover, without a semantically powerful lexicon such as Pustejovsky’s (1991), even the most productive fragment of derivational morphology is hard </context>
<context position="86877" citStr="Jackendoff 1997" startWordPosition="14106" endWordPosition="14107">st rate’ f.kredi kart-a yallak faiz oran-a g.*kredi kart-a faiz yallak oran-a annual ’credit card annual interest rate’ 7. Conclusion Theoretical and computational commitment to word-based grammar—and to regard inflectional morphology as a word-internal process—puts artificial limits on specifying the syntactic and semantic domains of all meaning-bearing elements and on the transparent projection of scope from the lexicon. Designating words as minimal units of the lexicon is too constraining for many languages. This traditional notion is also challenged in current linguistic theorizing (e.g., Jackendoff 1997 and Keenan and Stabler 1997). Marslen-Wilson (1999) argues on psycholinguistic grounds that the lexicon must be morphemic even for morphologically simpler languages such as English. We have argued in this article that the key to the integration of inflectional morphology and syntax is granting representational status to morphemes, which, in a computational system, requires certain precautions. What we propose is enriching the expressive power of the combinatory morphemic lexicon to factor in morphosyntactic types and attachment modalities. Coupled with flexible constituency in the grammar and</context>
</contexts>
<marker>Jackendoff, 1997</marker>
<rawString>Jackendoff, Ray. 1997. The Architecture of the Language Faculty. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pauline Jacobson</author>
</authors>
<title>The syntax/ semantics interface in Categorial Grammar.</title>
<date>1996</date>
<booktitle>The Handbook of Contemporary Semantic Theory.</booktitle>
<pages>89--116</pages>
<editor>In Shalom Lappin, editor,</editor>
<publisher>Blackwell,</publisher>
<contexts>
<context position="15483" citStr="Jacobson 1996" startWordPosition="2369" endWordPosition="2370">) in which the grammar and the morphemic lexicon refer to morphosyntactic types rather than syntactic types. We first introduce the syntactic CCG in Section 2. Morphosyntactic CCG is described in Section 3. In Section 4, we look at the computational aspects of the framework. We then show its realization for some aspects of English (Section 5) and Turkish (Section 6). 150 Bozsahin The Combinatory Morphemic Lexicon 2. Syntactic Types CG is a theory of grammar in which the form-meaning relation is conceived as a transparent correspondence between the surface-syntactic and semantic combinatorics (Jacobson 1996). A CCG sign can be represented as a triplet π − σ: µ, where π is the prosodic element, σ is its syntactic type, and µ its semantic type. For instance, the lexical assignment for read is (8).3 (8) read := read − (S\NP)/NP: λx.λy.read xy Definition (Syntactic Types) • The set of basic syntactic categories: As = {N,NP,S,S−t,S+t} • The set of complex syntactic categories: Bs — As C Bs — If X E Bs and Y E Bs, thenX\Y and X/Y E Bs The classical Ajdukiewicz/Bar-Hillel (AB) CG is weakly equivalent to ContextFree Grammars (Bar-Hillel, Gaifman, and Shamir 1960). It has function application rules, defin</context>
</contexts>
<marker>Jacobson, 1996</marker>
<rawString>Jacobson, Pauline. 1996. The syntax/ semantics interface in Categorial Grammar. In Shalom Lappin, editor, The Handbook of Contemporary Semantic Theory. Blackwell, 89–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Janeway</author>
</authors>
<title>Unacceptable ambiguity in Categorial Grammar.</title>
<date>1990</date>
<booktitle>In Proceedings of the Ninth West Coast Conference on Formal Linguistics,</booktitle>
<pages>305--316</pages>
<contexts>
<context position="52611" citStr="Janeway (1990)" startWordPosition="8552" endWordPosition="8553">c–focus distinctions. The mapping of surface functions to grammatical relations is mediated by case marking. Word order variation has lesser functionality in embedded clauses because embedded arguments are less accessible to surface discourse functions like topic and focus. Embedded clauses are verb final. 6.1.1 Lexical Types. We start with the lexical type assignments for the verbs. We use the abbreviations in (24a) when no confusion arises about the arguments’ case or morphosyntactic type. Verb-final orders are regarded as basic, which suggests the category S\NP\NP for transitive verbs. But Janeway (1990) argued that such underspecification for verb-peripheral languages causes undesirable ambiguity. Grammatical relations of 164 Bozsahin The Combinatory Morphemic Lexicon the arguments are determined not by directionality but by case in such languages. The category S\NPnom\NPacc resolves the ambiguity (24b–c). (24) a. IV = S\NP TV = S\NP\NP DV = S\NP\NP\NP f f b. sev (like) := ◦s sev − &lt; v S\ &lt; NPnom\ &lt; NPacc: λx.λy.like xy f f f c. ver (give) := ◦s ver − &lt; v S\ &lt; NPnom\ &lt; NPdat\ &lt; NPacc: λx.λy.λz.giveyxz v f f d. &lt; S\ &lt; NPnom\ &lt; NPacc : λx.λy.like xy ⇒ v f f &lt; S\ &lt; NP+ref acc \ &lt; NPnom : λy.λx.</context>
</contexts>
<marker>Janeway, 1990</marker>
<rawString>Janeway, Roger. 1990. Unacceptable ambiguity in Categorial Grammar. In Proceedings of the Ninth West Coast Conference on Formal Linguistics, pages 305–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Deductive parsing with multiple levels of representation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the ACL,</booktitle>
<pages>241--248</pages>
<contexts>
<context position="7452" citStr="Johnson 1988" startWordPosition="1089" endWordPosition="1090">Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax woul</context>
</contexts>
<marker>Johnson, 1988</marker>
<rawString>Johnson, Mark. 1988. Deductive parsing with multiple levels of representation. In Proceedings of the 26th Annual Meeting of the ACL, pages 241–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Sam Bayer</author>
</authors>
<title>Features and agreement in Lambek Categorial Grammar.</title>
<date>1995</date>
<booktitle>In Proceedings of the 1995 ESSLLI Formal Grammar Workshop,</booktitle>
<pages>123--137</pages>
<contexts>
<context position="33817" citStr="Johnson and Bayer 1995" startWordPosition="5555" endWordPosition="5558">positions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providing an elaborate agreement system, we note that Pulman’s techniques provide the mechanism for implementing agreement as atomic unification, subsumption hierarchies represented as lattices, or set-valued features. The categorial ingredient of phrase-internal agreement can be provided by endotypic functors when necessary (see Sections 5 and 6). 157 Computational Linguistics Volume 28, Number 2 There is also a switch for checking the PAS equivalence, with the warning that the equivalence of two lambda expressions is undeci</context>
</contexts>
<marker>Johnson, Bayer, 1995</marker>
<rawString>Johnson, Mark and Sam Bayer. 1995. Features and agreement in Lambek Categorial Grammar. In Proceedings of the 1995 ESSLLI Formal Grammar Workshop, pages 123–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="38010" citStr="Jurafsky and Martin (2000)" startWordPosition="6274" endWordPosition="6277">with only T and the relation &lt; would undo all the effects of parameterization; it would be equivalent to a syntactic grammar in which every basic T category X stands for &lt; X. To enforce a completely lexemic syntax, a lattice with T and free would define all functional categories as functions over free forms. Morphological processing seems inevitable for languages like Turkish, and morphological and lexical ambiguity such as that shown in (19) must be passed on to syntax irrespective of how inflectional morphology is processed (isolated from or integrated with syntax). For the verbal paradigm, Jurafsky and Martin (2000) reports Oflazer’s estimation that inflectional suffixes alone create around 40,000 word forms per root. In the nominal paradigm, iterative processes such as ki-relativization (Section 6.5) can create millions of word forms per nominal root (Hankamer 1989). (19) a. kazma-ları pickaxe-POSS3p ’their pickaxe’ b. kazma-lar-ı pickaxe-PLU-POSS3p ’their pickaxes’ c. kazma-lar-ı pickaxe-PLU-POSS3s ’his/her pickaxes’ d. kaz-ma-ları dig-SUB-AGR ’their digging’ The questions that need to be answered related to processing are (1) What should a (super)linear fragment of processing for morphology deliver to</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel and James H. Martin. 2000. Speech and Language Processing. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Radical lexicalism.</title>
<date>1989</date>
<booktitle>In Mark Baltin and Anthony Kroch, editors, Alternative Conceptions of Phrase Structure.</booktitle>
<pages>43--65</pages>
<publisher>University of Chicago Press,</publisher>
<contexts>
<context position="7718" citStr="Karttunen 1989" startWordPosition="1127" endWordPosition="1128">llard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. A lexemic PSG provides a lexica</context>
<context position="33113" citStr="Karttunen 1989" startWordPosition="5453" endWordPosition="5454"> lattice condition as in (15) incurs a constant factor with a finite lattice. Type raising and composition cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, </context>
</contexts>
<marker>Karttunen, 1989</marker>
<rawString>Karttunen, Lauri. 1989. Radical lexicalism. In Mark Baltin and Anthony Kroch, editors, Alternative Conceptions of Phrase Structure. University of Chicago Press, pages 43–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward L Keenan</author>
<author>Edward Stabler</author>
</authors>
<title>Bare grammar. Course notes,</title>
<date>1997</date>
<booktitle>Ninth European Summer School on Logic, Language, and Information,</booktitle>
<location>Aix-en-Provence.</location>
<contexts>
<context position="86906" citStr="Keenan and Stabler 1997" startWordPosition="14109" endWordPosition="14113">t-a yallak faiz oran-a g.*kredi kart-a faiz yallak oran-a annual ’credit card annual interest rate’ 7. Conclusion Theoretical and computational commitment to word-based grammar—and to regard inflectional morphology as a word-internal process—puts artificial limits on specifying the syntactic and semantic domains of all meaning-bearing elements and on the transparent projection of scope from the lexicon. Designating words as minimal units of the lexicon is too constraining for many languages. This traditional notion is also challenged in current linguistic theorizing (e.g., Jackendoff 1997 and Keenan and Stabler 1997). Marslen-Wilson (1999) argues on psycholinguistic grounds that the lexicon must be morphemic even for morphologically simpler languages such as English. We have argued in this article that the key to the integration of inflectional morphology and syntax is granting representational status to morphemes, which, in a computational system, requires certain precautions. What we propose is enriching the expressive power of the combinatory morphemic lexicon to factor in morphosyntactic types and attachment modalities. Coupled with flexible constituency in the grammar and directionality information c</context>
</contexts>
<marker>Keenan, Stabler, 1997</marker>
<rawString>Keenan, Edward L. and Edward Stabler. 1997. Bare grammar. Course notes, Ninth European Summer School on Logic, Language, and Information, Aix-en-Provence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobo Komagata</author>
</authors>
<title>Efficient parsing for CCGs with generalized type-raised categories.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Int. Workshop on Parsing Technologies,</booktitle>
<pages>135--146</pages>
<contexts>
<context position="33129" citStr="Komagata 1997" startWordPosition="5455" endWordPosition="5456">on as in (15) incurs a constant factor with a finite lattice. Type raising and composition cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of ag</context>
<context position="35239" citStr="Komagata (1997)" startWordPosition="5780" endWordPosition="5781">tituents of length k, the unary rules apply to the CKY table entries T[αi, αi+k ], i = 0,1, ... , n − k; that is, k-length results of binary rules are input to potential unary constituents of length k. In practice, this allows, for instance, a nominalized clause to be type-raised after it is derived as a category of type N. The remaining combinatory schema is already in Chomsky Normal Form, as required by CKY. The finite schematization of CCG rules and constant costs incurred by the normal form and lattice checking provide a straightforward extension of CKY-style context-free parsing for CCG. Komagata (1997) claims that the average complexity of CCG parsing is O(n3) even without the finite schematization of type raising (based on the parsing of 22 sentences consisting of around 20 words, with a lexicon of 200 entries and no derivation of semantics in the grammar; a morphological analyzer provided five analyses per second to the parser). Statistical techniques developed for lexicalized grammars (e.g., Collins 1997), readily apply to CCG to improve the average parsing performance in large-scale practical applications (Hockenmaier, Bierner, and Baldridge 2000). Both Collins and Hockenmeier, Bierner,</context>
</contexts>
<marker>Komagata, 1997</marker>
<rawString>Komagata, Nobo. 1997. Efficient parsing for CCGs with generalized type-raised categories. In Proceedings of the Fifth Int. Workshop on Parsing Technologies, pages 135–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther K¨onig</author>
</authors>
<title>Parsing as natural deduction.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting of the ACL,</booktitle>
<pages>272--279</pages>
<marker>K¨onig, 1989</marker>
<rawString>K¨onig, Esther. 1989. Parsing as natural deduction. In Proceedings of the 27th Annual Meeting of the ACL, pages 272–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Kracht</author>
</authors>
<title>Referent systems, argument structure, and syntax. ESSLLI lecture notes,</title>
<date>1999</date>
<location>Utrecht.</location>
<contexts>
<context position="56532" citStr="Kracht 1999" startWordPosition="9197" endWordPosition="9198">C read-TENSE Nnom Nacc Nnom Nacc S\NPnom\NPacc &gt;T &gt;T S/(S\NPnom) (S\NP) /(S\NP\NPacc) ... &gt;B &gt;B S/(S\NPnom\NPacc) S/(S\NPnom\NPacc) &amp; S/(S\NPnom\NPacc) &gt; S ’Mehmet read the little green book, and the child, the newly arrived magazine’. Our lexical type assignment to case morphemes (24e–f) departs from other CCG analyses of case (e.g., Steedman 1985, 1991a, Bozsahin 1998). These studies correlate morphological case with type raising of arguments, in the case of Bozsahin (1998), via a value-raised category assignment to case morphemes. Evidence from NP-internal case agreement and case stacking (Kracht 1999) challenges the type-raising approach. Agreement phenomena require that case (which can be marked on articles, adjectives, and nouns) be regulated as an agreement feature within the category N before the case-marked argument looks for the verb via type raising. Kracht observes that, in case stacking, there may be other morphemes between two case morphemes. Thus, treating the two cases as composite affixes for the purpose of type raising is not feasible. If the first case type-raises the noun to say, T/(T\NP), the second case would require a category, (T/(T\NP))\(T/(T\NP)); that is, it is endot</context>
</contexts>
<marker>Kracht, 1999</marker>
<rawString>Kracht, Markus. 1999. Referent systems, argument structure, and syntax. ESSLLI lecture notes, Utrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan M Kruijff</author>
<author>Jason M Baldridge</author>
</authors>
<title>Relating categorial type logics and CCG through simulation.</title>
<date>2000</date>
<institution>University of Edinburgh.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="14741" citStr="Kruijff and Baldridge 2000" startWordPosition="2253" endWordPosition="2256"> lexicon; they are not properties of the grammar (we elaborate more on this later). This paves the way to the morphemic lexicon by licensing type assignments to units smaller than words. Besides problems with lexical rules, the automata-theoretic power of MCGs is problematic: Unrestricted use of structural modalities and postulates leads to Turing completeness (Carpenter 1999). Indeed, one of the identifiable fragments of Mul149 Computational Linguistics Volume 28, Number 2 Figure 1 HPSG analysis of (5c). timodal languages that is computationally tractable is Combinatory Categorial languages (Kruijff and Baldridge 2000), which we adopt as the basis for the framework presented here. We propose a morphosyntactic Combinatory Categorial Grammar (CCG) in which the grammar and the morphemic lexicon refer to morphosyntactic types rather than syntactic types. We first introduce the syntactic CCG in Section 2. Morphosyntactic CCG is described in Section 3. In Section 4, we look at the computational aspects of the framework. We then show its realization for some aspects of English (Section 5) and Turkish (Section 6). 150 Bozsahin The Combinatory Morphemic Lexicon 2. Syntactic Types CG is a theory of grammar in which t</context>
</contexts>
<marker>Kruijff, Baldridge, 2000</marker>
<rawString>Kruijff, Geert-Jan M. and Jason M. Baldridge. 2000. Relating categorial type logics and CCG through simulation. Unpublished manuscript, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>The mathematics of sentence structure.</title>
<date>1958</date>
<pages>65--154</pages>
<publisher>American Mathematical Monthly,</publisher>
<marker>Lambek, 1958</marker>
<rawString>Lambek, Joachim. 1958. The mathematics of sentence structure. American Mathematical Monthly, 65:154–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Marslen-Wilson</author>
</authors>
<title>Abstractness and combination: The morphemic lexicon.</title>
<date>1999</date>
<pages>101--119</pages>
<editor>In Simon Garrod and Martin J. Pickering, editors, Language Processing.</editor>
<publisher>Psychology Press,</publisher>
<location>East Sussex, UK,</location>
<contexts>
<context position="86929" citStr="Marslen-Wilson (1999)" startWordPosition="14114" endWordPosition="14115">kredi kart-a faiz yallak oran-a annual ’credit card annual interest rate’ 7. Conclusion Theoretical and computational commitment to word-based grammar—and to regard inflectional morphology as a word-internal process—puts artificial limits on specifying the syntactic and semantic domains of all meaning-bearing elements and on the transparent projection of scope from the lexicon. Designating words as minimal units of the lexicon is too constraining for many languages. This traditional notion is also challenged in current linguistic theorizing (e.g., Jackendoff 1997 and Keenan and Stabler 1997). Marslen-Wilson (1999) argues on psycholinguistic grounds that the lexicon must be morphemic even for morphologically simpler languages such as English. We have argued in this article that the key to the integration of inflectional morphology and syntax is granting representational status to morphemes, which, in a computational system, requires certain precautions. What we propose is enriching the expressive power of the combinatory morphemic lexicon to factor in morphosyntactic types and attachment modalities. Coupled with flexible constituency in the grammar and directionality information coming from the lexicon,</context>
</contexts>
<marker>Marslen-Wilson, 1999</marker>
<rawString>Marslen-Wilson, William. 1999. Abstractness and combination: The morphemic lexicon. In Simon Garrod and Martin J. Pickering, editors, Language Processing. Psychology Press, East Sussex, UK, pages 101–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip H Miller</author>
<author>Ivan A Sag</author>
</authors>
<title>French clitic movement without clitics or movement. Natural Language and Linguistic Theory,</title>
<date>1997</date>
<pages>15--573</pages>
<contexts>
<context position="10643" citStr="Miller and Sag 1997" startWordPosition="1587" endWordPosition="1590">ncy, such as SO (subject-object) in the SVO &amp; SO gapping pattern of English and SV (subject-verb) constituency in the OSV &amp; SV pattern of Turkish. Nontraditional constituents are also needed in specifying semantically transparent constituency of words, affixes, clitics, and phrases. Constraint-based PSGs such as HPSG appeal to coindexation and feature passing via unification, rather than movement, to deal with such processes. HPSG also makes the commitment that inflectional morphology is internal to the lexicon, handled either by lexical rules (Pollard and Sag 1994) or by lexical inheritance (Miller and Sag 1997). We look at (5c) to highlight a problem with the stem-and-inflections view. As words enter syntax fully inflected, the sign of the verb ver-di˘g-i in the relative clause (5c) would be as in (6a), in which the SUBCAT list of the verb stem is, as specified in the lexical entry for ver, unsaturated. The participle adds coindexation in MODJ · · · JINDEX. The HPSG analysis of this example would be as in Figure 1. Although passing the agreement features of the head separately (Sehitoglu 1996) solves the case problem alluded to in (5c), however, structure sharing of the NPdat with the SLASH, INDEX, </context>
</contexts>
<marker>Miller, Sag, 1997</marker>
<rawString>Miller, Philip H. and Ivan A. Sag. 1997. French clitic movement without clitics or movement. Natural Language and Linguistic Theory, 15:573–639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus. Foris,</title>
<date>1988</date>
<location>Dordrecht.</location>
<contexts>
<context position="7733" citStr="Moortgat 1988" startWordPosition="1129" endWordPosition="1130">94, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. A lexemic PSG provides a lexical interface for</context>
<context position="18529" citStr="Moortgat 1988" startWordPosition="2888" endWordPosition="2889"> a variable. 151 Computational Linguistics Volume 28, Number 2 looking for a VP (= S\NP) to the right to become S. The reversal of directionality such as topicalization (e.g., This book, I recommend) requires another schema. The reversal is with respect to the position of the verb, which we shall call contraposition and formulate as in (12).6 (&lt;XP) is leftward extraction of a right constituent, and (&gt;XP) is rightward extraction of a left constituent, both of which are marked constructions. Directionally insensitive types such as T|(T|X) cause the collapse of directionality in surface grammar (Moortgat 1988a). (12) Leftward Contraposition (&lt;XP): X: a S+t/(S/X): λf .f [a] S+t/(S+t/X): λf.f [a] Rightward Contraposition (&gt;XP): X: a S−t\(S\X): λf .f [a] S−t\(S−t\X): λf.f [a] The semantics of contraposition depends on discourse properties as well. We leave this issue aside by (1) noting that it is related to type raising in changing the functionargument relation and (2) categorizing the sentence as S+t (topicalized) or S−t (detopicalized), which are not discourse equivalent to S. Syntactic characterization as such also helps a discourse component do its work on syntactic derivations. CCG’s notion of </context>
</contexts>
<marker>Moortgat, 1988</marker>
<rawString>Moortgat, Michael. 1988a. Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus. Foris, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Mixed composition and discontinuous dependencies.</title>
<date>1988</date>
<booktitle>Categorial Grammars and Natural Language Structures.</booktitle>
<pages>319--348</pages>
<editor>In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors,</editor>
<location>Dordrecht,</location>
<contexts>
<context position="7733" citStr="Moortgat 1988" startWordPosition="1129" endWordPosition="1130">94, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. A lexemic PSG provides a lexical interface for</context>
<context position="18529" citStr="Moortgat 1988" startWordPosition="2888" endWordPosition="2889"> a variable. 151 Computational Linguistics Volume 28, Number 2 looking for a VP (= S\NP) to the right to become S. The reversal of directionality such as topicalization (e.g., This book, I recommend) requires another schema. The reversal is with respect to the position of the verb, which we shall call contraposition and formulate as in (12).6 (&lt;XP) is leftward extraction of a right constituent, and (&gt;XP) is rightward extraction of a left constituent, both of which are marked constructions. Directionally insensitive types such as T|(T|X) cause the collapse of directionality in surface grammar (Moortgat 1988a). (12) Leftward Contraposition (&lt;XP): X: a S+t/(S/X): λf .f [a] S+t/(S+t/X): λf.f [a] Rightward Contraposition (&gt;XP): X: a S−t\(S\X): λf .f [a] S−t\(S−t\X): λf.f [a] The semantics of contraposition depends on discourse properties as well. We leave this issue aside by (1) noting that it is related to type raising in changing the functionargument relation and (2) categorizing the sentence as S+t (topicalized) or S−t (detopicalized), which are not discourse equivalent to S. Syntactic characterization as such also helps a discourse component do its work on syntactic derivations. CCG’s notion of </context>
</contexts>
<marker>Moortgat, 1988</marker>
<rawString>Moortgat, Michael. 1988b. Mixed composition and discontinuous dependencies. In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors, Categorial Grammars and Natural Language Structures. D. Reidel, Dordrecht, pages 319–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
<author>Richard T Oehrle</author>
</authors>
<title>Adjacency, dependency and order.</title>
<date>1994</date>
<booktitle>In Proceedings of the Ninth</booktitle>
<location>Amsterdam Colloquium.</location>
<contexts>
<context position="12610" citStr="Moortgat and Oehrle 1994" startWordPosition="1938" endWordPosition="1941"> Bozsahin The Combinatory Morphemic Lexicon assignment for trace introduces phonologically null elements into the lexicon, which, as we show later, is not necessary. (6) a. ver-di˘g-i := � � � � �PERSON thin HEAD AGR [NUMBER sing CAT CASE dat � SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt; LOCAL MOD |MODSYN |LOCAL |CONT |INDEX 1 � � RELNgive GIVER 3 CONTENT � � GIVEE 1 GIFT 2 NONLOCAL |TO-BIND |SLASH { 1 } 1 1 � � � � � � � � � � � � � � � � b. -di˘g-i := � � � CAT f HEAD noun [acc or dat]l LOCAL LSUBCAT &lt;&gt; J CONTENT npro[INDEX 1 ] NONLOCAL |INHER |SLASH { 1 } 1 1 MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different modes of combination in the grammar. In addition to binary modes such as wrapping and commutative operations, unary modalities provide finer control over the categories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyntactic features such as case, number, and person for economy in lexical assignments. For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for case and declension. Underspecification is dealt with in the grammar using inclusion postulates (e.g., (7)). The interaction of different modalities is regulated by di</context>
</contexts>
<marker>Moortgat, Oehrle, 1994</marker>
<rawString>Moortgat, Michael and Richard T. Oehrle. 1994. Adjacency, dependency and order. In Proceedings of the Ninth Amsterdam Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glyn V Morrill</author>
</authors>
<title>Type Logical Grammar: Categorial Logic of Signs.</title>
<date>1994</date>
<publisher>Kluwer.</publisher>
<contexts>
<context position="12583" citStr="Morrill 1994" startWordPosition="1936" endWordPosition="1937">text free. 148 Bozsahin The Combinatory Morphemic Lexicon assignment for trace introduces phonologically null elements into the lexicon, which, as we show later, is not necessary. (6) a. ver-di˘g-i := � � � � �PERSON thin HEAD AGR [NUMBER sing CAT CASE dat � SUBCAT &lt; 3 NP[gen], 2 NP[acc],1 NP[dat]&gt; LOCAL MOD |MODSYN |LOCAL |CONT |INDEX 1 � � RELNgive GIVER 3 CONTENT � � GIVEE 1 GIFT 2 NONLOCAL |TO-BIND |SLASH { 1 } 1 1 � � � � � � � � � � � � � � � � b. -di˘g-i := � � � CAT f HEAD noun [acc or dat]l LOCAL LSUBCAT &lt;&gt; J CONTENT npro[INDEX 1 ] NONLOCAL |INHER |SLASH { 1 } 1 1 MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow different modes of combination in the grammar. In addition to binary modes such as wrapping and commutative operations, unary modalities provide finer control over the categories. Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyntactic features such as case, number, and person for economy in lexical assignments. For instance, Frau has the category ✷case✷fem✷sg✷3p✷declN, which underspecifies it for case and declension. Underspecification is dealt with in the grammar using inclusion postulates (e.g., (7)). The interaction of different mo</context>
</contexts>
<marker>Morrill, 1994</marker>
<rawString>Morrill, Glyn V. 1994. Type Logical Grammar: Categorial Logic of Signs. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glyn V Morrill</author>
</authors>
<title>Geometry of lexico-syntactic interaction.</title>
<date>1999</date>
<booktitle>In Proceedings of the Ninth EACL,</booktitle>
<location>Bergen.</location>
<contexts>
<context position="33347" citStr="Morrill 1999" startWordPosition="5487" endWordPosition="5488">ossible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlati´c 2000). Rather than providing an elaborate agreement system, we note that Pulman’</context>
</contexts>
<marker>Morrill, 1999</marker>
<rawString>Morrill, Glyn V. 1999. Geometry of lexico-syntactic interaction. In Proceedings of the Ninth EACL, Bergen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan M¨uller</author>
</authors>
<title>Deutsche Syntax deklarativ. Head-Driven Phrase Structure Grammar f¨ur das Deutsche. Linguistische Arbeiten 394.</title>
<date>1999</date>
<publisher>Max Niemeyer Verlag, T¨ubingen.</publisher>
<marker>M¨uller, 1999</marker>
<rawString>M¨uller, Stefan. 1999. Deutsche Syntax deklarativ. Head-Driven Phrase Structure Grammar f¨ur das Deutsche. Linguistische Arbeiten 394. Max Niemeyer Verlag, T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Two-level description of Turkish morphology.</title>
<date>1994</date>
<journal>Literary and Linguistic Computing,</journal>
<volume>9</volume>
<issue>2</issue>
<marker>Oflazer, 1994</marker>
<rawString>Oflazer, Kemal. 1994. Two-level description of Turkish morphology. Literary and Linguistic Computing, 9(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--73</pages>
<marker>Oflazer, 1996</marker>
<rawString>Oflazer, Kemal. 1996. Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction. Computational Linguistics, 22:73–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>Elvan G¨o¸cmen</author>
<author>Cem Bozsahin</author>
</authors>
<title>An outline of Turkish morphology.</title>
<date>1994</date>
<booktitle>Report to NATO Science Division SfS III (TU-LANGUAGE),</booktitle>
<location>Brussels.</location>
<marker>Oflazer, G¨o¸cmen, Bozsahin, 1994</marker>
<rawString>Oflazer, Kemal, Elvan G¨o¸cmen, and Cem Bozsahin. 1994. An outline of Turkish morphology. Report to NATO Science Division SfS III (TU-LANGUAGE), Brussels.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur.</title>
<date>2001</date>
<booktitle>Building and Exploiting Syntactically-Annotated Corpora.</booktitle>
<editor>In Anne Abeille, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>Oflazer, 2001</marker>
<rawString>Oflazer, Kemal, Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur. 2001. Building a Turkish treebank. In Anne Abeille, editor, Building and Exploiting Syntactically-Annotated Corpora. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remo Pareschi</author>
<author>Mark Steedman</author>
</authors>
<title>A lazy way to chart-parse with Categorial Grammars.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the ACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="33233" citStr="Pareschi and Steedman 1987" startWordPosition="5467" endWordPosition="5470">cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and </context>
</contexts>
<marker>Pareschi, Steedman, 1987</marker>
<rawString>Pareschi, Remo and Mark Steedman. 1987. A lazy way to chart-parse with Categorial Grammars. In Proceedings of the 25th Annual Meeting of the ACL, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Stuart M Shieber</author>
</authors>
<title>Prolog and Natural-Language Analysis.</title>
<date>1987</date>
<location>CSLI, Stanford, CA.</location>
<contexts>
<context position="17585" citStr="Pereira and Shieber 1987" startWordPosition="2731" endWordPosition="2734">-first” convention for CG. For instance, transitive verbs of English are written as (S\NP)/NP, which translates to (NP\S)/NP in the “result-on-top” convention. 4 We omit the prosodic element for ease of exposition. For instance, the complete definition of forward application is s1 − X/Y: f s2 − Y: a ⇒ s1 • s2 − X: fa, where • is prosodic combination and fa is the application of f to a. The • will play a crucial role in the lexicalization of attachment later on. 5 The lambda term f [a] denotes internal one-step β-reduction of f on a. In parsing, we achieve the same effect by partial execution (Pereira and Shieber 1987). Af .f [a] is encoded as (a&amp;quot;F)&amp;quot;F in Prolog, where ˆ is lambda abstraction. We opted for the explicit f [a] notation mainly for ease of exposition (cf. the semantics of raising verbs, relative participles, etc. in Section 6). Moreover, as Pereira and Shieber noted, (a&amp;quot;F)&amp;quot;F is not a lambda term in the strict sense because a is not a variable. 151 Computational Linguistics Volume 28, Number 2 looking for a VP (= S\NP) to the right to become S. The reversal of directionality such as topicalization (e.g., This book, I recommend) requires another schema. The reversal is with respect to the position</context>
</contexts>
<marker>Pereira, Shieber, 1987</marker>
<rawString>Pereira, Fernando C. N. and Stuart M. Shieber. 1987. Prolog and Natural-Language Analysis. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="7122" citStr="Pollard and Sag 1994" startWordPosition="1037" endWordPosition="1040">)), which corresponds to four [truck]-s, because it denotes the subset of nonempty nonsingleton sets of trucks with four members. The status of inflectional morphology among theories of grammar is far from settled, but, starting with Chomsky (1970), there seems to be an agreement that derivational morphology is internal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Mo</context>
<context position="10595" citStr="Pollard and Sag 1994" startWordPosition="1579" endWordPosition="1582">on under coordination call for flexible constituency, such as SO (subject-object) in the SVO &amp; SO gapping pattern of English and SV (subject-verb) constituency in the OSV &amp; SV pattern of Turkish. Nontraditional constituents are also needed in specifying semantically transparent constituency of words, affixes, clitics, and phrases. Constraint-based PSGs such as HPSG appeal to coindexation and feature passing via unification, rather than movement, to deal with such processes. HPSG also makes the commitment that inflectional morphology is internal to the lexicon, handled either by lexical rules (Pollard and Sag 1994) or by lexical inheritance (Miller and Sag 1997). We look at (5c) to highlight a problem with the stem-and-inflections view. As words enter syntax fully inflected, the sign of the verb ver-di˘g-i in the relative clause (5c) would be as in (6a), in which the SUBCAT list of the verb stem is, as specified in the lexical entry for ver, unsaturated. The participle adds coindexation in MODJ · · · JINDEX. The HPSG analysis of this example would be as in Figure 1. Although passing the agreement features of the head separately (Sehitoglu 1996) solves the case problem alluded to in (5c), however, struct</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, Carl and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>Unification encodings of grammatical notations.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--295</pages>
<contexts>
<context position="30864" citStr="Pulman (1996)" startWordPosition="5094" endWordPosition="5095">• (iste • di)− a S 156 Bozsahin The Combinatory Morphemic Lexicon The lexicalization of attachment modality helps to determine the prosodic domain of postconditions. For instance, for Turkish, vowel harmony does not apply over word boundaries, which can be enforced by applying it when the modality is ◦a and ◦c , but s not ◦. Voicing applies to ◦a and ◦s, but not to ◦c . The basic categories N, NP, S, S+t, and S−t carry agreement features of fixed arity (e.g., tense and person for S, S+t, and S−t, and case, number, person, and gender for N and NP). Positional encoding of such information as in Pulman (1996) allows efficient term unification for the propagation of these features.14 Term unification also handles the matching of complex categories in the CCG schema. For instance, α1 ✷1 A/(o22B \ o; C) combines with β2 ✷4B\ β3 ✷5C via (&gt;) for B, C E As, if β2 ❑2 α2, β3 ❑3 α3 (❑i E {&lt;, M}). Apart from the matching of syntactic types and agreement, unification does no linguistic work in this framework, in contrast to structure-sharing in HPSG and slash passing in Unification CG (Calder, Klein, and Zeevat 1988). CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993). This result depends </context>
</contexts>
<marker>Pulman, 1996</marker>
<rawString>Pulman, Stephen G. 1996. Unification encodings of grammatical notations. Computational Linguistics, 22:295–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The generative lexicon.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="82949" citStr="Pustejovsky 1991" startWordPosition="13483" endWordPosition="13484"> -POSS -GEN house -POSS N N/(N\N)\N N N\N\N N/(N\N)\N N N\N\N &lt; &lt; &lt; N/(N\N) N\N N\N &gt; &lt; N/(N\N) &gt; N: poss house(poss friend i) ’my friend’s house’ N 180 Bozsahin The Combinatory Morphemic Lexicon 6.6.3 Lexical Types for Compounds. Syntactic compounds exhibit syntactic patterns similar to possessive constructions, but they signify semantic relations of a different kind. In what follows, we use the function comp to signify that the arguments in the PAS form a compound but say nothing about the range of productivity of this function. The lexical semantics of the arguments and a qualia structure (Pustejovsky 1991) may indicate the function’s range of applicability. Lexical type assignments for compound markers are as in (52). (52) -COMP := o s − A N\ &lt; N\ A N: Ax.Ay.comp xy -COMP2 :=o s− AN\ AN\ &lt; N\ A N: Ax.Ay.Az.comp(compxy)z (nested comp) Syntactic compounds are formed by means of compound markers that are attached to the head of the compound. For morphosyntactic modality, nonreferentiality of the head implies no inflection (AN) or modification (53a–b). The left component can be a noun group (53c) in which there is ambiguity in the scope of modification. This is regulated by typing, for example, the</context>
</contexts>
<marker>Pustejovsky, 1991</marker>
<rawString>Pustejovsky, James. 1991. The generative lexicon. Computational Linguistics, 17(4):409–441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Onur Sehitoglu</author>
</authors>
<title>A sign-based phrase structure grammar for Turkish. Master’s thesis,</title>
<date>1996</date>
<institution>Middle East Technical University.</institution>
<contexts>
<context position="11135" citStr="Sehitoglu 1996" startWordPosition="1677" endWordPosition="1678">rnal to the lexicon, handled either by lexical rules (Pollard and Sag 1994) or by lexical inheritance (Miller and Sag 1997). We look at (5c) to highlight a problem with the stem-and-inflections view. As words enter syntax fully inflected, the sign of the verb ver-di˘g-i in the relative clause (5c) would be as in (6a), in which the SUBCAT list of the verb stem is, as specified in the lexical entry for ver, unsaturated. The participle adds coindexation in MODJ · · · JINDEX. The HPSG analysis of this example would be as in Figure 1. Although passing the agreement features of the head separately (Sehitoglu 1996) solves the case problem alluded to in (5c), however, structure sharing of the NPdat with the SLASH, INDEX, and CONTENT features of ver-di˘g-i is needed for semantics (GIVEE), but this conflicts with the head features of the topmost NPacc in the tree. The relative participle as a lexical entry (e.g., (6b)) would resolve the problem with subcategorization because its SUBCAT list is empty (like the relative pronoun that in English), hence there would be no indirect dependence of the nonlocal SLASH feature and the local SUBCAT feature via semantics (CONTENT). Such morphemic alternatives are not c</context>
</contexts>
<marker>Sehitoglu, 1996</marker>
<rawString>Sehitoglu, Onur. 1996. A sign-based phrase structure grammar for Turkish. Master’s thesis, Middle East Technical University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Onur Sehitoglu</author>
<author>Cem Bozsahin</author>
</authors>
<title>Lexical rules and lexical organization: Productivity in the lexicon.</title>
<date>1999</date>
<booktitle>In Evelyne Viegas, editor, Breadth and Depth of Semantic Lexicons.</booktitle>
<pages>39--57</pages>
<publisher>Kluwer,</publisher>
<contexts>
<context position="4553" citStr="Sehitoglu and Bozsahin 1999" startWordPosition="658" endWordPosition="661">ean the syntax of words, in contrast to the syntax of phrases. By morphosyntax we mean those aspects of morphology and syntax that collectively contribute to grammatical meaning composition. This is more in line with the inflectional-morphology-is-syntax view. In this respect, we will not address problems related to derivational morphology; its semantics is notoriously noncompositional and does not interact with grammatical meaning. Moreover, without a semantically powerful lexicon such as Pustejovsky’s (1991), even the most productive fragment of derivational morphology is hard to deal with (Sehitoglu and Bozsahin 1999). 146 Bozsahin The Combinatory Morphemic Lexicon Phrasal scope of inflection can be seen in subordination and relativization as well. In (5a), the entire nominalized clause marked with the accusative case is the object of want. In (5b), the relative participle applies to the relative clause, which lacks an object. The object’s case is governed by the subordinate verb, whose case requirements might differ from that of the matrix verb (5c). As we show later in this section, the coindexing mechanisms in word-based unification accounts of unbounded extraction face a conflict between the local and </context>
<context position="13947" citStr="Sehitoglu and Bozsahin 1999" startWordPosition="2135" endWordPosition="2138">ds carry unary modalities: boys has the type ✷plN, in contrast to ✷sgN for boy. Although such regulation of inflectional features successfully mediates, for example, subject-verb agreement or NP-internal case agreement (as in German), it is essentially word-based, because type assignments are to inflected forms; morphemes do not carry types. This reliance on word types necessitates a lexical rule–based approach to some morphosyntactic processes that create indefinitely long words, such as ki-relativization in Turkish (see Section 6.5). But lexical rules for such processes risk nontermination (Sehitoglu and Bozsahin 1999). Our main point of departure from MCG accounts is the morphemic versus lexemic nature of the lexicon: The morphosyntactic and attachment modalities originate from the lexicon; they are not properties of the grammar (we elaborate more on this later). This paves the way to the morphemic lexicon by licensing type assignments to units smaller than words. Besides problems with lexical rules, the automata-theoretic power of MCGs is problematic: Unrestricted use of structural modalities and postulates leads to Turing completeness (Carpenter 1999). Indeed, one of the identifiable fragments of Mul149 </context>
<context position="50025" citStr="Sehitoglu and Bozsahin (1999)" startWordPosition="8177" endWordPosition="8180">ve the domain of the modifiers and the plural without rebracketing. 6. Case Study: Turkish Morphosyntax There have been several computational studies to model morphology–syntax interaction in Turkish. These unification-based approaches represent varying degrees of integration. G¨ung¨ordu¨ and Oflazer (1995) isolates morphology from syntax by having separate modules (a finite-state transducer for the former, and an LFG component for the latter), that is, the syntax is lexemic. The morphological component is expected to handle all aspects of morphology, including inflections and derivations. In Sehitoglu and Bozsahin (1999), lexical rules implement inflectional morphology, and derivations are assumed to take place in the lexicon. Hoffman’s (1995) categorial analysis of Turkish is also lexemic; all lexical entries are fully inflected. Interpretive components of these systems face the aforementioned difficulties because of their commitment to lexemic syntax. Inflectional morphology is incorporated into syntax in another categorial approach (Bozsahin and G¨o¸cmen 1995), but morphotactic constraints are modeled with nonmonotonic unification, such as nonexistence checks for features and overrides. The system cannot m</context>
</contexts>
<marker>Sehitoglu, Bozsahin, 1999</marker>
<rawString>Sehitoglu, Onur and Cem Bozsahin. 1999. Lexical rules and lexical organization: Productivity in the lexicon. In Evelyne Viegas, editor, Breadth and Depth of Semantic Lexicons. Kluwer, pages 39–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Dependency and co¨ordination in the grammar of Dutch and English.</title>
<date>1985</date>
<journal>Language,</journal>
<volume>61</volume>
<issue>3</issue>
<contexts>
<context position="16308" citStr="Steedman 1985" startWordPosition="2514" endWordPosition="2515">(S\NP)/NP: λx.λy.read xy Definition (Syntactic Types) • The set of basic syntactic categories: As = {N,NP,S,S−t,S+t} • The set of complex syntactic categories: Bs — As C Bs — If X E Bs and Y E Bs, thenX\Y and X/Y E Bs The classical Ajdukiewicz/Bar-Hillel (AB) CG is weakly equivalent to ContextFree Grammars (Bar-Hillel, Gaifman, and Shamir 1960). It has function application rules, defined originally in a nondirectional fashion. The directional variants and their associated semantics are as follows: (9) Forward Application (&gt;):4 X/Y: f Y: a X: fa Backward Application (&lt;): Y: a X\Y: f X: fa CCG (Steedman 1985, 1987, 1988; Szabolcsi 1983, 1987) is an extended version of AB that includes function composition (10), substitution, and type raising (11). These extensions make CCGs mildly context sensitive. (10) Forward Composition (&gt;B): X/Y: f Y/Z: g X/Z: λx.f (gx) Backward Composition (&lt;B): Y\Z:g X\Y: f X\Z: λx.f (gx) (11) Forward Type Raising (&gt;T):5 X: a T/(T\X): λf .f [a] Backward Type Raising (&lt;T): X: a T\(T/X): λf .f [a] Type raising is an order-preserving operation. For instance, Lambek’s (1958) category S/(S\NP) is a positional encoding of the grammatical subject as a function 3 We take π to be t</context>
<context position="20474" citStr="Steedman 1985" startWordPosition="3185" endWordPosition="3186">n yields the bracketing in (13) for the PAS. Having the primary argument as the outermost term is motivated by the observations on binding asymmetries between subjects and complements in many languages (e.g., *Himself saw John, *heself). (13) 3. Morphosyntactic Types A syntactic type such as N does not discriminate morphosyntactically. A finer distinction can be made as singular nouns, plural nouns, case-marked nouns, etc. For 6 In fact, topicalization of nonperipheral arguments (This book, I would give to Mary) requires that (12) be finitely schematized over valencies, such as S, S/NP, S/PP (Steedman 1985). 7 We will not elaborate on the theoretical consequences of having this level of representation; see, for instance, Dowty (1991) and Steedman (1996). 152 Bozsahin The Combinatory Morphemic Lexicon free (f) (t) (n) n-num s-tense (v) n-base (b) s-base s-base (v) (r) n-relbase n-root (l) s-caus (u) s-reflex (x) s-recip (a) s-person s-modal (m) n-comp (m) n-poss (a) (o) (g) (i) (p) n-num (n) n-case (c) n-base (b) s-tense s-abil s-neg s-imp s-pass (b) (c) free (f) Figure 2 The lattice of diacritics for (a) Turkish and (b) English. instance, the set of number-marked nouns can be represented as n✶N,</context>
<context position="56270" citStr="Steedman 1985" startWordPosition="9160" endWordPosition="9161">hat is type raised can be a syntactically derived noun (28). SO (and OS) constituency required for gapping is provided by &gt;T and &gt;B. (28) Mehmet k¨u¸c¨uk ye¸sil kitab-ı, ¸cocuk da yeni gelen dergi-yi oku-du M.NOM little green book-ACC child-COORD new come mag.-ACC read-TENSE Nnom Nacc Nnom Nacc S\NPnom\NPacc &gt;T &gt;T S/(S\NPnom) (S\NP) /(S\NP\NPacc) ... &gt;B &gt;B S/(S\NPnom\NPacc) S/(S\NPnom\NPacc) &amp; S/(S\NPnom\NPacc) &gt; S ’Mehmet read the little green book, and the child, the newly arrived magazine’. Our lexical type assignment to case morphemes (24e–f) departs from other CCG analyses of case (e.g., Steedman 1985, 1991a, Bozsahin 1998). These studies correlate morphological case with type raising of arguments, in the case of Bozsahin (1998), via a value-raised category assignment to case morphemes. Evidence from NP-internal case agreement and case stacking (Kracht 1999) challenges the type-raising approach. Agreement phenomena require that case (which can be marked on articles, adjectives, and nouns) be regulated as an agreement feature within the category N before the case-marked argument looks for the verb via type raising. Kracht observes that, in case stacking, there may be other morphemes between</context>
</contexts>
<marker>Steedman, 1985</marker>
<rawString>Steedman, Mark. 1985. Dependency and co¨ordination in the grammar of Dutch and English. Language, 61(3):523–568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Combinatory grammars and parasitic gaps.</title>
<date>1987</date>
<booktitle>Natural Language and Linguistic Theory,</booktitle>
<pages>5--403</pages>
<contexts>
<context position="33233" citStr="Steedman 1987" startWordPosition="5469" endWordPosition="5470">called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during parsing to obtain all surface bracketings. 14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has important consequences on underspecification, the domain of agreement, and the notion of “like categories” in coordination (see Johnson and Bayer 1995; Dalrymple and </context>
</contexts>
<marker>Steedman, 1987</marker>
<rawString>Steedman, Mark. 1987. Combinatory grammars and parasitic gaps. Natural Language and Linguistic Theory, 5:403–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Combinators and grammars.</title>
<date>1988</date>
<booktitle>Categorial Grammars and Natural Language Structures.</booktitle>
<pages>417--442</pages>
<editor>In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors,</editor>
<location>Dordrecht,</location>
<marker>Steedman, 1988</marker>
<rawString>Steedman, Mark. 1988. Combinators and grammars. In Richard T. Oehrle, Emmon Bach, and Deirdre Wheeler, editors, Categorial Grammars and Natural Language Structures. D. Reidel, Dordrecht, pages 417–442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<date>1991</date>
<booktitle>Structure and intonation. Language,</booktitle>
<pages>67--260</pages>
<contexts>
<context position="29726" citStr="Steedman 1991" startWordPosition="4898" endWordPosition="4899">NPgen . . . ((ay¸se a s a s a a t f t f f • nin) • (kitab • ı • oku) • ması) • nı−( .4 S\ a NPnom)/( a S\ a NPnom\ a NPacc) . . . s can • (ay¸se : want(read book ay¸se)can ’Can wanted Ay¸se to read the book.’ f f b. -TENSE := ◦a dı|di|du|d¨u|tı|ti|tu|t¨u − (� t S\ � NP)\( � a S\ � NP): Af f 13 Clearly, much more needs to be done to incorporate intonation into the system. The motive for attachment types is to provide the representational ingredients on behalf of the morphemic lexicon. As one reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomous prosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b). The present proposal for attachment modality is computationally compatible with both accounts: Combinatory prosody can match prosodic types with morphosyntactic types. Prosodic features are associated with the basic categories of a syntactic type in the latter formulation, hence they become part of the featural inference that goes along with the matching of categories in the application of combinatory rules. a s a s a a s a t • nin • kitab • ı • oku • ması • nı) • (iste • di)− a S 156 Bozsahin The Combinatory Morphemic Lexicon The lexic</context>
<context position="32934" citStr="Steedman 1991" startWordPosition="5427" endWordPosition="5428">hema (contraposition) available in the grammar. Since both are finite schemas in the revised formulation, the complexity result of Vijay-Shanker and Weir still holds. Checking the lattice condition as in (15) incurs a constant factor with a finite lattice. Type raising and composition cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during </context>
</contexts>
<marker>Steedman, 1991</marker>
<rawString>Steedman, Mark. 1991a. Structure and intonation. Language, 67:260–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Type raising and directionality in Combinatory Grammar.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the ACL,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="29726" citStr="Steedman 1991" startWordPosition="4898" endWordPosition="4899">NPgen . . . ((ay¸se a s a s a a t f t f f • nin) • (kitab • ı • oku) • ması) • nı−( .4 S\ a NPnom)/( a S\ a NPnom\ a NPacc) . . . s can • (ay¸se : want(read book ay¸se)can ’Can wanted Ay¸se to read the book.’ f f b. -TENSE := ◦a dı|di|du|d¨u|tı|ti|tu|t¨u − (� t S\ � NP)\( � a S\ � NP): Af f 13 Clearly, much more needs to be done to incorporate intonation into the system. The motive for attachment types is to provide the representational ingredients on behalf of the morphemic lexicon. As one reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomous prosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b). The present proposal for attachment modality is computationally compatible with both accounts: Combinatory prosody can match prosodic types with morphosyntactic types. Prosodic features are associated with the basic categories of a syntactic type in the latter formulation, hence they become part of the featural inference that goes along with the matching of categories in the application of combinatory rules. a s a s a a s a t • nin • kitab • ı • oku • ması • nı) • (iste • di)− a S 156 Bozsahin The Combinatory Morphemic Lexicon The lexic</context>
<context position="32934" citStr="Steedman 1991" startWordPosition="5427" endWordPosition="5428">hema (contraposition) available in the grammar. Since both are finite schemas in the revised formulation, the complexity result of Vijay-Shanker and Weir still holds. Checking the lattice condition as in (15) incurs a constant factor with a finite lattice. Type raising and composition cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989; K¨onig 1989; Morrill 1999). We adopt Eisner’s method, which eliminates chains of compositions in O(1) time via tags in the grammar, before derivations are licensed. There is a switch that can be turned off during </context>
</contexts>
<marker>Steedman, 1991</marker>
<rawString>Steedman, Mark. 1991b. Type raising and directionality in Combinatory Grammar. In Proceedings of the 29th Annual Meeting of the ACL, pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="19452" citStr="Steedman 1996" startWordPosition="3029" endWordPosition="3030">ising in changing the functionargument relation and (2) categorizing the sentence as S+t (topicalized) or S−t (detopicalized), which are not discourse equivalent to S. Syntactic characterization as such also helps a discourse component do its work on syntactic derivations. CCG’s notion of interpretation is represented in the Predicate-Argument Structure (PAS). Its organization is crucial for our purposes, since the bracketing in the PAS is the arbitrator for reconciling the bracketings in morphology and syntax via proper lexical type assignments. It is the sole level of representation in CCG (Steedman 1996, page 89).7 It is the level at which the conditions on objects of interpretation, such as binding and control, are formulated. For instance, Steedman (1996) defines c-command and binding conditions A, B, and C over the PAS. The PAS also reflects the obliqueness order of the arguments: Predicate ... Tertiary-Term Secondary-Term Primary-Term Assuming left associativity for juxtaposition, this representation yields the bracketing in (13) for the PAS. Having the primary argument as the outermost term is motivated by the observations on binding asymmetries between subjects and complements in many </context>
<context position="24924" citStr="Steedman (1996)" startWordPosition="3986" endWordPosition="3987">is tradition is followed in MCG; attachment types are related with the slash (e.g., /w for wrapping), which is a grammatical modality.10 In the present framework, however, attachment is projected from the lexicon to the grammar as a prosodic property of the lexical items.11 The grammar is unimodal in the sense that / and \ simply indicate the function-argument distinction in adjacent prosodic elements. The lexical projection of attachment further complements the notion of morphemic lexicon so that bound morphemes are no longer parasitic on words but have an independent 10 See Dowty (1996) and Steedman (1996) for a discussion of bringing nonconcatenative combination into grammar. 11 There is a precedent of associating attachment characteristics with the prosodic element rather than the slash in CG (Hoeksema and Janda 1988). In Hoeksema and Janda’s notation, arguments can be constrained on phonological properties and attachment. For instance, the English article a has its NP/N category spelled out as &lt;/CX/N,NP,Pref&gt;, indicating a consonantal first segment for the noun argument and concatenation to the left. 154 Bozsahin The Combinatory Morphemic Lexicon Table 1 Attachment properties of some Turkish</context>
<context position="51200" citStr="Steedman (1996)" startWordPosition="8342" endWordPosition="8343">tures and overrides. The system cannot make finer distinctions in morphosyntactic types either. The result is an overgenerating and nontransparent integration of morphology and syntax because of the possibility of rebracketing and the unresolved representational basis of the lexicon. In this section, we outline the application of the proposed framework to Turkish. We analyze a large fragment of the language, without any claims for a comprehensive grammar. The phenomena modeled here exhibit particular morphosyntactic problems described in the preceding sections. We assume the binding theory in Steedman (1996), which is predicated over the PAS. In each section, we provide a brief empirical observation about the phenomenon, propose lexical type assignments, exemplify derivations of the parser, and briefly discuss the constraints imposed by morphosyntactic types. Because of space considerations, we sometimes use abbreviated forms in derivations such as the genitive affix’s (N/(N\N))\N category for (&lt;o N/(o✶ Npn\ o✶ Npn))\ &lt;o Npn, but the parser operates on full morphosyntactic representations. 6.1 Case Marking and Word Order Turkish is regarded as a free constituent order language; all permutations o</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Steedman, Mark. 1996. Surface Structure and Interpretation. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9899" citStr="Steedman (2000)" startWordPosition="1479" endWordPosition="1481">ow supply the ingredients of a morphosyntactic calculus. This leads to a theory in which semantic composition parallels morphosyntactic combination by virtue of bound morphemes’ being able to pick their domains just like words (above X0, if needed). A comparison of English and Turkish in this regard is noteworthy. The English relative pronouns that/whom and the Turkish relative participle -di˘g-i would have exactly the same semantics when the latter is granted a representational status in the lexicon (see Section 6). Furthermore, rule-based PSGs project a rigid notion of surface constituency. Steedman (2000) argued, however, that syntactic processes such as identical element deletion under coordination call for flexible constituency, such as SO (subject-object) in the SVO &amp; SO gapping pattern of English and SV (subject-verb) constituency in the OSV &amp; SV pattern of Turkish. Nontraditional constituents are also needed in specifying semantically transparent constituency of words, affixes, clitics, and phrases. Constraint-based PSGs such as HPSG appeal to coindexation and feature passing via unification, rather than movement, to deal with such processes. HPSG also makes the commitment that inflection</context>
<context position="29780" citStr="Steedman 2000" startWordPosition="4904" endWordPosition="4905">tab • ı • oku) • ması) • nı−( .4 S\ a NPnom)/( a S\ a NPnom\ a NPacc) . . . s can • (ay¸se : want(read book ay¸se)can ’Can wanted Ay¸se to read the book.’ f f b. -TENSE := ◦a dı|di|du|d¨u|tı|ti|tu|t¨u − (� t S\ � NP)\( � a S\ � NP): Af f 13 Clearly, much more needs to be done to incorporate intonation into the system. The motive for attachment types is to provide the representational ingredients on behalf of the morphemic lexicon. As one reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomous prosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b). The present proposal for attachment modality is computationally compatible with both accounts: Combinatory prosody can match prosodic types with morphosyntactic types. Prosodic features are associated with the basic categories of a syntactic type in the latter formulation, hence they become part of the featural inference that goes along with the matching of categories in the application of combinatory rules. a s a s a a s a t • nin • kitab • ı • oku • ması • nı) • (iste • di)− a S 156 Bozsahin The Combinatory Morphemic Lexicon The lexicalization of attachment modality helps to determine th</context>
<context position="31598" citStr="Steedman 2000" startWordPosition="5217" endWordPosition="5218"> complex categories in the CCG schema. For instance, α1 ✷1 A/(o22B \ o; C) combines with β2 ✷4B\ β3 ✷5C via (&gt;) for B, C E As, if β2 ❑2 α2, β3 ❑3 α3 (❑i E {&lt;, M}). Apart from the matching of syntactic types and agreement, unification does no linguistic work in this framework, in contrast to structure-sharing in HPSG and slash passing in Unification CG (Calder, Klein, and Zeevat 1988). CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993). This result depends on the finite schematization of type raising and bounded composition. Assuming a maximum valence of four in the lexicon (Steedman 2000a), composition (Bn) is bounded by n ≤ 3. The refinement of the type raising schema (11) for finite schematization is shown in (17). (17) a. Revised Forward Type Raising (&gt;T): NP: a T/(T\NP): Af .f [a] b. Revised Backward Type Raising (&lt;T): NP: a T\(T/NP): Af .f [a] T E {S,S\NP, S\NP\NP, S\NP\NP\NP}. The finite schematization of type raising suggests that it can be delegated to the lexicon, for example, by a lexical rule that value-raises all functions onto NP to their type-raised variety, such as NP/N to (S/(S\NP))/N. But this move presupposes the presence of such functions in the lexicon, th</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000a. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Information structure and the syntax-phonology interface.</title>
<date>2000</date>
<journal>Linguistic Inquiry,</journal>
<volume>31</volume>
<issue>4</issue>
<pages>649--689</pages>
<contexts>
<context position="9899" citStr="Steedman (2000)" startWordPosition="1479" endWordPosition="1481">ow supply the ingredients of a morphosyntactic calculus. This leads to a theory in which semantic composition parallels morphosyntactic combination by virtue of bound morphemes’ being able to pick their domains just like words (above X0, if needed). A comparison of English and Turkish in this regard is noteworthy. The English relative pronouns that/whom and the Turkish relative participle -di˘g-i would have exactly the same semantics when the latter is granted a representational status in the lexicon (see Section 6). Furthermore, rule-based PSGs project a rigid notion of surface constituency. Steedman (2000) argued, however, that syntactic processes such as identical element deletion under coordination call for flexible constituency, such as SO (subject-object) in the SVO &amp; SO gapping pattern of English and SV (subject-verb) constituency in the OSV &amp; SV pattern of Turkish. Nontraditional constituents are also needed in specifying semantically transparent constituency of words, affixes, clitics, and phrases. Constraint-based PSGs such as HPSG appeal to coindexation and feature passing via unification, rather than movement, to deal with such processes. HPSG also makes the commitment that inflection</context>
<context position="29780" citStr="Steedman 2000" startWordPosition="4904" endWordPosition="4905">tab • ı • oku) • ması) • nı−( .4 S\ a NPnom)/( a S\ a NPnom\ a NPacc) . . . s can • (ay¸se : want(read book ay¸se)can ’Can wanted Ay¸se to read the book.’ f f b. -TENSE := ◦a dı|di|du|d¨u|tı|ti|tu|t¨u − (� t S\ � NP)\( � a S\ � NP): Af f 13 Clearly, much more needs to be done to incorporate intonation into the system. The motive for attachment types is to provide the representational ingredients on behalf of the morphemic lexicon. As one reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomous prosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b). The present proposal for attachment modality is computationally compatible with both accounts: Combinatory prosody can match prosodic types with morphosyntactic types. Prosodic features are associated with the basic categories of a syntactic type in the latter formulation, hence they become part of the featural inference that goes along with the matching of categories in the application of combinatory rules. a s a s a a s a t • nin • kitab • ı • oku • ması • nı) • (iste • di)− a S 156 Bozsahin The Combinatory Morphemic Lexicon The lexicalization of attachment modality helps to determine th</context>
<context position="31598" citStr="Steedman 2000" startWordPosition="5217" endWordPosition="5218"> complex categories in the CCG schema. For instance, α1 ✷1 A/(o22B \ o; C) combines with β2 ✷4B\ β3 ✷5C via (&gt;) for B, C E As, if β2 ❑2 α2, β3 ❑3 α3 (❑i E {&lt;, M}). Apart from the matching of syntactic types and agreement, unification does no linguistic work in this framework, in contrast to structure-sharing in HPSG and slash passing in Unification CG (Calder, Klein, and Zeevat 1988). CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993). This result depends on the finite schematization of type raising and bounded composition. Assuming a maximum valence of four in the lexicon (Steedman 2000a), composition (Bn) is bounded by n ≤ 3. The refinement of the type raising schema (11) for finite schematization is shown in (17). (17) a. Revised Forward Type Raising (&gt;T): NP: a T/(T\NP): Af .f [a] b. Revised Backward Type Raising (&lt;T): NP: a T\(T/NP): Af .f [a] T E {S,S\NP, S\NP\NP, S\NP\NP\NP}. The finite schematization of type raising suggests that it can be delegated to the lexicon, for example, by a lexical rule that value-raises all functions onto NP to their type-raised variety, such as NP/N to (S/(S\NP))/N. But this move presupposes the presence of such functions in the lexicon, th</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000b. Information structure and the syntax-phonology interface. Linguistic Inquiry, 31(4): 649–689.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Szabolcsi</author>
</authors>
<date>1983</date>
<institution>Max-Planck Institute.</institution>
<note>ECP in categorial grammar. Unpublished manuscript,</note>
<contexts>
<context position="16336" citStr="Szabolcsi 1983" startWordPosition="2518" endWordPosition="2519">finition (Syntactic Types) • The set of basic syntactic categories: As = {N,NP,S,S−t,S+t} • The set of complex syntactic categories: Bs — As C Bs — If X E Bs and Y E Bs, thenX\Y and X/Y E Bs The classical Ajdukiewicz/Bar-Hillel (AB) CG is weakly equivalent to ContextFree Grammars (Bar-Hillel, Gaifman, and Shamir 1960). It has function application rules, defined originally in a nondirectional fashion. The directional variants and their associated semantics are as follows: (9) Forward Application (&gt;):4 X/Y: f Y: a X: fa Backward Application (&lt;): Y: a X\Y: f X: fa CCG (Steedman 1985, 1987, 1988; Szabolcsi 1983, 1987) is an extended version of AB that includes function composition (10), substitution, and type raising (11). These extensions make CCGs mildly context sensitive. (10) Forward Composition (&gt;B): X/Y: f Y/Z: g X/Z: λx.f (gx) Backward Composition (&lt;B): Y\Z:g X\Y: f X\Z: λx.f (gx) (11) Forward Type Raising (&gt;T):5 X: a T/(T\X): λf .f [a] Backward Type Raising (&lt;T): X: a T\(T/X): λf .f [a] Type raising is an order-preserving operation. For instance, Lambek’s (1958) category S/(S\NP) is a positional encoding of the grammatical subject as a function 3 We take π to be the surface string for simpli</context>
</contexts>
<marker>Szabolcsi, 1983</marker>
<rawString>Szabolcsi, Anna. 1983. ECP in categorial grammar. Unpublished manuscript, Max-Planck Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Szabolcsi</author>
</authors>
<title>Bound variables in syntax: Are there any?</title>
<date>1987</date>
<booktitle>In Proceedings of the 6th Amsterdam Colloquium,</booktitle>
<pages>331--350</pages>
<marker>Szabolcsi, 1987</marker>
<rawString>Szabolcsi, Anna. 1987. Bound variables in syntax: Are there any? In Proceedings of the 6th Amsterdam Colloquium, pages 331–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaru Tomita</author>
</authors>
<title>The Generalized LR Parser/Compiler.</title>
<date>1988</date>
<tech>Technical report,</tech>
<institution>Center for Machine Translation, Carnegie Mellon University.</institution>
<contexts>
<context position="7431" citStr="Tomita 1988" startWordPosition="1085" endWordPosition="1086">rnal to the lexicon. Lexical Functional Grammar (LFG) (Bresnan 1995) and earlier Government and Binding (GB) proposals e.g. (Anderson 1982) consider inflectional morphology to be part of syntax, but it has been delegated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollard and Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives </context>
</contexts>
<marker>Tomita, 1988</marker>
<rawString>Tomita, Masaru. 1988. The Generalized LR Parser/Compiler. Technical report, Center for Machine Translation, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>Parsing some constrained grammar formalisms. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="31442" citStr="Vijay-Shanker and Weir 1993" startWordPosition="5190" endWordPosition="5193">l encoding of such information as in Pulman (1996) allows efficient term unification for the propagation of these features.14 Term unification also handles the matching of complex categories in the CCG schema. For instance, α1 ✷1 A/(o22B \ o; C) combines with β2 ✷4B\ β3 ✷5C via (&gt;) for B, C E As, if β2 ❑2 α2, β3 ❑3 α3 (❑i E {&lt;, M}). Apart from the matching of syntactic types and agreement, unification does no linguistic work in this framework, in contrast to structure-sharing in HPSG and slash passing in Unification CG (Calder, Klein, and Zeevat 1988). CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993). This result depends on the finite schematization of type raising and bounded composition. Assuming a maximum valence of four in the lexicon (Steedman 2000a), composition (Bn) is bounded by n ≤ 3. The refinement of the type raising schema (11) for finite schematization is shown in (17). (17) a. Revised Forward Type Raising (&gt;T): NP: a T/(T\NP): Af .f [a] b. Revised Backward Type Raising (&lt;T): NP: a T\(T/NP): Af .f [a] T E {S,S\NP, S\NP\NP, S\NP\NP\NP}. The finite schematization of type raising suggests that it can be delegated to the lexicon, for example, by a lexical rule that value-raises a</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1993</marker>
<rawString>Vijay-Shanker, K. and David J. Weir. 1993. Parsing some constrained grammar formalisms. Computational Linguistics, 19:591–636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wechsler</author>
<author>Larisa Zlati´c</author>
</authors>
<title>A theory of agreement and its application to Serbo-Croatian. Language,</title>
<date>2000</date>
<pages>76--799</pages>
<marker>Wechsler, Zlati´c, 2000</marker>
<rawString>Wechsler, Stephen and Larisa Zlati´c. 2000. A theory of agreement and its application to Serbo-Croatian. Language, 76:799–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pete J Whitelock</author>
</authors>
<title>A feature-based categorial morpho-syntax for Japanese. In Uwe Reyle</title>
<date>1988</date>
<pages>230--261</pages>
<editor>and C. Rohrer, editors, Natural</editor>
<contexts>
<context position="7751" citStr="Whitelock 1988" startWordPosition="1131" endWordPosition="1132"> in the Minimalist Program (Chomsky 1995, page 195). The representational status of the morpheme is even less clear. Parallel developments in computational studies of HPSG propose lexical rules to model inflectional morphology (Carpenter and Penn 1994). Computational models of LFG (Tomita 1988) and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal regarding inflectional morphology. Finally, morphosyntactic aspects have always been a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty 1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock 1988), but the issues of constraining the morphosyntactic derivations and resolving the apparent mismatches have been relatively untouched in computational studies. We briefly look at Phrase Structure Grammars (PSGs), HPSG, and Multimodal CGs (MCGs) to see how word-based alternatives for morphosyntax would deal with 147 Computational Linguistics Volume 28, Number 2 the issues raised so far. For convenience, we call a grammar that expects words from the lexicon a lexemic grammar and a grammar that expects morphemes a morphemic grammar. A lexemic PSG provides a lexical interface for inflected words (</context>
</contexts>
<marker>Whitelock, 1988</marker>
<rawString>Whitelock, Pete J. 1988. A feature-based categorial morpho-syntax for Japanese. In Uwe Reyle and C. Rohrer, editors, Natural Language Parsing and Linguistic Theories. D. Reidel, pages 230–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edwin Williams</author>
</authors>
<title>On the notions “lexically related” and “head of a word.” Linguistic Inquiry,</title>
<date>1981</date>
<contexts>
<context position="1515" citStr="Williams (1981)" startWordPosition="207" endWordPosition="208">the lexicon to language-particular properties. The result is a transparent interface of inflectional morphology, syntax, and semantics. We present a computational system and show the application of the framework to English and Turkish. 1. Introduction The study presented in this article is concerned with the integrated representation and processing of inflectional morphology, syntax, and semantics in a unified grammar architecture. An important issue in such integration is mismatches in morphological, syntactic, and semantic bracketings. The problem was first noted in derivational morphology. Williams (1981) provided examples from English; the semantic bracketings in (1a–2a) are in conflict with the morphological bracketings in (1b–2b). If the problem were confined to derivational morphology, we could avoid it by making derivational morphology part of the lexicon that does not interact with grammar. But this is not the case. Mismatches in morphosyntactic and semantic bracketing ∗ Computer Engineering and Cognitive Science, Middle East Technical University, 06531 Ankara, Turkey. E-mail: bozsahin@metu.edu.tr. (1) a. -ing b. G¨odel G¨odel number number -ing (1) a. hydro electric -ity b. hydro electr</context>
</contexts>
<marker>Williams, 1981</marker>
<rawString>Williams, Edwin. 1981. On the notions “lexically related” and “head of a word.” Linguistic Inquiry, 12(2):245–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kent Wittenburg</author>
</authors>
<title>Predictive combinators.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the ACL,</booktitle>
<pages>73--79</pages>
<contexts>
<context position="32670" citStr="Wittenburg 1987" startWordPosition="5389" endWordPosition="5390"> onto NP to their type-raised variety, such as NP/N to (S/(S\NP))/N. But this move presupposes the presence of such functions in the lexicon, that is, a language with determiners. To be transparent with respect to the lexicon, we make type raising and other unary schema (contraposition) available in the grammar. Since both are finite schemas in the revised formulation, the complexity result of Vijay-Shanker and Weir still holds. Checking the lattice condition as in (15) incurs a constant factor with a finite lattice. Type raising and composition cause the so-called spurious-ambiguity problem (Wittenburg 1987): Multiple analyses of semantically equivalent derivations are possible in parsing. This is shown to be desirable from the perspective of prosody; for example, different bracketings are needed to match intonational phrasing with syntactic structure (Steedman 1991). From the parsing perspective, the redundancy of analyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checking the chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the processor parsimonious on using long-distance compositions (Pareschi and Steedman 1987), or (4) parsing into normal forms (E</context>
</contexts>
<marker>Wittenburg, 1987</marker>
<rawString>Wittenburg, Kent. 1987. Predictive combinators. In Proceedings of the 25th Annual Meeting of the ACL, pages 73–79.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>