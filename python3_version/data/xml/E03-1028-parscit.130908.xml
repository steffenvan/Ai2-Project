<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000053">
<title confidence="0.985334">
AVM Description Compilation using Types as Modes
</title>
<author confidence="0.997159">
Gerald Penn
</author>
<affiliation confidence="0.9993455">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.996541">
gpenn@cs.toronto.edu
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999981176470588">
This paper provides a method for generat-
ing compact and efficient code to imple-
ment the enforcement of a description in
typed feature logic. It does so by view-
ing information about types through the
course of code generation as modes of in-
stantiation — a generalization of the com-
mon practice in logic programming of the
hi nary instantiated/variable mode decl ara-
tions that advanced Prolog compilers use.
Section 1 introduces the description lan-
guage. Sections 2 and 3 motivate the view
of mode and compilation taken here, and
outline a mode declaration language for
typed feature logic. Sections 4 through 7
then present the compiler. An evaluation on
two grammars is presented at the end.
</bodyText>
<sectionHeader confidence="0.996789" genericHeader="keywords">
1 Descriptions
</sectionHeader>
<bodyText confidence="0.99970245">
The logic of typed feature structures (Carpenter,
1992) has been widely used as a means of formal-
izing and developing natural language grammars,
notably in Head-driven Phrase Structure Gram-
mar (Pollard and Sag, 1994). These grammars
are stated using a vocabulary consisting of a fi-
nite meet semi-lattice of types and a set of fea-
tures that must be specified for each grammar, and
this vocabulary must obey certain rules. A set of
appropriateness conditions must specify, for each
feature, which types of feature structures may bear
it, and which types of values it may take. Unique
feature introduction states that every feature has a
least type that bears it, called its introducer. The
effect of these rules is that typed feature structures
(TFSs) can be described using a very terse descrip-
tion language. A TFS that matches the description
NUMBER : singular, for example, might implic-
itly be of a type index, which introduces NUMBER.
From that, we can deduce that the TFS also bears
values for PERSON and GENDER, with particular
appropriate values, because those features are in-
troduced by the same type. Terse descriptions al-
low us to work with very large TFSs conveniently.
Given this basic vocabulary, descriptions can be
used in implicational constraints that encode prin-
ciples of grammar. These are often restricted to
the form T 0, where T is a type, and 0 is a
description. They also appear in several control
strategies that are used to combine TFSs, such as
extended phrase structure rules for parsing or gen-
eration (Wintner, 1997; Malouf et al., 2000), or
resolution with a Prolog-like relational language
(Carpenter and Penn, 1996; Makino et al., 1998).
While description languages vary, they are usu-
ally restricted to a subset of the following:
Definition: The set of descriptions over a count-
able set of types, T, a finite set of features, Feat,
and a countable set of variables, Var, is the small-
est set Desc that contains:
</bodyText>
<listItem confidence="0.999922">
• Var,
• zX,allXE Var,
• T,
• 7F : all 71 E Feat*, 0 E Desc, and
• A V), V 11), all 0,&apos;O E Desc.
</listItem>
<bodyText confidence="0.9059945">
Variables are used to enforce sharing of struc-
ture among substructures, and are often used with
</bodyText>
<page confidence="0.99615">
275
</page>
<bodyText confidence="0.999965">
wider scope than a single TFS to pass structure —
for example, from daughter categories to mother
categories in phrase structure rules or between ar-
guments in definite clause relations. With inequa-
tions X), they can also be used to prohibit
structure sharing. Preceding a description with a
feature path, 7r, causes that description to be en-
forced on the substructure at the end of that path.
</bodyText>
<sectionHeader confidence="0.532971" genericHeader="introduction">
2 Types as Modes
</sectionHeader>
<bodyText confidence="0.999928368421052">
What makes descriptions so terse, and what distin-
guishes the logic of typed feature structures from
more general order-sorted terms or record struc-
tures, is their strong notion of typing. Types intro-
duce features, types determine the arity (number
of features) of a TFS, types are the antecedents
to grammar constraints and types are what nor-
mally determine unifiability through the existence
of least upper bounds.
A similar situation exists in Prolog. The functor
and arity of a Prolog term characterize the number
of arguments, the interpretation of the argument
positions (which, unlike TFSs, are unnamed), and
the unifiability of the term with other Prolog terms.
In Prolog, however, a term has one of two de-
grees of instantiation — either its functor/arity is
not known (variable), or it is (instantiated term).
Advanced Prolog compilers use this information
where available to generate faster code for both
kinds of arguments. This is called mode, because
the degree of instantiation often corresponds to
whether an argument is being used operationally
as &amp;quot;input&amp;quot; or &amp;quot;output&amp;quot; to a Prolog predicate.
To date, TFS-based parsers and logic program-
ming systems have relied on the potential terse-
ness of descriptions for efficiency in enforcing
them. It is possible, however, to use informa-
tion about types derived from appropriateness and
knowledge of flow control in grammars/programs
as a kind of mode, only now with many more
shades of distinction. Figure 1 shows a sample
meet semi-lattice annotated with appropriateness
conditions. Features are shown annotating their
introducers, with the understanding that all sub-
types of the introducer bear those features as well.
Along with the feature name appears the type to
which the feature&apos;s value is restricted, called a
value restriction. The most general type, I (&amp;quot;bot-
</bodyText>
<figure confidence="0.900753833333333">
adj noun
CASE: case
nom acc plus minus subst
case bool head
PRD: bool
MOD: bool
</figure>
<figureCaption confidence="0.999921">
Figure 1: A sample type semi-lattice.
Figure 2: A type semi-lattice for Prolog terms.
</figureCaption>
<bodyText confidence="0.996461121212121">
tom&amp;quot;), corresponds to an uninstantiated variable,
but then there are potentially many degrees of suc-
cessive refinement. A _L-typed TFS could be in-
stantiated to a head-typed TFS, for example, at
which point we know it has two &amp;quot;arguments&amp;quot; for
the features PRD and MOD. But then it could be in-
stantiated further to a subst, and even further still
to a noun, at which point its arity increases by one
to accommodate the feature CASE. By contrast,
Prolog terms always appear in the same very flat
semi-lattice (Figure 2), in which what little inheri-
tance there is is determined structurally rather than
from named declarations.
Just as with Prolog, it is also possible to aug-
ment what we can statically infer from programs
with user-provided mode declarations. Even with
compilers that do not use them, mode declarations
are often recommended because they make pro-
grams more readable. In the case of typed fea-
ture logic, the correspondence to true input/output
mode is not as direct, and is probably better distin-
guished from mode in its typed sense. With def-
inite clauses over TFSs, for example, one would
expect to provide an input type and output type for
each argument in the general case:
:- mode append(list-list,list-list,
bot-list).
This declaration says that append/3 is called
with its first two arguments instantiated to type
list, and a third argument that might not be more
instantiated than I. Input is given by the first type
in each pair. Output is given by the second type —
in this case, all list-instantiated.
</bodyText>
<page confidence="0.996373">
276
</page>
<bodyText confidence="0.999972315789474">
Another possibility is to interpret mode as a
promise that a TFS will be no more instantiated
than, but still consistent with the type given. This
corresponds to viewing declared modes as great-
est elements in principal ideals of the type semi-
lattice, rather than as least elements of principal
filters. While both views could be exploited by a
compiler, unification promotes the type of a TFS
within its principal filter, so we would expect to
be able to provide useful mode information more
often with the filter view. With append/ 3, for
example, the first argument could be a list, or one
of its subtypes, ne-list and e-list, corresponding to
non-empty and empty lists, respectively.&apos;
These declarations will not be discussed further
here, as they simply serve to seed the description
compilation process below with initial mode val-
ues. What is more interesting is how mode is used
and updated within a description.
</bodyText>
<sectionHeader confidence="0.9815" genericHeader="method">
3 Descriptions as Compilable Objects
</sectionHeader>
<bodyText confidence="0.999841558139535">
One way to determine whether a given TFS
matches a description is to find the description&apos;s
most general satisfier, i.e., the least informa-
tive TFS in its denotation, and unify it with the
given TFS. This is typically too slow. TFS-
unification combines corresponding substructures
without making use of the fact that one of them
is a most general satisfier. By only combining
those parts of the TFSs that are explicitly men-
tioned in the description plus the types that can
be inferred from appropriateness, we avoid a great
deal of unnecessary work. TFS-unification must
also enumerate all possible most general satisfiers
in the case of disjunctive descriptions, but using
the description as a guide exploits the naturally lo-
calized non-determinism that users often provide,
thereby avoiding redundant unifications (Carpen-
ter and Penn, 1996).
There is a limit, however, to how terse a de-
scription can become. In part, this is due to the
fact that more verbose descriptions may be more
readable. With very large descriptions, in fact, it
may be quite difficult to find an optimally terse
equivalent. But even the description language it-
&apos; As useful idioms, one should also provide the declaration
type or +type as shorthand for type-type, and -type
for bot-type.
self imposes limits With respect to Figure 1, for
example, a purely compositional treatment of the
conjunctive description PRD : plus A MOD : plus
would enforce the requirement that the TFS is of
type head in both conjuncts. Once a given serial-
ization of this description&apos;s operations is chosen,
the mode of the candidate TFS can be tracked in-
ternally to generate more efficient code. In addi-
tion, descriptions with shared variables, such as
PRD : X A MOD : X can transmit mode informa-
tion through their variables from one substructure
to another. Tracking the modes of variables can be
particularly useful in languages where the scope of
variables extends over multiple TFSs, such as the
categories of a phrase structure rule — nothing in
appropriateness can provide a substitute.
</bodyText>
<sectionHeader confidence="0.945576" genericHeader="method">
4 Parameters of Compiler
</sectionHeader>
<bodyText confidence="0.999943833333333">
Compiling descriptions is already more efficient
than unifying with most general satisfiers, but
tracking mode (type) with both substructures and
variables makes it even more so. The compiler de-
scribed here uses Prolog as the target language,
but it should be obvious that any other internal
representation that supports unification with par-
tial templates of TFSs and the atomic operations
used below will suffice.
Our compiler requires six inputs: (1) the de-
scription to be compiled, (2) a TFS pointer that
points at run-time to the TFS that the description is
being enforced on, (3) the input mode of TFS, (4)
the input modes of previously seen variables, (5)
a description variable binding flag (CBS af e), and
(6) a template substitution flag (Temp1Subst).
If no input mode information is available for the
TFS at compile-time, the mode is taken to be I.
Previously unseen variables also have 1 as their
input mode. Seen variables are those variables
that may have been bound earlier in the code —
because of disjunctive descriptions, it not always
possible to say with certainty. CBSafe tells us
when it is safe to bind a description variable at
compile-time. This is generally true, with the ex-
ceptions being compilation of disjunctive descrip-
tions, in which the same variable used in one dis-
junct should not be bound by the other disjunct,
and compilation of co-routined predicates (such as
SICStus when/ 2), in which binding a description
</bodyText>
<page confidence="0.976444">
277
</page>
<bodyText confidence="0.999898512820513">
variable at compile-time in the delayed body could
transmit structure back into the guard.
The second flag, Temp1Subst, tells us
whether it is safe at compile-time to instantiate the
Prolog variable that implements the TFS pointer2
passed to the description compiler. Normally,
this should be true. With some kinds of descrip-
tion compilation, such as type-antecedent implica-
tional constraints, propagating templates from one
constraint into another at compile-time can often
create compile-time unification failures. Without
the right support for tracing where these failures
occur, they are better left to a run-time system.
Templates for us will be partial Prolog term en-
codings of TFSs. In general they are partial rep-
resentations of TFSs, in that by themselves they
may not look well-typed or even well-formed —
certain feature values might be missing or occur
with invalid types. In the context of a given in-
put mode, however, they will still be sufficient for
unifying with particular kinds of TFSs, and more
efficient than their well-formed, well-typed coun-
terparts. The outputs of our compiler are then: (1)
the TFS pointer, which now possibly points to a
template, (2) output modes for that pointer and any
variables seen so far, and (3) a stream of code that
should be executed at run-time on the TFS pointed
to by the TFS pointer, after it has been unified with
its template, if any.
In constructs for which variables have wider
scope than a single description, it is assumed that
descriptions will be compiled in the order estab-
lished by the model of control flow for that con-
struct. Compilation of a phrase structure rule
in a left-to-right bottom-up parser, for example,
would compile the daughter descriptions from left
to right, and finally the mother description. This
allows variable modes to be threaded from one de-
scription to the next.
</bodyText>
<sectionHeader confidence="0.965118" genericHeader="method">
5 Pre-processing
</sectionHeader>
<bodyText confidence="0.804797857142857">
Before compilation proper begins, we must con-
vert the input description to a canonical form. The
2Note that because we are compiling a description lan-
guage with variables into a target language (Prolog) with vari-
ables, we need to distinguish the two kinds. We will refer to
the target-language variables as pointers, since this is how
they are realized internally in the Wuren Abstract Machine.
</bodyText>
<equation confidence="0.716485222222222">
(list_synsem, append (L1, L2) ) ,
[Head I Tail]
(1) expansion of macros
(list_synsem, append (L1, L2) ) ,
(hd: Head, tl : Tail)
(2) left-regular conjunct transformation
list_synsem, (append (L1, L2) ,
(hd:Head, tl :Tail) )
(3) functional block segmentation
</equation>
<figureCaption confidence="0.863751666666667">
list_synsem I append (L1, L2) I
(hd: Head, tl : Tail)
Figure 3: Stages of Pre-processing.
</figureCaption>
<bodyText confidence="0.999932294117647">
major stages of pre-processing are given in Fig-
ure 3. In the example shown, a list macro is ex-
panded to its syntactic form as a TFS description,
but other user-defined macros may exist too. Con-
junction of descriptions translates during compila-
tion into continuations of code, so wherever pos-
sible, we would like to represent descriptions as
streams of (conjoined) subdescriptions that will
directly correspond to the streams of code we gen-
erate. Empirically, one can also observe that de-
scriptions tend to be highly conjunctive, so this
step can save quite a bit of time later. This as-
sociative reshuffling is disrupted by disjunctive,
inequational or path descriptions, whose internal
subdescriptions are also reshuffled but not com-
bined with their external contexts (that is, nothing
like DNF is computed).
Some description languages also have func-
tional or procedural extensions that extend beyond
the power of the normal description language and
may even perform I/O operations. Since our com-
piler will re-order many components of the input
description, it is important to preserve the order
in which these extensions occur relative to other
components of the description. So the third step
of pre-processing divides a description into func-
tional or non-functional blocks. Non-functional
blocks will be re-ordered internally, and mode will
be transmitted from one block to the next, but the
order of the blocks themselves must be preserved
in the generated code. Functional block compila-
tion is outside the scope of this paper.
The result of block compilation, apart
from an output mode, is one of three things:
</bodyText>
<page confidence="0.97491">
278
</page>
<figure confidence="0.9894505">
compile_desc (Desc, FS, CBSafe, Temp1Subst, Mode
Compile the blocks:
1. if the result is empty, return Code-Code.
2. if the result is tem-
plate (Template, TCode, Rest) :
(a) if Temp1Subst is true, then bind the TFS
pointer, FS=Template and return TCode-Rest
(b) else return [FS=Template I TCode ] -Rest.
3. if the result is var (FS, Code, Rest) , then return
Code-Rest.
</figure>
<figureCaption confidence="0.847432666666667">
4. if the result is failure, then return fail-Rest with an
output mode of top (T).
Figure 4: The top-level description compiler.
</figureCaption>
<bodyText confidence="0.9687192">
empty, meaning that the description is re-
dundant with the given input mode, tem-
plate (Templ, Code, Rest) , meaning
there is a template with code stream Code-
Rest encoded as a difference list, and
var (Pt r , Code, Rest ) , meaning there is
no template — only the TFS pointer. Top-level
description compilation is shown in Figure 4.
Depending on the value of the Temp1Subs t
flag, the TFS pointer, FS, is instantiated to a
template, if one exists, either at compile-time, or
at run-time by adding a unify instruction to the
front of the code stream. The blocks compiler
threads together code from individual blocks in a
similar fashion given the results on each block.
</bodyText>
<sectionHeader confidence="0.98041" genericHeader="method">
6 Block Compilation
</sectionHeader>
<bodyText confidence="0.999791875">
The first step of block compilation is then to par-
tition top-level conjuncts into their kind of de-
scription. These classes are then compiled sepa-
rately, and their code is threaded together in this
order: (1) seen variables, (2) type, (3) unseen
variables, (4) feature descriptions, (5) inequation
descriptions, and (6) disjunctive descriptions. The
order has been chosen according to the extent to
which each class can deterministically and quicldy
produce a failure. Those that potentially can very
well, such as types, occur early in the thread in or-
der to avoid wasting time on the code of the others.
This is admittedly rather naive, since unification
with a seen variable or a type could result in apply-
ing a highly disjunctive constraint that is not con-
sidered here. In addition, small non-disjunctive
) feature descriptions could be much quicker than
unification with a large TFS to which a seen vari-
able is instantiated. The right way to determine
this order is through empirical estimation of the
likelihood of failure. This problem, in fact, is
closely related to the general indexing problem for
TFSs and to that of quick-check paths for early de-
tection of unification failure (Malouf et al., 2000).
The last three classes have subdescriptions.
These are recursively block-segmented, pre-
processed and compiled using the same partition-
ing method. Nothing more needs to be said about
the inequation and disjunctive classes.
The type in the type class is computed by unify-
ing: (1) all of the type descriptions in the current
block, (2) all of the introducers of the feature de-
scriptions in the block, and (3) the meet (greatest
lower bound) in each disjunctive description of the
type class of each of its disjuncts. In other words,
we are extracting as much type information as we
deterministically can from all but one class in the
current block and applying it first. We do not in-
clude the input modes of variables because unifi-
cation will add the type information in these au-
tomatically, as well as enforce any necessary im-
plicational constraints. The type class contains the
type information that we may need to enforce con-
straints on ourselves.
The output mode of the TFS pointer is this type
unified with the input mode and the input modes
of the seen variables. Note that while code for the
type class is among the first to be executed at run-
time, it must be the last generated at compile-time.
Variables (seen or unseen) either bind to the
TFS pointer at compile-time or generate code to
bind the variable at run-time according to the value
of CBSafe. Variable modes are updated by unifi-
cation with the TFS pointer&apos;s output mode.
When feature descriptions are collected in a
block, they are also further partitioned by the first
feature in their paths and compiled together so that
the value at that feature only needs to be deref-
erenced once (at least for feature descriptions).
Conveniently enough, appropriateness provides us
with an input mode for our recursive compilation
of a feature&apos;s descriptions — namely the value re-
striction of that feature at the TFS pointer&apos;s out-
put mode. This is everything we will know about
</bodyText>
<page confidence="0.995637">
279
</page>
<bodyText confidence="0.9970615">
this feature&apos;s value after executing the code for the
type class.
</bodyText>
<sectionHeader confidence="0.967928" genericHeader="method">
7 Combining Class Information
</sectionHeader>
<bodyText confidence="0.998962818181818">
The last step of block compilation is then to com-
bine the results of compiling each class to generate
the minimal amount of code. There are three cases
to consider here, which refer both to the output
of class compilation and to a relation defined by
where implicational constraints occur in the type
semi-lattice. That relation is defined as follows:
Definition: A type, T, is relatively constrained by
a mode ft if there exists a a II p which is unifi-
able with 7- and a p such that pETH a, p a,
and there is an implicational constraint p ch for
some description 0.
If we add T to a TFS pointer with input mode p,
then under the filter view of mode, we might need
to enforce some constraint on the resulting TFS if
7- is relatively constrained by jt. Since seen vari-
ables are unified before type class information is
added, we can actually take p to be the input mode
unified with the input modes of the seen variables
instead. This will possibly result in a smaller filter,
and therefore possibly fewer constraints to add.
Case 1: T Pp and all feature descriptions
compile to empty. In this case, the type and
features add no new information. If no run-time
code is added by variables, inequations or disjunc-
tions either, then we can return empty. Other-
wise, we can thread the code together, and return
var (Ptr, Code, Rest) ,where Ptr is the cur-
rent TFS pointer.
Case 2: T is relatively constrained by p. In this
case, we must add the type using code, so that
constraints can be enforced if necessary at run-
time. This is actually the case we want to avoid,
but unless p = T, there is no guarantee that any
particular constraint will definitely be required, so
nothing else should be done at compile-time. All
TFS-based abstract machines possess a primitive
operation for this. In the Carpenter-Qu machine
(implemented in LiLFeS (Makino et al., 1998)), it
is addtype. AMALIA (Wintner, 1997) and ALE
(Carpenter and Penn, 1996) have something sim-
ilar. This instruction must then be threaded with
the code generated by other classes.
Case 3: Otherwise. In this case, we should try
to do as much work as possible in a template. If
feature descriptions, inequation descriptions and
disjunctive descriptions generate no code, then we
can do all of the work in a template. If they do
generate code, then we can still build a template,
but we should instantiate the TFS pointer with it at
run-time to avoid propagating the template&apos;s struc-
ture through the generated code at compile-time.
This would result in an unnecessary amount of ex-
tra structure in the code stream, and therefore extra
work at run-time.
In Prolog, our templates look like terms
f (Type, Fl, . , En), where Type is a term
encoding of the type, given by one of several first-
order encodings available for meet semi-lattices
(Mellish, 1992; Penn, 2000), and the Fi are en-
codings of appropriate features. f is determined
by a modularization algorithm that breaks a semi-
lattice into inconsistent pieces that can be encoded
separately. n, the number of feature positions,
is determined by a graph coloring algorithm on
that module that finds the minimum number of re-
quired positions (Penn, 2000). Unused positions
are left as variables, and in general a description
compiler must be prepared to fill those variables
in once a TFS becomes specific enough to employ
them (Penn, 2002). TFS-based abstract machines
can construct a similar fixed-width encoding.
The term encoding of T should fill the Type
position. It only needs to be filled with those
parts of the term encoding that the encoding of
it lacks, however. Filling the type position is not
the only requirement for adding a type with a
template, however. When we add a type, new
features may be introduced and value restrictions
may be refined, requiring extra structure to be
added in an argument position. At the same time,
feature descriptions may demand to use those
positions as TFS pointers for compiled code. The
algorithm for combining these requirements is
given below. We initially call the algorithm by
first allocating our Template, and then calling
build_template(r,p,€,Tempiate), where e is
the empty path.
</bodyText>
<footnote confidence="0.67970375">
build_template(7,pjr,Template)
TypePos( Template) := TEncoding(T, p)
For each feature F appropriate to T:
1. If VR(F, T) L VR(F, or VR(F, T)
</footnote>
<page confidence="0.979863">
280
</page>
<figure confidence="0.967862333333333">
VR(F, Intro(F)):
(a) If FRes (7r, F) =empty, then continue.
(b) If FRes(7r, F) =template (FTem, Code, Rest ) :
</figure>
<listItem confidence="0.792922761904762">
• Pos(Template, F) :=FTem,
• add Code—Rest to code stream,
• and continue.
(c) otherwise FRes(7r, F) =var (FV, Code, Rest) :
• Pos(Template, F) :=FV,
• add Code—Rest to code stream,
• and continue.
2. If VR(F, 7-) is relatively constrained by VR(F, p):
add an addt ype (VR(F, r)) instruction to the code
stream,
(a) If FRes (7r, F) =empty, then continue.
(b) If FRes(7r, F) =template (FTem, Code, Rest ) :
• Pos(Template, F) :=FV,
• add [FV=FTem I Code] —Rest to the code
stream,
• and continue.
(c) otherwise FRes(7c, F) =var (FV, Code, Rest) :
• Pos(Template, F) :=FV,
• add Code—Rest to the code stream,
• and continue.
3. otherwise:
</listItem>
<figure confidence="0.94109125">
allocate a new template, FTemplate,
(a) If FRes(7r, F) =empty, then
Pos( Template, F) :=FTemplate,
(b) If FRes(7r, F) =template (FTem, Code, Rest
</figure>
<listItem confidence="0.9674405">
• Pos(Template, F) :=FV,
• call build_template(VR(F, T),VR(F, p),
it : F,FTernplate), which returns code stream
FCode-FRest,
• add [FV=FTemplate I FCode] -FRest to
the code stream,
• add [FV=FTem I Code] —Rest to the code
stream,
• and continue.
(c) otherwise FRes(7r, F) =var (FV, Code, Rest) :
• Pos(Template, F) :=FV,
• call build_template(VR(F, T),VR(F, p),
it : F,FTemplate), which returns code stream
FCode-FRest,
• add [FV=FTemplate I FCode] -FRest to
the code stream,
• and Code—Rest to the code stream,
• and continue.
</listItem>
<subsectionHeader confidence="0.442784">
Return the code stream.
</subsectionHeader>
<bodyText confidence="0.9999835">
Here, FRes(7, F) is the result of compiling the
feature descriptions at path 7F : F, VR(F ,t) is the
value restriction of feature F at type t, Intro(F)
is the introducer of F, TEncoding(T, /1) is the
portion of the term encoding of T that the term
encoding of ia lacks, TypePos( Template) is the
position of the type encoding in Template, and
Pos(Template, F) is the position for F in Tem-
plate. The first case determines that the added type
does not need the position for F, and allows the
feature descriptions to use it. The second case de-
termines that the added type does need the posi-
tion for F as a variable so that it can make an ad-
dt ype call in the code stream to add a constraint.
That means that we can use a template in that po-
sition, but we must instantiate it at run-time, since
otherwise the template would propagate through
the run-time code. The third case determines that
the added type needs the position for adding ap-
propriateness information. This appropriateness
information is added using a new template, FTem-
plate, in each feature position that requires it. A
recursive call is also made to fill in the feature po-
sitions of FTemplate.
</bodyText>
<sectionHeader confidence="0.997409" genericHeader="conclusions">
8 Evaluation
</sectionHeader>
<footnote confidence="0.607685">
3The small size of the suite is due to the fact that only a
small part of the ERG lexicon had been converted as of this
writing.
</footnote>
<bodyText confidence="0.999970357142857">
To test the effectiveness of this mode-sensitive
compiler, it was implemented to replace ALE 3.3&apos;s
compiler and measured against the old one on
parsing with two grammars All other components
of the system were identical. Neither grammar has
mode declarations for relations, so only the ben-
) efit of internal mode tracking is measured here.
The first grammar is a version of the original En-
glish Resource Grammar (ERG, 1999), ported to
ALE and modified by Kordula DeKuthy and Det-
mar Meurers of Ohio State University to use fewer
types. Compilation times with the two compilers
were roughly the same. The generated code was
run over a test suite distributed with this version
of 61 sentences, 41 of them grammatical.3 For
both versions of code, the suite was parsed in or-
der 5 times and the times for each sentence were
averaged to control for variations in system load.
Those averages are plotted in Figure 5. Sentences
are ordered by average parse time with the new
mode-sensitive compiler. The code generated by
this compiler parses sentences in this test suite on
an average of 41.8% less time, with a minimum
of 36.5% less, and a maximum of 50.7%. On an
absolute basis, the new compiler&apos;s code parses an
average of 541 ms faster, with a minimum of 34
ms and a maximum of 9082 ms.
The second grammar is the HPSG gram-
</bodyText>
<page confidence="0.895929">
281
</page>
<bodyText confidence="0.9602592">
10000 and a maximum of 81,952 ms. The smaller aver-
1000 age reduction and larger variability are both likely
100 due to the greater modularity of the grammar.
9 Conclusion
Using modes plus reordering description contents
has been shown to measurably improve parse
times on two grammars. The best way to find a re-
ordering is of course to profile the input grammar
on representative data to gather such information
empirically.
</bodyText>
<figure confidence="0.960669">
10 20 30 40 50 60
</figure>
<figureCaption confidence="0.90404">
Figure 5: Average parse times (in ms) for ALE
compiled code with and without modes on the
ERG test suite.
</figureCaption>
<bodyText confidence="0.999895727272727">
mar distributed with ALE. This grammar and
was designed to be a literal translation of
Pollard and Sag (1994). It has many more rela-
tions, applies more descriptions at run-time, and is
far less efficient. It was benchmarked on 274 sen-
tences randomly selected from a larger test suite
that was automatically generated by a context-free
grammar with the same lexicon. The grammar
found 80% of the sample to be grammatical. The
same protocol as above was used. The results are
shown in Figure 6. Here, the average reduction
</bodyText>
<figure confidence="0.965252333333333">
10000
1000
I 00
</figure>
<figureCaption confidence="0.853127">
Figure 6: Average parse times (in ms) for ALE
compiled code with and without modes on an
HPSG test suite.
</figureCaption>
<bodyText confidence="0.999655333333333">
in parse time is 28.9%, with a minimum of 17.3%
and a maximum of 99.6%. The average absolute
reduction was 497 ms with a minimum of 10 ms,
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996106470588236">
B. Carpenter and G. Penn. 1996. Compiling typed
attribute-value logic grammars. In H. Bunt and
M. Tomita, editors, Recent Advances in Parsing
Technologies, pages 145-168. Kluwer.
B. Carpenter. 1992. The Logic of Typed Feature Struc-
tures. Cambridge.
ERG. 1999. The English Resource Grammar and lexi-
con. Available on-line at http://lingo.stanford.edu.
T. Makino, K. Torisawa, and J. Tsuji. 1998. LiLFeS —
practical unification-based programming system for
typed feature structures. In Proceedings of the 36th
Annual Meeting of the Association for Computa-
tional Linguistics and the 17th International Confer-
ence on Computational Linguistics (COLING/ACL-
98), volume 2, pages 807-811.
R. Malouf, J. Carroll, and A. Copestake. 2000. Effi-
cient feature structure operations without compila-
tion. Natural Language Engineering, 6(1 ):29-46.
C. Mellish. 1992. Term-encodable description spaces.
In D.R. Brough, editor, Logic Programming: New
Frontiers, pages 189-207. Kluwer.
G. Penn. 2000. The Algebraic Structure of Attributed
Type Signatures. Ph.D. thesis, Carnegie Mellon
University.
G. Penn. 2002. Generalized encoding of description
spaces and its application to typed feature structures.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics (ACL-02),
pages 64-71.
C. Pollard and I. Sag. 1994. Head-driven Phrase
Structure Grammar. Chicago.
S. Wintner. 1997. An Abstract Machine for Unification
Grammars with Applications to an HPSG Grammar
fbr Hebrew. Ph.D. thesis, Technion.
</reference>
<figure confidence="0.862882666666667">
NO MODE
MODE
50 100 150 200 250
</figure>
<page confidence="0.954986">
282
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.804685">
<title confidence="0.999779">AVM Description Compilation using Types as Modes</title>
<author confidence="0.999895">Gerald Penn</author>
<affiliation confidence="0.9999655">Department of Computer Science University of Toronto</affiliation>
<email confidence="0.999795">gpenn@cs.toronto.edu</email>
<abstract confidence="0.991042161290323">This paper provides a method for generating compact and efficient code to implement the enforcement of a description in typed feature logic. It does so by viewing information about types through the course of code generation as modes of instantiation — a generalization of the common practice in logic programming of the hi nary instantiated/variable mode decl arations that advanced Prolog compilers use. Section 1 introduces the description language. Sections 2 and 3 motivate the view of mode and compilation taken here, and outline a mode declaration language for typed feature logic. Sections 4 through 7 then present the compiler. An evaluation on two grammars is presented at the end. 1 Descriptions The logic of typed feature structures (Carpenter, 1992) has been widely used as a means of formalizing and developing natural language grammars, notably in Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). These grammars are stated using a vocabulary consisting of a finite meet semi-lattice of types and a set of features that must be specified for each grammar, and this vocabulary must obey certain rules. A set of conditions specify, for each feature, which types of feature structures may bear and which types of values it may take.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Carpenter</author>
<author>G Penn</author>
</authors>
<title>Compiling typed attribute-value logic grammars.</title>
<date>1996</date>
<booktitle>Recent Advances in Parsing Technologies,</booktitle>
<pages>145--168</pages>
<editor>In H. Bunt and M. Tomita, editors,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="2495" citStr="Carpenter and Penn, 1996" startWordPosition="407" endWordPosition="410"> particular appropriate values, because those features are introduced by the same type. Terse descriptions allow us to work with very large TFSs conveniently. Given this basic vocabulary, descriptions can be used in implicational constraints that encode principles of grammar. These are often restricted to the form T 0, where T is a type, and 0 is a description. They also appear in several control strategies that are used to combine TFSs, such as extended phrase structure rules for parsing or generation (Wintner, 1997; Malouf et al., 2000), or resolution with a Prolog-like relational language (Carpenter and Penn, 1996; Makino et al., 1998). While description languages vary, they are usually restricted to a subset of the following: Definition: The set of descriptions over a countable set of types, T, a finite set of features, Feat, and a countable set of variables, Var, is the smallest set Desc that contains: • Var, • zX,allXE Var, • T, • 7F : all 71 E Feat*, 0 E Desc, and • A V), V 11), all 0,&apos;O E Desc. Variables are used to enforce sharing of structure among substructures, and are often used with 275 wider scope than a single TFS to pass structure — for example, from daughter categories to mother categori</context>
<context position="8713" citStr="Carpenter and Penn, 1996" startWordPosition="1446" endWordPosition="1450">y too slow. TFSunification combines corresponding substructures without making use of the fact that one of them is a most general satisfier. By only combining those parts of the TFSs that are explicitly mentioned in the description plus the types that can be inferred from appropriateness, we avoid a great deal of unnecessary work. TFS-unification must also enumerate all possible most general satisfiers in the case of disjunctive descriptions, but using the description as a guide exploits the naturally localized non-determinism that users often provide, thereby avoiding redundant unifications (Carpenter and Penn, 1996). There is a limit, however, to how terse a description can become. In part, this is due to the fact that more verbose descriptions may be more readable. With very large descriptions, in fact, it may be quite difficult to find an optimally terse equivalent. But even the description language it&apos; As useful idioms, one should also provide the declaration type or +type as shorthand for type-type, and -type for bot-type. self imposes limits With respect to Figure 1, for example, a purely compositional treatment of the conjunctive description PRD : plus A MOD : plus would enforce the requirement tha</context>
<context position="21981" citStr="Carpenter and Penn, 1996" startWordPosition="3691" endWordPosition="3694">rn var (Ptr, Code, Rest) ,where Ptr is the current TFS pointer. Case 2: T is relatively constrained by p. In this case, we must add the type using code, so that constraints can be enforced if necessary at runtime. This is actually the case we want to avoid, but unless p = T, there is no guarantee that any particular constraint will definitely be required, so nothing else should be done at compile-time. All TFS-based abstract machines possess a primitive operation for this. In the Carpenter-Qu machine (implemented in LiLFeS (Makino et al., 1998)), it is addtype. AMALIA (Wintner, 1997) and ALE (Carpenter and Penn, 1996) have something similar. This instruction must then be threaded with the code generated by other classes. Case 3: Otherwise. In this case, we should try to do as much work as possible in a template. If feature descriptions, inequation descriptions and disjunctive descriptions generate no code, then we can do all of the work in a template. If they do generate code, then we can still build a template, but we should instantiate the TFS pointer with it at run-time to avoid propagating the template&apos;s structure through the generated code at compile-time. This would result in an unnecessary amount of</context>
</contexts>
<marker>Carpenter, Penn, 1996</marker>
<rawString>B. Carpenter and G. Penn. 1996. Compiling typed attribute-value logic grammars. In H. Bunt and M. Tomita, editors, Recent Advances in Parsing Technologies, pages 145-168. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures.</title>
<date>1992</date>
<location>Cambridge.</location>
<contexts>
<context position="906" citStr="Carpenter, 1992" startWordPosition="143" endWordPosition="144">es so by viewing information about types through the course of code generation as modes of instantiation — a generalization of the common practice in logic programming of the hi nary instantiated/variable mode decl arations that advanced Prolog compilers use. Section 1 introduces the description language. Sections 2 and 3 motivate the view of mode and compilation taken here, and outline a mode declaration language for typed feature logic. Sections 4 through 7 then present the compiler. An evaluation on two grammars is presented at the end. 1 Descriptions The logic of typed feature structures (Carpenter, 1992) has been widely used as a means of formalizing and developing natural language grammars, notably in Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). These grammars are stated using a vocabulary consisting of a finite meet semi-lattice of types and a set of features that must be specified for each grammar, and this vocabulary must obey certain rules. A set of appropriateness conditions must specify, for each feature, which types of feature structures may bear it, and which types of values it may take. Unique feature introduction states that every feature has a least type that bear</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>B. Carpenter. 1992. The Logic of Typed Feature Structures. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ERG</author>
</authors>
<title>The English Resource Grammar and lexicon. Available on-line at http://lingo.stanford.edu.</title>
<date>1999</date>
<contexts>
<context position="27505" citStr="ERG, 1999" startWordPosition="4645" endWordPosition="4646"> fill in the feature positions of FTemplate. 8 Evaluation 3The small size of the suite is due to the fact that only a small part of the ERG lexicon had been converted as of this writing. To test the effectiveness of this mode-sensitive compiler, it was implemented to replace ALE 3.3&apos;s compiler and measured against the old one on parsing with two grammars All other components of the system were identical. Neither grammar has mode declarations for relations, so only the ben) efit of internal mode tracking is measured here. The first grammar is a version of the original English Resource Grammar (ERG, 1999), ported to ALE and modified by Kordula DeKuthy and Detmar Meurers of Ohio State University to use fewer types. Compilation times with the two compilers were roughly the same. The generated code was run over a test suite distributed with this version of 61 sentences, 41 of them grammatical.3 For both versions of code, the suite was parsed in order 5 times and the times for each sentence were averaged to control for variations in system load. Those averages are plotted in Figure 5. Sentences are ordered by average parse time with the new mode-sensitive compiler. The code generated by this compi</context>
</contexts>
<marker>ERG, 1999</marker>
<rawString>ERG. 1999. The English Resource Grammar and lexicon. Available on-line at http://lingo.stanford.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Makino</author>
<author>K Torisawa</author>
<author>J Tsuji</author>
</authors>
<title>LiLFeS — practical unification-based programming system for typed feature structures.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING/ACL98),</booktitle>
<volume>2</volume>
<pages>807--811</pages>
<contexts>
<context position="2517" citStr="Makino et al., 1998" startWordPosition="411" endWordPosition="414">lues, because those features are introduced by the same type. Terse descriptions allow us to work with very large TFSs conveniently. Given this basic vocabulary, descriptions can be used in implicational constraints that encode principles of grammar. These are often restricted to the form T 0, where T is a type, and 0 is a description. They also appear in several control strategies that are used to combine TFSs, such as extended phrase structure rules for parsing or generation (Wintner, 1997; Malouf et al., 2000), or resolution with a Prolog-like relational language (Carpenter and Penn, 1996; Makino et al., 1998). While description languages vary, they are usually restricted to a subset of the following: Definition: The set of descriptions over a countable set of types, T, a finite set of features, Feat, and a countable set of variables, Var, is the smallest set Desc that contains: • Var, • zX,allXE Var, • T, • 7F : all 71 E Feat*, 0 E Desc, and • A V), V 11), all 0,&apos;O E Desc. Variables are used to enforce sharing of structure among substructures, and are often used with 275 wider scope than a single TFS to pass structure — for example, from daughter categories to mother categories in phrase structure</context>
<context position="21906" citStr="Makino et al., 1998" startWordPosition="3679" endWordPosition="3682">can return empty. Otherwise, we can thread the code together, and return var (Ptr, Code, Rest) ,where Ptr is the current TFS pointer. Case 2: T is relatively constrained by p. In this case, we must add the type using code, so that constraints can be enforced if necessary at runtime. This is actually the case we want to avoid, but unless p = T, there is no guarantee that any particular constraint will definitely be required, so nothing else should be done at compile-time. All TFS-based abstract machines possess a primitive operation for this. In the Carpenter-Qu machine (implemented in LiLFeS (Makino et al., 1998)), it is addtype. AMALIA (Wintner, 1997) and ALE (Carpenter and Penn, 1996) have something similar. This instruction must then be threaded with the code generated by other classes. Case 3: Otherwise. In this case, we should try to do as much work as possible in a template. If feature descriptions, inequation descriptions and disjunctive descriptions generate no code, then we can do all of the work in a template. If they do generate code, then we can still build a template, but we should instantiate the TFS pointer with it at run-time to avoid propagating the template&apos;s structure through the ge</context>
</contexts>
<marker>Makino, Torisawa, Tsuji, 1998</marker>
<rawString>T. Makino, K. Torisawa, and J. Tsuji. 1998. LiLFeS — practical unification-based programming system for typed feature structures. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING/ACL98), volume 2, pages 807-811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malouf</author>
<author>J Carroll</author>
<author>A Copestake</author>
</authors>
<title>Efficient feature structure operations without compilation.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>29--46</pages>
<contexts>
<context position="2415" citStr="Malouf et al., 2000" startWordPosition="396" endWordPosition="399">at, we can deduce that the TFS also bears values for PERSON and GENDER, with particular appropriate values, because those features are introduced by the same type. Terse descriptions allow us to work with very large TFSs conveniently. Given this basic vocabulary, descriptions can be used in implicational constraints that encode principles of grammar. These are often restricted to the form T 0, where T is a type, and 0 is a description. They also appear in several control strategies that are used to combine TFSs, such as extended phrase structure rules for parsing or generation (Wintner, 1997; Malouf et al., 2000), or resolution with a Prolog-like relational language (Carpenter and Penn, 1996; Makino et al., 1998). While description languages vary, they are usually restricted to a subset of the following: Definition: The set of descriptions over a countable set of types, T, a finite set of features, Feat, and a countable set of variables, Var, is the smallest set Desc that contains: • Var, • zX,allXE Var, • T, • 7F : all 71 E Feat*, 0 E Desc, and • A V), V 11), all 0,&apos;O E Desc. Variables are used to enforce sharing of structure among substructures, and are often used with 275 wider scope than a single </context>
<context position="18021" citStr="Malouf et al., 2000" startWordPosition="2996" endWordPosition="2999"> of the others. This is admittedly rather naive, since unification with a seen variable or a type could result in applying a highly disjunctive constraint that is not considered here. In addition, small non-disjunctive ) feature descriptions could be much quicker than unification with a large TFS to which a seen variable is instantiated. The right way to determine this order is through empirical estimation of the likelihood of failure. This problem, in fact, is closely related to the general indexing problem for TFSs and to that of quick-check paths for early detection of unification failure (Malouf et al., 2000). The last three classes have subdescriptions. These are recursively block-segmented, preprocessed and compiled using the same partitioning method. Nothing more needs to be said about the inequation and disjunctive classes. The type in the type class is computed by unifying: (1) all of the type descriptions in the current block, (2) all of the introducers of the feature descriptions in the block, and (3) the meet (greatest lower bound) in each disjunctive description of the type class of each of its disjuncts. In other words, we are extracting as much type information as we deterministically c</context>
</contexts>
<marker>Malouf, Carroll, Copestake, 2000</marker>
<rawString>R. Malouf, J. Carroll, and A. Copestake. 2000. Efficient feature structure operations without compilation. Natural Language Engineering, 6(1 ):29-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Mellish</author>
</authors>
<title>Term-encodable description spaces.</title>
<date>1992</date>
<booktitle>Logic Programming: New Frontiers,</booktitle>
<pages>189--207</pages>
<editor>In D.R. Brough, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="22854" citStr="Mellish, 1992" startWordPosition="3844" endWordPosition="3845">ive descriptions generate no code, then we can do all of the work in a template. If they do generate code, then we can still build a template, but we should instantiate the TFS pointer with it at run-time to avoid propagating the template&apos;s structure through the generated code at compile-time. This would result in an unnecessary amount of extra structure in the code stream, and therefore extra work at run-time. In Prolog, our templates look like terms f (Type, Fl, . , En), where Type is a term encoding of the type, given by one of several firstorder encodings available for meet semi-lattices (Mellish, 1992; Penn, 2000), and the Fi are encodings of appropriate features. f is determined by a modularization algorithm that breaks a semilattice into inconsistent pieces that can be encoded separately. n, the number of feature positions, is determined by a graph coloring algorithm on that module that finds the minimum number of required positions (Penn, 2000). Unused positions are left as variables, and in general a description compiler must be prepared to fill those variables in once a TFS becomes specific enough to employ them (Penn, 2002). TFS-based abstract machines can construct a similar fixed-w</context>
</contexts>
<marker>Mellish, 1992</marker>
<rawString>C. Mellish. 1992. Term-encodable description spaces. In D.R. Brough, editor, Logic Programming: New Frontiers, pages 189-207. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Penn</author>
</authors>
<title>The Algebraic Structure of Attributed Type Signatures.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="22867" citStr="Penn, 2000" startWordPosition="3846" endWordPosition="3847">s generate no code, then we can do all of the work in a template. If they do generate code, then we can still build a template, but we should instantiate the TFS pointer with it at run-time to avoid propagating the template&apos;s structure through the generated code at compile-time. This would result in an unnecessary amount of extra structure in the code stream, and therefore extra work at run-time. In Prolog, our templates look like terms f (Type, Fl, . , En), where Type is a term encoding of the type, given by one of several firstorder encodings available for meet semi-lattices (Mellish, 1992; Penn, 2000), and the Fi are encodings of appropriate features. f is determined by a modularization algorithm that breaks a semilattice into inconsistent pieces that can be encoded separately. n, the number of feature positions, is determined by a graph coloring algorithm on that module that finds the minimum number of required positions (Penn, 2000). Unused positions are left as variables, and in general a description compiler must be prepared to fill those variables in once a TFS becomes specific enough to employ them (Penn, 2002). TFS-based abstract machines can construct a similar fixed-width encoding</context>
</contexts>
<marker>Penn, 2000</marker>
<rawString>G. Penn. 2000. The Algebraic Structure of Attributed Type Signatures. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Penn</author>
</authors>
<title>Generalized encoding of description spaces and its application to typed feature structures.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02),</booktitle>
<pages>64--71</pages>
<contexts>
<context position="23393" citStr="Penn, 2002" startWordPosition="3933" endWordPosition="3934">ral firstorder encodings available for meet semi-lattices (Mellish, 1992; Penn, 2000), and the Fi are encodings of appropriate features. f is determined by a modularization algorithm that breaks a semilattice into inconsistent pieces that can be encoded separately. n, the number of feature positions, is determined by a graph coloring algorithm on that module that finds the minimum number of required positions (Penn, 2000). Unused positions are left as variables, and in general a description compiler must be prepared to fill those variables in once a TFS becomes specific enough to employ them (Penn, 2002). TFS-based abstract machines can construct a similar fixed-width encoding. The term encoding of T should fill the Type position. It only needs to be filled with those parts of the term encoding that the encoding of it lacks, however. Filling the type position is not the only requirement for adding a type with a template, however. When we add a type, new features may be introduced and value restrictions may be refined, requiring extra structure to be added in an argument position. At the same time, feature descriptions may demand to use those positions as TFS pointers for compiled code. The al</context>
</contexts>
<marker>Penn, 2002</marker>
<rawString>G. Penn. 2002. Generalized encoding of description spaces and its application to typed feature structures. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02), pages 64-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<date>1994</date>
<booktitle>Head-driven Phrase Structure Grammar.</booktitle>
<location>Chicago.</location>
<contexts>
<context position="1067" citStr="Pollard and Sag, 1994" startWordPosition="167" endWordPosition="170"> programming of the hi nary instantiated/variable mode decl arations that advanced Prolog compilers use. Section 1 introduces the description language. Sections 2 and 3 motivate the view of mode and compilation taken here, and outline a mode declaration language for typed feature logic. Sections 4 through 7 then present the compiler. An evaluation on two grammars is presented at the end. 1 Descriptions The logic of typed feature structures (Carpenter, 1992) has been widely used as a means of formalizing and developing natural language grammars, notably in Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). These grammars are stated using a vocabulary consisting of a finite meet semi-lattice of types and a set of features that must be specified for each grammar, and this vocabulary must obey certain rules. A set of appropriateness conditions must specify, for each feature, which types of feature structures may bear it, and which types of values it may take. Unique feature introduction states that every feature has a least type that bears it, called its introducer. The effect of these rules is that typed feature structures (TFSs) can be described using a very terse description language. A TFS th</context>
<context position="29062" citStr="Pollard and Sag (1994)" startWordPosition="4922" endWordPosition="4925">e smaller aver1000 age reduction and larger variability are both likely 100 due to the greater modularity of the grammar. 9 Conclusion Using modes plus reordering description contents has been shown to measurably improve parse times on two grammars. The best way to find a reordering is of course to profile the input grammar on representative data to gather such information empirically. 10 20 30 40 50 60 Figure 5: Average parse times (in ms) for ALE compiled code with and without modes on the ERG test suite. mar distributed with ALE. This grammar and was designed to be a literal translation of Pollard and Sag (1994). It has many more relations, applies more descriptions at run-time, and is far less efficient. It was benchmarked on 274 sentences randomly selected from a larger test suite that was automatically generated by a context-free grammar with the same lexicon. The grammar found 80% of the sample to be grammatical. The same protocol as above was used. The results are shown in Figure 6. Here, the average reduction 10000 1000 I 00 Figure 6: Average parse times (in ms) for ALE compiled code with and without modes on an HPSG test suite. in parse time is 28.9%, with a minimum of 17.3% and a maximum of 9</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. Sag. 1994. Head-driven Phrase Structure Grammar. Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wintner</author>
</authors>
<title>An Abstract Machine for Unification Grammars with Applications to an HPSG Grammar fbr Hebrew.</title>
<date>1997</date>
<tech>Ph.D. thesis, Technion.</tech>
<contexts>
<context position="2393" citStr="Wintner, 1997" startWordPosition="394" endWordPosition="395">NUMBER. From that, we can deduce that the TFS also bears values for PERSON and GENDER, with particular appropriate values, because those features are introduced by the same type. Terse descriptions allow us to work with very large TFSs conveniently. Given this basic vocabulary, descriptions can be used in implicational constraints that encode principles of grammar. These are often restricted to the form T 0, where T is a type, and 0 is a description. They also appear in several control strategies that are used to combine TFSs, such as extended phrase structure rules for parsing or generation (Wintner, 1997; Malouf et al., 2000), or resolution with a Prolog-like relational language (Carpenter and Penn, 1996; Makino et al., 1998). While description languages vary, they are usually restricted to a subset of the following: Definition: The set of descriptions over a countable set of types, T, a finite set of features, Feat, and a countable set of variables, Var, is the smallest set Desc that contains: • Var, • zX,allXE Var, • T, • 7F : all 71 E Feat*, 0 E Desc, and • A V), V 11), all 0,&apos;O E Desc. Variables are used to enforce sharing of structure among substructures, and are often used with 275 wide</context>
<context position="21946" citStr="Wintner, 1997" startWordPosition="3687" endWordPosition="3688"> code together, and return var (Ptr, Code, Rest) ,where Ptr is the current TFS pointer. Case 2: T is relatively constrained by p. In this case, we must add the type using code, so that constraints can be enforced if necessary at runtime. This is actually the case we want to avoid, but unless p = T, there is no guarantee that any particular constraint will definitely be required, so nothing else should be done at compile-time. All TFS-based abstract machines possess a primitive operation for this. In the Carpenter-Qu machine (implemented in LiLFeS (Makino et al., 1998)), it is addtype. AMALIA (Wintner, 1997) and ALE (Carpenter and Penn, 1996) have something similar. This instruction must then be threaded with the code generated by other classes. Case 3: Otherwise. In this case, we should try to do as much work as possible in a template. If feature descriptions, inequation descriptions and disjunctive descriptions generate no code, then we can do all of the work in a template. If they do generate code, then we can still build a template, but we should instantiate the TFS pointer with it at run-time to avoid propagating the template&apos;s structure through the generated code at compile-time. This would</context>
</contexts>
<marker>Wintner, 1997</marker>
<rawString>S. Wintner. 1997. An Abstract Machine for Unification Grammars with Applications to an HPSG Grammar fbr Hebrew. Ph.D. thesis, Technion.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>