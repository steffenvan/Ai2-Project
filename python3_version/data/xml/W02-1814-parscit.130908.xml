<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000028">
<title confidence="0.9994545">
Extracting Pronunciation-translated Names from Chinese
Texts using Bootstrapping Approach
</title>
<author confidence="0.994715">
Jing Xiao
</author>
<affiliation confidence="0.9993435">
School of Computing,
National University of Singapore
</affiliation>
<email confidence="0.870156">
xiaojing@comp.nus.edu.sg
</email>
<author confidence="0.815427">
Jimin Liu
</author>
<affiliation confidence="0.9993355">
School of Computing,
National University of Singapore
</affiliation>
<email confidence="0.970684">
liujm@comp.nus.edu.sg
</email>
<author confidence="0.98903">
Tat-Seng Chua
</author>
<affiliation confidence="0.9998315">
School of Computing,
National University of Singapore
</affiliation>
<email confidence="0.983121">
chuats@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.993572" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999794363636364">
Pronunciation-translated names (P-Names)
bring more ambiguities to Chinese word
segmentation and generic named entity
recognition. As there are few annotated
resources that can be used to develop a good
P-Name extraction system, this paper
presents a bootstrapping algorithm, called
PN-Finder, to tackle this problem. Starting
from a small set of P-Name characters and
context cue-words, the algorithm iteratively
locates more P-Names from the Internet.
The algorithm uses a combination of
P-Name and context word probabilities to
identify new P-Names. Experiments show
that our PN-Finder is able to locate a large
number of P-Names (over 100,000) from the
Internet with a high recognition accuracy of
over 85%. Further tests on the MET-2 test
set show that our PN-Finder can achieve a
performance of over 90% in F1 value in
locating P-Names. The results demonstrate
that our PN-Finder is effective.
</bodyText>
<sectionHeader confidence="0.999129" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993861045454546">
Pronunciation-translated names (P-Names) are
those foreign names that are translated to Chinese
characters according to their pronunciations. A
P-Name sometimes forms part of but not a
complete named entity. For instance, in the place
name “ ” (Berkeley University), only
the term “ ” (Berkeley) is a P-Name, while
“ ” (University) is not since it is translated
semantically.
The ability to recognize P-Names helps to reduce
ambiguities in word segmentation and improve the
performance of Chinese information retrieval
since many unknown words are P-Names,
especially for international Chinese news. Unlike
English, there is no blank between words in
Chinese, in which a word is a linguistic token
consisting of one or more characters. In addition, the
same characters may appear in multiple context with
different meanings (Chua and Liu, 2002). The
presence of P-Names brings more ambiguities to
Chinese word segmentation since every character in
a P-Name can be used as a common character.
Intuitively, we can extract the P-Names based on the
distinctive sequence of characters that they are used
as compared to common words. In addition, we can
use local context around the P-Names to confirm
and classify them into person or part of location and
organization names. One way to perform these tasks
effectively is to rely on statistics derived from a
large corpus in which the P-Names are annotated.
While some annotated corpuses with general named
entities are available such as the PKUC (Yu, 1999)
and MET-2 (Chinchor, 2001), there is no such
annotated corpus for P-Names. While annotated data
is difficult to obtain, un-annotated data is readily
available and plentiful, especially on the Internet. To
take advantage of that, we need to tackle two major
problems. The first is how to gather sufficient
distinct P-Names from the Internet, and the second is
how to use the available resources to derive reliable
statistical information to characterize the P-Names.
The problem of gathering sufficient reliable
information from a small initial set of seed resources
has been tackled in bootstrapping research for
information extraction (Agichtein and Gravano,
2000; Brin, 1998; Collins and Singer, 1999;
Mihalcea and Moldovan, 2001; Riloff and Jones,
1999). Bootstrapping approach aims to perform
unsupervised text processing to extract information
from open resources such as the Internet using
minimum manual labor. Given the lack of annotated
training samples for P-Name extraction, this paper
introduces a bootstrapping algorithm, called
PN-Finder. It starts from a small set of seed samples,
and iteratively locates, extracts and classifies the
new and more P-Names. It works in conjunction
with a general Chinese named entity recognizer
(Chua and Liu, 2002) to extract general named
entities.
In the remaining parts of this paper, we describe
the details of PN-Finder in Section 2 and its
application in locating P-Names from new
documents in Section 3. Section 4 presents the
experimental results using the MET-2 test corpus.
Section 5 contains our conclusion and outline for
future work.
</bodyText>
<sectionHeader confidence="0.4620065" genericHeader="method">
2 Bootstrapping Algorithm for Locating
P-Names
</sectionHeader>
<bodyText confidence="0.998007857142857">
Currently, there is no standard corpus that
annotates all P-Names. Since annotating thousands
of P-Names is more difficult than collecting
thousands of P-Names from the Internet, we recur
to using the Internet search engine to collect a
large set of P-Names. Figure 1 illustrates our main
components in bootstrapping process.
</bodyText>
<figureCaption confidence="0.994224">
Figure 1: Main components of the bootstrapping
</figureCaption>
<bodyText confidence="0.991119">
The inputs to the PN-Finder are:
</bodyText>
<listItem confidence="0.99438484375">
a) A seed P-Name character set Cs(0) consisting of
5 characters {“”, “”, “”, “”, “”}.
b) A set of seed context cue words CW(0)
consisting of 60 context words, such as
{“NULL”, “
PKUC1 (the PoS Corpus of Peking University),
which contains one month of news from the
People Daily.
c) A set of P-Name candidates P(0), which is null at
the beginning.
d) A common word dictionary extracted from
PKUC by removing proper nouns, numbers and
non-Chinese symbols. It contains about 37,000
words.
From the initial seeds, we perform the followings:
a) We use every two characters in Cs(i-1) as query to
retrieve relevant web pages from the Internet
using a commercial search engine. We then
extract possible P-Names from the returned web
pages to update P(i).
b) We find a most probable new P-Name character.
Update Cs(i-1) to Cs(i) by adding the new character.
c) We bootstrap new context words around the new
P-Names found to derive CW(i). We then perform
the lexical chaining to generalize these context
words to generate semantic classes.
d) We repeat the process from step (a) until any of
the following conditions is satisfied: (i) when no
new P-Name is found; (ii) when the desired
number of iterations is reached; or (iii) when the
number of P-Names found exceeds a desired
number.
</listItem>
<bodyText confidence="0.733026">
The following subsections discuss the details of
the bootstrapping process.
</bodyText>
<subsectionHeader confidence="0.987777">
2.1 Querying and Extracting the P-Names
from the Web
</subsectionHeader>
<bodyText confidence="0.998912235294118">
The first step of the algorithm is to derive good
queries from the character set Cs(m-1) to search the
Internet to obtain new web pages. If we use all single
characters from Cs(m-1) to perform the search, we are
likely to get too many pages containing irrelevant
information. As a compromise, we use every two
characters cicj in Cs(m-1) (except those combinations
that have been used in the previous iterations) to
search the Internet using Google (by using its
language tool2). We consider only up to 300 entries
returned by Google. We divide the content of the
web pages into text segments by using the
non-alphanumeric characters as delimiters. We
extract those text segments that contain the search
characters ci, cj or both and store them in R(m). For
example, from the web page given in Figure 2, the
text segments extracted include: strings “
</bodyText>
<listItem confidence="0.861957">
” and “” from the first
entry; and strings “
” and “
” from the second entry.
</listItem>
<bodyText confidence="0.99964825">
Given R(m), we next extract the possible P-Names.
Firstly, we segment those entries in R(m) by
performing the longest forward match using the
common word dictionary. We then remove all
</bodyText>
<figure confidence="0.8778607">
Seed P-Name characters
Seed context cue words
Search Engine
Webpages
Search Engine
Generate new P-Name characters
And new context cue words
StringMatch
P-Names
Evaluate
</figure>
<bodyText confidence="0.885281888888889">
”, “”, “”, “”, “”}.
These are typical context words found around
person, location and organization names in
”, “
1 http://icl.pku.edu.cn/Introduction/corpustagging.htm 2 http://www.google.com/intl/zh-CN/
non-Chinese letters and common words containing
more than one character. From the remaining
string segments in R(m), we locate all sub-strings
with at
</bodyText>
<figureCaption confidence="0.997421">
Figure 2: A web page returned by Google
</figureCaption>
<bodyText confidence="0.823294125">
least 2-character in length and contain the query
terms ci, cj or cicj. We extract those sub-strings that
appear at least τn (we use 3) times as P-Name
candidates by string matching. We store the new
P-Name candidates found in P(m-1) to obtain P(m).
For example, if we use “, ” obtained from Cs(0)
as query to Google, among the returned entries, we
will have:
“()()()”
“(WTO)()()()...”
“()( )...”
“()...”
Here the bracketed words are common words or
English letters and they are removed from string
matching. The sub-string “” appears
5 times and it is matched as a possible P-Name.
</bodyText>
<subsectionHeader confidence="0.999003">
2.2 Deriving New P-Name Characters
</subsectionHeader>
<bodyText confidence="0.9997205">
Given the set of P-Name candidates in P(m), we
next use both the context words and corpus
statistics to confirm the P-Name and extract new
P-Name characters.
</bodyText>
<subsubsectionHeader confidence="0.986604">
2.2.1 Classifying P-Names
</subsubsectionHeader>
<bodyText confidence="0.999943555555556">
From observation, context information is useful to
comfirm a P-Name and determine its left and right
boundary. Thus we use one-word context to confirm
and classify P-Name candidates into person names
or part of location or organization names. For each
context word wc in CW(m), we first compute its
probability vector of occurrences, PV(wc), around
person, location and organization names in PKUC as
follows:
</bodyText>
<equation confidence="0.993115142857143">
PV(wc) =&lt;c−p,c+p,c−l,c+l,c−o,c+o &gt; (1)
where: c+x(wc) = n+x
n n n
+ +
+p + l + o
−x (1.2)
n−p +n−l +n−o
</equation>
<bodyText confidence="0.9647644">
Here x∈{p, l, o}, and n-p ( or n+p), n-l (or n+l), n-o (or
n+o) respectively give the number of times wc
appears at the left (or right) boundary of person (p),
location (l) and organization (o) names in PKUC. c-x
(or c+x) gives the probability that the P-Name is of
type x, if this cue-word is at the left (or right)
boundary of the P-Name.
Given a P-Name candidate pk(m) in P(m), we extract
the set of its left and right context words as Wcl and
Wcr. We then derive the average probability vectors
of Wcl = &lt;cl -p, cl +p, cl-l, cl+l, cl -o, cl +o&gt; and Wc r = &lt;cr -p,
c
confidence vector of pk(m) as:
r+p, cr -l, cr +l, cr-o, cr
+o&gt;, and use these to compute the
</bodyText>
<equation confidence="0.900115">
CV(pk(m)) =&lt;cp,cl,co &gt; (2)
</equation>
<bodyText confidence="0.99997825">
where cp=cl-p+cr+p, cl=cl-l+cr+l, co=cl-o+cr+o. Here we
simply average the probabilities of the left and right
context words to derive the final probability vector.
We assign pk(m) to be part of a named entity of type x,
if cx τp for x∈{p, l, o}. Here we set τp to be 0.8. In
case that there are more than one value greater than
τp, we select the one with the highest value in the
type vector as the type of that P-Name.
</bodyText>
<subsubsectionHeader confidence="0.985041">
2.2.2 Evaluating P-Names
</subsubsectionHeader>
<bodyText confidence="0.994267666666667">
We next derive an objective measure to evaluate
how likely a candidate in P(m) could be a P-Name.
We observe that a string is likely to be a P-Name if:
(a) it contains some sub-strings that frequently
appear in typical P-Names such as “”, “”,
“”, etc; and (b) it has context words in CW(m-1) set
that indicates that it has high probability of being
part of a named entity. Thus for each P-Name
candidate pk (m) (pk (m)=c1c2...cn) in P(m), we compute:
</bodyText>
<equation confidence="0.9638552">
“()()()...”
c w
( ) =
− x c
n
ns1(pk(m))=ω∑Nnmjn j(c)®2n−1Nn injil j®3n−2Nnj(cici❑cie i j
= =
1 1
s2 (pk(m)) max( , , )
= cp cl co (3.2)
</equation>
<bodyText confidence="0.9998316">
where n is the number of characters in pk(m), and N
equals |P(m)|. nj(ci), nj(cici+1) and nj(cici+1ci+2) are
respectively number of times the character strings
ci, cici+1 and cici+1ci+2 in pk(m) also appear in other
P-Name candidates in P(m). β and ω are predefined
constants (here we use β =0.5 and ω =1.5).
Equation (3.1) gives higher weight to pk(m) that has
better match with longer string sequence of, say,
cici+1ci+2 with other known P-Names candidates.
Equation (3.2) selects the highest confidence value
of context words around pk(m) as support for pk(m).
As s1 and s2 are of different scales, we normalize s1
by dividing it by M, the maximum s1 values found
in the current iteration, before fusing the two
values in Equation (3).
</bodyText>
<subsubsectionHeader confidence="0.935349">
2.2.3 Generating New P-Name Characters
</subsubsectionHeader>
<bodyText confidence="0.998428432432433">
Since we would like to obtain more new P-Names
during bootstrapping, in each iteration, we would
like to expand the P-Name character set. In order
to select the most likely P-Name characters, we
derive a quasi-probability, Conf(ci(m)), to estimate
how likely a character ci(m) in the P-Name
candidate set P(m) could be used as a P-Name
character. To do this, we make use of both the
PKUC corpus and P(m). We observe that most
characters in P(m) also appear in the PKUC corpus,
sometimes as P-Name characters sometimes as
common characters. Thus, intuitively we estimate
Conf(ci(m)) by its occurrences in both PKUC and
P(m) as:
Here we assume that there are Nc P-Name
candidates in P(m) that contain ci(m); and Nneg is the
number of times that ci(m) is used as
single-character word in PKUC. Equation (4) aims
to identify characters that appear frequently as part
of P-Names, but rarely as part of common words.
It also favors characters that appear in more
probable P-Names through the s(pk(m)) measures.
Although Equation (4) is effective in identifying
individual P-Name characters, it is not good at
locating the sequences of P-Name characters that
form the P-Names. This is because there are many
characters that have low Conf(ci(m)) values that are
part of a P-Name. For example, in a P-Name “
”, the character “” has low confidence to be a
P-Name character as defined by Equation (4).
However, it co-occurs with high confident P-Name
characters such as “” and “”. To overcome this
problem, we modify the confidence value of each
character by considering its neighbors (context) to
derive a smoothed confidence measure in Equation
(5).
where α is a predefined constant (we use α = 1),
</bodyText>
<equation confidence="0.988542727272727">
C c c
( ) C c c
( )
i i + 1
= ; ( )
− .
i − 1 i
( ) B c
c =
i i
C c
( ) Cc
( )
i
( ) ( )/
( )
m ( )
m ( )
m
( )
s p =s p M +β∗ s p (3)
k 1 k 2 k
</equation>
<bodyText confidence="0.994845777777778">
Conf(ci) is defined in Equation (4); C(ci) and C(cicj)
is respectively the co-occurrence of characters ci and
cicj in the P-Name set. Equation (5) tries to
supplement the confidence of ci by its context, that
is, it uses the higher of the bi-gram statistics with its
preceding and succeeding word to enhance its
confidence. We rank all the characters in P(m) using
Equation (5) and add the top new character into
CS(m-1) to obtain CS(m).
</bodyText>
<subsectionHeader confidence="0.997703">
2.3 Deriving New Context Words
</subsectionHeader>
<bodyText confidence="0.99998175">
In addition to finding new P-Name characters, there
is also a need to expand the context word set CW(m-1)
in order to help identify more P-Names. As
mentioned before, if at least one of cp, cl, co values of
a P-Name candidate in Equation (2) is greater than a
threshold τp, we regard it as part of a named entity.
For these P-Names which could be possible part of
named entities, the following steps are performed:
</bodyText>
<listItem confidence="0.839967">
a) We retrieve all their context words in R(m).
b) We add all new context words to form CW(m).
c) We update probability vectors of the new context
words using Equation (1).
d) We group these context words under the category
of c-x or c+x (for x∈{p, l, o}) if their probabilities
under that category is greater than a threshold τg
(say, 0.5).
e) We then perform lexical chaining using HowNet
to generalize the context words under each of the
6 categories separately. The general lexical
chaining algorithm is given in detail in Chua and
Liu (2002).
</listItem>
<equation confidence="0.964482064516129">
( ci(m)) =k=1 ∗ ln (Nc s(pk(m)) )
Nc1
+
s(pk(m))
Conf
)
s(p k(m ) k
N
n e g
(4)
1
=
k
N c
SConf c
( i
∗max{
) = Conf (ci) +
B− ( c ) ( )
i ∗ Conf c
∗ Conf c
( ),eB c
i−1 i+ 1
+
i ( )}
α
e
(5)
) (3.1)
+
B
</equation>
<bodyText confidence="0.968655777777778">
and
f) After lexical chaining, some semantically
related words are grouped together. We update
the confidence vectors of the semantic groups
by averaging the confidence values of words in
each of the semantic groups.
At the end of this process, we obtain a new set of
context word CW(m) which contains some
generalized context word classes.
</bodyText>
<sectionHeader confidence="0.93293" genericHeader="method">
3 Identifying P-Names from New Texts
</sectionHeader>
<bodyText confidence="0.998863833333333">
At the end of the bootstrapping process, we obtain
expanded lists of likely P-Name characters Cs(m),
context cue words CW(m) and P-Names P(m). Given
a new document, we want to use these resources to
identify all P-Names. The process is carried out as
follows:
</bodyText>
<listItem confidence="0.966171692307693">
a) We first use our common word dictionary to
remove all common words.
b) Next we use knowledge of P-Name candidates
and corpus statistics to identify a sequence of
likely P-Name characters. Any sub-string in
which the Sconf(ci) (see Equation (5)) of each
consecutive character in that string is greater
than a pre-specified threshold τc (we use 5) is
considered as a P-Name.
c) A frequently occurring problem during testing
is how to handle new characters not found in
the Cs(m) set that we do not know their
confidence values. Such problem occurs as a
</listItem>
<bodyText confidence="0.648098666666667">
same foreign name may be translated to
different P-Names with similar Chinese PinYin.
For these characters, we adopt the similar
homophone approach to relate unknown
characters to the known characters in Cs(m) set
with similar Chinese PinYin.
</bodyText>
<sectionHeader confidence="0.995547" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9994416">
We devise several tests to evaluate our extraction
scheme with bootstrapping. We use the MET-2
test corpus for two of the tests, and PKUC as basic
language resource to support the process. We use
PKUC to extract common word dictionary, which
consists of about 37,000 words. We also use
PKUC to extract and evaluate typical context cue
words around person, location and organization
names. Our experiments start from a “seed”
P-Name character set:
</bodyText>
<subsectionHeader confidence="0.999516">
4.1 Obtaining P-Names from the Internet
</subsectionHeader>
<bodyText confidence="0.999961882352941">
We perform the bootstrapping process as discussed
in Section 2 to extract P-Names from the Internet,
and stopped after about 650 iterations. We manually
count the number of correct P-Names obtained at the
end of every 65-iterations. We also use the first
100,000 P-Names found at the end of the
bootstrapping process as the ground truth to
compute the accuracy of P-Name identification.
Figure 3 presents the results of the P-Name
extraction process. From the figure, we can see that
as we increased the number of iterations, the number
of P-Names obtained also increased proportionally.
This demonstrates that our bootstrapping process is
consistent. We also observe that the system is able to
maintain a high accuracy of over 85% even when the
number of P-Names found approaches 100,000.
This demonstrates that our method is effective.
</bodyText>
<figureCaption confidence="0.917202">
Figure 3: Obtaining P-Names with Bootstrapping
</figureCaption>
<subsectionHeader confidence="0.994663">
4.2 Extracting P-Names from MET-2 set
</subsectionHeader>
<bodyText confidence="0.998759909090909">
We use MET-2 test corpus to test the effectiveness
of our approach to identify P-Names from new texts
as discussed in Section 3. We consider a P-Name as
correctly extracted only when every of its character
are correctly identified. The results are presented in
Table 1. The results show that we are able to achieve
a recall of over 95% and precision of close to 90%.
The results are encouraging as we did not use the
training resource of MET-2 corpus to train the
system, which is expected to lead to higher
accuracy.
</bodyText>
<tableCaption confidence="0.999005">
Table 1: Results of P-Name extraction from MET2
</tableCaption>
<note confidence="0.5030185">
Actual # System Nc Np Nm Ns Rc Pr
457 491 437 20 0 34 95.6% 89%
</note>
<equation confidence="0.91089725">
Nc = number of P-Names correctly recognized.
Np = number of P-Names partially recognized.
Nm = number of P-Names missed.
Ns = number of P-Names found but not in the annotated list.
</equation>
<figure confidence="0.91464704">
65 130 195 260 325 390 455 520 585 650
Accurracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
80000
60000
40000
20000
0
100000
Num. of P-Names
Acccuracy P-Names
Cs (0) = {“”, “”, “”, “”, “”};
and a set of 60 context cue words.
Recall (Rc) = Nc/(Nc + Np + Nm);
Precision (Pr) = Nc /(Nc + Np + Ns).
</figure>
<bodyText confidence="0.999694333333333">
As a by-product of the PN-Finder, we obtained a
large set of context words. We found that we can
use these context words to correctly classify about
25% of the extracted P-Names in MET-2 test set
into person names or part of location or
organization names using the method described in
Section 2.2. The employing of context words to
classify P-Names is mainly to confirm more
P-Names and P-Name characters.
</bodyText>
<subsectionHeader confidence="0.987904">
4.3 Contributions of PN-Finder to a
Generic NE Recognition Module
</subsectionHeader>
<bodyText confidence="0.999908619047619">
The most important contribution of PN-Finder is
that it can be used to improve the performance of a
generic Chinese named entity recognizer as
discussed in Chua and Liu (2002). Here, we
conducted several trials by using the PN-Finder to
extract a different number of P-Names. We use the
first 100,000 P-Names found by the PN-Finder,
together with the pattern rules in the general
named entity recognizer, to conduct a baseline test.
This test merely performs direct table look-up to
locate all possible P-Names. Table 2 lists the
performance of the general NE recognition system
by using an increasing number of P-Names found
by the PN-Finder, together with the use of the
confidence statistics, context words obtained from
the current sets of P-Names and pattern rules. The
results indicate that as we increase the number of
P-Names found by the PN-Finder, the performance
of the general NE recognition system is improved
steadily until it reaches over 92% in average F1
value.
</bodyText>
<tableCaption confidence="0.998718">
Table 2: Contributions to general NE recognition
</tableCaption>
<table confidence="0.951305166666667">
# of P-Names used Ave F1
100,000 (baseline) 71.3
40,000 88.9
60,000 90.5
80,000 91.7
100,000 92.3
</table>
<sectionHeader confidence="0.99256" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999974588235294">
The presence of P-Names brings more ambiguities
to Chinese word segmentation and general
Chinese named entity recognition. However, there
is a dearth of annotated corpus for extracting and
classifying P-Names. To cope with the problem of
sparse training resources, this paper presents a
bootstrapping module to identify P-Names and
classify them into parts of named entitites if
possible. The PN-Finder could also contribute to
general Chinese named entity recognition and
achieve promising performance on the MET-2 test
corpus.
Currently, we use only a single word as the context,
more context could be considered in the future
research. We also aim to extend this method to
extract organization names from Chinese documents
obtained from the Internet.
</bodyText>
<sectionHeader confidence="0.999424" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996258428571429">
Agichtein E. and Gravano L. (2000). Snowball:
Extracting Relations from Large Plain-Text
Collections. Proceedings of the 5th ACM International
Conference on Digital Libraries.
Brin S. (1998). Extracting Patterns and Relations from
the World Wide Web. WebDB Workshop at 6th
International Conference on Extending Database
Technology, EDBT’ 98.
Chinchor A. Nancy (2001). Overview of MUC7/MET-2.
available at:
http://www.itl.nist.gov/iaui/894.02/related projects/muc/
proceedings/muc 7 proceedings/overview.html
Chua T.S. and Liu J.M. (2002), Learning Pattern Rules
for Chinese Named Entity Extraction. To Appear in
AAAI’02.
Collins M. and Singer Y. (1999). Unsupervised Models
for Named Entity Classification. In Proceedings of the
Joint SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Corpora.
Liu J.M. and Chua T.S. (2001), Building semantic
Perceptron net for topic spotting, In Proceeding of
Association for Computational Linguistics 39th
Anniversary Meeting, 306-313
Mihalcea F. R. and Moldovan I. D. (2001) A Highly
Accurate Bootstrapping Algorithm for Word Sense
Disambiguation. International Journal on Artificial
Intelligence Tools. Vol.10, No 1-2(2001). pp. 5-21
Riloff E. and Jones R. (1999) Learning Dictionaries for
Information Extraction by Multi-Level Bootstrapping.
In Proceedings of the Sixteenth National Conference on
Artificial Intelligence, pp. 1044-1049.
Yu S. (1999), The Specification and Manual of Chinese
Word Segmentation and Part of Speech Tagging,
available at:
http://www.icl.pku.edu.cn/Introduction/corpustagging.htm
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.275650">
<title confidence="0.978172">Extracting Pronunciation-translated Names from Texts using Bootstrapping Approach</title>
<author confidence="0.941984">Jing</author>
<affiliation confidence="0.9962265">School of National University of</affiliation>
<email confidence="0.805154">xiaojing@comp.nus.edu.sg</email>
<affiliation confidence="0.808958333333333">Jimin School of National University of</affiliation>
<email confidence="0.88222">liujm@comp.nus.edu.sg</email>
<author confidence="0.982398">Tat-Seng Chua</author>
<affiliation confidence="0.9993525">School of Computing, National University of Singapore</affiliation>
<email confidence="0.988497">chuats@comp.nus.edu.sg</email>
<abstract confidence="0.998098391304348">Pronunciation-translated names (P-Names) bring more ambiguities to Chinese word segmentation and generic named entity recognition. As there are few annotated resources that can be used to develop a good P-Name extraction system, this paper presents a bootstrapping algorithm, called PN-Finder, to tackle this problem. Starting from a small set of P-Name characters and context cue-words, the algorithm iteratively locates more P-Names from the Internet. The algorithm uses a combination of P-Name and context word probabilities to identify new P-Names. Experiments show that our PN-Finder is able to locate a large number of P-Names (over 100,000) from the Internet with a high recognition accuracy of over 85%. Further tests on the MET-2 test set show that our PN-Finder can achieve a of over 90% in in locating P-Names. The results demonstrate that our PN-Finder is effective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: Extracting Relations from Large Plain-Text Collections.</title>
<date>2000</date>
<booktitle>Proceedings of the 5th ACM International Conference on Digital Libraries.</booktitle>
<contexts>
<context position="3446" citStr="Agichtein and Gravano, 2000" startWordPosition="517" endWordPosition="520">no such annotated corpus for P-Names. While annotated data is difficult to obtain, un-annotated data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) </context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Agichtein E. and Gravano L. (2000). Snowball: Extracting Relations from Large Plain-Text Collections. Proceedings of the 5th ACM International Conference on Digital Libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
</authors>
<title>Extracting Patterns and Relations from the World Wide Web. WebDB</title>
<date>1998</date>
<booktitle>Workshop at 6th International Conference on Extending Database Technology, EDBT’ 98.</booktitle>
<contexts>
<context position="3458" citStr="Brin, 1998" startWordPosition="521" endWordPosition="522">P-Names. While annotated data is difficult to obtain, un-annotated data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract g</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Brin S. (1998). Extracting Patterns and Relations from the World Wide Web. WebDB Workshop at 6th International Conference on Extending Database Technology, EDBT’ 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chinchor A Nancy</author>
</authors>
<title>Overview of MUC7/MET-2. available at:</title>
<date>2001</date>
<note>http://www.itl.nist.gov/iaui/894.02/related projects/muc/ proceedings/muc 7 proceedings/overview.html</note>
<marker>Nancy, 2001</marker>
<rawString>Chinchor A. Nancy (2001). Overview of MUC7/MET-2. available at: http://www.itl.nist.gov/iaui/894.02/related projects/muc/ proceedings/muc 7 proceedings/overview.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>T S Chua</author>
<author>J M Liu</author>
</authors>
<title>Learning Pattern Rules for Chinese Named Entity Extraction.</title>
<date>2002</date>
<note>To Appear in AAAI’02.</note>
<contexts>
<context position="2124" citStr="Chua and Liu, 2002" startWordPosition="307" endWordPosition="310">the place name “ ” (Berkeley University), only the term “ ” (Berkeley) is a P-Name, while “ ” (University) is not since it is translated semantically. The ability to recognize P-Names helps to reduce ambiguities in word segmentation and improve the performance of Chinese information retrieval since many unknown words are P-Names, especially for international Chinese news. Unlike English, there is no blank between words in Chinese, in which a word is a linguistic token consisting of one or more characters. In addition, the same characters may appear in multiple context with different meanings (Chua and Liu, 2002). The presence of P-Names brings more ambiguities to Chinese word segmentation since every character in a P-Name can be used as a common character. Intuitively, we can extract the P-Names based on the distinctive sequence of characters that they are used as compared to common words. In addition, we can use local context around the P-Names to confirm and classify them into person or part of location and organization names. One way to perform these tasks effectively is to rely on statistics derived from a large corpus in which the P-Names are annotated. While some annotated corpuses with general</context>
<context position="4045" citStr="Chua and Liu, 2002" startWordPosition="606" endWordPosition="609">in and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract general named entities. In the remaining parts of this paper, we describe the details of PN-Finder in Section 2 and its application in locating P-Names from new documents in Section 3. Section 4 presents the experimental results using the MET-2 test corpus. Section 5 contains our conclusion and outline for future work. 2 Bootstrapping Algorithm for Locating P-Names Currently, there is no standard corpus that annotates all P-Names. Since annotating thousands of P-Names is more difficult than collecting thousands of P-Names from the Internet, we recur to using the Internet search eng</context>
<context position="14997" citStr="Chua and Liu (2002)" startWordPosition="2535" endWordPosition="2538">d be possible part of named entities, the following steps are performed: a) We retrieve all their context words in R(m). b) We add all new context words to form CW(m). c) We update probability vectors of the new context words using Equation (1). d) We group these context words under the category of c-x or c+x (for x∈{p, l, o}) if their probabilities under that category is greater than a threshold τg (say, 0.5). e) We then perform lexical chaining using HowNet to generalize the context words under each of the 6 categories separately. The general lexical chaining algorithm is given in detail in Chua and Liu (2002). ( ci(m)) =k=1 ∗ ln (Nc s(pk(m)) ) Nc1 + s(pk(m)) Conf ) s(p k(m ) k N n e g (4) 1 = k N c SConf c ( i ∗max{ ) = Conf (ci) + B− ( c ) ( ) i ∗ Conf c ∗ Conf c ( ),eB c i−1 i+ 1 + i ( )} α e (5) ) (3.1) + B and f) After lexical chaining, some semantically related words are grouped together. We update the confidence vectors of the semantic groups by averaging the confidence values of words in each of the semantic groups. At the end of this process, we obtain a new set of context word CW(m) which contains some generalized context word classes. 3 Identifying P-Names from New Texts At the end of th</context>
<context position="19812" citStr="Chua and Liu (2002)" startWordPosition="3394" endWordPosition="3397">der, we obtained a large set of context words. We found that we can use these context words to correctly classify about 25% of the extracted P-Names in MET-2 test set into person names or part of location or organization names using the method described in Section 2.2. The employing of context words to classify P-Names is mainly to confirm more P-Names and P-Name characters. 4.3 Contributions of PN-Finder to a Generic NE Recognition Module The most important contribution of PN-Finder is that it can be used to improve the performance of a generic Chinese named entity recognizer as discussed in Chua and Liu (2002). Here, we conducted several trials by using the PN-Finder to extract a different number of P-Names. We use the first 100,000 P-Names found by the PN-Finder, together with the pattern rules in the general named entity recognizer, to conduct a baseline test. This test merely performs direct table look-up to locate all possible P-Names. Table 2 lists the performance of the general NE recognition system by using an increasing number of P-Names found by the PN-Finder, together with the use of the confidence statistics, context words obtained from the current sets of P-Names and pattern rules. The </context>
</contexts>
<marker>Chua, Liu, 2002</marker>
<rawString>Chua T.S. and Liu J.M. (2002), Learning Pattern Rules for Chinese Named Entity Extraction. To Appear in AAAI’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Y Singer</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="3484" citStr="Collins and Singer, 1999" startWordPosition="523" endWordPosition="526">le annotated data is difficult to obtain, un-annotated data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract general named entities. In </context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Collins M. and Singer Y. (1999). Unsupervised Models for Named Entity Classification. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Liu</author>
<author>T S Chua</author>
</authors>
<title>Building semantic Perceptron net for topic spotting,</title>
<date>2001</date>
<booktitle>In Proceeding of Association for Computational Linguistics 39th Anniversary Meeting,</booktitle>
<pages>306--313</pages>
<marker>Liu, Chua, 2001</marker>
<rawString>Liu J.M. and Chua T.S. (2001), Building semantic Perceptron net for topic spotting, In Proceeding of Association for Computational Linguistics 39th Anniversary Meeting, 306-313</rawString>
</citation>
<citation valid="true">
<authors>
<author>F R Mihalcea</author>
<author>I D Moldovan</author>
</authors>
<title>A Highly Accurate Bootstrapping Algorithm for Word Sense Disambiguation.</title>
<date>2001</date>
<journal>International Journal on Artificial Intelligence Tools.</journal>
<volume>2</volume>
<issue>2001</issue>
<pages>5--21</pages>
<contexts>
<context position="3513" citStr="Mihalcea and Moldovan, 2001" startWordPosition="527" endWordPosition="530">cult to obtain, un-annotated data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract general named entities. In the remaining parts of this p</context>
</contexts>
<marker>Mihalcea, Moldovan, 2001</marker>
<rawString>Mihalcea F. R. and Moldovan I. D. (2001) A Highly Accurate Bootstrapping Algorithm for Word Sense Disambiguation. International Journal on Artificial Intelligence Tools. Vol.10, No 1-2(2001). pp. 5-21</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence,</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="3538" citStr="Riloff and Jones, 1999" startWordPosition="531" endWordPosition="534">data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999). Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor. Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder. It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names. It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract general named entities. In the remaining parts of this paper, we describe the det</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Riloff E. and Jones R. (1999) Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence, pp. 1044-1049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yu</author>
</authors>
<title>The Specification and Manual of Chinese Word Segmentation and Part of Speech Tagging, available at: http://www.icl.pku.edu.cn/Introduction/corpustagging.htm</title>
<date>1999</date>
<contexts>
<context position="2781" citStr="Yu, 1999" startWordPosition="418" endWordPosition="419">s to Chinese word segmentation since every character in a P-Name can be used as a common character. Intuitively, we can extract the P-Names based on the distinctive sequence of characters that they are used as compared to common words. In addition, we can use local context around the P-Names to confirm and classify them into person or part of location and organization names. One way to perform these tasks effectively is to rely on statistics derived from a large corpus in which the P-Names are annotated. While some annotated corpuses with general named entities are available such as the PKUC (Yu, 1999) and MET-2 (Chinchor, 2001), there is no such annotated corpus for P-Names. While annotated data is difficult to obtain, un-annotated data is readily available and plentiful, especially on the Internet. To take advantage of that, we need to tackle two major problems. The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names. The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping</context>
</contexts>
<marker>Yu, 1999</marker>
<rawString>Yu S. (1999), The Specification and Manual of Chinese Word Segmentation and Part of Speech Tagging, available at: http://www.icl.pku.edu.cn/Introduction/corpustagging.htm</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>