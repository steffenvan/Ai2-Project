<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.983218">
Splittability of Bilexical Context-Free
Grammars is Undecidable
</title>
<author confidence="0.996715">
Mark-Jan Nederhof∗
</author>
<affiliation confidence="0.995918">
University of St. Andrews
</affiliation>
<author confidence="0.984563">
Giorgio Satta∗∗
</author>
<affiliation confidence="0.977317">
University of Padua
</affiliation>
<bodyText confidence="0.972804375">
Bilexical context-free grammars (2-LCFGs) have proved to be accurate models for statistical
natural language parsing. Existing dynamic programming algorithms used to parse sentences
under these models have running time of O(|w|4), where w is the input string.
A 2-LCFG is splittable if the left arguments of a lexical head are always independent
of the right arguments, and vice versa. When a 2-LCFGs is splittable, parsing time can be
asymptotically improved to O(|w|3). Testing this property is therefore of central interest to
parsing efficiency. In this article, however, we show the negative result that splittability of
2-LCFGs is undecidable.
</bodyText>
<sectionHeader confidence="0.97726" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999850176470588">
Bilexical context-free grammars, or 2-LCFGs for short, are specialized context-free
grammars where each nonterminal is associated with a terminal symbol representing a
lexical element of the language of interest. Furthermore, no more than two symbols can
be used in the right-hand side of a rule, and the terminal symbol associated with the left-
hand side of a rule must also occur on the right-hand side. In this way, 2-LCFGs are able
to specify syntactic constraints as well as lexically specific preferences that influence
the combination of predicates with their arguments or modifiers. Models based on
2-LCFGs have therefore been of central interest in statistical natural language parsing, as
they allow selection of high-quality parse trees. One can in fact see 2-LCFGs as abstract
models of the head automata of Alshawi (1996), the probabilistic projective dependency
grammars of Eisner (1996), and the head-driven statistical models of Charniak (2001)
and Collins (2003).
Parsing algorithms based on 2-LCFGs can be very efficient. In the general case,
existing dynamic programming algorithms have running time of O(|w|4), where w is
the input string. (In this article we disregard complexity factors that depend on the
input grammar, which we will consider to be constants.) In cases in which, for each
(lexical) head, the two processes of generating its left and right arguments are, to some
</bodyText>
<affiliation confidence="0.529393">
∗ School of Computer Science, University of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX,
Scotland. E-mail: markjan.nederhof@gmail.com.
∗∗ Department of Information Engineering, University of Padua, via Gradenigo 6/A, I-35131 Padova, Italy.
</affiliation>
<email confidence="0.971747">
E-mail: satta@dei.unipd.it.
</email>
<note confidence="0.92136825">
Submission received: 8 September 2010; revised submission received: 21 January 2011; accepted for
publication: 17 April 2011.
© 2011 Association for Computational Linguistics
Computational Linguistics Volume 37, Number 4
</note>
<bodyText confidence="0.999932575757576">
extent, independent one of the other, parsing based on 2-LCFGs can be asymptotically
improved to O(|w|3). The reader is referred to Eisner and Satta (1999) for a detailed
presentation of these computational results.
In the literature, this condition on independence between left and right arguments
of each head has been called splittability (Eisner 1997; Eisner and Satta 1999). Testing
for splittability on an input 2-LCFG is therefore of central interest to parsing efficiency.
The computability of this test has never been investigated, however.
In this article splittability is defined for 2-LCFGs in terms of equivalence to another
grammar in which independence between left and right arguments of each head is
ensured by a simple syntactic restriction. This restriction is called split form. Informally,
a 2-LCFG is in split form if it can be factorized into individual subgrammars, one for
each head, and each subgrammar produces the left and the right arguments of its head
through two derivation processes, one happening strictly after the other.
One may believe that a necessary and sufficient condition for splittability is that a
2-LCFG does not allow recursive structures that alternately generate left (L) and right
(R) arguments of some head a. These structures could well result in subderivations
producing sequences of the form LnaRn, for any n &gt; 0, which would appear to preclude
the application of the O(|w|3) algorithm.
This situation, however, does not mean in general that the grammar is not splittable.
Although a subset of the rules in a grammar may generate structures such as those just
discussed, there may be additional rules that make the observed dependencies between
left and right arguments irrelevant. In fact, splittability of a 2-LCFG is undecidable, as
will be shown in this article.
Our result is based on the fact that it is undecidable whether a linear context-free
grammar with a center marker (to be defined later) generates a regular language. This
fact is originally proved in this article, and does not follow from the weaker result stat-
ing the undecidability of regularity of (general) linear context-free languages, which is
well known in the formal language literature (Hopcroft and Ullman 1979, exercise 8.10a,
page 214) and which is originally due to Hunt III and Rosenkrantz (1974).
The remaining part of this article is organized as follows. In Section 2 we present
some preliminary background, and in Section 3 we define 2-LCFGs and the notion
of splittability. In Section 4 we prove the main result of this article, and draw some
conclusions in Section 5.
</bodyText>
<sectionHeader confidence="0.976309" genericHeader="keywords">
2. Preliminaries
</sectionHeader>
<bodyText confidence="0.999943846153846">
In this article we assume the reader is familiar with the notions of context-free grammar,
Turing machine, and undecidability (see, e.g., Hopcroft and Ullman 1979). We briefly
summarize the adopted notation now.
A context-free grammar (CFG) is a 4-tuple G = (Σ, N, S, R), where Σ is a finite set
of terminals, N is a finite set of nonterminals, disjoint from Σ and including the start
symbol S, and R is a finite set of rules. Each rule has the form A -+ α, where A E N and
α E (Σ U N)*. A CFG is called linear if each rule A -+ α has at most one nonterminal in
the right-hand side α.
We associate with G a binary relation called rewrite and denoted by the symbol
=&gt;G, defined such that γAγ&apos; =&gt;G γαγ&apos; if A -+ α is a rule in R and γ,γ&apos; E (Σ U N)*. We
drop subscript G from =&gt;G whenever it is understood from the context. The reflexive
and transitive closure of =&gt; is denoted as =&gt;*. The language generated by G is defined
as L(G) = {w E Σ*  |S =&gt;* w}.
</bodyText>
<page confidence="0.987684">
868
</page>
<note confidence="0.517512">
Nederhof and Satta Splittability of 2-LCFGs
</note>
<bodyText confidence="0.998665888888889">
We now introduce a special class of CFGs that will play a central role in the proofs
in this article. Assume a distinguished symbol # E E, which we will refer to as a center
marker. The class of linear CFGs with center marker #, or lin-CFG(#) for short, is the
class of CFGs in which each rule either has the form A # or the form A uBv,
where A, B E N and u, v E (E \ {#})*, where symbol “\” denotes set difference. We
say a grammar in lin-CFG(#) is in binary form if the total length of u and v in rules
A uBv is at most 1. It is not difficult to see that there is a language-preserving
transformation of grammars in lin-CFG(#) to binary form, as suggested by the following
example.
</bodyText>
<figure confidence="0.885059857142857">
Example 1
Let E = {a, b, #}. One member of lin-CFG(#) is the CFG G defined by the rules:
S a S a,
S a S b,
S b S a,
S b S b,
S #.
</figure>
<bodyText confidence="0.9929715">
For this grammar, strings in L(G) have the form u#v, with u E (E \ {#})* and v E (E \
{#})* having the same length.
A rule such as S aSb can be replaced by a pair of rules in binary form, for example
S aA and A Sb, where A is a new nonterminal.
</bodyText>
<sectionHeader confidence="0.477311" genericHeader="introduction">
3. Bilexical CFGs and Splittability
</sectionHeader>
<bodyText confidence="0.998528666666667">
We start this section with the definition of 2-LCFG, which is based on Eisner and
Satta (1999). Let ND be a finite alphabet whose symbols will be called delexicalized
nonterminals. We combine ND with a set E of terminal symbols as follows:
</bodyText>
<equation confidence="0.889037">
ND(E) = {A[a]  |A E ND, a E E}.
</equation>
<bodyText confidence="0.993884">
A bilexical context-free grammar is a CFG G = (E, ND(E) U {S}, S, R). Every rule in R
has one of the following five forms:
</bodyText>
<listItem confidence="0.999877">
• S A[a];
• A[a] B[b] C[a];
• A[a] B[a] C[c];
• A[a] B[a];
• A[a] a.
</listItem>
<bodyText confidence="0.9999225">
The nonterminal occurrences C[a] and B[a] in the second and third rules, respectively,
and the nonterminal occurrence B[a] in the fourth rule will be referred to as head child
occurrences. Notice that the head child of a rule is always associated with the same
terminal as the left-hand-side nonterminal. The nonterminal occurrence A[a] in the
first rule, and the nonterminal occurrences B[b] and C[c] in the second and third rules,
respectively, will be referred to as maximal projection occurrences. Observe how in a
</bodyText>
<page confidence="0.99383">
869
</page>
<note confidence="0.294902">
Computational Linguistics Volume 37, Number 4
</note>
<bodyText confidence="0.9928706">
parse tree generated by a 2-LCFG, each occurrence of a lexical element (represented as
a terminal symbol) is also part of several head child occurrences of nonterminals above
it, up to some unique maximal projection occurrence. We assume that the head child
occurrence in a rule is always marked within the rule itself, in order to disambiguate
cases in which the head child and the maximal projection share the same terminal (a = b
in the second rule or a = c in the third).1
Let G = (Σ, N, S, R) be a 2-LCFG and choose some A[a] ∈ N that occurs as maximal
pro!
ro ection in some rule in R. We now define a grammar G(A[a]) = (Σ(A[a]), N(A[a]), A[a],
R(A�a])) in lin-CFG(a). The main idea here is that G(A[a]) captures all descending paths in
parse trees of G from any maximal projection occurrence of A[a] down to a, treating the
maximal projection occurrences of G’s nonterminals to the left and right of these paths
as terminal symbols of G(A[a]). Each such maximal projection nonterminal B[b], when
treated as a terminal, will be denoted as B[b]. The start symbol is A[a] and the rule set
R(A[a]) is specified as follows:
</bodyText>
<listItem confidence="0.999995">
• D[a] → B[b] C[a] is in R(A[a]) for each rule D[a] → B[b] C[a] in R;
• D[a] → B[a] C[c] is in R(A[a]) for each rule D[a] → B[a] C[c] in R;
• D[a] → B[a] is in R(A[a]) for each rule D[a] → B[a] in R;
• D[a] → a is in R(A[a]) for each rule D[a] → a in R.
</listItem>
<bodyText confidence="0.937183833333333">
Grammar G(A[a]) might contain useless rules, that is, rules that never appear in a deriva-
tion of a string of the generated language, but this is irrelevant to the development of
the results in this article.
We now introduce an equivalence relation on 2-LCFGs, which will be used later
in the definition of splittability. As we will see, our equivalence relation is stronger
than the usual weak equivalence between grammars, where the latter only requires
that the languages generated by two grammars be the same. In addition to weak
equivalence, we demand that two 2-LCFGs establish the same predicate–argument
dependencies between lexical elements in the generated sentences, as will be explained
here.
Definition 1
Two 2-LCFGs G1 and G2 are d-equivalent if the following conditions are all satisfied:
</bodyText>
<listItem confidence="0.999285">
1. G1 and G2 have the same set of nonterminals that occur as maximal
projections;
2. G1 and G2 have the same rules rewriting the start symbol, that is, the rules
of the form S → A[a]; and
3. for each nonterminal A[a] that occurs as a maximal projection in G1 and
</listItem>
<bodyText confidence="0.6819644">
G2, the grammars G(A[a]) 1and G(A[a]) 2generate the same languages.
Lemma 1
If two 2-LCFGs G1 and G2 are d-equivalent, then L(G1) = L(G2).
1 One way to formalize this marking is to have a separate subset of delexicalized nonterminals that are part
of each maximal projection occurrence and never a part of any head child occurrence.
</bodyText>
<page confidence="0.938013">
870
</page>
<bodyText confidence="0.883809">
Nederhof and Satta Splittability of 2-LCFGs
Proof
We show the stronger statement that, for each maximal projection occurrence A[a] from
G1 and G2 (item 1 in Definition 1) and for each w ∈ E∗, we have A[a] ⇒∗ G1 w if and only
if A[a] ⇒∗G2 w. The statement of the lemma easily follows from item 2 in Definition 1. We
proceed by induction on |w|.
Assume |w |= 1, w = a. If A[a] ⇒∗G1 a, then A[a] ⇒∗G(A[a]) a. From item 3 in Defini-
tion 1 we also have A[a] ⇒∗(A[a]) a and hence A[a] ⇒∗a. The converse statement is
shown similarly. 2
Assume now |w |&gt; 1. If A[a] ⇒∗G1 w, there must be a “head-driven” derivation
rewriting maximal projection occurrence A[a] into a through a chain of head child
nonterminal occurrences. More precisely, we can write:
</bodyText>
<equation confidence="0.998371">
A[a] ⇒∗G1 B1[b1] ··· Bl[bl]aC1[c1] ··· Cr[cr]
⇒∗G1 uaC1[c1] ··· Cr[cr]
⇒∗G1 uav = w (1)
</equation>
<bodyText confidence="0.99307725">
with l, r ≥ 0, l + r &gt; 0 (because |w |&gt; 1), and the indicated occurrence of a in uav is
generated from A[a] through a chain of rule applications always rewriting the head child
of the previous rule and generating the maximal projection occurrences Bi[bi],1 ≤ i ≤ l,
and Cj[cj], 1 ≤ j ≤ r.
</bodyText>
<equation confidence="0.718587166666667">
Due to Equation (1) we have A[a] ⇒∗G(A[a]) 1B1[b1] · · · Bl[bl]aC1[c1] · · ·Cr[cr] and from
item 3 in Definition 1 we have A[a] ⇒∗G(A[a]) B1 [b1] · · · Bl[bl]aC1[c1] · · · Cr[cr]. We thus con-
2
clude that A[a] ⇒∗G2 B1[b1] · · · Bl[bl]aC1[c1] · · · Cr[cr].
From Equation (1) we can also see that there must be strings ui, 1 ≤ i ≤ l and vj,
1 ≤ j ≤ r, such that Bi[bi] ⇒∗G1 ui and Cj[bj] ⇒∗G1 vj, where u1 · · · ul = u and v1 · · · vr = v.
</equation>
<bodyText confidence="0.984784954545454">
Because each Bi[bi] and each Cj[cj] is a maximal projection occurrence, we can apply the
inductive hypothesis and conclude that Bi[bi] ⇒∗G2 ui and Cj[bj] ⇒∗G2 vj, 1 ≤ i ≤ l and
1 ≤ j ≤ r.
Putting together all of this, we have A[a] ⇒∗G2 u1 · · · ulav1 · · · vr = w. With a similar
argument we can show that A[a] ⇒∗G2 w implies A[a] ⇒∗ G1 w. ■
Besides enforcing the weak equivalence between two 2-LCFGs, the d-equivalence
relation guarantees that the grammars establish the same dependencies between pairs
of lexical elements in the generated sentences. To explain this, we borrow subsequently
the notion of dependency structure from dependency grammars.
Let G be a 2-LCFG and let t be a parse tree assigned by G to a string w ∈ E∗.
We can associate with t a dependency structure, by considering all rule occurrences
in t that link two lexical elements from w. For each rule occurrence A[a] → B[b] C[a]
in t, a link is constructed from the corresponding occurrence of b in w to the corre-
sponding occurrence of a. Similarly, a rule occurrence A[a] → B[a] C[c] gives rise to
a link from the corresponding occurrence of c to the corresponding occurrence of a.
Notice that a dependency structure abstracts away from some topological aspects of
the parse trees. For example, two rules A[a] → B[a] C[c] and B[a] → D[d] E[a] could give
rise to the same dependency structures as the two rules A[a] → D[d] F[a] and F[a] →
E[a] C[c].
It is not difficult to see that if two 2-LCFGs G1 and G2 are d-equivalent, then the sets
of dependency structures they assign to strings in the common language (via the set of
parse trees as sketched above) are identical.
</bodyText>
<page confidence="0.988336">
871
</page>
<table confidence="0.929575733333333">
Computational Linguistics Volume 37, Number 4
Example 2
Consider the 2-LCFG G1 defined by the rules:
S A[a], A[a]
A[a] B[b] A[a], B[b]
A[a] C[c] A[a], C[c]
A[a] A[a] D[d], D[d]
A[a] A[a] E[e], E[e] e;
and the 2-LCFG G2 defined by the rules:
S A[a], A&apos;[a]
A[a] B[b] A[a], B[b]
A[a] C[c] A[a], C[c]
A[a] A�[a], D[d]
A&apos;[a] A&apos;[a] D[d], E[e]
A&apos;[a] A&apos;[a] E[e].
</table>
<bodyText confidence="0.900027666666667">
G1 and G2 are d-equivalent, and thus generate the same language by Lemma 1. This
language consists of all strings of the form uav, where u E Ib,c}∗ and v E Id, e}∗. Fur-
thermore, the set of dependency structures associated by G1 and G2 to any of the strings
they can generate are the same. Figure 1 shows one instance of such a correspondence.
Note that in addition to the tree in Figure 1(a), there are two more trees generated by
grammar G1 that correspond to the dependency structure in Figure 1(c).
</bodyText>
<figureCaption confidence="0.917612">
Figure 1
</figureCaption>
<bodyText confidence="0.948667">
Two parse trees for the string bcad under grammars G1 (a) and G2 (b) from Example 2. Both trees
correspond to the same associated dependency structure (c).
</bodyText>
<page confidence="0.970466">
872
</page>
<note confidence="0.687809">
Nederhof and Satta Splittability of 2-LCFGs
</note>
<bodyText confidence="0.926386777777778">
We conclude this section with the definition of splittability, which is central to this
article. We first introduce a special form for 2-LCFGs, which we call split form. The
intuition is that a 2-LCFG is in split form if, for each maximal projection nonterminal
occurrence A[a], all arguments on the left are generated first, followed by the generation
of all arguments on the right.
Definition 2
A 2-LCFG G = (Σ,ND(Σ) U {S}, S, R) is in split form if, for each maximal projection
occurrence of a nonterminal A[a] E ND(Σ), the nonterminals in G(A[a]) can be divided
into two disjoint sets N(A[a]) land N(A[a])
</bodyText>
<equation confidence="0.918551">
r , such that A[a] E N(A[a])
l and all of the following
conditions are satisfied:
1. if D[a] B[b] C[a] in R(A[a]), then D[a], C[a] E N(A[a])
l ;
2. if D[a] B[a] C[c] in R(A[a]), then D[a], B[a] E N(A[a])
r ;
3. if D[a] B[a] in R(A[a]), then D[a] E N(A[a])
l or B[a] E N(A[a])
r ; and
</equation>
<listItem confidence="0.848381">
4. if D[a] a in R(A[a]), then D[a] E N(A[a])
r.
Note that the left arguments of A[a] are generated via the nonterminals in N(A[a])
</listItem>
<bodyText confidence="0.8322525">
l ,
and the right arguments are generated via nonterminals in N(A[a])
</bodyText>
<equation confidence="0.945834888888889">
r . Furthermore, in
the top–down generation of the arguments we can switch from nonterminals in N(A[a])
l
to nonterminals in N(A[a])
r only once, through a rule of the form D[a] B[a] such that
D[a] E NlA[a]) and B[a] E NrA[a]), as stated by the third item in Definition 2. Gram-
mar G2 from Example 2 is in split form, with N(A[a])
l = {A[a]} and N(A[a])
r = {A&apos;[a]}.
</equation>
<bodyText confidence="0.92687">
The importance of 2-LCFGs in split form is that they allow parsing in time O(|w|3),
which is independent of the size of G assuming ND is fixed. This contrasts with the time
complexity O(|w|4) for arbitrary 2-LCFGs.
We say a 2-LCFG G1 is splittable if there is a 2-LCFG G2 in split form such that
G1 and G2 are d-equivalent. Grammar G1 from Example 2 is splittable, because it is
d-equivalent to grammar G2 in the same example, and the latter is in split form.
Example 3
Consider the 2-LCFG defined by the following rules:
</bodyText>
<table confidence="0.993966666666667">
S A[a], A[a]
A[a] B[b] A&apos;[a], B[b]
A&apos;[a] A[a] C[c], C[c] c.
</table>
<bodyText confidence="0.95997825">
Note that there is an equal number of arguments on either side of the head a. No 2-LCFG
in split form can achieve this dependency, and therefore this grammar is not splittable.
We can now formally prove that if a 2-LCFG is splittable, then the left arguments of
each head are independent of its right arguments, and vice versa, in the sense that only
a finite amount of information can be passed between the two sides.
Theorem 1
Let G be a 2-LCFG. G is splittable if and only if, for each maximal projection occurrence
A[a] from G, the lin-CFG(a) G(A[a]) generates a regular language.
</bodyText>
<page confidence="0.989288">
873
</page>
<note confidence="0.292469">
Computational Linguistics Volume 37, Number 4
</note>
<equation confidence="0.889024066666667">
Proof
If G is splittable, then there exists a split 2-LCFG Gs such that G and Gs are d-equivalent.
Let A[a] be a nonterminal of Gs that occurs as maximal projection, and consider the
lin-CFG(a) G(A[a])
s , whose nonterminals are partitioned into sets N(A[a])
l and N(A[a])
r as in
Definition 2. It is not difficult to see that L(G(A[a])
s ) is a regular language. This regular
language is the finite union of the languages:
L(B[a],C[a]) = {uav  |A[a] =&gt;∗ uB[a] =&gt; uC[a] =&gt;∗ uav},
for all possible distinct choices of rules of the form B[a] -+ C[a] from G(A[a]) with
s
B[a] E N(A[a])
l and C[a] E N(A[a])
</equation>
<bodyText confidence="0.91862095">
r . For each such choice, the set of strings u is clearly
regular, as it is generated by a right-linear subgrammar. Similarly, the set of strings v
is regular. Because G and Gs are d-equivalent, it follows that each G(A[a]) generates a
regular language as well.
Conversely, assume that for each maximal projection occurrence A[a] from G
we have that G(A[a]) generates a regular language. Then we can construct an alternative
grammar in lin-CFG(a) generating the same language as G(A[a]), but now in split form.
To this end, assume a finite automaton M accepting L(G(A[a])) with a finite set Q of states
and a transition relation �. For each transition q1 � q2 of M, we can construct right-
linear rules corresponding to transitions occurring on paths from the initial state of M
to state q1, and left-linear rules corresponding to transitions occurring on paths from
state q2 to any final state of M.
B[b]
Concretely, for each transition q �-+ q� such that q1 is reachable from q&apos;, we construct
rule a -+ B b &apos; a B[b] &apos;
q[ ] [ ] q [ ], and for each transition q � q such that q is reachable from q2, we
construct rule q&apos;[a] -+ q[a] B[b]. We also construct rule A[a] -+ q0[a], where q0 is the initial
state of M, and the rule q2[a] -+ a. For each final state qf of M that is reachable from q2
we furthermore construct the rule q1[a] -+ qf[a]. The resulting grammar generates the
strings that are accepted by M by computations that traverse the transition q1 �-+ q2.
</bodyText>
<figure confidence="0.983267">
a
Each transition q1 �-+ q2 gives rise to one such grammar.
a
We can now take the disjoint union of such grammars for all transitions q1 �-+ q2,
a
</figure>
<bodyText confidence="0.998194333333333">
taking different copies of automaton states q in nonterminals q[A] for each combi-
nation of q1 and q2. The result is a grammar generating all strings accepted by M.
Nonterminals q[a] are defined to be in N(A[a])
</bodyText>
<equation confidence="0.9154936">
l or in N(A[a])
r depending on whether a state
q1 in a transition q1 �-+ q2 is reachable from q or whether q is reachable from a state q2 in a
a
transition q1 �-+ q2. Naturally A[a] is taken to be in N(A[a])
</equation>
<bodyText confidence="0.7909345">
a l . The requirements on split form
are now clearly satisfied. ■
</bodyText>
<sectionHeader confidence="0.897041" genericHeader="method">
4. Undecidability Results
</sectionHeader>
<bodyText confidence="0.99995">
This section presents the main results of this article. We start with some basic notions
from computability theory and with the adopted notation for Turing machines.
We use single-tape, single-head, deterministic Turing machines. A configuration of
a Turing machine M is a string over some alphabet Σ, encoding the current content
of the tape along with the position of the head on the tape and the current state. In
the initial configuration, the tape contains the input to the Turing machine, the head
is placed at the start of the tape, and the machine is in its (unique) initial state. An
accepting configuration is any configuration of M of which the current state belongs to
a distinguished set of accepting states. An accepting computation of M is a sequence
of configurations of M starting with an initial configuration and ending with a final
</bodyText>
<page confidence="0.989845">
874
</page>
<note confidence="0.681825">
Nederhof and Satta Splittability of 2-LCFGs
</note>
<bodyText confidence="0.999653857142857">
configuration, and such that consecutive configurations are related by a valid move of
the machine. Without loss of generality, we assume that any accepting computation has
an odd number of moves, and at least three.
For a given string w, we write w� to denote the mirror image of w. Consider a Turing
machine M whose configurations are defined over some alphabet Σ, and assume two
fresh symbols $ and # not in Σ. Following the notation of Bordihn, Holzer, and Kutrib
(2005), we encode accepting computations of M as strings of the form:
</bodyText>
<equation confidence="0.99741">
w0$w2$ ... $w2k#w2k+1$ ... $w3$�w1 (2)
</equation>
<bodyText confidence="0.989498866666667">
Here, w0, ..., w2k+1 are configurations of M, with w0 an initial configuration and w2k+1
an accepting configuration. Furthermore, for each i with 0 &lt; i &lt; 2k, configuration wi is
related to configuration wi+1 by a valid move of M. We define VALC(M) to be the set
of all valid computations of M, represented as before. We say that a string u is accepted
by M if u occurs in an initial configuration w0 in some computation in VALC(M). The
language L(M) is defined to be the set of all strings accepted by M.
We rely on the following result (Hopcroft and Ullman 1979, page 189):
Lemma 2
For a Turing machine M, it is undecidable whether the language L(M) is finite.
We also need the following result, which is essentially the same as a result reported
by Hopcroft and Ullman (1979, Lemma 8.8, page 204). We provide a complete proof
here because we need to adapt the result to our special encoding of valid computa-
tions, which is somewhat different from that used by Hopcroft and Ullman (1979), and
because Hopcroft and Ullman only report a sketch of the proof.
Lemma 3
For a Turing machine M, the language VALC(M) is context-free if and only if L(M) is
finite.
Proof
If L(M) is finite, then VALC(M) is also finite (because M is deterministic). Hence
VALC(M) is a context-free language.
If L(M) is an infinite language, we need to show that VALC(M) cannot be a context-
free language. To this end, we use the version of Ogden’s lemma presented by Hopcroft
and Ullman (1979, page 129). This lemma states that if L is a context-free language, there
exists a constant n such that, if we arbitrarily mark n or more distinct positions in a string
in L, then we can write that string as uvwxy in such a way that v and x together include
at least one marked position, vwx includes at most n marked positions, and uviwxiy is
in L for any i ≥ 0.
Assume now that VALC(M) is a CFL. Because L(M) is an infinite language,
the length of its strings can be arbitrarily large. Therefore there must be a string in
VALC(M) of the form:
</bodyText>
<equation confidence="0.856733">
α = w0$w2$ ... $w2k#�w2k+1$ ... $w3$�w1,
</equation>
<bodyText confidence="0.9840885">
with w2 having length greater than n. This is so because the initial configuration w0,
representing the input string, can be chosen with arbitrarily large length, and only two
</bodyText>
<page confidence="0.994086">
875
</page>
<note confidence="0.584489">
Computational Linguistics Volume 37, Number 4
</note>
<bodyText confidence="0.998818736842105">
moves of M have been applied to obtain w2 from w0. Let us mark all positions of α that
fall within w2.
Now let α = uvwxy be a factorization satisfying Ogden’s lemma. If v or x contain
one or more occurrences of the symbol $, we can pump such a string in α and obtain a
new string which is not a valid computation, which is a contradiction. More precisely,
assume that v contains exactly one occurrence of $, and write v = v&apos;$v&apos;&apos;. If we choose
i = 3 in Ogden’s lemma, we obtain a new string with two instances of configuration v&apos;&apos;v&apos;
in it. This would imply a loop in the computation of a deterministic Turing machine,
and therefore the resulting string cannot be an accepting computation. Using similar
arguments, we can conclude that neither v nor x contains an occurrence of symbol $.
Because v and x together must include at least one marked position, we can distin-
guish two (not necessarily distinct) cases. In the first case, v is entirely included in the
string w2. This means that we can pump w2 to a new configuration of arbitrarily large
length, without pumping w0. But this is a contradiction, because w0 and w2 are only two
moves apart. In the second case, x is entirely included in the string w2. Similarly to the
first case, we can pump w2 to a new configuration of arbitrarily large length, without
pumping w1, but this is also a contradiction because the two configurations are related
by a single move. Therefore VALC(M) cannot be a CFL. ■
We now define the set of invalid computations of M, written INVALC(M), as:
</bodyText>
<equation confidence="0.977075">
INVALC(M) = ((Σ U {$})* · {#} · (Σ U {$})*) \ VALC(M) (3)
</equation>
<bodyText confidence="0.9723240625">
We deviate from Bordihn, Holzer, and Kutrib (2005) in that we only consider those
strings in the complement of VALC(M) that contain exactly one occurrence of #. Be-
cause all the operations that need to be applied to obtain INVALC(M) from VALC(M),
or vice versa, preserve regular languages, it follows that VALC(M) is a regular language
if and only if INVALC(M) is a regular language.
The following result relates the language INVALC(M) to the class lin-CFG(#), that
is, the linear context-free grammars with center marker #, introduced in Section 2. Our
proof differs somewhat from proofs of similar statements in Hopcroft and Ullman (1979)
for general linear CFGs, in that the center marker has a prominent role in the grammar,
and the construction must ensure that # occurs exactly once.
Lemma 4
Given a Turing machine M, one can effectively construct a grammar in lin-CFG(#)
generating INVALC(M).
Proof
Intuitively, our grammar is the union of several subgrammars, which generate,
respectively:
</bodyText>
<listItem confidence="0.9971155">
• a set of strings of the form (2) in which the wi can be arbitrary strings over
Σ, except that w0 must not be an initial configuration,
• similarly, a set of strings of the form (2) in which w2k+1 must not be a final
configuration,
• a set of strings of the form (2) in which for some i, w2i+1 must not be the
successor of w2i,
</listItem>
<page confidence="0.985831">
876
</page>
<note confidence="0.695367">
Nederhof and Satta Splittability of 2-LCFGs
</note>
<listItem confidence="0.999774666666667">
• a set of strings of the form (2) in which for some i, w2i must not be the
successor of w2i−1,
• a set of strings of the form:
</listItem>
<equation confidence="0.661066">
u1$ ... $uk#v1$ ... $vm
</equation>
<bodyText confidence="0.803266">
where ui E E* (1 &lt; i &lt; k), vj E E* (1 &lt; j &lt; m) and k &lt; m,
</bodyText>
<listItem confidence="0.981393">
• a set of strings of the form:
</listItem>
<equation confidence="0.826941">
u1$ ... $uk#v1$ ... $vm
</equation>
<bodyText confidence="0.994156033333333">
where ui E E* (1 &lt; i &lt; k), vj E E* (1 &lt; j &lt; m) and m &lt; k.
It is straightforward to construct each of these subgrammars as linear grammars with
center marker #, similarly to proofs from Hopcroft and Ullman (1979, pages 203 and
215). The statement of the theorem then follows from the fact that the class lin-CFG(#)
is closed under (finite) union. ■
We now show that it is undecidable whether a linear context-free grammar with
a center marker generates a regular language. This result is stronger than a similar
result stating the undecidability of regularity for general linear context-free languages,
originally obtained by Hunt III and Rosenkrantz (1974) and also reported by Hopcroft
and Ullman (1979, Exercise 8.10a, page 214), in that our languages have an explicit center
marker that unambiguously splits the string into two parts. Here we report a direct
proof of the result for linear context-free grammars with a center marker, whereas the
similar result for general linear context-free grammars is indirectly obtained by Hunt
III and Rosenkrantz (1974, Corollary 2.7(5) and discussion at page 66) through sufficient
conditions for the undecidability of a family of general predicates.
Theorem 2
It is undecidable whether a grammar in lin-CFG(#) generates a regular language.
Proof
Let M be a Turing machine. We start by claiming that L(M) is finite if and only if
INVALC(M) is regular. To show this, assume first that L(M) is finite. Because our
Turing machines are deterministic, VALC(M) is also finite, and therefore regular. From
Equation (3), it follows that INVALC(M) is regular as well. Conversely, if INVALC(M)
is regular, then so is VALC(M). This means that VALC(M) is context-free and, by
Lemma 3, that L(M) is finite.
Suppose now that it is decidable whether a grammar in lin-CFG(#) generates a
regular language. Following Lemma 4, we can effectively construct a grammar in lin-
CFG(#) generating INVALC(M). Under our assumption, we can now decide whether
INVALC(M) is regular and hence, by our claim, whether L(M) is finite. This contradicts
Lemma 2. Hence, it must be undecidable whether a grammar in lin-CFG(#) generates a
regular language. ■
</bodyText>
<page confidence="0.96983">
877
</page>
<figure confidence="0.986966571428571">
Computational Linguistics Volume 37, Number 4
Example 4
Consider the (unambiguous) grammar that is defined by the rules:
S -+ AJBJC
A - +aAaJbAbJaAbJbAaJ#
B - +aBJbBJaAJbA
C -+ CaJCbJAaJAb
</figure>
<bodyText confidence="0.9281591875">
Despite rules such as A -+ aAa and A -+ bAb, which by themselves may appear to make
the language non-regular, the generated language is in fact {a, b}*#{a, b}*.
We now return to bilexical context-free grammars. In Section 3 we have constructed
grammars G(A[a]) out of a 2-LCFG G, for each nonterminal A[a] that occurs as maximal
projection in rules from G. We then characterized splittability of G, in Theorem 1, in
terms of the regularity of the languages generated by each G(A[a]). Note that each G(A[a])
is in lin-CFG(a). In order to obtain the main result of this article, we only need to look
at a very simple type of 2-LCFG in which we can identify a given linear context-free
grammar with a center marker.
Theorem 3
Splittability of bilexical CFGs is undecidable.
Proof
We show that the existence of an algorithm for deciding whether a 2-LCFG is splittable
would imply an algorithm for deciding whether any grammar in lin-CFG(#) generates
a regular language, contrary to Theorem 2.
Let G1 be a grammar in lin-CFG(#). Without any loss of generality, we assume that:
</bodyText>
<listItem confidence="0.9992232">
• G1 is in binary form;
• the start symbol of G1 has the form S[#];
• each nonterminal symbol of G1 has the form A[#], for some A; and
• each terminal symbol of G1 is either # or a symbol of the form B[b], for
some B and some b.
</listItem>
<bodyText confidence="0.998798">
From G1 we construct a 2-LCFG G2 as follows. The start symbol of G2 is S†, and G2
has a single rule S† -+ S[#] expanding the start symbol. Each rule from G1 is copied to
be a rule of G2, after replacing each terminal symbol B[b] by a nonterminal B[b]. The
remaining rules are of the form B[b] -+ b for each terminal symbol B[b] of G1.
It is easy to see that G(2S[#]) = G1. We also observe that, for each nonterminal B[b] of
G2, grammar G(B[b])
2 generates the regular language {b}. From Theorem 1 it then follows
that G2 is splittable if and only if G1 is regular. ■
</bodyText>
<sectionHeader confidence="0.998135" genericHeader="discussions">
5. Discussion
</sectionHeader>
<bodyText confidence="0.999856">
Splittability of 2-LCFGs is of central importance to the processing efficiency of several
models that are currently being used in statistical natural language parsing, as discussed
in the Introduction. The notion of splittability has been originally introduced by Eisner
(1997) and Eisner and Satta (1999) for the closely related formalism of head automaton
grammars. In this article we gave an equivalent definition for 2-LCFGs, through the
notion of d-equivalence, and we showed that splittability of 2-LCFGs is undecidable.
</bodyText>
<page confidence="0.984886">
878
</page>
<note confidence="0.737016">
Nederhof and Satta Splittability of 2-LCFGs
</note>
<bodyText confidence="0.999972">
The result immediately carries over to head automaton grammars, through the standard
mapping defined by Eisner and Satta (1999).
Our result is based on a characterization of the notion of splittability (theorem 1) in
terms of a factorization of a bilexical CFG into linear context-free grammars with center
markers, and on the regularity of these linear grammars. The same characterization has
been claimed by Eisner and Satta (1999) relative to head automaton grammars, without
a formal proof. Central to our result is a proof showing the undecidability of regularity
for linear context-free grammars with center markers (Theorem 2). This strengthens an
already known result stating the undecidability of regularity for general linear context-
free languages.
The main implication of our results is that mechanical analysis of a 2-LCFG will not
suffice to determine whether the grammar is splittable or not. There are trivial sufficient
conditions for splittability, as for example requiring that the grammar is already in the
split form of definition 2. Also, if G(B[b]) has a single nonterminal, for each B[b] that
occurs as maximal projection in a 2-LCFG G, then G is trivially splittable. It is an open
problem whether splittability is decidable in case the number of nonterminals in each
G(B[b]) is bounded by some constant larger than one. The proof techniques presented in
this article do not seem to lend themselves to extension of our undecidability results in
this direction. Other interesting sufficient conditions for splittability are not known.
To obtain a more general setting, one might depart from 2-LCFGs and consider
Chomsky normal form context-free grammars where each binary rule classifies its two
nonterminals into functor (or predicate projection) and argument. Also in this case, one
can pose the question of whether the two processes of generating the left and the right
arguments of each predicate are independent one of the other. The results reported in
this article can be extended to show undecidability of this question as well.
</bodyText>
<sectionHeader confidence="0.996509" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999980833333333">
We are indebted to the anonymous reviewers
for many detailed and helpful comments.
Among other things, the terminology has
been improved relative to the first version
of this article. This we owe to a valuable
suggestion from one of the reviewers.
</bodyText>
<sectionHeader confidence="0.99835" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708212765957">
Alshawi, H. 1996. Head automata and
bilingual tiling: Translation with minimal
representations. In 34th Annual Meeting of
the Association for Computational Linguistics,
Proceedings of the Conference, pages 167–176,
Santa Cruz, CA.
Bordihn, H., M. Holzer, and M. Kutrib.
2005. Some non-semi-decidability
problems for linear and deterministic
context-free languages. In Implementation
and Application of Automata: 9th
International Conference, pages 68–79,
Kingston.
Charniak, E. 2001. Immediate-head parsing
for language models. In 39th Annual
Meeting and 10th Conference of the European
Chapter of the Association for Computational
Linguistics, Proceedings of the Conference,
pages 116–123, Toulouse.
Collins, M. 2003. Head-driven statistical
models for natural language parsing.
Computational Linguistics, 29(4):589–637.
Eisner, J. 1996. Three new probabilistic
models for dependency parsing: An
exploration. In The 16th International
Conference on Computational Linguistics,
volume 1, pages 340–345, Copenhagen.
Eisner, J. 1997. Bilexical grammars and
a cubic-time probabilistic parser.
In International Workshop on Parsing
Technologies, pages 54–65, Cambridge, MA.
Eisner, J. and G. Satta. 1999. Efficient parsing
for bilexical context-free grammars and
head automaton grammars. In 37th Annual
Meeting of the Association for Computational
Linguistics, Proceedings of the Conference,
pages 457–464, College Park, MD.
Hopcroft, J. E. and J. D. Ullman. 1979.
Introduction to Automata Theory, Languages,
and Computation. Addison-Wesley,
Reading, MA.
Hunt III, H. B. and D. J. Rosenkrantz.1974.
Computational parallels between the
regular and context-free languages.
In Conference Record of the Sixth Annual
ACM Symposium on Theory of Computing,
pages 64–74, Seattle, WA.
</reference>
<page confidence="0.998968">
879
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.634801">
<title confidence="0.895969">Splittability of Bilexical Context-Free</title>
<author confidence="0.695895">Grammars is Undecidable</author>
<affiliation confidence="0.9915665">University of St. Andrews University of Padua</affiliation>
<abstract confidence="0.990609875">Bilexical context-free grammars (2-LCFGs) have proved to be accurate models for statistical natural language parsing. Existing dynamic programming algorithms used to parse sentences these models have running time of where w is the input string. A 2-LCFG is splittable if the left arguments of a lexical head are always independent of the right arguments, and vice versa. When a 2-LCFGs is splittable, parsing time can be improved to Testing this property is therefore of central interest to parsing efficiency. In this article, however, we show the negative result that splittability of 2-LCFGs is undecidable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>Head automata and bilingual tiling: Translation with minimal representations.</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>167--176</pages>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="1644" citStr="Alshawi (1996)" startWordPosition="247" endWordPosition="248">rmore, no more than two symbols can be used in the right-hand side of a rule, and the terminal symbol associated with the lefthand side of a rule must also occur on the right-hand side. In this way, 2-LCFGs are able to specify syntactic constraints as well as lexically specific preferences that influence the combination of predicates with their arguments or modifiers. Models based on 2-LCFGs have therefore been of central interest in statistical natural language parsing, as they allow selection of high-quality parse trees. One can in fact see 2-LCFGs as abstract models of the head automata of Alshawi (1996), the probabilistic projective dependency grammars of Eisner (1996), and the head-driven statistical models of Charniak (2001) and Collins (2003). Parsing algorithms based on 2-LCFGs can be very efficient. In the general case, existing dynamic programming algorithms have running time of O(|w|4), where w is the input string. (In this article we disregard complexity factors that depend on the input grammar, which we will consider to be constants.) In cases in which, for each (lexical) head, the two processes of generating its left and right arguments are, to some ∗ School of Computer Science, Un</context>
</contexts>
<marker>Alshawi, 1996</marker>
<rawString>Alshawi, H. 1996. Head automata and bilingual tiling: Translation with minimal representations. In 34th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pages 167–176, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bordihn</author>
<author>M Holzer</author>
<author>M Kutrib</author>
</authors>
<title>Some non-semi-decidability problems for linear and deterministic context-free languages.</title>
<date>2005</date>
<booktitle>In Implementation and Application of Automata: 9th International Conference,</booktitle>
<pages>68--79</pages>
<location>Kingston.</location>
<marker>Bordihn, Holzer, Kutrib, 2005</marker>
<rawString>Bordihn, H., M. Holzer, and M. Kutrib. 2005. Some non-semi-decidability problems for linear and deterministic context-free languages. In Implementation and Application of Automata: 9th International Conference, pages 68–79, Kingston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Immediate-head parsing for language models.</title>
<date>2001</date>
<booktitle>In 39th Annual Meeting and 10th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>116--123</pages>
<location>Toulouse.</location>
<contexts>
<context position="1770" citStr="Charniak (2001)" startWordPosition="263" endWordPosition="264">thand side of a rule must also occur on the right-hand side. In this way, 2-LCFGs are able to specify syntactic constraints as well as lexically specific preferences that influence the combination of predicates with their arguments or modifiers. Models based on 2-LCFGs have therefore been of central interest in statistical natural language parsing, as they allow selection of high-quality parse trees. One can in fact see 2-LCFGs as abstract models of the head automata of Alshawi (1996), the probabilistic projective dependency grammars of Eisner (1996), and the head-driven statistical models of Charniak (2001) and Collins (2003). Parsing algorithms based on 2-LCFGs can be very efficient. In the general case, existing dynamic programming algorithms have running time of O(|w|4), where w is the input string. (In this article we disregard complexity factors that depend on the input grammar, which we will consider to be constants.) In cases in which, for each (lexical) head, the two processes of generating its left and right arguments are, to some ∗ School of Computer Science, University of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX, Scotland. E-mail: markjan.nederhof@gmail.com. ∗∗ Department</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>Charniak, E. 2001. Immediate-head parsing for language models. In 39th Annual Meeting and 10th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, pages 116–123, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="1789" citStr="Collins (2003)" startWordPosition="266" endWordPosition="267"> must also occur on the right-hand side. In this way, 2-LCFGs are able to specify syntactic constraints as well as lexically specific preferences that influence the combination of predicates with their arguments or modifiers. Models based on 2-LCFGs have therefore been of central interest in statistical natural language parsing, as they allow selection of high-quality parse trees. One can in fact see 2-LCFGs as abstract models of the head automata of Alshawi (1996), the probabilistic projective dependency grammars of Eisner (1996), and the head-driven statistical models of Charniak (2001) and Collins (2003). Parsing algorithms based on 2-LCFGs can be very efficient. In the general case, existing dynamic programming algorithms have running time of O(|w|4), where w is the input string. (In this article we disregard complexity factors that depend on the input grammar, which we will consider to be constants.) In cases in which, for each (lexical) head, the two processes of generating its left and right arguments are, to some ∗ School of Computer Science, University of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX, Scotland. E-mail: markjan.nederhof@gmail.com. ∗∗ Department of Information Eng</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Collins, M. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In The 16th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>340--345</pages>
<location>Copenhagen.</location>
<contexts>
<context position="1711" citStr="Eisner (1996)" startWordPosition="255" endWordPosition="256">f a rule, and the terminal symbol associated with the lefthand side of a rule must also occur on the right-hand side. In this way, 2-LCFGs are able to specify syntactic constraints as well as lexically specific preferences that influence the combination of predicates with their arguments or modifiers. Models based on 2-LCFGs have therefore been of central interest in statistical natural language parsing, as they allow selection of high-quality parse trees. One can in fact see 2-LCFGs as abstract models of the head automata of Alshawi (1996), the probabilistic projective dependency grammars of Eisner (1996), and the head-driven statistical models of Charniak (2001) and Collins (2003). Parsing algorithms based on 2-LCFGs can be very efficient. In the general case, existing dynamic programming algorithms have running time of O(|w|4), where w is the input string. (In this article we disregard complexity factors that depend on the input grammar, which we will consider to be constants.) In cases in which, for each (lexical) head, the two processes of generating its left and right arguments are, to some ∗ School of Computer Science, University of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX, </context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Eisner, J. 1996. Three new probabilistic models for dependency parsing: An exploration. In The 16th International Conference on Computational Linguistics, volume 1, pages 340–345, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Bilexical grammars and a cubic-time probabilistic parser.</title>
<date>1997</date>
<booktitle>In International Workshop on Parsing Technologies,</booktitle>
<pages>54--65</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="3065" citStr="Eisner 1997" startWordPosition="453" endWordPosition="454"> Italy. E-mail: satta@dei.unipd.it. Submission received: 8 September 2010; revised submission received: 21 January 2011; accepted for publication: 17 April 2011. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 4 extent, independent one of the other, parsing based on 2-LCFGs can be asymptotically improved to O(|w|3). The reader is referred to Eisner and Satta (1999) for a detailed presentation of these computational results. In the literature, this condition on independence between left and right arguments of each head has been called splittability (Eisner 1997; Eisner and Satta 1999). Testing for splittability on an input 2-LCFG is therefore of central interest to parsing efficiency. The computability of this test has never been investigated, however. In this article splittability is defined for 2-LCFGs in terms of equivalence to another grammar in which independence between left and right arguments of each head is ensured by a simple syntactic restriction. This restriction is called split form. Informally, a 2-LCFG is in split form if it can be factorized into individual subgrammars, one for each head, and each subgrammar produces the left and the</context>
<context position="32421" citStr="Eisner (1997)" startWordPosition="5810" endWordPosition="5811"> B[b]. The remaining rules are of the form B[b] -+ b for each terminal symbol B[b] of G1. It is easy to see that G(2S[#]) = G1. We also observe that, for each nonterminal B[b] of G2, grammar G(B[b]) 2 generates the regular language {b}. From Theorem 1 it then follows that G2 is splittable if and only if G1 is regular. ■ 5. Discussion Splittability of 2-LCFGs is of central importance to the processing efficiency of several models that are currently being used in statistical natural language parsing, as discussed in the Introduction. The notion of splittability has been originally introduced by Eisner (1997) and Eisner and Satta (1999) for the closely related formalism of head automaton grammars. In this article we gave an equivalent definition for 2-LCFGs, through the notion of d-equivalence, and we showed that splittability of 2-LCFGs is undecidable. 878 Nederhof and Satta Splittability of 2-LCFGs The result immediately carries over to head automaton grammars, through the standard mapping defined by Eisner and Satta (1999). Our result is based on a characterization of the notion of splittability (theorem 1) in terms of a factorization of a bilexical CFG into linear context-free grammars with ce</context>
</contexts>
<marker>Eisner, 1997</marker>
<rawString>Eisner, J. 1997. Bilexical grammars and a cubic-time probabilistic parser. In International Workshop on Parsing Technologies, pages 54–65, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
<author>G Satta</author>
</authors>
<title>Efficient parsing for bilexical context-free grammars and head automaton grammars.</title>
<date>1999</date>
<booktitle>In 37th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>457--464</pages>
<location>College Park, MD.</location>
<contexts>
<context position="2866" citStr="Eisner and Satta (1999)" startWordPosition="422" endWordPosition="425">niversity of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX, Scotland. E-mail: markjan.nederhof@gmail.com. ∗∗ Department of Information Engineering, University of Padua, via Gradenigo 6/A, I-35131 Padova, Italy. E-mail: satta@dei.unipd.it. Submission received: 8 September 2010; revised submission received: 21 January 2011; accepted for publication: 17 April 2011. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 4 extent, independent one of the other, parsing based on 2-LCFGs can be asymptotically improved to O(|w|3). The reader is referred to Eisner and Satta (1999) for a detailed presentation of these computational results. In the literature, this condition on independence between left and right arguments of each head has been called splittability (Eisner 1997; Eisner and Satta 1999). Testing for splittability on an input 2-LCFG is therefore of central interest to parsing efficiency. The computability of this test has never been investigated, however. In this article splittability is defined for 2-LCFGs in terms of equivalence to another grammar in which independence between left and right arguments of each head is ensured by a simple syntactic restrict</context>
<context position="7525" citStr="Eisner and Satta (1999)" startWordPosition="1271" endWordPosition="1274">a language-preserving transformation of grammars in lin-CFG(#) to binary form, as suggested by the following example. Example 1 Let E = {a, b, #}. One member of lin-CFG(#) is the CFG G defined by the rules: S a S a, S a S b, S b S a, S b S b, S #. For this grammar, strings in L(G) have the form u#v, with u E (E \ {#})* and v E (E \ {#})* having the same length. A rule such as S aSb can be replaced by a pair of rules in binary form, for example S aA and A Sb, where A is a new nonterminal. 3. Bilexical CFGs and Splittability We start this section with the definition of 2-LCFG, which is based on Eisner and Satta (1999). Let ND be a finite alphabet whose symbols will be called delexicalized nonterminals. We combine ND with a set E of terminal symbols as follows: ND(E) = {A[a] |A E ND, a E E}. A bilexical context-free grammar is a CFG G = (E, ND(E) U {S}, S, R). Every rule in R has one of the following five forms: • S A[a]; • A[a] B[b] C[a]; • A[a] B[a] C[c]; • A[a] B[a]; • A[a] a. The nonterminal occurrences C[a] and B[a] in the second and third rules, respectively, and the nonterminal occurrence B[a] in the fourth rule will be referred to as head child occurrences. Notice that the head child of a rule is al</context>
<context position="32449" citStr="Eisner and Satta (1999)" startWordPosition="5813" endWordPosition="5816">ng rules are of the form B[b] -+ b for each terminal symbol B[b] of G1. It is easy to see that G(2S[#]) = G1. We also observe that, for each nonterminal B[b] of G2, grammar G(B[b]) 2 generates the regular language {b}. From Theorem 1 it then follows that G2 is splittable if and only if G1 is regular. ■ 5. Discussion Splittability of 2-LCFGs is of central importance to the processing efficiency of several models that are currently being used in statistical natural language parsing, as discussed in the Introduction. The notion of splittability has been originally introduced by Eisner (1997) and Eisner and Satta (1999) for the closely related formalism of head automaton grammars. In this article we gave an equivalent definition for 2-LCFGs, through the notion of d-equivalence, and we showed that splittability of 2-LCFGs is undecidable. 878 Nederhof and Satta Splittability of 2-LCFGs The result immediately carries over to head automaton grammars, through the standard mapping defined by Eisner and Satta (1999). Our result is based on a characterization of the notion of splittability (theorem 1) in terms of a factorization of a bilexical CFG into linear context-free grammars with center markers, and on the reg</context>
</contexts>
<marker>Eisner, Satta, 1999</marker>
<rawString>Eisner, J. and G. Satta. 1999. Efficient parsing for bilexical context-free grammars and head automaton grammars. In 37th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pages 457–464, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hopcroft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="4953" citStr="Hopcroft and Ullman 1979" startWordPosition="753" endWordPosition="756">ussed, there may be additional rules that make the observed dependencies between left and right arguments irrelevant. In fact, splittability of a 2-LCFG is undecidable, as will be shown in this article. Our result is based on the fact that it is undecidable whether a linear context-free grammar with a center marker (to be defined later) generates a regular language. This fact is originally proved in this article, and does not follow from the weaker result stating the undecidability of regularity of (general) linear context-free languages, which is well known in the formal language literature (Hopcroft and Ullman 1979, exercise 8.10a, page 214) and which is originally due to Hunt III and Rosenkrantz (1974). The remaining part of this article is organized as follows. In Section 2 we present some preliminary background, and in Section 3 we define 2-LCFGs and the notion of splittability. In Section 4 we prove the main result of this article, and draw some conclusions in Section 5. 2. Preliminaries In this article we assume the reader is familiar with the notions of context-free grammar, Turing machine, and undecidability (see, e.g., Hopcroft and Ullman 1979). We briefly summarize the adopted notation now. A c</context>
<context position="22961" citStr="Hopcroft and Ullman 1979" startWordPosition="4119" endWordPosition="4122">s strings of the form: w0$w2$ ... $w2k#w2k+1$ ... $w3$�w1 (2) Here, w0, ..., w2k+1 are configurations of M, with w0 an initial configuration and w2k+1 an accepting configuration. Furthermore, for each i with 0 &lt; i &lt; 2k, configuration wi is related to configuration wi+1 by a valid move of M. We define VALC(M) to be the set of all valid computations of M, represented as before. We say that a string u is accepted by M if u occurs in an initial configuration w0 in some computation in VALC(M). The language L(M) is defined to be the set of all strings accepted by M. We rely on the following result (Hopcroft and Ullman 1979, page 189): Lemma 2 For a Turing machine M, it is undecidable whether the language L(M) is finite. We also need the following result, which is essentially the same as a result reported by Hopcroft and Ullman (1979, Lemma 8.8, page 204). We provide a complete proof here because we need to adapt the result to our special encoding of valid computations, which is somewhat different from that used by Hopcroft and Ullman (1979), and because Hopcroft and Ullman only report a sketch of the proof. Lemma 3 For a Turing machine M, the language VALC(M) is context-free if and only if L(M) is finite. Proof</context>
<context position="26904" citStr="Hopcroft and Ullman (1979)" startWordPosition="4826" endWordPosition="4829">om Bordihn, Holzer, and Kutrib (2005) in that we only consider those strings in the complement of VALC(M) that contain exactly one occurrence of #. Because all the operations that need to be applied to obtain INVALC(M) from VALC(M), or vice versa, preserve regular languages, it follows that VALC(M) is a regular language if and only if INVALC(M) is a regular language. The following result relates the language INVALC(M) to the class lin-CFG(#), that is, the linear context-free grammars with center marker #, introduced in Section 2. Our proof differs somewhat from proofs of similar statements in Hopcroft and Ullman (1979) for general linear CFGs, in that the center marker has a prominent role in the grammar, and the construction must ensure that # occurs exactly once. Lemma 4 Given a Turing machine M, one can effectively construct a grammar in lin-CFG(#) generating INVALC(M). Proof Intuitively, our grammar is the union of several subgrammars, which generate, respectively: • a set of strings of the form (2) in which the wi can be arbitrary strings over Σ, except that w0 must not be an initial configuration, • similarly, a set of strings of the form (2) in which w2k+1 must not be a final configuration, • a set o</context>
<context position="28608" citStr="Hopcroft and Ullman (1979" startWordPosition="5150" endWordPosition="5153">d to construct each of these subgrammars as linear grammars with center marker #, similarly to proofs from Hopcroft and Ullman (1979, pages 203 and 215). The statement of the theorem then follows from the fact that the class lin-CFG(#) is closed under (finite) union. ■ We now show that it is undecidable whether a linear context-free grammar with a center marker generates a regular language. This result is stronger than a similar result stating the undecidability of regularity for general linear context-free languages, originally obtained by Hunt III and Rosenkrantz (1974) and also reported by Hopcroft and Ullman (1979, Exercise 8.10a, page 214), in that our languages have an explicit center marker that unambiguously splits the string into two parts. Here we report a direct proof of the result for linear context-free grammars with a center marker, whereas the similar result for general linear context-free grammars is indirectly obtained by Hunt III and Rosenkrantz (1974, Corollary 2.7(5) and discussion at page 66) through sufficient conditions for the undecidability of a family of general predicates. Theorem 2 It is undecidable whether a grammar in lin-CFG(#) generates a regular language. Proof Let M be a T</context>
</contexts>
<marker>Hopcroft, Ullman, 1979</marker>
<rawString>Hopcroft, J. E. and J. D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H B Hunt</author>
<author>D J Rosenkrantz 1974</author>
</authors>
<title>Computational parallels between the regular and context-free languages.</title>
<booktitle>In Conference Record of the Sixth Annual ACM Symposium on Theory of Computing,</booktitle>
<pages>64--74</pages>
<location>Seattle, WA.</location>
<marker>Hunt, 1974, </marker>
<rawString>Hunt III, H. B. and D. J. Rosenkrantz.1974. Computational parallels between the regular and context-free languages. In Conference Record of the Sixth Annual ACM Symposium on Theory of Computing, pages 64–74, Seattle, WA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>