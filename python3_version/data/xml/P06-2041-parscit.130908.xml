<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000362">
<title confidence="0.995759">
Discriminative Classifiers for Deterministic Dependency Parsing
</title>
<author confidence="0.977644">
Johan Hall Joakim Nivre Jens Nilsson
</author>
<affiliation confidence="0.91774">
V¨axj¨o University V¨axj¨o University and V¨axj¨o University
jni@msi.vxu.se Uppsala University jha@msi.vxu.se
</affiliation>
<email confidence="0.990616">
nivre@msi.vxu.se
</email>
<sectionHeader confidence="0.99367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999903263157895">
Deterministic parsing guided by treebank-
induced classifiers has emerged as a
simple and efficient alternative to more
complex models for data-driven parsing.
We present a systematic comparison of
memory-based learning (MBL) and sup-
port vector machines (SVM) for inducing
classifiers for deterministic dependency
parsing, using data from Chinese, English
and Swedish, together with a variety of
different feature models. The comparison
shows that SVM gives higher accuracy for
richly articulated feature models across all
languages, albeit with considerably longer
training times. The results also confirm
that classifier-based deterministic parsing
can achieve parsing accuracy very close to
the best results reported for more complex
parsing models.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999797407407407">
Mainstream approaches in statistical parsing are
based on nondeterministic parsing techniques,
usually employing some kind of dynamic pro-
gramming, in combination with generative prob-
abilistic models that provide an n-best ranking of
the set of candidate analyses derived by the parser
(Collins, 1997; Collins, 1999; Charniak, 2000).
These parsers can be enhanced by using a discrim-
inative model, which reranks the analyses out-
put by the parser (Johnson et al., 1999; Collins
and Duffy, 2005; Charniak and Johnson, 2005).
Alternatively, discriminative models can be used
to search the complete space of possible parses
(Taskar et al., 2004; McDonald et al., 2005).
A radically different approach is to perform
disambiguation deterministically, using a greedy
parsing algorithm that approximates a globally op-
timal solution by making a sequence of locally
optimal choices, guided by a classifier trained on
gold standard derivations from a treebank. This
methodology has emerged as an alternative to
more complex models, especially in dependency-
based parsing. It was first used for unlabeled de-
pendency parsing by Kudo and Matsumoto (2002)
(for Japanese) and Yamada and Matsumoto (2003)
(for English). It was extended to labeled depen-
dency parsing by Nivre et al. (2004) (for Swedish)
and Nivre and Scholz (2004) (for English). More
recently, it has been applied with good results to
lexicalized phrase structure parsing by Sagae and
Lavie (2005).
The machine learning methods used to induce
classifiers for deterministic parsing are dominated
by two approaches. Support vector machines
(SVM), which combine the maximum margin
strategy introduced by Vapnik (1995) with the use
of kernel functions to map the original feature
space to a higher-dimensional space, have been
used by Kudo and Matsumoto (2002), Yamada and
Matsumoto (2003), and Sagae and Lavie (2005),
among others. Memory-based learning (MBL),
which is based on the idea that learning is the
simple storage of experiences in memory and that
solving a new problem is achieved by reusing so-
lutions from similar previously solved problems
(Daelemans and Van den Bosch, 2005), has been
used primarily by Nivre et al. (2004), Nivre and
Scholz (2004), and Sagae and Lavie (2005).
Comparative studies of learning algorithms are
relatively rare. Cheng et al. (2005b) report that
SVM outperforms MaxEnt models in Chinese de-
pendency parsing, using the algorithms of Yamada
and Matsumoto (2003) and Nivre (2003), while
Sagae and Lavie (2005) find that SVM gives better
</bodyText>
<page confidence="0.986381">
316
</page>
<note confidence="0.726786">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99921088">
performance than MBL in a constituency-based
shift-reduce parser for English.
In this paper, we present a detailed comparison
of SVM and MBL for dependency parsing using
the deterministic algorithm of Nivre (2003). The
comparison is based on data from three different
languages – Chinese, English, and Swedish – and
on five different feature models of varying com-
plexity, with a separate optimization of learning
algorithm parameters for each combination of lan-
guage and feature model. The central importance
of feature selection and parameter optimization in
machine learning research has been shown very
clearly in recent research (Daelemans and Hoste,
2002; Daelemans et al., 2003).
The rest of the paper is structured as follows.
Section 2 presents the parsing framework, includ-
ing the deterministic parsing algorithm and the
history-based feature models. Section 3 discusses
the two learning algorithms used in the experi-
ments, and section 4 describes the experimental
setup, including data sets, feature models, learn-
ing algorithm parameters, and evaluation metrics.
Experimental results are presented and discussed
in section 5, and conclusions in section 6.
</bodyText>
<sectionHeader confidence="0.986224" genericHeader="method">
2 Inductive Dependency Parsing
</sectionHeader>
<bodyText confidence="0.9982455">
The system we use for the experiments uses no
grammar but relies completely on inductive learn-
ing from treebank data. The methodology is based
on three essential components:
</bodyText>
<listItem confidence="0.996682272727273">
1. Deterministic parsing algorithms for building
dependency graphs (Kudo and Matsumoto,
2002; Yamada and Matsumoto, 2003; Nivre,
2003)
2. History-based models for predicting the next
parser action (Black et al., 1992; Magerman,
1995; Ratnaparkhi, 1997; Collins, 1999)
3. Discriminative learning to map histories to
parser actions (Kudo and Matsumoto, 2002;
Yamada and Matsumoto, 2003; Nivre et al.,
2004)
</listItem>
<bodyText confidence="0.9994785">
In this section we will define dependency graphs,
describe the parsing algorithm used in the experi-
ments and finally explain the extraction of features
for the history-based models.
</bodyText>
<subsectionHeader confidence="0.988979">
2.1 Dependency Graphs
</subsectionHeader>
<bodyText confidence="0.9037922">
A dependency graph is a labeled directed graph,
the nodes of which are indices corresponding to
the tokens of a sentence. Formally:
Definition 1 Given a set R of dependency types
(arc labels), a dependency graph for a sentence
</bodyText>
<equation confidence="0.8526235">
x = (w1, ... , wn) is a labeled directed graph
G = (V, E, L), where:
</equation>
<listItem confidence="0.663970333333333">
1. V = Zn+1
2. E C V x V
3. L : E — *R
</listItem>
<bodyText confidence="0.996740304347826">
The set V of nodes (or vertices) is the set Zn+1 =
10, 1, 2, ... , n} (n E Z+), i.e., the set of non-
negative integers up to and including n. This
means that every token index i of the sentence is a
node (1 &lt; i &lt; n) and that there is a special node
0, which does not correspond to any token of the
sentence and which will always be a root of the
dependency graph (normally the only root). We
use V + to denote the set of nodes corresponding
to tokens (i.e., V + = V − 101), and we use the
term token node for members of V +.
The set E of arcs (or edges) is a set of ordered
pairs (i, j), where i and j are nodes. Since arcs are
used to represent dependency relations, we will
say that i is the head and j is the dependent of
the arc (i, j). As usual, we will use the notation
i —* j to mean that there is an arc connecting i
and j (i.e., (i, j) E E) and we will use the nota-
tion i —** j for the reflexive and transitive closure
of the arc relation E (i.e., i —** j if and only if
i = j or there is a path of arcs connecting i to j).
The function L assigns a dependency type (arc
label) r E R to every arc e E E.
</bodyText>
<listItem confidence="0.857712">
Definition 2 A dependency graph G is well-
formed if and only if:
1. The node 0 is a root.
2. Every node has in-degree at most 1.
3. G is connected.1
4. G is acyclic.
5. G is projective.2
</listItem>
<bodyText confidence="0.5358746">
Conditions 1–4, which are more or less standard in
dependency parsing, together entail that the graph
is a rooted tree. The condition of projectivity, by
contrast, is somewhat controversial, since the anal-
ysis of certain linguistic constructions appears to
</bodyText>
<footnote confidence="0.997008714285714">
1To be more exact, we require G to be weakly connected,
which entails that the corresponding undirected graph is con-
nected, whereas a strongly connected graph has a directed
path between any pair of nodes.
2An arc (i, j) is projective iff there is a path from i to
every node k such that i &lt; j &lt; k or i &gt; j &gt; k. A graph G
is projective if all its arcs are projective.
</footnote>
<page confidence="0.996922">
317
</page>
<figure confidence="0.965081304347826">
P
✞☎
OBJ PMOD
✞ ☎ ✞ ☎
❄
❄
✞ ☎
SBJ
❄
✞NMOD ☎
❄
NMOD
✞ ☎
❄
NMOD
❄
NMOD
✞ ☎
❄
✞ ☎
❄
JJ NN VB JJ NN IN JJ NN .
Economic news had little effect on financial markets .
</figure>
<figureCaption confidence="0.999975">
Figure 1: Dependency graph for an English sentence from the WSJ section of the Penn Treebank
</figureCaption>
<bodyText confidence="0.999956333333333">
require non-projective dependency arcs. For the
purpose of this paper, however, this assumption is
unproblematic, given that all the treebanks used in
the experiments are restricted to projective depen-
dency graphs.
Figure 1 shows a well-formed dependency
graph for an English sentence, where each word
of the sentence is tagged with its part-of-speech
and each arc labeled with a dependency type.
</bodyText>
<subsectionHeader confidence="0.99969">
2.2 Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.998943428571429">
We begin by defining parser configurations and the
abstract data structures needed for the definition of
history-based feature models.
Definition 3 Given a set R = {r0, r1, ... rm}
of dependency types and a sentence x =
(w1, ... , wn), a parser configuration for x is a
quadruple c = (σ, τ, h, d), where:
</bodyText>
<listItem confidence="0.995756142857143">
1. σ is a stack of tokens nodes.
2. τ is a sequence of token nodes.
3. h : V,+ —* V is a function from token nodes
to nodes.
4. d : V,+ —* R is a function from token nodes
to dependency types.
5. For every token node i E V,, h(i) = 0 if
</listItem>
<bodyText confidence="0.979628869565217">
and only if d(i) = r0.
The idea is that the sequence τ represents the re-
maining input tokens in a left-to-right pass over
the input sentence x; the stack σ contains partially
processed nodes that are still candidates for de-
pendency arcs, either as heads or dependents; and
the functions h and d represent a (dynamically de-
fined) dependency graph for the input sentence x.
We refer to the token node on top of the stack as
the top token and the first token node of the input
sequence as the next token.
When parsing a sentence x = (w1, ... , wn),
the parser is initialized to a configuration c0 =
(ǫ, (1, ... , n), h0, d0) with an empty stack, with
all the token nodes in the input sequence, and with
all token nodes attached to the special root node
0 with a special dependency type r0. The parser
terminates in any configuration cm = (σ,ǫ, h, d)
where the input sequence is empty, which happens
after one left-to-right pass over the input.
There are four possible parser transitions, two
of which are parameterized for a dependency type
rER.
</bodyText>
<listItem confidence="0.9953126">
1. LEFT-ARC(r) makes the top token i a (left)
dependent of the next token j with depen-
dency type r, i.e., j � i, and immediately
pops the stack.
2. RIGHT-ARC(r) makes the next token j a
(right) dependent of the top token i with de-
pendency type r, i.e., i —*� j, and immediately
pushes j onto the stack.
3. REDUCE pops the stack.
4. SHIFT pushes the next token i onto the stack.
</listItem>
<bodyText confidence="0.99996175">
The choice between different transitions is nonde-
terministic in the general case and is resolved by a
classifier induced from a treebank, using features
extracted from the parser configuration.
</bodyText>
<subsectionHeader confidence="0.995703">
2.3 Feature Models
</subsectionHeader>
<bodyText confidence="0.995409142857143">
The task of the classifier is to predict the next
transition given the current parser configuration,
where the configuration is represented by a fea-
ture vector 4b(1,p) = (φ1, ... , φp). Each feature φZ
is a function of the current configuration, defined
in terms of an address function aoz, which identi-
fies a specific token in the current parser configu-
ration, and an attribute function foz, which picks
out a specific attribute of the token.
Definition 4 Let c = (σ, τ, h, d) be the current
parser configuration.
1. For every i (i &gt; 0), σZ and τZ are address
functions identifying the ith token of σ and
τ, respectively (with indexing starting at 0).
</bodyText>
<page confidence="0.988325">
318
</page>
<listItem confidence="0.6650939">
2. If α is an address function, then h(α), l(α),
and r(α) are address functions, identifying
the head (h), the leftmost child (l), and the
rightmost child (r), of the token identified by
α (according to the function h).
3. If α is an address function, then p(α), w(α)
and d(α) are feature functions, identifying
the part-of-speech (p), word form (w) and de-
pendency type (d) of the token identified by
α. We call p, w and d attribute functions.
</listItem>
<bodyText confidence="0.993761666666667">
A feature model is defined by specifying a vector
of feature functions. In section 4.2 we will define
the feature models used in the experiments.
</bodyText>
<sectionHeader confidence="0.993848" genericHeader="method">
3 Learning Algorithms
</sectionHeader>
<bodyText confidence="0.9999335">
The learning problem for inductive dependency
parsing, defined in the preceding section, is a pure
classification problem, where the input instances
are parser configurations, represented by feature
vectors, and the output classes are parser transi-
tions. In this section, we introduce the two ma-
chine learning methods used to solve this problem
in the experiments.
</bodyText>
<subsectionHeader confidence="0.96766">
3.1 MBL
</subsectionHeader>
<bodyText confidence="0.993049125">
MBL is a lazy learning method, based on the idea
that learning is the simple storage of experiences
in memory and that solving a new problem is
achieved by reusing solutions from similar previ-
ously solved problems (Daelemans and Van den
Bosch, 2005). In essence, this is a k nearest neigh-
bor approach to classification, although a vari-
ety of sophisticated techniques, including different
distance metrics and feature weighting schemes
can be used to improve classification accuracy.
For the experiments reported in this paper we
use the TIMBL software package for memory-
based learning and classification (Daelemans and
Van den Bosch, 2005), which directly handles
multi-valued symbolic features. Based on results
from previous optimization experiments (Nivre et
al., 2004), we use the modified value difference
metric (MVDM) to determine distances between
instances, and distance-weighted class voting for
determining the class of a new instance. The para-
meters varied during experiments are the number
k of nearest neighbors and the frequency threshold
l below which MVDM is replaced by the simple
Overlap metric.
</bodyText>
<subsectionHeader confidence="0.989751">
3.2 SVM
</subsectionHeader>
<bodyText confidence="0.999969255813953">
SVM in its simplest form is a binary classifier
that tries to separate positive and negative cases in
training data by a hyperplane using a linear kernel
function. The goal is to find the hyperplane that
separates the training data into two classes with
the largest margin. By using other kernel func-
tions, such as polynomial or radial basis function
(RBF), feature vectors are mapped into a higher
dimensional space (Vapnik, 1998; Kudo and Mat-
sumoto, 2001). Multi-class classification with
n classes can be handled by the one-versus-all
method, with n classifiers that each separate one
class from the rest, or the one-versus-one method,
with n(n − 1)/2 classifiers, one for each pair of
classes (Vural and Dy, 2004). SVM requires all
features to be numerical, which means that sym-
bolic features have to be converted, normally by
introducing one binary feature for each value of
the symbolic feature.
For the experiments reported in this paper
we use the LIBSVM library (Wu et al., 2004;
Chang and Lin, 2005) with the polynomial kernel
K(xZ, xj) _ (-yxT xj +r)d,-y &gt; 0, where d, -y and
r are kernel parameters. Other parameters that are
varied in experiments are the penalty parameter C,
which defines the tradeoff between training error
and the magnitude of the margin, and the termina-
tion criterion E, which determines the tolerance of
training errors.
We adopt the standard method for converting
symbolic features to numerical features by bina-
rization, and we use the one-versus-one strategy
for multi-class classification. However, to reduce
training times, we divide the training data into
smaller sets, according to the part-of-speech of
the next token in the current parser configuration,
and train one set of classifiers for each smaller
set. Similar techniques have previously been used
by Yamada and Matsumoto (2003), among others,
without significant loss of accuracy. In order to
avoid too small training sets, we pool together all
parts-of-speech that have a frequency below a cer-
tain threshold t (set to 1000 in all the experiments).
</bodyText>
<sectionHeader confidence="0.999411" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99976275">
In this section, we describe the experimental setup,
including data sets, feature models, parameter op-
timization, and evaluation metrics. Experimental
results are presented in section 5.
</bodyText>
<page confidence="0.996126">
319
</page>
<subsectionHeader confidence="0.979686">
4.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.99994352">
The data set used for Swedish comes from Tal-
banken (Einarsson, 1976), which contains both
written and spoken Swedish. In the experiments,
the professional prose section is used, consisting
of about 100k words taken from newspapers, text-
books and information brochures. The data has
been manually annotated with a combination of
constituent structure, dependency structure, and
topological fields (Teleman, 1974). This annota-
tion has been converted to dependency graphs and
the original fine-grained classification of gram-
matical functions has been reduced to 17 depen-
dency types. We use a pseudo-randomized data
split, dividing the data into 10 sections by allocat-
ing sentence i to section i mod 10. Sections 1–9
are used for 9-fold cross-validation during devel-
opment and section 0 for final evaluation.
The English data are from the Wall Street Jour-
nal section of the Penn Treebank II (Marcus et al.,
1994). We use sections 2–21 for training, sec-
tion 0 for development, and section 23 for the
final evaluation. The head percolation table of
Yamada and Matsumoto (2003) has been used
to convert constituent structures to dependency
graphs, and a variation of the scheme employed
by Collins (1999) has been used to construct arc
labels that can be mapped to a set of 12 depen-
dency types.
The Chinese data are taken from the Penn Chi-
nese Treebank (CTB) version 5.1 (Xue et al.,
2005), consisting of about 500k words mostly
from Xinhua newswire, Sinorama news magazine
and Hong Kong News. CTB is annotated with
a combination of constituent structure and gram-
matical functions in the Penn Treebank style, and
has been converted to dependency graphs using es-
sentially the same method as for the English data,
although with a different head percolation table
and mapping scheme. We use the same kind of
pseudo-randomized data split as for Swedish, but
we use section 9 as the development test set (train-
ing on section 1–8) and section 0 as the final test
set (training on section 1–9).
A standard HMM part-of-speech tagger with
suffix smoothing has been used to tag the test data
with an accuracy of 96.5% for English and 95.1%
for Swedish. For the Chinese experiments we have
used the original (gold standard) tags from the
treebank, to facilitate comparison with results pre-
viously reported in the literature.
</bodyText>
<equation confidence="0.997602066666667">
Feature 41 42 43 44 45
p(σ0) + + + + +
p(τ0) + + + + +
+ + + + +
+ +
+ +
p(σ1) +
d(σ0) + + + +
d(l(σ0)) + + + +
d(r(σ0)) + + + +
d(l(τ0)) + + + +
w(σ0) + + +
w(τ0) + + +
w(τ1) +
w(h(σ0)) +
</equation>
<tableCaption confidence="0.992354">
Table 1: Feature models
</tableCaption>
<subsectionHeader confidence="0.872429">
4.2 Feature Models
</subsectionHeader>
<bodyText confidence="0.9999491">
Table 1 describes the five feature models 41–45
used in the experiments, with features specified
in column 1 using the functional notation defined
in section 2.3. Thus, p(σ0) refers to the part-of-
speech of the top token, while d(l(τ0)) picks out
the dependency type of the leftmost child of the
next token. It is worth noting that models 41–42
are unlexicalized, since they do not contain any
features of the form w(α), while models 43–45
are all lexicalized to different degrees.
</bodyText>
<subsectionHeader confidence="0.99383">
4.3 Optimization
</subsectionHeader>
<bodyText confidence="0.9999826">
As already noted, optimization of learning algo-
rithm parameters is a prerequisite for meaningful
comparison of different algorithms, although an
exhaustive search of the parameter space is usu-
ally impossible in practice.
For MBL we have used the modified value
difference metric (MVDM) and class voting
weighted by inverse distance (ID) in all experi-
ments, and performed a grid search for the op-
timal values of the number k of nearest neigh-
bors and the frequency threshold l for switching
from MVDM to the simple Overlap metric (cf.
section 3.1). The best values are different for dif-
ferent combinations of data sets and models but
are generally found in the range 3–10 for k and in
the range 1–8 for l.
The polynomial kernel of degree 2 has been
used for all the SVM experiments, but the kernel
parameters γ and r have been optimized together
with the penalty parameter C and the termination
</bodyText>
<page confidence="0.992215">
320
</page>
<table confidence="0.984467076923077">
FM LM Swedish English Chinese
AS EM AS EM AS EM
U L U L U L U L U L U L
4)1 MBL 75.3 68.7 16.0 11.4 *76.5 73.7 9.8 7.7 66.4 63.6 14.3 12.1
SVM 75.4 68.9 16.3 12.1 76.4 73.6 9.8 7.7 66.4 63.6 14.2 12.1
4)2 MBL 81.9 74.4 31.4 19.8 81.2 78.2 19.8 14.9 73.0 70.7 22.6 18.8
SVM *83.1 *76.3 *34.3 *24.0 81.3 78.3 19.4 14.9 *73.2 *71.0 22.1 18.6
4)3 MBL 85.9 81.4 37.9 28.9 85.5 83.7 26.5 23.7 77.9 76.3 26.3 23.4
SVM 86.2 *82.6 38.7 *32.5 *86.4 *84.8 *28.5 *25.9 *79.7 *78.3 *30.1 *25.9
4)4 MBL 86.1 82.1 37.6 30.1 87.0 85.2 29.8 26.0 79.4 77.7 28.0 24.7
SVM 86.0 82.2 37.9 31.2 *88.4 *86.8 *33.2 *30.3 *81.7 *80.1 *31.0 *27.0
4)5 MBL 86.6 82.3 39.9 29.9 88.0 86.2 32.8 28.4 81.1 79.2 30.2 25.9
SVM 86.9 *83.2 40.7 *33.7 *89.4 *87.9 *36.4 *33.1 *84.3 *82.7 *34.5 *30.5
</table>
<tableCaption confidence="0.954384666666667">
Table 2: Parsing accuracy; FM: feature model; LM: learning method; AS: attachment score, EM: exact
match; U: unlabeled, L: labeled
criterion e. The intervals for the parameters are:
</tableCaption>
<bodyText confidence="0.462363">
γ: 0.16–0.40; r: 0–0.6; C: 0.5–1.0; e: 0.1–1.0.
</bodyText>
<subsectionHeader confidence="0.99175">
4.4 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99996635">
The evaluation metrics used for parsing accuracy
are the unlabeled attachment score ASU, which is
the proportion of tokens that are assigned the cor-
rect head (regardless of dependency type), and the
labeled attachment score ASL, which is the pro-
portion of tokens that are assigned the correct head
and the correct dependency type. We also consider
the unlabeled exact match EMU, which is the pro-
portion of sentences that are assigned a completely
correct dependency graph without considering de-
pendency type labels, and the labeled exact match
EML, which also takes dependency type labels
into account. Attachment scores are presented as
mean scores per token, and punctuation tokens are
excluded from all counts. For all experiments we
have performed a McNemar test of significance at
α = 0.01 for differences between the two learning
methods. We also compare learning and parsing
times, as measured on an AMD 64-bit processor
running Linux.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.99998662">
Table 2 shows the parsing accuracy for the com-
bination of three languages (Swedish, English and
Chinese), two learning methods (MBL and SVM)
and five feature models (41–45), with algorithm
parameters optimized as described in section 4.3.
For each combination, we measure the attachment
score (AS) and the exact match (EM). A signif-
icant improvement for one learning method over
the other is marked by an asterisk (*).
Independently of language and learning
method, the most complex feature model 45
gives the highest accuracy across all metrics. Not
surprisingly, the lowest accuracy is obtained with
the simplest feature model 41. By and large, more
complex feature models give higher accuracy,
with one exception for Swedish and the feature
models 43 and 44. It is significant in this context
that the Swedish data set is the smallest of the
three (about 20% of the Chinese data set and
about 10% of the English one).
If we compare MBL and SVM, we see that
SVM outperforms MBL for the three most com-
plex models 43, 44 and 45, both for English and
Chinese. The results for Swedish are less clear,
although the labeled accuracy for 43 and 45 are
significantly better. For the 41 model there is no
significant improvement using SVM. In fact, the
small differences found in the ASU scores are to
the advantage of MBL. By contrast, there is a large
gap between MBL and SVM for the model 45 and
the languages Chinese and English. For Swedish,
the differences are much smaller (except for the
EML score), which may be due to the smaller size
of the Swedish data set in combination with the
technique of dividing the training data for SVM
(cf. section 3.2).
Another important factor when comparing two
learning methods is the efficiency in terms of time.
Table 3 reports learning and parsing time for the
three languages and the five feature models. The
learning time correlates very well with the com-
plexity of the feature model and MBL, being a lazy
learning method, is much faster than SVM. For the
unlexicalized feature models 41 and 42, the pars-
ing time is also considerably lower for MBL, espe-
cially for the large data sets (English and Chinese).
But as model complexity grows, especially with
the addition of lexical features, SVM gradually
gains an advantage over MBL with respect to pars-
ing time. This is especially striking for Swedish,
</bodyText>
<page confidence="0.996158">
321
</page>
<note confidence="0.51878325">
Method Model Swedish English Chinese
LT PT LT PT LT PT
4)1 MBL 1 s 2 s 16 s 26 s 7 s 8 s
SVM 40 s 14 s 1.5 h 14 min 1.5 h 17 min
4)2 MBL 3 s 5 s 35 s 32 s 13 s 14 s
SVM 40 s 13 s 1 h 11 min 1.5 h 15 min
4)3 MBL 6 s 1 min 1.5 min 9.5 min 46 s 10 min
SVM 1 min 15 s 1 h 9 min 2 h 16 min
4)4 MBL 8 s 2 min 1.5 min 9 min 45 s 12 min
SVM 2 min 18 s 2 h 12 min 2.5 h 14 min
4)5 MBL 10 s 7 min 3 min 41 min 1.5 min 46 min
SVM 2 min 25 s 1.5 h 10 min 6 h 24 min
</note>
<tableCaption confidence="0.999805">
Table 3: Time efficiency; LT: learning time, PT: parsing time
</tableCaption>
<bodyText confidence="0.999990578947369">
where the training data set is considerably smaller
than for the other languages.
Compared to the state of the art in dependency
parsing, the unlabeled attachment scores obtained
for Swedish with model 45, for both MBL and
SVM, are about 1 percentage point higher than the
results reported for MBL by Nivre et al. (2004).
For the English data, the result for SVM with
model 45 is about 3 percentage points below the
results obtained with the parser of Charniak (2000)
and reported by Yamada and Matsumoto (2003).
For Chinese, finally, the accuracy for SVM with
model 45 is about one percentage point lower than
the best reported results, achieved with a deter-
ministic classifier-based approach using SVM and
preprocessing to detect root nodes (Cheng et al.,
2005a), although these results are not based on
exactly the same dependency conversion and data
split as ours.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999989923076923">
We have performed an empirical comparison of
MBL (TIMBL) and SVM (LIBSVM) as learning
methods for classifier-based deterministic depen-
dency parsing, using data from three languages
and feature models of varying complexity. The
evaluation shows that SVM gives higher parsing
accuracy and comparable or better parsing effi-
ciency for complex, lexicalized feature models
across all languages, whereas MBL is superior
with respect to training efficiency, even if training
data is divided into smaller sets for SVM. The best
accuracy obtained for SVM is close to the state of
the art for all languages involved.
</bodyText>
<sectionHeader confidence="0.996513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999950666666667">
The work presented in this paper was partially sup-
ported by the Swedish Research Council. We are
grateful to Hiroyasu Yamada and Yuan Ding for
sharing their head percolation tables for English
and Chinese, respectively, and to three anonymous
reviewers for helpful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998922" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.98872475">
Ezra Black, Frederick Jelinek, John D. Lafferty,
David M. Magerman, Robert L. Mercer, and Salim
Roukos. 1992. Towards history-based grammars:
Using richer models for probabilistic parsing. In
Proceedings of the 5th DARPA Speech and Natural
Language Workshop, pages 31–37.
Chih-Chung Chang and Chih-Jen Lin. 2005. LIB-
SVM: A library for support vector machines.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 173–180.
Eugene Charniak. 2000. A Maximum-Entropy-
Inspired Parser. In Proceedings of the First Annual
Meeting of the North American Chapter of the As-
sociation for Computational Linguistics (NAACL),
pages 132–139.
Yuchang Cheng, Masayuki Asahara, and Yuji Mat-
sumoto. 2005a. Chinese deterministic dependency
analyzer: Examining effects of global features and
root node finder. In Proceedings of the Fourth
SIGHAN Workshop on Chinese Language Process-
ing, pages 17–24.
Yuchang Cheng, Masayuki Asahara, and Yuji Mat-
sumoto. 2005b. Machine learning-based depen-
dency analyzer for Chinese. In Proceedings of
the International Conference on Chinese Computing
(ICCC).
Michael Collins and Nigel Duffy. 2005. Discrimina-
tive reranking for natural language parsing. Compu-
tational Linguistics, 31:25–70.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of the
35th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 16–23.
</reference>
<page confidence="0.99061">
322
</page>
<reference confidence="0.99978643">
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Walter Daelemans and Veronique Hoste. 2002. Eval-
uation of machine learning methods for natural lan-
guage processing tasks. In Proceedings of the Third
International Conference on Language Resources
and Evaluation (LREC), pages 755–760.
Walter Daelemans and Antal Van den Bosch. 2005.
Memory-Based Language Processing. Cambridge
University Press.
Walter Daelemans, Veronique Hoste, Fien De Meulder,
and Bart Naudts. 2003. Combined optimization of
feature selection and algorithm parameter interac-
tion in machine learning of language. In Proceed-
ings of the 14th European Conference on Machine
Learning (ECML), pages 84–95.
Jan Einarsson. 1976. Talbankens skrift-
spr˚akskonkordans. Lund University, Department of
Scandinavian Languages.
Mark Johnson, Stuart Geman, Steven Canon, Zhiyi
Chi, and Stefan Riezler. 1999. Estimators for
stochastic “unification-based” grammars. In Pro-
ceedings of the 37th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
535–541.
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In Proceedings of
the Second Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL).
Taku Kudo and Yuji Matsumoto. 2002. Japanese de-
pendency analysis using cascaded chunking. In Pro-
ceedings of the Sixth Workshop on Computational
Language Learning (CoNLL), pages 63–69.
David M. Magerman. 1995. Statistical decision-tree
models for parsing. In Proceedings of the 33rd An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 276–283.
Mitchell P. Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark
Ferguson, Karen Katz, and Britta Schasberger.
1994. The Penn Treebank: Annotating predicate-
argument structure. In Proceedings of the ARPA Hu-
man Language Technology Workshop, pages 114–
119.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 91–98.
Joakim Nivre and Mario Scholz. 2004. Deterministic
dependency parsing of English text. In Proceedings
of the 20th International Conference on Computa-
tional Linguistics (COLING), pages 64–70.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2004.
Memory-based dependency parsing. In Proceed-
ings of the 8th Conference on Computational Nat-
ural Language Learning (CoNLL), pages 49–56.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of the
8th International Workshop on Parsing Technologies
(IWPT), pages 149–160.
Adwait Ratnaparkhi. 1997. A linear observed time
statistical parser based on maximum entropy mod-
els. In Proceedings of the Second Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1–10.
Kenji Sagae and Alon Lavie. 2005. A classifier-based
parser with linear run-time complexity. In Proceed-
ings of the 9th International Workshop on Parsing
Technologies (IWPT), pages 125–132.
Ben Taskar, Dan Klein, Michael Collins, Daphne
Koller, and Christopher Manning. 2004. Max-
margin parsing. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 1–8.
Ulf Teleman. 1974. Manual f¨or grammatisk beskriv-
ning av talad och skriven svenska. Studentlitteratur.
Vladimir Vapnik. 1995. The Nature of Statistical
Learning Theory. Springer.
Vladimir Vapnik. 1998. Statistical Learning Theory.
John Wiley and Sons, New York.
Volkan Vural and Jennifer G. Dy. 2004. A hierarchi-
cal method for multi-class support vector machines.
ACM International Conference Proceeding Series,
69:105–113.
Ting-Fan Wu, Chih-Jen Lin, and Ruby C. Weng. 2004.
Probability estimates for multi-class classification
by pairwise coupling. Journal ofMachine Learning
Research, 5:975–1005.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The Penn Chinese Treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207–238.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statis-
tical dependency analysis with support vector ma-
chines. In Proceedings of the 8th International
Workshop on Parsing Technologies (IWPT), pages
195–206.
</reference>
<page confidence="0.99939">
323
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.598684">
<title confidence="0.999906">Discriminative Classifiers for Deterministic Dependency Parsing</title>
<author confidence="0.999413">Johan Hall Joakim Nivre Jens Nilsson</author>
<affiliation confidence="0.9431945">V¨axj¨o University V¨axj¨o University and V¨axj¨o University University jha@msi.vxu.se</affiliation>
<email confidence="0.657525">nivre@msi.vxu.se</email>
<abstract confidence="0.99908475">Deterministic parsing guided by treebankinduced classifiers has emerged as a simple and efficient alternative to more complex models for data-driven parsing. We present a systematic comparison of memory-based learning (MBL) and support vector machines (SVM) for inducing classifiers for deterministic dependency parsing, using data from Chinese, English and Swedish, together with a variety of different feature models. The comparison shows that SVM gives higher accuracy for richly articulated feature models across all languages, albeit with considerably longer training times. The results also confirm that classifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>Frederick Jelinek</author>
<author>John D Lafferty</author>
<author>David M Magerman</author>
<author>Robert L Mercer</author>
<author>Salim Roukos</author>
</authors>
<title>Towards history-based grammars: Using richer models for probabilistic parsing.</title>
<date>1992</date>
<booktitle>In Proceedings of the 5th DARPA Speech and Natural Language Workshop,</booktitle>
<pages>31--37</pages>
<contexts>
<context position="5264" citStr="Black et al., 1992" startWordPosition="777" endWordPosition="780">ntal setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. Formally: Definition 1 Given a set R of dependency types (arc labels), a dependency g</context>
</contexts>
<marker>Black, Jelinek, Lafferty, Magerman, Mercer, Roukos, 1992</marker>
<rawString>Ezra Black, Frederick Jelinek, John D. Lafferty, David M. Magerman, Robert L. Mercer, and Salim Roukos. 1992. Towards history-based grammars: Using richer models for probabilistic parsing. In Proceedings of the 5th DARPA Speech and Natural Language Workshop, pages 31–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2005</date>
<contexts>
<context position="14542" citStr="Chang and Lin, 2005" startWordPosition="2481" endWordPosition="2484"> a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial kernel K(xZ, xj) _ (-yxT xj +r)d,-y &gt; 0, where d, -y and r are kernel parameters. Other parameters that are varied in experiments are the penalty parameter C, which defines the tradeoff between training error and the magnitude of the margin, and the termination criterion E, which determines the tolerance of training errors. We adopt the standard method for converting symbolic features to numerical features by binarization, and we use the one-versus-one strategy for multi-class classification. However, to reduce training times, we divide the training data into smaller sets,</context>
</contexts>
<marker>Chang, Lin, 2005</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2005. LIBSVM: A library for support vector machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and MaxEnt discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>173--180</pages>
<contexts>
<context position="1522" citStr="Charniak and Johnson, 2005" startWordPosition="207" endWordPosition="210">ve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo an</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and MaxEnt discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A Maximum-EntropyInspired Parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>132--139</pages>
<contexts>
<context position="1334" citStr="Charniak, 2000" startWordPosition="177" endWordPosition="178"> articulated feature models across all languages, albeit with considerably longer training times. The results also confirm that classifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations </context>
<context position="25055" citStr="Charniak (2000)" startWordPosition="4364" endWordPosition="4365">4)5 MBL 10 s 7 min 3 min 41 min 1.5 min 46 min SVM 2 min 25 s 1.5 h 10 min 6 h 24 min Table 3: Time efficiency; LT: learning time, PT: parsing time where the training data set is considerably smaller than for the other languages. Compared to the state of the art in dependency parsing, the unlabeled attachment scores obtained for Swedish with model 45, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al. (2004). For the English data, the result for SVM with model 45 is about 3 percentage points below the results obtained with the parser of Charniak (2000) and reported by Yamada and Matsumoto (2003). For Chinese, finally, the accuracy for SVM with model 45 is about one percentage point lower than the best reported results, achieved with a deterministic classifier-based approach using SVM and preprocessing to detect root nodes (Cheng et al., 2005a), although these results are not based on exactly the same dependency conversion and data split as ours. 6 Conclusion We have performed an empirical comparison of MBL (TIMBL) and SVM (LIBSVM) as learning methods for classifier-based deterministic dependency parsing, using data from three languages and </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A Maximum-EntropyInspired Parser. In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuchang Cheng</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chinese deterministic dependency analyzer: Examining effects of global features and root node finder.</title>
<date>2005</date>
<booktitle>In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="3320" citStr="Cheng et al. (2005" startWordPosition="487" endWordPosition="490">ap the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, Sydney, July 2006. c�2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on d</context>
<context position="25350" citStr="Cheng et al., 2005" startWordPosition="4409" endWordPosition="4412">labeled attachment scores obtained for Swedish with model 45, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al. (2004). For the English data, the result for SVM with model 45 is about 3 percentage points below the results obtained with the parser of Charniak (2000) and reported by Yamada and Matsumoto (2003). For Chinese, finally, the accuracy for SVM with model 45 is about one percentage point lower than the best reported results, achieved with a deterministic classifier-based approach using SVM and preprocessing to detect root nodes (Cheng et al., 2005a), although these results are not based on exactly the same dependency conversion and data split as ours. 6 Conclusion We have performed an empirical comparison of MBL (TIMBL) and SVM (LIBSVM) as learning methods for classifier-based deterministic dependency parsing, using data from three languages and feature models of varying complexity. The evaluation shows that SVM gives higher parsing accuracy and comparable or better parsing efficiency for complex, lexicalized feature models across all languages, whereas MBL is superior with respect to training efficiency, even if training data is divid</context>
</contexts>
<marker>Cheng, Asahara, Matsumoto, 2005</marker>
<rawString>Yuchang Cheng, Masayuki Asahara, and Yuji Matsumoto. 2005a. Chinese deterministic dependency analyzer: Examining effects of global features and root node finder. In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuchang Cheng</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Machine learning-based dependency analyzer for Chinese.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Conference on Chinese Computing (ICCC).</booktitle>
<contexts>
<context position="3320" citStr="Cheng et al. (2005" startWordPosition="487" endWordPosition="490">ap the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, Sydney, July 2006. c�2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on d</context>
<context position="25350" citStr="Cheng et al., 2005" startWordPosition="4409" endWordPosition="4412">labeled attachment scores obtained for Swedish with model 45, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al. (2004). For the English data, the result for SVM with model 45 is about 3 percentage points below the results obtained with the parser of Charniak (2000) and reported by Yamada and Matsumoto (2003). For Chinese, finally, the accuracy for SVM with model 45 is about one percentage point lower than the best reported results, achieved with a deterministic classifier-based approach using SVM and preprocessing to detect root nodes (Cheng et al., 2005a), although these results are not based on exactly the same dependency conversion and data split as ours. 6 Conclusion We have performed an empirical comparison of MBL (TIMBL) and SVM (LIBSVM) as learning methods for classifier-based deterministic dependency parsing, using data from three languages and feature models of varying complexity. The evaluation shows that SVM gives higher parsing accuracy and comparable or better parsing efficiency for complex, lexicalized feature models across all languages, whereas MBL is superior with respect to training efficiency, even if training data is divid</context>
</contexts>
<marker>Cheng, Asahara, Matsumoto, 2005</marker>
<rawString>Yuchang Cheng, Masayuki Asahara, and Yuji Matsumoto. 2005b. Machine learning-based dependency analyzer for Chinese. In Proceedings of the International Conference on Chinese Computing (ICCC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--25</pages>
<contexts>
<context position="1493" citStr="Collins and Duffy, 2005" startWordPosition="203" endWordPosition="206">inistic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled </context>
</contexts>
<marker>Collins, Duffy, 2005</marker>
<rawString>Michael Collins and Nigel Duffy. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 31:25–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>16--23</pages>
<contexts>
<context position="1302" citStr="Collins, 1997" startWordPosition="173" endWordPosition="174">ves higher accuracy for richly articulated feature models across all languages, albeit with considerably longer training times. The results also confirm that classifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier train</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL), pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1317" citStr="Collins, 1999" startWordPosition="175" endWordPosition="176">racy for richly articulated feature models across all languages, albeit with considerably longer training times. The results also confirm that classifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold stan</context>
<context position="5315" citStr="Collins, 1999" startWordPosition="785" endWordPosition="786">ng algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. Formally: Definition 1 Given a set R of dependency types (arc labels), a dependency graph for a sentence x = (w1, ... , wn) is a labeled</context>
<context position="17005" citStr="Collins (1999)" startWordPosition="2873" endWordPosition="2874">use a pseudo-randomized data split, dividing the data into 10 sections by allocating sentence i to section i mod 10. Sections 1–9 are used for 9-fold cross-validation during development and section 0 for final evaluation. The English data are from the Wall Street Journal section of the Penn Treebank II (Marcus et al., 1994). We use sections 2–21 for training, section 0 for development, and section 23 for the final evaluation. The head percolation table of Yamada and Matsumoto (2003) has been used to convert constituent structures to dependency graphs, and a variation of the scheme employed by Collins (1999) has been used to construct arc labels that can be mapped to a set of 12 dependency types. The Chinese data are taken from the Penn Chinese Treebank (CTB) version 5.1 (Xue et al., 2005), consisting of about 500k words mostly from Xinhua newswire, Sinorama news magazine and Hong Kong News. CTB is annotated with a combination of constituent structure and grammatical functions in the Penn Treebank style, and has been converted to dependency graphs using essentially the same method as for the English data, although with a different head percolation table and mapping scheme. We use the same kind of</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Veronique Hoste</author>
</authors>
<title>Evaluation of machine learning methods for natural language processing tasks.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>755--760</pages>
<contexts>
<context position="4336" citStr="Daelemans and Hoste, 2002" startWordPosition="639" endWordPosition="642">ency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five different feature models of varying complexity, with a separate optimization of learning algorithm parameters for each combination of language and feature model. The central importance of feature selection and parameter optimization in machine learning research has been shown very clearly in recent research (Daelemans and Hoste, 2002; Daelemans et al., 2003). The rest of the paper is structured as follows. Section 2 presents the parsing framework, including the deterministic parsing algorithm and the history-based feature models. Section 3 discusses the two learning algorithms used in the experiments, and section 4 describes the experimental setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but reli</context>
</contexts>
<marker>Daelemans, Hoste, 2002</marker>
<rawString>Walter Daelemans and Veronique Hoste. 2002. Evaluation of machine learning methods for natural language processing tasks. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC), pages 755–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal Van den Bosch</author>
</authors>
<title>Memory-Based Language Processing.</title>
<date>2005</date>
<publisher>Cambridge University Press.</publisher>
<marker>Daelemans, Van den Bosch, 2005</marker>
<rawString>Walter Daelemans and Antal Van den Bosch. 2005. Memory-Based Language Processing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Veronique Hoste</author>
<author>Fien De Meulder</author>
<author>Bart Naudts</author>
</authors>
<title>Combined optimization of feature selection and algorithm parameter interaction in machine learning of language.</title>
<date>2003</date>
<booktitle>In Proceedings of the 14th European Conference on Machine Learning (ECML),</booktitle>
<pages>84--95</pages>
<marker>Daelemans, Hoste, De Meulder, Naudts, 2003</marker>
<rawString>Walter Daelemans, Veronique Hoste, Fien De Meulder, and Bart Naudts. 2003. Combined optimization of feature selection and algorithm parameter interaction in machine learning of language. In Proceedings of the 14th European Conference on Machine Learning (ECML), pages 84–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Einarsson</author>
</authors>
<title>Talbankens skriftspr˚akskonkordans.</title>
<date>1976</date>
<institution>Lund University, Department of Scandinavian Languages.</institution>
<contexts>
<context position="15876" citStr="Einarsson, 1976" startWordPosition="2694" endWordPosition="2695">rs for each smaller set. Similar techniques have previously been used by Yamada and Matsumoto (2003), among others, without significant loss of accuracy. In order to avoid too small training sets, we pool together all parts-of-speech that have a frequency below a certain threshold t (set to 1000 in all the experiments). 4 Experimental Setup In this section, we describe the experimental setup, including data sets, feature models, parameter optimization, and evaluation metrics. Experimental results are presented in section 5. 319 4.1 Data Sets The data set used for Swedish comes from Talbanken (Einarsson, 1976), which contains both written and spoken Swedish. In the experiments, the professional prose section is used, consisting of about 100k words taken from newspapers, textbooks and information brochures. The data has been manually annotated with a combination of constituent structure, dependency structure, and topological fields (Teleman, 1974). This annotation has been converted to dependency graphs and the original fine-grained classification of grammatical functions has been reduced to 17 dependency types. We use a pseudo-randomized data split, dividing the data into 10 sections by allocating </context>
</contexts>
<marker>Einarsson, 1976</marker>
<rawString>Jan Einarsson. 1976. Talbankens skriftspr˚akskonkordans. Lund University, Department of Scandinavian Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stuart Geman</author>
<author>Steven Canon</author>
<author>Zhiyi Chi</author>
<author>Stefan Riezler</author>
</authors>
<title>Estimators for stochastic “unification-based” grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>535--541</pages>
<contexts>
<context position="1468" citStr="Johnson et al., 1999" startWordPosition="199" endWordPosition="202">lassifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was </context>
</contexts>
<marker>Johnson, Geman, Canon, Chi, Riezler, 1999</marker>
<rawString>Mark Johnson, Stuart Geman, Steven Canon, Zhiyi Chi, and Stefan Riezler. 1999. Estimators for stochastic “unification-based” grammars. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 535–541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="13990" citStr="Kudo and Matsumoto, 2001" startWordPosition="2388" endWordPosition="2392">meters varied during experiments are the number k of nearest neighbors and the frequency threshold l below which MVDM is replaced by the simple Overlap metric. 3.2 SVM SVM in its simplest form is a binary classifier that tries to separate positive and negative cases in training data by a hyperplane using a linear kernel function. The goal is to find the hyperplane that separates the training data into two classes with the largest margin. By using other kernel functions, such as polynomial or radial basis function (RBF), feature vectors are mapped into a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial kernel K(xZ, xj) _ (-yxT xj</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proceedings of the Sixth Workshop on Computational Language Learning (CoNLL),</booktitle>
<pages>63--69</pages>
<contexts>
<context position="2140" citStr="Kudo and Matsumoto (2002)" startWordPosition="300" endWordPosition="303">, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a hig</context>
<context position="5140" citStr="Kudo and Matsumoto, 2002" startWordPosition="758" endWordPosition="761">ased feature models. Section 3 discusses the two learning algorithms used in the experiments, and section 4 describes the experimental setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corr</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Proceedings of the Sixth Workshop on Computational Language Learning (CoNLL), pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>276--283</pages>
<contexts>
<context position="5280" citStr="Magerman, 1995" startWordPosition="781" endWordPosition="782">g data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. Formally: Definition 1 Given a set R of dependency types (arc labels), a dependency graph for a sente</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>David M. Magerman. 1995. Statistical decision-tree models for parsing. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 276–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn Treebank: Annotating predicateargument structure.</title>
<date>1994</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop,</booktitle>
<pages>114--119</pages>
<contexts>
<context position="16716" citStr="Marcus et al., 1994" startWordPosition="2824" endWordPosition="2827">anually annotated with a combination of constituent structure, dependency structure, and topological fields (Teleman, 1974). This annotation has been converted to dependency graphs and the original fine-grained classification of grammatical functions has been reduced to 17 dependency types. We use a pseudo-randomized data split, dividing the data into 10 sections by allocating sentence i to section i mod 10. Sections 1–9 are used for 9-fold cross-validation during development and section 0 for final evaluation. The English data are from the Wall Street Journal section of the Penn Treebank II (Marcus et al., 1994). We use sections 2–21 for training, section 0 for development, and section 23 for the final evaluation. The head percolation table of Yamada and Matsumoto (2003) has been used to convert constituent structures to dependency graphs, and a variation of the scheme employed by Collins (1999) has been used to construct arc labels that can be mapped to a set of 12 dependency types. The Chinese data are taken from the Penn Chinese Treebank (CTB) version 5.1 (Xue et al., 2005), consisting of about 500k words mostly from Xinhua newswire, Sinorama news magazine and Hong Kong News. CTB is annotated with</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn Treebank: Annotating predicateargument structure. In Proceedings of the ARPA Human Language Technology Workshop, pages 114– 119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>91--98</pages>
<contexts>
<context position="1665" citStr="McDonald et al., 2005" startWordPosition="229" endWordPosition="232">sing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. </context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>64--70</pages>
<contexts>
<context position="2313" citStr="Nivre and Scholz (2004)" startWordPosition="329" endWordPosition="332">pproach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proceedings of the 20th International Conference on Computational Linguistics (COLING), pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Memory-based dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>49--56</pages>
<contexts>
<context position="2271" citStr="Nivre et al. (2004)" startWordPosition="322" endWordPosition="325">et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among </context>
<context position="5452" citStr="Nivre et al., 2004" startWordPosition="804" endWordPosition="807">ection 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. Formally: Definition 1 Given a set R of dependency types (arc labels), a dependency graph for a sentence x = (w1, ... , wn) is a labeled directed graph G = (V, E, L), where: 1. V = Zn+1 2. E C V x V 3. L : E — *R The set V of nodes (or vertices) is the set Zn+1 = 10, 1, 2,</context>
<context position="13182" citStr="Nivre et al., 2004" startWordPosition="2257" endWordPosition="2260">by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005). In essence, this is a k nearest neighbor approach to classification, although a variety of sophisticated techniques, including different distance metrics and feature weighting schemes can be used to improve classification accuracy. For the experiments reported in this paper we use the TIMBL software package for memorybased learning and classification (Daelemans and Van den Bosch, 2005), which directly handles multi-valued symbolic features. Based on results from previous optimization experiments (Nivre et al., 2004), we use the modified value difference metric (MVDM) to determine distances between instances, and distance-weighted class voting for determining the class of a new instance. The parameters varied during experiments are the number k of nearest neighbors and the frequency threshold l below which MVDM is replaced by the simple Overlap metric. 3.2 SVM SVM in its simplest form is a binary classifier that tries to separate positive and negative cases in training data by a hyperplane using a linear kernel function. The goal is to find the hyperplane that separates the training data into two classes </context>
<context position="24908" citStr="Nivre et al. (2004)" startWordPosition="4336" endWordPosition="4339">min 1.5 min 9.5 min 46 s 10 min SVM 1 min 15 s 1 h 9 min 2 h 16 min 4)4 MBL 8 s 2 min 1.5 min 9 min 45 s 12 min SVM 2 min 18 s 2 h 12 min 2.5 h 14 min 4)5 MBL 10 s 7 min 3 min 41 min 1.5 min 46 min SVM 2 min 25 s 1.5 h 10 min 6 h 24 min Table 3: Time efficiency; LT: learning time, PT: parsing time where the training data set is considerably smaller than for the other languages. Compared to the state of the art in dependency parsing, the unlabeled attachment scores obtained for Swedish with model 45, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al. (2004). For the English data, the result for SVM with model 45 is about 3 percentage points below the results obtained with the parser of Charniak (2000) and reported by Yamada and Matsumoto (2003). For Chinese, finally, the accuracy for SVM with model 45 is about one percentage point lower than the best reported results, achieved with a deterministic classifier-based approach using SVM and preprocessing to detect root nodes (Cheng et al., 2005a), although these results are not based on exactly the same dependency conversion and data split as ours. 6 Conclusion We have performed an empirical compari</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2004</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2004. Memory-based dependency parsing. In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL), pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>149--160</pages>
<contexts>
<context position="3464" citStr="Nivre (2003)" startWordPosition="511" endWordPosition="512">avie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, Sydney, July 2006. c�2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five different feature models of varying complexity, with a separate</context>
<context position="5182" citStr="Nivre, 2003" startWordPosition="766" endWordPosition="767">ing algorithms used in the experiments, and section 4 describes the experimental setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. For</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A linear observed time statistical parser based on maximum entropy models.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--10</pages>
<contexts>
<context position="5299" citStr="Ratnaparkhi, 1997" startWordPosition="783" endWordPosition="784">ture models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a sentence. Formally: Definition 1 Given a set R of dependency types (arc labels), a dependency graph for a sentence x = (w1, ... , </context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>Adwait Ratnaparkhi. 1997. A linear observed time statistical parser based on maximum entropy models. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>A classifier-based parser with linear run-time complexity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>125--132</pages>
<contexts>
<context position="2447" citStr="Sagae and Lavie (2005)" startWordPosition="350" endWordPosition="353">by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusi</context>
</contexts>
<marker>Sagae, Lavie, 2005</marker>
<rawString>Kenji Sagae and Alon Lavie. 2005. A classifier-based parser with linear run-time complexity. In Proceedings of the 9th International Workshop on Parsing Technologies (IWPT), pages 125–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Dan Klein</author>
<author>Michael Collins</author>
<author>Daphne Koller</author>
<author>Christopher Manning</author>
</authors>
<title>Maxmargin parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--8</pages>
<contexts>
<context position="1641" citStr="Taskar et al., 2004" startWordPosition="225" endWordPosition="228">es in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency </context>
</contexts>
<marker>Taskar, Klein, Collins, Koller, Manning, 2004</marker>
<rawString>Ben Taskar, Dan Klein, Michael Collins, Daphne Koller, and Christopher Manning. 2004. Maxmargin parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Teleman</author>
</authors>
<title>Manual f¨or grammatisk beskrivning av talad och skriven svenska.</title>
<date>1974</date>
<journal>Studentlitteratur.</journal>
<contexts>
<context position="16219" citStr="Teleman, 1974" startWordPosition="2742" endWordPosition="2743"> this section, we describe the experimental setup, including data sets, feature models, parameter optimization, and evaluation metrics. Experimental results are presented in section 5. 319 4.1 Data Sets The data set used for Swedish comes from Talbanken (Einarsson, 1976), which contains both written and spoken Swedish. In the experiments, the professional prose section is used, consisting of about 100k words taken from newspapers, textbooks and information brochures. The data has been manually annotated with a combination of constituent structure, dependency structure, and topological fields (Teleman, 1974). This annotation has been converted to dependency graphs and the original fine-grained classification of grammatical functions has been reduced to 17 dependency types. We use a pseudo-randomized data split, dividing the data into 10 sections by allocating sentence i to section i mod 10. Sections 1–9 are used for 9-fold cross-validation during development and section 0 for final evaluation. The English data are from the Wall Street Journal section of the Penn Treebank II (Marcus et al., 1994). We use sections 2–21 for training, section 0 for development, and section 23 for the final evaluation</context>
</contexts>
<marker>Teleman, 1974</marker>
<rawString>Ulf Teleman. 1974. Manual f¨or grammatisk beskrivning av talad och skriven svenska. Studentlitteratur.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2664" citStr="Vapnik (1995)" startWordPosition="382" endWordPosition="383"> parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of lea</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir Vapnik. 1995. The Nature of Statistical Learning Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley and Sons,</publisher>
<location>New York.</location>
<contexts>
<context position="13963" citStr="Vapnik, 1998" startWordPosition="2386" endWordPosition="2387">ance. The parameters varied during experiments are the number k of nearest neighbors and the frequency threshold l below which MVDM is replaced by the simple Overlap metric. 3.2 SVM SVM in its simplest form is a binary classifier that tries to separate positive and negative cases in training data by a hyperplane using a linear kernel function. The goal is to find the hyperplane that separates the training data into two classes with the largest margin. By using other kernel functions, such as polynomial or radial basis function (RBF), feature vectors are mapped into a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial </context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir Vapnik. 1998. Statistical Learning Theory. John Wiley and Sons, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Volkan Vural</author>
<author>Jennifer G Dy</author>
</authors>
<title>A hierarchical method for multi-class support vector machines.</title>
<date>2004</date>
<booktitle>ACM International Conference Proceeding Series,</booktitle>
<pages>69--105</pages>
<contexts>
<context position="14250" citStr="Vural and Dy, 2004" startWordPosition="2431" endWordPosition="2434"> in training data by a hyperplane using a linear kernel function. The goal is to find the hyperplane that separates the training data into two classes with the largest margin. By using other kernel functions, such as polynomial or radial basis function (RBF), feature vectors are mapped into a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial kernel K(xZ, xj) _ (-yxT xj +r)d,-y &gt; 0, where d, -y and r are kernel parameters. Other parameters that are varied in experiments are the penalty parameter C, which defines the tradeoff between training error and the magnitude of the margin, and the termination criterion E, which determ</context>
</contexts>
<marker>Vural, Dy, 2004</marker>
<rawString>Volkan Vural and Jennifer G. Dy. 2004. A hierarchical method for multi-class support vector machines. ACM International Conference Proceeding Series, 69:105–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ting-Fan Wu</author>
<author>Chih-Jen Lin</author>
<author>Ruby C Weng</author>
</authors>
<title>Probability estimates for multi-class classification by pairwise coupling.</title>
<date>2004</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>5--975</pages>
<contexts>
<context position="14520" citStr="Wu et al., 2004" startWordPosition="2477" endWordPosition="2480">s are mapped into a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial kernel K(xZ, xj) _ (-yxT xj +r)d,-y &gt; 0, where d, -y and r are kernel parameters. Other parameters that are varied in experiments are the penalty parameter C, which defines the tradeoff between training error and the magnitude of the margin, and the termination criterion E, which determines the tolerance of training errors. We adopt the standard method for converting symbolic features to numerical features by binarization, and we use the one-versus-one strategy for multi-class classification. However, to reduce training times, we divide the training d</context>
</contexts>
<marker>Wu, Lin, Weng, 2004</marker>
<rawString>Ting-Fan Wu, Chih-Jen Lin, and Ruby C. Weng. 2004. Probability estimates for multi-class classification by pairwise coupling. Journal ofMachine Learning Research, 5:975–1005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese Treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="17190" citStr="Xue et al., 2005" startWordPosition="2908" endWordPosition="2911">ent and section 0 for final evaluation. The English data are from the Wall Street Journal section of the Penn Treebank II (Marcus et al., 1994). We use sections 2–21 for training, section 0 for development, and section 23 for the final evaluation. The head percolation table of Yamada and Matsumoto (2003) has been used to convert constituent structures to dependency graphs, and a variation of the scheme employed by Collins (1999) has been used to construct arc labels that can be mapped to a set of 12 dependency types. The Chinese data are taken from the Penn Chinese Treebank (CTB) version 5.1 (Xue et al., 2005), consisting of about 500k words mostly from Xinhua newswire, Sinorama news magazine and Hong Kong News. CTB is annotated with a combination of constituent structure and grammatical functions in the Penn Treebank style, and has been converted to dependency graphs using essentially the same method as for the English data, although with a different head percolation table and mapping scheme. We use the same kind of pseudo-randomized data split as for Swedish, but we use section 9 as the development test set (training on section 1–8) and section 0 as the final test set (training on section 1–9). A</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer. 2005. The Penn Chinese Treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>195--206</pages>
<contexts>
<context position="2187" citStr="Yamada and Matsumoto (2003)" startWordPosition="307" endWordPosition="310"> can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo a</context>
<context position="3447" citStr="Yamada and Matsumoto (2003)" startWordPosition="506" endWordPosition="509">atsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, Sydney, July 2006. c�2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five different feature models of varying complexity</context>
<context position="5168" citStr="Yamada and Matsumoto, 2003" startWordPosition="762" endWordPosition="765">on 3 discusses the two learning algorithms used in the experiments, and section 4 describes the experimental setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) In this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 2.1 Dependency Graphs A dependency graph is a labeled directed graph, the nodes of which are indices corresponding to the tokens of a</context>
<context position="15360" citStr="Yamada and Matsumoto (2003)" startWordPosition="2610" endWordPosition="2613">es the tradeoff between training error and the magnitude of the margin, and the termination criterion E, which determines the tolerance of training errors. We adopt the standard method for converting symbolic features to numerical features by binarization, and we use the one-versus-one strategy for multi-class classification. However, to reduce training times, we divide the training data into smaller sets, according to the part-of-speech of the next token in the current parser configuration, and train one set of classifiers for each smaller set. Similar techniques have previously been used by Yamada and Matsumoto (2003), among others, without significant loss of accuracy. In order to avoid too small training sets, we pool together all parts-of-speech that have a frequency below a certain threshold t (set to 1000 in all the experiments). 4 Experimental Setup In this section, we describe the experimental setup, including data sets, feature models, parameter optimization, and evaluation metrics. Experimental results are presented in section 5. 319 4.1 Data Sets The data set used for Swedish comes from Talbanken (Einarsson, 1976), which contains both written and spoken Swedish. In the experiments, the profession</context>
<context position="16878" citStr="Yamada and Matsumoto (2003)" startWordPosition="2851" endWordPosition="2854">rted to dependency graphs and the original fine-grained classification of grammatical functions has been reduced to 17 dependency types. We use a pseudo-randomized data split, dividing the data into 10 sections by allocating sentence i to section i mod 10. Sections 1–9 are used for 9-fold cross-validation during development and section 0 for final evaluation. The English data are from the Wall Street Journal section of the Penn Treebank II (Marcus et al., 1994). We use sections 2–21 for training, section 0 for development, and section 23 for the final evaluation. The head percolation table of Yamada and Matsumoto (2003) has been used to convert constituent structures to dependency graphs, and a variation of the scheme employed by Collins (1999) has been used to construct arc labels that can be mapped to a set of 12 dependency types. The Chinese data are taken from the Penn Chinese Treebank (CTB) version 5.1 (Xue et al., 2005), consisting of about 500k words mostly from Xinhua newswire, Sinorama news magazine and Hong Kong News. CTB is annotated with a combination of constituent structure and grammatical functions in the Penn Treebank style, and has been converted to dependency graphs using essentially the sa</context>
<context position="25099" citStr="Yamada and Matsumoto (2003)" startWordPosition="4369" endWordPosition="4372">1.5 min 46 min SVM 2 min 25 s 1.5 h 10 min 6 h 24 min Table 3: Time efficiency; LT: learning time, PT: parsing time where the training data set is considerably smaller than for the other languages. Compared to the state of the art in dependency parsing, the unlabeled attachment scores obtained for Swedish with model 45, for both MBL and SVM, are about 1 percentage point higher than the results reported for MBL by Nivre et al. (2004). For the English data, the result for SVM with model 45 is about 3 percentage points below the results obtained with the parser of Charniak (2000) and reported by Yamada and Matsumoto (2003). For Chinese, finally, the accuracy for SVM with model 45 is about one percentage point lower than the best reported results, achieved with a deterministic classifier-based approach using SVM and preprocessing to detect root nodes (Cheng et al., 2005a), although these results are not based on exactly the same dependency conversion and data split as ours. 6 Conclusion We have performed an empirical comparison of MBL (TIMBL) and SVM (LIBSVM) as learning methods for classifier-based deterministic dependency parsing, using data from three languages and feature models of varying complexity. The ev</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>