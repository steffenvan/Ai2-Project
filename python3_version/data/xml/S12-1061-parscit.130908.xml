<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000095">
<title confidence="0.698801">
Soft Cardinality: A Parameterized Similarity Function for Text Comparison
</title>
<note confidence="0.525807333333333">
Sergio Jimenez Claudia Becerra Alexander Gelbukh
Universidad Nacional Universidad Nacional CIC-IPN
de Colombia, Bogota, de Colombia, Bogota Av. Juan Dios Bátiz,
Ciudad Universitaria cjbecerrac@unal.edu.co Av. Mendizábal, Col.
edificio 453, oficina 220 Nueva Industrial Vallejo,
sgjimenezv@unal.edu.co CP 07738, DF, México
</note>
<email confidence="0.81501">
gelbukh@gelbukh.com
</email>
<sectionHeader confidence="0.992537" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.988854684210526">
We present an approach for the construction of text
similarity functions using a parameterized resem-
blance coefficient in combination with a softened
cardinality function called soft cardinality. Our ap-
proach provides a consistent and recursive model,
varying levels of granularity from sentences to char-
acters. Therefore, our model was used to compare
sentences divided into words, and in turn, words di-
vided into q-grams of characters. Experimentally,
we observed that a performance correlation func-
tion in a space defined by all parameters was rel-
atively smooth and had a single maximum achiev-
able by “hill climbing.” Our approach used only sur-
face text information, a stop-word remover, and a
stemmer to tackle the semantic text similarity task
6 at SEMEVAL 2012. The proposed method ranked
3rd (average), 5th (normalized correlation), and 15th
(aggregated correlation) among 89 systems submit-
ted by 31 teams.
</bodyText>
<sectionHeader confidence="0.998645" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962222222222">
Similarity is the intrinsic ability of humans and some
animals to balance commonalities and differences when
comparing objects that are not identical. Although there
is no direct evidence of how this process works in liv-
ing organisms, some models have been proposed from
the cognitive perspective (Sjöberg, 1972; Tversky, 1977;
Navarro and Lee, 2004). On the other hand, several simi-
larity models have been proposed in mathematics, statis-
tics, and computer science among other fields. Particu-
larly in AI, similarity measures play an important role in
the construction of intelligent systems that are required
to exhibit behavior similar to humans. For instance, in
the field of natural language processing, text similarity
functions provide estimates of the human similarity judg-
ments related to language. In this paper, we combine el-
ements from the perspective of cognitive psychology and
computer science to propose a model for building simi-
larity functions suitable for the task of semantic text sim-
ilarity.
We identify four main families of text similarity func-
tions: i) resemblance coefficients based on sets (e.g. Jac-
card’s (1901) and Dice’s (1945) coefficients) ii) functions
in metric spaces (e.g. cosine tf-idf similarity (Salton et
al., 1975)); iii) the edit distance family of measures (e.g.
Levenstein (1966) distance, LCS (Hirschberg, 1977));
and iv) hybrid approaches ((Monge and Elkan, 1996; Co-
hen et al., 2003; Corley and Mihalcea, 2005; Jimenez et
al., 2010)). All of these measures use a subdivision of
the texts in different granularity levels, such as q-grams
of words, words, q-grams of characters, syllables, and
characters. Among hybrid approaches, Monge-Elkan’s
measure and soft cardinality methods are recursive and
can be used to build similarity functions at any arbitrary
range of granularity. For instance, it is possible to con-
struct a similarity function to compare sentences based
on a function that compares words, which in turn can be
constructed based on a function that compares bigrams of
characters. Furthermore, hybrid approaches can integrate
similarity functions that are not based on the representa-
tion of the surface of text, such as semantic relatedness
measures (Pedersen et al., 2004).
Text similarity measures can be static or adaptive
whether they are binary functions using only surface in-
formation of the two texts, or are functions that suit
to a wider set of texts. For instance, measures using
tf-idf weights adapt their results to the set of texts in
which those weights were obtained. Other approaches
learn parameters of the similarity function from a set of
texts to optimize a particular task. For instance, Ris-
tad and Yianilos (1998) and Bikenko and Mooney (2003)
learned the costs of edit operations for all characters for
an edit-distance function in a name-matching task. Other
machine-learning approaches have also been proposed to
build adaptive measures in name-matching (Bilenko and
</bodyText>
<page confidence="0.99265">
449
</page>
<note confidence="0.545722">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 449–453,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998835616666667">
Mooney, 2003) and textual-entailment tasks.
However, those machine-learning-based methods for
adaptive similarity suffer from sparseness and the “curse
of dimensionality”. For example, the method of Ristad
and Yianilos learns n2 + 2n parameters, where n is the
size of the character set. Similarly, dimensionality in the
method of Bilenko and Mooney is the size of the data
set vocabulary. This issue is addressed primarily through
machine-learning algorithms, which reduce the dimen-
sionality of the problem regularizating to achieve enough
generalization to get an acceptable performance differ-
ence between training and test data. Although machine-
learning solutions have proven effective for many appli-
cations, the principle of Occam’s razor suggests that it
should be preferable to have a model that explains the
data with a smaller number of significant parameters. In
this paper, we seek a simpler adaptive similarity model
with few meaningful parameters.
Our proposed similarity model starts with a
cardinality-based resemblance coefficient (i.e. Dice’s
coefficient 2|AnB|/|A|+|B|) and generalizes it to model
the effect of asymmetric selection of the referent. This
effect is a human factor discovered by Tversky (1977)
that affects judgments of similarity, i.e. humans tends
to select the more prominent stimulus as the referent
and the less salient stimulus as the object. Some of
Tversky’s examples are “the son resembles the father”
rather than “the father resembles the son”, “an ellipse is
like a circle” not “a circle is like an ellipse”, and “North
Korea is like Red China” rather than “Red China is like
North Korea”. Generally speaking, “the variant is more
similar to the prototype than vice versa”. In the previous
example, stimulus salience is associated with the promi-
nence of the country; for text comparison we associate
word salience with tf-idf weights. At the text level, we
associate salience with a combination of word-salience,
inter-word similarity, and text length provided by soft
cardinality. Experimentally, we observed that this effect
also occurs when comparing texts, but not necessarily
in the same direction suggested by Tversky. We used
this effect to improve the performance of our similarity
model. In addition, we proposed a parameter that biases
the function to generate greater or lower similarity
scores.
Finally, in our model we used a soft cardinality func-
tion (Jimenez et al., 2010) instead of the classical set car-
dinality. Just as classical cardinality counts the number
of elements which are not identical in a set, soft cardi-
nality uses an auxiliary inter-element similarity function
to make a soft count. For instance, the soft cardinality of
a set with two very similar (but not identical) elements
should be a real number closer to 1.0 instead of 2.0.
The rest of the paper is organized as follows. In Sec-
tion 2 we briefly present soft cardinality. In Section 3 the
proposed parameterized similarity model is presented. In
Section 4 experimental validation is provided using 8 data
sets annotated with human similarity judgments from the
“Semantic-Text-Similarity” task at SEMEVAL-2012. Fi-
nally, a brief discussion is provided in Section 5 and con-
clusions are presented in Section 6.
</bodyText>
<sectionHeader confidence="0.800729" genericHeader="method">
2 Soft Cardinality
</sectionHeader>
<bodyText confidence="0.928422">
ILet A = fa1, a2, ... , a|A |I and B = fb1, b2, ... , b|B|
be two sets being compared. When each element of ai
or bj has an associated weight wai or wbi the problem
of comparing those sets becomes a weighted similarity
problem. This means that such model has to take into
account not only the commonalities and diferences, but
also their weights. Also, if an (|A U B|) x (|A U B|)
similarity matrix S is available, the problem becomes a
weighted soft similarity problem because the common-
ality between A and B has to be computed not only
with identical elements, but also with elements with a
degree of similarity. The values of S can be obtained
from an auxiliary similarity function sim(a, b) that sat-
isfies at least non-negativity (da, b, sim(a, b) &gt; 0) and
reflexivity (da, sim(a, a) = 1). Other postulates such as
symmetry (da, b, sim(a, b) = sim(b, a)) and triangle in-
equality1 (da, b, c, sim(a, c) &gt; sim(a, b) + sim(b, c) −
1) are not strictly necessary.
Jimenez et al. (2010) proposed a set-based weighted
soft-similarity model using resemblance coefficients and
the soft cardinality function instead of classical set car-
dinality. The idea of calculating the soft cardinality is
to treat elements ai in set the A as sets themselves and
to treat inter-element similarities as the intersections be-
tween the elements sim(ai, aj) = |ai n aj|. Therefore,
�|A |.
the soft cardinality of set A becomes |A|&apos; = i�1ai
Since it is not feasible to calculate this union, they pro-
posed the following weighted approximation using |ai |=
wai:
</bodyText>
<equation confidence="0.9523368">
0
�wai @ sim(ai, aj)p
j
Parameter p &gt; 0 in
controls the
</equation>
<bodyText confidence="0.999041857142857">
of
the cardinality, taking p = 1 its no-effect value and leav-
ing element similarities unchanged for the calculation of
soft cardinality. When p is large, all sim(*, *) results
lower than 1 are transformed into a number approaching
0. As a result, the soft cardinality behaves like the clas-
sical cardinality, returning the addition of all the weights
</bodyText>
<equation confidence="0.914875272727273">
�_-
When pis close
to 0, all sim(*.*) results are tran
eq.1
“softeness”
|A|&apos;si-m,
�|A|
iwai.
sformed approaching
1 _1
A (1)
</equation>
<bodyText confidence="0.678787333333333">
of the elements, i.e
inequality postulate for similarity is derived from its coun-
terpart for dissimilarity (distan
</bodyText>
<equation confidence="0.8838224">
1triangle
ce) distance(a, b) = 1 − sim(a, b).
|A|&apos; sign, � � |A|
i
|A|
</equation>
<page confidence="0.957504">
450
</page>
<bodyText confidence="0.9997106">
into a number approaching 1, making the soft cardinal-
ity returns the average of the weights of the elements, i.e.
|A|�sim |A |��A |wai. Jimenez et al. used p = 2 and
idf weights in the same name-matching task proposed by
Cohen et al. (Cohen et al., 2003).
</bodyText>
<sectionHeader confidence="0.984093" genericHeader="method">
3 A Parameterized Similarity Model
</sectionHeader>
<bodyText confidence="0.947707631578948">
As we mentioned above, Tvesky proposed that humans
tends to select more salient stimulus as referent and less
salient stimulus as object when comparing two objects A
and B. Based on the idea of Tvesrky, the similarity be-
tween two objects can be measured as the ratio between
the salience of commonalities and the salience of the less
salient object. Drawing an analogy between objects as
sets and salience as the cardinality of a set, the salience
of commonalities is |A n B|, and the salience of the less
salient object is min(|A|, |B|). This ratio is known as the
overlap coefficient Overlap(A, B) = |A∩B|
mi��|A|,|B|). How-
ever, whether |A |&lt; |B |or whether |A |« |B|, the sim-
ilarity obtained by Overlap(A, B) is the same. Hence,
we propose to model the selecction of the referent using
a parameter α that makes a weighted average between
min(|A|, |B|) and max(|A|, |B|), controling the degree
to which the asymmetric referent-selection effect is con-
sidered in the similarity measure.
</bodyText>
<figure confidence="0.719778">
|A n B |+ bias
SIM(A, B) =
α max (|A|, |B|) + (1 − α) min (|A|, |B|)
(2)
</figure>
<bodyText confidence="0.999450625">
The parameter α controls the degree to which the
asymmetric referent-selection effect is considered in the
similarity measure. Its no-effect value is α = 0.5, so
the eq.2 becomes the Dice coefficient. Moreover, when
α = 0 the eq.2 becomes the overlap coefficient, other-
wise when α = 1 the opposite effect is modeled.
In addition, we introduced a bias parameter in eq. 2
that increases the commonalities of each object pair by
the same amount, and so it measures the degree to which
all of the objects have commonalities among each other.
Clearly, the non-effect value for the bias parameter is 0.
Besides, the bias parameter has the effect of biasing
SIM(A, B) by considering any pair (A, B) more sim-
ilar if bias &gt; 0 and their cardinalities are small. Con-
versely, the similarity between pairs with large cardinal-
ities is promoted if bias &lt; 0. However, as higher values
of bias may result in similarity scores outside the interval
[0, 1], additional post-procesing to limit the similarities in
this interval may be required.
The proposed parameterized text similarity measure is
constructed by combining the proposed resemblance co-
efficient in eq.2 and the soft cardinality in eq.1. The
resulting measure has three parameters: α, bias, and p.
Weights wai can be idf weights. This measure takes two
</bodyText>
<table confidence="0.999659571428571">
α Asymetric referent selection at text level
bias Bias parameter at text level
p Soft cardinality exponent at word level
wai Element weights at word level
q1, q2 q,-grams or [q, : q2]spectra word division
αsim Asymetric referent selection at q-gram level
biassim Bias parameter q-gram level
</table>
<tableCaption confidence="0.999925">
Table 1: Parameters of the proposed similarity model
</tableCaption>
<bodyText confidence="0.999869875">
texts represented as sets of words and returns their simi-
larity. The auxiliary similarity function sim(a, b) neces-
sary for calculating the soft cardinality is another param-
eter of the model. This auxiliary function is any function
that can compare two words and return a similarity score
in [0, 1].
To build this sim(a, b) function, we chose to reuse the
eq.2 but representing words as sets of q-grams or ranges
of q-grams of different sizes, i.e. [q1 : q2] spectra. Q-
grams are consecutive overlapped substrings of size q.
For instance, the word “saturday” divided into trigrams
is {asa, sat, atu, tur, urd, rda, day, ay&gt;}. The character
’�’ is a padding character added to differenciate q-grams
at the begining or end of the string. A [2 : 4]spectra
is the combined representation of a word using –in this
example– bigrams, trigrams and quadgrams (Jimenez and
Gelbukh, 2011). The cardinality function for sim() was
the classical set cardinality. Clearly, the soft cardinal-
ity could be used again if an auxiliary similarity func-
tion for character comparison and a q-gram weighting
mechanism are provided to allow another level of recur-
sion. Therefore, the parameters of sim(a, b) are: αsim,
biassim. Finally, the entire set of parameters of the pro-
posed similarity model is shown in Table 1.
</bodyText>
<sectionHeader confidence="0.985895" genericHeader="method">
4 Experimental Setup and Results
</sectionHeader>
<bodyText confidence="0.9999825625">
The aim of these experiments is to observe the behavior
of the parameters of our similarity model and verify if the
hypothesis that motivated these parameters can be con-
firmed experimentally. The experimental data are 8 data
sets (3 for training and 5 for test) proposed in the “Seman-
tic Text Similarity” task at SEMEVAL-2012. Each data
set consist of a set of pairs of text annotated with human-
similarity judgments on a scale of 0 to 5. Each similarity
judgment is the average of the judgments provided by 5
human judges. For a comprehensible description of the
task see(Agirre et al., 2012).
For the experiments, all data sets were pre-processed
by converting to lowercase characters, English stop-
words removal and stemming using Porter stemmer
(Porter, 1980). The performance measure used for all ex-
periments was the Pearson correlation r.
</bodyText>
<page confidence="0.996913">
451
</page>
<subsectionHeader confidence="0.996951">
4.1 Model Parameters
</subsectionHeader>
<bodyText confidence="0.999991789473684">
In order to make an initial exploration of the parame-
ters in Table 1, we set ql = 2 (i.e. bigrams) and used
w,,,, = idf(ai). For other parameters, we started with all
the non-effect values, i.e. a = 0.5, bias = 0, p = 1,
asi�n. = 0.5 and biassi,.. = 0. Plots in Figure 1 show
the Pearson correlation measured in each of the data sets.
For each graph, the non-effect configuration was used and
each parameter varies in the range indicated in each hor-
izontal axis. For best viewing, the non-effect values on
each graph are represented by a vertical line.
In this exploration of the parameters it was noted that
each parameter defines a function for the performance
measure that is smooth and with an unique global maxi-
mum. Therefore, we assumed that the join performance
function in the space defined by the 5 parameters also
had the same properties. The parameters for each data set
shown in Table 2 were found using a simple hill-climbing
algorithm. Different q-gram and spectra configurations
were tested manually.
</bodyText>
<sectionHeader confidence="0.998728" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99997392">
It is possible to observe from the results in Figure 1 and
Table 2 that the behavior of the parameters is similar in
pairs of data sets that have training and test parts. This
behavior is evident in both MSRvid and MSRpar data
sets, but it is less evident in SMTeuroparl. Furthermore,
the optimal parameters for training data sets MSRvid and
MSRpar were similar to those of their test data sets. In
conclusion, the proposed set of parameters provides a set
of features that characterize a data set for the text similar-
ity task.
Regarding the effect of asymmetry in referent selecc-
tion proposed by Tvesrky, it was observed that –at text
level– the MSRvid data sets were the only ones that sup-
ported this hypothesis (a = 0.32, 0.42). The remaining
data sets showed the opposite effect (a &gt; 0.5). That is,
annotators chose the most salient document (the longer)
as the referent when a pair of texts is being compared.
The Table 2 also shows that the optimal parameters
for all data sets were different from the no-effect values
combination. This result can also be seen in Figure 1,
where curves crossed the vertical line of no-effect value
–in most of the cases– in values different to the optimum.
Clearly, the proposed set of parameters is useful for ad-
justing the similarity function for a particular data set and
task.
</bodyText>
<sectionHeader confidence="0.996818" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999943631578947">
We have proposed a new parameterized similarity func-
tion for text comparison and a method for finding the op-
timal values of the parameter set when training data is
available. In addition, the parameter a, which was moti-
vated by the similarity model of Tversky, proved effective
in obtaining better performance, but we could not con-
firm the Tvesky’s hypothesis that humans tends to select
the object (text) with less stimulus salience (text length)
as the referent. This result might have occurred because
either the stimulus salience is not properly represented by
the length of the text, or Tversky’s hypothesis cannot be
extended to text comparison.
The proposed similarity function proved effective in
the task of “Semantic Text Similarity” in SEMEVAL
2012. Our method obtained the third best average cor-
relation on the 5 test data sets. This result is remarkable
because our method only used data from the surface of
the texts, a stop-word remover, and a stemmer, which can
be even be considered as a baseline method.
</bodyText>
<sectionHeader confidence="0.998465" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999416">
This research was funded by the Systems and Industrial
Engineering Department, the Office of Student Welfare
of the National University of Colombia, Bogotá, and
throught a grant from the Colombian Department for
Science, Technology and Innovation Colciencias, proj.
110152128465. The second author recognizes the sup-
port from Mexican Government (SNI, COFAA-IPN, SIP
20113295, CONACYT 50206-H) and CONACYT–DST
India (proj. “Answer Validation through Textual Entail-
ment”).
</bodyText>
<sectionHeader confidence="0.997809" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999381782608695">
Eneko Agirre, Daniel Cer, Mona Diab, and Gonzalez-Agirre
Aitor. 2012. SemEval-2012 task 6: A pilot on semantic
textual similarity. In Proc. of the 6th International Workshop
on Semantic Evaluation (SemEval 2012), in conjunction with
the First Joint Conference on Lexical and Computational Se-
mantics (*SEM 2012)., Montreal,Canada.
Mikhail Bilenko and Raymond J. Mooney. 2003. Adaptive du-
plicate detection using learnable string similarity measures.
In Proc. of the ninth ACM SIGKDD international confer-
ence on Knowledge discovery and data mining, pages 39–48,
Washington, D.C. ACM.
William W Cohen, Pradeep Ravikumar, and Stephen E Fien-
berg. 2003. A comparison of string distance metrics for
Name-Matching tasks. In Proc. of the IJCAI2003 Workshop
on Information Integration on the Web II Web03.
Courtney Corley and Rada Mihalcea. 2005. Measuring the se-
mantic similarity of texts. In Proc. of the ACL Workshop
on Empirical Modeling of Semantic Equivalence and Entail-
ment, Stroudsburg, PA.
Lee R. Dice. 1945. Measures of the amount of ecologic associ-
ation between species. Ecology, pages 297–302.
Daniel S. Hirschberg. 1977. Algorithms for the longest com-
mon subsequence problem. J. ACM, 24(4):664–675.
</reference>
<page confidence="0.996708">
452
</page>
<figure confidence="0.854534">
MSRvid(tr) MSRvid(te) MSRpar(tr) MSRpar(te) SMTeur(tr) SMTeur(te) OnWN SMTnews no effect
</figure>
<figureCaption confidence="0.995886">
Figure 1: Exploring similarity model parameters around their no-effect values (tr=training, te=test)
</figureCaption>
<table confidence="0.788045428571429">
Parameters correl. Official Results
Data set [q1 : q2] α bias p αsim biassim r SoftCard Best
MSRpar.training [4] 0.62 1.14 0.77 -0.04 -0.38 0.6598 n/a n/a
MSR.par.test [4] 0.60 1.02 0.9 -0.02 -0.4 0.6335 0.64051 0.7343
MSRvid.training [1:4] 0.42 -0.80 2.28 0.18 0.08 0.8323 n/a n/a
MSRvid.test [1:4] 1 -0.80 3 1.08 0.08 0.8579 0.8562 0.8803
0.32 1.88
SMTeuroparl.training [2:4] 0.74 -0.06 0.91 1.88 2.90 0.6193 n/a n/a
SMTeuroparl.test [2:4] 0.84 -0.16 0.71 1.78 3.00 0.5178 0.51522 0.5666
OnWN.test [2:5] 0.88 -0.62 1.36 -0.02 -0.70 0.7202 0.71091 0.7273
SMTnews.test [1:4] 0.88 0.88 1.57 0.80 3.21 0.5344 0.48331 0.6085
1Result obtained using Jaro-Winkler (Winkler, 1990) measure as sim(a, b) function between words.
2Result obtained using generalized Monge-Elkan measure p = 4, no stop-words removal and no term weights
(Jimenez et al., 2009).
</table>
<tableCaption confidence="0.999552">
Table 2: Results with optimized parameters and official SEMEVAL 2012 results
</tableCaption>
<figure confidence="0.9988013125">
0.4
0.3
0 1 2 3 4 5 6 7 8
0 0.5 1 1.5
-15 -5 5 15
-0.5 0.5 1.5
-4 -2 0 2 4
0.8
Pearson correlation
0.7
0.6
0.5
α
bias
αsi.
biassim
</figure>
<reference confidence="0.993839386363636">
Paul Jaccard. 1901. Etude comparative de la distribution florare
dans une portion des alpes et des jura. Bulletin de la Société
Vaudoise des Sciences Naturelles, pages 547–579.
Sergio Jimenez and Alexander Gelbukh. 2011. SC spectra: a
linear-time soft cardinality approximation for text compari-
son. In Proc. of the 10th international conference on Artifi-
cial Intelligence, MICAI’11, Puebla, Mexico.
Sergio Jimenez, Claudia Becerra, Alexander Gelbukh, and
Fabio Gonzalez. 2009. Generalized Monge-Elkan method
for approximate text string comparison. In Computational
Linguistics and Intelligent Text Processing, volume 5449 of
LNCS, pages 559–570.
Sergio Jimenez, Fabio Gonzalez, and Alexander Gelbukh.
2010. Text comparison using soft cardinality. In String Pro-
cessing and Information Retrieval, volume 6393 of LNCS,
pages 297–302.
Vladimir I. Levenshtein. 1966. Binary codes capable of cor-
recting deletions, insertions, and reversals. Soviet Physics
Doklady, 10(8):707–710.
Alvaro E. Monge and Charles Elkan. 1996. The field matching
problem: Algorithms and applications. In Proc. KDD-96,
pages 267–270, Portland, OR.
Daniel Navarro and Michael D. Lee. 2004. Common and dis-
tinctive features in stimulis representation: A modified ver-
sion of the contrast model. Psychonomic Bulletin &amp; Review,
11:961–974.
Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi.
2004. WordNet::Similarity: measuring the relatedness of
concepts. In Proc. HLT-NAACL–Demonstration Papers,
Stroudsburg, PA.
Martin Porter. 1980. An algorithm for suffix stripping. Pro-
gram, 3(14):130–137.
Eric S. Ristad and Peter N. Yianilos. 1998. Learning string
edit distance. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 20(5):522–532.
Gerard Salton, A. Wong, and C.S. Yang. 1975. A vector space
model for automatic indexing. Com. ACM, 18(11):613–620.
L. Sjöberg. 1972. A cognitive theory of similarity. Göteborg
Psychological Reports.
Amos Tversky. 1977. Features of similarity. Psychological
Review, 84(4):327–352.
William E. Winkler. 1990. String comparator metrics and en-
hanced decision rules in the Fellegi-Sunter model of record
linkage. In Proc. of the Section on Survey Research Methods.
</reference>
<page confidence="0.999374">
453
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.180444">
<title confidence="0.998432">Soft Cardinality: A Parameterized Similarity Function for Text Comparison</title>
<author confidence="0.99971">Sergio Jimenez Claudia Becerra Alexander Gelbukh</author>
<affiliation confidence="0.932459333333333">Universidad Nacional Universidad Nacional CIC-IPN de Colombia, Bogota, de Colombia, Bogota Av. Juan Dios Bátiz, Universitaria Mendizábal, Col.</affiliation>
<address confidence="0.8265365">edificio 453, oficina 220 Nueva Industrial Vallejo, 07738, DF, México</address>
<email confidence="0.999752">gelbukh@gelbukh.com</email>
<abstract confidence="0.9216077">We present an approach for the construction of text similarity functions using a parameterized resemblance coefficient in combination with a softened cardinality function called soft cardinality. Our approach provides a consistent and recursive model, varying levels of granularity from sentences to characters. Therefore, our model was used to compare sentences divided into words, and in turn, words diinto of characters. Experimentally, we observed that a performance correlation function in a space defined by all parameters was relatively smooth and had a single maximum achievable by “hill climbing.” Our approach used only surface text information, a stop-word remover, and a stemmer to tackle the semantic text similarity task 6 at SEMEVAL 2012. The proposed method ranked 3rd (average), 5th (normalized correlation), and 15th (aggregated correlation) among 89 systems submitted by 31 teams.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Gonzalez-Agirre Aitor</author>
</authors>
<title>SemEval-2012 task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In Proc. of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012).,</booktitle>
<location>Montreal,Canada.</location>
<contexts>
<context position="14898" citStr="Agirre et al., 2012" startWordPosition="2426" endWordPosition="2429">erimental Setup and Results The aim of these experiments is to observe the behavior of the parameters of our similarity model and verify if the hypothesis that motivated these parameters can be confirmed experimentally. The experimental data are 8 data sets (3 for training and 5 for test) proposed in the “Semantic Text Similarity” task at SEMEVAL-2012. Each data set consist of a set of pairs of text annotated with humansimilarity judgments on a scale of 0 to 5. Each similarity judgment is the average of the judgments provided by 5 human judges. For a comprehensible description of the task see(Agirre et al., 2012). For the experiments, all data sets were pre-processed by converting to lowercase characters, English stopwords removal and stemming using Porter stemmer (Porter, 1980). The performance measure used for all experiments was the Pearson correlation r. 451 4.1 Model Parameters In order to make an initial exploration of the parameters in Table 1, we set ql = 2 (i.e. bigrams) and used w,,,, = idf(ai). For other parameters, we started with all the non-effect values, i.e. a = 0.5, bias = 0, p = 1, asi�n. = 0.5 and biassi,.. = 0. Plots in Figure 1 show the Pearson correlation measured in each of the </context>
</contexts>
<marker>Agirre, Cer, Diab, Aitor, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, and Gonzalez-Agirre Aitor. 2012. SemEval-2012 task 6: A pilot on semantic textual similarity. In Proc. of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012)., Montreal,Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bilenko</author>
<author>Raymond J Mooney</author>
</authors>
<title>Adaptive duplicate detection using learnable string similarity measures.</title>
<date>2003</date>
<booktitle>In Proc. of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>39--48</pages>
<publisher>ACM.</publisher>
<location>Washington, D.C.</location>
<marker>Bilenko, Mooney, 2003</marker>
<rawString>Mikhail Bilenko and Raymond J. Mooney. 2003. Adaptive duplicate detection using learnable string similarity measures. In Proc. of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 39–48, Washington, D.C. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Pradeep Ravikumar</author>
<author>Stephen E Fienberg</author>
</authors>
<title>A comparison of string distance metrics for Name-Matching tasks.</title>
<date>2003</date>
<booktitle>In Proc. of the IJCAI2003 Workshop on Information Integration on the Web II Web03.</booktitle>
<contexts>
<context position="2779" citStr="Cohen et al., 2003" startWordPosition="410" endWordPosition="414">n this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which in turn can be constructed based on a function that compares bigrams of</context>
<context position="10243" citStr="Cohen et al., 2003" startWordPosition="1633" endWordPosition="1636">inality, returning the addition of all the weights �_- When pis close to 0, all sim(*.*) results are tran eq.1 “softeness” |A|&apos;si-m, �|A| iwai. sformed approaching 1 _1 A (1) of the elements, i.e inequality postulate for similarity is derived from its counterpart for dissimilarity (distan 1triangle ce) distance(a, b) = 1 − sim(a, b). |A|&apos; sign, � � |A| i |A| 450 into a number approaching 1, making the soft cardinality returns the average of the weights of the elements, i.e. |A|�sim |A |��A |wai. Jimenez et al. used p = 2 and idf weights in the same name-matching task proposed by Cohen et al. (Cohen et al., 2003). 3 A Parameterized Similarity Model As we mentioned above, Tvesky proposed that humans tends to select more salient stimulus as referent and less salient stimulus as object when comparing two objects A and B. Based on the idea of Tvesrky, the similarity between two objects can be measured as the ratio between the salience of commonalities and the salience of the less salient object. Drawing an analogy between objects as sets and salience as the cardinality of a set, the salience of commonalities is |A n B|, and the salience of the less salient object is min(|A|, |B|). This ratio is known as t</context>
</contexts>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>William W Cohen, Pradeep Ravikumar, and Stephen E Fienberg. 2003. A comparison of string distance metrics for Name-Matching tasks. In Proc. of the IJCAI2003 Workshop on Information Integration on the Web II Web03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Corley</author>
<author>Rada Mihalcea</author>
</authors>
<title>Measuring the semantic similarity of texts.</title>
<date>2005</date>
<booktitle>In Proc. of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment,</booktitle>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="2806" citStr="Corley and Mihalcea, 2005" startWordPosition="415" endWordPosition="418">bine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which in turn can be constructed based on a function that compares bigrams of characters. Furthermore, h</context>
</contexts>
<marker>Corley, Mihalcea, 2005</marker>
<rawString>Courtney Corley and Rada Mihalcea. 2005. Measuring the semantic similarity of texts. In Proc. of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee R Dice</author>
</authors>
<title>Measures of the amount of ecologic association between species.</title>
<date>1945</date>
<journal>Ecology,</journal>
<pages>297--302</pages>
<marker>Dice, 1945</marker>
<rawString>Lee R. Dice. 1945. Measures of the amount of ecologic association between species. Ecology, pages 297–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel S Hirschberg</author>
</authors>
<title>Algorithms for the longest common subsequence problem.</title>
<date>1977</date>
<journal>J. ACM,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="2707" citStr="Hirschberg, 1977" startWordPosition="400" endWordPosition="401">vide estimates of the human similarity judgments related to language. In this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which</context>
</contexts>
<marker>Hirschberg, 1977</marker>
<rawString>Daniel S. Hirschberg. 1977. Algorithms for the longest common subsequence problem. J. ACM, 24(4):664–675.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Jaccard</author>
</authors>
<title>Etude comparative de la distribution florare dans une portion des alpes et des jura.</title>
<date>1901</date>
<booktitle>Bulletin de la Société Vaudoise des Sciences Naturelles,</booktitle>
<pages>547--579</pages>
<marker>Jaccard, 1901</marker>
<rawString>Paul Jaccard. 1901. Etude comparative de la distribution florare dans une portion des alpes et des jura. Bulletin de la Société Vaudoise des Sciences Naturelles, pages 547–579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Alexander Gelbukh</author>
</authors>
<title>SC spectra: a linear-time soft cardinality approximation for text comparison.</title>
<date>2011</date>
<booktitle>In Proc. of the 10th international conference on Artificial Intelligence, MICAI’11,</booktitle>
<location>Puebla, Mexico.</location>
<contexts>
<context position="13856" citStr="Jimenez and Gelbukh, 2011" startWordPosition="2250" endWordPosition="2253">wo words and return a similarity score in [0, 1]. To build this sim(a, b) function, we chose to reuse the eq.2 but representing words as sets of q-grams or ranges of q-grams of different sizes, i.e. [q1 : q2] spectra. Qgrams are consecutive overlapped substrings of size q. For instance, the word “saturday” divided into trigrams is {asa, sat, atu, tur, urd, rda, day, ay&gt;}. The character ’�’ is a padding character added to differenciate q-grams at the begining or end of the string. A [2 : 4]spectra is the combined representation of a word using –in this example– bigrams, trigrams and quadgrams (Jimenez and Gelbukh, 2011). The cardinality function for sim() was the classical set cardinality. Clearly, the soft cardinality could be used again if an auxiliary similarity function for character comparison and a q-gram weighting mechanism are provided to allow another level of recursion. Therefore, the parameters of sim(a, b) are: αsim, biassim. Finally, the entire set of parameters of the proposed similarity model is shown in Table 1. 4 Experimental Setup and Results The aim of these experiments is to observe the behavior of the parameters of our similarity model and verify if the hypothesis that motivated these pa</context>
</contexts>
<marker>Jimenez, Gelbukh, 2011</marker>
<rawString>Sergio Jimenez and Alexander Gelbukh. 2011. SC spectra: a linear-time soft cardinality approximation for text comparison. In Proc. of the 10th international conference on Artificial Intelligence, MICAI’11, Puebla, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
<author>Fabio Gonzalez</author>
</authors>
<title>Generalized Monge-Elkan method for approximate text string comparison.</title>
<date>2009</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<volume>5449</volume>
<pages>559--570</pages>
<marker>Jimenez, Becerra, Gelbukh, Gonzalez, 2009</marker>
<rawString>Sergio Jimenez, Claudia Becerra, Alexander Gelbukh, and Fabio Gonzalez. 2009. Generalized Monge-Elkan method for approximate text string comparison. In Computational Linguistics and Intelligent Text Processing, volume 5449 of LNCS, pages 559–570.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Fabio Gonzalez</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Text comparison using soft cardinality.</title>
<date>2010</date>
<booktitle>In String Processing and Information Retrieval,</booktitle>
<volume>6393</volume>
<pages>297--302</pages>
<contexts>
<context position="2829" citStr="Jimenez et al., 2010" startWordPosition="419" endWordPosition="422">pective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which in turn can be constructed based on a function that compares bigrams of characters. Furthermore, hybrid approaches can in</context>
<context position="6906" citStr="Jimenez et al., 2010" startWordPosition="1046" endWordPosition="1049"> for text comparison we associate word salience with tf-idf weights. At the text level, we associate salience with a combination of word-salience, inter-word similarity, and text length provided by soft cardinality. Experimentally, we observed that this effect also occurs when comparing texts, but not necessarily in the same direction suggested by Tversky. We used this effect to improve the performance of our similarity model. In addition, we proposed a parameter that biases the function to generate greater or lower similarity scores. Finally, in our model we used a soft cardinality function (Jimenez et al., 2010) instead of the classical set cardinality. Just as classical cardinality counts the number of elements which are not identical in a set, soft cardinality uses an auxiliary inter-element similarity function to make a soft count. For instance, the soft cardinality of a set with two very similar (but not identical) elements should be a real number closer to 1.0 instead of 2.0. The rest of the paper is organized as follows. In Section 2 we briefly present soft cardinality. In Section 3 the proposed parameterized similarity model is presented. In Section 4 experimental validation is provided using </context>
<context position="8717" citStr="Jimenez et al. (2010)" startWordPosition="1367" endWordPosition="1370"> U B|) x (|A U B|) similarity matrix S is available, the problem becomes a weighted soft similarity problem because the commonality between A and B has to be computed not only with identical elements, but also with elements with a degree of similarity. The values of S can be obtained from an auxiliary similarity function sim(a, b) that satisfies at least non-negativity (da, b, sim(a, b) &gt; 0) and reflexivity (da, sim(a, a) = 1). Other postulates such as symmetry (da, b, sim(a, b) = sim(b, a)) and triangle inequality1 (da, b, c, sim(a, c) &gt; sim(a, b) + sim(b, c) − 1) are not strictly necessary. Jimenez et al. (2010) proposed a set-based weighted soft-similarity model using resemblance coefficients and the soft cardinality function instead of classical set cardinality. The idea of calculating the soft cardinality is to treat elements ai in set the A as sets themselves and to treat inter-element similarities as the intersections between the elements sim(ai, aj) = |ai n aj|. Therefore, �|A |. the soft cardinality of set A becomes |A|&apos; = i�1ai Since it is not feasible to calculate this union, they proposed the following weighted approximation using |ai |= wai: 0 �wai @ sim(ai, aj)p j Parameter p &gt; 0 in contr</context>
</contexts>
<marker>Jimenez, Gonzalez, Gelbukh, 2010</marker>
<rawString>Sergio Jimenez, Fabio Gonzalez, and Alexander Gelbukh. 2010. Text comparison using soft cardinality. In String Processing and Information Retrieval, volume 6393 of LNCS, pages 297–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<issue>8</issue>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(8):707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvaro E Monge</author>
<author>Charles Elkan</author>
</authors>
<title>The field matching problem: Algorithms and applications. In</title>
<date>1996</date>
<booktitle>Proc. KDD-96,</booktitle>
<pages>267--270</pages>
<location>Portland, OR.</location>
<contexts>
<context position="2759" citStr="Monge and Elkan, 1996" startWordPosition="406" endWordPosition="409"> related to language. In this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which in turn can be constructed based on a function that</context>
</contexts>
<marker>Monge, Elkan, 1996</marker>
<rawString>Alvaro E. Monge and Charles Elkan. 1996. The field matching problem: Algorithms and applications. In Proc. KDD-96, pages 267–270, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Navarro</author>
<author>Michael D Lee</author>
</authors>
<title>Common and distinctive features in stimulis representation: A modified version of the contrast model.</title>
<date>2004</date>
<journal>Psychonomic Bulletin &amp; Review,</journal>
<pages>11--961</pages>
<contexts>
<context position="1704" citStr="Navarro and Lee, 2004" startWordPosition="244" endWordPosition="247">information, a stop-word remover, and a stemmer to tackle the semantic text similarity task 6 at SEMEVAL 2012. The proposed method ranked 3rd (average), 5th (normalized correlation), and 15th (aggregated correlation) among 89 systems submitted by 31 teams. 1 Introduction Similarity is the intrinsic ability of humans and some animals to balance commonalities and differences when comparing objects that are not identical. Although there is no direct evidence of how this process works in living organisms, some models have been proposed from the cognitive perspective (Sjöberg, 1972; Tversky, 1977; Navarro and Lee, 2004). On the other hand, several similarity models have been proposed in mathematics, statistics, and computer science among other fields. Particularly in AI, similarity measures play an important role in the construction of intelligent systems that are required to exhibit behavior similar to humans. For instance, in the field of natural language processing, text similarity functions provide estimates of the human similarity judgments related to language. In this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity </context>
</contexts>
<marker>Navarro, Lee, 2004</marker>
<rawString>Daniel Navarro and Michael D. Lee. 2004. Common and distinctive features in stimulis representation: A modified version of the contrast model. Psychonomic Bulletin &amp; Review, 11:961–974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proc. HLT-NAACL–Demonstration Papers,</booktitle>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="3584" citStr="Pedersen et al., 2004" startWordPosition="535" endWordPosition="538">characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible to construct a similarity function to compare sentences based on a function that compares words, which in turn can be constructed based on a function that compares bigrams of characters. Furthermore, hybrid approaches can integrate similarity functions that are not based on the representation of the surface of text, such as semantic relatedness measures (Pedersen et al., 2004). Text similarity measures can be static or adaptive whether they are binary functions using only surface information of the two texts, or are functions that suit to a wider set of texts. For instance, measures using tf-idf weights adapt their results to the set of texts in which those weights were obtained. Other approaches learn parameters of the similarity function from a set of texts to optimize a particular task. For instance, Ristad and Yianilos (1998) and Bikenko and Mooney (2003) learned the costs of edit operations for all characters for an edit-distance function in a name-matching ta</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. WordNet::Similarity: measuring the relatedness of concepts. In Proc. HLT-NAACL–Demonstration Papers, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>3</volume>
<issue>14</issue>
<contexts>
<context position="15067" citStr="Porter, 1980" startWordPosition="2452" endWordPosition="2453">parameters can be confirmed experimentally. The experimental data are 8 data sets (3 for training and 5 for test) proposed in the “Semantic Text Similarity” task at SEMEVAL-2012. Each data set consist of a set of pairs of text annotated with humansimilarity judgments on a scale of 0 to 5. Each similarity judgment is the average of the judgments provided by 5 human judges. For a comprehensible description of the task see(Agirre et al., 2012). For the experiments, all data sets were pre-processed by converting to lowercase characters, English stopwords removal and stemming using Porter stemmer (Porter, 1980). The performance measure used for all experiments was the Pearson correlation r. 451 4.1 Model Parameters In order to make an initial exploration of the parameters in Table 1, we set ql = 2 (i.e. bigrams) and used w,,,, = idf(ai). For other parameters, we started with all the non-effect values, i.e. a = 0.5, bias = 0, p = 1, asi�n. = 0.5 and biassi,.. = 0. Plots in Figure 1 show the Pearson correlation measured in each of the data sets. For each graph, the non-effect configuration was used and each parameter varies in the range indicated in each horizontal axis. For best viewing, the non-effe</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin Porter. 1980. An algorithm for suffix stripping. Program, 3(14):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric S Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<title>Learning string edit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="4046" citStr="Ristad and Yianilos (1998)" startWordPosition="612" endWordPosition="616">es can integrate similarity functions that are not based on the representation of the surface of text, such as semantic relatedness measures (Pedersen et al., 2004). Text similarity measures can be static or adaptive whether they are binary functions using only surface information of the two texts, or are functions that suit to a wider set of texts. For instance, measures using tf-idf weights adapt their results to the set of texts in which those weights were obtained. Other approaches learn parameters of the similarity function from a set of texts to optimize a particular task. For instance, Ristad and Yianilos (1998) and Bikenko and Mooney (2003) learned the costs of edit operations for all characters for an edit-distance function in a name-matching task. Other machine-learning approaches have also been proposed to build adaptive measures in name-matching (Bilenko and 449 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 449–453, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics Mooney, 2003) and textual-entailment tasks. However, those machine-learning-based methods for adaptive similarity suffer from sparseness and the “curse of dimensionality”</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric S. Ristad and Peter N. Yianilos. 1998. Learning string edit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Com. ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="2606" citStr="Salton et al., 1975" startWordPosition="384" endWordPosition="387">ilar to humans. For instance, in the field of natural language processing, text similarity functions provide estimates of the human similarity judgments related to language. In this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model for building similarity functions suitable for the task of semantic text similarity. We identify four main families of text similarity functions: i) resemblance coefficients based on sets (e.g. Jaccard’s (1901) and Dice’s (1945) coefficients) ii) functions in metric spaces (e.g. cosine tf-idf similarity (Salton et al., 1975)); iii) the edit distance family of measures (e.g. Levenstein (1966) distance, LCS (Hirschberg, 1977)); and iv) hybrid approaches ((Monge and Elkan, 1996; Cohen et al., 2003; Corley and Mihalcea, 2005; Jimenez et al., 2010)). All of these measures use a subdivision of the texts in different granularity levels, such as q-grams of words, words, q-grams of characters, syllables, and characters. Among hybrid approaches, Monge-Elkan’s measure and soft cardinality methods are recursive and can be used to build similarity functions at any arbitrary range of granularity. For instance, it is possible t</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Gerard Salton, A. Wong, and C.S. Yang. 1975. A vector space model for automatic indexing. Com. ACM, 18(11):613–620. L. Sjöberg. 1972. A cognitive theory of similarity. Göteborg Psychological Reports.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amos Tversky</author>
</authors>
<title>Features of similarity.</title>
<date>1977</date>
<journal>Psychological Review,</journal>
<volume>84</volume>
<issue>4</issue>
<contexts>
<context position="1680" citStr="Tversky, 1977" startWordPosition="242" endWordPosition="243">y surface text information, a stop-word remover, and a stemmer to tackle the semantic text similarity task 6 at SEMEVAL 2012. The proposed method ranked 3rd (average), 5th (normalized correlation), and 15th (aggregated correlation) among 89 systems submitted by 31 teams. 1 Introduction Similarity is the intrinsic ability of humans and some animals to balance commonalities and differences when comparing objects that are not identical. Although there is no direct evidence of how this process works in living organisms, some models have been proposed from the cognitive perspective (Sjöberg, 1972; Tversky, 1977; Navarro and Lee, 2004). On the other hand, several similarity models have been proposed in mathematics, statistics, and computer science among other fields. Particularly in AI, similarity measures play an important role in the construction of intelligent systems that are required to exhibit behavior similar to humans. For instance, in the field of natural language processing, text similarity functions provide estimates of the human similarity judgments related to language. In this paper, we combine elements from the perspective of cognitive psychology and computer science to propose a model </context>
<context position="5701" citStr="Tversky (1977)" startWordPosition="854" endWordPosition="855">ining and test data. Although machinelearning solutions have proven effective for many applications, the principle of Occam’s razor suggests that it should be preferable to have a model that explains the data with a smaller number of significant parameters. In this paper, we seek a simpler adaptive similarity model with few meaningful parameters. Our proposed similarity model starts with a cardinality-based resemblance coefficient (i.e. Dice’s coefficient 2|AnB|/|A|+|B|) and generalizes it to model the effect of asymmetric selection of the referent. This effect is a human factor discovered by Tversky (1977) that affects judgments of similarity, i.e. humans tends to select the more prominent stimulus as the referent and the less salient stimulus as the object. Some of Tversky’s examples are “the son resembles the father” rather than “the father resembles the son”, “an ellipse is like a circle” not “a circle is like an ellipse”, and “North Korea is like Red China” rather than “Red China is like North Korea”. Generally speaking, “the variant is more similar to the prototype than vice versa”. In the previous example, stimulus salience is associated with the prominence of the country; for text compar</context>
</contexts>
<marker>Tversky, 1977</marker>
<rawString>Amos Tversky. 1977. Features of similarity. Psychological Review, 84(4):327–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William E Winkler</author>
</authors>
<title>String comparator metrics and enhanced decision rules in the Fellegi-Sunter model of record linkage.</title>
<date>1990</date>
<booktitle>In Proc. of the Section on Survey Research Methods.</booktitle>
<marker>Winkler, 1990</marker>
<rawString>William E. Winkler. 1990. String comparator metrics and enhanced decision rules in the Fellegi-Sunter model of record linkage. In Proc. of the Section on Survey Research Methods.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>