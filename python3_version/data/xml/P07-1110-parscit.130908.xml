<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014803">
<title confidence="0.998804">
Benefits of the ‘Massively Parallel Rosetta Stone’:
Cross-Language Information Retrieval with over 30 Languages
</title>
<author confidence="0.702325">
Peter A. Chew
</author>
<affiliation confidence="0.657686">
Sandia National Laboratories
</affiliation>
<address confidence="0.6743035">
P. O. Box 5800, MS 1012
Albuquerque, NM 87185-1012, USA
</address>
<email confidence="0.995652">
pchew@sandia.gov
</email>
<author confidence="0.816611">
Ahmed Abdelali
</author>
<affiliation confidence="0.8058">
New Mexico State University
</affiliation>
<address confidence="0.986784">
P.O. Box 30002, Mail Stop 3CRL
Las Cruces, NM 88003-8001, USA
</address>
<email confidence="0.999629">
ahmed@crl.nmsu.edu
</email>
<sectionHeader confidence="0.996673" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998152">
In this paper, we describe our experiences
in extending a standard cross-language in-
formation retrieval (CLIR) approach
which uses parallel aligned corpora and
Latent Semantic Indexing. Most, if not
all, previous work which follows this ap-
proach has focused on bilingual retrieval;
two examples involve the use of French-
English or English-Greek parallel cor-
pora. Our extension to the approach is
‘massively parallel’ in two senses, one
linguistic and the other computational.
First, we make use of a parallel aligned
corpus consisting of almost 50 parallel
translations in over 30 distinct languages,
each in over 30,000 documents. Given the
size of this dataset, a ‘massively parallel’
approach was also necessitated in the
more usual computational sense. Our re-
sults indicate that, far from adding more
noise, more linguistic parallelism is better
when it comes to cross-language retrieval
precision, in addition to the self-evident
benefit that CLIR can be performed on
more languages.
</bodyText>
<sectionHeader confidence="0.999163" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996736">
Approaches to cross-language information retrieval
(CLIR) fall generally into one of two types, or
some combination thereof: the ‘query translation’
approach or the ‘parallel corpus’ approach. The
first of these, which is perhaps more common, in-
</bodyText>
<page confidence="0.965787">
872
</page>
<bodyText confidence="0.999814166666667">
volves translation of the query into the target lan-
guage, for example using machine translation or
on-line dictionaries. The second makes use of par-
allel aligned corpora as training sets. One approach
which uses parallel corpora does this in conjunc-
tion with Latent Semantic Indexing (LSI) (Lan-
dauer and Littman 1990, Young 1994). According
to Berry et al. (1994:21), the use of LSI with paral-
lel corpora can be just as effective as the query
translation approach, and avoids some of the draw-
backs of the latter, discussed in Nie et al. (1999).
Generally, research in CLIR has not attempted
to use very many languages at a time (see for ex-
ample Nie and Jin 2002). With query translation
(although that is not the approach that Nie and Jin
take), this is perhaps understandable, as for each
new language, a new translation algorithm must be
included. The effort involved in extending query
translation to multiple languages, therefore, is
likely to be in proportion to the number of lan-
guages.
With parallel corpora, the reason that research
has been limited to only a few languages at a time
– and usually just two at a time, as in the LSI work
cited above – is more likely to be rooted in the
widespread perception that good parallel corpora
are difficult to obtain (see for example Asker
2004). However, recent work (Resnik et al. 1999,
Chew et al. 2006) has challenged this idea.
One advantage of a ‘massively parallel’ multi-
lingual corpus is perhaps self-evident: within the
LSI framework, the more languages are mapped
into the single conceptual space, the fewer restric-
tions there are on which languages documents can
be selected from for cross-language retrieval.
However, several questions were raised for us as
</bodyText>
<note confidence="0.902559">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 872–879,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999859294117647">
we contemplated the use of a massively parallel
corpus. Would the addition of languages not used
in testing create ‘noise’ for a given language pair,
reducing the precision of CLIR? Could partially
parallel corpora be used? Our work appears to
show both that more languages are generally bene-
ficial, and even incomplete parallel corpora can be
used. In the remainder of this paper, we provide
evidence for this claim. The paper is organized as
follows: section 2 describes the work we undertook
to build the parallel corpus and its characteristics.
In section 3, we outline the mechanics behind the
&apos;Rosetta-Stone&apos; type method we use for cross-
language comparison. In section 4, we present and
discuss the results of the various tests we per-
formed. Finally, we conclude on our findings in
section 5.
</bodyText>
<sectionHeader confidence="0.898822" genericHeader="method">
2 The massively parallel corpus
</sectionHeader>
<bodyText confidence="0.99813537037037">
Following Chew et al. (2006), our parallel corpus
was built up from translations of the Bible which
are freely available on the World Wide Web. Al-
though reliable comparable statistics are hard to
find, it appears to be generally agreed that the Bi-
ble is the world’s most widely translated book,
with complete translations in 426 languages and
partial translations in 2,403 as of December 31,
2005 (Bible Society, 2006). Great care is taken
over the translations, and they are alignable by
chapter and verse. According to Resnik et al.
(1999), the Bible’s coverage of modern vocabulary
may be as high as 85%. The vast majority of the
translations we used came from the ‘Unbound Bi-
ble’ website (Biola University, 2005-2006); from
this website, the text of a large number of different
translations of the Bible can – most importantly for
our purposes – be downloaded in a tab-delimited
format convenient for loading into a database and
then indexing by chapter and verse in order to en-
sure ‘parallelism’ in the corpus. The number of
translations available at the website is apparently
being added to, based on our observations access-
ing the website on a number of different occasions.
The languages we have included in our multilin-
gual parallel corpus include those both ancient and
modern, and are as follows:
</bodyText>
<table confidence="0.99495193939394">
Language No. of Used in
translations tests
Afrikaans 1 12+
Albanian 1 27+
Arabic 1 All
Chinese (Simplified) 1 44+
Chinese (Traditional) 1 44+
Croatian 1 27+
Czech 2 12+
Danish 1 12+
Dutch 1 12+
English 7 All
Finnish 3 27+
French 2 All
German 4 8,27+
Greek (New Testament) 2 46+
Hebrew (Old Testament) 1 46+
Hebrew (Modern) 1 6,12+
Hungarian 1 6+
Italian 2 8,27+
Japanese* 1 9+
Korean 1 27+
Latin 1 8,9,28+
Maori 1 7,8,9,27+
Norwegian 1 27+
Polish* 1 27+
Portuguese 1 27+
Russian 1 All
Spanish 2 All
Swedish 1 27+
Tagalog 1 27+
Thai 1 27+
Vietnamese 1 27,44+
</table>
<tableCaption confidence="0.999764">
Table 1. Languages
</tableCaption>
<bodyText confidence="0.999797083333334">
The languages above represent many of the ma-
jor language groups: Austronesian (Maori and
Tagalog); Altaic (Japanese and Korean); Sino-
Tibetan (Chinese); Semitic (Arabic and Hebrew);
Finno-Ugric (Finnish and Hungarian); Austro-
Asiatic (Vietnamese); Tai-Kadai (Thai); and Indo-
European (the remaining languages). The two New
Testament Greek versions are the Byzan-
tine/Majority Text (2000), and the parsed version
of the same text, in which we treated distinct mor-
phological elements (such as roots or inflectional
endings) as distinct terms. Overall, the list includes
</bodyText>
<footnote confidence="0.9489488">
1 Translations in languages marked with an asterisk above
were obtained from websites other than the ‘Unbound Bible’
website. ‘Used in tests’ indicates in which tests in Table 2
below the language was used as training data, and hence the
order of addition of languages to the training data.
</footnote>
<page confidence="0.9982">
873
</page>
<bodyText confidence="0.998630805970149">
47 versions in 31 distinct languages (assuming documents in the corpus. The last term in the ex-
without further discussion here that each entry in pression above, log2 (N), is the maximum entropy
the list represents a distinct language). that any term can have in the corpus, and therefore
We aligned the translations by verse, and, since (1 + Ht / log2 (N)) is 1 for the most distinctive
there are some differences in versification between terms in the corpus, 0 for those which are least dis-
translations (for example, the Hebrew Old Testa- tinctive.
ment includes the headings for the Psalms as sepa- The sparse document-by-term matrix is sub-
rate verses, unlike most translations), we spent jected to singular value decomposition (SVD), and
some time cleaning the data to ensure the align- a reduced non-sparse matrix is output. Generally,
ment was as good as possible, given available re- we used the output corresponding to the top 300
sources and our knowledge of the languages. (Even singular values in our experiments. When we had a
after this process, the alignment was not perfect, smaller number of languages in the mix, it was
and differences in how well the various transla- possible to use SVDPACK (Berry et al. 1996),
tions were aligned may account for some of the which is an open-source non-parallel algorithm for
variability in the outcome of our experiments, de- computing the SVD, but for larger problems (in-
pending on which translations were used.) The end volving more than a couple of dozen parallel ver-
result was that our parallel corpus consisted of sions), use of a parallel algorithm (in a library
31,226 ‘mini-documents’ – the total number of text called Trilinos) was necessitated. (This was run on
chunks2 after the cleaning process, aligned across a Linux cluster consisting of 4,096 dual CPU com-
all 47 versions. The two New Testament Greek pute nodes, running on Dell PowerEdge 1850 1U
versions, and the one Old Testament Hebrew ver- Servers with 6GB of RAM.)
sion, were exceptions because these are only par- In order to test the precision versus recall of our
tially complete; the former have text in only 7,953 framework, we used translations of the 114 suras
of the verses, and the latter has text in 23,266 of of the Qu’ran into five languages, Arabic, English,
the verses. For some versions, a few of the verse French, Russian and Spanish. The number of
translations are incomplete where a particular verse documents used for testing is fairly small, but large
has been skipped in translation; this also explains enough to give comparative results for our pur-
the fact that the number of Hebrew and Greek text poses which are still highly statistically significant.
chunks together do not add up to 31,226. However, The test set was split into each of the 10 possible
the number of such verses is negligible in compari- language-pair combinations: Arabic-English, Ara-
son to the total. bic-French, English-French, and so on.
For each language pair and test, 228 distinct
‘queries’ were submitted – each query consisting
of one of the 228 sura ‘documents’. If the highest-
ranking document in the other language of the pair
was in fact the query’s translation, then the result
was deemed ‘correct’. To assess the aggregate per-
formance of the framework, we used two meas-
ures: average precision at 0 (the maximum
precision at any level of recall), and average preci-
sion at 1 document (1 if the ‘correct’ document
ranked highest, zero otherwise). The second meas-
ure is a stricter one, but we generally found that
there is a high rate of correlation between the two
measures anyway.
4 Results and Discussion
The following tables show the results of our tests.
First, we present in Table 2 the overall summary,
3 Framework
The framework we used was the standard LSI
framework described in Berry et al. (1994). Each
aligned mini-document from the parallel corpus
consists of the combination of text from all the 31
languages. A document-by-term matrix is formed
in which each cell represents a weighted frequency
of a particular term t in a particular document k.
We used a standard log-entropy weighting scheme,
where the weighted frequency W is given by:
W = log2 (F) × (1 + Ht / log2 (N))
where F is the raw frequency of t in k, Ht is the
standard ‘p log p’ measure of the entropy of the
term across all documents, and N is the number of
2 The text chunks generally had the same boundaries as the
verses in the original text.
874
with averages across all language pairs used in
testing.
</bodyText>
<table confidence="0.999861277777778">
No. of Average precision
parallel
versions
At 0 at 1 doc.
2 0.706064 0.571491
3 0.747620 0.649269
4 0.617615 0.531873
5 0.744951 0.656140
6 0.811666 0.732602
7 0.827246 0.753070
8 0.824501 0.750000
9 0.823430 0.746053
12 0.827761 0.752632
27 0.825577 0.751316
28 0.823137 0.747807
44 0.839346 0.765789
46 0.839319 0.766667
47 0.842936 0.774561
</table>
<tableCaption confidence="0.999701">
Table 2. Summary results for all language pairs
</tableCaption>
<bodyText confidence="0.999040125000001">
From the above, the following should be clear:
as more parallel translations are added to the index,
the average precision rises considerably at first,
and then begins to level off after about the seventh
parallel translation. The results will of course vary
according to which combination of translations is
selected for the index. The number of such combi-
nations is generally very large: for example, with
47 translations available, there are 47! / (40! 7!), or
62,891,499, possible ways of selecting 7 transla-
tions. Thus, for any particular number of parallel
versions, we had to use some judgement in which
parallel versions to select, since there was no way
to achieve anything like exhaustive coverage of the
possibilities.
Further, with more than 7 parallel translations,
there is certainly no justification for saying that
adding more translations or languages increases the
‘noise’ for languages in the test set, since beyond 7
the average precision remains fairly level. If any-
thing, in fact, the precision still appears to rise
slightly. For example, the average precision at 1
document rises by more than 0.75 percentage
points between 46 and 47 versions. Given that in
each of these experiments, we are measuring preci-
sion 228 times per language pair, and therefore
2,280 times in total, this small rise in precision is
significant (p ≈ 0.034). Interestingly, the 47th ver-
sion to be added was parsed New Testament
Greek. It appears, therefore, that the parsing helped
in particular; we also have evidence from other
experiments (not presented here) that overall preci-
sion is generally improved for all languages when
Arabic wordforms are replaced by their respective
citation forms (the bare root, or stem) – also a form
of morphological parsing. Ancient Greek, like
Arabic, is morphologically highly complex, so it
would be understandable that parsing (or stem-
ming) would help when parsing of either language
is used in training.
One other point needs to be made here: the three
versions added after the 44th version were the three
incomplete versions (the two Greek versions cover
just the New Testament, while Ancient Hebrew
covers just the Old Testament). The above-
mentioned increase in precision which resulted
from the addition of these three versions is clear
evidence that even in the case where a parallel cor-
pus is defective for some language(s), including
those languages can still result in the twofold bene-
fit that (1) those languages are now available for
analysis, and (2) precision is maintained or in-
creased for the remaining languages.
Finally, precision at 1 document, the stricter of
the two measures, is by definition less than or
equal to precision at 0. This taken into account, it
is also interesting that the gap between the two
measures seems to narrow as more parallel transla-
tions and parsing are added, as Figure 1 shows.
For certain applications where it is important
that the translation is ranked first, not just highly,
among all retrieved documents, there is thus a par-
ticular benefit in using a ‘massively parallel’
aligned corpus.
</bodyText>
<figure confidence="0.994846272727273">
16%
14%
12%
10%
8%
6%
4%
2%
0%
2 3 4 5 6 7 8 9 12 27 28 44 46 47
Number of parallel translations
</figure>
<figureCaption confidence="0.999733">
Figure 1. Differential between precision at 0 and
precision at 1 document, by number of languages
</figureCaption>
<bodyText confidence="0.517258">
Differential in percentage points
</bodyText>
<page confidence="0.997137">
875
</page>
<bodyText confidence="0.99994432">
Now we move on to look at more detailed re-
sults by language pair. Figure 2 below breaks
down the results for precision at 1 document by
language pair. In all tests, the two languages in
each pair were (naturally) always included in the
languages used for training. There is more volatil-
ity in the results by language pair than there is in
the overall results, shown again at the right of the
graph, which should come as no surprise since the
averages are based on samples a tenth of the size.
Generally, however, the pattern is the same for
particular language pairs as it is overall; the more
parallel versions are used in training, the better the
average precision.
There are some more detailed observations
which should also be made from Figure 2. First,
the average precision clearly varies quite widely
between language pairs. The language pairs with
the best average precision are those in which two
of English, French and Spanish are present. Of the
five languages used for testing, these three cluster
together genetically, since all three are Western
(Germanic or Romance) Indo-European languages.
Moreover, these are the three languages of the five
which are written in the Roman alphabet.
</bodyText>
<figure confidence="0.9863592">
Precision at 1 document
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Spanish- Arabic- Russian- English- Spanish- Russian- English- English- Spanish- English- OVERALL
Arabic French Arabic Arabic Russian French Russian Spanish French French
Language Pair
</figure>
<figureCaption confidence="0.999955">
Figure 2. Chart of precision at 1 doc. by language pair and number of parallel training versions
</figureCaption>
<bodyText confidence="0.985416866666667">
Number of languages
2 3 4 5 6 7 8 9 12 27 28 44 46 47
However, we believe the explanation for the
poorer results for language pairs involving either
Arabic, Russian, or both, can be pinned down to
something more specific. We have already par-
tially alluded to the obvious difference between
Arabic and Russian on the one hand, and English,
French and Spanish on the other: that Arabic and
Russian are highly morphologically rich, while
English, French and Spanish are generally analytic
languages. This has a clear effect on the statistics
for the languages in question, as can be seen in
Table 3, which is based on selected translations of
the Bible for each of the languages in question.
</bodyText>
<table confidence="0.992477833333333">
Translation Types Tokens
English (King James) 12,335 789,744
Spanish (Reina Valera 1909) 28,456 704,004
Russian (Synodal 1876) 47,226 560,524
Arabic (Smith Van Dyke) 55,300 440,435
French (Darby) 20,428 812,947
</table>
<tableCaption confidence="0.998584">
Table 3. Statistics for Bible translations in 5 lan-
guages used in test data
</tableCaption>
<page confidence="0.998617">
876
</page>
<bodyText confidence="0.997953782608696">
Assuming that the respective translations are
faithful (and we have no reason to believe other-
wise), and based on the statistics in Table 3, it
should be the case that Arabic contains the most
‘information’ per term (in the information theoretic
sense), followed by Russian, Spanish, English and
French.3 Again, this corresponds to our intuition
that much information is contained in Arabic pat-
terns and Russian inflectional morphemes, which
in English, French and Spanish would be contained
in separate terms (for example, prepositions).
Without additional pre-processing, however,
LSI cannot deal adequately with root-pattern or
inflectional morphology. Moreover, it is clearly a
weakness of LSI, or at least the standard log-
entropy weighting scheme as applied within this
framework, that it makes no adjustment for differ-
ences in information content per word between
languages. Even though we can assume near-
equivalency of information content between the
different translations above, according to the stan-
dard log-entropy weighting scheme there are large
differences between the total entropy of particular
parallel documents; in general, languages such as
English are overweighted while those such as Ara-
bic are underweighted.
Now that this issue is in perspective, we should
draw attention to another detail in Figure 2. Note
that the language pairs which benefited most from
the addition of Ancient Greek and Hebrew into the
training data were those which included Russian,
and Russian-Arabic saw the greatest increase in
precision. Recall also that the 47th version to be
added was the parsed Greek, so that essentially
each Greek morpheme is represented by a distinct
term. From Figure 2, it seems clear that the inclu-
sion of parsed Greek in particular boosted the pre-
cision for Russian (this is most visible at the right-
hand side of the set of columns for Russian-Arabic
and English-Russian). There are, after all, notable
similarities between modern Russian and Ancient
Greek morphology (for example, the nominal case
system). Essentially, the parsed Greek acts as a
‘clue’ to LSI in associating inflected forms in Rus-
3 To clarify the meaning of ‘term’ here: for all languages ex-
cept Chinese, text is tokenized in our framework into terms
using regular expressions; each non-word character (such as
punctuation or white space) is assumed to mark the boundary
of a word. For Chinese, we made the simplifying assumption
that each character represented a separate term.
sian with preposition/non-inflected combinations
in other languages. These results seem to be further
confirmation of the notion that parsing just one of
the languages in the mix helps overall; the greatest
boost is for those languages with morphology re-
lated to that of the parsed language, but there is at
least a maintenance, and perhaps a small boost, in
the precision for unrelated languages too.
Finally, we turn to look at some effects of the
particular languages selected for training. Included
in the results above, there were three separate tests
run in which there were 6 training versions. In all
three, Arabic, English, French, Russian and Span-
ish were included. The only factor we varied in the
three tests was the sixth version. In the three tests,
we used Modern Hebrew (a Semitic language,
along with Arabic), Hungarian (a Uralic language,
not closely related to any of the other five lan-
guages), and a second English version respectively.
The results of these tests are shown in Figure 3,
with figures for the test in which only 5 versions
were included for comparative purposes.
From these results, it is apparent first of all that
it was generally beneficial to add a sixth version,
regardless of whether the version added was Eng-
lish, Hebrew or Hungarian. This is consistent with
the results reported elsewhere in this paper. Sec-
ond, it is also apparent that the greatest benefit
overall was had by using an additional English ver-
sion, rather than using Hebrew or Hungarian.
Moreover, perhaps surprisingly, the use of Hebrew
in training – even though Hebrew is related to
Arabic – was of less benefit to Arabic than either
Hungarian or an additional English version. It ap-
pears that the use of multiple versions in the same
language is beneficial because it enables LSI to
make use of the many different instantiations in the
expression of a concept in a single language, and
that this effect can be greater than the effect which
obtains from using heterogeneous languages, even
if there is a genetic relationship to existing lan-
guages.
</bodyText>
<page confidence="0.976966">
877
</page>
<figure confidence="0.9743902">
Precision at 1 doc.
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Russian- Spanish- Arabic- English- Spanish- Russian- English- English- Spanish- English- OVERALL
Arabic Arabic French Arabic Russian French Russian Spanish French French
Language pair
</figure>
<figureCaption confidence="0.991882">
Figure 3. Precision at 1 document for 6 training versions, with results of using different mixes of lan-
guages for training
</figureCaption>
<bodyText confidence="0.924947705882353">
Arabic, English, French, Russian, Spanish Arabic, English, French, Hebrew, Russian, Spanish
Arabic, English, French, Hungarian, Russian, Spanish Arabic, English x 2, French, Russian, Spanish
Figure 3 may also shed some additional light on
one other detail from Figure 2: a perceptible jump
in precision between 28 and 44 training versions
for Arabic-English and Arabic-French. It should be
mentioned that among the 16 additional versions
were five English versions (American Standard
Version, Basic English Bible, Darby, Webster’s
Bible, and Young’s Literal Translation), and one
French version (Louis Segond 1910). It seems that
Figure 2 and Figure 3 both point to the same thing:
that the use of parallel versions or translations in a
single language can be particularly beneficial to
overall precision within the LSI framework – even
to a greater extent than the use of parallel transla-
tions in different languages.
</bodyText>
<sectionHeader confidence="0.999183" genericHeader="method">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999985615384616">
In this paper, we have shown how ‘massive paral-
lelism’ in an aligned corpus can be used to im-
prove the results of cross-language information
retrieval. Apart from the obvious advantage (the
ability to automate the processing of a greater vari-
ety of linguistic data within a single framework),
we have shown that including more parallel trans-
lations in training improves the precision of CLIR
across the board. This is true whether the addi-
tional translations are in the language of another
translation already within the training set, whether
they are in a related language, or whether they are
in an unrelated language; although this is not to say
that these choices do not lead to (generally minor)
variations in the results. The improvement in preci-
sion also appears to hold whether the additional
translations are complete or incomplete, and it ap-
pears that morphological pre-processing helps, not
just for the languages pre-processed, but again
across the board.
Our work also offers further evidence that the
supply of useful pre-existing parallel corpora is not
perhaps as scarce as it is sometimes claimed to be.
Compilation of the 47-version parallel corpus we
used was not very time-consuming, especially if
the time taken to clean the data is not taken into
</bodyText>
<page confidence="0.993656">
878
</page>
<bodyText confidence="0.999946307692308">
account, and all the textual material we used is
publicly available on the World Wide Web.
While the experiments we performed were on
non-standard test collections (primarily because
the Qu’ran was easy to obtain in multiple lan-
guages), it seems that there is no reason to believe
our general observation – that more parallelism in
the training data is beneficial for cross-language
retrieval – would not hold for text from other do-
mains. Whether the genre of text used as training
data affects the absolute rate of retrieval precision
for text of a different genre (e.g. news articles,
shopping websites) is a separate question, and one
we intend to address more fully in future work.
In summary, it appears that we are able to
achieve the results we do partly because of the in-
herent properties of LSI. In essence, when the data
from more and more parallel translations are sub-
jected to SVD, the LSI ‘concepts’ become more
and more reinforced. The resulting trend for preci-
sion to increase, despite ‘blips’ for individual lan-
guages, can be seen for all languages. To put it in
more prosaic terms, the more different ways the
same things are said in, the more understandable
they become – including in cross-language infor-
mation retrieval.
</bodyText>
<sectionHeader confidence="0.974609" genericHeader="method">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9955576">
Sandia is a multiprogram laboratory operated by
Sandia Corporation, a Lockheed Martin Company,
for the United States Department of Energy’s Na-
tional Nuclear Security Administration under con-
tract DE-AC04-94AL85000.
</bodyText>
<sectionHeader confidence="0.998742" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866951612903">
Lars Asker. 2004. Building Resources: Experiences
from Amharic Cross Language Information Re-
trieval. Paper presented at Cross-Language Informa-
tion Retrieval and Evaluation: Workshop of the
Cross-Language Evaluation Forum, CLEF 2004.
Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999.
Modern Information Retrieval. New York: ACM
Press.
Michael Berry, Theresa Do, Gavin O’Brien, Vijay
Krishna, and Sowmimi Varadhan. 1996.
SVDPACKC (Version 1.0) User’s Guide. Knoxville,
TN: University of Tennessee.
Bible Society. 2006. A Statistical Summary of Lan-
guages with the Scriptures. Accessed at
http://www.biblesociety.org/latestnews/latest341-
slr2005stats.html on Jan. 5, 2007.
Biola University. 2005-2006. The Unbound Bible. Ac-
cessed at http://www.unboundbible.com/ on Jan. 5,
2007.
Peter Chew, Stephen Verzi, Travis Bauer and Jonathan
McClain. 2006. Evaluation of the Bible as a Re-
source for Cross-Language Information Retrieval. In
Proceedings of the Workshop on Multilingual Lan-
guage Resources and Interoperability, 68-74. Syd-
ney: Association for Computational Linguistics.
Susan Dumais. 1991. Improving the Retrieval of Infor-
mation from External Sources. Behavior Research
Methods, Instruments, and Computers 23(2):229-
236.
Julio Gonzalo. 2001. Language Resources in Cross-
Language Text Retrieval: a CLEF Perspective. In
Carol Peters (ed.). Cross-Language Information Re-
trieval and Evaluation: Workshop of the Cross-
Language Evaluation Forum, CLEF 2000: 36-47.
Berlin: Springer-Verlag.
Dragos Munteanu and Daniel Marcu. 2006. Improving
Machine Translation Performance by Exploiting
Non-Parallel Corpora. Computational Linguistics
31(4):477-504.
Jian-Yun Nie and Fuman Jin. 2002. A Multilingual Ap-
proach to Multilingual Information Retrieval. Pro-
ceedings of the Cross-Language Evaluation Forum,
101-110. Berlin: Springer-Verlag.
Jian-Yun Nie, Michel Simard, Pierre Isabelle, and Rich-
ard Durand. 1999. Cross-Language Retrieval based
on Parallel Texts and Automatic Mining of Parallel
Texts from the Web. Proceedings of the 22nd Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, 74-81,
August 15-19, 1999, Berkeley, CA.
Carol Peters (ed.). 2001. Cross-Language Information
Retrieval and Evaluation: Workshop of the Cross-
Language Evaluation Forum, CLEF 2000. Berlin:
Springer-Verlag.
Recherche appliquée en linguistique informatique
(RALI). 2006. Corpus aligné bilingue anglais-
français. Accessed at http://rali.iro.umontreal.ca/ on
February 22, 2006.
Philip Resnik, Mari Broman Olsen, and Mona Diab.
1999. The Bible as a Parallel Corpus: Annotating the
&amp;quot;Book of 2000 Tongues&amp;quot;. Computers and the Hu-
manities, 33: 129-153.
</reference>
<page confidence="0.998976">
879
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904330">
<title confidence="0.972998">Benefits of the ‘Massively Parallel Rosetta Stone’: Cross-Language Information Retrieval with over 30 Languages</title>
<author confidence="0.999768">Peter A Chew</author>
<affiliation confidence="0.99936">Sandia National Laboratories</affiliation>
<address confidence="0.998227">P. O. Box 5800, MS 1012 Albuquerque, NM 87185-1012, USA</address>
<email confidence="0.991661">pchew@sandia.gov</email>
<author confidence="0.997783">Ahmed Abdelali</author>
<affiliation confidence="0.996268">New Mexico State University</affiliation>
<address confidence="0.990024">P.O. Box 30002, Mail Stop 3CRL Las Cruces, NM 88003-8001, USA</address>
<email confidence="0.999474">ahmed@crl.nmsu.edu</email>
<abstract confidence="0.999692">In this paper, we describe our experiences in extending a standard cross-language information retrieval (CLIR) approach which uses parallel aligned corpora and Latent Semantic Indexing. Most, if not all, previous work which follows this approach has focused on bilingual retrieval; two examples involve the use of French- English or English-Greek parallel corpora. Our extension to the approach is ‘massively parallel’ in two senses, one linguistic and the other computational. First, we make use of a parallel aligned corpus consisting of almost 50 parallel translations in over 30 distinct languages, each in over 30,000 documents. Given the size of this dataset, a ‘massively parallel’ approach was also necessitated in the more usual computational sense. Our results indicate that, far from adding more noise, more linguistic parallelism is better when it comes to cross-language retrieval precision, in addition to the self-evident benefit that CLIR can be performed on more languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lars Asker</author>
</authors>
<title>Building Resources: Experiences from Amharic Cross Language Information Retrieval. Paper presented at Cross-Language Information Retrieval and Evaluation: Workshop of the Cross-Language Evaluation Forum,</title>
<date>2004</date>
<location>CLEF</location>
<contexts>
<context position="2909" citStr="Asker 2004" startWordPosition="465" endWordPosition="466">on (although that is not the approach that Nie and Jin take), this is perhaps understandable, as for each new language, a new translation algorithm must be included. The effort involved in extending query translation to multiple languages, therefore, is likely to be in proportion to the number of languages. With parallel corpora, the reason that research has been limited to only a few languages at a time – and usually just two at a time, as in the LSI work cited above – is more likely to be rooted in the widespread perception that good parallel corpora are difficult to obtain (see for example Asker 2004). However, recent work (Resnik et al. 1999, Chew et al. 2006) has challenged this idea. One advantage of a ‘massively parallel’ multilingual corpus is perhaps self-evident: within the LSI framework, the more languages are mapped into the single conceptual space, the fewer restrictions there are on which languages documents can be selected from for cross-language retrieval. However, several questions were raised for us as Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 872–879, Prague, Czech Republic, June 2007. c�2007 Association for Computational </context>
</contexts>
<marker>Asker, 2004</marker>
<rawString>Lars Asker. 2004. Building Resources: Experiences from Amharic Cross Language Information Retrieval. Paper presented at Cross-Language Information Retrieval and Evaluation: Workshop of the Cross-Language Evaluation Forum, CLEF 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>ACM Press.</publisher>
<location>New York:</location>
<marker>Baeza-Yates, Ribeiro-Neto, 1999</marker>
<rawString>Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999. Modern Information Retrieval. New York: ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Berry</author>
<author>Theresa Do</author>
<author>Gavin O’Brien</author>
<author>Vijay Krishna</author>
<author>Sowmimi Varadhan</author>
</authors>
<date>1996</date>
<journal>SVDPACKC (Version</journal>
<volume>1</volume>
<institution>User’s Guide. Knoxville, TN: University of Tennessee.</institution>
<marker>Berry, Do, O’Brien, Krishna, Varadhan, 1996</marker>
<rawString>Michael Berry, Theresa Do, Gavin O’Brien, Vijay Krishna, and Sowmimi Varadhan. 1996. SVDPACKC (Version 1.0) User’s Guide. Knoxville, TN: University of Tennessee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bible Society</author>
</authors>
<title>A Statistical Summary of Languages with the Scriptures. Accessed at http://www.biblesociety.org/latestnews/latest341-slr2005stats.html on</title>
<date>2006</date>
<volume>5</volume>
<contexts>
<context position="4770" citStr="Society, 2006" startWordPosition="763" endWordPosition="764">or crosslanguage comparison. In section 4, we present and discuss the results of the various tests we performed. Finally, we conclude on our findings in section 5. 2 The massively parallel corpus Following Chew et al. (2006), our parallel corpus was built up from translations of the Bible which are freely available on the World Wide Web. Although reliable comparable statistics are hard to find, it appears to be generally agreed that the Bible is the world’s most widely translated book, with complete translations in 426 languages and partial translations in 2,403 as of December 31, 2005 (Bible Society, 2006). Great care is taken over the translations, and they are alignable by chapter and verse. According to Resnik et al. (1999), the Bible’s coverage of modern vocabulary may be as high as 85%. The vast majority of the translations we used came from the ‘Unbound Bible’ website (Biola University, 2005-2006); from this website, the text of a large number of different translations of the Bible can – most importantly for our purposes – be downloaded in a tab-delimited format convenient for loading into a database and then indexing by chapter and verse in order to ensure ‘parallelism’ in the corpus. Th</context>
</contexts>
<marker>Society, 2006</marker>
<rawString>Bible Society. 2006. A Statistical Summary of Languages with the Scriptures. Accessed at http://www.biblesociety.org/latestnews/latest341-slr2005stats.html on Jan. 5, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Biola University</author>
</authors>
<title>The Unbound Bible. Accessed at http://www.unboundbible.com/ on</title>
<date>2005</date>
<contexts>
<context position="5067" citStr="University, 2005" startWordPosition="814" endWordPosition="815"> are freely available on the World Wide Web. Although reliable comparable statistics are hard to find, it appears to be generally agreed that the Bible is the world’s most widely translated book, with complete translations in 426 languages and partial translations in 2,403 as of December 31, 2005 (Bible Society, 2006). Great care is taken over the translations, and they are alignable by chapter and verse. According to Resnik et al. (1999), the Bible’s coverage of modern vocabulary may be as high as 85%. The vast majority of the translations we used came from the ‘Unbound Bible’ website (Biola University, 2005-2006); from this website, the text of a large number of different translations of the Bible can – most importantly for our purposes – be downloaded in a tab-delimited format convenient for loading into a database and then indexing by chapter and verse in order to ensure ‘parallelism’ in the corpus. The number of translations available at the website is apparently being added to, based on our observations accessing the website on a number of different occasions. The languages we have included in our multilingual parallel corpus include those both ancient and modern, and are as follows: Languag</context>
</contexts>
<marker>University, 2005</marker>
<rawString>Biola University. 2005-2006. The Unbound Bible. Accessed at http://www.unboundbible.com/ on Jan. 5, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Chew</author>
<author>Stephen Verzi</author>
<author>Travis Bauer</author>
<author>Jonathan McClain</author>
</authors>
<title>Evaluation of the Bible as a Resource for Cross-Language Information Retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multilingual Language Resources and Interoperability,</booktitle>
<pages>68--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney:</location>
<contexts>
<context position="2970" citStr="Chew et al. 2006" startWordPosition="474" endWordPosition="477">take), this is perhaps understandable, as for each new language, a new translation algorithm must be included. The effort involved in extending query translation to multiple languages, therefore, is likely to be in proportion to the number of languages. With parallel corpora, the reason that research has been limited to only a few languages at a time – and usually just two at a time, as in the LSI work cited above – is more likely to be rooted in the widespread perception that good parallel corpora are difficult to obtain (see for example Asker 2004). However, recent work (Resnik et al. 1999, Chew et al. 2006) has challenged this idea. One advantage of a ‘massively parallel’ multilingual corpus is perhaps self-evident: within the LSI framework, the more languages are mapped into the single conceptual space, the fewer restrictions there are on which languages documents can be selected from for cross-language retrieval. However, several questions were raised for us as Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 872–879, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics we contemplated the use of a massively parallel c</context>
<context position="4380" citStr="Chew et al. (2006)" startWordPosition="696" endWordPosition="699">to show both that more languages are generally beneficial, and even incomplete parallel corpora can be used. In the remainder of this paper, we provide evidence for this claim. The paper is organized as follows: section 2 describes the work we undertook to build the parallel corpus and its characteristics. In section 3, we outline the mechanics behind the &apos;Rosetta-Stone&apos; type method we use for crosslanguage comparison. In section 4, we present and discuss the results of the various tests we performed. Finally, we conclude on our findings in section 5. 2 The massively parallel corpus Following Chew et al. (2006), our parallel corpus was built up from translations of the Bible which are freely available on the World Wide Web. Although reliable comparable statistics are hard to find, it appears to be generally agreed that the Bible is the world’s most widely translated book, with complete translations in 426 languages and partial translations in 2,403 as of December 31, 2005 (Bible Society, 2006). Great care is taken over the translations, and they are alignable by chapter and verse. According to Resnik et al. (1999), the Bible’s coverage of modern vocabulary may be as high as 85%. The vast majority of</context>
</contexts>
<marker>Chew, Verzi, Bauer, McClain, 2006</marker>
<rawString>Peter Chew, Stephen Verzi, Travis Bauer and Jonathan McClain. 2006. Evaluation of the Bible as a Resource for Cross-Language Information Retrieval. In Proceedings of the Workshop on Multilingual Language Resources and Interoperability, 68-74. Sydney: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Dumais</author>
</authors>
<title>Improving the Retrieval of Information from External Sources.</title>
<date>1991</date>
<journal>Behavior Research Methods, Instruments, and Computers</journal>
<pages>23--2</pages>
<marker>Dumais, 1991</marker>
<rawString>Susan Dumais. 1991. Improving the Retrieval of Information from External Sources. Behavior Research Methods, Instruments, and Computers 23(2):229-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Gonzalo</author>
</authors>
<title>Language Resources in CrossLanguage Text Retrieval:</title>
<date>2001</date>
<booktitle>Cross-Language Information Retrieval and Evaluation: Workshop of the CrossLanguage Evaluation Forum, CLEF 2000:</booktitle>
<pages>36--47</pages>
<editor>a CLEF Perspective. In Carol Peters (ed.).</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin:</location>
<marker>Gonzalo, 2001</marker>
<rawString>Julio Gonzalo. 2001. Language Resources in CrossLanguage Text Retrieval: a CLEF Perspective. In Carol Peters (ed.). Cross-Language Information Retrieval and Evaluation: Workshop of the CrossLanguage Evaluation Forum, CLEF 2000: 36-47. Berlin: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting Non-Parallel Corpora.</title>
<date>2006</date>
<journal>Computational Linguistics</journal>
<pages>31--4</pages>
<marker>Munteanu, Marcu, 2006</marker>
<rawString>Dragos Munteanu and Daniel Marcu. 2006. Improving Machine Translation Performance by Exploiting Non-Parallel Corpora. Computational Linguistics 31(4):477-504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Fuman Jin</author>
</authors>
<title>A Multilingual Approach to Multilingual Information Retrieval.</title>
<date>2002</date>
<booktitle>Proceedings of the Cross-Language Evaluation Forum,</booktitle>
<pages>101--110</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin:</location>
<contexts>
<context position="2276" citStr="Nie and Jin 2002" startWordPosition="353" endWordPosition="356">et language, for example using machine translation or on-line dictionaries. The second makes use of parallel aligned corpora as training sets. One approach which uses parallel corpora does this in conjunction with Latent Semantic Indexing (LSI) (Landauer and Littman 1990, Young 1994). According to Berry et al. (1994:21), the use of LSI with parallel corpora can be just as effective as the query translation approach, and avoids some of the drawbacks of the latter, discussed in Nie et al. (1999). Generally, research in CLIR has not attempted to use very many languages at a time (see for example Nie and Jin 2002). With query translation (although that is not the approach that Nie and Jin take), this is perhaps understandable, as for each new language, a new translation algorithm must be included. The effort involved in extending query translation to multiple languages, therefore, is likely to be in proportion to the number of languages. With parallel corpora, the reason that research has been limited to only a few languages at a time – and usually just two at a time, as in the LSI work cited above – is more likely to be rooted in the widespread perception that good parallel corpora are difficult to ob</context>
</contexts>
<marker>Nie, Jin, 2002</marker>
<rawString>Jian-Yun Nie and Fuman Jin. 2002. A Multilingual Approach to Multilingual Information Retrieval. Proceedings of the Cross-Language Evaluation Forum, 101-110. Berlin: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
<author>Richard Durand</author>
</authors>
<title>Cross-Language Retrieval based on Parallel Texts and Automatic Mining of Parallel Texts from the Web.</title>
<date>1999</date>
<booktitle>Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>74--81</pages>
<location>Berkeley, CA.</location>
<contexts>
<context position="2157" citStr="Nie et al. (1999)" startWordPosition="330" endWordPosition="333">corpus’ approach. The first of these, which is perhaps more common, in872 volves translation of the query into the target language, for example using machine translation or on-line dictionaries. The second makes use of parallel aligned corpora as training sets. One approach which uses parallel corpora does this in conjunction with Latent Semantic Indexing (LSI) (Landauer and Littman 1990, Young 1994). According to Berry et al. (1994:21), the use of LSI with parallel corpora can be just as effective as the query translation approach, and avoids some of the drawbacks of the latter, discussed in Nie et al. (1999). Generally, research in CLIR has not attempted to use very many languages at a time (see for example Nie and Jin 2002). With query translation (although that is not the approach that Nie and Jin take), this is perhaps understandable, as for each new language, a new translation algorithm must be included. The effort involved in extending query translation to multiple languages, therefore, is likely to be in proportion to the number of languages. With parallel corpora, the reason that research has been limited to only a few languages at a time – and usually just two at a time, as in the LSI wor</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>Jian-Yun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-Language Retrieval based on Parallel Texts and Automatic Mining of Parallel Texts from the Web. Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 74-81, August 15-19, 1999, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Peters</author>
</authors>
<date>2001</date>
<booktitle>Cross-Language Information Retrieval and Evaluation: Workshop of the CrossLanguage Evaluation Forum, CLEF 2000.</booktitle>
<publisher>Springer-Verlag.</publisher>
<location>Berlin:</location>
<marker>Peters, 2001</marker>
<rawString>Carol Peters (ed.). 2001. Cross-Language Information Retrieval and Evaluation: Workshop of the CrossLanguage Evaluation Forum, CLEF 2000. Berlin: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<title>Recherche appliquée en linguistique informatique (RALI).</title>
<date>2006</date>
<contexts>
<context position="4380" citStr="(2006)" startWordPosition="699" endWordPosition="699"> that more languages are generally beneficial, and even incomplete parallel corpora can be used. In the remainder of this paper, we provide evidence for this claim. The paper is organized as follows: section 2 describes the work we undertook to build the parallel corpus and its characteristics. In section 3, we outline the mechanics behind the &apos;Rosetta-Stone&apos; type method we use for crosslanguage comparison. In section 4, we present and discuss the results of the various tests we performed. Finally, we conclude on our findings in section 5. 2 The massively parallel corpus Following Chew et al. (2006), our parallel corpus was built up from translations of the Bible which are freely available on the World Wide Web. Although reliable comparable statistics are hard to find, it appears to be generally agreed that the Bible is the world’s most widely translated book, with complete translations in 426 languages and partial translations in 2,403 as of December 31, 2005 (Bible Society, 2006). Great care is taken over the translations, and they are alignable by chapter and verse. According to Resnik et al. (1999), the Bible’s coverage of modern vocabulary may be as high as 85%. The vast majority of</context>
</contexts>
<marker>2006</marker>
<rawString>Recherche appliquée en linguistique informatique (RALI). 2006. Corpus aligné bilingue anglaisfrançais. Accessed at http://rali.iro.umontreal.ca/ on February 22, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Mari Broman Olsen</author>
<author>Mona Diab</author>
</authors>
<title>The Bible as a Parallel Corpus: Annotating the &amp;quot;Book of</title>
<date>1999</date>
<journal>Tongues&amp;quot;. Computers and the Humanities,</journal>
<volume>33</volume>
<pages>129--153</pages>
<contexts>
<context position="2951" citStr="Resnik et al. 1999" startWordPosition="470" endWordPosition="473">ch that Nie and Jin take), this is perhaps understandable, as for each new language, a new translation algorithm must be included. The effort involved in extending query translation to multiple languages, therefore, is likely to be in proportion to the number of languages. With parallel corpora, the reason that research has been limited to only a few languages at a time – and usually just two at a time, as in the LSI work cited above – is more likely to be rooted in the widespread perception that good parallel corpora are difficult to obtain (see for example Asker 2004). However, recent work (Resnik et al. 1999, Chew et al. 2006) has challenged this idea. One advantage of a ‘massively parallel’ multilingual corpus is perhaps self-evident: within the LSI framework, the more languages are mapped into the single conceptual space, the fewer restrictions there are on which languages documents can be selected from for cross-language retrieval. However, several questions were raised for us as Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 872–879, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics we contemplated the use of a m</context>
<context position="4893" citStr="Resnik et al. (1999)" startWordPosition="782" endWordPosition="785">lly, we conclude on our findings in section 5. 2 The massively parallel corpus Following Chew et al. (2006), our parallel corpus was built up from translations of the Bible which are freely available on the World Wide Web. Although reliable comparable statistics are hard to find, it appears to be generally agreed that the Bible is the world’s most widely translated book, with complete translations in 426 languages and partial translations in 2,403 as of December 31, 2005 (Bible Society, 2006). Great care is taken over the translations, and they are alignable by chapter and verse. According to Resnik et al. (1999), the Bible’s coverage of modern vocabulary may be as high as 85%. The vast majority of the translations we used came from the ‘Unbound Bible’ website (Biola University, 2005-2006); from this website, the text of a large number of different translations of the Bible can – most importantly for our purposes – be downloaded in a tab-delimited format convenient for loading into a database and then indexing by chapter and verse in order to ensure ‘parallelism’ in the corpus. The number of translations available at the website is apparently being added to, based on our observations accessing the web</context>
</contexts>
<marker>Resnik, Olsen, Diab, 1999</marker>
<rawString>Philip Resnik, Mari Broman Olsen, and Mona Diab. 1999. The Bible as a Parallel Corpus: Annotating the &amp;quot;Book of 2000 Tongues&amp;quot;. Computers and the Humanities, 33: 129-153.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>