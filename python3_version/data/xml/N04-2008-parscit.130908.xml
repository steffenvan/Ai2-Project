<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009133">
<title confidence="0.979698">
Greek Word Segmentation Using Minimal Information
</title>
<author confidence="0.96976">
C. Anton Rytting
</author>
<affiliation confidence="0.9947435">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.559966">
Columbus, Ohio 43210
</address>
<email confidence="0.998001">
rytting@ling.ohio-state.edu
</email>
<sectionHeader confidence="0.998597" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999931">
Several computational simulations have been
proposed for how children solve the word
segmentation problem, but most have been
tested only on a limited number of languages,
often only English. In order to extend the
cross-linguistic dimension of word segmenta-
tion research, a finite-state framework for test-
ing various models of word segmentation is
sketched, and a very simple cue is tested in
this framework. Data is taken from Modern
Greek, a language with phonological patterns
distinct from English. A small-scale simula-
tion shows using this cue performs signifi-
cantly better than chance. The utility and
flexibility of the finite-state approach is con-
firmed; suggestions for improvement are
noted and directions for future work outlined.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922739130435">
A substantial portion of research in first-language ac-
quisition focuses on the “word segmentation prob-
lem”—how children learn to extract words (or word
candidates) from a continuous speech signal prior to
having acquired a substantial vocabulary. Note that the
hardware and software constraints on the human learner
are very different from those faced by a speech recogni-
tion system, and hence strategies appropriate for one
may be irrelevant or disastrously inappropriate for the
other.
While a number of robust strategies have been pro-
posed and tested for English and a few other languages
(discussed below), it is not clear whether or how these
apply to other languages. For example, the Metrical
Segmentation Strategy (e.g., Cutler &amp; Norris 1988)
turns out to be very robust for English, but is not neces-
sarily applicable to other languages, simply because not
all languages share English’s predilection for strong
word-initial syllables (though language-appropriate
variants of the strategy (stress-based for English) have
been proposed, e.g., using the syllable in French (Cutler
&amp; Mehler, 1993) and the mora in Japanese (Otake,
Hatano, Cutler, &amp; Mehler, 1993)).
Some more generic strategies (e.g., the Possible
Word Constraint: see e.g., Norris et al. 1997, 2001) have
been proposed and tested, primarily on English, but also
on typologically distinct languages such as Sesotho
(Cutler, Demuth, &amp; McQueen, 2002). Nevertheless,
rigorous testing in a larger sample of languages seems
advisable before making strong claims of universal ap-
plicability. One interesting strategy explored in e.g.,
(Aslin et al., 1996) is the use of context around (and
particularly before) utterance boundaries to predict word
boundaries. The applicability of this cue is discussed
for both English and Turkish; a simulation on English
data is reported. One goal of the research presented
here is to further explore that strategy on a different data
set, taken from a language with phonological patterns
quite different from English or Turkish.
The work presented here is intended as a small part
of a more general line of research, whose purpose is
twofold: on the one hand I wish to understand the nature
of the cues present in Modern Greek, on the other I wish
to establish a framework for orderly comparison of
word segmentation algorithms across the desired broad
range of languages.
</bodyText>
<subsectionHeader confidence="0.998064">
1.1 Infant Studies
</subsectionHeader>
<bodyText confidence="0.999961285714286">
At least four types of information in the speech signal
have been identified as likely cues for infants: (1) super-
segmental cues (e.g., stress) which begins to play a role
in (English-learning) 7.5 month-olds (Jusczyk, Houston,
et al., 1999); (2) sub-segmental cues such as co-
articulation and allophonic alternations, which infants
begin using between 7.5 and 10.5 months of age (Jusc-
zyk, Hohne, et al., 1999); (3) segmental cues, such as
wordlikeness and phonotactic constraints, which seem
to be available by 9 months of age (e.g., Jusczyk, Luce,
et al., 1994; Mattys and Jusczyk, 2001), and (4) statisti-
cal cues from recurrent patterns e.g., of syllables, evi-
dent in English-learning 8-month-olds on an artificial
micro-language of 4 words (Saffran et al. 1996).1
</bodyText>
<subsectionHeader confidence="0.973145">
1.2 Computational Models
</subsectionHeader>
<bodyText confidence="0.961291240740741">
While the infant studies discussed above focus primarily
on the properties of particular cues, computational stud-
ies of word-segmentation must also choose between
various implementations, which further complicates
comparisons. In addition, several models (e.g.,
Batchelder, 2002; Brent’s MLDP-1, 1999a; Davis,
2000; de Marcken, 1996; Olivier, 1968) simultaneously
address the question of vocabulary acquisition, using
previously learned word-candidates to bootstrap later
segmentations. While these models are highly interest-
ing both from their view of the long-term process of
language acquisition and their high success rate, they
are hard to relate to the infant studies discussed above.
Hence, it is beyond the scope of this paper to discuss
them at length.2
Rather, this paper focuses on models that do not ac-
cumulate a stored vocabulary, but rely on either on sta-
tistics derived from utterance boundaries (typically
generalized over feature matrices, as in (Aslin et al.,
1996; Christiansen et al., 1998)) or from the degree of
predictability of the next syllable (e.g., Saffran et al.,
1996) or segment (Christiansen et al., 1998). The intui-
tion here, first articulated by Harris (1954) is that word
boundaries will be marked by a spike in unpredictability
of the following phoneme. Christiansen et al. (1998)
also test the contribution of stress and phonemic infor-
mation in addition to that of utterance boundaries, and
show that while stress contributes in certain circum-
stances, it is not as crucial as featural information near
utterance boundaries.
The general line of research herein proposed focuses
on the same cues as (Christiansen et al., 1998) begin-
ning (in the work reported here) with segmental prob-
ability distributions at utterance boundaries. This first
step corresponds most closely with (Aslin et al., 1996),
where utterance boundaries were treated as a cue on
their own. Aslin and his colleagues propose that “even
the most minimal assumption about what an infant can
recognize as a word boundary--namely, the pause after
an utterance--is sufficient, in principle, for the learning
the word boundaries within an utterance” (p. 133). In
1 Full mention of all the studies done is not possible
here; for a fuller review see e.g., (Johnson &amp; Jusczyk, 2001).
2 For useful reviews of various computational models,
see (Brent, 1999a,b).
that study, however, a considerable amount of context
before such an utterance was given, namely 18-bit fea-
ture vectors of one, two, or three phonemes immediately
preceding the final utterance boundary. For a model
with 30 hidden units, the following results for boundary
detection are reported (as estimated from their bar
graph, fig.8.8, p. 132), accompanied by the claim that
only with two- and three-phoneme sequences is their
system capable of learning boundary locations:
</bodyText>
<table confidence="0.995864">
Hits False Precision
Alarms (H/(H+FA))
3 phones 62% 22% 74%
2 phones 53% 23% 70%
1 phone 45% 44% 51%
Random 5% 15% 25%
</table>
<tableCaption confidence="0.840675">
Table 1. Results reported in Aslin et al. (1996,
Fig. 8.8, p. 132).
</tableCaption>
<bodyText confidence="0.999761379310345">
They further claim that feature vectors are necessary for
learning: a string of three phonemes (where each pho-
neme is represented as an atomistic unit) is not suffi-
cient information, although no comparative figures are
listed for this condition.
This study may be seen as a replication of (Aslin et
al., 1996); however, it differs in several crucial re-
spects—not with an eye toward improving upon their
results, but rather on examining further their definition
of “minimal necessary cues.” First, instead of training
the transitional probabilities indirectly with connection-
ist networks, the probabilities are encoded directly
within a finite-state framework. Secondly, actual phone
identities (rather than feature bundles) are used as sym-
bols. Finally, information about a single segment is
used. While this very austere use of minimal informa-
tion is surely inadequate to the full task of segmentation,
it nevertheless serves to demonstrate the gains even a
very small amount of information can give. Any evi-
dence of better-than-chance results would suggest that,
for Modern Greek at least, even more minimal cues are
possible than those Aslin et al. (1996) propose.
The results of this study may be taken as a rough
approximation of how predictable word boundaries are
from (unigram) segmental information alone in the sub-
set of Modern Greek experienced by young children.
These findings may provide an additional baseline for
measuring and comparing the relative contributions of
other cues such as stress as a word segmentation cue.
</bodyText>
<sectionHeader confidence="0.750897" genericHeader="method">
2 Constructing a Finite-State Model
</sectionHeader>
<subsectionHeader confidence="0.877692">
2.1 Data
</subsectionHeader>
<bodyText confidence="0.99998595">
The Greek CHILDES corpus (Stephany, 1995) is a da-
tabase of conversations between children and caretak-
ers, broadly transcribed, currently with no notations for
lexical stress. Audio tapes exist, but are currently un-
available for general use (Stephany, p.c.). However, the
transcriptions themselves give an indication at the pho-
nemic level of the sort of input Greek children are likely
to have in learning their language. In order to preserve
adequate unseen data for future simulations and experi-
ments, only a small subset of the total Greek CHILDES
corpus was used.
As in other studies, only adult input was used for
training and testing. In addition, non-segmental infor-
mation such as punctuation, dysfluencies, parenthetical
references to real-world objects, etc. were removed.
Word boundaries are represented by the symbol #, ut-
terance boundaries by $, following Brent (1999a). Each
line of the file was assumed to be an independent utter-
ance. Spaces were assumed to represent word bounda-
ries without comment or correction; however, it is worth
noting that the transcribers sometimes departed from
standard orthographic practice with respect to certain
types of word-clitic combinations. The text also con-
tains a significant number of unrealized final vowels
(apocopy), such as [in] for /ine/ &apos;is&apos;. Such variation was
not regularized, but treated as part of the learning task.
The training corpus contains 367 utterance tokens
with a total of 1066 word tokens (319 types). Whereas
the average number of words per utterance (2.9) is com-
parable to the Korman (1984) corpus used by
Christiansen et al. (3.0), utterances and words were
slightly longer in terms of phonemes (12.8 and 4.4 pho-
nemes respectively, compared to 9.0 and 3.0). (Statis-
tics on the corpus used in (Aslin et al., 1996) were not
provided.)
The test corpus consists of utterances by adults to
the same child as in the training corpus. Utterances
with dysfluencies, missing words, or other irregularities
were discarded; the remaining utterances include 273
utterance tokens with a total of 699 words (229 types).
</bodyText>
<subsectionHeader confidence="0.997493">
2.2 Model Design
</subsectionHeader>
<bodyText confidence="0.986608095238095">
This model differs from incremental models such as
(Brent 1999a) in that it pre-compiles statistics for the
candidate word-final phonemes off-line, over the entire
corpus. These probabilities are thus static. While this
difference is not intended as a strong theoretical claim,
it reflects the fact that even before infants seem to be
learning the word segmentation process, they have al-
ready been exposed to a large amount of linguistic ma-
terial. The information gleaned from the corpus is
represented in three separate (but composible) finite-
state machines:
(1) Like most models in the literature, this model as-
sumes (for sake of convenience and simplicity) that the
child hears the correct sequence of the actual segments
produced within an utterance. Hence, the model does
not take into account the possibility of mishearing a
segment, as that would add undue complication at this
stage. This assumption translates into the finite-state
domain as a simple acceptor (or equivalently, an iden-
tity transducer) over the segment sequence for a given
utterance.3
</bodyText>
<listItem confidence="0.99067825">
(2) An optional source of knowledge used is the number
of words in a given utterance. This is naturally a strong
assumption to make; it is included primarily to provide
comparisons with baselines used by Brent (1999a) and
Christiansen et al. (1998), which provide pseudo-
random baselines that make reference either to number
of boundaries directly or information concerning aver-
age word length. Results are given both with and with-
out this constraint.
(3) The main item under examination is naturally the
relative likelihood of breaking the word after a given
segment S.
</listItem>
<bodyText confidence="0.999960043478261">
The third information source was tested in three vari-
ants. The first one is of course the approximation sug-
gested by Aslin et al. (1996), that P(#|S) may be
approximated by using P($|S), the probability of an ut-
terance-break given the segment. This approximation
yields the ranking e&gt;s&gt;o&gt;u&gt;i&gt;a&gt;m&gt;n, with /e/ most
likely to end an utterance. This information source was
compared to two related alternatives, which were used
as upper and lower bounds to measure the effectiveness
of the utterance-boundary approximation of word
boundaries. As an upper bound (3U), the true value for
P(#|S) is used, corresponding to training on labeled data,
or a store of already-learned vocabulary.4 The lower
bound (3L) consists of the seven final segments
{a,e,i,o,u,n,s}, but the frequency ranking replaced by an
equi-probable assumption. In a sense, this is equivalent
to a grammar book listing the possible final segments of
Greek without regard to their actual likelihood. Finally,
these three variants are compared with a random walk
for which no information is used, but boundaries are
inserted completely by chance. Each of these three
types of knowledge was modeled by means of a finite
state machine, using the AT&amp;T finite-state tools.5
</bodyText>
<footnote confidence="0.673083333333333">
3 While modeling the mishearing of segments is beyond
the scope of this study, a weighted transducer could in prin-
ciple represent a segmental confusion matrix in a modular
way and augment the current identity transducer. For
further discussion of issues in using “unsanitized data,”
(Sundaram, 2003) may be helpful.
4 The resulting ranking, o&gt;i&gt;e&gt;s&gt;a&gt;u&gt;n&gt;j&gt;m&gt;p, is
rather different than the one above, reflecting the frequency
of masculine and feminine articles /o/ and /i/, which are
never utterance-final.
5 FSM Library Version 3.7, freely available from
http://www.research.att.com/sw/tools/fsm/
</footnote>
<listItem confidence="0.858188857142857">
(1) Segments: Linear FSA (trivially equivalent to an
identity transducer).
(2) Number of words: Unweighted FSA.
(3U) Upper bound: Weighted FST, with weights corre-
sponding to -Log(P(#|S)) for a word boundary
and -Log(1-P(#|S)) for an arc with no word boundary.
(3) Utterance-Boundary Probabilities: Same as (3U),
</listItem>
<bodyText confidence="0.973693545454545">
with weights corresponding to -Log(P($|S)) for a word
boundary and -Log(1-P($|S)) for no word boundary. In
the condition where (2) was not used, a weight of -1.7
(determined empirically on the training data) was added
to the word-boundary arc, to offset the tendency of
P($|S) to underestimate P(#|S).
(3L) Unweighted (or equally weighted) version of (3).
In the condition where (2) was not used, a weight of
(-0.5) was added to the arc that adds boundaries, which
caused the FST to insert word boundaries after every
instance of a vowel, /n/, or /s/.
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.9997508">
Six different conditions were tested, corresponding to
the three variants FSTs (3), (3U), and (3L), both with and
without the exact-word constraint in FSM (2). Each of
these were composed (separately) with the “segment
identity” acceptor (1) for a given utterance. The output-
projection of the best path from each resulting FST was
converted back into text and compared to the text of the
original utterance. Scores for both boundaries and
words are reported (where a word is counted as cor-
rectly segmented only if both its left and right bounda-
ries are correctly placed). In the case where several
best-paths of equal cost exist, the average scores for
precision and recall are counted.
The results with and without the number of words
known are shown in Tables 2 and 3, following. In both
cases, the precision scores patterned as expected. The
upper bound condition (representing a supervised case,
where statistics on the word boundaries are available for
the training data) proved the most accurate on the test
data. This suggests (as has been confirmed for English
in such studies as Brent 1999a) that the learning of pat-
terns over already-acquired vocabulary has perhaps the
largest effect in the acquisition of new vocabulary.
The utterance-based approximation, corresponding
most closely to (Aslin et al., 1996), seems to be slightly
better overall than the lower bound. Without the num-
ber of words known, (3) has an F-score of 20.2 for
words and 70.2 for boundaries, whereas (3L) has F-
scores of only 17.0 (word) and 68.0 (boundaries),
though this difference may not be significant. This dif-
ference was less than expected, given preliminary ex-
amination of the training data; it may be that once the
set of allowable word-final phonemes is observed, the
relative probabilities of those phonemes is not as use-
fully learned from utterance boundaries. However, the
lower bound (corresponding to purely symbolic knowl-
edge of the allowable word-final segments) is signifi-
cantly better than the random walk, suggesting that any
knowledge, no matter how rudimentary, begins to make
a difference.
</bodyText>
<table confidence="0.999554272727273">
Words Word Boundaries
Precision Recall Preci- Recall
sion
Upper 277/699 277/699 751/972 751/972
bound (39.6%) (39.6%) (77.3%) (77.3%)
Utt- 226/699 226/699 721/972 721/972
prob. (32.4%) (32.4%) (74.2%) (74.2%)
Lower 221/699 221/699 708/972 708/972
bound (31.6%) (31.6%) (72.9%) (72.9%)
Random 119/699 119/699 639/972 639/972
Walk (17.0%) (17.0%) (65.7%) (65.7%)
</table>
<tableCaption confidence="0.897835">
Table 2: Test Results with Constraint (2)
</tableCaption>
<table confidence="0.9999133">
Words Word Boundaries
Precision Recall Precision Recall
Upper 219/720 219/699 737/993 737/972
bound (30.4%) (31.3%) (74.2%) (75.8%)
Utt- 159/860 159/699 739/1133 739/972
prob. (18.5%) (22.7%) (65.2%) (76.0%)
Lower 195/1599 195/699 967/1872 967/972
bound (12.2%) (27.9%) (51.7%) (99.5%)
Random 39/1569 39/699 767/1842 767/972
Walk (2.5%) (5.6%) (41.6%) (78.9%)
</table>
<tableCaption confidence="0.998983">
Table 3: Test Results without Constraint (2)
</tableCaption>
<sectionHeader confidence="0.999102" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999985">
4.1 Comparisons with Aslin et al. (1996)
</subsectionHeader>
<bodyText confidence="0.960426036363636">
Obviously, the cues of preceding and following seg-
ments are in and of itself insufficient to predict a word
boundary with any reasonable degree of accuracy, just
as Christiansen et al. (1998) found that no one cue was
sufficient for English. However, a few comparisons
with Aslin’s et al. (1996) data in Table 1 may be useful,
although they should be interpreted cautiously given the
differences in the training and testing corpora between
their study and this one. Their results for the single-
phoneme condition have nearly equal hits and false
alarms—a precision of about 51%. They apparently do
not consider this sufficient evidence of learning, al-
though it is significantly better than their random base-
line. Similarly, the worst non-random condition
reported here (lower bound without constraint (2)) also
has a precision of 51%. This, too, is difficult to call
“learning,” as it represents the heuristic of always in-
serting a word boundary any time there could be one.
The only fact that has been learned is which segments
cannot be (excepting foreign loan-words) word-final.
However, if the criterion for learning (or at least
satisfactory performance) is hits exceeding false alarms,
then the utterance-boundary statistical heuristic, with
739 hits and only 396 false alarms, is nearly as accurate
as Table 1’s two-phoneme condition. While further
information (whether phonological features, longer
strings of phonemes, or some other cue) is needed to
reach the 74% accuracy of Table 1’s three-phoneme
condition, it seems that even these very basic cues come
closer to Aslin’s et al. (1996) results than might be sup-
posed. Importantly, the same general trend was shown--
that utterance-final information translates into word-
boundary information not only for English, but for other
languages such as Modern Greek as well.
A number of further directions are possible under
this framework, including:
(1) Using transitional probability (P(Sk+1 |Sk)) and mu-
tual information measures over two adjacent segments
as cues to the likelihood of word boundaries between
those two segments, as suggested in e.g., (Brent, 1999a).
(2) Developing more plausible models for approximat-
ing word-length distributions from utterance-length in-
formation, distances between stressed vowels, pause
information, and other salient cues available to children.
(3) Incorporating stress cues (as potentially signaling
both beginnings and approaching ends of content
words) both alone and in combination with segmental
cues.
Preliminary work on each of these avenues is currently
underway. While some of these heuristics may require
the use of other techniques in addition to finite-state
techniques, the general finite-state framework is ex-
pected to prove useful as an organizing tool for compar-
ing various cues in a simple, rational, and transparent
way.
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99952775308642">
Aslin, Richard N., Woodward, Julide Z., LaMendola,
Nicholas P., &amp; Bever, Thomas G. 1996. Models of
word segmentation in fluent maternal speech to in-
fants. In James L. Morgan &amp; Katherine Demuth , edi-
tors, Signal to syntax, pages 117-134. Mahwah, NJ:
Lawrence Erlbaum Associates.
Batchelder, Elanor Olds 2002. Bootstrapping the lexi-
con: A computational model of infant speech seg-
mentation. Cognition 83:167-206.
Brent, Michael R. 1999a. An efficient, probabilistically
sound algorithm for segmentation and word discov-
ery. Machine Learning, 34:71-105.
Brent, Michael R. 1999b. Speech segmentation and
word discovery: a computational perspective. Trends
in Cognitive Sciences, 3(8):294-301.
Christiansen, Morton H., Allen, Joseph, &amp; Seidenberg,
Mark S. 1998. Learning to segment speech using
multiple cues: A connectionist model. Language and
Cognitive Processes, 13(2/3):221-268.
Davis, Matt H. (2000) Lexical segmentation in spoken
word recognition. Unpublished PhD thesis, Birkbeck
College, University of London. Available:
http://www.mrc-
cbu.cam.ac.uk/personal/matt.davis/thesis/index.html
de Marcken, Carl G. 1996b. Unsupervised language
acquisition. PhD dissertation, MIT, Cambridge, MA.
Available: http://xxx.lanl.gov/abs/cmp- lg/9611002
Harris, Zelig S. 1954. Distributional structure. Word,
10:146-162.
Johnson, Elizabeth K., &amp; Jusczyk, Peter W. 2001. Word
segmentation by 8- month-olds: when speech cues
count more than statistics. Journal of Memory and
Language, 44 (4), 548 567.
Joseph, Brian. 2001. ‘Word’ in Modern Greek. In
R.M.W. Dixon &amp; A. Aikhenvald (eds.) Proceedings
of the International Workshop on the Status of
‘Word’. Cambridge: Cambridge University Press
(2001).
Jusczyk, Peter W., &amp; Aslin, R. N. 1995. Infant&apos;s detec-
tion of sound patterns of words in fluent speech.
Cognitive Psychology, 29:1-23.
Jusczyk, Peter W., Hohne, E. A., &amp; Bauman, A. 1999.
Infants&apos; sensitivity to allophonic cues for word seg-
mentation. Perception &amp; Psychophysics, 61:1465-
1476.
Jusczyk, Peter W., Houston, Derek, &amp; Newsome, Mary.
1999. The beginnings of word segmentation in Eng-
lish-learning infants. Cognitive Psychology, 39:159-
207.
Jusczyk, Peter W., Luce, Paul A., &amp; Charles-Luce, Jan
1994. Infants&apos; sensitivity to phonotactic patterns in
the native language. Journal of Memory and Lan-
guage, 33:630-645.
Korman, Myron. 1984. Adaptive aspects of maternal
vocalizations in differing contexts at ten weeks. First
Language, 5:44-45.
Mattys, Sven L., Jusczyk, Peter W., Luce, Paul A., &amp;
Morgan, James L. 1999. Word segmentation in in-
fants: How phonotactics and prosody combine. Cog-
nitive Psychology, 38:465-494.
Mattys, Sven L. and Jusczyk, Peter W. 2001. Phono-
tactic cues for segmentation of fluent speech by in-
fants. Cognition 78:91-121.
Olivier, D. C. 1968. Stochastic grammars and language
acquisition mechanisms. PhD dissertation, Harvard
University, Cambridge, MA.
Saffran, Jenny R., Aslin, Richard N., &amp; Newport, Elissa
L. 1996. Statistical cues in language acquisition:
word segmentation by infants. In G.W. Cottrell, edi-
tor, Proceedings of the 18th Annual Conference of
the Cognitive Science Society. pages 376-380. Hills-
dale, NJ: Lawrence Erlbaum Associates.
Stephany, U. 1995. The acquisition of Greek. In D. I.
Slobin, editor, The crosslinguistic study of language
acquisition. Vol. 4.
Sundaram, Ramasubramanian. 2003. Effects of Tran-
scription Errors on Supervised Learning in Speech
Recognition. Unpublished Masters Thesis. Missis-
sippi State University, Mississippi State, MS.
http://www.isip.msstate.edu/publications/books/msst
ate_theses/2003/transcription_errors/.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.867214">
<title confidence="0.999809">Greek Word Segmentation Using Minimal Information</title>
<author confidence="0.999384">C Anton</author>
<affiliation confidence="0.985375">Department of The Ohio State</affiliation>
<address confidence="0.93631">Columbus, Ohio</address>
<email confidence="0.999888">rytting@ling.ohio-state.edu</email>
<abstract confidence="0.997254055555555">Several computational simulations have been proposed for how children solve the word segmentation problem, but most have been tested only on a limited number of languages, often only English. In order to extend the cross-linguistic dimension of word segmentation research, a finite-state framework for testing various models of word segmentation is sketched, and a very simple cue is tested in this framework. Data is taken from Modern Greek, a language with phonological patterns distinct from English. A small-scale simulation shows using this cue performs significantly better than chance. The utility and flexibility of the finite-state approach is confirmed; suggestions for improvement are noted and directions for future work outlined.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richard N Aslin</author>
<author>Julide Z Woodward</author>
<author>Nicholas P LaMendola</author>
<author>Thomas G Bever</author>
</authors>
<title>Models of word segmentation in fluent maternal speech to infants.</title>
<date>1996</date>
<booktitle>Signal to syntax,</booktitle>
<pages>117--134</pages>
<editor>In James L. Morgan &amp; Katherine Demuth , editors,</editor>
<publisher>Lawrence Erlbaum Associates.</publisher>
<location>Mahwah, NJ:</location>
<contexts>
<context position="2553" citStr="Aslin et al., 1996" startWordPosition="380" endWordPosition="383">ress-based for English) have been proposed, e.g., using the syllable in French (Cutler &amp; Mehler, 1993) and the mora in Japanese (Otake, Hatano, Cutler, &amp; Mehler, 1993)). Some more generic strategies (e.g., the Possible Word Constraint: see e.g., Norris et al. 1997, 2001) have been proposed and tested, primarily on English, but also on typologically distinct languages such as Sesotho (Cutler, Demuth, &amp; McQueen, 2002). Nevertheless, rigorous testing in a larger sample of languages seems advisable before making strong claims of universal applicability. One interesting strategy explored in e.g., (Aslin et al., 1996) is the use of context around (and particularly before) utterance boundaries to predict word boundaries. The applicability of this cue is discussed for both English and Turkish; a simulation on English data is reported. One goal of the research presented here is to further explore that strategy on a different data set, taken from a language with phonological patterns quite different from English or Turkish. The work presented here is intended as a small part of a more general line of research, whose purpose is twofold: on the one hand I wish to understand the nature of the cues present in Mode</context>
<context position="5101" citStr="Aslin et al., 1996" startWordPosition="779" endWordPosition="782">address the question of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations. While these models are highly interesting both from their view of the long-term process of language acquisition and their high success rate, they are hard to relate to the infant studies discussed above. Hence, it is beyond the scope of this paper to discuss them at length.2 Rather, this paper focuses on models that do not accumulate a stored vocabulary, but rely on either on statistics derived from utterance boundaries (typically generalized over feature matrices, as in (Aslin et al., 1996; Christiansen et al., 1998)) or from the degree of predictability of the next syllable (e.g., Saffran et al., 1996) or segment (Christiansen et al., 1998). The intuition here, first articulated by Harris (1954) is that word boundaries will be marked by a spike in unpredictability of the following phoneme. Christiansen et al. (1998) also test the contribution of stress and phonemic information in addition to that of utterance boundaries, and show that while stress contributes in certain circumstances, it is not as crucial as featural information near utterance boundaries. The general line of r</context>
<context position="7119" citStr="Aslin et al. (1996" startWordPosition="1106" endWordPosition="1109">siderable amount of context before such an utterance was given, namely 18-bit feature vectors of one, two, or three phonemes immediately preceding the final utterance boundary. For a model with 30 hidden units, the following results for boundary detection are reported (as estimated from their bar graph, fig.8.8, p. 132), accompanied by the claim that only with two- and three-phoneme sequences is their system capable of learning boundary locations: Hits False Precision Alarms (H/(H+FA)) 3 phones 62% 22% 74% 2 phones 53% 23% 70% 1 phone 45% 44% 51% Random 5% 15% 25% Table 1. Results reported in Aslin et al. (1996, Fig. 8.8, p. 132). They further claim that feature vectors are necessary for learning: a string of three phonemes (where each phoneme is represented as an atomistic unit) is not sufficient information, although no comparative figures are listed for this condition. This study may be seen as a replication of (Aslin et al., 1996); however, it differs in several crucial respects—not with an eye toward improving upon their results, but rather on examining further their definition of “minimal necessary cues.” First, instead of training the transitional probabilities indirectly with connectionist n</context>
<context position="10512" citStr="Aslin et al., 1996" startWordPosition="1645" endWordPosition="1648">clitic combinations. The text also contains a significant number of unrealized final vowels (apocopy), such as [in] for /ine/ &apos;is&apos;. Such variation was not regularized, but treated as part of the learning task. The training corpus contains 367 utterance tokens with a total of 1066 word tokens (319 types). Whereas the average number of words per utterance (2.9) is comparable to the Korman (1984) corpus used by Christiansen et al. (3.0), utterances and words were slightly longer in terms of phonemes (12.8 and 4.4 phonemes respectively, compared to 9.0 and 3.0). (Statistics on the corpus used in (Aslin et al., 1996) were not provided.) The test corpus consists of utterances by adults to the same child as in the training corpus. Utterances with dysfluencies, missing words, or other irregularities were discarded; the remaining utterances include 273 utterance tokens with a total of 699 words (229 types). 2.2 Model Design This model differs from incremental models such as (Brent 1999a) in that it pre-compiles statistics for the candidate word-final phonemes off-line, over the entire corpus. These probabilities are thus static. While this difference is not intended as a strong theoretical claim, it reflects </context>
<context position="12589" citStr="Aslin et al. (1996)" startWordPosition="1978" endWordPosition="1981">his is naturally a strong assumption to make; it is included primarily to provide comparisons with baselines used by Brent (1999a) and Christiansen et al. (1998), which provide pseudorandom baselines that make reference either to number of boundaries directly or information concerning average word length. Results are given both with and without this constraint. (3) The main item under examination is naturally the relative likelihood of breaking the word after a given segment S. The third information source was tested in three variants. The first one is of course the approximation suggested by Aslin et al. (1996), that P(#|S) may be approximated by using P($|S), the probability of an utterance-break given the segment. This approximation yields the ranking e&gt;s&gt;o&gt;u&gt;i&gt;a&gt;m&gt;n, with /e/ most likely to end an utterance. This information source was compared to two related alternatives, which were used as upper and lower bounds to measure the effectiveness of the utterance-boundary approximation of word boundaries. As an upper bound (3U), the true value for P(#|S) is used, corresponding to training on labeled data, or a store of already-learned vocabulary.4 The lower bound (3L) consists of the seven final segm</context>
<context position="16475" citStr="Aslin et al., 1996" startWordPosition="2589" endWordPosition="2592">with and without the number of words known are shown in Tables 2 and 3, following. In both cases, the precision scores patterned as expected. The upper bound condition (representing a supervised case, where statistics on the word boundaries are available for the training data) proved the most accurate on the test data. This suggests (as has been confirmed for English in such studies as Brent 1999a) that the learning of patterns over already-acquired vocabulary has perhaps the largest effect in the acquisition of new vocabulary. The utterance-based approximation, corresponding most closely to (Aslin et al., 1996), seems to be slightly better overall than the lower bound. Without the number of words known, (3) has an F-score of 20.2 for words and 70.2 for boundaries, whereas (3L) has Fscores of only 17.0 (word) and 68.0 (boundaries), though this difference may not be significant. This difference was less than expected, given preliminary examination of the training data; it may be that once the set of allowable word-final phonemes is observed, the relative probabilities of those phonemes is not as usefully learned from utterance boundaries. However, the lower bound (corresponding to purely symbolic know</context>
<context position="18113" citStr="Aslin et al. (1996)" startWordPosition="2834" endWordPosition="2837">/972 bound (31.6%) (31.6%) (72.9%) (72.9%) Random 119/699 119/699 639/972 639/972 Walk (17.0%) (17.0%) (65.7%) (65.7%) Table 2: Test Results with Constraint (2) Words Word Boundaries Precision Recall Precision Recall Upper 219/720 219/699 737/993 737/972 bound (30.4%) (31.3%) (74.2%) (75.8%) Utt- 159/860 159/699 739/1133 739/972 prob. (18.5%) (22.7%) (65.2%) (76.0%) Lower 195/1599 195/699 967/1872 967/972 bound (12.2%) (27.9%) (51.7%) (99.5%) Random 39/1569 39/699 767/1842 767/972 Walk (2.5%) (5.6%) (41.6%) (78.9%) Table 3: Test Results without Constraint (2) 4 Discussion 4.1 Comparisons with Aslin et al. (1996) Obviously, the cues of preceding and following segments are in and of itself insufficient to predict a word boundary with any reasonable degree of accuracy, just as Christiansen et al. (1998) found that no one cue was sufficient for English. However, a few comparisons with Aslin’s et al. (1996) data in Table 1 may be useful, although they should be interpreted cautiously given the differences in the training and testing corpora between their study and this one. Their results for the singlephoneme condition have nearly equal hits and false alarms—a precision of about 51%. They apparently do no</context>
</contexts>
<marker>Aslin, Woodward, LaMendola, Bever, 1996</marker>
<rawString>Aslin, Richard N., Woodward, Julide Z., LaMendola, Nicholas P., &amp; Bever, Thomas G. 1996. Models of word segmentation in fluent maternal speech to infants. In James L. Morgan &amp; Katherine Demuth , editors, Signal to syntax, pages 117-134. Mahwah, NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Batchelder</author>
</authors>
<title>Elanor Olds 2002. Bootstrapping the lexicon: A computational model of infant speech segmentation.</title>
<journal>Cognition</journal>
<pages>83--167</pages>
<marker>Batchelder, </marker>
<rawString>Batchelder, Elanor Olds 2002. Bootstrapping the lexicon: A computational model of infant speech segmentation. Cognition 83:167-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>An efficient, probabilistically sound algorithm for segmentation and word discovery.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--71</pages>
<contexts>
<context position="6469" citStr="Brent, 1999" startWordPosition="1001" endWordPosition="1002">s at utterance boundaries. This first step corresponds most closely with (Aslin et al., 1996), where utterance boundaries were treated as a cue on their own. Aslin and his colleagues propose that “even the most minimal assumption about what an infant can recognize as a word boundary--namely, the pause after an utterance--is sufficient, in principle, for the learning the word boundaries within an utterance” (p. 133). In 1 Full mention of all the studies done is not possible here; for a fuller review see e.g., (Johnson &amp; Jusczyk, 2001). 2 For useful reviews of various computational models, see (Brent, 1999a,b). that study, however, a considerable amount of context before such an utterance was given, namely 18-bit feature vectors of one, two, or three phonemes immediately preceding the final utterance boundary. For a model with 30 hidden units, the following results for boundary detection are reported (as estimated from their bar graph, fig.8.8, p. 132), accompanied by the claim that only with two- and three-phoneme sequences is their system capable of learning boundary locations: Hits False Precision Alarms (H/(H+FA)) 3 phones 62% 22% 74% 2 phones 53% 23% 70% 1 phone 45% 44% 51% Random 5% 15% 2</context>
<context position="9600" citStr="Brent (1999" startWordPosition="1497" endWordPosition="1498">the transcriptions themselves give an indication at the phonemic level of the sort of input Greek children are likely to have in learning their language. In order to preserve adequate unseen data for future simulations and experiments, only a small subset of the total Greek CHILDES corpus was used. As in other studies, only adult input was used for training and testing. In addition, non-segmental information such as punctuation, dysfluencies, parenthetical references to real-world objects, etc. were removed. Word boundaries are represented by the symbol #, utterance boundaries by $, following Brent (1999a). Each line of the file was assumed to be an independent utterance. Spaces were assumed to represent word boundaries without comment or correction; however, it is worth noting that the transcribers sometimes departed from standard orthographic practice with respect to certain types of word-clitic combinations. The text also contains a significant number of unrealized final vowels (apocopy), such as [in] for /ine/ &apos;is&apos;. Such variation was not regularized, but treated as part of the learning task. The training corpus contains 367 utterance tokens with a total of 1066 word tokens (319 types). W</context>
<context position="10884" citStr="Brent 1999" startWordPosition="1705" endWordPosition="1706">e Korman (1984) corpus used by Christiansen et al. (3.0), utterances and words were slightly longer in terms of phonemes (12.8 and 4.4 phonemes respectively, compared to 9.0 and 3.0). (Statistics on the corpus used in (Aslin et al., 1996) were not provided.) The test corpus consists of utterances by adults to the same child as in the training corpus. Utterances with dysfluencies, missing words, or other irregularities were discarded; the remaining utterances include 273 utterance tokens with a total of 699 words (229 types). 2.2 Model Design This model differs from incremental models such as (Brent 1999a) in that it pre-compiles statistics for the candidate word-final phonemes off-line, over the entire corpus. These probabilities are thus static. While this difference is not intended as a strong theoretical claim, it reflects the fact that even before infants seem to be learning the word segmentation process, they have already been exposed to a large amount of linguistic material. The information gleaned from the corpus is represented in three separate (but composible) finitestate machines: (1) Like most models in the literature, this model assumes (for sake of convenience and simplicity) th</context>
<context position="12098" citStr="Brent (1999" startWordPosition="1899" endWordPosition="1900">the child hears the correct sequence of the actual segments produced within an utterance. Hence, the model does not take into account the possibility of mishearing a segment, as that would add undue complication at this stage. This assumption translates into the finite-state domain as a simple acceptor (or equivalently, an identity transducer) over the segment sequence for a given utterance.3 (2) An optional source of knowledge used is the number of words in a given utterance. This is naturally a strong assumption to make; it is included primarily to provide comparisons with baselines used by Brent (1999a) and Christiansen et al. (1998), which provide pseudorandom baselines that make reference either to number of boundaries directly or information concerning average word length. Results are given both with and without this constraint. (3) The main item under examination is naturally the relative likelihood of breaking the word after a given segment S. The third information source was tested in three variants. The first one is of course the approximation suggested by Aslin et al. (1996), that P(#|S) may be approximated by using P($|S), the probability of an utterance-break given the segment. T</context>
<context position="16255" citStr="Brent 1999" startWordPosition="2560" endWordPosition="2561">rrectly segmented only if both its left and right boundaries are correctly placed). In the case where several best-paths of equal cost exist, the average scores for precision and recall are counted. The results with and without the number of words known are shown in Tables 2 and 3, following. In both cases, the precision scores patterned as expected. The upper bound condition (representing a supervised case, where statistics on the word boundaries are available for the training data) proved the most accurate on the test data. This suggests (as has been confirmed for English in such studies as Brent 1999a) that the learning of patterns over already-acquired vocabulary has perhaps the largest effect in the acquisition of new vocabulary. The utterance-based approximation, corresponding most closely to (Aslin et al., 1996), seems to be slightly better overall than the lower bound. Without the number of words known, (3) has an F-score of 20.2 for words and 70.2 for boundaries, whereas (3L) has Fscores of only 17.0 (word) and 68.0 (boundaries), though this difference may not be significant. This difference was less than expected, given preliminary examination of the training data; it may be that o</context>
<context position="20234" citStr="Brent, 1999" startWordPosition="3170" endWordPosition="3171">condition, it seems that even these very basic cues come closer to Aslin’s et al. (1996) results than might be supposed. Importantly, the same general trend was shown-- that utterance-final information translates into wordboundary information not only for English, but for other languages such as Modern Greek as well. A number of further directions are possible under this framework, including: (1) Using transitional probability (P(Sk+1 |Sk)) and mutual information measures over two adjacent segments as cues to the likelihood of word boundaries between those two segments, as suggested in e.g., (Brent, 1999a). (2) Developing more plausible models for approximating word-length distributions from utterance-length information, distances between stressed vowels, pause information, and other salient cues available to children. (3) Incorporating stress cues (as potentially signaling both beginnings and approaching ends of content words) both alone and in combination with segmental cues. Preliminary work on each of these avenues is currently underway. While some of these heuristics may require the use of other techniques in addition to finite-state techniques, the general finite-state framework is expe</context>
</contexts>
<marker>Brent, 1999</marker>
<rawString>Brent, Michael R. 1999a. An efficient, probabilistically sound algorithm for segmentation and word discovery. Machine Learning, 34:71-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>Speech segmentation and word discovery: a computational perspective. Trends in Cognitive Sciences,</title>
<date>1999</date>
<pages>3--8</pages>
<contexts>
<context position="6469" citStr="Brent, 1999" startWordPosition="1001" endWordPosition="1002">s at utterance boundaries. This first step corresponds most closely with (Aslin et al., 1996), where utterance boundaries were treated as a cue on their own. Aslin and his colleagues propose that “even the most minimal assumption about what an infant can recognize as a word boundary--namely, the pause after an utterance--is sufficient, in principle, for the learning the word boundaries within an utterance” (p. 133). In 1 Full mention of all the studies done is not possible here; for a fuller review see e.g., (Johnson &amp; Jusczyk, 2001). 2 For useful reviews of various computational models, see (Brent, 1999a,b). that study, however, a considerable amount of context before such an utterance was given, namely 18-bit feature vectors of one, two, or three phonemes immediately preceding the final utterance boundary. For a model with 30 hidden units, the following results for boundary detection are reported (as estimated from their bar graph, fig.8.8, p. 132), accompanied by the claim that only with two- and three-phoneme sequences is their system capable of learning boundary locations: Hits False Precision Alarms (H/(H+FA)) 3 phones 62% 22% 74% 2 phones 53% 23% 70% 1 phone 45% 44% 51% Random 5% 15% 2</context>
<context position="9600" citStr="Brent (1999" startWordPosition="1497" endWordPosition="1498">the transcriptions themselves give an indication at the phonemic level of the sort of input Greek children are likely to have in learning their language. In order to preserve adequate unseen data for future simulations and experiments, only a small subset of the total Greek CHILDES corpus was used. As in other studies, only adult input was used for training and testing. In addition, non-segmental information such as punctuation, dysfluencies, parenthetical references to real-world objects, etc. were removed. Word boundaries are represented by the symbol #, utterance boundaries by $, following Brent (1999a). Each line of the file was assumed to be an independent utterance. Spaces were assumed to represent word boundaries without comment or correction; however, it is worth noting that the transcribers sometimes departed from standard orthographic practice with respect to certain types of word-clitic combinations. The text also contains a significant number of unrealized final vowels (apocopy), such as [in] for /ine/ &apos;is&apos;. Such variation was not regularized, but treated as part of the learning task. The training corpus contains 367 utterance tokens with a total of 1066 word tokens (319 types). W</context>
<context position="10884" citStr="Brent 1999" startWordPosition="1705" endWordPosition="1706">e Korman (1984) corpus used by Christiansen et al. (3.0), utterances and words were slightly longer in terms of phonemes (12.8 and 4.4 phonemes respectively, compared to 9.0 and 3.0). (Statistics on the corpus used in (Aslin et al., 1996) were not provided.) The test corpus consists of utterances by adults to the same child as in the training corpus. Utterances with dysfluencies, missing words, or other irregularities were discarded; the remaining utterances include 273 utterance tokens with a total of 699 words (229 types). 2.2 Model Design This model differs from incremental models such as (Brent 1999a) in that it pre-compiles statistics for the candidate word-final phonemes off-line, over the entire corpus. These probabilities are thus static. While this difference is not intended as a strong theoretical claim, it reflects the fact that even before infants seem to be learning the word segmentation process, they have already been exposed to a large amount of linguistic material. The information gleaned from the corpus is represented in three separate (but composible) finitestate machines: (1) Like most models in the literature, this model assumes (for sake of convenience and simplicity) th</context>
<context position="12098" citStr="Brent (1999" startWordPosition="1899" endWordPosition="1900">the child hears the correct sequence of the actual segments produced within an utterance. Hence, the model does not take into account the possibility of mishearing a segment, as that would add undue complication at this stage. This assumption translates into the finite-state domain as a simple acceptor (or equivalently, an identity transducer) over the segment sequence for a given utterance.3 (2) An optional source of knowledge used is the number of words in a given utterance. This is naturally a strong assumption to make; it is included primarily to provide comparisons with baselines used by Brent (1999a) and Christiansen et al. (1998), which provide pseudorandom baselines that make reference either to number of boundaries directly or information concerning average word length. Results are given both with and without this constraint. (3) The main item under examination is naturally the relative likelihood of breaking the word after a given segment S. The third information source was tested in three variants. The first one is of course the approximation suggested by Aslin et al. (1996), that P(#|S) may be approximated by using P($|S), the probability of an utterance-break given the segment. T</context>
<context position="16255" citStr="Brent 1999" startWordPosition="2560" endWordPosition="2561">rrectly segmented only if both its left and right boundaries are correctly placed). In the case where several best-paths of equal cost exist, the average scores for precision and recall are counted. The results with and without the number of words known are shown in Tables 2 and 3, following. In both cases, the precision scores patterned as expected. The upper bound condition (representing a supervised case, where statistics on the word boundaries are available for the training data) proved the most accurate on the test data. This suggests (as has been confirmed for English in such studies as Brent 1999a) that the learning of patterns over already-acquired vocabulary has perhaps the largest effect in the acquisition of new vocabulary. The utterance-based approximation, corresponding most closely to (Aslin et al., 1996), seems to be slightly better overall than the lower bound. Without the number of words known, (3) has an F-score of 20.2 for words and 70.2 for boundaries, whereas (3L) has Fscores of only 17.0 (word) and 68.0 (boundaries), though this difference may not be significant. This difference was less than expected, given preliminary examination of the training data; it may be that o</context>
<context position="20234" citStr="Brent, 1999" startWordPosition="3170" endWordPosition="3171">condition, it seems that even these very basic cues come closer to Aslin’s et al. (1996) results than might be supposed. Importantly, the same general trend was shown-- that utterance-final information translates into wordboundary information not only for English, but for other languages such as Modern Greek as well. A number of further directions are possible under this framework, including: (1) Using transitional probability (P(Sk+1 |Sk)) and mutual information measures over two adjacent segments as cues to the likelihood of word boundaries between those two segments, as suggested in e.g., (Brent, 1999a). (2) Developing more plausible models for approximating word-length distributions from utterance-length information, distances between stressed vowels, pause information, and other salient cues available to children. (3) Incorporating stress cues (as potentially signaling both beginnings and approaching ends of content words) both alone and in combination with segmental cues. Preliminary work on each of these avenues is currently underway. While some of these heuristics may require the use of other techniques in addition to finite-state techniques, the general finite-state framework is expe</context>
</contexts>
<marker>Brent, 1999</marker>
<rawString>Brent, Michael R. 1999b. Speech segmentation and word discovery: a computational perspective. Trends in Cognitive Sciences, 3(8):294-301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morton H Christiansen</author>
<author>Joseph Allen</author>
<author>Mark S Seidenberg</author>
</authors>
<title>Learning to segment speech using multiple cues: A connectionist model.</title>
<date>1998</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>13--2</pages>
<contexts>
<context position="5129" citStr="Christiansen et al., 1998" startWordPosition="783" endWordPosition="786"> of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations. While these models are highly interesting both from their view of the long-term process of language acquisition and their high success rate, they are hard to relate to the infant studies discussed above. Hence, it is beyond the scope of this paper to discuss them at length.2 Rather, this paper focuses on models that do not accumulate a stored vocabulary, but rely on either on statistics derived from utterance boundaries (typically generalized over feature matrices, as in (Aslin et al., 1996; Christiansen et al., 1998)) or from the degree of predictability of the next syllable (e.g., Saffran et al., 1996) or segment (Christiansen et al., 1998). The intuition here, first articulated by Harris (1954) is that word boundaries will be marked by a spike in unpredictability of the following phoneme. Christiansen et al. (1998) also test the contribution of stress and phonemic information in addition to that of utterance boundaries, and show that while stress contributes in certain circumstances, it is not as crucial as featural information near utterance boundaries. The general line of research herein proposed focu</context>
<context position="12131" citStr="Christiansen et al. (1998)" startWordPosition="1902" endWordPosition="1905">e correct sequence of the actual segments produced within an utterance. Hence, the model does not take into account the possibility of mishearing a segment, as that would add undue complication at this stage. This assumption translates into the finite-state domain as a simple acceptor (or equivalently, an identity transducer) over the segment sequence for a given utterance.3 (2) An optional source of knowledge used is the number of words in a given utterance. This is naturally a strong assumption to make; it is included primarily to provide comparisons with baselines used by Brent (1999a) and Christiansen et al. (1998), which provide pseudorandom baselines that make reference either to number of boundaries directly or information concerning average word length. Results are given both with and without this constraint. (3) The main item under examination is naturally the relative likelihood of breaking the word after a given segment S. The third information source was tested in three variants. The first one is of course the approximation suggested by Aslin et al. (1996), that P(#|S) may be approximated by using P($|S), the probability of an utterance-break given the segment. This approximation yields the rank</context>
<context position="18305" citStr="Christiansen et al. (1998)" startWordPosition="2866" endWordPosition="2869">ecision Recall Precision Recall Upper 219/720 219/699 737/993 737/972 bound (30.4%) (31.3%) (74.2%) (75.8%) Utt- 159/860 159/699 739/1133 739/972 prob. (18.5%) (22.7%) (65.2%) (76.0%) Lower 195/1599 195/699 967/1872 967/972 bound (12.2%) (27.9%) (51.7%) (99.5%) Random 39/1569 39/699 767/1842 767/972 Walk (2.5%) (5.6%) (41.6%) (78.9%) Table 3: Test Results without Constraint (2) 4 Discussion 4.1 Comparisons with Aslin et al. (1996) Obviously, the cues of preceding and following segments are in and of itself insufficient to predict a word boundary with any reasonable degree of accuracy, just as Christiansen et al. (1998) found that no one cue was sufficient for English. However, a few comparisons with Aslin’s et al. (1996) data in Table 1 may be useful, although they should be interpreted cautiously given the differences in the training and testing corpora between their study and this one. Their results for the singlephoneme condition have nearly equal hits and false alarms—a precision of about 51%. They apparently do not consider this sufficient evidence of learning, although it is significantly better than their random baseline. Similarly, the worst non-random condition reported here (lower bound without co</context>
</contexts>
<marker>Christiansen, Allen, Seidenberg, 1998</marker>
<rawString>Christiansen, Morton H., Allen, Joseph, &amp; Seidenberg, Mark S. 1998. Learning to segment speech using multiple cues: A connectionist model. Language and Cognitive Processes, 13(2/3):221-268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt H Davis</author>
</authors>
<title>Lexical segmentation in spoken word recognition.</title>
<date>2000</date>
<tech>Unpublished PhD thesis,</tech>
<institution>Birkbeck College, University of London.</institution>
<note>Available: http://www.mrc-</note>
<contexts>
<context position="4433" citStr="Davis, 2000" startWordPosition="677" endWordPosition="678">be available by 9 months of age (e.g., Jusczyk, Luce, et al., 1994; Mattys and Jusczyk, 2001), and (4) statistical cues from recurrent patterns e.g., of syllables, evident in English-learning 8-month-olds on an artificial micro-language of 4 words (Saffran et al. 1996).1 1.2 Computational Models While the infant studies discussed above focus primarily on the properties of particular cues, computational studies of word-segmentation must also choose between various implementations, which further complicates comparisons. In addition, several models (e.g., Batchelder, 2002; Brent’s MLDP-1, 1999a; Davis, 2000; de Marcken, 1996; Olivier, 1968) simultaneously address the question of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations. While these models are highly interesting both from their view of the long-term process of language acquisition and their high success rate, they are hard to relate to the infant studies discussed above. Hence, it is beyond the scope of this paper to discuss them at length.2 Rather, this paper focuses on models that do not accumulate a stored vocabulary, but rely on either on statistics derived from utterance boundaries (ty</context>
</contexts>
<marker>Davis, 2000</marker>
<rawString>Davis, Matt H. (2000) Lexical segmentation in spoken word recognition. Unpublished PhD thesis, Birkbeck College, University of London. Available: http://www.mrc-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl G de Marcken</author>
</authors>
<title>Unsupervised language acquisition.</title>
<date>1996</date>
<location>MIT, Cambridge, MA. Available:</location>
<note>PhD dissertation,</note>
<marker>de Marcken, 1996</marker>
<rawString>de Marcken, Carl G. 1996b. Unsupervised language acquisition. PhD dissertation, MIT, Cambridge, MA. Available: http://xxx.lanl.gov/abs/cmp- lg/9611002</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig S Harris</author>
</authors>
<date>1954</date>
<booktitle>Distributional structure. Word,</booktitle>
<pages>10--146</pages>
<contexts>
<context position="5312" citStr="Harris (1954)" startWordPosition="815" endWordPosition="816">nguage acquisition and their high success rate, they are hard to relate to the infant studies discussed above. Hence, it is beyond the scope of this paper to discuss them at length.2 Rather, this paper focuses on models that do not accumulate a stored vocabulary, but rely on either on statistics derived from utterance boundaries (typically generalized over feature matrices, as in (Aslin et al., 1996; Christiansen et al., 1998)) or from the degree of predictability of the next syllable (e.g., Saffran et al., 1996) or segment (Christiansen et al., 1998). The intuition here, first articulated by Harris (1954) is that word boundaries will be marked by a spike in unpredictability of the following phoneme. Christiansen et al. (1998) also test the contribution of stress and phonemic information in addition to that of utterance boundaries, and show that while stress contributes in certain circumstances, it is not as crucial as featural information near utterance boundaries. The general line of research herein proposed focuses on the same cues as (Christiansen et al., 1998) beginning (in the work reported here) with segmental probability distributions at utterance boundaries. This first step corresponds</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Harris, Zelig S. 1954. Distributional structure. Word, 10:146-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth K Johnson</author>
<author>Peter W Jusczyk</author>
</authors>
<title>Word segmentation by 8- month-olds: when speech cues count more than statistics.</title>
<date>2001</date>
<journal>Journal of Memory and Language,</journal>
<volume>44</volume>
<issue>4</issue>
<pages>548--567</pages>
<contexts>
<context position="6397" citStr="Johnson &amp; Jusczyk, 2001" startWordPosition="988" endWordPosition="991">, 1998) beginning (in the work reported here) with segmental probability distributions at utterance boundaries. This first step corresponds most closely with (Aslin et al., 1996), where utterance boundaries were treated as a cue on their own. Aslin and his colleagues propose that “even the most minimal assumption about what an infant can recognize as a word boundary--namely, the pause after an utterance--is sufficient, in principle, for the learning the word boundaries within an utterance” (p. 133). In 1 Full mention of all the studies done is not possible here; for a fuller review see e.g., (Johnson &amp; Jusczyk, 2001). 2 For useful reviews of various computational models, see (Brent, 1999a,b). that study, however, a considerable amount of context before such an utterance was given, namely 18-bit feature vectors of one, two, or three phonemes immediately preceding the final utterance boundary. For a model with 30 hidden units, the following results for boundary detection are reported (as estimated from their bar graph, fig.8.8, p. 132), accompanied by the claim that only with two- and three-phoneme sequences is their system capable of learning boundary locations: Hits False Precision Alarms (H/(H+FA)) 3 pho</context>
</contexts>
<marker>Johnson, Jusczyk, 2001</marker>
<rawString>Johnson, Elizabeth K., &amp; Jusczyk, Peter W. 2001. Word segmentation by 8- month-olds: when speech cues count more than statistics. Journal of Memory and Language, 44 (4), 548 567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Joseph</author>
</authors>
<title>Word’ in Modern Greek.</title>
<date>2001</date>
<booktitle>Proceedings of the International Workshop on the Status of ‘Word’. Cambridge:</booktitle>
<editor>In R.M.W. Dixon &amp; A. Aikhenvald (eds.)</editor>
<publisher>Cambridge University Press</publisher>
<marker>Joseph, 2001</marker>
<rawString>Joseph, Brian. 2001. ‘Word’ in Modern Greek. In R.M.W. Dixon &amp; A. Aikhenvald (eds.) Proceedings of the International Workshop on the Status of ‘Word’. Cambridge: Cambridge University Press (2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>R N Aslin</author>
</authors>
<title>Infant&apos;s detection of sound patterns of words in fluent speech.</title>
<date>1995</date>
<pages>29--1</pages>
<publisher>Cognitive Psychology,</publisher>
<marker>Jusczyk, Aslin, 1995</marker>
<rawString>Jusczyk, Peter W., &amp; Aslin, R. N. 1995. Infant&apos;s detection of sound patterns of words in fluent speech. Cognitive Psychology, 29:1-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>E A Hohne</author>
<author>A Bauman</author>
</authors>
<title>Infants&apos; sensitivity to allophonic cues for word segmentation.</title>
<date>1999</date>
<journal>Perception &amp; Psychophysics,</journal>
<pages>61--1465</pages>
<marker>Jusczyk, Hohne, Bauman, 1999</marker>
<rawString>Jusczyk, Peter W., Hohne, E. A., &amp; Bauman, A. 1999. Infants&apos; sensitivity to allophonic cues for word segmentation. Perception &amp; Psychophysics, 61:1465-1476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>Derek Houston</author>
<author>Mary Newsome</author>
</authors>
<title>The beginnings of word segmentation in English-learning infants.</title>
<date>1999</date>
<pages>39--159</pages>
<publisher>Cognitive Psychology,</publisher>
<marker>Jusczyk, Houston, Newsome, 1999</marker>
<rawString>Jusczyk, Peter W., Houston, Derek, &amp; Newsome, Mary. 1999. The beginnings of word segmentation in English-learning infants. Cognitive Psychology, 39:159-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>Paul A Luce</author>
<author>Charles-Luce</author>
</authors>
<title>Infants&apos; sensitivity to phonotactic patterns in the native language.</title>
<date>1994</date>
<journal>Journal of Memory and Language,</journal>
<pages>33--630</pages>
<marker>Jusczyk, Luce, Charles-Luce, 1994</marker>
<rawString>Jusczyk, Peter W., Luce, Paul A., &amp; Charles-Luce, Jan 1994. Infants&apos; sensitivity to phonotactic patterns in the native language. Journal of Memory and Language, 33:630-645.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myron Korman</author>
</authors>
<title>Adaptive aspects of maternal vocalizations in differing contexts at ten weeks.</title>
<date>1984</date>
<journal>First Language,</journal>
<pages>5--44</pages>
<contexts>
<context position="10289" citStr="Korman (1984)" startWordPosition="1608" endWordPosition="1609"> were assumed to represent word boundaries without comment or correction; however, it is worth noting that the transcribers sometimes departed from standard orthographic practice with respect to certain types of word-clitic combinations. The text also contains a significant number of unrealized final vowels (apocopy), such as [in] for /ine/ &apos;is&apos;. Such variation was not regularized, but treated as part of the learning task. The training corpus contains 367 utterance tokens with a total of 1066 word tokens (319 types). Whereas the average number of words per utterance (2.9) is comparable to the Korman (1984) corpus used by Christiansen et al. (3.0), utterances and words were slightly longer in terms of phonemes (12.8 and 4.4 phonemes respectively, compared to 9.0 and 3.0). (Statistics on the corpus used in (Aslin et al., 1996) were not provided.) The test corpus consists of utterances by adults to the same child as in the training corpus. Utterances with dysfluencies, missing words, or other irregularities were discarded; the remaining utterances include 273 utterance tokens with a total of 699 words (229 types). 2.2 Model Design This model differs from incremental models such as (Brent 1999a) in</context>
</contexts>
<marker>Korman, 1984</marker>
<rawString>Korman, Myron. 1984. Adaptive aspects of maternal vocalizations in differing contexts at ten weeks. First Language, 5:44-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven L Mattys</author>
<author>Peter W Jusczyk</author>
<author>Paul A Luce</author>
<author>James L Morgan</author>
</authors>
<title>Word segmentation in infants: How phonotactics and prosody combine.</title>
<date>1999</date>
<journal>Cognitive Psychology,</journal>
<pages>38--465</pages>
<marker>Mattys, Jusczyk, Luce, Morgan, 1999</marker>
<rawString>Mattys, Sven L., Jusczyk, Peter W., Luce, Paul A., &amp; Morgan, James L. 1999. Word segmentation in infants: How phonotactics and prosody combine. Cognitive Psychology, 38:465-494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven L Mattys</author>
<author>Peter W Jusczyk</author>
</authors>
<title>Phonotactic cues for segmentation of fluent speech by infants.</title>
<date>2001</date>
<journal>Cognition</journal>
<pages>78--91</pages>
<contexts>
<context position="3915" citStr="Mattys and Jusczyk, 2001" startWordPosition="604" endWordPosition="607">nge of languages. 1.1 Infant Studies At least four types of information in the speech signal have been identified as likely cues for infants: (1) supersegmental cues (e.g., stress) which begins to play a role in (English-learning) 7.5 month-olds (Jusczyk, Houston, et al., 1999); (2) sub-segmental cues such as coarticulation and allophonic alternations, which infants begin using between 7.5 and 10.5 months of age (Jusczyk, Hohne, et al., 1999); (3) segmental cues, such as wordlikeness and phonotactic constraints, which seem to be available by 9 months of age (e.g., Jusczyk, Luce, et al., 1994; Mattys and Jusczyk, 2001), and (4) statistical cues from recurrent patterns e.g., of syllables, evident in English-learning 8-month-olds on an artificial micro-language of 4 words (Saffran et al. 1996).1 1.2 Computational Models While the infant studies discussed above focus primarily on the properties of particular cues, computational studies of word-segmentation must also choose between various implementations, which further complicates comparisons. In addition, several models (e.g., Batchelder, 2002; Brent’s MLDP-1, 1999a; Davis, 2000; de Marcken, 1996; Olivier, 1968) simultaneously address the question of vocabula</context>
</contexts>
<marker>Mattys, Jusczyk, 2001</marker>
<rawString>Mattys, Sven L. and Jusczyk, Peter W. 2001. Phonotactic cues for segmentation of fluent speech by infants. Cognition 78:91-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Olivier</author>
</authors>
<title>Stochastic grammars and language acquisition mechanisms.</title>
<date>1968</date>
<institution>Harvard University,</institution>
<location>Cambridge, MA.</location>
<note>PhD dissertation,</note>
<contexts>
<context position="4467" citStr="Olivier, 1968" startWordPosition="682" endWordPosition="683"> (e.g., Jusczyk, Luce, et al., 1994; Mattys and Jusczyk, 2001), and (4) statistical cues from recurrent patterns e.g., of syllables, evident in English-learning 8-month-olds on an artificial micro-language of 4 words (Saffran et al. 1996).1 1.2 Computational Models While the infant studies discussed above focus primarily on the properties of particular cues, computational studies of word-segmentation must also choose between various implementations, which further complicates comparisons. In addition, several models (e.g., Batchelder, 2002; Brent’s MLDP-1, 1999a; Davis, 2000; de Marcken, 1996; Olivier, 1968) simultaneously address the question of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations. While these models are highly interesting both from their view of the long-term process of language acquisition and their high success rate, they are hard to relate to the infant studies discussed above. Hence, it is beyond the scope of this paper to discuss them at length.2 Rather, this paper focuses on models that do not accumulate a stored vocabulary, but rely on either on statistics derived from utterance boundaries (typically generalized over feature m</context>
</contexts>
<marker>Olivier, 1968</marker>
<rawString>Olivier, D. C. 1968. Stochastic grammars and language acquisition mechanisms. PhD dissertation, Harvard University, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Saffran</author>
<author>Richard N Aslin</author>
<author>Elissa L Newport</author>
</authors>
<title>Statistical cues in language acquisition: word segmentation by infants.</title>
<date>1996</date>
<booktitle>Proceedings of the 18th Annual Conference of the Cognitive Science Society.</booktitle>
<pages>376--380</pages>
<editor>In G.W. Cottrell, editor,</editor>
<publisher>Lawrence Erlbaum Associates.</publisher>
<location>Hillsdale, NJ:</location>
<contexts>
<context position="4091" citStr="Saffran et al. 1996" startWordPosition="631" endWordPosition="634">which begins to play a role in (English-learning) 7.5 month-olds (Jusczyk, Houston, et al., 1999); (2) sub-segmental cues such as coarticulation and allophonic alternations, which infants begin using between 7.5 and 10.5 months of age (Jusczyk, Hohne, et al., 1999); (3) segmental cues, such as wordlikeness and phonotactic constraints, which seem to be available by 9 months of age (e.g., Jusczyk, Luce, et al., 1994; Mattys and Jusczyk, 2001), and (4) statistical cues from recurrent patterns e.g., of syllables, evident in English-learning 8-month-olds on an artificial micro-language of 4 words (Saffran et al. 1996).1 1.2 Computational Models While the infant studies discussed above focus primarily on the properties of particular cues, computational studies of word-segmentation must also choose between various implementations, which further complicates comparisons. In addition, several models (e.g., Batchelder, 2002; Brent’s MLDP-1, 1999a; Davis, 2000; de Marcken, 1996; Olivier, 1968) simultaneously address the question of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations. While these models are highly interesting both from their view of the long-term proce</context>
</contexts>
<marker>Saffran, Aslin, Newport, 1996</marker>
<rawString>Saffran, Jenny R., Aslin, Richard N., &amp; Newport, Elissa L. 1996. Statistical cues in language acquisition: word segmentation by infants. In G.W. Cottrell, editor, Proceedings of the 18th Annual Conference of the Cognitive Science Society. pages 376-380. Hillsdale, NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Stephany</author>
</authors>
<title>The acquisition of Greek. In</title>
<date>1995</date>
<volume>4</volume>
<editor>D. I. Slobin, editor,</editor>
<contexts>
<context position="8763" citStr="Stephany, 1995" startWordPosition="1366" endWordPosition="1367">idence of better-than-chance results would suggest that, for Modern Greek at least, even more minimal cues are possible than those Aslin et al. (1996) propose. The results of this study may be taken as a rough approximation of how predictable word boundaries are from (unigram) segmental information alone in the subset of Modern Greek experienced by young children. These findings may provide an additional baseline for measuring and comparing the relative contributions of other cues such as stress as a word segmentation cue. 2 Constructing a Finite-State Model 2.1 Data The Greek CHILDES corpus (Stephany, 1995) is a database of conversations between children and caretakers, broadly transcribed, currently with no notations for lexical stress. Audio tapes exist, but are currently unavailable for general use (Stephany, p.c.). However, the transcriptions themselves give an indication at the phonemic level of the sort of input Greek children are likely to have in learning their language. In order to preserve adequate unseen data for future simulations and experiments, only a small subset of the total Greek CHILDES corpus was used. As in other studies, only adult input was used for training and testing. I</context>
</contexts>
<marker>Stephany, 1995</marker>
<rawString>Stephany, U. 1995. The acquisition of Greek. In D. I. Slobin, editor, The crosslinguistic study of language acquisition. Vol. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramasubramanian Sundaram</author>
</authors>
<title>Effects of Transcription Errors on Supervised Learning in Speech Recognition. Unpublished Masters Thesis.</title>
<date>2003</date>
<institution>Mississippi State University,</institution>
<location>Mississippi State, MS.</location>
<note>http://www.isip.msstate.edu/publications/books/msst ate_theses/2003/transcription_errors/.</note>
<contexts>
<context position="13983" citStr="Sundaram, 2003" startWordPosition="2197" endWordPosition="2198">eek without regard to their actual likelihood. Finally, these three variants are compared with a random walk for which no information is used, but boundaries are inserted completely by chance. Each of these three types of knowledge was modeled by means of a finite state machine, using the AT&amp;T finite-state tools.5 3 While modeling the mishearing of segments is beyond the scope of this study, a weighted transducer could in principle represent a segmental confusion matrix in a modular way and augment the current identity transducer. For further discussion of issues in using “unsanitized data,” (Sundaram, 2003) may be helpful. 4 The resulting ranking, o&gt;i&gt;e&gt;s&gt;a&gt;u&gt;n&gt;j&gt;m&gt;p, is rather different than the one above, reflecting the frequency of masculine and feminine articles /o/ and /i/, which are never utterance-final. 5 FSM Library Version 3.7, freely available from http://www.research.att.com/sw/tools/fsm/ (1) Segments: Linear FSA (trivially equivalent to an identity transducer). (2) Number of words: Unweighted FSA. (3U) Upper bound: Weighted FST, with weights corresponding to -Log(P(#|S)) for a word boundary and -Log(1-P(#|S)) for an arc with no word boundary. (3) Utterance-Boundary Probabilities: Sa</context>
</contexts>
<marker>Sundaram, 2003</marker>
<rawString>Sundaram, Ramasubramanian. 2003. Effects of Transcription Errors on Supervised Learning in Speech Recognition. Unpublished Masters Thesis. Mississippi State University, Mississippi State, MS. http://www.isip.msstate.edu/publications/books/msst ate_theses/2003/transcription_errors/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>