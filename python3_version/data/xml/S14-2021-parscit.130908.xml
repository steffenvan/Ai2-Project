<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011427">
<title confidence="0.9976745">
BUAP: Evaluating Compositional Distributional Semantic Models on Full
Sentences through Semantic Relatedness and Textual Entailment
</title>
<author confidence="0.993531">
Sa´ul Le´on, Darnes Vilari˜no, David Pinto, Mireya Tovar, Beatriz Beltrin
</author>
<affiliation confidence="0.9936085">
Benem´erita Universidad Aut´onoma de Puebla
Faculty of Computer Science
</affiliation>
<address confidence="0.9843315">
14 Sur y Av. San Claudio, CU
Puebla, Puebla, M´exico
</address>
<email confidence="0.99868">
{saul.leon,darnes,dpinto,mtovar,bbeltran}@cs.buap.mx
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999642533333333">
The results obtained by the BUAP team at
Task 1 of SemEval 2014 are presented in this
paper. The run submitted is a supervised ver-
sion based on two classification models: 1)
We used logistic regression for determining
the semantic relatedness between a pair of
sentences, and 2) We employed support vec-
tor machines for identifying textual entailment
degree between the two sentences. The be-
haviour for the second subtask (textual entail-
ment) obtained much better performance than
the one evaluated at the first subtask (related-
ness), ranking our approach in the 7th position
of 18 teams that participated at the competi-
tion.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994452235294118">
The Compositional Distributional Semantic Models
(CDSM) applied to sentences aim to approximate
the meaning of those sentences with vectors summa-
rizing their patterns of co-occurrence in corpora. In
the Task 1 of SemEval 2014, the organizers aimed
to evaluate the performance of this kind of models
through the following two tasks: semantic related-
ness and textual entailment. Semantic relatedness
captures the degree of semantic similarity, in this
case, between a pair of sentences, whereas textual
entailment allows to determine the entailment rela-
tion holding between two sentences.
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
This document is a description paper, therefore,
we focus the rest of it on the features and models we
used for carrying out the experiments. A complete
description of the task and the dataset used are given
in Marelli et al. (2014a) and in Marelli et al. (2014b),
respectively.
The remaining of this paper is structured as fol-
lows. In Section 2 we describe the general model
we used for comparing two sentences and the set of
the features used for constructing the vectorial rep-
resentation for each sentence. Section 3 shows how
we integrate the features calculated in a single vector
which fed a supervised classifier aiming to construct
a classication model that solves the two aforemen-
tioned problems: semantic relatedness and textual
entailment. In the same section we show the ob-
tained results. Finally, in Section 4 we present our
findings.
</bodyText>
<sectionHeader confidence="0.588226" genericHeader="method">
2 Description of the Distributional
</sectionHeader>
<subsectionHeader confidence="0.842151">
Semantic Model Used
</subsectionHeader>
<bodyText confidence="0.9991285">
Given a sentence S = w1w2 · · · w|S|, with wi a sen-
tence word, we have calculated different correlated
terms (ti,j) or a numeric vector (Vi) for each word
wi as follows:
</bodyText>
<listItem confidence="0.999125857142857">
1. {ti,j|relation(ti,j, wi)} such as “relation” is
one the following dependency relations: “ob-
ject”, “subject” or “property”.
2. {ti,j|ti,j = ck ·· · ck+n} with n = 2, ··· , 5, and
ck E wi; these tokens are also known as n-
grams of length n.
3. {ti,j|ti,j = ck ··· ck+((n−1)∗r)} with n =
</listItem>
<page confidence="0.97542">
145
</page>
<note confidence="0.6499015">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 145–148,
Dublin, Ireland, August 23-24, 2014.
</note>
<listItem confidence="0.902699666666667">
2, · · · , 5, r = 2, · · · , 5, and ck ∈ wi; these to-
kens are also known as skip-grams of length
n.
</listItem>
<bodyText confidence="0.968536333333333">
4. Vi is obtained by applying the Latent Semantic
Analysis (LSA) algorithm implemented in the
R software environment for statistical comput-
ing and graphics. Vi is basically a vector of val-
ues that represent relation of the word wi with
it context, calculated by using a corpus con-
structed by us, by integrating information from
Europarl, Project-Gutenberg and Open Office
Thesaurus.
</bodyText>
<sectionHeader confidence="0.992972" genericHeader="method">
3 A Classification Model for Semantic
Relatedness and Textual Entailment
based on DSM
</sectionHeader>
<bodyText confidence="0.999723388888889">
Once each sentence has been represented by means
of a vectorial representation of patterns, we con-
structed a single vector, −→u , for each pair of sen-
tences with the aim of capturing the semantic relat-
edness on the basis of a training corpus.
The entries of this representation vector are calcu-
lated by obtaining the semantic similarity between
each pair of sentences, using each of the DSM
shown in the previous section. In order to calcu-
late each entry, we have found the maximum similar-
ity between each word of the first sentence with re-
spect to the second sentence and, thereafter, we have
added all these values, thus, →−u = {f1, · · · , f9}.
Given a pair of sentences S1 =
w1,1w2,1 ··· w|S1|,1 and S2 = w1,2w2,2 ··· w|S2|,2,
such as each wi,k is represented according to the
correlated terms or numeric vectors established
at Section 2, the entry fi of →−u is calculated
</bodyText>
<equation confidence="0.924586">
as: fl = �|S1|
i=1 max{sim(wi,1, wj,2)}, with
j = 1, · · · , |S2|.
</equation>
<bodyText confidence="0.951148166666667">
The specific similarity measure (sim()) and the
correlated term or numeric vector used for each fl is
described as follows:
1. f1 : wi,k is the “object” of wi (as defined
in 2), and sim() is the maximum similar-
ity obtained by using the following six Word-
Net similarity metrics offered by NLTK: Lea-
cock &amp; Chodorow (Leacock and Chodorow,
1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu
and Palmer, 1994), Resnik (Resnik, 1995), Lin
(Lin, 1998), and Jiang &amp; Conrath1 (Jiang and
Conrath, 1997).
</bodyText>
<listItem confidence="0.995774157894737">
2. f2 : wi,k is the “subject” of wi, and sim() is
the maximum similarity obtained by using the
same six WordNet similarity metrics.
3. f3 : wi,k is the “property” of wi, and sim() is
the maximum similarity obtained by using the
same six WordNet similarity metrics.
4. f4 : wi,k is an n-gram containing wi, and sim()
is the cosine similarity measure.
5. f5 : wi,k is an skip-gram containing wi, and
sim() is the cosine similarity measure.
6. f6 : wi,k is numeric vector obtained with LSA,
and sim() is the Rada Mihalcea semantic sim-
ilarity measure (Mihalcea et al., 2006).
7. f7 : wi,k is numeric vector obtained with LSA,
and sim() is the cosine similarity measure.
8. f8 : wi,k is numeric vector obtained with LSA,
and sim() is the euclidean distance.
9. f9 : wi,k is numeric vector obtained with LSA,
and sim() is the Chebyshev distance.
</listItem>
<bodyText confidence="0.999914923076923">
All these 9 features were introduced to a logistic
regression classifier in order to obtain a classifica-
tion model which allows us to determine the value of
relatedness between a new pair of sentences2. Here,
we use as supervised class, the value of relatedness
given to each pair of sentences on the training cor-
pus.
The obtained results for the relatedness subtask
are given in Table 1. In columns 2, 3 and 5, a large
value signals a more efficient system, but a large
MSE (column 4) means a less efficient system. As
can be seen, our run obtained the rank 12 of 17, with
values slightly below the overall average.
</bodyText>
<subsectionHeader confidence="0.9972">
3.1 Textual Entailment
</subsectionHeader>
<bodyText confidence="0.999479666666667">
In order to calculate the textual entailment judgment,
we have enriched the vectorial representation previ-
ously mentioned with synonyms, antonyms and cue-
</bodyText>
<footnote confidence="0.998820666666667">
1Natural Language Toolkit of Python; http://www.nltk.org/
2We have employed the Weka tool with the default settings
for this purpose
</footnote>
<page confidence="0.998895">
146
</page>
<tableCaption confidence="0.999934">
Table 1: Results obtained at the substask “Relatedness” of the Semeval 2014 Task 1
</tableCaption>
<table confidence="0.99415635">
TEAM ID PEARSON SPEARMAN MSE Rank
ECNU run1 0.82795 0.76892 0.32504 1
StanfordNLP run5 0.82723 0.75594 0.32300 2
The Meaning Factory run1 0.82680 0.77219 0.32237 3
UNAL-NLP run1 0.80432 0.74582 0.35933 4
Illinois-LH run1 0.79925 0.75378 0.36915 5
CECL ALL run1 0.78044 0.73166 0.39819 6
SemantiKLUE run1 0.78019 0.73598 0.40347 7
CNGL run1 0.76391 0.68769 0.42906 8
UTexas run1 0.71455 0.67444 0.49900 9
UoW run1 0.71116 0.67870 0.51137 10
FBK-TR run3 0.70892 0.64430 0.59135 11
BUAP run1 0.69698 0.64524 0.52774 12
UANLPCourse run2 0.69327 0.60269 0.54225 13
UQeResearch run1 0.64185 0.62565 0.82252 14
ASAP run1 0.62780 0.59709 0.66208 15
Yamraj run1 0.53471 0.53561 2.66520 16
asjai run5 0.47952 0.46128 1.10372 17
overall average 0.71876 0.67159 0.63852 8-9
Our difference against the overall average -2% -3% 11% -
</table>
<bodyText confidence="0.997089823529412">
words (“no”, “not”, “nobody” and “none”) for de-
tecting negation at the sentences3. Thus, if some of
these new features exist on the training pair of sen-
tences, we add a boolean value of 1, otherwise we
set the feature to zero.
This new set of vectors is introduced to a support
vector machine classifier4, using as class the textual
entailment judgment given on the training corpus.
The obtained results for the textual entailment
subtask are given in Table 2. Our run obtained the
rank 7 of 18, with values above the overall average.
We consider that this improvement over the related-
ness task was a result of using other features that
are quite important for semantic relatedness, such
as lexical relations (synonyms and antonyms), and
the consideration of the negation phenomenon in the
sentences.
</bodyText>
<sectionHeader confidence="0.99738" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.973691368421053">
This paper describes the use of compositional distri-
butional semantic models for solving the problems
3Synonyms were extracted from WordNet, whereas the
antonyms were collected from Wikipedia.
4Again, we have employed the weka tool with the default
settings for this purpose.
of semantic relatedness and textual entailment. We
proposed different features and measures for that
purpose. The obtained results show a competitive
approach that may be further improved by consider-
ing more lexical relations or other type of semantic
similarity measures.
In general, we obtained the 7th place in the official
ranking list from a total of 18 teams that participated
at the textual entailment subtask. The result at the
semantic relatedness subtask could be improved if
we were considered to add the new features taken
into consideration at the textual entailment subtask,
an idea that we will implement in the future.
</bodyText>
<sectionHeader confidence="0.994514" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.834019555555556">
Jay J. Jiang and David W. Conrath. Semantic simi-
larity based on corpus statistics and lexical taxon-
omy. In Proc of 10th International Conference
on Research in Computational Linguistics, RO-
CLING’97, pages 19–33, 1997.
Claudia Leacock and Martin Chodorow. Combin-
ing local context and wordnet similarity for word
sense identification. In Christiane Fellfaum, edi-
tor, MIT Press, pages 265–283, 1998.
</reference>
<page confidence="0.999182">
147
</page>
<tableCaption confidence="0.99934">
Table 2: Results obtained at the substask “Textual Entailment” of the Semeval 2014 Task 1
</tableCaption>
<table confidence="0.997685523809524">
TEAM ID ACCURACY Rank
Illinois-LH run1 84.575 1
ECNU run1 83.641 2
UNAL-NLP run1 83.053 3
SemantiKLUE run1 82.322 4
The Meaning Factory run1 81.591 5
CECL ALL run1 79.988 6
BUAP run1 79.663 7
UoW run1 78.526 8
CDT run1 77.106 9
UIO-Lien run1 77.004 10
FBK-TR run3 75.401 11
StanfordNLP run5 74.488 12
UTexas run1 73.229 13
Yamraj run1 70.753 14
asjai run5 69.758 15
haLF run2 69.413 16
CNGL run1 67.201 17
UANLPCourse run2 48.731 18
Overall average 75.358 11-12
Our difference against the overall average 4.31% -
</table>
<bodyText confidence="0.6282275">
Michael Lesk. Automatic sense disambiguation us-
ing machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceed-
ings of the 5th Annual International Conference
</bodyText>
<reference confidence="0.985329485714286">
on Systems Documentation, pages 24–26. ACM,
1986.
Dekang Lin. An information-theoretic definition of
similarity. In Proceedings of the Fifteenth Inter-
national Conference on Machine Learning, ICML
’98, pages 296–304, San Francisco, CA, USA,
1998. Morgan Kaufmann Publishers Inc.
Marco Marelli, Luisa Bentivogli, Marco Baroni,
Raffaella Bernardi, Stefano Menini, and Roberto
Zamparelli. Semeval-2014 task 1: Evaluation of
compositional distributional semantic models on
full sentences through semantic relatedness and
textual entailment. In Proceedings of the 8th
International Workshop on Semantic Evaluation
(SemEval-2014), Dublin, Ireland, 2014a.
Marco Marelli, Stefano Menini, Marco Baroni,
Luisa Bentivogli, Raffaella Bernardi, and Roberto
Zamparelli. A sick cure for the evaluation of
compositional distributional semantic models. In
Proceedings of LREC 2014, Reykjavik, Iceland,
2014b.
Rada Mihalcea, Courtney Corley, and Carlo Strap-
parava. Corpus-based and knowledge-based mea-
sures of text semantic similarity. In Proceedings
of the 21st National Conference on Artificial In-
telligence, pages 775–780, 2006.
Philip Resnik. Using information content to evalu-
ate semantic similarity in a taxonomy. In Proceed-
ings of the 14th International Joint Conference on
Artificial Intelligence, IJCAI’95, pages 448–453,
San Francisco, CA, USA, 1995.
Zhibiao Wu and Martha Stone Palmer. Verb seman-
tics and lexical selection. In Proceedings of the
32nd Annual Meeting of the Association for Com-
putational Linguistics, pages 133–138, 1994.
</reference>
<page confidence="0.996824">
148
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.331499">
<title confidence="0.990702">BUAP: Evaluating Compositional Distributional Semantic Models on Sentences through Semantic Relatedness and Textual Entailment</title>
<author confidence="0.819695">Darnes David Pinto Le´on</author>
<author confidence="0.819695">Mireya Tovar</author>
<author confidence="0.819695">Beatriz Benem´erita Universidad Aut´onoma de</author>
<affiliation confidence="0.808439">Faculty of Computer 14 Sur y Av. San Claudio,</affiliation>
<address confidence="0.967337">Puebla, Puebla,</address>
<abstract confidence="0.989819">The results obtained by the BUAP team at Task 1 of SemEval 2014 are presented in this paper. The run submitted is a supervised version based on two classification models: 1) We used logistic regression for determining the semantic relatedness between a pair of sentences, and 2) We employed support vector machines for identifying textual entailment degree between the two sentences. The behaviour for the second subtask (textual entailment) obtained much better performance than the one evaluated at the first subtask (relatedness), ranking our approach in the 7th position of 18 teams that participated at the competition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proc of 10th International Conference on Research in Computational Linguistics, ROCLING’97,</booktitle>
<pages>pages</pages>
<contexts>
<context position="5330" citStr="Jiang and Conrath, 1997" startWordPosition="883" endWordPosition="886">meric vectors established at Section 2, the entry fi of →−u is calculated as: fl = �|S1| i=1 max{sim(wi,1, wj,2)}, with j = 1, · · · , |S2|. The specific similarity measure (sim()) and the correlated term or numeric vector used for each fl is described as follows: 1. f1 : wi,k is the “object” of wi (as defined in 2), and sim() is the maximum similarity obtained by using the following six WordNet similarity metrics offered by NLTK: Leacock &amp; Chodorow (Leacock and Chodorow, 1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu and Palmer, 1994), Resnik (Resnik, 1995), Lin (Lin, 1998), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is numeric vector obtained with LSA, and sim() is the Rada Mihalcea semantic similarity measure (Mihalcea et al., 2006). 7. f7 : wi,k is numeric ve</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. Semantic similarity based on corpus statistics and lexical taxonomy. In Proc of 10th International Conference on Research in Computational Linguistics, ROCLING’97, pages 19–33, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and wordnet similarity for word sense identification.</title>
<date>1998</date>
<pages>265--283</pages>
<editor>In Christiane Fellfaum, editor,</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="5188" citStr="Leacock and Chodorow, 1998" startWordPosition="859" endWordPosition="862">ir of sentences S1 = w1,1w2,1 ··· w|S1|,1 and S2 = w1,2w2,2 ··· w|S2|,2, such as each wi,k is represented according to the correlated terms or numeric vectors established at Section 2, the entry fi of →−u is calculated as: fl = �|S1| i=1 max{sim(wi,1, wj,2)}, with j = 1, · · · , |S2|. The specific similarity measure (sim()) and the correlated term or numeric vector used for each fl is described as follows: 1. f1 : wi,k is the “object” of wi (as defined in 2), and sim() is the maximum similarity obtained by using the following six WordNet similarity metrics offered by NLTK: Leacock &amp; Chodorow (Leacock and Chodorow, 1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu and Palmer, 1994), Resnik (Resnik, 1995), Lin (Lin, 1998), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is nu</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow. Combining local context and wordnet similarity for word sense identification. In Christiane Fellfaum, editor, MIT Press, pages 265–283, 1998.</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>on Systems Documentation,</booktitle>
<pages>24--26</pages>
<publisher>ACM,</publisher>
<marker>1986</marker>
<rawString>on Systems Documentation, pages 24–26. ACM, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fifteenth International Conference on Machine Learning, ICML ’98,</booktitle>
<pages>296--304</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA,</location>
<contexts>
<context position="5282" citStr="Lin, 1998" startWordPosition="877" endWordPosition="878">ding to the correlated terms or numeric vectors established at Section 2, the entry fi of →−u is calculated as: fl = �|S1| i=1 max{sim(wi,1, wj,2)}, with j = 1, · · · , |S2|. The specific similarity measure (sim()) and the correlated term or numeric vector used for each fl is described as follows: 1. f1 : wi,k is the “object” of wi (as defined in 2), and sim() is the maximum similarity obtained by using the following six WordNet similarity metrics offered by NLTK: Leacock &amp; Chodorow (Leacock and Chodorow, 1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu and Palmer, 1994), Resnik (Resnik, 1995), Lin (Lin, 1998), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is numeric vector obtained with LSA, and sim() is the Rada Mihalcea semantic similarity measure (Mi</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. An information-theoretic definition of similarity. In Proceedings of the Fifteenth International Conference on Machine Learning, ICML ’98, pages 296–304, San Francisco, CA, USA, 1998. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Marelli</author>
<author>Luisa Bentivogli</author>
<author>Marco Baroni</author>
<author>Raffaella Bernardi</author>
<author>Stefano Menini</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval-2014),</booktitle>
<location>Dublin, Ireland,</location>
<contexts>
<context position="2063" citStr="Marelli et al. (2014" startWordPosition="303" endWordPosition="306"> degree of semantic similarity, in this case, between a pair of sentences, whereas textual entailment allows to determine the entailment relation holding between two sentences. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ This document is a description paper, therefore, we focus the rest of it on the features and models we used for carrying out the experiments. A complete description of the task and the dataset used are given in Marelli et al. (2014a) and in Marelli et al. (2014b), respectively. The remaining of this paper is structured as follows. In Section 2 we describe the general model we used for comparing two sentences and the set of the features used for constructing the vectorial representation for each sentence. Section 3 shows how we integrate the features calculated in a single vector which fed a supervised classifier aiming to construct a classication model that solves the two aforementioned problems: semantic relatedness and textual entailment. In the same section we show the obtained results. Finally, in Section 4 we prese</context>
</contexts>
<marker>Marelli, Bentivogli, Baroni, Bernardi, Menini, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Luisa Bentivogli, Marco Baroni, Raffaella Bernardi, Stefano Menini, and Roberto Zamparelli. Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval-2014), Dublin, Ireland, 2014a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Marelli</author>
<author>Stefano Menini</author>
<author>Marco Baroni</author>
<author>Luisa Bentivogli</author>
<author>Raffaella Bernardi</author>
<author>Roberto Zamparelli</author>
</authors>
<title>A sick cure for the evaluation of compositional distributional semantic models.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC 2014,</booktitle>
<location>Reykjavik, Iceland,</location>
<contexts>
<context position="2063" citStr="Marelli et al. (2014" startWordPosition="303" endWordPosition="306"> degree of semantic similarity, in this case, between a pair of sentences, whereas textual entailment allows to determine the entailment relation holding between two sentences. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ This document is a description paper, therefore, we focus the rest of it on the features and models we used for carrying out the experiments. A complete description of the task and the dataset used are given in Marelli et al. (2014a) and in Marelli et al. (2014b), respectively. The remaining of this paper is structured as follows. In Section 2 we describe the general model we used for comparing two sentences and the set of the features used for constructing the vectorial representation for each sentence. Section 3 shows how we integrate the features calculated in a single vector which fed a supervised classifier aiming to construct a classication model that solves the two aforementioned problems: semantic relatedness and textual entailment. In the same section we show the obtained results. Finally, in Section 4 we prese</context>
</contexts>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Roberto Zamparelli. A sick cure for the evaluation of compositional distributional semantic models. In Proceedings of LREC 2014, Reykjavik, Iceland, 2014b.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
<author>Carlo Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence,</booktitle>
<pages>775--780</pages>
<contexts>
<context position="5902" citStr="Mihalcea et al., 2006" startWordPosition="987" endWordPosition="990">8), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is numeric vector obtained with LSA, and sim() is the Rada Mihalcea semantic similarity measure (Mihalcea et al., 2006). 7. f7 : wi,k is numeric vector obtained with LSA, and sim() is the cosine similarity measure. 8. f8 : wi,k is numeric vector obtained with LSA, and sim() is the euclidean distance. 9. f9 : wi,k is numeric vector obtained with LSA, and sim() is the Chebyshev distance. All these 9 features were introduced to a logistic regression classifier in order to obtain a classification model which allows us to determine the value of relatedness between a new pair of sentences2. Here, we use as supervised class, the value of relatedness given to each pair of sentences on the training corpus. The obtained</context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Rada Mihalcea, Courtney Corley, and Carlo Strapparava. Corpus-based and knowledge-based measures of text semantic similarity. In Proceedings of the 21st National Conference on Artificial Intelligence, pages 775–780, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence, IJCAI’95,</booktitle>
<pages>448--453</pages>
<location>San Francisco, CA, USA,</location>
<contexts>
<context position="5265" citStr="Resnik, 1995" startWordPosition="874" endWordPosition="875">is represented according to the correlated terms or numeric vectors established at Section 2, the entry fi of →−u is calculated as: fl = �|S1| i=1 max{sim(wi,1, wj,2)}, with j = 1, · · · , |S2|. The specific similarity measure (sim()) and the correlated term or numeric vector used for each fl is described as follows: 1. f1 : wi,k is the “object” of wi (as defined in 2), and sim() is the maximum similarity obtained by using the following six WordNet similarity metrics offered by NLTK: Leacock &amp; Chodorow (Leacock and Chodorow, 1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu and Palmer, 1994), Resnik (Resnik, 1995), Lin (Lin, 1998), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is numeric vector obtained with LSA, and sim() is the Rada Mihalcea semantic simil</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, IJCAI’95, pages 448–453, San Francisco, CA, USA, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Stone Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<contexts>
<context position="5242" citStr="Wu and Palmer, 1994" startWordPosition="869" endWordPosition="872">·· w|S2|,2, such as each wi,k is represented according to the correlated terms or numeric vectors established at Section 2, the entry fi of →−u is calculated as: fl = �|S1| i=1 max{sim(wi,1, wj,2)}, with j = 1, · · · , |S2|. The specific similarity measure (sim()) and the correlated term or numeric vector used for each fl is described as follows: 1. f1 : wi,k is the “object” of wi (as defined in 2), and sim() is the maximum similarity obtained by using the following six WordNet similarity metrics offered by NLTK: Leacock &amp; Chodorow (Leacock and Chodorow, 1998), Lesk (Lesk, 1986), Wu &amp; Palmer (Wu and Palmer, 1994), Resnik (Resnik, 1995), Lin (Lin, 1998), and Jiang &amp; Conrath1 (Jiang and Conrath, 1997). 2. f2 : wi,k is the “subject” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 3. f3 : wi,k is the “property” of wi, and sim() is the maximum similarity obtained by using the same six WordNet similarity metrics. 4. f4 : wi,k is an n-gram containing wi, and sim() is the cosine similarity measure. 5. f5 : wi,k is an skip-gram containing wi, and sim() is the cosine similarity measure. 6. f6 : wi,k is numeric vector obtained with LSA, and sim() is the Rada </context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Stone Palmer. Verb semantics and lexical selection. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 133–138, 1994.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>