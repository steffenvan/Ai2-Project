<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004689">
<title confidence="0.991084">
Learning Multilingual Subjective Language via Cross-Lingual Projections
</title>
<author confidence="0.996552">
Rada Mihalcea and Carmen Banea Janyce Wiebe
</author>
<affiliation confidence="0.9997195">
Department of Computer Science Department of Computer Science
University of North Texas University of Pittsburgh
</affiliation>
<email confidence="0.998975">
rada@cs.unt.edu, carmenb@unt.edu wiebe@cs.pitt.edu
</email>
<sectionHeader confidence="0.995653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979888888889">
This paper explores methods for generating
subjectivity analysis resources in a new lan-
guage by leveraging on the tools and re-
sources available in English. Given a bridge
between English and the selected target lan-
guage (e.g., a bilingual dictionary or a par-
allel corpus), the methods can be used to
rapidly create tools for subjectivity analysis
in the new language.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999924488372093">
There is growing interest in the automatic extraction
of opinions, emotions, and sentiments in text (sub-
jectivity), to provide tools and support for various
natural language processing applications. Most of
the research to date has focused on English, which
is mainly explained by the availability of resources
for subjectivity analysis, such as lexicons and man-
ually labeled corpora.
In this paper, we investigate methods to auto-
matically generate resources for subjectivity analy-
sis for a new target language by leveraging on the
resources and tools available for English, which in
many cases took years of work to complete. Specif-
ically, through experiments with cross-lingual pro-
jection of subjectivity, we seek answers to the fol-
lowing questions.
First, can we derive a subjectivity lexicon for a
new language using an existing English subjectivity
lexicon and a bilingual dictionary? Second, can we
derive subjectivity-annotated corpora in a new lan-
guage using existing subjectivity analysis tools for
English and a parallel corpus? Finally, third, can we
build tools for subjectivity analysis for a new target
language by relying on these automatically gener-
ated resources?
We focus our experiments on Romanian, selected
as a representative of the large number of languages
that have only limited text processing resources de-
veloped to date. Note that, although we work with
Romanian, the methods described are applicable to
any other language, as in these experiments we (pur-
posely) do not use any language-specific knowledge
of the target language. Given a bridge between En-
glish and the selected target language (e.g., a bilin-
gual dictionary or a parallel corpus), the methods
can be applied to other languages as well.
After providing motivations, we present two ap-
proaches to developing sentence-level subjectivity
classifiers for a new target language. The first uses a
subjectivity lexicon translated from an English one.
The second uses an English subjectivity classifier
and a parallel corpus to create target-language train-
ing data for developing a statistical classifier.
</bodyText>
<sectionHeader confidence="0.991344" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.997147090909091">
Automatic subjectivity analysis methods have been
used in a wide variety of text processing applica-
tions, such as tracking sentiment timelines in on-
line forums and news (Lloyd et al., 2005; Balog
et al., 2006), review classification (Turney, 2002;
Pang et al., 2002), mining opinions from product
reviews (Hu and Liu, 2004), automatic expressive
text-to-speech synthesis (Alm et al., 2005), text se-
mantic analysis (Wiebe and Mihalcea, 2006; Esuli
and Sebastiani, 2006), and question answering (Yu
and Hatzivassiloglou, 2003).
</bodyText>
<page confidence="0.976014">
976
</page>
<note confidence="0.9256285">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999888307692308">
While much recent work in subjectivity analysis
focuses on sentiment (a type of subjectivity, namely
positive and negative emotions, evaluations, and
judgments), we opt to focus on recognizing subjec-
tivity in general, for two reasons.
First, even when sentiment is the desired focus,
researchers in sentiment analysis have shown that
a two-stage approach is often beneficial, in which
subjective instances are distinguished from objec-
tive ones, and then the subjective instances are fur-
ther classified according to polarity (Yu and Hatzi-
vassiloglou, 2003; Pang and Lee, 2004; Wilson et
al., 2005; Kim and Hovy, 2006). In fact, the prob-
lem of distinguishing subjective versus objective in-
stances has often proved to be more difficult than
subsequent polarity classification, so improvements
in subjectivity classification promise to positively
impact sentiment classification. This is reported in
studies of manual annotation of phrases (Takamura
et al., 2006), recognizing contextual polarity of ex-
pressions (Wilson et al., 2005), and sentiment tag-
ging of words and word senses (Andreevskaia and
Bergler, 2006; Esuli and Sebastiani, 2006).
Second, an NLP application may seek a wide
range of types of subjectivity attributed to a per-
son, such as their motivations, thoughts, and specu-
lations, in addition to their positive and negative sen-
timents. For instance, the opinion tracking system
Lydia (Lloyd et al., 2005) gives separate ratings for
subjectivity and sentiment. These can be detected
with subjectivity analysis but not by a method fo-
cused only on sentiment.
There is world-wide interest in text analysis appli-
cations. While work on subjectivity analysis in other
languages is growing (e.g., Japanese data are used in
(Takamura et al., 2006; Kanayama and Nasukawa,
2006), Chinese data are used in (Hu et al., 2005),
and German data are used in (Kim and Hovy, 2006)),
much of the work in subjectivity analysis has been
applied to English data. Creating corpora and lexical
resources for a new language is very time consum-
ing. In general, we would like to leverage resources
already developed for one language to more rapidly
create subjectivity analysis tools for a new one. This
motivates our exploration and use of cross-lingual
lexicon translations and annotation projections.
Most if not all work on subjectivity analysis has
been carried out in a monolingual framework. We
are not aware of multi-lingual work in subjectivity
analysis such as that proposed here, in which subjec-
tivity analysis resources developed for one language
are used to support developing resources in another.
</bodyText>
<sectionHeader confidence="0.92775" genericHeader="method">
3 A Lexicon-Based Approach
</sectionHeader>
<bodyText confidence="0.9995825">
Many subjectivity and sentiment analysis tools rely
on manually or semi-automatically constructed lex-
icons (Yu and Hatzivassiloglou, 2003; Riloff and
Wiebe, 2003; Kim and Hovy, 2006). Given the suc-
cess of such techniques, the first approach we take
to generating a target-language subjectivity classi-
fier is to create a subjectivity lexicon by translating
an existing source language lexicon, and then build
a classifier that relies on the resulting lexicon.
Below, we describe the translation process and
discuss the results of an annotation study to assess
the quality of the translated lexicon. We then de-
scribe and evaluate a lexicon-based target-language
classifier.
</bodyText>
<subsectionHeader confidence="0.999787">
3.1 Translating a Subjectivity Lexicon
</subsectionHeader>
<bodyText confidence="0.999603260869565">
The subjectivity lexicon we use is from Opinion-
Finder (Wiebe and Riloff, 2005), an English sub-
jectivity analysis system which, among other things,
classifies sentences as subjective or objective. The
lexicon was compiled from manually developed re-
sources augmented with entries learned from cor-
pora. It contains 6,856 unique entries, out of which
990 are multi-word expressions. The entries in the
lexicon have been labeled for part of speech, and for
reliability – those that appear most often in subjec-
tive contexts are strong clues of subjectivity, while
those that appear less often, but still more often than
expected by chance, are labeled weak.
To perform the translation, we use two bilingual
dictionaries. The first is an authoritative English-
Romanian dictionary, consisting of 41,500 entries,1
which we use as the main translation resource for the
lexicon translation. The second dictionary, drawn
from the Universal Dictionary download site (UDP,
2007) consists of 4,500 entries written largely by
Web volunteer contributors, and thus is not error
free. We use this dictionary only for those entries
that do not appear in the main dictionary.
</bodyText>
<footnote confidence="0.9910685">
1Unique English entries, each with multiple Romanian
translations.
</footnote>
<page confidence="0.997583">
977
</page>
<bodyText confidence="0.999977541666667">
There were several challenges encountered in the
translation process. First, although the English sub-
jectivity lexicon contains inflected words, we must
use the lemmatized form in order to be able to trans-
late the entries using the bilingual dictionary. How-
ever, words may lose their subjective meaning once
lemmatized. For instance, the inflected form of
memories becomes memory. Once translated into
Romanian (as memorie), its main meaning is ob-
jective, referring to the power of retaining informa-
tion as in Iron supplements may improve a woman’s
memory.
Second, neither the lexicon nor the bilingual dic-
tionary provides information on the sense of the in-
dividual entries, and therefore the translation has to
rely on the most probable sense in the target lan-
guage. Fortunately, the bilingual dictionary lists the
translations in reverse order of their usage frequen-
cies. Nonetheless, the ambiguity of the words and
the translations still seems to represent an impor-
tant source of error. Moreover, the lexicon some-
times includes identical entries expressed through
different parts of speech, e.g., grudge has two sepa-
rate entries, for its noun and verb roles, respectively.
On the other hand, the bilingual dictionary does not
make this distinction, and therefore we have again
to rely on the “most frequent” heuristic captured by
the translation order in the bilingual dictionary.
Finally, the lexicon includes a significant number
(990) of multi-word expressions that pose transla-
tion difficulties, sometimes because their meaning
is idiomatic, and sometimes because the multi-word
expression is not listed in the bilingual dictionary
and the translation of the entire phrase is difficult
to reconstruct from the translations of the individual
words. To address this problem, when a translation
is not found in the dictionary, we create one using
a word-by-word approach. These translations are
then validated by enforcing that they occur at least
three times on the Web, using counts collected from
the AltaVista search engine. The multi-word expres-
sions that are not validated in this process are dis-
carded, reducing the number of expressions from an
initial set of 990 to a final set of 264.
The final subjectivity lexicon in Romanian con-
tains 4,983 entries. Table 1 shows examples of en-
tries in the Romanian lexicon, together with their
corresponding original English form. The table
</bodyText>
<table confidence="0.392261">
Romanian English attributes
infrumuset¸a beautifying strong, verb
notabil notable weak, adj
plin de regret full of regrets strong, adj
sclav slaves weak,noun
</table>
<tableCaption confidence="0.838943">
Table 1: Examples of entries in the Romanian sub-
jectivity lexicon
</tableCaption>
<bodyText confidence="0.999488">
also shows the reliability of the expression (weak or
strong) and the part of speech – attributes that are
provided in the English subjectivity lexicon.
</bodyText>
<subsectionHeader confidence="0.62903">
Manual Evaluation.
</subsectionHeader>
<bodyText confidence="0.9998775">
We want to assess the quality of the translated lexi-
con, and compare it to the quality of the original En-
glish lexicon. The English subjectivity lexicon was
evaluated in (Wiebe and Riloff, 2005) against a cor-
pus of English-language news articles manually an-
notated for subjectivity (the MPQA corpus (Wiebe et
al., 2005)). According to this evaluation, 85% of the
instances of the clues marked as strong and 71.5% of
the clues marked as weak are in subjective sentences
in the MPQA corpus.
Since there is no comparable Romanian corpus,
an alternate way to judge the subjectivity of a Ro-
manian lexicon entry is needed.
Two native speakers of Romanian annotated the
subjectivity of 150 randomly selected entries. Each
annotator independently read approximately 100 ex-
amples of each drawn from the Web, including a
large number from news sources. The subjectivity
of a word was consequently judged in the contexts
where it most frequently appears, accounting for its
most frequent meanings on the Web.
The tagset used for the annotations consists of
S(ubjective), O(bjective), and B(oth). A W(rong) la-
bel is also used to indicate a wrong translation. Table
2 shows the contingency table for the two annota-
tors’ judgments on this data.
</bodyText>
<table confidence="0.950313666666667">
S O B W Total
S 53 6 9 0 68
O 1 27 1 0 29
B 5 3 18 0 26
W 0 0 0 27 27
Total 59 36 28 27 150
</table>
<tableCaption confidence="0.8380725">
Table 2: Agreement on 150 entries in the Romanian
lexicon
</tableCaption>
<bodyText confidence="0.974275">
Without counting the wrong translations, the
agreement is measured at 0.80, with a Kappa κ =
</bodyText>
<page confidence="0.992512">
978
</page>
<bodyText confidence="0.99998244">
0.70, which indicates consistent agreement. After
the disagreements were reconciled through discus-
sions, the final set of 123 correctly translated entries
does include 49.6% (61) subjective entries, but fully
23.6% (29) were found in the study to have primar-
ily objective uses (the other 26.8% are mixed).
Thus, this study suggests that the Romanian sub-
jectivity clues derived through translation are less re-
liable than the original set of English clues. In sev-
eral cases, the subjectivity is lost in the translation,
mainly due to word ambiguity in either the source
or target language, or both. For instance, the word
fragile correctly translates into Romanian as fragil,
yet this word is frequently used to refer to breakable
objects, and it loses its subjective meaning of del-
icate. Other words, such as one-sided, completely
lose subjectivity once translated, as it becomes in
Romanian cu o singura latur˘a, meaning with only
one side (as of objects).
Interestingly, the reliability of clues in the English
lexicon seems to help preserve subjectivity. Out of
the 77 entries marked as strong, 11 were judged to be
objective in Romanian (14.3%), compared to 14 ob-
jective Romanian entries obtained from the 36 weak
English clues (39.0%).
</bodyText>
<subsectionHeader confidence="0.9955865">
3.2 Rule-based Subjectivity Classifier Using a
Subjectivity Lexicon
</subsectionHeader>
<bodyText confidence="0.999879925373134">
Starting with the Romanian lexicon, we developed
a lexical classifier similar to the one introduced by
(Riloff and Wiebe, 2003). At the core of this method
is a high-precision subjectivity and objectivity clas-
sifier that can label large amounts of raw text using
only a subjectivity lexicon. Their method is further
improved with a bootstrapping process that learns
extraction patterns. In our experiments, however, we
apply only the rule-based classification step, since
the extraction step cannot be implemented without
tools for syntactic parsing and information extrac-
tion not available in Romanian.
The classifier relies on three main heuristics to la-
bel subjective and objective sentences: (1) if two
or more strong subjective expressions occur in the
same sentence, the sentence is labeled Subjective;
(2) if no strong subjective expressions occur in a
sentence, and at most two weak subjective expres-
sions occur in the previous, current, and next sen-
tence combined, then the sentence is labeled Objec-
tive; (3) otherwise, if none of the previous rules ap-
ply, the sentence is labeled Unknown.
The quality of the classifier was evaluated on a
Romanian gold-standard corpus annotated for sub-
jectivity. Two native Romanian speakers (Rol and
Roe) manually annotated the subjectivity of the sen-
tences of five randomly selected documents (504
sentences) from the Romanian side of an English-
Romanian parallel corpus, according to the anno-
tation scheme in (Wiebe et al., 2005). Agreement
between annotators was measured, and then their
differences were adjudicated. The baseline on this
data set is 54.16%, which can be obtained by as-
signing a default Subjective label to all sentences.
(More information about the corpus and annotations
are given in Section 4 below, where agreement be-
tween English and Romanian aligned sentences is
also assessed.)
As mentioned earlier, due to the lexicon projec-
tion process that is performed via a bilingual dictio-
nary, the entries in our Romanian subjectivity lex-
icon are in a lemmatized form. Consequently, we
also lemmatize the gold-standard corpus, to allow
for the identification of matches with the lexicon.
For this purpose, we use the Romanian lemmatizer
developed by Ion and Tufis¸ (Ion, 2007), which has
an estimated accuracy of 98%.2
Table 3 shows the results of the rule-based classi-
fier. We show the precision, recall, and F-measure
independently measured for the subjective, objec-
tive, and all sentences. We also evaluated a vari-
ation of the rule-based classifier that labels a sen-
tence as objective if there are at most three weak ex-
pressions in the previous, current, and next sentence
combined, which raises the recall of the objective
classifier. Our attempts to increase the recall of the
subjective classifier all resulted in significant loss in
precision, and thus we kept the original heuristic.
In its original English implementation, this sys-
tem was proposed as being high-precision but low
coverage. Evaluated on the MPQA corpus, it has
subjective precision of 90.4, subjective recall of
34.2, objective precision of 82.4, and objective re-
call of 30.7; overall, precision is 86.7 and recall is
32.6 (Wiebe and Riloff, 2005). We see a similar be-
havior on Romanian for subjective sentences. The
subjective precision is good, albeit at the cost of low
</bodyText>
<footnote confidence="0.927607">
2Dan Tufis¸, personal communication.
</footnote>
<page confidence="0.983147">
979
</page>
<table confidence="0.991012222222222">
Measure Subjective Objective All
subj = at least two strong; obj = at most two weak
Precision 80.00 56.50 62.59
Recall 20.51 48.91 33.53
F-measure 32.64 52.52 43.66
subj = at least two strong; obj = at most three weak
Precision 80.00 56.85 61.94
Recall 20.51 61.03 39.08
F-measure 32.64 58.86 47.93
</table>
<tableCaption confidence="0.999947">
Table 3: Evaluation of the rule-based classifier
</tableCaption>
<bodyText confidence="0.999837375">
recall, and thus the classifier could be used to har-
vest subjective sentences from unlabeled Romanian
data (e.g., for a subsequent bootstrapping process).
The system is not very effective for objective classi-
fication, however. Recall that the objective classifier
relies on the weak subjectivity clues, for which the
transfer of subjectivity in the translation process was
particularly low.
</bodyText>
<sectionHeader confidence="0.992517" genericHeader="method">
4 A Corpus-Based Approach
</sectionHeader>
<bodyText confidence="0.975592233766234">
Given the low number of subjective entries found in
the automatically generated lexicon and the subse-
quent low recall of the lexical classifier, we decided
to also explore a second, corpus-based approach.
This approach builds a subjectivity-annotated cor-
pus for the target language through projection, and
then trains a statistical classifier on the resulting
corpus (numerous statistical classifiers have been
trained for subjectivity or sentiment classification,
e.g., (Pang et al., 2002; Yu and Hatzivassiloglou,
2003)). The hypothesis is that we can eliminate
some of the ambiguities (and consequent loss of sub-
jectivity) observed during the lexicon translation by
accounting for the context of the ambiguous words,
which is possible in a corpus-based approach. Ad-
ditionally, we also hope to improve the recall of the
classifier, by addressing those cases not covered by
the lexicon-based approach.
In the experiments reported in this section, we
use a parallel corpus consisting of 107 documents
from the SemCor corpus (Miller et al., 1993) and
their manual translations into Romanian.3 The cor-
pus consists of roughly 11,000 sentences, with ap-
proximately 250,000 tokens on each side. It is a bal-
anced corpus covering a number of topics in sports,
politics, fashion, education, and others.
3The translation was carried out by a Romanian native
speaker, student in a department of “Foreign Languages and
Translations” in Romania.
Below, we begin with a manual annotation study
to assess the quality of annotation and preservation
of subjectivity in translation. We then describe the
automatic construction of a target-language training
set, and evaluate a classifier trained on that data.
Annotation Study.
We start by performing an agreement study meant
to determine the extent to which subjectivity is pre-
served by the cross-lingual projections. In the study,
three annotators – one native English speaker (En)
and two native Romanian speakers (Ro1 and Ro2) –
first trained on 3 randomly selected documents (331
sentences). They then independently annotated the
subjectivity of the sentences of two randomly se-
lected documents from the parallel corpus, account-
ing for 173 aligned sentence pairs. The annotators
had access exclusively to the version of the sen-
tences in their language, to avoid any bias that could
be introduced by seeing the translation in the other
language.
Note that the Romanian annotations (after all dif-
ferences between the Romanian annotators were ad-
judicated) of all 331 + 173 sentences make up the
gold standard corpus used in the experiments re-
ported in Sections 3.2 and 4.1.
Before presenting the results of the annotation
study, we give some examples. The following are
English subjective sentences and their Romanian
translations (the subjective elements are shown in
bold).
[en] The desire to give Broglio as many starts as
possible.
[ro] Dorint¸a de a-i da lui Broglio cˆat mai multe
starturi posibile.
[en] Suppose he did lie beside Lenin, would it be
permanent ?
[ro] S˘a presupunem c˘a ar fi as¸ezat al˘aturi de Lenin,
oare va fi pentru totdeauna?
The following are examples of objective parallel
sentences.
[en]The Pirates have a 9-6 record this year and the
Redbirds are 7-9.
[ro] Pirat¸ii au un palmares de 9 la 6 anul acesta si
P˘as˘arile Ros¸ii au 7 la 9.
[en] One of the obstacles to the easy control of a
2-year old child is a lack of verbal communication.
[ro] Unul dintre obstacolele in controlarea unui
copil de 2 ani este lipsa comunic˘arii verbale.
</bodyText>
<page confidence="0.994749">
980
</page>
<bodyText confidence="0.9997551">
The annotators were trained using the MPQA
annotation guidelines (Wiebe et al., 2005). The
tagset consists of S(ubjective), O(bjective) and
U(ncertain). For the U tags, a class was also given;
OU means, for instance, that the annotator is uncer-
tain but she is leaning toward O. Table 4 shows the
pairwise agreement figures and the Kappa (K) calcu-
lated for the three annotators. The table also shows
the agreement when the borderline uncertain cases
are removed.
</bodyText>
<table confidence="0.99875">
all sentences Uncertain removed
pair agree κ agree κ (%) removed
Ro1 &amp; Ro2 0.83 0.67 0.89 0.77 23
En &amp; Ro1 0.77 0.54 0.86 0.73 26
En &amp; Ro2 0.78 0.55 0.91 0.82 20
</table>
<tableCaption confidence="0.992798">
Table 4: Agreement on the data set of 173 sentences.
</tableCaption>
<bodyText confidence="0.983382949152542">
Annotations performed by three annotators: one na-
tive English speaker (En) and two native Romanian
speakers (Rol and Roe)
When all the sentences are included, the agree-
ment between the two Romanian annotators is mea-
sured at 0.83 (K = 0.67). If we remove the border-
line cases where at least one annotator’s tag is Un-
certain, the agreement rises to 0.89 with K = 0.77.
These figures are somewhat lower than the agree-
ment observed during previous subjectivity anno-
tation studies conducted on English (Wiebe et al.,
2005) (the annotators were more extensively trained
in those studies), but they nonetheless indicate con-
sistent agreement.
Interestingly, when the agreement is conducted
cross-lingually between an English and a Romanian
annotator, the agreement figures, although some-
what lower, are comparable. In fact, once the
Uncertain tags are removed, the monolingual and
cross-lingual agreement and K values become al-
most equal, which suggests that in most cases the
sentence-level subjectivity is preserved.
The disagreements were reconciled first between
the labels assigned by the two Romanian annotators,
followed by a reconciliation between the resulting
Romanian “gold-standard” labels and the labels as-
signed by the English annotator. In most cases, the
disagreement across the two languages was found
to be due to a difference of opinion about the sen-
tence subjectivity, similar to the differences encoun-
tered in monolingual annotations. However, there
are cases where the differences are due to the sub-
jectivity being lost in the translation. Sometimes,
this is due to several possible interpretations for the
translated sentence. For instance, the following sen-
tence:
[en] They honored the battling Billikens last night.
[ro] Ei i-au celebrat pe Billikens seara trecut˘a.
is marked as Subjective in English (in context, the
English annotator interpreted honored as referring
to praises of the Billikens). However, the Romanian
translation of honored is celebrat which, while cor-
rect as a translation, has the more frequent interpre-
tation of having a party. The two Romanian annota-
tors chose this interpretation, which correspondingly
lead them to mark the sentence as Objective.
In other cases, in particular when the subjectivity
is due to figures of speech such as irony, the trans-
lation sometimes misses the ironic aspects. For in-
stance, the translation of egghead was not perceived
as ironic by the Romanian annotators, and conse-
quently the following sentence labeled Subjective in
English is annotated as Objective in Romanian.
[en] I have lived for many years in a Connecti-
cut commuting town with a high percentage of [...]
business executives of egghead tastes.
[ro] Am tr˘ait mult¸i ani intr-un oras¸ din apropiere de
Connecticut ce avea o mare proport¸ie de [...] oa-
meni de afaceri cu gusturi intelectuale.
</bodyText>
<subsectionHeader confidence="0.996287333333333">
4.1 Translating a Subjectivity-Annotated
Corpus and Creating a Machine Learning
Subjectivity Classifier
</subsectionHeader>
<bodyText confidence="0.999820294117647">
To further validate the corpus-based projection of
subjectivity, we developed a subjectivity classifier
trained on Romanian subjectivity-annotated corpora
obtained via cross-lingual projections.
Ideally, one would generate an annotated Roma-
nian corpus by translating English documents man-
ually annotated for subjectivity such as the MPQA
corpus. Unfortunately, the manual translation of this
corpus would be prohibitively expensive, both time-
wise and financially. The other alternative – auto-
matic machine translation – has not yet reached a
level that would enable the generation of a high-
quality translated corpus. We therefore decided to
use a different approach where we automatically
annotate the English side of an existing English-
Romanian corpus, and subsequently project the an-
notations onto the Romanian side of the parallel cor-
</bodyText>
<page confidence="0.993596">
981
</page>
<table confidence="0.999935">
Precision Recall F-measure
high-precision 86.7 32.6 47.4
high-coverage 79.4 70.6 74.7
</table>
<tableCaption confidence="0.662865">
Table 5: Precision, recall, and F-measure for the
two OpinionFinder classifiers, as measured on the
MPQA corpus.
</tableCaption>
<bodyText confidence="0.997757321428571">
pus across the sentence-level alignments available in
the corpus.
For the automatic subjectivity annotations, we
generated two sets of the English-side annotations,
one using the high-precision classifier and one using
the high-coverage classifier available in the Opinion-
Finder tool. The high-precision classifier in Opin-
ionFinder uses the clues of the subjectivity lexicon
to harvest subjective and objective sentences from
a large amount of unannotated text; this data is then
used to automatically identify a set of extraction pat-
terns, which are then used iteratively to identify a
larger set of subjective and objective sentences.
In addition, in OpinionFinder, the high-precision
classifier is used to produce an English labeled data
set for training, which is used to generate its Naive
Bayes high-coverage subjectivity classifier. Table
5 shows the performance of the two classifiers on
the MPQA corpus as reported in (Wiebe and Riloff,
2005). Note that 55% of the sentences in the MPQA
corpus are subjective – which represents the baseline
for this data set.
The two OpinionFinder classifiers are used to la-
bel the training corpus. After removing the 504 test
sentences, we are left with 10,628 sentences that
are automatically annotated for subjectivity. Table
6 shows the number of subjective and objective sen-
tences obtained with each classifier.
</bodyText>
<table confidence="0.969018">
Classifier Subjective Objective All
high-precision 1,629 2,334 3,963
high-coverage 5,050 5,578 10,628
</table>
<tableCaption confidence="0.878532">
Table 6: Subjective and objective training sentences
automatically annotated with OpinionFinder.
</tableCaption>
<bodyText confidence="0.99981125">
Next, the OpinionFinder annotations are pro-
jected onto the Romanian training sentences, which
are then used to develop a probabilistic classifier for
the automatic labeling of subjectivity in Romanian
sentences.
Similar to, e.g., (Pang et al., 2002), we use a
Naive Bayes algorithm trained on word features co-
occurring with the subjective and the objective clas-
sifications. We assume word independence, and we
use a 0.3 cut-off for feature selection. While re-
cent work has also considered more complex syn-
tactic features, we are not able to generate such fea-
tures for Romanian as they require tools currently
not available for this language.
We create two classifiers, one trained on each
data set. The quality of the classifiers is evaluated
on the 504-sentence Romanian gold-standard corpus
described above. Recall that the baseline on this data
set is 54.16%, the percentage of sentences in the cor-
pus that are subjective. Table 7 shows the results.
</bodyText>
<table confidence="0.990924777777778">
Subjective Objective All
projection source: OF high-precision classifier
Precision 65.02 69.62 64.48
Recall 82.41 47.61 64.48
F-measure 72.68 56.54 64.68
projection source: OF high-coverage classifier
Precision 66.66 70.17 67.85
Recall 81.31 52.17 67.85
F-measure 72.68 56.54 67.85
</table>
<tableCaption confidence="0.995594">
Table 7: Evaluation of the machine learning classi-
</tableCaption>
<bodyText confidence="0.9965145">
fier using training data obtained via projections from
data automatically labeled by OpinionFinder (OF).
Our best classifier has an F-measure of 67.85,
and is obtained by training on projections from
the high-coverage OpinionFinder annotations. Al-
though smaller than the 74.70 F-measure obtained
by the English high-coverage classifier (see Ta-
ble 5), the result appears remarkable given that no
language-specific Romanian information was used.
The overall results obtained with the machine
learning approach are considerably higher than
those obtained from the rule-based classifier (except
for the precision of the subjective sentences). This
is most likely due to the lexicon translation process,
which as mentioned in the agreement study in Sec-
tion 3.1, leads to ambiguity and loss of subjectivity.
Instead, the corpus-based translations seem to better
account for the ambiguity of the words, and the sub-
jectivity is generally preserved in the sentence trans-
lations.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.953803">
In this paper, we described two approaches to gener-
ating resources for subjectivity annotations for a new
</bodyText>
<page confidence="0.991928">
982
</page>
<bodyText confidence="0.999956571428571">
language, by leveraging on resources and tools avail-
able for English. The first approach builds a target
language subjectivity lexicon by translating an exist-
ing English lexicon using a bilingual dictionary. The
second generates a subjectivity-annotated corpus in
a target language by projecting annotations from an
automatically annotated English corpus.
These resources were validated in two ways.
First, we carried out annotation studies measuring
the extent to which subjectivity is preserved across
languages in each of the two resources. These stud-
ies show that only a relatively small fraction of the
entries in the lexicon preserve their subjectivity in
the translation, mainly due to the ambiguity in both
the source and the target languages. This is con-
sistent with observations made in previous work
that subjectivity is a property associated not with
words, but with word meanings (Wiebe and Mihal-
cea, 2006). In contrast, the sentence-level subjectiv-
ity was found to be more reliably preserved across
languages, with cross-lingual inter-annotator agree-
ments comparable to the monolingual ones.
Second, we validated the two automatically gen-
erated subjectivity resources by using them to build
a tool for subjectivity analysis in the target language.
Specifically, we developed two classifiers: a rule-
based classifier that relies on the subjectivity lexi-
con described in Section 3.1, and a machine learn-
ing classifier trained on the subjectivity-annotated
corpus described in Section 4.1. While the highest
precision for the subjective classification is obtained
with the rule-based classifier, the overall best result
of 67.85 F-measure is due to the machine learning
approach. This result is consistent with the anno-
tation studies, showing that the corpus projections
preserve subjectivity more reliably than the lexicon
translations.
Finally, neither one of the classifiers relies on
language-specific information, but rather on knowl-
edge obtained through projections from English. A
similar method can therefore be used to derive tools
for subjectivity analysis in other languages.
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999282666666667">
Alina Andreevskaia and Sabine Bergler. Mining wordnet for
fuzzy sentiment: Sentiment tag extraction from WordNet
glosses. In Proceedings ofEACL 2006.
Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005.
Emotions from text: Machine learning for text-based emo-
tion prediction. In Proceedings ofHLT/EMNLP 2005.
Krisztian Balog, Gilad Mishne, and Maarten de Rijke. 2006.
Why are they excited? identifying and explaining spikes in
blog mood levels. In EACL-2006.
Andrea Esuli and Fabrizio Sebastiani. 2006. Determining term
subjectivity and term orientation for opinion mining. In Pro-
ceedings the EACL 2006.
Minqing Hu and Bing Liu. 2004. Mining and summarizing
customer reviews. In Proceedings ofACM SIGKDD.
Yi Hu, Jianyong Duan, Xiaoming Chen, Bingzhen Pei, and
Ruzhan Lu. 2005. A new method for sentiment classifi-
cation in text retrieval. In Proceedings ofIJCNLP.
Radu Ion. 2007. Methods for automatic semantic disambigua-
tion. Applications to English and Romanian. Ph.D. thesis,
The Romanian Academy, RACAI.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully auto-
matic lexicon expansion for domain-oriented sentiment anal-
ysis. In Proceedings of EMNLP 2006.
Soo-Min Kim and Eduard Hovy. 2006. Identifying and ana-
lyzing judgment opinions. In Proceedings of HLT/NAACL
2006.
Levon Lloyd, Dimitrios Kechagias, and Steven Skiena. 2005.
Lydia: A system for large-scale news analysis. In Proceed-
ings of SPIRE 2005.
George Miller, Claudia Leacock, Tangee Randee, and Ross
Bunker. 1993. A semantic concordance. In Proceedings
of the DARPA Workshop on Human Language Technology.
Bo Pang and Lillian Lee. 2004. A sentimental education: Sen-
timent analysis using subjectivity summarization based on
minimum cuts. In Proceedings ofACL 2004.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002.
Thumbs up? Sentiment classification using machine learning
techniques. In Proceedings ofEMNLP 2002.
Ellen Riloff and Janyce Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In Proceedings of EMNLP
2003.
Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2006.
Latent variable models for semantic orientations of phrases.
In Proceedings of EACL 2006.
Peter Turney. 2002. Thumbs up or thumbs down? Semantic
orientation applied to unsupervised classification of reviews.
In Proceedings ofACL 2002.
Universal Dictionary. 2007. Available at
www.dicts.info/uddl.php.
Janyce Wiebe and Rada Mihalcea. 2006. Word sense and sub-
jectivity. In Proceedings of COLING-ACL 2006.
Janyce Wiebe and Ellen Riloff. 2005. Creating subjective
and objective sentence classifiers from unannotated texts. In
Proceedings of CICLing 2005 (invited paper). Available at
www.cs.pitt.edu/mpqarequest.
Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.
Annotating expressions of opinions and emotions in lan-
guage. Language Resources and Evaluation, 39(2/3):164–
210. Available at www.cs.pitt.edu/mpqa.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005.
Recognizing contextual polarity in phrase-level sentiment
analysis. In Proceedings of HLT/EMNLP 2005.
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards an-
swering opinion questions: Separating facts from opinions
and identifying the polarity of opinion sentences. In Pro-
ceedings ofEMNLP 2003.
</reference>
<page confidence="0.999077">
983
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.991845">
<title confidence="0.999951">Learning Multilingual Subjective Language via Cross-Lingual Projections</title>
<author confidence="0.999697">Mihalcea Banea Janyce Wiebe</author>
<affiliation confidence="0.999931">Department of Computer Science Department of Computer Science University of North Texas University of Pittsburgh</affiliation>
<email confidence="0.999683">rada@cs.unt.edu,carmenb@unt.eduwiebe@cs.pitt.edu</email>
<abstract confidence="0.9992559">This paper explores methods for generating subjectivity analysis resources in a new language by leveraging on the tools and resources available in English. Given a bridge between English and the selected target language (e.g., a bilingual dictionary or a parallel corpus), the methods can be used to rapidly create tools for subjectivity analysis in the new language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining wordnet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings ofEACL</booktitle>
<contexts>
<context position="4601" citStr="Andreevskaia and Bergler, 2006" startWordPosition="686" endWordPosition="689">are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. Mining wordnet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses. In Proceedings ofEACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecilia Ovesdotter Alm</author>
<author>Dan Roth</author>
<author>Richard Sproat</author>
</authors>
<title>Emotions from text: Machine learning for text-based emotion prediction.</title>
<date>2005</date>
<booktitle>In Proceedings ofHLT/EMNLP</booktitle>
<contexts>
<context position="3164" citStr="Alm et al., 2005" startWordPosition="476" endWordPosition="479"> uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the des</context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In Proceedings ofHLT/EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krisztian Balog</author>
<author>Gilad Mishne</author>
<author>Maarten de Rijke</author>
</authors>
<title>Why are they excited? identifying and explaining spikes in blog mood levels.</title>
<date>2006</date>
<booktitle>In EACL-2006.</booktitle>
<marker>Balog, Mishne, de Rijke, 2006</marker>
<rawString>Krisztian Balog, Gilad Mishne, and Maarten de Rijke. 2006. Why are they excited? identifying and explaining spikes in blog mood levels. In EACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Determining term subjectivity and term orientation for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings the EACL</booktitle>
<contexts>
<context position="3243" citStr="Esuli and Sebastiani, 2006" startWordPosition="488" endWordPosition="491">nd uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage appro</context>
<context position="4630" citStr="Esuli and Sebastiani, 2006" startWordPosition="690" endWordPosition="693"> to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura e</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Determining term subjectivity and term orientation for opinion mining. In Proceedings the EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings ofACM SIGKDD.</booktitle>
<contexts>
<context position="3098" citStr="Hu and Liu, 2004" startWordPosition="468" endWordPosition="471">evel subjectivity classifiers for a new target language. The first uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings ofACM SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Hu</author>
<author>Jianyong Duan</author>
<author>Xiaoming Chen</author>
<author>Bingzhen Pei</author>
<author>Ruzhan Lu</author>
</authors>
<title>A new method for sentiment classification in text retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings ofIJCNLP.</booktitle>
<contexts>
<context position="5315" citStr="Hu et al., 2005" startWordPosition="802" endWordPosition="805">tivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is very time consuming. In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We are not aware of multi-lingual work i</context>
</contexts>
<marker>Hu, Duan, Chen, Pei, Lu, 2005</marker>
<rawString>Yi Hu, Jianyong Duan, Xiaoming Chen, Bingzhen Pei, and Ruzhan Lu. 2005. A new method for sentiment classification in text retrieval. In Proceedings ofIJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Ion</author>
</authors>
<title>Methods for automatic semantic disambiguation.</title>
<date>2007</date>
<booktitle>Applications to English and Romanian. Ph.D. thesis, The Romanian Academy, RACAI.</booktitle>
<contexts>
<context position="15861" citStr="Ion, 2007" startWordPosition="2491" endWordPosition="2492"> by assigning a default Subjective label to all sentences. (More information about the corpus and annotations are given in Section 4 below, where agreement between English and Romanian aligned sentences is also assessed.) As mentioned earlier, due to the lexicon projection process that is performed via a bilingual dictionary, the entries in our Romanian subjectivity lexicon are in a lemmatized form. Consequently, we also lemmatize the gold-standard corpus, to allow for the identification of matches with the lexicon. For this purpose, we use the Romanian lemmatizer developed by Ion and Tufis¸ (Ion, 2007), which has an estimated accuracy of 98%.2 Table 3 shows the results of the rule-based classifier. We show the precision, recall, and F-measure independently measured for the subjective, objective, and all sentences. We also evaluated a variation of the rule-based classifier that labels a sentence as objective if there are at most three weak expressions in the previous, current, and next sentence combined, which raises the recall of the objective classifier. Our attempts to increase the recall of the subjective classifier all resulted in significant loss in precision, and thus we kept the orig</context>
</contexts>
<marker>Ion, 2007</marker>
<rawString>Radu Ion. 2007. Methods for automatic semantic disambiguation. Applications to English and Romanian. Ph.D. thesis, The Romanian Academy, RACAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domain-oriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="5271" citStr="Kanayama and Nasukawa, 2006" startWordPosition="793" endWordPosition="796">NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is very time consuming. In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framewo</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domain-oriented sentiment analysis. In Proceedings of EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying and analyzing judgment opinions.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT/NAACL</booktitle>
<contexts>
<context position="4108" citStr="Kim and Hovy, 2006" startWordPosition="615" endWordPosition="618">cs While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity at</context>
<context position="5365" citStr="Kim and Hovy, 2006" startWordPosition="812" endWordPosition="815">tivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is very time consuming. In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We are not aware of multi-lingual work in subjectivity analysis such as that proposed here</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. In Proceedings of HLT/NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levon Lloyd</author>
<author>Dimitrios Kechagias</author>
<author>Steven Skiena</author>
</authors>
<title>Lydia: A system for large-scale news analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of SPIRE</booktitle>
<contexts>
<context position="2963" citStr="Lloyd et al., 2005" startWordPosition="447" endWordPosition="450">, the methods can be applied to other languages as well. After providing motivations, we present two approaches to developing sentence-level subjectivity classifiers for a new target language. The first uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a</context>
<context position="4908" citStr="Lloyd et al., 2005" startWordPosition="736" endWordPosition="739">ectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on sentiment. There is world-wide interest in text analysis applications. While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data. Creating corpora and lexical resources for a new language is ver</context>
</contexts>
<marker>Lloyd, Kechagias, Skiena, 2005</marker>
<rawString>Levon Lloyd, Dimitrios Kechagias, and Steven Skiena. 2005. Lydia: A system for large-scale news analysis. In Proceedings of SPIRE 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
<author>Claudia Leacock</author>
<author>Tangee Randee</author>
<author>Ross Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the DARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="18784" citStr="Miller et al., 1993" startWordPosition="2949" endWordPosition="2952">bjectivity or sentiment classification, e.g., (Pang et al., 2002; Yu and Hatzivassiloglou, 2003)). The hypothesis is that we can eliminate some of the ambiguities (and consequent loss of subjectivity) observed during the lexicon translation by accounting for the context of the ambiguous words, which is possible in a corpus-based approach. Additionally, we also hope to improve the recall of the classifier, by addressing those cases not covered by the lexicon-based approach. In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al., 1993) and their manual translations into Romanian.3 The corpus consists of roughly 11,000 sentences, with approximately 250,000 tokens on each side. It is a balanced corpus covering a number of topics in sports, politics, fashion, education, and others. 3The translation was carried out by a Romanian native speaker, student in a department of “Foreign Languages and Translations” in Romania. Below, we begin with a manual annotation study to assess the quality of annotation and preservation of subjectivity in translation. We then describe the automatic construction of a target-language training set, a</context>
</contexts>
<marker>Miller, Leacock, Randee, Bunker, 1993</marker>
<rawString>George Miller, Claudia Leacock, Tangee Randee, and Ross Bunker. 1993. A semantic concordance. In Proceedings of the DARPA Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="4066" citStr="Pang and Lee, 2004" startWordPosition="607" endWordPosition="610">7 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may see</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings ofACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings ofEMNLP</booktitle>
<contexts>
<context position="3041" citStr="Pang et al., 2002" startWordPosition="459" endWordPosition="462">ations, we present two approaches to developing sentence-level subjectivity classifiers for a new target language. The first uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and</context>
<context position="18228" citStr="Pang et al., 2002" startWordPosition="2861" endWordPosition="2864">tivity clues, for which the transfer of subjectivity in the translation process was particularly low. 4 A Corpus-Based Approach Given the low number of subjective entries found in the automatically generated lexicon and the subsequent low recall of the lexical classifier, we decided to also explore a second, corpus-based approach. This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus (numerous statistical classifiers have been trained for subjectivity or sentiment classification, e.g., (Pang et al., 2002; Yu and Hatzivassiloglou, 2003)). The hypothesis is that we can eliminate some of the ambiguities (and consequent loss of subjectivity) observed during the lexicon translation by accounting for the context of the ambiguous words, which is possible in a corpus-based approach. Additionally, we also hope to improve the recall of the classifier, by addressing those cases not covered by the lexicon-based approach. In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al., 1993) and their manual translations into Romanian</context>
<context position="27701" citStr="Pang et al., 2002" startWordPosition="4351" endWordPosition="4354">ft with 10,628 sentences that are automatically annotated for subjectivity. Table 6 shows the number of subjective and objective sentences obtained with each classifier. Classifier Subjective Objective All high-precision 1,629 2,334 3,963 high-coverage 5,050 5,578 10,628 Table 6: Subjective and objective training sentences automatically annotated with OpinionFinder. Next, the OpinionFinder annotations are projected onto the Romanian training sentences, which are then used to develop a probabilistic classifier for the automatic labeling of subjectivity in Romanian sentences. Similar to, e.g., (Pang et al., 2002), we use a Naive Bayes algorithm trained on word features cooccurring with the subjective and the objective classifications. We assume word independence, and we use a 0.3 cut-off for feature selection. While recent work has also considered more complex syntactic features, we are not able to generate such features for Romanian as they require tools currently not available for this language. We create two classifiers, one trained on each data set. The quality of the classifiers is evaluated on the 504-sentence Romanian gold-standard corpus described above. Recall that the baseline on this data s</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings ofEMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="6276" citStr="Riloff and Wiebe, 2003" startWordPosition="951" endWordPosition="954">tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We are not aware of multi-lingual work in subjectivity analysis such as that proposed here, in which subjectivity analysis resources developed for one language are used to support developing resources in another. 3 A Lexicon-Based Approach Many subjectivity and sentiment analysis tools rely on manually or semi-automatically constructed lexicons (Yu and Hatzivassiloglou, 2003; Riloff and Wiebe, 2003; Kim and Hovy, 2006). Given the success of such techniques, the first approach we take to generating a target-language subjectivity classifier is to create a subjectivity lexicon by translating an existing source language lexicon, and then build a classifier that relies on the resulting lexicon. Below, we describe the translation process and discuss the results of an annotation study to assess the quality of the translated lexicon. We then describe and evaluate a lexicon-based target-language classifier. 3.1 Translating a Subjectivity Lexicon The subjectivity lexicon we use is from OpinionFin</context>
<context position="13752" citStr="Riloff and Wiebe, 2003" startWordPosition="2156" endWordPosition="2159">sided, completely lose subjectivity once translated, as it becomes in Romanian cu o singura latur˘a, meaning with only one side (as of objects). Interestingly, the reliability of clues in the English lexicon seems to help preserve subjectivity. Out of the 77 entries marked as strong, 11 were judged to be objective in Romanian (14.3%), compared to 14 objective Romanian entries obtained from the 36 weak English clues (39.0%). 3.2 Rule-based Subjectivity Classifier Using a Subjectivity Lexicon Starting with the Romanian lexicon, we developed a lexical classifier similar to the one introduced by (Riloff and Wiebe, 2003). At the core of this method is a high-precision subjectivity and objectivity classifier that can label large amounts of raw text using only a subjectivity lexicon. Their method is further improved with a bootstrapping process that learns extraction patterns. In our experiments, however, we apply only the rule-based classification step, since the extraction step cannot be implemented without tools for syntactic parsing and information extraction not available in Romanian. The classifier relies on three main heuristics to label subjective and objective sentences: (1) if two or more strong subje</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of EMNLP 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Latent variable models for semantic orientations of phrases.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="4451" citStr="Takamura et al., 2006" startWordPosition="663" endWordPosition="666">wo-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments. For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment. These can be detected with subjectivity analysis but not by a method focused only on se</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2006</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2006. Latent variable models for semantic orientations of phrases. In Proceedings of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="3021" citStr="Turney, 2002" startWordPosition="457" endWordPosition="458">roviding motivations, we present two approaches to developing sentence-level subjectivity classifiers for a new target language. The first uses a subjectivity lexicon translated from an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotio</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. In Proceedings ofACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Universal Dictionary</author>
</authors>
<date>2007</date>
<note>Available at www.dicts.info/uddl.php.</note>
<marker>Dictionary, 2007</marker>
<rawString>Universal Dictionary. 2007. Available at www.dicts.info/uddl.php.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<contexts>
<context position="3214" citStr="Wiebe and Mihalcea, 2006" startWordPosition="484" endWordPosition="487">m an English one. The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have</context>
<context position="30750" citStr="Wiebe and Mihalcea, 2006" startWordPosition="4818" endWordPosition="4822">g annotations from an automatically annotated English corpus. These resources were validated in two ways. First, we carried out annotation studies measuring the extent to which subjectivity is preserved across languages in each of the two resources. These studies show that only a relatively small fraction of the entries in the lexicon preserve their subjectivity in the translation, mainly due to the ambiguity in both the source and the target languages. This is consistent with observations made in previous work that subjectivity is a property associated not with words, but with word meanings (Wiebe and Mihalcea, 2006). In contrast, the sentence-level subjectivity was found to be more reliably preserved across languages, with cross-lingual inter-annotator agreements comparable to the monolingual ones. Second, we validated the two automatically generated subjectivity resources by using them to build a tool for subjectivity analysis in the target language. Specifically, we developed two classifiers: a rulebased classifier that relies on the subjectivity lexicon described in Section 3.1, and a machine learning classifier trained on the subjectivity-annotated corpus described in Section 4.1. While the highest p</context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of COLING-ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating subjective and objective sentence classifiers from unannotated texts.</title>
<date>2005</date>
<booktitle>In Proceedings of CICLing</booktitle>
<note>(invited paper). Available at www.cs.pitt.edu/mpqarequest.</note>
<contexts>
<context position="6904" citStr="Wiebe and Riloff, 2005" startWordPosition="1048" endWordPosition="1051"> and Hovy, 2006). Given the success of such techniques, the first approach we take to generating a target-language subjectivity classifier is to create a subjectivity lexicon by translating an existing source language lexicon, and then build a classifier that relies on the resulting lexicon. Below, we describe the translation process and discuss the results of an annotation study to assess the quality of the translated lexicon. We then describe and evaluate a lexicon-based target-language classifier. 3.1 Translating a Subjectivity Lexicon The subjectivity lexicon we use is from OpinionFinder (Wiebe and Riloff, 2005), an English subjectivity analysis system which, among other things, classifies sentences as subjective or objective. The lexicon was compiled from manually developed resources augmented with entries learned from corpora. It contains 6,856 unique entries, out of which 990 are multi-word expressions. The entries in the lexicon have been labeled for part of speech, and for reliability – those that appear most often in subjective contexts are strong clues of subjectivity, while those that appear less often, but still more often than expected by chance, are labeled weak. To perform the translation</context>
<context position="11033" citStr="Wiebe and Riloff, 2005" startWordPosition="1696" endWordPosition="1699">original English form. The table Romanian English attributes infrumuset¸a beautifying strong, verb notabil notable weak, adj plin de regret full of regrets strong, adj sclav slaves weak,noun Table 1: Examples of entries in the Romanian subjectivity lexicon also shows the reliability of the expression (weak or strong) and the part of speech – attributes that are provided in the English subjectivity lexicon. Manual Evaluation. We want to assess the quality of the translated lexicon, and compare it to the quality of the original English lexicon. The English subjectivity lexicon was evaluated in (Wiebe and Riloff, 2005) against a corpus of English-language news articles manually annotated for subjectivity (the MPQA corpus (Wiebe et al., 2005)). According to this evaluation, 85% of the instances of the clues marked as strong and 71.5% of the clues marked as weak are in subjective sentences in the MPQA corpus. Since there is no comparable Romanian corpus, an alternate way to judge the subjectivity of a Romanian lexicon entry is needed. Two native speakers of Romanian annotated the subjectivity of 150 randomly selected entries. Each annotator independently read approximately 100 examples of each drawn from the </context>
<context position="16807" citStr="Wiebe and Riloff, 2005" startWordPosition="2642" endWordPosition="2645">e at most three weak expressions in the previous, current, and next sentence combined, which raises the recall of the objective classifier. Our attempts to increase the recall of the subjective classifier all resulted in significant loss in precision, and thus we kept the original heuristic. In its original English implementation, this system was proposed as being high-precision but low coverage. Evaluated on the MPQA corpus, it has subjective precision of 90.4, subjective recall of 34.2, objective precision of 82.4, and objective recall of 30.7; overall, precision is 86.7 and recall is 32.6 (Wiebe and Riloff, 2005). We see a similar behavior on Romanian for subjective sentences. The subjective precision is good, albeit at the cost of low 2Dan Tufis¸, personal communication. 979 Measure Subjective Objective All subj = at least two strong; obj = at most two weak Precision 80.00 56.50 62.59 Recall 20.51 48.91 33.53 F-measure 32.64 52.52 43.66 subj = at least two strong; obj = at most three weak Precision 80.00 56.85 61.94 Recall 20.51 61.03 39.08 F-measure 32.64 58.86 47.93 Table 3: Evaluation of the rule-based classifier recall, and thus the classifier could be used to harvest subjective sentences from un</context>
<context position="26844" citStr="Wiebe and Riloff, 2005" startWordPosition="4225" endWordPosition="4228">der uses the clues of the subjectivity lexicon to harvest subjective and objective sentences from a large amount of unannotated text; this data is then used to automatically identify a set of extraction patterns, which are then used iteratively to identify a larger set of subjective and objective sentences. In addition, in OpinionFinder, the high-precision classifier is used to produce an English labeled data set for training, which is used to generate its Naive Bayes high-coverage subjectivity classifier. Table 5 shows the performance of the two classifiers on the MPQA corpus as reported in (Wiebe and Riloff, 2005). Note that 55% of the sentences in the MPQA corpus are subjective – which represents the baseline for this data set. The two OpinionFinder classifiers are used to label the training corpus. After removing the 504 test sentences, we are left with 10,628 sentences that are automatically annotated for subjectivity. Table 6 shows the number of subjective and objective sentences obtained with each classifier. Classifier Subjective Objective All high-precision 1,629 2,334 3,963 high-coverage 5,050 5,578 10,628 Table 6: Subjective and objective training sentences automatically annotated with Opinion</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating subjective and objective sentence classifiers from unannotated texts. In Proceedings of CICLing 2005 (invited paper). Available at www.cs.pitt.edu/mpqarequest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2/3):164– 210. Available at www.cs.pitt.edu/mpqa.</title>
<date>2005</date>
<contexts>
<context position="11158" citStr="Wiebe et al., 2005" startWordPosition="1716" endWordPosition="1719"> de regret full of regrets strong, adj sclav slaves weak,noun Table 1: Examples of entries in the Romanian subjectivity lexicon also shows the reliability of the expression (weak or strong) and the part of speech – attributes that are provided in the English subjectivity lexicon. Manual Evaluation. We want to assess the quality of the translated lexicon, and compare it to the quality of the original English lexicon. The English subjectivity lexicon was evaluated in (Wiebe and Riloff, 2005) against a corpus of English-language news articles manually annotated for subjectivity (the MPQA corpus (Wiebe et al., 2005)). According to this evaluation, 85% of the instances of the clues marked as strong and 71.5% of the clues marked as weak are in subjective sentences in the MPQA corpus. Since there is no comparable Romanian corpus, an alternate way to judge the subjectivity of a Romanian lexicon entry is needed. Two native speakers of Romanian annotated the subjectivity of 150 randomly selected entries. Each annotator independently read approximately 100 examples of each drawn from the Web, including a large number from news sources. The subjectivity of a word was consequently judged in the contexts where it </context>
<context position="15099" citStr="Wiebe et al., 2005" startWordPosition="2368" endWordPosition="2371">in a sentence, and at most two weak subjective expressions occur in the previous, current, and next sentence combined, then the sentence is labeled Objective; (3) otherwise, if none of the previous rules apply, the sentence is labeled Unknown. The quality of the classifier was evaluated on a Romanian gold-standard corpus annotated for subjectivity. Two native Romanian speakers (Rol and Roe) manually annotated the subjectivity of the sentences of five randomly selected documents (504 sentences) from the Romanian side of an EnglishRomanian parallel corpus, according to the annotation scheme in (Wiebe et al., 2005). Agreement between annotators was measured, and then their differences were adjudicated. The baseline on this data set is 54.16%, which can be obtained by assigning a default Subjective label to all sentences. (More information about the corpus and annotations are given in Section 4 below, where agreement between English and Romanian aligned sentences is also assessed.) As mentioned earlier, due to the lexicon projection process that is performed via a bilingual dictionary, the entries in our Romanian subjectivity lexicon are in a lemmatized form. Consequently, we also lemmatize the gold-stan</context>
<context position="21329" citStr="Wiebe et al., 2005" startWordPosition="3365" endWordPosition="3368">Lenin, would it be permanent ? [ro] S˘a presupunem c˘a ar fi as¸ezat al˘aturi de Lenin, oare va fi pentru totdeauna? The following are examples of objective parallel sentences. [en]The Pirates have a 9-6 record this year and the Redbirds are 7-9. [ro] Pirat¸ii au un palmares de 9 la 6 anul acesta si P˘as˘arile Ros¸ii au 7 la 9. [en] One of the obstacles to the easy control of a 2-year old child is a lack of verbal communication. [ro] Unul dintre obstacolele in controlarea unui copil de 2 ani este lipsa comunic˘arii verbale. 980 The annotators were trained using the MPQA annotation guidelines (Wiebe et al., 2005). The tagset consists of S(ubjective), O(bjective) and U(ncertain). For the U tags, a class was also given; OU means, for instance, that the annotator is uncertain but she is leaning toward O. Table 4 shows the pairwise agreement figures and the Kappa (K) calculated for the three annotators. The table also shows the agreement when the borderline uncertain cases are removed. all sentences Uncertain removed pair agree κ agree κ (%) removed Ro1 &amp; Ro2 0.83 0.67 0.89 0.77 23 En &amp; Ro1 0.77 0.54 0.86 0.73 26 En &amp; Ro2 0.78 0.55 0.91 0.82 20 Table 4: Agreement on the data set of 173 sentences. Annotati</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2/3):164– 210. Available at www.cs.pitt.edu/mpqa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP</booktitle>
<contexts>
<context position="4087" citStr="Wilson et al., 2005" startWordPosition="611" endWordPosition="614">mputational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006). In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification. This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006). Second, an NLP application may seek a wide range of typ</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of HLT/EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings ofEMNLP</booktitle>
<contexts>
<context position="3299" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="495" endWordPosition="498">llel corpus to create target-language training data for developing a statistical classifier. 2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003). 976 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976–983, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons. First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances a</context>
<context position="6252" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="947" endWordPosition="950">y create subjectivity analysis tools for a new one. This motivates our exploration and use of cross-lingual lexicon translations and annotation projections. Most if not all work on subjectivity analysis has been carried out in a monolingual framework. We are not aware of multi-lingual work in subjectivity analysis such as that proposed here, in which subjectivity analysis resources developed for one language are used to support developing resources in another. 3 A Lexicon-Based Approach Many subjectivity and sentiment analysis tools rely on manually or semi-automatically constructed lexicons (Yu and Hatzivassiloglou, 2003; Riloff and Wiebe, 2003; Kim and Hovy, 2006). Given the success of such techniques, the first approach we take to generating a target-language subjectivity classifier is to create a subjectivity lexicon by translating an existing source language lexicon, and then build a classifier that relies on the resulting lexicon. Below, we describe the translation process and discuss the results of an annotation study to assess the quality of the translated lexicon. We then describe and evaluate a lexicon-based target-language classifier. 3.1 Translating a Subjectivity Lexicon The subjectivity lexicon w</context>
<context position="18260" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="2865" endWordPosition="2868">hich the transfer of subjectivity in the translation process was particularly low. 4 A Corpus-Based Approach Given the low number of subjective entries found in the automatically generated lexicon and the subsequent low recall of the lexical classifier, we decided to also explore a second, corpus-based approach. This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus (numerous statistical classifiers have been trained for subjectivity or sentiment classification, e.g., (Pang et al., 2002; Yu and Hatzivassiloglou, 2003)). The hypothesis is that we can eliminate some of the ambiguities (and consequent loss of subjectivity) observed during the lexicon translation by accounting for the context of the ambiguous words, which is possible in a corpus-based approach. Additionally, we also hope to improve the recall of the classifier, by addressing those cases not covered by the lexicon-based approach. In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al., 1993) and their manual translations into Romanian.3 The corpus consists of roughl</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings ofEMNLP 2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>