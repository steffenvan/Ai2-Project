<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.032492">
<title confidence="0.972811">
Evaluating Word Prediction: Framing Keystroke Savings
</title>
<author confidence="0.997954">
Keith Trnka and Kathleen F. McCoy
</author>
<affiliation confidence="0.998235">
University of Delaware
</affiliation>
<address confidence="0.943898">
Newark, DE 19716
</address>
<email confidence="0.999505">
trnka@cis.udel.edu
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999042923076923">
Researchers typically evaluate word predic-
tion using keystroke savings, however, this
measure is not straightforward. We present
several complications in computing keystroke
savings which may affect interpretation and
comparison of results. We address this prob-
lem by developing two gold standards as a
frame for interpretation. These gold standards
measure the maximum keystroke savings un-
der two different approximations of an ideal
language model. The gold standards addition-
ally narrow the scope of deficiencies in a word
prediction system.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908085714286">
Word prediction is an application of language mod-
eling to speeding up text entry, especially to entering
utterances to be spoken by an Augmentative and Al-
ternative Communication (AAC) device. AAC de-
vices seek to address the dual problem of speech and
motor impairment by attempting to optimize text in-
put. Even still, communication rates with AAC de-
vices are often below 10 words per minute (Newell
et al., 1998), compared to the common 130-200
words per minute speech rate of speaking people.
Word prediction addresses these issues by reducing
the number of keystrokes required to produce a mes-
sage, which has been shown to improve communi-
cation rate (Trnka et al., 2007). The reduction in
keystrokes also translates into a lower degree of fa-
tigue from typing all day (Carlberger et al., 1997).
Word prediction systems present multiple com-
pletions of the current word to the user. Systems
generate a list of W predictions on the basis of the
word being typed and a language model. The vo-
cabulary is filtered to match the prefix of the current
word and the language model ranks the words ac-
cording to their likelihood. In the case that no letters
of the current word have been entered, the language
model is the sole factor in generating predictions.
Systems often use a touchscreen or function/number
keys to select any of the predicted words.
Because the goal of word prediction systems is
to reduce the number of keystrokes, the primary
evaluation for word prediction is keystroke savings
(Garay-Vitoria and Abascal, 2006; Newell et al.,
1998; Li and Hirst, 2005; Trnka and McCoy, 2007;
Carlberger et al., 1997). Keystroke savings (KS)
measures the percentage reduction in keys pressed
compared to letter-by-letter text entry.
</bodyText>
<equation confidence="0.805123666666667">
keysnormal − keyswith prediction
KS =
keysnormal
</equation>
<bodyText confidence="0.999817857142857">
A word prediction system that offers higher savings
will benefit a user more in practice.
However, the equation for keystroke savings has
two major deficiencies. Firstly, the equation alone
is not enough to compute keystroke savings — actu-
ally computing keystroke savings requires a precise
definition of a keystroke and also requires a method
for determining how many keystrokes are used when
predictions are available, discussed in Section 2. Be-
yond simply computing keystroke savings, the equa-
tion alone does not provide much in the way of inter-
pretation — is 60% keystroke savings good? Can we
do better? Section 3 will present two gold standards
to allow better interpretation of keystroke savings.
</bodyText>
<equation confidence="0.907956">
X 100%
</equation>
<page confidence="0.928473">
261
</page>
<affiliation confidence="0.275076">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 261–264,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</affiliation>
<sectionHeader confidence="0.899064" genericHeader="method">
2 Computing Keystroke Savings
</sectionHeader>
<bodyText confidence="0.999975557692308">
We must have a way to determine how many
keystrokes a user would take under both letter-
by-letter entry and word prediction to compute
keystroke savings. The common trend in research
is to simulate a “perfect” user that will never make
typing mistakes and will select a word from the pre-
dictions as soon as it appears.
Implementation of perfect utilization of the pre-
dictions is not always straightforward. For exam-
ple, consider the predictive interface in Microsoft
WordTM: a single prediction is offered as an inline
completion. If the prediction is selected, the user
may backspace and edit the word. However, this
freedom makes finding the minimum sequence of
keys more difficult — now the user may select a
prediction with the incorrect suffix and correct the
suffix as the optimal action. We feel that a more in-
tuitive interface would allow a user to undo the pre-
diction selection by pressing backspace, an interface
which does not support backspace-editing. In addi-
tion to backspacing, future research in multi-word
prediction will face a similar problem, analogous to
the garden-path problem in parsing, where a greedy
approach does not always give the optimal result.
The keystrokes used for training and testing word
prediction systems can affect the results. We at-
tempt to evaluate word prediction as realistically as
possible. Firstly, many corpora have punctuation
marks, but an AAC user in a conversational setting
is unlikely to use punctuation due to the high cost
of each key press. Therefore, we remove punctua-
tion on the outside of words, such as commas and
periods, but leave word-internal punctuation intact.
Also, we treat capital letters as a single key press,
reflecting the trend of many AAC users to avoid cap-
italization. Another problem occurs for a newline or
“speak key”, which the user would press after com-
pleting an utterance. In pilot studies, including the
simulation of a speak key lowered keystroke savings
by 0.8–1.0% for window sizes 1–10, because new-
lines are not able to be predicted in the system. How-
ever, we feel that the simulation of a speak key will
produce an evaluation metric that is closer to the ac-
tual user’s experience, therefore we include a speak
key in our evaluations.
An evaluation of word prediction must address
these issues, if only implicitly. The effect of these
potentially implicit decisions on keystroke savings
can make comparison of results difficult. However,
if results are presented in reference to a gold stan-
dard under the same assumptions, we can draw more
reliable conclusions from results.
</bodyText>
<sectionHeader confidence="0.894723" genericHeader="method">
3 Towards a Gold Standard
</sectionHeader>
<bodyText confidence="0.999966346153846">
In trying to improve the state of word prediction,
several researchers have noted that it seems ex-
tremely difficult to improve keystroke savings be-
yond a certain point. Copestake (1997) discussed
the entropy of English to conclude that 50–60%
keystroke savings may be the most we can expect
in practice. Lesher et al. (2002) replaced the lan-
guage model in a word prediction system with a
human to try and estimate the limit of keystroke
savings. They found that humans could achieve
59% keystroke savings with access to their ad-
vanced language model and that their advanced lan-
guage model alone achieved 54% keystroke savings.
They noted that one subject achieved nearly 70%
keystroke savings on one particular text, and con-
cluded that further improvements on current meth-
ods are possible. Garay-Vitoria and Abascal (2006)
survey many prediction systems, showing a wide
spectrum of savings, but no system offers more than
70% keystroke savings.
We investigated the problem of the limitations
of keystroke savings first from a theoretical per-
spective, seeking a clearly defined upper boundary.
Keystroke savings can never reach 100% — it would
mean that the system divined the entire text they in-
tended without a single key.
</bodyText>
<subsectionHeader confidence="0.99798">
3.1 Theoretical keystroke savings limit
</subsectionHeader>
<bodyText confidence="0.999813545454545">
The minimum amount of input required corresponds
to a perfect system — one that predicts every word
as soon as possible. In a word completion sys-
tem, the predictions are delayed until after the first
character of the word is entered. In such a sys-
tem, the minimum amount of input using a perfect
language model is two keystrokes per word — one
for the first letter and one to select the prediction.
The system would also require one keystroke per
sentence. In a word prediction system, the predic-
tions are available immediately, so the minimal in-
</bodyText>
<page confidence="0.983981">
262
</page>
<bodyText confidence="0.999869454545455">
put for a perfect system is one keystroke per word
(to select the prediction) and one keystroke per sen-
tence. We added the ability to measure the minimum
number of keystrokes and maximum savings to our
simulation software, which we call the theoretical
keystroke savings limit.
We evaluated a baseline trigram model under two
conditions with different keystroke requirements on
the Switchboard corpus. The simulation software
was modified to output the theoretical limit in ad-
dition to actual keystroke savings at various window
sizes. To demonstrate the effect of the theoretical
keystroke savings limit on actual savings, we eval-
uated the trigram model under conditions with two
different limits — word prediction and word com-
pletion. The evaluation of the trigram model using
word completion is shown in Figure 1. The actual
keystroke savings is graphed by window size in ref-
erence to the theoretical limit. As noted by other re-
searchers, keystroke savings increases with window
size, but with diminishing returns (this is the effect
of placing the most probable words first). One of
</bodyText>
<figure confidence="0.883797">
1 2 3 4 5 6 7 8 9 10
Window size
</figure>
<figureCaption confidence="0.977996">
Figure 1: Keystroke savings and the limit vs. window
size for word completion.
</figureCaption>
<bodyText confidence="0.999872333333334">
the problems with word completion is that the the-
oretical limit is so close to actual performance —
around 58.5% keystroke savings compared to 50.8%
keystroke savings with five predictions. At only five
predictions, the system has already realized 87% of
the possible keystroke savings. Under these circum-
stances, it would take a drastic change in the lan-
guage model to impact keystroke savings.
We repeated this analysis for word prediction,
shown in Figure 2 alongside word completion. Word
prediction is much higher than completion, both the-
oretically (the limit) and in actual keystroke savings.
</bodyText>
<figure confidence="0.9265585">
1 2 3 4 5 6 7 8 9 10
Window size
</figure>
<figureCaption confidence="0.9455125">
Figure 2: Keystroke savings and the limit vs. window
size for word prediction compared to word completion.
</figureCaption>
<bodyText confidence="0.99969725">
Word prediction offers much more headroom in
terms of improvements in keystroke savings. There-
fore our ongoing research will focus on word pre-
diction over word completion.
This analysis demonstrates a limit to keystroke
savings, but this limit is slightly different than
Copestake (1997) and Lesher et al. (2002) seek to
describe — beyond the limitations of the user in-
terface, there seems to be a limitation on the pre-
dictability of English. Ideally, we would like to have
a gold standard that is a closer estimate of an ideal
language model.
</bodyText>
<subsectionHeader confidence="0.998992">
3.2 Vocabulary limit
</subsectionHeader>
<bodyText confidence="0.9998911">
We can derive a more practical limit by simulating
word prediction using a perfect model of all words
that occur in the training data. This gold standard
will predict the correct word immediately so long as
it occurs in the training corpus. Words that never oc-
curred in training require letter-by-letter entry. We
call this measure the vocabulary limit and apply it to
evaluate whether the difference between training and
testing vocabulary is significant. Previous research
has focused on the percentage of out-of-vocabulary
(OOV) terms to explain changes in keystroke sav-
ings (Trnka and McCoy, 2007; Wandmacher and
Antoine, 2006). In contrast, the vocabulary limit
gives more guidance for research by translating the
problem of OOVs into keystroke savings.
Expanding the results from the theoretical limit,
the vocabulary limit is 77.6% savings, compared to
78.4% savings for the theoretical limit and 58.7%
actual keystroke savings with 5 predictions. The
practical limit is very close to the theoretical limit
</bodyText>
<figure confidence="0.9989775">
Keystroke savings
60%
50%
40%
30%
20%
10%
0%
Word completion
Theoretical limit
60%
50%
40%
30%
20%
10%
0%
80%
70%
Word prediction
Word prediction limit
Word completion
Word completion limit
Keystroke savings
</figure>
<page confidence="0.998316">
263
</page>
<bodyText confidence="0.999983">
in the case of Switchboard. Therefore, the remain-
ing gap between the practical limit and actual per-
formance must be due to other differences between
testing and training data, limitations of the model,
and limitations of language modeling.
</bodyText>
<subsectionHeader confidence="0.999494">
3.3 Application to corpus studies
</subsectionHeader>
<bodyText confidence="0.99443425">
We applied the gold standards to our corpus study, in
which a trigram model was individually trained and
tested on several different corpora (Trnka and Mc-
Coy, 2007). In contrast to the actual trigram model
</bodyText>
<table confidence="0.999185666666667">
Corpus Trigram Vocab. Theor.
limit limit
AAC Email 48.92% 61.94% 84.83%
Callhome 43.76% 54.62% 81.38%
Charlotte 48.30% 65.69% 83.74%
SBCSAE 42.30% 60.81% 79.86%
Micase 49.00% 69.18% 84.08%
Switchboard 60.35% 80.33% 82.57%
Slate 53.13% 81.61% 85.88%
</table>
<tableCaption confidence="0.999854">
Table 1: A trigram model compared to the limits.
</tableCaption>
<bodyText confidence="0.999949117647059">
performance, the theoretical limits all fall within a
relatively narrow range, suggesting that the achiev-
able keystroke savings may be similar even across
different domains. The more technical and formal
corpora (Micase, Slate, AAC) show higher limits, as
the theoretical limit is based on the length of words
and sentences in each corpus. The practical limit
exhibits much greater variation. Unlike the Switch-
board analysis, many other corpora have a substan-
tial gap between the theoretical and practical limits.
Although the practical measure seems to match the
actual savings similarly to OOVs testing with cross-
validation (Trnka and McCoy, 2007), this measure
more concretely illustrates the effect of OOVs on
actual keystroke savings — 60% keystroke savings
when training and testing on AAC Email would be
extraordinary.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999986388888889">
Although keystroke savings is the predominant eval-
uation for word prediction, this evaluation is not
straightforward, exacerbating the problem of inter-
preting and comparing results. We have presented
a novel solution — interpreting results alongside
gold standards which capture the difficulty of the
evaluation. These gold standards are also applica-
ble to drive future research — if actual performance
is very close to the theoretical limit, then relaxing
the minimum keystroke requirements should be the
most beneficial (e.g., multi-word prediction). Sim-
ilarly, if actual performance is very close to the
vocabulary limit, then the vocabulary of the lan-
guage model must be improved (e.g., cache mod-
eling, adding general-purpose training data). In the
case that keystroke savings is far from either limit,
then research into improving the language model is
likely to be the most beneficial.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.989599">
This work was supported by US Department of Ed-
ucation grant H113G040051.
</bodyText>
<sectionHeader confidence="0.99892" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99923">
Alice Carlberger, John Carlberger, Tina Magnuson,
M. Sharon Hunnicutt, Sira Palazuelos-Cagigas, and
Santiago Aguilera Navarro. 1997. Profet, a new gen-
eration of word prediction: An evaluation study. In
ACL-97 workshop on Natural Language Processing
for Communication Aids.
Ann Copestake. 1997. Augmented and alternative NLP
techniques for augmentative and alternative commu-
nication. In ACL-97 workshop on Natural Language
Processing for Communication Aids, pages 37–42.
Nestor Garay-Vitoria and Julio Abascal. 2006. Text pre-
diction systems: a survey. Univ Access Inf Soc, 4:183–
203.
Gregory W. Lesher, Bryan J. Moulton, D Jeffery Higgin-
botham, and Brenna Alsofrom. 2002. Limits of hu-
man word prediction performance. In CSUN.
Jianhua Li and Graeme Hirst. 2005. Semantic knowl-
edge in word completion. In ASSETS, pages 121–128.
Alan Newell, Stefan Langer, and Marianne Hickey. 1998.
The rˆole of natural language processing in alternative
and augmentative communication. Natural Language
Engineering, 4(1):1–16.
Keith Trnka and Kathleen F. McCoy. 2007. Corpus Stud-
ies in Word Prediction. In ASSETS, pages 195–202.
Keith Trnka, Debra Yarrington, John McCaw, Kathleen F.
McCoy, and Christopher Pennington. 2007. The Ef-
fects of Word Prediction on Communication Rate for
AAC. In NAACL-HLT; Companion Volume: Short Pa-
pers, pages 173–176.
Tonio Wandmacher and Jean-Yves Antoine. 2006.
Training Language Models without Appropriate Lan-
guage Resources: Experiments with an AAC System
for Disabled People. In Eurospeech.
</reference>
<page confidence="0.998209">
264
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.943962">
<title confidence="0.999968">Evaluating Word Prediction: Framing Keystroke Savings</title>
<author confidence="0.999915">Keith Trnka</author>
<author confidence="0.999915">Kathleen F McCoy</author>
<affiliation confidence="0.999971">University of Delaware</affiliation>
<address confidence="0.953347">Newark, DE 19716</address>
<email confidence="0.999523">trnka@cis.udel.edu</email>
<abstract confidence="0.999322142857143">Researchers typically evaluate word prediction using keystroke savings, however, this measure is not straightforward. We present several complications in computing keystroke savings which may affect interpretation and comparison of results. We address this problem by developing two gold standards as a frame for interpretation. These gold standards measure the maximum keystroke savings under two different approximations of an ideal language model. The gold standards additionally narrow the scope of deficiencies in a word prediction system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alice Carlberger</author>
<author>John Carlberger</author>
<author>Tina Magnuson</author>
<author>M Sharon Hunnicutt</author>
<author>Sira Palazuelos-Cagigas</author>
<author>Santiago Aguilera Navarro</author>
</authors>
<title>Profet, a new generation of word prediction: An evaluation study.</title>
<date>1997</date>
<booktitle>In ACL-97 workshop on Natural Language Processing for Communication Aids.</booktitle>
<contexts>
<context position="1510" citStr="Carlberger et al., 1997" startWordPosition="231" endWordPosition="234">ication (AAC) device. AAC devices seek to address the dual problem of speech and motor impairment by attempting to optimize text input. Even still, communication rates with AAC devices are often below 10 words per minute (Newell et al., 1998), compared to the common 130-200 words per minute speech rate of speaking people. Word prediction addresses these issues by reducing the number of keystrokes required to produce a message, which has been shown to improve communication rate (Trnka et al., 2007). The reduction in keystrokes also translates into a lower degree of fatigue from typing all day (Carlberger et al., 1997). Word prediction systems present multiple completions of the current word to the user. Systems generate a list of W predictions on the basis of the word being typed and a language model. The vocabulary is filtered to match the prefix of the current word and the language model ranks the words according to their likelihood. In the case that no letters of the current word have been entered, the language model is the sole factor in generating predictions. Systems often use a touchscreen or function/number keys to select any of the predicted words. Because the goal of word prediction systems is to</context>
</contexts>
<marker>Carlberger, Carlberger, Magnuson, Hunnicutt, Palazuelos-Cagigas, Navarro, 1997</marker>
<rawString>Alice Carlberger, John Carlberger, Tina Magnuson, M. Sharon Hunnicutt, Sira Palazuelos-Cagigas, and Santiago Aguilera Navarro. 1997. Profet, a new generation of word prediction: An evaluation study. In ACL-97 workshop on Natural Language Processing for Communication Aids.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Augmented and alternative NLP techniques for augmentative and alternative communication.</title>
<date>1997</date>
<booktitle>In ACL-97 workshop on Natural Language Processing for Communication Aids,</booktitle>
<pages>37--42</pages>
<contexts>
<context position="6173" citStr="Copestake (1997)" startWordPosition="993" endWordPosition="994">experience, therefore we include a speak key in our evaluations. An evaluation of word prediction must address these issues, if only implicitly. The effect of these potentially implicit decisions on keystroke savings can make comparison of results difficult. However, if results are presented in reference to a gold standard under the same assumptions, we can draw more reliable conclusions from results. 3 Towards a Gold Standard In trying to improve the state of word prediction, several researchers have noted that it seems extremely difficult to improve keystroke savings beyond a certain point. Copestake (1997) discussed the entropy of English to conclude that 50–60% keystroke savings may be the most we can expect in practice. Lesher et al. (2002) replaced the language model in a word prediction system with a human to try and estimate the limit of keystroke savings. They found that humans could achieve 59% keystroke savings with access to their advanced language model and that their advanced language model alone achieved 54% keystroke savings. They noted that one subject achieved nearly 70% keystroke savings on one particular text, and concluded that further improvements on current methods are possi</context>
<context position="10028" citStr="Copestake (1997)" startWordPosition="1634" endWordPosition="1635">s analysis for word prediction, shown in Figure 2 alongside word completion. Word prediction is much higher than completion, both theoretically (the limit) and in actual keystroke savings. 1 2 3 4 5 6 7 8 9 10 Window size Figure 2: Keystroke savings and the limit vs. window size for word prediction compared to word completion. Word prediction offers much more headroom in terms of improvements in keystroke savings. Therefore our ongoing research will focus on word prediction over word completion. This analysis demonstrates a limit to keystroke savings, but this limit is slightly different than Copestake (1997) and Lesher et al. (2002) seek to describe — beyond the limitations of the user interface, there seems to be a limitation on the predictability of English. Ideally, we would like to have a gold standard that is a closer estimate of an ideal language model. 3.2 Vocabulary limit We can derive a more practical limit by simulating word prediction using a perfect model of all words that occur in the training data. This gold standard will predict the correct word immediately so long as it occurs in the training corpus. Words that never occurred in training require letter-by-letter entry. We call thi</context>
</contexts>
<marker>Copestake, 1997</marker>
<rawString>Ann Copestake. 1997. Augmented and alternative NLP techniques for augmentative and alternative communication. In ACL-97 workshop on Natural Language Processing for Communication Aids, pages 37–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nestor Garay-Vitoria</author>
<author>Julio Abascal</author>
</authors>
<title>Text prediction systems: a survey. Univ Access Inf Soc,</title>
<date>2006</date>
<pages>4--183</pages>
<contexts>
<context position="2240" citStr="Garay-Vitoria and Abascal, 2006" startWordPosition="354" endWordPosition="357">erate a list of W predictions on the basis of the word being typed and a language model. The vocabulary is filtered to match the prefix of the current word and the language model ranks the words according to their likelihood. In the case that no letters of the current word have been entered, the language model is the sole factor in generating predictions. Systems often use a touchscreen or function/number keys to select any of the predicted words. Because the goal of word prediction systems is to reduce the number of keystrokes, the primary evaluation for word prediction is keystroke savings (Garay-Vitoria and Abascal, 2006; Newell et al., 1998; Li and Hirst, 2005; Trnka and McCoy, 2007; Carlberger et al., 1997). Keystroke savings (KS) measures the percentage reduction in keys pressed compared to letter-by-letter text entry. keysnormal − keyswith prediction KS = keysnormal A word prediction system that offers higher savings will benefit a user more in practice. However, the equation for keystroke savings has two major deficiencies. Firstly, the equation alone is not enough to compute keystroke savings — actually computing keystroke savings requires a precise definition of a keystroke and also requires a method f</context>
<context position="6810" citStr="Garay-Vitoria and Abascal (2006)" startWordPosition="1096" endWordPosition="1099">ussed the entropy of English to conclude that 50–60% keystroke savings may be the most we can expect in practice. Lesher et al. (2002) replaced the language model in a word prediction system with a human to try and estimate the limit of keystroke savings. They found that humans could achieve 59% keystroke savings with access to their advanced language model and that their advanced language model alone achieved 54% keystroke savings. They noted that one subject achieved nearly 70% keystroke savings on one particular text, and concluded that further improvements on current methods are possible. Garay-Vitoria and Abascal (2006) survey many prediction systems, showing a wide spectrum of savings, but no system offers more than 70% keystroke savings. We investigated the problem of the limitations of keystroke savings first from a theoretical perspective, seeking a clearly defined upper boundary. Keystroke savings can never reach 100% — it would mean that the system divined the entire text they intended without a single key. 3.1 Theoretical keystroke savings limit The minimum amount of input required corresponds to a perfect system — one that predicts every word as soon as possible. In a word completion system, the pred</context>
</contexts>
<marker>Garay-Vitoria, Abascal, 2006</marker>
<rawString>Nestor Garay-Vitoria and Julio Abascal. 2006. Text prediction systems: a survey. Univ Access Inf Soc, 4:183– 203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory W Lesher</author>
<author>Bryan J Moulton</author>
<author>D Jeffery Higginbotham</author>
<author>Brenna Alsofrom</author>
</authors>
<title>Limits of human word prediction performance.</title>
<date>2002</date>
<booktitle>In CSUN.</booktitle>
<contexts>
<context position="6312" citStr="Lesher et al. (2002)" startWordPosition="1015" endWordPosition="1018">plicitly. The effect of these potentially implicit decisions on keystroke savings can make comparison of results difficult. However, if results are presented in reference to a gold standard under the same assumptions, we can draw more reliable conclusions from results. 3 Towards a Gold Standard In trying to improve the state of word prediction, several researchers have noted that it seems extremely difficult to improve keystroke savings beyond a certain point. Copestake (1997) discussed the entropy of English to conclude that 50–60% keystroke savings may be the most we can expect in practice. Lesher et al. (2002) replaced the language model in a word prediction system with a human to try and estimate the limit of keystroke savings. They found that humans could achieve 59% keystroke savings with access to their advanced language model and that their advanced language model alone achieved 54% keystroke savings. They noted that one subject achieved nearly 70% keystroke savings on one particular text, and concluded that further improvements on current methods are possible. Garay-Vitoria and Abascal (2006) survey many prediction systems, showing a wide spectrum of savings, but no system offers more than 70</context>
<context position="10053" citStr="Lesher et al. (2002)" startWordPosition="1637" endWordPosition="1640">rediction, shown in Figure 2 alongside word completion. Word prediction is much higher than completion, both theoretically (the limit) and in actual keystroke savings. 1 2 3 4 5 6 7 8 9 10 Window size Figure 2: Keystroke savings and the limit vs. window size for word prediction compared to word completion. Word prediction offers much more headroom in terms of improvements in keystroke savings. Therefore our ongoing research will focus on word prediction over word completion. This analysis demonstrates a limit to keystroke savings, but this limit is slightly different than Copestake (1997) and Lesher et al. (2002) seek to describe — beyond the limitations of the user interface, there seems to be a limitation on the predictability of English. Ideally, we would like to have a gold standard that is a closer estimate of an ideal language model. 3.2 Vocabulary limit We can derive a more practical limit by simulating word prediction using a perfect model of all words that occur in the training data. This gold standard will predict the correct word immediately so long as it occurs in the training corpus. Words that never occurred in training require letter-by-letter entry. We call this measure the vocabulary </context>
</contexts>
<marker>Lesher, Moulton, Higginbotham, Alsofrom, 2002</marker>
<rawString>Gregory W. Lesher, Bryan J. Moulton, D Jeffery Higginbotham, and Brenna Alsofrom. 2002. Limits of human word prediction performance. In CSUN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianhua Li</author>
<author>Graeme Hirst</author>
</authors>
<title>Semantic knowledge in word completion.</title>
<date>2005</date>
<booktitle>In ASSETS,</booktitle>
<pages>121--128</pages>
<contexts>
<context position="2281" citStr="Li and Hirst, 2005" startWordPosition="362" endWordPosition="365"> being typed and a language model. The vocabulary is filtered to match the prefix of the current word and the language model ranks the words according to their likelihood. In the case that no letters of the current word have been entered, the language model is the sole factor in generating predictions. Systems often use a touchscreen or function/number keys to select any of the predicted words. Because the goal of word prediction systems is to reduce the number of keystrokes, the primary evaluation for word prediction is keystroke savings (Garay-Vitoria and Abascal, 2006; Newell et al., 1998; Li and Hirst, 2005; Trnka and McCoy, 2007; Carlberger et al., 1997). Keystroke savings (KS) measures the percentage reduction in keys pressed compared to letter-by-letter text entry. keysnormal − keyswith prediction KS = keysnormal A word prediction system that offers higher savings will benefit a user more in practice. However, the equation for keystroke savings has two major deficiencies. Firstly, the equation alone is not enough to compute keystroke savings — actually computing keystroke savings requires a precise definition of a keystroke and also requires a method for determining how many keystrokes are us</context>
</contexts>
<marker>Li, Hirst, 2005</marker>
<rawString>Jianhua Li and Graeme Hirst. 2005. Semantic knowledge in word completion. In ASSETS, pages 121–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Newell</author>
<author>Stefan Langer</author>
<author>Marianne Hickey</author>
</authors>
<title>The rˆole of natural language processing in alternative and augmentative communication.</title>
<date>1998</date>
<journal>Natural Language Engineering,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="1128" citStr="Newell et al., 1998" startWordPosition="167" endWordPosition="170">asure the maximum keystroke savings under two different approximations of an ideal language model. The gold standards additionally narrow the scope of deficiencies in a word prediction system. 1 Introduction Word prediction is an application of language modeling to speeding up text entry, especially to entering utterances to be spoken by an Augmentative and Alternative Communication (AAC) device. AAC devices seek to address the dual problem of speech and motor impairment by attempting to optimize text input. Even still, communication rates with AAC devices are often below 10 words per minute (Newell et al., 1998), compared to the common 130-200 words per minute speech rate of speaking people. Word prediction addresses these issues by reducing the number of keystrokes required to produce a message, which has been shown to improve communication rate (Trnka et al., 2007). The reduction in keystrokes also translates into a lower degree of fatigue from typing all day (Carlberger et al., 1997). Word prediction systems present multiple completions of the current word to the user. Systems generate a list of W predictions on the basis of the word being typed and a language model. The vocabulary is filtered to </context>
</contexts>
<marker>Newell, Langer, Hickey, 1998</marker>
<rawString>Alan Newell, Stefan Langer, and Marianne Hickey. 1998. The rˆole of natural language processing in alternative and augmentative communication. Natural Language Engineering, 4(1):1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Trnka</author>
<author>Kathleen F McCoy</author>
</authors>
<title>Corpus Studies in Word Prediction. In</title>
<date>2007</date>
<booktitle>ASSETS,</booktitle>
<pages>195--202</pages>
<location>Keith Trnka, Debra Yarrington, John McCaw, Kathleen F.</location>
<contexts>
<context position="2304" citStr="Trnka and McCoy, 2007" startWordPosition="366" endWordPosition="369">anguage model. The vocabulary is filtered to match the prefix of the current word and the language model ranks the words according to their likelihood. In the case that no letters of the current word have been entered, the language model is the sole factor in generating predictions. Systems often use a touchscreen or function/number keys to select any of the predicted words. Because the goal of word prediction systems is to reduce the number of keystrokes, the primary evaluation for word prediction is keystroke savings (Garay-Vitoria and Abascal, 2006; Newell et al., 1998; Li and Hirst, 2005; Trnka and McCoy, 2007; Carlberger et al., 1997). Keystroke savings (KS) measures the percentage reduction in keys pressed compared to letter-by-letter text entry. keysnormal − keyswith prediction KS = keysnormal A word prediction system that offers higher savings will benefit a user more in practice. However, the equation for keystroke savings has two major deficiencies. Firstly, the equation alone is not enough to compute keystroke savings — actually computing keystroke savings requires a precise definition of a keystroke and also requires a method for determining how many keystrokes are used when predictions are</context>
<context position="10906" citStr="Trnka and McCoy, 2007" startWordPosition="1779" endWordPosition="1782">3.2 Vocabulary limit We can derive a more practical limit by simulating word prediction using a perfect model of all words that occur in the training data. This gold standard will predict the correct word immediately so long as it occurs in the training corpus. Words that never occurred in training require letter-by-letter entry. We call this measure the vocabulary limit and apply it to evaluate whether the difference between training and testing vocabulary is significant. Previous research has focused on the percentage of out-of-vocabulary (OOV) terms to explain changes in keystroke savings (Trnka and McCoy, 2007; Wandmacher and Antoine, 2006). In contrast, the vocabulary limit gives more guidance for research by translating the problem of OOVs into keystroke savings. Expanding the results from the theoretical limit, the vocabulary limit is 77.6% savings, compared to 78.4% savings for the theoretical limit and 58.7% actual keystroke savings with 5 predictions. The practical limit is very close to the theoretical limit Keystroke savings 60% 50% 40% 30% 20% 10% 0% Word completion Theoretical limit 60% 50% 40% 30% 20% 10% 0% 80% 70% Word prediction Word prediction limit Word completion Word completion li</context>
<context position="12959" citStr="Trnka and McCoy, 2007" startWordPosition="2098" endWordPosition="2101">l limits all fall within a relatively narrow range, suggesting that the achievable keystroke savings may be similar even across different domains. The more technical and formal corpora (Micase, Slate, AAC) show higher limits, as the theoretical limit is based on the length of words and sentences in each corpus. The practical limit exhibits much greater variation. Unlike the Switchboard analysis, many other corpora have a substantial gap between the theoretical and practical limits. Although the practical measure seems to match the actual savings similarly to OOVs testing with crossvalidation (Trnka and McCoy, 2007), this measure more concretely illustrates the effect of OOVs on actual keystroke savings — 60% keystroke savings when training and testing on AAC Email would be extraordinary. 4 Conclusions Although keystroke savings is the predominant evaluation for word prediction, this evaluation is not straightforward, exacerbating the problem of interpreting and comparing results. We have presented a novel solution — interpreting results alongside gold standards which capture the difficulty of the evaluation. These gold standards are also applicable to drive future research — if actual performance is ver</context>
</contexts>
<marker>Trnka, McCoy, 2007</marker>
<rawString>Keith Trnka and Kathleen F. McCoy. 2007. Corpus Studies in Word Prediction. In ASSETS, pages 195–202. Keith Trnka, Debra Yarrington, John McCaw, Kathleen F.</rawString>
</citation>
<citation valid="true">
<authors>
<author>McCoy</author>
<author>Christopher Pennington</author>
</authors>
<title>The Effects of Word Prediction on Communication Rate for AAC. In NAACL-HLT; Companion Volume: Short Papers,</title>
<date>2007</date>
<pages>173--176</pages>
<marker>McCoy, Pennington, 2007</marker>
<rawString>McCoy, and Christopher Pennington. 2007. The Effects of Word Prediction on Communication Rate for AAC. In NAACL-HLT; Companion Volume: Short Papers, pages 173–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tonio Wandmacher</author>
<author>Jean-Yves Antoine</author>
</authors>
<title>Training Language Models without Appropriate Language Resources: Experiments with an AAC System for Disabled People. In Eurospeech.</title>
<date>2006</date>
<contexts>
<context position="10937" citStr="Wandmacher and Antoine, 2006" startWordPosition="1783" endWordPosition="1786"> can derive a more practical limit by simulating word prediction using a perfect model of all words that occur in the training data. This gold standard will predict the correct word immediately so long as it occurs in the training corpus. Words that never occurred in training require letter-by-letter entry. We call this measure the vocabulary limit and apply it to evaluate whether the difference between training and testing vocabulary is significant. Previous research has focused on the percentage of out-of-vocabulary (OOV) terms to explain changes in keystroke savings (Trnka and McCoy, 2007; Wandmacher and Antoine, 2006). In contrast, the vocabulary limit gives more guidance for research by translating the problem of OOVs into keystroke savings. Expanding the results from the theoretical limit, the vocabulary limit is 77.6% savings, compared to 78.4% savings for the theoretical limit and 58.7% actual keystroke savings with 5 predictions. The practical limit is very close to the theoretical limit Keystroke savings 60% 50% 40% 30% 20% 10% 0% Word completion Theoretical limit 60% 50% 40% 30% 20% 10% 0% 80% 70% Word prediction Word prediction limit Word completion Word completion limit Keystroke savings 263 in th</context>
</contexts>
<marker>Wandmacher, Antoine, 2006</marker>
<rawString>Tonio Wandmacher and Jean-Yves Antoine. 2006. Training Language Models without Appropriate Language Resources: Experiments with an AAC System for Disabled People. In Eurospeech.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>