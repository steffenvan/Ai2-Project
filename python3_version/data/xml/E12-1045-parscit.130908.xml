<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000065">
<title confidence="0.989501">
Cutting the Long Tail: Hybrid Language Models
for Translation Style Adaptation
</title>
<author confidence="0.713501">
Arianna Bisazza and Marcello Federico
</author>
<affiliation confidence="0.5593895">
Fondazione Bruno Kessler
Trento, Italy
</affiliation>
<email confidence="0.996809">
{bisazza,federico}@fbk.eu
</email>
<sectionHeader confidence="0.995613" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999741263157895">
In this paper, we address statistical ma-
chine translation of public conference talks.
Modeling the style of this genre can be very
challenging given the shortage of available
in-domain training data. We investigate the
use of a hybrid LM, where infrequent words
are mapped into classes. Hybrid LMs are
used to complement word-based LMs with
statistics about the language style of the
talks. Extensive experiments comparing
different settings of the hybrid LM are re-
ported on publicly available benchmarks
based on TED talks, from Arabic to English
and from English to French. The proposed
models show to better exploit in-domain
data than conventional word-based LMs for
the target language modeling component of
a phrase-based statistical machine transla-
tion system.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999819769230769">
The translation of TED conference talks1 is an
emerging task in the statistical machine transla-
tion (SMT) community (Federico et al., 2011).
The variety of topics covered by the speeches, as
well as their specific language style, make this a
very challenging problem.
Fixed expressions, colloquial terms, figures of
speech and other phenomena recurrent in the talks
should be properly modeled to produce transla-
tions that are not only fluent but that also em-
ploy the right register. In this paper, we propose
a language modeling technique that leverages in-
domain training data for style adaptation.
</bodyText>
<footnote confidence="0.875038">
1http://www.ted.com/talks
</footnote>
<bodyText confidence="0.999532103448276">
Hybrid class-based LMs are trained on text
where only infrequent words are mapped to Part-
of-Speech (POS) classes. In this way, topic-
specific words are discarded and the model fo-
cuses on generic words that we assume more use-
ful to characterize the language style. The factor-
ization of similar expressions made possible by
this mixed text representation yields a better n-
gram coverage, but with a much higher discrimi-
native power than POS-level LMs.
Hybrid LM also differs from POS-level LM in
that it uses a word-to-class mapping to determine
POS tags. Consequently, it doesn’t require the de-
coding overload of factored models nor the tag-
ging of all parallel data used to build phrase ta-
bles. A hybrid LM trained on in-domain data can
thus be easily added to an existing baseline sys-
tem trained on large amounts of background data.
The proposed models are used in addition to
standard word-based LMs, in the framework of
log-linear phrase-based SMT.
The remainder of this paper is organized as fol-
lows. After discussing the language style adapta-
tion problem, we will give an overview of relevant
work. In the following sections we will describe
in detail hybrid LM and its possible variants. Fi-
nally, we will present an empirical analysis of the
proposed technique, including intrinsic evaluation
and SMT experiments.
</bodyText>
<sectionHeader confidence="0.989178" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9999634">
Our working scenario is the translation of TED
talks transcripts as proposed by the IWSLT Eval-
uation Campaign2. This genre covers a variety
of topics ranging from business to psychology.
The available training material – both parallel and
</bodyText>
<footnote confidence="0.987394">
2http://www.iwslt2011.org
</footnote>
<page confidence="0.961149">
439
</page>
<note confidence="0.843510666666667">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 439–448,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
Beginning of Sentence: [s] End of Sentence: [/s]
</note>
<listItem confidence="0.871276236842105">
TED NEWS
1st [s] Thank you. [/s] 1st [s] ( AP ) -
2 [s] Thank you very much 2 [s] WASHINGTON ( ...
3 [s] I ’m going to 3 [s] NEW YORK ( AP
4 [s] And I said, 4 [s] ( CNN ) –
5 [s] I don ’t know 5 [s] NEW YORK ( R...
6 [s] He said, “ 6 [s] He said: “
7 [s] I said, “ 7 [s] ” I don ’t
8 [s] And of course , 8 [s] It was last updated
9 [s] And one of the 9 [s] At the same time
10 [s] And I want to ...
11 [s] And that ’s what 69 [s] I don ’t know
12 [s] We ’re going to 612 [s] I ’m going to
13 [s] And I think that 2434 [s] ” I said,
14 [s] And you can see 7034 [s] He said, “
15 [s] And this is a 8199 [s] And I said,
16 [s] And this is the 8233 [s] Thank you very much
17 [s] And he said, ...
18 [s] So this is a 0 [s] Thank you . [/s]
TED NEWS
1st [s] Thank you. [/s] 1st ” he said. [/s]
2 you very much. [/s] 2 ” she said. [/s]
3 in the world. [/s] 3 , he said. [/s]
4 and so on . [/s] 4 ” he said. [/s]
5 , you know. [/s] 5 in a statement. [/s]
6 of the world. [/s] 6 the United States . [/s]
7 around the world. [/s] 7 to this report. [/s]
8 . Thank you. [/s] 8 ” he added. [/s]
9 the United States . [/s] 9 , police said. [/s]
10 all the time. [/s] 10 , officials said. [/s]
11 to do it . [/s] ...
12 and so forth . [/s] 13 in the world. [/s]
13 don ’t know. [/s] 17 around the world. [/s]
14 to do that. [/s] 46 of the world. [/s]
15 in the future . [/s] 129 all the time. [/s]
16 the same time. [/s] 157 and so on . [/s]
17 , you know ? [/s] 1652 , you know. [/s]
18 to do this . [/s] 5509 you very much. [/s]
</listItem>
<tableCaption confidence="0.987997">
Table 1: Common sentence-initial and sentence-final 5-grams, as ranked by frequency, in the TED and NEWS
corpora. Numbers denote the frequency rank.
</tableCaption>
<bodyText confidence="0.99979875">
monolingual – consists of a rather small collection
of TED talks plus a variety of large out-of-domain
corpora, such as news stories and UN proceed-
ings.
Given the diversity of topics, the in-domain
data alone cannot ensure sufficient coverage to an
SMT system. The addition of background data
can certainly improve the n-gram coverage and
thus the fluency of our translations, but it may also
move our system towards an unsuitable language
style, such as that of written news.
In our study, we focus on the subproblem of
target language modeling and consider two En-
glish text collections, namely the in-domain TED
and the out-of-domain NEWS3, summarized in
Table 2. Because of its larger size – two orders
of magnitude – the NEWS corpus can provide a
better LM coverage than the TED on the test data.
This is reflected both on perplexity and on the av-
erage length of the context (or history h) actually
</bodyText>
<footnote confidence="0.890211">
3http://www.statmt.org/wmt11/translation-task.html
</footnote>
<table confidence="0.943763333333333">
LM Data |� ||W ||V  |PP h59
TED-En 124K 2.4M 51K 112 1.7
NEWS-En 30.7M 782M 2.2M 104 2.5
</table>
<tableCaption confidence="0.880786">
Table 2: Training data and coverage statistics of two
5-gram LMs used for the TED task: number of sen-
tences and tokens, vocabulary size; perplexity and av-
erage word history.
</tableCaption>
<bodyText confidence="0.972710181818182">
used by these two LMs to score the test’s refer-
ence translations. Note that the latter measure is
bounded at the LM order minus one, and is in-
versely proportional to the number of back-offs
performed by the model. Hence, we use this value
to estimate how well an n-gram LM fits the test
data. Indeed, despite the genre mismatch, the per-
plexity of a NEWS 5-gram LM on the TED-2010
test reference translations is 104 versus 112 for
the in-domain LM, and the average history size is
2.5 versus 1.7 words.
</bodyText>
<table confidence="0.992511111111111">
TED NEWS
1st , 1st the
... ...
9 I 40 I
12 you 64 you
90 actually 965 actually
268 stuff 2479 guy
370 guy 2861 stuff
436 amazing 4706 amazing
</table>
<tableCaption confidence="0.936028">
Table 3: Excerpts from TED and NEWS training vo-
cabularies, as ranked by frequency. Numbers denote
the frequency rank.
</tableCaption>
<bodyText confidence="0.9991805">
Yet we observe that the style of public speeches
is much better represented in the in-domain cor-
pus than in the out-of-domain one. For instance,
let us consider the vocabulary distribution4 of the
</bodyText>
<footnote confidence="0.989027666666667">
4Hesitations and filler words, typical of spoken language,
are not covered in our study because they are generally not
reported in the TED talk transcripts.
</footnote>
<page confidence="0.997753">
440
</page>
<bodyText confidence="0.999803303030303">
two corpora (Table 3). The very first forms, as
ranked by frequency, are quite similar in the two
corpora. However, there are important excep-
tions: the pronouns I and you are among the top
20 frequent forms in the TED, while in the NEWS
they are ranked only 40th and 64th respectively.
Other interesting cases are the words actually,
stuff, guy and amazing, all ranked about 10 times
higher in the TED than in the NEWS corpus.
We can also analyze the most typical ways
to start and end a sentence in the two text col-
lections. As shown in Table 1, the frequency
ranking of sentence-initial and sentence-final 5-
grams in the in-domain corpus is notably different
from the out-of-domain one. TED’s most frequent
sentence-initial 5-gram “[s] Thank you. [/s] ” is
not at all attested in the NEWS corpus. As for
the 4th most common sentence start “[s] And I
said ,” is only ranked 8199th in the NEWS, and
so on. Notably, the top ranked NEWS 5-grams in-
clude names of cities (Washington, New York) and
of news agency (AP, Reuters). As regards sen-
tence endings, we observe similar contrasts: for
instance, the word sequence “and so on . [/s] ”
is ranked 4th in the TED and 157th in the NEWS
while “, you know. [/s] ” is 5th in the TED and
only 1652th in the NEWS.
These figures confirm that the talks have a spe-
cific language style, remarkably different from
that of the written news genre. In summary, talks
are characterized by a massive use of first and sec-
ond persons, by shorter sentences, and by more
colloquial lexical and syntactic constructions.
</bodyText>
<sectionHeader confidence="0.999957" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999911854166667">
The brittleness of n-gram LMs in case of mis-
match between training and task data is a well
known issue (Rosenfeld, 2000). So called do-
main adaptation methods (Bellegarda, 2004) can
improve the situation, once a limited amount
of task specific data become available. Ideally,
domain-adaptive LMs aim to improve model ro-
bustness under changing conditions, involving
possible variations in vocabulary, syntax, content,
and style. Most of the known LM adaption tech-
niques (Bellegarda, 2004), however, address all
these variations in a holistic way. A possible rea-
son for this is that LM adaptation methods were
originally developed under the automatic speech
recognition framework, which typically assumes
the presence of one single LM. The progressive
adoption of the log-linear modeling framework in
many NLP tasks has recently introduced the use
of multiple LM components (features), which per-
mit to naturally factor out and integrate different
aspects of language into one model. In SMT, the
factored model (Koehn and Hoang, 2007), for in-
stance, permits to better tailor the LM to the task
syntax, by complementing word-based n-grams
with a part-of-speech (POS) LM , that can be es-
timated even on a limited amount of task-specific
data. Besides many works addressing holistic LM
domain adaptation for SMT, e.g. Foster and Kuhn
(2007), recently methods were also proposed to
explicitly adapt the LM to the discourse topic of a
talk (Ruiz and Federico, 2011). Our work makes
another step in this direction by investigating hy-
brid LMs that try to explicitly represent the speak-
ing style of the talk genre. As a difference from
standard class-based LMs (Brown et al., 1992) or
the more recent local LMs (Monz, 2011), which
are used to predict sequences of classes or word-
class pairs, our hybrid LM is devised to pre-
dict sequences of classes interleaved by words.
While we do not claim any technical novelty in
the model itself, to our knowledge a deep investi-
gation of hybrid LMs for the sake of style adap-
tation is definitely new. Finally, the term hybrid
LM was inspired by Yazgan and Sarac¸lar (2004),
which called with this name a LM predicting se-
quences of words and sub-words units, devised to
let a speech recognizer detect out-of-vocabulary-
words.
</bodyText>
<sectionHeader confidence="0.99449" genericHeader="method">
4 Hybrid Language Model
</sectionHeader>
<bodyText confidence="0.999884352941177">
Hybrid LMs are n-gram models trained on a
mixed text representation where each word is ei-
ther mapped to a class or left as is. This choice
is made according to a measure of word common-
ness and is univocal for each word type.
The rationale is to discard topic-specific words,
while preserving those words that best character-
ize the language style (note that word frequency
is computed on the in-domain corpus only). Map-
ping non-frequent terms to classes naturally leads
to a shorter tail in the frequency distribution, as
visualized by Figure 1. A model trained on such
data has a better n-gram coverage of the test set
and may take advantage of a larger context when
scoring translation hypotheses.
As classes, we use deterministically assigned
POS tags, obtained by first tagging the data with
</bodyText>
<page confidence="0.992937">
441
</page>
<figure confidence="0.991713">
0 1000 2000 3000 4000 5000 6000
</figure>
<figureCaption confidence="0.734255833333333">
Figure 1: Type frequency distribution in the English
TED corpus before and after POS-mapping of words
with less than 500 occurrences (25% of tokens). The
rank in the frequency list (x-axis) is plotted against the
respective frequency in logarithmic scale. Types with
less than 20 occurrences are omitted from the graph.
</figureCaption>
<bodyText confidence="0.81219225">
Tree Tagger (Schmid, 1994) and then choosing
the most likely tag for each word type. In this
way, we avoid the overload of searching for the
best tagging decisions at run-time at the cost of
a slightly higher imprecision (see Section 5.1).
The hybridly mapped data is used to train a high-
order n-gram LM that is plugged into an SMT de-
coder as an additional feature on target word se-
quences. During the translation process, words
are mapped to their class just before querying the
hybrid LM, therefore translation models can be
trained on plain un-tagged data.
As exemplified in Table 4, hybrid LMs can
draw useful statistics on the context of common
words even from a small corpus such as the TED.
To have an idea of data sparseness, consider that
in the unprocessed TED corpus the most frequent
5-gram containing the common word guy occurs
only 3 times. After the mapping of words with
frequency &lt;500, the highest 5-gram frequency
grows to 17, the second one to 9, and so on.
guy 598 actually 3978
a guy VBN NP NP 17 [s] This is actually a 20
guy VBN NP NP , 9 [s] It ’s actually a 17
guy , NP NP , 8 , you can actually VB 13
a guy called NP NP 8 is actually a JJ NN 13
this guy , NP NP 6 This is actually a NN 12
guy VBN NP NP . 6 [s] And this is actually 12
by a guy VBN NP 5 [s] And that ’s actually 10
a JJ guy. [/s] 5 , but it ’s actually 10
I was VBG this guy 4 NN , it ’s actually 9
guy VBN NP . [/s] 4 we’re actually going to 8
</bodyText>
<tableCaption confidence="0.9661385">
Table 4: Most common hybrid 5-grams containing the
words guy and actually, along with absolute frequency.
</tableCaption>
<subsectionHeader confidence="0.995491">
4.1 Word commonness criteria
</subsectionHeader>
<bodyText confidence="0.999314875">
The most intuitive way to measure word common-
ness is by absolute term frequency (F). We will
use this criterion in most of our experiments. A
finer solution would be to also consider the com-
monness of a word across different talks. At this
end, we propose to use the fdf statistics, that is the
product of relative term frequency and document
frequency5:
</bodyText>
<equation confidence="0.994405">
fdfw = c(w) X c(dw)
&apos;w, c(w&apos;) c(d)
</equation>
<bodyText confidence="0.999993421052632">
where dw are the documents (talks) containing at
least one occurrence of the word w.
If available, real talk boundaries can be used
to define the documents. Alternatively, we can
simply split the corpus into chunks of fixed size.
In this work we use this approximation.
Another issue is how to set the threshold. In-
dependently from the chosen commonness mea-
sure, we can reason in terms of the ratio of tokens
that are mapped to POS classes (WP). For in-
stance, in our experiments with English, we can
set the threshold to F=500 and observe that WP
corresponds to 25% of the tokens (and 99% of the
types). In the same corpus, a similar ratio is ob-
tained with fdf=0.012.
In our study, we consider three ratios WP=1.25,
.50, .75} that correspond to different levels of lan-
guage modeling: from a domain-generic word-
level LM to a lexically anchored POS-level LM.
</bodyText>
<subsectionHeader confidence="0.99884">
4.2 Handling morphology
</subsectionHeader>
<bodyText confidence="0.9999645">
Token frequency-based measures may not be suit-
able for languages other than English. When
translating into French, for instance, we have to
deal with a much richer morphology.
As a solution we can use lemmas, univocally
assigned to word types in the same manner as
POS tags. Lemmas can be employed in two ways:
only for word selection, as a frequency measure,
or also for word representation, as a mapping for
common words. In the former, we preserve in-
flected variants that may be useful to model the
language style, but we also risk to see n-gram cov-
erage decrease due to the presence of rare types.
In the latter, only canonical forms and POS tags
</bodyText>
<footnote confidence="0.99003075">
5This differs from the tf-idf widely used in information
retrieval, which is used to measure the relevance of a term in
a document. Instead, we measure commonness of a term in
the whole corpus.
</footnote>
<figure confidence="0.983702">
100000
100
10
10000
1000
w*rds
25%P0S
</figure>
<page confidence="0.993823">
442
</page>
<bodyText confidence="0.8728985">
appear in the processed text, thus introducing a
further level of abstraction from the original text.
Here follows a TED sentence in its original
version (first line) and after three different hy-
brid mappings – namely Wp=.25, Wp=.25 with
lemma forms, and Wp=.50:
Now you laugh, but that quote has kind of a sting to it, right.
Now you VB , but that NN has kind of a NN to it, right.
Now you VB , but that NN have kind of a NN to it, right.
RB you VB , CC that NN VBZ NN of a NN to it, RB .
</bodyText>
<sectionHeader confidence="0.997025" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999869">
In this section we perform an intrinsic evaluation
of the proposed LM technique, then we measure
its impact on translation quality when integrated
into a state-of-the-art phrase-based SMT system.
</bodyText>
<subsectionHeader confidence="0.837904">
5.1 Intrinsic evaluation
</subsectionHeader>
<bodyText confidence="0.999896870967742">
We analyze here a set of hybrid LMs trained on
the English TED corpus by varying the ratio of
POS-mapped words and the word representation
technique (word vs lemma). All models were
trained with the IRSTLM toolkit (Federico et al.,
2008), using a very high n-gram order (10) and
Witten-Bell smoothing.
First, we estimate an upper bound of the POS
tagging errors introduced by deterministic tag-
ging. At this end, the hybridly mapped data is
compared with the actual output of Tree Tagger on
the TED training corpus (see Table 5). Naturally,
the impact of tagging errors correlates with the ra-
tio of POS-mapped tokens, as no error is counted
on non-mapped tokens. For instance, we note that
the POS error rate is only 1.9% in our primary set-
ting, Wp=.25 and word representation, whereas
on a fully POS-mapped text it is 6.6%. Note that
the English tag set used by Tree Tagger includes
43 classes.
Now we focus on the main goal of hybrid text
representation, namely increasing the coverage of
the in-domain LM on the test data. Here too, we
measure coverage by the average length of word
history h used to score the test reference transla-
tions (see Section 2). We do not provide perplex-
ity figures, since these are not directly compara-
ble across models with different vocabularies. As
shown by Table 5, n-gram coverage increases with
the ratio of POS-mapped tokens, ranging from 1.7
on an all-words LM to 4.4 on an all-POS LM. Of
</bodyText>
<table confidence="0.999732222222222">
Hybrid 10g LM IVI POS-Err hlo9
all words 51299 0.0% 1.7
all lemmas 38486 0.0% 1.9
.25 POS/words 475 1.9% 2.7
.50 POS/words 93 4.1% 3.5
.75 POS/words 50 5.7% 4.1
allPOS 43 6.6% 4.4
.25 POS/lemmas 302 1.8% 2.8
.25 POS/words(fdf) 301 1.9% 2.7
</table>
<tableCaption confidence="0.98683">
Table 5: Comparison of LMs obtained from different
hybrid mappings of the English TED corpus: vocabu-
lary size, POS error rate, and average word history on
IWSLT–tst2010’s reference translations.
</tableCaption>
<bodyText confidence="0.9999298">
course, the more words are mapped, the less dis-
criminative our model will be. Thus, choosing the
best hybrid mapping means finding the best trade-
off between coverage and informativeness.
We also applied hybrid LM to the French lan-
guage, again using Tree Tagger to create the POS
mapping. The tag set in this case comprises 34
classes and the POS error rate with Wp=.25 is
1.2% (compare with 1.9% in English). As previ-
ously discussed, morphology has a notable effect
on the modeling of French. In fact, the vocabu-
lary reduction obtained by mapping all the words
to their most probable lemma is -45% (57959 to
31908 types in the TED corpus), while in English
it is only -25%.
</bodyText>
<subsectionHeader confidence="0.997479">
5.2 SMT baseline
</subsectionHeader>
<bodyText confidence="0.9998525">
Our SMT experiments address the translation of
TED talks from Arabic to English and from En-
glish to French. The training and test datasets
were provided by the organizers of the IWSLT11
evaluation, and are summarized in Table 6.
Marked in bold are the corpora used for hybrid
LM training. Dev and test sets have a single ref-
erence translation.
For both language pairs, we set up com-
petitive phrase-based systems6 using the Moses
toolkit (Koehn et al., 2007). The decoder fea-
tures a statistical log-linear model including a
phrase translation model and a phrase reordering
model (Tillmann, 2004; Koehn et al., 2005), two
word-based language models, distortion, word
and phrase penalties. The translation and re-
ordering models are obtained by combining mod-
els independently trained on the available paral-
</bodyText>
<footnote confidence="0.975134">
6The SMT systems used in this paper are thoroughly de-
scribed in (Ruiz et al., 2011).
</footnote>
<page confidence="0.996891">
443
</page>
<table confidence="0.999265777777778">
Corpus A |W I B
AR-EN TED 90K 1.7M 18.9
UN 7.9M 220M 27.8
TED 124K 2.4M 19.5
EN
NEWS 30.7M 782M 25.4
dev2010 934 19K 20.0
AR test 1664 30K 18.1
tst2010
TED 105K 2.0M 19.5
EN-FR UN 11M 291M 26.5
NEWS 111K 3.1M 27.6
TED 107K 2.2M 20.6
FR
NEWS 11.6M 291M 25.2
dev2010 934 20K 21.5
EN test 1664 32K 19.1
tst2010
</table>
<tableCaption confidence="0.9662845">
Table 6: IWSLT11 training and test data statistics:
number of sentences ISI, number of tokens IWI and
average sentence length t. Token numbers are com-
puted on the target language, except for the test sets.
</tableCaption>
<bodyText confidence="0.990448482758621">
lel corpora: namely TED and NEWS for Arabic-
English; TED, NEWS and UN for English-
French. To this end we applied the fill-up method
(Nakov, 2008; Bisazza et al., 2011) in which out-
of-domain phrase tables are merged with the in-
domain table by adding only new phrase pairs.
Out-of-domain phrases are marked with a binary
feature whose weight is tuned together with the
SMT system weights.
For each target language, two standard 5-gram
LMs are trained separately on the monolingual
TED and NEWS datasets, and log-linearly com-
bined at decoding time. In the Arabic-English
task, we use a hierarchical reordering model (Gal-
ley and Manning, 2008; Hardmeier et al., 2011),
while in the English-French task we use a default
word-based bidirectional model. The distortion
limit is set to the default value of 6. Note that
the use of large n-gram LMs and of lexicalized
reordering models was shown to wipe out the im-
provement achievable by POS-level LM (Kirch-
hoff and Yang, 2005; Birch et al., 2007).
Concerning data preprocessing we apply stan-
dard tokenization to the English and French text,
while for Arabic we use an in-house tokenizer that
removes diacritics and normalizes special charac-
ters and digits. Arabic text is then segmented with
AMIRA (Diab et al., 2004) according to the ATB
scheme7. The Arabic-English system uses cased
</bodyText>
<footnote confidence="0.873321666666667">
7The Arabic Treebank tokenization scheme isolates con-
junctions w+ and f+, prepositions l+, k+, b+, future marker
s+, pronominal suffixes, but not the article Al+.
</footnote>
<bodyText confidence="0.999666181818182">
translation models, while the English-French sys-
tem uses lowercased models and a standard re-
casing post-process.
Feature weights are tuned on dev2010 by
means of a minimum error training procedure
(MERT) (Och, 2003). Following suggestions by
Clark et al. (2011) and Cettolo et al. (2011) on
controlling optimizer instability, we run MERT
four times on the same configuration and use the
average of the resulting weights to evaluate trans-
lation performance.
</bodyText>
<subsectionHeader confidence="0.996589">
5.3 Hybrid LM integration
</subsectionHeader>
<bodyText confidence="0.999313166666667">
As previously stated, hybrid LMs are trained only
on in-domain data and are added to the log-linear
decoder as an additional target LM. To this end,
we use the class-based LM implementation pro-
vided in Moses and IRSTLM, which applies the
word-to-class mapping to translation hypotheses
before LM querying8. The order of the additional
LM is set to 10 in the Arabic-English evaluation
and 7 in the English-French, as these appeared to
be the best settings in preliminary tests.
Translation quality is measured by BLEU (Pa-
pineni et al., 2002), METEOR (Banerjee and
Lavie, 2005) and TER (Snover et al., 2006)9. To
test whether differences among systems are statis-
tically significant we use approximate randomiza-
tion as done in (Riezler and Maxwell, 2005)10.
Model variants. The effect on MT quality of
various hybrid LM variants is shown in Table 7.
Note that allPOS and allLemmas refer to deter-
ministically assigned POS tags and lemmas, re-
spectively. Concerning the ratio of POS-mapped
tokens, the best performing values are Wp=.25 in
Arabic-English and Wp=.50 in English-French.
These hybrid mappings outperform all the uni-
form representations (words, lemmas and POS)
with statistically significant BLEU and METEOR
improvements.
The fdf experiment involves the use of doc-
ument frequency for the selection of common
words. Its performance is very close to that of hy-
</bodyText>
<footnote confidence="0.9996435">
8Detailed instructions on how to build and use hybrid
LMs can be found at http://hlt.fbk.eu/people/bisazza.
9We use case-sensitive BLEU and TER, but case-
insensitive METEOR to enable the use of paraphrase tables
distributed with the tool (version 1.3).
10Translation scores and significance tests were com-
puted with the Multeval toolkit (Clark et al., 2011):
https://github.com/jhclark/multeval.
</footnote>
<page confidence="0.998153">
444
</page>
<figure confidence="0.84864">
(a) Arabic to English, IWSLT–tst2010
</figure>
<table confidence="0.995328904761905">
Added InDomain 10gLM BLEUT MET T TER t
.00 POS/words (all words)† 26.1 30.5 55.4
.00 POS/lemmas (all lem.) 26.0 30.5 55.4
1.0 POS/words (all POS)† 25.9 30.6 55.3
.25 POS/words† 26.5 30.6 54.7
.50 POS/words 26.5 30.6 54.9
.75 POS/words 26.3 30.7 55.0
.25 POS/words(fdf) 26.5 30.7 54.7
.25 POS/lemmaF 26.4 30.6 54.8
.25 POS/lemmas 26.5 30.8 54.6
(b) English to French, IWSLT–tst2010
Added InDomain 7gLM BLEUT MET T TER t
.00 POS/words (all words) 31.1 52.5 49.9
.00 POS/lemmas (all lem.)† 31.2 52.6 49.7
1.0 POS/words (all POS)† 31.4 52.8 49.8
.25 POS/lemmas† 31.5 52.9 49.7
.50 POS/lemmas 31.9 53.3 49.5
.75 POS/lemmas 31.7 53.2 49.6
.50 POS/lemmas(fdf) 31.9 53.3 49.5
.50 POS/lemmaF 31.6 53.0 49.6
.50 POS/words 31.7 53.1 49.5
</table>
<tableCaption confidence="0.999246666666667">
Table 7: Comparison of various hybrid LM variants. Translation quality is measured with BLEU, METEOR and
TER (all in percentage form). The settings used for weight tuning are marked with †. Best models according to
all metrics are highlighted in bold.
</tableCaption>
<bodyText confidence="0.9997325">
brid LMs simply based on term frequency; only
METEOR gains 0.1 points in Arabic-English. A
possible reason for this is that document fre-
quency was computed on fixed-size text chunks
rather than on real document boundaries (see Sec-
tion 4.1). The lemmaF experiment refers to the
use of canonical forms for frequency measuring:
this technique does not seem to help in either lan-
guage pair. Finally, we compare the use of lem-
mas versus surface forms to represent common
words. As expected, lemmas appear to be help-
ful for French language modeling. Interestingly
this is also the case for English, even if by a small
margin (+0.2 METEOR, -0.1 TER).
Summing up, hybrid mapping appears as a
winning strategy compared to uniform map-
ping. Although differences among LM variants
are small, the best model in Arabic-English is
.25-POS/lemmas, which can be thought of as
a domain-generic lemma-level LM. In English-
French, instead, the highest scores are achieved
by .50-POS/lemmas or .50-POS/lemmas(fdf), that
is POS-level LM with few frequently occurring
lexical anchors (vocabulary size 59). An inter-
pretation of this result is that, for French, mod-
eling the syntax is more helpful than modeling
the style. We also suspect that the French TED
corpus is more irregular and diverse with respect
to the style, than its English counterpart. In fact,
while the English corpus include transcripts of
talks given by English speakers, the French one is
mostly a collection of (human) translations. Typi-
cal features of the speech style may have been lost
in this process.
Comparison with baseline. In Table 8 the
best performing hybrid LM is compared against
the baseline that only includes the standard LMs
described in Section 5.2. To complete our eval-
uation, we also report the effect of an in-domain
LM trained on 50 word classes induced from the
corpus by maximum-likelihood based clustering
(Och, 1999).
In the two language pairs, both types of LM
result in consistent improvements over the base-
line. However, the gains achieved by the hybrid
approach are larger and all statistically signifi-
cant. The hybrid approach is significantly bet-
ter than the unsupervised one by TER in Arabic-
English and by BLEU and METEOR in English-
French (these siginificances are not reported in
</bodyText>
<figure confidence="0.552088">
(a) Arabic to English, IWSLT–tst2010
</figure>
<table confidence="0.983888818181818">
Added InDomain BLEUT MET T TER t
10g LM
none (baseline) 26.0 30.4 55.6
unsup. classes 26.4◦ 30.8• 55.1◦
hybrid 26.5•(+.5) 30.8•(+.4) 54.6•(-1.0)
(b) English to French, IWSLT–tst2010
Added InDomain BLEUT MET T TER t
7g LM
none (baseline) 31.2 52.7 49.8
unsup. classes 31.5 52.9 49.6
hybrid 31.9•(+.7) 53.3•(+.6) 49.5◦(-.3)
</table>
<tableCaption confidence="0.75424">
Table 8: Final MT results: baseline vs unsupervised
word classes-based LM and best hybrid LM. Statis-
tically significant improvements over the baseline are
marked with • at the p &lt; .01 and ◦ at the p &lt; .05 level.
</tableCaption>
<page confidence="0.998861">
445
</page>
<bodyText confidence="0.999989787878788">
the table for clarity). The proposed method ap-
pears to better leverage the available in-domain
data, achieving improvements according to all
metrics: +0.5/+0.4/-1.0 BLEU/METEOR/TER
in Arabic-English and +0.7/-0.6/-0.3 in English-
French, without requiring any bitext annotation or
decoder modification.
Talk-level analysis. To conclude the study,
we analyze the effect of our best hybrid LM
on Arabic-English translation quality, at the sin-
gle talk level. The test used in the experiments
(tst2010) consists of 11 transcripts with an av-
erage length of 151±73 sentences. For each
talk, we compare the baseline BLEU score with
that obtained by adding a.25-POS/lemmas hybrid
LM. Results are presented in Figure 2. The dark
and light columns denote baseline and hybrid-LM
BLEU scores, respectively, and refer to the left y-
axis. Additional data points, plotted on the right
y-axis in reverse order, represent talk-level per-
plexities (PP) of a standard 5-gram LM trained
on TED (o) and those of the .25-POS/lemmas
10-gram hybrid LM (A), computed on reference
translations.
What emerges first is a dramatic variation of
performance among the speeches, with baseline
BLEU scores ranging from 33.95 on talk “00” to
only 12.42 on talk “02”. The latter talk appears as
a corner case also according to perplexities (397
by word LM and 111 by hybrid LM). Notably, the
perplexities of the two LMs correlate well with
each other, but the hybrid’s PP is much more sta-
ble across talks: its standard deviation is only 14
</bodyText>
<figureCaption confidence="0.902401">
Figure 2: Talk-level evaluation on Arabic-English
(IWSLT-tst2010). Left y-axis: BLEU impact of a .25-
POS/lemma hybrid LM. Right y-axis: perplexities by
word LM and by hybrid LM.
</figureCaption>
<bodyText confidence="0.999953">
points, while that of the word-based PP is 79. The
BLEU improvement given by hybrid LM, how-
ever modest, is consistent across the talks, with
only two outliers: a drop of -0.2 on talk “00”, and
a drop of -0.7 on talk “02”. The largest gain (+1.1)
is observed on talk “10”, from 16.8 to 17.9 BLEU.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999983166666667">
We have proposed a language modeling technique
that leverages the in-domain data for SMT style
adaptation. Trained to predict mixed sequences
of POS classes and frequent words, hybrid LMs
are devised to capture typical lexical and syntactic
constructions that characterize the style of speech
transcripts.
Compared to standard language models, hy-
brid LMs generalize better to the test data and
partially compensate for the disproportion be-
tween in-domain and out-of-domain training data.
At the same time, hybrid LMs show more dis-
criminative power than merely POS-level LMs.
The integration of hybrid LMs into a competi-
tive phrase-based SMT system is straightforward
and leads to consistent improvements on the TED
task, according to three different translation qual-
ity metrics.
Target language modeling is only one aspect
of the statistical translation problem. Now that
the usability of the proposed method has been as-
sessed for language modeling, future work will
address the extension of the idea to the modeling
of phrase translation and reordering.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9994148">
This work was supported by the T4ME network
of excellence (IST-249119), funded by the DG
INFSO of the European Commission through the
7th Framework Programme. We thank the anony-
mous reviewers for their valuable suggestions.
</bodyText>
<sectionHeader confidence="0.983701" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.80591025">
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with im-
proved correlation with human judgments. In Pro-
ceedings of the ACL Workshop on Intrinsic and Ex-
trinsic Evaluation Measures for Machine Transla-
tion and/or Summarization, pages 65–72, Ann Ar-
bor, Michigan, June. Association for Computational
Linguistics.
</bodyText>
<figure confidence="0.995815652173913">
00 01 02 03 04 05 06 07 08 09 10
35.00
32.50
30.00
27.50
25.00
22.50
20.00
17.50
15.00
12.50
10.00
BLEU (base) BLEU (hyb) PP(words5g) PP(hyb)
0
50
400
450
200
250
300
350
100
150
</figure>
<page confidence="0.995916">
446
</page>
<reference confidence="0.999769535087719">
Jerome R. Bellegarda. 2004. Statistical language
model adaptation: review and perspectives. Speech
Communication, 42(1):93 – 108.
Alexandra Birch, Miles Osborne, and Philipp Koehn.
2007. CCG supertags in factored statistical ma-
chine translation. In Proceedings of the Second
Workshop on Statistical Machine Translation, pages
9–16, Prague, Czech Republic, June. Association
for Computational Linguistics.
Arianna Bisazza, Nick Ruiz, and Marcello Fed-
erico. 2011. Fill-up versus Interpolation Meth-
ods for Phrase-based SMT Adaptation. In Interna-
tional Workshop on Spoken Language Translation
(IWSLT), San Francisco, CA.
P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai,
and R. L. Mercer. 1992. Class-based n-gram mod-
els of natural language. Computational Linguistics,
18(4):467–479.
Mauro Cettolo, Nicola Bertoldi, and Marcello Fed-
erico. 2011. Methods for smoothing the optimizer
instability in SMT. In MT Summit XIII: the Thir-
teenth Machine Translation Summit, pages 32–39,
Xiamen, China.
Jonathan Clark, Chris Dyer, Alon Lavie, and
Noah Smith. 2011. Better hypothesis testing
for statistical machine translation: Controlling
for optimizer instability. In Proceedings of
the Association for Computational Lingustics,
ACL 2011, Portland, Oregon, USA. Associa-
tion for Computational Linguistics. available at
http://www.cs.cmu.edu/ jhclark/pubs/significance.pdf.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004. Automatic Tagging of Arabic Text: From
Raw Text to Base Phrase Chunks. In Daniel Marcu
Susan Dumais and Salim Roukos, editors, HLT-
NAACL 2004: Short Papers, pages 149–152,
Boston, Massachusetts, USA, May 2 - May 7. As-
sociation for Computational Linguistics.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an Open Source Toolkit for
Handling Large Scale Language Models. In Pro-
ceedings of Interspeech, pages 1618–1621, Mel-
bourne, Australia.
Marcello Federico, Luisa Bentivogli, Michael Paul,
and Sebastian St¨uker. 2011. Overview of the
IWSLT 2011 Evaluation Campaign. In Interna-
tional Workshop on Spoken Language Translation
(IWSLT), San Francisco, CA.
George Foster and Roland Kuhn. 2007. Mixture-
model adaptation for SMT. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, pages 128–135, Prague, Czech Republic, June.
Association for Computational Linguistics.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In EMNLP ’08: Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 848–856, Morristown, NJ, USA.
Association for Computational Linguistics.
Christian Hardmeier, J¨org Tiedemann, Markus Saers,
Marcello Federico, and Mathur Prashant. 2011.
The Uppsala-FBK systems at WMT 2011. In Pro-
ceedings of the Sixth Workshop on Statistical Ma-
chine Translation, pages 372–378, Edinburgh, Scot-
land, July. Association for Computational Linguis-
tics.
Katrin Kirchhoff and Mei Yang. 2005. Improved lan-
guage modeling for statistical machine translation.
In Proceedings of the ACL Workshop on Building
and Using Parallel Texts, pages 125–128, Ann Ar-
bor, Michigan, June. Association for Computational
Linguistics.
Philipp Koehn and Hieu Hoang. 2007. Factored
translation models. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pages 868–
876, Prague, Czech Republic, June. Association for
Computational Linguistics.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system description
for the 2005 IWSLT speech translation evaluation.
In Proc. of the International Workshop on Spoken
Language Translation, October.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of the 45th Annual Meeting of the Associa-
tion for Computational Linguistics Companion Vol-
ume Proceedings of the Demo and Poster Sessions,
pages 177–180, Prague, Czech Republic.
Christof Monz. 2011. Statistical Machine Translation
with Local Language Models. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, pages 869–879, Edinburgh,
Scotland, UK., July. Association for Computational
Linguistics.
Preslav Nakov. 2008. Improving English-Spanish
Statistical Machine Translation: Experiments in
Domain Adaptation, Sentence Paraphrasing, Tok-
enization, and Recasing.. In Workshop on Statis-
tical Machine Translation, Association for Compu-
tational Linguistics.
Franz Josef Och. 1999. An efficient method for de-
termining bilingual word classes. In Proceedings of
the 9th Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 71–76.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Erhard
Hinrichs and Dan Roth, editors, Proceedings of the
</reference>
<page confidence="0.982606">
447
</page>
<reference confidence="0.999485725490196">
41st Annual Meeting of the Association for Compu-
tational Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the Asso-
ciation of Computational Linguistics (ACL), pages
311–318, Philadelphia, PA.
Stefan Riezler and John T. Maxwell. 2005. On some
pitfalls in automatic evaluation and significance
testing for MT. In Proceedings of the ACL Work-
shop on Intrinsic and Extrinsic Evaluation Mea-
sures for Machine Translation and/or Summariza-
tion, pages 57–64, Ann Arbor, Michigan, June. As-
sociation for Computational Linguistics.
R. Rosenfeld. 2000. Two decades of statistical lan-
guage modeling: where do we go from here? Pro-
ceedings of the IEEE, 88(8):1270 –1278.
Nick Ruiz and Marcello Federico. 2011. Topic adap-
tation for lecture translation through bilingual la-
tent semantic models. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
294–302, Edinburgh, Scotland, July. Association
for Computational Linguistics.
Nick Ruiz, Arianna Bisazza, Fabio Brugnara, Daniele
Falavigna, Diego Giuliani, Suhel Jaber, Roberto
Gretter, and Marcello Federico. 2011. FBK @
IWSLT 2011. In International Workshop on Spo-
ken Language Translation (IWSLT), San Francisco,
CA.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of In-
ternational Conference on New Methods in Lan-
guage Processing.
Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea
Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In 5th Conference of the Association for Machine
Translation in the Americas (AMTA), Boston, Mas-
sachusetts, August.
Christoph Tillmann. 2004. A Unigram Orientation
Model for Statistical Machine Translation. In Pro-
ceedings of the Joint Conference on Human Lan-
guage Technologies and the Annual Meeting of the
North American Chapter of the Association of Com-
putational Linguistics (HLT-NAACL).
A. Yazgan and M. Sarac¸lar. 2004. Hybrid language
models for out of vocabulary word detection in large
vocabulary conversational speech recognition. In
Proceedings of ICASSP, volume 1, pages I – 745–8
vol.1, may.
</reference>
<page confidence="0.997708">
448
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.316108">
<title confidence="0.9995345">Cutting the Long Tail: Hybrid Language for Translation Style Adaptation</title>
<author confidence="0.7037585">Bisazza Fondazione Bruno</author>
<affiliation confidence="0.644859">Trento,</affiliation>
<abstract confidence="0.99903365">In this paper, we address statistical machine translation of public conference talks. Modeling the style of this genre can be very challenging given the shortage of available in-domain training data. We investigate the use of a hybrid LM, where infrequent words are mapped into classes. Hybrid LMs are used to complement word-based LMs with statistics about the language style of the talks. Extensive experiments comparing different settings of the hybrid LM are reported on publicly available benchmarks based on TED talks, from Arabic to English and from English to French. The proposed models show to better exploit in-domain data than conventional word-based LMs for the target language modeling component of a phrase-based statistical machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jerome R Bellegarda</author>
</authors>
<title>Statistical language model adaptation: review and perspectives.</title>
<date>2004</date>
<journal>Speech Communication,</journal>
<volume>42</volume>
<issue>1</issue>
<pages>108</pages>
<contexts>
<context position="9197" citStr="Bellegarda, 2004" startWordPosition="1665" endWordPosition="1666">so on . [/s] ” is ranked 4th in the TED and 157th in the NEWS while “, you know. [/s] ” is 5th in the TED and only 1652th in the NEWS. These figures confirm that the talks have a specific language style, remarkably different from that of the written news genre. In summary, talks are characterized by a massive use of first and second persons, by shorter sentences, and by more colloquial lexical and syntactic constructions. 3 Related Work The brittleness of n-gram LMs in case of mismatch between training and task data is a well known issue (Rosenfeld, 2000). So called domain adaptation methods (Bellegarda, 2004) can improve the situation, once a limited amount of task specific data become available. Ideally, domain-adaptive LMs aim to improve model robustness under changing conditions, involving possible variations in vocabulary, syntax, content, and style. Most of the known LM adaption techniques (Bellegarda, 2004), however, address all these variations in a holistic way. A possible reason for this is that LM adaptation methods were originally developed under the automatic speech recognition framework, which typically assumes the presence of one single LM. The progressive adoption of the log-linear </context>
</contexts>
<marker>Bellegarda, 2004</marker>
<rawString>Jerome R. Bellegarda. 2004. Statistical language model adaptation: review and perspectives. Speech Communication, 42(1):93 – 108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
<author>Philipp Koehn</author>
</authors>
<title>CCG supertags in factored statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="21845" citStr="Birch et al., 2007" startWordPosition="3902" endWordPosition="3905">T system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>Alexandra Birch, Miles Osborne, and Philipp Koehn. 2007. CCG supertags in factored statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 9–16, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arianna Bisazza</author>
<author>Nick Ruiz</author>
<author>Marcello Federico</author>
</authors>
<title>Fill-up versus Interpolation Methods for Phrase-based SMT Adaptation.</title>
<date>2011</date>
<booktitle>In International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<location>San Francisco, CA.</location>
<contexts>
<context position="21024" citStr="Bisazza et al., 2011" startWordPosition="3764" endWordPosition="3767">TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M 19.5 EN-FR UN 11M 291M 26.5 NEWS 111K 3.1M 27.6 TED 107K 2.2M 20.6 FR NEWS 11.6M 291M 25.2 dev2010 934 20K 21.5 EN test 1664 32K 19.1 tst2010 Table 6: IWSLT11 training and test data statistics: number of sentences ISI, number of tokens IWI and average sentence length t. Token numbers are computed on the target language, except for the test sets. lel corpora: namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit</context>
</contexts>
<marker>Bisazza, Ruiz, Federico, 2011</marker>
<rawString>Arianna Bisazza, Nick Ruiz, and Marcello Federico. 2011. Fill-up versus Interpolation Methods for Phrase-based SMT Adaptation. In International Workshop on Spoken Language Translation (IWSLT), San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>P V deSouza</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="10690" citStr="Brown et al., 1992" startWordPosition="1902" endWordPosition="1905">its to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM was inspired by Yazgan and Sarac¸lar (2004), which called with this name a LM predicting sequences of words and sub-words units, devised to let a speech recognizer detect out-of-vocabularywords. 4 Hybrid Language </context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai, and R. L. Mercer. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Nicola Bertoldi</author>
<author>Marcello Federico</author>
</authors>
<title>Methods for smoothing the optimizer instability in SMT.</title>
<date>2011</date>
<booktitle>In MT Summit XIII: the Thirteenth Machine Translation Summit,</booktitle>
<pages>32--39</pages>
<location>Xiamen, China.</location>
<contexts>
<context position="22634" citStr="Cettolo et al. (2011)" startWordPosition="4025" endWordPosition="4028"> normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English</context>
</contexts>
<marker>Cettolo, Bertoldi, Federico, 2011</marker>
<rawString>Mauro Cettolo, Nicola Bertoldi, and Marcello Federico. 2011. Methods for smoothing the optimizer instability in SMT. In MT Summit XIII: the Thirteenth Machine Translation Summit, pages 32–39, Xiamen, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Lingustics, ACL 2011,</booktitle>
<publisher>Association</publisher>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="22608" citStr="Clark et al. (2011)" startWordPosition="4020" endWordPosition="4023">t removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the additional LM is set to 10 in the Arabic-English evalu</context>
<context position="24550" citStr="Clark et al., 2011" startWordPosition="4328" endWordPosition="4331">utperform all the uniform representations (words, lemmas and POS) with statistically significant BLEU and METEOR improvements. The fdf experiment involves the use of document frequency for the selection of common words. Its performance is very close to that of hy8Detailed instructions on how to build and use hybrid LMs can be found at http://hlt.fbk.eu/people/bisazza. 9We use case-sensitive BLEU and TER, but caseinsensitive METEOR to enable the use of paraphrase tables distributed with the tool (version 1.3). 10Translation scores and significance tests were computed with the Multeval toolkit (Clark et al., 2011): https://github.com/jhclark/multeval. 444 (a) Arabic to English, IWSLT–tst2010 Added InDomain 10gLM BLEUT MET T TER t .00 POS/words (all words)† 26.1 30.5 55.4 .00 POS/lemmas (all lem.) 26.0 30.5 55.4 1.0 POS/words (all POS)† 25.9 30.6 55.3 .25 POS/words† 26.5 30.6 54.7 .50 POS/words 26.5 30.6 54.9 .75 POS/words 26.3 30.7 55.0 .25 POS/words(fdf) 26.5 30.7 54.7 .25 POS/lemmaF 26.4 30.6 54.8 .25 POS/lemmas 26.5 30.8 54.6 (b) English to French, IWSLT–tst2010 Added InDomain 7gLM BLEUT MET T TER t .00 POS/words (all words) 31.1 52.5 49.9 .00 POS/lemmas (all lem.)† 31.2 52.6 49.7 1.0 POS/words (all</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan Clark, Chris Dyer, Alon Lavie, and Noah Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proceedings of the Association for Computational Lingustics, ACL 2011, Portland, Oregon, USA. Association for Computational Linguistics. available at http://www.cs.cmu.edu/ jhclark/pubs/significance.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLTNAACL 2004: Short Papers,</booktitle>
<volume>2</volume>
<pages>149--152</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="22116" citStr="Diab et al., 2004" startWordPosition="3945" endWordPosition="3948">ardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configur</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLTNAACL 2004: Short Papers, pages 149–152, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: an Open Source Toolkit for Handling Large Scale Language Models.</title>
<date>2008</date>
<booktitle>In Proceedings of Interspeech,</booktitle>
<pages>1618--1621</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="17138" citStr="Federico et al., 2008" startWordPosition="3081" endWordPosition="3084"> but that NN has kind of a NN to it, right. Now you VB , but that NN have kind of a NN to it, right. RB you VB , CC that NN VBZ NN of a NN to it, RB . 5 Evaluation In this section we perform an intrinsic evaluation of the proposed LM technique, then we measure its impact on translation quality when integrated into a state-of-the-art phrase-based SMT system. 5.1 Intrinsic evaluation We analyze here a set of hybrid LMs trained on the English TED corpus by varying the ratio of POS-mapped words and the word representation technique (word vs lemma). All models were trained with the IRSTLM toolkit (Federico et al., 2008), using a very high n-gram order (10) and Witten-Bell smoothing. First, we estimate an upper bound of the POS tagging errors introduced by deterministic tagging. At this end, the hybridly mapped data is compared with the actual output of Tree Tagger on the TED training corpus (see Table 5). Naturally, the impact of tagging errors correlates with the ratio of POS-mapped tokens, as no error is counted on non-mapped tokens. For instance, we note that the POS error rate is only 1.9% in our primary setting, Wp=.25 and word representation, whereas on a fully POS-mapped text it is 6.6%. Note that the</context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an Open Source Toolkit for Handling Large Scale Language Models. In Proceedings of Interspeech, pages 1618–1621, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Luisa Bentivogli</author>
<author>Michael Paul</author>
<author>Sebastian St¨uker</author>
</authors>
<date>2011</date>
<booktitle>Overview of the IWSLT 2011 Evaluation Campaign. In International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<location>San Francisco, CA.</location>
<marker>Federico, Bentivogli, Paul, St¨uker, 2011</marker>
<rawString>Marcello Federico, Luisa Bentivogli, Michael Paul, and Sebastian St¨uker. 2011. Overview of the IWSLT 2011 Evaluation Campaign. In International Workshop on Spoken Language Translation (IWSLT), San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixturemodel adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="10354" citStr="Foster and Kuhn (2007)" startWordPosition="1844" endWordPosition="1847">nce of one single LM. The progressive adoption of the log-linear modeling framework in many NLP tasks has recently introduced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our kn</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixturemodel adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>A simple and effective hierarchical phrase reordering model.</title>
<date>2008</date>
<booktitle>In EMNLP ’08: Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>848--856</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="21495" citStr="Galley and Manning, 2008" startWordPosition="3840" endWordPosition="3844"> namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIR</context>
</contexts>
<marker>Galley, Manning, 2008</marker>
<rawString>Michel Galley and Christopher D. Manning. 2008. A simple and effective hierarchical phrase reordering model. In EMNLP ’08: Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 848–856, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
<author>J¨org Tiedemann</author>
<author>Markus Saers</author>
<author>Marcello Federico</author>
<author>Mathur Prashant</author>
</authors>
<title>The Uppsala-FBK systems at WMT</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>372--378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="21520" citStr="Hardmeier et al., 2011" startWordPosition="3845" endWordPosition="3848">rabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) acc</context>
</contexts>
<marker>Hardmeier, Tiedemann, Saers, Federico, Prashant, 2011</marker>
<rawString>Christian Hardmeier, J¨org Tiedemann, Markus Saers, Marcello Federico, and Mathur Prashant. 2011. The Uppsala-FBK systems at WMT 2011. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 372–378, Edinburgh, Scotland, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Kirchhoff</author>
<author>Mei Yang</author>
</authors>
<title>Improved language modeling for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>125--128</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="21824" citStr="Kirchhoff and Yang, 2005" startWordPosition="3897" endWordPosition="3901">tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional model. The distortion limit is set to the default value of 6. Note that the use of large n-gram LMs and of lexicalized reordering models was shown to wipe out the improvement achievable by POS-level LM (Kirchhoff and Yang, 2005; Birch et al., 2007). Concerning data preprocessing we apply standard tokenization to the English and French text, while for Arabic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models an</context>
</contexts>
<marker>Kirchhoff, Yang, 2005</marker>
<rawString>Katrin Kirchhoff and Mei Yang. 2005. Improved language modeling for statistical machine translation. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 125–128, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="10051" citStr="Koehn and Hoang, 2007" startWordPosition="1793" endWordPosition="1796">ontent, and style. Most of the known LM adaption techniques (Bellegarda, 2004), however, address all these variations in a holistic way. A possible reason for this is that LM adaptation methods were originally developed under the automatic speech recognition framework, which typically assumes the presence of one single LM. The progressive adoption of the log-linear modeling framework in many NLP tasks has recently introduced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standa</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868– 876, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Alexandra Birch Mayne</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>Edinburgh system description for the 2005 IWSLT speech translation evaluation.</title>
<date>2005</date>
<booktitle>In Proc. of the International Workshop on Spoken Language Translation,</booktitle>
<contexts>
<context position="20068" citStr="Koehn et al., 2005" startWordPosition="3590" endWordPosition="3593">line Our SMT experiments address the translation of TED talks from Arabic to English and from English to French. The training and test datasets were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 6. Marked in bold are the corpora used for hybrid LM training. Dev and test sets have a single reference translation. For both language pairs, we set up competitive phrase-based systems6 using the Moses toolkit (Koehn et al., 2007). The decoder features a statistical log-linear model including a phrase translation model and a phrase reordering model (Tillmann, 2004; Koehn et al., 2005), two word-based language models, distortion, word and phrase penalties. The translation and reordering models are obtained by combining models independently trained on the available paral6The SMT systems used in this paper are thoroughly described in (Ruiz et al., 2011). 443 Corpus A |W I B AR-EN TED 90K 1.7M 18.9 UN 7.9M 220M 27.8 TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M 19.5 EN-FR UN 11M 291M 26.5 NEWS 111K 3.1M 27.6 TED 107K 2.2M 20.6 FR NEWS 11.6M 291M 25.2 dev2010 934 20K 21.5 EN test 1664 32K 19.1 tst2010 Table 6: IWSLT1</context>
</contexts>
<marker>Koehn, Axelrod, Mayne, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne, and David Talbot. 2005. Edinburgh system description for the 2005 IWSLT speech translation evaluation. In Proc. of the International Workshop on Spoken Language Translation, October.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="19911" citStr="Koehn et al., 2007" startWordPosition="3566" endWordPosition="3569">tained by mapping all the words to their most probable lemma is -45% (57959 to 31908 types in the TED corpus), while in English it is only -25%. 5.2 SMT baseline Our SMT experiments address the translation of TED talks from Arabic to English and from English to French. The training and test datasets were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 6. Marked in bold are the corpora used for hybrid LM training. Dev and test sets have a single reference translation. For both language pairs, we set up competitive phrase-based systems6 using the Moses toolkit (Koehn et al., 2007). The decoder features a statistical log-linear model including a phrase translation model and a phrase reordering model (Tillmann, 2004; Koehn et al., 2005), two word-based language models, distortion, word and phrase penalties. The translation and reordering models are obtained by combining models independently trained on the available paral6The SMT systems used in this paper are thoroughly described in (Ruiz et al., 2011). 443 Corpus A |W I B AR-EN TED 90K 1.7M 18.9 UN 7.9M 220M 27.8 TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christof Monz</author>
</authors>
<title>Statistical Machine Translation with Local Language Models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>869--879</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="10732" citStr="Monz, 2011" startWordPosition="1912" endWordPosition="1913"> complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM was inspired by Yazgan and Sarac¸lar (2004), which called with this name a LM predicting sequences of words and sub-words units, devised to let a speech recognizer detect out-of-vocabularywords. 4 Hybrid Language Model Hybrid LMs are n-gram models trained</context>
</contexts>
<marker>Monz, 2011</marker>
<rawString>Christof Monz. 2011. Statistical Machine Translation with Local Language Models. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 869–879, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
</authors>
<title>Improving English-Spanish Statistical Machine Translation: Experiments in Domain Adaptation, Sentence Paraphrasing, Tokenization, and Recasing..</title>
<date>2008</date>
<booktitle>In Workshop on Statistical Machine Translation, Association for Computational Linguistics.</booktitle>
<contexts>
<context position="21001" citStr="Nakov, 2008" startWordPosition="3762" endWordPosition="3763">9M 220M 27.8 TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M 19.5 EN-FR UN 11M 291M 26.5 NEWS 111K 3.1M 27.6 TED 107K 2.2M 20.6 FR NEWS 11.6M 291M 25.2 dev2010 934 20K 21.5 EN test 1664 32K 19.1 tst2010 Table 6: IWSLT11 training and test data statistics: number of sentences ISI, number of tokens IWI and average sentence length t. Token numbers are computed on the target language, except for the test sets. lel corpora: namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for EnglishFrench. To this end we applied the fill-up method (Nakov, 2008; Bisazza et al., 2011) in which outof-domain phrase tables are merged with the indomain table by adding only new phrase pairs. Out-of-domain phrases are marked with a binary feature whose weight is tuned together with the SMT system weights. For each target language, two standard 5-gram LMs are trained separately on the monolingual TED and NEWS datasets, and log-linearly combined at decoding time. In the Arabic-English task, we use a hierarchical reordering model (Galley and Manning, 2008; Hardmeier et al., 2011), while in the English-French task we use a default word-based bidirectional mode</context>
</contexts>
<marker>Nakov, 2008</marker>
<rawString>Preslav Nakov. 2008. Improving English-Spanish Statistical Machine Translation: Experiments in Domain Adaptation, Sentence Paraphrasing, Tokenization, and Recasing.. In Workshop on Statistical Machine Translation, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>An efficient method for determining bilingual word classes.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>71--76</pages>
<contexts>
<context position="27498" citStr="Och, 1999" startWordPosition="4811" endWordPosition="4812">ect to the style, than its English counterpart. In fact, while the English corpus include transcripts of talks given by English speakers, the French one is mostly a collection of (human) translations. Typical features of the speech style may have been lost in this process. Comparison with baseline. In Table 8 the best performing hybrid LM is compared against the baseline that only includes the standard LMs described in Section 5.2. To complete our evaluation, we also report the effect of an in-domain LM trained on 50 word classes induced from the corpus by maximum-likelihood based clustering (Och, 1999). In the two language pairs, both types of LM result in consistent improvements over the baseline. However, the gains achieved by the hybrid approach are larger and all statistically significant. The hybrid approach is significantly better than the unsupervised one by TER in ArabicEnglish and by BLEU and METEOR in EnglishFrench (these siginificances are not reported in (a) Arabic to English, IWSLT–tst2010 Added InDomain BLEUT MET T TER t 10g LM none (baseline) 26.0 30.4 55.6 unsup. classes 26.4◦ 30.8• 55.1◦ hybrid 26.5•(+.5) 30.8•(+.4) 54.6•(-1.0) (b) English to French, IWSLT–tst2010 Added InD</context>
</contexts>
<marker>Och, 1999</marker>
<rawString>Franz Josef Och. 1999. An efficient method for determining bilingual word classes. In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 71–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<editor>In Erhard Hinrichs and Dan Roth, editors,</editor>
<contexts>
<context position="22562" citStr="Och, 2003" startWordPosition="4015" endWordPosition="4016">abic we use an in-house tokenizer that removes diacritics and normalizes special characters and digits. Arabic text is then segmented with AMIRA (Diab et al., 2004) according to the ATB scheme7. The Arabic-English system uses cased 7The Arabic Treebank tokenization scheme isolates conjunctions w+ and f+, prepositions l+, k+, b+, future marker s+, pronominal suffixes, but not the article Al+. translation models, while the English-French system uses lowercased models and a standard recasing post-process. Feature weights are tuned on dev2010 by means of a minimum error training procedure (MERT) (Och, 2003). Following suggestions by Clark et al. (2011) and Cettolo et al. (2011) on controlling optimizer instability, we run MERT four times on the same configuration and use the average of the resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the addition</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Erhard Hinrichs and Dan Roth, editors, Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="23370" citStr="Papineni et al., 2002" startWordPosition="4144" endWordPosition="4148"> resulting weights to evaluate translation performance. 5.3 Hybrid LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9. To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10. Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are Wp=.25 in Arabic-English and Wp=.50 in English-French. These hybrid mappings outperform all the uniform representatio</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL), pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>John T Maxwell</author>
</authors>
<title>On some pitfalls in automatic evaluation and significance testing for MT.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>57--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="23581" citStr="Riezler and Maxwell, 2005" startWordPosition="4178" endWordPosition="4181">target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9. To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10. Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are Wp=.25 in Arabic-English and Wp=.50 in English-French. These hybrid mappings outperform all the uniform representations (words, lemmas and POS) with statistically significant BLEU and METEOR improvements. The fdf experiment involves the use of document frequency for the selection of common words. Its performance is very close </context>
</contexts>
<marker>Riezler, Maxwell, 2005</marker>
<rawString>Stefan Riezler and John T. Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing for MT. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 57–64, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
</authors>
<title>Two decades of statistical language modeling: where do we go from here?</title>
<date>2000</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>88</volume>
<issue>8</issue>
<pages>1278</pages>
<contexts>
<context position="9141" citStr="Rosenfeld, 2000" startWordPosition="1657" endWordPosition="1658">imilar contrasts: for instance, the word sequence “and so on . [/s] ” is ranked 4th in the TED and 157th in the NEWS while “, you know. [/s] ” is 5th in the TED and only 1652th in the NEWS. These figures confirm that the talks have a specific language style, remarkably different from that of the written news genre. In summary, talks are characterized by a massive use of first and second persons, by shorter sentences, and by more colloquial lexical and syntactic constructions. 3 Related Work The brittleness of n-gram LMs in case of mismatch between training and task data is a well known issue (Rosenfeld, 2000). So called domain adaptation methods (Bellegarda, 2004) can improve the situation, once a limited amount of task specific data become available. Ideally, domain-adaptive LMs aim to improve model robustness under changing conditions, involving possible variations in vocabulary, syntax, content, and style. Most of the known LM adaption techniques (Bellegarda, 2004), however, address all these variations in a holistic way. A possible reason for this is that LM adaptation methods were originally developed under the automatic speech recognition framework, which typically assumes the presence of on</context>
</contexts>
<marker>Rosenfeld, 2000</marker>
<rawString>R. Rosenfeld. 2000. Two decades of statistical language modeling: where do we go from here? Proceedings of the IEEE, 88(8):1270 –1278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Ruiz</author>
<author>Marcello Federico</author>
</authors>
<title>Topic adaptation for lecture translation through bilingual latent semantic models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>294--302</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="10477" citStr="Ruiz and Federico, 2011" startWordPosition="1865" endWordPosition="1868">uced the use of multiple LM components (features), which permit to naturally factor out and integrate different aspects of language into one model. In SMT, the factored model (Koehn and Hoang, 2007), for instance, permits to better tailor the LM to the task syntax, by complementing word-based n-grams with a part-of-speech (POS) LM , that can be estimated even on a limited amount of task-specific data. Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011). Our work makes another step in this direction by investigating hybrid LMs that try to explicitly represent the speaking style of the talk genre. As a difference from standard class-based LMs (Brown et al., 1992) or the more recent local LMs (Monz, 2011), which are used to predict sequences of classes or wordclass pairs, our hybrid LM is devised to predict sequences of classes interleaved by words. While we do not claim any technical novelty in the model itself, to our knowledge a deep investigation of hybrid LMs for the sake of style adaptation is definitely new. Finally, the term hybrid LM </context>
</contexts>
<marker>Ruiz, Federico, 2011</marker>
<rawString>Nick Ruiz and Marcello Federico. 2011. Topic adaptation for lecture translation through bilingual latent semantic models. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 294–302, Edinburgh, Scotland, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Ruiz</author>
<author>Arianna Bisazza</author>
<author>Fabio Brugnara</author>
<author>Daniele Falavigna</author>
<author>Diego Giuliani</author>
<author>Suhel Jaber</author>
<author>Roberto Gretter</author>
<author>Marcello Federico</author>
</authors>
<date>2011</date>
<journal>FBK @ IWSLT</journal>
<booktitle>In International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<location>San Francisco, CA.</location>
<contexts>
<context position="20339" citStr="Ruiz et al., 2011" startWordPosition="3633" endWordPosition="3636">r hybrid LM training. Dev and test sets have a single reference translation. For both language pairs, we set up competitive phrase-based systems6 using the Moses toolkit (Koehn et al., 2007). The decoder features a statistical log-linear model including a phrase translation model and a phrase reordering model (Tillmann, 2004; Koehn et al., 2005), two word-based language models, distortion, word and phrase penalties. The translation and reordering models are obtained by combining models independently trained on the available paral6The SMT systems used in this paper are thoroughly described in (Ruiz et al., 2011). 443 Corpus A |W I B AR-EN TED 90K 1.7M 18.9 UN 7.9M 220M 27.8 TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M 19.5 EN-FR UN 11M 291M 26.5 NEWS 111K 3.1M 27.6 TED 107K 2.2M 20.6 FR NEWS 11.6M 291M 25.2 dev2010 934 20K 21.5 EN test 1664 32K 19.1 tst2010 Table 6: IWSLT11 training and test data statistics: number of sentences ISI, number of tokens IWI and average sentence length t. Token numbers are computed on the target language, except for the test sets. lel corpora: namely TED and NEWS for ArabicEnglish; TED, NEWS and UN for English</context>
</contexts>
<marker>Ruiz, Bisazza, Brugnara, Falavigna, Giuliani, Jaber, Gretter, Federico, 2011</marker>
<rawString>Nick Ruiz, Arianna Bisazza, Fabio Brugnara, Daniele Falavigna, Diego Giuliani, Suhel Jaber, Roberto Gretter, and Marcello Federico. 2011. FBK @ IWSLT 2011. In International Workshop on Spoken Language Translation (IWSLT), San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="12473" citStr="Schmid, 1994" startWordPosition="2209" endWordPosition="2210">such data has a better n-gram coverage of the test set and may take advantage of a larger context when scoring translation hypotheses. As classes, we use deterministically assigned POS tags, obtained by first tagging the data with 441 0 1000 2000 3000 4000 5000 6000 Figure 1: Type frequency distribution in the English TED corpus before and after POS-mapping of words with less than 500 occurrences (25% of tokens). The rank in the frequency list (x-axis) is plotted against the respective frequency in logarithmic scale. Types with less than 20 occurrences are omitted from the graph. Tree Tagger (Schmid, 1994) and then choosing the most likely tag for each word type. In this way, we avoid the overload of searching for the best tagging decisions at run-time at the cost of a slightly higher imprecision (see Section 5.1). The hybridly mapped data is used to train a highorder n-gram LM that is plugged into an SMT decoder as an additional feature on target word sequences. During the translation process, words are mapped to their class just before querying the hybrid LM, therefore translation models can be trained on plain un-tagged data. As exemplified in Table 4, hybrid LMs can draw useful statistics o</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Rich Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In 5th Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="23435" citStr="Snover et al., 2006" startWordPosition="4156" endWordPosition="4159">LM integration As previously stated, hybrid LMs are trained only on in-domain data and are added to the log-linear decoder as an additional target LM. To this end, we use the class-based LM implementation provided in Moses and IRSTLM, which applies the word-to-class mapping to translation hypotheses before LM querying8. The order of the additional LM is set to 10 in the Arabic-English evaluation and 7 in the English-French, as these appeared to be the best settings in preliminary tests. Translation quality is measured by BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006)9. To test whether differences among systems are statistically significant we use approximate randomization as done in (Riezler and Maxwell, 2005)10. Model variants. The effect on MT quality of various hybrid LM variants is shown in Table 7. Note that allPOS and allLemmas refer to deterministically assigned POS tags and lemmas, respectively. Concerning the ratio of POS-mapped tokens, the best performing values are Wp=.25 in Arabic-English and Wp=.50 in English-French. These hybrid mappings outperform all the uniform representations (words, lemmas and POS) with statistically significant BLEU an</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In 5th Conference of the Association for Machine Translation in the Americas (AMTA), Boston, Massachusetts, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
</authors>
<title>A Unigram Orientation Model for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Joint Conference on Human Language Technologies and the Annual Meeting of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL).</booktitle>
<contexts>
<context position="20047" citStr="Tillmann, 2004" startWordPosition="3588" endWordPosition="3589">5%. 5.2 SMT baseline Our SMT experiments address the translation of TED talks from Arabic to English and from English to French. The training and test datasets were provided by the organizers of the IWSLT11 evaluation, and are summarized in Table 6. Marked in bold are the corpora used for hybrid LM training. Dev and test sets have a single reference translation. For both language pairs, we set up competitive phrase-based systems6 using the Moses toolkit (Koehn et al., 2007). The decoder features a statistical log-linear model including a phrase translation model and a phrase reordering model (Tillmann, 2004; Koehn et al., 2005), two word-based language models, distortion, word and phrase penalties. The translation and reordering models are obtained by combining models independently trained on the available paral6The SMT systems used in this paper are thoroughly described in (Ruiz et al., 2011). 443 Corpus A |W I B AR-EN TED 90K 1.7M 18.9 UN 7.9M 220M 27.8 TED 124K 2.4M 19.5 EN NEWS 30.7M 782M 25.4 dev2010 934 19K 20.0 AR test 1664 30K 18.1 tst2010 TED 105K 2.0M 19.5 EN-FR UN 11M 291M 26.5 NEWS 111K 3.1M 27.6 TED 107K 2.2M 20.6 FR NEWS 11.6M 291M 25.2 dev2010 934 20K 21.5 EN test 1664 32K 19.1 ts</context>
</contexts>
<marker>Tillmann, 2004</marker>
<rawString>Christoph Tillmann. 2004. A Unigram Orientation Model for Statistical Machine Translation. In Proceedings of the Joint Conference on Human Language Technologies and the Annual Meeting of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yazgan</author>
<author>M Sarac¸lar</author>
</authors>
<title>Hybrid language models for out of vocabulary word detection in large vocabulary conversational speech recognition.</title>
<date>2004</date>
<journal>I –</journal>
<booktitle>In Proceedings of ICASSP,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<marker>Yazgan, Sarac¸lar, 2004</marker>
<rawString>A. Yazgan and M. Sarac¸lar. 2004. Hybrid language models for out of vocabulary word detection in large vocabulary conversational speech recognition. In Proceedings of ICASSP, volume 1, pages I – 745–8 vol.1, may.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>