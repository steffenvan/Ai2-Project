<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006968">
<note confidence="0.645895">
LOCAL AND GLOBAL STRUCTURES IN DISCOURSE UNDERSTANDING
</note>
<author confidence="0.55342">
M. Koit, S. Litvak, H. Oim, T. Roosmaa, M. Saluveer
</author>
<affiliation confidence="0.88605">
Artificial Intelligence Laboratory
Tartu State University
</affiliation>
<address confidence="0.661398666666667">
202400 Tartu, Estonian S.S.R., U.S.S.R.
(Oim&apos;s present address is Estonian Department, University of Helsinki,
Fabianinkatu 33, 00170 Helsinki 17, Finland.)
</address>
<sectionHeader confidence="0.838648" genericHeader="method">
I INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99891062962963">
We are interested in the nature of content
structures in terms of which it would be possible
to account for reasoning processes in
understanding natural language texts. One of the
most crucial problems here at the present time is
how and by which mechanisms these reasoning
processes are controlled and directed. As the
emphasis in the design of discourse understanding
systems so far has been on the problems of
knowledge organization and representation, we are
only beginning to guess what the corresponding
processing mechanisms are and how they function,
although an increasing number of papers has been
devoted to these problems as well. There are
studies of the relation of understanding to such
types of knowledge processing as problem solving
and planning (e.g., Black and Bower 1980, Wilensky
1981). Various types of content units and
structures needed to account for knowledge
processing have been proposed in the general
context of modeling discourse understanding (e.g.,
Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980).
We ourselves have discussed an approach to
knowledge units and processing mechanisms in
questions, as a part of a computer system which
understands stories of a certain kind (Litvak et
al. 1981), as well as on a more theoretical level
(Oim 1980).
To our mind, there are two general faults
that characterize present day computer systems
designed to understand coherent natural language
texts. First, they make too heavy and rigorous
use of predetermined knowledge schemes relating to
the subject matter of texts and to the
organization of reasoning processes which carry
out understanding. Secondly, these predetermined
knowledge and reasoning structures operate on
levels of organization that are too far away from
the level on which immediate text contents are
presented. So the understanding processes
modelled by these systems are prevailingly
knowledge—driven and, secondly, reflect relatively
high level, global macro—operations upon events
described in a text. There is little knowledge of
the ways in which a text itself dynamically
manipulates reasoning processes and decision
makings of human understanders.
We do not want to claim that global schemes
are not needed at all in discourse understanding.
But there is a theoretical and empirical lacuna
between this global level of processing, where
story schemes or plan and goal hierarchies are
acting, and the level of immediate text
presentation.
</bodyText>
<sectionHeader confidence="0.976941" genericHeader="method">
II LOCAL REASONING STRUCTURES
</sectionHeader>
<bodyText confidence="0.999954947368421">
There should exist, between two levels, a
&amp;quot;local&amp;quot; level of processing and, correspondingly,
&amp;quot;local reasoning mechanisms&amp;quot; that are sensitive to
the ways in which immediate text contents are
organized. These local mechanisms should operate
in terms of knowledge units and structures they
obtain from text, on the one hand, and they should
reflect intuitive attention, interest and judgment
processes of the understander that occur during
reading a text, on the other. They should be
usable in interpreting very different kinds of
texts--just as words, for instance, when looked at
from the side of their contents, constitute
preorganized &amp;quot;packets&amp;quot; of knowledge which can be
used to build up different kinds of sentences and
texts. There exist already some interesting
studies dealing with such local text processing
mechanisms (e.g., Granger 1982).
The crucial question here is, how do the
local thought processes of the understander
develop; how does his reasoning proceed from one
state to another under the influence of the
incoming text. There should exist certain units
by which these processes could be described and
predicted on this local level, certain &amp;quot;packets of
(local) thought processes.&amp;quot;
We want to specify here one type of such a
unit. For the lack of a better term, we call them
&amp;quot;reasoning molecules&amp;quot; (RM). By this term we want
to stress two characteristic features of these
units. First, they are namely processing units,
units of thought processes, not static knowledge
structures (like frames). Secondly, they are not
thought to represent elementary, indivisible steps
in these processes. They represent certain
complexes of such steps, but complexes that
function as wholes, when triggered by text. Using
a somewhat metaphorical way of speaking, we can
</bodyText>
<page confidence="0.991981">
152
</page>
<bodyText confidence="0.975218588235294">
say that RMs embody certain agents that work as
experts&amp;quot; in certain types of problems. They make
use of the data coming from the text and their
built-in knowledge about the given problem they
are specialists of. They may interact together,
engaging one another for obtaining additional
information and to solve- certain subproblems of
their particular problems. As such, RMs form a
relatively loose, decentralized society of experts
whose activity is chiefly directed by the
immediate text structure. There is also a
general, central &amp;quot;supervisor&amp;quot; in such a reasoning
system (Litvak et al. 1982), but its role and
influence appear more clearly on higher levels of
reasoning and decision making. An RM is
characterized by the basic properties described in
the following four sections.
</bodyText>
<listItem confidence="0.897232">
(1) It has a built-in goal. As RMs function
as &amp;quot;experts,&amp;quot; their task is to notice the problems
</listItem>
<bodyText confidence="0.974613232323232">
they are experts for, and to solve them. The
general end of any RM is to make sense of the
situation to which it applies. But let us stress
that this &amp;quot;making sense&amp;quot; does not necessarily
amount to incorporating the corresponding event or
situation into some goal-plan hierarchy. Instead,
making sense may mean for the understander, for
instance, recognizing what a particular feature of
a situation or event was representing in the world
described in the text. For instance, there exist
RMs for determining such structural aspects of
events as to what end something was done (&amp;quot;Goal-
expert&amp;quot;), or at what time something was done
(&amp;quot;Time-expert&amp;quot;), but there exist also RMs which
are experts in such questions as what counts as a
relevant motivation of a refusal (cf. the
following). Further, making sense of a partner&apos;s
response in a dialogue _may mean to the other
partner making a decision about how to react to
this response. Especially on the basis of this
latter example it may be said that in fact the
primary interest of an understander is not just to
make sense of a piece of text itself but, instead,
to make sense of the situation in which he himself
is the interpreter of the corresponding part of
the text.
In general, it may be right that for the
investigation of local reasoning mechanisms, texts
are more suitable where global organizational
structures are lacking, or are not so significant;
interactions in face-to-face dialogue present an
example of such texts.
(2) RMs make use of semantic categories and
structures identified in text, as well as speech-
act-type pragmatic structures. In an RM these
structures function as &amp;quot;influence factors,&amp;quot; i.e.,
as units that are characterized on the basis of
their effect upon the understander. Influence
factors are semantic and pragmatic situations in
text that manipulate the attention of an
understander: provoke or satisfy his interest,
trigger him to pose questions and to seek answers
to them, to choose between alternative possible
evaluations, and so on. The task of RMs is just
to notice such &amp;quot;interest provoking situations&amp;quot; in
text, to register their components and to provide
the understander with &amp;quot;packets&amp;quot; of reasoning steps
which may lead him to the needed decision
(ultimately, to make sense of the corresponding
situation). For instance, assume that someone is
presented with the response:
&amp;quot;I am not coming. I do not want to take
such a risk.&amp;quot;
which is presented as an answer to his request (or
order, or proposal). The &amp;quot;refusal reasoning
molecule&amp;quot; identifies the latter sentence in the
response as motivation for the refusal. &amp;quot;Not-
wanting-to-take-risks&amp;quot; is an influence factor
which provides the motive of the refusal. But at
the same time it functions as an influence factor
in another RM which leads the given participant of
the dialogue to accept or to reject the refusal,
and to react accordingly.
(3) RMs are characterized by a certain inner
organization. Typically, an RM has three
functional components. First it includes a
&amp;quot;sensor mechanism&amp;quot; whose task is to notice in text
the situations which are relevant to the given RM.
Second, there is the &amp;quot;task formulator&amp;quot; which
functions as the central monitor and &amp;quot;bookkeeper&amp;quot;
of the corresponding RM; departing from the built-
in task of the RM and the data provided by text
(or by other RMs) it formulates the concrete
problem to be solved, determines the method of its
solution and keeps track of the course of its
realization. Third, there is the processing unit
of the RM which carries out the
operations/processes determined by the task
formulator.
Further, there apparently should exist
definite empirical constraints concerning the size
of the &amp;quot;working space&amp;quot; of an RM. It must be
possible for the understander to hold the
influence factors relevant to an RM simultaneously
in his working memory and to take them all into
account in making the resulting decision. Again,
the face-to-face dialogue is a good example: in
order to react adequately to a response in such a
dialogue, the participant should take
simultaneously into account all the relevant
factors contained in the response of his partner.
Because of this, it is not surprising that the
length of the replies in face-to-face dialogue
tends to remain in certain limits. It would be
premature to try to determine here the exact
nature of the given constraints, e.g., in terms of
the allowed number of influence factors in a
reasoning molecule (although the well known number
7 plus or minus 2 could be a good guess).
</bodyText>
<listItem confidence="0.924832333333333">
(4) There exist certain basic types of RMs.
First of all, we can differentiate between
thematic and textual RMs. Thematic RMs are
experts concerning the contents of a text (the
provided examples, such as &amp;quot;Goal-expert&amp;quot; or
&amp;quot;Refusal-expert&amp;quot; belong to this type). Textual
</listItem>
<page confidence="0.998674">
153
</page>
<bodyText confidence="0.999869666666667">
RMs are experts concerning the organizational
structure of various texts (e.g., stories, tales,
scientific arguments). Ultimately, they should be
able to answer the question: &amp;quot;Why is this
particular utterance presented at this place in
the text?&amp;quot;
</bodyText>
<sectionHeader confidence="0.994546" genericHeader="method">
II/ CONCLUDING REMARKS
</sectionHeader>
<bodyText confidence="0.950491032258065">
As empirical material we have analyzed the
structure of interactions in directive dialogues,
and still more concretely, the mechanisms needed
to understand interactions which present requests
and orders in such dialogues, on the one hand, and
the possible reactions, e.g., refusals to fulfill
these requests and orders, on the other. We have
built a taxonomy of influence factors typical of
these types of interactions, and constructed some
basic types of reasoning molecules used in
interpreting the replies.
The work is not yet implemented, but we have
planned to implement it in the frames of our text
understanding systems TARLUS (Litvak et al. 1981;
Koit et al. 1983). TARLUS is a system whose main
task is to interpret stories of a certain kind, in
particular by recognizing so—called hyperevents
implicitly described in text, (e.g., by
recognizing that certain actions of a person
described in text can be qualified as robbery or
stealing).
IV REFERENCES
Allen J.E., What&apos;s necessary to hide?: Modeling
action verbs. Proceedings of the 19th Annual
Meeting of the ACL, Stanford, 1981, 77-81.
Black J.B. and Bower G.H., Story understanding as
problem solving. Poetics, v.9, 1980.
Cohen R., Investigation of processing strategies
for the structural analysis of arguments.
Proceedings of the 19th Annual Meeting of the
ACL Stanford, 1981, 71-75.
</bodyText>
<reference confidence="0.99388927027027">
Dyer M.G., In—depth understanding: a computer
model of integrated processing for narrative
comprehension. Res. Report No. 219, Yale
University, May 1982.
Granger R.H., Judgmental inference: a theory of
inferential decision — making during
understanding. Proceedings of the 4th Annual
Conference of the Cognitive Science Society,
Ann Arbor, Michigan, 1982.
Koit M., Litvak S., Roosmaa T., Saluveer M., Oim
H., Using frames in causal reasoning. Papers
on Artificial Intelligence, vol. 5. Tartu
State University, Tartu 1983.
Lehnert W., Plot units and narrative
summarization. Cognitive Science, 1981, vol.
5, No. 4.
Litvak S., Roosmaa T., Saluveer M., Oim H.,
Recognizing hyperevents by a text understanding
system. Papers on Artificial Intelligence,
vol. 4. Tartu State University, Tartu, 1981.
(in Russian)
Litvak S., Roosmaa T., Saluveer M., Oim H., On the
interaction of knowledge representation and
reasoning mechanism in discourse comprehension.
Proceedings of the 1982 European Conference on
Artificial Intelligence. Orsay, France, 1982.
Oim H., Episodes in the structure of discourse.
In: A. Narin&apos;yani (ed.), Knowledge
representation and modelling of understanding
processes. Novosibirsk, 1980. (in Russian)
Wilensky R., Points: a theory of story content.
EEGS Memo No. UCB/ERL/M80/17. University of
California at Berkeley, 1980.
Wilensky R., Meta—planning: representing and using
knowledge about planning in problem solving and
language understanding. Cognitive Science,
1981, vol. 5 No. 3.
</reference>
<page confidence="0.999771">
154
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.919678">
<title confidence="0.999298">LOCAL AND GLOBAL STRUCTURES IN DISCOURSE UNDERSTANDING</title>
<author confidence="0.999925">M Koit</author>
<author confidence="0.999925">S Litvak</author>
<author confidence="0.999925">H Oim</author>
<author confidence="0.999925">T Roosmaa</author>
<author confidence="0.999925">M Saluveer</author>
<affiliation confidence="0.999783">Artificial Intelligence Laboratory Tartu State University</affiliation>
<address confidence="0.999697">202400 Tartu, Estonian S.S.R., U.S.S.R.</address>
<affiliation confidence="0.928463">Oim&apos;s present address is Estonian Department, University of Helsinki,</affiliation>
<address confidence="0.940983">Fabianinkatu 33, 00170 Helsinki 17, Finland.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M G Dyer</author>
</authors>
<title>In—depth understanding: a computer model of integrated processing for narrative comprehension.</title>
<date>1982</date>
<tech>Res. Report No. 219,</tech>
<institution>Yale University,</institution>
<contexts>
<context position="1353" citStr="Dyer 1982" startWordPosition="203" endWordPosition="204">ms of knowledge organization and representation, we are only beginning to guess what the corresponding processing mechanisms are and how they function, although an increasing number of papers has been devoted to these problems as well. There are studies of the relation of understanding to such types of knowledge processing as problem solving and planning (e.g., Black and Bower 1980, Wilensky 1981). Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding (e.g., Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980). We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind (Litvak et al. 1981), as well as on a more theoretical level (Oim 1980). To our mind, there are two general faults that characterize present day computer systems designed to understand coherent natural language texts. First, they make too heavy and rigorous use of predetermined knowledge schemes relating to the subject matter of texts and to the organization of reasoning processes which carry out understa</context>
</contexts>
<marker>Dyer, 1982</marker>
<rawString>Dyer M.G., In—depth understanding: a computer model of integrated processing for narrative comprehension. Res. Report No. 219, Yale University, May 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>Judgmental inference: a theory of inferential decision — making during understanding.</title>
<date>1982</date>
<booktitle>Proceedings of the 4th Annual Conference of the Cognitive Science Society,</booktitle>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="3653" citStr="Granger 1982" startWordPosition="553" endWordPosition="554">erate in terms of knowledge units and structures they obtain from text, on the one hand, and they should reflect intuitive attention, interest and judgment processes of the understander that occur during reading a text, on the other. They should be usable in interpreting very different kinds of texts--just as words, for instance, when looked at from the side of their contents, constitute preorganized &amp;quot;packets&amp;quot; of knowledge which can be used to build up different kinds of sentences and texts. There exist already some interesting studies dealing with such local text processing mechanisms (e.g., Granger 1982). The crucial question here is, how do the local thought processes of the understander develop; how does his reasoning proceed from one state to another under the influence of the incoming text. There should exist certain units by which these processes could be described and predicted on this local level, certain &amp;quot;packets of (local) thought processes.&amp;quot; We want to specify here one type of such a unit. For the lack of a better term, we call them &amp;quot;reasoning molecules&amp;quot; (RM). By this term we want to stress two characteristic features of these units. First, they are namely processing units, units of</context>
</contexts>
<marker>Granger, 1982</marker>
<rawString>Granger R.H., Judgmental inference: a theory of inferential decision — making during understanding. Proceedings of the 4th Annual Conference of the Cognitive Science Society, Ann Arbor, Michigan, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Koit</author>
<author>S Litvak</author>
<author>T Roosmaa</author>
<author>M Saluveer</author>
<author>H Oim</author>
</authors>
<title>Using frames in causal reasoning.</title>
<date>1983</date>
<journal>Papers on Artificial Intelligence,</journal>
<volume>5</volume>
<institution>Tartu State University,</institution>
<location>Tartu</location>
<contexts>
<context position="11177" citStr="Koit et al. 1983" startWordPosition="1780" endWordPosition="1783"> interactions in directive dialogues, and still more concretely, the mechanisms needed to understand interactions which present requests and orders in such dialogues, on the one hand, and the possible reactions, e.g., refusals to fulfill these requests and orders, on the other. We have built a taxonomy of influence factors typical of these types of interactions, and constructed some basic types of reasoning molecules used in interpreting the replies. The work is not yet implemented, but we have planned to implement it in the frames of our text understanding systems TARLUS (Litvak et al. 1981; Koit et al. 1983). TARLUS is a system whose main task is to interpret stories of a certain kind, in particular by recognizing so—called hyperevents implicitly described in text, (e.g., by recognizing that certain actions of a person described in text can be qualified as robbery or stealing). IV REFERENCES Allen J.E., What&apos;s necessary to hide?: Modeling action verbs. Proceedings of the 19th Annual Meeting of the ACL, Stanford, 1981, 77-81. Black J.B. and Bower G.H., Story understanding as problem solving. Poetics, v.9, 1980. Cohen R., Investigation of processing strategies for the structural analysis of argumen</context>
</contexts>
<marker>Koit, Litvak, Roosmaa, Saluveer, Oim, 1983</marker>
<rawString>Koit M., Litvak S., Roosmaa T., Saluveer M., Oim H., Using frames in causal reasoning. Papers on Artificial Intelligence, vol. 5. Tartu State University, Tartu 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lehnert</author>
</authors>
<title>Plot units and narrative summarization. Cognitive Science,</title>
<date>1981</date>
<volume>5</volume>
<marker>Lehnert, 1981</marker>
<rawString>Lehnert W., Plot units and narrative summarization. Cognitive Science, 1981, vol. 5, No. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Litvak</author>
<author>T Roosmaa</author>
<author>M Saluveer</author>
<author>H Oim</author>
</authors>
<title>Recognizing hyperevents by a text understanding system.</title>
<date>1981</date>
<journal>Papers on Artificial Intelligence,</journal>
<volume>4</volume>
<institution>Tartu State University,</institution>
<location>Tartu,</location>
<note>(in Russian)</note>
<contexts>
<context position="1565" citStr="Litvak et al. 1981" startWordPosition="235" endWordPosition="238">evoted to these problems as well. There are studies of the relation of understanding to such types of knowledge processing as problem solving and planning (e.g., Black and Bower 1980, Wilensky 1981). Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding (e.g., Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980). We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind (Litvak et al. 1981), as well as on a more theoretical level (Oim 1980). To our mind, there are two general faults that characterize present day computer systems designed to understand coherent natural language texts. First, they make too heavy and rigorous use of predetermined knowledge schemes relating to the subject matter of texts and to the organization of reasoning processes which carry out understanding. Secondly, these predetermined knowledge and reasoning structures operate on levels of organization that are too far away from the level on which immediate text contents are presented. So the understanding </context>
<context position="11158" citStr="Litvak et al. 1981" startWordPosition="1776" endWordPosition="1779">zed the structure of interactions in directive dialogues, and still more concretely, the mechanisms needed to understand interactions which present requests and orders in such dialogues, on the one hand, and the possible reactions, e.g., refusals to fulfill these requests and orders, on the other. We have built a taxonomy of influence factors typical of these types of interactions, and constructed some basic types of reasoning molecules used in interpreting the replies. The work is not yet implemented, but we have planned to implement it in the frames of our text understanding systems TARLUS (Litvak et al. 1981; Koit et al. 1983). TARLUS is a system whose main task is to interpret stories of a certain kind, in particular by recognizing so—called hyperevents implicitly described in text, (e.g., by recognizing that certain actions of a person described in text can be qualified as robbery or stealing). IV REFERENCES Allen J.E., What&apos;s necessary to hide?: Modeling action verbs. Proceedings of the 19th Annual Meeting of the ACL, Stanford, 1981, 77-81. Black J.B. and Bower G.H., Story understanding as problem solving. Poetics, v.9, 1980. Cohen R., Investigation of processing strategies for the structural </context>
</contexts>
<marker>Litvak, Roosmaa, Saluveer, Oim, 1981</marker>
<rawString>Litvak S., Roosmaa T., Saluveer M., Oim H., Recognizing hyperevents by a text understanding system. Papers on Artificial Intelligence, vol. 4. Tartu State University, Tartu, 1981. (in Russian)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Litvak</author>
<author>T Roosmaa</author>
<author>M Saluveer</author>
<author>H Oim</author>
</authors>
<title>On the interaction of knowledge representation and reasoning mechanism in discourse comprehension.</title>
<date>1982</date>
<booktitle>Proceedings of the 1982 European Conference on Artificial Intelligence.</booktitle>
<location>Orsay, France,</location>
<contexts>
<context position="5177" citStr="Litvak et al. 1982" startWordPosition="794" endWordPosition="797"> of speaking, we can 152 say that RMs embody certain agents that work as experts&amp;quot; in certain types of problems. They make use of the data coming from the text and their built-in knowledge about the given problem they are specialists of. They may interact together, engaging one another for obtaining additional information and to solve- certain subproblems of their particular problems. As such, RMs form a relatively loose, decentralized society of experts whose activity is chiefly directed by the immediate text structure. There is also a general, central &amp;quot;supervisor&amp;quot; in such a reasoning system (Litvak et al. 1982), but its role and influence appear more clearly on higher levels of reasoning and decision making. An RM is characterized by the basic properties described in the following four sections. (1) It has a built-in goal. As RMs function as &amp;quot;experts,&amp;quot; their task is to notice the problems they are experts for, and to solve them. The general end of any RM is to make sense of the situation to which it applies. But let us stress that this &amp;quot;making sense&amp;quot; does not necessarily amount to incorporating the corresponding event or situation into some goal-plan hierarchy. Instead, making sense may mean for the</context>
</contexts>
<marker>Litvak, Roosmaa, Saluveer, Oim, 1982</marker>
<rawString>Litvak S., Roosmaa T., Saluveer M., Oim H., On the interaction of knowledge representation and reasoning mechanism in discourse comprehension. Proceedings of the 1982 European Conference on Artificial Intelligence. Orsay, France, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Oim</author>
</authors>
<title>Episodes in the structure of discourse.</title>
<date>1980</date>
<editor>In: A. Narin&apos;yani (ed.),</editor>
<location>Novosibirsk,</location>
<note>(in Russian)</note>
<contexts>
<context position="1616" citStr="Oim 1980" startWordPosition="247" endWordPosition="248">lation of understanding to such types of knowledge processing as problem solving and planning (e.g., Black and Bower 1980, Wilensky 1981). Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding (e.g., Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980). We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind (Litvak et al. 1981), as well as on a more theoretical level (Oim 1980). To our mind, there are two general faults that characterize present day computer systems designed to understand coherent natural language texts. First, they make too heavy and rigorous use of predetermined knowledge schemes relating to the subject matter of texts and to the organization of reasoning processes which carry out understanding. Secondly, these predetermined knowledge and reasoning structures operate on levels of organization that are too far away from the level on which immediate text contents are presented. So the understanding processes modelled by these systems are prevailingl</context>
</contexts>
<marker>Oim, 1980</marker>
<rawString>Oim H., Episodes in the structure of discourse. In: A. Narin&apos;yani (ed.), Knowledge representation and modelling of understanding processes. Novosibirsk, 1980. (in Russian)</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Points: a theory of story content.</title>
<date>1980</date>
<tech>EEGS Memo No. UCB/ERL/M80/17.</tech>
<institution>University of California at Berkeley,</institution>
<contexts>
<context position="1369" citStr="Wilensky 1980" startWordPosition="205" endWordPosition="206">edge organization and representation, we are only beginning to guess what the corresponding processing mechanisms are and how they function, although an increasing number of papers has been devoted to these problems as well. There are studies of the relation of understanding to such types of knowledge processing as problem solving and planning (e.g., Black and Bower 1980, Wilensky 1981). Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding (e.g., Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980). We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind (Litvak et al. 1981), as well as on a more theoretical level (Oim 1980). To our mind, there are two general faults that characterize present day computer systems designed to understand coherent natural language texts. First, they make too heavy and rigorous use of predetermined knowledge schemes relating to the subject matter of texts and to the organization of reasoning processes which carry out understanding. Secondly,</context>
</contexts>
<marker>Wilensky, 1980</marker>
<rawString>Wilensky R., Points: a theory of story content. EEGS Memo No. UCB/ERL/M80/17. University of California at Berkeley, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Meta—planning: representing and using knowledge about planning in problem solving and language understanding.</title>
<date>1981</date>
<journal>Cognitive Science,</journal>
<volume>5</volume>
<contexts>
<context position="1144" citStr="Wilensky 1981" startWordPosition="172" endWordPosition="173">problems here at the present time is how and by which mechanisms these reasoning processes are controlled and directed. As the emphasis in the design of discourse understanding systems so far has been on the problems of knowledge organization and representation, we are only beginning to guess what the corresponding processing mechanisms are and how they function, although an increasing number of papers has been devoted to these problems as well. There are studies of the relation of understanding to such types of knowledge processing as problem solving and planning (e.g., Black and Bower 1980, Wilensky 1981). Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding (e.g., Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980). We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind (Litvak et al. 1981), as well as on a more theoretical level (Oim 1980). To our mind, there are two general faults that characterize present day computer systems designed to understand coherent natur</context>
</contexts>
<marker>Wilensky, 1981</marker>
<rawString>Wilensky R., Meta—planning: representing and using knowledge about planning in problem solving and language understanding. Cognitive Science, 1981, vol. 5 No. 3.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>