<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997605">
met*: A Method for Discriminating
Metonymy and Metaphor by Computer
</title>
<author confidence="0.999564">
Dan Fass.
</author>
<affiliation confidence="0.979225">
Simon Fraser University
</affiliation>
<bodyText confidence="0.995547">
The met* method distinguishes selected examples of metonymy from metaphor and from liter-
alness and anomaly in short English sentences. In the met* method, literalness is distinguished
because it satisfies contextual constraints that the nonliteral others all violate. Metonymy is
discriminated from metaphor and anomaly in a way that [1] supports Lakoff and Johnson&apos;s
(1980) view that in metonymy one entity stands for another whereas in metaphor one en-
tity is viewed as another, [2] permits chains of metonymies (Reddy 1979), and [3] allows
metonymies to co-occur with instances of either literalness, metaphor, or anomaly. Metaphor is
distinguished from anomaly because the former contains a relevant analogy, unlike the latter.
The met* method is part of Collative Semantics, a semantics for natural language processing,
and has been implemented in a computer program called meta5. Some examples of meta5&apos;s
analysis of metaphor and metonymy are given. The met* method is compared with approaches
from artificial intelligence, linguistics, philosophy, and psychology.
</bodyText>
<sectionHeader confidence="0.990126" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.883282">
Metaphor and metonymy are kinds of figurative language or tropes. Other tropes
include simile, irony, understatement (litotes), and overstatement (hyperbole).
</bodyText>
<subsectionHeader confidence="0.463806">
Example 1
</subsectionHeader>
<bodyText confidence="0.782662">
&amp;quot;My car drinks gasoline&amp;quot; (Wilks 1978, p. 199).
</bodyText>
<subsectionHeader confidence="0.684999">
Example 2
</subsectionHeader>
<bodyText confidence="0.980423461538461">
&amp;quot;The ham sandwich is waiting for his check&amp;quot; (Lakoff and Johnson 1980, p. 35).
Sentences (1) and (2) contain examples of metaphor and metonymy respectively. Nei-
ther sentence is literally true: cars do not literally drink nor do ham sandwiches literally
wait. Notice, though, that the two sentences are interpreted differently. &amp;quot;My car&amp;quot; in
(1) is commonly understood as resembling an animate drinker while in (2) &amp;quot;the ham
sandwich&amp;quot; is generally interpreted as referring to the person who ordered the ham
sandwich.
Most of the considerable literature on metaphor and the smaller one on metonymy
(see Van Noppen, De Knop and Jongen 1985; Shibles 1971) is from philosophy, lin-
guistics, and psychology. On the whole, the two phenomena remain vague, poorly
defined notions in that literature. In artificial intelligence (AI), detailed treatments of
either metaphor or metonymy are relatively scarce. Moreover, most of those treatments
are paper implementations that have not been coded up and run on a computer.
</bodyText>
<footnote confidence="0.6287935">
* Centre for Systems Science, Simon Fraser University, Burnaby, British Columbia, Canada V5A 156
© 1991 Association for Computational Linguistics
</footnote>
<note confidence="0.767288">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.999596476190476">
The met* (pronounced &amp;quot;met star&amp;quot;) method provides a means for recognizing se-
lected examples of metonymy and metaphor, and also anomaly and literalness, in
short English sentences.&apos; The method is part of Collative Semantics (hereafter CS),
which is a semantics for natural language processing. CS, and hence the met* method,
has been implemented in a program called meta5 (so called because it does more than
metaphor). The meta5 program is, as far as I know, the first system to recognize exam-
ples of metaphor and metonymy. To my knowledge, there is only one other working
program that might be said to recognize instances of metaphor (Martin 1988; 1990)
and two systems that appear to recognize cases of metonymy, TEAM (Grosz et al.
1987) and TACITUS (Hobbs and Martin 1987).
The rest of the paper is organized as follows. Section 2 surveys general issues
and approaches in metaphor and metonymy, notably the distinctive characteristics
of metaphor and metonymy, the relationship between metaphor and metonymy, and
the relationship between literalness and nonliteralness. Section 3 presents the met*
method, concentrating on the basic topology of the met* method algorithm. Section 4
shows details of representations and processes used in CS. Section 5 gives examples
of the meta5 program analyzing simple metaphors and metonymies. Descriptions get
progressively more detailed from Section 2 through to Section 5. Sections 6 and 7 de-
scribe some extensions to metaphor interpretation in CS and compare the met* method
against other approaches to metaphor and metonymy, especially computational ones.
A glossary of key terms is provided at the very end of the paper.
</bodyText>
<subsectionHeader confidence="0.435168">
2. Survey of Metonymy and Metaphor Research
</subsectionHeader>
<bodyText confidence="0.97513875">
Metonymy and metaphor are so poorly understood that widely divergent views exist
about them and their relationship to each other. This section reviews research on
metaphor (2.1), metonymy (2.2), the relationship between them (2.3), and the more
general relationship between literalness and nonliteralness (2.4).
</bodyText>
<subsectionHeader confidence="0.966603">
2.1 Metaphor
</subsectionHeader>
<bodyText confidence="0.9997894">
Four views of metaphor are critically discussed: the comparison view, the interactive
view, the selection restriction violation view, and the conventional metaphor view.
Computational examples of each kind are included by Gentner, Indurkhya, Hobbs,
Wilks, and Martin. Space does not permit discussion of other AT work on metaphor
by, e.g., Russell (1976) and Weiner (1984; 1985).
</bodyText>
<subsubsectionHeader confidence="0.935023">
2.1.1 The Comparison View. According to the comparison view
</subsubsectionHeader>
<bodyText confidence="0.985070444444444">
a metaphor is a comparison in which one term (the tenor or subject of the
comparison) is asserted to bear a partial resemblance (the ground of the
comparison) to something else (the vehicle), the resemblance being insufficient to
sustain a literal comparison. As with any comparison, there is always some
residual dissimilarity (the tension) between the terms involved in the comparison,
but comparison theorists tend not to emphasize this dissimilarity (Tourangeau
and Sternberg 1982, p. 205, their italics).
What is crucial in the comparison approach, then, is finding the correct ground
in a metaphor. According to Tourangeau and Sternberg, Aristotle proposed the first
</bodyText>
<footnote confidence="0.676987666666667">
1 The met* method takes its name from a remark made by Yorick Wilks. He used met* to refer
collectively to metonymy and metaphor: &amp;quot;&amp;quot;&amp;quot; is a match-anything symbol in the Unix operating system;
hence, the token &amp;quot;&apos;nee&amp;quot; matches the two tokens &amp;quot;metonymy&amp;quot; and &amp;quot;metaphor.&amp;quot;
</footnote>
<page confidence="0.988769">
50
</page>
<note confidence="0.783922">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.99873096969697">
comparison theory and suggested several principles for finding the ground of a metaphor.
Tourangeau and Sternberg reduce these principles to two basic ones: finding a
category to which the tenor and vehicle belong and constructing an analogy involving
them.
Gentner&apos;s (1983) Structure-Mapping Theory, which has been implemented in the
Structure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989), closely resembles
a comparison view of metaphor. The theory addresses literal similarity, analogy, ab-
straction, and anomaly, which Gentner refers to as four &amp;quot;kinds of comparison.&amp;quot; An
algorithm compares the semantic information from two concepts represented as sets
of properties. Properties are either &amp;quot;attributes,&amp;quot; one-place predicates like LARGE(x),
or &amp;quot;relations,&amp;quot; two-place predicates such as COLLIDE(x,y). The four kinds of compar-
ison are distinguished by the relative proportions of attributes and relations that are
matched, and the forms of mappings established between them. Mappings between
relations are sought before those between attributes. Pairs of relations are compared us-
ing the &amp;quot;systematicity principle&amp;quot; that regular structural correspondences should exist
between terms occupying the same positions in those relations. Mappings are purely
structural and independent of the content of the relations (i.e., the predicates).
Tourangeau and Sternberg (1982) list some problems with the comparison view,
including the following:
(a) that everything has some feature or category that it shares with everything
else, but we cannot combine just any two things in metaphor; (b) that the most
obvious shared features are often irrelevant to a reading of the metaphor; (c) that
even when the feature is relevant, it is often shared only metaphorically; ... and
(e) that metaphors are novel and surprising is hard to reconcile with the idea
that they rely completely on extant similarities (ibid., pp. 226-227).
Johnson (1980) also notes problem (a) with comparison theories, pointing out that
as a result they cannot account for the semantic tension between the two terms of a
metaphor:
the comparison theory ... tries to circumvent the experienced semantic strain by
interpreting metaphor as nothing but a way of comparing two things to see in
what respects they are alike. And since any two things are similar in some
respects, this kind of theory can never explain what is interesting and important
about metaphor (ibid., p. 52).
</bodyText>
<subsubsectionHeader confidence="0.981253">
2.1.2 The Interaction View. The interaction view focuses more upon the surprise and
</subsubsectionHeader>
<bodyText confidence="0.992125769230769">
novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212),
proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967),
Richards (1936), and Wheelwright (1962).
Interaction theorists argue that the vehicle of a metaphor is a template for seeing
the tenor in a new way. This reorganization of the tenor is necessary, because the
characteristics or features of the vehicle cannot be applied directly to the tenor;
the features they &apos;share&apos; are often only shared metaphorically. As Black (1962)
observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in
Black&apos;s example, in part because both are predators; but they are predators in
sharply different senses that may only strike us as similar when we interpret the
metaphor. In Black&apos;s reading of this metaphor, we see competition in social
relations as corresponding to predacity in beasts (Tourangeau and Sternberg
1982, pp. 212-213).
</bodyText>
<page confidence="0.99584">
51
</page>
<note confidence="0.800722">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.99801593877551">
A problem with the interaction view is that theorists have not provided much
detail about the processes involved, though Black (1962) does make some suggestions.
According to Black, tenor and vehicle... each have a &apos;system of commonplaces&apos;
associated with them. These commonplaces are stereotypes, not necessarily
definitional, not even necessarily true, just widely agreed upon. In interpreting
&apos;man is a wolf,&apos; we &apos;evoke the wolf-system of related commonplaces&apos; and are led
by them &apos;to construct a corresponding system of implications about the principal
subject (Man)&apos; (Black, 1962, p. 41). In Black&apos;s view, then, interpretation involves
not so much comparing tenor and vehicle for existing similarities, as construing
them in a new way so as to create similarity between them (Tourangeau and
Sternberg 1982, p. 213).
One might distinguish, then, two main differences between the interaction and
comparison views. First, similarities are &amp;quot;created&amp;quot; in the interaction view (accounting
for the novelty and surprise in a metaphor) whereas only pre-existing similarities
are found in the comparison view. Second, a whole system of similarities are evoked
between tenor and vehicle in the interactions view, whereas the comparisons view is
based upon finding a single similarity.
One version of the interaction view is the domains-interaction view, set forth by
Tourangeau and Sternberg (1982), who take the view that
features &apos;shared&apos; by tenor and vehicle are often at best only analogous features,
each limited in its application to one domain or another. Of course, some
features or dimensions are quite general, applying across the board to a number
of domains (p. 218).
Among comparison and interaction theorists, much attention had been paid to
selecting the comparisons or interactions in a metaphor. The importance of analogy
or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979),
Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mecha-
nisms have been advanced for highlighting certain comparisons or interactions, in-
cluding relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985).
Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Trans-
ference theory of metaphor can be viewed as a formalization of Black&apos;s interaction
theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relation-
ships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain
is imposed on the target domain, thereby shaping the features of the target domain,
which in turn produces changes in the features of the source domain, hence the &amp;quot;in-
teraction.&amp;quot; It is assumed that a structural analogy underlies every metaphor (ibid.,
p. 129).
A metaphor is identified with the formal notion of a T-MAP which is a pair ( F,S )
where F is a function that maps vocabulary of the source domain onto vocabulary
of the target domain and S is a set of sentences from the source domain which are
expected to transfer to the target domain. A metaphor is &amp;quot;coherent&amp;quot; if the transferred
sentences S are logically consistent with the axioms of the target domain, and &amp;quot;strongly
coherent&amp;quot; if they already lie in the deductive closure of those axioms (cf. Stallard 1987,
p. 181). S is thus the &amp;quot;implicative complex&amp;quot; of the source domain imposed on the target
domain. Every metaphorical interpretation of a given set of sentences is associated with
a T-MAP. There may be several possible T-MAPs for a set of sentences.
I would argue that Hobbs (1983a; 1983b) has also taken an interaction view of
metaphor. Hobbs&apos; goal has been to develop a unified process of discourse interpre-
tation based on the drawing of appropriate inferences from a large knowledge base,
</bodyText>
<page confidence="0.99657">
52
</page>
<note confidence="0.783381">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.975635555555556">
which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective in-
ferencing is concerned with drawing or refraining from drawing certain inferences in
a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same
or almost the same inferencing solutions. These solutions are found via four separate
semantic operations that all draw inferences from text (e.g., Hobbs 1977).
2.1.3 The Selection Restrictions Violations View. The selection restriction violation
view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the
anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this
view as a common one among linguists; Tourangeau and Sternberg (1982) list the
following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell
(1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this
list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where:
metaphor constitutes a violation of selection restriction rules within a given
context, where the fact of this violation is supposed to explain the semantic
tension one experiences in comprehending any live metaphor.
The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a
selection restrictions view and a comparison view. In the theory, information about
word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An
algorithm matches pairs of semantic formulas, seeking satisfied or violated preferences
between them. A satisfied preference indicates a literal semantic relation; a violated
preference indicates either a metaphorical or anomalous one. This part of the theory
is implemented in a machine translation system (Wilks 1973).
To distinguish metaphor from anomaly, a different knowledge structure and a
second algorithm are used. The algorithm, called projection, operates on a knowl-
edge structure, called a pseudo-text, that contains lists of templates (a further kind of
knowledge structure) linked by case ties. A brief example of projection is given for (1).
Example 3
&amp;quot;My car drinks gasoline.&amp;quot;
Projection operates only on preference violations. The best representation of (1) con-
tains a preference violation, so projection is used. The algorithm compares the template
representation for the sentence
[my+car drink gasoline]
against templates from the pseudo-text of &apos;car&apos; seeking &amp;quot;the closest match,&amp;quot; and selects
fICengine (USE)#liquidl. (USE) is projected onto drink in the sentence representation
which becomes
[ny+car use gasoline]
</bodyText>
<footnote confidence="0.9044985">
Example 3
&amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242).
</footnote>
<page confidence="0.995006">
53
</page>
<note confidence="0.505087">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.898693571428572">
Example 4
&amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51).
Example 5
&amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134).
Example 6
&amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII).
The main problem with the selection restrictions view is that perfectly well-formed
sentences exist that have a metaphorical interpretation and yet contain no selection
restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3),
there is a literal interpretation when uttered about a stone and a metaphorical one
when said about a decrepit professor emeritus. Sentences (4), (5) and (6) also have
twin interpretations.
The existence of such sentences suggests that a condition that occasionally holds
(i.e., a selection restriction violation) has been elevated into a necessary condition
of metaphor (Johnson 1980). Moreover, viewing metaphor only in terms of selection
restriction violations ignores the influence of context:
We seem to interpret an utterance metaphorically when to do so makes sense of
more aspects of the total context than if the sentence is read literally. Consider
the simple case of the sentence All men are animals as uttered by Professor X to an
introductory biology class and as uttered later by one of his female students to
her roommate upon returning from a date. In the latter instance the roommate
understands the utterance as metaphorical (ibid., p. 51).
In a similar way, Ortony (1980) suggests that metaphor should be thought of as
contextually anomalous. This means that a literal interpretation of the expression,
be it a word, phrase, sentence, or an even larger unit of text, fails to fit the
context (p. 73, his italics),
so whether or not a sentence is a metaphor depends upon the context in which it
is used:
if something is a metaphor then it will be contextually anomalous if interpreted
literally.... Insofar as the violation of selection restrictions can be interpreted in
terms of semantic incompatibilities at the lexical level, such violations may
sometimes be the basis of the contextual anomaly (ibid., p. 74).
2.1.4 The Conventional Metaphor View. Lakoff and Johnson (1980) have popular-
ized the idea of conventional metaphors, also known as conceptual metaphors. They
distinguish three main kinds: orientational, ontological, and structural. Orientational
metaphors are mainly to do with kinds of spatial orientation like up-down, in-out,
and deep-shallow. Example metaphors include MORE IS UP and HAPPY IS UP. They
arise from human experience of spatial orientation and thus develop from the sort of
bodies we have and the way they function in our physical environment.
Ontological metaphors arise from our basic human experiences with substances
and physical objects (especially our own bodies). Some examples are TIME IS A SUB-
STANCE, THE MIND IS AN ENTITY, and THE VISUAL FIELD IS A CONTAINER.
</bodyText>
<page confidence="0.996976">
54
</page>
<note confidence="0.784056">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.998820388888889">
Structural metaphors are elaborated orientational and ontological metaphors (cf.
Lakoff and Johnson 1980) in which concepts that correspond to natural kinds of ex-
perience, e.g., PHYSICAL ORIENTATIONS, SUBSTANCES, WAR, JOURNEYS, and
BUILDINGS, are used to define other concepts, also natural kinds of experience,
e.g., LOVE, TIME, IDEAS, UNDERSTANDING, and ARGUMENTS. Some examples
of structural metaphors are ARGUMENT IS WAR and TIME IS MONEY.
The ARGUMENT IS WAR metaphor forms a systematic way of talking about the
battling aspects of arguing.... Because the metaphorical concept is systematic,
the language we use to talk about the concept is systematic (ibid., p. 5).
What Lakoff and Johnson fail to discuss is how metaphors in general, let alone
individual metaphorical concepts, are recognized. Martin&apos;s (1988; 1990) work has ad-
dressed this issue. He has pursued a conventional metaphor view using KODIAK
(Wilensky 1984), a variant of Brachman&apos;s KLONE knowledge representation language.
Within KODIAK, metaphorical relationships are represented using a primitive link
type called a &amp;quot;VIEW.&amp;quot; A VIEW &amp;quot;is used to assert that... one concept may in cer-
tain circumstances be considered as another &amp;quot;(Martin 1990, p. 59). In Martin&apos;s work,
&amp;quot;metaphor-maps,&amp;quot; a kind of VIEW (ibid., p. 64), are used to represent conventional
metaphors and the conceptual information they contain.
</bodyText>
<subsectionHeader confidence="0.999691">
2.2 Metonymy
</subsectionHeader>
<bodyText confidence="0.999639">
Metonymy involves &amp;quot;using one entity to refer to another that is related to it&amp;quot; (Lakoff
and Johnson 1980, p. 35).
</bodyText>
<subsectionHeader confidence="0.866206">
Example 2
</subsectionHeader>
<bodyText confidence="0.997564">
&amp;quot;The ham sandwich is waiting for his check.&amp;quot;
For example, in (2) the metonymy is that the concept for ham sandwich is related
to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot;
Several attempts have been made to organize instances of metonymy into cat-
egories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or &amp;quot;metonymic
concepts,&amp;quot; as Lakoff and Johnson call them. A common metonymic concept is PART
FOR WHOLE, otherwise known as synechdoche.
</bodyText>
<subsectionHeader confidence="0.976462">
Example 7
</subsectionHeader>
<bodyText confidence="0.994276">
&amp;quot;Dave drank the glasses&amp;quot; (= the liquid in the glasses).
</bodyText>
<subsectionHeader confidence="0.937373">
Example 8
</subsectionHeader>
<bodyText confidence="0.9965095">
&amp;quot;The kettle is boiling&amp;quot; (= the liquid in the kettle) (Waldron 1967, p. 186; Yamanashi
1987, p. 78).
CONTAINER FOR CONTENTS, another metonymic concept, occurs in (7) between
&apos;drink&apos; and the sense of &apos;glasses&apos; meaning &amp;quot;containers,&amp;quot; and also in (8). In (7), &apos;drink&apos;
has an object preference for a potable liquid, but there is a preference violation because
glasses are not potable liquids. It is not glasses that are drunk, but the potable liquids
in them. There is a relationship here between a CONTAINER (a glass) and its typical
CONTENTS (a liquid): this relationship is the metonymic concept CONTAINER FOR
</bodyText>
<page confidence="0.993618">
55
</page>
<figure confidence="0.218670230769231">
Computational Linguistics Volume 17, Number 1
CONTENTS. Below are examples of two further metonymic concepts (from Lakoff
and Johnson 1980, p. 38, italics in original).
PRODUCER FOR PRODUCT
&amp;quot;I&apos;ll have a Leiwenbrdu. &amp;quot;
&amp;quot;He bought a Ford.&amp;quot;
&amp;quot;He&apos;s got a Picasso in his den.&amp;quot;
&amp;quot;I hate to read Heidegger.&amp;quot;
OBJECT USED FOR USER
&amp;quot;The sax has the flu today.&amp;quot;
&amp;quot;The BLT is a lousy tipper.&amp;quot;**2
&amp;quot;The buses are on strike.&amp;quot;
Example 9
</figure>
<bodyText confidence="0.964601">
&amp;quot;You&apos;ll find better ideas than that in the library&amp;quot; (Reddy 1979, p. 309).
Reddy (1979) has observed that metonymies can occur in chains. He suggests that
(9) contains a chain of PART FOR WHOLE metonymies between &apos;ideas&apos; and &apos;library&apos;:
the ideas are expressed in words, words are printed on pages, pages are in books, and
books are found in a library.
</bodyText>
<subsectionHeader confidence="0.898378">
Example 10
</subsectionHeader>
<bodyText confidence="0.959351">
&amp;quot;I found an old car on the road. The steering wheel was broken&amp;quot; (Yamanashi 1987, p. 79).
</bodyText>
<subsectionHeader confidence="0.941373">
Example 11
</subsectionHeader>
<bodyText confidence="0.9892645">
&amp;quot;We had a party in a mysterious room. The walls were painted in psychedelic color&amp;quot;
(ibid.).
</bodyText>
<subsectionHeader confidence="0.924945">
Example 12
</subsectionHeader>
<bodyText confidence="0.977921">
A: &amp;quot;I bought an interesting book.&amp;quot; B: &amp;quot;Who is the author?&amp;quot; (ibid.).
</bodyText>
<subsectionHeader confidence="0.968339">
Example 13
</subsectionHeader>
<bodyText confidence="0.998727285714286">
&amp;quot;He happened to die of some disease, though I don&apos;t know what the cause was&amp;quot; (ibid.).
Yamanashi (1987) points out that basic metonymic relationships like part-whole
and cause-result often also link sentences. According to him, the links in (10) and (11)
are PART-WHOLE relations, the one in (12) is PRODUCT-PRODUCER, and the one
in (13) is a CAUSE-RESULT relation.
There has been some computational work on metonymy (Weischedel and Sond-
heimer 1983; Grosz et al. 1987; Hobbs and Martin 1987; Stallard 1987; Wilensky 1987).
The TEAM project (Grosz et al. 1987) handles metonymy, though metonymy is not
mentioned by name but referred to instead as &amp;quot;coercion,&amp;quot; which &amp;quot;occurs whenever
some property of an object is used to refer indirectly to the object&amp;quot; (ibid., p. 213).
Coercion is handled by &amp;quot;coercion-relations;&amp;quot; for example, a coercion relation could be
used to understand that &apos;Fords&apos; means &amp;quot;cars whose CAR-MANUFACTURER is Ford&amp;quot;
(in Lakoff and Johnson&apos;s terms, this is an example of a PRODUCER FOR PRODUCT
metonymic concept).
</bodyText>
<page confidence="0.9491015">
2 A BLT is a bacon, lettuce, and tomato sandwich.
56
</page>
<subsectionHeader confidence="0.632637">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.998065724137931">
Grosz et al. (1987) note a similarity between coercion (i.e., metonymy) and modifi-
cation in noun-noun compounds, and use &amp;quot;modification relations&amp;quot; to decide whether,
e.g., &amp;quot;U.S. ships&amp;quot; means &amp;quot;ships of U.S. registry&amp;quot; or &amp;quot;ships whose destination is the U.S.&amp;quot;
Hobbs and Martin (1987) and Stallard (1987) also discuss the relationship between
metonymy and nominal compounds. Hobbs and Martin treat the two phenomena
as twin problems of reference resolution in their TACITUS system. They argue that
resolving reference requires finding a knowledge base entity for an entity mentioned in
discourse (i.e., what that entity refers to), and suggest that the resolution of metonymy
and nominal compounds both require discovering an implicit relation between two
entities referred to in discourse. The example of metonymy they show is &amp;quot;after the
alarm,&amp;quot; which really means after the sounding of the alarm.
Hobbs and Martin seem to assume a selection restrictions approach to metonymy
because metonymy is sought after a selection restrictions violation (ibid., p. 521). In
their approach, solving metonymy involves finding: [1] the referents for &apos;after&apos; and
&apos;alarm&apos; in the domain model, which are after(e0, a) and alarm(a); [2] an implicit entity
z to which &apos;after&apos; really refers, which is after(eo, z); and [3] the implicit relation between
the implicit entity z and the referent of &apos;alarm,&apos; q(z, a).
Like Hobbs and Martin (1987), Stallard (1987) translates language into logical form.
Stallard argues that with nominal compounds and metonymies &amp;quot;the problem is deter-
mining the binary relation which has been &apos;elided&apos; from the utterance&amp;quot; (ibid., p. 180)
and suggests shifting the argument place of a predicate &amp;quot;by interposing an arbitrary,
sortally compatible relation between an argument place of the predicate and the ac-
tual argument&amp;quot; (ibid., p. 182). Stallard notes that &amp;quot;in any usage of the metonomy (sic)
operation there is a choice about which of two clashing elements to extend&amp;quot; (ibid.).
Stallard&apos;s work has not yet been implemented (ibid., p. 184).
Stallard (1987) also briefly discusses anaphora resolution. Brown (1990) is be-
ginning research on metonymy and reference resolution, particularly pronouns. This
should prove a promising line of investigation because metonymy and anaphora share
the function of allowing one entity to refer to another entity.
</bodyText>
<subsectionHeader confidence="0.870768">
Example 2
</subsectionHeader>
<bodyText confidence="0.9991775">
&amp;quot;The ham sandwich is waiting for his check&amp;quot; (= the male person who ordered the
ham sandwich).
</bodyText>
<subsectionHeader confidence="0.973569">
Example 14
</subsectionHeader>
<bodyText confidence="0.995283333333333">
&amp;quot;He is waiting for his check&amp;quot; (= the male person).
This similarity of function can be seen in comparing (2), which is metonymic, with
(14), which is anaphoric.
</bodyText>
<subsectionHeader confidence="0.999721">
2.3 Relationship between Metonymy and Metaphor
</subsectionHeader>
<bodyText confidence="0.996492625">
Both metonymy and metaphor have been identified as central to the development
of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron
1967). Some of the best examples of the differences between the two phenomena come
from data used in studies of metonymic and metaphorical effects on language change.
Nevertheless, there are widely differing views on which phenomenon is the more
important. Some argue that metaphor is a kind of metonymy, and others propose that
metonymy is a kind of metaphor, while still others suggest that they are quite different
(see Fass 1988c).
</bodyText>
<page confidence="0.99348">
57
</page>
<note confidence="0.300776">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.999980142857143">
Among the third group, two differences between metonymy and metaphor are
commonly mentioned. One difference is that metonymy is founded on contiguity
whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962).
Contiguity and similarity are two kinds of association. Contiguity refers to a state
of being connected or touching whereas similarity refers to a state of being alike in
essentials or having characteristics in common (Mish 1986).
A second difference, advanced by Lakoff and Johnson (1980) for example, is that
metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and
its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has
primarily a referential function, that is, it allows us to use one entity to stand for
another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses
on certain aspects of what is being referred to.
There is little computational work about the relationship between metonymy and
metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in
word sense extension. According to him, metonymy shifts the argument place of a
predicate, whereas metaphor shifts the whole predicate. Hobbs (1983a; 1983b) writes
about metaphor, and he and Martin (1987) develop a theory of &amp;quot;local pragmatics&amp;quot; that
includes metonymy, but Hobbs does not seem to have written about the relationship
between metaphor and metonymy.
In knowledge representation, metonymic and metaphorical relations are both rep-
resented in the knowledge representation language CycL (Lenat and Guha 1990).
</bodyText>
<subsectionHeader confidence="0.998737">
2.4 Literalness and Nonliteralness
</subsectionHeader>
<bodyText confidence="0.98716932">
Much of the preceding material assumes what Gibbs (1984) calls the &amp;quot;literal meanings
hypothesis,&amp;quot; which is that
sentences have well defined literal meanings and that computation of the literal
meaning is a necessary step on the path to understanding speakers&apos; utterances
(ibid., p. 275).
There are a number of points here, which Gibbs expands upon in his paper. One
point concerns the traditional notion of literal meaning, that all sentences have literal
meanings that are entirely determined by the meanings of their component words,
and that the literal meaning of a sentence is its meaning independent of context.
A second point concerns the traditional view of metaphor interpretation, though
Gibbs&apos; criticism applies to metonymy interpretation also. Using Searle&apos;s (1979) views
on metaphor as an example, he characterizes the typical model for detecting nonliteral
meaning as a three-stage process: [11 compute the literal meaning of a sentence, [21
decide if the literal meaning is defective, and if so, [3] seek an alternative meaning,
i.e., a metaphorical one (though, presumably, a metonymic interpretation might also
be sought at this stage). Gibbs (1984, p. 275) concludes that the distinction between
literal and metaphoric meanings has &amp;quot;little psychological validity.&amp;quot;
Among AT researchers, Martin (1990) shares many of Gibbs&apos;s views in criticizing
the &amp;quot;literal meaning first approach&amp;quot; (ibid., p. 24). Martin suggests a two-stage process
for interpreting sentences containing metaphors: [1] parse the sentence to produce
a syntactic parse tree plus primal (semantic) representation, and [21 apply inference
processes of &amp;quot;concretion&amp;quot; and &amp;quot;metaphoric viewing&amp;quot; to produce the most detailed
semantic representation possible.
The primal representation represents a level of semantic interpretation that is
explicitly in need of further processing. Although it is obviously related to what
</bodyText>
<page confidence="0.998075">
58
</page>
<subsectionHeader confidence="0.633012">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.965595555555556">
has traditionally been called a literal meaning, it should not be thought of as a
meaning at all. The primal representation should be simply considered as an
intermediate stage in the interpretation process where only syntactic and lexical
information has been utilized (ibid., p. 90, his italics).
However, Martin believes that at least some sentence meaning is independent of
context because the primal representation contains part of the primal content of an
utterance and
[t]he Primal Content represents the meaning of an utterance that is derivable
from knowledge of the conventions of a language, independent of context (ibid.).
</bodyText>
<subsectionHeader confidence="0.998834">
2.5 Review Summary
</subsectionHeader>
<bodyText confidence="0.999946692307692">
The metaphor literature contains many differing views, including the comparison,
interaction, selection restrictions, and conventional metaphors views. AT research on
metaphor includes all of these views. Of the AT research, only Martin&apos;s work has
been implemented to my knowledge. Among the points raised are that metaphorical
sentences exist that do not contain selection restriction violations and that metaphor
requires interpretation in context. The much smaller metonymy literature stresses the
selection restrictions view too. The TEAM and TACITUS systems both seem to process
metonymics.
The two main differences commonly noted between metonymy and metaphor
are in their function (referential for metonymy and understanding with metaphor)
and the kind of relationship established (contiguity in metonymy versus similarity
in metaphor). No one to my knowledge has a working system that discriminates
examples of metaphor and metonymy.
</bodyText>
<sectionHeader confidence="0.858535" genericHeader="method">
3. met* Method
</sectionHeader>
<bodyText confidence="0.999809875">
In this section, the basic met* algorithm is outlined. The met* method is based on the
selection restriction, also known as the preference. Metonymy, metaphor, literalness,
and anomaly are recognized by evaluating preferences, which produces four kinds of
basic &amp;quot;preference-based&amp;quot; relationship or semantic relation: literal, metonymic, metaphor-
ical, and anomalous. Within the method, the main difference between metonymy and
metaphor is that a metonymy is viewed as consisting of one or more semantic re-
lationships like CONTAINER FOR CONTENTS and PART FOR WHOLE, whereas a
metaphor is viewed as containing a relevant analogy.
I agree with Ortony&apos;s remark that metaphor be viewed as contextual anomaly, but
would suggest two modifications. First, not just metaphor but all of the preference-
based relations should be understood in terms of the presence or absence of contextual
constraint violation. Second, I prefer the term contextual constraint violation because
[1] one of the phenomena detected by contextual violation is anomaly and [2] the
selection restriction/preference (on which the met* method is based) is a kind of
lexical contextual constraint. The section starts with an explanation of some of the
linguistic background behind the met* method.
</bodyText>
<subsectionHeader confidence="0.999832">
3.1 Linguistic Background
</subsectionHeader>
<bodyText confidence="0.962553666666667">
I have argued elsewhere (Fass 1989a) that understanding natural language (or seman-
tic interpretation) be viewed as the integration of constraints from language and from
context. Some language constraints are syntactic, while others are semantic. Some
</bodyText>
<page confidence="0.995114">
59
</page>
<note confidence="0.300481">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.999357461538461">
language constraints are lexical constraints; that is, constraints possessed by lexical
items (words and fixed phrases). Lexical syntactic constraints include those on word
order, number, and tense. This sec tion describes three lexical semantic constraints: pref-
erences, assertions, and a lexical notion of relevance.
Preferences (Wilks 1973), selection restrictions (Katz 1964), and expectations
(Schank 1975) are the same (see Fass 1989c; Fass and Wilks 1983; Wilks and Fass in
press): all are restrictions possessed by senses of lexical items of certain parts of speech
about the semantic classes of lexical items with which they co-occur. Thus an adjective
sense has a preference for the semantic class of nouns with which it co-occurs and a
verb sense has preferences for the semantic classes of nouns that fill its case roles. For
example, the main sense of the verb &apos;drink&apos; prefers an animal to fill its agent case role,
i.e., it is animals that drink.
The assertion of semantic information was noted by Lees (1960) in the formation
of noun phrases and later developed by Katz (1964) as the process of &amp;quot;attribution.&amp;quot;
Assertions contain information that is possessed by senses of lexical items of certain
parts of speech and that is imposed onto senses of lexical items of other parts of speech,
e.g., the adjective &apos;female&apos; contains information that any noun to which it applies is
of the female sex.
Lexical syntactic and semantic constraints are enforced at certain places in sen-
tences which I call dependencies. Within a dependency, the lexical item whose con-
straints are enforced is called the source and the other lexical item is called the target
(after Martin 1985). Syntactic dependencies consist of pairs of lexical items of certain
parts of speech in which the source, an item from one part of speech, applies one or
more syntactic constraints to the target, another lexical item. Examples of source-target
pairs include a determiner and a noun, an adjective and a noun, a noun and a verb,
and an adverb and a verb.
</bodyText>
<subsectionHeader confidence="0.400009">
Example 15
</subsectionHeader>
<bodyText confidence="0.992382045454545">
&amp;quot;The ship ploughed the waves.&amp;quot;
Semantic dependencies occur in the same places as syntactic dependencies. The
(metaphorical) sentence (15) contains four semantic dependencies: between the deter-
miner &apos;the&apos; and the noun &apos;ship,&apos; between &apos;ship&apos; and the verb stem &apos;plough,&apos; between
&apos;the&apos; and the noun &apos;waves,&apos; and between &apos;waves&apos; and &apos;plough.&apos; In each semantic de-
pendency, one lexical item acts as the source and applies constraints upon the other
lexical item, which acts as the target. In (15), &apos;the&apos; and &apos;plough&apos; both apply constraints
upon &apos;ship,&apos; and &apos;the&apos; and &apos;plough&apos; apply constraints on &apos;waves.&apos; Semantic dependen-
cies exist between not just pairs of lexical items but also pairs of senses of lexical items.
For example, the metaphorical reading of (15) is because &apos;waves&apos; is understood as
being the sense meaning &amp;quot;movement of water,&amp;quot; not for example the sense meaning
&amp;quot;movement of the hand.&amp;quot;
Semantic relations result from evaluating lexical semantic constraints in sentences.
Every semantic relation has a source (a lexical item whose semantic constraints are
applied) and a target (a lexical item which receives those constraints). Other terms
used to refer to the source and target in a semantic relation include: vehicle and tenor
(Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term
and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject
and primary subject (Black 1979), source and destination (Winston 1980), old domain
and new domain (Hobbs 1983a), and base and target (Gentner 1983).
In CS, seven kinds of semantic relation are distinguished: literal, metonymic,
metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may
</bodyText>
<page confidence="0.997097">
60
</page>
<subsectionHeader confidence="0.632879">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.999445625">
not be exhaustive — there could be others). Combinations of these seven semantic
relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, re-
dundancy, contradiction, contrariness, and novelty. Semantic relations belong to two
classes, the preference-based and assertion-based classes of relations, depending on the
kind of lexical semantic constraint enforced. The preference-based class of semantic
relations, which are the focus of this paper, contains literal, metonymic, metaphorical,
and anomalous semantic relations. The assertion-based class of relations are described
in greater length in Pass (1989a).
</bodyText>
<figureCaption confidence="0.83777925">
Figure 1 shows the met* method laid out as a flow chart and illustrates how the
preference-based class of semantic relations is discriminated. A satisfied preference
(diamond 1) distinguishes literal relations from the remaining three relations, which
are all nonliteral.
</figureCaption>
<subsectionHeader confidence="0.675107">
Example 16
</subsectionHeader>
<bodyText confidence="0.893450666666667">
&amp;quot;The man drank beer.&amp;quot;
There is a literal relation between &apos;man&apos; and &apos;drink&apos; in (16) because &apos;drink&apos; prefers an
animal as its agent and a man is a type of animal so the preference is satisfied.
</bodyText>
<subsectionHeader confidence="0.949236">
Example 7
</subsectionHeader>
<bodyText confidence="0.9883185">
&amp;quot;Dave drank the glasses&amp;quot; (= potable liquid in the glasses CONTAINER FOR CON-
TENTS).
</bodyText>
<subsectionHeader confidence="0.886611">
Example 17
</subsectionHeader>
<bodyText confidence="0.975144">
&amp;quot;Denise drank the bottle&amp;quot; (= potable liquid from the bottle —4 CONTAINER FOR CON-
TENTS).
</bodyText>
<figureCaption confidence="0.8321945">
Figure 1
The met* method
</figureCaption>
<figure confidence="0.923708090909091">
1
satisfied
preference
(contextual
constraint)
61
Computational Linguistics Volume 17, Number 1
Example 18
&amp;quot;Anne reads Steinbeck&amp;quot; (= writings of Steinbeck ARTIST FOR ART FORM).
Example 19
&amp;quot;Ted played Bach&amp;quot; (= music of Bach ARTIST FOR ART FORM).
</figure>
<bodyText confidence="0.99866104">
Metonymy is viewed as a kind of domain-dependent inference. The process of
finding metonymies is called metonymic inferencing. The metonymic concepts presently
used are adapted from the metonymic concepts of Lakoff and Johnson (1980). Two of
the metonymic concepts used are CONTAINER FOR CONTENTS and ARTIST FOR
ART FORM. In (19), for example, Ted does not literally play the composer Bach — he
plays music composed by him.
As Figure 1 shows, a metonymy is recognized in the met* method if a metonymic
inference (diamond 2) is found. Conversely, if no successful inference is found then no
metonymy is discovered and a metaphorical or anomalous semantic relation is then
sought. A successful inference establishes a relationship between the original source
or the target (&amp;quot;one entity&amp;quot;) and a term (&amp;quot;another that is related to it&amp;quot;) that refers to
one of them.
Like Stallard (1987), who noted that &amp;quot;in any usage of the metonomy (sic) operation
there is a choice about which of two clashing elements to extend&amp;quot; (ibid., p. 182), the
met* method allows for metonymies that develop in different &amp;quot;directions.&amp;quot; A successful
inference is sometimes directed &amp;quot;forward&amp;quot; from the preference or &amp;quot;backward&amp;quot; from
the target, depending on the metonymic concept (more on this shortly). It is this
direction of inferencing that determines whether the source or target is substituted
in a successful metonymy. The substitute source or target is used to discover another
semantic relation that can be literal, metonymic again, metaphorical, or anomalous.
In Figure 1, the presence of a relevant analogy (diamond 3) discriminates metaphor-
ical relations from anomalous ones. No one else (to my knowledge) has emphasized
the role of relevance in the discovery of an analogy central to a metaphor though, as
noted in Section 2.2, the importance of relevance in recognizing metaphors and the
centrality of some analogy have both been discussed.
</bodyText>
<subsectionHeader confidence="0.600901">
Example 20
</subsectionHeader>
<bodyText confidence="0.99649">
&amp;quot;The car drank gasoline&amp;quot; (adapted from Wilks 1978).
The form of relevance used is a lexical notion — i.e., the third kind of lexical semantic
constraint — that what is relevant in a sentence is given by the sense of the main
sentence verb being currently analyzed. Thus, it is claimed that the semantic relation
between &apos;car&apos; and &apos;drink&apos; in (20) is metaphorical because there is a preference violation
and an underlying relevant analogy between &apos;car&apos; and &apos;animal,&apos; the preferred agent of
&apos;drink.&apos; A car is not a type of animal, hence the preference violation. However, what is
relevant in (20) is drinking, and there is a relevant analogy that animals and cars both
use up a liquid of some kind: animals drink potable liquids while cars use gasoline.
Hence the metaphorical relation between &apos;car&apos; and &apos;drink.&apos;
Metaphor recognition in the met* method is related to all four views of metaphor
described in Section 2. Recognition is viewed as a two-part process consisting of [1]
a contextual constraint violation and [2] a set of &amp;quot;correspondences&amp;quot; including a key
correspondence, a relevant analogy. The contextual constraint violation may be a pref-
erence violation, as in the selection restrictions view of metaphor. The set of &amp;quot;corre-
spondences&amp;quot; is rather like the system of commonplaces between tenor and vehicle in
the interaction view. The relevant analogy is related to the comparison and interaction
</bodyText>
<page confidence="0.995591">
62
</page>
<subsectionHeader confidence="0.476761">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.9608956875">
views, which emphasize a special comparison or an analogy as central to metaphor.
Moreover, the relevant analogies seem to form groupings not unlike the conceptual
metaphors found in the conventional view.
Example 21
&amp;quot;The idea drank the heart.&amp;quot;
Anomalous relations have neither the semantic relationships of a metonymic rela-
tion nor the relevant analogy of a metaphorical relation. Hence the semantic relation
between &apos;idea&apos; and &apos;drink&apos; is anomalous in (21) because &apos;idea&apos; is not a preferred agent
of &apos;drink&apos; and no metonymic link or relevant analogy can be found between animals
(the preferred agent) and ideas; that is, &apos;idea&apos; in (21) does not use up a liquid like &apos;car&apos;
does in (20). This is not to say that an anomalous relation is uninterpretable or that
no analogy can possibly be found in one. In special circumstances (for example, in a
poem), search for analogies might be expanded to permit weaker analogies, thereby
allowing &amp;quot;ideas drinking&amp;quot; to be interpreted metaphorically.
The topology of the flow chart in Figure 1 results from needing to satisfy a number
of observations about the preference-based phenomena, particularly metonymy:
</bodyText>
<listItem confidence="0.9938382">
1. literalness is distinct from the others, which are all nonliteral;
2. metonymies can occur in chains (Reddy 1979);
3. metonymy always seems to occur with one of the other three; and
4. metaphor and anomaly are the hardest to tell apart (and thus require the
most extended processing to distinguish).
</listItem>
<bodyText confidence="0.878451428571429">
Hence a preference-based semantic relation can be either a single relation or a
multi-relation. A single relation consists of one literal, metaphorical, or anomalous re-
lation. A multi-relation contains one literal, metaphorical, or anomalous relation plus
either a single metonymy or a chain of metonymies. All these combinations, but only
these, are derivable from Figure 1.
Note that in the met* method as presented in Figure 1, semantic relations are
tried in a certain order: literal, metonymic, metaphorical, and finally anomalous. This
ordering implies that a literal interpretation is sought before a nonliteral one (cf. Harris
1976). The ordering results from thinking about discriminating the semantic relations
in serial processing terms rather than parallel processing terms, particularly the serial
order in which selection restrictions are evaluated and metonymic inference rules are
tried: satisfied selection restrictions (indicating literalness) then metonymic inference
(metonymy) then violated selection restrictions (metaphor or anomaly).
Gibbs (1984) criticizes the idea that literal and nonliteral meaning can be discrimi-
nated in ordered processing stages. My response is that if the met* method is viewed in
parallel processing terms then literal, metonymic, metaphorical, and anomalous inter-
pretations are all sought at the same time and there is no ordering such that the literal
meaning of a sentence is computed first and then an alternative meaning sought if
the literal meaning is defective. Gibbs&apos; other main criticism, concerning the traditional
analysis of sentence meaning as composed from word meanings and independent of
context, will be discussed in Section 7.
</bodyText>
<page confidence="0.990998">
63
</page>
<figure confidence="0.468449">
Computational Linguistics Volume 17, Number 1
4. Collative Semantics
</figure>
<bodyText confidence="0.960255720930233">
CS is a semantics for natural language processing that extends many of the main
ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and
Fass in press). CS has four components: sense-frames, collation, semantic vectors, and
screening. The met* method is part of the process of collation. Fuller and more general
descriptions of the four components appear in Fass (1988a; 1989b).
Sense-frames are dictionary entries for individual word senses. Sense-frames are
composed of other word senses that have their own sense-frames, much like Quillian&apos;s
(1967) planes. Each sense-frame consists of two parts, an arcs section and a node section,
that correspond to the genus and differentia commonly found in dictionary definitions
(Amsler 1980).
The arcs part of a sense-frame contains a labeled arc to its genus term (a word
sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a
densely structured semantic network of word senses called the sense-network. The node
part of a sense-frame contains the differentia of the word sense defined by that sense-
frame, i.e., information distinguishing that word sense from other word senses sharing
the same genus. The two lexical semantic constraints mentioned earlier, preferences
and assertions, play a prominent part in sense-frame nodes.
Sense-frame nodes for nouns (node-type 0) resemble Wilks&apos; (1978) pseudo-texts.
The nodes contain lists of two-element and three-element lists called cells. Cells contain
word senses and have a syntax modeled on English. Each cell expresses a piece of
functional or structural information and can be thought of as a complex semantic
feature or property of a noun. Figure 2 shows sense-frames for two senses of the noun
&apos;crook.&apos; Crookl is the sense meaning &amp;quot;thief&amp;quot; and crook2 is the shepherd&apos;s tool.
All the terms in sense-frames are word senses with their own sense-frames or
words used in a particular sense that could be replaced by word senses. It1 refers
to the word sense being defined by the sense-frame so, for example, crookl can be
substituted for it1 in Iit1, steall, valuables11. Common dictionary practice is followed
in that word senses are listed separately for each part of speech and numbered by
frequency of occurrence. Hence in crook2, the cell [shepherdl, usel, it11 contains the
noun sense shepherd1 while the cell [itl, shepherdl, sheep11 contains the verb sense
shepherdl (in a three-element cell, the second position is always a verb, and the first
and third positions are always nouns).
Sense-frame nodes for adjectives, adverbs and other modifiers (node-type 1) con-
tain preferences and assertions but space does not permit a description of them here.
Sense-frame nodes for verbs and prepositions (node-type 2) are case frames con-
taining case subparts filled by case roles such as &apos;agent,&apos; object,&apos; and &apos;instrument.&apos;
Case subparts contain preferences, and assertions if the verb describes a state change.
sf(crookl, sf(crook2,
[[arcs, [[arcs,
Usupertype, [[supertype, stick1M,
[node°, [node0,
[[itl, steall, valuables-1H). [[shepherdl, usel, ti 1.
[itl, shepherdl, sheepin).
</bodyText>
<figureCaption confidence="0.817414">
Figure 2
</figureCaption>
<bodyText confidence="0.37703">
Sense-frames for crook1 and crook2 (noun senses)
</bodyText>
<page confidence="0.991347">
64
</page>
<subsectionHeader confidence="0.89456">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.833435625">
sf(eatl, sf(drinkl,
[faros, [[arcs,
[[supertype, [ingestl, espendl MI, (isupertype, [ingestl, expendl MI,
[node2. [n ode2
[[agent, [[agent,
[preference. animalljj, [preference, animall 1],
[object, (object,
[preference, foodijljjj). [preference, drinkl1M1).
</bodyText>
<figureCaption confidence="0.864448666666667">
Figure 3
Sense-frames for eatl and drinkl (verb senses)
Figure 4
</figureCaption>
<bodyText confidence="0.884968791666667">
The met* method (CS version)
Figure 3 shows the sense-frames for the verb senses eat1 and drink1. In both, the agent
preference is for an animal but the object preferences differ: the preference of eatl is
for foodl, i.e., an edible solid, while the preference of drinkl is for drink1 (the noun
sense), i.e., a potable liquid.
The second component of CS is the process of collation. It is collation that con-
tains the met* method in CS. Collation matches the sense-frames of two word senses
and finds a system of multiple mappings between those sense-frames, thereby dis-
criminating the semantic relations between the word senses. Figure 4 shows the use
of the met* method in CS. Figure 4 is similar to the one in Figure 1 except that the
diamonds contain the processes used in CS to check for satisfied preferences (diamond
1), metonymic inferences (diamond 2), and relevant analogies (diamond 3).
The basic mappings in collation are paths found by a graph search algorithm
that operates over the sense-network. Five types of network path are distinguished.
Two types of path, called ancestor and same, denote kinds of &amp;quot;inclusion,&amp;quot; e.g., that the
class of vehicles includes the class of cars (this is an ancestor relationship). Satisfied
Substitu e
metonym for
source or target
2
applicable
metonymic
inference
rule
</bodyText>
<page confidence="0.920883">
65
</page>
<note confidence="0.259675">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.999812625">
preferences are indicated by network paths denoting inclusion, also known as &amp;quot;inclu-
sive&amp;quot; paths (see diamond 1 in Figure 4). The other three types of network path, called
sister, descendant, and estranged, denote &amp;quot;exclusion,&amp;quot; e.g., that the class of cars does not
include the class of vehicles (this is a descendant relationship). Violated preferences
are network paths denoting exclusion, also known as &amp;quot;exclusive&amp;quot; paths.
These paths are used to build more complex mappings found by a frame-matching
algorithm. The frame-matching algorithm matches the sets of cells from two sense-
frames. The sets of cells, which need not be ordered, are inherited down the sense-
network. A series of structural constraints isolate pairs of cells that are matched using
the graph search algorithm. Network paths are then sought between terms occupying
identical positions in those cells. Seven kinds of cell match are distinguished, based
on the structural constraints and types of network path found. Ancestor and same are
&amp;quot;inclusive&amp;quot; cell matches, e.g. [compositionl, metal]] includes [composition1, steell]
because the class of metals includes the class of steels (another ancestor relationship).
Sister, descendant, and estranged are types of &amp;quot;exclusive&amp;quot; cell matches, e.g. [composi-
tion1, stee11] and [compositionl, aluminium1] are exclusive because the class of steels
does not include the class of aluminiums since both belong to the class of metals (this
is a sister relationship). The remaining cell matches, distinctive source and distinctive
target, account for cells that fail the previous five kinds of cell match. For more detail
on cell matches, see Fass (1988a).
A kind of lexical relevance is found dynamically from the sentence context. This
notion of relevance is used in finding the relevant analogies that distinguish metaphori-
cal from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITY
metonymies. Relevance divides the set of cells from the source sense-frame into two
subsets. One cell is selected as relevant given the context; the remaining cells are termed
nonrelevant. Collation matches both the source&apos;s relevant and nonrelevant cells against
the cells from the target sense-frame. A relevant analogy is indicated by a sister match
of the source&apos;s relevant cell (see diamond 3 in Figure 4).
Five types of metonymic concepts are currently distinguished. Examples of two
of the metonymic concepts, CONTAINER FOR CONTENTS and ARTIST FOR ART
FORM, have already been given. The remaining three are PART FOR WHOLE, PROP-
ERTY FOR WHOLE, and CO-AGENT FOR ACTIVITY.
</bodyText>
<subsectionHeader confidence="0.841219">
Example 22
</subsectionHeader>
<bodyText confidence="0.866441">
&amp;quot;Arthur Ashe is black&amp;quot; (= skin colored black --+ PART FOR WHOLE).
</bodyText>
<subsectionHeader confidence="0.819777">
Example 23
</subsectionHeader>
<bodyText confidence="0.957521666666667">
&amp;quot;John McEnroe is white&amp;quot; (= skin colored white -4 PART FOR WHOLE).
In (22) and (23), the skins of Arthur Ashe and John McEnroe, parts of their bodies,
are colored black (white).
</bodyText>
<subsectionHeader confidence="0.831224">
Example 24
</subsectionHeader>
<bodyText confidence="0.851394">
&amp;quot;John McEnroe is yellow&amp;quot; (= limited in bravery —* PROPERTY FOR WHOLE).
</bodyText>
<subsectionHeader confidence="0.850034">
Example 25
</subsectionHeader>
<bodyText confidence="0.9741">
&amp;quot;Natalia Zvereva is green&amp;quot; (= limited in experience -4 PROPERTY FOR WHOLE).
In (24), for example, John McEnroe is limited with respect to his bravery, a property
possessed by humans and other animals.
</bodyText>
<page confidence="0.681717">
66
</page>
<note confidence="0.239882">
Fass Discriminating Metonymy
</note>
<subsectionHeader confidence="0.39112">
Example 26
</subsectionHeader>
<bodyText confidence="0.994094693877551">
&amp;quot;Ashe played McEnroe&amp;quot; (= tennis with McEnroe -4 CO-AGENT FOR ACTIVITY).
These concepts are encoded in metonymic inference rules in CS (see diamond 2 in Fig-
ure 4). The rules are ordered from most common (synecdoche) to least. The order used
is PART FOR WHOLE, PROPERTY FOR WHOLE, CONTAINER FOR CONTENTS,
CO-AGENT FOR ACTIVITY, and ARTIST FOR ART FORM.
The first two concepts, PART FOR WHOLE and PROPERTY FOR WHOLE, are
source-driven; the others are target-driven. The difference in direction seems to be
dependent on the epistemological structure of the knowledge being related by the
different inferences. PART FOR WHOLE metonymies are source-driven, perhaps be-
cause the epistemological nature of parts and wholes is that a part generally belongs
to fewer wholes than wholes have parts, hence it makes sense to drive inferencing
from a part (source) toward the whole (target) than vice versa.
In CONTAINER FOR CONTENTS (target-driven), on the other hand, the episte-
mological nature of containers and contents is that the containers generally mentioned
in CONTAINER FOR CONTENTS metonymies are artifacts designed for the function
of containing — hence one can usually find quite specific information about the typ-
ical contents of a certain container, for example, some glasses as in (7) — whereas
the contents do not generally have the function of being the contents of something.
Hence it makes sense to drive inferencing from the container, and the function it per-
forms, toward the contents than vice versa. The same reasoning applies to ARTIST
FOR ART FORM (target-driven). An artist has the vocation of creating art: that is
his/her purpose.
A further step in collation distinguishes metaphorical from anomalous semantic
relations. Recall that a metaphorical relation contains a relevant analogy, as in (15)
and (20), while an anomalous relation does not, as in (21). A relevant analogy is found
by matching the relevant cell from the source sense-frame with one of the cells from
the target sense-frame. If the match of cells is composed of a set of sister network
paths between corresponding word senses in those cells, then this is interpreted as
analogical and hence indicative of a metaphorical relation. Any other match of cells is
interpreted as not analogical and thus an anomalous semantic relation is recognized
(see Fass 1986; 1987).
The third component of CS is the semantic vector which is a form of representation,
like the sense-frame; but sense-frames represent lexical knowledge, whereas semantic
vectors represent coherence. Semantic vectors are therefore described as a kind of coher-
ence representation. A semantic vector is a data structure that contains nested labels and
ordered arrays structured by a simple dependency syntax. The labels form into sets.
The outer sets of labels indicate the application of the three kinds of lexical semantic
constraints. The outermost set of labels is &apos;preference&apos; and &apos;assertion.&apos; The middle set is
&apos;relevant&apos; and &apos;nonrelevant.&apos; The innermost set is the kind of mapping used: &apos;network
path&apos; and &apos;cell matches.&apos; The nesting of labels shows the order in which each source of
knowledge was introduced. The ordered arrays represent the subkinds of each kind
of mapping. Five-column arrays are for the five network paths; seven-column arrays
are for the seven types of cell match. Each column contains a positive number that
shows the number of occurrences of a particular network path or cell match.
The fourth component of CS is the process of screening. During analysis of a
sentence constituent, a semantic vector is created for every pairwise combination of
word senses. These word sense combinations are called semantic readings or simply
&amp;quot;readings.&amp;quot; Each reading has an associated semantic vector. Screening chooses between
two semantic vectors and hence their attached semantic readings. Rank orderings
</bodyText>
<page confidence="0.993555">
67
</page>
<note confidence="0.482333">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.990157071428571">
among semantic relations are applied. In the event of a tie, a measure of conceptual
similarity is used.
The ranking of semantic relations aims to achieve the most coherent possible in-
terpretation of a reading. The class of preference-based semantic relations takes prece-
dence over the class of assertion-based semantic relations for lexical disambiguation.
The rank order among preference-based semantic relations is
literal metaphorical —&gt; anomalous.
If the semantic vectors are still tied then the measure of conceptual similarity is
employed. This measure was initially developed to test a claim by Tourangeau and
Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a
function of the distance between the conceptual domains of the source and target
involved: the claim is that the more distant the domains, the better the metaphor. This
is discussed further in Section 5. The conceptual similarity measure is also used for
lexical ambiguity resolution (see Fass 1988c).
</bodyText>
<sectionHeader confidence="0.914844" genericHeader="method">
5. The Meta5 Program
</sectionHeader>
<bodyText confidence="0.999683090909091">
CS has been implemented in the meta5 natural language program. The meta5 program
is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just
over 500 word senses, a small grammar, and semantic routines that embody collation
and screening, the two processes of CS. The program is syntax-driven, a form of
control carried over from the structure of earlier programs by Boguraev (1979) and
Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the
seven kinds of semantic relation between pairs of word senses in those sentences (i.e.,
the program recognizes metonymies, metaphors, and so on), and resolves any lexical
ambiguity in those sentences. Meta5 analyzes all the sentences given in Sections 3
and 4, plus a couple more metaphorical sentences discussed in Section 7.
Below are simplified versions of some of the metonymic inference rules used in
meta5. The metonymic concepts used in CS contain three key elements: the conceptual
relationship involved, the direction of inference, and a replacement of the source or
target. The metonymic inference rules in meta5 contain all three key elements. The
rules, though written in a prolog-like format, assume no knowledge of Prolog on the
part of the reader and fit with the role of metonymy shown in Figures 1 and 4.
Each metonymic inference rule has a left-hand side and a right-hand side. The left-
hand side is the topmost statement and is of the form metonymic_inference_rule(Source,
Target). The right-hand side consists of the remaining statements. These statements
represent the conceptual relationship and the direction of inference, except for the
bottom most one, which controls the substitution of the discovered metonym for either
the source or target: this statement is always a call to find a new sense-network path.
</bodyText>
<table confidence="0.529456">
Rule 1
PROPERTY FOR WHOLE: source-driven.
metonymic_inference_rule (Source, Target):-
find_cell (Source, [Whole, have1, it1]), [11
find_sense_network_path (Whole, Target). [21
</table>
<bodyText confidence="0.95393725">
This rule represents PROPERTY FOR WHOLE, which is source-driven. State-
ment [1] represents the conceptual relationship and direction of inference. The concep-
tual relationship is that the source is a property possessed by the whole in a property-
whole relation. The inference is driven from the source: find_cell searches through the
</bodyText>
<page confidence="0.997002">
68
</page>
<note confidence="0.560863">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.996549">
source&apos;s list of cells for one referring to a &amp;quot;whole&amp;quot; of which the source is a &amp;quot;part.&amp;quot;
Statement [2] controls the substitution of the discovered metonym: the &amp;quot;whole&amp;quot; is
the substitute metonym that replaces the source, and the next sense-network path is
sought between the whole and the target.
</bodyText>
<table confidence="0.80950375">
Rule 2
CONTAINER FOR CONTENTS: target-driven.
metonymic_inference_rule (Source, Target):-
find_cell (Target, [in, contain1, Contents]), [1]
find_sense_network_path (Source, Contents). [2]
This metonymic concept is target-driven. The target is the &amp;quot;container&amp;quot; in a container-
contents relation ([1]). The &amp;quot;contents&amp;quot; is the substitute metonym that replaces the tar-
get. The next sense-network path is sought between the source and the contents ([2]).
Rule 3
ARTIST FOR ART FORM: target-driven.
metonymicinference_rule (Source, Target):-
find_genus (Target, Occupation), [1]
find_cell (Occupation, [itl, Make, Art form]), [2]
confirm_type (create1, Make), [3]
confirm_type (art_form1, Art form), [4]
find_sense_network_path (Source, Art form). [5]
</table>
<bodyText confidence="0.9989662">
Again, the inference in ARTIST FOR ART FORM is from the target. The target
is a person who is an &amp;quot;artist&amp;quot; in an artist—art form relation. The occupation of the
person is found by searching up the sense-network ([1]). The list of cells associated
with the occupation are searched for a cell describing the main activity involved in
the occupation ([2]), e.g., a cook cooks food and an artist makes art forms. Checks are
done to confirm that any activity found is indeed making an art form, i.e., that the
&amp;quot;making&amp;quot; involved is a type of creating ([3]) and that the &amp;quot;art form&amp;quot; is a type of art
forml ([4]). The &amp;quot;art form&amp;quot; is the substitute metonym that replaces the target. A new
sense-network path is computed between the source and the art form ([5]). I will now
describe how meta5 recognizes some metonymies and metaphors.
</bodyText>
<equation confidence="0.490844">
Example 19
&amp;quot;Ted played Bach&amp;quot; (= the music of Bach).
</equation>
<bodyText confidence="0.999974461538461">
In (19), between &apos;Bach&apos; and the twelfth sense of &apos;play&apos; in meta5&apos;s lexicon (meaning &amp;quot;to
play music&amp;quot;), there is a chain of metonymies plus a literal relation. The chain consists
of ARTIST FOR ART FORM and CONTAINER FOR CONTENTS metonymies. Both
metonymic concepts are target-driven. In ARTIST FOR ART FORM the inference is
from the ARTIST (the target) to the ART FORM (the source), so the substitute metonym
replaces the target (the ARTIST) if the inference is successful.
The sense-frames of the verb sense play12 and the noun senses musicl and jo-
hann_sebastian_bach are shown in Figure 5. The semantic relation results from match-
ing the object preference of play12, which is for music, against the surface object,
which is &apos;Bach,&apos; short for &apos;Johann Sebastian Bach.&apos; The preference is the source and
the surface object is the target.
We will follow what happens using the flow chart of Figure 4. (Enter diamond 1
of the chart.) The sense-network path between the source (music1) and the target
</bodyText>
<page confidence="0.991966">
69
</page>
<bodyText confidence="0.16885">
Computational Linguistics Volume 17, Number 1
</bodyText>
<equation confidence="0.8086305625">
sf(play12,
Hams,
[[supertype. perform-1U],
[node2,
[[agent,
[preference, human_being11],
[object,
[preference,muslc1M]j).
sf(musicl, st(johann_sebastian_bach,
[[arcs, [(arcs,
[[supertype, Esound1, art_form111)], [[supertype, composer11]],
[node°, [node0,
[[musicianl, play12, Winn. Hanimacy1, dead1],
(sex1, male1],
[born1, 1685],
[died1, 1750[1]]).
</equation>
<figureCaption confidence="0.55354">
Figure 5
</figureCaption>
<bodyText confidence="0.990169971428571">
Sense-frames for play12 (verb sense), musicl and johann_sebastian_bach (noun senses)
(johann_sebastian_bach) is sought. The path is not inclusive because johann_sebastian_
bach is not a type of music1.
(Enter diamond 2 of the chart.) Metonymic inference rules are applied. The rules
for PART FOR WHOLE, PROPERTY FOR WHOLE, CONTAINER FOR CONTENTS,
CO-AGENT FOR ACTIVITY are tried in turn, but all fail. The rule for ARTIST FOR
ART FORM, however, succeeds. The discovered metonymic inference is that johann_
sebastian_bach (the ARTIST) composes musical pieces (the ART FORM). The metonymic
inference is driven from the target (the ARTIST), which is johann_sebastian_bach. The
successful metonymic inference, using the ARTIST FOR ART FORM inference rule
above, is as follows: [1] johann_sebastian_bach (the ARTIST) is a composer1, [2] com-
posers compose1 musical pieces (the ART FORM). Additional tests confirm [2], which
are that [3] composing is a type of creating, and [4] a musical_piece1 is a type of
art_forml.
(Enter the leftmost statement box — also step [5] of the ARTIST FOR ART FORM
inference rule above.) The original target (johann_sebastian_bach) is replaced by the
substitute metonym (musical_piece1).
(Enter diamond 1 for a second time.) The sense-network path between the source
(music1) and the new target (musical_piecel) is sought. The path is not inclusive.
(Enter diamond 2 for a second time.) Metonymic inference rules are applied. The
rules for PART FOR WHOLE and PROPERTY FOR WHOLE fail, but the rule for
CONTAINER FOR CONTENTS succeeds. The successful inference, using the descrip-
tion of the CONTAINER–CONTENTS inference rule given previously, is that [1] a
musical_piecel (the CONTAINER) contains music1 (the CONTENTS).
(Enter the leftmost statement box for a second time.) The direction of inference in
the CONTAINER FOR CONTENTS metonymic concept is from the target (the CON-
TAINER) towards the source (the CONTENTS), so [2] the target (the CONTAINER) is
replaced by the substitute metonym when an inference is successful. Hence in our ex-
ample, the target (musical_piece1) is again replaced by a substitute metonym (music1).
The source, which is music1, the object preference of play12, remains unchanged.
(Enter diamond 1 for a third time.) The sense-network path between the source
(music1) and the latest target (music1) is sought. The path is inclusive, that music1 is
a type of musicl, so a literal relation is found.
(Exit the chart.) The processing of the preference-based semantic relation(s) be-
tween play12, and its preference for music1, and johann_sebastian_bach is completed.
</bodyText>
<page confidence="0.99065">
70
</page>
<note confidence="0.555368">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.9858342">
After an initial preference violation (Johann Sebastian Bach is not a kind of music), the
semantic relation found was an ARTIST FOR ART FORM metonymic relation (that
johann_sebastian_bach composes musical pieces) followed by a CONTAINER FOR
CONTENTS metonymic relation (that musical pieces contain music) followed by a
literal relation (that music is music).
</bodyText>
<figure confidence="0.3925555">
Example 20
&amp;quot;The car drank gasoline.&amp;quot;
</figure>
<bodyText confidence="0.99980436">
There is a metaphorical relation between carl and the verb sense drinkl in (20). The
source is drinkl, whose agent preference is animall, and the target is carl (see Fig-
ure 6).
A metaphorical relation is sought after failing to find an inclusive network path
or a metonymic inference between animall and carl, hence the network path between
animall and carl must be exclusive. The network path found is an estranged one.
The second stage is the match between the relevant cell of animall and the cells of
carl. In the present example, drinkl is relevant. The list of cells for animall is searched
for one referring to drinking. The relevant cell in the list is [animall, drinkl, drink11,
which is matched against the inherited cells of carl (see Figure 7). A sister match is
found between [animall, drinkl, drinkl] and [carl, use2, gasoline1] from carl.
The sister match is composed of two sister paths found in the sense-network. The
first sister path is between the verb senses drinkl and use2, which are both types
of expending (Figure 8). The second path is between the noun senses drinkl and
gasolinel, which are both types of liquid (Figure 9). The effect of the network paths is to
establish correspondences between the two cells such that an analogy is &amp;quot;discovered&amp;quot;
that animals drink potable liquids as cars use gasoline. Note that, like Gentner&apos;s (1983)
systematicity principle, the correspondences found are structural and independent of
the content of the word senses they connect. Note also that the two cells have an
underlying similarity or &amp;quot;ground&amp;quot; (Richards 1936) in that both refer to the expenditure
of liquids. This second stage of finding a relevant analogy seems the crucial one in
metaphor recognition.
Figure 10 shows the match of the nonrelevant cells from animall and carl. The cell
use2, gasolinel I has been removed. There are three inclusive cell matches as an-
imals and cars share physical objectlike properties of boundedness, three dimensions,
</bodyText>
<equation confidence="0.920328416666667">
sf(drinkl,
[[arcs,
[[supertype, [ingestl, expendljjjj,
[node2,
[[agent,
[preference, anlmallll,
[object,
[preference, drinkl[]]]]).
sf(animall, sf(carl,
[[arcs, [[arcs,
[[supertype, organisml]jj, [[supertype, motor_vehiclel][1,
[node0, [node0,
</equation>
<footnote confidence="0.3975588">
Ubiologyl, animall[, [[itl, carry 1, passenger-1H).
[itl, drinkl, drinkl],
[itl, earl, foodl]]]]).
Figure 6
Sense-frames for drinkl (verb sense), animall and carl (noun senses)
</footnote>
<page confidence="0.933365">
71
</page>
<table confidence="0.997711857142857">
Computational Linguistics Volume 17, Number 1
Relevant cell of animall Cells of carl
(SOURCE) (TARGET)
[animall, drinkl, drinkl] aboundsl, distinctl],
[extentl, three_dimensionall],
[behaviourl, solidi],
[animacyl, nonliving1],
[cart rolll, [on3, landl]],
[compositionl, steell],
[driverl, drivel, Carl],
[carl, havel, [4, wheell]],
[earl, havel, enginel],
[carl, use2, gasolinell,
[Carl, carryl, passengerl]]
</table>
<figureCaption confidence="0.73275">
Figure 7
</figureCaption>
<figure confidence="0.677931833333333">
Match of relevant cell from animall against cells of carl
411/ enterl contractl
supertype supe type
ingestl expendl
supertype supertype supertype supertype supertype
eatl drinkl use2
</figure>
<figureCaption confidence="0.727209">
Figure 8
</figureCaption>
<figure confidence="0.867323">
Sister sense-network path between drink1 and use2 (verb senses)
</figure>
<figureCaption confidence="0.833765">
Figure 9
</figureCaption>
<figure confidence="0.8342903125">
Sister sense-network path between gasolinel and drinkl (noun senses)
energy_sourcel
supertype supertype supertype
iguidl
supertype supertype supertype supertype supertype
drinkl gasolinel WcoaIl
solidi
ertype
foodi
Well
72
Fass Discriminating Metonymy
Figure 10
Matches of non-relevant cells from animall and carl
[preference, I First array:
anetwork_path, preference violation
</figure>
<equation confidence="0.848164142857143">
[0, 0, 0, 0, 11 (estranged sense-network path)
[Ce]) match, I Second array:
[[relevant, relevant analogy
[0, 0, 1, 0, 0, 0, 10Th (sister match of relevant cell)
[non_relevant, I Third array:
[0, 3, 2, 0, 0, 2, 5]]]]]] distance betw. conceptual domains
(matches of non-relevant cells)
</equation>
<figureCaption confidence="0.569885">
Figure 11
</figureCaption>
<bodyText confidence="0.99037047826087">
Semantic vector for a metaphorical semantic relation
and solidity. Two cell matches are exclusive. Animals are composed of flesh, whereas
cars are composed of steel. Animals are living, whereas cars are nonliving. There are
two distinctive cells of animall and five distinctive cells of carl . Tourangeau and Stern-
berg&apos;s (1982) hypothesis predicts that the greater the distance between the conceptual
domains of the terms involved in a metaphor, the more apt the metaphor. The pro-
portion of similarities (inclusive cell matches) to differences (exclusive cell matches) is
3 to 2, which is a middling distance suggesting, tentatively, an unimposing metaphor.
All of these matches made by collation are recorded in the semantic vector shown
in Figure 11. The crucial elements of the metaphorical relation in (20) are the preference
violation and the relevant analogy. In Figure 11, the preference violation has been
recorded as the 1 in the first array and the relevant analogy is the 1 in the second
array. Information about the distance between conceptual domains is recorded in the
third array.
The &apos;preference&apos; label indicates that a preference has been matched (rather than
an assertion). The five columns of the first array record the presence of ancestor,
same, sister, descendant and estranged network paths respectively. When a preference
is evaluated, only one network path is found, hence the single 1 in the fifth column,
which indicates that an estranged network path was found between animall and car1.
Cell matches are recorded in the second and third arrays, which each contain seven
columns. Those columns record the presence of ancestor, same, sister, descendant,
estranged, distinctive source, and distinctive target cell matches respectively. The 1 in
the third column of the second array is the relevant analogy — a sister match of the
</bodyText>
<figure confidence="0.83035">
Non-relevant Cells of animall
(SOURCE)
</figure>
<figureCaption confidence="0.857745071428572">
abounds), distinct1J,
[eztentl, three dimensionall
[behaviourl, solid)],
fanimacyl, living)),
[composition), flesh 1),
[anirnall , eatl food1],
[biology l, animall]]
[animacyl, nonlIvingil,
(compositionl, steell],
[cart, roll I. lon3. landli),
[driverl, drivel, cart],
[cart, have), 14, whoa))]],
[cart, navel, engine)],
[car), carryl, passengerlfl
</figureCaption>
<figure confidence="0.998726">
112 sister
cell matches
2 distinctive
source cells
(of animal))
5 distinctive
target cells
(of cart)
Non-relevant cells of cart (:ell matches
(TARGET)
UbOundsl, distinctl],
I. [extent), three dimensionalll 3 sl matches [behavieurl, scTlid1J, cel
</figure>
<page confidence="0.780697">
73
</page>
<note confidence="0.382192">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.998539">
relevant cell [animall, drinkl, drink1] and the cell [carl, use2, gasoline-1i The 10 is
the ten distinctive cells of carl that did not match [animall, drink1, drink1]. This is
the match of 12 cells, 1 from the source and 11 from the target (see Figure 7). The sum
of array columns is:
</bodyText>
<equation confidence="0.979732">
((0 + 0 + 1 + 0 + 0) x 2) + ((0 + 10) x1.) =(l x 2) + (10 x 1) = 12.
</equation>
<bodyText confidence="0.9988025">
The 3 similarities, 2 differences, 2 distinctive cells of animall and 5 distinctive cells
of carl are the nonzero numbers of the final array. The 3 similarities are all same cell
matches; the 2 differences are both sister cell matches. A total of 17 cells are matched,
7 from the source and 10 from the target (see Figure 10). The total of array columns is:
</bodyText>
<equation confidence="0.9641345">
((0 + 3 + 2 + 0 + 0) x 2) + ((2 + 5) x 1) = (5 x 2) + (7 x 1) = 17.
Example 15
</equation>
<bodyText confidence="0.977357944444444">
&amp;quot;The ship ploughed the waves.&amp;quot;
In (15), there is a metaphorical relation between a sense of the noun &apos;ship&apos; and the
second sense of the verb &apos;plough&apos; in meta5&apos;s lexicon. Note that &apos;plough,&apos; like &apos;drink,&apos;
belongs to several parts of speech. Figure 12 shows the sense-frames for the verb sense
plough2, the noun sense plough1, which is the instrument preference of plough2, and
the noun sense ship1.
In (15), meta5 matches senses of &apos;ship&apos; against senses of &apos;plough.&apos; When meta5
pairs ship1 with plough2, it calls upon collation to match shipl against the noun
sense plough1, the instrument preference of plough2.
First, the graph search algorithm searches the sense-network for a path between
plough1 (which is the preference) and ship1 and finds an estranged network path
between them, i.e., a ship is not a kind of plough, so plough2&apos;s instrument preference
is violated.
Next, collation inherits down lists of cells for ploughl and shipl from their super-
ordinates in the sense-network. What is relevant in the present context is the action of
ploughing because (15) is about a ship ploughing waves. Collation then runs through
the list of inherited cells for the noun sense plough1 searching for a cell that refers to
the action of ploughing in the sense currently under examination by meta5, plough2.
</bodyText>
<equation confidence="0.852772714285714">
sf(plough2,
[[arcs
Usupertype, transfer1M,
[node2,
[[instrument,
[preference, ploughl]] ,
[object,
[preference, soill]l]11).
sf(ploughl, sf(shipl,
[taros, [[arcs,
[(supertype, toollj]], [[supertype, watercraftl]]],
[node0, [node0,
[[farmerl, ploughl, [[itl, carryl, shipmentl],
[itl, plough2, soill]]]]). [itl, havel, enginel]111).
</equation>
<figureCaption confidence="0.695896">
Figure 12
</figureCaption>
<bodyText confidence="0.670714">
Sense-frames for plough2 (verb sense), ploughl and ship1 (noun senses)
</bodyText>
<page confidence="0.986081">
74
</page>
<subsectionHeader confidence="0.414693">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.427676">
Relevant cell of olough1 Cells of shipi
</bodyText>
<equation confidence="0.609585666666667">
(SOURCE) (TARGET)
[plough1, plough2, soul] [&apos;bounds&apos;&apos;, distincti],
[extenti, three_dimensional1],
[behaviour1, solidi],
[animacy1, nonliving1],
[composition i, metaI1],
use2, energy_source1],
[boatman&apos;&apos;, sail1, shipl},
sail2, water2],
</equation>
<figureCaption confidence="0.8365306">
[ship&apos;&apos;, carry&apos;&apos;, shipment-l],
[shipi, havel, enginei]]
Figure 13
Match of relevant cell from ploughl against cells from shipl
Figure 14
</figureCaption>
<subsectionHeader confidence="0.570406">
Matches of non-relevant cells from ploughl and shipl
</subsectionHeader>
<bodyText confidence="0.999932705882353">
Collation finds a relevant cell [plough1, plough2, soill ] and uses its frame-matching
algorithm to seek a match for the cell against the list of inherited cells for shipl, shown
in Figure 13 (for ease of reading, itl has again been replaced by the word senses being
defined). The algorithm finds a match with [shipl, sail2, water2] (highlighted in Figure
13), and hence collation &amp;quot;discovers&amp;quot; a relevant analogy that both ships and ploughs
move through a medium, i.e., that ploughs plough through soil as ships sail through
water.
Finally, collation employs the frame matching algorithm a second time to match
together the remaining nonrelevant cells of plough1 and ship1 (see Figure 14). The cell
[shipl, sail2, water is removed to prevent it from being used a second time.
Figure 15 shows the semantic vector produced. As with Figure 11, it shows a
metaphorical relation. There is a preference violation, an estranged network path in-
dicated by the 1 in the fifth column of the first array. There is also a relevant analogy,
shown by the 1 in the third column of the second array: the analogical match of the
cells [plough1, plough2, soil]] and [shipl, sail2, water2]. The second array shows that
11 cells are matched, 1 from the source and 10 from the target (check against Figure 13).
The sum of the array&apos;s columns is:
</bodyText>
<equation confidence="0.77337325">
((0 0 + 1 + 0 + 0) x + ((0 + 9) x 1) = (1 x 2) + (9 x 1) = 11.
Non-relevant cells of olouohl Non-relevant cells of shio1
(SOURCE) (TARGET)
[[composition1, matter1), Hcomposition1, metal1 J,
Cell matchea
I1 ancestor
cell match
lbounds1, distinct1], [bounds1, distinct1],
[extent1, three_dimensional1], [extent1, three_dimensionall, 4 same
[behaviour1, solidi], [behaviourl , solidi], cell matches
lanimacy1, nonliving1], [animacy1, nonliving11,
[farmer1, plough1, plough1]] [boatmant saill , ship1J, 111 sister
]shipl, use2, energy_source1], cell match
[shipl, carry1, shipmentl], 3 distinctive
[ship1, navel, engine111 target cells
(of ship1)
</equation>
<page confidence="0.987165">
75
</page>
<figure confidence="0.607892">
Computational Linguistics Volume 17, Number 1
</figure>
<figureCaption confidence="0.904141">
Figure 15
</figureCaption>
<bodyText confidence="0.87699975">
Semantic vector for another metaphorical semantic relation
In the third array, the match of nonrelevant cells, there is 1 ancestor match, 4 same
matches, 1 sister match, and 3 distinctive cells of ship1. Fifteen cells are matched, 6
from the source and 9 from the target (see Figure 14). The totals are:
</bodyText>
<equation confidence="0.97286">
((1 + 4 + 1 + 0 + 0) x 2) + ((0 + 3) x 1) = (6 x 2) + (3 x 1) = 15.
</equation>
<bodyText confidence="0.9985844">
Semantic vectors can represent all the semantic relations except metonymic ones. The
reason is that metonymic relations, unlike the others, are not discriminated by CS in
terms of only five kinds of network path and seven kinds of cell matches. Instead,
they consist of combinations of network paths and specialized matches of cells that
have not fallen into a regular enough pattern to be represented systematically.
</bodyText>
<sectionHeader confidence="0.973132" genericHeader="method">
6. Extensions
</sectionHeader>
<bodyText confidence="0.995039">
Even for those semantic dependencies investigated, the interpretation of semantic re-
lations seems to require more complexity than has been described so far in this paper.
Consider the differences between the following sentences:
</bodyText>
<figure confidence="0.658332">
Example 20
&amp;quot;The car drank gasoline.&amp;quot;
Example 27
&amp;quot;The car drank coffee.&amp;quot;
</figure>
<bodyText confidence="0.999691923076923">
Intuitively, sentence (20) is metaphorical while (27) is metaphorical/anomalous.
In (20), the semantic relation between &apos;car&apos; and &apos;drink&apos; is thought to be metaphorical,
and the isolated semantic relation between just &apos;drink&apos; and &apos;gasoline&apos; is anomalous,
but the sentence as a whole is metaphorical because it is metaphorical that cars should
use up gasoline.
In (27), the semantic relation between &apos;car&apos; and &apos;drink&apos; is metaphorical; the seman-
tic relation between just &apos;drink&apos; and &apos;coffee&apos; is literal; yet the effect of (27) as a whole is
metaphorical/anomalous. The object preference of &apos;drink&apos; is for a drink, i.e., a potable
liquid. It seems that it is metaphorical for cars to &amp;quot;drink&amp;quot; a liquid commonly used up
by cars, e.g., gasoline, but anomalous if the liquid has nothing to do with cars, e.g.,
coffee, as in (27).
The problem of understanding the differences between sentences (20) and (27)
requires some further observations about the nature of semantic relations, principally
</bodyText>
<equation confidence="0.93434475">
[preference,
[[network_path,
[0, 0, 0, 0, 1]),
[cell_match,
[[relevant,
[0,0, 1, 0, 0, 0, 9]],
[non_relevant,
[1, 4, 1, 0, 0, 0,3111111
</equation>
<figureCaption confidence="0.670764555555556">
IIIFirst array:
preference violation
(estranged sense-network path)
Second array:
relevant analogy
(sister match of relevant cell)
Third array:
distance betw. conceptual domains
(matches of non-relevant cells)
</figureCaption>
<page confidence="0.742939">
76
</page>
<note confidence="0.253564">
Foss Discriminating Metonymy
</note>
<bodyText confidence="0.99983168">
that the differences are caused by the combinations of semantic relations found in the
sentences and the relationships between those relations. Below is a suggestion as to
how deeper semantic processing might discriminate the differences between the two
sentences.
Before getting to the deeper processing, we need a better semantic vector notation.
The better semantic vector notation, which developed from a discussion with Afzal
Ballim, is a modification of the notation shown in Section 5. The key differences are
reformulation by rewriting the five and seven column arrays in terms of the predicate-
argument notation used in the rest of semantic vectors, and extension by adding the
domain knowledge connected by every network path and cell match.
Figure 16 shows the semantic vector in Figure 11 reformulated and extended. The
advantage of vectors like the one in Figure 16 is that they record both how the sense-
frames of two word senses are matched (i.e., as various kinds of network path and cell
match) and what information in the sense-frames is matched (i.e., all the cells). For
example, the part of Figure 16 that begins &amp;quot;[relevant, &amp;quot; contains all the information
found in Figure 7, the match of the relevant cell from animall against the cells of car1,
both the types of cell matches and the cells matched. The equivalent part of Figure 11
only records the types of cell matches. Recording the contents of the matched cells is
useful because it enables a deepened analysis of semantic relations. Such an analysis
is needed to detect the differences between (20) and (27).
In the description of CS in Section 4, collation discriminates the one or more
semantic relations in each semantic dependency, but treats the semantic relations in
one dependency as isolated from and unaffected by the semantic relations in another
dependency. What is needed is extra processing that interprets the semantic relation(s)
in a later dependency with respect to the semantic relation(s) established in an earlier
</bodyText>
<equation confidence="0.861865428571429">
[preference,
[[network_path,
[estranged,
[1, [animall, carl]]]],
[cell_match,
[[relevant,
[(sister,
</equation>
<bodyText confidence="0.938002714285714">
[1, Manima11, drink1, drink1j, [cart, use2, gasolinelth],
[distInctive_larget,
[10, [[bounds1, distinctl], [extentl, three_dimensionall],
[behaviourl, solidi], [compositionl, metall],
[animacyl, nonlivinglj, [cart, rolll, [on3, landith
[driverl, drivel, cart[, [cart, hovel, [4, whee111],
[carl, havel, anginal], [cart, carryl, passengerl]]]]]],
[non_relevant,
[[same,
[3, Eboundsl, distinctl], [bounds1, distinctl]],
[[extentl, three_dimensionallj, [extent1, three_dimensionall]],
[[behaviourl, solidi], [behaviourl, solidl]]]],
[sister,
[2, [[[compositionl, fleshl], [compositionl, meta111],
[[animacyl, livingl], [animacyl, nonlivingi][]],
[distinctive_source,
[2, [[animall, earl, foodl], [biologyl, animall]]]],
[distinctive_target,
[5, [(cart rolll, [on3, land1]], [driven, drivel, car1],
[Carl, havel, [4, wheell]], [cart havel, enginel],
[cart, carryl, passengerl]]]]]]]]]]
</bodyText>
<footnote confidence="0.42313">
Figure 16
Reformulated and extended version of Figure 11
</footnote>
<page confidence="0.943102">
77
</page>
<figure confidence="0.923334">
Computational Linguistics Volume 17, Number 1
[preference,
[cell_match,
[relevant,
[sister,
[1,
[[animall, drink1, drink1], [car1, use2, gasolinel[)[[[[[
</figure>
<figureCaption confidence="0.856222">
Figure 17
</figureCaption>
<bodyText confidence="0.520244">
Vector statement of match of relevant cell from animall against cells of carl
</bodyText>
<equation confidence="0.684357666666667">
[preference,
[cell_match,
[relevant,
[sister,
[1, [[animall, drink1, drink1], [vehicle1, use2, gasolinel[[[[]]]
Figure 18
</equation>
<bodyText confidence="0.989126">
Vector statement of match of relevant cell from drinkl against cells of gasolinel (noun senses)
one. This processing matches the domain knowledge in semantic vectors, i.e., this
processing is a comparison of coherence representations.
In sentences such as (20) and (27) there are two key semantic dependencies. The
first one is between the subject noun and the verb; the second is between the verb
and object noun. In each dependency, the source is the verb (through its agent and
object preferences) and the targets are the nouns. Semantic relations are found for each
dependency. One way to detect the difference between metaphorical sentences such
as (20) and metaphorical/anomalous ones such as (27) is in each sentence to consult
the semantic vectors produced in its two main semantic dependencies and compare
the matches of the relevant cells that are found by collation.
Let us go through such an analysis using CS, starting with the first semantic
dependency between subject noun and verb. In this semantic dependency in both (20)
and (27), a relevant analogy is discovered as part of a metaphorical relation between
the target car1 and animall, the agent preference of the source drinkl. The semantic
vector in Figure 16 records the two cells that figure in that relevant analogy. Figure 17
shows the same information from the semantic vector but written as a statement.
When the second semantic dependency is analyzed in (20), the target is gasolinel
and is matched against the noun sense drink1, the object preference of the source
drink1 (the verb sense). A semantic vector is produced. The relevant cell found in
the noun sense drinkl is [animall, drinkl, drink1]. Its match against [vehicle1, use2,
gasolinel], a cell from gasolinel, is shown in the vector statement in Figure 18. The
match is a sister match, indicating a relevant analogy.
Now this is peculiar because &amp;quot;drinking gasoline&amp;quot; is anomalous, yet a relevant
analogy has been found and this paper has argued that relevant analogies are special
to metaphorical relations. One possible explanation is that differences exist between the
recognition of metaphorical relations that concern agents and metaphorical relations
that concern objects and other case roles. It may be that metaphorical relations are
indicated by a relevant analogy, but only in selected circumstances. This needs further
investigation.
</bodyText>
<page confidence="0.987999">
78
</page>
<figure confidence="0.496226">
Fass Discriminating Metonymy
[preference,
[cell_match,
[relevant,
[ancestor,
[1, ffanima11, drink1, drink1], [human_being1, drink1, coffeel[]][[][
</figure>
<figureCaption confidence="0.758675">
Figure 19
</figureCaption>
<bodyText confidence="0.989607684210526">
Vector statement of match of relevant cell from drinkl against cells from coffeel (noun senses)
To return to the analysis of (20), what appears to be important in determining that
(20) is a metaphorical sentence is the comparison of the two pairs of matched relevant
cells:
[[animall, drinkl, drinkl], [carl, use2, gasoline1[1
[[animall, drink1, drink1], [vehicle1, use2, gasoline1]1
The two source cells are the same and the two target cells, [carl, use2, gasoline]]
and [vehicle1, use2, gasolinel], are almost identical, indicating that the same basic
analogy runs through the whole of (20), hence the sentence as a whole is metaphorical.
Now let us analyze the second semantic dependency in (27). The target is coffeel
and is again matched against drinkl, the object preference of the verb sense drinkl, the
source. The relevant cell from the noun sense drinkl is again [animall, drinkl, drink1],
which matches against [human_being1, drink1, coffeel I from the target coffeel. This
time, the match is an ancestor match and hence not a relevant analogy. Figure 19
shows this match of the relevant cell as a vector statement. Let us compare the two
pairs of matched relevant cells for (27):
[[animall, drink1, drinkl], [carl, use2, gasolinel ]]
[[animall, drinkl, drinkl], [human_beingl, drinkl, coffeel]]
The two source cells are the same but the two target cells, [carl, use2, gasoline]]
and [human_being1, drinkl, coffeel], are very different. The reason that the sentence as
a whole is metaphorical/anomalous is because of the clash between these target cells.
The basic analogy of a car ingesting a liquid does not carry over from the first semantic
dependency into the second. The anomalous flavor of (27) could not be detected by
looking at the semantic relations in the dependencies in isolation because one semantic
relation is metaphorical and the other is literal. Neither relation is anomalous — the
anomaly comes from the interaction between the two relations.
Figure 20 is a proposed representation for sentence (20). The left side of Figure
20 shows the knowledge representation part of the sentence representation: a simple
case-frame based representation of (20). The right side of Figure 20, within the grey
partition, is the coherence representation component of the sentence representation:
abridged semantic vectors for the two main semantic dependencies in (20). The upper
semantic vector is the match of the target carl against the source animall. The lower
semantic vector is the match of the target gasoline1 against the source drinkl, the
noun sense. The upper abridged semantic vector indicates a metaphorical relation.
The lower semantic vector also indicates a metaphorical relation though, as was noted
earlier, &amp;quot;drinking gasoline&amp;quot; when interpreted in isolation is surely anomalous.
The underlines in Figure 20 denote pointers linking the semantic vectors to the
case frame. The grey vertical arrows show that the two semantic vectors are also linked
</bodyText>
<page confidence="0.993057">
79
</page>
<figure confidence="0.620950333333333">
Computational Linguistics Volume 17, Number 1
Figure 20
Sentence representation for &amp;quot;The car drank gasoline&amp;quot;
</figure>
<figureCaption confidence="0.73328">
Figure 21
</figureCaption>
<bodyText confidence="0.986619727272727">
Sentence representation for &amp;quot;The car drank coffee&amp;quot;
together via the matches of their relevant cells. In those matches, the arrows are sense-
network paths found between the elements of the two target cells. The network paths
indicated in grey, that connect the two abridged semantic vectors, show processing of
coherence representations. The particular network paths found (indicated in italics), a
descendant path and two same &amp;quot;paths,&amp;quot; show that the same relevant analogy is used
in both semantic relations — that both semantic relations involve a match between
animals drinking potable liquids and vehicles (including cars) using gasoline — hence
sentence (20) as a whole is metaphorical. Figure 20 is therefore unlike any of the
coherence representations shown previously, because it shows a representation of a
metaphorical sentence, not just two isolated metaphorical relations.
</bodyText>
<figure confidence="0.981607105263158">
[[[source,
[[explicit, drink1],
animallM,
[target, -1j],
[preference,
[[network_path,
[estranged,
[1, (animall, cart[[[[,
(cell_match,
((relevant,
[(sister,
[I, [([animalt , drInk1, drink1], [cart, use2, gasoline1M/[[]]
[preference, SAME ME
Unetwork_path,
[sister,
[1, [drink1, gasoline1M,
(cell_match,
[(relevant,
[(sister,
[1, [flanima11, drinkl, drink1], [vehicle1, use2, gasoline1][[[IMM
[drink1,
[agent,
£LLU.
[object,
gasoline1]]
[[[source,
[(explicit, drink1J,
[Implicit, diink1111,
[target, pasollnel][,
[[[source,
[(explicit, drink11,
(implidt, animalln],
[target,
[preference,
[[network_path,
[estranged,
[1, (animall, carr[[[[,
[cell_match,
[(relevant,
((sister,
[1, [((animall, drinkt, drinkl], (cart use2, gasolinellIMMID
Mecums,
[(explicit, drinklj,
drinkl]I],
(target, coffeell
[preference
Detwork_path,
[ancestor,
(1, (drinkl, coffeelnll,
[cell_match,
[(relevant,
[(ancestor,
[1, drinkt, drink1], (human_beingt, drinkl, coffeet MIMI)]
[drinkl,
[agent,
[object,
coffeel]]
</figure>
<page confidence="0.869346">
80
</page>
<note confidence="0.462582">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.999742">
Compare Figure 20 with Figure 21, a sentence representation for (27). The upper
semantic vector again indicates a metaphorical relation between carl and drink1. The
lower semantic vector indicates a literal relation between drinkl and coffee1. What is
important here is the match of relevant information discovered in the two semantic
relations, as indicated by the three network paths. The paths found are two estranged
paths and a. sister path, indicating that the relevant information found during the two
semantic relations is different: in one semantic relation, information about animals
drinking potable liquids is matched against cars using gasoline; in the other, the same
information is matched against human beings drinking coffee; but cars using gasoline and
human beings drinking coffee are quite different, hence sentence (27) is anomalous
overall.
Note that in Figures 20 and 21, the coherence representation part of the sentence
representation is much larger than the knowledge representation part. The detailed
&amp;quot;world knowledge&amp;quot; about car1, the verb sense drinkl, gasolinel, and coffeel are all on
the right side. It is interesting to contrast the figures with early Conceptual Dependency
(CD) diagrams such as those in Schank (1973) because, rather than the large and
seemingly unlimited amounts of world knowledge that appear in CD diagrams, the
two figures present only the world knowledge needed to discriminate the semantic
relations in (20) and (27).
</bodyText>
<sectionHeader confidence="0.441506" genericHeader="discussions">
7. Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.999827965517241">
This section reviews the material on metonymy and metaphor in Section 2 in light of
the explanation of the met* method given in Sections 3-6. When compared with the Al
work described in Section 2, the met* method has three main advantages. First, it con-
tains a detailed treatment of metonymy. Second, it shows the interrelationship between
metonymy, metaphor, literalness, and anomaly. Third, it has been programmed.
Preference Semantics addresses the recognition of literal, metaphorical, and anoma-
lous relations, but does not have a treatment of metonymy. In the case of Preference
Semantics, the theory described in Wilks (1978) has not been implemented, though
the projection algorithm was implemented (Modiano 1986) using some parts of CS to
supply detail missing from Wilks&apos; original specification.
Gentner&apos;s (1983) Structure-Mapping Theory has no treatment of metonymy. The
theory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbus
and Gentner 1989) and some examples analyzed by it but not, to my knowledge,
examples of metaphor or anomaly.
Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no
treatment of metonymy, anomaly or literalness. It has also not been implemented: see
Indurkhya (1987) for reasons why.
Hobbs and Martin (1987) offer a relatively shallow treatment of metonymy with-
out, for instance, acknowledgement that metonymies can be driven from either the
source or the target. Hobbs&apos; &amp;quot;selective inferencing&amp;quot; approach to text interpretation has
been applied to problems including lexical ambiguity (Hobbs 1977; 1982b; Hobbs and
Martin 1987), metaphor (Hobbs 1977; 1983a; 1983b) and the &amp;quot;local pragmatics&amp;quot; phe-
nomena of metonymy (Hobbs and Martin 1987), but not anomaly. To my knowledge,
Hobbs has yet to produce a unified description of selective inferencing that shows
in detail how lexical ambiguity is resolved or how the differences between metaphor,
metonymy, and so on can be recognized. Hobbs&apos; earlier papers include a series of
programs — SATE, DIANA, and DIANA-2 — but the papers are not clear about what
the programs can do. It is not clear, for example, whether any of the programs actually
analyze any metaphors.
</bodyText>
<page confidence="0.994301">
81
</page>
<note confidence="0.59037">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.92692808">
Martin&apos;s (1990) work is the only other computational approach to metaphor that
has been implemented. However, the work does not have a treatment of metonymy.
Martin&apos;s metaphor-maps, which are used to represent conventional metaphors and
the conceptual information they contain, seem to complement semantic vectors of
the extended kind described in Section 6. In Section 6, I argued that vectors need to
record the conceptual information involved when finding mappings between a source
and target. What metaphor-maps do is freeze (some of) the conceptual information
involved in particular metaphorical relations. There is some theoretical convergence
here between our approaches; it would be interesting to explore this further.
Moreover, the metaphors studied so far in CS seem linked to certain conventional
metaphors because certain types of ground have recurred, types which resemble Lakoff
and Johnson&apos;s (1980) structural metaphors. Two types of ground have cropped up so
far.
Example 28
&amp;quot;Time flies.&amp;quot;
The first is a use-up-a-resource metaphor which occurs in (20) and in (28) when
viewed as noun-verb sentence. Both sentences are analyzed by meta5. Use-up-a-re-
source resembles structural metaphors like TIME IS A RESOURCE and LABOR IS A
RESOURCE which, according to Lakoff and Johnson (1980, p. 66), both employ the
simple ontological metaphors of TIME IS A SUBSTANCE and AN ACTIVITY IS A
SUBSTANCE:
These two substance metaphors permit labor and time to be quantified — that is,
measured, conceived of as being progressively &amp;quot;used up,&amp;quot; and assigned
monetary values; they allow us to view time and labor as things that can be
&amp;quot;used&amp;quot; for various ends.
</bodyText>
<subsectionHeader confidence="0.884826">
Example 29
</subsectionHeader>
<bodyText confidence="0.9933439">
&amp;quot;The horse flew.&amp;quot;
The second type of ground is motion-through-a-medium, a type of ground dis-
cussed by Russell (1976). This appears in (15) and (29), again both analyzed by meta5.
Incidentally, it is worth noting that structural metaphors have proven more amena-
ble to the met* method than other kinds tried. I assumed initially that orientational and
ontological metaphors would be easier to analyze than structural metaphors because
they were less complex. However, structural metaphors have proved easier to analyze,
probably because structural metaphors contain more specific concepts such as &amp;quot;drink&amp;quot;
and &amp;quot;plough,&amp;quot; which are more simple to represent in a network structure (like the
sense-network of CS) so that analogies can be found between those concepts.
</bodyText>
<subsectionHeader confidence="0.999711">
7.1 Relationship between Literalness and Nonliteralness
</subsectionHeader>
<bodyText confidence="0.996282">
We return here to Gibbs&apos; point concerning the traditional notion of literal meaning that
[1] all sentences have literal meanings that are entirely determined by the meanings
of their component words and that [2] the literal meaning of a sentence is its meaning
independent of context. Although [1] and [2] are both presently true of CS, there are
means by which context can be introduced more actively into sentence interpretation.
At present, the meaning of a sentence in CS — whether literal or nonliteral —
is not derived entirely independently of context; however, the only context used is a
</bodyText>
<page confidence="0.997744">
82
</page>
<note confidence="0.532431">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.997854">
limited notion of relevance which is generated by collation from within the sentence
being analyzed: what is relevant is given by the sense of the main sentence verb.
Nevertheless, because of this notion of relevance, contextual influence is present in
semantic interpretation in CS. Moreover, the notion of relevance is recorded in semantic
vectors (Figures 11 and 15) and the extended coherence representations discussed in
Section 6. Hence, the processes and representations of CS possess basic equipment for
handling further kinds of context.
</bodyText>
<subsectionHeader confidence="0.999635">
7.2 Relationship between Metonymy and Metaphor
</subsectionHeader>
<bodyText confidence="0.9999842">
The met* method is consistent with the view that metaphor is based on similarity,
whereas metonymy is based on contiguity (cf. Jakobsen and Halle 1956). Contiguity,
readers may recall, refers to being connected or touching whereas similarity refers to
being alike in essentials or having characteristics in common. The difference comes
from what and how the conceptual information is related.
</bodyText>
<subsectionHeader confidence="0.745298">
Example 1
</subsectionHeader>
<bodyText confidence="0.9797544">
&amp;quot;My car drinks gasoline.&amp;quot;
Let us consider what is related first. In metaphor, an aspect of one concept is similar
to an aspect of another concept; e.g., in (1), an aspect of the concept for animal, that
animals drink potable liquids, is similar to an aspect of another concept, that cars use
gasoline.
</bodyText>
<subsectionHeader confidence="0.846325">
Example 2
</subsectionHeader>
<bodyText confidence="0.999144809523809">
&amp;quot;The ham sandwich is waiting for his check.&amp;quot;
However, in metonymy, a whole concept is related to an aspect of another concept.
For example, in (2) the metonymy is that the concept for ham sandwich is related to
an aspect of another concept, for &amp;quot;the man who ate a ham sandwich.&amp;quot;
Regarding how that conceptual information is related: in the case of metaphor,
the met* method assigns a central role to finding an analogy, and an analogy be-
tween two terms is due to some underlying similarity between them (the ground),
e.g., in the analogy that animals drinking potable liquids is like cars using gasoline,
the underlying similarity is that both animals and cars ingest liquids. In an analogy,
the relationship between aspects of two concepts is purely structural. In metonymies,
however, the relationships are &amp;quot;knowledge-laden&amp;quot; connections, e.g., PART-WHOLE
and CONTAINER-CONTENTS.
So in summary, &amp;quot;similarity&amp;quot; in metaphor is understood to be based on struc-
tural relationships between aspects of concepts, whereas &amp;quot;contiguity&amp;quot; in metonymy
is based on knowledge-specific relationships between a concept and an aspect of an-
other concept. These observations, I would argue, support the view that metonymy
has primarily a referential function, allowing something to stand for something else —
a connection between a concept and an aspect of another concept. The observations
also support the view that metaphor&apos;s primary function is understanding, allowing
something to be conceived of in terms of something else: the role of analogy is espe-
cially crucial to this function.
</bodyText>
<subsectionHeader confidence="0.99822">
7.3 Metonymy
</subsectionHeader>
<bodyText confidence="0.9994905">
The treatment of metonymy permits chains of metonymies (Reddy 1979), and allows
metonymies to co-occur with instances of either literalness, metaphor, or anomaly.
</bodyText>
<page confidence="0.995647">
83
</page>
<note confidence="0.584583">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.8407311875">
The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987)
notes link sentences. An obvious direction in which to extend the present work is
toward across-sentence inferences.
Example 30
&amp;quot;John drank from the faucet&amp;quot; (Lehnert 1978, p. 221).
Example 31
&amp;quot;John filled his canteen at the spring&amp;quot; (Ibid.).
Metonymy seems closely related to the work on non-logical inferencing done by
Schank (Schank 1973) and the Yale Group (Schank 1975; Schank and Abelson 1977;
Schank and Riesbeck 1981). For example, Lehnert (1978) observes that just one infer-
ence is required for understanding both (30) and (31). The inference, that water comes
from the faucet in (30) and the spring in (31), is an instance of PRODUCER FOR
PRODUCT in which the faucet and spring are PRODUCERs and water is the PROD-
UCT. However, the inference is not a metonymy because it is from unused cases of the
verbs &apos;drink&apos; and &apos;fill&apos; whereas metonymy only occurs in the presence of a violated
selection restriction, that neither (30) nor (31) contain.
</bodyText>
<subsectionHeader confidence="0.850846">
7.4 Metaphor
</subsectionHeader>
<bodyText confidence="0.903737">
Metaphor recognition in the met* method is related to all four views of metaphor
described in Section 2, consisting of:
</bodyText>
<listItem confidence="0.964649571428572">
1. a contextual constraint violation, such as a preference violation — as in
the selection restrictions view;
2. a set of &amp;quot;correspondences&amp;quot; — rather like the system of commonplaces in
the interaction view;
3. a relevant analogy — cf. the comparison and interaction views; with
4. analogies that fall into patterns not unlike conceptual metaphors found
in the conventional view.
</listItem>
<bodyText confidence="0.999889642857143">
In CS, the presence of metaphor has been investigated in violations of preferences,
a kind of lexical contextual constraint. Though clearly this is a small part of the picture,
it seems worth establishing an extensive picture of preference violation and metaphor
before moving on to other contextual constraints.
Collation and the met* method have certain similarities with the comparison view
of metaphor, especially in the cell matching process. The relevant analogies discovered
in CS are indeed, to quote Tourangeau and Sternberg, &amp;quot;a comparison in which one
term... is asserted to bear a partial resemblance to something else.&amp;quot;
The collation process gives quite a clear picture of the ground and tension in a
metaphor. The ground is the most specific statement that subsumes both statements
that figure in the analogy, e.g., [it1, ingest1, liquidl] is the ground for the analogy
involving [anima11, drinkl, drinkl ] and [car1, use2, gasoline11 (see Figures 8 and 9).
Moreover, the details of the process match well Aristotle&apos;s two basic principles for
finding the ground of a metaphor in that both terms in a metaphorical relation belong
</bodyText>
<page confidence="0.996113">
84
</page>
<note confidence="0.574062">
Fass Discriminating Metonymy
</note>
<bodyText confidence="0.996971195652174">
to a common category (in the example above, the common categories are it1, ingest1,
and liquidl) and an analogy is found between them.
The collation process also takes care of many of the problems Tourangeau and
Sternberg (1980) note with the comparison view. Regarding the problem that &amp;quot;every-
thing shares some feature or category... with everything else,&amp;quot; CS is in agreement: the
only significant combination of features in a metaphor are those involved in a relevant
analogy. The problem that &amp;quot;the most obvious shared features are often irrelevant,&amp;quot; i.e.,
that the most obvious shared features are irrelevant to a metaphor, is borne out by
experience with CS — for example, animals and cars share some basic physical object-
like properties, but these have a minor role in understanding cars drinking. The met*
method bears out another problem that, &amp;quot;even when a feature is relevant, it is often
shared only metaphorically.&amp;quot; Finally, with the problem that novel metaphors cannot
be based on &amp;quot;extant similarities,&amp;quot; — the relevant analogies found in the met* method
are not &amp;quot;extant&amp;quot; but have to be actively discovered.
In Section 2, two main differences were noted between the interaction and com-
parison views: first, that similarities are &amp;quot;created&amp;quot; in the interaction view, whereas only
pre-existing similarities are found in the comparison view, and second, that a whole
system of similarities are evoked in the interactions view, unlike the comparisons view,
which focuses upon finding a single similarity. Regarding the first difference, I would
argue that the difference is a mistaken one and that interaction theorists are simply us-
ing a sophisticated form of comparison. This is quite evident when one examines, for
example, the methods Tourangeau and Sternberg propose for relating features across
domains in their theory. The second of Aristotle&apos;s basic principles is finding an anal-
ogy, yet Tourangeau and Sternberg (1982, p. 218) themselves say that, &amp;quot;in a sense, we
are proposing that metaphors are analogies that include both tenor and vehicle and
their different domains as terms.&amp;quot;
And, of course, finding an analogy is central to the met* method on CS.
Regarding the second difference, I would agree that finding a system of common-
places is distinctive. However, the extensions to CS described in Section 6 move toward
the direction of finding a system of commonplaces in that the deeper semantic vec-
tors, and sentence representations shown in Figures 20 and 21 contain the information
crucial to finding a system of commonplaces. Having identified the crucial analogy in
(20), the deeper semantic vector contains the two pairs of matched relevant cells that
provide the core analogy on which the metaphorical interpretation of (20) is built:
ffanimall, drink1, drink1J, [car1, use2, gasoline1]]
Ranima11, drink1, drinkl], [vehiclel, use2, gasolinel]]
With this information at hand, the sense-frames for word senses in analogical corre-
spondence — the verb senses drink1 and use2, the noun senses animall and car1,
animal1 and vehicle1, and drinkl and gasolinel — can be systematically expanded to
uncover deeper commonplaces between animals and cars.
In conclusion, the view of metonymy and metaphor in the met* method is consis-
tent with much of the literature on these phenomena. The met* method is consistent
with the view that the primary function of metaphor is understanding while that of
metonymy is referential, like anaphora. Nevertheless, metonymy and metaphor do
have much in common: both might be described as forms of &amp;quot;conceptual ellipsis,&amp;quot; a
shorthand way of expressing ideas.
</bodyText>
<page confidence="0.997858">
85
</page>
<note confidence="0.5624">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.972318">
The met* method in its present serial form recognizes literalness, metonymy,
metaphor, and anomaly in the following order and by the following characteristics.
</bodyText>
<listItem confidence="0.999942">
• Literalness — a satisfied preference.
• Metonymy — a successful conceptual inference.
• Metaphor — an underlying relevant analogy.
• Anomaly — none of the above.
</listItem>
<bodyText confidence="0.902959351351351">
The above analysis also illustrates, I hope, why metonymy and metaphor are easily
confused: both are nonliteral and are found through the discovery of some aspect (a
property) shared by the source, a preference, and the target, in the above case a surface
noun. The differences are (a) how that aspect is selected, (b) the operations that follow,
(c) the effect those operations produce, and (d) subsequent processing.
In the case of metonymy, (a) the selected aspect forms a regular semantic relation-
ship with a property from the target; (b) there is substitution, i.e., replacement of one
concept with another; (c) hence the apparent referential function of metonymy; and
(d) is unclear at present.
In the case of metaphor, (a) the selected aspect is relevant; (b) forms an analogy
with another aspect from the target; and (c) the effect is of surprise discovery of
similarity between the two concepts; and (d) the discovered analogy is used to unearth
further similarities between the two concepts (i.e, to deepen the analogy) and to guide
subsequent sentence interpretation. Moreover, the view of metaphor in CS contains
elements of the selection restrictions view, the comparisons view, and the interactions
view of metaphor.
It should be emphasized that the met* method has only been applied to a small
set of English sentences. Metonymy interpretation has been investigated only for
adjective-noun and subject-verb-object constructions; metaphor interpretation, only for
the latter. The best avenue for progress with the met* method appears to be the exten-
sions to metaphor interpretation described in Section 6. In the meantime I am looking
for sentences that contain semantic relations consisting of a metonymy (or chain of
metonymies) followed by a metaphor.
Example 32
&amp;quot;America believes in democracy&amp;quot; (Hobbs 1983b, p. 134).
On a related point, some sentences are interesting in this respect because they
have either a metaphorical or metonymic interpretation. In (32), for example, &amp;quot;Are
we viewing America metaphorically as something which can believe, or are we using
it metonymically to refer to the typical inhabitant, or the majority of inhabitants, of
America?&amp;quot; (Ibid., p. 135).
Example 33
&amp;quot;Prussia invaded France in 1870.&amp;quot;
Sentence (33), which was discussed in a group working on beliefs at the CRL (see
Acknowledgments), also has separate metonymic and metaphorical interpretations.
The key semantic relation is between &apos;Prussia&apos; and &apos;invade.&apos; The relation is nonliteral
because &apos;army&apos; is the expected agent of &apos;invade&apos; and &apos;Prussia&apos; is a country, not an army.
What, then, is the semantic relation between &apos;Prussia&apos; and &apos;army&apos;? One possibility is
</bodyText>
<page confidence="0.990167">
86
</page>
<subsectionHeader confidence="0.843969">
Fass Discriminating Metonymy
</subsectionHeader>
<bodyText confidence="0.999905">
that a chain of metonymies is involved, that the army is controlled by the govern-
ment which also controls Prussia. A second possibility is that Prussia is understood
metaphorically as being an animate thing that extends itself into France.
</bodyText>
<sectionHeader confidence="0.982859" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999507833333333">
I would like to thank the many people at
the Cognitive Studies Centre, University of
Essex; the Computing Research Laboratory,
New Mexico State University; and the
Centre for Systems Science, Simon Fraser
University, with whom I have had fruitful
discussions over the years, especially those
in the beliefs group at the CRL (Afzal
Ballim, John Barnden, Sylvia Candelaria de
Ram, and Yorick Wilks); others at the CRL
(including Xiuming Huang, David Farwell,
and Eric Dietrich); and colleagues in the
CSS who made helpful comments on earlier
drafts of this paper (Chris Groeneboer, Gary
Hall, and Carl Vogel). A special word of
thanks for the help given by Yorick Wilks,
the director of the CRL, and Nick Cercone,
the director of the CSS. I also gratefully
acknowledge the financial support provided
by SERC Project GR/C/68828 while at
Essex, by the New Mexico State Legislature
while at NMSU, and by the Advanced
Systems Institute and the Centre for
Systems Science while at SFU.
</bodyText>
<sectionHeader confidence="0.99198" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998834988095238">
Amsler, Robert A. (1980). The structure of the
Merriam-Webster Pocket Dictionary.
Doctoral dissertation TR-164, University
of Texas, Austin, Texas.
Basso, K.H. (1976). &amp;quot; &apos;Wise words&apos; of the
Western Apache: metaphor and semantic
theory.&amp;quot; In Meaning in anthropology, edited
by K.H. Basso and H. Selby, New Mexico
Press.
Beardsley, M. (1962). &amp;quot;The metaphorical
twist.&amp;quot; Philosophy and Phenomenological
Research, 22:293-307.
Bickerton, Derek (1969). &amp;quot;Prolegomena to a
linguistic theory of metaphor.&amp;quot;
Foundations of Language, 5:36-51.
Black, Max (1979). &amp;quot;More about metaphor.&amp;quot;
In Metaphor and thought, edited by
A. Ortony, 19-43. Cambridge University
Press.
Black, Max (1962). Models and Metaphors.
Cornell University Press.
Boguraev, Branimir K. (1979). &amp;quot;Automatic
resolution of linguistic ambiguities.&amp;quot;
Technical Report No. 11, University of
Cambridge Computer Laboratory,
Cambridge, England.
Campbell, P. (1975). &amp;quot;Metaphor and
linguistic theory.&amp;quot; Quarterly Journal of
Speech, 61:1-12.
Chomsky, Noam (1964). &amp;quot;Degrees of
grammaticalness.&amp;quot; In The Structure of
Language: Readings in the Philosophy of
Language, edited by J.A. Fodor and
J.J. Katz, 384-389, Prentice-Hall.
Van Dijk, T. (1975). &amp;quot;Formal semantics of
metaphorical discourse.&amp;quot; Poetics,
4:173-198.
Dubois, J.; Edeline, E; Klinkenberg, J.-M.;
Minguet, P.; Fire, E; and Trinon, H. (1970).
Rhetorique Generale. Larousse. Published
as: A General Rhetoric, translated by
RB. Burrell and E.M. Slotkin, 1981, The
John Hopkins University Press.
Falkenhainer, Brian; Forbus, Kenneth D.;
and Gentner, Dedre (1986). &amp;quot;The
structure-mapping engine: algorithm and
examples.&amp;quot; Artificial Intelligence, 41:1-63.
Fass, Dan C. (1986). &amp;quot;Collative semantics: an
approach to coherence.&amp;quot; Technical Report
MCCS-86-56, Computing Research
Laboratory, June 1986.
Fass, Dan C. (1987). &amp;quot;Semantic relations,
metonymy, and lexical ambiguity
resolution: a coherence-based account.&amp;quot; In
Proceedings, 9th Annual Cognitive Science
Society Conference, University of
Washington, Seattle, Washington: 575-586.
Fass, Dan C. (1988a). Collative semantics: a
semantics for natural language processing.
Doctoral dissertation, New Mexico State
University, New Mexico.
Fass, Dan C. (1988b). &amp;quot;An account of
coherence, semantic relations, metonymy,
and lexical ambiguity resolution.&amp;quot; In
Lexical Ambiguity Resolution: Perspectives
from Psycholinguistics, Neuropsychology, and
Artificial Intelligence, edited by Steven
L. Small, Garrison W. Cottrell, and
Michael K. Tanenhaus, Morgan
Kaufmann, 151-178.
Fass, Dan C. (1988c). &amp;quot;Metonymy and
metaphor: what&apos;s the difference?&amp;quot; In
Proceedings, 12th International Conference on
Computational Linguistics (COLING-88),
Budapest, Hungary, 177-181.
Fass, Dan C. (1988d). &amp;quot;Collative semantics: a
study in the discrimination of meaning.&amp;quot;
Technical Report CSS/LCCR TR 88-24,
Centre for Systems Science, Simon Fraser
University.
Fass, Dan C. (1989a). &amp;quot;Lexical semantic
constraints.&amp;quot; Technical Report CSS/LCCR
TR 89-11, Centre for Systems Science,
Simon Fraser University. (To appear in
</reference>
<page confidence="0.997225">
87
</page>
<reference confidence="0.982328106557377">
Computational Linguistics Volume 17, Number 1
Semantics and the Lexicon, edited by James
Pustejovsky. Kluwer Academic
Publishers.)
Fass, Dan C. (1989b). &amp;quot;Four general
representations and processes for use in
problem solving.&amp;quot; In Knowledge Based
Computer Systems (Proceedings of KBCS &apos;89,
Bombay, India), edited by S. Ramani,
R. Chandrasekar, and K.S.R. Anjeyulu,
Narosa Publishing House, 169-178.
Genette, Gerard (1970). &amp;quot;La rhetorique
restreinte.&amp;quot; Communications, 16:158-171.
Gentner, Dedre (1983). &amp;quot;Structure mapping:
a theoretical framework for analogy.&amp;quot;
Cognitive Science, 7:155-170.
Gibbs, Raymond W. Jr. (1984). &amp;quot;Literal
meaning and psychological theory.&amp;quot;
Cognitive Science, 8:275-304.
Grosz, Barbara J.; Appelt, Douglas E.;
Martin, Paul; and Pereira, Fernando C.N.
(1987). &amp;quot;TEAM: An experiment in the
design of transportable natural-language
interfaces.&amp;quot; Artificial Intelligence,
32(2):173-243.
Harris, R. (1976). &amp;quot;Comprehension of
metaphor: a test of a two-stage processing
model.&amp;quot; Bulletin of the Psychonomic Society,
8:321-324.
Hesse, M. (1966). Models and Analogies in
Science. Notre Dame University Press.
Hobbs, Jerry R. (1977). &amp;quot;Coherence and
interpretation in English texts.&amp;quot; In
Proceedings, 5th International Joint
Conference on Artificial Intelligence
(IJCAI-77), Cambridge, Massachusetts,
110-116.
Hobbs, Jerry R. (1979). &amp;quot;Coherence and
coreference.&amp;quot; Cognitive Science, 3:67-90.
Hobbs, Jerry R. (1980). &amp;quot;Selective
inferencing.&amp;quot; In Proceedings, 3rd National
Conference of the Canadian Society for
Computational Studies of Intelligence
(CSCSI-3), Victoria, British Columbia,
Canada, 101-114.
Hobbs, Jerry R. (1982a). &amp;quot;Towards an
understanding of coherence in discourse.&amp;quot;
In Strategies for Natural Language
Processing, edited by Wendy G. Lehnert
and Martin H. Ringle, Erlbaum
Associates, 223-243.
Hobbs, Jerry R. (1982b). &amp;quot;Representing
ambiguity.&amp;quot; In Proceedings, 1st West Coast
Conference on Formal Linguistics, Stanford,
California, 15-28.
Hobbs, Jerry R. (1983a). &amp;quot;Metaphor
interpretation as selective inferencing:
cognitive processes in understanding
metaphor (Part 1).&amp;quot; Empirical Studies of the
Arts, 1:17-33.
Hobbs, Jerry R. (1983b). &amp;quot;Metaphor
interpretation as selective inferencirtg:
cognitive processes in understanding
metaphor (Part 2).&amp;quot; Empirical Studies of the
Arts, 1:125-141.
Hobbs, Jerry R. (1985). &amp;quot;On the coherence
and structure of discourse.&amp;quot; Technical
Report No. CSLI-85-37, Center for the
Study of Language and Information
(CSLI), Stanford University.
Hobbs, Jerry R. and Martin, Paul (1987).
&amp;quot;Local Pragmatics.&amp;quot; In Proceedings, 10th
International Joint Conference on Artificial
Intelligence (IJCAI-87), Milan, Italy,
520-523.
Huang, Xiuming (1985). &amp;quot;Machine
translation in the SDCG (Semantic
Definite Clause Grammars) formalism.&amp;quot;
In Proceedings, Conference on Theoretical and
Methodological Issues in Machine Translation
of Natural Languages, Colgate University,
New York, New York, 135-144.
Indurkhya, Bipin (1985). &amp;quot;A computational
theory of metaphor comprehension and
analogical reasoning.&amp;quot; Technical Report
#85/001, Boston University.
Indurkhya, Bipin (1987). &amp;quot;Approximate
semantic transference: a computational
theory of metaphors and analogies.&amp;quot;
Cognitive Science, 11(4):445-480.
Indurkhya, Bipin (1988). &amp;quot;Constrained
semantic transference: a formal theory of
metaphors.&amp;quot; In Analogica: Proceedings of
the First Workshop on Analogical Reasoning,
edited by Armand Prieditis, Morgan
Kaufmann (Pitman Research Notes in
Artificial Intelligence), Los Altos,
California, 129-157.
Jacobs, Paul S. (1985). &amp;quot;A knowledge-based
approach to language production.&amp;quot;
Technical Report No. UCB/CSD 86/254,
Computer Science Division (EECS),
University of California, Berkeley.
Jakobsen, Roman and Halle, Morris (1956).
Fundamentals of Language. Mouton.
Johnson, Mark (1980). &amp;quot;A philosophical
perspective on the problems of
metaphor.&amp;quot; In Cognition and Figurative
Language, edited by Richard P. Honeck
and Robert R. Hoffman, 47-68, Erlbaum
Associates.
Katz, Jerrold J. (1964). &amp;quot;Analyticity and
contradiction in natural language.&amp;quot; In The
Structure of Language: Readings in the Phil-
osophy of Language, edited by J.A. Fodor
and J.J. Katz, 519-543, Prentice-Hall.
Lakoff, George and Johnson, Mark (1980).
Metaphors We Live By. Chicago University
Press.
Lees, R.B. (1960). &amp;quot;The grammar of English
nominalizations.&amp;quot; International Journal of
American Linguistics, 26(3).
</reference>
<page confidence="0.987786">
88
</page>
<reference confidence="0.999457098360656">
Fass Discriminating Metonymy
Lenat, Douglas B. and Guha, R. V. (1990).
Building Large Knowledge-Based Systems:
Representation and Inference in the CYC
Project. Addison-Wesley.
Levin, Samuel R. (1977). The Semantics of
Metaphor. John Hopkins University Press.
Loewenberg, Ina (1975). &amp;quot;Identifying
metaphors.&amp;quot; Foundations of Language,
12:315-338.
Malgady, R. and Johnson, M. (1976).
&amp;quot;Modifiers in metaphors: effects of
constituent phrase similarity on the
interpretation of figurative sentences.&amp;quot;
Journal of Psycholinguistic Research, 5:43-52.
Martin, James H. (1990). A Computational
Model of Metaphor Interpretation. Academic
Press.
Martin, James H. (1988). &amp;quot;A computational
theory of metaphor.&amp;quot; Technical Report
No. UCB/CSD 88/465, Computer Science
Division (EECS), University of California,
Berkeley.
Martin, James H. (1985). &amp;quot;Knowledge
acquisition through natural language
dialogue.&amp;quot; In Proceedings, 2nd Annual
Conference on Artificial Intelligence
Applications, Miami, Florida.
Matthews, R. J. (1971). &amp;quot;Concerning a
&apos;linguistic theory&apos; of metaphor.&amp;quot;
Foundations of Language, 7:413-425.
Miles, J. (1967). Style and Proportion. Little,
Brown and Co.
Mish, Frederick C. (1986). Webster&apos;s Ninth
New Collegiate Dictionary. Merriam-
Webster Inc.
Modiano, Nicole (1986). &amp;quot;Two procedures
for sense projection.&amp;quot; Unpublished ms.,
Computing Research Laboratory, New
Mexico State University.
Van Noppen, Jean-Pierre; De Knop, S.; and
Jongen, R. (1985). Metaphor: A Bibliography
of post-1970 Publications. Amsterdam
Studies in the Theory and History of
Linguistic Science (Series V: Library and
Information Sources in Linguistics),
Volume 17, John Benjamins Publishing
Company.
Ortony, Andrew (1980). &amp;quot;Some
psycholinguistic aspects of metaphor.&amp;quot; In
Cognition and Figurative Language, edited
by Richard P. Honeck and Robert
R. Hoffman, 69-83, Erlbaum Associates.
Ortony, Andrew (1979). &amp;quot;Beyond literal
similarity.&amp;quot; Psychological Review,
86:161-180.
Percy, Walker (1954). The Message in the
Bottle. Farrar, Strauss, and Giroux.
Quillian, M. Ross (1968). &amp;quot;Semantic
memory.&amp;quot; In Semantic Information
Processing, edited by Marvin Minsky,
216-270, MIT Press.
Perrine, Lawrence (1971). &amp;quot;Psychological
forms of metaphor.&amp;quot; College English,
33:125-138.
Reddy, Michael J. (1979). &amp;quot;The conduit
metaphor - a case of frame conflict in
our language about language.&amp;quot; In
Metaphor and Thought, edited by Andrew
Ortony, 284-324, Cambridge University
Press.
Reddy, Michael J. (1969). &amp;quot;A semantic
approach to metaphor.&amp;quot; In Chicago
Linguistic Society Collected Papers, Chicago
University Press, 240-251.
Richards, Ivor A. (1936). The Philosophy of
Rhetoric. Oxford University Press.
Russell, Sylvia Weber (1976). &amp;quot;Computer
understanding of metaphorically used
verbs.&amp;quot; American Journal of Computational
Linguistics, Microfiche 44.
Schank, Roger C. (1975). &amp;quot;The structure of
episodes in memory.&amp;quot; In Representation
and Understanding, edited by Daniel
G. Bobrow and Allan Collins, 237-272.
Academic Press.
Schank, Roger C. (1973). &amp;quot;Identification of
conceptualizations underlying natural
language.&amp;quot; In Computer Models of Thought
and Language, edited by Roger C. Schank
and Kenneth M. Colby, 187-247.
W.H. Freeman.
Shibles, Warren (1971). Metaphor: An
Annotated Bibliography and History. The
Language Press.
Stern, Gustaf (1968). (first published in
Sweden 1931) Meaning and Changes of
Meaning. Indiana University Press.
Tourangeau, Roger and Sternberg, Robert J.
(1982). &amp;quot;Understanding and appreciating
metaphors.&amp;quot; Cognition, 11:203-244.
Tversky, Amos (1977). &amp;quot;Features of
similarity.&amp;quot; Psychological Review,
84:327-352.
Ullmann, Stephen (1962). Semantics: An
Introduction to the Science of Meaning. Basil
Blackwell &amp; Mott Ltd.
Waldron, Ronald A. (1967). Sense and Sense
Development. Andre Deutsch.
Weiner, E. Judith (1985). &amp;quot;Solving the
containment problem for figurative
language.&amp;quot; International journal of
Man-Machine Studies, 23:527-537.
Weiner, E. Judith (1984). &amp;quot;A knowledge
representation approach to understanding
metaphors.&amp;quot; American Journal of
Computational Linguistics, 10:1-14.
Wheelwright, P. (1962). Metaphor and Reality.
Indiana University Press.
Wilks, Yorick A. (1978). &amp;quot;Making
preferences more active.&amp;quot; Artificial
Intelligence, 11:197-223.
</reference>
<page confidence="0.994218">
89
</page>
<reference confidence="0.930448078125">
Computational Linguistics Volume 17, Number 1
Wilks, Yorick A. (1975b). &amp;quot;An intelligent
analyzer and understander for English.&amp;quot;
Communications of the ACM, 18:264-274.
Wilks,Yorick A. (1975a). &amp;quot;A preferential
pattern-seeking semantics for natural
language inference.&amp;quot; Artificial Intelligence,
6:53-74.
Wilks, Yorick A. (1973). &amp;quot;An artificial
intelligence approach to machine
translation.&amp;quot; In Computer Models of
Thought and Language, edited by Roger
C. Schank and Kenneth M. Colby,
114-151, W.H. Freeman.
Wilks, Yorick A. and Fass, Dan C. (In press).
&amp;quot;The preference semantics family.&amp;quot; To
appear in Computers and Mathematics with
Applications, Special Issue on Semantic
Networks in Artificial Intelligence.
Winston, Patrick H. (1980). &amp;quot;Learning by
creatifying transfer frames.&amp;quot; In Artificial
Intelligence: An MIT Perspective, Volume 1,
edited by Patrick H. Winston and Richard
H. Brown, 347-376, MIT Press.
Yamanashi, Masa-aki (1987). &amp;quot;Metonymic
interpretation and associative processes in
natural language.&amp;quot; In Language and
Artificial Intelligence (Proceedings of an
International Symposium on Language and
Artificial Intelligence held in Kyoto, Japan,
16-21 March 1986), edited by Makoto
Nagao, 77-86, Elsevier Science Publishers.
Glossary of Main Terms
Anomalous relation: a semantic relation
indicated by a violated preference and the
absence of a relevant analogy [see
Section 31.
Assertion: a word sense-based contextual
constraint in which semantic information is
imposed onto the local context of a word
sense [Section 3].
Collation: a process that discriminates the
semantic relation(s) between two word
senses by matching the sense-frames for the
word senses [Section 4].
Literal relation: a semantic relation indicated
by a satisfied preference [Section 3].
Metaphor: a trope in which one entity is
used to view another entity to which it
bears a partial resemblance [Sections 2-7].
Metaphorical relation: a semantic relation
indicated by a violated preference and the
presence of a relevant analogy [Section 3].
Metonymy: a trope in which one entity is
used to refer to another that is related to it
[Sections 2-71
Metonymic relation: a semantic relation
indicated by failure to satisfy a preference
and the presence of one or more conceptual
relationships like PART-WHOLE [Section 3].
Preference: a word sense-based contextual
constraint in which semantic information
restricts the local context of a word sense
[Section 31.
</reference>
<bodyText confidence="0.931225193548387">
Screening: a process that resolves lexical
ambiguity by choosing among semantic
vectors on the basis of rank orderings
among semantic relations and a measure of
conceptual similarity [Section 41.
Semantic relation: the basis of literalness,
metonymy, metaphor, etc.; found by
evaluating lexical semantic constraints in
sentences [Section 3].
Semantic vector: a data structure that
represents semantic relations by recording
the matches produced by collation
[Section 4].
Sense-frame: a framelike data structure that
represents a word sense and is composed of
other word senses having their own
sense-frames [Section 41.
Sense-network: a semantic network of word
senses formed from information in
sense-frames [Section 4].
Source: the lexical item in a semantic
relation whose contextual constraint(s) are
enforced [Section 3].
Target: the lexical item in a semantic relation
on which contextual constraint(s) are
applied [Section 31.
Trope: the technical term for a nonliteral
figure of speech, e.g., metaphor, metonymy,
simile, understatement (litotes),
overstatement (hyperbole), and irony
[Section 1].
</bodyText>
<page confidence="0.997205">
90
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.826655">
<title confidence="0.9997485">met*: A Method for Discriminating Metonymy and Metaphor by Computer</title>
<author confidence="0.999517">Dan Fass</author>
<affiliation confidence="0.930646">Simon Fraser University</affiliation>
<abstract confidence="0.9895245">The met* method distinguishes selected examples of metonymy from metaphor and from literalness and anomaly in short English sentences. In the met* method, literalness is distinguished because it satisfies contextual constraints that the nonliteral others all violate. Metonymy is discriminated from metaphor and anomaly in a way that [1] supports Lakoff and Johnson&apos;s (1980) view that in metonymy one entity stands for another whereas in metaphor one entity is viewed as another, [2] permits chains of metonymies (Reddy 1979), and [3] allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. Metaphor is distinguished from anomaly because the former contains a relevant analogy, unlike the latter. The met* method is part of Collative Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5&apos;s analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert A Amsler</author>
</authors>
<title>The structure of the Merriam-Webster Pocket Dictionary. Doctoral dissertation TR-164,</title>
<date>1980</date>
<institution>University of Texas,</institution>
<location>Austin, Texas.</location>
<contexts>
<context position="46652" citStr="Amsler 1980" startWordPosition="7230" endWordPosition="7231">lso Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found in dictionary definitions (Amsler 1980). The arcs part of a sense-frame contains a labeled arc to its genus term (a word sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a densely structured semantic network of word senses called the sense-network. The node part of a sense-frame contains the differentia of the word sense defined by that senseframe, i.e., information distinguishing that word sense from other word senses sharing the same genus. The two lexical semantic constraints mentioned earlier, preferences and assertions, play a prominent part in sense-frame nodes. Sense-frame nodes for nouns </context>
</contexts>
<marker>Amsler, 1980</marker>
<rawString>Amsler, Robert A. (1980). The structure of the Merriam-Webster Pocket Dictionary. Doctoral dissertation TR-164, University of Texas, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K H Basso</author>
</authors>
<title>Wise words&apos; of the Western Apache: metaphor and semantic theory.&amp;quot; In Meaning</title>
<date>1976</date>
<publisher>Mexico Press.</publisher>
<location>New</location>
<note>in anthropology, edited by</note>
<marker>Basso, 1976</marker>
<rawString>Basso, K.H. (1976). &amp;quot; &apos;Wise words&apos; of the Western Apache: metaphor and semantic theory.&amp;quot; In Meaning in anthropology, edited by K.H. Basso and H. Selby, New Mexico Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Beardsley</author>
</authors>
<title>The metaphorical twist.&amp;quot;</title>
<date>1962</date>
<journal>Philosophy and Phenomenological Research,</journal>
<pages>22--293</pages>
<contexts>
<context position="14178" citStr="Beardsley (1962)" startWordPosition="2176" endWordPosition="2177">cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is co</context>
</contexts>
<marker>Beardsley, 1962</marker>
<rawString>Beardsley, M. (1962). &amp;quot;The metaphorical twist.&amp;quot; Philosophy and Phenomenological Research, 22:293-307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derek Bickerton</author>
</authors>
<title>Prolegomena to a linguistic theory of metaphor.&amp;quot;</title>
<date>1969</date>
<journal>Foundations of Language,</journal>
<pages>5--36</pages>
<contexts>
<context position="14196" citStr="Bickerton (1969)" startWordPosition="2178" endWordPosition="2179">He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowled</context>
</contexts>
<marker>Bickerton, 1969</marker>
<rawString>Bickerton, Derek (1969). &amp;quot;Prolegomena to a linguistic theory of metaphor.&amp;quot; Foundations of Language, 5:36-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Black</author>
</authors>
<title>More about metaphor.&amp;quot; In Metaphor and thought, edited by A. Ortony,</title>
<date>1979</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="37416" citStr="Black 1979" startWordPosition="5795" endWordPosition="5796">&amp;quot; not for example the sense meaning &amp;quot;movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relations belong to two classes, the preference-based and as</context>
</contexts>
<marker>Black, 1979</marker>
<rawString>Black, Max (1979). &amp;quot;More about metaphor.&amp;quot; In Metaphor and thought, edited by A. Ortony, 19-43. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Black</author>
</authors>
<title>Models and Metaphors.</title>
<date>1962</date>
<publisher>Cornell University Press.</publisher>
<contexts>
<context position="8722" citStr="Black (1962)" startWordPosition="1326" endWordPosition="1327">sion between the two terms of a metaphor: the comparison theory ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212), proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967), Richards (1936), and Wheelwright (1962). Interaction theorists argue that the vehicle of a metaphor is a template for seeing the tenor in a new way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may onl</context>
<context position="10172" citStr="Black, 1962" startWordPosition="1549" endWordPosition="1550">istics Volume 17, Number 1 A problem with the interaction view is that theorists have not provided much detail about the processes involved, though Black (1962) does make some suggestions. According to Black, tenor and vehicle... each have a &apos;system of commonplaces&apos; associated with them. These commonplaces are stereotypes, not necessarily definitional, not even necessarily true, just widely agreed upon. In interpreting &apos;man is a wolf,&apos; we &apos;evoke the wolf-system of related commonplaces&apos; and are led by them &apos;to construct a corresponding system of implications about the principal subject (Man)&apos; (Black, 1962, p. 41). In Black&apos;s view, then, interpretation involves not so much comparing tenor and vehicle for existing similarities, as construing them in a new way so as to create similarity between them (Tourangeau and Sternberg 1982, p. 213). One might distinguish, then, two main differences between the interaction and comparison views. First, similarities are &amp;quot;created&amp;quot; in the interaction view (accounting for the novelty and surprise in a metaphor) whereas only pre-existing similarities are found in the comparison view. Second, a whole system of similarities are evoked between tenor and vehicle in t</context>
<context position="37278" citStr="Black 1962" startWordPosition="5776" endWordPosition="5777">xical items. For example, the metaphorical reading of (15) is because &apos;waves&apos; is understood as being the sense meaning &amp;quot;movement of water,&amp;quot; not for example the sense meaning &amp;quot;movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, meta</context>
</contexts>
<marker>Black, 1962</marker>
<rawString>Black, Max (1962). Models and Metaphors. Cornell University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir K Boguraev</author>
</authors>
<title>Automatic resolution of linguistic ambiguities.&amp;quot;</title>
<date>1979</date>
<tech>Technical Report No. 11,</tech>
<institution>University of Cambridge Computer Laboratory,</institution>
<location>Cambridge, England.</location>
<contexts>
<context position="59337" citStr="Boguraev (1979)" startWordPosition="9224" endWordPosition="9225">distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those sentences (i.e., the program recognizes metonymies, metaphors, and so on), and resolves any lexical ambiguity in those sentences. Meta5 analyzes all the sentences given in Sections 3 and 4, plus a couple more metaphorical sentences discussed in Section 7. Below are simplified versions of some of the metonymic inference rules used in meta5. The metonymic concepts used in CS contain three key elements: the conceptual relationship involved,</context>
</contexts>
<marker>Boguraev, 1979</marker>
<rawString>Boguraev, Branimir K. (1979). &amp;quot;Automatic resolution of linguistic ambiguities.&amp;quot; Technical Report No. 11, University of Cambridge Computer Laboratory, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Campbell</author>
</authors>
<title>Metaphor and linguistic theory.&amp;quot;</title>
<date>1975</date>
<journal>Quarterly Journal of Speech,</journal>
<pages>61--1</pages>
<contexts>
<context position="14213" citStr="Campbell (1975)" startWordPosition="2180" endWordPosition="2181">y problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures cal</context>
</contexts>
<marker>Campbell, 1975</marker>
<rawString>Campbell, P. (1975). &amp;quot;Metaphor and linguistic theory.&amp;quot; Quarterly Journal of Speech, 61:1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Degrees of grammaticalness.&amp;quot;</title>
<date>1964</date>
<booktitle>In The Structure of Language: Readings in the Philosophy of Language,</booktitle>
<pages>384--389</pages>
<note>edited by</note>
<marker>Chomsky, 1964</marker>
<rawString>Chomsky, Noam (1964). &amp;quot;Degrees of grammaticalness.&amp;quot; In The Structure of Language: Readings in the Philosophy of Language, edited by J.A. Fodor and J.J. Katz, 384-389, Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Van Dijk</author>
</authors>
<title>Formal semantics of metaphorical discourse.&amp;quot;</title>
<date>1975</date>
<journal>Poetics,</journal>
<pages>4--173</pages>
<marker>Van Dijk, 1975</marker>
<rawString>Van Dijk, T. (1975). &amp;quot;Formal semantics of metaphorical discourse.&amp;quot; Poetics, 4:173-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dubois</author>
<author>E Edeline</author>
<author>J-M Klinkenberg</author>
<author>P Minguet</author>
<author>E Fire</author>
<author>H Trinon</author>
</authors>
<title>Rhetorique Generale. Larousse. Published as: A General Rhetoric, translated by RB.</title>
<date>1970</date>
<journal>Burrell</journal>
<publisher>The John Hopkins University Press.</publisher>
<marker>Dubois, Edeline, Klinkenberg, Minguet, Fire, Trinon, 1970</marker>
<rawString>Dubois, J.; Edeline, E; Klinkenberg, J.-M.; Minguet, P.; Fire, E; and Trinon, H. (1970). Rhetorique Generale. Larousse. Published as: A General Rhetoric, translated by RB. Burrell and E.M. Slotkin, 1981, The John Hopkins University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Falkenhainer</author>
<author>Kenneth D Forbus</author>
<author>Dedre Gentner</author>
</authors>
<title>The structure-mapping engine: algorithm and examples.&amp;quot;</title>
<date>1986</date>
<journal>Artificial Intelligence,</journal>
<pages>41--1</pages>
<marker>Falkenhainer, Forbus, Gentner, 1986</marker>
<rawString>Falkenhainer, Brian; Forbus, Kenneth D.; and Gentner, Dedre (1986). &amp;quot;The structure-mapping engine: algorithm and examples.&amp;quot; Artificial Intelligence, 41:1-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Collative semantics: an approach to coherence.&amp;quot;</title>
<date>1986</date>
<tech>Technical Report MCCS-86-56,</tech>
<institution>Computing Research Laboratory,</institution>
<contexts>
<context position="56327" citStr="Fass 1986" startWordPosition="8755" endWordPosition="8756">ons. Recall that a metaphorical relation contains a relevant analogy, as in (15) and (20), while an anomalous relation does not, as in (21). A relevant analogy is found by matching the relevant cell from the source sense-frame with one of the cells from the target sense-frame. If the match of cells is composed of a set of sister network paths between corresponding word senses in those cells, then this is interpreted as analogical and hence indicative of a metaphorical relation. Any other match of cells is interpreted as not analogical and thus an anomalous semantic relation is recognized (see Fass 1986; 1987). The third component of CS is the semantic vector which is a form of representation, like the sense-frame; but sense-frames represent lexical knowledge, whereas semantic vectors represent coherence. Semantic vectors are therefore described as a kind of coherence representation. A semantic vector is a data structure that contains nested labels and ordered arrays structured by a simple dependency syntax. The labels form into sets. The outer sets of labels indicate the application of the three kinds of lexical semantic constraints. The outermost set of labels is &apos;preference&apos; and &apos;assertio</context>
</contexts>
<marker>Fass, 1986</marker>
<rawString>Fass, Dan C. (1986). &amp;quot;Collative semantics: an approach to coherence.&amp;quot; Technical Report MCCS-86-56, Computing Research Laboratory, June 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Semantic relations, metonymy, and lexical ambiguity resolution: a coherence-based account.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, 9th Annual Cognitive Science Society Conference,</booktitle>
<pages>575--586</pages>
<institution>University of Washington,</institution>
<location>Seattle, Washington:</location>
<marker>Fass, 1987</marker>
<rawString>Fass, Dan C. (1987). &amp;quot;Semantic relations, metonymy, and lexical ambiguity resolution: a coherence-based account.&amp;quot; In Proceedings, 9th Annual Cognitive Science Society Conference, University of Washington, Seattle, Washington: 575-586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Collative semantics: a semantics for natural language processing. Doctoral dissertation,</title>
<date>1988</date>
<institution>Mexico State University,</institution>
<location>New</location>
<contexts>
<context position="27096" citStr="Fass 1988" startWordPosition="4221" endWordPosition="4222">nymy and Metaphor Both metonymy and metaphor have been identified as central to the development of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron 1967). Some of the best examples of the differences between the two phenomena come from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that m</context>
<context position="46285" citStr="Fass (1988" startWordPosition="7177" endWordPosition="7178">ning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will be discussed in Section 7. 63 Computational Linguistics Volume 17, Number 1 4. Collative Semantics CS is a semantics for natural language processing that extends many of the main ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found in dictionary definitions (Amsler 1980). The arcs part of a sense-frame contains a labeled arc to its genus term (a word sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a densely structured semantic network of word senses called the se</context>
<context position="52455" citStr="Fass (1988" startWordPosition="8129" endWordPosition="8130">ionl, metal]] includes [composition1, steell] because the class of metals includes the class of steels (another ancestor relationship). Sister, descendant, and estranged are types of &amp;quot;exclusive&amp;quot; cell matches, e.g. [composition1, stee11] and [compositionl, aluminium1] are exclusive because the class of steels does not include the class of aluminiums since both belong to the class of metals (this is a sister relationship). The remaining cell matches, distinctive source and distinctive target, account for cells that fail the previous five kinds of cell match. For more detail on cell matches, see Fass (1988a). A kind of lexical relevance is found dynamically from the sentence context. This notion of relevance is used in finding the relevant analogies that distinguish metaphorical from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITY metonymies. Relevance divides the set of cells from the source sense-frame into two subsets. One cell is selected as relevant given the context; the remaining cells are termed nonrelevant. Collation matches both the source&apos;s relevant and nonrelevant cells against the cells from the target sense-frame. A relevant analogy is indicated by a sister</context>
<context position="58902" citStr="Fass 1988" startWordPosition="9153" endWordPosition="9154">e-based semantic relations is literal metaphorical —&gt; anomalous. If the semantic vectors are still tied then the measure of conceptual similarity is employed. This measure was initially developed to test a claim by Tourangeau and Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a function of the distance between the conceptual domains of the source and target involved: the claim is that the more distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those senten</context>
</contexts>
<marker>Fass, 1988</marker>
<rawString>Fass, Dan C. (1988a). Collative semantics: a semantics for natural language processing. Doctoral dissertation, New Mexico State University, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>An account of coherence, semantic relations, metonymy, and lexical ambiguity resolution.&amp;quot; In Lexical Ambiguity Resolution: Perspectives from</title>
<date>1988</date>
<journal>Psycholinguistics, Neuropsychology, and Artificial Intelligence, edited by</journal>
<pages>151--178</pages>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="27096" citStr="Fass 1988" startWordPosition="4221" endWordPosition="4222">nymy and Metaphor Both metonymy and metaphor have been identified as central to the development of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron 1967). Some of the best examples of the differences between the two phenomena come from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that m</context>
<context position="46285" citStr="Fass (1988" startWordPosition="7177" endWordPosition="7178">ning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will be discussed in Section 7. 63 Computational Linguistics Volume 17, Number 1 4. Collative Semantics CS is a semantics for natural language processing that extends many of the main ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found in dictionary definitions (Amsler 1980). The arcs part of a sense-frame contains a labeled arc to its genus term (a word sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a densely structured semantic network of word senses called the se</context>
<context position="52455" citStr="Fass (1988" startWordPosition="8129" endWordPosition="8130">ionl, metal]] includes [composition1, steell] because the class of metals includes the class of steels (another ancestor relationship). Sister, descendant, and estranged are types of &amp;quot;exclusive&amp;quot; cell matches, e.g. [composition1, stee11] and [compositionl, aluminium1] are exclusive because the class of steels does not include the class of aluminiums since both belong to the class of metals (this is a sister relationship). The remaining cell matches, distinctive source and distinctive target, account for cells that fail the previous five kinds of cell match. For more detail on cell matches, see Fass (1988a). A kind of lexical relevance is found dynamically from the sentence context. This notion of relevance is used in finding the relevant analogies that distinguish metaphorical from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITY metonymies. Relevance divides the set of cells from the source sense-frame into two subsets. One cell is selected as relevant given the context; the remaining cells are termed nonrelevant. Collation matches both the source&apos;s relevant and nonrelevant cells against the cells from the target sense-frame. A relevant analogy is indicated by a sister</context>
<context position="58902" citStr="Fass 1988" startWordPosition="9153" endWordPosition="9154">e-based semantic relations is literal metaphorical —&gt; anomalous. If the semantic vectors are still tied then the measure of conceptual similarity is employed. This measure was initially developed to test a claim by Tourangeau and Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a function of the distance between the conceptual domains of the source and target involved: the claim is that the more distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those senten</context>
</contexts>
<marker>Fass, 1988</marker>
<rawString>Fass, Dan C. (1988b). &amp;quot;An account of coherence, semantic relations, metonymy, and lexical ambiguity resolution.&amp;quot; In Lexical Ambiguity Resolution: Perspectives from Psycholinguistics, Neuropsychology, and Artificial Intelligence, edited by Steven L. Small, Garrison W. Cottrell, and Michael K. Tanenhaus, Morgan Kaufmann, 151-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Metonymy and metaphor: what&apos;s the difference?&amp;quot; In</title>
<date>1988</date>
<booktitle>Proceedings, 12th International Conference on Computational Linguistics (COLING-88),</booktitle>
<pages>177--181</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="27096" citStr="Fass 1988" startWordPosition="4221" endWordPosition="4222">nymy and Metaphor Both metonymy and metaphor have been identified as central to the development of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron 1967). Some of the best examples of the differences between the two phenomena come from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that m</context>
<context position="46285" citStr="Fass (1988" startWordPosition="7177" endWordPosition="7178">ning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will be discussed in Section 7. 63 Computational Linguistics Volume 17, Number 1 4. Collative Semantics CS is a semantics for natural language processing that extends many of the main ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found in dictionary definitions (Amsler 1980). The arcs part of a sense-frame contains a labeled arc to its genus term (a word sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a densely structured semantic network of word senses called the se</context>
<context position="52455" citStr="Fass (1988" startWordPosition="8129" endWordPosition="8130">ionl, metal]] includes [composition1, steell] because the class of metals includes the class of steels (another ancestor relationship). Sister, descendant, and estranged are types of &amp;quot;exclusive&amp;quot; cell matches, e.g. [composition1, stee11] and [compositionl, aluminium1] are exclusive because the class of steels does not include the class of aluminiums since both belong to the class of metals (this is a sister relationship). The remaining cell matches, distinctive source and distinctive target, account for cells that fail the previous five kinds of cell match. For more detail on cell matches, see Fass (1988a). A kind of lexical relevance is found dynamically from the sentence context. This notion of relevance is used in finding the relevant analogies that distinguish metaphorical from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITY metonymies. Relevance divides the set of cells from the source sense-frame into two subsets. One cell is selected as relevant given the context; the remaining cells are termed nonrelevant. Collation matches both the source&apos;s relevant and nonrelevant cells against the cells from the target sense-frame. A relevant analogy is indicated by a sister</context>
<context position="58902" citStr="Fass 1988" startWordPosition="9153" endWordPosition="9154">e-based semantic relations is literal metaphorical —&gt; anomalous. If the semantic vectors are still tied then the measure of conceptual similarity is employed. This measure was initially developed to test a claim by Tourangeau and Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a function of the distance between the conceptual domains of the source and target involved: the claim is that the more distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those senten</context>
</contexts>
<marker>Fass, 1988</marker>
<rawString>Fass, Dan C. (1988c). &amp;quot;Metonymy and metaphor: what&apos;s the difference?&amp;quot; In Proceedings, 12th International Conference on Computational Linguistics (COLING-88), Budapest, Hungary, 177-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Collative semantics: a study in the discrimination of meaning.&amp;quot;</title>
<date>1988</date>
<tech>Technical Report CSS/LCCR TR 88-24,</tech>
<institution>Centre for Systems Science, Simon Fraser University.</institution>
<contexts>
<context position="27096" citStr="Fass 1988" startWordPosition="4221" endWordPosition="4222">nymy and Metaphor Both metonymy and metaphor have been identified as central to the development of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron 1967). Some of the best examples of the differences between the two phenomena come from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that m</context>
<context position="46285" citStr="Fass (1988" startWordPosition="7177" endWordPosition="7178">ning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will be discussed in Section 7. 63 Computational Linguistics Volume 17, Number 1 4. Collative Semantics CS is a semantics for natural language processing that extends many of the main ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found in dictionary definitions (Amsler 1980). The arcs part of a sense-frame contains a labeled arc to its genus term (a word sense with its own sense-frame). Together, the arcs of all the sense-frames comprise a densely structured semantic network of word senses called the se</context>
<context position="52455" citStr="Fass (1988" startWordPosition="8129" endWordPosition="8130">ionl, metal]] includes [composition1, steell] because the class of metals includes the class of steels (another ancestor relationship). Sister, descendant, and estranged are types of &amp;quot;exclusive&amp;quot; cell matches, e.g. [composition1, stee11] and [compositionl, aluminium1] are exclusive because the class of steels does not include the class of aluminiums since both belong to the class of metals (this is a sister relationship). The remaining cell matches, distinctive source and distinctive target, account for cells that fail the previous five kinds of cell match. For more detail on cell matches, see Fass (1988a). A kind of lexical relevance is found dynamically from the sentence context. This notion of relevance is used in finding the relevant analogies that distinguish metaphorical from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITY metonymies. Relevance divides the set of cells from the source sense-frame into two subsets. One cell is selected as relevant given the context; the remaining cells are termed nonrelevant. Collation matches both the source&apos;s relevant and nonrelevant cells against the cells from the target sense-frame. A relevant analogy is indicated by a sister</context>
<context position="58902" citStr="Fass 1988" startWordPosition="9153" endWordPosition="9154">e-based semantic relations is literal metaphorical —&gt; anomalous. If the semantic vectors are still tied then the measure of conceptual similarity is employed. This measure was initially developed to test a claim by Tourangeau and Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a function of the distance between the conceptual domains of the source and target involved: the claim is that the more distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those senten</context>
</contexts>
<marker>Fass, 1988</marker>
<rawString>Fass, Dan C. (1988d). &amp;quot;Collative semantics: a study in the discrimination of meaning.&amp;quot; Technical Report CSS/LCCR TR 88-24, Centre for Systems Science, Simon Fraser University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Lexical semantic constraints.&amp;quot;</title>
<date>1989</date>
<booktitle>Computational Linguistics Volume 17, Number 1 Semantics and</booktitle>
<tech>Technical Report CSS/LCCR TR 89-11,</tech>
<publisher>Kluwer Academic Publishers.</publisher>
<institution>Centre for Systems Science, Simon Fraser University.</institution>
<note>To appear in</note>
<contexts>
<context position="33659" citStr="Fass 1989" startWordPosition="5200" endWordPosition="5201">ld suggest two modifications. First, not just metaphor but all of the preferencebased relations should be understood in terms of the presence or absence of contextual constraint violation. Second, I prefer the term contextual constraint violation because [1] one of the phenomena detected by contextual violation is anomaly and [2] the selection restriction/preference (on which the met* method is based) is a kind of lexical contextual constraint. The section starts with an explanation of some of the linguistic background behind the met* method. 3.1 Linguistic Background I have argued elsewhere (Fass 1989a) that understanding natural language (or semantic interpretation) be viewed as the integration of constraints from language and from context. Some language constraints are syntactic, while others are semantic. Some 59 Computational Linguistics Volume 17, Number 1 language constraints are lexical constraints; that is, constraints possessed by lexical items (words and fixed phrases). Lexical syntactic constraints include those on word order, number, and tense. This sec tion describes three lexical semantic constraints: preferences, assertions, and a lexical notion of relevance. Preferences (Wi</context>
</contexts>
<marker>Fass, 1989</marker>
<rawString>Fass, Dan C. (1989a). &amp;quot;Lexical semantic constraints.&amp;quot; Technical Report CSS/LCCR TR 89-11, Centre for Systems Science, Simon Fraser University. (To appear in Computational Linguistics Volume 17, Number 1 Semantics and the Lexicon, edited by James Pustejovsky. Kluwer Academic Publishers.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>Four general representations and processes for use in problem solving.&amp;quot;</title>
<date>1989</date>
<booktitle>In Knowledge Based Computer Systems (Proceedings of KBCS &apos;89,</booktitle>
<pages>169--178</pages>
<publisher>Narosa Publishing House,</publisher>
<location>Bombay, India), edited</location>
<contexts>
<context position="33659" citStr="Fass 1989" startWordPosition="5200" endWordPosition="5201">ld suggest two modifications. First, not just metaphor but all of the preferencebased relations should be understood in terms of the presence or absence of contextual constraint violation. Second, I prefer the term contextual constraint violation because [1] one of the phenomena detected by contextual violation is anomaly and [2] the selection restriction/preference (on which the met* method is based) is a kind of lexical contextual constraint. The section starts with an explanation of some of the linguistic background behind the met* method. 3.1 Linguistic Background I have argued elsewhere (Fass 1989a) that understanding natural language (or semantic interpretation) be viewed as the integration of constraints from language and from context. Some language constraints are syntactic, while others are semantic. Some 59 Computational Linguistics Volume 17, Number 1 language constraints are lexical constraints; that is, constraints possessed by lexical items (words and fixed phrases). Lexical syntactic constraints include those on word order, number, and tense. This sec tion describes three lexical semantic constraints: preferences, assertions, and a lexical notion of relevance. Preferences (Wi</context>
</contexts>
<marker>Fass, 1989</marker>
<rawString>Fass, Dan C. (1989b). &amp;quot;Four general representations and processes for use in problem solving.&amp;quot; In Knowledge Based Computer Systems (Proceedings of KBCS &apos;89, Bombay, India), edited by S. Ramani, R. Chandrasekar, and K.S.R. Anjeyulu, Narosa Publishing House, 169-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Genette</author>
</authors>
<title>La rhetorique restreinte.&amp;quot;</title>
<date>1970</date>
<journal>Communications,</journal>
<pages>16--158</pages>
<marker>Genette, 1970</marker>
<rawString>Genette, Gerard (1970). &amp;quot;La rhetorique restreinte.&amp;quot; Communications, 16:158-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dedre Gentner</author>
</authors>
<title>Structure mapping: a theoretical framework for analogy.&amp;quot;</title>
<date>1983</date>
<journal>Cognitive Science,</journal>
<pages>7--155</pages>
<contexts>
<context position="11485" citStr="Gentner (1983)" startWordPosition="1752" endWordPosition="1753">ersion of the interaction view is the domains-interaction view, set forth by Tourangeau and Sternberg (1982), who take the view that features &apos;shared&apos; by tenor and vehicle are often at best only analogous features, each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is impo</context>
<context position="37532" citStr="Gentner 1983" startWordPosition="5813" endWordPosition="5814">ntic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relations belong to two classes, the preference-based and assertion-based classes of relations, depending on the kind of lexical semantic constraint enforced. The preference-ba</context>
</contexts>
<marker>Gentner, 1983</marker>
<rawString>Gentner, Dedre (1983). &amp;quot;Structure mapping: a theoretical framework for analogy.&amp;quot; Cognitive Science, 7:155-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond W Jr Gibbs</author>
</authors>
<title>Literal meaning and psychological theory.&amp;quot;</title>
<date>1984</date>
<journal>Cognitive Science,</journal>
<pages>8--275</pages>
<contexts>
<context position="28856" citStr="Gibbs (1984)" startWordPosition="4488" endWordPosition="4489">in word sense extension. According to him, metonymy shifts the argument place of a predicate, whereas metaphor shifts the whole predicate. Hobbs (1983a; 1983b) writes about metaphor, and he and Martin (1987) develop a theory of &amp;quot;local pragmatics&amp;quot; that includes metonymy, but Hobbs does not seem to have written about the relationship between metaphor and metonymy. In knowledge representation, metonymic and metaphorical relations are both represented in the knowledge representation language CycL (Lenat and Guha 1990). 2.4 Literalness and Nonliteralness Much of the preceding material assumes what Gibbs (1984) calls the &amp;quot;literal meanings hypothesis,&amp;quot; which is that sentences have well defined literal meanings and that computation of the literal meaning is a necessary step on the path to understanding speakers&apos; utterances (ibid., p. 275). There are a number of points here, which Gibbs expands upon in his paper. One point concerns the traditional notion of literal meaning, that all sentences have literal meanings that are entirely determined by the meanings of their component words, and that the literal meaning of a sentence is its meaning independent of context. A second point concerns the traditiona</context>
<context position="45190" citStr="Gibbs (1984)" startWordPosition="7005" endWordPosition="7006">d in a certain order: literal, metonymic, metaphorical, and finally anomalous. This ordering implies that a literal interpretation is sought before a nonliteral one (cf. Harris 1976). The ordering results from thinking about discriminating the semantic relations in serial processing terms rather than parallel processing terms, particularly the serial order in which selection restrictions are evaluated and metonymic inference rules are tried: satisfied selection restrictions (indicating literalness) then metonymic inference (metonymy) then violated selection restrictions (metaphor or anomaly). Gibbs (1984) criticizes the idea that literal and nonliteral meaning can be discriminated in ordered processing stages. My response is that if the met* method is viewed in parallel processing terms then literal, metonymic, metaphorical, and anomalous interpretations are all sought at the same time and there is no ordering such that the literal meaning of a sentence is computed first and then an alternative meaning sought if the literal meaning is defective. Gibbs&apos; other main criticism, concerning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will b</context>
</contexts>
<marker>Gibbs, 1984</marker>
<rawString>Gibbs, Raymond W. Jr. (1984). &amp;quot;Literal meaning and psychological theory.&amp;quot; Cognitive Science, 8:275-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Douglas E Appelt</author>
<author>Paul Martin</author>
<author>Fernando C N Pereira</author>
</authors>
<title>TEAM: An experiment in the design of transportable natural-language interfaces.&amp;quot;</title>
<date>1987</date>
<journal>Artificial Intelligence,</journal>
<pages>32--2</pages>
<contexts>
<context position="3349" citStr="Grosz et al. 1987" startWordPosition="512" endWordPosition="515"> also anomaly and literalness, in short English sentences.&apos; The method is part of Collative Semantics (hereafter CS), which is a semantics for natural language processing. CS, and hence the met* method, has been implemented in a program called meta5 (so called because it does more than metaphor). The meta5 program is, as far as I know, the first system to recognize examples of metaphor and metonymy. To my knowledge, there is only one other working program that might be said to recognize instances of metaphor (Martin 1988; 1990) and two systems that appear to recognize cases of metonymy, TEAM (Grosz et al. 1987) and TACITUS (Hobbs and Martin 1987). The rest of the paper is organized as follows. Section 2 surveys general issues and approaches in metaphor and metonymy, notably the distinctive characteristics of metaphor and metonymy, the relationship between metaphor and metonymy, and the relationship between literalness and nonliteralness. Section 3 presents the met* method, concentrating on the basic topology of the met* method algorithm. Section 4 shows details of representations and processes used in CS. Section 5 gives examples of the meta5 program analyzing simple metaphors and metonymies. Descri</context>
<context position="23188" citStr="Grosz et al. 1987" startWordPosition="3602" endWordPosition="3605"> room. The walls were painted in psychedelic color&amp;quot; (ibid.). Example 12 A: &amp;quot;I bought an interesting book.&amp;quot; B: &amp;quot;Who is the author?&amp;quot; (ibid.). Example 13 &amp;quot;He happened to die of some disease, though I don&apos;t know what the cause was&amp;quot; (ibid.). Yamanashi (1987) points out that basic metonymic relationships like part-whole and cause-result often also link sentences. According to him, the links in (10) and (11) are PART-WHOLE relations, the one in (12) is PRODUCT-PRODUCER, and the one in (13) is a CAUSE-RESULT relation. There has been some computational work on metonymy (Weischedel and Sondheimer 1983; Grosz et al. 1987; Hobbs and Martin 1987; Stallard 1987; Wilensky 1987). The TEAM project (Grosz et al. 1987) handles metonymy, though metonymy is not mentioned by name but referred to instead as &amp;quot;coercion,&amp;quot; which &amp;quot;occurs whenever some property of an object is used to refer indirectly to the object&amp;quot; (ibid., p. 213). Coercion is handled by &amp;quot;coercion-relations;&amp;quot; for example, a coercion relation could be used to understand that &apos;Fords&apos; means &amp;quot;cars whose CAR-MANUFACTURER is Ford&amp;quot; (in Lakoff and Johnson&apos;s terms, this is an example of a PRODUCER FOR PRODUCT metonymic concept). 2 A BLT is a bacon, lettuce, and tomato</context>
</contexts>
<marker>Grosz, Appelt, Martin, Pereira, 1987</marker>
<rawString>Grosz, Barbara J.; Appelt, Douglas E.; Martin, Paul; and Pereira, Fernando C.N. (1987). &amp;quot;TEAM: An experiment in the design of transportable natural-language interfaces.&amp;quot; Artificial Intelligence, 32(2):173-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harris</author>
</authors>
<title>Comprehension of metaphor: a test of a two-stage processing model.&amp;quot;</title>
<date>1976</date>
<journal>Bulletin of the Psychonomic Society,</journal>
<pages>8--321</pages>
<contexts>
<context position="44760" citStr="Harris 1976" startWordPosition="6952" endWordPosition="6953">antic relation can be either a single relation or a multi-relation. A single relation consists of one literal, metaphorical, or anomalous relation. A multi-relation contains one literal, metaphorical, or anomalous relation plus either a single metonymy or a chain of metonymies. All these combinations, but only these, are derivable from Figure 1. Note that in the met* method as presented in Figure 1, semantic relations are tried in a certain order: literal, metonymic, metaphorical, and finally anomalous. This ordering implies that a literal interpretation is sought before a nonliteral one (cf. Harris 1976). The ordering results from thinking about discriminating the semantic relations in serial processing terms rather than parallel processing terms, particularly the serial order in which selection restrictions are evaluated and metonymic inference rules are tried: satisfied selection restrictions (indicating literalness) then metonymic inference (metonymy) then violated selection restrictions (metaphor or anomaly). Gibbs (1984) criticizes the idea that literal and nonliteral meaning can be discriminated in ordered processing stages. My response is that if the met* method is viewed in parallel p</context>
</contexts>
<marker>Harris, 1976</marker>
<rawString>Harris, R. (1976). &amp;quot;Comprehension of metaphor: a test of a two-stage processing model.&amp;quot; Bulletin of the Psychonomic Society, 8:321-324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hesse</author>
</authors>
<title>Models and Analogies in Science.</title>
<date>1966</date>
<publisher>Notre Dame University Press.</publisher>
<contexts>
<context position="8736" citStr="Hesse (1966)" startWordPosition="1328" endWordPosition="1329">he two terms of a metaphor: the comparison theory ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212), proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967), Richards (1936), and Wheelwright (1962). Interaction theorists argue that the vehicle of a metaphor is a template for seeing the tenor in a new way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may only strike us as</context>
</contexts>
<marker>Hesse, 1966</marker>
<rawString>Hesse, M. (1966). Models and Analogies in Science. Notre Dame University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Coherence and interpretation in English texts.&amp;quot;</title>
<date>1977</date>
<booktitle>In Proceedings, 5th International Joint Conference on Artificial Intelligence (IJCAI-77),</booktitle>
<pages>110--116</pages>
<location>Cambridge, Massachusetts,</location>
<contexts>
<context position="13782" citStr="Hobbs 1977" startWordPosition="2117" endWordPosition="2118"> of metaphor. Hobbs&apos; goal has been to develop a unified process of discourse interpretation based on the drawing of appropriate inferences from a large knowledge base, 52 Fass Discriminating Metonymy which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: me</context>
<context position="95489" citStr="Hobbs 1977" startWordPosition="14720" endWordPosition="14721">er 1989) and some examples analyzed by it but not, to my knowledge, examples of metaphor or anomaly. Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no treatment of metonymy, anomaly or literalness. It has also not been implemented: see Indurkhya (1987) for reasons why. Hobbs and Martin (1987) offer a relatively shallow treatment of metonymy without, for instance, acknowledgement that metonymies can be driven from either the source or the target. Hobbs&apos; &amp;quot;selective inferencing&amp;quot; approach to text interpretation has been applied to problems including lexical ambiguity (Hobbs 1977; 1982b; Hobbs and Martin 1987), metaphor (Hobbs 1977; 1983a; 1983b) and the &amp;quot;local pragmatics&amp;quot; phenomena of metonymy (Hobbs and Martin 1987), but not anomaly. To my knowledge, Hobbs has yet to produce a unified description of selective inferencing that shows in detail how lexical ambiguity is resolved or how the differences between metaphor, metonymy, and so on can be recognized. Hobbs&apos; earlier papers include a series of programs — SATE, DIANA, and DIANA-2 — but the papers are not clear about what the programs can do. It is not clear, for example, whether any of the programs actually analyze </context>
</contexts>
<marker>Hobbs, 1977</marker>
<rawString>Hobbs, Jerry R. (1977). &amp;quot;Coherence and interpretation in English texts.&amp;quot; In Proceedings, 5th International Joint Conference on Artificial Intelligence (IJCAI-77), Cambridge, Massachusetts, 110-116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Coherence and coreference.&amp;quot;</title>
<date>1979</date>
<journal>Cognitive Science,</journal>
<pages>3--67</pages>
<marker>Hobbs, 1979</marker>
<rawString>Hobbs, Jerry R. (1979). &amp;quot;Coherence and coreference.&amp;quot; Cognitive Science, 3:67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Selective inferencing.&amp;quot;</title>
<date>1980</date>
<booktitle>In Proceedings, 3rd National Conference of the Canadian Society for Computational Studies of Intelligence (CSCSI-3),</booktitle>
<pages>101--114</pages>
<location>Victoria, British Columbia, Canada,</location>
<contexts>
<context position="13441" citStr="Hobbs 1980" startWordPosition="2065" endWordPosition="2066">(cf. Stallard 1987, p. 181). S is thus the &amp;quot;implicative complex&amp;quot; of the source domain imposed on the target domain. Every metaphorical interpretation of a given set of sentences is associated with a T-MAP. There may be several possible T-MAPs for a set of sentences. I would argue that Hobbs (1983a; 1983b) has also taken an interaction view of metaphor. Hobbs&apos; goal has been to develop a unified process of discourse interpretation based on the drawing of appropriate inferences from a large knowledge base, 52 Fass Discriminating Metonymy which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this </context>
</contexts>
<marker>Hobbs, 1980</marker>
<rawString>Hobbs, Jerry R. (1980). &amp;quot;Selective inferencing.&amp;quot; In Proceedings, 3rd National Conference of the Canadian Society for Computational Studies of Intelligence (CSCSI-3), Victoria, British Columbia, Canada, 101-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Towards an understanding of coherence in discourse.&amp;quot;</title>
<date>1982</date>
<booktitle>In Strategies for Natural Language Processing,</booktitle>
<pages>223--243</pages>
<note>edited by</note>
<marker>Hobbs, 1982</marker>
<rawString>Hobbs, Jerry R. (1982a). &amp;quot;Towards an understanding of coherence in discourse.&amp;quot; In Strategies for Natural Language Processing, edited by Wendy G. Lehnert and Martin H. Ringle, Erlbaum Associates, 223-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Representing ambiguity.&amp;quot;</title>
<date>1982</date>
<booktitle>In Proceedings, 1st West Coast Conference on Formal Linguistics,</booktitle>
<pages>15--28</pages>
<location>Stanford, California,</location>
<marker>Hobbs, 1982</marker>
<rawString>Hobbs, Jerry R. (1982b). &amp;quot;Representing ambiguity.&amp;quot; In Proceedings, 1st West Coast Conference on Formal Linguistics, Stanford, California, 15-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Metaphor interpretation as selective inferencing: cognitive processes in understanding metaphor (Part 1).&amp;quot;</title>
<date>1983</date>
<booktitle>Empirical Studies of the Arts,</booktitle>
<pages>1--17</pages>
<contexts>
<context position="11696" citStr="Hobbs 1983" startWordPosition="1781" endWordPosition="1782">each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is imposed on the target domain, thereby shaping the features of the target domain, which in turn produces changes in the features of the source domain, hence the &amp;quot;interaction.&amp;quot; It is assumed that a structural analogy </context>
<context position="13127" citStr="Hobbs (1983" startWordPosition="2018" endWordPosition="2019">omain and S is a set of sentences from the source domain which are expected to transfer to the target domain. A metaphor is &amp;quot;coherent&amp;quot; if the transferred sentences S are logically consistent with the axioms of the target domain, and &amp;quot;strongly coherent&amp;quot; if they already lie in the deductive closure of those axioms (cf. Stallard 1987, p. 181). S is thus the &amp;quot;implicative complex&amp;quot; of the source domain imposed on the target domain. Every metaphorical interpretation of a given set of sentences is associated with a T-MAP. There may be several possible T-MAPs for a set of sentences. I would argue that Hobbs (1983a; 1983b) has also taken an interaction view of metaphor. Hobbs&apos; goal has been to develop a unified process of discourse interpretation based on the drawing of appropriate inferences from a large knowledge base, 52 Fass Discriminating Metonymy which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operation</context>
<context position="16198" citStr="Hobbs 1983" startWordPosition="2478" endWordPosition="2479"> best representation of (1) contains a preference violation, so projection is used. The algorithm compares the template representation for the sentence [my+car drink gasoline] against templates from the pseudo-text of &apos;car&apos; seeking &amp;quot;the closest match,&amp;quot; and selects fICengine (USE)#liquidl. (USE) is projected onto drink in the sentence representation which becomes [ny+car use gasoline] Example 3 &amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242). 53 Computational Linguistics Volume 17, Number 1 Example 4 &amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51). Example 5 &amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134). Example 6 &amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII). The main problem with the selection restrictions view is that perfectly well-formed sentences exist that have a metaphorical interpretation and yet contain no selection restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3), there is a literal interpretation when uttered about a stone and a metaphorical one when said about a decrepit professor emeritus. Sentences (4), (5) and (6) also have twin interpretations. The existence of such sentences suggests that a condition that occasionally hold</context>
<context position="28394" citStr="Hobbs (1983" startWordPosition="4421" endWordPosition="4422">rimary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses on certain aspects of what is being referred to. There is little computational work about the relationship between metonymy and metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in word sense extension. According to him, metonymy shifts the argument place of a predicate, whereas metaphor shifts the whole predicate. Hobbs (1983a; 1983b) writes about metaphor, and he and Martin (1987) develop a theory of &amp;quot;local pragmatics&amp;quot; that includes metonymy, but Hobbs does not seem to have written about the relationship between metaphor and metonymy. In knowledge representation, metonymic and metaphorical relations are both represented in the knowledge representation language CycL (Lenat and Guha 1990). 2.4 Literalness and Nonliteralness Much of the preceding material assumes what Gibbs (1984) calls the &amp;quot;literal meanings hypothesis,&amp;quot; which is that sentences have well defined literal meanings and that computation of the literal m</context>
<context position="37494" citStr="Hobbs 1983" startWordPosition="5807" endWordPosition="5808">result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relations belong to two classes, the preference-based and assertion-based classes of relations, depending on the kind of lexical semantic </context>
<context position="110887" citStr="Hobbs 1983" startWordPosition="17154" endWordPosition="17155">view of metaphor. It should be emphasized that the met* method has only been applied to a small set of English sentences. Metonymy interpretation has been investigated only for adjective-noun and subject-verb-object constructions; metaphor interpretation, only for the latter. The best avenue for progress with the met* method appears to be the extensions to metaphor interpretation described in Section 6. In the meantime I am looking for sentences that contain semantic relations consisting of a metonymy (or chain of metonymies) followed by a metaphor. Example 32 &amp;quot;America believes in democracy&amp;quot; (Hobbs 1983b, p. 134). On a related point, some sentences are interesting in this respect because they have either a metaphorical or metonymic interpretation. In (32), for example, &amp;quot;Are we viewing America metaphorically as something which can believe, or are we using it metonymically to refer to the typical inhabitant, or the majority of inhabitants, of America?&amp;quot; (Ibid., p. 135). Example 33 &amp;quot;Prussia invaded France in 1870.&amp;quot; Sentence (33), which was discussed in a group working on beliefs at the CRL (see Acknowledgments), also has separate metonymic and metaphorical interpretations. The key semantic relat</context>
</contexts>
<marker>Hobbs, 1983</marker>
<rawString>Hobbs, Jerry R. (1983a). &amp;quot;Metaphor interpretation as selective inferencing: cognitive processes in understanding metaphor (Part 1).&amp;quot; Empirical Studies of the Arts, 1:17-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Metaphor interpretation as selective inferencirtg: cognitive processes in understanding metaphor (Part 2).&amp;quot;</title>
<date>1983</date>
<booktitle>Empirical Studies of the Arts,</booktitle>
<pages>1--125</pages>
<contexts>
<context position="11696" citStr="Hobbs 1983" startWordPosition="1781" endWordPosition="1782">each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is imposed on the target domain, thereby shaping the features of the target domain, which in turn produces changes in the features of the source domain, hence the &amp;quot;interaction.&amp;quot; It is assumed that a structural analogy </context>
<context position="13127" citStr="Hobbs (1983" startWordPosition="2018" endWordPosition="2019">omain and S is a set of sentences from the source domain which are expected to transfer to the target domain. A metaphor is &amp;quot;coherent&amp;quot; if the transferred sentences S are logically consistent with the axioms of the target domain, and &amp;quot;strongly coherent&amp;quot; if they already lie in the deductive closure of those axioms (cf. Stallard 1987, p. 181). S is thus the &amp;quot;implicative complex&amp;quot; of the source domain imposed on the target domain. Every metaphorical interpretation of a given set of sentences is associated with a T-MAP. There may be several possible T-MAPs for a set of sentences. I would argue that Hobbs (1983a; 1983b) has also taken an interaction view of metaphor. Hobbs&apos; goal has been to develop a unified process of discourse interpretation based on the drawing of appropriate inferences from a large knowledge base, 52 Fass Discriminating Metonymy which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operation</context>
<context position="16198" citStr="Hobbs 1983" startWordPosition="2478" endWordPosition="2479"> best representation of (1) contains a preference violation, so projection is used. The algorithm compares the template representation for the sentence [my+car drink gasoline] against templates from the pseudo-text of &apos;car&apos; seeking &amp;quot;the closest match,&amp;quot; and selects fICengine (USE)#liquidl. (USE) is projected onto drink in the sentence representation which becomes [ny+car use gasoline] Example 3 &amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242). 53 Computational Linguistics Volume 17, Number 1 Example 4 &amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51). Example 5 &amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134). Example 6 &amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII). The main problem with the selection restrictions view is that perfectly well-formed sentences exist that have a metaphorical interpretation and yet contain no selection restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3), there is a literal interpretation when uttered about a stone and a metaphorical one when said about a decrepit professor emeritus. Sentences (4), (5) and (6) also have twin interpretations. The existence of such sentences suggests that a condition that occasionally hold</context>
<context position="28394" citStr="Hobbs (1983" startWordPosition="4421" endWordPosition="4422">rimary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses on certain aspects of what is being referred to. There is little computational work about the relationship between metonymy and metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in word sense extension. According to him, metonymy shifts the argument place of a predicate, whereas metaphor shifts the whole predicate. Hobbs (1983a; 1983b) writes about metaphor, and he and Martin (1987) develop a theory of &amp;quot;local pragmatics&amp;quot; that includes metonymy, but Hobbs does not seem to have written about the relationship between metaphor and metonymy. In knowledge representation, metonymic and metaphorical relations are both represented in the knowledge representation language CycL (Lenat and Guha 1990). 2.4 Literalness and Nonliteralness Much of the preceding material assumes what Gibbs (1984) calls the &amp;quot;literal meanings hypothesis,&amp;quot; which is that sentences have well defined literal meanings and that computation of the literal m</context>
<context position="37494" citStr="Hobbs 1983" startWordPosition="5807" endWordPosition="5808">result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relations belong to two classes, the preference-based and assertion-based classes of relations, depending on the kind of lexical semantic </context>
<context position="110887" citStr="Hobbs 1983" startWordPosition="17154" endWordPosition="17155">view of metaphor. It should be emphasized that the met* method has only been applied to a small set of English sentences. Metonymy interpretation has been investigated only for adjective-noun and subject-verb-object constructions; metaphor interpretation, only for the latter. The best avenue for progress with the met* method appears to be the extensions to metaphor interpretation described in Section 6. In the meantime I am looking for sentences that contain semantic relations consisting of a metonymy (or chain of metonymies) followed by a metaphor. Example 32 &amp;quot;America believes in democracy&amp;quot; (Hobbs 1983b, p. 134). On a related point, some sentences are interesting in this respect because they have either a metaphorical or metonymic interpretation. In (32), for example, &amp;quot;Are we viewing America metaphorically as something which can believe, or are we using it metonymically to refer to the typical inhabitant, or the majority of inhabitants, of America?&amp;quot; (Ibid., p. 135). Example 33 &amp;quot;Prussia invaded France in 1870.&amp;quot; Sentence (33), which was discussed in a group working on beliefs at the CRL (see Acknowledgments), also has separate metonymic and metaphorical interpretations. The key semantic relat</context>
</contexts>
<marker>Hobbs, 1983</marker>
<rawString>Hobbs, Jerry R. (1983b). &amp;quot;Metaphor interpretation as selective inferencirtg: cognitive processes in understanding metaphor (Part 2).&amp;quot; Empirical Studies of the Arts, 1:125-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>On the coherence and structure of discourse.&amp;quot;</title>
<date>1985</date>
<tech>Technical Report No. CSLI-85-37,</tech>
<institution>Center for the Study of Language and Information (CSLI), Stanford University.</institution>
<marker>Hobbs, 1985</marker>
<rawString>Hobbs, Jerry R. (1985). &amp;quot;On the coherence and structure of discourse.&amp;quot; Technical Report No. CSLI-85-37, Center for the Study of Language and Information (CSLI), Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Paul Martin</author>
</authors>
<title>Local Pragmatics.&amp;quot; In</title>
<date>1987</date>
<booktitle>Proceedings, 10th International Joint Conference on Artificial Intelligence (IJCAI-87),</booktitle>
<pages>520--523</pages>
<location>Milan, Italy,</location>
<contexts>
<context position="3385" citStr="Hobbs and Martin 1987" startWordPosition="518" endWordPosition="521">n short English sentences.&apos; The method is part of Collative Semantics (hereafter CS), which is a semantics for natural language processing. CS, and hence the met* method, has been implemented in a program called meta5 (so called because it does more than metaphor). The meta5 program is, as far as I know, the first system to recognize examples of metaphor and metonymy. To my knowledge, there is only one other working program that might be said to recognize instances of metaphor (Martin 1988; 1990) and two systems that appear to recognize cases of metonymy, TEAM (Grosz et al. 1987) and TACITUS (Hobbs and Martin 1987). The rest of the paper is organized as follows. Section 2 surveys general issues and approaches in metaphor and metonymy, notably the distinctive characteristics of metaphor and metonymy, the relationship between metaphor and metonymy, and the relationship between literalness and nonliteralness. Section 3 presents the met* method, concentrating on the basic topology of the met* method algorithm. Section 4 shows details of representations and processes used in CS. Section 5 gives examples of the meta5 program analyzing simple metaphors and metonymies. Descriptions get progressively more detail</context>
<context position="23211" citStr="Hobbs and Martin 1987" startWordPosition="3606" endWordPosition="3609">re painted in psychedelic color&amp;quot; (ibid.). Example 12 A: &amp;quot;I bought an interesting book.&amp;quot; B: &amp;quot;Who is the author?&amp;quot; (ibid.). Example 13 &amp;quot;He happened to die of some disease, though I don&apos;t know what the cause was&amp;quot; (ibid.). Yamanashi (1987) points out that basic metonymic relationships like part-whole and cause-result often also link sentences. According to him, the links in (10) and (11) are PART-WHOLE relations, the one in (12) is PRODUCT-PRODUCER, and the one in (13) is a CAUSE-RESULT relation. There has been some computational work on metonymy (Weischedel and Sondheimer 1983; Grosz et al. 1987; Hobbs and Martin 1987; Stallard 1987; Wilensky 1987). The TEAM project (Grosz et al. 1987) handles metonymy, though metonymy is not mentioned by name but referred to instead as &amp;quot;coercion,&amp;quot; which &amp;quot;occurs whenever some property of an object is used to refer indirectly to the object&amp;quot; (ibid., p. 213). Coercion is handled by &amp;quot;coercion-relations;&amp;quot; for example, a coercion relation could be used to understand that &apos;Fords&apos; means &amp;quot;cars whose CAR-MANUFACTURER is Ford&amp;quot; (in Lakoff and Johnson&apos;s terms, this is an example of a PRODUCER FOR PRODUCT metonymic concept). 2 A BLT is a bacon, lettuce, and tomato sandwich. 56 Fass Disc</context>
<context position="25248" citStr="Hobbs and Martin (1987)" startWordPosition="3925" endWordPosition="3928">ple of metonymy they show is &amp;quot;after the alarm,&amp;quot; which really means after the sounding of the alarm. Hobbs and Martin seem to assume a selection restrictions approach to metonymy because metonymy is sought after a selection restrictions violation (ibid., p. 521). In their approach, solving metonymy involves finding: [1] the referents for &apos;after&apos; and &apos;alarm&apos; in the domain model, which are after(e0, a) and alarm(a); [2] an implicit entity z to which &apos;after&apos; really refers, which is after(eo, z); and [3] the implicit relation between the implicit entity z and the referent of &apos;alarm,&apos; q(z, a). Like Hobbs and Martin (1987), Stallard (1987) translates language into logical form. Stallard argues that with nominal compounds and metonymies &amp;quot;the problem is determining the binary relation which has been &apos;elided&apos; from the utterance&amp;quot; (ibid., p. 180) and suggests shifting the argument place of a predicate &amp;quot;by interposing an arbitrary, sortally compatible relation between an argument place of the predicate and the actual argument&amp;quot; (ibid., p. 182). Stallard notes that &amp;quot;in any usage of the metonomy (sic) operation there is a choice about which of two clashing elements to extend&amp;quot; (ibid.). Stallard&apos;s work has not yet been im</context>
<context position="95201" citStr="Hobbs and Martin (1987)" startWordPosition="14677" endWordPosition="14680">ojection algorithm was implemented (Modiano 1986) using some parts of CS to supply detail missing from Wilks&apos; original specification. Gentner&apos;s (1983) Structure-Mapping Theory has no treatment of metonymy. The theory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989) and some examples analyzed by it but not, to my knowledge, examples of metaphor or anomaly. Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no treatment of metonymy, anomaly or literalness. It has also not been implemented: see Indurkhya (1987) for reasons why. Hobbs and Martin (1987) offer a relatively shallow treatment of metonymy without, for instance, acknowledgement that metonymies can be driven from either the source or the target. Hobbs&apos; &amp;quot;selective inferencing&amp;quot; approach to text interpretation has been applied to problems including lexical ambiguity (Hobbs 1977; 1982b; Hobbs and Martin 1987), metaphor (Hobbs 1977; 1983a; 1983b) and the &amp;quot;local pragmatics&amp;quot; phenomena of metonymy (Hobbs and Martin 1987), but not anomaly. To my knowledge, Hobbs has yet to produce a unified description of selective inferencing that shows in detail how lexical ambiguity is resolved or how t</context>
</contexts>
<marker>Hobbs, Martin, 1987</marker>
<rawString>Hobbs, Jerry R. and Martin, Paul (1987). &amp;quot;Local Pragmatics.&amp;quot; In Proceedings, 10th International Joint Conference on Artificial Intelligence (IJCAI-87), Milan, Italy, 520-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiuming Huang</author>
</authors>
<title>Machine translation in the SDCG (Semantic Definite Clause Grammars) formalism.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<pages>135--144</pages>
<institution>Colgate University,</institution>
<location>New York, New York,</location>
<contexts>
<context position="59354" citStr="Huang (1985)" startWordPosition="9227" endWordPosition="9228"> the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and semantic routines that embody collation and screening, the two processes of CS. The program is syntax-driven, a form of control carried over from the structure of earlier programs by Boguraev (1979) and Huang (1985), on which meta5 is based. Meta5 analyzes sentences, discriminates the seven kinds of semantic relation between pairs of word senses in those sentences (i.e., the program recognizes metonymies, metaphors, and so on), and resolves any lexical ambiguity in those sentences. Meta5 analyzes all the sentences given in Sections 3 and 4, plus a couple more metaphorical sentences discussed in Section 7. Below are simplified versions of some of the metonymic inference rules used in meta5. The metonymic concepts used in CS contain three key elements: the conceptual relationship involved, the direction of</context>
</contexts>
<marker>Huang, 1985</marker>
<rawString>Huang, Xiuming (1985). &amp;quot;Machine translation in the SDCG (Semantic Definite Clause Grammars) formalism.&amp;quot; In Proceedings, Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages, Colgate University, New York, New York, 135-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bipin Indurkhya</author>
</authors>
<title>A computational theory of metaphor comprehension and analogical reasoning.&amp;quot;</title>
<date>1985</date>
<tech>Technical Report #85/001,</tech>
<institution>Boston University.</institution>
<marker>Indurkhya, 1985</marker>
<rawString>Indurkhya, Bipin (1985). &amp;quot;A computational theory of metaphor comprehension and analogical reasoning.&amp;quot; Technical Report #85/001, Boston University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bipin Indurkhya</author>
</authors>
<title>Approximate semantic transference: a computational theory of metaphors and analogies.&amp;quot;</title>
<date>1987</date>
<journal>Cognitive Science,</journal>
<pages>11--4</pages>
<contexts>
<context position="95160" citStr="Indurkhya (1987)" startWordPosition="14672" endWordPosition="14673">ot been implemented, though the projection algorithm was implemented (Modiano 1986) using some parts of CS to supply detail missing from Wilks&apos; original specification. Gentner&apos;s (1983) Structure-Mapping Theory has no treatment of metonymy. The theory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989) and some examples analyzed by it but not, to my knowledge, examples of metaphor or anomaly. Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no treatment of metonymy, anomaly or literalness. It has also not been implemented: see Indurkhya (1987) for reasons why. Hobbs and Martin (1987) offer a relatively shallow treatment of metonymy without, for instance, acknowledgement that metonymies can be driven from either the source or the target. Hobbs&apos; &amp;quot;selective inferencing&amp;quot; approach to text interpretation has been applied to problems including lexical ambiguity (Hobbs 1977; 1982b; Hobbs and Martin 1987), metaphor (Hobbs 1977; 1983a; 1983b) and the &amp;quot;local pragmatics&amp;quot; phenomena of metonymy (Hobbs and Martin 1987), but not anomaly. To my knowledge, Hobbs has yet to produce a unified description of selective inferencing that shows in detail h</context>
</contexts>
<marker>Indurkhya, 1987</marker>
<rawString>Indurkhya, Bipin (1987). &amp;quot;Approximate semantic transference: a computational theory of metaphors and analogies.&amp;quot; Cognitive Science, 11(4):445-480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bipin Indurkhya</author>
</authors>
<title>Constrained semantic transference: a formal theory of metaphors.&amp;quot;</title>
<date>1988</date>
<booktitle>In Analogica: Proceedings of the First Workshop on Analogical Reasoning, edited by Armand Prieditis,</booktitle>
<pages>129--157</pages>
<publisher>Morgan Kaufmann (Pitman</publisher>
<location>Los Altos, California,</location>
<marker>Indurkhya, 1988</marker>
<rawString>Indurkhya, Bipin (1988). &amp;quot;Constrained semantic transference: a formal theory of metaphors.&amp;quot; In Analogica: Proceedings of the First Workshop on Analogical Reasoning, edited by Armand Prieditis, Morgan Kaufmann (Pitman Research Notes in Artificial Intelligence), Los Altos, California, 129-157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul S Jacobs</author>
</authors>
<title>A knowledge-based approach to language production.&amp;quot;</title>
<date>1985</date>
<tech>Technical Report No. UCB/CSD 86/254,</tech>
<institution>Computer Science Division (EECS), University of California, Berkeley.</institution>
<marker>Jacobs, 1985</marker>
<rawString>Jacobs, Paul S. (1985). &amp;quot;A knowledge-based approach to language production.&amp;quot; Technical Report No. UCB/CSD 86/254, Computer Science Division (EECS), University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Jakobsen</author>
<author>Morris Halle</author>
</authors>
<date>1956</date>
<journal>Fundamentals of Language. Mouton.</journal>
<contexts>
<context position="27367" citStr="Jakobsen and Halle 1956" startWordPosition="4259" endWordPosition="4262">me from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their</context>
<context position="100011" citStr="Jakobsen and Halle 1956" startWordPosition="15427" endWordPosition="15430">given by the sense of the main sentence verb. Nevertheless, because of this notion of relevance, contextual influence is present in semantic interpretation in CS. Moreover, the notion of relevance is recorded in semantic vectors (Figures 11 and 15) and the extended coherence representations discussed in Section 6. Hence, the processes and representations of CS possess basic equipment for handling further kinds of context. 7.2 Relationship between Metonymy and Metaphor The met* method is consistent with the view that metaphor is based on similarity, whereas metonymy is based on contiguity (cf. Jakobsen and Halle 1956). Contiguity, readers may recall, refers to being connected or touching whereas similarity refers to being alike in essentials or having characteristics in common. The difference comes from what and how the conceptual information is related. Example 1 &amp;quot;My car drinks gasoline.&amp;quot; Let us consider what is related first. In metaphor, an aspect of one concept is similar to an aspect of another concept; e.g., in (1), an aspect of the concept for animal, that animals drink potable liquids, is similar to an aspect of another concept, that cars use gasoline. Example 2 &amp;quot;The ham sandwich is waiting for his</context>
</contexts>
<marker>Jakobsen, Halle, 1956</marker>
<rawString>Jakobsen, Roman and Halle, Morris (1956). Fundamentals of Language. Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>A philosophical perspective on the problems of metaphor.&amp;quot; In Cognition and Figurative Language, edited by</title>
<date>1980</date>
<contexts>
<context position="1482" citStr="Johnson 1980" startWordPosition="218" endWordPosition="219">Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5&apos;s analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology. 1. Introduction Metaphor and metonymy are kinds of figurative language or tropes. Other tropes include simile, irony, understatement (litotes), and overstatement (hyperbole). Example 1 &amp;quot;My car drinks gasoline&amp;quot; (Wilks 1978, p. 199). Example 2 &amp;quot;The ham sandwich is waiting for his check&amp;quot; (Lakoff and Johnson 1980, p. 35). Sentences (1) and (2) contain examples of metaphor and metonymy respectively. Neither sentence is literally true: cars do not literally drink nor do ham sandwiches literally wait. Notice, though, that the two sentences are interpreted differently. &amp;quot;My car&amp;quot; in (1) is commonly understood as resembling an animate drinker while in (2) &amp;quot;the ham sandwich&amp;quot; is generally interpreted as referring to the person who ordered the ham sandwich. Most of the considerable literature on metaphor and the smaller one on metonymy (see Van Noppen, De Knop and Jongen 1985; Shibles 1971) is from philosophy, </context>
<context position="7990" citStr="Johnson (1980)" startWordPosition="1208" endWordPosition="1209">.e., the predicates). Tourangeau and Sternberg (1982) list some problems with the comparison view, including the following: (a) that everything has some feature or category that it shares with everything else, but we cannot combine just any two things in metaphor; (b) that the most obvious shared features are often irrelevant to a reading of the metaphor; (c) that even when the feature is relevant, it is often shared only metaphorically; ... and (e) that metaphors are novel and surprising is hard to reconcile with the idea that they rely completely on extant similarities (ibid., pp. 226-227). Johnson (1980) also notes problem (a) with comparison theories, pointing out that as a result they cannot account for the semantic tension between the two terms of a metaphor: the comparison theory ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty </context>
<context position="13938" citStr="Johnson 1980" startWordPosition="2138" endWordPosition="2139">wledge base, 52 Fass Discriminating Metonymy which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic t</context>
<context position="16143" citStr="Johnson 1980" startWordPosition="2468" endWordPosition="2469">.&amp;quot; Projection operates only on preference violations. The best representation of (1) contains a preference violation, so projection is used. The algorithm compares the template representation for the sentence [my+car drink gasoline] against templates from the pseudo-text of &apos;car&apos; seeking &amp;quot;the closest match,&amp;quot; and selects fICengine (USE)#liquidl. (USE) is projected onto drink in the sentence representation which becomes [ny+car use gasoline] Example 3 &amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242). 53 Computational Linguistics Volume 17, Number 1 Example 4 &amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51). Example 5 &amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134). Example 6 &amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII). The main problem with the selection restrictions view is that perfectly well-formed sentences exist that have a metaphorical interpretation and yet contain no selection restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3), there is a literal interpretation when uttered about a stone and a metaphorical one when said about a decrepit professor emeritus. Sentences (4), (5) and (6) also have twin interpretations. The existence of such sen</context>
<context position="18224" citStr="Johnson (1980)" startWordPosition="2801" endWordPosition="2802">teral interpretation of the expression, be it a word, phrase, sentence, or an even larger unit of text, fails to fit the context (p. 73, his italics), so whether or not a sentence is a metaphor depends upon the context in which it is used: if something is a metaphor then it will be contextually anomalous if interpreted literally.... Insofar as the violation of selection restrictions can be interpreted in terms of semantic incompatibilities at the lexical level, such violations may sometimes be the basis of the contextual anomaly (ibid., p. 74). 2.1.4 The Conventional Metaphor View. Lakoff and Johnson (1980) have popularized the idea of conventional metaphors, also known as conceptual metaphors. They distinguish three main kinds: orientational, ontological, and structural. Orientational metaphors are mainly to do with kinds of spatial orientation like up-down, in-out, and deep-shallow. Example metaphors include MORE IS UP and HAPPY IS UP. They arise from human experience of spatial orientation and thus develop from the sort of bodies we have and the way they function in our physical environment. Ontological metaphors arise from our basic human experiences with substances and physical objects (esp</context>
<context position="20471" citStr="Johnson 1980" startWordPosition="3143" endWordPosition="3144">onal metaphor view using KODIAK (Wilensky 1984), a variant of Brachman&apos;s KLONE knowledge representation language. Within KODIAK, metaphorical relationships are represented using a primitive link type called a &amp;quot;VIEW.&amp;quot; A VIEW &amp;quot;is used to assert that... one concept may in certain circumstances be considered as another &amp;quot;(Martin 1990, p. 59). In Martin&apos;s work, &amp;quot;metaphor-maps,&amp;quot; a kind of VIEW (ibid., p. 64), are used to represent conventional metaphors and the conceptual information they contain. 2.2 Metonymy Metonymy involves &amp;quot;using one entity to refer to another that is related to it&amp;quot; (Lakoff and Johnson 1980, p. 35). Example 2 &amp;quot;The ham sandwich is waiting for his check.&amp;quot; For example, in (2) the metonymy is that the concept for ham sandwich is related to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot; Several attempts have been made to organize instances of metonymy into categories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or &amp;quot;metonymic concepts,&amp;quot; as Lakoff and Johnson call them. A common metonymic concept is PART FOR WHOLE, otherwise known as synechdoche. Example 7 &amp;quot;Dave drank the glasses&amp;quot; (= the liquid in the glasses). Example 8 &amp;quot;The kettle is boili</context>
<context position="21799" citStr="Johnson 1980" startWordPosition="3362" endWordPosition="3363">nymic concept, occurs in (7) between &apos;drink&apos; and the sense of &apos;glasses&apos; meaning &amp;quot;containers,&amp;quot; and also in (8). In (7), &apos;drink&apos; has an object preference for a potable liquid, but there is a preference violation because glasses are not potable liquids. It is not glasses that are drunk, but the potable liquids in them. There is a relationship here between a CONTAINER (a glass) and its typical CONTENTS (a liquid): this relationship is the metonymic concept CONTAINER FOR 55 Computational Linguistics Volume 17, Number 1 CONTENTS. Below are examples of two further metonymic concepts (from Lakoff and Johnson 1980, p. 38, italics in original). PRODUCER FOR PRODUCT &amp;quot;I&apos;ll have a Leiwenbrdu. &amp;quot; &amp;quot;He bought a Ford.&amp;quot; &amp;quot;He&apos;s got a Picasso in his den.&amp;quot; &amp;quot;I hate to read Heidegger.&amp;quot; OBJECT USED FOR USER &amp;quot;The sax has the flu today.&amp;quot; &amp;quot;The BLT is a lousy tipper.&amp;quot;**2 &amp;quot;The buses are on strike.&amp;quot; Example 9 &amp;quot;You&apos;ll find better ideas than that in the library&amp;quot; (Reddy 1979, p. 309). Reddy (1979) has observed that metonymies can occur in chains. He suggests that (9) contains a chain of PART FOR WHOLE metonymies between &apos;ideas&apos; and &apos;library&apos;: the ideas are expressed in words, words are printed on pages, pages are in books, and </context>
<context position="27673" citStr="Johnson (1980)" startWordPosition="4308" endWordPosition="4309">ey are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses on certain aspects of what is being referred to. There is little computational work about the relationship between metonymy and metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in word sense extension. Acco</context>
<context position="39536" citStr="Johnson (1980)" startWordPosition="6112" endWordPosition="6113"> CONTENTS). Example 17 &amp;quot;Denise drank the bottle&amp;quot; (= potable liquid from the bottle —4 CONTAINER FOR CONTENTS). Figure 1 The met* method 1 satisfied preference (contextual constraint) 61 Computational Linguistics Volume 17, Number 1 Example 18 &amp;quot;Anne reads Steinbeck&amp;quot; (= writings of Steinbeck ARTIST FOR ART FORM). Example 19 &amp;quot;Ted played Bach&amp;quot; (= music of Bach ARTIST FOR ART FORM). Metonymy is viewed as a kind of domain-dependent inference. The process of finding metonymies is called metonymic inferencing. The metonymic concepts presently used are adapted from the metonymic concepts of Lakoff and Johnson (1980). Two of the metonymic concepts used are CONTAINER FOR CONTENTS and ARTIST FOR ART FORM. In (19), for example, Ted does not literally play the composer Bach — he plays music composed by him. As Figure 1 shows, a metonymy is recognized in the met* method if a metonymic inference (diamond 2) is found. Conversely, if no successful inference is found then no metonymy is discovered and a metaphorical or anomalous semantic relation is then sought. A successful inference establishes a relationship between the original source or the target (&amp;quot;one entity&amp;quot;) and a term (&amp;quot;another that is related to it&amp;quot;) th</context>
<context position="97449" citStr="Johnson (1980" startWordPosition="15025" endWordPosition="15026">would be interesting to explore this further. Moreover, the metaphors studied so far in CS seem linked to certain conventional metaphors because certain types of ground have recurred, types which resemble Lakoff and Johnson&apos;s (1980) structural metaphors. Two types of ground have cropped up so far. Example 28 &amp;quot;Time flies.&amp;quot; The first is a use-up-a-resource metaphor which occurs in (20) and in (28) when viewed as noun-verb sentence. Both sentences are analyzed by meta5. Use-up-a-resource resembles structural metaphors like TIME IS A RESOURCE and LABOR IS A RESOURCE which, according to Lakoff and Johnson (1980, p. 66), both employ the simple ontological metaphors of TIME IS A SUBSTANCE and AN ACTIVITY IS A SUBSTANCE: These two substance metaphors permit labor and time to be quantified — that is, measured, conceived of as being progressively &amp;quot;used up,&amp;quot; and assigned monetary values; they allow us to view time and labor as things that can be &amp;quot;used&amp;quot; for various ends. Example 29 &amp;quot;The horse flew.&amp;quot; The second type of ground is motion-through-a-medium, a type of ground discussed by Russell (1976). This appears in (15) and (29), again both analyzed by meta5. Incidentally, it is worth noting that structural </context>
</contexts>
<marker>Johnson, 1980</marker>
<rawString>Johnson, Mark (1980). &amp;quot;A philosophical perspective on the problems of metaphor.&amp;quot; In Cognition and Figurative Language, edited by Richard P. Honeck and Robert R. Hoffman, 47-68, Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
</authors>
<title>Analyticity and contradiction in natural language.&amp;quot;</title>
<date>1964</date>
<booktitle>In The Structure of Language: Readings in the Philosophy of Language, edited</booktitle>
<pages>519--543</pages>
<marker>Katz, 1964</marker>
<rawString>Katz, Jerrold J. (1964). &amp;quot;Analyticity and contradiction in natural language.&amp;quot; In The Structure of Language: Readings in the Philosophy of Language, edited by J.A. Fodor and J.J. Katz, 519-543, Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="1482" citStr="Lakoff and Johnson 1980" startWordPosition="216" endWordPosition="219"> Collative Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5&apos;s analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology. 1. Introduction Metaphor and metonymy are kinds of figurative language or tropes. Other tropes include simile, irony, understatement (litotes), and overstatement (hyperbole). Example 1 &amp;quot;My car drinks gasoline&amp;quot; (Wilks 1978, p. 199). Example 2 &amp;quot;The ham sandwich is waiting for his check&amp;quot; (Lakoff and Johnson 1980, p. 35). Sentences (1) and (2) contain examples of metaphor and metonymy respectively. Neither sentence is literally true: cars do not literally drink nor do ham sandwiches literally wait. Notice, though, that the two sentences are interpreted differently. &amp;quot;My car&amp;quot; in (1) is commonly understood as resembling an animate drinker while in (2) &amp;quot;the ham sandwich&amp;quot; is generally interpreted as referring to the person who ordered the ham sandwich. Most of the considerable literature on metaphor and the smaller one on metonymy (see Van Noppen, De Knop and Jongen 1985; Shibles 1971) is from philosophy, </context>
<context position="18224" citStr="Lakoff and Johnson (1980)" startWordPosition="2799" endWordPosition="2802">s that a literal interpretation of the expression, be it a word, phrase, sentence, or an even larger unit of text, fails to fit the context (p. 73, his italics), so whether or not a sentence is a metaphor depends upon the context in which it is used: if something is a metaphor then it will be contextually anomalous if interpreted literally.... Insofar as the violation of selection restrictions can be interpreted in terms of semantic incompatibilities at the lexical level, such violations may sometimes be the basis of the contextual anomaly (ibid., p. 74). 2.1.4 The Conventional Metaphor View. Lakoff and Johnson (1980) have popularized the idea of conventional metaphors, also known as conceptual metaphors. They distinguish three main kinds: orientational, ontological, and structural. Orientational metaphors are mainly to do with kinds of spatial orientation like up-down, in-out, and deep-shallow. Example metaphors include MORE IS UP and HAPPY IS UP. They arise from human experience of spatial orientation and thus develop from the sort of bodies we have and the way they function in our physical environment. Ontological metaphors arise from our basic human experiences with substances and physical objects (esp</context>
<context position="20471" citStr="Lakoff and Johnson 1980" startWordPosition="3141" endWordPosition="3144"> a conventional metaphor view using KODIAK (Wilensky 1984), a variant of Brachman&apos;s KLONE knowledge representation language. Within KODIAK, metaphorical relationships are represented using a primitive link type called a &amp;quot;VIEW.&amp;quot; A VIEW &amp;quot;is used to assert that... one concept may in certain circumstances be considered as another &amp;quot;(Martin 1990, p. 59). In Martin&apos;s work, &amp;quot;metaphor-maps,&amp;quot; a kind of VIEW (ibid., p. 64), are used to represent conventional metaphors and the conceptual information they contain. 2.2 Metonymy Metonymy involves &amp;quot;using one entity to refer to another that is related to it&amp;quot; (Lakoff and Johnson 1980, p. 35). Example 2 &amp;quot;The ham sandwich is waiting for his check.&amp;quot; For example, in (2) the metonymy is that the concept for ham sandwich is related to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot; Several attempts have been made to organize instances of metonymy into categories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or &amp;quot;metonymic concepts,&amp;quot; as Lakoff and Johnson call them. A common metonymic concept is PART FOR WHOLE, otherwise known as synechdoche. Example 7 &amp;quot;Dave drank the glasses&amp;quot; (= the liquid in the glasses). Example 8 &amp;quot;The kettle is boili</context>
<context position="21799" citStr="Lakoff and Johnson 1980" startWordPosition="3360" endWordPosition="3363">nother metonymic concept, occurs in (7) between &apos;drink&apos; and the sense of &apos;glasses&apos; meaning &amp;quot;containers,&amp;quot; and also in (8). In (7), &apos;drink&apos; has an object preference for a potable liquid, but there is a preference violation because glasses are not potable liquids. It is not glasses that are drunk, but the potable liquids in them. There is a relationship here between a CONTAINER (a glass) and its typical CONTENTS (a liquid): this relationship is the metonymic concept CONTAINER FOR 55 Computational Linguistics Volume 17, Number 1 CONTENTS. Below are examples of two further metonymic concepts (from Lakoff and Johnson 1980, p. 38, italics in original). PRODUCER FOR PRODUCT &amp;quot;I&apos;ll have a Leiwenbrdu. &amp;quot; &amp;quot;He bought a Ford.&amp;quot; &amp;quot;He&apos;s got a Picasso in his den.&amp;quot; &amp;quot;I hate to read Heidegger.&amp;quot; OBJECT USED FOR USER &amp;quot;The sax has the flu today.&amp;quot; &amp;quot;The BLT is a lousy tipper.&amp;quot;**2 &amp;quot;The buses are on strike.&amp;quot; Example 9 &amp;quot;You&apos;ll find better ideas than that in the library&amp;quot; (Reddy 1979, p. 309). Reddy (1979) has observed that metonymies can occur in chains. He suggests that (9) contains a chain of PART FOR WHOLE metonymies between &apos;ideas&apos; and &apos;library&apos;: the ideas are expressed in words, words are printed on pages, pages are in books, and </context>
<context position="27673" citStr="Lakoff and Johnson (1980)" startWordPosition="4306" endWordPosition="4309">est that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses on certain aspects of what is being referred to. There is little computational work about the relationship between metonymy and metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in word sense extension. Acco</context>
<context position="39536" citStr="Lakoff and Johnson (1980)" startWordPosition="6110" endWordPosition="6113">NTAINER FOR CONTENTS). Example 17 &amp;quot;Denise drank the bottle&amp;quot; (= potable liquid from the bottle —4 CONTAINER FOR CONTENTS). Figure 1 The met* method 1 satisfied preference (contextual constraint) 61 Computational Linguistics Volume 17, Number 1 Example 18 &amp;quot;Anne reads Steinbeck&amp;quot; (= writings of Steinbeck ARTIST FOR ART FORM). Example 19 &amp;quot;Ted played Bach&amp;quot; (= music of Bach ARTIST FOR ART FORM). Metonymy is viewed as a kind of domain-dependent inference. The process of finding metonymies is called metonymic inferencing. The metonymic concepts presently used are adapted from the metonymic concepts of Lakoff and Johnson (1980). Two of the metonymic concepts used are CONTAINER FOR CONTENTS and ARTIST FOR ART FORM. In (19), for example, Ted does not literally play the composer Bach — he plays music composed by him. As Figure 1 shows, a metonymy is recognized in the met* method if a metonymic inference (diamond 2) is found. Conversely, if no successful inference is found then no metonymy is discovered and a metaphorical or anomalous semantic relation is then sought. A successful inference establishes a relationship between the original source or the target (&amp;quot;one entity&amp;quot;) and a term (&amp;quot;another that is related to it&amp;quot;) th</context>
<context position="97449" citStr="Lakoff and Johnson (1980" startWordPosition="15023" endWordPosition="15026">oaches; it would be interesting to explore this further. Moreover, the metaphors studied so far in CS seem linked to certain conventional metaphors because certain types of ground have recurred, types which resemble Lakoff and Johnson&apos;s (1980) structural metaphors. Two types of ground have cropped up so far. Example 28 &amp;quot;Time flies.&amp;quot; The first is a use-up-a-resource metaphor which occurs in (20) and in (28) when viewed as noun-verb sentence. Both sentences are analyzed by meta5. Use-up-a-resource resembles structural metaphors like TIME IS A RESOURCE and LABOR IS A RESOURCE which, according to Lakoff and Johnson (1980, p. 66), both employ the simple ontological metaphors of TIME IS A SUBSTANCE and AN ACTIVITY IS A SUBSTANCE: These two substance metaphors permit labor and time to be quantified — that is, measured, conceived of as being progressively &amp;quot;used up,&amp;quot; and assigned monetary values; they allow us to view time and labor as things that can be &amp;quot;used&amp;quot; for various ends. Example 29 &amp;quot;The horse flew.&amp;quot; The second type of ground is motion-through-a-medium, a type of ground discussed by Russell (1976). This appears in (15) and (29), again both analyzed by meta5. Incidentally, it is worth noting that structural </context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>Lakoff, George and Johnson, Mark (1980). Metaphors We Live By. Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R B Lees</author>
</authors>
<title>The grammar of English nominalizations.&amp;quot;</title>
<date>1960</date>
<journal>International Journal of American Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="34948" citStr="Lees (1960)" startWordPosition="5400" endWordPosition="5401">are the same (see Fass 1989c; Fass and Wilks 1983; Wilks and Fass in press): all are restrictions possessed by senses of lexical items of certain parts of speech about the semantic classes of lexical items with which they co-occur. Thus an adjective sense has a preference for the semantic class of nouns with which it co-occurs and a verb sense has preferences for the semantic classes of nouns that fill its case roles. For example, the main sense of the verb &apos;drink&apos; prefers an animal to fill its agent case role, i.e., it is animals that drink. The assertion of semantic information was noted by Lees (1960) in the formation of noun phrases and later developed by Katz (1964) as the process of &amp;quot;attribution.&amp;quot; Assertions contain information that is possessed by senses of lexical items of certain parts of speech and that is imposed onto senses of lexical items of other parts of speech, e.g., the adjective &apos;female&apos; contains information that any noun to which it applies is of the female sex. Lexical syntactic and semantic constraints are enforced at certain places in sentences which I call dependencies. Within a dependency, the lexical item whose constraints are enforced is called the source and the ot</context>
</contexts>
<marker>Lees, 1960</marker>
<rawString>Lees, R.B. (1960). &amp;quot;The grammar of English nominalizations.&amp;quot; International Journal of American Linguistics, 26(3).</rawString>
</citation>
<citation valid="false">
<institution>Fass Discriminating Metonymy</institution>
<marker></marker>
<rawString>Fass Discriminating Metonymy</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas B Lenat</author>
<author>R V Guha</author>
</authors>
<title>Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project.</title>
<date>1990</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="28763" citStr="Lenat and Guha 1990" startWordPosition="4473" endWordPosition="4476">etween metonymy and metaphor. Stallard (1987) distinguishes separate roles for metonymy and metaphor in word sense extension. According to him, metonymy shifts the argument place of a predicate, whereas metaphor shifts the whole predicate. Hobbs (1983a; 1983b) writes about metaphor, and he and Martin (1987) develop a theory of &amp;quot;local pragmatics&amp;quot; that includes metonymy, but Hobbs does not seem to have written about the relationship between metaphor and metonymy. In knowledge representation, metonymic and metaphorical relations are both represented in the knowledge representation language CycL (Lenat and Guha 1990). 2.4 Literalness and Nonliteralness Much of the preceding material assumes what Gibbs (1984) calls the &amp;quot;literal meanings hypothesis,&amp;quot; which is that sentences have well defined literal meanings and that computation of the literal meaning is a necessary step on the path to understanding speakers&apos; utterances (ibid., p. 275). There are a number of points here, which Gibbs expands upon in his paper. One point concerns the traditional notion of literal meaning, that all sentences have literal meanings that are entirely determined by the meanings of their component words, and that the literal meanin</context>
</contexts>
<marker>Lenat, Guha, 1990</marker>
<rawString>Lenat, Douglas B. and Guha, R. V. (1990). Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel R Levin</author>
</authors>
<title>The Semantics of Metaphor.</title>
<date>1977</date>
<publisher>John Hopkins University Press.</publisher>
<contexts>
<context position="14326" citStr="Levin (1977)" startWordPosition="2198" endWordPosition="2199">tic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An algorithm matches pairs of semantic formulas, seeking satisfied or violated preferenc</context>
</contexts>
<marker>Levin, 1977</marker>
<rawString>Levin, Samuel R. (1977). The Semantics of Metaphor. John Hopkins University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ina Loewenberg</author>
</authors>
<title>Identifying metaphors.&amp;quot;</title>
<date>1975</date>
<journal>Foundations of Language,</journal>
<pages>12--315</pages>
<marker>Loewenberg, 1975</marker>
<rawString>Loewenberg, Ina (1975). &amp;quot;Identifying metaphors.&amp;quot; Foundations of Language, 12:315-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malgady</author>
<author>M Johnson</author>
</authors>
<title>Modifiers in metaphors: effects of constituent phrase similarity on the interpretation of figurative sentences.&amp;quot;</title>
<date>1976</date>
<journal>Journal of Psycholinguistic Research,</journal>
<pages>5--43</pages>
<marker>Malgady, Johnson, 1976</marker>
<rawString>Malgady, R. and Johnson, M. (1976). &amp;quot;Modifiers in metaphors: effects of constituent phrase similarity on the interpretation of figurative sentences.&amp;quot; Journal of Psycholinguistic Research, 5:43-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>A Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="20189" citStr="Martin 1990" startWordPosition="3098" endWordPosition="3099">he language we use to talk about the concept is systematic (ibid., p. 5). What Lakoff and Johnson fail to discuss is how metaphors in general, let alone individual metaphorical concepts, are recognized. Martin&apos;s (1988; 1990) work has addressed this issue. He has pursued a conventional metaphor view using KODIAK (Wilensky 1984), a variant of Brachman&apos;s KLONE knowledge representation language. Within KODIAK, metaphorical relationships are represented using a primitive link type called a &amp;quot;VIEW.&amp;quot; A VIEW &amp;quot;is used to assert that... one concept may in certain circumstances be considered as another &amp;quot;(Martin 1990, p. 59). In Martin&apos;s work, &amp;quot;metaphor-maps,&amp;quot; a kind of VIEW (ibid., p. 64), are used to represent conventional metaphors and the conceptual information they contain. 2.2 Metonymy Metonymy involves &amp;quot;using one entity to refer to another that is related to it&amp;quot; (Lakoff and Johnson 1980, p. 35). Example 2 &amp;quot;The ham sandwich is waiting for his check.&amp;quot; For example, in (2) the metonymy is that the concept for ham sandwich is related to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot; Several attempts have been made to organize instances of metonymy into categories (e.g., Lak</context>
<context position="30118" citStr="Martin (1990)" startWordPosition="4679" endWordPosition="4680">criticism applies to metonymy interpretation also. Using Searle&apos;s (1979) views on metaphor as an example, he characterizes the typical model for detecting nonliteral meaning as a three-stage process: [11 compute the literal meaning of a sentence, [21 decide if the literal meaning is defective, and if so, [3] seek an alternative meaning, i.e., a metaphorical one (though, presumably, a metonymic interpretation might also be sought at this stage). Gibbs (1984, p. 275) concludes that the distinction between literal and metaphoric meanings has &amp;quot;little psychological validity.&amp;quot; Among AT researchers, Martin (1990) shares many of Gibbs&apos;s views in criticizing the &amp;quot;literal meaning first approach&amp;quot; (ibid., p. 24). Martin suggests a two-stage process for interpreting sentences containing metaphors: [1] parse the sentence to produce a syntactic parse tree plus primal (semantic) representation, and [21 apply inference processes of &amp;quot;concretion&amp;quot; and &amp;quot;metaphoric viewing&amp;quot; to produce the most detailed semantic representation possible. The primal representation represents a level of semantic interpretation that is explicitly in need of further processing. Although it is obviously related to what 58 Fass Discriminati</context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>Martin, James H. (1990). A Computational Model of Metaphor Interpretation. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>A computational theory of metaphor.&amp;quot;</title>
<date>1988</date>
<tech>Technical Report No. UCB/CSD 88/465,</tech>
<institution>Computer Science Division (EECS), University of California, Berkeley.</institution>
<contexts>
<context position="3257" citStr="Martin 1988" startWordPosition="498" endWordPosition="499">thod provides a means for recognizing selected examples of metonymy and metaphor, and also anomaly and literalness, in short English sentences.&apos; The method is part of Collative Semantics (hereafter CS), which is a semantics for natural language processing. CS, and hence the met* method, has been implemented in a program called meta5 (so called because it does more than metaphor). The meta5 program is, as far as I know, the first system to recognize examples of metaphor and metonymy. To my knowledge, there is only one other working program that might be said to recognize instances of metaphor (Martin 1988; 1990) and two systems that appear to recognize cases of metonymy, TEAM (Grosz et al. 1987) and TACITUS (Hobbs and Martin 1987). The rest of the paper is organized as follows. Section 2 surveys general issues and approaches in metaphor and metonymy, notably the distinctive characteristics of metaphor and metonymy, the relationship between metaphor and metonymy, and the relationship between literalness and nonliteralness. Section 3 presents the met* method, concentrating on the basic topology of the met* method algorithm. Section 4 shows details of representations and processes used in CS. Sec</context>
</contexts>
<marker>Martin, 1988</marker>
<rawString>Martin, James H. (1988). &amp;quot;A computational theory of metaphor.&amp;quot; Technical Report No. UCB/CSD 88/465, Computer Science Division (EECS), University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>Knowledge acquisition through natural language dialogue.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, 2nd Annual Conference on Artificial Intelligence Applications,</booktitle>
<location>Miami, Florida.</location>
<contexts>
<context position="35605" citStr="Martin 1985" startWordPosition="5509" endWordPosition="5510">eveloped by Katz (1964) as the process of &amp;quot;attribution.&amp;quot; Assertions contain information that is possessed by senses of lexical items of certain parts of speech and that is imposed onto senses of lexical items of other parts of speech, e.g., the adjective &apos;female&apos; contains information that any noun to which it applies is of the female sex. Lexical syntactic and semantic constraints are enforced at certain places in sentences which I call dependencies. Within a dependency, the lexical item whose constraints are enforced is called the source and the other lexical item is called the target (after Martin 1985). Syntactic dependencies consist of pairs of lexical items of certain parts of speech in which the source, an item from one part of speech, applies one or more syntactic constraints to the target, another lexical item. Examples of source-target pairs include a determiner and a noun, an adjective and a noun, a noun and a verb, and an adverb and a verb. Example 15 &amp;quot;The ship ploughed the waves.&amp;quot; Semantic dependencies occur in the same places as syntactic dependencies. The (metaphorical) sentence (15) contains four semantic dependencies: between the determiner &apos;the&apos; and the noun &apos;ship,&apos; between &apos;s</context>
</contexts>
<marker>Martin, 1985</marker>
<rawString>Martin, James H. (1985). &amp;quot;Knowledge acquisition through natural language dialogue.&amp;quot; In Proceedings, 2nd Annual Conference on Artificial Intelligence Applications, Miami, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Matthews</author>
</authors>
<title>Concerning a &apos;linguistic theory&apos; of metaphor.&amp;quot;</title>
<date>1971</date>
<journal>Foundations of Language,</journal>
<pages>7--413</pages>
<marker>Matthews, 1971</marker>
<rawString>Matthews, R. J. (1971). &amp;quot;Concerning a &apos;linguistic theory&apos; of metaphor.&amp;quot; Foundations of Language, 7:413-425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Miles</author>
</authors>
<date>1967</date>
<note>Style</note>
<contexts>
<context position="8750" citStr="Miles (1967)" startWordPosition="1330" endWordPosition="1331">f a metaphor: the comparison theory ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212), proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967), Richards (1936), and Wheelwright (1962). Interaction theorists argue that the vehicle of a metaphor is a template for seeing the tenor in a new way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may only strike us as similar when </context>
</contexts>
<marker>Miles, 1967</marker>
<rawString>Miles, J. (1967). Style and Proportion. Little, Brown and Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick C Mish</author>
</authors>
<title>Webster&apos;s Ninth New Collegiate Dictionary.</title>
<date>1986</date>
<publisher>MerriamWebster Inc.</publisher>
<contexts>
<context position="27613" citStr="Mish 1986" startWordPosition="4299" endWordPosition="4300">s a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), though it has a role in understanding because it focuses on certain aspects of what is being referred to. There is little computational work about the relationship between metonymy and metaphor. Stallard (1987) distinguishes separate r</context>
</contexts>
<marker>Mish, 1986</marker>
<rawString>Mish, Frederick C. (1986). Webster&apos;s Ninth New Collegiate Dictionary. MerriamWebster Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Modiano</author>
</authors>
<title>Two procedures for sense projection.&amp;quot; Unpublished ms.,</title>
<date>1986</date>
<institution>Computing Research Laboratory, New Mexico State University.</institution>
<contexts>
<context position="94627" citStr="Modiano 1986" startWordPosition="14595" endWordPosition="14596">met* method given in Sections 3-6. When compared with the Al work described in Section 2, the met* method has three main advantages. First, it contains a detailed treatment of metonymy. Second, it shows the interrelationship between metonymy, metaphor, literalness, and anomaly. Third, it has been programmed. Preference Semantics addresses the recognition of literal, metaphorical, and anomalous relations, but does not have a treatment of metonymy. In the case of Preference Semantics, the theory described in Wilks (1978) has not been implemented, though the projection algorithm was implemented (Modiano 1986) using some parts of CS to supply detail missing from Wilks&apos; original specification. Gentner&apos;s (1983) Structure-Mapping Theory has no treatment of metonymy. The theory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989) and some examples analyzed by it but not, to my knowledge, examples of metaphor or anomaly. Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no treatment of metonymy, anomaly or literalness. It has also not been implemented: see Indurkhya (1987) for reasons why. Hobbs and Martin (1987) offer a relatively shallo</context>
</contexts>
<marker>Modiano, 1986</marker>
<rawString>Modiano, Nicole (1986). &amp;quot;Two procedures for sense projection.&amp;quot; Unpublished ms., Computing Research Laboratory, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Van Noppen</author>
<author>S De Knop</author>
<author>R Jongen</author>
</authors>
<title>Metaphor: A Bibliography of post-1970 Publications.</title>
<date>1985</date>
<booktitle>Amsterdam Studies in the Theory and History of Linguistic Science (Series V: Library and Information Sources in Linguistics), Volume 17,</booktitle>
<publisher>Benjamins Publishing Company.</publisher>
<location>John</location>
<marker>Van Noppen, De Knop, Jongen, 1985</marker>
<rawString>Van Noppen, Jean-Pierre; De Knop, S.; and Jongen, R. (1985). Metaphor: A Bibliography of post-1970 Publications. Amsterdam Studies in the Theory and History of Linguistic Science (Series V: Library and Information Sources in Linguistics), Volume 17, John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Ortony</author>
</authors>
<title>Some psycholinguistic aspects of metaphor.&amp;quot; In Cognition and Figurative Language, edited by</title>
<date>1980</date>
<contexts>
<context position="16492" citStr="Ortony 1980" startWordPosition="2521" endWordPosition="2522">E) is projected onto drink in the sentence representation which becomes [ny+car use gasoline] Example 3 &amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242). 53 Computational Linguistics Volume 17, Number 1 Example 4 &amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51). Example 5 &amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134). Example 6 &amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII). The main problem with the selection restrictions view is that perfectly well-formed sentences exist that have a metaphorical interpretation and yet contain no selection restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3), there is a literal interpretation when uttered about a stone and a metaphorical one when said about a decrepit professor emeritus. Sentences (4), (5) and (6) also have twin interpretations. The existence of such sentences suggests that a condition that occasionally holds (i.e., a selection restriction violation) has been elevated into a necessary condition of metaphor (Johnson 1980). Moreover, viewing metaphor only in terms of selection restriction violations ignores the influence of context: We seem to interpret an utterance metaphorically when to do so mak</context>
</contexts>
<marker>Ortony, 1980</marker>
<rawString>Ortony, Andrew (1980). &amp;quot;Some psycholinguistic aspects of metaphor.&amp;quot; In Cognition and Figurative Language, edited by Richard P. Honeck and Robert R. Hoffman, 69-83, Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Ortony</author>
</authors>
<title>Beyond literal similarity.&amp;quot;</title>
<date>1979</date>
<journal>Psychological Review,</journal>
<pages>86--161</pages>
<contexts>
<context position="11500" citStr="Ortony (1979)" startWordPosition="1754" endWordPosition="1755">teraction view is the domains-interaction view, set forth by Tourangeau and Sternberg (1982), who take the view that features &apos;shared&apos; by tenor and vehicle are often at best only analogous features, each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is imposed on the targ</context>
</contexts>
<marker>Ortony, 1979</marker>
<rawString>Ortony, Andrew (1979). &amp;quot;Beyond literal similarity.&amp;quot; Psychological Review, 86:161-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walker Percy</author>
</authors>
<date>1954</date>
<booktitle>The Message in the Bottle.</booktitle>
<location>Farrar, Strauss, and Giroux.</location>
<contexts>
<context position="14244" citStr="Percy (1954)" startWordPosition="2184" endWordPosition="2185"> the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An alg</context>
</contexts>
<marker>Percy, 1954</marker>
<rawString>Percy, Walker (1954). The Message in the Bottle. Farrar, Strauss, and Giroux.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ross Quillian</author>
</authors>
<title>Semantic memory.&amp;quot;</title>
<date>1968</date>
<booktitle>In Semantic Information Processing, edited by Marvin Minsky,</booktitle>
<pages>216--270</pages>
<publisher>MIT Press.</publisher>
<marker>Quillian, 1968</marker>
<rawString>Quillian, M. Ross (1968). &amp;quot;Semantic memory.&amp;quot; In Semantic Information Processing, edited by Marvin Minsky, 216-270, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Perrine</author>
</authors>
<title>Psychological forms of metaphor.&amp;quot;</title>
<date>1971</date>
<journal>College English,</journal>
<pages>33--125</pages>
<contexts>
<context position="37327" citStr="Perrine 1971" startWordPosition="5783" endWordPosition="5784">ing of (15) is because &apos;waves&apos; is understood as being the sense meaning &amp;quot;movement of water,&amp;quot; not for example the sense meaning &amp;quot;movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrar</context>
</contexts>
<marker>Perrine, 1971</marker>
<rawString>Perrine, Lawrence (1971). &amp;quot;Psychological forms of metaphor.&amp;quot; College English, 33:125-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Reddy</author>
</authors>
<title>The conduit metaphor - a case of frame conflict in our language about language.&amp;quot; In Metaphor and Thought, edited by Andrew Ortony,</title>
<date>1979</date>
<pages>284--324</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="627" citStr="Reddy 1979" startWordPosition="94" endWordPosition="95">or Discriminating Metonymy and Metaphor by Computer Dan Fass. Simon Fraser University The met* method distinguishes selected examples of metonymy from metaphor and from literalness and anomaly in short English sentences. In the met* method, literalness is distinguished because it satisfies contextual constraints that the nonliteral others all violate. Metonymy is discriminated from metaphor and anomaly in a way that [1] supports Lakoff and Johnson&apos;s (1980) view that in metonymy one entity stands for another whereas in metaphor one entity is viewed as another, [2] permits chains of metonymies (Reddy 1979), and [3] allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. Metaphor is distinguished from anomaly because the former contains a relevant analogy, unlike the latter. The met* method is part of Collative Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5&apos;s analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology. 1. Introduction Metaphor and metonymy are kinds of figu</context>
<context position="22141" citStr="Reddy 1979" startWordPosition="3425" endWordPosition="3426">re between a CONTAINER (a glass) and its typical CONTENTS (a liquid): this relationship is the metonymic concept CONTAINER FOR 55 Computational Linguistics Volume 17, Number 1 CONTENTS. Below are examples of two further metonymic concepts (from Lakoff and Johnson 1980, p. 38, italics in original). PRODUCER FOR PRODUCT &amp;quot;I&apos;ll have a Leiwenbrdu. &amp;quot; &amp;quot;He bought a Ford.&amp;quot; &amp;quot;He&apos;s got a Picasso in his den.&amp;quot; &amp;quot;I hate to read Heidegger.&amp;quot; OBJECT USED FOR USER &amp;quot;The sax has the flu today.&amp;quot; &amp;quot;The BLT is a lousy tipper.&amp;quot;**2 &amp;quot;The buses are on strike.&amp;quot; Example 9 &amp;quot;You&apos;ll find better ideas than that in the library&amp;quot; (Reddy 1979, p. 309). Reddy (1979) has observed that metonymies can occur in chains. He suggests that (9) contains a chain of PART FOR WHOLE metonymies between &apos;ideas&apos; and &apos;library&apos;: the ideas are expressed in words, words are printed on pages, pages are in books, and books are found in a library. Example 10 &amp;quot;I found an old car on the road. The steering wheel was broken&amp;quot; (Yamanashi 1987, p. 79). Example 11 &amp;quot;We had a party in a mysterious room. The walls were painted in psychedelic color&amp;quot; (ibid.). Example 12 A: &amp;quot;I bought an interesting book.&amp;quot; B: &amp;quot;Who is the author?&amp;quot; (ibid.). Example 13 &amp;quot;He happened to die</context>
<context position="43933" citStr="Reddy 1979" startWordPosition="6823" endWordPosition="6824">a liquid like &apos;car&apos; does in (20). This is not to say that an anomalous relation is uninterpretable or that no analogy can possibly be found in one. In special circumstances (for example, in a poem), search for analogies might be expanded to permit weaker analogies, thereby allowing &amp;quot;ideas drinking&amp;quot; to be interpreted metaphorically. The topology of the flow chart in Figure 1 results from needing to satisfy a number of observations about the preference-based phenomena, particularly metonymy: 1. literalness is distinct from the others, which are all nonliteral; 2. metonymies can occur in chains (Reddy 1979); 3. metonymy always seems to occur with one of the other three; and 4. metaphor and anomaly are the hardest to tell apart (and thus require the most extended processing to distinguish). Hence a preference-based semantic relation can be either a single relation or a multi-relation. A single relation consists of one literal, metaphorical, or anomalous relation. A multi-relation contains one literal, metaphorical, or anomalous relation plus either a single metonymy or a chain of metonymies. All these combinations, but only these, are derivable from Figure 1. Note that in the met* method as prese</context>
<context position="102223" citStr="Reddy 1979" startWordPosition="15780" endWordPosition="15781">is based on knowledge-specific relationships between a concept and an aspect of another concept. These observations, I would argue, support the view that metonymy has primarily a referential function, allowing something to stand for something else — a connection between a concept and an aspect of another concept. The observations also support the view that metaphor&apos;s primary function is understanding, allowing something to be conceived of in terms of something else: the role of analogy is especially crucial to this function. 7.3 Metonymy The treatment of metonymy permits chains of metonymies (Reddy 1979), and allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. 83 Computational Linguistics Volume 17, Number 1 The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987) notes link sentences. An obvious direction in which to extend the present work is toward across-sentence inferences. Example 30 &amp;quot;John drank from the faucet&amp;quot; (Lehnert 1978, p. 221). Example 31 &amp;quot;John filled his canteen at the spring&amp;quot; (Ibid.). Metonymy seems closely related to the work on non-logical inferencing done by Schank (Schank 1973) and the Yale Group (Schank 19</context>
</contexts>
<marker>Reddy, 1979</marker>
<rawString>Reddy, Michael J. (1979). &amp;quot;The conduit metaphor - a case of frame conflict in our language about language.&amp;quot; In Metaphor and Thought, edited by Andrew Ortony, 284-324, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Reddy</author>
</authors>
<title>A semantic approach to metaphor.&amp;quot; In Chicago Linguistic Society Collected Papers,</title>
<date>1969</date>
<pages>240--251</pages>
<publisher>Chicago University Press,</publisher>
<contexts>
<context position="16036" citStr="Reddy 1969" startWordPosition="2450" endWordPosition="2451">e) linked by case ties. A brief example of projection is given for (1). Example 3 &amp;quot;My car drinks gasoline.&amp;quot; Projection operates only on preference violations. The best representation of (1) contains a preference violation, so projection is used. The algorithm compares the template representation for the sentence [my+car drink gasoline] against templates from the pseudo-text of &apos;car&apos; seeking &amp;quot;the closest match,&amp;quot; and selects fICengine (USE)#liquidl. (USE) is projected onto drink in the sentence representation which becomes [ny+car use gasoline] Example 3 &amp;quot;The rock is becoming brittle with age&amp;quot; (Reddy 1969, p. 242). 53 Computational Linguistics Volume 17, Number 1 Example 4 &amp;quot;Idi Amin is an animal&amp;quot; (Johnson 1980, p. 51). Example 5 &amp;quot;People are not cattle&amp;quot; (Hobbs 1983b, p. 134). Example 6 &amp;quot;No man is an Island&amp;quot; (John Donne, Meditations XVII). The main problem with the selection restrictions view is that perfectly well-formed sentences exist that have a metaphorical interpretation and yet contain no selection restriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3), there is a literal interpretation when uttered about a stone and a metaphorical one when said about a decrep</context>
</contexts>
<marker>Reddy, 1969</marker>
<rawString>Reddy, Michael J. (1969). &amp;quot;A semantic approach to metaphor.&amp;quot; In Chicago Linguistic Society Collected Papers, Chicago University Press, 240-251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivor A Richards</author>
</authors>
<title>The Philosophy of Rhetoric.</title>
<date>1936</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="8767" citStr="Richards (1936)" startWordPosition="1332" endWordPosition="1333">the comparison theory ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212), proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967), Richards (1936), and Wheelwright (1962). Interaction theorists argue that the vehicle of a metaphor is a template for seeing the tenor in a new way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may only strike us as similar when we interpret the </context>
<context position="37223" citStr="Richards 1936" startWordPosition="5769" endWordPosition="5770">just pairs of lexical items but also pairs of senses of lexical items. For example, the metaphorical reading of (15) is because &apos;waves&apos; is understood as being the sense meaning &amp;quot;movement of water,&amp;quot; not for example the sense meaning &amp;quot;movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations ar</context>
<context position="69231" citStr="Richards 1936" startWordPosition="10757" endWordPosition="10758">e verb senses drinkl and use2, which are both types of expending (Figure 8). The second path is between the noun senses drinkl and gasolinel, which are both types of liquid (Figure 9). The effect of the network paths is to establish correspondences between the two cells such that an analogy is &amp;quot;discovered&amp;quot; that animals drink potable liquids as cars use gasoline. Note that, like Gentner&apos;s (1983) systematicity principle, the correspondences found are structural and independent of the content of the word senses they connect. Note also that the two cells have an underlying similarity or &amp;quot;ground&amp;quot; (Richards 1936) in that both refer to the expenditure of liquids. This second stage of finding a relevant analogy seems the crucial one in metaphor recognition. Figure 10 shows the match of the nonrelevant cells from animall and carl. The cell use2, gasolinel I has been removed. There are three inclusive cell matches as animals and cars share physical objectlike properties of boundedness, three dimensions, sf(drinkl, [[arcs, [[supertype, [ingestl, expendljjjj, [node2, [[agent, [preference, anlmallll, [object, [preference, drinkl[]]]]). sf(animall, sf(carl, [[arcs, [[arcs, [[supertype, organisml]jj, [[superty</context>
</contexts>
<marker>Richards, 1936</marker>
<rawString>Richards, Ivor A. (1936). The Philosophy of Rhetoric. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvia Weber Russell</author>
</authors>
<title>Computer understanding of metaphorically used verbs.&amp;quot;</title>
<date>1976</date>
<journal>American Journal of Computational Linguistics, Microfiche</journal>
<volume>44</volume>
<contexts>
<context position="4999" citStr="Russell (1976)" startWordPosition="760" endWordPosition="761">ent views exist about them and their relationship to each other. This section reviews research on metaphor (2.1), metonymy (2.2), the relationship between them (2.3), and the more general relationship between literalness and nonliteralness (2.4). 2.1 Metaphor Four views of metaphor are critically discussed: the comparison view, the interactive view, the selection restriction violation view, and the conventional metaphor view. Computational examples of each kind are included by Gentner, Indurkhya, Hobbs, Wilks, and Martin. Space does not permit discussion of other AT work on metaphor by, e.g., Russell (1976) and Weiner (1984; 1985). 2.1.1 The Comparison View. According to the comparison view a metaphor is a comparison in which one term (the tenor or subject of the comparison) is asserted to bear a partial resemblance (the ground of the comparison) to something else (the vehicle), the resemblance being insufficient to sustain a literal comparison. As with any comparison, there is always some residual dissimilarity (the tension) between the terms involved in the comparison, but comparison theorists tend not to emphasize this dissimilarity (Tourangeau and Sternberg 1982, p. 205, their italics). What</context>
<context position="97937" citStr="Russell (1976)" startWordPosition="15108" endWordPosition="15109">ce resembles structural metaphors like TIME IS A RESOURCE and LABOR IS A RESOURCE which, according to Lakoff and Johnson (1980, p. 66), both employ the simple ontological metaphors of TIME IS A SUBSTANCE and AN ACTIVITY IS A SUBSTANCE: These two substance metaphors permit labor and time to be quantified — that is, measured, conceived of as being progressively &amp;quot;used up,&amp;quot; and assigned monetary values; they allow us to view time and labor as things that can be &amp;quot;used&amp;quot; for various ends. Example 29 &amp;quot;The horse flew.&amp;quot; The second type of ground is motion-through-a-medium, a type of ground discussed by Russell (1976). This appears in (15) and (29), again both analyzed by meta5. Incidentally, it is worth noting that structural metaphors have proven more amenable to the met* method than other kinds tried. I assumed initially that orientational and ontological metaphors would be easier to analyze than structural metaphors because they were less complex. However, structural metaphors have proved easier to analyze, probably because structural metaphors contain more specific concepts such as &amp;quot;drink&amp;quot; and &amp;quot;plough,&amp;quot; which are more simple to represent in a network structure (like the sense-network of CS) so that an</context>
</contexts>
<marker>Russell, 1976</marker>
<rawString>Russell, Sylvia Weber (1976). &amp;quot;Computer understanding of metaphorically used verbs.&amp;quot; American Journal of Computational Linguistics, Microfiche 44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
</authors>
<title>The structure of episodes in memory.&amp;quot;</title>
<date>1975</date>
<booktitle>In Representation and Understanding, edited by</booktitle>
<pages>237--272</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="34336" citStr="Schank 1975" startWordPosition="5292" endWordPosition="5293">n) be viewed as the integration of constraints from language and from context. Some language constraints are syntactic, while others are semantic. Some 59 Computational Linguistics Volume 17, Number 1 language constraints are lexical constraints; that is, constraints possessed by lexical items (words and fixed phrases). Lexical syntactic constraints include those on word order, number, and tense. This sec tion describes three lexical semantic constraints: preferences, assertions, and a lexical notion of relevance. Preferences (Wilks 1973), selection restrictions (Katz 1964), and expectations (Schank 1975) are the same (see Fass 1989c; Fass and Wilks 1983; Wilks and Fass in press): all are restrictions possessed by senses of lexical items of certain parts of speech about the semantic classes of lexical items with which they co-occur. Thus an adjective sense has a preference for the semantic class of nouns with which it co-occurs and a verb sense has preferences for the semantic classes of nouns that fill its case roles. For example, the main sense of the verb &apos;drink&apos; prefers an animal to fill its agent case role, i.e., it is animals that drink. The assertion of semantic information was noted by</context>
<context position="102825" citStr="Schank 1975" startWordPosition="15872" endWordPosition="15873">ddy 1979), and allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. 83 Computational Linguistics Volume 17, Number 1 The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987) notes link sentences. An obvious direction in which to extend the present work is toward across-sentence inferences. Example 30 &amp;quot;John drank from the faucet&amp;quot; (Lehnert 1978, p. 221). Example 31 &amp;quot;John filled his canteen at the spring&amp;quot; (Ibid.). Metonymy seems closely related to the work on non-logical inferencing done by Schank (Schank 1973) and the Yale Group (Schank 1975; Schank and Abelson 1977; Schank and Riesbeck 1981). For example, Lehnert (1978) observes that just one inference is required for understanding both (30) and (31). The inference, that water comes from the faucet in (30) and the spring in (31), is an instance of PRODUCER FOR PRODUCT in which the faucet and spring are PRODUCERs and water is the PRODUCT. However, the inference is not a metonymy because it is from unused cases of the verbs &apos;drink&apos; and &apos;fill&apos; whereas metonymy only occurs in the presence of a violated selection restriction, that neither (30) nor (31) contain. 7.4 Metaphor Metaphor </context>
</contexts>
<marker>Schank, 1975</marker>
<rawString>Schank, Roger C. (1975). &amp;quot;The structure of episodes in memory.&amp;quot; In Representation and Understanding, edited by Daniel G. Bobrow and Allan Collins, 237-272. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
</authors>
<title>Identification of conceptualizations underlying natural language.&amp;quot; In Computer Models of Thought and Language, edited by</title>
<date>1973</date>
<publisher>W.H. Freeman.</publisher>
<contexts>
<context position="93653" citStr="Schank (1973)" startWordPosition="14445" endWordPosition="14446"> cars using gasoline; in the other, the same information is matched against human beings drinking coffee; but cars using gasoline and human beings drinking coffee are quite different, hence sentence (27) is anomalous overall. Note that in Figures 20 and 21, the coherence representation part of the sentence representation is much larger than the knowledge representation part. The detailed &amp;quot;world knowledge&amp;quot; about car1, the verb sense drinkl, gasolinel, and coffeel are all on the right side. It is interesting to contrast the figures with early Conceptual Dependency (CD) diagrams such as those in Schank (1973) because, rather than the large and seemingly unlimited amounts of world knowledge that appear in CD diagrams, the two figures present only the world knowledge needed to discriminate the semantic relations in (20) and (27). 7. Discussion and Conclusions This section reviews the material on metonymy and metaphor in Section 2 in light of the explanation of the met* method given in Sections 3-6. When compared with the Al work described in Section 2, the met* method has three main advantages. First, it contains a detailed treatment of metonymy. Second, it shows the interrelationship between metony</context>
<context position="102793" citStr="Schank 1973" startWordPosition="15866" endWordPosition="15867"> permits chains of metonymies (Reddy 1979), and allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. 83 Computational Linguistics Volume 17, Number 1 The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987) notes link sentences. An obvious direction in which to extend the present work is toward across-sentence inferences. Example 30 &amp;quot;John drank from the faucet&amp;quot; (Lehnert 1978, p. 221). Example 31 &amp;quot;John filled his canteen at the spring&amp;quot; (Ibid.). Metonymy seems closely related to the work on non-logical inferencing done by Schank (Schank 1973) and the Yale Group (Schank 1975; Schank and Abelson 1977; Schank and Riesbeck 1981). For example, Lehnert (1978) observes that just one inference is required for understanding both (30) and (31). The inference, that water comes from the faucet in (30) and the spring in (31), is an instance of PRODUCER FOR PRODUCT in which the faucet and spring are PRODUCERs and water is the PRODUCT. However, the inference is not a metonymy because it is from unused cases of the verbs &apos;drink&apos; and &apos;fill&apos; whereas metonymy only occurs in the presence of a violated selection restriction, that neither (30) nor (31)</context>
</contexts>
<marker>Schank, 1973</marker>
<rawString>Schank, Roger C. (1973). &amp;quot;Identification of conceptualizations underlying natural language.&amp;quot; In Computer Models of Thought and Language, edited by Roger C. Schank and Kenneth M. Colby, 187-247. W.H. Freeman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Warren Shibles</author>
</authors>
<title>Metaphor: An Annotated Bibliography and History.</title>
<date>1971</date>
<publisher>The Language Press.</publisher>
<contexts>
<context position="2061" citStr="Shibles 1971" startWordPosition="311" endWordPosition="312">is check&amp;quot; (Lakoff and Johnson 1980, p. 35). Sentences (1) and (2) contain examples of metaphor and metonymy respectively. Neither sentence is literally true: cars do not literally drink nor do ham sandwiches literally wait. Notice, though, that the two sentences are interpreted differently. &amp;quot;My car&amp;quot; in (1) is commonly understood as resembling an animate drinker while in (2) &amp;quot;the ham sandwich&amp;quot; is generally interpreted as referring to the person who ordered the ham sandwich. Most of the considerable literature on metaphor and the smaller one on metonymy (see Van Noppen, De Knop and Jongen 1985; Shibles 1971) is from philosophy, linguistics, and psychology. On the whole, the two phenomena remain vague, poorly defined notions in that literature. In artificial intelligence (AI), detailed treatments of either metaphor or metonymy are relatively scarce. Moreover, most of those treatments are paper implementations that have not been coded up and run on a computer. * Centre for Systems Science, Simon Fraser University, Burnaby, British Columbia, Canada V5A 156 © 1991 Association for Computational Linguistics Computational Linguistics Volume 17, Number 1 The met* (pronounced &amp;quot;met star&amp;quot;) method provides a</context>
</contexts>
<marker>Shibles, 1971</marker>
<rawString>Shibles, Warren (1971). Metaphor: An Annotated Bibliography and History. The Language Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gustaf Stern</author>
</authors>
<title>(first published in Sweden 1931) Meaning and Changes of Meaning.</title>
<date>1968</date>
<publisher>Indiana University Press.</publisher>
<marker>Stern, 1968</marker>
<rawString>Stern, Gustaf (1968). (first published in Sweden 1931) Meaning and Changes of Meaning. Indiana University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Tourangeau</author>
<author>Robert J Sternberg</author>
</authors>
<title>Understanding and appreciating metaphors.&amp;quot;</title>
<date>1982</date>
<journal>Cognition,</journal>
<pages>11--203</pages>
<contexts>
<context position="5569" citStr="Tourangeau and Sternberg 1982" startWordPosition="845" endWordPosition="848">ssion of other AT work on metaphor by, e.g., Russell (1976) and Weiner (1984; 1985). 2.1.1 The Comparison View. According to the comparison view a metaphor is a comparison in which one term (the tenor or subject of the comparison) is asserted to bear a partial resemblance (the ground of the comparison) to something else (the vehicle), the resemblance being insufficient to sustain a literal comparison. As with any comparison, there is always some residual dissimilarity (the tension) between the terms involved in the comparison, but comparison theorists tend not to emphasize this dissimilarity (Tourangeau and Sternberg 1982, p. 205, their italics). What is crucial in the comparison approach, then, is finding the correct ground in a metaphor. According to Tourangeau and Sternberg, Aristotle proposed the first 1 The met* method takes its name from a remark made by Yorick Wilks. He used met* to refer collectively to metonymy and metaphor: &amp;quot;&amp;quot;&amp;quot; is a match-anything symbol in the Unix operating system; hence, the token &amp;quot;&apos;nee&amp;quot; matches the two tokens &amp;quot;metonymy&amp;quot; and &amp;quot;metaphor.&amp;quot; 50 Fass Discriminating Metonymy comparison theory and suggested several principles for finding the ground of a metaphor. Tourangeau and Sternberg </context>
<context position="7429" citStr="Tourangeau and Sternberg (1982)" startWordPosition="1114" endWordPosition="1117">LARGE(x), or &amp;quot;relations,&amp;quot; two-place predicates such as COLLIDE(x,y). The four kinds of comparison are distinguished by the relative proportions of attributes and relations that are matched, and the forms of mappings established between them. Mappings between relations are sought before those between attributes. Pairs of relations are compared using the &amp;quot;systematicity principle&amp;quot; that regular structural correspondences should exist between terms occupying the same positions in those relations. Mappings are purely structural and independent of the content of the relations (i.e., the predicates). Tourangeau and Sternberg (1982) list some problems with the comparison view, including the following: (a) that everything has some feature or category that it shares with everything else, but we cannot combine just any two things in metaphor; (b) that the most obvious shared features are often irrelevant to a reading of the metaphor; (c) that even when the feature is relevant, it is often shared only metaphorically; ... and (e) that metaphors are novel and surprising is hard to reconcile with the idea that they rely completely on extant similarities (ibid., pp. 226-227). Johnson (1980) also notes problem (a) with comparison</context>
<context position="9523" citStr="Tourangeau and Sternberg 1982" startWordPosition="1451" endWordPosition="1454">w way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may only strike us as similar when we interpret the metaphor. In Black&apos;s reading of this metaphor, we see competition in social relations as corresponding to predacity in beasts (Tourangeau and Sternberg 1982, pp. 212-213). 51 Computational Linguistics Volume 17, Number 1 A problem with the interaction view is that theorists have not provided much detail about the processes involved, though Black (1962) does make some suggestions. According to Black, tenor and vehicle... each have a &apos;system of commonplaces&apos; associated with them. These commonplaces are stereotypes, not necessarily definitional, not even necessarily true, just widely agreed upon. In interpreting &apos;man is a wolf,&apos; we &apos;evoke the wolf-system of related commonplaces&apos; and are led by them &apos;to construct a corresponding system of implication</context>
<context position="10979" citStr="Tourangeau and Sternberg (1982)" startWordPosition="1669" endWordPosition="1672">larity between them (Tourangeau and Sternberg 1982, p. 213). One might distinguish, then, two main differences between the interaction and comparison views. First, similarities are &amp;quot;created&amp;quot; in the interaction view (accounting for the novelty and surprise in a metaphor) whereas only pre-existing similarities are found in the comparison view. Second, a whole system of similarities are evoked between tenor and vehicle in the interactions view, whereas the comparisons view is based upon finding a single similarity. One version of the interaction view is the domains-interaction view, set forth by Tourangeau and Sternberg (1982), who take the view that features &apos;shared&apos; by tenor and vehicle are often at best only analogous features, each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mech</context>
<context position="14000" citStr="Tourangeau and Sternberg 1982" startWordPosition="2146" endWordPosition="2149">which Hobbs sometimes calls &amp;quot;selective inferencing&amp;quot; (e.g., Hobbs 1980). Selective inferencing is concerned with drawing or refraining from drawing certain inferences in a controlled fashion (cf. Hobbs 1983a). He argues that many problems have the same or almost the same inferencing solutions. These solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The</context>
<context position="58539" citStr="Tourangeau and Sternberg (1982)" startWordPosition="9091" endWordPosition="9094">ng semantic relations are applied. In the event of a tie, a measure of conceptual similarity is used. The ranking of semantic relations aims to achieve the most coherent possible interpretation of a reading. The class of preference-based semantic relations takes precedence over the class of assertion-based semantic relations for lexical disambiguation. The rank order among preference-based semantic relations is literal metaphorical —&gt; anomalous. If the semantic vectors are still tied then the measure of conceptual similarity is employed. This measure was initially developed to test a claim by Tourangeau and Sternberg (1982) about the aptness of a metaphor. They contend that aptness is a function of the distance between the conceptual domains of the source and target involved: the claim is that the more distant the domains, the better the metaphor. This is discussed further in Section 5. The conceptual similarity measure is also used for lexical ambiguity resolution (see Fass 1988c). 5. The Meta5 Program CS has been implemented in the meta5 natural language program. The meta5 program is written in Quintus Prolog and consists of a lexicon holding the sense-frames of just over 500 word senses, a small grammar, and </context>
<context position="107017" citStr="Tourangeau and Sternberg (1982" startWordPosition="16542" endWordPosition="16545">similarities are found in the comparison view, and second, that a whole system of similarities are evoked in the interactions view, unlike the comparisons view, which focuses upon finding a single similarity. Regarding the first difference, I would argue that the difference is a mistaken one and that interaction theorists are simply using a sophisticated form of comparison. This is quite evident when one examines, for example, the methods Tourangeau and Sternberg propose for relating features across domains in their theory. The second of Aristotle&apos;s basic principles is finding an analogy, yet Tourangeau and Sternberg (1982, p. 218) themselves say that, &amp;quot;in a sense, we are proposing that metaphors are analogies that include both tenor and vehicle and their different domains as terms.&amp;quot; And, of course, finding an analogy is central to the met* method on CS. Regarding the second difference, I would agree that finding a system of commonplaces is distinctive. However, the extensions to CS described in Section 6 move toward the direction of finding a system of commonplaces in that the deeper semantic vectors, and sentence representations shown in Figures 20 and 21 contain the information crucial to finding a system of</context>
</contexts>
<marker>Tourangeau, Sternberg, 1982</marker>
<rawString>Tourangeau, Roger and Sternberg, Robert J. (1982). &amp;quot;Understanding and appreciating metaphors.&amp;quot; Cognition, 11:203-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amos Tversky</author>
</authors>
<title>Features of similarity.&amp;quot;</title>
<date>1977</date>
<journal>Psychological Review,</journal>
<pages>84--327</pages>
<contexts>
<context position="11712" citStr="Tversky 1977" startWordPosition="1783" endWordPosition="1784">in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is imposed on the target domain, thereby shaping the features of the target domain, which in turn produces changes in the features of the source domain, hence the &amp;quot;interaction.&amp;quot; It is assumed that a structural analogy underlies every </context>
<context position="37364" citStr="Tversky 1977" startWordPosition="5788" endWordPosition="5789">erstood as being the sense meaning &amp;quot;movement of water,&amp;quot; not for example the sense meaning &amp;quot;movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relation</context>
</contexts>
<marker>Tversky, 1977</marker>
<rawString>Tversky, Amos (1977). &amp;quot;Features of similarity.&amp;quot; Psychological Review, 84:327-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Ullmann</author>
</authors>
<title>Semantics: An Introduction to the Science of Meaning.</title>
<date>1962</date>
<publisher>Basil Blackwell &amp; Mott Ltd.</publisher>
<contexts>
<context position="27382" citStr="Ullmann 1962" startWordPosition="4263" endWordPosition="4264">ies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that metonymy is founded on contiguity whereas metaphor is based on similarity (cf. Jakobsen and Halle 1956; Ullmann 1962). Contiguity and similarity are two kinds of association. Contiguity refers to a state of being connected or touching whereas similarity refers to a state of being alike in essentials or having characteristics in common (Mish 1986). A second difference, advanced by Lakoff and Johnson (1980) for example, is that metaphor is &amp;quot;principally a way of conceiving of one thing in terms of another, and its primary function is understanding&amp;quot; (ibid., pp. 36-37) whereas metonymy &amp;quot;has primarily a referential function, that is, it allows us to use one entity to stand for another&amp;quot; (ibid., their italics), thou</context>
</contexts>
<marker>Ullmann, 1962</marker>
<rawString>Ullmann, Stephen (1962). Semantics: An Introduction to the Science of Meaning. Basil Blackwell &amp; Mott Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald A Waldron</author>
</authors>
<title>Sense and Sense Development.</title>
<date>1967</date>
<publisher>Andre Deutsch.</publisher>
<contexts>
<context position="21117" citStr="Waldron 1967" startWordPosition="3253" endWordPosition="3254">ich is waiting for his check.&amp;quot; For example, in (2) the metonymy is that the concept for ham sandwich is related to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot; Several attempts have been made to organize instances of metonymy into categories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or &amp;quot;metonymic concepts,&amp;quot; as Lakoff and Johnson call them. A common metonymic concept is PART FOR WHOLE, otherwise known as synechdoche. Example 7 &amp;quot;Dave drank the glasses&amp;quot; (= the liquid in the glasses). Example 8 &amp;quot;The kettle is boiling&amp;quot; (= the liquid in the kettle) (Waldron 1967, p. 186; Yamanashi 1987, p. 78). CONTAINER FOR CONTENTS, another metonymic concept, occurs in (7) between &apos;drink&apos; and the sense of &apos;glasses&apos; meaning &amp;quot;containers,&amp;quot; and also in (8). In (7), &apos;drink&apos; has an object preference for a potable liquid, but there is a preference violation because glasses are not potable liquids. It is not glasses that are drunk, but the potable liquids in them. There is a relationship here between a CONTAINER (a glass) and its typical CONTENTS (a liquid): this relationship is the metonymic concept CONTAINER FOR 55 Computational Linguistics Volume 17, Number 1 CONTENTS. </context>
<context position="26669" citStr="Waldron 1967" startWordPosition="4151" endWordPosition="4152">sing line of investigation because metonymy and anaphora share the function of allowing one entity to refer to another entity. Example 2 &amp;quot;The ham sandwich is waiting for his check&amp;quot; (= the male person who ordered the ham sandwich). Example 14 &amp;quot;He is waiting for his check&amp;quot; (= the male person). This similarity of function can be seen in comparing (2), which is metonymic, with (14), which is anaphoric. 2.3 Relationship between Metonymy and Metaphor Both metonymy and metaphor have been identified as central to the development of new word senses, and hence to language change (see, e.g., Stern 1931; Waldron 1967). Some of the best examples of the differences between the two phenomena come from data used in studies of metonymic and metaphorical effects on language change. Nevertheless, there are widely differing views on which phenomenon is the more important. Some argue that metaphor is a kind of metonymy, and others propose that metonymy is a kind of metaphor, while still others suggest that they are quite different (see Fass 1988c). 57 Computational Linguistics Volume 17, Number 1 Among the third group, two differences between metonymy and metaphor are commonly mentioned. One difference is that meto</context>
</contexts>
<marker>Waldron, 1967</marker>
<rawString>Waldron, Ronald A. (1967). Sense and Sense Development. Andre Deutsch.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Judith Weiner</author>
</authors>
<title>Solving the containment problem for figurative language.&amp;quot;</title>
<date>1985</date>
<journal>International journal of Man-Machine Studies,</journal>
<pages>23--527</pages>
<marker>Weiner, 1985</marker>
<rawString>Weiner, E. Judith (1985). &amp;quot;Solving the containment problem for figurative language.&amp;quot; International journal of Man-Machine Studies, 23:527-537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Judith Weiner</author>
</authors>
<title>A knowledge representation approach to understanding metaphors.&amp;quot;</title>
<date>1984</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>10--1</pages>
<contexts>
<context position="5016" citStr="Weiner (1984" startWordPosition="763" endWordPosition="764">ut them and their relationship to each other. This section reviews research on metaphor (2.1), metonymy (2.2), the relationship between them (2.3), and the more general relationship between literalness and nonliteralness (2.4). 2.1 Metaphor Four views of metaphor are critically discussed: the comparison view, the interactive view, the selection restriction violation view, and the conventional metaphor view. Computational examples of each kind are included by Gentner, Indurkhya, Hobbs, Wilks, and Martin. Space does not permit discussion of other AT work on metaphor by, e.g., Russell (1976) and Weiner (1984; 1985). 2.1.1 The Comparison View. According to the comparison view a metaphor is a comparison in which one term (the tenor or subject of the comparison) is asserted to bear a partial resemblance (the ground of the comparison) to something else (the vehicle), the resemblance being insufficient to sustain a literal comparison. As with any comparison, there is always some residual dissimilarity (the tension) between the terms involved in the comparison, but comparison theorists tend not to emphasize this dissimilarity (Tourangeau and Sternberg 1982, p. 205, their italics). What is crucial in th</context>
</contexts>
<marker>Weiner, 1984</marker>
<rawString>Weiner, E. Judith (1984). &amp;quot;A knowledge representation approach to understanding metaphors.&amp;quot; American Journal of Computational Linguistics, 10:1-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wheelwright</author>
</authors>
<title>Metaphor and Reality.</title>
<date>1962</date>
<publisher>Indiana University Press.</publisher>
<contexts>
<context position="8791" citStr="Wheelwright (1962)" startWordPosition="1335" endWordPosition="1336"> ... tries to circumvent the experienced semantic strain by interpreting metaphor as nothing but a way of comparing two things to see in what respects they are alike. And since any two things are similar in some respects, this kind of theory can never explain what is interesting and important about metaphor (ibid., p. 52). 2.1.2 The Interaction View. The interaction view focuses more upon the surprise and novelty that metaphors create. According to Tourangeau and Sternberg (1982, p. 212), proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967), Richards (1936), and Wheelwright (1962). Interaction theorists argue that the vehicle of a metaphor is a template for seeing the tenor in a new way. This reorganization of the tenor is necessary, because the characteristics or features of the vehicle cannot be applied directly to the tenor; the features they &apos;share&apos; are often only shared metaphorically. As Black (1962) observes, the ground of a metaphor may itself be nonliteral. &apos;Men are wolves,&apos; in Black&apos;s example, in part because both are predators; but they are predators in sharply different senses that may only strike us as similar when we interpret the metaphor. In Black&apos;s rea</context>
<context position="14285" citStr="Wheelwright (1962)" startWordPosition="2190" endWordPosition="2191">ese solutions are found via four separate semantic operations that all draw inferences from text (e.g., Hobbs 1977). 2.1.3 The Selection Restrictions Violations View. The selection restriction violation view has also been called &amp;quot;the semantic deviance view&amp;quot; (Johnson 1980, p. 50) and &amp;quot;the anomaly view&amp;quot; (Tourangeau and Sternberg 1982, p. 211). Johnson (1980) describes this view as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An algorithm matches pairs of semantic formulas</context>
</contexts>
<marker>Wheelwright, 1962</marker>
<rawString>Wheelwright, P. (1962). Metaphor and Reality. Indiana University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>Making preferences more active.&amp;quot;</title>
<date>1978</date>
<journal>Artificial Intelligence,</journal>
<pages>11--197</pages>
<contexts>
<context position="1393" citStr="Wilks 1978" startWordPosition="202" endWordPosition="203">r contains a relevant analogy, unlike the latter. The met* method is part of Collative Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5&apos;s analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology. 1. Introduction Metaphor and metonymy are kinds of figurative language or tropes. Other tropes include simile, irony, understatement (litotes), and overstatement (hyperbole). Example 1 &amp;quot;My car drinks gasoline&amp;quot; (Wilks 1978, p. 199). Example 2 &amp;quot;The ham sandwich is waiting for his check&amp;quot; (Lakoff and Johnson 1980, p. 35). Sentences (1) and (2) contain examples of metaphor and metonymy respectively. Neither sentence is literally true: cars do not literally drink nor do ham sandwiches literally wait. Notice, though, that the two sentences are interpreted differently. &amp;quot;My car&amp;quot; in (1) is commonly understood as resembling an animate drinker while in (2) &amp;quot;the ham sandwich&amp;quot; is generally interpreted as referring to the person who ordered the ham sandwich. Most of the considerable literature on metaphor and the smaller one</context>
<context position="11551" citStr="Wilks (1978)" startWordPosition="1761" endWordPosition="1762">forth by Tourangeau and Sternberg (1982), who take the view that features &apos;shared&apos; by tenor and vehicle are often at best only analogous features, each limited in its application to one domain or another. Of course, some features or dimensions are quite general, applying across the board to a number of domains (p. 218). Among comparison and interaction theorists, much attention had been paid to selecting the comparisons or interactions in a metaphor. The importance of analogy or correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979), Tourangeau and Sternberg (1982), and Wilks (1978), among others. Various mechanisms have been advanced for highlighting certain comparisons or interactions, including relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al. 1985). Among computational approaches, Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor can be viewed as a formalization of Black&apos;s interaction theory (ibid., p. 129). Source and target domains are viewed as &amp;quot;systems of relationships.&amp;quot; In metaphorical interpretation, an &amp;quot;implicative complex&amp;quot; of the source domain is imposed on the target domain, thereby shaping the features of the targ</context>
<context position="41283" citStr="Wilks 1978" startWordPosition="6395" endWordPosition="6396">successful metonymy. The substitute source or target is used to discover another semantic relation that can be literal, metonymic again, metaphorical, or anomalous. In Figure 1, the presence of a relevant analogy (diamond 3) discriminates metaphorical relations from anomalous ones. No one else (to my knowledge) has emphasized the role of relevance in the discovery of an analogy central to a metaphor though, as noted in Section 2.2, the importance of relevance in recognizing metaphors and the centrality of some analogy have both been discussed. Example 20 &amp;quot;The car drank gasoline&amp;quot; (adapted from Wilks 1978). The form of relevance used is a lexical notion — i.e., the third kind of lexical semantic constraint — that what is relevant in a sentence is given by the sense of the main sentence verb being currently analyzed. Thus, it is claimed that the semantic relation between &apos;car&apos; and &apos;drink&apos; in (20) is metaphorical because there is a preference violation and an underlying relevant analogy between &apos;car&apos; and &apos;animal,&apos; the preferred agent of &apos;drink.&apos; A car is not a type of animal, hence the preference violation. However, what is relevant in (20) is drinking, and there is a relevant analogy that animal</context>
<context position="94538" citStr="Wilks (1978)" startWordPosition="14583" endWordPosition="14584">s the material on metonymy and metaphor in Section 2 in light of the explanation of the met* method given in Sections 3-6. When compared with the Al work described in Section 2, the met* method has three main advantages. First, it contains a detailed treatment of metonymy. Second, it shows the interrelationship between metonymy, metaphor, literalness, and anomaly. Third, it has been programmed. Preference Semantics addresses the recognition of literal, metaphorical, and anomalous relations, but does not have a treatment of metonymy. In the case of Preference Semantics, the theory described in Wilks (1978) has not been implemented, though the projection algorithm was implemented (Modiano 1986) using some parts of CS to supply detail missing from Wilks&apos; original specification. Gentner&apos;s (1983) Structure-Mapping Theory has no treatment of metonymy. The theory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989) and some examples analyzed by it but not, to my knowledge, examples of metaphor or anomaly. Indurkhya&apos;s (1988) Constrained Semantic Transference theory of metaphor has no treatment of metonymy, anomaly or literalness. It has also not been implemented</context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Wilks, Yorick A. (1978). &amp;quot;Making preferences more active.&amp;quot; Artificial Intelligence, 11:197-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>An intelligent analyzer and understander for English.&amp;quot;</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<pages>18--264</pages>
<contexts>
<context position="14655" citStr="Wilks 1975" startWordPosition="2248" endWordPosition="2249"> as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An algorithm matches pairs of semantic formulas, seeking satisfied or violated preferences between them. A satisfied preference indicates a literal semantic relation; a violated preference indicates either a metaphorical or anomalous one. This part of the theory is implemented in a machine translation system (Wilks 1973). To distinguish metaphor from anomaly, a different knowledge structure and a second algorithm </context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks, Yorick A. (1975b). &amp;quot;An intelligent analyzer and understander for English.&amp;quot; Communications of the ACM, 18:264-274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>A preferential pattern-seeking semantics for natural language inference.&amp;quot;</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<pages>6--53</pages>
<contexts>
<context position="14655" citStr="Wilks 1975" startWordPosition="2248" endWordPosition="2249"> as a common one among linguists; Tourangeau and Sternberg (1982) list the following people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell (1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962). To this list one might add Levin (1977). Johnson (1980, p. 50) describes this view as where: metaphor constitutes a violation of selection restriction rules within a given context, where the fact of this violation is supposed to explain the semantic tension one experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An algorithm matches pairs of semantic formulas, seeking satisfied or violated preferences between them. A satisfied preference indicates a literal semantic relation; a violated preference indicates either a metaphorical or anomalous one. This part of the theory is implemented in a machine translation system (Wilks 1973). To distinguish metaphor from anomaly, a different knowledge structure and a second algorithm </context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks,Yorick A. (1975a). &amp;quot;A preferential pattern-seeking semantics for natural language inference.&amp;quot; Artificial Intelligence, 6:53-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>An artificial intelligence approach to machine translation.&amp;quot; In Computer Models of Thought and Language, edited by</title>
<date>1973</date>
<contexts>
<context position="15160" citStr="Wilks 1973" startWordPosition="2320" endWordPosition="2321">experiences in comprehending any live metaphor. The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of a selection restrictions view and a comparison view. In the theory, information about word senses is contained in knowledge structures called &amp;quot;semantic formulas.&amp;quot; An algorithm matches pairs of semantic formulas, seeking satisfied or violated preferences between them. A satisfied preference indicates a literal semantic relation; a violated preference indicates either a metaphorical or anomalous one. This part of the theory is implemented in a machine translation system (Wilks 1973). To distinguish metaphor from anomaly, a different knowledge structure and a second algorithm are used. The algorithm, called projection, operates on a knowledge structure, called a pseudo-text, that contains lists of templates (a further kind of knowledge structure) linked by case ties. A brief example of projection is given for (1). Example 3 &amp;quot;My car drinks gasoline.&amp;quot; Projection operates only on preference violations. The best representation of (1) contains a preference violation, so projection is used. The algorithm compares the template representation for the sentence [my+car drink gasoli</context>
<context position="34268" citStr="Wilks 1973" startWordPosition="5284" endWordPosition="5285">89a) that understanding natural language (or semantic interpretation) be viewed as the integration of constraints from language and from context. Some language constraints are syntactic, while others are semantic. Some 59 Computational Linguistics Volume 17, Number 1 language constraints are lexical constraints; that is, constraints possessed by lexical items (words and fixed phrases). Lexical syntactic constraints include those on word order, number, and tense. This sec tion describes three lexical semantic constraints: preferences, assertions, and a lexical notion of relevance. Preferences (Wilks 1973), selection restrictions (Katz 1964), and expectations (Schank 1975) are the same (see Fass 1989c; Fass and Wilks 1983; Wilks and Fass in press): all are restrictions possessed by senses of lexical items of certain parts of speech about the semantic classes of lexical items with which they co-occur. Thus an adjective sense has a preference for the semantic class of nouns with which it co-occurs and a verb sense has preferences for the semantic classes of nouns that fill its case roles. For example, the main sense of the verb &apos;drink&apos; prefers an animal to fill its agent case role, i.e., it is an</context>
<context position="46013" citStr="Wilks 1973" startWordPosition="7134" endWordPosition="7135">taphorical, and anomalous interpretations are all sought at the same time and there is no ordering such that the literal meaning of a sentence is computed first and then an alternative meaning sought if the literal meaning is defective. Gibbs&apos; other main criticism, concerning the traditional analysis of sentence meaning as composed from word meanings and independent of context, will be discussed in Section 7. 63 Computational Linguistics Volume 17, Number 1 4. Collative Semantics CS is a semantics for natural language processing that extends many of the main ideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks and Fass in press). CS has four components: sense-frames, collation, semantic vectors, and screening. The met* method is part of the process of collation. Fuller and more general descriptions of the four components appear in Fass (1988a; 1989b). Sense-frames are dictionary entries for individual word senses. Sense-frames are composed of other word senses that have their own sense-frames, much like Quillian&apos;s (1967) planes. Each sense-frame consists of two parts, an arcs section and a node section, that correspond to the genus and differentia commonly found </context>
</contexts>
<marker>Wilks, 1973</marker>
<rawString>Wilks, Yorick A. (1973). &amp;quot;An artificial intelligence approach to machine translation.&amp;quot; In Computer Models of Thought and Language, edited by Roger C. Schank and Kenneth M. Colby, 114-151, W.H. Freeman.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yorick A Wilks</author>
<author>Dan C Fass</author>
</authors>
<title>The preference semantics family.&amp;quot;</title>
<journal>Computers and Mathematics with Applications, Special Issue on Semantic Networks in Artificial Intelligence.</journal>
<note>To appear in</note>
<marker>Wilks, Fass, </marker>
<rawString>Wilks, Yorick A. and Fass, Dan C. (In press). &amp;quot;The preference semantics family.&amp;quot; To appear in Computers and Mathematics with Applications, Special Issue on Semantic Networks in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick H Winston</author>
</authors>
<title>Learning by creatifying transfer frames.&amp;quot;</title>
<date>1980</date>
<journal>In Artificial Intelligence: An MIT Perspective,</journal>
<volume>1</volume>
<pages>347--376</pages>
<publisher>MIT Press.</publisher>
<note>edited by</note>
<contexts>
<context position="37455" citStr="Winston 1980" startWordPosition="5800" endWordPosition="5801">movement of the hand.&amp;quot; Semantic relations result from evaluating lexical semantic constraints in sentences. Every semantic relation has a source (a lexical item whose semantic constraints are applied) and a target (a lexical item which receives those constraints). Other terms used to refer to the source and target in a semantic relation include: vehicle and tenor (Richards 1936), subsidiary subject and principal subject (Black 1962), figurative term and literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subject and primary subject (Black 1979), source and destination (Winston 1980), old domain and new domain (Hobbs 1983a), and base and target (Gentner 1983). In CS, seven kinds of semantic relation are distinguished: literal, metonymic, metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may 60 Fass Discriminating Metonymy not be exhaustive — there could be others). Combinations of these seven semantic relations are the basis of (at minimum) literalness, metonymy, metaphor, anomaly, redundancy, contradiction, contrariness, and novelty. Semantic relations belong to two classes, the preference-based and assertion-based classes of relations, dep</context>
</contexts>
<marker>Winston, 1980</marker>
<rawString>Winston, Patrick H. (1980). &amp;quot;Learning by creatifying transfer frames.&amp;quot; In Artificial Intelligence: An MIT Perspective, Volume 1, edited by Patrick H. Winston and Richard H. Brown, 347-376, MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Masa-aki Yamanashi</author>
</authors>
<title>Metonymic interpretation and associative processes in natural language.&amp;quot;</title>
<date>1987</date>
<journal>edited by Makoto Nagao,</journal>
<booktitle>In Language and Artificial Intelligence (Proceedings of an International Symposium on Language and Artificial Intelligence held in Kyoto, Japan,</booktitle>
<pages>16--21</pages>
<institution>Elsevier Science Publishers. Glossary of Main</institution>
<contexts>
<context position="20838" citStr="Yamanashi 1987" startWordPosition="3206" endWordPosition="3207">hor-maps,&amp;quot; a kind of VIEW (ibid., p. 64), are used to represent conventional metaphors and the conceptual information they contain. 2.2 Metonymy Metonymy involves &amp;quot;using one entity to refer to another that is related to it&amp;quot; (Lakoff and Johnson 1980, p. 35). Example 2 &amp;quot;The ham sandwich is waiting for his check.&amp;quot; For example, in (2) the metonymy is that the concept for ham sandwich is related to an aspect of another concept, for &amp;quot;the person who ordered the ham sandwich.&amp;quot; Several attempts have been made to organize instances of metonymy into categories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or &amp;quot;metonymic concepts,&amp;quot; as Lakoff and Johnson call them. A common metonymic concept is PART FOR WHOLE, otherwise known as synechdoche. Example 7 &amp;quot;Dave drank the glasses&amp;quot; (= the liquid in the glasses). Example 8 &amp;quot;The kettle is boiling&amp;quot; (= the liquid in the kettle) (Waldron 1967, p. 186; Yamanashi 1987, p. 78). CONTAINER FOR CONTENTS, another metonymic concept, occurs in (7) between &apos;drink&apos; and the sense of &apos;glasses&apos; meaning &amp;quot;containers,&amp;quot; and also in (8). In (7), &apos;drink&apos; has an object preference for a potable liquid, but there is a preference violation because glasses are not potable liquids. </context>
<context position="22519" citStr="Yamanashi 1987" startWordPosition="3492" endWordPosition="3493">ot a Picasso in his den.&amp;quot; &amp;quot;I hate to read Heidegger.&amp;quot; OBJECT USED FOR USER &amp;quot;The sax has the flu today.&amp;quot; &amp;quot;The BLT is a lousy tipper.&amp;quot;**2 &amp;quot;The buses are on strike.&amp;quot; Example 9 &amp;quot;You&apos;ll find better ideas than that in the library&amp;quot; (Reddy 1979, p. 309). Reddy (1979) has observed that metonymies can occur in chains. He suggests that (9) contains a chain of PART FOR WHOLE metonymies between &apos;ideas&apos; and &apos;library&apos;: the ideas are expressed in words, words are printed on pages, pages are in books, and books are found in a library. Example 10 &amp;quot;I found an old car on the road. The steering wheel was broken&amp;quot; (Yamanashi 1987, p. 79). Example 11 &amp;quot;We had a party in a mysterious room. The walls were painted in psychedelic color&amp;quot; (ibid.). Example 12 A: &amp;quot;I bought an interesting book.&amp;quot; B: &amp;quot;Who is the author?&amp;quot; (ibid.). Example 13 &amp;quot;He happened to die of some disease, though I don&apos;t know what the cause was&amp;quot; (ibid.). Yamanashi (1987) points out that basic metonymic relationships like part-whole and cause-result often also link sentences. According to him, the links in (10) and (11) are PART-WHOLE relations, the one in (12) is PRODUCT-PRODUCER, and the one in (13) is a CAUSE-RESULT relation. There has been some computationa</context>
<context position="102453" citStr="Yamanashi (1987)" startWordPosition="15813" endWordPosition="15814">and for something else — a connection between a concept and an aspect of another concept. The observations also support the view that metaphor&apos;s primary function is understanding, allowing something to be conceived of in terms of something else: the role of analogy is especially crucial to this function. 7.3 Metonymy The treatment of metonymy permits chains of metonymies (Reddy 1979), and allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. 83 Computational Linguistics Volume 17, Number 1 The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987) notes link sentences. An obvious direction in which to extend the present work is toward across-sentence inferences. Example 30 &amp;quot;John drank from the faucet&amp;quot; (Lehnert 1978, p. 221). Example 31 &amp;quot;John filled his canteen at the spring&amp;quot; (Ibid.). Metonymy seems closely related to the work on non-logical inferencing done by Schank (Schank 1973) and the Yale Group (Schank 1975; Schank and Abelson 1977; Schank and Riesbeck 1981). For example, Lehnert (1978) observes that just one inference is required for understanding both (30) and (31). The inference, that water comes from the faucet in (30) and the</context>
</contexts>
<marker>Yamanashi, 1987</marker>
<rawString>Yamanashi, Masa-aki (1987). &amp;quot;Metonymic interpretation and associative processes in natural language.&amp;quot; In Language and Artificial Intelligence (Proceedings of an International Symposium on Language and Artificial Intelligence held in Kyoto, Japan, 16-21 March 1986), edited by Makoto Nagao, 77-86, Elsevier Science Publishers. Glossary of Main Terms Anomalous relation: a semantic relation indicated by a violated preference and the absence of a relevant analogy [see Section 31.</rawString>
</citation>
<citation valid="false">
<title>Assertion: a word sense-based contextual constraint in which semantic information is imposed onto the local context of a word sense [Section 3].</title>
<marker></marker>
<rawString>Assertion: a word sense-based contextual constraint in which semantic information is imposed onto the local context of a word sense [Section 3].</rawString>
</citation>
<citation valid="false">
<title>Collation: a process that discriminates the semantic relation(s) between two word senses by matching the sense-frames for the word senses [Section 4].</title>
<marker></marker>
<rawString>Collation: a process that discriminates the semantic relation(s) between two word senses by matching the sense-frames for the word senses [Section 4].</rawString>
</citation>
<citation valid="false">
<title>Literal relation: a semantic relation indicated by a satisfied preference [Section 3]. Metaphor: a trope in which one entity is used to view another entity to which it bears a partial resemblance [Sections</title>
<pages>2--7</pages>
<marker></marker>
<rawString>Literal relation: a semantic relation indicated by a satisfied preference [Section 3]. Metaphor: a trope in which one entity is used to view another entity to which it bears a partial resemblance [Sections 2-7].</rawString>
</citation>
<citation valid="false">
<title>Metaphorical relation: a semantic relation indicated by a violated preference and the presence of a relevant analogy [Section 3]. Metonymy: a trope in which one entity is used to refer to another that is related to it [Sections</title>
<pages>2--71</pages>
<marker></marker>
<rawString>Metaphorical relation: a semantic relation indicated by a violated preference and the presence of a relevant analogy [Section 3]. Metonymy: a trope in which one entity is used to refer to another that is related to it [Sections 2-71</rawString>
</citation>
<citation valid="false">
<title>Metonymic relation: a semantic relation indicated by failure to satisfy a preference and the presence of one or more conceptual relationships like</title>
<journal>PART-WHOLE [Section</journal>
<volume>3</volume>
<marker></marker>
<rawString>Metonymic relation: a semantic relation indicated by failure to satisfy a preference and the presence of one or more conceptual relationships like PART-WHOLE [Section 3].</rawString>
</citation>
<citation valid="false">
<title>Preference: a word sense-based contextual constraint in which semantic information restricts the local context of a word sense [Section 31.</title>
<marker></marker>
<rawString>Preference: a word sense-based contextual constraint in which semantic information restricts the local context of a word sense [Section 31.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>