<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9984535">
A Generative Entity-Mention Model for Linking Entities with
Knowledge Base
</title>
<author confidence="0.998773">
Xianpei Han Le Sun
</author>
<affiliation confidence="0.8026565">
Institute of Software, Chinese Academy of Sciences
HaiDian District, Beijing, China.
</affiliation>
<email confidence="0.995182">
{xianpei, sunle}@nfs.iscas.ac.cn
</email>
<sectionHeader confidence="0.98288" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99913156">
Linking entities with knowledge base (entity
linking) is a key issue in bridging the textual
data with the structural knowledge base. Due to
the name variation problem and the name
ambiguity problem, the entity linking decisions
are critically depending on the heterogenous
knowledge of entities. In this paper, we propose
a generative probabilistic model, called entity-
mention model, which can leverage
heterogenous entity knowledge (including
popularity knowledge, name knowledge and
context knowledge) for the entity linking task.
In our model, each name mention to be linked
is modeled as a sample generated through a
three-step generative story, and the entity
knowledge is encoded in the distribution of
entities in document P(e), the distribution of
possible names of a specific entity P(s|e), and
the distribution of possible contexts of a
specific entity P(c|e). To find the referent entity
of a name mention, our method combines the
evidences from all the three distributions P(e),
P(s|e) and P(c|e). Experimental results show
that our method can significantly outperform
the traditional methods.
</bodyText>
<sectionHeader confidence="0.995114" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997816">
In recent years, due to the proliferation of
knowledge-sharing communities like Wikipedia 1
and the many research efforts for the automated
knowledge base population from Web like the
Read the Web2 project, more and more large-scale
knowledge bases are available. These knowledge
bases contain rich knowledge about the world’s
entities, their semantic properties, and the semantic
relations between each other. One of the most
notorious examples is Wikipedia: its 2010 English
</bodyText>
<footnote confidence="0.849388">
1 http://www.wikipedia.org/
2 http://rtw.ml.cmu.edu/
</footnote>
<bodyText confidence="0.9925435">
version contains more than 3 million entities and
20 million semantic relations. Bridging these
knowledge bases with the textual data can facilitate
many different tasks such as entity search,
information extraction and text classification. For
example, as shown in Figure 1, knowing the word
Jordan in the document refers to a basketball
player and the word Bulls refers to a NBA team
would be helpful in classifying this document into
the Sport/Basketball class.
</bodyText>
<figure confidence="0.8250275">
Part-of
IS-A
</figure>
<figureCaption confidence="0.999748">
Figure 1. A Demo of Entity Linking
</figureCaption>
<bodyText confidence="0.999227052631579">
A key issue in bridging the knowledge base with
the textual data is linking the entities in a
document with their referents in a knowledge base,
which is usually referred to as the Entity Linking
task. Given a set of name mentions M = {m1,
m2, ..., mk} contained in documents and a
knowledge base KB containing a set of entities E =
{e1, e2, ..., en}, an entity linking system is a
function which links these name
mentions to their referent entities in KB. For
example, in Figure 1 an entity linking system
should link the name mention Jordan to the entity
Michael Jeffrey Jordan and the name mention
Bulls to the entity Chicago Bulls.
The entity linking task, however, is not trivial
due to the name variation problem and the name
ambiguity problem. Name variation means that an
entity can be mentioned in different ways such as
full name, aliases, acronyms and misspellings. For
</bodyText>
<figure confidence="0.9759668">
After a standout career at the University,
joined the Bulls in 1984.
Chicago Bulls
IS-A
NBA Team
Sport Organization
IS-A IS-A
Knowledge Base
NBA
Employer-of
Michael Jeffrey Jordan
Basketball Player
NBA Player
Jordan
IS-A
</figure>
<page confidence="0.711361">
945
</page>
<bodyText confidence="0.999668777777778">
example, the entity Michael Jeffrey Jordan can be
mentioned using more than 10 names, such as
Michael Jordan, MJ and Jordan. The name
ambiguity problem is related to the fact that a
name may refer to different entities in different
contexts. For example, the name Bulls can refer to
more than 20 entities in Wikipedia, such as the
NBA team Chicago Bulls, the football team Belfast
Bulls and the cricket team Queensland Bulls.
Complicated by the name variation problem and
the name ambiguity problem, the entity linking
decisions are critically depending on the
knowledge of entities (Li et al., 2004; Bunescu &amp;
Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten,
2008 and Fader et al., 2009). Based on the previous
work, we found that the following three types of
entity knowledge can provide critical evidence for
the entity linking decisions:
</bodyText>
<listItem confidence="0.796715774193548">
• Popularity Knowledge. The popularity
knowledge of entities tells us the likelihood of an
entity appearing in a document. In entity linking,
the entity popularity knowledge can provide a
priori information to the possible referent entities
of a name mention. For example, without any other
information, the popularity knowledge can tell that
in a Web page the name “Michael Jordan” will
more likely refer to the notorious basketball player
Michael Jeffrey Jordan, rather than the less
popular Berkeley professor Michael I. Jordan.
• Name Knowledge. The name knowledge
tells us the possible names of an entity and the
likelihood of a name referring to a specific entity.
For example, we would expect the name
knowledge tells that both the “MJ” and “Michael
Jordan” are possible names of the basketball
player Michael Jeffrey Jordan, but the “Michael
Jordan” has a larger likelihood. The name
knowledge plays the central role in resolving the
name variation problem, and is also helpful in
resolving the name ambiguity problem.
• Context Knowledge. The context
knowledge tells us the likelihood of an entity
appearing in a specific context. For example, given
the context “__wins NBA MVP”, the name
“Michael Jordan” should more likely refer to the
basketball player Michael Jeffrey Jordan than the
Berkeley professor Michael I. Jordan. Context
knowledge is crucial in solving the name
ambiguities.
</listItem>
<bodyText confidence="0.942138307692308">
Unfortunately, in entity linking system, the
modeling and exploitation of these types of entity
knowledge is not straightforward. As shown above,
these types of knowledge are heterogenous,
making it difficult to be incorporated in the same
model. Furthermore, in most cases the knowledge
of entities is not explicitly given, making it
challenging to extract the entity knowledge from
data.
To resolve the above problems, this paper
proposes a generative probabilistic model, called
entity-mention model, which can leverage the
heterogeneous entity knowledge (including
popularity knowledge, name knowledge and
context knowledge) for the entity linking task. In
our model, each name mention is modeled as a
sample generated through a three-step generative
story, where the entity knowledge is encoded in
three distributions: the entity popularity knowledge
is encoded in the distribution of entities in
document P(e), the entity name knowledge is
encoded in the distribution of possible names of a
specific entity P(s|e), and the entity context
knowledge is encoded in the distribution of
possible contexts of a specific entity P(c|e). The
P(e), P(s|e) and P(c|e) are respectively called the
entity popularity model, the entity name model and
the entity context model. To find the referent entity
of a name mention, our method combines the
evidences from all the three distributions P(e),
P(s|e) and P(c|e). We evaluate our method on both
Wikipedia articles and general newswire
documents. Experimental results show that our
method can significantly improve the entity linking
accuracy.
Our Contributions. Specifically, the main
contributions of this paper are as follows:
1) We propose a new generative model, the
entity-mention model, which can leverage
heterogenous entity knowledge (including
popularity knowledge, name knowledge and
context knowledge) for the entity linking task;
2) By modeling the entity knowledge as
probabilistic distributions, our model has a
statistical foundation, making it different from
most previous ad hoc approaches.
This paper is organized as follows. The entity-
mention model is described in Section 2. The
model estimation is described in Section 3. The
experimental results are presented and discussed in
Section 4. The related work is reviewed in Section
5. Finally we conclude this paper in Section 6.
</bodyText>
<page confidence="0.926002">
946
</page>
<sectionHeader confidence="0.789416" genericHeader="method">
2 The Generative Entity-Mention Model
</sectionHeader>
<subsectionHeader confidence="0.469146">
for Entity Linking
</subsectionHeader>
<bodyText confidence="0.99998425">
In this section we describe the generative entity-
mention model. We first describe the generative
story of our model, then formulate the model and
show how to apply it to the entity linking task.
</bodyText>
<subsectionHeader confidence="0.996216">
2.1 The Generative Story
</subsectionHeader>
<bodyText confidence="0.991386925925926">
In the entity mention model, each name mention is
modeled as a generated sample. For demonstration,
Figure 2 shows two examples of name mention
generation. As shown in Figure 2, the generative
story of a name mention is composed of three steps,
which are detailed as follows:
(i) Firstly, the model chooses the referent
entity e of the name mention from the given
knowledge base, according to the distribution of
entities in document P(e). In Figure 2, the model
chooses the entity “Michael Jeffrey Jordan” for the
first name mention, and the entity “Michael I.
Jordan” for the second name mention;
(ii) Secondly, the model outputs the name s of
the name mention according to the distribution of
possible names of the referent entity P(s|e). In
Figure 2, the model outputs “Jordan” as the name
of the entity “Michael Jeffrey Jordan”, and the
“Michael Jordan” as the name of the entity
“Michael I. Jordan”;
(iii) Finally, the model outputs the context c of
the name mention according to the distribution of
possible contexts of the referent entity P(c|e). In
Figure 2, the model outputs the context “joins
Bulls in 1984” for the first name mention, and the
context “is a professor in UC Berkeley” for the
second name mention.
</bodyText>
<subsectionHeader confidence="0.999079">
2.2 Model
</subsectionHeader>
<bodyText confidence="0.9998872">
Based on the above generative story, the
probability of a name mention m (its context is c
and its name is s) referring to a specific entity e
can be expressed as the following formula (here we
assume that s and c are independent given e):
</bodyText>
<equation confidence="0.918606">
P(m,e)= P(s, c, e)= P(e)P(s  |e)P(c  |e)
</equation>
<bodyText confidence="0.9782725625">
This model incorporates the three types of entity
knowledge we explained earlier: P(e) corresponds
to the popularity knowledge, P(s|e) corresponds to
the name knowledge and P(c|e) corresponds to the
context knowledge.
Figure 2. Two examples of name mention
generation
Given a name mention m, to perform entity
linking, we need to find the entity e which
maximizes the probability P(e|m). Then we can
resolve the entity linking task as follows:
Therefore, the main problem of entity linking is to
estimate the three distributions P(e), P(s|e) and
P(c|e), i.e., to extract the entity knowledge from
data. In Section 3, we will show how to estimate
these three distributions.
Candidate Selection. Because a knowledge base
usually contains millions of entities, it is time-
consuming to compute all P(m,e) scores between a
name mention and all the entities contained in a
knowledge base. To reduce the time required, the
entity linking system employs a candidate selection
process to filter out the impossible referent
candidates of a name mention. In this paper, we
adopt the candidate selection method of
AEPR_KBP system (Han and Zhao, 2009), the
main idea of which is first building a name-to-
entity dictionary using the redirect links,
disambiguation pages, anchor texts of Wikipedia,
then the candidate entities of a name mention are
selected by finding its name’s corresponding entry
in the dictionary.
</bodyText>
<sectionHeader confidence="0.957193" genericHeader="method">
3 Model Estimation
</sectionHeader>
<bodyText confidence="0.9998544">
Section 2 shows that the entity mention model can
decompose the entity linking task into the
estimation of three distributions P(e), P(s|e) and
P(c|e). In this section, we describe the details of the
estimation of these three distributions. We first
</bodyText>
<figure confidence="0.98458875">
Knowledge Base
Entity
Michael Jeffrey Jordan Michael I. Jordan
Jordan
Michael Jordan
Jordan joins Bulls in
1984.
Michael Jordan is a
professor in UC Berkeley.
Name
Mention
947
</figure>
<bodyText confidence="0.956852">
introduce the training data, then describe the
estimation methods.
</bodyText>
<subsectionHeader confidence="0.999635">
3.1 Training Data
</subsectionHeader>
<bodyText confidence="0.999950666666667">
In this paper, the training data of our model is a set
of annotated name mentions M = {m1, m2, ..., mn}.
Each annotated name mention is a triple m={s, e,
c}, where s is the name, e is the referent entity and
c is the context. For example, two annotated name
mentions are as follows:
</bodyText>
<listItem confidence="0.996927">
• Jordan  |Michael Jeffrey Jordan  |... wins his first NBA
MVP in 1991.
• NBA  |National Basketball Association  |... is the pre-
eminent men&apos;s professional basketball league.
</listItem>
<bodyText confidence="0.999145176470588">
In this paper, we focus on the task of linking
entities with Wikipedia, even though the proposed
method can be applied to other resources. We will
only show how to get the training data from
Wikipedia. In Wikipedia, a hyperlink between two
articles is an annotated name mention (Milne &amp;
Witten, 2008): its anchor text is the name and its
target article is the referent entity. For example, in
following hyperlink (in Wiki syntax), the NBA is
the name and the National Basketball Association
is the referent entity.
“He won his first [[National Basketball Association |
NBA]] championship with the Bulls”
Therefore, we can get the training data by
collecting all annotated name mentions from the
hyperlink data of Wikipedia. In total, we collected
more than 23,000,000 annotated name mentions.
</bodyText>
<subsectionHeader confidence="0.997028">
3.2 Entity Popularity Model
</subsectionHeader>
<bodyText confidence="0.998815583333334">
The distribution P(e) encodes the popularity
knowledge as a distribution of entities, i.e., the
P(e1) should be larger than P(e2) if e1 is more
popular than e2. For example, on the Web the
P(Michael Jeffrey Jordan) should be higher than
the P(Michael I. Jordan). In this section, we
estimate the distribution P(e) using a model called
entity popularity model.
Given a knowledge base KB which contains N
entities, in its simplest form, we can assume that
all entities have equal popularity, and the
distribution P(e) can be estimated as:
</bodyText>
<equation confidence="0.983147">
P(e) 1 N
</equation>
<bodyText confidence="0.99991695">
However, this does not reflect well the real
situation because some entities are obviously more
popular than others. To get a more precise
estimation, we observed that a more popular entity
usually appears more times than a less popular
entity in a large text corpus, i.e., more name
mentions refer to this entity. For example, in
Wikipedia the NBA player Michael Jeffrey Jordan
appears more than 10 times than the Berkeley
professor Michael I. Jordan. Based on the above
observation, our entity popularity model uses the
entity frequencies in the name mention data set M
to estimate the distribution P(e) as follows:
where Count(e) is the count of the name mentions
whose referent entity is e, and the |M |is the total
name mention size. The estimation is further
smoothed using the simple add-one smoothing
method for the zero probability problem. For
illustration, Table 1 shows three selected entities’
popularity.
</bodyText>
<table confidence="0.99729275">
Entity Popularity
National Basketball Association 1.73 *10-5
Michael Jeffrey Jordan(NBA player) 8.21 *10-6
Michael I. Jordan(Berkeley Professor) 7.50 *10-8
</table>
<tableCaption confidence="0.999757">
Table 1. Three examples of entity popularity
</tableCaption>
<subsectionHeader confidence="0.969355">
3.3 Entity Name Model
</subsectionHeader>
<bodyText confidence="0.987228785714286">
The distribution P(s|e) encodes the name
knowledge of entities, i.e., for a specific entity e,
its more frequently used name should be assigned a
higher P(s|e) value than the less frequently used
name, and a zero P(s|e) value should be assigned
to those never used names. For instance, we would
expect the P(Michael Jordan|Michael Jeffrey
Jordan) to be high, P(MJ|Michael Jeffrey Jordan)
to be relative high and P(Michael I.
Jordan|Michael Jeffrey Jordan) to be zero.
Intuitively, the name model can be estimated by
first collecting all (entity, name) pairs from the
name mention data set, then using the maximum
likelihood estimation:
</bodyText>
<equation confidence="0.90697025">
 Count e s
( , )
P(s  |e)  Count(e,s)
s
</equation>
<bodyText confidence="0.999985222222222">
where the Count(e,s) is the count of the name
mentions whose referent entity is e and name is s.
However, this method does not work well because
it cannot correctly deal with an unseen entity or an
unseen name. For example, because the name
“MJ” doesn’t refer to the Michael Jeffrey Jordan in
Wikipedia, the name model will not be able to
identify “MJ” as a name of him, even “MJ” is a
popular name of Michael Jeffrey Jordan on Web.
</bodyText>
<page confidence="0.660167">
948
</page>
<bodyText confidence="0.998593153846154">
To better estimate the distribution P(s|e), this
paper proposes a much more generic model, called
entity name model, which can capture the
variations (including full name, aliases, acronyms
and misspellings) of an entity&apos;s name using a
statistical translation model. Given an entity’s
name s, our model assumes that it is a translation
of this entity’s full name f using the IBM model 1
(Brown, et al., 1993). Let ∑ be the vocabulary
containing all words may be used in the name of
entities, the entity name model assumes that a
word in ∑ can be translated through the following
four ways:
</bodyText>
<listItem confidence="0.9340134">
1) It is retained (translated into itself);
2) It is translated into its acronym;
3) It is omitted(translated into the word NULL);
4) It is translated into another word (misspelling
or alias).
</listItem>
<bodyText confidence="0.9982232">
In this way, all name variations of an entity are
captured as the possible translations of its full
name. To illustrate, Figure 3 shows how the full
name “Michael Jeffrey Jordan” can be transalted
into its misspelling name “Micheal Jordan”.
</bodyText>
<figure confidence="0.9858312">
l l
s f
�
P(s|e) = g HE
Name Micheal NULL Jordan
</figure>
<figureCaption confidence="0.999782">
Figure 3. The translation from Michael Jefferey
</figureCaption>
<note confidence="0.353852">
Jordan to Micheal Jordan
</note>
<bodyText confidence="0.999191529411765">
Based on the translation model, P(s|e) can be
written as:
where is a normalization factor, f is the full name
of entity e, lf is the length of f, ls is the length of the
name s, si the ith word of s, fj is the jth word of f and
t(si|fj) is the lexical translation probability which
indicates the probability of a word fj in the full
name will be written as si in the output name.
Now the main problem is to estimate the lexical
translation probability t(si|fj). In this paper, we first
collect the (name, entity full name) pairs from all
annotated name mentions, then get the lexical
translation probability by feeding this data set into
an IBM model 1 training system (we use the
GIZA++ Toolkit3).
Table 2 shows several resulting lexical
translation probabilities through the above process.
</bodyText>
<footnote confidence="0.363309">
3 http://fjoch.com/GIZA++.html
</footnote>
<bodyText confidence="0.99916575">
We can see that the entity name model can capture
the different name variations, such as the acronym
(Michael4M), the misspelling (Michael4Micheal)
and the omission (St. 4 NULL).
</bodyText>
<table confidence="0.957821">
Full name word Name word Probability
Michael Michael 0.77
Michael M 0.008
Michael Micheal 2.64*10-4
Jordan Jordan 0.96
Jordan J 6.13*10-4
St. NULL 0.14
Sir NULL 0.02
</table>
<tableCaption confidence="0.999123">
Table 2. Several lexical translation probabilities
</tableCaption>
<sectionHeader confidence="0.576184" genericHeader="method">
3.4 Entity Context Model
</sectionHeader>
<bodyText confidence="0.947269407407407">
The distribution P(c|e) encodes the context
knowledge of entities, i.e., it will assign a high
P(c|e) value if the entity e frequently appears in the
context c, and will assign a low P(c|e) value if the
entity e rarely appears in the context c. For
example, given the following two contexts:
C1: __wins NBA MVP.
C2: __is a researcher in machine learning.
Then P(C1|Michael Jeffrey Jordan) should be high
because the NBA player Michael Jeffrey Jordan
often appears in C1 and the P(C2|Michael Jeffrey
Jordan) should be extremely low because he rarely
appears in C2.
...
Figure 4. Two entity context models
To estimate the distribution P(c|e), we propose a
method based on language modeling, called entity
context model. In our model, the context of each
name mention m is the word window surrounding
m, and the window size is set to 50 according to
the experiments in (Pedersen et al., 2005).
Specifically, the context knowledge of an entity e
is encoded in an unigram language model:
where Pe(t) is the probability of the term t
appearing in the context of e. In our model, the
term may indicate a word, a named entity
(extracted using the Stanford Named Entity
</bodyText>
<figure confidence="0.998643903225806">
Full Name
Michael
Jeffrey
Jordan
t(si|fj)
l
(
f + 1)
j=
1
=0
__ wins NBA MVP.
Michael Jeffrey Jordan
(NBA Player)
NBA=0.03
MVP=0.008
Basketball=0.02
player=0.005
win=0.00008
professor=0
...
Michael I. Jordan
(Berkeley Professor)
professor=0.003
Berkeley=0.002
machine learning=0.1
researcher = 0.006
NBA = 0
MVP=0
__is a professor in UC
Berkeley.
</figure>
<page confidence="0.52236">
949
</page>
<bodyText confidence="0.981071">
Recognizer4) or a Wikipedia concept (extracted
using the method described in (Han and Zhao,
2010)). Figure 4 shows two entity context models
and the contexts generated using them.
Now, given a context c containing n terms
t1t2...tn, the entity context model estimates the
probability P(c|e) as:
</bodyText>
<equation confidence="0.92881">
P(c I e) = P(t1t2 ...tn I Me) = P. (t, )P. (t2) .... P,, (tn )
</equation>
<bodyText confidence="0.999741157894737">
So the main problem is to estimate Pe(t), the
probability of a term t appearing in the context of
the entity e.
Using the annotated name mention data set M,
we can get the maximum likelihood estimation of
Pe(t) as follows:
where Counte(t) is the frequency of occurrences of
a term t in the contexts of the name mentions
whose referent entity is e.
Because an entity e’s name mentions are usually
not enough to support a robust estimation of Pe(t)
due to the sparse data problem (Chen and
Goodman, 1999), we further smooth Pe(t) using the
Jelinek-Mercer smoothing method (Jelinek and
Mercer, 1980):
where Pg(t) is a general language model which is
estimated using the whole Wikipedia data, and the
optimal value of λ is set to 0.2 through a learning
process shown in Section 4.
</bodyText>
<subsectionHeader confidence="0.703945">
3.5 The NIL Entity Problem
</subsectionHeader>
<bodyText confidence="0.999973133333333">
By estimating P(e), P(s|e) and P(c|e), our method
can effectively link a name mention to its referent
entity contained in a knowledge base.
Unfortunately, there is still the NIL entity problem
(McNamee and Dang, 2009), i.e., the referent
entity may not be contained in the given
knowledge base. In this situation, the name
mention should be linked to the NIL entity.
Traditional methods usually resolve this problem
with an additional classification step (Zheng et al.
2010): a classifier is trained to identify whether a
name mention should be linked to the NIL entity.
Rather than employing an additional step, our
entity mention model seamlessly takes into account
the NIL entity problem. The start assumption of
</bodyText>
<footnote confidence="0.346402">
4 http://nlp.stanford.edu/software/CRF-NER.shtml
</footnote>
<bodyText confidence="0.997600588235294">
our solution is that “If a name mention refers to a
specific entity, then the probability of this name
mention is generated by the specific entity’s model
should be significantly higher than the probability
it is generated by a general language model”.
Based on the above assumption, we first add a
pseudo entity, the NIL entity, into the knowledge
base and assume that the NIL entity generates a
name mention according to the general language
model Pg, without using any entity knowledge;
then we treat the NIL entity in the same way as
other entities: if the probability of a name mention
is generated by the NIL entity is higher than all
other entities in Knowledge base, we link the name
mention to the NIL entity. Based on the above
discussion, we compute the three probabilities of
the NIL entity: P(e), P(s|e) and P(c|e) as follows:
</bodyText>
<sectionHeader confidence="0.999206" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999402">
In this section, we assess the performance of our
method and compare it with the traditional
methods. In following, we first explain the
experimental settings in Section 4.1, 4.2 and 4.3,
then evaluate and discuss the results in Section 4.4.
</bodyText>
<subsectionHeader confidence="0.993122">
4.1 Knowledge Base
</subsectionHeader>
<bodyText confidence="0.999991">
In our experiments, we use the Jan. 30, 2010
English version of Wikipedia as the knowledge
base, which contains over 3 million distinct entities.
</bodyText>
<subsectionHeader confidence="0.993314">
4.2 Data Sets
</subsectionHeader>
<bodyText confidence="0.999948461538462">
To evaluate the entity linking performance, we
adopted two data sets: the first is WikiAmbi, which
is used to evaluate the performance on Wikipedia
articles; the second is TAC_KBP, which is used to
evaluate the performance on general newswire
documents. In following, we describe these two
data sets in detail.
WiWmbi: The WikiAmbi data set contains 1000
annotated name mentions which are randomly
selected from Wikipedia hyperlinks data set (as
shown in Section 3.1, the hyperlinks between
Wikipedia articles are manually annotated name
mentions). In WikiAmbi, there were 207 distinct
</bodyText>
<page confidence="0.661335">
950
</page>
<bodyText confidence="0.999977925925926">
names and each name contains at least two
possible referent entities (on average 6.7 candidate
referent entities for each name) 5 . In our
experiments, the name mentions contained in the
WikiAmbi are removed from the training data.
TAC_KBP: The TAC_KBP is the standard data
set used in the Entity Linking task of the TAC
2009 (McNamee and Dang, 2009). The TAC_KBP
contains 3904 name mentions which are selected
from English newswire articles. For each name
mention, its referent entity in Wikipedia is
manually annotated. Overall, 57% (2229 of 3904)
name mentions’s referent entities are missing in
Wikipedia, so TAC_KBP is also suitable to
evaluate the NIL entity detection performance.
The above two data sets can provide a standard
testbed for the entity linking task. However, there
were still some limitations of these data sets: First,
these data sets only annotate the salient name
mentions in a document, meanwhile many NLP
applications need all name mentions are linked.
Second, these data sets only contain well-formed
documents, but in many real-world applications the
entity linking often be applied to noisy documents
such as product reviews and microblog messages.
In future, we want to develop a data set which can
reflect these real-world settings.
</bodyText>
<subsectionHeader confidence="0.998934">
4.3 Evaluation Criteria
</subsectionHeader>
<bodyText confidence="0.999117333333333">
We adopted the standard performance metrics used
in the Entity Linking task of the TAC 2009
(McNamee and Dang, 2009). These metrics are:
</bodyText>
<listItem confidence="0.992540333333333">
• Micro-Averaged Accuracy (Micro-
Accuracy): measures entity linking accuracy
averaged over all the name mentions;
• Macro-Averaged Accuracy (Macro-
Accuracy): measures entity linking accuracy
averaged over all the target entities.
</listItem>
<bodyText confidence="0.939447">
As in TAC 2009, we used Micro-Accuracy as the
primary performance metric.
</bodyText>
<subsectionHeader confidence="0.998439">
4.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.992168294117647">
We compared our method with three baselines: (1)
The first is the traditional Bag of Words based
method (Cucerzan, 2007): a name mention’s
referent entity is the entity which has the highest
cosine similarity with its context – we denoted it as
BoW; (2) The second is the method described in
5 This is because we want to create a highly ambiguous test
data set
(Medelyan et al., 2008), where a name mention’s
referent entity is the entity which has the largest
average semantic relatedness with the name
mention’s unambiguous context entities – we
denoted it as TopicIndex. (3) The third one is the
same as the method described in (Milne &amp; Witten,
2008), which uses learning techniques to balance
the semantic relatedness, commoness and context
quality – we denoted it as Learning2Link.
</bodyText>
<subsectionHeader confidence="0.837949">
4.4.1 Overall Performance
</subsectionHeader>
<bodyText confidence="0.998989375">
We conduct experiments on both WikiAmbi and
TAC_KBP datasets with several methods: the
baseline BoW; the baseline TopicIndex; the
baseline Learning2Link; the proposed method
using only popularity knowledge (Popu), i.e., the
P(m,e)=P(e); the proposed method with one
component of the model is ablated(this is used to
evaluate the independent contributions of the three
components), correspondingly Popu+Name(i.e.,
the P(m,e)=P(e)P(sje)), Name+Context(i.e., the
P(m,e)=P(cje)P(sje)) and Popu+Context (i.e., the
P(m,e)=P(e)P(cje)); and the full entity mention
model (Full Model). For all methods, the
parameters were configured through 10-fold cross
validation. The overall performance results are
shown in Table 3 and 4.
</bodyText>
<table confidence="0.999419444444445">
Micro-Accuracy Macro-Accuracy
BoW 0.60 0.61
TopicIndex 0.66 0.49
Learning2Link 0.70 0.54
Popu 0.39 0.24
Popu + Name 0.50 0.31
Name+Context 0.70 0.68
Popu+Context 0.72 0.73
Full Model 0.80 0.77
</table>
<tableCaption confidence="0.998084">
Table 3. The overall results on WikiAmbi dataset
</tableCaption>
<table confidence="0.999824666666667">
Micro-Accuracy Macro-Accuracy
BoW 0.72 0.75
TopicIndex 0.80 0.76
Learning2Link 0.83 0.79
Popu 0.60 0.53
Popu + Name 0.63 0.59
Name+Context 0.81 0.78
Popu+Context 0.84 0.83
Full Model 0.86 0.88
</table>
<tableCaption confidence="0.999654">
Table 4. The overall results on TAC-KBP dataset
</tableCaption>
<bodyText confidence="0.8091005">
From the results in Table 3 and 4, we can make the
following observations:
1) Compared with the traditional methods,
our entity mention model can achieve a significant
</bodyText>
<page confidence="0.771688">
951
</page>
<bodyText confidence="0.996585">
performance improvement: In WikiAmbi and
TAC_KBP datasets, compared with the BoW
baseline, our method respectively gets 20% and
14% micro-accuracy improvement; compared with
the TopicIndex baseline, our method respectively
gets 14% and 6% micro-accuracy improvement;
compared with the Learning2Link baseline, our
method respectively gets 10% and 3% micro-
accuracy improvement.
</bodyText>
<listItem confidence="0.571814">
2) By incorporating more entity knowledge,
our method can significantly improve the entity
linking performance: When only using the
popularity knowledge, our method can only
achieve 49.5% micro-accuracy. By adding the
name knowledge, our method can achieve 56.5%
micro-accuracy, a 7% improvement over the Popu.
By further adding the context knowledge, our
method can achieve 83% micro-accuracy, a 33.5%
improvement over Popu and a 26.5% improvement
over Popu+Name.
3) All three types of entity knowledge
</listItem>
<bodyText confidence="0.997199411764706">
contribute to the final performance improvement,
and the context knowledge contributes the most:
By respectively ablating the popularity knowledge,
the name knowledge and the context knowledge,
the performance of our model correspondingly
reduces 7.5%, 5% and 26.5%.
NIL Entity Detection Performance. To
compare the performances of resolving the NIL
entity problem, Table 5 shows the micro-
accuracies of different systems on the TAC_KBP
data set (where All is the whole data set, NIL only
contains the name mentions whose referent entity
is NIL, InKB only contains the name mentions
whose referent entity is contained in the
knowledge base). From Table 5 we can see that our
method can effectively detect the NIL entity
meanwhile retaining the high InKB accuracy.
</bodyText>
<table confidence="0.9989474">
All NIL InKB
BoW 0.72 0.77 0.65
TopicIndex 0.80 0.91 0.65
Learning2Link 0.83 0.90 0.73
Full Model 0.86 0.90 0.79
</table>
<tableCaption confidence="0.9084095">
Table 5. The NIL entity detection performance on
the TAC KBP data set
</tableCaption>
<subsectionHeader confidence="0.679859">
4.4.2 Optimizing Parameters
</subsectionHeader>
<bodyText confidence="0.999675125">
Our model needs to tune one parameter: the
Jelinek-Mercer smoothing parameter A used in the
entity context model. Intuitively, a smaller A
means that the general language model plays a
more important role. Figure 5 plots the tradeoff. In
both WikiAmbi and TAC_KBP data sets, Figure 5
shows that a A value 0.2 will result in the best
performance.
</bodyText>
<figureCaption confidence="0.985767">
Figure 5. The micro-accuracy vs. A
</figureCaption>
<subsectionHeader confidence="0.587357">
4.4.3 Detailed Analysis
</subsectionHeader>
<bodyText confidence="0.995316666666667">
To better understand the reasons why and how the
proposed method works well, in this Section we
analyze our method in detail.
The Effect of Incorporating Heterogenous
Entity Knowledge. The first advantage of our
method is the entity mention model can
incorporate heterogeneous entity knowledge. The
Table 3 and 4 have shown that, by incorporating
heterogenous entity knowledge (including the
name knowledge, the popularity knowledge and
the context knowledge), the entity linking
performance can obtain a significant improvement.
</bodyText>
<figureCaption confidence="0.747122">
Figure 6. The performance vs. training mention
</figureCaption>
<bodyText confidence="0.985023909090909">
size on WikiAmbi data set
The Effect of Better Entity Knowledge
Extraction. The second advantage of our method
is that, by representing the entity knowledge as
probabilistic distributions, our model has a
statistical foundation and can better extract the
entity knowledge using more training data through
the entity popularity model, the entity name model
and the entity context model. For instance, we can
train a better entity context model P(c|e) using
more name mentions. To find whether a better
</bodyText>
<page confidence="0.601515">
952
</page>
<bodyText confidence="0.999573666666667">
entity knowledge extraction will result in a better
performance, Figure 6 plots the micro-accuray
along with the size of the training data on name
mentions for P(c|e) of each entity e. From Figure
6, we can see that when more training data is used,
the performance increases.
</bodyText>
<subsectionHeader confidence="0.736999">
4.4.4 Comparision with State-of-the-Art
</subsectionHeader>
<bodyText confidence="0.986168">
Performance
We also compared our method with the state-of-
the-art entity linking systems in the TAC 2009
KBP track (McNamee and Dang, 2009). Figure 7
plots the comparison with the top five
performances in TAC 2009 KBP track. From
Figure 7, we can see that our method can
outperform the state-of-the-art approaches:
compared with the best ranking system, our
method can achieve a 4% performance
improvement.
</bodyText>
<figureCaption confidence="0.791881">
Figure 7. A comparison with top 5 TAC 2009
KBP systems
</figureCaption>
<sectionHeader confidence="0.999653" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999983888888889">
In this section, we briefly review the related work.
To the date, most entity linking systems employed
the context similarity based methods. The essential
idea was to extract the discriminative features of an
entity from its description, then link a name
mention to the entity which has the largest context
similarity with it. Cucerzan (2007) proposed a Bag
of Words based method, which represents each
target entity as a vector of terms, then the
similarity between a name mention and an entity
was computed using the cosine similarity measure.
Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca
(2006), Fader et al. (2009) extended the BoW
model by incorporating more entity knowledge
such as popularity knowledge, entity category
knowledge, etc. Zheng et al. (2010), Dredze et al.
(2010), Zhang et al. (2010) and Zhou et al. (2010)
employed the learning to rank techniques which
can further take the relations between candidate
entities into account. Because the context
similarity based methods can only represent the
entity knowledge as features, the main drawback of
it was the difficulty to incorporate heterogenous
entity knowledge.
Recently there were also some entity linking
methods based on inter-dependency. These
methods assumed that the entities in the same
document are related to each other, thus the
referent entity of a name mention is the entity
which is most related to its contextual entities.
Medelyan et al. (2008) found the referent entity of
a name mention by computing the weighted
average of semantic relatedness between the
candidate entity and its unambiguous contextual
entities. Milne and Witten (2008) extended
Medelyan et al. (2008) by adopting learning-based
techniques to balance the semantic relatedness,
commoness and context quality. Kulkarni et al.
(2009) proposed a method which collectively
resolves the entity linking tasks in a document as
an optimization problem. The drawback of the
inter-dependency based methods is that they are
usually specially designed to the leverage of
semantic relations, doesn’t take the other types of
entity knowledge into consideration.
</bodyText>
<sectionHeader confidence="0.997989" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999992285714286">
This paper proposes a generative probabilistic
model, the entity-mention model, for the entity
linking task. The main advantage of our model is it
can incorporate multiple types of heterogenous
entity knowledge. Furthermore, our model has a
statistical foundation, making the entity knowledge
extraction approach different from most previous
ad hoc approaches. Experimental results show that
our method can achieve competitive performance.
In our method, we did not take into account the
dependence between entities in the same document.
This aspect could be complementary to those we
considered in this paper. For our future work, we
can integrate such dependencies in our model.
</bodyText>
<sectionHeader confidence="0.996654" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.967456714285714">
The work is supported by the National Natural
Science Foundation of China under Grants no.
60773027, 60736044, 90920010, 61070106 and
61003117, and the National High Technology
Development 863 Program of China under Grants
no. 2008AA01Z145. Moreover, we sincerely thank
the reviewers for their valuable comments.
</bodyText>
<page confidence="0.912588">
953
</page>
<sectionHeader confidence="0.995346" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999915108433735">
Adafre, S. F. &amp; de Rijke, M. 2005. Discovering missing
links in Wikipedia. In: Proceedings of the 3rd
international workshop on Link discovery.
Bunescu, R. &amp; Pasca, M. 2006. Using encyclopedic
knowledge for named entity disambiguation. In:
Proceedings of EACL, vol. 6.
Brown, P., Pietra, S. D., Pietra, V. D., and Mercer, R.
1993. The mathematics of statistical machine
translation: parameter estimation. Computational
Linguistics, 19(2), 263-31.
Chen, S. F. &amp; Goodman, J. 1999. An empirical study of
smoothing techniques for language modeling. In
Computer Speech and Language, London; Orlando:
Academic Press, c1986-, pp. 359-394.
Cucerzan, S. 2007. Large-scale named entity
disambiguation based on Wikipedia data. In:
Proceedings of EMNLP-CoNLL, pp. 708-716.
Dredze, M., McNamee, P., Rao, D., Gerber, A. &amp; Finin,
T. 2010. Entity Disambiguation for Knowledge Base
Population. In: Proceedings of the 23rd International
Conference on Computational Linguistics.
Fader, A., Soderland, S., Etzioni, O. &amp; Center, T. 2009.
Scaling Wikipedia-based named entity
disambiguation to arbitrary web text. In: Proceedings
of Wiki-AI Workshop at IJCAI, vol. 9.
Han, X. &amp; Zhao, J. 2009. NLPR_KBP in TAC 2009
KBP Track: A Two-Stage Method to Entity Linking.
In: Proceeding of Text Analysis Conference.
Han, X. &amp; Zhao, J. 2010. Structural semantic
relatedness: a knowledge-based method to named
entity disambiguation. In: Proceedings of the 48th
Annual Meeting of the Association for
Computational Linguistics.
Jelinek, Frederick and Robert L. Mercer. 1980.
Interpolated estimation of Markov source parameters
from sparse data. In: Proceedings of the Workshop
on Pattern Recognition in Practice.
Kulkarni, S., Singh, A., Ramakrishnan, G. &amp;
Chakrabarti, S. 2009. Collective annotation of
Wikipedia entities in web text. In: Proceedings of the
15th ACM SIGKDD international conference on
Knowledge discovery and data mining, pp. 457-466.
Li, X., Morie, P. &amp; Roth, D. 2004. Identification and
tracing of ambiguous names: Discriminative and
generative approaches. In: Proceedings of the
National Conference on Artificial Intelligence, pp.
419-424.
McNamee, P. &amp; Dang, H. T. 2009. Overview of the
TAC 2009 Knowledge Base Population Track. In:
Proceeding of Text Analysis Conference.
Milne, D. &amp; Witten, I. H. 2008. Learning to link with
Wikipedia. In: Proceedings of the 17th ACM
conference on Conference on information and
knowledge management.
Milne, D., et al. 2006. Mining Domain-Specific
Thesauri from Wikipedia: A case study. In Proc. of
IEEE/WIC/ACM WI.
Medelyan, O., Witten, I. H. &amp; Milne, D. 2008. Topic
indexing with Wikipedia. In: Proceedings of the
AAAI WikiAI workshop.
Mihalcea, R. &amp; Csomai, A. 2007. Wikify!: linking
documents to encyclopedic knowledge. In:
Proceedings of the sixteenth ACM conference on
Conference on information and knowledge
management, pp. 233-242.
Pedersen, T., Purandare, A. &amp; Kulkarni, A. 2005. Name
discrimination by clustering similar contexts.
Computational Linguistics and Intelligent Text
Processing, pp. 226-237.
Zhang, W., Su, J., Tan, Chew Lim &amp; Wang, W. T.
2010. Entity Linking Leveraging Automatically
Generated Annotation. In: Proceedings of the 23rd
International Conference on Computational
Linguistics (Coling 2010).
Zheng, Z., Li, F., Huang, M. &amp; Zhu, X. 2010. Learning
to Link Entities with Knowledge Base. In: The
Proceedings of the Annual Conference of the North
American Chapter of the ACL.
Zhou, Y., Nie, L., Rouhani-Kalleh, O., Vasile, F. &amp;
Gaffney, S. 2010. Resolving Surface Forms to
Wikipedia Topics. In: Proceedings of the 23rd
International Conference on Computational
Linguistics (Coling 2010), pp. 1335-1343.
</reference>
<page confidence="0.940011">
954
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.284772">
<title confidence="0.999951">A Generative Entity-Mention Model for Linking Entities</title>
<author confidence="0.7631705">Knowledge Base Xianpei Han Le_Sun</author>
<affiliation confidence="0.7851365">Institute of Software, Chinese Academy of HaiDian District, Beijing, China.</affiliation>
<email confidence="0.972652">xianpei@nfs.iscas.ac.cn</email>
<email confidence="0.972652">sunle@nfs.iscas.ac.cn</email>
<abstract confidence="0.998786961538461">Linking entities with knowledge base (entity linking) is a key issue in bridging the textual data with the structural knowledge base. Due to the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the heterogenous knowledge of entities. In this paper, we propose generative probabilistic model, called entitywhich can leverage heterogenous entity knowledge (including knowledge for the entity linking task. In our model, each name mention to be linked is modeled as a sample generated through a three-step generative story, and the entity knowledge is encoded in the distribution of in document the distribution of names of a specific entity and the distribution of possible contexts of a entity To find the referent entity of a name mention, our method combines the from all the three distributions Experimental results show that our method can significantly outperform the traditional methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S F Adafre</author>
<author>M de Rijke</author>
</authors>
<title>Discovering missing links in Wikipedia. In:</title>
<date>2005</date>
<booktitle>Proceedings of the 3rd international workshop on Link discovery.</booktitle>
<marker>Adafre, de Rijke, 2005</marker>
<rawString>Adafre, S. F. &amp; de Rijke, M. 2005. Discovering missing links in Wikipedia. In: Proceedings of the 3rd international workshop on Link discovery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>M Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation. In:</title>
<date>2006</date>
<booktitle>Proceedings of EACL,</booktitle>
<volume>6</volume>
<contexts>
<context position="4114" citStr="Bunescu &amp; Pasca, 2006" startWordPosition="645" endWordPosition="648">xample, the entity Michael Jeffrey Jordan can be mentioned using more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls. Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu &amp; Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions: • Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the name “Michael Jordan” w</context>
<context position="32234" citStr="Bunescu &amp; Pasca (2006)" startWordPosition="5192" endWordPosition="5195"> KBP systems 5 Related Work In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on </context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Bunescu, R. &amp; Pasca, M. 2006. Using encyclopedic knowledge for named entity disambiguation. In: Proceedings of EACL, vol. 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S D Pietra</author>
<author>V D Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263--31</pages>
<contexts>
<context position="16280" citStr="Brown, et al., 1993" startWordPosition="2620" endWordPosition="2623">ecause the name “MJ” doesn’t refer to the Michael Jeffrey Jordan in Wikipedia, the name model will not be able to identify “MJ” as a name of him, even “MJ” is a popular name of Michael Jeffrey Jordan on Web. 948 To better estimate the distribution P(s|e), this paper proposes a much more generic model, called entity name model, which can capture the variations (including full name, aliases, acronyms and misspellings) of an entity&apos;s name using a statistical translation model. Given an entity’s name s, our model assumes that it is a translation of this entity’s full name f using the IBM model 1 (Brown, et al., 1993). Let ∑ be the vocabulary containing all words may be used in the name of entities, the entity name model assumes that a word in ∑ can be translated through the following four ways: 1) It is retained (translated into itself); 2) It is translated into its acronym; 3) It is omitted(translated into the word NULL); 4) It is translated into another word (misspelling or alias). In this way, all name variations of an entity are captured as the possible translations of its full name. To illustrate, Figure 3 shows how the full name “Michael Jeffrey Jordan” can be transalted into its misspelling name “M</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, P., Pietra, S. D., Pietra, V. D., and Mercer, R. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2), 263-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
<author>J Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1999</date>
<booktitle>In Computer Speech and Language,</booktitle>
<pages>359--394</pages>
<publisher>Academic Press,</publisher>
<location>London; Orlando:</location>
<contexts>
<context position="20635" citStr="Chen and Goodman, 1999" startWordPosition="3366" endWordPosition="3369">entity context model estimates the probability P(c|e) as: P(c I e) = P(t1t2 ...tn I Me) = P. (t, )P. (t2) .... P,, (tn ) So the main problem is to estimate Pe(t), the probability of a term t appearing in the context of the entity e. Using the annotated name mention data set M, we can get the maximum likelihood estimation of Pe(t) as follows: where Counte(t) is the frequency of occurrences of a term t in the contexts of the name mentions whose referent entity is e. Because an entity e’s name mentions are usually not enough to support a robust estimation of Pe(t) due to the sparse data problem (Chen and Goodman, 1999), we further smooth Pe(t) using the Jelinek-Mercer smoothing method (Jelinek and Mercer, 1980): where Pg(t) is a general language model which is estimated using the whole Wikipedia data, and the optimal value of λ is set to 0.2 through a learning process shown in Section 4. 3.5 The NIL Entity Problem By estimating P(e), P(s|e) and P(c|e), our method can effectively link a name mention to its referent entity contained in a knowledge base. Unfortunately, there is still the NIL entity problem (McNamee and Dang, 2009), i.e., the referent entity may not be contained in the given knowledge base. In </context>
</contexts>
<marker>Chen, Goodman, 1999</marker>
<rawString>Chen, S. F. &amp; Goodman, J. 1999. An empirical study of smoothing techniques for language modeling. In Computer Speech and Language, London; Orlando: Academic Press, c1986-, pp. 359-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data. In:</title>
<date>2007</date>
<booktitle>Proceedings of EMNLP-CoNLL,</booktitle>
<pages>708--716</pages>
<contexts>
<context position="4130" citStr="Cucerzan, 2007" startWordPosition="649" endWordPosition="650">ael Jeffrey Jordan can be mentioned using more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls. Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu &amp; Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions: • Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the name “Michael Jordan” will more likely </context>
<context position="25440" citStr="Cucerzan, 2007" startWordPosition="4138" endWordPosition="4139">tings. 4.3 Evaluation Criteria We adopted the standard performance metrics used in the Entity Linking task of the TAC 2009 (McNamee and Dang, 2009). These metrics are: • Micro-Averaged Accuracy (MicroAccuracy): measures entity linking accuracy averaged over all the name mentions; • Macro-Averaged Accuracy (MacroAccuracy): measures entity linking accuracy averaged over all the target entities. As in TAC 2009, we used Micro-Accuracy as the primary performance metric. 4.4 Experimental Results We compared our method with three baselines: (1) The first is the traditional Bag of Words based method (Cucerzan, 2007): a name mention’s referent entity is the entity which has the highest cosine similarity with its context – we denoted it as BoW; (2) The second is the method described in 5 This is because we want to create a highly ambiguous test data set (Medelyan et al., 2008), where a name mention’s referent entity is the entity which has the largest average semantic relatedness with the name mention’s unambiguous context entities – we denoted it as TopicIndex. (3) The third one is the same as the method described in (Milne &amp; Witten, 2008), which uses learning techniques to balance the semantic relatednes</context>
<context position="31982" citStr="Cucerzan (2007)" startWordPosition="5152" endWordPosition="5153"> TAC 2009 KBP track. From Figure 7, we can see that our method can outperform the state-of-the-art approaches: compared with the best ranking system, our method can achieve a 4% performance improvement. Figure 7. A comparison with top 5 TAC 2009 KBP systems 5 Related Work In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into accoun</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Cucerzan, S. 2007. Large-scale named entity disambiguation based on Wikipedia data. In: Proceedings of EMNLP-CoNLL, pp. 708-716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dredze</author>
<author>P McNamee</author>
<author>D Rao</author>
<author>A Gerber</author>
<author>T Finin</author>
</authors>
<title>Entity Disambiguation for Knowledge Base Population. In:</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="32421" citStr="Dredze et al. (2010)" startWordPosition="5221" endWordPosition="5224">as to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to</context>
</contexts>
<marker>Dredze, McNamee, Rao, Gerber, Finin, 2010</marker>
<rawString>Dredze, M., McNamee, P., Rao, D., Gerber, A. &amp; Finin, T. 2010. Entity Disambiguation for Knowledge Base Population. In: Proceedings of the 23rd International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fader</author>
<author>S Soderland</author>
<author>O Etzioni</author>
<author>T Center</author>
</authors>
<title>Scaling Wikipedia-based named entity disambiguation to arbitrary web text. In:</title>
<date>2009</date>
<booktitle>Proceedings of Wiki-AI Workshop at IJCAI,</booktitle>
<volume>9</volume>
<contexts>
<context position="4176" citStr="Fader et al., 2009" startWordPosition="656" endWordPosition="659"> more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls. Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu &amp; Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions: • Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the name “Michael Jordan” will more likely refer to the notorious basketball player Micha</context>
<context position="32255" citStr="Fader et al. (2009)" startWordPosition="5196" endWordPosition="5199">ork In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. The</context>
</contexts>
<marker>Fader, Soderland, Etzioni, Center, 2009</marker>
<rawString>Fader, A., Soderland, S., Etzioni, O. &amp; Center, T. 2009. Scaling Wikipedia-based named entity disambiguation to arbitrary web text. In: Proceedings of Wiki-AI Workshop at IJCAI, vol. 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Han</author>
<author>J Zhao</author>
</authors>
<title>NLPR_KBP in TAC</title>
<date>2009</date>
<contexts>
<context position="11000" citStr="Han and Zhao, 2009" startWordPosition="1745" endWordPosition="1748">tributions P(e), P(s|e) and P(c|e), i.e., to extract the entity knowledge from data. In Section 3, we will show how to estimate these three distributions. Candidate Selection. Because a knowledge base usually contains millions of entities, it is timeconsuming to compute all P(m,e) scores between a name mention and all the entities contained in a knowledge base. To reduce the time required, the entity linking system employs a candidate selection process to filter out the impossible referent candidates of a name mention. In this paper, we adopt the candidate selection method of AEPR_KBP system (Han and Zhao, 2009), the main idea of which is first building a name-toentity dictionary using the redirect links, disambiguation pages, anchor texts of Wikipedia, then the candidate entities of a name mention are selected by finding its name’s corresponding entry in the dictionary. 3 Model Estimation Section 2 shows that the entity mention model can decompose the entity linking task into the estimation of three distributions P(e), P(s|e) and P(c|e). In this section, we describe the details of the estimation of these three distributions. We first Knowledge Base Entity Michael Jeffrey Jordan Michael I. Jordan Jor</context>
</contexts>
<marker>Han, Zhao, 2009</marker>
<rawString>Han, X. &amp; Zhao, J. 2009. NLPR_KBP in TAC 2009 KBP Track: A Two-Stage Method to Entity Linking. In: Proceeding of Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Han</author>
<author>J Zhao</author>
</authors>
<title>Structural semantic relatedness: a knowledge-based method to named entity disambiguation. In:</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="19872" citStr="Han and Zhao, 2010" startWordPosition="3227" endWordPosition="3230">e(t) is the probability of the term t appearing in the context of e. In our model, the term may indicate a word, a named entity (extracted using the Stanford Named Entity Full Name Michael Jeffrey Jordan t(si|fj) l ( f + 1) j= 1 =0 __ wins NBA MVP. Michael Jeffrey Jordan (NBA Player) NBA=0.03 MVP=0.008 Basketball=0.02 player=0.005 win=0.00008 professor=0 ... Michael I. Jordan (Berkeley Professor) professor=0.003 Berkeley=0.002 machine learning=0.1 researcher = 0.006 NBA = 0 MVP=0 __is a professor in UC Berkeley. 949 Recognizer4) or a Wikipedia concept (extracted using the method described in (Han and Zhao, 2010)). Figure 4 shows two entity context models and the contexts generated using them. Now, given a context c containing n terms t1t2...tn, the entity context model estimates the probability P(c|e) as: P(c I e) = P(t1t2 ...tn I Me) = P. (t, )P. (t2) .... P,, (tn ) So the main problem is to estimate Pe(t), the probability of a term t appearing in the context of the entity e. Using the annotated name mention data set M, we can get the maximum likelihood estimation of Pe(t) as follows: where Counte(t) is the frequency of occurrences of a term t in the contexts of the name mentions whose referent enti</context>
</contexts>
<marker>Han, Zhao, 2010</marker>
<rawString>Han, X. &amp; Zhao, J. 2010. Structural semantic relatedness: a knowledge-based method to named entity disambiguation. In: Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
<author>Robert L Mercer</author>
</authors>
<title>Interpolated estimation of Markov source parameters from sparse data. In:</title>
<date>1980</date>
<booktitle>Proceedings of the Workshop on Pattern Recognition in Practice.</booktitle>
<contexts>
<context position="20729" citStr="Jelinek and Mercer, 1980" startWordPosition="3379" endWordPosition="3382"> (t, )P. (t2) .... P,, (tn ) So the main problem is to estimate Pe(t), the probability of a term t appearing in the context of the entity e. Using the annotated name mention data set M, we can get the maximum likelihood estimation of Pe(t) as follows: where Counte(t) is the frequency of occurrences of a term t in the contexts of the name mentions whose referent entity is e. Because an entity e’s name mentions are usually not enough to support a robust estimation of Pe(t) due to the sparse data problem (Chen and Goodman, 1999), we further smooth Pe(t) using the Jelinek-Mercer smoothing method (Jelinek and Mercer, 1980): where Pg(t) is a general language model which is estimated using the whole Wikipedia data, and the optimal value of λ is set to 0.2 through a learning process shown in Section 4. 3.5 The NIL Entity Problem By estimating P(e), P(s|e) and P(c|e), our method can effectively link a name mention to its referent entity contained in a knowledge base. Unfortunately, there is still the NIL entity problem (McNamee and Dang, 2009), i.e., the referent entity may not be contained in the given knowledge base. In this situation, the name mention should be linked to the NIL entity. Traditional methods usual</context>
</contexts>
<marker>Jelinek, Mercer, 1980</marker>
<rawString>Jelinek, Frederick and Robert L. Mercer. 1980. Interpolated estimation of Markov source parameters from sparse data. In: Proceedings of the Workshop on Pattern Recognition in Practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulkarni</author>
<author>A Singh</author>
<author>G Ramakrishnan</author>
<author>S Chakrabarti</author>
</authors>
<title>Collective annotation of Wikipedia entities in web text. In:</title>
<date>2009</date>
<booktitle>Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>457--466</pages>
<contexts>
<context position="33426" citStr="Kulkarni et al. (2009)" startWordPosition="5374" endWordPosition="5377">tity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entities. Medelyan et al. (2008) found the referent entity of a name mention by computing the weighted average of semantic relatedness between the candidate entity and its unambiguous contextual entities. Milne and Witten (2008) extended Medelyan et al. (2008) by adopting learning-based techniques to balance the semantic relatedness, commoness and context quality. Kulkarni et al. (2009) proposed a method which collectively resolves the entity linking tasks in a document as an optimization problem. The drawback of the inter-dependency based methods is that they are usually specially designed to the leverage of semantic relations, doesn’t take the other types of entity knowledge into consideration. 6 Conclusions and Future Work This paper proposes a generative probabilistic model, the entity-mention model, for the entity linking task. The main advantage of our model is it can incorporate multiple types of heterogenous entity knowledge. Furthermore, our model has a statistical </context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Kulkarni, S., Singh, A., Ramakrishnan, G. &amp; Chakrabarti, S. 2009. Collective annotation of Wikipedia entities in web text. In: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 457-466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>P Morie</author>
<author>D Roth</author>
</authors>
<title>Identification and tracing of ambiguous names: Discriminative and generative approaches. In:</title>
<date>2004</date>
<booktitle>Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>419--424</pages>
<contexts>
<context position="4091" citStr="Li et al., 2004" startWordPosition="641" endWordPosition="644">Jordan IS-A 945 example, the entity Michael Jeffrey Jordan can be mentioned using more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls. Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu &amp; Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions: • Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the </context>
</contexts>
<marker>Li, Morie, Roth, 2004</marker>
<rawString>Li, X., Morie, P. &amp; Roth, D. 2004. Identification and tracing of ambiguous names: Discriminative and generative approaches. In: Proceedings of the National Conference on Artificial Intelligence, pp. 419-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P McNamee</author>
<author>H T Dang</author>
</authors>
<title>Knowledge Base Population Track. In: Proceeding of Text Analysis Conference.</title>
<date>2009</date>
<journal>Overview of the TAC</journal>
<contexts>
<context position="21154" citStr="McNamee and Dang, 2009" startWordPosition="3452" endWordPosition="3455">t enough to support a robust estimation of Pe(t) due to the sparse data problem (Chen and Goodman, 1999), we further smooth Pe(t) using the Jelinek-Mercer smoothing method (Jelinek and Mercer, 1980): where Pg(t) is a general language model which is estimated using the whole Wikipedia data, and the optimal value of λ is set to 0.2 through a learning process shown in Section 4. 3.5 The NIL Entity Problem By estimating P(e), P(s|e) and P(c|e), our method can effectively link a name mention to its referent entity contained in a knowledge base. Unfortunately, there is still the NIL entity problem (McNamee and Dang, 2009), i.e., the referent entity may not be contained in the given knowledge base. In this situation, the name mention should be linked to the NIL entity. Traditional methods usually resolve this problem with an additional classification step (Zheng et al. 2010): a classifier is trained to identify whether a name mention should be linked to the NIL entity. Rather than employing an additional step, our entity mention model seamlessly takes into account the NIL entity problem. The start assumption of 4 http://nlp.stanford.edu/software/CRF-NER.shtml our solution is that “If a name mention refers to a </context>
<context position="23917" citStr="McNamee and Dang, 2009" startWordPosition="3903" endWordPosition="3906">: The WikiAmbi data set contains 1000 annotated name mentions which are randomly selected from Wikipedia hyperlinks data set (as shown in Section 3.1, the hyperlinks between Wikipedia articles are manually annotated name mentions). In WikiAmbi, there were 207 distinct 950 names and each name contains at least two possible referent entities (on average 6.7 candidate referent entities for each name) 5 . In our experiments, the name mentions contained in the WikiAmbi are removed from the training data. TAC_KBP: The TAC_KBP is the standard data set used in the Entity Linking task of the TAC 2009 (McNamee and Dang, 2009). The TAC_KBP contains 3904 name mentions which are selected from English newswire articles. For each name mention, its referent entity in Wikipedia is manually annotated. Overall, 57% (2229 of 3904) name mentions’s referent entities are missing in Wikipedia, so TAC_KBP is also suitable to evaluate the NIL entity detection performance. The above two data sets can provide a standard testbed for the entity linking task. However, there were still some limitations of these data sets: First, these data sets only annotate the salient name mentions in a document, meanwhile many NLP applications need </context>
<context position="31302" citStr="McNamee and Dang, 2009" startWordPosition="5038" endWordPosition="5041">e entity name model and the entity context model. For instance, we can train a better entity context model P(c|e) using more name mentions. To find whether a better 952 entity knowledge extraction will result in a better performance, Figure 6 plots the micro-accuray along with the size of the training data on name mentions for P(c|e) of each entity e. From Figure 6, we can see that when more training data is used, the performance increases. 4.4.4 Comparision with State-of-the-Art Performance We also compared our method with the state-ofthe-art entity linking systems in the TAC 2009 KBP track (McNamee and Dang, 2009). Figure 7 plots the comparison with the top five performances in TAC 2009 KBP track. From Figure 7, we can see that our method can outperform the state-of-the-art approaches: compared with the best ranking system, our method can achieve a 4% performance improvement. Figure 7. A comparison with top 5 TAC 2009 KBP systems 5 Related Work In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention</context>
</contexts>
<marker>McNamee, Dang, 2009</marker>
<rawString>McNamee, P. &amp; Dang, H. T. 2009. Overview of the TAC 2009 Knowledge Base Population Track. In: Proceeding of Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>I H Witten</author>
</authors>
<title>Learning to link with Wikipedia. In:</title>
<date>2008</date>
<booktitle>Proceedings of the 17th ACM conference on Conference on information and knowledge management.</booktitle>
<contexts>
<context position="33265" citStr="Milne and Witten (2008)" startWordPosition="5352" endWordPosition="5355">resent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entities. Medelyan et al. (2008) found the referent entity of a name mention by computing the weighted average of semantic relatedness between the candidate entity and its unambiguous contextual entities. Milne and Witten (2008) extended Medelyan et al. (2008) by adopting learning-based techniques to balance the semantic relatedness, commoness and context quality. Kulkarni et al. (2009) proposed a method which collectively resolves the entity linking tasks in a document as an optimization problem. The drawback of the inter-dependency based methods is that they are usually specially designed to the leverage of semantic relations, doesn’t take the other types of entity knowledge into consideration. 6 Conclusions and Future Work This paper proposes a generative probabilistic model, the entity-mention model, for the enti</context>
<context position="4152" citStr="Milne &amp; Witten, 2008" startWordPosition="651" endWordPosition="654">an can be mentioned using more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls. Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu &amp; Pasca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions: • Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the name “Michael Jordan” will more likely refer to the notorious</context>
<context position="12548" citStr="Milne &amp; Witten, 2008" startWordPosition="2004" endWordPosition="2007"> is a triple m={s, e, c}, where s is the name, e is the referent entity and c is the context. For example, two annotated name mentions are as follows: • Jordan |Michael Jeffrey Jordan |... wins his first NBA MVP in 1991. • NBA |National Basketball Association |... is the preeminent men&apos;s professional basketball league. In this paper, we focus on the task of linking entities with Wikipedia, even though the proposed method can be applied to other resources. We will only show how to get the training data from Wikipedia. In Wikipedia, a hyperlink between two articles is an annotated name mention (Milne &amp; Witten, 2008): its anchor text is the name and its target article is the referent entity. For example, in following hyperlink (in Wiki syntax), the NBA is the name and the National Basketball Association is the referent entity. “He won his first [[National Basketball Association | NBA]] championship with the Bulls” Therefore, we can get the training data by collecting all annotated name mentions from the hyperlink data of Wikipedia. In total, we collected more than 23,000,000 annotated name mentions. 3.2 Entity Popularity Model The distribution P(e) encodes the popularity knowledge as a distribution of ent</context>
<context position="25973" citStr="Milne &amp; Witten, 2008" startWordPosition="4230" endWordPosition="4233">e baselines: (1) The first is the traditional Bag of Words based method (Cucerzan, 2007): a name mention’s referent entity is the entity which has the highest cosine similarity with its context – we denoted it as BoW; (2) The second is the method described in 5 This is because we want to create a highly ambiguous test data set (Medelyan et al., 2008), where a name mention’s referent entity is the entity which has the largest average semantic relatedness with the name mention’s unambiguous context entities – we denoted it as TopicIndex. (3) The third one is the same as the method described in (Milne &amp; Witten, 2008), which uses learning techniques to balance the semantic relatedness, commoness and context quality – we denoted it as Learning2Link. 4.4.1 Overall Performance We conduct experiments on both WikiAmbi and TAC_KBP datasets with several methods: the baseline BoW; the baseline TopicIndex; the baseline Learning2Link; the proposed method using only popularity knowledge (Popu), i.e., the P(m,e)=P(e); the proposed method with one component of the model is ablated(this is used to evaluate the independent contributions of the three components), correspondingly Popu+Name(i.e., the P(m,e)=P(e)P(sje)), Nam</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>Milne, D. &amp; Witten, I. H. 2008. Learning to link with Wikipedia. In: Proceedings of the 17th ACM conference on Conference on information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
</authors>
<title>Mining Domain-Specific Thesauri from Wikipedia: A case study.</title>
<date>2006</date>
<booktitle>In Proc. of IEEE/WIC/ACM WI.</booktitle>
<marker>Milne, 2006</marker>
<rawString>Milne, D., et al. 2006. Mining Domain-Specific Thesauri from Wikipedia: A case study. In Proc. of IEEE/WIC/ACM WI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Medelyan</author>
<author>I H Witten</author>
<author>D Milne</author>
</authors>
<title>Topic indexing with Wikipedia. In:</title>
<date>2008</date>
<booktitle>Proceedings of the AAAI WikiAI workshop.</booktitle>
<contexts>
<context position="25704" citStr="Medelyan et al., 2008" startWordPosition="4185" endWordPosition="4188"> all the name mentions; • Macro-Averaged Accuracy (MacroAccuracy): measures entity linking accuracy averaged over all the target entities. As in TAC 2009, we used Micro-Accuracy as the primary performance metric. 4.4 Experimental Results We compared our method with three baselines: (1) The first is the traditional Bag of Words based method (Cucerzan, 2007): a name mention’s referent entity is the entity which has the highest cosine similarity with its context – we denoted it as BoW; (2) The second is the method described in 5 This is because we want to create a highly ambiguous test data set (Medelyan et al., 2008), where a name mention’s referent entity is the entity which has the largest average semantic relatedness with the name mention’s unambiguous context entities – we denoted it as TopicIndex. (3) The third one is the same as the method described in (Milne &amp; Witten, 2008), which uses learning techniques to balance the semantic relatedness, commoness and context quality – we denoted it as Learning2Link. 4.4.1 Overall Performance We conduct experiments on both WikiAmbi and TAC_KBP datasets with several methods: the baseline BoW; the baseline TopicIndex; the baseline Learning2Link; the proposed meth</context>
<context position="33069" citStr="Medelyan et al. (2008)" startWordPosition="5323" endWordPosition="5326">Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entities. Medelyan et al. (2008) found the referent entity of a name mention by computing the weighted average of semantic relatedness between the candidate entity and its unambiguous contextual entities. Milne and Witten (2008) extended Medelyan et al. (2008) by adopting learning-based techniques to balance the semantic relatedness, commoness and context quality. Kulkarni et al. (2009) proposed a method which collectively resolves the entity linking tasks in a document as an optimization problem. The drawback of the inter-dependency based methods is that they are usually specially designed to the leverage of semantic relati</context>
</contexts>
<marker>Medelyan, Witten, Milne, 2008</marker>
<rawString>Medelyan, O., Witten, I. H. &amp; Milne, D. 2008. Topic indexing with Wikipedia. In: Proceedings of the AAAI WikiAI workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>A Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge. In:</title>
<date>2007</date>
<booktitle>Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>233--242</pages>
<contexts>
<context position="32210" citStr="Mihalcea &amp; Csomai (2007)" startWordPosition="5188" endWordPosition="5191">arison with top 5 TAC 2009 KBP systems 5 Related Work In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity l</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Mihalcea, R. &amp; Csomai, A. 2007. Wikify!: linking documents to encyclopedic knowledge. In: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pp. 233-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>A Purandare</author>
<author>A Kulkarni</author>
</authors>
<title>Name discrimination by clustering similar contexts.</title>
<date>2005</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>226--237</pages>
<contexts>
<context position="19152" citStr="Pedersen et al., 2005" startWordPosition="3111" endWordPosition="3114">following two contexts: C1: __wins NBA MVP. C2: __is a researcher in machine learning. Then P(C1|Michael Jeffrey Jordan) should be high because the NBA player Michael Jeffrey Jordan often appears in C1 and the P(C2|Michael Jeffrey Jordan) should be extremely low because he rarely appears in C2. ... Figure 4. Two entity context models To estimate the distribution P(c|e), we propose a method based on language modeling, called entity context model. In our model, the context of each name mention m is the word window surrounding m, and the window size is set to 50 according to the experiments in (Pedersen et al., 2005). Specifically, the context knowledge of an entity e is encoded in an unigram language model: where Pe(t) is the probability of the term t appearing in the context of e. In our model, the term may indicate a word, a named entity (extracted using the Stanford Named Entity Full Name Michael Jeffrey Jordan t(si|fj) l ( f + 1) j= 1 =0 __ wins NBA MVP. Michael Jeffrey Jordan (NBA Player) NBA=0.03 MVP=0.008 Basketball=0.02 player=0.005 win=0.00008 professor=0 ... Michael I. Jordan (Berkeley Professor) professor=0.003 Berkeley=0.002 machine learning=0.1 researcher = 0.006 NBA = 0 MVP=0 __is a profess</context>
</contexts>
<marker>Pedersen, Purandare, Kulkarni, 2005</marker>
<rawString>Pedersen, T., Purandare, A. &amp; Kulkarni, A. 2005. Name discrimination by clustering similar contexts. Computational Linguistics and Intelligent Text Processing, pp. 226-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zhang</author>
<author>J Su</author>
<author>Chew Lim Tan</author>
<author>W T Wang</author>
</authors>
<title>Entity Linking Leveraging Automatically Generated Annotation. In:</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<contexts>
<context position="32442" citStr="Zhang et al. (2010)" startWordPosition="5225" endWordPosition="5228">riminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entit</context>
</contexts>
<marker>Zhang, Su, Tan, Wang, 2010</marker>
<rawString>Zhang, W., Su, J., Tan, Chew Lim &amp; Wang, W. T. 2010. Entity Linking Leveraging Automatically Generated Annotation. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zheng</author>
<author>F Li</author>
<author>M Huang</author>
<author>X Zhu</author>
</authors>
<title>Learning to Link Entities with Knowledge Base. In:</title>
<date>2010</date>
<booktitle>The Proceedings of the Annual Conference of the North American Chapter of the ACL.</booktitle>
<contexts>
<context position="21411" citStr="Zheng et al. 2010" startWordPosition="3493" endWordPosition="3496">ng the whole Wikipedia data, and the optimal value of λ is set to 0.2 through a learning process shown in Section 4. 3.5 The NIL Entity Problem By estimating P(e), P(s|e) and P(c|e), our method can effectively link a name mention to its referent entity contained in a knowledge base. Unfortunately, there is still the NIL entity problem (McNamee and Dang, 2009), i.e., the referent entity may not be contained in the given knowledge base. In this situation, the name mention should be linked to the NIL entity. Traditional methods usually resolve this problem with an additional classification step (Zheng et al. 2010): a classifier is trained to identify whether a name mention should be linked to the NIL entity. Rather than employing an additional step, our entity mention model seamlessly takes into account the NIL entity problem. The start assumption of 4 http://nlp.stanford.edu/software/CRF-NER.shtml our solution is that “If a name mention refers to a specific entity, then the probability of this name mention is generated by the specific entity’s model should be significantly higher than the probability it is generated by a general language model”. Based on the above assumption, we first add a pseudo ent</context>
<context position="32399" citStr="Zheng et al. (2010)" startWordPosition="5217" endWordPosition="5220"> The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity wh</context>
</contexts>
<marker>Zheng, Li, Huang, Zhu, 2010</marker>
<rawString>Zheng, Z., Li, F., Huang, M. &amp; Zhu, X. 2010. Learning to Link Entities with Knowledge Base. In: The Proceedings of the Annual Conference of the North American Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhou</author>
<author>L Nie</author>
<author>O Rouhani-Kalleh</author>
<author>F Vasile</author>
<author>S Gaffney</author>
</authors>
<title>Resolving Surface Forms to Wikipedia Topics. In:</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>1335--1343</pages>
<contexts>
<context position="32465" citStr="Zhou et al. (2010)" startWordPosition="5230" endWordPosition="5233">n entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea &amp; Csomai (2007), Bunescu &amp; Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge. Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entities. Medelyan et al. (2</context>
</contexts>
<marker>Zhou, Nie, Rouhani-Kalleh, Vasile, Gaffney, 2010</marker>
<rawString>Zhou, Y., Nie, L., Rouhani-Kalleh, O., Vasile, F. &amp; Gaffney, S. 2010. Resolving Surface Forms to Wikipedia Topics. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pp. 1335-1343.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>