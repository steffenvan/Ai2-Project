<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000080">
<title confidence="0.9972315">
May All Your Wishes Come True:
A Study of Wishes and How to Recognize Them
</title>
<author confidence="0.9711685">
Andrew B. Goldberg, Nathanael Fillmore, David Andrzejewski
Zhiting Xu, Bryan Gibson, Xiaojin Zhu
</author>
<affiliation confidence="0.99824">
Computer Sciences Department, University of Wisconsin-Madison, Madison, WI 53706, USA
</affiliation>
<email confidence="0.943926">
{goldberg, nathanae, andrzeje, zhiting, bgibson, jerryzhu}@cs.wisc.edu
</email>
<sectionHeader confidence="0.998519" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999528764705882">
A wish is “a desire or hope for something
to happen.” In December 2007, people from
around the world offered up their wishes to
be printed on confetti and dropped from the
sky during the famous New Year’s Eve “ball
drop” in New York City’s Times Square. We
present an in-depth analysis of this collection
of wishes. We then leverage this unique re-
source to conduct the first study on building
general “wish detectors” for natural language
text. Wish detection complements traditional
sentiment analysis and is valuable for collect-
ing business intelligence and insights into the
world’s wants and desires. We demonstrate
the wish detectors’ effectiveness on domains
as diverse as consumer product reviews and
online political discussions.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999902923076923">
Each year, New York City rings in the New Year
with the famous “ball drop” in Times Square. In
December 2007, the Times Square Alliance, co-
producer of the Times Square New Year’s Eve Cele-
bration, launched a Web site called the Virtual Wish-
ing Wall1 that allowed people around the world to
submit their New Year’s wishes. These wishes were
then printed on confetti and dropped from the sky
at midnight on December 31, 2007 in sync with the
ball drop.
We obtained access to this set of nearly 100,000
New Year’s wishes, which we call the “WISH cor-
pus.” Table 1 shows a selected sample of the WISH
</bodyText>
<footnote confidence="0.977394">
1http://www.timessquarenyc.org/nye/nye interactive.html
</footnote>
<bodyText confidence="0.999610722222222">
corpus. Some are far-reaching fantasies and aspi-
rations, while others deal with everyday concerns
like economic and medical distress. We analyze this
first-of-its-kind corpus in Section 2.
The New Oxford American Dictionary defines
“wish” as “a desire or hope for something to hap-
pen.” How wishes are expressed, and how such
wishful expressions can be automatically recog-
nized, are open questions in natural language pro-
cessing. Leveraging the WISH corpus, we conduct
the first study on building general “wish detectors”
for natural language text, and demonstrate their ef-
fectiveness on domains as diverse as consumer prod-
uct reviews and online political discussions. Such
wish detectors have tremendous value in collecting
business intelligence and public opinions. We dis-
cuss the wish detectors in Section 3, and experimen-
tal results in Section 4.
</bodyText>
<subsectionHeader confidence="0.997259">
1.1 Relation to Prior Work
</subsectionHeader>
<bodyText confidence="0.966616357142857">
Studying wishes is valuable in at least two aspects:
1. Being a special genre of subjective expression,
wishes add a novel dimension to sentiment analy-
sis. Sentiment analysis is often used as an auto-
matic market research tool to collect valuable busi-
ness intelligence from online text (Pang and Lee,
2008; Shanahan et al., 2005; Koppel and Shtrim-
berg, 2004; Mullen and Malouf, 2008). Wishes
differ from the recent focus of sentiment analysis,
namely opinion mining, by revealing what people
explicitly want to happen, not just what they like or
dislike (Ding et al., 2008; Hu and Liu, 2004). For ex-
ample, wishes in product reviews could contain new
feature requests. Consider the following (real) prod-
</bodyText>
<page confidence="0.981824">
263
</page>
<note confidence="0.789513777777778">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
514 peace on earth
351 peace
331 world peace
244 happy new year
112 love
76 health and happiness
75 to be happy
</note>
<figure confidence="0.908872529411765">
51 i wish for world peace
21 i wish for health and happiness for my family
21 let there be peace on earth
16 i wish u to call me ifyou read this 555-1234
16 to find my true love
8 i wish for a puppy
7 for the war in iraq to end
6 peace on earth please
5 a free democratic venezuela
5 may the best of 2007 be the worst of 2008
5 to be financially stable
1 a little goodness for everyone would be nice
1 i hope i get accepted into a college that i like
1 i wish to get more sex in 2008
1 please let name be healthy and live all year
1 to be emotionally stable and happy
1 to take over the world
</figure>
<tableCaption confidence="0.9845115">
Table 1: Example wishes and their frequencies in the
WISH corpus.
</tableCaption>
<bodyText confidence="0.99515565">
uct review excerpt: “Great camera. Indoor shots
with a flash are not quite as good as 35mm. I wish
the camera had a higher optical zoom so that I could
take even better wildlife photos.” The first sentence
contains positive opinion, the second negative opin-
ion. However, wishful statements like the third sen-
tence are often annotated as non-opinion-bearing in
sentiment analysis corpora (Hu and Liu, 2004; Ding
et al., 2008), even though they clearly contain im-
portant information. An automatic “wish detector”
text-processing tool can be useful for product manu-
facturers, advertisers, politicians, and others looking
to discover what people want.
2. Wishes can tell us a lot about people: their in-
nermost feelings, perceptions of what they’re lack-
ing, and what they desire (Speer, 1939). Many
psychology researchers have attempted to quantify
the contents of wishes and how they vary with
factors such as location, gender, age, and per-
sonality type (Speer, 1939; Milgram and Riedel,
1969; Ehrlichman and Eichenstein, 1992; King and
Broyles, 1997). These studies have been small scale
with only dozens or hundreds of participants. The
WISH corpus provides the first large-scale collec-
tion of wishes as a window into the world’s desires.
Beyond sentiment analysis, classifying sentences
as wishes is an instance of non-topical classifica-
tion. Tasks under this heading include compu-
tational humor (Mihalcea and Strapparava, 2005),
genre classification (Boese and Howe, 2005), au-
thorship attribution (Argamon and Shimoni, 2003),
and metaphor detection (Krishnakumaran and Zhu,
2007), among others (Mishne et al., 2007; Mihal-
cea and Liu, 2006). We share the common goal of
classifying text into a unique set of target categories
(in our case, wishful and non-wishful), but use dif-
ferent techniques catered to our specific task. Our
feature-generation technique for wish detection re-
sembles template-based methods for information ex-
traction (Brin, 1999; Agichtein and Gravano, 2000).
</bodyText>
<sectionHeader confidence="0.807189" genericHeader="method">
2 Analyzing the WISH Corpus
</sectionHeader>
<bodyText confidence="0.9999495">
We analyze the WISH corpus with a variety of sta-
tistical methods. Our analyses not only reveal what
people wished for on New Year’s Eve, but also pro-
vide insight for the development of wish detectors in
Section 3.
The complete WISH corpus contains nearly
100,000 wishes collected over a period of 10 days
in December 2007, most written in English, with the
remainder in Portuguese, Spanish, Chinese, French,
and other languages. For this paper, we consider
only the 89,574 English wishes. Most of these En-
glish wishes contain optional geographic meta data
provided by the wisher, indicating a variety of coun-
tries (not limited to English-speaking) around the
world. We perform minimal preprocessing, includ-
ing TreeBank-style tokenization, downcasing, and
punctuation removal. Each wish is treated as a sin-
gle entity, regardless of whether it contains multiple
sentences. After preprocessing, the average length
of a wish is 8 tokens.
</bodyText>
<subsectionHeader confidence="0.999561">
2.1 The Topic and Scope of Wishes
</subsectionHeader>
<bodyText confidence="0.9998794">
As a first step in understanding the content of the
wishes, we asked five annotators to manually an-
notate a random subsample of 5,000 wishes. Sec-
tions 2.1 and 2.2 report results on this subsample.
The wishes were annotated in terms of two at-
</bodyText>
<page confidence="0.996142">
264
</page>
<figure confidence="0.97435">
(a) Topic of Wishes
(b) Scope of Wishes
</figure>
<figureCaption confidence="0.998928">
Figure 1: Topic and scope distributions based on manual
annotations of a random sample of 5,000 wishes in the
WISH corpus.
</figureCaption>
<bodyText confidence="0.99940075">
tributes: topic and scope. We used 11 pre-defined
topic categories, and their distribution in this sub-
sample of the WISH corpus is shown in Figure 1(a).
The most frequent topic is love, while health,
happiness, and peace are also common themes.
Many wishes also fell into an other category, in-
cluding specific individual requests (“i wish for a
new puppy”), solicitations or advertisements (“call
me 555-1234”, “visit website.com”), or sinister
thoughts (“to take over the world”).
The 5,000 wishes were also manually assigned
a scope. The scope of a wish refers to the range
of people that are targeted by the wish. We used
6 pre-defined scope categories: self (“I want to be
happy”), family (“For a cure for my husband”), spe-
cific person by name (“Prayers for name”), country
(“Bring our troops home!”), world (“Peace to every-
one in the world”), and other. In cases where mul-
tiple scope labels applied, the broadest scope was
selected. Figure 1(b) shows the scope distribution.
It is bimodal: over one third of the wishes are nar-
rowly directed at one’s self, while broad wishes at
the world level are also frequent. The in-between
scopes are less frequent.
</bodyText>
<subsectionHeader confidence="0.998446">
2.2 Wishes Differ by Geographic Location
</subsectionHeader>
<bodyText confidence="0.99827387804878">
As mentioned earlier, wishers had the option to enter
a city/country when submitting wishes. Of the man-
ually annotated wishes, about 4,000 included valid
location information, covering all 50 states in the
U.S., and all continents except Antarctica.
We noticed a statistically significant difference
between wishes submitted from the United States
(about 3600) versus non-U.S. (about 400), both in
terms of their topic and scope distributions. For each
comparison, we performed a Pearson x2-test using
location as the explanatory variable and either topic
or scope as the response variable.2 The null hypoth-
esis is that the variables are independent. For both
tests we reject the null hypothesis, with p &lt; 0.001
for topic, and p = 0.006 for scope. This indicates a
dependence between location and topic/scope. As-
terisks in Figure 2 denote the labels that differ sig-
nificantly between U.S. and non-U.S. wishes.3
In particular, we observed that there are signif-
icantly more wishes about love, peace, and travel
from non-U.S. locales, and more about religion from
the U.S. There are significantly more world-scoped
wishes from non-U.S. locales, and more country-
and family-scoped wishes from the U.S.
We also compared wishes from “red states” ver-
sus “blue states” (U.S. states that voted a majority
for the Republican and Democratic presidential can-
didates in 2008, respectively), but found no signifi-
cant differences.
2The topic test examined a 2 × 11 contingency table, while
the scope test used a 2 × 6 contingency table. In both tests, all
of the cells in the tables had an expected frequency of at least 5,
so the χ2 approximation is valid.
3To identify the labels that differ significantly by location,
we computed the standardized residuals for the cells in the two
contingency tables. Standardized residuals are approximately
N(0,1)-distributed and can be used to locate the major con-
tributors to a significant χ2-test statistic (Agresti, 2002). The
asterisks in Figure 2 indicate the surprisingly large residuals,
i.e., the difference between observed and expected frequencies
is outside a 95% confidence interval.
</bodyText>
<page confidence="0.989295">
265
</page>
<figure confidence="0.981305">
(a) Wish topics differ by Location
(b) Wish scopes differ by Location
</figure>
<figureCaption confidence="0.99688075">
Figure 2: Geographical breakdown of topic and scope
distributions based on approximately 4,000 location-
tagged wishes. Asterisks indicate statistically significant
differences.
</figureCaption>
<subsectionHeader confidence="0.998602">
2.3 Wishes Follow Zipf’s Law
</subsectionHeader>
<bodyText confidence="0.999991666666667">
We now move beyond the annotated subsample and
examine the full set of 89,574 English wishes. We
noticed that a small fraction (4%) of unique wishes
account for a relatively large portion (16%) of wish
occurrences, while there are also many wishes that
only occur once. The question naturally arises: do
wishes obey Zipf’s Law (Zipf, 1932; Manning and
Sch¨utze, 1999)? If so, we should expect the fre-
quency of a unique wish to be inversely proportional
to its rank, when sorted by frequency. Figure 3
plots rank versus frequency on a log-log scale and
reveals an approximately linear negative slope, thus
suggesting that wishes do follow Zipf’s law. It also
shows that low-occurrence wishes dominate, hence
learning might be hindered by data sparseness.
</bodyText>
<subsectionHeader confidence="0.998215">
2.4 Latent Topic Modeling for Wishes
</subsectionHeader>
<bodyText confidence="0.9999614">
The 11 topics in Section 2.1 were manually pre-
defined based on domain knowledge. In contrast,
in this section we applied Latent Dirichlet Alloca-
tion (LDA) (Blei et al., 2003) to identify the latent
topics in the full set of 89,574 English wishes in an
</bodyText>
<figure confidence="0.494198">
100 101 102 103 104 105
log(rank)
</figure>
<figureCaption confidence="0.9918955">
Figure 3: The rank vs. frequency plot of wishes, approx-
imately obeying Zipf’s law. Note the log-log scale.
</figureCaption>
<bodyText confidence="0.996693105263158">
unsupervised fashion. The goal is to validate and
complement the study in Section 2.1.
To apply LDA to the wishes, we treated each indi-
vidual wish as a short document. We used 12 topics,
Collapsed Gibbs Sampling (Griffiths and Steyvers,
2004) for inference, hyperparameters α = 0.5 and
Q = 0.1, and ran Markov Chain Monte Carlo for
2000 iterations.
The resulting 12 LDA topics are shown in Ta-
ble 2, in the form of the highest probability words
p(wordltopic) in each topic. We manually added
summary descriptors for readability. With LDA, it is
also possible to observe which words were assigned
to which topics in each wish. For example, LDA as-
signed most words in the wish “world(8) peace(8)
and my friends(4) in iraq(1) to come(1) home(1)”
to two topics: peace and troops (topic numbers in
parentheses). Interestingly, these LDA topics largely
agree with the pre-defined topics in Section 2.1.
</bodyText>
<sectionHeader confidence="0.988591" genericHeader="method">
3 Building Wish Detectors
</sectionHeader>
<bodyText confidence="0.999238090909091">
We now study the novel NLP task of wish detection,
i.e., classifying individual sentences as being wishes
or not. Importantly, we want our approach to trans-
fer to domains other than New Year’s wishes, in-
cluding consumer product reviews and online politi-
cal discussions. It should be pointed out that wishes
are highly domain dependent. For example, “I wish
for world peace” is a common wish on New Year’s
Eve, but is exceedingly rare in product reviews; and
vice versa: “I want to have instant access to the vol-
ume” may occur in product reviews, but is an un-
</bodyText>
<figure confidence="0.941169444444444">
103
peace
102
to find my true love
101
to take over
the world
100
log(frequency)
</figure>
<page confidence="0.951627">
266
</page>
<table confidence="0.999066769230769">
Topic Summary Top words in the topic, sorted by p(wordltopic)
0 New Year year, new, happy, 2008, best, everyone, great, years, wishing, prosperous, may, hope
1 Troops all, god, home, come, may, safe, s, us, bless, troops, bring, iraq, return, 2008, true, dreams
2 Election wish, end, no, more, 2008, war, stop, president, paul, not, ron, up, free, less, bush, vote
3 Life more, better, life, one, live, time, make, people, than, everyone, day, wish, every, each
4 Prosperity health, happiness, good, family, friends, all, love, prosperity, wealth, success, wish, peace
5 Love love, me, find, wish, true, life, meet, want, man, marry, call, someone, boyfriend, fall, him
6 Career get, wish, job, out, t, hope, school, better, house, well, want, back, don, college, married
7 Lottery wish, win, 2008, money, want, make, become, lottery, more, great, lots, see, big, times
8 Peace peace, world, all, love, earth, happiness, everyone, joy, may, 2008, prosperity, around
9 Religion love, forever, jesus, know, loves, together, u, always, 2, 3, 4, much, best, mom, christ
10 Family healthy, happy, wish, 2008, family, baby, life, children, long, safe, husband, stay, marriage
11 Health com, wish, s, me, lose, please, let, cancer, weight, cure, mom, www, mother, visit, dad
</table>
<tableCaption confidence="0.999174">
Table 2: Wish topics learned from Latent Dirichlet Allocation. Words are sorted by p(wordltopic).
</tableCaption>
<bodyText confidence="0.998476">
likely New Year’s wish. For this initial study, we do
assume that there are some labeled training data in
the target domains of interest.
To transfer the knowledge learned from the out-
of-domain WISH corpus to other domains, our key
insight is the following: while the content of wishes
(e.g., “world peace”) may not transfer across do-
mains, the ways wishes are expressed (e.g., “I wish
for ”) may. We call these expressions wish tem-
plates. Our novel contribution is an unsupervised
method for discovering candidate templates from the
WISH corpus which, when applied to other target
domains, improve wish detection in those domains.
</bodyText>
<subsectionHeader confidence="0.996123">
3.1 Two Simple Wish Detectors
</subsectionHeader>
<bodyText confidence="0.997892666666667">
Before describing our template discovery method,
we first describe two simple wish detectors, which
serve as baselines.
</bodyText>
<listItem confidence="0.847114">
1. [Manual]: It may seem easy to locate
</listItem>
<bodyText confidence="0.992665428571428">
wishes. Perhaps looking for sentences containing
the phrases “i wish,” “i hope,” or some other sim-
ple patterns is sufficient for identifying the vast ma-
jority of wishes in a domain. To test this hypothe-
sis, we asked two native English speakers (not the
annotators, nor affiliated with the project; no expo-
sure to any of the wish datasets) to come up with
text patterns that might be used to express wishes.
They were shown three dictionary definitions of “to
wish (v)” and “wish (n)”. They produced a ranked
list of 13 templates; see Table 3. The underscore
matches any string. These templates can be turned
into a simple rule-based classifier: If part of a sen-
tence matches one of the templates, the sentence is
</bodyText>
<tableCaption confidence="0.995275">
Table 3: Manual templates for identifying wishes.
</tableCaption>
<bodyText confidence="0.999687">
classified as a wish. By varying the depth of the list,
one can produce different precision/recall behaviors.
Overall, we expect [Manual] to have relatively high
precision but low recall.
</bodyText>
<listItem confidence="0.518099">
2. [Words]: Another simple method for detecting
wishes is to train a standard word-based text clas-
</listItem>
<bodyText confidence="0.997130909090909">
sifier using the labeled training set in the target do-
main. Specifically, we represent each sentence as
a binary word-indicator vector, normalized to sum
to 1. We then train a linear Support Vector Ma-
chine (SVM). This method may have higher recall,
but precision may suffer. For instance, the sentence
“Her wish was carried out by her husband” is not a
wish, but could be misclassified as one because of
the word “wish.”
Note that neither of the two baseline methods uses
the WISH corpus.
</bodyText>
<figure confidence="0.821723076923077">
i wish
i hope
i want
hopefully
if only
would be better if
would like if
should
would that
can’t believe didn’t
don’t believe didn’t
do want
i can has
</figure>
<page confidence="0.957106">
267
</page>
<subsectionHeader confidence="0.997736">
3.2 Automatically Discovering Wish Templates
</subsectionHeader>
<bodyText confidence="0.997850681818181">
We now present our method to automatically dis-
cover high quality wish templates using the WISH
corpus. The key idea is to exploit redundancy in
how the same wish content is expressed. For ex-
ample, as we see in Table 1, both “world peace” and
“i wish for world peace” are common wishes. Sim-
ilarly, both “health and happiness” and “i wish for
health and happiness” appear in the WISH corpus.
It is thus reasonable to speculate that “i wish for ”
is a good wish template. Less obvious templates can
be discovered in this way, too, such as “let there be
” from “peace on earth” and “let there be peace
on earth.”
We formalize this intuition as a bipartite graph, il-
lustrated in Figure 4. Let W = {w1, ... , wn} be the
set of unique wishes in the WISH corpus. The bi-
partite graph has two types of nodes: content nodes
C and template nodes T, and they are generated as
follows. If a wish wj (e.g., “i wish for world peace”)
contains another wish wi (e.g., “world peace”), we
create a content node c1 = wi and a template node
t1 =“i wish for ”. We denote this relationship by
wj = c1 +t1. Note the order of c1 and t1 is insignif-
icant, as how the two combine is determined by the
underscore in t1, and wj = t1 + c1 is just fine. In
addition, we place a directed edge from c1 to t1 with
edge weight count(wj), the frequency of wish wj in
the WISH corpus. Then, a template node appears to
be a good one if many heavy edges point to it.
On the other hand, a template is less desirable
if it is part of a content node. For example, when
wj =“health and happiness” and wi =“health”, we
create the template t2 =“ and happiness” and the
content node c3 = wi. If there is another wish
wk =“i wish for health and happiness”, then there
will be a content node c2 = wj. The template t2
thus contains some content words (since it matches
c2), and may not generalize well in a new domain.
We capture this by backward edges: if Ic&apos; E C, and
I string s (s not necessarily in C or W) such that
c&apos; = s + t, we add a backward edge from t to c&apos; with
edge weight count(c&apos;).
Based on such considerations, we devised the fol-
lowing scheme for scoring templates:
</bodyText>
<equation confidence="0.924588">
score(t) = in(t) − out(t), (1)
count(c1+t1)
i wish for ___
health and happiness
count(c2)
health
</equation>
<figureCaption confidence="0.999321">
Figure 4: The bipartite graph to create templates.
</figureCaption>
<bodyText confidence="0.999954153846154">
where in(t) is the in-degree of node t, defined as the
sum of edge weights coming into t; out(t) is the out-
degree of node t, defined similarly. In other words, a
template receives a high score if it is “used” by many
frequent wishes but does not match many frequent
content-only wishes. To create the final set of tem-
plate features, we apply the threshold score(t) &gt; 5.
This produces a final list of 811 templates. Table 4
lists some of the top templates ranked by score(t).
While some of these templates still contain time- or
scope-related words (“for my family”), they are de-
void of specific topical content. Notice that we have
automatically identified several of the manually de-
rived templates in Table 3, and introduce many new
variations that a learning algorithm can leverage.
Top 10 Others in Top 200
in 2008 i want to
i wish for for everyone
i wish i hope
i want my wish is
this year please
i wish in 2008 wishing for
i wish to may you
for my family i wish i had
i wish this year to finally
in the new year for my family to have
</bodyText>
<tableCaption confidence="0.985209">
Table 4: Top templates according to Equation 1.
</tableCaption>
<subsectionHeader confidence="0.999947">
3.3 Learning with Wish Template Features
</subsectionHeader>
<bodyText confidence="0.9999236">
After discovering wish templates as described
above, we use them as features for learning in a new
domain (e.g., product reviews). For each sentence in
the new domain, we assign binary features indicat-
ing which templates match the sentence. Two types
of matching are possible. Strict matching requires
that the template must match an entire sentence from
beginning to end, with at least one word filling in for
the underscore. (All matching during the template
generation process was strict.) Non-strict matching
</bodyText>
<figure confidence="0.99150985">
world peace c1
c2
c3
t1
t2
___ and happiness
268
Precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
00 0.2 0.4 0.6 0.8 1
1
Manual
Words
Templates
Words + Templates
Precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
00 0.2 0.4 0.6 0.8 1
1
Manual
Words
Templates
Words + Templates
Recall
</figure>
<figureCaption confidence="0.972072">
Figure 5: Politics domain precision-recall curves.
</figureCaption>
<figure confidence="0.86537">
Recall
</figure>
<figureCaption confidence="0.999678">
Figure 6: Products domain precision-recall curves.
</figureCaption>
<bodyText confidence="0.99992">
requires only that template match somewhere within
a sentence. Rather than choose one type of match-
ing, we create both strict and non-strict template fea-
tures (1622 binary features total) and let the machine
learning algorithm decide what is most useful.
Our third wish detector, [Templates], is a linear
SVM with the 1622 binary wish template features.
Our fourth wish detector, [Words + Templates], is
a linear SVM with both template and word features.
</bodyText>
<sectionHeader confidence="0.999231" genericHeader="method">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.999902">
4.1 Target Domains and Experimental Setup
</subsectionHeader>
<bodyText confidence="0.998481">
We experimented with two domains, manually la-
beled at the sentence-level as wishes or non-wishes.4
Example wishes are listed in Table 6.
Products. Consumer product reviews: 1,235 sen-
tences selected from a collection of amazon.com and
cnet.com reviews (Hu and Liu, 2004; Ding et al.,
2008). 12% of the sentences are labeled as wishes.
Politics. Political discussion board postings:
6,379 sentences selected from politics.com (Mullen
and Malouf, 2008). 34% are labeled as wishes.
We automatically split the corpora into sen-
tences using MxTerminator (Reynar and Ratna-
parkhi, 1997). As preprocessing before learning, we
tokenized the text in the Penn TreeBank style, down-
</bodyText>
<footnote confidence="0.778693">
4Thesewish-annotated corpora are available for download
at http://pages.cs.wisc.edu/∼goldberg/wish data.
</footnote>
<bodyText confidence="0.997502470588235">
cased, and removed all punctuation.
For all four wish detectors, we performed 10-fold
cross validation. We used the default parameter in
SVMlight for all trials (Joachims, 1999). As the
data sets are skewed, we compare the detectors us-
ing precision-recall curves and the area under the
curve (AUC). For the manual baseline, we produce
the curve by varying the number of templates ap-
plied (in rank order), which gradually predicts more
sentences as wishes (increasing recall at the expense
of precision). A final point is added at recall 1.0,
corresponding to applying an empty template that
matches all sentences. For the SVM-based meth-
ods, we vary the threshold applied to the real-valued
margin prediction to produce the curves. All curves
are interpolated, and AUC measures are computed,
using the techniques of (Davis and Goadrich, 2006).
</bodyText>
<sectionHeader confidence="0.767475" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.9998694">
Figure 5 shows the precision-recall curves for the
Politics corpus. All curves are averages over 10
folds (i.e., for each of 100 evenly spaced, interpo-
lated recall points, the 10 precision values are aver-
aged). As expected, [Manual] can be very precise
with low recall—only the very top few templates
achieve high precision and pick out a small num-
ber of wishes with “i wish” and “i hope.” As we
introduce more templates to cover more true wishes,
precision drops off quickly. [Templates] is similar,
</bodyText>
<page confidence="0.993891">
269
</page>
<table confidence="0.992715666666667">
Corpus [Manual] [Words] [Templates] [Words + Templates]
Politics 0.67 f 0.03 0.77 f 0.03 0.73 f 0.03 0.80 f 0.03
Products 0.49 f 0.13 0.52 f 0.16 0.47 f 0.16 0.56 f 0.16
</table>
<tableCaption confidence="0.990598">
Table 5: AUC results (10-fold averages f one standard deviation).
</tableCaption>
<figure confidence="0.5585389">
Products:
the only area i wish apple had improved upon would be the screen
i just want music to eminate from it when i want how i want
the dial on the original zen was perfect and i wish it was on this model
i would like album order for my live albums and was just wondering
Politics:
all children should be allowed healthcare
please call on your representatives in dc and ask them to please stop the waste in iraq
i hope that this is a new beginning for the middle east
may god bless and protect the brave men and that we will face these dangers in the future
</figure>
<tableCaption confidence="0.99059">
Table 6: Example target-domain wishes correctly identified by [Words + Templates].
</tableCaption>
<bodyText confidence="0.999903074074074">
with slightly better precision in low recall regions.
[Words] is the opposite: bad in high recall but good
in low recall regions. [Words + Templates] is the
best, taking the best from both kinds of features to
dominate other curves. Table 5 shows the average
AUC across 10 folds. [Words + Templates] is sig-
nificantly better than all other detectors under paired
t-tests (p = 1 x 10−7 vs. [Manual], p = 0.01 vs.
[Words], and p = 4 x 10−7 vs. [Templates]). All
other differences are statistically significant, too.
Figure 6 shows the precision-recall curves for
the Products corpus. Again, [Words + Templates]
mostly dominates other detectors. In terms of av-
erage AUC across folds (Table 5), [Words + Tem-
plates] is also the best. However, due to the small
size of this corpus, the AUC values have high vari-
ance, and the difference between [Words + Tem-
plates] and [Words] is not statistically significant un-
der a paired t-test (p = 0.16).
Finally, to understand what is being learned in
more detail, we take a closer look at the SVM mod-
els’ weights for one fold of the Products corpus
(Table 7). The most positive and negative features
make intuitive sense. Note that [Words + Templates]
seems to rely on templates for selecting wishes and
words for excluding non-wishes. This partially ex-
plains the synergy of combining the feature types.
</bodyText>
<table confidence="0.997635333333333">
Sign [Words] [Templates] [Words +
Templates]
+ wish i hope hoping
+ hope i wish i hope
+ hopefully hoping i just want
+ hoping i just want i wish
+ want i would like i would like
- money family micro
- find forever about
- digital let me fix
- again d digital
- you for my dad you
</table>
<tableCaption confidence="0.94019">
Table 7: Features with the largest magnitude weights in
</tableCaption>
<copyright confidence="0.401825">
the SVM models for one fold of the Products corpus.
</copyright>
<sectionHeader confidence="0.998969" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9999176">
We have presented a novel study of wishes from
an NLP perspective. Using the first-of-its-kind
WISH corpus, we generated domain-independent
wish templates that improve wish detection perfor-
mance across product reviews and political discus-
sion posts. Much work remains in this new research
area, including the creation of more types of fea-
tures. Also, due to the difficulty in obtaining wish-
annotated training data, we plan to explore semi-
supervised learning for wish detection.
</bodyText>
<footnote confidence="0.931041">
Acknowledgements We thank the Times Square Al-
liance for providing the WISH corpus, and the Wisconsin
Alumni Research Foundation. AG is supported in part by
a Yahoo! Key Technical Challenges Grant.
</footnote>
<page confidence="0.994655">
270
</page>
<sectionHeader confidence="0.995883" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999416854166667">
Eugene Agichtein and Luis Gravano. 2000. Snowball:
Extracting relations from large plain-text collections.
In In Proceedings of the 5th ACM International Con-
ference on Digital Libraries, pages 85–94.
Alan Agresti. 2002. Categorical Data Analysis. Wiley-
Interscience, second edition.
Shlomo Argamon and Anat Rachel Shimoni. 2003. Au-
tomatically categorizing written texts by author gen-
der. Literary and Linguistic Computing, 17:401–412.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.
Elizabeth Sugar Boese and Adele Howe. 2005. Genre
classification of web documents. In Proceedings of
the 20th National Conference on Artificial Intelligence
(AAAI-05), Poster paper.
Sergey Brin. 1999. Extracting patterns and relations
from the world wide web. In WebDB ’98: Selected
papers from the International Workshop on The World
Wide Web and Databases, pages 172–183. Springer-
Verlag.
Jesse Davis and Mark Goadrich. 2006. The relationship
between precision-recall and roc curves. In ICML ’06:
Proceedings of the 23rd international conference on
Machine learning, New York, NY, USA. ACM.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining. In
WSDM ’08: Proceedings of the international confer-
ence on Web search and web data mining, pages 231–
240. ACM.
Howard Ehrlichman and Rosalind Eichenstein. 1992.
Private wishes: Gender similarities and difference.
Sex Roles, 26(9):399–422.
Thomas Griffiths and Mark Steyvers. 2004. Finding sci-
entific topics. Proceedings of the National Academy of
Sciences, 101(suppl. 1):5228–5235.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of KDD ’04,
the ACMSIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177. ACM
Press.
Thorsten Joachims. 1999. Making large-scale svm
learning practical. In B. Sch¨olkopf, C. Burges, and
A. Smola, editors, Advances in Kernel Methods - Sup-
port Vector Learning. MIT Press.
Laura A. King and Sheri J. Broyles. 1997. Wishes, gen-
der, personality, and well-being. Journal of Personal-
ity, 65(1):49–76.
Moshe Koppel and Itai Shtrimberg. 2004. Good news
or bad news? let the market decide. In AAAI Spring
Symposium on Exploring Attitude and Affect in Text,
pages 86–88.
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proceedings of the Workshop on Computational
Approaches to Figurative Language, pages 13–20,
Rochester, New York, April. Association for Compu-
tational Linguistics.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Process-
ing. The MIT Press, Cambridge, Massachusetts.
Rada Mihalcea and Hugo Liu. 2006. A corpus-based ap-
proach to finding happiness. In Proceedings ofAAAI-
CAAW-06, the Spring Symposia on Computational Ap-
proaches to Analyzing Weblogs.
Rada Mihalcea and Carlo Strapparava. 2005. Making
computers laugh: Investigations in automatic humor
recognition. In Empirical Methods in Natural Lan-
guage Processing.
Norman A. Milgram and Wolfgang W. Riedel. 1969.
Developmental and experiential factors in making
wishes. Child Development, 40(3):763–771.
Gilad Mishne, Krisztian Balog, Maarten de Rijke, and
Breyten Ernsting. 2007. Moodviews: Tracking and
searching mood-annotated blog posts. In Proceed-
ings International Conf. on Weblogs and Social Media
(ICWSM-2007), pages 323–324.
Tony Mullen and Robert Malouf. 2008. Taking sides:
User classification for informal online political dis-
course. Internet Research, 18:177–190.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2):1–135.
Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A
maximum entropy approach to identifying sentence
boundaries. In Fifth Conference on Applied Natural
Language Processing.
James Shanahan, Yan Qu, and Janyce Wiebe, editors.
2005. Computing attitude and affect in text. Springer,
Dordrecht, The Netherlands.
George S. Speer. 1939. Oral and written wishes of
rural and city school children. Child Development,
10(3):151–155.
G. K. Zipf. 1932. Selected Studies of the Principle of
Relative Frequency in Language. Harvard University
Press.
</reference>
<page confidence="0.997793">
271
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.337586">
<title confidence="0.98668">May All Your Wishes Come True: A Study of Wishes and How to Recognize Them</title>
<author confidence="0.837026">Andrew B Goldberg</author>
<author confidence="0.837026">Nathanael Fillmore</author>
<author confidence="0.837026">David Zhiting Xu</author>
<author confidence="0.837026">Bryan Gibson</author>
<author confidence="0.837026">Xiaojin</author>
<affiliation confidence="0.401596">Computer Sciences Department, University of Wisconsin-Madison, Madison, WI 53706,</affiliation>
<abstract confidence="0.998853111111111">A wish is “a desire or hope for something to happen.” In December 2007, people from around the world offered up their wishes to be printed on confetti and dropped from the sky during the famous New Year’s Eve “ball drop” in New York City’s Times Square. We present an in-depth analysis of this collection of wishes. We then leverage this unique resource to conduct the first study on building general “wish detectors” for natural language text. Wish detection complements traditional sentiment analysis and is valuable for collecting business intelligence and insights into the world’s wants and desires. We demonstrate the wish detectors’ effectiveness on domains as diverse as consumer product reviews and online political discussions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: Extracting relations from large plain-text collections. In</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th ACM International Conference on Digital Libraries,</booktitle>
<pages>85--94</pages>
<contexts>
<context position="6264" citStr="Agichtein and Gravano, 2000" startWordPosition="1025" endWordPosition="1028">nder this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods. Our analyses not only reveal what people wished for on New Year’s Eve, but also provide insight for the development of wish detectors in Section 3. The complete WISH corpus contains nearly 100,000 wishes collected over a period of 10 days in December 2007, most written in English, with the remainder in Portuguese, Spanish, Chinese, French, and other languages. For this paper, we consider only the 89,574 English wishes. Most of these English wishes contain optional geographic meta data provided by th</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting relations from large plain-text collections. In In Proceedings of the 5th ACM International Conference on Digital Libraries, pages 85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Agresti</author>
</authors>
<title>Categorical Data Analysis. WileyInterscience,</title>
<date>2002</date>
<note>second edition.</note>
<contexts>
<context position="10818" citStr="Agresti, 2002" startWordPosition="1774" endWordPosition="1775">dential candidates in 2008, respectively), but found no significant differences. 2The topic test examined a 2 × 11 contingency table, while the scope test used a 2 × 6 contingency table. In both tests, all of the cells in the tables had an expected frequency of at least 5, so the χ2 approximation is valid. 3To identify the labels that differ significantly by location, we computed the standardized residuals for the cells in the two contingency tables. Standardized residuals are approximately N(0,1)-distributed and can be used to locate the major contributors to a significant χ2-test statistic (Agresti, 2002). The asterisks in Figure 2 indicate the surprisingly large residuals, i.e., the difference between observed and expected frequencies is outside a 95% confidence interval. 265 (a) Wish topics differ by Location (b) Wish scopes differ by Location Figure 2: Geographical breakdown of topic and scope distributions based on approximately 4,000 locationtagged wishes. Asterisks indicate statistically significant differences. 2.3 Wishes Follow Zipf’s Law We now move beyond the annotated subsample and examine the full set of 89,574 English wishes. We noticed that a small fraction (4%) of unique wishes </context>
</contexts>
<marker>Agresti, 2002</marker>
<rawString>Alan Agresti. 2002. Categorical Data Analysis. WileyInterscience, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Anat Rachel Shimoni</author>
</authors>
<title>Automatically categorizing written texts by author gender.</title>
<date>2003</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>17--401</pages>
<contexts>
<context position="5811" citStr="Argamon and Shimoni, 2003" startWordPosition="956" endWordPosition="959">such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods. Our analyses not only reveal what people wished for</context>
</contexts>
<marker>Argamon, Shimoni, 2003</marker>
<rawString>Shlomo Argamon and Anat Rachel Shimoni. 2003. Automatically categorizing written texts by author gender. Literary and Linguistic Computing, 17:401–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="12234" citStr="Blei et al., 2003" startWordPosition="1995" endWordPosition="1998"> and Sch¨utze, 1999)? If so, we should expect the frequency of a unique wish to be inversely proportional to its rank, when sorted by frequency. Figure 3 plots rank versus frequency on a log-log scale and reveals an approximately linear negative slope, thus suggesting that wishes do follow Zipf’s law. It also shows that low-occurrence wishes dominate, hence learning might be hindered by data sparseness. 2.4 Latent Topic Modeling for Wishes The 11 topics in Section 2.1 were manually predefined based on domain knowledge. In contrast, in this section we applied Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to identify the latent topics in the full set of 89,574 English wishes in an 100 101 102 103 104 105 log(rank) Figure 3: The rank vs. frequency plot of wishes, approximately obeying Zipf’s law. Note the log-log scale. unsupervised fashion. The goal is to validate and complement the study in Section 2.1. To apply LDA to the wishes, we treated each individual wish as a short document. We used 12 topics, Collapsed Gibbs Sampling (Griffiths and Steyvers, 2004) for inference, hyperparameters α = 0.5 and Q = 0.1, and ran Markov Chain Monte Carlo for 2000 iterations. The resulting 12 LDA topics are </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Sugar Boese</author>
<author>Adele Howe</author>
</authors>
<title>Genre classification of web documents.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05), Poster paper.</booktitle>
<contexts>
<context position="5759" citStr="Boese and Howe, 2005" startWordPosition="949" endWordPosition="952">tents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods.</context>
</contexts>
<marker>Boese, Howe, 2005</marker>
<rawString>Elizabeth Sugar Boese and Adele Howe. 2005. Genre classification of web documents. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05), Poster paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the world wide web.</title>
<date>1999</date>
<booktitle>In WebDB ’98: Selected papers from the International Workshop on The World Wide Web and Databases,</booktitle>
<pages>172--183</pages>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="6234" citStr="Brin, 1999" startWordPosition="1023" endWordPosition="1024">ion. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods. Our analyses not only reveal what people wished for on New Year’s Eve, but also provide insight for the development of wish detectors in Section 3. The complete WISH corpus contains nearly 100,000 wishes collected over a period of 10 days in December 2007, most written in English, with the remainder in Portuguese, Spanish, Chinese, French, and other languages. For this paper, we consider only the 89,574 English wishes. Most of these English wishes contain optional geogr</context>
</contexts>
<marker>Brin, 1999</marker>
<rawString>Sergey Brin. 1999. Extracting patterns and relations from the world wide web. In WebDB ’98: Selected papers from the International Workshop on The World Wide Web and Databases, pages 172–183. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesse Davis</author>
<author>Mark Goadrich</author>
</authors>
<title>The relationship between precision-recall and roc curves.</title>
<date>2006</date>
<booktitle>In ICML ’06: Proceedings of the 23rd international conference on Machine learning,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="24381" citStr="Davis and Goadrich, 2006" startWordPosition="4093" endWordPosition="4096">re the detectors using precision-recall curves and the area under the curve (AUC). For the manual baseline, we produce the curve by varying the number of templates applied (in rank order), which gradually predicts more sentences as wishes (increasing recall at the expense of precision). A final point is added at recall 1.0, corresponding to applying an empty template that matches all sentences. For the SVM-based methods, we vary the threshold applied to the real-valued margin prediction to produce the curves. All curves are interpolated, and AUC measures are computed, using the techniques of (Davis and Goadrich, 2006). 4.2 Results Figure 5 shows the precision-recall curves for the Politics corpus. All curves are averages over 10 folds (i.e., for each of 100 evenly spaced, interpolated recall points, the 10 precision values are averaged). As expected, [Manual] can be very precise with low recall—only the very top few templates achieve high precision and pick out a small number of wishes with “i wish” and “i hope.” As we introduce more templates to cover more true wishes, precision drops off quickly. [Templates] is similar, 269 Corpus [Manual] [Words] [Templates] [Words + Templates] Politics 0.67 f 0.03 0.77</context>
</contexts>
<marker>Davis, Goadrich, 2006</marker>
<rawString>Jesse Davis and Mark Goadrich. 2006. The relationship between precision-recall and roc curves. In ICML ’06: Proceedings of the 23rd international conference on Machine learning, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In WSDM ’08: Proceedings of the international conference on Web</booktitle>
<pages>231--240</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3190" citStr="Ding et al., 2008" startWordPosition="504" endWordPosition="507">ults in Section 4. 1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 peace on earth 351 peace 331 world peace 244 happy new year 112 love 76 health and happiness 75 to be happy 51 i wish for world peace 21 i wish for health and happiness for my family 21 let there be peace on earth 16 i wish u to call me ifyou read this 555-1234 16 to fi</context>
<context position="4711" citStr="Ding et al., 2008" startWordPosition="790" endWordPosition="793">t more sex in 2008 1 please let name be healthy and live all year 1 to be emotionally stable and happy 1 to take over the world Table 1: Example wishes and their frequencies in the WISH corpus. uct review excerpt: “Great camera. Indoor shots with a flash are not quite as good as 35mm. I wish the camera had a higher optical zoom so that I could take even better wildlife photos.” The first sentence contains positive opinion, the second negative opinion. However, wishful statements like the third sentence are often annotated as non-opinion-bearing in sentiment analysis corpora (Hu and Liu, 2004; Ding et al., 2008), even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; </context>
<context position="23056" citStr="Ding et al., 2008" startWordPosition="3893" endWordPosition="3896">d let the machine learning algorithm decide what is most useful. Our third wish detector, [Templates], is a linear SVM with the 1622 binary wish template features. Our fourth wish detector, [Words + Templates], is a linear SVM with both template and word features. 4 Experimental Results 4.1 Target Domains and Experimental Setup We experimented with two domains, manually labeled at the sentence-level as wishes or non-wishes.4 Example wishes are listed in Table 6. Products. Consumer product reviews: 1,235 sentences selected from a collection of amazon.com and cnet.com reviews (Hu and Liu, 2004; Ding et al., 2008). 12% of the sentences are labeled as wishes. Politics. Political discussion board postings: 6,379 sentences selected from politics.com (Mullen and Malouf, 2008). 34% are labeled as wishes. We automatically split the corpora into sentences using MxTerminator (Reynar and Ratnaparkhi, 1997). As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down4Thesewish-annotated corpora are available for download at http://pages.cs.wisc.edu/∼goldberg/wish data. cased, and removed all punctuation. For all four wish detectors, we performed 10-fold cross validation. We used the </context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In WSDM ’08: Proceedings of the international conference on Web search and web data mining, pages 231– 240. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Ehrlichman</author>
<author>Rosalind Eichenstein</author>
</authors>
<date>1992</date>
<booktitle>Private wishes: Gender similarities and difference. Sex Roles,</booktitle>
<pages>26--9</pages>
<contexts>
<context position="5309" citStr="Ehrlichman and Eichenstein, 1992" startWordPosition="882" endWordPosition="885"> and Liu, 2004; Ding et al., 2008), even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalc</context>
</contexts>
<marker>Ehrlichman, Eichenstein, 1992</marker>
<rawString>Howard Ehrlichman and Rosalind Eichenstein. 1992. Private wishes: Gender similarities and difference. Sex Roles, 26(9):399–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>101</volume>
<pages>1--5228</pages>
<contexts>
<context position="12695" citStr="Griffiths and Steyvers, 2004" startWordPosition="2076" endWordPosition="2079"> topics in Section 2.1 were manually predefined based on domain knowledge. In contrast, in this section we applied Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to identify the latent topics in the full set of 89,574 English wishes in an 100 101 102 103 104 105 log(rank) Figure 3: The rank vs. frequency plot of wishes, approximately obeying Zipf’s law. Note the log-log scale. unsupervised fashion. The goal is to validate and complement the study in Section 2.1. To apply LDA to the wishes, we treated each individual wish as a short document. We used 12 topics, Collapsed Gibbs Sampling (Griffiths and Steyvers, 2004) for inference, hyperparameters α = 0.5 and Q = 0.1, and ran Markov Chain Monte Carlo for 2000 iterations. The resulting 12 LDA topics are shown in Table 2, in the form of the highest probability words p(wordltopic) in each topic. We manually added summary descriptors for readability. With LDA, it is also possible to observe which words were assigned to which topics in each wish. For example, LDA assigned most words in the wish “world(8) peace(8) and my friends(4) in iraq(1) to come(1) home(1)” to two topics: peace and troops (topic numbers in parentheses). Interestingly, these LDA topics larg</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101(suppl. 1):5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD ’04, the ACMSIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="3209" citStr="Hu and Liu, 2004" startWordPosition="508" endWordPosition="511">1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 peace on earth 351 peace 331 world peace 244 happy new year 112 love 76 health and happiness 75 to be happy 51 i wish for world peace 21 i wish for health and happiness for my family 21 let there be peace on earth 16 i wish u to call me ifyou read this 555-1234 16 to find my true love 8 i</context>
<context position="4691" citStr="Hu and Liu, 2004" startWordPosition="786" endWordPosition="789">ike 1 i wish to get more sex in 2008 1 please let name be healthy and live all year 1 to be emotionally stable and happy 1 to take over the world Table 1: Example wishes and their frequencies in the WISH corpus. uct review excerpt: “Great camera. Indoor shots with a flash are not quite as good as 35mm. I wish the camera had a higher optical zoom so that I could take even better wildlife photos.” The first sentence contains positive opinion, the second negative opinion. However, wishful statements like the third sentence are often annotated as non-opinion-bearing in sentiment analysis corpora (Hu and Liu, 2004; Ding et al., 2008), even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and</context>
<context position="23036" citStr="Hu and Liu, 2004" startWordPosition="3889" endWordPosition="3892">features total) and let the machine learning algorithm decide what is most useful. Our third wish detector, [Templates], is a linear SVM with the 1622 binary wish template features. Our fourth wish detector, [Words + Templates], is a linear SVM with both template and word features. 4 Experimental Results 4.1 Target Domains and Experimental Setup We experimented with two domains, manually labeled at the sentence-level as wishes or non-wishes.4 Example wishes are listed in Table 6. Products. Consumer product reviews: 1,235 sentences selected from a collection of amazon.com and cnet.com reviews (Hu and Liu, 2004; Ding et al., 2008). 12% of the sentences are labeled as wishes. Politics. Political discussion board postings: 6,379 sentences selected from politics.com (Mullen and Malouf, 2008). 34% are labeled as wishes. We automatically split the corpora into sentences using MxTerminator (Reynar and Ratnaparkhi, 1997). As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down4Thesewish-annotated corpora are available for download at http://pages.cs.wisc.edu/∼goldberg/wish data. cased, and removed all punctuation. For all four wish detectors, we performed 10-fold cross vali</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of KDD ’04, the ACMSIGKDD international conference on Knowledge discovery and data mining, pages 168–177. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale svm learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning.</booktitle>
<editor>In B. Sch¨olkopf, C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="23717" citStr="Joachims, 1999" startWordPosition="3987" endWordPosition="3988">Politics. Political discussion board postings: 6,379 sentences selected from politics.com (Mullen and Malouf, 2008). 34% are labeled as wishes. We automatically split the corpora into sentences using MxTerminator (Reynar and Ratnaparkhi, 1997). As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down4Thesewish-annotated corpora are available for download at http://pages.cs.wisc.edu/∼goldberg/wish data. cased, and removed all punctuation. For all four wish detectors, we performed 10-fold cross validation. We used the default parameter in SVMlight for all trials (Joachims, 1999). As the data sets are skewed, we compare the detectors using precision-recall curves and the area under the curve (AUC). For the manual baseline, we produce the curve by varying the number of templates applied (in rank order), which gradually predicts more sentences as wishes (increasing recall at the expense of precision). A final point is added at recall 1.0, corresponding to applying an empty template that matches all sentences. For the SVM-based methods, we vary the threshold applied to the real-valued margin prediction to produce the curves. All curves are interpolated, and AUC measures </context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale svm learning practical. In B. Sch¨olkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura A King</author>
<author>Sheri J Broyles</author>
</authors>
<title>Wishes, gender, personality, and well-being.</title>
<date>1997</date>
<journal>Journal of Personality,</journal>
<volume>65</volume>
<issue>1</issue>
<contexts>
<context position="5334" citStr="King and Broyles, 1997" startWordPosition="886" endWordPosition="889">, even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We sha</context>
</contexts>
<marker>King, Broyles, 1997</marker>
<rawString>Laura A. King and Sheri J. Broyles. 1997. Wishes, gender, personality, and well-being. Journal of Personality, 65(1):49–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Itai Shtrimberg</author>
</authors>
<title>Good news or bad news? let the market decide.</title>
<date>2004</date>
<booktitle>In AAAI Spring Symposium on Exploring Attitude and Affect in Text,</booktitle>
<pages>86--88</pages>
<contexts>
<context position="2975" citStr="Koppel and Shtrimberg, 2004" startWordPosition="468" endWordPosition="472">as consumer product reviews and online political discussions. Such wish detectors have tremendous value in collecting business intelligence and public opinions. We discuss the wish detectors in Section 3, and experimental results in Section 4. 1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 peace on earth 351 peace 331 world peace 244 happy new </context>
</contexts>
<marker>Koppel, Shtrimberg, 2004</marker>
<rawString>Moshe Koppel and Itai Shtrimberg. 2004. Good news or bad news? let the market decide. In AAAI Spring Symposium on Exploring Attitude and Affect in Text, pages 86–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saisuresh Krishnakumaran</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="5866" citStr="Krishnakumaran and Zhu, 2007" startWordPosition="963" endWordPosition="966">(Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods. Our analyses not only reveal what people wished for on New Year’s Eve, but also provide insight for the de</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13–20, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Hugo Liu</author>
</authors>
<title>A corpus-based approach to finding happiness.</title>
<date>2006</date>
<booktitle>In Proceedings ofAAAICAAW-06, the Spring Symposia on Computational Approaches to Analyzing Weblogs.</booktitle>
<contexts>
<context position="5926" citStr="Mihalcea and Liu, 2006" startWordPosition="973" endWordPosition="977">, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH corpus with a variety of statistical methods. Our analyses not only reveal what people wished for on New Year’s Eve, but also provide insight for the development of wish detectors in Section 3. The complete WISH </context>
</contexts>
<marker>Mihalcea, Liu, 2006</marker>
<rawString>Rada Mihalcea and Hugo Liu. 2006. A corpus-based approach to finding happiness. In Proceedings ofAAAICAAW-06, the Spring Symposia on Computational Approaches to Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carlo Strapparava</author>
</authors>
<title>Making computers laugh: Investigations in automatic humor recognition.</title>
<date>2005</date>
<booktitle>In Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5714" citStr="Mihalcea and Strapparava, 2005" startWordPosition="943" endWordPosition="946">ychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among others (Mishne et al., 2007; Mihalcea and Liu, 2006). We share the common goal of classifying text into a unique set of target categories (in our case, wishful and non-wishful), but use different techniques catered to our specific task. Our feature-generation technique for wish detection resembles template-based methods for information extraction (Brin, 1999; Agichtein and Gravano, 2000). 2 Analyzing the WISH Corpus We analyze the WISH </context>
</contexts>
<marker>Mihalcea, Strapparava, 2005</marker>
<rawString>Rada Mihalcea and Carlo Strapparava. 2005. Making computers laugh: Investigations in automatic humor recognition. In Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman A Milgram</author>
<author>Wolfgang W Riedel</author>
</authors>
<title>Developmental and experiential factors in making wishes.</title>
<date>1969</date>
<journal>Child Development,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="5275" citStr="Milgram and Riedel, 1969" startWordPosition="878" endWordPosition="881">iment analysis corpora (Hu and Liu, 2004; Ding et al., 2008), even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computational humor (Mihalcea and Strapparava, 2005), genre classification (Boese and Howe, 2005), authorship attribution (Argamon and Shimoni, 2003), and metaphor detection (Krishnakumaran and Zhu, 2007), among o</context>
</contexts>
<marker>Milgram, Riedel, 1969</marker>
<rawString>Norman A. Milgram and Wolfgang W. Riedel. 1969. Developmental and experiential factors in making wishes. Child Development, 40(3):763–771.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilad Mishne</author>
<author>Krisztian Balog</author>
<author>Maarten de Rijke</author>
<author>Breyten Ernsting</author>
</authors>
<title>Moodviews: Tracking and searching mood-annotated blog posts.</title>
<date>2007</date>
<booktitle>In Proceedings International Conf. on Weblogs and Social Media (ICWSM-2007),</booktitle>
<pages>323--324</pages>
<marker>Mishne, Balog, de Rijke, Ernsting, 2007</marker>
<rawString>Gilad Mishne, Krisztian Balog, Maarten de Rijke, and Breyten Ernsting. 2007. Moodviews: Tracking and searching mood-annotated blog posts. In Proceedings International Conf. on Weblogs and Social Media (ICWSM-2007), pages 323–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Mullen</author>
<author>Robert Malouf</author>
</authors>
<title>Taking sides: User classification for informal online political discourse.</title>
<date>2008</date>
<journal>Internet Research,</journal>
<pages>18--177</pages>
<contexts>
<context position="3001" citStr="Mullen and Malouf, 2008" startWordPosition="473" endWordPosition="476">nd online political discussions. Such wish detectors have tremendous value in collecting business intelligence and public opinions. We discuss the wish detectors in Section 3, and experimental results in Section 4. 1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 peace on earth 351 peace 331 world peace 244 happy new year 112 love 76 health an</context>
<context position="23217" citStr="Mullen and Malouf, 2008" startWordPosition="3915" endWordPosition="3918">eatures. Our fourth wish detector, [Words + Templates], is a linear SVM with both template and word features. 4 Experimental Results 4.1 Target Domains and Experimental Setup We experimented with two domains, manually labeled at the sentence-level as wishes or non-wishes.4 Example wishes are listed in Table 6. Products. Consumer product reviews: 1,235 sentences selected from a collection of amazon.com and cnet.com reviews (Hu and Liu, 2004; Ding et al., 2008). 12% of the sentences are labeled as wishes. Politics. Political discussion board postings: 6,379 sentences selected from politics.com (Mullen and Malouf, 2008). 34% are labeled as wishes. We automatically split the corpora into sentences using MxTerminator (Reynar and Ratnaparkhi, 1997). As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down4Thesewish-annotated corpora are available for download at http://pages.cs.wisc.edu/∼goldberg/wish data. cased, and removed all punctuation. For all four wish detectors, we performed 10-fold cross validation. We used the default parameter in SVMlight for all trials (Joachims, 1999). As the data sets are skewed, we compare the detectors using precision-recall curves and the area u</context>
</contexts>
<marker>Mullen, Malouf, 2008</marker>
<rawString>Tony Mullen and Robert Malouf. 2008. Taking sides: User classification for informal online political discourse. Internet Research, 18:177–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="2923" citStr="Pang and Lee, 2008" startWordPosition="460" endWordPosition="463"> their effectiveness on domains as diverse as consumer product reviews and online political discussions. Such wish detectors have tremendous value in collecting business intelligence and public opinions. We discuss the wish detectors in Section 3, and experimental results in Section 4. 1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 pea</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy approach to identifying sentence boundaries.</title>
<date>1997</date>
<booktitle>In Fifth Conference on Applied Natural Language Processing.</booktitle>
<contexts>
<context position="23345" citStr="Reynar and Ratnaparkhi, 1997" startWordPosition="3934" endWordPosition="3938">l Results 4.1 Target Domains and Experimental Setup We experimented with two domains, manually labeled at the sentence-level as wishes or non-wishes.4 Example wishes are listed in Table 6. Products. Consumer product reviews: 1,235 sentences selected from a collection of amazon.com and cnet.com reviews (Hu and Liu, 2004; Ding et al., 2008). 12% of the sentences are labeled as wishes. Politics. Political discussion board postings: 6,379 sentences selected from politics.com (Mullen and Malouf, 2008). 34% are labeled as wishes. We automatically split the corpora into sentences using MxTerminator (Reynar and Ratnaparkhi, 1997). As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down4Thesewish-annotated corpora are available for download at http://pages.cs.wisc.edu/∼goldberg/wish data. cased, and removed all punctuation. For all four wish detectors, we performed 10-fold cross validation. We used the default parameter in SVMlight for all trials (Joachims, 1999). As the data sets are skewed, we compare the detectors using precision-recall curves and the area under the curve (AUC). For the manual baseline, we produce the curve by varying the number of templates applied (in rank order), </context>
</contexts>
<marker>Reynar, Ratnaparkhi, 1997</marker>
<rawString>Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Fifth Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shanahan</author>
<author>Yan Qu</author>
<author>Janyce Wiebe</author>
<author>editors</author>
</authors>
<title>Computing attitude and affect in text.</title>
<date>2005</date>
<publisher>Springer,</publisher>
<location>Dordrecht, The Netherlands.</location>
<contexts>
<context position="2946" citStr="Shanahan et al., 2005" startWordPosition="464" endWordPosition="467"> on domains as diverse as consumer product reviews and online political discussions. Such wish detectors have tremendous value in collecting business intelligence and public opinions. We discuss the wish detectors in Section 3, and experimental results in Section 4. 1.1 Relation to Prior Work Studying wishes is valuable in at least two aspects: 1. Being a special genre of subjective expression, wishes add a novel dimension to sentiment analysis. Sentiment analysis is often used as an automatic market research tool to collect valuable business intelligence from online text (Pang and Lee, 2008; Shanahan et al., 2005; Koppel and Shtrimberg, 2004; Mullen and Malouf, 2008). Wishes differ from the recent focus of sentiment analysis, namely opinion mining, by revealing what people explicitly want to happen, not just what they like or dislike (Ding et al., 2008; Hu and Liu, 2004). For example, wishes in product reviews could contain new feature requests. Consider the following (real) prod263 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263–271, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 514 peace on earth 351 peace 3</context>
</contexts>
<marker>Shanahan, Qu, Wiebe, editors, 2005</marker>
<rawString>James Shanahan, Yan Qu, and Janyce Wiebe, editors. 2005. Computing attitude and affect in text. Springer, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George S Speer</author>
</authors>
<title>Oral and written wishes of rural and city school children.</title>
<date>1939</date>
<journal>Child Development,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="5074" citStr="Speer, 1939" startWordPosition="848" endWordPosition="849">fe photos.” The first sentence contains positive opinion, the second negative opinion. However, wishful statements like the third sentence are often annotated as non-opinion-bearing in sentiment analysis corpora (Hu and Liu, 2004; Ding et al., 2008), even though they clearly contain important information. An automatic “wish detector” text-processing tool can be useful for product manufacturers, advertisers, politicians, and others looking to discover what people want. 2. Wishes can tell us a lot about people: their innermost feelings, perceptions of what they’re lacking, and what they desire (Speer, 1939). Many psychology researchers have attempted to quantify the contents of wishes and how they vary with factors such as location, gender, age, and personality type (Speer, 1939; Milgram and Riedel, 1969; Ehrlichman and Eichenstein, 1992; King and Broyles, 1997). These studies have been small scale with only dozens or hundreds of participants. The WISH corpus provides the first large-scale collection of wishes as a window into the world’s desires. Beyond sentiment analysis, classifying sentences as wishes is an instance of non-topical classification. Tasks under this heading include computationa</context>
</contexts>
<marker>Speer, 1939</marker>
<rawString>George S. Speer. 1939. Oral and written wishes of rural and city school children. Child Development, 10(3):151–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>Selected Studies of the Principle of Relative Frequency in Language.</title>
<date>1932</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="11607" citStr="Zipf, 1932" startWordPosition="1894" endWordPosition="1895"> Wish topics differ by Location (b) Wish scopes differ by Location Figure 2: Geographical breakdown of topic and scope distributions based on approximately 4,000 locationtagged wishes. Asterisks indicate statistically significant differences. 2.3 Wishes Follow Zipf’s Law We now move beyond the annotated subsample and examine the full set of 89,574 English wishes. We noticed that a small fraction (4%) of unique wishes account for a relatively large portion (16%) of wish occurrences, while there are also many wishes that only occur once. The question naturally arises: do wishes obey Zipf’s Law (Zipf, 1932; Manning and Sch¨utze, 1999)? If so, we should expect the frequency of a unique wish to be inversely proportional to its rank, when sorted by frequency. Figure 3 plots rank versus frequency on a log-log scale and reveals an approximately linear negative slope, thus suggesting that wishes do follow Zipf’s law. It also shows that low-occurrence wishes dominate, hence learning might be hindered by data sparseness. 2.4 Latent Topic Modeling for Wishes The 11 topics in Section 2.1 were manually predefined based on domain knowledge. In contrast, in this section we applied Latent Dirichlet Allocatio</context>
</contexts>
<marker>Zipf, 1932</marker>
<rawString>G. K. Zipf. 1932. Selected Studies of the Principle of Relative Frequency in Language. Harvard University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>