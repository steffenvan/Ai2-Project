<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000314">
<title confidence="0.980994">
iSTART: Paraphrase Recognition
</title>
<author confidence="0.984117">
Chutima Boonthum
</author>
<affiliation confidence="0.941281">
Computer Science Department
Old Dominion University, Norfolk, VA-23508 USA
</affiliation>
<email confidence="0.996599">
cboont@cs.odu.edu
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999934285714286">
Paraphrase recognition is used in a num-
ber of applications such as tutoring sys-
tems, question answering systems, and
information retrieval systems. The con-
text of our research is the iSTART read-
ing strategy trainer for science texts,
which needs to understand and recognize
the trainee’s input and respond appropri-
ately. This paper describes the motivation
for paraphrase recognition and develops a
definition of the strategy as well as a rec-
ognition model for paraphrasing. Lastly,
we discuss our preliminary implementa-
tion and research plan.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998726754716981">
A web-based automated reading strategy trainer
called iSTART (Interactive Strategy Trainer for
Active Reading and Thinking) adaptively assigns
individual students to appropriate reading train-
ing programs. It follows the SERT (Self-
Explanation Reading Training) methodology de-
veloped by McNamara (in press) as a way to im-
prove high school students’ reading ability by
teaching them to use active reading strategies in
self-explaining difficult texts. Details of the
strategies can be found in McNamara (in press)
and of iSTART in Levinstein et al. (2003)
During iSTART’s practice module, the student
self-explains a sentence. Then the trainer ana-
lyzes the student’s explanation and responds. The
current system uses simple word- matching algo-
rithms to evaluate the student’s input that do not
yield results that are sufficiently reliable or accu-
rate. We therefore propose a new system for han-
dling the student’s explanation more effectively.
Two major tasks of this semantically-based sys-
tem are to (1) construct an internal representation
of sentences and explanations and (2) recognize
the reading strategies the student uses beginning
with paraphrasing.
Construct an Internal Representation: We
transform the natural language explanation into a
representation suitable for later analysis. The
Sentence Parser gives us a syntactically and
morphologically tagged representation. We trans-
form the output of the Link Grammar parser
(CMU, 2000) that generates syntactical and mor-
phological information into an appropriate
knowledge representation using the Representa-
tion Generator.
Recognize Paraphrasing: In what follows,
we list the paraphrase patterns that we plan to
cover and define a recognition model for each
pattern. This involves two steps: (1) recognizing
paraphrasing patterns, and (2) reporting the re-
sult. The Paraphrase Recognizer compares two
internal representation (one is of a given sentence
and another is of the student’s explanation) and
finds paraphrase matches (“concept-relation-
concept” triplet matches) according to a para-
phrasing pattern. The Reporter provides the final
summary of the total paraphrase matches, noting
unmatched information in either the sentence or
the explanation. Based on the similarity measure,
the report will include whether the student has
fully or partially paraphrased a given sentence
and whether it contains any additional informa-
tion.
</bodyText>
<sectionHeader confidence="0.989416" genericHeader="introduction">
2 Paraphrase
</sectionHeader>
<bodyText confidence="0.999684857142857">
When two expressions describe the same situa-
tion, each is considered to be a paraphrase of the
other. There is no precise paraphrase definition in
general; instead there are frequently-accepted
paraphrasing patterns to which various authori-
ties refer. Academic writing centers (ASU Writ-
ing Center, 2000; BAC Writing Center; USCA
Writing Room; and Hawes, 2003) provide a
number of characterizations, such as using syno-
nyms, changing part-of-speech, reordering ideas,
breaking a sentence into smaller ones, using defi-
nitions, and using examples. McNamara (in
press), on the other hand, does not consider using
definitions or examples to be part of paraphras-
ing, but rather considers them elaboration. Stede
(1996) considers different aspects or intentions to
be paraphrases if they mention the same content
or situation.
Instead of attempting to find a single para-
phrase definition, we will start with six com-
monly mentioned paraphrasing patterns:
</bodyText>
<listItem confidence="0.993797461538461">
1. Synonym: substitute a word with its syno-
nym, e.g. help, assist, aid;
2. Voice: change the voice of sentence from ac-
tive to passive or vice versa;
3. Word-Form/Part-of-speech: change a word
into a different form, e.g. change a noun to a
verb, adverb, or adjective;
4. Break down Sentence: break a long sen-
tence down into small sentences;
5. Definition/Meaning: substitute a word with
its definition or meaning;
6. Sentence Structure: use different sentence
structures to express the same thing.
</listItem>
<bodyText confidence="0.9995174">
If the explanation has any additional information
or misses some information that appeared in the
original sentence, we should be able to detect this
as well for use in discovering additional strate-
gies employed.
</bodyText>
<sectionHeader confidence="0.99851" genericHeader="method">
3 Recognition Model
</sectionHeader>
<bodyText confidence="0.99983">
To recognize paraphrasing, we convert natural
language sentences into Conceptual Graphs (CG,
Sowa, 1983; 1992) and then compare two CGs
for matching according to paraphrasing patterns.
The matching process is to find as many “con-
cept-relation-concept triplet” matches as possi-
ble. A triplet match means that a triplet from the
student’s input matches with a triplet from the
given sentence. In particular, the left-concept,
right-concept, and relation of both sub-graphs
have to be exactly the same, or the same under a
transformation based on a relationship of synon-
ymy (or other relation defined in WordNet), or
the same because of idiomatic usage. It is also
possible that several triplets of one sentence to-
gether match a single triplet of the other. At the
end of this pattern matching, a summary result is
provided: total paraphrasing matches, unpara-
phrased information and additional information
(not appearing in the given sentence).
</bodyText>
<subsectionHeader confidence="0.99974">
3.1 Conceptual Graph Generation
</subsectionHeader>
<bodyText confidence="0.999947083333333">
A natural language sentence is converted into a
conceptual graph using the Link Grammar parser.
This process mainly requires mapping one or
more Link connector types into a relation of the
conceptual graph.
A parse from the Link Grammar consists of
triplets: starting word, an ending word, and a
connector type between these two words. For
example, [1 2 (Sp)] means word-1 connects to
word-2 with a subject connector or that word-1 is
the subject of word-2. The sentence “A walnut is
eaten by a monkey” is parsed as follows:
</bodyText>
<equation confidence="0.7994785">
[(0=LEFT-WALL)(1=a)(2=walnut.n)(3=is.v)
(4=eaten.v)(5=by)(6=a)(7=monkey.n)(8=.)]
[[0 8 (Xp)][0 2 (Wd)][1 2 (Dsu)][2 3 (Ss)]
[3 4 (Pv)][4 5 (MVp)][5 7 (Js)][6 7 (Ds)]]
</equation>
<bodyText confidence="0.999789538461539">
We then convert each Link triplet into a corre-
sponding CG triplet. Two words in the Link trip-
let can be converted into two concepts of the CG.
To decide whether to put a word on the left or the
right side of the CG triplet, we define a mapping
rule for each Link connector type. For example, a
Link triplet [1 2 (S*)] will be mapped to the
‘Agent’ relation, with word-2 as the left-concept
and word-1 as the right-concept: [Word-2] —&gt;
(Agent) —&gt; [Word-1]. Sometimes it is necessary
to consider several Link triplets in generating a
single CG triplet. A CG of previous example is
shown below:
</bodyText>
<equation confidence="0.943762583333333">
0 [0 8 (Xp)] -&gt; #S# -&gt; - N/A -
1 [0 2 (Wd)] -&gt; #S# -&gt; - N/A -
2 [1 2 (Dsu)] -&gt; #S# -&gt;
[walnut.n]-&gt;(Article)-&gt;[a]
3 [2 3 (Ss)] -&gt; #M# S + Pv (4) # -&gt;
[eaten.v]-&gt;(Patient)-&gt;[walnut.n]
4 [3 4 (Pv)] -&gt; #M# Pv +MV(5)+O(6)# -&gt;
[eaten.v] -&gt; (Agent) -&gt; [monkey.n]
5 [4 5 (MVp)] -&gt; #S# eaten.v by
6 [5 7 (Js)] -&gt; #S# monkey.n by
7 [6 7 (Ds)] -&gt; #S# -&gt;
[monkey.n] -&gt; (Article) -&gt; [a]
</equation>
<bodyText confidence="0.99703675">
Each line (numbered 0-7) shows a Link triplet
and its corresponding CG triplet. These will be
used in the recognition process. The ‘#S#’ and
‘#M’ indicate single and multiple mapping rules.
</bodyText>
<subsectionHeader confidence="0.999522">
3.2 Paraphrase Recognition
</subsectionHeader>
<bodyText confidence="0.999849210526316">
We illustrate our approach to paraphrase pattern
recognition on single sentences: using synonyms
(single or compound-word synonyms and idio-
matic expressions), changing the voice, using a
different word form, breaking a long sentence
into smaller sentences, substituting a definition
for a word, and changing the sentence structure.
Preliminaries: Before we start the recognition
process, we need to assume that we have all the
information about the text: each sentence has
various content words (excluding such ‘stop
words’ as a, an, the, etc.); each content word has
a definition together with a list of synonyms, an-
tonyms, and other relations provided by WordNet
(Fellbaum, 1998). To prepare a given text and a
sentence, we plan to have an automated process
that generates necessary information as well as
manual intervention to verify and rectify the
automated result, if necessary.
</bodyText>
<listItem confidence="0.95018">
Single-Word Synonyms: First we discover
that both CGs have the same pattern and then we
check whether words in the same position are
synonyms. Example:
</listItem>
<figure confidence="0.845513428571429">
“Jenny helps Kay”
[Help]  (Agent)  [Person: Jenny]
+ (Patient)  [Person: Kay]
vs.
“Jenny assists Kay”
[Assist]  (Agent)  [Person: Jenny]
+ (Patient)  [Person: Kay]
</figure>
<bodyText confidence="0.927214714285714">
Compound-Word Synonyms: In this case,
we need to be able to match a word and its com-
pound-word synonym. For example, ‘install’ has
‘set up’ and ‘put in’ as its compound-word syno-
nyms. The compound words are declared by the
parser program. During the preliminary process-
ing CGs are pre-generated.
</bodyText>
<equation confidence="0.667364333333333">
[Install]  (Object)  [Thing]
 [Set-Up]  (Object)  [Thing]
 [Put-In]  (Object)  [Thing]
</equation>
<bodyText confidence="0.6245325">
Then, this case will be treated like the single-
word synonym.
</bodyText>
<equation confidence="0.615959714285714">
“Jenny installs a computer”
[Install]  (Agent)  [Person: Jenny]
+ (Object)  [Computer]
vs.
“Jenny sets up a computer”
[Set-Up]  (Agent)  [Person: Jenny]
+ (Object)  [Computer]
</equation>
<bodyText confidence="0.8962178">
Idiomatic Clause/Phrase: For each idiom, a
CG will be generated and used in the comparison
process. For example, the phrase ‘give someone a
hand’ means ‘help’. The preliminary process will
generate the following conceptual graph:
</bodyText>
<equation confidence="0.468335375">
[Help]  (Patient)  [Person: x]
 [Give]  (Patient)  [Person: x]
+ (Object)  [Hand]
which gives us
“Jenny gives Kay a hand”
[Give]  (Agent)  [Person: Jenny]
+ (Patient)  [Person: Kay]
+ (Object)  [Hand]
</equation>
<bodyText confidence="0.999539444444444">
In this example, one might say that a ‘hand’
might be an actual (physical) hand rather than a
synonym phrase for ‘help’. To reduce this par-
ticular ambiguity, the analysis of the context may
be necessary.
Voice: Even if the voice of a sentence is
changed, it will have the same CG. For example,
both “Jenny helps Kay” and “Kay is helped by
Jenny” have the same graphs as follows:
</bodyText>
<equation confidence="0.729411">
[Help]  (Agent)  [Person: Jenny]
+ (Patient)  [Person: Kay]
</equation>
<bodyText confidence="0.942362074074074">
At this time we are assuming that if two CGs are
exactly the same, it means paraphrasing by
changing voice pattern. However, we plan to in-
troduce a modified conceptual graph that retains
the original sentence structure so that we can ver-
ify that it was paraphrasing by change of voice
and not simple copying.
Part-of-speech: A paraphrase can be gener-
ated by changing the part-of-speech of some
keywords. In the following example, the student
uses “a historical life story” instead of “life his-
tory”, and ‘similarity’ instead of ‘similar’.
Original sentence: “All thunderstorms have a similar
life history.”
Student’s Explanation: “All thunderstorms have
similarity in their historical life story.”
To find this paraphrasing pattern, we look for the
same word, or a word that has the same base-
form. In this example, the sentences share the
same base-form for ‘similar’ and ‘similarity’ as
well as for ‘history’ and ‘historical’.
Breaking long sentence: A sentence can be
explained by small sentences coupled up together
in such a way that each covers a part of the origi-
nal sentence. We integrate CGs of all sentences
in the student’s input together before comparing
it with the original sentence.
</bodyText>
<figure confidence="0.786699642857143">
Original sentence: “All thunderstorms have a similar
life history.”
[Thunderstorm: b&apos;] –
(Feature) --&gt; [History] –
(Attribute) --&gt; [Life]
(Attribute) --&gt; [Similar]
Student’s Explanation: “Thunderstorms have life
history. It is similar among all thunderstorms”
[Thunderstorm] –
(Feature) --&gt; [History] –
(Attribute) --&gt; [Life]
[It] (pronoun)–
(Attribute) --&gt; [Similar]
(Mod) --&gt; [Thunderstorm: b&apos;] (among)
</figure>
<bodyText confidence="0.999285388888889">
We will provisionally assume that the student
uses only the words that appear in the sentence in
this breaking down process. One solution is to
combine graphs from all sentences together. This
can be done by merging graphs of the same con-
cept. This process involves pronoun resolution.
In this example, ‘it’ could refer to ‘life’ or ‘his-
tory’. Our plan is to exercise all possible pronoun
references and select one that gives the best para-
phrasing recognition result.
Definition/Meaning: A CG is pre-generated
for a definition of each word and its associations
(synonyms, idiomatic expressions, etc.). To find
a paraphrasing pattern of using the definition, for
example, a ‘history’ means “the continuum of
events occurring in succession leading from the
past to the present and even into the future”, we
build a CG for this as shown below:
</bodyText>
<equation confidence="0.9995269">
[Continuum] –
(Attribute) --&gt; [Event: 3]
[Occur] –
(Patient) --&gt; [Event: 3]
(Mod) --&gt; [Succession] (in)
[Lead] –
(Initiator) --&gt; [Succession]
(Source) --&gt; [Time: Past] (from)
(Path) --&gt; [Time: Present] (to)
(Path) --&gt; [Time: Future] (into)
</equation>
<bodyText confidence="0.999309">
We refine this CG by incorporating CGs of the
definition into a single integrated CG, if possible.
</bodyText>
<equation confidence="0.9982256">
(Patient) --&gt; [Event: 3]
(Mod) --&gt; [Succession] (in)
(Source) --&gt; [Time: Past] (from)
(Path) --&gt; [Time: Present] (to)
(Path) --&gt; [Time: Future] (into)
</equation>
<bodyText confidence="0.999699">
From WordNet 2.0, the synonyms of ‘past’, ‘pre-
sent’, and ‘future’ found to be “begin, start, be-
ginning process”, “middle, go though, middle
process”, and “end, last, ending process”, respec-
tively. The following example shows how they
can be used in recognizing paraphrases.
</bodyText>
<figure confidence="0.605745428571429">
Original sentence: “All thunderstorms have a similar
life history.”
[Thunderstorm: b&apos;] –
(Feature) --&gt; [History] –
(Attribute) --&gt; [Life]
(Attribute) --&gt; [Similar]
Student’s Explanation: “Thunderstorms go through
</figure>
<figureCaption confidence="0.455164">
similar cycles. They will begin the same, go through
</figureCaption>
<bodyText confidence="0.570256">
the same things, and end the same way.”
</bodyText>
<equation confidence="0.970667916666667">
[Go] –
(Agent) --&gt; [Thunderstorm: #]
(Path) --&gt; [Cycle] --&gt; (Attribute) --&gt; [Similar]
[Begin] –
(Agent) --&gt; [Thunderstorm: #]
(Attribute) --&gt; [Same]
[Go-Through] –
(Agent) --&gt; [Thunderstorm: #]
(Path) --&gt; [Thing: 3 ] --&gt; (Attribute) --&gt; [Same]
[End] –
(Agent) --&gt; [Thunderstorm: #]
(Path) --&gt; [Way: 3 ] --&gt; (Attribute) --&gt; [Same]
</equation>
<bodyText confidence="0.999824875">
From this CG, we found the use of ‘begin’, ‘go-
through’, and ‘end’, which are parts of the CG of
history’s definition. These together with the cor-
respondence of words in the sentences show that
the student has used paraphrasing by using a
definition of ‘history’ in the self-explanation.
Sentence Structure: The same thing can be
said in a number of different ways. For example,
to say “There is someone happy”, we can say
“Someone is happy”, “A person is happy”, or
“There is a person who is happy”, etc. As can be
easily seen, all sentences have a similar CG trip-
let of “[Person: 3] --&gt; (Char) --&gt; [Happy]” in their
CGs. But, we cannot simply say that they are
paraphrases of each other; therefore, need to
study more on possible solutions.
</bodyText>
<subsectionHeader confidence="0.999683">
3.3 Similarity Measure
</subsectionHeader>
<bodyText confidence="0.998467666666667">
The similarity between the student’s input and
the given sentence can be categorized into one of
these four cases:
</bodyText>
<listItem confidence="0.9996475">
1. Complete paraphrase without extra info.
2. Complete paraphrase with extra info.
3. Partial paraphrase without extra info.
4. Partial paraphrase with extra info.
</listItem>
<bodyText confidence="0.984198047619048">
To distinguish between ‘complete’ and ‘partial’
paraphrasing, we will use the triplet matching
result. What counts as complete depends on the
context in which the paraphrasing occurs. If we
consider the paraphrasing as a writing technique,
the ‘complete’ paraphrasing would mean that all
triplets of the given sentence are matched to
those in the student’s input. Similarly, if any trip-
lets in the given sentence do not have a match, it
means that the student is ‘partially’ paraphrasing
at best. On the other hand, if we consider the
paraphrasing as a reading behavior or strategy,
the ‘complete’ paraphrasing may not need all
triplets of the given sentence to be matched.
Hence, recognizing which part of the student’s
input is a paraphrase of which part of the given
sentence is significant. How can we tell that this
explanation is an adequate paraphrase? Can we
use information provided in the given sentence as
a measurement? If so, how can we use it? These
questions still need to be answered.
</bodyText>
<sectionHeader confidence="0.999916" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999494135135135">
A number of people have worked on paraphras-
ing such as the multilingual-translation recogni-
tion by Smith (2003), the multilingual sentence
generation by Stede (1996), universal model
paraphrasing using transformation by Murata and
Isahara (2001), DIRT – using inference rules in
question answering and information retrieval by
Lin and Pantel (2001). Due to the space limita-
tion we will mention only a few related works.
ExtrAns (Extracting answers from technical
texts) by (Molla et al, 2003) and (Rinaldi et al,
2003) uses minimal logical forms (MLF) to rep-
resent both texts and questions. They identify
terminological paraphrases by using a term-based
hierarchy with their synonyms and variations;
and syntactic paraphrases by constructing a
common representation for different types of syn-
tactic variation via meaning postulates. Absent a
paraphrase, they loosen the criteria by using hy-
ponyms, finding highest overlap of predicates,
and simple keyword matching.
Barzilay &amp; Lee (2003) also identify para-
phrases in their paraphrased sentence generation
system. They first find different paraphrasing
rules by clustering sentences in comparable cor-
pora using n-gram word-overlap. Then for each
cluster, they use multi-sequence alignment to find
intra-cluster paraphrasing rules: either morpho-
syntactic or lexical patterns. To identify inter-
cluster paraphrasing, they compare the slot val-
ues without considering word ordering.
In our system sentences are represented by
conceptual graphs. Paraphrases are recognized
through idiomatic expressions, definition, and
sentence break up. Morpho-syntatic variations
are also used but in more general way than the
term hierarchy-based approach of ExtrAns.
</bodyText>
<sectionHeader confidence="0.996163" genericHeader="method">
5 Preliminary Implementation
</sectionHeader>
<bodyText confidence="0.999384214285714">
We have implemented two components to recog-
nize paraphrasing with the CG for a single simple
sentence: Automated Conceptual Graph Genera-
tor and Automated Paraphrasing Recognizer.
Automated Conceptual Graph Generator: is a
C++ program that calls the Link Grammar API to
get the parse result for the input sentence, and
generates a CG. We can generate a CG for a sim-
ple sentence using the first linkage result. Future
versions will deal with complex sentence struc-
ture as well as multiple linkages, so that we can
cover most paraphrases.
Automated Paraphrasing Recognizer: The in-
put to the Recognizer is a pair of CGs: one from
the original sentence and another from the stu-
dent’s explanation. Our goal is to recognize
whether any paraphrasing was used and, if so,
what was the paraphrasing pattern. Our first im-
plementation is able to recognize paraphrasing on
a single sentence for exact match, direct synonym
match, first level antonyms match, hyponyms and
hypernyms match. We plan to cover more rela-
tionships available in WordNet as well as defini-
tions, idioms, and logically equivalent
expressions. Currently, voice difference is treated
as an exact match because both active voices
have the same CGs and we have not yet modified
the conceptual graph as indicated above.
</bodyText>
<sectionHeader confidence="0.998594" genericHeader="discussions">
6 Discussion and Remaining Work
</sectionHeader>
<bodyText confidence="0.999987692307692">
Our preliminary implementation shows us that
paraphrase recognition is feasible and allows us
to recognize different types of paraphrases. We
continue to work on this and improve our recog-
nizer so that it can handle more word relations
and more types of paraphrases. During the test-
ing, we will use data gathered during our previ-
ous iSTART trainer experiments. These are the
actual explanations entered by students who were
given the task of explaining sentences. Fortu-
nately, quite a bit of these data have been evalu-
ated by human experts for quality of explanation.
Therefore, we can validate our paraphrasing rec-
ognition result against the human evaluation.
Besides implementing the recognizer to cover
all paraphrasing patterns addressed above, there
are many issues that need to be solved and im-
plemented during this course of research.
The Representation for a simple sentence is
the Conceptual Graph, which is not powerful
enough to represent complex, compound sen-
tences, multiple sentences, paragraphs, or entire
texts. We will use Rhetorical Structure Theory
(RST) to represent the relations among the CGs
of these components of these more complex
structures. This will also involve Pronoun Reso-
lution as well as Discourse Chunking. Once a
representation has been selected, we will imple-
ment an automated generator for such representa-
tion.
The Recognizer and Paraphrase Reporter have
to be completed. The similarity measures for
writing technique and reading behavior must still
be defined.
Once all processes have been implemented, we
need to verify that they are correct and validate
the results. Finally, we can integrate this recog-
nition process into the iSTART trainer in order to
improve the existing evaluation system.
</bodyText>
<sectionHeader confidence="0.996006" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99928225">
This dissertation work is under the supervision of
Dr. Shunichi Toida and Dr. Irwin Levinstein.
iSTART is supported by National Science Foun-
dation grant REC-0089271.
</bodyText>
<sectionHeader confidence="0.999248" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998845">
ASU Writing Center. 2000. Paraphrasing: Restating
Ideas in Your Own Words. Arizona State Univer-
sity, Tempe: AZ.
BAC Writing Center. Paraphrasing. Boston Architec-
tural Center. Boston: MA.
Carnegie Mellon University. 2000. Link Grammar.
R. Barzilay and L. Lee. 2003. Learning to Paraphrase:
An Unsupervised Approach Using Multiple-
Sequence Alignment. In HLT-NAACL, Edmonton:
Canada, pp. 16-23.
C. Boonthum, S. Toida, and I. Levinstein. 2003. Para-
phrasing Recognition through Conceptual Graphs.
Computer Science Department, Old Dominion
University, Norfolk: VA. (TR# is not available)
C. Boonthum. 2004. iSTART: Paraphrasing Recogni-
tion. Ph.D. Proposal: Computer Science Depart-
ment, Old Dominion University, VA.
C. Fellbaum. 1998. WordNet: an electronic lexical
database. The MIT Press: MA.
K. Hawes. 2003. Mastering Academic Writing: Write
a Paraphrase Sentence. University of Memphis,
Memphis: TN.
I. Levinstein, D. McNamara, C. Boonthum, S. Pillar-
isetti, and K. Yadavalli. 2003. Web-Based Inter-
vention for Higher-Order Reading Skills. In ED-
MEDIA, Honolulu: HI, pp. 835-841.
D. Lin and P. Pantel. 2001. Discovery of Inference
Rules for Question Answering. Natural Language
Engineering 7(4):343-360.
W. Mann and S. Thompson, 1987. Rhetorical Struc-
ture Theory: A Theory of Text Organization. The
Structure of Discourse, Ablex.
D. McNamara. (in press). SERT: Self-Explanation
Reading Training. Discourse Processes.
D. Molla, R. Schwitter, F. Rinaldi, J. Dowdall, and M.
Hess. 2003. ExtrAns: Extracting Answers from
Technical Texts. IEEE Intelligent System 18(4):
12-17.
M. Murata and H. Isahara. 2001. Universal Model for
Paraphrasing – Using Transformation Based on a
Defined Criteria. In NLPRS: Workshop on Auto-
matic Paraphrasing: Theories and Application.
F. Rinaldi, J. Dowdall, K. Kaljurand, M. Hess, and D.
Molla. 2003. Exploiting Paraphrases in Question
Answering System. In ACL: Workshop in Para-
phrasing, Sapporo: Japan, pp. 25-32.
N. Smith. 2002. From Words to Corpora: Recognizing
Translation. In EMNLP, Philadelphia: PA.
J. Sowa. 1983. Conceptual Structures: Information
Processing in Mind and Machine. Addison-Wesley,
MA.
J. Sowa. 1992. Conceptual Graphs as a Universal
Knowledge Representation. Computers Math. Ap-
plication, 23(2-5): 75-93.
M. Stede. 1996. Lexical semantics and knowledge
representation in multilingual sentence generation.
Ph.D. thesis: Department of Computer Science,
University of Toronto, Canada.
USCA Writing Room. Paraphrasing. The University
of South Carolina: Aiken. Aiken: SC.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.558163">
<title confidence="0.999837">iSTART: Paraphrase Recognition</title>
<author confidence="0.989072">Chutima Boonthum</author>
<affiliation confidence="0.999599">Computer Science Department</affiliation>
<address confidence="0.588364">Old Dominion University, Norfolk, VA-23508 USA</address>
<email confidence="0.999569">cboont@cs.odu.edu</email>
<abstract confidence="0.997284533333333">Paraphrase recognition is used in a number of applications such as tutoring systems, question answering systems, and information retrieval systems. The context of our research is the iSTART reading strategy trainer for science texts, which needs to understand and recognize the trainee’s input and respond appropriately. This paper describes the motivation for paraphrase recognition and develops a definition of the strategy as well as a recognition model for paraphrasing. Lastly, we discuss our preliminary implementation and research plan.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ASU Writing Center</author>
</authors>
<title>Paraphrasing: Restating Ideas in Your Own Words. Arizona State University,</title>
<date>2000</date>
<publisher>AZ.</publisher>
<location>Tempe:</location>
<contexts>
<context position="3413" citStr="Center, 2000" startWordPosition="499" endWordPosition="500">al summary of the total paraphrase matches, noting unmatched information in either the sentence or the explanation. Based on the similarity measure, the report will include whether the student has fully or partially paraphrased a given sentence and whether it contains any additional information. 2 Paraphrase When two expressions describe the same situation, each is considered to be a paraphrase of the other. There is no precise paraphrase definition in general; instead there are frequently-accepted paraphrasing patterns to which various authorities refer. Academic writing centers (ASU Writing Center, 2000; BAC Writing Center; USCA Writing Room; and Hawes, 2003) provide a number of characterizations, such as using synonyms, changing part-of-speech, reordering ideas, breaking a sentence into smaller ones, using definitions, and using examples. McNamara (in press), on the other hand, does not consider using definitions or examples to be part of paraphrasing, but rather considers them elaboration. Stede (1996) considers different aspects or intentions to be paraphrases if they mention the same content or situation. Instead of attempting to find a single paraphrase definition, we will start with si</context>
</contexts>
<marker>Center, 2000</marker>
<rawString>ASU Writing Center. 2000. Paraphrasing: Restating Ideas in Your Own Words. Arizona State University, Tempe: AZ.</rawString>
</citation>
<citation valid="false">
<institution>BAC Writing Center. Paraphrasing. Boston Architectural Center.</institution>
<location>Boston: MA.</location>
<marker></marker>
<rawString>BAC Writing Center. Paraphrasing. Boston Architectural Center. Boston: MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Learning to Paraphrase: An Unsupervised Approach Using MultipleSequence Alignment.</title>
<date>2000</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>16--23</pages>
<publisher>Canada,</publisher>
<institution>Carnegie Mellon University.</institution>
<location>Edmonton:</location>
<marker>Barzilay, Lee, 2000</marker>
<rawString>Carnegie Mellon University. 2000. Link Grammar. R. Barzilay and L. Lee. 2003. Learning to Paraphrase: An Unsupervised Approach Using MultipleSequence Alignment. In HLT-NAACL, Edmonton: Canada, pp. 16-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Boonthum</author>
<author>S Toida</author>
<author>I Levinstein</author>
</authors>
<title>Paraphrasing Recognition through Conceptual Graphs.</title>
<date>2003</date>
<institution>Computer Science Department, Old Dominion University,</institution>
<location>Norfolk: VA.</location>
<note>(TR# is not available)</note>
<marker>Boonthum, Toida, Levinstein, 2003</marker>
<rawString>C. Boonthum, S. Toida, and I. Levinstein. 2003. Paraphrasing Recognition through Conceptual Graphs. Computer Science Department, Old Dominion University, Norfolk: VA. (TR# is not available)</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Boonthum</author>
</authors>
<title>iSTART: Paraphrasing Recognition.</title>
<date>2004</date>
<tech>Ph.D. Proposal:</tech>
<institution>Computer Science Department, Old Dominion University, VA.</institution>
<marker>Boonthum, 2004</marker>
<rawString>C. Boonthum. 2004. iSTART: Paraphrasing Recognition. Ph.D. Proposal: Computer Science Department, Old Dominion University, VA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>The MIT Press: MA.</publisher>
<contexts>
<context position="8317" citStr="Fellbaum, 1998" startWordPosition="1308" endWordPosition="1309">ngle sentences: using synonyms (single or compound-word synonyms and idiomatic expressions), changing the voice, using a different word form, breaking a long sentence into smaller sentences, substituting a definition for a word, and changing the sentence structure. Preliminaries: Before we start the recognition process, we need to assume that we have all the information about the text: each sentence has various content words (excluding such ‘stop words’ as a, an, the, etc.); each content word has a definition together with a list of synonyms, antonyms, and other relations provided by WordNet (Fellbaum, 1998). To prepare a given text and a sentence, we plan to have an automated process that generates necessary information as well as manual intervention to verify and rectify the automated result, if necessary. Single-Word Synonyms: First we discover that both CGs have the same pattern and then we check whether words in the same position are synonyms. Example: “Jenny helps Kay” [Help]  (Agent)  [Person: Jenny] + (Patient)  [Person: Kay] vs. “Jenny assists Kay” [Assist]  (Agent)  [Person: Jenny] + (Patient)  [Person: Kay] Compound-Word Synonyms: In this case, we need to be able to match a w</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: an electronic lexical database. The MIT Press: MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hawes</author>
</authors>
<title>Mastering Academic Writing: Write a Paraphrase Sentence.</title>
<date>2003</date>
<publisher>TN.</publisher>
<institution>University of Memphis,</institution>
<location>Memphis:</location>
<contexts>
<context position="3470" citStr="Hawes, 2003" startWordPosition="508" endWordPosition="509">hed information in either the sentence or the explanation. Based on the similarity measure, the report will include whether the student has fully or partially paraphrased a given sentence and whether it contains any additional information. 2 Paraphrase When two expressions describe the same situation, each is considered to be a paraphrase of the other. There is no precise paraphrase definition in general; instead there are frequently-accepted paraphrasing patterns to which various authorities refer. Academic writing centers (ASU Writing Center, 2000; BAC Writing Center; USCA Writing Room; and Hawes, 2003) provide a number of characterizations, such as using synonyms, changing part-of-speech, reordering ideas, breaking a sentence into smaller ones, using definitions, and using examples. McNamara (in press), on the other hand, does not consider using definitions or examples to be part of paraphrasing, but rather considers them elaboration. Stede (1996) considers different aspects or intentions to be paraphrases if they mention the same content or situation. Instead of attempting to find a single paraphrase definition, we will start with six commonly mentioned paraphrasing patterns: 1. Synonym: s</context>
</contexts>
<marker>Hawes, 2003</marker>
<rawString>K. Hawes. 2003. Mastering Academic Writing: Write a Paraphrase Sentence. University of Memphis, Memphis: TN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Levinstein</author>
<author>D McNamara</author>
<author>C Boonthum</author>
<author>S Pillarisetti</author>
<author>K Yadavalli</author>
</authors>
<title>Web-Based Intervention for Higher-Order Reading Skills.</title>
<date>2003</date>
<booktitle>In EDMEDIA,</booktitle>
<pages>835--841</pages>
<publisher>HI,</publisher>
<location>Honolulu:</location>
<contexts>
<context position="1261" citStr="Levinstein et al. (2003)" startWordPosition="182" endWordPosition="185">iscuss our preliminary implementation and research plan. 1 Introduction A web-based automated reading strategy trainer called iSTART (Interactive Strategy Trainer for Active Reading and Thinking) adaptively assigns individual students to appropriate reading training programs. It follows the SERT (SelfExplanation Reading Training) methodology developed by McNamara (in press) as a way to improve high school students’ reading ability by teaching them to use active reading strategies in self-explaining difficult texts. Details of the strategies can be found in McNamara (in press) and of iSTART in Levinstein et al. (2003) During iSTART’s practice module, the student self-explains a sentence. Then the trainer analyzes the student’s explanation and responds. The current system uses simple word- matching algorithms to evaluate the student’s input that do not yield results that are sufficiently reliable or accurate. We therefore propose a new system for handling the student’s explanation more effectively. Two major tasks of this semantically-based system are to (1) construct an internal representation of sentences and explanations and (2) recognize the reading strategies the student uses beginning with paraphrasin</context>
</contexts>
<marker>Levinstein, McNamara, Boonthum, Pillarisetti, Yadavalli, 2003</marker>
<rawString>I. Levinstein, D. McNamara, C. Boonthum, S. Pillarisetti, and K. Yadavalli. 2003. Web-Based Intervention for Higher-Order Reading Skills. In EDMEDIA, Honolulu: HI, pp. 835-841.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2001</date>
<journal>Natural Language Engineering</journal>
<pages>7--4</pages>
<contexts>
<context position="16628" citStr="Lin and Pantel (2001)" startWordPosition="2660" endWordPosition="2663">of which part of the given sentence is significant. How can we tell that this explanation is an adequate paraphrase? Can we use information provided in the given sentence as a measurement? If so, how can we use it? These questions still need to be answered. 4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT – using inference rules in question answering and information retrieval by Lin and Pantel (2001). Due to the space limitation we will mention only a few related works. ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions. They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation for different types of syntactic variation via meaning postulates. Absent a paraphrase, they loosen the criteria by using hyponyms, finding highest overlap of predicates, and simple </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>D. Lin and P. Pantel. 2001. Discovery of Inference Rules for Question Answering. Natural Language Engineering 7(4):343-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>S Thompson</author>
</authors>
<title>Rhetorical Structure Theory: A Theory of Text Organization. The Structure of Discourse,</title>
<date>1987</date>
<location>Ablex.</location>
<marker>Mann, Thompson, 1987</marker>
<rawString>W. Mann and S. Thompson, 1987. Rhetorical Structure Theory: A Theory of Text Organization. The Structure of Discourse, Ablex.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D McNamara</author>
</authors>
<title>(in press). SERT: Self-Explanation Reading Training. Discourse Processes.</title>
<marker>McNamara, </marker>
<rawString>D. McNamara. (in press). SERT: Self-Explanation Reading Training. Discourse Processes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Molla</author>
<author>R Schwitter</author>
<author>F Rinaldi</author>
<author>J Dowdall</author>
<author>M Hess</author>
</authors>
<title>ExtrAns: Extracting Answers from Technical Texts.</title>
<date>2003</date>
<journal>IEEE Intelligent System</journal>
<volume>18</volume>
<issue>4</issue>
<pages>12--17</pages>
<contexts>
<context position="16772" citStr="Molla et al, 2003" startWordPosition="2685" endWordPosition="2688">d in the given sentence as a measurement? If so, how can we use it? These questions still need to be answered. 4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT – using inference rules in question answering and information retrieval by Lin and Pantel (2001). Due to the space limitation we will mention only a few related works. ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions. They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation for different types of syntactic variation via meaning postulates. Absent a paraphrase, they loosen the criteria by using hyponyms, finding highest overlap of predicates, and simple keyword matching. Barzilay &amp; Lee (2003) also identify paraphrases in their paraphrased sentence generation system. They first find different par</context>
</contexts>
<marker>Molla, Schwitter, Rinaldi, Dowdall, Hess, 2003</marker>
<rawString>D. Molla, R. Schwitter, F. Rinaldi, J. Dowdall, and M. Hess. 2003. ExtrAns: Extracting Answers from Technical Texts. IEEE Intelligent System 18(4): 12-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Murata</author>
<author>H Isahara</author>
</authors>
<title>Universal Model for Paraphrasing – Using Transformation Based on a Defined Criteria. In</title>
<date>2001</date>
<booktitle>NLPRS: Workshop on Automatic Paraphrasing: Theories and Application.</booktitle>
<contexts>
<context position="16525" citStr="Murata and Isahara (2001)" startWordPosition="2644" endWordPosition="2647"> of the given sentence to be matched. Hence, recognizing which part of the student’s input is a paraphrase of which part of the given sentence is significant. How can we tell that this explanation is an adequate paraphrase? Can we use information provided in the given sentence as a measurement? If so, how can we use it? These questions still need to be answered. 4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT – using inference rules in question answering and information retrieval by Lin and Pantel (2001). Due to the space limitation we will mention only a few related works. ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions. They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation for different types of syntactic variation via meaning postulates. Absent a par</context>
</contexts>
<marker>Murata, Isahara, 2001</marker>
<rawString>M. Murata and H. Isahara. 2001. Universal Model for Paraphrasing – Using Transformation Based on a Defined Criteria. In NLPRS: Workshop on Automatic Paraphrasing: Theories and Application.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Rinaldi</author>
<author>J Dowdall</author>
<author>K Kaljurand</author>
<author>M Hess</author>
<author>D Molla</author>
</authors>
<title>Exploiting Paraphrases in Question Answering System. In</title>
<date>2003</date>
<booktitle>ACL: Workshop in Paraphrasing,</booktitle>
<pages>25--32</pages>
<location>Sapporo:</location>
<contexts>
<context position="16798" citStr="Rinaldi et al, 2003" startWordPosition="2690" endWordPosition="2693">as a measurement? If so, how can we use it? These questions still need to be answered. 4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT – using inference rules in question answering and information retrieval by Lin and Pantel (2001). Due to the space limitation we will mention only a few related works. ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions. They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation for different types of syntactic variation via meaning postulates. Absent a paraphrase, they loosen the criteria by using hyponyms, finding highest overlap of predicates, and simple keyword matching. Barzilay &amp; Lee (2003) also identify paraphrases in their paraphrased sentence generation system. They first find different paraphrasing rules by cluster</context>
</contexts>
<marker>Rinaldi, Dowdall, Kaljurand, Hess, Molla, 2003</marker>
<rawString>F. Rinaldi, J. Dowdall, K. Kaljurand, M. Hess, and D. Molla. 2003. Exploiting Paraphrases in Question Answering System. In ACL: Workshop in Paraphrasing, Sapporo: Japan, pp. 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Smith</author>
</authors>
<title>From Words to Corpora: Recognizing Translation. In EMNLP,</title>
<date>2002</date>
<location>Philadelphia: PA.</location>
<marker>Smith, 2002</marker>
<rawString>N. Smith. 2002. From Words to Corpora: Recognizing Translation. In EMNLP, Philadelphia: PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sowa</author>
</authors>
<date>1983</date>
<booktitle>Conceptual Structures: Information Processing in Mind and Machine.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>MA.</location>
<contexts>
<context position="4890" citStr="Sowa, 1983" startWordPosition="730" endWordPosition="731">nge a noun to a verb, adverb, or adjective; 4. Break down Sentence: break a long sentence down into small sentences; 5. Definition/Meaning: substitute a word with its definition or meaning; 6. Sentence Structure: use different sentence structures to express the same thing. If the explanation has any additional information or misses some information that appeared in the original sentence, we should be able to detect this as well for use in discovering additional strategies employed. 3 Recognition Model To recognize paraphrasing, we convert natural language sentences into Conceptual Graphs (CG, Sowa, 1983; 1992) and then compare two CGs for matching according to paraphrasing patterns. The matching process is to find as many “concept-relation-concept triplet” matches as possible. A triplet match means that a triplet from the student’s input matches with a triplet from the given sentence. In particular, the left-concept, right-concept, and relation of both sub-graphs have to be exactly the same, or the same under a transformation based on a relationship of synonymy (or other relation defined in WordNet), or the same because of idiomatic usage. It is also possible that several triplets of one sen</context>
</contexts>
<marker>Sowa, 1983</marker>
<rawString>J. Sowa. 1983. Conceptual Structures: Information Processing in Mind and Machine. Addison-Wesley, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sowa</author>
</authors>
<title>Conceptual Graphs as a Universal Knowledge Representation.</title>
<date>1992</date>
<journal>Computers Math. Application,</journal>
<volume>23</volume>
<issue>2</issue>
<pages>75--93</pages>
<marker>Sowa, 1992</marker>
<rawString>J. Sowa. 1992. Conceptual Graphs as a Universal Knowledge Representation. Computers Math. Application, 23(2-5): 75-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stede</author>
</authors>
<title>Lexical semantics and knowledge representation in multilingual sentence generation.</title>
<date>1996</date>
<tech>Ph.D. thesis:</tech>
<institution>Department of Computer Science, University of Toronto, Canada.</institution>
<contexts>
<context position="3822" citStr="Stede (1996)" startWordPosition="561" endWordPosition="562">r. There is no precise paraphrase definition in general; instead there are frequently-accepted paraphrasing patterns to which various authorities refer. Academic writing centers (ASU Writing Center, 2000; BAC Writing Center; USCA Writing Room; and Hawes, 2003) provide a number of characterizations, such as using synonyms, changing part-of-speech, reordering ideas, breaking a sentence into smaller ones, using definitions, and using examples. McNamara (in press), on the other hand, does not consider using definitions or examples to be part of paraphrasing, but rather considers them elaboration. Stede (1996) considers different aspects or intentions to be paraphrases if they mention the same content or situation. Instead of attempting to find a single paraphrase definition, we will start with six commonly mentioned paraphrasing patterns: 1. Synonym: substitute a word with its synonym, e.g. help, assist, aid; 2. Voice: change the voice of sentence from active to passive or vice versa; 3. Word-Form/Part-of-speech: change a word into a different form, e.g. change a noun to a verb, adverb, or adjective; 4. Break down Sentence: break a long sentence down into small sentences; 5. Definition/Meaning: su</context>
<context position="16445" citStr="Stede (1996)" startWordPosition="2636" endWordPosition="2637"> or strategy, the ‘complete’ paraphrasing may not need all triplets of the given sentence to be matched. Hence, recognizing which part of the student’s input is a paraphrase of which part of the given sentence is significant. How can we tell that this explanation is an adequate paraphrase? Can we use information provided in the given sentence as a measurement? If so, how can we use it? These questions still need to be answered. 4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT – using inference rules in question answering and information retrieval by Lin and Pantel (2001). Due to the space limitation we will mention only a few related works. ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions. They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation</context>
</contexts>
<marker>Stede, 1996</marker>
<rawString>M. Stede. 1996. Lexical semantics and knowledge representation in multilingual sentence generation. Ph.D. thesis: Department of Computer Science, University of Toronto, Canada.</rawString>
</citation>
<citation valid="false">
<publisher>SC.</publisher>
<institution>USCA Writing Room. Paraphrasing. The University of South</institution>
<location>Carolina: Aiken. Aiken:</location>
<marker></marker>
<rawString>USCA Writing Room. Paraphrasing. The University of South Carolina: Aiken. Aiken: SC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>