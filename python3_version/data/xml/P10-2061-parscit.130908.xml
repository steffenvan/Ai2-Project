<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006375">
<title confidence="0.9546775">
Last but Definitely not Least:
On the Role of the Last Sentence in Automatic Polarity-Classification
</title>
<author confidence="0.540851">
Israela Becker and Vered Aharonson
</author>
<affiliation confidence="0.445159">
AFEKA – Tel-Aviv Academic College of Engineering
</affiliation>
<address confidence="0.872031">
218 Bney-Efraim Rd.
Tel-Aviv 69107, Israel
</address>
<email confidence="0.998243">
{IsraelaB,Vered}@afeka.ac.il
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998715166666667">
Two psycholinguistic and psychophysical ex-
periments show that in order to efficiently ex-
tract polarity of written texts such as customer-
reviews on the Internet, one should concentrate
computational efforts on messages in the final
position of the text.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959545454546">
The ever-growing field of polarity-classification
of written texts may benefit greatly from lin-
guistic insights and tools that will allow to effi-
ciently (and thus economically) extract the po-
larity of written texts, in particular, online cus-
tomer reviews.
Many researchers interpret “efficiently” as us-
ing better computational methods to resolve the
polarity of written texts. We suggest that text
units should be handled with tools of discourse
linguistics too in order to reveal where, within
texts, their polarity is best manifested. Specifi-
cally, we propose to focus on the last sentence
of the given text in order to efficiently extract
the polarity of the whole text. This will reduce
computational costs, as well as improve the
quality of polarity detection and classification
when large databases of text units are involved.
This paper aims to provide psycholinguistic
support to the hypothesis (which psycholinguis-
tic literature lacks) that the last sentence of a
customer review is a better predictor for the po-
larity of the whole review than other sentences
in the review, in order to be later used for auto-
matic polarity-classification. Therefore, we first
briefly review the well-established structure of
text units while comparing notions of topic-
extraction vs. our notion of polarity-
classification. We then report the psycholinguis-
tic experiments that we ran in order to support
our prediction as to the role of the last sentence
in polarity manifestation. Finally, we discuss
the experimental results.
</bodyText>
<sectionHeader confidence="0.838098" genericHeader="introduction">
2 Topic-extraction
</sectionHeader>
<bodyText confidence="0.999974433333333">
One of the basic features required to perform
automatic topic-extraction is sentence position.
The importance of sentence position for compu-
tational purposes was first indicated by Baxen-
dale in the late 1950s (Baxendale, 1958): Bax-
endale hypothesized that the first and the last
sentence of a given text are the potential topic-
containing sentences. He tested this hypothesis
on a corpus of 200 paragraphs extracted out of 6
technical articles. He found that in 85% of the
documents, the first sentence was the topic sen-
tence, whereas in only 7% of the documents, it
was the last sentence. A large scale study sup-
porting Baxendale’s hypothesis was conducted
by Lin and Hovy (Lin and Hovy, 1997) who ex-
amined 13,000 documents of the Ziff-Davis
newswire corpus of articles reviewing computer
hardware and software. In this corpus, each
document was accompanied by a set of topic
keywords and a small abstract of six sentences.
Lin and Hovy measured the yield of each sen-
tence against the topic keywords and ranked the
sentences by their average yield. They con-
cluded that in ~2/3 of the documents, the topic
keywords are indeed mentioned in the title and
first five sentences of the document.
Baxendale’s theory gained further psycholin-
guistic support by the experimental results of
Kieras (Kieras, 1978, Kieras, 1980) who
showed that subjects re-constructed the content
</bodyText>
<page confidence="0.984473">
331
</page>
<note confidence="0.5067015">
Proceedings of the ACL 2010 Conference Short Papers, pages 331–335,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999896785714285">
of paragraphs they were asked to read by rely-
ing on sentences in initial positions. These find-
ing subsequently gained extensive theoretical
and experimental support by Giora (Giora,
1983, Giora, 1985) who correlated the position
of a sentence within a text with its degree of in-
formativeness.
Giora (Giora, 1985, Giora, 1988) defined a
discourse topic (DT) as the least informative
(most uninformative) yet dominant proposition
of a text. The DT best represents the redun-
dancy structure of the text. As such, this propo-
sition functions as a reference point for process-
ing the rest of the propositions. The text posi-
tion which best benefits such processing is text
initial; it facilitates processing of oncoming
propositions (with respect to the DT) relative to
when the DT is placed in text final position.
Furthermore, Giora and Lee showed (Giora
and Lee, 1996) that when the DT appears also
at the end of a text it is somewhat information-
ally redundant. However, functionally, it plays a
role in wrapping the text up and marking its
boundary. Authors often make reference to the
DT at the end of a text in order to summarize
and deliberately recapitulate what has been
written up to that point while also signaling the
end of discourse topic segment.
</bodyText>
<sectionHeader confidence="0.9821465" genericHeader="method">
3 Polarity-classification vs. Topic-
extraction
</sectionHeader>
<bodyText confidence="0.999871961538461">
When dealing with polarity-classification (as
with topic-extraction), one should again identify
the most uninformative yet dominant proposi-
tion of the text. However, given the cognitive
prominence of discourse final position in terms
of memorability, known as “recency effect” (see
below and see also (Giora, 1988)), we predict
that when it comes to polarity-classification, the
last proposition of a given text should be of
greater importance than the first one (contrary
to topic-extraction).
Based on preliminary investigations, we sug-
gest that the DT of any customer review is the
customer’s evaluation, whether negative or
positive, of a product that s/he has purchased or
a service s/he has used, rather than the details of
the specific product or service. The message
that customer reviews try to get across is, there-
fore, of evaluative nature. To best communicate
this affect, the DT should appear at the end of
the review (instead of the beginning of the re-
view) as a means of recapitulating the point of
the message, thereby guaranteeing that it is fully
understood by the readership.
Indeed, the cognitive prominence of informa-
tion in final position - the recency-effect - has
been well established in numerous psychologi-
cal experiments (see, for example, (Murdock,
1962)). Thus, the most frequent evaluation of
the product (which is the most uninformative
one) also should surface at the end of the text
due to the ease of its retrieval, which is pre-
sumably what product review readers would re-
fer to as “the bottom line”.
To the best of our knowledge, this psycholin-
guistic prediction has not been supported by psy-
cholinguistic evidence to date. However, it has
been somewhat supported by the computational
results of Yang, Lin and Chen (Yang et al.,
2007a, Yang et al., 2007b) who classified emo-
tions of posts in blog corpora. Yang, Lin &amp; Chen
realized that bloggers tend to emphasize their
feelings by using emoticons (such as: ☺,6 and
&amp;) and that these emoticons frequently appear in
final sentences. Thus, they first focused on the
last sentence of posts as representing the polarity
of the entire posts. Then, they divided the posi-
tive category into 2 sub-categories - happy and
joy, and the negative category - into angry and
sad. They showed that extracting polarity and
consequently sentiments from last sentences out-
performs all other computational strategies.
</bodyText>
<sectionHeader confidence="0.983549" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.996503916666667">
We aim to show that the last sentence of a cus-
tomer review is a better predictor for the polarity
of the whole review than any other sentence (as-
suming that the first sentence is devoted to pre-
senting the product or service). To test our pre-
diction, we ran two experiments and compared
their results. In the first experiment we exam-
ined the readers’ rating of the polarity of reviews
in their entirety, while in the second experiment
we examined the readers’ rating of the same re-
views based on reading single sentences ex-
tracted from these reviews: the last sentence or
the second one. The second sentence could have
been replaced by any other sentence, but the first
one, as our preliminary investigations clearly
show that the first sentence is in many cases de-
voted to presenting the product or service dis-
cussed and does not contain any polarity con-
tent. For example: &amp;quot;I read Isaac’s storm, by Erik
Larson, around 1998. Recently I had occasion to
thumb through it again which has prompted this
review All in all a most interesting and re-
warding book, one that I would recommend
highly.” (Gerald T. Westbrook, “GTW”)
</bodyText>
<page confidence="0.990189">
332
</page>
<subsectionHeader confidence="0.811456">
4.1 Materials
</subsectionHeader>
<bodyText confidence="0.999981545454545">
Sixteen customer-reviews were extracted from
Blitzer, Dredze, and Pereira’s sentiment data-
base (Blitzer et al., 2007). This database con-
tains product-reviews taken from Amazon 1
where each review is rated by its author on a 1-
5 star scale. The database covers 4 product
types (domains): Kitchen, Books, DVDs, and
Electronics. Four reviews were selected from
each domain. Of the 16 extracted reviews, 8
were positive (4-5 star rating) and the other 8 –
negative (1-2 star rating).
Given that in this experiment we examine the
polarity of the last sentence relative to that of the
whole review or to a few other sentences, we
focused on the first reviews (as listed in the
aforementioned database) of at least 5 sentences
or longer, rather than on too-short reviews. By
“too-short” we refer to reviews in which such
comparison would be meaningless; for example,
ones that range between 1-3 sentences will not
allow to compare the last sentence with any of
the others.
</bodyText>
<subsectionHeader confidence="0.902855">
4.2 Participants
</subsectionHeader>
<bodyText confidence="0.99995825">
Thirty-five subjects participated in the first ex-
periment: 14 women and 21 men, ranging in age
from 22 to 73. Thirty-six subjects participated in
the second experiment: 23 women and 13 men
ranging in age from 20 to 59. All participants
were native speakers of English, had an aca-
demic education, and had normal or corrected-to-
normal eye-vision.
</bodyText>
<subsectionHeader confidence="0.993274">
4.3 Procedure
</subsectionHeader>
<bodyText confidence="0.989099352941176">
In the first experiment, subjects were asked to
read 16 reviews; in the second experiment sub-
jects were asked to read 32 single sentences ex-
tracted from the same 16 reviews: the last sen-
tence and the second sentence of each review.
The last and the second sentence of each review
were not presented together but individually.
In both experiments subjects were asked to
guess the ratings of the texts which were given
by the authors on a 1-5 star scale, by clicking on
a radio-button: “In each of the following screens
you will be asked to read a customer review (or a
sentence extracted out of a customer review). All
the reviews were extracted from the
www.amazon.com customer review section.
Each review (or sentence) describes a different
product. At the end of each review (or sentence)
</bodyText>
<footnote confidence="0.850668">
1 http://www.amazon.com
</footnote>
<bodyText confidence="0.9998200625">
you will be asked to decide whether the reviewer
who wrote the review recommended or did not
recommend the reviewed product on a 1-5 scale:
Number 5 indicates that the reviewer highly rec-
ommended the product, while number 1 indicates
that the reviewer was unsatisfied with the prod-
uct and did not recommend it.”
In the second experiment, in addition to the
psychological experiment, the latencies follow-
ing reading of the texts up until the clicking of
the mouse, as well as the biometric measure-
ments of the mouse’s trajectories, were recorded.
In both experiments each subject was run in an
individual session and had an unlimited time to
reflect and decide on the polarity of each text.
Five seconds after a decision was made (as to
whether the reviewer was in favor of the product
or not), the subject was presented with the next
text. The texts were presented in random order so
as to prevent possible interactions between them.
In the initial design phase of the experiment
we discussed the idea of adding an “irrelevant”
option in addition to the 5-star scale of polarity.
This option was meant to be used for sentences
that carry no evaluation at all. Such an addition
would have necessitated locating the extra-
choice radio button at a separated remote place
from the 5-star scale radio buttons, since concep-
tually it cannot be located on a nearby position.
From the user interaction point of view, the
mouse movement to that location would have
been either considerably shorter or longer (de-
pending on its distance from the initial location
of the mouse curser at the beginning of each
trial), and the mouse trajectory and click time
would have been, thus, very different and diffi-
cult to analyze.
Although the reviews were randomly selected,
32 sentences extracted out of 16 reviews might
seem like a small sample. However, the upper
time limit for reliable psycholinguistic experi-
ments is 20-25 minute. Although tempted to ex-
tend the experiments in order to acquire more
data, longer times result in subject impatience,
which shows on lower scoring rates. Therefore,
we chose to trade sample size for accuracy. Ex-
perimental times in both experiments ranged be-
tween 15-35 minutes.
</bodyText>
<sectionHeader confidence="0.99995" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.9981008">
Results of the distribution of differences be-
tween the authors’ and the readers’ ratings of
the texts are presented in Figure 1: The distribu-
tion of differences for whole reviews is (un-
surprisingly) the narrowest (Figure 1a). The dis-
</bodyText>
<page confidence="0.998507">
333
</page>
<bodyText confidence="0.999990114754098">
tribution of differences for last sentences (Fig-
ure 1b) is somewhat wider than (but still quite
similar to) the distribution of differences for
whole reviews. The distribution of differences
for second sentences is the widest of the three
(Figure 1c).
Pearson correlation coefficient calculations
(Table 1) show that both the correlation be-
tween authors’ ratings and readers’ rating for
whole reviews and the correlation between au-
thors’ rating and readers’ rating upon reading
the last sentence are similar, while the correla-
tion between authors’ rating and readers’ rating
when presented with the second sentence of
each review is significantly lower. Moreover,
when correlating readers’ rating of whole re-
views with readers’ rating of single sentences,
the correlation coefficient for last sentences is
significantly higher than for second sentences.
As for the biometric measurements per-
formed in the second experiment, since all sub-
jects were computer-skilled, hesitation revealed
through mouse-movements was assumed to be
attributed to difficulty of decision-making rather
than to problems in operating the mouse. As
previously stated, we recorded mouse latency
times following the reading of the texts up until
clicking the mouse. Mouse latency times were
not normalized for each subject due to the lim-
ited number of results. However, the average
latency time is shorter for last sentences
(19.61±12.23s) than for second sentences
(22.06±14.39s). Indeed, the difference between
latency times is not significant, as a paired t-test
could not reject the null hypothesis that those
distributions have equal means, but might show
some tendency.
We also used the WizWhy software (Meidan,
2005) to perform combined analyses of readers’
rating and response times. The analyses showed
that when the difference between authors’ and
readers’ ratings was ≤I1Iand the response time
much shorter than average (&lt;14.1 sec), then
96% of the sentences were last sentences. Due
to the small sample size, we cautiously infer
that last sentences express polarity better than
second sentences, bearing in mind that the sec-
ond sentence in our experiment represents any
other sentence in the text except for the first
one.
We also predicted that hesitation in making a
decision would effect not only latency times but
also mouse trajectories. Namely, hesitation will
be accompanied by moving the mouse here and
there, while decisiveness will show a firm
movement. However, no such difference be-
tween the responses to last sentences or to sec-
ond sentences appeared in our analysis; most
subjects laid their hand still while reading the
texts and while reflecting upon their answers.
They moved the mouse only to rate the texts.
</bodyText>
<sectionHeader confidence="0.99105" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999917076923077">
In 2 psycholinguistic and psychophysical ex-
periments, we showed that rating whole cus-
tomer-reviews as compared to rating final sen-
tences of these reviews showed an (expected)
insignificant difference. In contrast, rating whole
customer-reviews as compared to rating second
sentences of these reviews, showed a consider-
able difference. Thus, instead of focusing on
whole texts, computational linguists should focus
on the last sentences for efficient and accurate
automatic polarity-classification. Indeed, last but
definitely not least!
We are currently running experiments that
</bodyText>
<figure confidence="0.997404956521739">
Counts
350
300
250
200
150
100
50
0
-5 -4 -3 -2 -1 0 1 2 3 4 5
a
-5 -4 -3 -2 -1 0 1 2 3 4 5 -5 -4 -3 -2 -1 0 1 2 3 4 5
b
c
350
300
250
200
50
0
150
100
Rating Difference (Authors&apos; rating - Readers&apos; rating)
</figure>
<figureCaption confidence="0.999233">
Figure 1. Histograms of the rating differences between the authors of reviews and their
</figureCaption>
<bodyText confidence="0.816197">
readers: for whole reviews (a), for last sentence only (b), and for second sentence only (c).
</bodyText>
<page confidence="0.993996">
334
</page>
<table confidence="0.464797666666667">
Readers’ star rating of: Correlated with: Pearson Correlation Coefficient (P&lt;0.0001)
Whole reviews Authors’ star rating 0.7891
Last sentences of whole reviews 0.7616
Second sentences 0.4705
Last sentences Readers’ star rating 0.8463
Second sentences of whole reviews 0.6563
</table>
<tableCaption confidence="0.998291">
Table 1. Pearson Correlation Coefficients
</tableCaption>
<bodyText confidence="0.999811333333333">
include hundreds of subjects in order to draw a
profile of polarity evolvement throughout cus-
tomer reviews. Specifically, we present our sub-
jects with sentences in various locations in cus-
tomer reviews asking them to rate them. As the
expanded experiment is not psychophysical, we
added an additional remote radio button named
“irrelevant” where subjects can judge a given
text as lacking any evident polarity. Based on the
rating results we will draw polarity profiles in
order to see where, within customer reviews, po-
larity is best manifested and whether there are
other “candidates” sentences that would serve as
useful polarity indicators. The profiles will be
used as a feature in our computational analysis.
</bodyText>
<sectionHeader confidence="0.997761" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999934666666667">
We thank Prof. Rachel Giora and Prof. Ido Da-
gan for most valuable discussions, the 2 anony-
mous reviewers – for their excellent suggestions,
and Thea Pagelson and Jason S. Henry - for their
help with programming and running the psycho-
physical experiment.
</bodyText>
<sectionHeader confidence="0.999179" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99896832">
Baxendale, P. B. 1958. Machine-Made Index for
Technical Literature - An Experiment. IBM jour-
nal of research development 2:263-311.
Blitzer, John, Dredze, Mark, and Pereira, Fernando.
2007. Biographies, Bollywood, Boom-boxes and
Blenders: Domain Adaptation for Sentiment
Classification. Paper presented at Association of
Computational Linguistics (ACL).
Giora, Rachel. 1983. Segmentation and Segment Co-
hesion: On the Thematic Organization of the
Text. Text 3:155-182.
Giora, Rachel. 1985. A Text-based Analysis of Non-
narrative Texts. Theoretical Linguistics 12:115-
135.
Giora, Rachel. 1988. On the Informativeness Re-
quirement. Journal of Pragmatics 12:547-565.
Giora, Rachel, and Lee, Cher-Leng. 1996. Written
Discourse Segmentation: The Function of Un-
stressed Pronouns in Mandarin Chinese. In Refer-
ence and Reference Accessibility ed. J. Gundel
and T. Fretheim, 113-140. Amsterdam: Benja-
mins.
Kieras, David E. 1978. Good and Bad Structure in
Simple Paragraphs: Effects on Apparent Theme,
Reading Time, and Recall. Journal of Verbal
Learning and Verbal Behavior 17:13-28.
Kieras, David E. 1980. Initial Mention as a Cue to the
Main Idea and the Main Item of a Technical Pas-
sage. Memory and Cognition 8:345-353.
Lin, Chen-Yew, and Hovy, Edward. 1997. Identifying
Topic by Position. Paper presented at Proceeding
of the Fifth Conference on Applied Natural Lan-
guage Processing, San Francisco.
Meidan, Abraham. 2005. Wizsoft&apos;s WizWhy. In The
Data Mining and Knowledge Discovery Hand-
book, eds. Oded Maimon and Lior Rokach,
1365-1369: Springer.
Murdock, B. B. Jr. 1962. The Serial Position Effect of
Free Recall. Journal of Experimental Psychology
62:618-625.
Yang, Changua, Lin, Kevin Hsin-Yih, and Chen,
Hsin-Hsi. 2007a. Emotion Classification Using
Web Blog Corpora. In IEEE/WIC/ACM/ Interna-
tional Conference on Web Intelligence. Silicon
Valley, San Francisco.
Yang, Changua, Lin, Kevin Hsin-Yih, and Chen,
Hsin-Hsin. 2007b. Building Emotion Lexicon
from Weblog Corpora. Paper presented at Pro-
ceeding of the ACL 2007 Demo and Poster Ses-
sion, Prague.
</reference>
<page confidence="0.999155">
335
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.864306">
<title confidence="0.997671">but Least: On the Role of the Last Sentence in Automatic Polarity-Classification</title>
<author confidence="0.953065">Israela Becker</author>
<author confidence="0.953065">Vered Aharonson</author>
<affiliation confidence="0.980895">Tel-Aviv Academic College of Engineering</affiliation>
<address confidence="0.9706855">218 Bney-Efraim Rd. Tel-Aviv 69107, Israel</address>
<email confidence="0.967061">IsraelaB@afeka.ac.il</email>
<email confidence="0.967061">Vered@afeka.ac.il</email>
<abstract confidence="0.997913571428571">Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P B Baxendale</author>
</authors>
<title>Machine-Made Index for Technical Literature - An Experiment.</title>
<date>1958</date>
<journal>IBM journal of research development</journal>
<pages>2--263</pages>
<contexts>
<context position="2297" citStr="Baxendale, 1958" startWordPosition="348" endWordPosition="349">. Therefore, we first briefly review the well-established structure of text units while comparing notions of topicextraction vs. our notion of polarityclassification. We then report the psycholinguistic experiments that we ran in order to support our prediction as to the role of the last sentence in polarity manifestation. Finally, we discuss the experimental results. 2 Topic-extraction One of the basic features required to perform automatic topic-extraction is sentence position. The importance of sentence position for computational purposes was first indicated by Baxendale in the late 1950s (Baxendale, 1958): Baxendale hypothesized that the first and the last sentence of a given text are the potential topiccontaining sentences. He tested this hypothesis on a corpus of 200 paragraphs extracted out of 6 technical articles. He found that in 85% of the documents, the first sentence was the topic sentence, whereas in only 7% of the documents, it was the last sentence. A large scale study supporting Baxendale’s hypothesis was conducted by Lin and Hovy (Lin and Hovy, 1997) who examined 13,000 documents of the Ziff-Davis newswire corpus of articles reviewing computer hardware and software. In this corpus</context>
</contexts>
<marker>Baxendale, 1958</marker>
<rawString>Baxendale, P. B. 1958. Machine-Made Index for Technical Literature - An Experiment. IBM journal of research development 2:263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. Paper presented at Association of Computational Linguistics (ACL).</title>
<date>2007</date>
<contexts>
<context position="8541" citStr="Blitzer et al., 2007" startWordPosition="1380" endWordPosition="1383">any other sentence, but the first one, as our preliminary investigations clearly show that the first sentence is in many cases devoted to presenting the product or service discussed and does not contain any polarity content. For example: &amp;quot;I read Isaac’s storm, by Erik Larson, around 1998. Recently I had occasion to thumb through it again which has prompted this review All in all a most interesting and rewarding book, one that I would recommend highly.” (Gerald T. Westbrook, “GTW”) 332 4.1 Materials Sixteen customer-reviews were extracted from Blitzer, Dredze, and Pereira’s sentiment database (Blitzer et al., 2007). This database contains product-reviews taken from Amazon 1 where each review is rated by its author on a 1- 5 star scale. The database covers 4 product types (domains): Kitchen, Books, DVDs, and Electronics. Four reviews were selected from each domain. Of the 16 extracted reviews, 8 were positive (4-5 star rating) and the other 8 – negative (1-2 star rating). Given that in this experiment we examine the polarity of the last sentence relative to that of the whole review or to a few other sentences, we focused on the first reviews (as listed in the aforementioned database) of at least 5 senten</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>Blitzer, John, Dredze, Mark, and Pereira, Fernando. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. Paper presented at Association of Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Giora</author>
</authors>
<title>Segmentation and Segment Cohesion: On the Thematic Organization of the Text.</title>
<date>1983</date>
<journal>Text</journal>
<pages>3--155</pages>
<contexts>
<context position="3780" citStr="Giora, 1983" startWordPosition="588" endWordPosition="589"> topic keywords are indeed mentioned in the title and first five sentences of the document. Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331 Proceedings of the ACL 2010 Conference Short Papers, pages 331–335, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics of paragraphs they were asked to read by relying on sentences in initial positions. These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most uninformative) yet dominant proposition of a text. The DT best represents the redundancy structure of the text. As such, this proposition functions as a reference point for processing the rest of the propositions. The text position which best benefits such processing is text initial; it facilitates processing of oncoming propositions (with respect to the DT) relative to when the DT is placed in </context>
</contexts>
<marker>Giora, 1983</marker>
<rawString>Giora, Rachel. 1983. Segmentation and Segment Cohesion: On the Thematic Organization of the Text. Text 3:155-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Giora</author>
</authors>
<title>A Text-based Analysis of Nonnarrative Texts.</title>
<date>1985</date>
<journal>Theoretical Linguistics</journal>
<pages>12--115</pages>
<contexts>
<context position="3794" citStr="Giora, 1985" startWordPosition="590" endWordPosition="591">ds are indeed mentioned in the title and first five sentences of the document. Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331 Proceedings of the ACL 2010 Conference Short Papers, pages 331–335, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics of paragraphs they were asked to read by relying on sentences in initial positions. These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most uninformative) yet dominant proposition of a text. The DT best represents the redundancy structure of the text. As such, this proposition functions as a reference point for processing the rest of the propositions. The text position which best benefits such processing is text initial; it facilitates processing of oncoming propositions (with respect to the DT) relative to when the DT is placed in text final pos</context>
</contexts>
<marker>Giora, 1985</marker>
<rawString>Giora, Rachel. 1985. A Text-based Analysis of Nonnarrative Texts. Theoretical Linguistics 12:115-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Giora</author>
</authors>
<title>On the Informativeness Requirement.</title>
<date>1988</date>
<journal>Journal of Pragmatics</journal>
<pages>12--547</pages>
<contexts>
<context position="3919" citStr="Giora, 1988" startWordPosition="611" endWordPosition="612">stic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331 Proceedings of the ACL 2010 Conference Short Papers, pages 331–335, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics of paragraphs they were asked to read by relying on sentences in initial positions. These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most uninformative) yet dominant proposition of a text. The DT best represents the redundancy structure of the text. As such, this proposition functions as a reference point for processing the rest of the propositions. The text position which best benefits such processing is text initial; it facilitates processing of oncoming propositions (with respect to the DT) relative to when the DT is placed in text final position. Furthermore, Giora and Lee showed (Giora and Lee, 1996) that when the DT appears also at the end of a text it is somew</context>
<context position="5207" citStr="Giora, 1988" startWordPosition="820" endWordPosition="821">pping the text up and marking its boundary. Authors often make reference to the DT at the end of a text in order to summarize and deliberately recapitulate what has been written up to that point while also signaling the end of discourse topic segment. 3 Polarity-classification vs. Topicextraction When dealing with polarity-classification (as with topic-extraction), one should again identify the most uninformative yet dominant proposition of the text. However, given the cognitive prominence of discourse final position in terms of memorability, known as “recency effect” (see below and see also (Giora, 1988)), we predict that when it comes to polarity-classification, the last proposition of a given text should be of greater importance than the first one (contrary to topic-extraction). Based on preliminary investigations, we suggest that the DT of any customer review is the customer’s evaluation, whether negative or positive, of a product that s/he has purchased or a service s/he has used, rather than the details of the specific product or service. The message that customer reviews try to get across is, therefore, of evaluative nature. To best communicate this affect, the DT should appear at the e</context>
</contexts>
<marker>Giora, 1988</marker>
<rawString>Giora, Rachel. 1988. On the Informativeness Requirement. Journal of Pragmatics 12:547-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Giora</author>
<author>Cher-Leng Lee</author>
</authors>
<title>Written Discourse Segmentation: The Function of Unstressed Pronouns in Mandarin Chinese.</title>
<date>1996</date>
<booktitle>In Reference and Reference Accessibility</booktitle>
<pages>113--140</pages>
<editor>ed. J. Gundel and T. Fretheim,</editor>
<location>Amsterdam: Benjamins.</location>
<contexts>
<context position="4456" citStr="Giora and Lee, 1996" startWordPosition="698" endWordPosition="701"> within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most uninformative) yet dominant proposition of a text. The DT best represents the redundancy structure of the text. As such, this proposition functions as a reference point for processing the rest of the propositions. The text position which best benefits such processing is text initial; it facilitates processing of oncoming propositions (with respect to the DT) relative to when the DT is placed in text final position. Furthermore, Giora and Lee showed (Giora and Lee, 1996) that when the DT appears also at the end of a text it is somewhat informationally redundant. However, functionally, it plays a role in wrapping the text up and marking its boundary. Authors often make reference to the DT at the end of a text in order to summarize and deliberately recapitulate what has been written up to that point while also signaling the end of discourse topic segment. 3 Polarity-classification vs. Topicextraction When dealing with polarity-classification (as with topic-extraction), one should again identify the most uninformative yet dominant proposition of the text. Howeve</context>
</contexts>
<marker>Giora, Lee, 1996</marker>
<rawString>Giora, Rachel, and Lee, Cher-Leng. 1996. Written Discourse Segmentation: The Function of Unstressed Pronouns in Mandarin Chinese. In Reference and Reference Accessibility ed. J. Gundel and T. Fretheim, 113-140. Amsterdam: Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David E Kieras</author>
</authors>
<title>Good and Bad Structure in Simple Paragraphs: Effects on Apparent Theme, Reading Time, and Recall.</title>
<date>1978</date>
<journal>Journal of Verbal Learning and Verbal Behavior</journal>
<pages>17--13</pages>
<contexts>
<context position="3371" citStr="Kieras, 1978" startWordPosition="529" endWordPosition="530">1997) who examined 13,000 documents of the Ziff-Davis newswire corpus of articles reviewing computer hardware and software. In this corpus, each document was accompanied by a set of topic keywords and a small abstract of six sentences. Lin and Hovy measured the yield of each sentence against the topic keywords and ranked the sentences by their average yield. They concluded that in ~2/3 of the documents, the topic keywords are indeed mentioned in the title and first five sentences of the document. Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331 Proceedings of the ACL 2010 Conference Short Papers, pages 331–335, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics of paragraphs they were asked to read by relying on sentences in initial positions. These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informa</context>
</contexts>
<marker>Kieras, 1978</marker>
<rawString>Kieras, David E. 1978. Good and Bad Structure in Simple Paragraphs: Effects on Apparent Theme, Reading Time, and Recall. Journal of Verbal Learning and Verbal Behavior 17:13-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David E Kieras</author>
</authors>
<title>Initial Mention as a Cue to the Main Idea and the Main Item of a Technical Passage. Memory and Cognition</title>
<date>1980</date>
<pages>8--345</pages>
<contexts>
<context position="3386" citStr="Kieras, 1980" startWordPosition="531" endWordPosition="532">ined 13,000 documents of the Ziff-Davis newswire corpus of articles reviewing computer hardware and software. In this corpus, each document was accompanied by a set of topic keywords and a small abstract of six sentences. Lin and Hovy measured the yield of each sentence against the topic keywords and ranked the sentences by their average yield. They concluded that in ~2/3 of the documents, the topic keywords are indeed mentioned in the title and first five sentences of the document. Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331 Proceedings of the ACL 2010 Conference Short Papers, pages 331–335, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics of paragraphs they were asked to read by relying on sentences in initial positions. These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most unin</context>
</contexts>
<marker>Kieras, 1980</marker>
<rawString>Kieras, David E. 1980. Initial Mention as a Cue to the Main Idea and the Main Item of a Technical Passage. Memory and Cognition 8:345-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen-Yew Lin</author>
<author>Edward Hovy</author>
</authors>
<title>Identifying Topic by Position.</title>
<date>1997</date>
<booktitle>Paper presented at Proceeding of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<location>San Francisco.</location>
<contexts>
<context position="2764" citStr="Lin and Hovy, 1997" startWordPosition="428" endWordPosition="431">s sentence position. The importance of sentence position for computational purposes was first indicated by Baxendale in the late 1950s (Baxendale, 1958): Baxendale hypothesized that the first and the last sentence of a given text are the potential topiccontaining sentences. He tested this hypothesis on a corpus of 200 paragraphs extracted out of 6 technical articles. He found that in 85% of the documents, the first sentence was the topic sentence, whereas in only 7% of the documents, it was the last sentence. A large scale study supporting Baxendale’s hypothesis was conducted by Lin and Hovy (Lin and Hovy, 1997) who examined 13,000 documents of the Ziff-Davis newswire corpus of articles reviewing computer hardware and software. In this corpus, each document was accompanied by a set of topic keywords and a small abstract of six sentences. Lin and Hovy measured the yield of each sentence against the topic keywords and ranked the sentences by their average yield. They concluded that in ~2/3 of the documents, the topic keywords are indeed mentioned in the title and first five sentences of the document. Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kiera</context>
</contexts>
<marker>Lin, Hovy, 1997</marker>
<rawString>Lin, Chen-Yew, and Hovy, Edward. 1997. Identifying Topic by Position. Paper presented at Proceeding of the Fifth Conference on Applied Natural Language Processing, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Meidan</author>
</authors>
<title>Wizsoft&apos;s WizWhy.</title>
<date>2005</date>
<booktitle>In The Data Mining and Knowledge Discovery Handbook, eds. Oded Maimon and Lior Rokach,</booktitle>
<pages>1365--1369</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="14715" citStr="Meidan, 2005" startWordPosition="2397" endWordPosition="2398">n to problems in operating the mouse. As previously stated, we recorded mouse latency times following the reading of the texts up until clicking the mouse. Mouse latency times were not normalized for each subject due to the limited number of results. However, the average latency time is shorter for last sentences (19.61±12.23s) than for second sentences (22.06±14.39s). Indeed, the difference between latency times is not significant, as a paired t-test could not reject the null hypothesis that those distributions have equal means, but might show some tendency. We also used the WizWhy software (Meidan, 2005) to perform combined analyses of readers’ rating and response times. The analyses showed that when the difference between authors’ and readers’ ratings was ≤I1Iand the response time much shorter than average (&lt;14.1 sec), then 96% of the sentences were last sentences. Due to the small sample size, we cautiously infer that last sentences express polarity better than second sentences, bearing in mind that the second sentence in our experiment represents any other sentence in the text except for the first one. We also predicted that hesitation in making a decision would effect not only latency tim</context>
</contexts>
<marker>Meidan, 2005</marker>
<rawString>Meidan, Abraham. 2005. Wizsoft&apos;s WizWhy. In The Data Mining and Knowledge Discovery Handbook, eds. Oded Maimon and Lior Rokach, 1365-1369: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B B Jr Murdock</author>
</authors>
<title>The Serial Position Effect of Free Recall.</title>
<date>1962</date>
<journal>Journal of Experimental Psychology</journal>
<pages>62--618</pages>
<contexts>
<context position="6175" citStr="Murdock, 1962" startWordPosition="978" endWordPosition="979">chased or a service s/he has used, rather than the details of the specific product or service. The message that customer reviews try to get across is, therefore, of evaluative nature. To best communicate this affect, the DT should appear at the end of the review (instead of the beginning of the review) as a means of recapitulating the point of the message, thereby guaranteeing that it is fully understood by the readership. Indeed, the cognitive prominence of information in final position - the recency-effect - has been well established in numerous psychological experiments (see, for example, (Murdock, 1962)). Thus, the most frequent evaluation of the product (which is the most uninformative one) also should surface at the end of the text due to the ease of its retrieval, which is presumably what product review readers would refer to as “the bottom line”. To the best of our knowledge, this psycholinguistic prediction has not been supported by psycholinguistic evidence to date. However, it has been somewhat supported by the computational results of Yang, Lin and Chen (Yang et al., 2007a, Yang et al., 2007b) who classified emotions of posts in blog corpora. Yang, Lin &amp; Chen realized that bloggers t</context>
</contexts>
<marker>Murdock, 1962</marker>
<rawString>Murdock, B. B. Jr. 1962. The Serial Position Effect of Free Recall. Journal of Experimental Psychology 62:618-625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changua Yang</author>
<author>Kevin Hsin-Yih Lin</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Emotion Classification Using Web Blog Corpora.</title>
<date>2007</date>
<booktitle>In IEEE/WIC/ACM/ International Conference on Web Intelligence. Silicon</booktitle>
<location>Valley, San Francisco.</location>
<contexts>
<context position="6661" citStr="Yang et al., 2007" startWordPosition="1061" endWordPosition="1064"> position - the recency-effect - has been well established in numerous psychological experiments (see, for example, (Murdock, 1962)). Thus, the most frequent evaluation of the product (which is the most uninformative one) also should surface at the end of the text due to the ease of its retrieval, which is presumably what product review readers would refer to as “the bottom line”. To the best of our knowledge, this psycholinguistic prediction has not been supported by psycholinguistic evidence to date. However, it has been somewhat supported by the computational results of Yang, Lin and Chen (Yang et al., 2007a, Yang et al., 2007b) who classified emotions of posts in blog corpora. Yang, Lin &amp; Chen realized that bloggers tend to emphasize their feelings by using emoticons (such as: ☺,6 and &amp;) and that these emoticons frequently appear in final sentences. Thus, they first focused on the last sentence of posts as representing the polarity of the entire posts. Then, they divided the positive category into 2 sub-categories - happy and joy, and the negative category - into angry and sad. They showed that extracting polarity and consequently sentiments from last sentences outperforms all other computation</context>
</contexts>
<marker>Yang, Lin, Chen, 2007</marker>
<rawString>Yang, Changua, Lin, Kevin Hsin-Yih, and Chen, Hsin-Hsi. 2007a. Emotion Classification Using Web Blog Corpora. In IEEE/WIC/ACM/ International Conference on Web Intelligence. Silicon Valley, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changua Yang</author>
<author>Kevin Hsin-Yih Lin</author>
<author>Hsin-Hsin Chen</author>
</authors>
<title>Building Emotion Lexicon from Weblog Corpora.</title>
<date>2007</date>
<booktitle>Paper presented at Proceeding of the ACL 2007 Demo and Poster Session,</booktitle>
<location>Prague.</location>
<contexts>
<context position="6661" citStr="Yang et al., 2007" startWordPosition="1061" endWordPosition="1064"> position - the recency-effect - has been well established in numerous psychological experiments (see, for example, (Murdock, 1962)). Thus, the most frequent evaluation of the product (which is the most uninformative one) also should surface at the end of the text due to the ease of its retrieval, which is presumably what product review readers would refer to as “the bottom line”. To the best of our knowledge, this psycholinguistic prediction has not been supported by psycholinguistic evidence to date. However, it has been somewhat supported by the computational results of Yang, Lin and Chen (Yang et al., 2007a, Yang et al., 2007b) who classified emotions of posts in blog corpora. Yang, Lin &amp; Chen realized that bloggers tend to emphasize their feelings by using emoticons (such as: ☺,6 and &amp;) and that these emoticons frequently appear in final sentences. Thus, they first focused on the last sentence of posts as representing the polarity of the entire posts. Then, they divided the positive category into 2 sub-categories - happy and joy, and the negative category - into angry and sad. They showed that extracting polarity and consequently sentiments from last sentences outperforms all other computation</context>
</contexts>
<marker>Yang, Lin, Chen, 2007</marker>
<rawString>Yang, Changua, Lin, Kevin Hsin-Yih, and Chen, Hsin-Hsin. 2007b. Building Emotion Lexicon from Weblog Corpora. Paper presented at Proceeding of the ACL 2007 Demo and Poster Session, Prague.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>