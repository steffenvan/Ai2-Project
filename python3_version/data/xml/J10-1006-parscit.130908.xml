<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<figure confidence="0.562078272727273">
Book Reviews
Representation and Management of Narrative Information:
Theoretical Principles and Implementation
Gian Piero Zarri
(Politecnico di Milano)
Springer Verlag (Advanced Information and Knowledge Processing series, edited by
Lakhmi Jain and Xindong Wu), 2009, x+301 pp; hardbound, ISBN 978-1-84800-077-3,
$99.00; e-book, ISBN 978-1-84800-078-0; DOI 10.1007/978-1-84800-078-0
Reviewed by
Frank Schilder
Thomson Reuters
</figure>
<bodyText confidence="0.97515635">
Gian Piero Zarri’s book summarizes more than a decade of his research on knowledge
representation for narrative text. The centerpiece of Zarri’s work is the Narrative Knowl-
edge Representation Language (NKRL), which he describes and compares to other
competing theories. In addition, he discusses how to model the meaning of narrative
text by giving many real-world examples. NKRL provides three different components
or capabilities: (a) a representation system, (b) inferencing, and (c) an implementation.
It is implemented via a Java-based system that shows how a representational theory can
be applied to narrative texts.
The book consists of five chapters and two appendices. Chapter 1 introduces the
basic principles of NKRL. The chapter first defines the focus on nonfiction narratives
by contrasting the domain with fictional narratives, for example, a novel. Zarri chooses
n-ary predicates in order to represent events formally. He argues for a neo-Davidsonian
knowledge representation following Schank (1980), Schubert (1976), and others, and at
the same time he sets his approach apart from the knowledge representation proposals
one can find in Semantic Web representation languages such as RDF and OWL. How-
ever, Zarri emphasizes that NKRL, despite its similarity to conceptual graphs (Sowa
1999), is more focused on practical applications. The chapter concludes by introducing
so-called templates in an attempt to demonstrate the practical usefulness of NKRL.
Chapter 2 provides an in-depth description of NKRL. Four connected components
are introduced:
</bodyText>
<listItem confidence="0.929841571428571">
• The definitional component provides a hierarchy of abstract concepts (e.g.,
artifact, company, activity) called HClass (hierarchy of classes).
• The descriptive component is a hierarchy of event types called HTemp
(hierarchy of templates) commonly found in the domain of non-fiction
narratives (e.g., moving an object, producing a task or activity).
• The factual component describes the concrete instantiation of an event. For
example, the sentence Berlex Laboratories have performed an evaluation of a
given compound would be represented as
[PRODUCE: [ SUBJ BERLEX LABORATORIES, OBJ: ASSESSMENT 1,
TOPIC: COMPOUND 27]]
Computational Linguistics Volume 36, Number 1
• The enumerative component links the values of the event description from
the factual component to unique instantiations of these participants of an
object, such as in COMPOUND 27.
</listItem>
<bodyText confidence="0.999341906976744">
This chapter also contains a comparison of NKRL and other formalisms that deal with
the representation of temporal information, such as TimeML (Pustejovsky et al. 2003) or
Discourse Representation Theory (DRT; Kamp and Reyle 1993). A detailed description
is given of how NKRL represents temporal information based on Allen’s (1984) interval
calculus and how NKRL approaches the problem of underspecified or coarse temporal
information such as in around December 25, 2005.
Chapter 3 adds more information about the semantics and the ontologies in NKRL.
A set of predefined conceptual structures is introduced and numerous examples taken
from real-world narratives are provided. The definitional component introduced in
Chapter 2 is fleshed out and the distinction between sortal and non-sortal concepts
(e.g., CHAIR versus GOLD) is described. This hierarchy is quite similar to other so-called
upper-level ontologies such as CYC or SUMO (Guha and Lenat 1991; Pease, Niles, and
Li 2002), which are introduced to the reader in more detail in the beginning of this
chapter. In addition to the conceptual hierarchy HClass, the descriptive component
HTemp holds a set of often-used templates. Each template is described with a specific
example that shows how different slots of the templates may be filled.
Chapter 4 covers in more detail how inferences can be drawn within the imple-
mented system. The NKRL system provides several query tools for retrieving infor-
mation from the knowledge base encoded in NKRL annotations, as described by the
previous chapters. The query tools comprise querying by search patterns, unification /
filtering operations, and indexing temporal information. The indexing of temporal
information considers different levels of temporal information including a temporal
perspective. The temporal perspective is used to represent information about when an
event starts or ends in addition to whether it is observed by somebody.
Chapter 5 provides the author’s conclusions, suggesting technological and theoret-
ical enhancement to the current version of NKRL. Appendix A contains a detailed de-
scription of the NKRL software and Appendix B discusses the treatment of a particular
linguistic phenomenon within NKRL: plural entities.
The book offers a unique combination of different tools for modeling narrative
information. It contains valuable discussions of important questions such as whether
n-ary predicates should be used. However, some of these discussions would have
benefited from a more in-depth treatment. The comparison with TimeML (Pustejovsky
et al. 2003), for example, only partly covers recent developments and does not men-
tion software that utilizes TimeML. For example, the TARSQI toolset,1 not mentioned
by Zarri, allows the user to extract events and temporal expressions while temporal
links are derived and consistency checks can be run via a constraint propagation
component.
Zarri often compares and contrasts his work with the representation languages used
for the Semantic Web, such as RDF and OWL. He rightly points out similarities while
addressing shortcomings of the Semantic Web technology (e.g., restriction to ternary
predicates). But he overlooks an important point: RDF and OWL were not created for
the semantic representation of non-fictional narratives—the focus of this book. Halevy,
Norvig, and Pereira (2009), for instance, point out that one needs to distinguish between
</bodyText>
<footnote confidence="0.94348">
1 http://www.timeml.org/site/tarsqi/toolkit/index.html.
</footnote>
<page confidence="0.992304">
152
</page>
<subsectionHeader confidence="0.892601">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999964903225807">
approaches to the semantic interpretation problem of natural language and the repre-
sentation of the Semantic Web. The former tries to address the question of how language
can be formally represented while the latter focuses on the interoperability of semantic
information expressed by Web pages (e.g., flight information provided by a travel
agency). Because Zarri proposes an approach for solving the semantic interpretation
problem, a clear distinction as to what problem is being addressed would be helpful in
order to avoid giving the wrong impression that the proposed methods are suitable for
the Semantic Web.
On a more detailed level, Zarri’s introduction to sortal and non-sortal concepts does
not cite work by Krifka (1992) and Dowty (1991). These authors presented theories on
sortal event hierarchies similar to the one discussed by Zarri, and both theories discuss
how the sortal quality of an object influences the event type (e.g., eating an apple
vs. eating apple pur´ee). Zarri’s introduction to his theoretical framework could have
been improved by a more in-depth treatment of event semantics, such as the theories
introduced by Krifka, Dowty, and others.
On a more minor note, the readability of the book is slightly hampered by the
overuse of italics and other fonts. Less would have been definitely more here. In ad-
dition, a list of abbreviations and a glossary of important terms would have been useful
so that the reader could use the book as a quick reference, for example.
Though the working implementation of the system is intriguing, and the book
provides many narrative texts exemplifying the expressiveness and capability of NKRL,
an unaddressed issue is whether the implementation can be scaled. Unfortunately, there
is no way for the reader to decide, because the book does not include a CD with a demo
of the system, let alone the source code.
This book would be useful to researchers and practitioners in the field of modeling
narrative information, but not to beginners in this field. Students, for example, who are
interested in this area would need a more guided approach to the topic. Nevertheless,
the book provides a solid theoretical foundation for representing information extracted
from narrative text such as news messages; and I am pleased to see that the author
undertook the effort of implementing his theory in an actual system that has the poten-
tial for many different and exciting practical applications.
</bodyText>
<sectionHeader confidence="0.988082" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.817446736842105">
Allen, James. 1984. Towards a general
theory of action and time. Artificial
Intelligence, 23(2):123–154.
Dowty, David. 1991. Thematic proto-roles
and argument selection. Language,
67:547–619.
Guha, Ramanathan V. and Douglas B.
Lenat. 1991. Cyc: A mid-term
report. Applied Artificial Intelligence,
5(1):45–86.
Halevy, Alon, Peter Norvig, and Fernando
Pereira. 2009. The unreasonable
effectiveness of data. IEEE Intelligent
Systems, 24(2):8–12.
Kamp, Hans and Uwe Reyle. 1993. From
Discourse to Logic: Introduction to
Modeltheoretic Semantics of Natural
Language, Formal Logic and Discourse
Representation Theory. Kluwer Academic.
</reference>
<figureCaption confidence="0.47976655">
Krifka, Manfred. 1992. Thematic relations
as links between nominal reference
and temporal constitution. In Ivan Sag
and Anna Szabolcsi, editors, Lexical
Matters. CSLI Publications, Stanford,
CA, pages 29–53.
Pease, Adam, Ian Niles, and John Li.
2002. The suggested upper merged
ontology: A large ontology for the
Semantic Web and its applications.
In Working Notes of the AAAI-2002
Workshop on Ontologies and the
Semantic Web, Edmonton.
Pustejovsky, James, Jos´e Casta˜no,
Robert Ingria, Roser Saur´ı, Robert
Gaizauskas, Andrea Setzer, and
Graham Katz. 2003. TimeML: Robust
specification of event and temporal
expressions in text. In Proceedings of the
Fifth International Workshop on
</figureCaption>
<page confidence="0.985563">
153
</page>
<table confidence="0.825477666666667">
Computational Linguistics Volume 36, Number 1
Computational Semantics (IWCS-5), networks. Artificial Intelligence,
Tilburg. 7(2):163–198.
Schank, Roger C. 1980. Language and Sowa, John F. 1999. Knowledge Representation:
memory. Cognitive Science, 4(3):243–284. Logical, Philosophical, and Computational
Schubert, Lenhart K. 1976. Extending Foundations. Brooks Cole Publishing Co.,
the expressive power of semantic Pacific Grove, CA.
Frank Schilder is a senior research scientist at the Thomson Reuters Research &amp; Development
department. His research interests include temporal information extraction, summarization, and
discourse processing. His address is Thomson Reuters R&amp;D, 610 Opperman Drive, St. Paul, MN
55123, USA; e-mail: frank.schilder@thomsonreuters.com.
Dependency Parsing
</table>
<author confidence="0.765416">
Sandra K¨iibler, Ryan McDonald, and Joakim Nivre
</author>
<affiliation confidence="0.566757">
(Indiana University, Google Research, and Uppsala and V¨axj¨o Universities)
</affiliation>
<figure confidence="0.7411418">
Morgan &amp; Claypool (Synthesis Lectures on Human Language Technologies, edited by
Graeme Hirst, volume 2), 2009, xii+115 pp; paperbound, ISBN 978-1-59829-596-2,
$40.00; e-book, ISBN 978-1-59829-597-9, $30.00 or by subscription
Reviewed by
John Carroll
</figure>
<subsubsectionHeader confidence="0.476076">
University of Sussex
</subsubsectionHeader>
<bodyText confidence="0.996902857142857">
This book is a survey of the latest research in dependency parsing, describing some
of the approaches currently being investigated by the research community, assessing
their strengths and weaknesses, and exploring relationships between them. The book is
one of the first in a series of short monographs entitled Synthesis Lectures on Human
Language Technologies; other related series include speech and audio processing, and
artificial intelligence and machine learning. A PDF version of the book can be purchased
on-line for $30.00.
Dependency parsing is currently a very active area of research, so this book is
timely. Until recently, most research into inducing statistical parsers from syntactically
annotated text has worked with phrase structure tree representations. However, over
the last ten years or so a number of researchers have argued (Lin 1995; Briscoe and
Carroll 2006) that dependency analyses—in which syntactic structure is represented by
linking pairs of words by labeled dependency relations—have a number of important
advantages over phrase structure trees. In particular:
</bodyText>
<listItem confidence="0.997419666666667">
• For evaluation of parsing accuracy (with respect to a gold standard),
measuring correctness of dependency relations gives more reliable results
than measuring similarity of phrase structure.
• For applications requiring automatic linguistic analysis, dependencies
capture some aspects of predicate–argument structure in a more
convenient form than phrase structure.
</listItem>
<page confidence="0.999436">
154
</page>
<subsectionHeader confidence="0.927572">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.979847458333334">
In addition, as annotated corpora for languages other than English have become more
numerous, it has become evident that:
• For free word order languages, dependencies are better able to capture
syntactic generalizations than phrase structure trees.
The CoNLL shared tasks from 2006 onwards have played an important role in raising
interest in dependency parsing and supporting work in this area, by organizing the
annotation and distribution of dependency corpora in several languages, providing
the stimulus of friendly competition, and facilitating comparisons between the various
techniques used by the systems that have been entered.
The book describes a range of dependency parsing models, presenting them in
terms of a common framework consisting of three elements: a set of constraints defining
the space of permissible dependency structures for a given sentence, a set of param-
eters (possibly empty), and a parsing algorithm. Two main classes of models are dis-
tinguished: data-driven, in which the parser is learned from a corpus of dependency
structures; and grammar-based, in which the parser is directed by a formal grammar
(and also possibly by weights controlling how alternative solutions are explored).
At only a little over 100 pages, the book does not have room to address issues
such as how dependency grammar can be used to describe the linguistic facts about
a given language, how particular syntactic constructions could be analyzed, or how
hand-crafted dependency grammars are developed. The focus is on parsing algorithms,
and the two main data-driven approaches of transition-based and graph-based parsing
are described in some detail. The focus on the process of parsing itself also means
that the book does not refer (even in a further-reading section) to some widely distrib-
uted parsing systems which use other types of grammar internally but which output
dependencies, for example the C&amp;C parser (Clark and Curran 2007). And although
the CoNLL data sets have been very influential, there is no mention of the PARC 700
Dependency Bank (King et al. 2003), which has been used in comparative dependency-
based evaluations of a wide range of parsers.
The authors state that they are aiming the book at graduate students and researchers
in computer science, linguistics, and computational linguistics. The reader is assumed
to have some background knowledge of linguistics and computer science, and although
not necessary for an understanding of most of the material, at some points the reader
is expected to be comfortable with proof by induction, analysis of the complexity of
algorithms, and algorithms for directed graphs. Two of the chapters begin with a few
pages of formal definitions, propositions, and proofs, with little in the way of motivating
or illustrative examples, and here the less mathematically confident reader will have to
persevere.
The publisher has produced the book very quickly: Indeed, the date of publication
is only one month after the date at the end of the Preface. However, a side effect of this
is a lack of polish: There are a number of typographical errors (and at least one incom-
plete sentence), occasional lapses into unidiomatic English, some instances of incorrect
referencing style, and there is no index. Also, decisions on when references are given
within the body of a chapter or postponed to end-of-chapter notes are inconsistent,
some technical terms (e.g., ‘spurious ambiguity’) are not explained at the first point
at which they are mentioned, and others (e.g., ‘gap degree’) are not explained at all.
However, given that these problems are mostly textual and in general do not
impede the reader’s understanding, this book serves as a very useful and up to date
survey of the burgeoning research area of dependency parsing.
</bodyText>
<page confidence="0.992884">
155
</page>
<note confidence="0.367616">
Computational Linguistics Volume 36, Number 1
</note>
<sectionHeader confidence="0.801974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997956038461539">
Briscoe, Ted and John Carroll. 2006.
Evaluating the accuracy of an
unlexicalized statistical parser on the
PARC DepBank. In Proceedings of the
COLING/ACL 2006 Main Conference Poster
Sessions, Sydney, pages 41–48.
Clark, Stephen and James R. Curran. 2007.
Wide-coverage efficient statistical parsing
with CCG and log-linear models.
Computational Linguistics, 33(4):493–552.
King, Tracy H., Richard Crouch, Stefan
Riezler, Mary Dalrymple, and Ronald M.
Kaplan. 2003. The PARC 700 Dependency
Bank. In Proceedings of the 4th International
Workshop on Linguistically Interpreted
Corpora, Budapest, pages 1–8.
Lin, Dekang. 1995. A dependency-based
method for evaluating broad-coverage
parsers. In Proceedings of the 14th
International Joint Conference on Artificial
Intelligence, Montreal, pages 1420–1425.
This book review was edited by Pierre Isabelle.
John Carroll is Professor of Computational Linguistics at the University of Sussex, working on
parsing, tactical generation, opinion mining, and real-world applications of language technology.
Carroll’s address is School of Informatics, University of Sussex, Falmer, Brighton BN19QH, UK;
e-mail: J.A.Carroll@sussex.ac.uk.
</reference>
<page confidence="0.998752">
156
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.035198">
<title confidence="0.999043">Book Reviews Representation and Management of Narrative Information: Theoretical Principles and Implementation</title>
<author confidence="0.99494">Gian Piero Zarri</author>
<affiliation confidence="0.931591">(Politecnico di Milano)</affiliation>
<note confidence="0.4678705">Springer Verlag (Advanced Information and Knowledge Processing series, edited by Lakhmi Jain and Xindong Wu), 2009, x+301 pp; hardbound, ISBN 978-1-84800-077-3, $99.00; e-book, ISBN 978-1-84800-078-0; DOI 10.1007/978-1-84800-078-0 Reviewed by</note>
<author confidence="0.97889">Frank Schilder</author>
<title confidence="0.474274">Thomson Reuters</title>
<author confidence="0.561522">Gian Piero Zarri’s book summarizes more than a decade of his research on knowledge</author>
<abstract confidence="0.990611848837209">representation for narrative text. The centerpiece of Zarri’s work is the Narrative Knowledge Representation Language (NKRL), which he describes and compares to other competing theories. In addition, he discusses how to model the meaning of narrative text by giving many real-world examples. NKRL provides three different components or capabilities: (a) a representation system, (b) inferencing, and (c) an implementation. It is implemented via a Java-based system that shows how a representational theory can be applied to narrative texts. The book consists of five chapters and two appendices. Chapter 1 introduces the basic principles of NKRL. The chapter first defines the focus on nonfiction narratives by contrasting the domain with fictional narratives, for example, a novel. Zarri chooses predicates in order to represent events formally. He argues for a neo-Davidsonian knowledge representation following Schank (1980), Schubert (1976), and others, and at the same time he sets his approach apart from the knowledge representation proposals one can find in Semantic Web representation languages such as RDF and OWL. However, Zarri emphasizes that NKRL, despite its similarity to conceptual graphs (Sowa 1999), is more focused on practical applications. The chapter concludes by introducing so-called templates in an attempt to demonstrate the practical usefulness of NKRL. Chapter 2 provides an in-depth description of NKRL. Four connected components are introduced: • The definitional component provides a hierarchy of abstract concepts (e.g., artifact, company, activity) called HClass (hierarchy of classes). • The descriptive component is a hierarchy of event types called HTemp (hierarchy of templates) commonly found in the domain of non-fiction narratives (e.g., moving an object, producing a task or activity). • The factual component describes the concrete instantiation of an event. For the sentence Laboratories have performed an evaluation of a compound be represented as [PRODUCE: [ SUBJ BERLEX LABORATORIES, OBJ: ASSESSMENT 1, TOPIC: COMPOUND 27]] Computational Linguistics Volume 36, Number 1 • The enumerative component links the values of the event description from the factual component to unique instantiations of these participants of an object, such as in COMPOUND 27. This chapter also contains a comparison of NKRL and other formalisms that deal with the representation of temporal information, such as TimeML (Pustejovsky et al. 2003) or Discourse Representation Theory (DRT; Kamp and Reyle 1993). A detailed description is given of how NKRL represents temporal information based on Allen’s (1984) interval calculus and how NKRL approaches the problem of underspecified or coarse temporal such as in December 25, Chapter 3 adds more information about the semantics and the ontologies in NKRL. A set of predefined conceptual structures is introduced and numerous examples taken from real-world narratives are provided. The definitional component introduced in Chapter 2 is fleshed out and the distinction between sortal and non-sortal concepts is described. This hierarchy is quite similar to other so-called upper-level ontologies such as CYC or SUMO (Guha and Lenat 1991; Pease, Niles, and Li 2002), which are introduced to the reader in more detail in the beginning of this chapter. In addition to the conceptual hierarchy HClass, the descriptive component HTemp holds a set of often-used templates. Each template is described with a specific example that shows how different slots of the templates may be filled. Chapter 4 covers in more detail how inferences can be drawn within the implemented system. The NKRL system provides several query tools for retrieving information from the knowledge base encoded in NKRL annotations, as described by the previous chapters. The query tools comprise querying by search patterns, unification / filtering operations, and indexing temporal information. The indexing of temporal information considers different levels of temporal information including a temporal perspective. The temporal perspective is used to represent information about when an event starts or ends in addition to whether it is observed by somebody. Chapter 5 provides the author’s conclusions, suggesting technological and theoretical enhancement to the current version of NKRL. Appendix A contains a detailed description of the NKRL software and Appendix B discusses the treatment of a particular linguistic phenomenon within NKRL: plural entities. The book offers a unique combination of different tools for modeling narrative information. It contains valuable discussions of important questions such as whether predicates should be used. However, some of these discussions would have benefited from a more in-depth treatment. The comparison with TimeML (Pustejovsky et al. 2003), for example, only partly covers recent developments and does not mensoftware that utilizes TimeML. For example, the TARSQI not mentioned by Zarri, allows the user to extract events and temporal expressions while temporal links are derived and consistency checks can be run via a constraint propagation component. Zarri often compares and contrasts his work with the representation languages used for the Semantic Web, such as RDF and OWL. He rightly points out similarities while addressing shortcomings of the Semantic Web technology (e.g., restriction to ternary predicates). But he overlooks an important point: RDF and OWL were not created for the semantic representation of non-fictional narratives—the focus of this book. Halevy, Norvig, and Pereira (2009), for instance, point out that one needs to distinguish between 152 Book Reviews approaches to the semantic interpretation problem of natural language and the representation of the Semantic Web. The former tries to address the question of how language can be formally represented while the latter focuses on the interoperability of semantic information expressed by Web pages (e.g., flight information provided by a travel agency). Because Zarri proposes an approach for solving the semantic interpretation problem, a clear distinction as to what problem is being addressed would be helpful in order to avoid giving the wrong impression that the proposed methods are suitable for the Semantic Web.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Towards a general theory of action and time.</title>
<date>1984</date>
<journal>Artificial Intelligence,</journal>
<volume>23</volume>
<issue>2</issue>
<marker>Allen, 1984</marker>
<rawString>Allen, James. 1984. Towards a general theory of action and time. Artificial Intelligence, 23(2):123–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Thematic proto-roles and argument selection.</title>
<date>1991</date>
<journal>Language,</journal>
<pages>67--547</pages>
<contexts>
<context position="7093" citStr="Dowty (1991)" startWordPosition="1045" endWordPosition="1046">ess the question of how language can be formally represented while the latter focuses on the interoperability of semantic information expressed by Web pages (e.g., flight information provided by a travel agency). Because Zarri proposes an approach for solving the semantic interpretation problem, a clear distinction as to what problem is being addressed would be helpful in order to avoid giving the wrong impression that the proposed methods are suitable for the Semantic Web. On a more detailed level, Zarri’s introduction to sortal and non-sortal concepts does not cite work by Krifka (1992) and Dowty (1991). These authors presented theories on sortal event hierarchies similar to the one discussed by Zarri, and both theories discuss how the sortal quality of an object influences the event type (e.g., eating an apple vs. eating apple pur´ee). Zarri’s introduction to his theoretical framework could have been improved by a more in-depth treatment of event semantics, such as the theories introduced by Krifka, Dowty, and others. On a more minor note, the readability of the book is slightly hampered by the overuse of italics and other fonts. Less would have been definitely more here. In addition, a lis</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>Dowty, David. 1991. Thematic proto-roles and argument selection. Language, 67:547–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramanathan V Guha</author>
<author>Douglas B Lenat</author>
</authors>
<title>Cyc: A mid-term report.</title>
<date>1991</date>
<journal>Applied Artificial Intelligence,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="3798" citStr="Guha and Lenat 1991" startWordPosition="549" endWordPosition="552">val calculus and how NKRL approaches the problem of underspecified or coarse temporal information such as in around December 25, 2005. Chapter 3 adds more information about the semantics and the ontologies in NKRL. A set of predefined conceptual structures is introduced and numerous examples taken from real-world narratives are provided. The definitional component introduced in Chapter 2 is fleshed out and the distinction between sortal and non-sortal concepts (e.g., CHAIR versus GOLD) is described. This hierarchy is quite similar to other so-called upper-level ontologies such as CYC or SUMO (Guha and Lenat 1991; Pease, Niles, and Li 2002), which are introduced to the reader in more detail in the beginning of this chapter. In addition to the conceptual hierarchy HClass, the descriptive component HTemp holds a set of often-used templates. Each template is described with a specific example that shows how different slots of the templates may be filled. Chapter 4 covers in more detail how inferences can be drawn within the implemented system. The NKRL system provides several query tools for retrieving information from the knowledge base encoded in NKRL annotations, as described by the previous chapters. </context>
</contexts>
<marker>Guha, Lenat, 1991</marker>
<rawString>Guha, Ramanathan V. and Douglas B. Lenat. 1991. Cyc: A mid-term report. Applied Artificial Intelligence, 5(1):45–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Halevy</author>
<author>Peter Norvig</author>
<author>Fernando Pereira</author>
</authors>
<title>The unreasonable effectiveness of data.</title>
<date>2009</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>24</volume>
<issue>2</issue>
<marker>Halevy, Norvig, Pereira, 2009</marker>
<rawString>Halevy, Alon, Peter Norvig, and Fernando Pereira. 2009. The unreasonable effectiveness of data. IEEE Intelligent Systems, 24(2):8–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
<date>1993</date>
<publisher>Kluwer Academic.</publisher>
<contexts>
<context position="3072" citStr="Kamp and Reyle 1993" startWordPosition="440" endWordPosition="443">boratories have performed an evaluation of a given compound would be represented as [PRODUCE: [ SUBJ BERLEX LABORATORIES, OBJ: ASSESSMENT 1, TOPIC: COMPOUND 27]] Computational Linguistics Volume 36, Number 1 • The enumerative component links the values of the event description from the factual component to unique instantiations of these participants of an object, such as in COMPOUND 27. This chapter also contains a comparison of NKRL and other formalisms that deal with the representation of temporal information, such as TimeML (Pustejovsky et al. 2003) or Discourse Representation Theory (DRT; Kamp and Reyle 1993). A detailed description is given of how NKRL represents temporal information based on Allen’s (1984) interval calculus and how NKRL approaches the problem of underspecified or coarse temporal information such as in around December 25, 2005. Chapter 3 adds more information about the semantics and the ontologies in NKRL. A set of predefined conceptual structures is introduced and numerous examples taken from real-world narratives are provided. The definitional component introduced in Chapter 2 is fleshed out and the distinction between sortal and non-sortal concepts (e.g., CHAIR versus GOLD) is</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, Hans and Uwe Reyle. 1993. From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>41--48</pages>
<location>Sydney,</location>
<marker>Briscoe, Carroll, 2006</marker>
<rawString>Briscoe, Ted and John Carroll. 2006. Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, Sydney, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Wide-coverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, Stephen and James R. Curran. 2007. Wide-coverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The PARC 700 Dependency Bank.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora,</booktitle>
<pages>1--8</pages>
<location>Budapest,</location>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>King, Tracy H., Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald M. Kaplan. 2003. The PARC 700 Dependency Bank. In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora, Budapest, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>A dependency-based method for evaluating broad-coverage parsers.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1420--1425</pages>
<location>Montreal,</location>
<marker>Lin, 1995</marker>
<rawString>Lin, Dekang. 1995. A dependency-based method for evaluating broad-coverage parsers. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montreal, pages 1420–1425.</rawString>
</citation>
<citation valid="false">
<title>This book review was edited by Pierre Isabelle. John Carroll is Professor of Computational Linguistics at the University of Sussex, working on parsing, tactical generation, opinion mining, and real-world applications of language technology. Carroll’s address is School of Informatics,</title>
<institution>University of Sussex,</institution>
<location>Falmer, Brighton BN19QH, UK;</location>
<note>e-mail: J.A.Carroll@sussex.ac.uk.</note>
<marker></marker>
<rawString>This book review was edited by Pierre Isabelle. John Carroll is Professor of Computational Linguistics at the University of Sussex, working on parsing, tactical generation, opinion mining, and real-world applications of language technology. Carroll’s address is School of Informatics, University of Sussex, Falmer, Brighton BN19QH, UK; e-mail: J.A.Carroll@sussex.ac.uk.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>