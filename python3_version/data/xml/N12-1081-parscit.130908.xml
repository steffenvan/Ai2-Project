<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020604">
<title confidence="0.974694">
Comparing HMMs and Bayesian Networks for Surface Realisation
</title>
<author confidence="0.996841">
Nina Dethlefs Heriberto Cuay´ahuitl
</author>
<affiliation confidence="0.872134">
Heriot-Watt University German Research Centre for Artificial Intelligence
Edinburgh, Scotland Saarbr¨ucken, Germany
</affiliation>
<email confidence="0.997436">
n.s.dethlefs@hw.ac.uk heriberto.cuayahuitl@dfki.de
</email>
<sectionHeader confidence="0.99544" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993058214285714">
Natural Language Generation (NLG) systems
often use a pipeline architecture for sequen-
tial decision making. Recent studies how-
ever have shown that treating NLG decisions
jointly rather than in isolation can improve the
overall performance of systems. We present
a joint learning framework based on Hierar-
chical Reinforcement Learning (HRL) which
uses graphical models for surface realisation.
Our focus will be on a comparison of Bayesian
Networks and HMMs in terms of user satis-
faction and naturalness. While the former per-
form best in isolation, the latter present a scal-
able alternative within joint systems.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99916748">
NLG systems have traditionally used a pipeline ar-
chitecture which divides the generation process into
three distinct stages. Content selection chooses
‘what to say’ and constructs a semantic form. Ut-
terance planning organises the message into sub-
messages and surface realisation maps the seman-
tics onto words. Recently, a number of studies
have pointed out that many decisions made at these
distinct stages require interrelated, rather than iso-
lated, optimisations (Angeli et al., 2010; Lemon,
2011; Cuay´ahuitl and Dethlefs, 2011a; Dethlefs and
Cuay´ahuitl, 2011a). The key feature of a joint archi-
tecture is that decisions of all three NLG stages share
information and can be made in an interrelated fash-
ion. We present a joint NLG framework based on
Hierarchical RL and focus, in particular, on the sur-
face realisation component of joint NLG systems.
We compare the user satisfaction and naturalness
of surface realisation using Hidden Markov Models
(HMMs) and Bayesian Networks (BNs) which both
have been suggested as generation spaces—spaces
of surface form variants for a semantic concept—
within joint NLG systems (Dethlefs and Cuay´ahuitl,
2011a; Dethlefs and Cuay´ahuitl, 2011b) and in iso-
lation (Georgila et al., 2002; Mairesse et al., 2010).
</bodyText>
<sectionHeader confidence="0.722485" genericHeader="method">
2 Surface Realisation for Situated NLG
</sectionHeader>
<bodyText confidence="0.994889636363636">
We address the generation of navigation instruc-
tions, where e.g. the semantic form (path(target =
end of corridor) ∧ (landmark = lift ∧ dir =
left)) can be expressed as ‘Go to the end of the
corridor’, ‘Head to the end of the corridor past the
lift on your left’ and many more. The best realisa-
tion depends on the space (types and properties of
spatial objects), the user (position, orientation, prior
knowledge) and decisions of content selection and
utterance planning. These can be interrelated with
surface realisation, for example:
</bodyText>
<listItem confidence="0.998817666666667">
(1) ‘Follow this corridor and go past the lift on your
left. Then turn right at the junction.’
(2) ’Pass the lift and turn right at the junction.’
</listItem>
<bodyText confidence="0.999694">
Here, (1) is appropriate for a user unfamiliar with the
space and a high information need, so that more in-
formation should be given. For a familiar user, how-
ever, who may know where the lift is, it is redundant
and (2) is preferable, because it is more efficient. An
unfamiliar user may get confused with just (2).
In this paper, we distinguish navigation of des-
tination (‘go back to the office’), direction (‘turn
left’), orientation (‘turn around’), path (‘follow the
</bodyText>
<page confidence="0.910669333333333">
636
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 636–640,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.9969575">
corridor’) and straight’ (‘go forward’) in the GIVE
corpus (Gargett et al., 2010). Users can react to an
instruction by performing the action, performing an
undesired action, hesitating or requesting help.
</bodyText>
<sectionHeader confidence="0.984324" genericHeader="method">
3 Jointly Learnt NLG: Hierarchical RL
with Graphical Models
</sectionHeader>
<bodyText confidence="0.999804282051282">
In a joint framework, each subtask of content selec-
tion, utterance planning and surface realisation has
knowledge of the decisions made in the other two
subtasks. In an isolated framework, this knowledge
is absent. In the joint case, the relationship between
hierarchical RL and graphical models is that the lat-
ter provide feedback to the former’s surface realisa-
tion decisions according to a human corpus.
Hierarchical RL Our HRL agent consists of a
hierarchy of discrete-time Semi-Markov Decision
Processes, or SMDPs, Mij defined as 4-tuples &lt;
5ij, Aij, Tj i , R� &gt;, where i and j uniquely identify
a model in the hierarchy. These SMDPs represent
generation subtasks, e.g. generating destination in-
structions. 5ij is a set of states, Aij is a set of ac-
tions, and Tji is a probabilistic state transition func-
tion that determines the next state s′ from the current
state s and the performed action a. M j(s′, 7-|s, a) is
a reward function that specifies the reward that an
agent receives for taking an action a in state s last-
ing T time steps. Since actions in SMDPs may take
a variable number of time steps to complete, the ran-
dom variable T represents this number of time steps.
Actions can be either primitive or composite. The
former yield single rewards, the latter correspond to
SMDPs and yield cumulative rewards. The goal of
each SMDP is to find an optimal policy 7r* that max-
imises the reward for each visited state, according
to 7r*ij(s) = arg maxaEA Q*ij(s, a), where Qij(s, a)
specifies the expected cumulative reward for execut-
ing action a in state s and then following 7r*. Please
see (Dethlefs and Cuay´ahuitl, 2011b) for details on
the design of the hierarchical RL agent and the inte-
gration of graphical models for surface realisation.
Hidden Markov Models Representing surface re-
alisation as an HMM can be roughly defined as the
converse of POS tagging. While in POS tagging we
map an observation string of words onto a hidden
sequence of POS tags, in NLG we face the oppo-
</bodyText>
<figureCaption confidence="0.962841333333333">
Figure 1: Example trellis for an HMM for destination
instructions (not all states and transitions are shown).
Dashed arrows show paths that occur in the corpus.
</figureCaption>
<bodyText confidence="0.999697461538462">
site scenario. Given an observation sequence of se-
mantic symbols, we want to map it onto a hidden
most likely sequence of words. We treat states as
representing surface realisations for (observed) se-
mantic classes, so that a sequence of states s0...sn
represents phrases or sentences. An observation se-
quence o0...on consists of a finite set of semantic
symbols specific to an instruction type. Each symbol
has an observation likelihood bs(o)t giving the prob-
ability of observing o in state s at time t. We created
the HMMs and trained the transition and emission
probabilities from the GIVE corpus using the Baum-
Welch algorithm. Please see Fig. 1 for an example
HMM and (Dethlefs and Cuay´ahuitl, 2011a) for de-
tails on using HMMs for surface realisation.
Bayesian Networks Representing a surface re-
aliser as a BN, we can model the dynamics between
semantic concepts and their realisations. A BN mod-
els a joint probability distribution over a set of ran-
dom variables and their dependencies based on a di-
rected acyclic graph, where each node represents a
variable Yj with parents pa(Yj). Due to the Markov
condition, each variable depends only on its parents,
resulting in a unique joint probability distribution
p(Y ) = rtp(Yj|pa(Yj)), where every variable is as-
sociated with a conditional probability distribution
</bodyText>
<figure confidence="0.9285505625">
.
.
.
direc. direc. direc. direc.
point
room room room room
walk
into
go go go go
to
point point point
to to to
into into into
walk walk walk
. . .
637
</figure>
<figureCaption confidence="0.999509">
Figure 2: BN for generating destination instructions.
</figureCaption>
<bodyText confidence="0.99813328">
p(Yj|pa(Yj)). The meaning of random variables
corresponds to semantic symbols. The values of ran-
dom variables correspond to surface variants of a se-
mantic symbol. Figure 2 shows an example BN with
two main dependencies. First, the random variable
‘information need’ influences the inclusion of op-
tional semantic constituents and the process of the
utterance (‘destination verb’). Second, a sequence
of dependencies spans from the verb to the end of
the utterance (‘destination relatum’). The first de-
pendency is based on the intuition that more detail
is needed in an instruction for users with high infor-
mation need (e.g. with little prior knowledge).1 The
second dependency is based on the hypothesis that
the value of one constituent can be estimated based
on the previous constituent. In the future, we may
compare different configurations and effects of word
order. Given the word sequence represented by lex-
ical and syntactic variables Y0...Yn, and situation-
based variables Yn+1...Y,,t, we can compute the pos-
terior probability of a random variable Yj. The pa-
rameters of the BNs were estimated using MLE.
Please see (Dethlefs and Cuay´ahuitl, 2011b) for de-
tails on using BNs for surface realisation within a
joint learning framework.
</bodyText>
<sectionHeader confidence="0.998763" genericHeader="method">
4 Experimental Setting
</sectionHeader>
<bodyText confidence="0.997675666666667">
We compare instructions generated with the
HMMs and BNs according to their user sat-
isfaction and their naturalness. The learn-
</bodyText>
<footnote confidence="0.99379475">
1This is key to the joint treatment of content selection and
surface realisation: if an utterance is not informative in terms
of content, it will receive bad rewards, even with good surface
realisation choices (and vice versa).
</footnote>
<bodyText confidence="0.913461588235294">
ing agent is trained using the reward function
Reward= User satisfaction x P(w0 ... wn) x
CAS.2 User satisfaction is a function of task
success and the number of user turns based on
the PARADISE framework3 (Walker et al., 1997)
and CAS refers to the proportion of repetition
and variation in surface forms. Our focus in
this short paper is on P(w0 ... wn) which rewards
the agent for having generated a surface form se-
quence w0 ... wn. In HMMs, this corresponds to
the forward probability—obtained from the For-
ward algorithm—of observing the sequence in the
data. In BNs, P(w0 ... wn) corresponds to P(Yj =
v,|pa(Yj) = vy), the posterior probability given the
chosen values v,, and vy of random variables and
their dependencies. We assign a reward of −1 for
each action to prevent loops.
</bodyText>
<sectionHeader confidence="0.998325" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999962105263158">
User satisfaction Our trained policies learn the
same content selection and utterance planning be-
haviour reported by (Dethlefs and Cuay´ahuitl,
2011b). These policies contribute to the user sat-
isfaction of instructions. BNs and HMMs however
differ in their surface realisation choices. Figure
3 shows the performance in terms of average re-
wards over time for both models within the joint
learning framework and in isolation.4 For ease of
comparison, a learning curve using a greedy policy
is also shown. It always chooses the most likely
surface form according to the human corpus with-
out taking other tradeoffs into account. Within the
joint framework, both BNs and HMMs learn to gen-
erate context-sensitive surface forms that balance
the tradeoffs of the most likely sequence (accord-
ing to the human corpus) and the one that best cor-
responds to the user’s information need (e.g., using
nick names of rooms for familiar users). The BNs
</bodyText>
<footnote confidence="0.988081272727273">
2This reward function, the simulated environment and train-
ing parameters were adapted from (Dethlefs and Cuay´ahuitl,
2011b) to allow a comparison with related work in using graph-
ical models for surface realisation. Simulation is based on uni-
and bigrams for the spatial setting and Naive Bayes Classifica-
tion for user reactions to system instructions.
3See (Dethlefs et al., 2010) for evidence of the correlation
between user satisfaction, task success and dialogue length.
4In the isolated case, subtasks of content selection, utterance
planning and surface realisation are blind regarding the deci-
sions made by other subtasks, but in the joint case they are not.
</footnote>
<table confidence="0.89701695">
Information
Values: {high, low}
Need
Destination
Direction
Destination
Verb
Values: {left/right, Values: {go, keep going,
straight, empty} walk, continue, return,
get, you need, you want,
empty, ... }
Values:{into, in,
to, towards, until,
empty, ...}
Destination
Preposition
Destination
Relatum
Values:{landmark,
room}
</table>
<page confidence="0.724054">
638
</page>
<figure confidence="0.869791">
Episodes
</figure>
<figureCaption confidence="0.9998275">
Figure 3: Performance of HMMs, BNs and a greedy base-
line in conjunction and isolation of the joint framework.
</figureCaption>
<bodyText confidence="0.9999849375">
reach an average reward5 of −11.53 and outper-
form the HMMs (average −11.64) only marginally
by less than one percent. BNs and HMMs improve
the greedy baseline by 6% (p &lt; 0.0001, r = 0.90).
While BNs reach the same performance in isola-
tion of the joint framework, the performance of
HMMs deteriorates significantly to an average re-
ward of −12.12. This corresponds to a drop of 5%
(p &lt; 0.0001, r = 0.79) and is nearly as low as the
greedy baseline. HMMs thus reach a comparable
performance to BNs as a result of the joint learning
architecture: the HRL agent will discover the non-
optimal behaviour that is caused by the HMM’s lack
of context-awareness (due to their independence as-
sumptions) and learn to balance this drawback by
learning a more comprehensive policy itself. For the
more context-aware BNs this is not necessary.
Naturalness We compare the instructions gener-
ated with HMMs and BNs regarding their human-
likeness based on the Kullback-Leibler (KL) diver-
gence. It computes the difference between two prob-
ability distributions. For evidence of its usefulness
for measuring naturalness, cf. (Cuay´ahuitl, 2010).
We compare human instructions (based on strings)
drawn from the corpus against strings generated by
the HMMs and BNs to see how similar both are to
human authors. Splitting the human instructions in
half and comparing them to each other indicates how
similar human authors are to each other. It yields a
KL score of 1.77 as a gold standard (the lower the
better). BNs compared with human data obtain a
score of 2.83 and HMMs of 2.80. The difference in
</bodyText>
<footnote confidence="0.957749">
5The average rewards of agents have negative values due to
the negative reward of −1 the agent receives for each action.
</footnote>
<bodyText confidence="0.99988984375">
terms of similarity with humans for HMMs and BNs
in a joint NLG model is not significant.
Discussion While HMMs reach comparable user
satisfaction and naturalness to BNs in a joint system,
they show a 5% lower performance in isolation. This
is likely caused by their conditional independence
assumptions: (a) the Markov assumption, (b) the
stationary assumption, and (c) the observation inde-
pendence assumption. Even though these can make
HMMs easier to train and scale than more structured
models such as BNs, it also puts them in a disadvan-
tage concerning context-awareness and accuracy as
shown by our results. In contrast, the random vari-
ables of BNs allow them to keep a structured model
of the space, user, and relevant content selection and
utterance planning choices. BNs are thus able to
compute the posterior probability of a surface form
based on all relevant properties of the current situa-
tion (not just the occurrence in a corpus). While BNs
also place independence assumptions on their vari-
ables, they usually overcome the problem of lacking
context-awareness by their dependencies across ran-
dom variables. However, BNs also face limitations.
Given the dependencies they postulate, they are typ-
ically more data intensive and less scalable than less
structured models such as HMMs. This can be prob-
lematic for large domains such as many real world
applications. Regarding their application to surface
realisation, we can argue that while BNs are the best
performing model in isolation, HMMs represent a
cheap and scalable alternative especially for large-
scale problems in a joint NLG system.
</bodyText>
<sectionHeader confidence="0.997012" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999991076923077">
We have compared the user satisfaction and natural-
ness of instructions generated with HMMs and BNs
in a joint HRL model for NLG. Results showed that
while BNs perform best in isolation, HMMs repre-
sent a cheap and scalable alternative within the joint
framework. This is particularly attractive for large-
scale, data-intensive systems. While this paper has
focused on instruction generation, the hierarchical
approach in our learning framework helps to scale
up to larger NLG tasks, such as text or paragraph
generation. Future work could test this claim, com-
pare other graphical models, such as dynamic BNs,
and aim for a comprehensive human evaluation.
</bodyText>
<figure confidence="0.996956777777778">
−10
−11
−12
−13
−14
−15
BNs Joint
BNs Isolated
HMMs Joint
HMMs Isolated
Greedy
−19
−203
10 104 105
−16
−17
−18
Average Reward
</figure>
<page confidence="0.995245">
639
</page>
<bodyText confidence="0.9994355">
Acknowledgements This research was funded by
the European Commission’s FP7 programmes under
grant agreement no. 287615 (PARLANCE) and no.
ICT-248116 (ALIZ-E).
</bodyText>
<sectionHeader confidence="0.996413" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99973394">
Angeli, G., Liang, P. and D. Klein (2010). A simple
domain-independent probabilistic approach to gener-
ation , Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP) .
Cuay´ahuitl, H., Renals, S., Lemon, O. and H. Shimodaira
(2010). Evaluation of a Hierarchical Reinforcement
Learning Spoken Dialogue System, Computer Speech
and Language 24.
Cuay´ahuitl, H., and N. Dethlefs (2011a). Spatially-
Aware Dialogue Control Using Hierarchical Rein-
forcement Learning, ACM Transactions on Speech
and Language Processing (Special Issue on Machine
Learning for Robust and Adaptive Spoken Dialogue
Systems 7(3).
Dethlefs, N. and H. Cuay´ahuitl, 2011. Hierarchical Re-
inforcement Learning and Hidden Markov Models for
Task-Oriented Natural Language Generation, In Proc.
of the 49th Annual Meeting of the Association for
Computational Linguistics (ACL-HLT).
Dethlefs, N. and H. Cuay´ahuitl, 2011. Combining Hi-
erarchical Reinforcement Learning and Bayesian Net-
works for Natural Language Generation in Situated
Dialogue, In Proceedings of the 13th European Work-
shop on Natural Language Generation (ENLG).
Dethlefs, N., Cuay´ahuitl, H., Richter, K.-F., Andonova,
E. and J. Bateman, 2010. Evaluating Task Success in
a Dialogue System for Indoor Navigation, In Proceed-
ings of the Workshop on the Semantics and Pragmatics
ofDialogue (SemDial).
Gargett, A., Garoufi, K., Koller, A. and K. Striegnitz
(2010). The GIVE-2 Corpus of Giving Instructions
in Virtual Environments, Proc. of the 7th International
Conference on Language Resources and Evaluation.
Georgila, K., Fakotakis, N. and Kokkinakis, G. (2002).
Stochastic Language Modelling for Recognition and
Generation in Dialogue Systems. TAL (Traitement au-
tomatique des langues) Journal, Vol. 43(3).
Lemon, O. (2011). Learning what to say and how to say
it: joint optimization of spoken dialogue management
and Natural Language Generation, Computer Speech
and Language 25(2).
Mairesse, F., Gaˇsi´c, M., Jurˇciˇcek, F., Keizer, S., Thom-
son, B., Yu, K. and S. Young (2010). Phrase-based
statistical language generation using graphical models
and active learning, Proc. of the 48th Annual Meeting
of the Association for Computational Linguistics.
Walker, M., Litman, D., Kamm, C. and A. Abella (1997).
PARADISE: A Framework for Evaluating Spoken Di-
alogue Agents, Proceedings of the Annual Meeting of
the Association for Computational Linguistic (ACL).
</reference>
<page confidence="0.997682">
640
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.934799">
<title confidence="0.999586">Comparing HMMs and Bayesian Networks for Surface Realisation</title>
<author confidence="0.999182">Nina Dethlefs Heriberto Cuay´ahuitl</author>
<affiliation confidence="0.999489">Heriot-Watt University German Research Centre for Artificial Intelligence</affiliation>
<address confidence="0.96631">Edinburgh, Scotland Saarbr¨ucken, Germany</address>
<email confidence="0.978087">n.s.dethlefs@hw.ac.ukheriberto.cuayahuitl@dfki.de</email>
<abstract confidence="0.9992728">Natural Language Generation (NLG) systems often use a pipeline architecture for sequential decision making. Recent studies however have shown that treating NLG decisions jointly rather than in isolation can improve the overall performance of systems. We present a joint learning framework based on Hierarchical Reinforcement Learning (HRL) which uses graphical models for surface realisation. Our focus will be on a comparison of Bayesian Networks and HMMs in terms of user satisfaction and naturalness. While the former perform best in isolation, the latter present a scalable alternative within joint systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Angeli</author>
<author>P Liang</author>
<author>D Klein</author>
</authors>
<title>A simple domain-independent probabilistic approach to generation ,</title>
<date>2010</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) .</booktitle>
<contexts>
<context position="1385" citStr="Angeli et al., 2010" startWordPosition="194" endWordPosition="197">turalness. While the former perform best in isolation, the latter present a scalable alternative within joint systems. 1 Introduction NLG systems have traditionally used a pipeline architecture which divides the generation process into three distinct stages. Content selection chooses ‘what to say’ and constructs a semantic form. Utterance planning organises the message into submessages and surface realisation maps the semantics onto words. Recently, a number of studies have pointed out that many decisions made at these distinct stages require interrelated, rather than isolated, optimisations (Angeli et al., 2010; Lemon, 2011; Cuay´ahuitl and Dethlefs, 2011a; Dethlefs and Cuay´ahuitl, 2011a). The key feature of a joint architecture is that decisions of all three NLG stages share information and can be made in an interrelated fashion. We present a joint NLG framework based on Hierarchical RL and focus, in particular, on the surface realisation component of joint NLG systems. We compare the user satisfaction and naturalness of surface realisation using Hidden Markov Models (HMMs) and Bayesian Networks (BNs) which both have been suggested as generation spaces—spaces of surface form variants for a semanti</context>
</contexts>
<marker>Angeli, Liang, Klein, 2010</marker>
<rawString>Angeli, G., Liang, P. and D. Klein (2010). A simple domain-independent probabilistic approach to generation , Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) .</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cuay´ahuitl</author>
<author>S Renals</author>
<author>O Lemon</author>
<author>H Shimodaira</author>
</authors>
<title>Evaluation of a Hierarchical Reinforcement Learning Spoken Dialogue System,</title>
<date>2010</date>
<journal>Computer Speech and Language</journal>
<volume>24</volume>
<marker>Cuay´ahuitl, Renals, Lemon, Shimodaira, 2010</marker>
<rawString>Cuay´ahuitl, H., Renals, S., Lemon, O. and H. Shimodaira (2010). Evaluation of a Hierarchical Reinforcement Learning Spoken Dialogue System, Computer Speech and Language 24.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Cuay´ahuitl</author>
<author>N</author>
</authors>
<title>Dethlefs (2011a). SpatiallyAware Dialogue Control Using Hierarchical Reinforcement Learning,</title>
<booktitle>ACM Transactions on Speech and Language Processing (Special Issue on Machine Learning for Robust and Adaptive Spoken Dialogue Systems</booktitle>
<volume>7</volume>
<issue>3</issue>
<marker>Cuay´ahuitl, N, </marker>
<rawString>Cuay´ahuitl, H., and N. Dethlefs (2011a). SpatiallyAware Dialogue Control Using Hierarchical Reinforcement Learning, ACM Transactions on Speech and Language Processing (Special Issue on Machine Learning for Robust and Adaptive Spoken Dialogue Systems 7(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Dethlefs</author>
<author>H Cuay´ahuitl</author>
</authors>
<title>Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation,</title>
<date>2011</date>
<booktitle>In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-HLT).</booktitle>
<marker>Dethlefs, Cuay´ahuitl, 2011</marker>
<rawString>Dethlefs, N. and H. Cuay´ahuitl, 2011. Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation, In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Dethlefs</author>
<author>H Cuay´ahuitl</author>
</authors>
<title>Combining Hierarchical Reinforcement Learning and Bayesian Networks for Natural Language Generation in Situated Dialogue,</title>
<date>2011</date>
<booktitle>In Proceedings of the 13th European Workshop on Natural Language Generation (ENLG).</booktitle>
<marker>Dethlefs, Cuay´ahuitl, 2011</marker>
<rawString>Dethlefs, N. and H. Cuay´ahuitl, 2011. Combining Hierarchical Reinforcement Learning and Bayesian Networks for Natural Language Generation in Situated Dialogue, In Proceedings of the 13th European Workshop on Natural Language Generation (ENLG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Dethlefs</author>
<author>H Cuay´ahuitl</author>
<author>K-F Richter</author>
<author>E Andonova</author>
<author>J Bateman</author>
</authors>
<title>Evaluating Task Success in a Dialogue System for Indoor Navigation,</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on the Semantics and Pragmatics ofDialogue (SemDial).</booktitle>
<marker>Dethlefs, Cuay´ahuitl, Richter, Andonova, Bateman, 2010</marker>
<rawString>Dethlefs, N., Cuay´ahuitl, H., Richter, K.-F., Andonova, E. and J. Bateman, 2010. Evaluating Task Success in a Dialogue System for Indoor Navigation, In Proceedings of the Workshop on the Semantics and Pragmatics ofDialogue (SemDial).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gargett</author>
<author>K Garoufi</author>
<author>A Koller</author>
<author>K Striegnitz</author>
</authors>
<date>2010</date>
<booktitle>The GIVE-2 Corpus of Giving Instructions in Virtual Environments, Proc. of the 7th International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="3655" citStr="Gargett et al., 2010" startWordPosition="561" endWordPosition="564">ver, who may know where the lift is, it is redundant and (2) is preferable, because it is more efficient. An unfamiliar user may get confused with just (2). In this paper, we distinguish navigation of destination (‘go back to the office’), direction (‘turn left’), orientation (‘turn around’), path (‘follow the 636 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 636–640, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics corridor’) and straight’ (‘go forward’) in the GIVE corpus (Gargett et al., 2010). Users can react to an instruction by performing the action, performing an undesired action, hesitating or requesting help. 3 Jointly Learnt NLG: Hierarchical RL with Graphical Models In a joint framework, each subtask of content selection, utterance planning and surface realisation has knowledge of the decisions made in the other two subtasks. In an isolated framework, this knowledge is absent. In the joint case, the relationship between hierarchical RL and graphical models is that the latter provide feedback to the former’s surface realisation decisions according to a human corpus. Hierarch</context>
</contexts>
<marker>Gargett, Garoufi, Koller, Striegnitz, 2010</marker>
<rawString>Gargett, A., Garoufi, K., Koller, A. and K. Striegnitz (2010). The GIVE-2 Corpus of Giving Instructions in Virtual Environments, Proc. of the 7th International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Georgila</author>
<author>N Fakotakis</author>
<author>G Kokkinakis</author>
</authors>
<title>Stochastic Language Modelling for Recognition and Generation in Dialogue Systems.</title>
<date>2002</date>
<journal>TAL (Traitement automatique des langues) Journal,</journal>
<volume>43</volume>
<issue>3</issue>
<contexts>
<context position="2127" citStr="Georgila et al., 2002" startWordPosition="310" endWordPosition="313"> is that decisions of all three NLG stages share information and can be made in an interrelated fashion. We present a joint NLG framework based on Hierarchical RL and focus, in particular, on the surface realisation component of joint NLG systems. We compare the user satisfaction and naturalness of surface realisation using Hidden Markov Models (HMMs) and Bayesian Networks (BNs) which both have been suggested as generation spaces—spaces of surface form variants for a semantic concept— within joint NLG systems (Dethlefs and Cuay´ahuitl, 2011a; Dethlefs and Cuay´ahuitl, 2011b) and in isolation (Georgila et al., 2002; Mairesse et al., 2010). 2 Surface Realisation for Situated NLG We address the generation of navigation instructions, where e.g. the semantic form (path(target = end of corridor) ∧ (landmark = lift ∧ dir = left)) can be expressed as ‘Go to the end of the corridor’, ‘Head to the end of the corridor past the lift on your left’ and many more. The best realisation depends on the space (types and properties of spatial objects), the user (position, orientation, prior knowledge) and decisions of content selection and utterance planning. These can be interrelated with surface realisation, for example</context>
</contexts>
<marker>Georgila, Fakotakis, Kokkinakis, 2002</marker>
<rawString>Georgila, K., Fakotakis, N. and Kokkinakis, G. (2002). Stochastic Language Modelling for Recognition and Generation in Dialogue Systems. TAL (Traitement automatique des langues) Journal, Vol. 43(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Lemon</author>
</authors>
<title>Learning what to say and how to say it: joint optimization of spoken dialogue management and Natural Language Generation,</title>
<date>2011</date>
<journal>Computer Speech and Language</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1398" citStr="Lemon, 2011" startWordPosition="198" endWordPosition="199">former perform best in isolation, the latter present a scalable alternative within joint systems. 1 Introduction NLG systems have traditionally used a pipeline architecture which divides the generation process into three distinct stages. Content selection chooses ‘what to say’ and constructs a semantic form. Utterance planning organises the message into submessages and surface realisation maps the semantics onto words. Recently, a number of studies have pointed out that many decisions made at these distinct stages require interrelated, rather than isolated, optimisations (Angeli et al., 2010; Lemon, 2011; Cuay´ahuitl and Dethlefs, 2011a; Dethlefs and Cuay´ahuitl, 2011a). The key feature of a joint architecture is that decisions of all three NLG stages share information and can be made in an interrelated fashion. We present a joint NLG framework based on Hierarchical RL and focus, in particular, on the surface realisation component of joint NLG systems. We compare the user satisfaction and naturalness of surface realisation using Hidden Markov Models (HMMs) and Bayesian Networks (BNs) which both have been suggested as generation spaces—spaces of surface form variants for a semantic concept— wi</context>
</contexts>
<marker>Lemon, 2011</marker>
<rawString>Lemon, O. (2011). Learning what to say and how to say it: joint optimization of spoken dialogue management and Natural Language Generation, Computer Speech and Language 25(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M Gaˇsi´c</author>
<author>F Jurˇciˇcek</author>
<author>S Keizer</author>
<author>B Thomson</author>
<author>K Yu</author>
<author>S Young</author>
</authors>
<title>Phrase-based statistical language generation using graphical models and active learning,</title>
<date>2010</date>
<booktitle>Proc. of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Mairesse, Gaˇsi´c, Jurˇciˇcek, Keizer, Thomson, Yu, Young, 2010</marker>
<rawString>Mairesse, F., Gaˇsi´c, M., Jurˇciˇcek, F., Keizer, S., Thomson, B., Yu, K. and S. Young (2010). Phrase-based statistical language generation using graphical models and active learning, Proc. of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>D Litman</author>
<author>C Kamm</author>
<author>A Abella</author>
</authors>
<title>PARADISE: A Framework for Evaluating Spoken Dialogue Agents,</title>
<date>1997</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistic (ACL).</booktitle>
<contexts>
<context position="9355" citStr="Walker et al., 1997" startWordPosition="1515" endWordPosition="1518">rning framework. 4 Experimental Setting We compare instructions generated with the HMMs and BNs according to their user satisfaction and their naturalness. The learn1This is key to the joint treatment of content selection and surface realisation: if an utterance is not informative in terms of content, it will receive bad rewards, even with good surface realisation choices (and vice versa). ing agent is trained using the reward function Reward= User satisfaction x P(w0 ... wn) x CAS.2 User satisfaction is a function of task success and the number of user turns based on the PARADISE framework3 (Walker et al., 1997) and CAS refers to the proportion of repetition and variation in surface forms. Our focus in this short paper is on P(w0 ... wn) which rewards the agent for having generated a surface form sequence w0 ... wn. In HMMs, this corresponds to the forward probability—obtained from the Forward algorithm—of observing the sequence in the data. In BNs, P(w0 ... wn) corresponds to P(Yj = v,|pa(Yj) = vy), the posterior probability given the chosen values v,, and vy of random variables and their dependencies. We assign a reward of −1 for each action to prevent loops. 5 Experimental Results User satisfactio</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1997</marker>
<rawString>Walker, M., Litman, D., Kamm, C. and A. Abella (1997). PARADISE: A Framework for Evaluating Spoken Dialogue Agents, Proceedings of the Annual Meeting of the Association for Computational Linguistic (ACL).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>