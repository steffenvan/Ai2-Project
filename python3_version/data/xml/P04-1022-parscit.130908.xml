<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.995314">
Collocation Translation Acquisition Using Monolingual Corpora
</title>
<author confidence="0.985198">
Yajuan LÜ
</author>
<affiliation confidence="0.990877">
Microsoft Research Asia
</affiliation>
<address confidence="0.976298333333333">
5F Sigma Center,
No. 49 Zhichun Road, Haidian District,
Beijing, China, 100080
</address>
<email confidence="0.995621">
t-yjlv@microsoft.com
</email>
<author confidence="0.911898">
Ming ZHOU
</author>
<affiliation confidence="0.94488">
Microsoft Research Asia
</affiliation>
<address confidence="0.966629666666667">
5F Sigma Center,
No. 49 Zhichun Road, Haidian District,
Beijing, China, 100080
</address>
<email confidence="0.995195">
mingzhou@microsoft.com
</email>
<sectionHeader confidence="0.992451" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99977345">
Collocation translation is important for
machine translation and many other NLP tasks.
Unlike previous methods using bilingual
parallel corpora, this paper presents a new
method for acquiring collocation translations
by making use of monolingual corpora and
linguistic knowledge. First, dependency triples
are extracted from Chinese and English
corpora with dependency parsers. Then, a
dependency triple translation model is
estimated using the EM algorithm based on a
dependency correspondence assumption. The
generated triple translation model is used to
extract collocation translations from two
monolingual corpora. Experiments show that
our approach outperforms the existing
monolingual corpus based methods in
dependency triple translation and achieves
promising results in collocation translation
extraction.
</bodyText>
<sectionHeader confidence="0.998694" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940650793651">
A collocation is an arbitrary and recurrent word
combination (Benson, 1990). Previous work in
collocation acquisition varies in the kinds of
collocations they detect. These range from two-
word to multi-word, with or without syntactic
structure (Smadja 1993; Lin, 1998; Pearce, 2001;
Seretan et al. 2003). In this paper, a collocation
refers to a recurrent word pair linked with a certain
syntactic relation. For instance, &lt;solve, verb-object,
problem&gt; is a collocation with a syntactic relation
verb-object.
Translation of collocations is difficult for non-
native speakers. Many collocation translations are
idiosyncratic in the sense that they are
unpredictable by syntactic or semantic features.
Consider Chinese to English translation. The
translations of “解决” can be “solve” or “resolve”.
The translations of “问题” can be “problem” or
“issue”. However, translations of the collocation
“解决 — 问题” as “solve—problem” or “resolve—
issue” is preferred over “solve—issue” or “resolve
—problem”. Automatically acquiring these
collocation translations will be very useful for
machine translation, cross language information
retrieval, second language learning and many other
NLP applications. (Smadja et al., 1996; Gao et al.,
2002; Wu and Zhou, 2003).
Some studies have been done for acquiring
collocation translations using parallel corpora
(Smadja et al, 1996; Kupiec, 1993; Echizen-ya et
al., 2003). These works implicitly assume that a
bilingual corpus on a large scale can be obtained
easily. However, despite efforts in compiling
parallel corpora, sufficient amounts of such
corpora are still unavailable. Instead of heavily
relying on bilingual corpora, this paper aims to
solve the bottleneck in a different way: to mine
bilingual knowledge from structured monolingual
corpora, which can be more easily obtained in a
large volume.
Our method is based on the observation that
despite the great differences between Chinese and
English, the main dependency relations tend to
have a strong direct correspondence (Zhou et al.,
2001). Based on this assumption, a new translation
model based on dependency triples is proposed.
The translation probabilities are estimated from
two monolingual corpora using the EM algorithm
with the help of a bilingual translation dictionary.
Experimental results show that the proposed triple
translation model outperforms the other three
models in comparison. The obtained triple
translation model is also used for collocation
translation extraction. Evaluation results
demonstrate the effectiveness of our method.
The remainder of this paper is organized as
follows. Section 2 provides a brief description on
the related work. Section 3 describes our triple
translation model and training algorithm. Section 4
extracts collocation translations from two
independent monolingual corpora. Section 5
evaluates the proposed method, and the last section
draws conclusions and presents the future work.
</bodyText>
<sectionHeader confidence="0.999" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.992410615384616">
There has been much previous work done on
monolingual collocation extraction. They can in
general be classified into two types: window-based
and syntax-based methods. The former extracts
collocations within a fixed window (Church and
Hanks 1990; Smadja, 1993). The latter extracts
collocations which have a syntactic relationship
(Lin, 1998; Seretan et al., 2003). The syntax-based
method becomes more favorable with recent
significant increases in parsing efficiency and
accuracy. Several metrics have been adopted to
measure the association strength in collocation
extraction. Thanopoulos et al. (2002) give
comparative evaluations on these metrics.
Most previous research in translation knowledge
acquisition is based on parallel corpora (Brown et
al., 1993). As for collocation translation, Smadja et
al. (1996) implement a system to extract
collocation translations from a parallel English-
French corpus. English collocations are first
extracted using the Xtract system, then
corresponding French translations are sought based
on the Dice coefficient. Echizen-ya et al. (2003)
propose a method to extract bilingual collocations
using recursive chain-link-type learning. In
addition to collocation translation, there is also
some related work in acquiring phrase or term
translations from parallel corpus (Kupiec, 1993;
Yamamoto and Matsumoto 2000).
Since large aligned bilingual corpora are hard to
obtain, some research has been conducted to
exploit translation knowledge from non-parallel
corpora. Their work is mainly on word level.
Koehn and Knight (2000) presents an approach to
estimating word translation probabilities using
unrelated monolingual corpora with the EM
algorithm. The method exhibits promising results
in selecting the right translation among several
options provided by bilingual dictionary. Zhou et
al.(2001) proposes a method to simulate translation
probability with a cross language similarity score,
which is estimated from monolingual corpora
based on mutual information. The method achieves
good results in word translation selection. In
addition, (Dagan and Itai, 1994) and (Li, 2002)
propose using two monolingual corpora for word
sense disambiguation. (Fung, 1998) uses an IR
approach to induce new word translations from
comparable corpora. (Rapp, 1999) and (Koehn and
Knight, 2002) extract new word translations from
non-parallel corpus. (Cao and Li, 2002) acquire
noun phrase translations by making use of web
data. (Wu and Zhou, 2003) also make full use of
large scale monolingual corpora and limited
bilingual corpora for synonymous collocation
extraction.
3 Training a triple translation model from
monolingual corpora
In this section, we first describe the dependency
correspondence assumption underlying our
approach. Then a dependency triple translation
model and the monolingual corpus based training
algorithm are proposed. The obtained triple
translation model will be used for collocation
translation extraction in next section.
</bodyText>
<subsectionHeader confidence="0.9966065">
3.1 Dependency correspondence between
Chinese and English
</subsectionHeader>
<bodyText confidence="0.999919125">
A dependency triple consists of a head, a
dependant, and a dependency relation. Using a
dependency parser, a sentence can be analyzed into
dependency triples. We represent a triple as
(w1,r,w2), where w1 and w2 are words and r is the
dependency relation. It means that w2 has a
dependency relation r with w1. For example, a
triple (overcome, verb-object, difficulty) means that
“difficulty” is the object of the verb “overcome”.
Among all the dependency relations, we only
consider the following three key types that we
think, are the most important in text analysis and
machine translation: verb-object (VO), noun-
adj(AN), and verb- adv(AV).
It is our observation that there is a strong
correspondence in major dependency relations in
the translation between English and Chinese. For
example, an object-verb relation in Chinese
(e.g.(AER, VO, 困难)) is usually translated into
the same verb-object relation in English(e.g.
(overcome, VO, difficulty)).
This assumption has been experimentally
justified based on a large and balanced bilingual
corpus in our previous work (Zhou et al., 2001).
We come to the conclusion that more than 80% of
the above dependency relations have a one-one
mapping between Chinese and English. We can
conclude that there is indeed a very strong
correspondence between Chinese and English in
the three considered dependency relations. This
fact will be used to estimate triple translation
model using two monolingual corpora.
</bodyText>
<subsectionHeader confidence="0.99768">
3.2 Triple translation model
</subsectionHeader>
<bodyText confidence="0.9977826">
According to Bayes’s theorem, given a Chinese
triple ctri _ (c1 , rc , c2 ) , and the set of its candidate
English triple translations etri _ (e1 , re , e2) , the
best English triple eˆtri _ (eˆ1 , re , eˆ2 ) is the one that
maximizes the Equation (1):
</bodyText>
<equation confidence="0.998552363636364">
(1)
= arg max
etri
= arg max
etri
= arg max
p(etri  |ctri )
p(
tri
e
p(etri)p(
</equation>
<bodyText confidence="0.71999775">
Assumption 2: For an English triple etri ,
assume that ci only depends on ei (i ∈ {1,2}) ,
and rc only depends on re . Equation (6) is
rewritten as:
</bodyText>
<equation confidence="0.9936252">
ˆ
etri
Cm
)p( I )/p(ctri )
em
|
)
etri
ctri
etri
</equation>
<bodyText confidence="0.999343">
where p(etri) is usually called the language model
and p(ctri  |etri) is usually called the translation
model.
</bodyText>
<subsectionHeader confidence="0.950969">
Language Model
</subsectionHeader>
<bodyText confidence="0.999887142857143">
The language model p(etri) is calculated with
English triples database. In order to tackle with the
data sparseness problem, we smooth the language
model with an interpolation method, as described
below.
When the given English triple occurs in the
corpus, we can calculate it as in Equation (2).
</bodyText>
<equation confidence="0.9854605">
freq e r e
( , , )
1 e 2
p e
( ) = (2)
tri N
</equation>
<bodyText confidence="0.998836428571429">
where freq (e1 , re , e2) represents the frequency of
triple etri . N represents the total counts of all the
English triples in the training corpus.
For an English triple etri = (e1, re, e2) , if we
assume that two words e1 and e2 are conditionally
independent given the relation re , Equation (2) can
be rewritten as in (3)(Lin, 1998).
</bodyText>
<equation confidence="0.996986">
p(etri) = p(re)p(e1  |re)p(e2  |re) (3)
</equation>
<bodyText confidence="0.999431">
The wildcard symbol * means it can be any word
or relation. With Equations (2) and (3), we get the
interpolated language model as shown in (4).
</bodyText>
<equation confidence="0.98791575">
p(etri) = A N tri) +(1−A)p(re)p(e1  |re)p(e2  |re) (4)
fre
q
(e
</equation>
<bodyText confidence="0.981527">
where 0 &lt; A &lt; 1. A is calculated as below:
</bodyText>
<equation confidence="0.94768225">
A = −
1 (5)
1 + freq(etri)
1
</equation>
<subsectionHeader confidence="0.74531">
Translation Model
</subsectionHeader>
<bodyText confidence="0.9918948">
We simplify the translation model according the
following two assumptions.
Assumption 1: Given an English triple etri , and
the corresponding Chinese dependency relation rc ,
c1 and c2 are conditionally independent. We have:
</bodyText>
<equation confidence="0.999630333333333">
p(ctri  |etri) = p(c1, rc, c2
p(ctri  |etri=p(q
=p(c1  |e1)p(c2  |e2)p(rc  |re)
</equation>
<bodyText confidence="0.97673105">
Notice that p(c1  |e1) and p(c2  |e2) are
translation probabilities within triples, they are
different from the unrestricted probabilities such as
the ones in IBM models (Brown et al., 1993). We
distinguish translation probability between head
( p(c1  |e1) ) and dependant (p(c2  |e2) ). In the
rest of the paper, we use phead (c  |e) and
pdep (c  |e) to denote the head translation
probability and dependant translation probability
respectively.
As the correspondence between the same
dependency relation across English and Chinese is
strong, we simply assume p(rc  |re) =1 for the
corresponding re and rc , and p(rc  |re) = 0 for the
other cases.
phead (c1  |e1) and pdep (c2  |e2 ) cannot be
estimated directly because there is no triple-aligned
corpus available. Here, we present an approach to
estimating these probabilities from two
monolingual corpora based on the EM algorithm.
</bodyText>
<subsectionHeader confidence="0.928897">
3.3 Estimation of word translation
probability using the EM algorithm
</subsectionHeader>
<bodyText confidence="0.999906125">
Chinese and English corpora are first parsed
using a dependency parser, and two dependency
triple databases are generated. The candidate
English translation set of Chinese triples is
generated through a bilingual dictionary and the
assumption of strong correspondence of
dependency relations. There is a risk that unrelated
triples in Chinese and English can be connected
with this method. However, as the conditions that
are used to make the connection are quite strong
(i.e. possible word translations in the same triple
structure), we believe that this risk, is not very
severe. Then, the expectation maximization (EM)
algorithm is introduced to iteratively strengthen the
correct connections and weaken the incorrect
connections.
</bodyText>
<sectionHeader confidence="0.535011" genericHeader="method">
EM Algorithm
</sectionHeader>
<bodyText confidence="0.997738">
According to section 3.2, the translation
probabilities from a Chinese triple ctri to an
English triple etri can be computed using the
English triple language model p(etri) and a
translation model from English to Chinese
p(ctri  |etri) . The English language model can be
</bodyText>
<equation confidence="0.962762266666667">
p(e1  |re) = freq(e1,re,*)
*)
freq r e
(*, , )
e 2
p e r =
(  |) .
2 2
*)
freq r
(*, e
,
freqr
(*, e
,
</equation>
<table confidence="0.814840318181818">
*)
freq (*, re,
where
,
N
p(re)
= p c r , etri )p(c2  |rc
( |
1 c
)
 |etri
(6)
,
)
etri
) (
p rc
 |etri
r c , etri ) (  |r e p r  |etri )
p c2 c tri
, ) ( e
(7)
</table>
<bodyText confidence="0.7697626">
estimated using Equation (4) and the translation
model can be calculated using Equation (7). The
translation probabilities phead (c  |e) and
pdep (c  |e) are initially set to a uniform distribution
as follows:
</bodyText>
<equation confidence="0.90962225">
⎧ 1
if (c )
∈ Γ e (8)
otherwise
</equation>
<bodyText confidence="0.955924333333333">
Where Γe represents the translation set of the
English word e.
Then, the word translation probabilities are
estimated iteratively using the EM algorithm.
Figure 1 gives a formal description of the EM
algorithm.
</bodyText>
<figure confidence="0.939643875">
Train language model for English triple p(etri ) ;
Initialize word translation probabilities phead (c  |e)
and pdep (c  |e) uniformly as in Equation (8);
Iterate
Set scorehead (c  |e) and scoredep (c  |e) to 0 for all
dictionary entries (c,e);
for all Chinese triples ctri = (c1 , rc , c2 )
for all candidate English triple translations
etri = (e1, re, e2 )
compute triple translation probability
p(etri  |ctri) by
p(etri)phead(c1  |e1 )pdep(c2  |e2)p(rc  |re)
end for
normalize p(etri  |ctri ) , so that their sum is 1;
for all triple translation etri = (e1 , re , e2 )
add p(etri  |ctri ) to scorehead (c1  |e1 )
add p (etri  |ctri ) to scoredep (c2  |e2 )
endfor
endfor
for all translation pairs (c,e)
set phead (c  |e) to normalized scorehead (c  |e) ;
set pdep (c  |e) to normalized scoredep (c  |e) ;
endfor
enditerate
</figure>
<figureCaption confidence="0.999988">
Figure 1: EM algorithm
</figureCaption>
<bodyText confidence="0.99764515">
The basic idea is that under the restriction of the
English triple language model p(etri) and
translation dictionary, we wish to estimate the
translation probabilities phead (c  |e) and
pdep (c  |e) that best explain the Chinese triple
database as a translation from the English triple
database. In each iteration, the normalized triple
translation probabilities are used to update the
word translation probabilities. Intuitively, after
finding the most probable translation of the
Chinese triple, we can collect counts for the word
translation it contains. Since the English triple
language model provides context information for
the disambiguation of the Chinese words, only the
appropriate occurrences are counted.
Now, with the language model estimated using
Equation (4) and the translation probabilities
estimated using EM algorithm, we can compute the
best triple translation for a given Chinese triple
using Equations (1) and (7).
</bodyText>
<sectionHeader confidence="0.8400985" genericHeader="method">
4 Collocation translation extraction from two
monolingual corpora
</sectionHeader>
<bodyText confidence="0.999246666666667">
This section describes how to extract collocation
translation from independent monolingual corpora.
First, collocations are extracted from a
monolingual triples database. Then, collocation
translations are acquired using the triple translation
model obtained in section 3.
</bodyText>
<subsectionHeader confidence="0.991245">
4.1 Monolingual collocation extraction
</subsectionHeader>
<bodyText confidence="0.997409666666667">
As introduced in section 2, much work has been
done to extract collocations. Among all the
measure metrics, log likelihood ratio (LLR) has
proved to give better results (Duning, 1993;
Thanopoulos et al., 2002). In this paper, we take
LLR as the metric to extract collocations from a
dependency triple database.
For a given Chinese triple ctri = (c1 , rc , c2) , the
LLR score is calculated as follows:
</bodyText>
<equation confidence="0.968239466666667">
Logl a a b b c c d d
= log + log + log + log
)−(a+c)log(a+c ) (9)
)−(
c+d)log(c+d)
+N N
log
where,
a freq c
= ( 1 , rc ,c2),
, c ,*) − ( 1
r freq c
rc, c2) − freq (c1 rc, c2 ),
− −
b c.
</equation>
<bodyText confidence="0.996429625">
N is the total counts of all Chinese triples.
Those triples whose LLR values are larger than a
given threshold are taken as a collocation. This
syntax-based collocation has the advantage that it
can represent both adjacent and long distance word
association. Here, we only extract the three main
types of collocation that have been mentioned in
section 3.1.
</bodyText>
<subsectionHeader confidence="0.984658">
4.2 Collocation translation extraction
</subsectionHeader>
<bodyText confidence="0.9954665">
For the acquired collocations, we try to extract
their translations from the other monolingual
</bodyText>
<equation confidence="0.825030421052632">
⎪⎩0,
phead
(
−
a+b
)log(a+b
b+d )log(b+d
(
−
b freq c
= ( 1
(*,
c freq
=
),
, rc ,c2
=
N a
−
</equation>
<bodyText confidence="0.9701119375">
d
corpus using the triple translation model trained
with the method proposed in section 3.
Our objective is to acquire collocation
translations as translation knowledge for a machine
translation system, so only highly reliable
collocation translations are extracted. Figure 2
describes the algorithm for Chinese-English
collocation translation extraction. It can be seen
that the best English triple candidate is extracted as
the translation of the given Chinese collocation
only if the Chinese collocation is also the best
translation candidate of the English triple. But the
English triple is not necessarily a collocation.
English collocation translations can be extracted in
a similar way.
</bodyText>
<figure confidence="0.970299214285714">
For each Chinese collocation ccol :
a. Acquire the best English triple translation
eˆtri using C-E triple translation model:
e tri
ˆ = arg max p(etri) p(ctri  |etri)
etri
b. For the acquired eˆtri , calculate the best
Chinese triple translation cˆtri using E-C
triple translation model:
c tri
ˆ = arg max p(ctri) p(etri  |ctri )
ctri
c. If ccol = cˆtri , add ccol Ù eˆtri to collocation
translation database.
</figure>
<figureCaption confidence="0.999449">
Figure 2: Collocation translation extraction
</figureCaption>
<subsectionHeader confidence="0.948125">
4.3 Implementation of our approach
</subsectionHeader>
<bodyText confidence="0.998946636363636">
Our English corpus is from Wall Street Journal
(1987-1992) and Associated Press (1988-1990),
and the Chinese corpus is from People’s Daily
(1980-1998). The two corpora are parsed using the
NLPWin parser1 (Heidorn, 2000). The statistics for
three main types of dependency triples are shown
in tables 1 and 2. Token refers to the total number
of triple occurrences and Type refers to the number
of unique triples in the corpus. Statistic for the
extracted Chinese collocations and the collocation
translations is shown in Table 3.
</bodyText>
<table confidence="0.99204675">
Class #Type #Token
VO 1,579,783 19,168,229
AN 311,560 5,383,200
AV 546,054 9,467,103
</table>
<tableCaption confidence="0.999708">
Table 1: Chinese dependency triples
</tableCaption>
<footnote confidence="0.9656628">
1 The NLPWin parser is a rule-based parser
developed at Microsoft research, which parses several
languages including Chinese and English. Its output can
be a phrase structure parse tree or a logical form which
is represented with dependency triples.
</footnote>
<table confidence="0.85553125">
Class #Type #Token
VO 1,526,747 8,943,903
AN 1,163,440 6,386,097
AV 215,110 1,034,410
</table>
<tableCaption confidence="0.930604">
Table 2: English dependency triples
</tableCaption>
<table confidence="0.99970075">
Class #Type #Translated
VO 99,609 28,841
AN 35,951 12,615
AV 46,515 6,176
</table>
<tableCaption confidence="0.9626915">
Table 3: Extracted Chinese collocations
and E-C translation pairs
</tableCaption>
<bodyText confidence="0.9999282">
The translation dictionaries we used in training
and translation are combined from two dictionaries:
HITDic and NLPWinDic 2 . The final E-C
dictionary contains 126,135 entries, and C-E
dictionary contains 91,275 entries.
</bodyText>
<sectionHeader confidence="0.970148" genericHeader="evaluation">
5 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.999814166666667">
To evaluate the effectiveness of our methods,
two experiments have been conducted. The first
one compares our method with three other
monolingual corpus based methods in triple
translation. The second one evaluates the accuracy
of the acquired collocation translation.
</bodyText>
<subsectionHeader confidence="0.98224">
5.1 Dependency triple translation
</subsectionHeader>
<bodyText confidence="0.983163076923077">
Triple translation experiments are conducted
from Chinese to English. We randomly selected
2000 Chinese triples (whose frequency is larger
than 2) from the dependency triple database. The
standard translation answer sets were built
manually by three linguistic experts. For each
Chinese triple, its English translation set contain
English triples provided by anyone of the three
linguists. Among 2000 candidate triples, there are
101 triples that can’t be translated into English
triples with same relation. For example, the
Chinese triple (讲, VO, 价钱) should be translated
into “bargain”. The two words in triple cannot be
translated separately. We call this kind of
collocation translation no-compositional
translations. Our current model cannot deal with
this kind of translation. In addition, there are also
157 error dependency triples, which result from
parsing mistakes. We filtered out these two kinds
of triples and got a standard test set with 1,742
Chinese triples and 4,645 translations in total.
We compare our triple translation model with
three other models on the same standard test set
with the same translation dictionary. As the
2 These two dictionaries are built by Harbin Institute
of Technology and Microsoft Research respectively.
baseline experiment, Model A selects the highest-
frequency translation for each word in triple;
Model B selects translation with the maximal
target triple probability, as proposed in (Dagan
1994); Model C selects translation using both
language model and translation model, but the
translation probability is simulated by a similarity
score which is estimated from monolingual corpus
using mutual information measure (Zhou et al.,
2001). And our triple translation model is model D.
Suppose ctri = (c1 , rc , c2) is the Chinese triple to
be translated. The four compared models can be
formally expressed as follows:
</bodyText>
<equation confidence="0.968742866666667">
Model A:
emax = (arg max ( freq (e1)), re, arg max ( freq (e2 ))
e Trans c
∈ ( ) e Trans c
( )
1 1 2∈ 2
Model B:
arg max ( ) arg max ( , ,
p e = p e r e
tri 1 e 2
Model C:
)×likelyhood(ctri  |etri))
etri
( ( ) Sim( , ) Sim( , ))
p e × e c × e c
</equation>
<bodyText confidence="0.85151475">
tri 1 1 2
where, Sim(e, c) is similarity score between e
and c (Zhou et al., 2001).
Model D (our model):
</bodyText>
<table confidence="0.9348958">
emax =argmax(p(etri)p(ctri  |etri
etri
e2 ∈ Trans( c2 )
Cove- Accuracy(%) Oracle
Rage(%) (%)
Top 1 Top 3
Model A 83.98 17.21 ---- 66.30
Model B 33.56 53.79
Model C 35.88 57.74
Model D 36.91 58.58
</table>
<tableCaption confidence="0.999511">
Table 4: Translation results comparison
</tableCaption>
<bodyText confidence="0.9999781">
The evaluation results on the standard test set are
shown in Table 4, where coverage is the
percentages of triples which can be translated.
Some triples can’t be translated by Model B, C and
D because of the lack of dictionary translations or
data sparseness in triples. In fact, the coverage of
Model A is 100%. It was set to the same as others
in order to compare accuracy using the same test
set. The oracle score is the upper bound accuracy
under the conditions of current translation
dictionary and standard test set. Top N accuracy is
defined as the percentage of triples whose selected
top N translations include correct translations.
We can see that both Model C and Model D
achieve better results than Model B. This shows
that the translation model trained from
monolingual corpora really helps to improve the
performance of translation. Our model also
outperforms Model C, which demonstrates the
probabilities trained by our EM algorithm achieve
better performance than heuristic similarity scores.
In fact, our evaluation method is very rigorous.
To avoid bias in evaluation, we take human
translation results as standard. The real translation
accuracy is reasonably better than the evaluation
results. But as we can see, compared to the oracle
score, the current models still have much room for
improvement. And coverage is also not high due to
the limitations of the translation dictionary and the
sparse data problem.
</bodyText>
<subsectionHeader confidence="0.998979">
5.2 Collocation translation extraction
</subsectionHeader>
<bodyText confidence="0.999095375">
47,632 Chinese collocation translations are
extracted with the method proposed in section 4.
We randomly selected 1000 translations for
evaluation. Three linguistic experts tag the
acceptability of the translation. Those translations
that are tagged as acceptable by at least two
experts are evaluated as correct. The evaluation
results are shown in Table 5.
</bodyText>
<table confidence="0.999807">
Total Acceptance Accuracy (%)
VO 590 373 63.22
AN 292 199 68.15
AV 118 60 50.85
All 1000 632 63.20
ColTrans 334 241 72.16
</table>
<tableCaption confidence="0.999742">
Table 5: Extracted collocation translation results
</tableCaption>
<bodyText confidence="0.999809315789474">
We can see that the extracted collocation
translations achieve a much better result than triple
translation. The average accuracy is 63.20% and
the collocations with relation AN achieve the
highest accuracy of 68.15%. If we only consider
those Chinese collocations whose translations are
also English collocations, we obtain an even better
accuracy of 72.16% as shown in the last row of
Table 5. The results justify our idea that we can
acquire reliable translation for collocation by
making use of triple translation model in two
directions.
These acquired collocation translations are very
valuable for translation knowledge building.
Manually crafting collocation translations can be
time-consuming and cannot ensure high quality in
a consistent way. Our work will certainly improve
the quality and efficiency of collocation translation
acquisition.
</bodyText>
<figure confidence="0.997119913043478">
etri
e Trans
1∈
( )
c1
e2∈ Trans (c2 )
= argmax( (
p etri
∈Trans(c1 )
)phead(c1  |e1)pdep
e1
(c2  |e2 )p(rc  |re))
e =
max
)
arg
max( (
p etri
emax
arg max
e1∈Trans(c1)
e2∈Trans(c2 )
))
</figure>
<subsectionHeader confidence="0.855679">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999851333333333">
Although our approach achieves promising
results, it still has some limitations to be remedied
in future work.
</bodyText>
<listItem confidence="0.926856">
(1) Translation dictionary extension
</listItem>
<bodyText confidence="0.97494305882353">
Due to the limited coverage of the dictionary, a
correct translation may not be stored in the
dictionary. This naturally limits the coverage of
triple translations. Some research has been done to
expand translation dictionary using a non-parallel
corpus (Rapp, 1999; Keohn and Knight, 2002). It
can be used to improve our work.
(2) Noise filtering of parsers
Since we use parsers to generate dependency
triple databases, this inevitably introduces some
parsing mistakes. From our triple translation test
data, we can see that 7.85% (157/2000) types of
triples are error triples. These errors will certainly
influence the translation probability estimation in
the training process. We need to find an effective
way to filter out mistakes and perform necessary
automatic correction.
</bodyText>
<listItem confidence="0.930187">
(3) Non-compositional collocation translation.
</listItem>
<bodyText confidence="0.9999005">
Our model is based on the dependency
correspondence assumption, which assumes that a
triple’s translation is also a triple. But there are still
some collocations that can’t be translated word by
word. For example, the Chinese triple (&amp;4, VO,
)AxA) usually be translated into “be effective”; the
English triple (take, VO, place) usually be
translated into “Rt”. The two words in triple
cannot be translated separately. Our current model
cannot deal with this kind of non-compositional
collocation translation. Melamed (1997) and Lin
(1999) have done some research on non-
compositional phrases discovery. We will consider
taking their work as a complement to our model.
</bodyText>
<sectionHeader confidence="0.986983" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999984652173913">
This paper proposes a novel method to train a
triple translation model and extract collocation
translations from two independent monolingual
corpora. Evaluation results show that it
outperforms the existing monolingual corpus based
methods in triple translation, mainly due to the
employment of EM algorithm in cross language
translation probability estimation. By making use
of the acquired triple translation model in two
directions, promising results are achieved in
collocation translation extraction.
Our work also demonstrates the possibility of
making full use of monolingual resources, such as
corpora and parsers for bilingual tasks. This can
help overcome the bottleneck of the lack of a
large-scale bilingual corpus. This approach is also
applicable to comparable corpora, which are also
easier to access than bilingual corpora.
In future work, we are interested in extending
our method to solving the problem of non-
compositional collocation translation. We are also
interested in incorporating our triple translation
model for sentence level translation.
</bodyText>
<sectionHeader confidence="0.998431" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999892">
The authors would like to thank John Chen,
Jianfeng Gao and Yunbo Cao for their valuable
suggestions and comments on a preliminary draft
of this paper.
</bodyText>
<sectionHeader confidence="0.999401" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999619625">
Morton Benson. 1990. Collocations and general-
purpose dictionaries. International Journal of
Lexicography. 3(1):23–35
Yunbo Cao, Hang Li. 2002. Base noun phrase
translation using Web data and the EM algorithm.
The 19th International Conference on
Computational Linguistics. pp.127-133
Kenneth W. Church and Patrick Hanks. 1990.
Word association norms, mutural information,
and lexicography. Computational Linguistics,
16(1):22-29
Ido Dagan and Alon Itai. 1994. Word sense
disambiguation using a second language
monolingual corpus. Computational Linguistics,
20(4):563-596
Ted Dunning. 1993. Accurate methods for the
statistics of surprise and coincidence.
Computational Linguistics. 19(1):61-74
Hiroshi Echizen-ya, Kenji Araki, Yoshi Momouchi,
Koji Tochinai. 2003. Effectiveness of automatic
extraction of bilingual collocations using
recursive chain-link-type learning. The 9th
Machine Translation Summit. pp.102-109
Pascale Fung, and Yee Lo Yuen. 1998. An IR
approach for translating new words from
nonparallel, comparable Texts. The 36th annual
conference of the Association for Computational
Linguistics. pp. 414-420
Jianfeng Gao, Jianyun Nie, Hongzhao He, Weijun
Chen, Ming Zhou. 2002. Resolving query
translation ambiguity using a decaying co-
occurrence model and syntactic dependence
relations. The 25th Annual International ACM
SIGIR Conference on Research and
Development in Information Retrieval. pp.183 -
190
G. Heidorn. 2000. Intelligent writing assistant. In
R. Dale, H. Moisl, and H. Somers, editors, A
Handbook of Natural Language Processing:
Techniques and Applications for the Processing
of Language as Text. Marcel Dekker.
Philipp Koehn and Kevin Knight. 2000. Estimating
word translation probabilities from unrelated
monolingual corpora using the EM algorithm.
National Conference on Artificial Intelligence.
pp.711-715
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora.
Unsupervised Lexical Acquisition: Workshop of
the ACL Special Interest Group on the Lexicon.
pp. 9-16
Julian Kupiec. 1993. An algorithm for finding
noun phrase correspondences in bilingual
corpora. The 31st Annual Meeting of the
Association for Computational Linguistics, pp.
23-30
Cong Li, Hang Li. 2002. Word translation
disambiguation using bilingual bootstrapping.
The 40th annual conference of the Association
for Computational Linguistics. pp: 343-351
Dekang Lin. 1998. Extracting collocation from
Text corpora. First Workshop on Computational
Terminology. pp. 57-63
Dekang Lin 1999. Automatic identification of non-
compositional phrases. The 37th Annual Meeting
of the Association for Computational Linguistics.
pp.317--324
Ilya Dan Melamed. 1997. Automatic discovery of
non-compositional compounds in parallel data.
The 2nd Conference on Empirical Methods in
Natural Language Processing. pp. 97~108
Brown P.F., Pietra, S.A.D., Pietra, V. J. D., and
Mercer R. L. 1993. The mathematics of machine
translation: parameter estimation. Computational
Linguistics, 19(2):263-313
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated English and
German corpora. The 37th annual conference of
the Association for Computational Linguistics.
pp. 519-526
Violeta Seretan, Luka Nerima, Eric Wehrli. 2003.
Extraction of Multi-Word collocations using
syntactic bigram composition. International
Conference on Recent Advances in NLP. pp.
424-431
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics,
19(1):143-177
Frank Smadja, Kathleen R. Mckeown, Vasileios
Hatzivassiloglou. 1996. Translation collocations
for bilingual lexicons: a statistical approach.
Computational Linguistics, 22:1-38
Aristomenis Thanopoulos, Nikos Fakotakis,
George Kokkinakis. 2002. Comparative
evaluation of collocation extraction metrics. The
3rd International Conference on Language
Resource and Evaluation. pp.620-625
Hua Wu, Ming Zhou. 2003. Synonymous
collocation extraction using translation
Information. The 41th annual conference of the
Association for Computational Linguistics. pp.
120-127
Kaoru Yamamoto, Yuji Matsumoto. 2000.
Acquisition of phrase-level bilingual
correspondence using dependency structure. The
18th International Conference on Computational
Linguistics. pp. 933-939
Ming Zhou, Ding Yuan and Changning Huang.
2001. Improving translation selection with a new
translation model trained by independent
monolingual corpora. Computaional Linguistics
&amp; Chinese Language Processing. 6(1): 1-26
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.515689">
<title confidence="0.99941">Collocation Translation Acquisition Using Monolingual Corpora</title>
<author confidence="0.969208">Yajuan LÜ</author>
<affiliation confidence="0.900917">Microsoft Research Asia 5F Sigma Center,</affiliation>
<address confidence="0.977809">No. 49 Zhichun Road, Haidian District, Beijing, China, 100080</address>
<email confidence="0.998874">t-yjlv@microsoft.com</email>
<author confidence="0.997645">Ming ZHOU</author>
<affiliation confidence="0.9015365">Microsoft Research Asia 5F Sigma Center,</affiliation>
<address confidence="0.97765">No. 49 Zhichun Road, Haidian District, Beijing, China, 100080</address>
<email confidence="0.99947">mingzhou@microsoft.com</email>
<abstract confidence="0.996163190476191">Collocation translation is important for machine translation and many other NLP tasks. Unlike previous methods using bilingual parallel corpora, this paper presents a new method for acquiring collocation translations by making use of monolingual corpora and linguistic knowledge. First, dependency triples are extracted from Chinese and English corpora with dependency parsers. Then, a dependency triple translation model is estimated using the EM algorithm based on a dependency correspondence assumption. The generated triple translation model is used to extract collocation translations from two monolingual corpora. Experiments show that our approach outperforms the existing monolingual corpus based methods in dependency triple translation and achieves promising results in collocation translation extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Morton Benson</author>
</authors>
<title>Collocations and generalpurpose dictionaries.</title>
<date>1990</date>
<journal>International Journal of Lexicography.</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1247" citStr="Benson, 1990" startWordPosition="162" endWordPosition="163">ency triples are extracted from Chinese and English corpora with dependency parsers. Then, a dependency triple translation model is estimated using the EM algorithm based on a dependency correspondence assumption. The generated triple translation model is used to extract collocation translations from two monolingual corpora. Experiments show that our approach outperforms the existing monolingual corpus based methods in dependency triple translation and achieves promising results in collocation translation extraction. 1 Introduction A collocation is an arbitrary and recurrent word combination (Benson, 1990). Previous work in collocation acquisition varies in the kinds of collocations they detect. These range from twoword to multi-word, with or without syntactic structure (Smadja 1993; Lin, 1998; Pearce, 2001; Seretan et al. 2003). In this paper, a collocation refers to a recurrent word pair linked with a certain syntactic relation. For instance, &lt;solve, verb-object, problem&gt; is a collocation with a syntactic relation verb-object. Translation of collocations is difficult for nonnative speakers. Many collocation translations are idiosyncratic in the sense that they are unpredictable by syntactic o</context>
</contexts>
<marker>Benson, 1990</marker>
<rawString>Morton Benson. 1990. Collocations and generalpurpose dictionaries. International Journal of Lexicography. 3(1):23–35</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunbo Cao</author>
<author>Hang Li</author>
</authors>
<title>Base noun phrase translation using Web data and the EM algorithm.</title>
<date>2002</date>
<booktitle>The 19th International Conference on Computational Linguistics.</booktitle>
<pages>127--133</pages>
<contexts>
<context position="6507" citStr="Cao and Li, 2002" startWordPosition="919" endWordPosition="922">options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. (Fung, 1998) uses an IR approach to induce new word translations from comparable corpora. (Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus. (Cao and Li, 2002) acquire noun phrase translations by making use of web data. (Wu and Zhou, 2003) also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction. 3 Training a triple translation model from monolingual corpora In this section, we first describe the dependency correspondence assumption underlying our approach. Then a dependency triple translation model and the monolingual corpus based training algorithm are proposed. The obtained triple translation model will be used for collocation translation extraction in next section. 3.1 Dependency c</context>
</contexts>
<marker>Cao, Li, 2002</marker>
<rawString>Yunbo Cao, Hang Li. 2002. Base noun phrase translation using Web data and the EM algorithm. The 19th International Conference on Computational Linguistics. pp.127-133</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutural information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="4358" citStr="Church and Hanks 1990" startWordPosition="616" endWordPosition="619">s paper is organized as follows. Section 2 provides a brief description on the related work. Section 3 describes our triple translation model and training algorithm. Section 4 extracts collocation translations from two independent monolingual corpora. Section 5 evaluates the proposed method, and the last section draws conclusions and presents the future work. 2 Related work There has been much previous work done on monolingual collocation extraction. They can in general be classified into two types: window-based and syntax-based methods. The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993). The latter extracts collocations which have a syntactic relationship (Lin, 1998; Seretan et al., 2003). The syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extrac</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word association norms, mutural information, and lexicography. Computational Linguistics, 16(1):22-29</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Word sense disambiguation using a second language monolingual corpus.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="6216" citStr="Dagan and Itai, 1994" startWordPosition="875" endWordPosition="878"> non-parallel corpora. Their work is mainly on word level. Koehn and Knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the EM algorithm. The method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. (Fung, 1998) uses an IR approach to induce new word translations from comparable corpora. (Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus. (Cao and Li, 2002) acquire noun phrase translations by making use of web data. (Wu and Zhou, 2003) also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction. 3 Training a triple translation model from monolingual corpora In this section, we first describe the dep</context>
</contexts>
<marker>Dagan, Itai, 1994</marker>
<rawString>Ido Dagan and Alon Itai. 1994. Word sense disambiguation using a second language monolingual corpus. Computational Linguistics, 20(4):563-596</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence. Computational Linguistics.</title>
<date>1993</date>
<pages>19--1</pages>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics. 19(1):61-74</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Echizen-ya</author>
<author>Kenji Araki</author>
<author>Yoshi Momouchi</author>
<author>Koji Tochinai</author>
</authors>
<title>Effectiveness of automatic extraction of bilingual collocations using recursive chain-link-type learning.</title>
<date>2003</date>
<booktitle>The 9th Machine Translation Summit.</booktitle>
<pages>102--109</pages>
<contexts>
<context position="2567" citStr="Echizen-ya et al., 2003" startWordPosition="352" endWordPosition="355">olve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations of the collocation “解决 — 问题” as “solve—problem” or “resolve— issue” is preferred over “solve—issue” or “resolve —problem”. Automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other NLP applications. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al., 2003). These works implicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in a large volume. Our method is based on the observation that despite the great differences between Chinese and English, the main dependency relations tend to have a strong direct </context>
<context position="5194" citStr="Echizen-ya et al. (2003)" startWordPosition="732" endWordPosition="735"> efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora. Their work is mainly on word level. Koehn and Knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the EM al</context>
</contexts>
<marker>Echizen-ya, Araki, Momouchi, Tochinai, 2003</marker>
<rawString>Hiroshi Echizen-ya, Kenji Araki, Yoshi Momouchi, Koji Tochinai. 2003. Effectiveness of automatic extraction of bilingual collocations using recursive chain-link-type learning. The 9th Machine Translation Summit. pp.102-109</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Yee Lo Yuen</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable Texts.</title>
<date>1998</date>
<booktitle>The 36th annual conference of the Association for Computational Linguistics.</booktitle>
<pages>414--420</pages>
<marker>Fung, Yuen, 1998</marker>
<rawString>Pascale Fung, and Yee Lo Yuen. 1998. An IR approach for translating new words from nonparallel, comparable Texts. The 36th annual conference of the Association for Computational Linguistics. pp. 414-420</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Jianyun Nie</author>
<author>Hongzhao He</author>
<author>Weijun Chen</author>
<author>Ming Zhou</author>
</authors>
<title>Resolving query translation ambiguity using a decaying cooccurrence model and syntactic dependence relations.</title>
<date>2002</date>
<booktitle>The 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. pp.183</booktitle>
<pages>190</pages>
<contexts>
<context position="2396" citStr="Gao et al., 2002" startWordPosition="326" endWordPosition="329">iosyncratic in the sense that they are unpredictable by syntactic or semantic features. Consider Chinese to English translation. The translations of “解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations of the collocation “解决 — 问题” as “solve—problem” or “resolve— issue” is preferred over “solve—issue” or “resolve —problem”. Automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other NLP applications. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al., 2003). These works implicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in a large</context>
</contexts>
<marker>Gao, Nie, He, Chen, Zhou, 2002</marker>
<rawString>Jianfeng Gao, Jianyun Nie, Hongzhao He, Weijun Chen, Ming Zhou. 2002. Resolving query translation ambiguity using a decaying cooccurrence model and syntactic dependence relations. The 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. pp.183 -190</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heidorn</author>
</authors>
<title>Intelligent writing assistant. In</title>
<date>2000</date>
<booktitle>A Handbook of Natural Language Processing: Techniques and Applications for the Processing of Language as Text.</booktitle>
<editor>R. Dale, H. Moisl, and H. Somers, editors,</editor>
<publisher>Marcel Dekker.</publisher>
<contexts>
<context position="17986" citStr="Heidorn, 2000" startWordPosition="2881" endWordPosition="2882">ng C-E triple translation model: e tri ˆ = arg max p(etri) p(ctri |etri) etri b. For the acquired eˆtri , calculate the best Chinese triple translation cˆtri using E-C triple translation model: c tri ˆ = arg max p(ctri) p(etri |ctri ) ctri c. If ccol = cˆtri , add ccol Ù eˆtri to collocation translation database. Figure 2: Collocation translation extraction 4.3 Implementation of our approach Our English corpus is from Wall Street Journal (1987-1992) and Associated Press (1988-1990), and the Chinese corpus is from People’s Daily (1980-1998). The two corpora are parsed using the NLPWin parser1 (Heidorn, 2000). The statistics for three main types of dependency triples are shown in tables 1 and 2. Token refers to the total number of triple occurrences and Type refers to the number of unique triples in the corpus. Statistic for the extracted Chinese collocations and the collocation translations is shown in Table 3. Class #Type #Token VO 1,579,783 19,168,229 AN 311,560 5,383,200 AV 546,054 9,467,103 Table 1: Chinese dependency triples 1 The NLPWin parser is a rule-based parser developed at Microsoft research, which parses several languages including Chinese and English. Its output can be a phrase stru</context>
</contexts>
<marker>Heidorn, 2000</marker>
<rawString>G. Heidorn. 2000. Intelligent writing assistant. In R. Dale, H. Moisl, and H. Somers, editors, A Handbook of Natural Language Processing: Techniques and Applications for the Processing of Language as Text. Marcel Dekker.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Estimating word translation probabilities from unrelated monolingual corpora using the EM algorithm.</title>
<date>2000</date>
<booktitle>National Conference on Artificial Intelligence.</booktitle>
<pages>711--715</pages>
<contexts>
<context position="5677" citStr="Koehn and Knight (2000)" startWordPosition="801" endWordPosition="804">extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora. Their work is mainly on word level. Koehn and Knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the EM algorithm. The method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for wor</context>
</contexts>
<marker>Koehn, Knight, 2000</marker>
<rawString>Philipp Koehn and Kevin Knight. 2000. Estimating word translation probabilities from unrelated monolingual corpora using the EM algorithm. National Conference on Artificial Intelligence. pp.711-715</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora. Unsupervised Lexical Acquisition:</title>
<date>2002</date>
<booktitle>Workshop of the ACL Special Interest Group on the Lexicon.</booktitle>
<pages>9--16</pages>
<contexts>
<context position="6432" citStr="Koehn and Knight, 2002" startWordPosition="908" endWordPosition="911">thod exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. (Fung, 1998) uses an IR approach to induce new word translations from comparable corpora. (Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus. (Cao and Li, 2002) acquire noun phrase translations by making use of web data. (Wu and Zhou, 2003) also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction. 3 Training a triple translation model from monolingual corpora In this section, we first describe the dependency correspondence assumption underlying our approach. Then a dependency triple translation model and the monolingual corpus based training algorithm are proposed. The obtained triple translation model will be us</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. Unsupervised Lexical Acquisition: Workshop of the ACL Special Interest Group on the Lexicon. pp. 9-16</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>An algorithm for finding noun phrase correspondences in bilingual corpora.</title>
<date>1993</date>
<booktitle>The 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>23--30</pages>
<contexts>
<context position="2541" citStr="Kupiec, 1993" startWordPosition="350" endWordPosition="351">“解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations of the collocation “解决 — 问题” as “solve—problem” or “resolve— issue” is preferred over “solve—issue” or “resolve —problem”. Automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other NLP applications. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al., 2003). These works implicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in a large volume. Our method is based on the observation that despite the great differences between Chinese and English, the main dependency relations ten</context>
<context position="5435" citStr="Kupiec, 1993" startWordPosition="767" endWordPosition="768">on is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora. Their work is mainly on word level. Koehn and Knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the EM algorithm. The method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarit</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Julian Kupiec. 1993. An algorithm for finding noun phrase correspondences in bilingual corpora. The 31st Annual Meeting of the Association for Computational Linguistics, pp. 23-30</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cong Li</author>
<author>Hang Li</author>
</authors>
<title>Word translation disambiguation using bilingual bootstrapping.</title>
<date>2002</date>
<booktitle>The 40th annual conference of the Association for Computational Linguistics.</booktitle>
<pages>343--351</pages>
<marker>Li, Li, 2002</marker>
<rawString>Cong Li, Hang Li. 2002. Word translation disambiguation using bilingual bootstrapping. The 40th annual conference of the Association for Computational Linguistics. pp: 343-351</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Extracting collocation from Text corpora.</title>
<date>1998</date>
<booktitle>First Workshop on Computational Terminology.</booktitle>
<pages>57--63</pages>
<contexts>
<context position="1438" citStr="Lin, 1998" startWordPosition="191" endWordPosition="192">ndence assumption. The generated triple translation model is used to extract collocation translations from two monolingual corpora. Experiments show that our approach outperforms the existing monolingual corpus based methods in dependency triple translation and achieves promising results in collocation translation extraction. 1 Introduction A collocation is an arbitrary and recurrent word combination (Benson, 1990). Previous work in collocation acquisition varies in the kinds of collocations they detect. These range from twoword to multi-word, with or without syntactic structure (Smadja 1993; Lin, 1998; Pearce, 2001; Seretan et al. 2003). In this paper, a collocation refers to a recurrent word pair linked with a certain syntactic relation. For instance, &lt;solve, verb-object, problem&gt; is a collocation with a syntactic relation verb-object. Translation of collocations is difficult for nonnative speakers. Many collocation translations are idiosyncratic in the sense that they are unpredictable by syntactic or semantic features. Consider Chinese to English translation. The translations of “解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations</context>
<context position="4454" citStr="Lin, 1998" startWordPosition="631" endWordPosition="632">ibes our triple translation model and training algorithm. Section 4 extracts collocation translations from two independent monolingual corpora. Section 5 evaluates the proposed method, and the last section draws conclusions and presents the future work. 2 Related work There has been much previous work done on monolingual collocation extraction. They can in general be classified into two types: window-based and syntax-based methods. The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993). The latter extracts collocations which have a syntactic relationship (Lin, 1998; Seretan et al., 2003). The syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first </context>
<context position="9959" citStr="Lin, 1998" startWordPosition="1509" endWordPosition="1510">base. In order to tackle with the data sparseness problem, we smooth the language model with an interpolation method, as described below. When the given English triple occurs in the corpus, we can calculate it as in Equation (2). freq e r e ( , , ) 1 e 2 p e ( ) = (2) tri N where freq (e1 , re , e2) represents the frequency of triple etri . N represents the total counts of all the English triples in the training corpus. For an English triple etri = (e1, re, e2) , if we assume that two words e1 and e2 are conditionally independent given the relation re , Equation (2) can be rewritten as in (3)(Lin, 1998). p(etri) = p(re)p(e1 |re)p(e2 |re) (3) The wildcard symbol * means it can be any word or relation. With Equations (2) and (3), we get the interpolated language model as shown in (4). p(etri) = A N tri) +(1−A)p(re)p(e1 |re)p(e2 |re) (4) fre q (e where 0 &lt; A &lt; 1. A is calculated as below: A = − 1 (5) 1 + freq(etri) 1 Translation Model We simplify the translation model according the following two assumptions. Assumption 1: Given an English triple etri , and the corresponding Chinese dependency relation rc , c1 and c2 are conditionally independent. We have: p(ctri |etri) = p(c1, rc, c2 p(ctri |et</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Extracting collocation from Text corpora. First Workshop on Computational Terminology. pp. 57-63</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>The 37th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>317--324</pages>
<contexts>
<context position="26502" citStr="Lin (1999)" startWordPosition="4251" endWordPosition="4252">ry automatic correction. (3) Non-compositional collocation translation. Our model is based on the dependency correspondence assumption, which assumes that a triple’s translation is also a triple. But there are still some collocations that can’t be translated word by word. For example, the Chinese triple (&amp;4, VO, )AxA) usually be translated into “be effective”; the English triple (take, VO, place) usually be translated into “Rt”. The two words in triple cannot be translated separately. Our current model cannot deal with this kind of non-compositional collocation translation. Melamed (1997) and Lin (1999) have done some research on noncompositional phrases discovery. We will consider taking their work as a complement to our model. 6 Conclusion and future work This paper proposes a novel method to train a triple translation model and extract collocation translations from two independent monolingual corpora. Evaluation results show that it outperforms the existing monolingual corpus based methods in triple translation, mainly due to the employment of EM algorithm in cross language translation probability estimation. By making use of the acquired triple translation model in two directions, promis</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin 1999. Automatic identification of noncompositional phrases. The 37th Annual Meeting of the Association for Computational Linguistics. pp.317--324</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Dan Melamed</author>
</authors>
<title>Automatic discovery of non-compositional compounds in parallel data.</title>
<date>1997</date>
<booktitle>The 2nd Conference on Empirical Methods in Natural Language Processing.</booktitle>
<pages>97--108</pages>
<contexts>
<context position="26487" citStr="Melamed (1997)" startWordPosition="4248" endWordPosition="4249">and perform necessary automatic correction. (3) Non-compositional collocation translation. Our model is based on the dependency correspondence assumption, which assumes that a triple’s translation is also a triple. But there are still some collocations that can’t be translated word by word. For example, the Chinese triple (&amp;4, VO, )AxA) usually be translated into “be effective”; the English triple (take, VO, place) usually be translated into “Rt”. The two words in triple cannot be translated separately. Our current model cannot deal with this kind of non-compositional collocation translation. Melamed (1997) and Lin (1999) have done some research on noncompositional phrases discovery. We will consider taking their work as a complement to our model. 6 Conclusion and future work This paper proposes a novel method to train a triple translation model and extract collocation translations from two independent monolingual corpora. Evaluation results show that it outperforms the existing monolingual corpus based methods in triple translation, mainly due to the employment of EM algorithm in cross language translation probability estimation. By making use of the acquired triple translation model in two dir</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>Ilya Dan Melamed. 1997. Automatic discovery of non-compositional compounds in parallel data. The 2nd Conference on Empirical Methods in Natural Language Processing. pp. 97~108</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="4875" citStr="Brown et al., 1993" startWordPosition="687" endWordPosition="690">nd syntax-based methods. The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993). The latter extracts collocations which have a syntactic relationship (Lin, 1998; Seretan et al., 2003). The syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since la</context>
<context position="10783" citStr="Brown et al., 1993" startWordPosition="1650" endWordPosition="1653">1−A)p(re)p(e1 |re)p(e2 |re) (4) fre q (e where 0 &lt; A &lt; 1. A is calculated as below: A = − 1 (5) 1 + freq(etri) 1 Translation Model We simplify the translation model according the following two assumptions. Assumption 1: Given an English triple etri , and the corresponding Chinese dependency relation rc , c1 and c2 are conditionally independent. We have: p(ctri |etri) = p(c1, rc, c2 p(ctri |etri=p(q =p(c1 |e1)p(c2 |e2)p(rc |re) Notice that p(c1 |e1) and p(c2 |e2) are translation probabilities within triples, they are different from the unrestricted probabilities such as the ones in IBM models (Brown et al., 1993). We distinguish translation probability between head ( p(c1 |e1) ) and dependant (p(c2 |e2) ). In the rest of the paper, we use phead (c |e) and pdep (c |e) to denote the head translation probability and dependant translation probability respectively. As the correspondence between the same dependency relation across English and Chinese is strong, we simply assume p(rc |re) =1 for the corresponding re and rc , and p(rc |re) = 0 for the other cases. phead (c1 |e1) and pdep (c2 |e2 ) cannot be estimated directly because there is no triple-aligned corpus available. Here, we present an approach to</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown P.F., Pietra, S.A.D., Pietra, V. J. D., and Mercer R. L. 1993. The mathematics of machine translation: parameter estimation. Computational Linguistics, 19(2):263-313</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>The 37th annual conference of the Association for Computational Linguistics.</booktitle>
<pages>519--526</pages>
<contexts>
<context position="6403" citStr="Rapp, 1999" startWordPosition="905" endWordPosition="906">algorithm. The method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. (Fung, 1998) uses an IR approach to induce new word translations from comparable corpora. (Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus. (Cao and Li, 2002) acquire noun phrase translations by making use of web data. (Wu and Zhou, 2003) also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction. 3 Training a triple translation model from monolingual corpora In this section, we first describe the dependency correspondence assumption underlying our approach. Then a dependency triple translation model and the monolingual corpus based training algorithm are proposed. The obtained triple</context>
<context position="25401" citStr="Rapp, 1999" startWordPosition="4085" endWordPosition="4086">tri e Trans 1∈ ( ) c1 e2∈ Trans (c2 ) = argmax( ( p etri ∈Trans(c1 ) )phead(c1 |e1)pdep e1 (c2 |e2 )p(rc |re)) e = max ) arg max( ( p etri emax arg max e1∈Trans(c1) e2∈Trans(c2 ) )) 5.3 Discussion Although our approach achieves promising results, it still has some limitations to be remedied in future work. (1) Translation dictionary extension Due to the limited coverage of the dictionary, a correct translation may not be stored in the dictionary. This naturally limits the coverage of triple translations. Some research has been done to expand translation dictionary using a non-parallel corpus (Rapp, 1999; Keohn and Knight, 2002). It can be used to improve our work. (2) Noise filtering of parsers Since we use parsers to generate dependency triple databases, this inevitably introduces some parsing mistakes. From our triple translation test data, we can see that 7.85% (157/2000) types of triples are error triples. These errors will certainly influence the translation probability estimation in the training process. We need to find an effective way to filter out mistakes and perform necessary automatic correction. (3) Non-compositional collocation translation. Our model is based on the dependency </context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. The 37th annual conference of the Association for Computational Linguistics. pp. 519-526</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Luka Nerima</author>
</authors>
<title>Eric Wehrli.</title>
<date>2003</date>
<booktitle>International Conference on Recent Advances in NLP.</booktitle>
<pages>424--431</pages>
<marker>Seretan, Nerima, 2003</marker>
<rawString>Violeta Seretan, Luka Nerima, Eric Wehrli. 2003. Extraction of Multi-Word collocations using syntactic bigram composition. International Conference on Recent Advances in NLP. pp. 424-431</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="1427" citStr="Smadja 1993" startWordPosition="189" endWordPosition="190">ency correspondence assumption. The generated triple translation model is used to extract collocation translations from two monolingual corpora. Experiments show that our approach outperforms the existing monolingual corpus based methods in dependency triple translation and achieves promising results in collocation translation extraction. 1 Introduction A collocation is an arbitrary and recurrent word combination (Benson, 1990). Previous work in collocation acquisition varies in the kinds of collocations they detect. These range from twoword to multi-word, with or without syntactic structure (Smadja 1993; Lin, 1998; Pearce, 2001; Seretan et al. 2003). In this paper, a collocation refers to a recurrent word pair linked with a certain syntactic relation. For instance, &lt;solve, verb-object, problem&gt; is a collocation with a syntactic relation verb-object. Translation of collocations is difficult for nonnative speakers. Many collocation translations are idiosyncratic in the sense that they are unpredictable by syntactic or semantic features. Consider Chinese to English translation. The translations of “解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, t</context>
<context position="4373" citStr="Smadja, 1993" startWordPosition="620" endWordPosition="621"> follows. Section 2 provides a brief description on the related work. Section 3 describes our triple translation model and training algorithm. Section 4 extracts collocation translations from two independent monolingual corpora. Section 5 evaluates the proposed method, and the last section draws conclusions and presents the future work. 2 Related work There has been much previous work done on monolingual collocation extraction. They can in general be classified into two types: window-based and syntax-based methods. The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993). The latter extracts collocations which have a syntactic relationship (Lin, 1998; Seretan et al., 2003). The syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation t</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics, 19(1):143-177</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen R Mckeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translation collocations for bilingual lexicons: a statistical approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="2378" citStr="Smadja et al., 1996" startWordPosition="322" endWordPosition="325">n translations are idiosyncratic in the sense that they are unpredictable by syntactic or semantic features. Consider Chinese to English translation. The translations of “解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations of the collocation “解决 — 问题” as “solve—problem” or “resolve— issue” is preferred over “solve—issue” or “resolve —problem”. Automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other NLP applications. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al., 2003). These works implicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily o</context>
<context position="4929" citStr="Smadja et al. (1996)" startWordPosition="695" endWordPosition="698">ions within a fixed window (Church and Hanks 1990; Smadja, 1993). The latter extracts collocations which have a syntactic relationship (Lin, 1998; Seretan et al., 2003). The syntax-based method becomes more favorable with recent significant increases in parsing efficiency and accuracy. Several metrics have been adopted to measure the association strength in collocation extraction. Thanopoulos et al. (2002) give comparative evaluations on these metrics. Most previous research in translation knowledge acquisition is based on parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since large aligned bilingual corpora are hard to obtain, some</context>
</contexts>
<marker>Smadja, Mckeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Smadja, Kathleen R. Mckeown, Vasileios Hatzivassiloglou. 1996. Translation collocations for bilingual lexicons: a statistical approach. Computational Linguistics, 22:1-38</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aristomenis Thanopoulos</author>
</authors>
<title>Nikos Fakotakis, George Kokkinakis.</title>
<date>2002</date>
<booktitle>The 3rd International Conference on Language Resource and Evaluation.</booktitle>
<pages>620--625</pages>
<marker>Thanopoulos, 2002</marker>
<rawString>Aristomenis Thanopoulos, Nikos Fakotakis, George Kokkinakis. 2002. Comparative evaluation of collocation extraction metrics. The 3rd International Conference on Language Resource and Evaluation. pp.620-625</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Ming Zhou</author>
</authors>
<title>Synonymous collocation extraction using translation Information.</title>
<date>2003</date>
<booktitle>The 41th annual conference of the Association for Computational Linguistics.</booktitle>
<pages>120--127</pages>
<contexts>
<context position="2416" citStr="Wu and Zhou, 2003" startWordPosition="330" endWordPosition="333"> sense that they are unpredictable by syntactic or semantic features. Consider Chinese to English translation. The translations of “解决” can be “solve” or “resolve”. The translations of “问题” can be “problem” or “issue”. However, translations of the collocation “解决 — 问题” as “solve—problem” or “resolve— issue” is preferred over “solve—issue” or “resolve —problem”. Automatically acquiring these collocation translations will be very useful for machine translation, cross language information retrieval, second language learning and many other NLP applications. (Smadja et al., 1996; Gao et al., 2002; Wu and Zhou, 2003). Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al., 2003). These works implicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in a large volume. Our method </context>
<context position="6587" citStr="Wu and Zhou, 2003" startWordPosition="933" endWordPosition="936">o simulate translation probability with a cross language similarity score, which is estimated from monolingual corpora based on mutual information. The method achieves good results in word translation selection. In addition, (Dagan and Itai, 1994) and (Li, 2002) propose using two monolingual corpora for word sense disambiguation. (Fung, 1998) uses an IR approach to induce new word translations from comparable corpora. (Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus. (Cao and Li, 2002) acquire noun phrase translations by making use of web data. (Wu and Zhou, 2003) also make full use of large scale monolingual corpora and limited bilingual corpora for synonymous collocation extraction. 3 Training a triple translation model from monolingual corpora In this section, we first describe the dependency correspondence assumption underlying our approach. Then a dependency triple translation model and the monolingual corpus based training algorithm are proposed. The obtained triple translation model will be used for collocation translation extraction in next section. 3.1 Dependency correspondence between Chinese and English A dependency triple consists of a head</context>
</contexts>
<marker>Wu, Zhou, 2003</marker>
<rawString>Hua Wu, Ming Zhou. 2003. Synonymous collocation extraction using translation Information. The 41th annual conference of the Association for Computational Linguistics. pp. 120-127</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Acquisition of phrase-level bilingual correspondence using dependency structure.</title>
<date>2000</date>
<booktitle>The 18th International Conference on Computational Linguistics.</booktitle>
<pages>933--939</pages>
<contexts>
<context position="5465" citStr="Yamamoto and Matsumoto 2000" startWordPosition="769" endWordPosition="772"> parallel corpora (Brown et al., 1993). As for collocation translation, Smadja et al. (1996) implement a system to extract collocation translations from a parallel EnglishFrench corpus. English collocations are first extracted using the Xtract system, then corresponding French translations are sought based on the Dice coefficient. Echizen-ya et al. (2003) propose a method to extract bilingual collocations using recursive chain-link-type learning. In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus (Kupiec, 1993; Yamamoto and Matsumoto 2000). Since large aligned bilingual corpora are hard to obtain, some research has been conducted to exploit translation knowledge from non-parallel corpora. Their work is mainly on word level. Koehn and Knight (2000) presents an approach to estimating word translation probabilities using unrelated monolingual corpora with the EM algorithm. The method exhibits promising results in selecting the right translation among several options provided by bilingual dictionary. Zhou et al.(2001) proposes a method to simulate translation probability with a cross language similarity score, which is estimated fr</context>
</contexts>
<marker>Yamamoto, Matsumoto, 2000</marker>
<rawString>Kaoru Yamamoto, Yuji Matsumoto. 2000. Acquisition of phrase-level bilingual correspondence using dependency structure. The 18th International Conference on Computational Linguistics. pp. 933-939</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Zhou</author>
<author>Ding Yuan</author>
<author>Changning Huang</author>
</authors>
<title>Improving translation selection with a new translation model trained by independent monolingual corpora.</title>
<date>2001</date>
<journal>Computaional Linguistics &amp; Chinese Language Processing.</journal>
<volume>6</volume>
<issue>1</issue>
<pages>1--26</pages>
<contexts>
<context position="3201" citStr="Zhou et al., 2001" startWordPosition="450" endWordPosition="453">plicitly assume that a bilingual corpus on a large scale can be obtained easily. However, despite efforts in compiling parallel corpora, sufficient amounts of such corpora are still unavailable. Instead of heavily relying on bilingual corpora, this paper aims to solve the bottleneck in a different way: to mine bilingual knowledge from structured monolingual corpora, which can be more easily obtained in a large volume. Our method is based on the observation that despite the great differences between Chinese and English, the main dependency relations tend to have a strong direct correspondence (Zhou et al., 2001). Based on this assumption, a new translation model based on dependency triples is proposed. The translation probabilities are estimated from two monolingual corpora using the EM algorithm with the help of a bilingual translation dictionary. Experimental results show that the proposed triple translation model outperforms the other three models in comparison. The obtained triple translation model is also used for collocation translation extraction. Evaluation results demonstrate the effectiveness of our method. The remainder of this paper is organized as follows. Section 2 provides a brief desc</context>
<context position="8236" citStr="Zhou et al., 2001" startWordPosition="1179" endWordPosition="1182">nly consider the following three key types that we think, are the most important in text analysis and machine translation: verb-object (VO), nounadj(AN), and verb- adv(AV). It is our observation that there is a strong correspondence in major dependency relations in the translation between English and Chinese. For example, an object-verb relation in Chinese (e.g.(AER, VO, 困难)) is usually translated into the same verb-object relation in English(e.g. (overcome, VO, difficulty)). This assumption has been experimentally justified based on a large and balanced bilingual corpus in our previous work (Zhou et al., 2001). We come to the conclusion that more than 80% of the above dependency relations have a one-one mapping between Chinese and English. We can conclude that there is indeed a very strong correspondence between Chinese and English in the three considered dependency relations. This fact will be used to estimate triple translation model using two monolingual corpora. 3.2 Triple translation model According to Bayes’s theorem, given a Chinese triple ctri _ (c1 , rc , c2 ) , and the set of its candidate English triple translations etri _ (e1 , re , e2) , the best English triple eˆtri _ (eˆ1 , re , eˆ2 </context>
<context position="21170" citStr="Zhou et al., 2001" startWordPosition="3358" endWordPosition="3361">s on the same standard test set with the same translation dictionary. As the 2 These two dictionaries are built by Harbin Institute of Technology and Microsoft Research respectively. baseline experiment, Model A selects the highestfrequency translation for each word in triple; Model B selects translation with the maximal target triple probability, as proposed in (Dagan 1994); Model C selects translation using both language model and translation model, but the translation probability is simulated by a similarity score which is estimated from monolingual corpus using mutual information measure (Zhou et al., 2001). And our triple translation model is model D. Suppose ctri = (c1 , rc , c2) is the Chinese triple to be translated. The four compared models can be formally expressed as follows: Model A: emax = (arg max ( freq (e1)), re, arg max ( freq (e2 )) e Trans c ∈ ( ) e Trans c ( ) 1 1 2∈ 2 Model B: arg max ( ) arg max ( , , p e = p e r e tri 1 e 2 Model C: )×likelyhood(ctri |etri)) etri ( ( ) Sim( , ) Sim( , )) p e × e c × e c tri 1 1 2 where, Sim(e, c) is similarity score between e and c (Zhou et al., 2001). Model D (our model): emax =argmax(p(etri)p(ctri |etri etri e2 ∈ Trans( c2 ) Cove- Accuracy(%</context>
</contexts>
<marker>Zhou, Yuan, Huang, 2001</marker>
<rawString>Ming Zhou, Ding Yuan and Changning Huang. 2001. Improving translation selection with a new translation model trained by independent monolingual corpora. Computaional Linguistics &amp; Chinese Language Processing. 6(1): 1-26</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>