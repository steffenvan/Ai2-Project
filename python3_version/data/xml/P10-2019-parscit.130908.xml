<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.071175">
<title confidence="0.996415">
Semantics-Driven Shallow Parsing for Chinese Semantic Role Labeling
</title>
<author confidence="0.998684">
Weiwei Sun
</author>
<affiliation confidence="0.865103">
Department of Computational Linguistics, Saarland University
German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.666324">
D-66123, Saarbr¨ucken, Germany
</address>
<email confidence="0.996744">
wsun@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.993861" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999876928571429">
One deficiency of current shallow pars-
ing based Semantic Role Labeling (SRL)
methods is that syntactic chunks are too
small to effectively group words. To par-
tially resolve this problem, we propose
semantics-driven shallow parsing, which
takes into account both syntactic struc-
tures and predicate-argument structures.
We also introduce several new “path” fea-
tures to improve shallow parsing based
SRL method. Experiments indicate that
our new method obtains a significant im-
provement over the best reported Chinese
SRL result.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999802810810811">
In the last few years, there has been an increas-
ing interest in Semantic Role Labeling (SRL) on
several languages, which consists of recognizing
arguments involved by predicates of a given sen-
tence and labeling their semantic types. Both
full parsing based and shallow parsing based SRL
methods have been discussed for English and Chi-
nese. In Chinese SRL, shallow parsing based
methods that cast SRL as the classification of
syntactic chunks into semantic labels has gained
promising results. The performance reported in
(Sun et al., 2009) outperforms the best published
performance of full parsing based SRL systems.
Previously proposed shallow parsing takes into
account only syntactic information and basic
chunks are usually too small to group words into
argument candidates. This causes one main defi-
ciency of Chinese SRL. To partially resolve this
problem, we propose a new shallow parsing. The
new chunk definition takes into account both syn-
tactic structure and predicate-argument structures
of a given sentence. Because of the semantic in-
formation it contains, we call it semantics-driven
shallow parsing. The key idea is to make basic
chunks as large as possible but not overlap with ar-
guments. Additionally, we introduce several new
“path” features to express more structural infor-
mation, which is important for SRL.
We present encouraging SRL results on Chinese
PropBank (CPB) data. With semantics-driven
shallow parsing, our SRL system achieves 76.10
F-measure, with gold segmentation and POS tag-
ging. The performance further achieves 76.46
with the help of new “path” features. These re-
sults obtain significant improvements over the best
reported SRL performance (74.12) in the literature
(Sun et al., 2009).
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999503">
CPB is a project to add predicate-argument rela-
tions to the syntactic trees of the Chinese Tree-
Bank (CTB). Similar to English PropBank, the ar-
guments of a predicate are labeled with a contigu-
ous sequence of integers, in the form of AN (N is
a natural number); the adjuncts are annotated as
such with the label AM followed by a secondary
tag that represents the semantic classification of
the adjunct. The assignment of argument labels
is illustrated in Figure 1, where the predicate is the
verb “提供/provide” For example, the noun phrase
“保险公司/the insurance company” is labeled as
A0, meaning that it is the proto-Agent of “提供”.
Sun et al. (2009) explore the Chinese SRL prob-
lem on the basis of shallow syntactic information
at the level of phrase chunks. They present a se-
mantic chunking method to resolve SRL on basis
of shallow parsing. Their method casts SRL as
the classification of syntactic chunks with IOB2
representation for semantic roles (i.e. semantic
</bodyText>
<page confidence="0.991109">
103
</page>
<note confidence="0.761215">
Proceedings of the ACL 2010 Conference Short Papers, pages 103–108,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.943370666666667">
WORD: 保险 公司 已 为 E0 工程 提供 保险 服务
insurance company already for Sanxia Project provide insurance service
POS: [NN NN] [AD] [P] [NR] [NN] [VV] [NN NN]
SYN CH: [NP] [ADVP] [PP NP NP ] [VP] [NP]
SEM CH: B-A0 B-AM-ADV B-A2 I-A2 I-A2 B-V B-A1
The insurance company has provided insurance services for the Sanxia Project.
</table>
<figureCaption confidence="0.993159">
Figure 1: An example from Chinese PropBank.
</figureCaption>
<bodyText confidence="0.999248178571429">
chunks). Two labeling strategies are presented: 1)
directly tagging semantic chunks in one-stage, and
2) identifying argument boundaries as a chunking
task and labeling their semantic types as a clas-
sification task. On the basis of syntactic chunks,
they define semantic chunks which do not overlap
nor embed using IOB2 representation. Syntactic
chunks outside a chunk receive the tag O (Out-
side). For syntactic chunks forming a chunk of
type A*, the first chunk receives the B-A* tag (Be-
gin), and the remaining ones receive the tag I-A*
(Inside). Then a SRL system can work directly
by using sequence tagging technique. Shallow
chunk definition presented in (Chen et al., 2006)
is used in their experiments. The definition of syn-
tactic and semantic chunks is illustrated Figure 1.
For example, “保险公司/the insurance company”,
consisting of two nouns, is a noun phrase; in the
syntactic chunking stage, its two components “保
险” and “公司” should be labeled as B-NP and
I-NP. Because this phrase is the Agent of the pred-
icate “提供/provide”, it takes a semantic chunk
label B-A0. In the semantic chunking stage, this
phrase should be labeled as B-A0.
Their experiments on CPB indicate that accord-
ing to current state-of-the-art of Chinese parsing,
SRL systems on basis of full parsing do not per-
form better than systems based on shallow parsing.
They report the best SRL performance with gold
segmentation and POS tagging as inputs. This is
very different from English SRL. In English SRL,
previous work shows that full parsing, both con-
stituency parsing and dependency parsing, is nec-
essary.
Ding and Chang (2009) discuss semantic
chunking methods without any parsing informa-
tion. Different from (Sun et al., 2009), their
method formulates SRL as the classification of
words with semantic chunks. Comparison of ex-
perimental results in their work shows that parsing
is necessary for Chinese SRL, and the semantic
chunking methods on the basis of shallow parsing
outperform the ones without any parsing.
Joint learning of syntactic and semantic struc-
tures is another hot topic in dependency parsing
research. Some models have been well evalu-
ated in CoNLL 2008 and 2009 shared tasks (Sur-
deanu et al., 2008; Hajiˇc et al., 2009). The
CoNLL 2008/2009 shared tasks propose a unified
dependency-based formalism to model both syn-
tactic dependencies and semantic roles for multi-
ple languages. Several joint parsing models are
presented in the shared tasks. Our focus is differ-
ent from the shared tasks. In this paper, we hope
to find better syntactic representation for semantic
role labeling.
</bodyText>
<sectionHeader confidence="0.916064" genericHeader="method">
3 Semantics-Driven Shallow Parsing
</sectionHeader>
<subsectionHeader confidence="0.996886">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999992380952381">
There are two main jobs of semantic chunking: 1)
grouping words as argument candidate and 2) clas-
sifying semantic types of possible arguments. Pre-
viously proposed shallow parsing only considers
syntactic information and basic chunks are usu-
ally too small to effectively group words. This
causes one main deficiency of semantic chunking.
E.g. the argument “为E0工程/for the Sanxia
Project” consists of three chunks, each of which
only consists of one word. To rightly recognize
this A2, Semantic chunker should rightly predict
three chunk labels. Small chunks also make the
important “path” feature sparse, since there are
more chunks between a target chunk and the pred-
icate in focus. In this section, we introduce a new
chunk definition to improve shallow parsing based
SRL, which takes both syntactic and predicate-
argument structures into account. The key idea
is to make syntactic chunks as large as possible
for semantic chunking. The formal definition is as
follows.
</bodyText>
<subsectionHeader confidence="0.999774">
3.2 Chunk Bracketing
</subsectionHeader>
<bodyText confidence="0.9952085">
Given a sentence s = wi, ..., w, let c[i : j]
denote a constituent that is made up of words
between wz and wj (including wz and wj); let
pv = {c[i : j]�c[i : j] is an argument of v}
</bodyText>
<page confidence="0.993752">
104
</page>
<table confidence="0.997081928571429">
WORD POS TARGET PROPOSITION CHUNK 1 CHUNK 2
China 中国 NR - (A0* * * * B-NP B-NP&amp;quot;S
tax &amp;* NN - * * * * I-NP I-NP&amp;quot;S
department 部门 NN - *) * * * I-NP I-NP&amp;quot;S
stipulate 规定 VV 规定 (V*) * * * O O
: : PU - * * * * O O
owing 欠( VV 欠( (A1* (V*) * (A0* O O
tax payment &amp;款 NN - * (A1*) * * B-NP B-NP&amp;quot;VP
company 企业 NN - * (A0*) * * B-NP B-NP&amp;quot;NP
Function Word 的 DEG - * * * * O O
leaders 领导人 NN - * * * *) B-NP B-NP&amp;quot;NP
not 不 AD - * * * (AM-ADV*) B-ADVP B-ADVP&amp;quot;VP
can 得 VV 得 * * (V*) * O O
leave the country Hi境 VV Hi境 *) * * (V*) B-VP B-VP&amp;quot;VP
</table>
<figureCaption confidence="0.985254">
Figure 2: An example for definition of semantics-driven chunks with IOB2 representation.
</figureCaption>
<bodyText confidence="0.701004833333333">
denote one predicate-argument structure where v
is the predicate in focus. Given a syntactic tree
T = {c[i : j]|c[i : j] is a constituent of s}, and
its all argument structures Ps = {pv |v is a verbal
predicate in s}, there is one and only one chunk
set C = {c[i : j]} s.t.
</bodyText>
<listItem confidence="0.9982435">
1. Vc[i : j] EC,c[i: j] E T;
2. Vc[i : j] E C, Vc[iv : jv] E UPs, j &lt; iv or
i &gt; jv or iv &lt; i &lt; j &lt; jv;
3. Vc[i : j] E C, the parent of c[i : j] does not
satisfy the condition 2.
4. VC&apos; satisfies above conditions, C&apos; C C.
</listItem>
<bodyText confidence="0.999776875">
The first condition guarantees that every chunk
is a constituent. The second condition means that
chunks do not overlap with arguments, and further
guarantees that semantic chunking can recover all
arguments with the last condition. The third condi-
tion makes new chunks as big as possible. The last
one makes sure that C contains all sub-components
of all arguments. Figure 2 is an example to illus-
trate our new chunk definition. For example, “中
国/Chinese &amp;*/tax 部分/department” is a con-
stituent of current sentence, and is also an argu-
ment of “规定/stipulate”. If we take it as a chunk,
it does not conflict with any other arguments, so
it is a reasonable syntactic chunk. For the phrase
“欠(/owing &amp;款/tax payment”, though it does
not overlap with the first, third and fourth proposi-
tions, it is bigger than the argument “&amp;款” (con-
flicting with condition 2) while labeling the pred-
icate “欠(”, so it has to be separated into two
chunks. Note that the third condition also guar-
antees the constituents in C does not overlap with
each other since each one is as large as possible.
So we can still formulate our new shallow parsing
as an “IOB” sequence labeling problem.
</bodyText>
<subsectionHeader confidence="0.997823">
3.3 Chunk Type
</subsectionHeader>
<bodyText confidence="0.999640470588235">
We introduce two types of chunks. The first is
simply the phrase type, such as NP, PP, of cur-
rent chunk. The column CHUNK 1 illustrates
this kind of chunk type definition. The second is
more complicated. Inspired by (Klein and Man-
ning, 2003), we split one phrase type into several
subsymbols, which contain category information
of current constituent’s parent. For example, an
NP immediately dominated by a S, will be sub-
stituted by NPˆS. This strategy severely increases
the number of chunk types and make it hard to
train chunking models. To shrink this number, we
linguistically use a cluster of CTB phrasal types,
which was introduced in (Sun and Sui, 2009). The
column CHUNK 2 illustrates this definition. E.g.,
NPˆS implicitly represents Subject while NPˆVP
represents Object.
</bodyText>
<subsectionHeader confidence="0.985363">
3.4 New Path Features
</subsectionHeader>
<bodyText confidence="0.998645818181818">
The Path feature is defined as a chain of base
phrases between the token and the predicate. At
both ends, the chain is terminated with the POS
tags of the predicate and the headword of the to-
ken. For example, the path feature of “保险公
司” in Figure 1 is “公司-ADVP-PP-NP-NP-VV”.
Among all features, the “path” feature contains
more structural information, which is very impor-
tant for SRL. To better capture structural infor-
mation, we introduce several new “path” features.
They include:
</bodyText>
<listItem confidence="0.998759">
• NP|PP|VP path: only syntactic chunks
that takes tag NP, PP or VP are kept.
</listItem>
<page confidence="0.998875">
105
</page>
<bodyText confidence="0.996955">
When labeling the predicate “出境/leave the
country” in Figure 2, this feature of “+
国 &amp; * 部 门/Chinese tax departments” is
NP+NP+NP+NP+VP.
</bodyText>
<listItem confidence="0.988079">
• V|的 path: a sequential container of POS tags
of verbal words and “的”; This feature of “+
国&amp;*部门” is NP+VV+VV+的+VV+VP.
</listItem>
<table confidence="0.9999045">
Test P(%) R(%) F,3=1
(Chen et al., 2006) 93.51 92.81 93.16
Overall (C1) 91.66 89.13 90.38
Bracketing (C1) 92.31 89.72 91.00
Overall (C2) 88.77 86.71 87.73
Bracketing (C2) 92.71 90.55 91.62
</table>
<tableCaption confidence="0.999224">
Table 1: Shallow parsing performance.
</tableCaption>
<listItem confidence="0.9195178">
• O2POS path: if a word occupies a chunk
label O, use its POS in the path fea-
ture. This feature of “+国&amp;*部门” is
NP+VV+PU+VV+NP+NP+DEG+ADVP+
VV+VP.
</listItem>
<sectionHeader confidence="0.986993" genericHeader="evaluation">
4 Experiments and Analysis
</sectionHeader>
<subsectionHeader confidence="0.942915">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.99999465625">
Experiments in previous work are mainly based
on CPB 1.0 and CTB 5.0. We use CoNLL-2005
shared task software to process CPB and CTB. To
facilitate comparison with previous work, we use
the same data setting with (Xue, 2008). Nearly
all previous research on Chinese SRL evalua-
tion use this setting, also including (Ding and
Chang, 2008, 2009; Sun et al., 2009; Sun, 2010).
The data is divided into three parts: files from
chtb 081 to chtb 899 are used as training set; files
from chtb 041 to chtb 080 as development set;
files from chtb 001 to chtb 040, and chtb 900 to
chtb 931 as test set. Both syntactic chunkers and
semantic chunkers are trained and evaluated by us-
ing the same data set. By using CPB and CTB, we
can extract gold standard semantics-driven shal-
low chunks according to our definition. We use
this kind of gold chunks automatically generated
from training data to train syntactic chunkers.
For both syntactic and semantic chunking, we
used conditional random field model. Crfsgd1, is
used for experiments. Crfsgd provides a feature
template that defines a set of strong word and POS
features to do syntactic chunking. We use this
feature template to resolve shallow parsing. For
semantic chunking, we implement a similar one-
stage shallow parsing based SRL system described
in (Sun et al., 2009). There are two differences be-
tween our system and Sun et al.’s system. First,
our system uses Start/End method to represent se-
mantic chunks (Kudo and Matsumoto, 2001). Sec-
ond, word formation features are not used.
</bodyText>
<subsectionHeader confidence="0.998885">
4.2 Syntactic Chunking Performance
</subsectionHeader>
<bodyText confidence="0.999980923076923">
Table 1 shows the performance of shallow syntac-
tic parsing. Line Chen et al., 2006 is the chunk-
ing performance evaluated on syntactic chunk def-
inition proposed in (Chen et al., 2006). The sec-
ond and third blocks present the chunking perfor-
mance with new semantics-driven shallow pars-
ing. The second block shows the overall perfor-
mance when the first kind of chunks type is used,
while the last block shows the performance when
the more complex chunk type definition is used.
For the semantic-driven parsing experiments, we
add the path from current word to the first verb be-
fore or after as two new features. Line Bracketing
evaluates the word grouping ability of these two
kinds of chunks. In other words, detailed phrase
types are not considered. Because the two new
chunk definitions use the same chunk boundaries,
the fourth and sixth lines are comparable. There
is a clear decrease between the traditional shallow
parsing (Chen et al., 2006) and ours. We think one
main reason is that syntactic chunks in our new
definition are larger than the traditional ones. An
interesting phenomenon is that though the second
kind of chunk type definition increases the com-
plexity of the parsing job, it achieves better brack-
eting performance.
</bodyText>
<subsectionHeader confidence="0.999531">
4.3 SRL Performance
</subsectionHeader>
<bodyText confidence="0.999916181818182">
Table 2 summarizes the SRL performance. Line
Sun et al., 2009 is the SRL performance reported
in (Sun et al., 2009). To the author’s knowledge,
this is the best published SRL result in the liter-
ature. Line SRL (Chen et al., 2006) is the SRL
performance of our system. These two systems
are both evaluated by using syntactic chunking de-
fined in (Chen et al., 2006). From the first block
we can see that our semantic chunking system
reaches the state-of-the-art. The second and third
blocks in Table 2 present the performance with
</bodyText>
<footnote confidence="0.989617">
1http://leon.bottou.org/projects/sgd
</footnote>
<page confidence="0.996542">
106
</page>
<bodyText confidence="0.999165333333333">
new shallow parsing. Line SRL (C1) and SRL (C2)
show the overall performances with the first and
second chunk definition. The lines following are
the SRL performance when new “path” features
are added. We can see that new “path” features
are useful for semantic chunking.
</bodyText>
<table confidence="0.9998961">
Test P(%) R(%) Fa_1
(Sun et al., 2009) 79.25 69.61 74.12
SRL [(Chen et al., 2006)] 80.87 68.74 74.31
SRL [C1] 80.23 71.00 75.33
+ NPIPPIVP path 80.25 71.19 75.45
+ V|的 path 80.78 71.67 75.96
+ O2POS path 80.44 71.59 75.76
+ All new path 80.73 72.08 76.16
SRL [C2] 80.87 71.86 76.10
+ All new path 81.03 72.38 76.46
</table>
<tableCaption confidence="0.995558">
Table 2: SRL performance on the test data. Items
</tableCaption>
<bodyText confidence="0.97508425">
in the first column SRL [(Chen et al., 2006)], SRL
[C1] and SRL [C2] respetively denote the SRL
systems based on shallow parsing defined in (Chen
et al., 2006) and Section 3.
</bodyText>
<sectionHeader confidence="0.998819" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999365416666667">
In this paper we propose a new syntactic shal-
low parsing for Chinese SRL. The new chunk
definition contains both syntactic structure and
predicate-argument structure information. To im-
prove SRL, we also introduce several new “path”
features. Experimental results show that our new
chunk definition is more suitable for Chinese SRL.
It is still an open question what kinds of syntactic
information is most important for Chinese SRL.
We suggest that our attempt at semantics-driven
shallow parsing is a possible way to better exploit
this problem.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997714">
The author is funded both by German Academic
Exchange Service (DAAD) and German Research
Center for Artificial Intelligence (DFKI).
The author would like to thank the anonymous
reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998937" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998032283018868">
Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.
2006. An empirical study of Chinese chunking.
In Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions, pages 97–104. As-
sociation for Computational Linguistics, Syd-
ney, Australia.
Weiwei Ding and Baobao Chang. 2008. Improv-
ing Chinese semantic role classification with hi-
erarchical feature selection strategy. In Pro-
ceedings of the EMNLP 2008, pages 324–
333. Association for Computational Linguis-
tics, Honolulu, Hawaii.
Weiwei Ding and Baobao Chang. 2009. Fast se-
mantic role labeling for Chinese based on se-
mantic chunking. In ICCPOL ’09: Proceed-
ings of the 22nd International Conference on
Computer Processing of Oriental Languages.
Language Technology for the Knowledge-
based Economy, pages 79–90. Springer-Verlag,
Berlin, Heidelberg.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Jo-
hansson, Daisuke Kawahara, Maria Ant`onia
Mart´ı, Lluis M`arquez, Adam Meyers, Joakim
Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel
Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and
Yi Zhang. 2009. The CoNLL-2009 shared task:
Syntactic and semantic dependencies in multi-
ple languages. In Proceedings of the 13th Con-
ference on Computational Natural Language
Learning (CoNLL-2009), June 4-5. Boulder,
Colorado, USA.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of
the 41st Annual Meeting of the Association for
Computational Linguistics, pages 423–430. As-
sociation for Computational Linguistics, Sap-
poro, Japan.
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In NAACL ’01:
Second meeting of the North American Chapter
of the Association for Computational Linguis-
tics on Language technologies 2001, pages 1–
8. Association for Computational Linguistics,
Morristown, NJ, USA.
Weiwei Sun. 2010. Improving Chinese semantic
role labeling with rich features. In Proceedings
of the ACL 2010.
Weiwei Sun and Zhifang Sui. 2009. Chinese func-
tion tag labeling. In Proceedings of the 23rd
Pacific Asia Conference on Language, Informa-
tion and Computation. Hong Kong.
Weiwei Sun, Zhifang Sui, Meng Wang, and Xin
Wang. 2009. Chinese semantic role labeling
</reference>
<page confidence="0.983237">
107
</page>
<reference confidence="0.999578125">
with shallow parsing. In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1475–1483.
Association for Computational Linguistics, Sin-
gapore.
Mihai Surdeanu, Richard Johansson, Adam Mey-
ers, Lluis M`arquez, and Joakim Nivre. 2008.
The conll 2008 shared task on joint parsing of
syntactic and semantic dependencies. In CoNLL
2008: Proceedings of the Twelfth Conference
on Computational Natural Language Learning,
pages 159–177. Coling 2008 Organizing Com-
mittee, Manchester, England.
Nianwen Xue. 2008. Labeling Chinese predi-
cates with semantic roles. Comput. Linguist.,
34(2):225–255.
</reference>
<page confidence="0.998366">
108
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.817140">
<title confidence="0.999302">Semantics-Driven Shallow Parsing for Chinese Semantic Role Labeling</title>
<author confidence="0.999737">Weiwei Sun</author>
<affiliation confidence="0.984113">Department of Computational Linguistics, Saarland University German Research Center for Artificial Intelligence (DFKI)</affiliation>
<address confidence="0.997297">D-66123, Saarbr¨ucken, Germany</address>
<email confidence="0.999494">wsun@coli.uni-saarland.de</email>
<abstract confidence="0.988273666666667">One deficiency of current shallow parsing based Semantic Role Labeling (SRL) methods is that syntactic chunks are too small to effectively group words. To partially resolve this problem, we propose semantics-driven shallow parsing, which takes into account both syntactic structures and predicate-argument structures. We also introduce several new “path” features to improve shallow parsing based SRL method. Experiments indicate that our new method obtains a significant improvement over the best reported Chinese SRL result.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Yujie Zhang</author>
<author>Hitoshi Isahara</author>
</authors>
<title>An empirical study of Chinese chunking.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>97--104</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="4697" citStr="Chen et al., 2006" startWordPosition="737" endWordPosition="740">tagging semantic chunks in one-stage, and 2) identifying argument boundaries as a chunking task and labeling their semantic types as a classification task. On the basis of syntactic chunks, they define semantic chunks which do not overlap nor embed using IOB2 representation. Syntactic chunks outside a chunk receive the tag O (Outside). For syntactic chunks forming a chunk of type A*, the first chunk receives the B-A* tag (Begin), and the remaining ones receive the tag I-A* (Inside). Then a SRL system can work directly by using sequence tagging technique. Shallow chunk definition presented in (Chen et al., 2006) is used in their experiments. The definition of syntactic and semantic chunks is illustrated Figure 1. For example, “保险公司/the insurance company”, consisting of two nouns, is a noun phrase; in the syntactic chunking stage, its two components “保 险” and “公司” should be labeled as B-NP and I-NP. Because this phrase is the Agent of the predicate “提供/provide”, it takes a semantic chunk label B-A0. In the semantic chunking stage, this phrase should be labeled as B-A0. Their experiments on CPB indicate that according to current state-of-the-art of Chinese parsing, SRL systems on basis of full parsing </context>
<context position="11777" citStr="Chen et al., 2006" startWordPosition="2010" endWordPosition="2013">gure 1 is “公司-ADVP-PP-NP-NP-VV”. Among all features, the “path” feature contains more structural information, which is very important for SRL. To better capture structural information, we introduce several new “path” features. They include: • NP|PP|VP path: only syntactic chunks that takes tag NP, PP or VP are kept. 105 When labeling the predicate “出境/leave the country” in Figure 2, this feature of “+ 国 &amp; * 部 门/Chinese tax departments” is NP+NP+NP+NP+VP. • V|的 path: a sequential container of POS tags of verbal words and “的”; This feature of “+ 国&amp;*部门” is NP+VV+VV+的+VV+VP. Test P(%) R(%) F,3=1 (Chen et al., 2006) 93.51 92.81 93.16 Overall (C1) 91.66 89.13 90.38 Bracketing (C1) 92.31 89.72 91.00 Overall (C2) 88.77 86.71 87.73 Bracketing (C2) 92.71 90.55 91.62 Table 1: Shallow parsing performance. • O2POS path: if a word occupies a chunk label O, use its POS in the path feature. This feature of “+国&amp;*部门” is NP+VV+PU+VV+NP+NP+DEG+ADVP+ VV+VP. 4 Experiments and Analysis 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xu</context>
<context position="13805" citStr="Chen et al., 2006" startWordPosition="2351" endWordPosition="2354">sgd provides a feature template that defines a set of strong word and POS features to do syntactic chunking. We use this feature template to resolve shallow parsing. For semantic chunking, we implement a similar onestage shallow parsing based SRL system described in (Sun et al., 2009). There are two differences between our system and Sun et al.’s system. First, our system uses Start/End method to represent semantic chunks (Kudo and Matsumoto, 2001). Second, word formation features are not used. 4.2 Syntactic Chunking Performance Table 1 shows the performance of shallow syntactic parsing. Line Chen et al., 2006 is the chunking performance evaluated on syntactic chunk definition proposed in (Chen et al., 2006). The second and third blocks present the chunking performance with new semantics-driven shallow parsing. The second block shows the overall performance when the first kind of chunks type is used, while the last block shows the performance when the more complex chunk type definition is used. For the semantic-driven parsing experiments, we add the path from current word to the first verb before or after as two new features. Line Bracketing evaluates the word grouping ability of these two kinds of</context>
<context position="15209" citStr="Chen et al., 2006" startWordPosition="2589" endWordPosition="2592">s a clear decrease between the traditional shallow parsing (Chen et al., 2006) and ours. We think one main reason is that syntactic chunks in our new definition are larger than the traditional ones. An interesting phenomenon is that though the second kind of chunk type definition increases the complexity of the parsing job, it achieves better bracketing performance. 4.3 SRL Performance Table 2 summarizes the SRL performance. Line Sun et al., 2009 is the SRL performance reported in (Sun et al., 2009). To the author’s knowledge, this is the best published SRL result in the literature. Line SRL (Chen et al., 2006) is the SRL performance of our system. These two systems are both evaluated by using syntactic chunking defined in (Chen et al., 2006). From the first block we can see that our semantic chunking system reaches the state-of-the-art. The second and third blocks in Table 2 present the performance with 1http://leon.bottou.org/projects/sgd 106 new shallow parsing. Line SRL (C1) and SRL (C2) show the overall performances with the first and second chunk definition. The lines following are the SRL performance when new “path” features are added. We can see that new “path” features are useful for semant</context>
</contexts>
<marker>Chen, Zhang, Isahara, 2006</marker>
<rawString>Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. 2006. An empirical study of Chinese chunking. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 97–104. Association for Computational Linguistics, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
<author>Baobao Chang</author>
</authors>
<title>Improving Chinese semantic role classification with hierarchical feature selection strategy.</title>
<date>2008</date>
<booktitle>In Proceedings of the EMNLP</booktitle>
<pages>324--333</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="12496" citStr="Ding and Chang, 2008" startWordPosition="2128" endWordPosition="2131">.77 86.71 87.73 Bracketing (C2) 92.71 90.55 91.62 Table 1: Shallow parsing performance. • O2POS path: if a word occupies a chunk label O, use its POS in the path feature. This feature of “+国&amp;*部门” is NP+VV+PU+VV+NP+NP+DEG+ADVP+ VV+VP. 4 Experiments and Analysis 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xue, 2008). Nearly all previous research on Chinese SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. Both syntactic chunkers and semantic chunkers are trained and evaluated by using the same data set. By using CPB and CTB, we can extract gold standard semantics-driven shallow chunks according to our definition. We use this kind of gold chunks automatically generated from training data to train syntactic chunkers. For both syntactic and sema</context>
</contexts>
<marker>Ding, Chang, 2008</marker>
<rawString>Weiwei Ding and Baobao Chang. 2008. Improving Chinese semantic role classification with hierarchical feature selection strategy. In Proceedings of the EMNLP 2008, pages 324– 333. Association for Computational Linguistics, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
<author>Baobao Chang</author>
</authors>
<title>Fast semantic role labeling for Chinese based on semantic chunking.</title>
<date>2009</date>
<booktitle>In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledgebased Economy,</booktitle>
<pages>79--90</pages>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="5626" citStr="Ding and Chang (2009)" startWordPosition="892" endWordPosition="895">rase is the Agent of the predicate “提供/provide”, it takes a semantic chunk label B-A0. In the semantic chunking stage, this phrase should be labeled as B-A0. Their experiments on CPB indicate that according to current state-of-the-art of Chinese parsing, SRL systems on basis of full parsing do not perform better than systems based on shallow parsing. They report the best SRL performance with gold segmentation and POS tagging as inputs. This is very different from English SRL. In English SRL, previous work shows that full parsing, both constituency parsing and dependency parsing, is necessary. Ding and Chang (2009) discuss semantic chunking methods without any parsing information. Different from (Sun et al., 2009), their method formulates SRL as the classification of words with semantic chunks. Comparison of experimental results in their work shows that parsing is necessary for Chinese SRL, and the semantic chunking methods on the basis of shallow parsing outperform the ones without any parsing. Joint learning of syntactic and semantic structures is another hot topic in dependency parsing research. Some models have been well evaluated in CoNLL 2008 and 2009 shared tasks (Surdeanu et al., 2008; Hajiˇc et</context>
</contexts>
<marker>Ding, Chang, 2009</marker>
<rawString>Weiwei Ding and Baobao Chang. 2009. Fast semantic role labeling for Chinese based on semantic chunking. In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledgebased Economy, pages 79–90. Springer-Verlag, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Lluis M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009),</booktitle>
<pages>4--5</pages>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Lluis M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009), June 4-5. Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="10353" citStr="Klein and Manning, 2003" startWordPosition="1770" endWordPosition="1774">igger than the argument “&amp;款” (conflicting with condition 2) while labeling the predicate “欠(”, so it has to be separated into two chunks. Note that the third condition also guarantees the constituents in C does not overlap with each other since each one is as large as possible. So we can still formulate our new shallow parsing as an “IOB” sequence labeling problem. 3.3 Chunk Type We introduce two types of chunks. The first is simply the phrase type, such as NP, PP, of current chunk. The column CHUNK 1 illustrates this kind of chunk type definition. The second is more complicated. Inspired by (Klein and Manning, 2003), we split one phrase type into several subsymbols, which contain category information of current constituent’s parent. For example, an NP immediately dominated by a S, will be substituted by NPˆS. This strategy severely increases the number of chunk types and make it hard to train chunking models. To shrink this number, we linguistically use a cluster of CTB phrasal types, which was introduced in (Sun and Sui, 2009). The column CHUNK 2 illustrates this definition. E.g., NPˆS implicitly represents Subject while NPˆVP represents Object. 3.4 New Path Features The Path feature is defined as a cha</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423–430. Association for Computational Linguistics, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001,</booktitle>
<pages>pages</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="13640" citStr="Kudo and Matsumoto, 2001" startWordPosition="2324" endWordPosition="2327">rated from training data to train syntactic chunkers. For both syntactic and semantic chunking, we used conditional random field model. Crfsgd1, is used for experiments. Crfsgd provides a feature template that defines a set of strong word and POS features to do syntactic chunking. We use this feature template to resolve shallow parsing. For semantic chunking, we implement a similar onestage shallow parsing based SRL system described in (Sun et al., 2009). There are two differences between our system and Sun et al.’s system. First, our system uses Start/End method to represent semantic chunks (Kudo and Matsumoto, 2001). Second, word formation features are not used. 4.2 Syntactic Chunking Performance Table 1 shows the performance of shallow syntactic parsing. Line Chen et al., 2006 is the chunking performance evaluated on syntactic chunk definition proposed in (Chen et al., 2006). The second and third blocks present the chunking performance with new semantics-driven shallow parsing. The second block shows the overall performance when the first kind of chunks type is used, while the last block shows the performance when the more complex chunk type definition is used. For the semantic-driven parsing experiment</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001, pages 1– 8. Association for Computational Linguistics, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>Improving Chinese semantic role labeling with rich features.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL</booktitle>
<contexts>
<context position="12532" citStr="Sun, 2010" startWordPosition="2137" endWordPosition="2138">.62 Table 1: Shallow parsing performance. • O2POS path: if a word occupies a chunk label O, use its POS in the path feature. This feature of “+国&amp;*部门” is NP+VV+PU+VV+NP+NP+DEG+ADVP+ VV+VP. 4 Experiments and Analysis 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xue, 2008). Nearly all previous research on Chinese SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. Both syntactic chunkers and semantic chunkers are trained and evaluated by using the same data set. By using CPB and CTB, we can extract gold standard semantics-driven shallow chunks according to our definition. We use this kind of gold chunks automatically generated from training data to train syntactic chunkers. For both syntactic and semantic chunking, we used conditional r</context>
</contexts>
<marker>Sun, 2010</marker>
<rawString>Weiwei Sun. 2010. Improving Chinese semantic role labeling with rich features. In Proceedings of the ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Zhifang Sui</author>
</authors>
<title>Chinese function tag labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation. Hong Kong.</booktitle>
<contexts>
<context position="10773" citStr="Sun and Sui, 2009" startWordPosition="1840" endWordPosition="1843"> is simply the phrase type, such as NP, PP, of current chunk. The column CHUNK 1 illustrates this kind of chunk type definition. The second is more complicated. Inspired by (Klein and Manning, 2003), we split one phrase type into several subsymbols, which contain category information of current constituent’s parent. For example, an NP immediately dominated by a S, will be substituted by NPˆS. This strategy severely increases the number of chunk types and make it hard to train chunking models. To shrink this number, we linguistically use a cluster of CTB phrasal types, which was introduced in (Sun and Sui, 2009). The column CHUNK 2 illustrates this definition. E.g., NPˆS implicitly represents Subject while NPˆVP represents Object. 3.4 New Path Features The Path feature is defined as a chain of base phrases between the token and the predicate. At both ends, the chain is terminated with the POS tags of the predicate and the headword of the token. For example, the path feature of “保险公 司” in Figure 1 is “公司-ADVP-PP-NP-NP-VV”. Among all features, the “path” feature contains more structural information, which is very important for SRL. To better capture structural information, we introduce several new “pat</context>
</contexts>
<marker>Sun, Sui, 2009</marker>
<rawString>Weiwei Sun and Zhifang Sui. 2009. Chinese function tag labeling. In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation. Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Zhifang Sui</author>
<author>Meng Wang</author>
<author>Xin Wang</author>
</authors>
<title>Chinese semantic role labeling with shallow parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1475--1483</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics, Singapore.</institution>
<contexts>
<context position="1345" citStr="Sun et al., 2009" startWordPosition="192" endWordPosition="195">ificant improvement over the best reported Chinese SRL result. 1 Introduction In the last few years, there has been an increasing interest in Semantic Role Labeling (SRL) on several languages, which consists of recognizing arguments involved by predicates of a given sentence and labeling their semantic types. Both full parsing based and shallow parsing based SRL methods have been discussed for English and Chinese. In Chinese SRL, shallow parsing based methods that cast SRL as the classification of syntactic chunks into semantic labels has gained promising results. The performance reported in (Sun et al., 2009) outperforms the best published performance of full parsing based SRL systems. Previously proposed shallow parsing takes into account only syntactic information and basic chunks are usually too small to group words into argument candidates. This causes one main deficiency of Chinese SRL. To partially resolve this problem, we propose a new shallow parsing. The new chunk definition takes into account both syntactic structure and predicate-argument structures of a given sentence. Because of the semantic information it contains, we call it semantics-driven shallow parsing. The key idea is to make </context>
<context position="3189" citStr="Sun et al. (2009)" startWordPosition="488" endWordPosition="491">icate-argument relations to the syntactic trees of the Chinese TreeBank (CTB). Similar to English PropBank, the arguments of a predicate are labeled with a contiguous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of argument labels is illustrated in Figure 1, where the predicate is the verb “提供/provide” For example, the noun phrase “保险公司/the insurance company” is labeled as A0, meaning that it is the proto-Agent of “提供”. Sun et al. (2009) explore the Chinese SRL problem on the basis of shallow syntactic information at the level of phrase chunks. They present a semantic chunking method to resolve SRL on basis of shallow parsing. Their method casts SRL as the classification of syntactic chunks with IOB2 representation for semantic roles (i.e. semantic 103 Proceedings of the ACL 2010 Conference Short Papers, pages 103–108, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics WORD: 保险 公司 已 为 E0 工程 提供 保险 服务 insurance company already for Sanxia Project provide insurance service POS: [NN NN] [AD] [P] [NR</context>
<context position="5727" citStr="Sun et al., 2009" startWordPosition="907" endWordPosition="910">unking stage, this phrase should be labeled as B-A0. Their experiments on CPB indicate that according to current state-of-the-art of Chinese parsing, SRL systems on basis of full parsing do not perform better than systems based on shallow parsing. They report the best SRL performance with gold segmentation and POS tagging as inputs. This is very different from English SRL. In English SRL, previous work shows that full parsing, both constituency parsing and dependency parsing, is necessary. Ding and Chang (2009) discuss semantic chunking methods without any parsing information. Different from (Sun et al., 2009), their method formulates SRL as the classification of words with semantic chunks. Comparison of experimental results in their work shows that parsing is necessary for Chinese SRL, and the semantic chunking methods on the basis of shallow parsing outperform the ones without any parsing. Joint learning of syntactic and semantic structures is another hot topic in dependency parsing research. Some models have been well evaluated in CoNLL 2008 and 2009 shared tasks (Surdeanu et al., 2008; Hajiˇc et al., 2009). The CoNLL 2008/2009 shared tasks propose a unified dependency-based formalism to model b</context>
<context position="12520" citStr="Sun et al., 2009" startWordPosition="2133" endWordPosition="2136">C2) 92.71 90.55 91.62 Table 1: Shallow parsing performance. • O2POS path: if a word occupies a chunk label O, use its POS in the path feature. This feature of “+国&amp;*部门” is NP+VV+PU+VV+NP+NP+DEG+ADVP+ VV+VP. 4 Experiments and Analysis 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xue, 2008). Nearly all previous research on Chinese SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. Both syntactic chunkers and semantic chunkers are trained and evaluated by using the same data set. By using CPB and CTB, we can extract gold standard semantics-driven shallow chunks according to our definition. We use this kind of gold chunks automatically generated from training data to train syntactic chunkers. For both syntactic and semantic chunking, we used c</context>
<context position="15041" citStr="Sun et al., 2009" startWordPosition="2558" endWordPosition="2561">rds, detailed phrase types are not considered. Because the two new chunk definitions use the same chunk boundaries, the fourth and sixth lines are comparable. There is a clear decrease between the traditional shallow parsing (Chen et al., 2006) and ours. We think one main reason is that syntactic chunks in our new definition are larger than the traditional ones. An interesting phenomenon is that though the second kind of chunk type definition increases the complexity of the parsing job, it achieves better bracketing performance. 4.3 SRL Performance Table 2 summarizes the SRL performance. Line Sun et al., 2009 is the SRL performance reported in (Sun et al., 2009). To the author’s knowledge, this is the best published SRL result in the literature. Line SRL (Chen et al., 2006) is the SRL performance of our system. These two systems are both evaluated by using syntactic chunking defined in (Chen et al., 2006). From the first block we can see that our semantic chunking system reaches the state-of-the-art. The second and third blocks in Table 2 present the performance with 1http://leon.bottou.org/projects/sgd 106 new shallow parsing. Line SRL (C1) and SRL (C2) show the overall performances with the firs</context>
</contexts>
<marker>Sun, Sui, Wang, Wang, 2009</marker>
<rawString>Weiwei Sun, Zhifang Sui, Meng Wang, and Xin Wang. 2009. Chinese semantic role labeling with shallow parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1475–1483. Association for Computational Linguistics, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The conll 2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>159--177</pages>
<location>Manchester, England.</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis M`arquez, and Joakim Nivre. 2008. The conll 2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 159–177. Coling 2008 Organizing Committee, Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling Chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="12385" citStr="Xue, 2008" startWordPosition="2112" endWordPosition="2113">6) 93.51 92.81 93.16 Overall (C1) 91.66 89.13 90.38 Bracketing (C1) 92.31 89.72 91.00 Overall (C2) 88.77 86.71 87.73 Bracketing (C2) 92.71 90.55 91.62 Table 1: Shallow parsing performance. • O2POS path: if a word occupies a chunk label O, use its POS in the path feature. This feature of “+国&amp;*部门” is NP+VV+PU+VV+NP+NP+DEG+ADVP+ VV+VP. 4 Experiments and Analysis 4.1 Experimental Setting Experiments in previous work are mainly based on CPB 1.0 and CTB 5.0. We use CoNLL-2005 shared task software to process CPB and CTB. To facilitate comparison with previous work, we use the same data setting with (Xue, 2008). Nearly all previous research on Chinese SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. Both syntactic chunkers and semantic chunkers are trained and evaluated by using the same data set. By using CPB and CTB, we can extract gold standard semantics-driven shallow chunks according to our definition. We use this kind of </context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling Chinese predicates with semantic roles. Comput. Linguist., 34(2):225–255.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>