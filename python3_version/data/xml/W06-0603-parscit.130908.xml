<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003901">
<title confidence="0.975309">
How and Where do People Fail with Time: Temporal Reference Mapping
Annotation by Chinese and English Bilinguals
</title>
<author confidence="0.999617">
Yang Ye§, Steven Abney†§
</author>
<affiliation confidence="0.999289">
†Department of Linguistics
§Department of Electrical Engineering and Computer Science
University of Michigan
</affiliation>
<sectionHeader confidence="0.978824" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999942275862069">
This work reports on three human tense
annotation experiments for Chinese verbs
in Chinese-to-English translation scenar-
ios. The results show that inter-annotator
agreement increases as the context of the
verb under the annotation becomes in-
creasingly specified, i.e. as the context
moves from the situation in which the tar-
get English sentence is unknown to the
situation in which the target lexicon and
target syntactic structure are fully speci-
fied. The annotation scheme with a fully
specified syntax and lexicon in the tar-
get English sentence yields a satisfactorily
high agreement rate. The annotation re-
sults were then analyzed via an ANOVA
analysis, a logistic regression model and a
log-linear model. The analyses reveal that
while both the overt and the latent linguis-
tic factors seem to significantly affect an-
notation agreement under different scenar-
ios, the latent features are the real driving
factors of tense annotation disagreement
among multiple annotators. The analy-
ses also find the verb telicity feature, as-
pect marker presence and syntactic em-
bedding structure to be strongly associated
with tense, suggesting their utility in the
automatic tense classification task.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99990993877551">
In recent years, the research community has seen
a fast-growing volume of work in temporal infor-
mation processing. Consequently, the investiga-
tion and practice of temporal information anno-
tation by human experts have emerged from the
corpus annotation research. To evaluate automatic
temporal relation classification systems, annotated
corpora must be created and validated, which mo-
tivates experiments and research in temporal infor-
mation annotation.
One important temporal relation distinction that
human beings make is the temporal reference dis-
tinction based on relative positioning between the
following three time parameters, as proposed by
(Reichenbach, 1947): speech time (S), event time
(E) and reference time (R). Temporal reference
distinction is linguistically realized as tenses. Lan-
guages have various granularities of tense repre-
sentations; some have finer-grained tenses or as-
pects than others. This poses a great challenge to
automatic cross-lingual tense mapping. The same
challenge holds for cross-lingual tense annotation,
especially for language pairs that have dramati-
cally different tense strategies. A decent solution
for cross-lingual tense mapping will benefit a va-
riety of NLP tasks such as Machine Translation,
Cross-lingual Question Answering (CLQA), and
Multi-lingual Information Summarization. While
automatic cross-lingual tense mapping has re-
cently started to receive research attention, such
as in (Olsen,et al., 2001) and (Ye, et al., 2005),
to the best of our knowledge, human performance
on tense and aspect annotation for machine trans-
lation between English and Chinese has not re-
ceived any systematic investigation to date. Cross-
linguistic NLP tasks, especially those requiring a
more accurate tense and aspect resolution, await
a more focused study of human tense and aspect
annotation performance.
Chinese and English are a language pair in
which tense and aspect are represented at differ-
ent levels of units: one being realized at the word
level and the other at the morpheme level.
This paper reports on a series of cross-linguistic
tense annotation experiments between Chinese
and English, and provides statistical inference for
different linguistic factors via a series of statisti-
cal modeling. Since tense and aspect are mor-
phologically merged in English, tense annotation
</bodyText>
<page confidence="0.990812">
13
</page>
<note confidence="0.6944435">
Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 13–20,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999830105263158">
discussed in this paper also includes elements of
aspect. We only deal with tense annotation in
Chinese-to-English scenario in the scope of this
paper.
The remaining part of the paper is organized
as follows: Section 2 summarizes the significant
related works in temporal information annotation
and points out how this study relates to yet differs
from them. Section 3 reports the details of three
tense annotation experiments under three scenar-
ios. Section 4 discusses the inter-judge agree-
ment by presenting two measures of agreement:
the Kappa Statistic and accuracy-based measure-
ment. Section 5 investigates and reports on the
significance of different linguistic factors in tense
annotation via an ANOVA analysis, a logistic re-
gression analysis and a log-linear model analysis.
Finally, section 6 concludes the paper and points
out directions for future research.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999964864406779">
There are two basic types of temporal location re-
lationships. The first one is the ternary classifica-
tion of past, present and future. The second one
is the binary classification of “BEFORE” versus
“AFTER”. These two types of temporal relation-
ships are intrinsically related but each stands as a
separate issue and is dealt with in different works.
While the “BEFORE” versus “AFTER” relation-
ship can easily be transferred across a language
pair, the ternary tense taxonomy is often very hard
to transfer from one language to another.
(Wilson, et al., 1997) describes a multilin-
gual approach to annotating temporal information,
which involves flagging a temporal expression in
the document and identifying the time value that
the expression designates. Their work reports an
inter-annotator reliability F-measure of 0.79 and
0.86 respectively for English corpora.
(Katz, et al., 2001) describes a simple and gen-
eral technique for the annotation of temporal rela-
tion information based on binary interval relation
types: precedence and inclusion. Their annotation
scheme could benefit a range of NLP applications
and is easy to carry out.
(Pustejovsky et al., 2004) reports an annotation
scheme, the TimeML metadata, for the markup of
events and their anchoring in documents. The an-
notation schema of TimeML is very fine-grained
with a wide coverage of different event types, de-
pendencies between events and times, as well as
“LINK” tags which encode the various relations
existing between the temporal elements of a doc-
ument. The challenge of human labeling of links
among eventualities was discussed at great length
in their paper. Automatic “time-stamping” was
attempted on a small sample of text in an earlier
work of (Mani, 2003). The result was not partic-
ularly promising. It showed the need for a larger
quantity of training data as well as more predictive
features, especially on the discourse level. At the
word level, the semantic representation of tenses
could be approached in various ways depending
on different applications. So far, their work has
gone the furthest towards establishing a broad and
open standard metadata mark-up language for nat-
ural language texts.
(Setzer, et al., 2004) presents a method of eval-
uating temporal order relation annotations and an
approach to facilitate the creation of a gold stan-
dard by introducing the notion of temporal clo-
sure, which can be deduced from any annotations
through using a set of inference rules.
From the above works, it can be seen that the
effort in temporal information annotation has thus
far been dominated by annotating temporal rela-
tions that hold entities such as events or times
explicitly mentioned in the text. Cross-linguistic
tense and aspect annotation has so far gone un-
studied.
</bodyText>
<sectionHeader confidence="0.967096" genericHeader="method">
3 Chinese Tense Annotation
</sectionHeader>
<subsectionHeader confidence="0.505826">
Experiments1
</subsectionHeader>
<bodyText confidence="0.998249">
In current section, we present three tense annota-
tion experiments with the following scenarios:
</bodyText>
<listItem confidence="0.948760846153846">
1. Null-control situation by native Chinese
speakers where the annotators were provided
with the source Chinese sentences but not the
English translations;
2. High-control situation by native English
speakers where the annotators were provided
with the Chinese sentences as well as English
translations with specified syntax and lexi-
cons;
3. Semi-control situation by native English
speakers where the annotators were allowed
to choose the syntax and lexicons for the En-
glish sentence with appropriate tenses;
</listItem>
<footnote confidence="0.887040666666667">
1All experiments in the paper are approved by Behav-
ioral Sciences Institutional Review Board at the University
of Michigan, the IRB file number is B04-00007481-I.
</footnote>
<page confidence="0.997653">
14
</page>
<subsectionHeader confidence="0.997087">
3.1 Experiment One
</subsectionHeader>
<bodyText confidence="0.999985914285714">
Experiment One presents the first scenario of
tense annotation for Chinese verbs in Chinese-to-
English cross-lingual situation. In the first sce-
nario, the annotation experiment was carried out
on 25 news articles from LDC Xinhua News re-
lease with category number LDC2001T11. The ar-
ticles were divided into 5 groups with 5 articles in
each group. There are a total number of 985 verbs.
For each group, three native Chinese speakers who
were bilingual in Chinese and English annotated
the tense of the verbs in the articles independently.
Prior to annotating the data, the annotators under-
went brief training during which they were asked
to read an example of a Chinese sentence for each
tense and make sure they understand the exam-
ples. During the annotation, the annotators were
asked to read the whole articles first and then se-
lect a tense tag based on the context of each verb.
The tense taxonomy provided to the annotators in-
clude the twelve tenses that are different combi-
nations of the simple tenses (present, past and fu-
ture), the prograssive aspect and the perfect aspect.
In cases where the judges were unable to decide
the tense of a verb, they were instructed to tag it
as “unknown”. In this experiment, the annotators
were asked to tag the tense for all Chinese words
that were tagged as verbs in the Penn Treebank
corpora. Conceivably, the task under the current
scenario is meta-linguistic in nature for the reason
that tense is an elusive notion for Chinese speak-
ers. Nevertheless, the experiment provides a base-
line situation for human tense annotation agree-
ment. The following is an example of the anno-
tation where the annotators were to choose an ap-
propriate tense tag from the provided tense tags:
</bodyText>
<listItem confidence="0.9346445">
((IP (NP-TPC (NP-PN (NR Ё೑))(NP (NN ᓎㄥ)(NN Ꮦഎ)))(LCP-TMP (NP (NT 䖥
ᑈ))(LC ᴹ)) (NP-SBJ (NP (PP (P ᇍ)(NP (NN ໪)))(NP (NN ᓔᬒ)))(NP (NN ℹ
Ӥ)))(VP (ADVP (AD 䖯ϔℹ)) (VP (VV ࡴᖿ)))(PU DŽ)) )
1. simple present tense
2. simple past tense
3. simple future tense
4. present perfect tense
5. past perfect tense
6. future perfect tense
7. present progressive tense
8. past progressive tense
9. future progressive
10. present perfect progressive
11. past perfect progressive
</listItem>
<subsectionHeader confidence="0.999467">
3.2 Experiment Two
</subsectionHeader>
<bodyText confidence="0.999960521739131">
Experiment Two was carried out using 25 news
articles from the parallel Chinese and English
news articles available from LDC Multiple Trans-
lation Chinese corpora (MTC catalog number
LDC2002T01). In the previous experiment, the
annotators tagged all verbs. In the current experi-
mental set-up, we preprocessed the materials and
removed those verbs that lose their verbal status in
translation from Chinese to English due to nom-
inalization. After this preprocessing, there was
a total of 288 verbs annotated by the annotators.
Three native speakers, who were bilingually fluent
in English and Chinese, were recruited to annotate
the tense for the English verbs that were translated
from Chinese. As in the previous scenario, the an-
notators were encouraged to pay attention to the
context of the target verb when tagging its tense.
The annotators were provided with the full taxon-
omy illustrated by examples of English verbs and
they worked independently. The following is an
example of the annotation where the annotators
were to choose an appropriate tense tag from the
provided tense tags:
</bodyText>
<equation confidence="0.437911">
᥂㒳䅵ˈ䖭ѯජᏖএᑈᅠ៤೑ݙ⫳ѻᘏؐϔⱒбक໮ғܗˈ↨ᓔᬒࠡⱘϔббϔᑈ๲
䭓б៤໮DŽ
</equation>
<bodyText confidence="0.8311185">
According to statistics, the cities (achieve) a combined gross domestic product of RMB19
billion last year, an increase of more than 90% over 1991 before their opening.
</bodyText>
<figure confidence="0.991556923076923">
A. achieves
B. achieved
C. will achieve
D. are achieving
E. were achieving
F. will be achieving
G. have achieved
H. had achieved
I. will have achieved
J. have been achieving
K. had been achieving
L. will have been achieving
M. would achieve
</figure>
<subsectionHeader confidence="0.994125">
3.3 Experiment Three
</subsectionHeader>
<bodyText confidence="0.9999751">
Experiment Three was an experiment simulated
on 52 Xinhua news articles from the Multiple
Translation Corpus (MTC) mentioned in the pre-
vious section. Since in the MTC corpora, each
Chinese article is translated into English by ten
human translation teams, conceptually, we could
view these ten translation teams as different an-
notators. They were making decisions about ap-
propriate tense for the English verbs. These an-
notators differ from those in Experiment Two de-
scribed above in that they were allowed to choose
any syntactic structure and verb lexicon. This is
because they were performing tense annotation in
a bigger task of sentence translation. Therefore,
their tense annotations were performed with much
less specification of the annotation context. We
manually aligned the Chinese verbs with the En-
glish verbs for the 10 translation teams from the
MTC corpora and thus obtained our third source
of tense annotation results. For the Chinese verbs
</bodyText>
<page confidence="0.989706">
15
</page>
<bodyText confidence="0.99978025">
that were not translated as verbs into English, we
assigned a “Not Available” tag. There are 1505
verbs in total including the ones that lost their ver-
bal status across the language.
</bodyText>
<sectionHeader confidence="0.999257" genericHeader="method">
4 Inter-Judge Agreement
</sectionHeader>
<bodyText confidence="0.999747222222222">
Researchers use consistency checking to validate
human annotation experiments. There are vari-
ous ways of performing consistency checking de-
scribed in the literature, depending on the scale of
the measurements. Each has its advantages and
disadvantages. Since our tense taxonomy is nomi-
nal without any ordinal information, Kappa statis-
tics measurement is the most appropriate choice to
measure inter-judge agreement.
</bodyText>
<subsectionHeader confidence="0.993686">
4.1 Kappa Statistic
</subsectionHeader>
<bodyText confidence="0.999863666666667">
Kappa scores were calculated for the three human
judges’ annotation results. The Kappa score is the
de facto standard for evaluating inter-judge agree-
ment on tagging tasks. It reports the agreement
rate among multiple annotators while correcting
for the agreement brought about by pure chance.
It is defined by the following formula, where P(A)
is the observed agreement among the judges and
P(E) is the expected agreement:
</bodyText>
<equation confidence="0.998622">
P(A) − P(E)
k � (1)
1 − P(E)
</equation>
<bodyText confidence="0.999976382352941">
Depending on how one identifies the expected
agreement brought about by pure chance, there are
two ways to calculate the Kappa score. One is the
“Seigel-Castellian” Kappa discussed in (Eugenio,
2004), which assumes that there is one hypotheti-
cal distribution of labels for all judges. In contrast,
the “Cohen” Kappa discussed in (Cohen, 1960),
assumes that each annotator has an individual dis-
tribution of labels. This discrepancy slightly af-
fects the calculation of P(E). There is no consen-
sus regarding which Kappa is the ”right” one and
researchers use both. In our experiments, we use
the “Seigel-Castellian” Kappa.
The Kappa statistic for the annotation results of
Experiment One are 0.277 on the full taxonomy
and 0.37 if we collapse the tenses into three big
classes: present, past and future. The observed
agreement rate,that is, P(A), is 0.42.
The Kappa score for tense resolution from the
ten human translation teams for the 52 Xinhua
news articles is 0.585 on the full taxonomy; we
expect the Kappa score to be higher if we exclude
the verbs that are nominalized. Interestingly, the
Kappa score calculated by collapsing the 13 tenses
into 3 tenses (present, past and future) is only
slightly higher: 0.595. The observed agreement
rate is 0.72.
Human tense annotation in the Chinese-to-
English restricted translation scenario achieved a
Kappa score of 0.723 on the full taxonomy with an
observed agreement of 0.798. If we collapse sim-
ple past and present perfect, the Kappa score goes
up to 0.792 with an observed agreement of 0.893.
The Kappa score is 0.81 on the reduced taxonomy.
</bodyText>
<subsectionHeader confidence="0.983275">
4.2 Accuracy
</subsectionHeader>
<bodyText confidence="0.999976378378378">
The Kappa score is a relatively conservative mea-
surement of the inter-judge agreement rate. Con-
ceptually, we could also obtain an alternative mea-
surement of reliability by taking one annotator as
the gold standard at one time and averaging over
the accuracies of the different annotators across
different gold standards. While it is true that nu-
merically, this would yield a higher score than the
Kappa score and seems to be inflating the agree-
ment rate, we argue that the difference between
the Kappa score and the accuracy-based measure-
ment is not limited to one being more aggressive
than the other. The policies of these two mea-
surements are different. The Kappa score is con-
cerned purely with agreement without any consid-
eration of truthfulness or falsehood, while the pro-
cedure we described above gives equal weights to
each annotator being the gold standard. Therefore,
it considers both the agreement and the truthful-
ness of the annotation. Additionally, the accuracy-
based measurement is the same measurement that
is typically used to evaluate machine performance;
therefore it gives a genuine ceiling for machine
performance.
The accuracy under such a scheme for the three
annotators in Experiment One is 43% on the full
tense taxonomy.
The accuracy under such a scheme for tense
generation agreement from three annotators in Ex-
periment Two is 80% on the full tense taxonomy.
The accuracy under such a scheme for the ten
translation teams in Experiment Three is 70.8% on
the full tense taxonomy.
Table 1 summarizes the inter-judge agreement
for the three experiments.
Examining the annotation results, we identified
the following sources of disagreement. While the
</bodyText>
<page confidence="0.997087">
16
</page>
<table confidence="0.9998845">
Agreement Exp 1 Exp 2 Exp 3
Kappa Statistic 0.277 0.723 0.585
Kappa Statistic
0.37 0.81 0.595
(Reduced Taxonomy) 43% 80% 70.8%
Accuracy
</table>
<tableCaption confidence="0.963921">
Table 1: Inter-Annotator Agreement for the Three
Tense Annotation Experiments
</tableCaption>
<bodyText confidence="0.99918475">
first two factors can be controlled for by a clearly
pre-defined annotation guideline, the last two fac-
tors are intrinsically rooted in natural languages
and therefore hard to deal with:
</bodyText>
<listItem confidence="0.939555083333333">
1. Different compliance with Sequence of Tense
(SOT) principle among annotators;
2. “Headline Effect”;
3. Ambiguous POS of the “verb”: sometimes it
is not clear whether a verb is adjective or past
participle. e.g. The Fenglingdu Economic
Development Zone is the only one in China
that is/was built on the basis of a small town.
4. Ambiguous aspectual property of the verb:
the annotator’s view with respect to whether
or not the verb is an atelic verb or a telic verb.
e.g. “statistics showed/show ”
</listItem>
<bodyText confidence="0.9994086">
Put abstractly, ambiguity is an intrinsic property
of natural languages. A taxonomy allows us to
investigate the research problem, yet any clearly
defined discrete taxonomy will inevitably fail on
boundary cases between different classes.
</bodyText>
<sectionHeader confidence="0.97024" genericHeader="method">
5 Significance of Linguistic Factors in
Annotation
</sectionHeader>
<bodyText confidence="0.9836228">
In the NLP community, researchers carry out an-
notation experiments mainly to acquire a gold
standard data set for evaluation. Little effort has
been made beyond the scope of agreement rate
calculations. We propose that not only does fea-
ture analysis for annotation experiments fall un-
der the concern of psycholinguists, it also merits
investigation within the enterprise of natural lan-
guage processing. There are at least two ways
that the analysis of annotation results can help
the NLP task besides just providing a gold stan-
dard: identifying certain features that are respon-
sible for the inter-judge disagreement and model-
ing the situation of associations among the differ-
ent features. The former attempts to answer the
</bodyText>
<figureCaption confidence="0.9532575">
Figure 1: Interaction between Aspect Marker and
Temporal Modifier
</figureCaption>
<bodyText confidence="0.999903214285714">
question of where the challenge for human classi-
fication comes from, and thereby provides an ex-
ternal reference for an automatic NLP system, al-
though not necessarily in a direct way. The latter
sheds light on the structures hidden among groups
of features, the identification of which could pro-
vide insights for feature selection as well as of-
fer convergent evidence for the significance of cer-
tain features confirmed from classification practice
based on machine learning.
In this section, we discuss at some length a fea-
ture analysis for the results of each of the anno-
tation experiments discussed in the previous sec-
tions and summarize the findings.
</bodyText>
<subsectionHeader confidence="0.998569666666667">
5.1 ANOVA analysis of Agreement and
Linguistic Factors in Free Translation
Tense Annotation
</subsectionHeader>
<bodyText confidence="0.999967352941177">
This analysis tries to find the relationship be-
tween the linguistic properties of the verb and the
tense annotation agreement across the ten different
translation teams in Experiment Three. Specifi-
cally, we use an ANOVA analysis to explore how
the overall variance in the inconsistency of the
tenses of a particular verb with respect to differ-
ent translation teams can be attributed to different
linguistic properties associated with the Chinese
verb. It is a three-way ANOVA with three linguis-
tic factors under investigation: whether the sen-
tence contains a temporal modifier or not; whether
the verb is embedded in a relative clause, a senten-
tial complement, an appositive clause or none of
the above; and whether the verb is followed by as-
pect markers or not. The dependent variable is the
inconsistency of the tenses from the teams. The
</bodyText>
<page confidence="0.997819">
17
</page>
<bodyText confidence="0.999976054054054">
inconsistency rate is measured by the ratio of the
number of distinct tenses over the number of tense
tokens from the ten translation teams.
Our ANOVA analysis shows that all of the three
main effects, i.e. the embedding structures of the
verb (p « 0.001), the presence of aspect markers
(p « 0.01), and the presence of temporal mod-
ifiers (p &lt; 0.05) significantly affect the rate of
disagreement in tense generation among the dif-
ferent translation teams. The following graphs
show the trend: tense generation disagreement
rates are consistently lower when the Chinese as-
pect marker is present, whether there is a temporal
modifier present or not (Figure 1). The model also
suggested that the presence of temporal modifiers
is associated with a lower rate of disagreement
for three embedding structures except for verbs in
sentential complements (Figure 2, 0: the verb is
not in any embedding structures; 1: the verb is
embedded in a relative clause; 2: the verb is em-
bedded in an appositive clause; 3: the verb is em-
bedded in sentential complement). Our explana-
tion for this is that the annotators receive varying
degrees of prescriptive writing training, so when
there is a temporal modifier in the sentence as a
confounder, there will be a larger number, a higher
incidence of SOT violations than when there is
no temporal modifier present in the sentence. On
top of this, the rate of disagreement in tense tag-
ging between the case where a temporal modifier
is present in the sentence and the case where it is
not depends on different types of embedding struc-
tures (Figure 2, p value &lt; 0.05).
We also note that the relative clause embed-
ding structure is associated with a much higher
disagreement rate than any other embedding struc-
tures (Figure 3).
</bodyText>
<subsectionHeader confidence="0.996271333333333">
5.2 Logistic Regression Analysis of
Agreement and Linguistic Factors in
Restricted Tense Annotation
</subsectionHeader>
<bodyText confidence="0.9984529">
The ANOVA analysis in the previous section is
concerned with the confounding power of the
overt linguistic features. The current section ex-
amines the significance of the more latent fea-
tures on tense annotation agreement when the SOT
effect is removed by providing the annotators a
clear guideline about the SOT principle. Specif-
ically, we are interested in the effect of verb telic-
ity and punctuality features on tense annotation
agreement. The telicity and punctuality features
</bodyText>
<figureCaption confidence="0.598034">
Figure 2: Interaction between the Temporal Mod-
ifier and the Syntactic Embedding Structure
</figureCaption>
<bodyText confidence="0.999949828571429">
were obtained through manual annotation based
on the situation in the context. The data are from
Experiment Two. Since there are only three an-
notators, the inconsistency rate we discussed in
5.1 would have insufficient variance in the current
scenario, making logistic regression a more appro-
priate analysis. The response is now binary being
either agreement or disagreement (including par-
tial agreement and pure disagreement). To avoid a
multi-colinearity problem, we model Chinese fea-
tures and English features separately. In order
to truly investigate the effects of the latent fea-
tures, we keep the overt linguistic features in the
model as well. The overt features include: type of
syntactic embedding, presence of aspect marker,
presence of temporal expression in the sentence,
whether the verb is in a headline or not, and the
presence of certain signal adverbs including “yi-
jing”(already), “zhengzai” (Chinese pre-verb pro-
gressive marker), “jiang”(Chinese pre-verbal ad-
verb indicating future tense). We used backward
elimination to obtain the final model.
The result showed that punctuality is the only
factor that significantly affects the agreement rate
among multiple judges in both the model of En-
glish features and the model of Chinese features.
The significance level is higher for the punctuality
of English verbs, suggesting that the source lan-
guage environment is more relevant in tense gener-
ation. The annotators are roughly four times more
likely to fail to agree on the tense for verbs as-
sociated with an interval event. This supports the
hypothesis that human beings use the latent fea-
tures for tense classification tasks. Surprisingly,
the telicity feature is not significant at all. We sus-
</bodyText>
<page confidence="0.997958">
18
</page>
<figureCaption confidence="0.996544">
Figure 3: Effect of Syntactic Embedding Structure
on Tense Annotation Disagreement
</figureCaption>
<bodyText confidence="0.9841305">
pect this is partly due to the correlation between
the punctuality feature and the telicity feature. Ad-
ditionally, none of the overt linguistic features is
significant in the presence of the latent features,
which implies that the latent features drive dis-
agreement among multiple annotators.
</bodyText>
<subsectionHeader confidence="0.66532">
5.3 Log-linear Model Analysis of
</subsectionHeader>
<bodyText confidence="0.99277120754717">
Associations between Linguistic Factors
in Free Translation Tense Annotation
This section discusses the association patterns be-
tween tense and the relevant linguistic factors via
a log-linear model. A log-linear model is a special
case of generalized linear models (GLMs) and has
been widely applied in many fields of social sci-
ence research for multivariate analysis of categor-
ical data. The model reveals the interaction be-
tween categorical variables. The log-linear model
is different from other GLMs in that it does not
distinguish between “response” and “explanatory
variables”. All variables are treated alike as “re-
sponse variables”, whose mutual associations are
explored. Under the log-linear model, the ex-
pected cell frequencies are functions of all vari-
ables in the model. The most parsimonious model
that produces the smallest discrepancy between
the expected cell and the observed cell frequen-
cies is chosen as the final model. This provides
the best explanation of the observed relationships
among variables.
We use the data from Experiment Two for the
current analysis. The results show that three lin-
guistic features under investigation are signifi-
cantly associated with tense. First, there is a strong
association between aspect marker presence and
tense, independent of punctuality, telicity feature
and embedding structure. Second, there is a strong
association between telicity and tense, indepen-
dent of punctuality, aspect marker presence and
punctuality feature. Thirdly, there is a strong as-
sociation between embedding structure and tense,
independent of telicity, punctuality feature and as-
pect marker presence. This result is consistent
with (Olsen, 2001), in that the lexical telicity fea-
ture, when used heuristically as the single knowl-
edge source, can achieve a good prediction of verb
tense in Chinese to English Machine Translation.
For example, the odds of the verb being atelic in
the past tense is 2.5 times the odds of the verb
being atelic in the future tense, with a 95% con-
fidence interval of (0.9, 7.2). And the odds of a
verb in the future tense having an aspect marker
approaches zero when compared to the odds of a
verb in the past tense having an aspect marker.
Putting together the pieces from the logistic
analysis and the current analysis, we see that an-
notators fail to agree on tense selection mostly
with apunctual verbs, while the agreed-upon tense
is jointly decided by the telicity feature, aspect
marker feature and the syntactic embedding struc-
ture that are associated with the verb.
</bodyText>
<sectionHeader confidence="0.999056" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999932086956522">
As the initial attempt to assess human beings’
cross-lingual tense annotation, the current paper
carries out a series of tense annotation experi-
ments between Chinese and English under differ-
ent scenarios. We show that even if tense is an
abstract grammatical category, multiple annotators
are still able to achieve a good agreement rate
when the target English context is fully specified.
We also show that in a non-restricted scenario,
the overt linguistic features (aspect markers, em-
bedding structures and temporal modifiers), can
cause people to fail to agree with each other signif-
icantly in tense annotation. These factors exhibit
certain interaction patterns in the decision mak-
ing of the annotators. Our analysis of the anno-
tation results from the scenario with a fully speci-
fied context show that people tend to fail to agree
with each other on tense for verbs associated with
interval events. The disagreement seems not to
be driven by the overt linguistic features such as
embedding structure and aspect markers. Lastly,
among a set of overt and latent linguistic features,
aspect marker presence, embedding structure and
</bodyText>
<page confidence="0.996756">
19
</page>
<bodyText confidence="0.975575142857143">
the telicity feature exhibit the strongest association
with tense, potentially indicating their high utility
in tense classification task.
The current analysis, while suggesting certain
interesting patterns in tense annotation, could be
more significant if the findings could be replicated
by experiments of different scales on different data
sets. Furthermore, the statistical analysis could be
more finely geared to capture the more subtle dis-
tinctions encoded in the features.
Acknowledgement All of the annotation exper-
iments in this paper are funded by Rackham Grad-
uate School’s Discretionary Funds at the Univer-
sity of Michigan.
</bodyText>
<sectionHeader confidence="0.992153" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999956454545455">
Hans Reichenbach,1947. Elements of Symbolic Logic,
Macmillan, New York, N.Y.
Mari Olson, David Traum, Carol Van Ess-Dykema,
and Amy Weinberg, 2001. Implicit Cues for Explicit
Generation: Using Telicity as a Cue for Tense Struc-
ture in a Chinese to English MT System, Proceed-
ings Machine Translation Summit VIII, Santiago de
Compostela, Spain.
Yang Ye, Zhu Zhang, 2005. Tense Tagging for Verbs
in Cross-Lingual Context: A Case Study. Proceed-
ings of 2nd International Joint Conference in Natural
Language Processing (IJCNLP), 885-895.
George Wilson, Inderjeet Mani, Beth Sundheim, and
Lisa Ferro, 2001. A Multilingual Approach to An-
notating and Extracting Temporal Information, Pro-
ceedings of the ACL 2001 Workshop on Temporal
And Spatial Information Processing, 39th Annual
Meeting of ACL, Toulouse, 81-87.
Graham Katz and Fabrizio Arosio, 2001. The Annota-
tion of Temporal Information in Natural Language
Sentences, Proceedings of the ACL 2001 Workshop
on Temporal And Spatial Information Processing,
39th Annual Meeting of ACL, Toulouse, 104-111.
James Pustejovsky, Robert Ingria, Roser Sauri, Jose
Castano, Jessica Littman, Rob Gaizauskas, Andrea
Setzer, Graham Katz, and Inderjeet Mani. 2004. The
Specification Language TimeML. The Language of
Time: A Reader. Oxford, 185-96.
Barbara Di Eugenio and Michael Glass. 2004. The
kappa statistic: A second look. Computational Lin-
guistics, 30(1): 95-101.
Inderjeet Mani, 2003. Recent Developments in Tem-
poral Information Extraction. In Nicolov, N. and
Mitkov, R., editors, Proceedings of RANLP’03.
John Benjamins.
Andrea Setzer, Robert Gaizauskas, and Mark Hep-
ple, 2003. Using Semantic Inferences for Tem-
poral Annotation Comparison, Proceedings of the
Fourth International Workshop on Inference in
Computational Semantics (ICOS-4), INRIA, Lor-
raine, Nancy, France, September 25-26, 185-96.
Jacob Cohen, 1960. A Coefficient of Agreement for
Nominal Scales, Educational and Psychological
Measurement, 20, 37-46.
</reference>
<page confidence="0.994895">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.243100">
<title confidence="0.993535">How and Where do People Fail with Time: Temporal Reference Mapping Annotation by Chinese and English Bilinguals</title>
<author confidence="0.920807">Steven</author>
<degree confidence="0.467441">of</degree>
<affiliation confidence="0.874514">of Electrical Engineering and Computer University of Michigan</affiliation>
<abstract confidence="0.999865933333333">This work reports on three human tense annotation experiments for Chinese verbs in Chinese-to-English translation scenarios. The results show that inter-annotator agreement increases as the context of the verb under the annotation becomes increasingly specified, i.e. as the context moves from the situation in which the target English sentence is unknown to the situation in which the target lexicon and target syntactic structure are fully specified. The annotation scheme with a fully specified syntax and lexicon in the target English sentence yields a satisfactorily high agreement rate. The annotation results were then analyzed via an ANOVA analysis, a logistic regression model and a log-linear model. The analyses reveal that while both the overt and the latent linguistic factors seem to significantly affect annotation agreement under different scenarios, the latent features are the real driving factors of tense annotation disagreement among multiple annotators. The analyses also find the verb telicity feature, aspect marker presence and syntactic embedding structure to be strongly associated with tense, suggesting their utility in the automatic tense classification task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Hans Reichenbach</author>
</authors>
<title>Elements of Symbolic Logic,</title>
<publisher>Macmillan,</publisher>
<location>New York, N.Y.</location>
<marker>Reichenbach, </marker>
<rawString>Hans Reichenbach,1947. Elements of Symbolic Logic, Macmillan, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari Olson</author>
<author>David Traum</author>
<author>Carol Van Ess-Dykema</author>
<author>Amy Weinberg</author>
</authors>
<title>Implicit Cues for Explicit Generation: Using Telicity as a Cue for Tense Structure in a Chinese to English MT System,</title>
<date>2001</date>
<booktitle>Proceedings Machine Translation Summit VIII, Santiago de Compostela,</booktitle>
<marker>Olson, Traum, Van Ess-Dykema, Weinberg, 2001</marker>
<rawString>Mari Olson, David Traum, Carol Van Ess-Dykema, and Amy Weinberg, 2001. Implicit Cues for Explicit Generation: Using Telicity as a Cue for Tense Structure in a Chinese to English MT System, Proceedings Machine Translation Summit VIII, Santiago de Compostela, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>Zhu Zhang</author>
</authors>
<title>Tense Tagging for Verbs in Cross-Lingual Context: A Case Study.</title>
<date>2005</date>
<booktitle>Proceedings of 2nd International Joint Conference in Natural Language Processing (IJCNLP),</booktitle>
<pages>885--895</pages>
<marker>Ye, Zhang, 2005</marker>
<rawString>Yang Ye, Zhu Zhang, 2005. Tense Tagging for Verbs in Cross-Lingual Context: A Case Study. Proceedings of 2nd International Joint Conference in Natural Language Processing (IJCNLP), 885-895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Wilson</author>
<author>Inderjeet Mani</author>
<author>Beth Sundheim</author>
<author>Lisa Ferro</author>
</authors>
<title>A Multilingual Approach to Annotating and Extracting Temporal Information,</title>
<date>2001</date>
<booktitle>Proceedings of the ACL 2001 Workshop on Temporal And Spatial Information Processing, 39th Annual Meeting of ACL,</booktitle>
<pages>81--87</pages>
<location>Toulouse,</location>
<marker>Wilson, Mani, Sundheim, Ferro, 2001</marker>
<rawString>George Wilson, Inderjeet Mani, Beth Sundheim, and Lisa Ferro, 2001. A Multilingual Approach to Annotating and Extracting Temporal Information, Proceedings of the ACL 2001 Workshop on Temporal And Spatial Information Processing, 39th Annual Meeting of ACL, Toulouse, 81-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
<author>Fabrizio Arosio</author>
</authors>
<title>The Annotation of Temporal Information in Natural Language Sentences,</title>
<date>2001</date>
<booktitle>Proceedings of the ACL 2001 Workshop on Temporal And Spatial Information Processing, 39th Annual Meeting of ACL,</booktitle>
<pages>104--111</pages>
<location>Toulouse,</location>
<marker>Katz, Arosio, 2001</marker>
<rawString>Graham Katz and Fabrizio Arosio, 2001. The Annotation of Temporal Information in Natural Language Sentences, Proceedings of the ACL 2001 Workshop on Temporal And Spatial Information Processing, 39th Annual Meeting of ACL, Toulouse, 104-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Jose Castano</author>
<author>Jessica Littman</author>
<author>Rob Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Inderjeet Mani</author>
</authors>
<title>The Specification Language TimeML. The Language of Time: A Reader.</title>
<date>2004</date>
<pages>185--96</pages>
<location>Oxford,</location>
<contexts>
<context position="5992" citStr="Pustejovsky et al., 2004" startWordPosition="899" endWordPosition="902">lson, et al., 1997) describes a multilingual approach to annotating temporal information, which involves flagging a temporal expression in the document and identifying the time value that the expression designates. Their work reports an inter-annotator reliability F-measure of 0.79 and 0.86 respectively for English corpora. (Katz, et al., 2001) describes a simple and general technique for the annotation of temporal relation information based on binary interval relation types: precedence and inclusion. Their annotation scheme could benefit a range of NLP applications and is easy to carry out. (Pustejovsky et al., 2004) reports an annotation scheme, the TimeML metadata, for the markup of events and their anchoring in documents. The annotation schema of TimeML is very fine-grained with a wide coverage of different event types, dependencies between events and times, as well as “LINK” tags which encode the various relations existing between the temporal elements of a document. The challenge of human labeling of links among eventualities was discussed at great length in their paper. Automatic “time-stamping” was attempted on a small sample of text in an earlier work of (Mani, 2003). The result was not particular</context>
</contexts>
<marker>Pustejovsky, Ingria, Sauri, Castano, Littman, Gaizauskas, Setzer, Katz, Mani, 2004</marker>
<rawString>James Pustejovsky, Robert Ingria, Roser Sauri, Jose Castano, Jessica Littman, Rob Gaizauskas, Andrea Setzer, Graham Katz, and Inderjeet Mani. 2004. The Specification Language TimeML. The Language of Time: A Reader. Oxford, 185-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Michael Glass</author>
</authors>
<title>The kappa statistic: A second look.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<pages>95--101</pages>
<marker>Di Eugenio, Glass, 2004</marker>
<rawString>Barbara Di Eugenio and Michael Glass. 2004. The kappa statistic: A second look. Computational Linguistics, 30(1): 95-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Recent Developments in Temporal Information Extraction.</title>
<date>2003</date>
<booktitle>Proceedings of RANLP’03.</booktitle>
<editor>In Nicolov, N. and Mitkov, R., editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="6561" citStr="Mani, 2003" startWordPosition="994" endWordPosition="995">y to carry out. (Pustejovsky et al., 2004) reports an annotation scheme, the TimeML metadata, for the markup of events and their anchoring in documents. The annotation schema of TimeML is very fine-grained with a wide coverage of different event types, dependencies between events and times, as well as “LINK” tags which encode the various relations existing between the temporal elements of a document. The challenge of human labeling of links among eventualities was discussed at great length in their paper. Automatic “time-stamping” was attempted on a small sample of text in an earlier work of (Mani, 2003). The result was not particularly promising. It showed the need for a larger quantity of training data as well as more predictive features, especially on the discourse level. At the word level, the semantic representation of tenses could be approached in various ways depending on different applications. So far, their work has gone the furthest towards establishing a broad and open standard metadata mark-up language for natural language texts. (Setzer, et al., 2004) presents a method of evaluating temporal order relation annotations and an approach to facilitate the creation of a gold standard </context>
</contexts>
<marker>Mani, 2003</marker>
<rawString>Inderjeet Mani, 2003. Recent Developments in Temporal Information Extraction. In Nicolov, N. and Mitkov, R., editors, Proceedings of RANLP’03. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Setzer</author>
<author>Robert Gaizauskas</author>
<author>Mark Hepple</author>
</authors>
<title>Using Semantic Inferences for Temporal Annotation Comparison,</title>
<date>2003</date>
<booktitle>Proceedings of the Fourth International Workshop on Inference in Computational Semantics (ICOS-4), INRIA,</booktitle>
<pages>185--96</pages>
<location>Lorraine, Nancy, France,</location>
<marker>Setzer, Gaizauskas, Hepple, 2003</marker>
<rawString>Andrea Setzer, Robert Gaizauskas, and Mark Hepple, 2003. Using Semantic Inferences for Temporal Annotation Comparison, Proceedings of the Fourth International Workshop on Inference in Computational Semantics (ICOS-4), INRIA, Lorraine, Nancy, France, September 25-26, 185-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A Coefficient of Agreement for Nominal Scales,</title>
<date>1960</date>
<journal>Educational and Psychological Measurement,</journal>
<volume>20</volume>
<pages>37--46</pages>
<contexts>
<context position="14576" citStr="Cohen, 1960" startWordPosition="2286" endWordPosition="2287"> the agreement rate among multiple annotators while correcting for the agreement brought about by pure chance. It is defined by the following formula, where P(A) is the observed agreement among the judges and P(E) is the expected agreement: P(A) − P(E) k � (1) 1 − P(E) Depending on how one identifies the expected agreement brought about by pure chance, there are two ways to calculate the Kappa score. One is the “Seigel-Castellian” Kappa discussed in (Eugenio, 2004), which assumes that there is one hypothetical distribution of labels for all judges. In contrast, the “Cohen” Kappa discussed in (Cohen, 1960), assumes that each annotator has an individual distribution of labels. This discrepancy slightly affects the calculation of P(E). There is no consensus regarding which Kappa is the ”right” one and researchers use both. In our experiments, we use the “Seigel-Castellian” Kappa. The Kappa statistic for the annotation results of Experiment One are 0.277 on the full taxonomy and 0.37 if we collapse the tenses into three big classes: present, past and future. The observed agreement rate,that is, P(A), is 0.42. The Kappa score for tense resolution from the ten human translation teams for the 52 Xinh</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen, 1960. A Coefficient of Agreement for Nominal Scales, Educational and Psychological Measurement, 20, 37-46.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>