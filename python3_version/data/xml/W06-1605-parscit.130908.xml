<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000313">
<title confidence="0.998048">
Distributional Measures of Concept-Distance:
A Task-oriented Evaluation
</title>
<author confidence="0.992628">
Saif Mohammad and Graeme Hirst
</author>
<affiliation confidence="0.9982955">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.96016">
Toronto, ON M5S 3G4, Canada
</address>
<email confidence="0.999458">
{smm,gh}@cs.toronto.edu
</email>
<sectionHeader confidence="0.993908" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999602684210526">
We propose a framework to derive the
distance between concepts from distribu-
tional measures of word co-occurrences.
We use the categories in a published
thesaurus as coarse-grained concepts, al-
lowing all possible distance values to
be stored in a concept–concept matrix
roughly .01% the size of that created
by existing measures. We show that
the newly proposed concept-distance mea-
sures outperform traditional distributional
word-distance measures in the tasks of
(1) ranking word pairs in order of se-
mantic distance, and (2) correcting real-
word spelling errors. In the latter task,
of all the WordNet-based measures, only
that proposed by Jiang and Conrath out-
performs the best distributional concept-
distance measures.
</bodyText>
<sectionHeader confidence="0.951092" genericHeader="categories and subject descriptors">
1 Semantic and distributional measures
</sectionHeader>
<bodyText confidence="0.999869541666667">
Measures of distance of meaning are of two kinds.
The first kind, which we will refer to as seman-
tic measures, rely on the structure of a resource
such as WordNet or, in some cases, a semantic
network, and hence they measure the distance be-
tween the concepts or word-senses that the nodes
of the resource represent. Examples include the
measure for MeSH proposed by Rada et al. (1989)
and those for WordNet proposed by Leacock and
Chodorow (1998) and Jiang and Conrath (1997).
(Some of the more successful measures, such as
Jiang–Conrath, also use information content de-
rived from word frequency.) Typically, these mea-
sures rely on an extensive hierarchy of hyponymy
relationships for nouns. Therefore, these measures
are expected to perform poorly when used to es-
timate distance between senses of part-of-speech
pairs other than noun–noun, not just because the
WordNet hierarchies for other parts of speech are
less well developed, but also because the hierar-
chies for the different parts of speech are not well
connected.
The second kind of measures, which we will
refer to as distributional measures, are inspired
by the maxim “You shall know a word by the
company it keeps” (Firth, 1957). These measures
rely simply on raw text, and hence are much less
resource-hungry than the semantic measures; but
they measure the distance between words rather
than word-senses or concepts. In these measures,
two words are considered close if they occur in
similar contexts. The context (or “company”) of
a target word is represented by its distributional
profile (DP), which lists the strength of associ-
ation between the target and each of the lexical,
syntactic, and/or semantic units that co-occur with
it. Commonly used measures of strength of as-
sociation are conditional probability (0 to 1) and
pointwise mutual information (—∞ to ∞)1. Com-
monly used units of co-occurrence with the target
are other words, and so we speak of the lexical dis-
tributional profile of a word (lexical DPW). The
co-occurring words may be all those in a prede-
termined window around the target, or may be re-
stricted to those that have a certain syntactic (e.g.,
verb–object) or semantic (e.g., agent–theme) re-
lation with the target word. We will refer to the
former kind of DPs as relation-free. Usually in
</bodyText>
<footnote confidence="0.9909066">
1In our experiments, we set negative PMI values to 0, be-
cause Church and Hanks (1990), in their seminal paper on
word association ratio, show that negative PMI values are not
expected to be accurate unless co-occurrence counts are made
from an extremely large corpus.
</footnote>
<page confidence="0.982844">
35
</page>
<note confidence="0.992619">
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 35–43,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<tableCaption confidence="0.9457125">
Table 1: Measures of DP distance and measures of
strength of association.
</tableCaption>
<note confidence="0.465978">
DP distance Strength of association
</note>
<bodyText confidence="0.847239714285714">
α-skew divergence conditional probability
cosine pointwise mutual information
Jensen–Shannon divergence
Lin
the latter case, separate association values are cal-
culated for each of the different relations between
the target and the co-occurring units. We will refer
to such DPs as relation-constrained.
Typical relation-free DPs are those of Sch¨utze
and Pedersen (1997) and Yoshida et al. (2003).
Typical relation-constrained DPs are those of
Lin (1998) and Lee (2001). Below are contrived,
but plausible, examples of each for the word pulse;
the numbers are conditional probabilities.
</bodyText>
<sectionHeader confidence="0.686962" genericHeader="method">
relation-free DP
</sectionHeader>
<bodyText confidence="0.6520965">
pulse: beat (.28), racing (.2), grow
(.13), beans (.09), heart (.04), ...
</bodyText>
<sectionHeader confidence="0.734612" genericHeader="method">
relation-constrained DP
</sectionHeader>
<bodyText confidence="0.988836095890411">
pulse: &lt;beat, subject–verb&gt; (.34),
&lt;racing, noun–qualifying adjective&gt;
(.22), &lt;grow, subject–verb&gt; (.14), ...
The distance between two words, given their
DPs, is calculated using a measure of DP dis-
tance, such as cosine. While any of the mea-
sures of DP distance may be used with any of the
measures of strength of association (see Table 1),
in practice α-skew divergence (ASD), cosine, and
Jensen–Shannon divergence (JSD) are used with
conditional probability (CP), whereas Lin is used
with PMI, resulting in the distributional measures
ASDcp (Lee, 2001), Coscp (Sch¨utze and Pedersen,
1997), JSDcp, and Linpmi (Lin, 1998), respectively.
ASDcp is a modification of Kullback-Leibler diver-
gence that overcomes the latter’s problem of divi-
sion by zero, which can be caused by data sparse-
ness. JSDcp is another relative entropy–based
measure (like ASDcp) but it is symmetric. JSDcp
and ASDcp are distance measures that give scores
between 0 (identical) and infinity (maximally dis-
tant). Linpmi and Coscp are similarity measures that
give scores between 0 (maximally distant) and 1
(identical). See Mohammad and Hirst (2005) for a
detailed study of these and other measures.
2 The distributional hypothesis and its
limitations
The distributional hypothesis (Firth, 1957) states
that words that occur in similar contexts tend to be
semantically similar. It is often suggested, there-
fore, that a distributional measure can act as a
proxy for a semantic measure: the distance be-
tween the DPs of words will approximate the dis-
tance between their senses. But when words have
more than one sense, it is not at all clear what se-
mantic distance between them actually means. A
word in each of its senses is likely to co-occur
with different sets of words. For example, bank
in the ‘financial institution’ sense is likely to co-
occur with interest, money, accounts, and so on,
whereas the ‘river bank’ sense might have words
such as river, erosion, and silt around it. If we de-
fine the distance between two words, at least one
of which is ambiguous, to be the closest distance
between some sense of one and some sense of the
other, then distributional distance between words
may indeed be used in place of semantic distance
between concepts. However, because measures of
distributional distance depend on occurrences of
the target word in all its senses, this substitution is
inaccurate. For example, observe that both DPWs
of pulse above have words that co-occur with its
‘throbbing arteries’ sense and words that co-occur
with its ‘edible seed’ sense. Relation-free DPs of
pulse in its two separate senses might be as fol-
lows:
pulse ‘throbbing arteries’: beat (.36),
racing (.27), heart (.11), ...
pulse ‘edible seeds’: grow (.24), beans
(.14), . . .
Thus, it is clear that different senses of a word have
different distributional profiles (“different com-
pany”). Using a single DP for the word will mean
the union of those profiles. While this might be
useful for certain applications, we believe that in
a number of tasks (including estimating linguistic
distance), acquiring different DPs for the differ-
ent senses is not only more intuitive, but also, as
we will show through experiments in Section 5,
more useful. We argue that distributional pro-
files of senses or concepts (DPCs) can be used to
infer semantic properties of the senses: “You shall
know a sense by the company it keeps.”
</bodyText>
<page confidence="0.998931">
36
</page>
<sectionHeader confidence="0.982068" genericHeader="method">
3 Conceptual grain size and storage
requirements
</sectionHeader>
<bodyText confidence="0.998628625">
As applications for linguistic distance become
more sophisticated and demanding, it becomes at-
tractive to pre-compute and store the distance val-
ues between all possible pairs of words or senses.
But both kinds of measures have large space re-
quirements to do this, requiring matrices of size
N x N, where N is the size of the vocabulary (per-
haps 100,000 for most languages) in the case of
distributional measures and the number of senses
(75,000 just for nouns in WordNet) in the case of
semantic measures.
It is generally accepted, however, that WordNet
senses are far too fine-grained (Agirre and Lopez
de Lacalle Lekuona (2003) and citations therein).
On the other hand, published thesauri, such as Ro-
get’s and Macquarie, group near-synonymous and
semantically related words into a relatively small
number of categories—typically between 800 and
1100—that roughly correspond to very coarse
concepts or senses (Yarowsky, 1992). Words with
more than one sense are listed in more than one
category. A published thesaurus thus provides us
with a very coarse human-developed set or inven-
tory of word senses or concepts2 that are more in-
tuitive and discernible than the “concepts” gener-
ated by dimensionality-reduction methods such as
latent semantic analysis. Using coarse senses from
a known inventory means that the senses can be
represented unambiguously by a large number of
possibly ambiguous words (conveniently available
in the thesaurus)—a feature that we exploited in
our earlier work (Mohammad and Hirst, 2006) to
determine useful estimates of the strength of asso-
ciation between a concept and co-occurring words.
In this paper, we go one step further and use
the idea of a very coarse sense inventory to de-
velop a framework for distributional measures of
concepts that can more naturally and more ac-
curately be used in place of semantic measures
of word senses. We use the Macquarie The-
saurus (Bernard, 1986) as a sense inventory and
repository of words pertaining to each sense. It has
812 categories with around 176,000 word tokens
and 98,000 word types. This allows us to have
much smaller concept–concept distance matri-
ces of size just 812 x 812 (roughly .01% the size
2We use the terms senses and concepts interchangeably.
This is in contrast to studies, such as that of Cooper (2005),
that attempt to make a principled distinction between them.
of matrices required by existing measures). We
evaluate our distributional concept-distance mea-
sures on two tasks: ranking word pairs in order
of their semantic distance, and correcting real-
word spelling errors. We compare performance
with distributional word-distance measures and
the WordNet-based concept-distance measures.
</bodyText>
<sectionHeader confidence="0.950894" genericHeader="method">
4 Distributional measures of
concept-distance
</sectionHeader>
<subsectionHeader confidence="0.9706735">
4.1 Capturing distributional profiles of
concepts
</subsectionHeader>
<bodyText confidence="0.999990666666667">
We use relation-free lexical DPs—both DPWs and
DPCs—in our experiments, as they allow deter-
mination of semantic properties of the target from
just its co-occurring words.
Determining lexical DPWs simply involves
making word–word co-occurrence counts in a
corpus. A direct method to determine lexical
DPCs, on the other hand, requires information
about which words occur with which concepts.
This means that the text from which counts are
made has to be sense annotated. Since exist-
ing labeled data is minimal and manual annota-
tion is far too expensive, indirect means must be
used. In an earlier paper (Mohammad and Hirst,
2006), we showed how this can be done with sim-
ple word sense disambiguation and bootstrapping
techniques. Here, we summarize the method.
First, we create a word–category co-
occurrence matrix (WCCM) using the British
National Corpus (BNC) and the Macquarie
Thesaurus. The WCCM has the following form:
</bodyText>
<equation confidence="0.9347385">
c1 c2 ::: cj :::
w1 m11 m12 ::: m1j :::
w2 m21 m22 ::: m2j :::
... ... ... .. .::::::
wi mi1 mi2 ::: mij :::
... ... ... ... ... ...
</equation>
<bodyText confidence="0.9998893">
A cell mij, corresponding to word wi and cate-
gory cj, contains the number of times wi co-occurs
(in a window of ±5 words in the corpus) with
any of the words listed under category cj in the
thesaurus. Intuitively, the cell mij captures the
number of times cj and wi co-occur. A contin-
gency table for a single word and single category
can be created by simply collapsing all other rows
and columns into one and summing their frequen-
cies. Applying a suitable statistic, such as odds
</bodyText>
<page confidence="0.992195">
37
</page>
<figure confidence="0.976302818181818">
BNC BNC Thesaurus
word–category co-occurrence matrix
word–word
co-occurrence counting
word–word co-occurrence matrix
word–category
co-occurrence counting
bootstrapping and
sense disambiguation
distributional measures distributional measures
distributional relatedness of words distributional relatedness of concepts
</figure>
<figureCaption confidence="0.999988">
Figure 1: Distributional word-distance. Figure 2: Distributional concept-distance.
</figureCaption>
<bodyText confidence="0.999953761904762">
ratio, on the contingency table gives the strength
of association between a concept (category) and
co-occurring word. Therefore, the WCCM can be
used to create the lexical DP for any concept.
The matrix that is created after one pass of the
corpus, which we call the base WCCM, although
noisy (as it is created from raw text and not sense-
annotated data), captures strong associations be-
tween categories and co-occurring words. There-
fore the intended sense (thesaurus category) of a
word in the corpus can now be determined using
frequencies of co-occurring words and its various
senses as evidence. A new bootstrapped WCCM
is created, after a second pass of the corpus, in
which the cell mij contains the number of times
any word used in sense cj co-occurs with wi. We
have shown (Mohammad and Hirst, 2006) that the
bootstrapped WCCM captures word–category co-
occurrences much more accurately than the base
WCCM, using the task of determining word sense
dominance3 as a test bed.
</bodyText>
<subsectionHeader confidence="0.970732">
4.2 Applying distributional measures to
DPCs
</subsectionHeader>
<bodyText confidence="0.998186818181818">
Recall that in computing distributional word-
distance, we consider two target words to be dis-
tributionally similar (less distant) if they occur in
similar contexts. The contexts are represented by
the DPs of the target words, where a DP gives the
strength of association between the target and the
co-occurring units. A distributional measure uses
a measure of DP distance to determine the distance
between two DPs and thereby between the two tar-
get words (see Figure 1). The various measures
differ in what statistic they use to calculate the
strength of association and the measure of DP dis-
3Near-upper-bound results were achieved in the task of
determining predominant senses of 27 words in 11 target texts
with a wide range of sense distributions over their two most
dominant senses.
tance they use (see Mohammad and Hirst (2005)
for details). For example, following is the cosine
formula for distance between words w1 and w2 us-
ing relation-free lexical DPWs, with conditional
probability of the co-occurring word given the tar-
get as the strength of association:
</bodyText>
<equation confidence="0.999573">
Coscp(w1,w2) =
∑ w2C(w1)[C(w2) (P(wjw1) XP(wjw2))
�∑w2C(w1)P(wjw1)2 X�∑w2C(w2)P(wjw2)2
</equation>
<bodyText confidence="0.946649933333333">
Here, C(x) is the set of words that co-occur with
word x within a pre-determined window.
In order to calculate distributional concept-
distance, consider the same scenario, except that
the targets are now senses or concepts. Two con-
cepts are closer if their DPs are similar, and these
DPCs require the strength of association between
the target concepts and their co-occurring words.
The associations can be estimated from the boot-
strapped WCCM, described in Section 4.1 above.
Any of the distributional measures used for DPWs
can now be used to estimate concept-distance with
DPCs. Figure 2 illustrates our methodology. Be-
low is the formula for cosine with conditional
probabilities when applied to concepts:
</bodyText>
<equation confidence="0.999238">
Coscp(c1,c2) =
∑w2C(c1)[C(c2) (P(wjc1) XP(wjc2))
�∑w2C(c1)P(wjc1)2 X�∑w2C(c2)P(wjc2)2
</equation>
<bodyText confidence="0.883502125">
Now, C(x) is the set of words that co-occur with
concept x within a pre-determined window.
We will refer to such measures as distributional
measures of concept-distance (Distribconcept),
in contrast to the earlier-described distribu-
tional measures of word-distance (Distribword)
and WordNet-based (or semantic) measures of
concept-distance (WNetconcept). We shall refer
</bodyText>
<page confidence="0.996054">
38
</page>
<bodyText confidence="0.999960625">
to these three kinds of distance measures as
measure-types. Individual measures in each kind
will be referred to simply as measures.
A distributional measure of concept-distance
can be used to populate a small 812 x 812
concept–concept distance matrix where a cell
mij, pertaining to concepts ci and cj, contains
the distance between the two concepts. In con-
trast, a word–word distance matrix for a conserva-
tive vocabulary of 100,000 word types will have
a size 100,000 x 100,000, and a WordNet-based
concept–concept distance matrix will have a size
75,000 x 75,000 just for nouns. Our concept-
concept distance matrix is roughly .01% the size
of these matrices.
Note that the DPs we are using are relation-free
because (1) we use all co-occurring words (not just
those that are related to the target by certain syn-
tactic or semantic relations) and (2) the WCCM,
as described in Section 4.1, does not maintain sep-
arate counts for the different relations between the
target and co-occurring words. Creating a larger
matrix with separate counts for the different rela-
tions would lead to relation-constrained DPs.
</bodyText>
<sectionHeader confidence="0.998378" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999733739130435">
To evaluate the distributional concept-distance
measures, we used them in the tasks of ranking
word pairs in order of their semantic distance and
of correcting real-word spelling errors, and com-
pared our results to those that we obtained on the
same tasks with distributional word-distance mea-
sures and those that Budanitsky and Hirst (2006)
obtained with WordNet-based semantic measures.
The distributional concept-distance measures
used a bootstrapped WCCM created from the BNC
and the Macquarie Thesaurus. The word-distance
measures used a word–word co-occurrence matrix
created from the BNC alone. The BNC was not
lemmatized, part of speech tagged, or chunked.
The vocabulary was restricted to the words present
in the thesaurus (about 98,000 word types) both
to provide a level evaluation platform and to keep
the matrix to a manageable size. Co-occurrence
counts less than 5 were reset to 0, and words
that co-occurred with more than 2000 other words
were stoplisted (543 in all). We used ASDcp (α =
0.99), Coscp, JSDcp, and Linpmi4 to populate corre-
sponding concept–concept distance matrices and
</bodyText>
<footnote confidence="0.658091">
4Whereas Lin (1998) used relation-constrained DPs, in
our experiments all DPs are relation-free.
</footnote>
<tableCaption confidence="0.964401333333333">
Table 2: Correlation of distributional measures
with human ranking. Best results for each
measure-type are shown in boldface.
</tableCaption>
<table confidence="0.975401125">
Measure Measure-type
Distribword Distribconcept
closest average
ASDcp .45 .60
Coscp .54 .69 .42
JSDcp .48 .61
Linpmi .52 .71 .59
word–word distance matrices. Applications that
</table>
<bodyText confidence="0.931507">
require distance values will enjoy a run-time ben-
efit if the distances are precomputed. While it is
easy to completely populate the concept–concept
co-occurrence matrix, completely populating the
word–word distance matrix is a non-trivial task be-
cause of memory and time constraints.5
</bodyText>
<subsectionHeader confidence="0.992124">
5.1 Ranking word pairs
</subsectionHeader>
<bodyText confidence="0.999866115384615">
A direct approach to evaluating linguistic dis-
tance measures is to determine how close they
are to human judgment and intuition. Given a
set of word-pairs, humans can rank them in or-
der of their distance—placing near-synonyms on
one end of the ranking and unrelated pairs on the
other. Rubenstein and Goodenough (1965) pro-
vide a “gold-standard” list of 65 human-ranked
word-pairs (based on the responses of 51 sub-
jects). One automatic word-distance estimator,
then, is deemed to be more accurate than another
if its ranking of word-pairs correlates more closely
with this human ranking. Measures of concept-
distance can perform this task by determining
word-distance for each word-pair by finding the
concept-distance between all pairs of senses of the
two words, and choosing the distance of the clos-
est sense pair. This is based on the assumption that
when humans are asked to judge the semantic dis-
tance between a pair of words, they implicitly con-
sider its closest senses. For example, most people
will agree that bank and interest are semantically
related, even though both have multiple senses—
most of which are unrelated. Alternatively, the
method could take the average of the distance of
all pairs of senses.
</bodyText>
<footnote confidence="0.978033666666667">
5As we wanted to perform experiments with both
concept–concept and word–word distance matrices, we pop-
ulated them as and when new distance values were calculated.
</footnote>
<page confidence="0.999588">
39
</page>
<tableCaption confidence="0.9834855">
Table 3: Hirst and St-Onge metrics for evaluation
of real-word spelling correction.
</tableCaption>
<listItem confidence="0.9391663125">
suspect ratio = no. of true-suspects
alarm ratio = no. of malaps
no. of false-suspects
no. of non-malaps
no. of true-alarms
no. of true-suspects
no. of false-alarms
no. of false-suspects
detection ratio = no. of true-alarms
no. of malaps
no. of false-alarms
no. of non-malaps
no. corrected malaps
no. of malaps
no. of false-alarms
no. of non-malaps
</listItem>
<bodyText confidence="0.937123631578947">
correction accuracy = no. of corrected malaps
no. of true-alarms
Table 2 lists correlations of human rank-
ings with those created using distributional mea-
sures. Observe that Distribconcept measures
give markedly higher correlation values than
Distribword measures. Also, using the distance of
the closest sense pair (for Coscp and Linpmi) gives
much better results than using the average dis-
tance of all relevant sense pairs. (We do not report
average distance for ASDcp and JSDcp because
they give very large distance values when sense-
pairs are unrelated—values that dominate the av-
erages, overwhelming the others, and making the
results meaningless.) These correlations are, how-
ever, notably lower than those obtained by the best
WordNet-based measures (not shown in the table),
which fall in the range .78 to .84 (Budanitsky and
Hirst, 2006).
</bodyText>
<subsectionHeader confidence="0.998845">
5.2 Real-word spelling error correction
</subsectionHeader>
<bodyText confidence="0.999994107692308">
The set of Rubenstein and Goodenough word pairs
is much too small to safely assume that measures
that work well on them do so for the entire En-
glish vocabulary. Consequently, semantic mea-
sures have traditionally been evaluated through ap-
plications that use them, such as the work by Hirst
and Budanitsky (2005) on correcting real-word
spelling errors (or malapropisms). If a word
in a text is not “semantically close” to any other
word in its context, then it is considered a sus-
pect. If the suspect has a spelling-variant that
is “semantically close” to a word in its context,
then the suspect is declared a probable real-word
spelling error and an “alarm” is raised; the related
spelling-variant is considered its correction. Hirst
and Budanitsky tested the method on 500 articles
from the 1987–89 Wall Street Journal corpus for
their experiments, replacing every 200th word by
a spelling-variant. We adopt this method and this
test data, but whereas Hirst and Budanitsky used
WordNet-based semantic measures, we use distri-
butional measures Distribword and Distribconcept.
In order to determine whether two words are
“semantically close” or not as per any measure
of distance, a threshold must be set. If the dis-
tance between two words is less than the threshold,
then they will be considered semantically close.
Hirst and Budanitsky (2005) pointed out that there
is a notably wide band between 1.83 and 2.36
(on a scale of 0–4), such that all Rubenstein and
Goodenough word pairs were assigned values ei-
ther higher than 2.36 or lower than 1.83 by human
subjects. They argue that somewhere within this
band is a suitable threshold between semantically
close and semantically distant, and therefore set
thresholds for the WordNet-based measures such
that there was maximum overlap in what the mea-
sures and human judgments considered semanti-
cally close and distant. Following this idea, we
use an automatic method to determine thresholds
for the various Distribword and Distribconcept mea-
sures. Given a list of Rubenstein and Goodenough
word pairs ordered according to a distance mea-
sure, we repeatedly consider the mean of all con-
secutive distance values as candidate thresholds.
Then we determine the number of word-pairs cor-
rectly classified as semantically close or semanti-
cally distant for each candidate threshold, consid-
ering which side of the band they lie as per human
judgments. The candidate threshold with highest
accuracy is chosen as the threshold.
We follow Hirst and St-Onge (1998) in the met-
rics that we use to evaluate real-word spelling cor-
rection; they are listed in Table 3. Suspect ratio
and alarm ratio evaluate the processes of identify-
ing suspects and raising alarms, respectively. De-
tection ratio is the product of the two, and mea-
sures overall performance in detecting the errors.
Correction ratio indicates overall correction per-
formance, and is the “bottom-line” statistic that we
focus on. Values greater than 1 for each of these
ratios indicate results better than random guessing.
The ability of the system to determine the intended
word, given that it has correctly detected an error,
is indicated by the correction accuracy (0 to 1).
</bodyText>
<equation confidence="0.373793">
correction ratio =
</equation>
<page confidence="0.994338">
40
</page>
<tableCaption confidence="0.996774333333333">
Table 4: Real-word error correction using distributional word-distance (Distribword), distributional
concept-distance (Distribconcept), and Hirst and Budanitsky’s (2005) results using WordNet-based
concept-distance measures (WNetconcept). Best results for each measure-type are shown in boldface.
</tableCaption>
<table confidence="0.999898166666667">
Measure suspect alarm detection correction correction detection F correction
ratio ratio ratio accuracy ratio P R performance
Distribword
ASDcp 3.36 1.78 5.98 0.84 5.03 7.37 45.53 12.69 10.66
Coscp 2.91 1.64 4.77 0.85 4.06 5.97 37.15 10.28 8.74
JSDcp 3.29 1.77 5.82 0.83 4.88 7.19 44.32 12.37 10.27
Linpmi 3.63 2.15 7.78 0.84 6.52 9.38 58.38 16.16 13.57
Distribconcept
ASDcp 4.11 2.54 10.43 0.91 9.49 12.19 25.28 16.44 14.96
Coscp 4.00 2.51 10.03 0.90 9.05 11.77 26.99 16.38 14.74
JSDcp 3.58 2.46 8.79 0.90 7.87 10.47 34.66 16.08 14.47
Linpmi 3.02 2.60 7.84 0.88 6.87 9.45 36.86 15.04 13.24
WNetconcept
Hirst–St-Onge 4.24 1.95 8.27 0.93 7.70 9.67 26.33 14.15 13.16
Jiang–Conrath 4.73 2.97 14.02 0.92 12.91 14.33 46.22 21.88 20.13
Leacock–Chodrow 3.23 2.72 8.80 0.83 7.30 11.56 60.33 19.40 16.10
Lin 3.57 2.71 9.70 0.87 8.48 9.56 51.56 16.13 14.03
Resnik 2.58 2.75 7.10 0.78 5.55 9.00 55.00 15.47 12.07
</table>
<bodyText confidence="0.999783557692308">
Notice that the correction ratio is the product of the
detection ratio and correction accuracy. The over-
all (single-point) precision P (no. of true-alarms /
no. of alarms), recall R (no. of true-alarms / no.
of malapropisms), and F-score (2�P�R
P�R ) of detec-
tion are also computed. The product of detection
F-score and correction accuracy, which we will
call correction performance, can also be used as
a bottom-line performance metric.
Table 4 details the performance of Distribword
and Distribconcept measures. For comparison, re-
sults obtained by Hirst and Budanitsky (2005)
with the use of WNetconcept measures are also
shown. Observe that the correction ratio results
for the Distribword measures are poor compared to
Distribconcept measures; the concept-distance mea-
sures are clearly superior, in particular ASDcp and
Coscp. Moreover, if we consider correction ratio to
be the bottom-line statistic, then the Distribconcept
measures outperform all WNetconcept measures ex-
cept the Jiang–Conrath measure. If we con-
sider correction performance to be the bottom-line
statistic, then again we see that the distributional
concept-distance measures outperform the word-
distance measures, except in the case of Linpmi,
which gives slightly poorer results with concept-
distance. Also, in contrast to correction ratio val-
ues, using the Leacock–Chodorow measure results
in relatively higher correction performance values
than the best Distribconcept measures. While it is
clear that the Leacock–Chodorow measure is rela-
tively less accurate in choosing the right spelling-
variant for an alarm (correction accuracy), detec-
tion ratio and detection F-score present contrary
pictures of relative performance in detection. As
correction ratio is determined by the product of
a number of ratios, each evaluating the various
stages of malapropism correction (identifying sus-
pects, raising alarms, and applying the correction),
we believe it is a better indicator of overall per-
formance than correction performance, which is
a not-so-elegant product of an F-score and accu-
racy. However, no matter which of the two is
chosen as the bottom-line performance statistic,
the results show that the newly proposed distri-
butional concept-distance measures are clearly su-
perior to word-distance measures. Further, of all
the WordNet-based measures, only that proposed
by Jiang and Conrath outperforms the best dis-
tributional concept-distance measures consistently
with respect to both bottom-line statistics.
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999461">
Patwardhan and Pedersen (2006) create aggregate
co-occurrence vectors for a WordNet sense by
adding the co-occurrence vectors of the words in
its WordNet gloss. The distance between two
senses is then determined by the cosine of the an-
</bodyText>
<page confidence="0.998033">
41
</page>
<bodyText confidence="0.999984341463415">
gle between their aggregate vectors. However, as
we pointed out in Mohammad and Hirst (2005),
such aggregate co-occurrence vectors are expected
to be noisy because they are created from data that
is not sense-annotated. Therefore, we employed
simple word sense disambiguation and bootstrap-
ping techniques on our base WCCM to create
more-accurate co-occurrence vectors, which gave
markedly higher accuracies in the task of deter-
mining word sense dominance. In the exper-
iments described in this paper, we used these
bootstrapped co-occurrence vectors to determine
concept-distance.
Pantel (2005) also provides a way to create
co-occurrence vectors for WordNet senses. The
lexical co-occurrence vectors of words in a leaf
node are propagated up the WordNet hierarchy.
A parent node inherits those co-occurrences that
are shared by its children. Lastly, co-occurrences
not pertaining to the leaf nodes are removed from
its vector. Even though the methodology at-
tempts at associating a WordNet node or sense
with only those co-occurrences that pertain to it,
no attempt is made at correcting the frequency
counts. After all, word]–word2 co-occurrence fre-
quency (or association) is likely not the same as
SENSE1–word2 co-occurrence frequency (or asso-
ciation), simply because word] may have senses
other than SENSE1, as well. The co-occurrence
frequency of a parent is the weighted sum of co-
occurrence frequencies of its children. The fre-
quencies of the child nodes are used as weights.
Sense ambiguity issues apart, this is still prob-
lematic because a parent concept (say, BIRD) may
co-occur much more frequently (or infrequently)
with a word than its children (such as, hen, ar-
chaeopteryx, aquatic bird, trogon, and others). In
contrast, the bootstrapped WCCM we use not only
identifies which words co-occur with which con-
cepts, but also has more sophisticated estimates of
the co-occurrence frequencies.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999990915254237">
We have proposed a framework that allows dis-
tributional measures to estimate concept-distance
using a published thesaurus and raw text. We
evaluated them in comparison with traditional dis-
tributional word-distance measures and WordNet-
based measures through their ability in ranking
word-pairs in order of their human-judged linguis-
tic distance, and in correcting real-word spelling
errors. We showed that distributional concept-
distance measures outperformed word-distance
measures in both tasks. They do not perform
as well as the best WordNet-based measures in
ranking a small set of word pairs, but in the task
of correcting real-word spelling errors, they beat
all WordNet-based measures except for Jiang-
Conrath (which is markedly better) and Leacock-
Chodorow (which is slightly better if we consider
correction performance as the bottom-line statis-
tic, but slightly worse if we rely on correction
ratio). It should be noted that the Rubenstein
and Goodenough word-pairs used in the ranking
task, as well as all the real-word spelling errors
in the correction task are nouns. We expect that
the WordNet-based measures will perform poorly
when other parts of speech are involved, as those
hierarchies of WordNet are not as extensively de-
veloped. On the other hand, our DPC-based mea-
sures do not rely on any hierarchies (even if they
exist in a thesaurus) but on sets of words that un-
ambiguously represent each sense. Further, be-
cause our measures are tied closely to the corpus
from which co-occurrence counts are made, we
expect the use of domain-specific corpora to result
in even better results.
All the distributional measures that we have
considered in this paper are lexical—that is, the
distributional profiles of the target word or con-
cept are based on their co-occurrence with words
in a text. By contrast, semantic DPs would be
based on information such as what concepts usu-
ally co-occur with the target word or concept. Se-
mantic profiles of words can be obtained from
the WCCM itself (using the row entry for the
word). It would be interesting to see how distri-
butional measures of word-distance that use these
semantic DPs of words perform. We also intend
to explore the use of semantic DPs of concepts
acquired from a concept–concept co-occurrence
matrix (CCCM). A CCCM can be created from
the WCCM by setting the row entry for a concept
or category to be the average of WCCM row val-
ues for all the words pertaining to it.
Both DPW- and WordNet-based measures have
large space and time requirements for pre-
computing and storing all possible distance val-
ues for a language. However, by using the cate-
gories of a thesaurus as very coarse concepts, pre-
computing and storing all possible distance values
for our DPC-based measures requires a matrix of
</bodyText>
<page confidence="0.996993">
42
</page>
<bodyText confidence="0.999978777777778">
size only about 800 x 800. This level of concept-
coarseness might seem drastic at first glance, but
we have shown that distributional measures of dis-
tance between these coarse concepts are quite use-
ful. Part of our future work will be to try an inter-
mediate degree of coarseness (still much coarser
than WordNet) by using the paragraph subdivi-
sions of the thesaurus instead of its categories to
see if this gives even better results.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999894125">
We thank Afsaneh Fazly, Siddharth Patwardhan,
and the CL group at the University of Toronto
for their valuable feedback. We thank Alex Bu-
danitsky for helping us adapt his malapropism-
correction software to work with distributional
measures. This research is financially supported
by the Natural Sciences and Engineering Research
Council of Canada and the University of Toronto.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999851688888889">
Eneko Agirre and O. Lopez de Lacalle Lekuona. 2003.
Clustering WordNet word senses. In Proceedings of
the Conference on Recent Advances in Natural Lan-
guage Processing (RANLP’03), Bulgaria.
J.R.L. Bernard, editor. 1986. The Macquarie The-
saurus. Macquarie Library, Sydney, Australia.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating WordNet-based measures of semantic dis-
tance. Computational Linguistics, 32(1).
Kenneth Church and Patrick Hanks. 1990. Word asso-
ciation norms, mutual information and lexicography.
Computational Linguistics, 16(1):22–29.
Martin C. Cooper. 2005. A mathematical model
of historical semantics and the grouping of word
meanings into concepts. Computational Linguistics,
31(2):227–248.
John R. Firth. 1957. A synopsis of linguistic theory
1930–55. In Studies in Linguistic Analysis (special
volume ofthe Philological Society), pages 1–32, Ox-
ford. The Philological Society.
Graeme Hirst and Alexander Budanitsky. 2005. Cor-
recting real-word spelling errors by restoring lex-
ical cohesion. Natural Language Engineering,
11(1):87–111.
Graeme Hirst and David St-Onge. 1998. Lexical
chains as representations of context for the detec-
tion and correction of malapropisms. In Christiane
Fellbaum, editor, WordNet: An Electronic Lexical
Database, chapter 13, pages 305–332. The MIT
Press, Cambridge, MA.
Jay J. Jiang and David W. Conrath. 1997. Seman-
tic similarity based on corpus statistics and lexical
taxonomy. In Proceedings of International Con-
ference on Research on Computational Linguistics
(ROCLING X), Taiwan.
Claudia Leacock and Martin Chodorow. 1998. Com-
bining local context and WordNet similarity for
word sense identification. In Christiane Fellbaum,
editor, WordNet: An Electronic Lexical Database,
chapter 11, pages 265–283. The MIT Press, Cam-
bridge, MA.
Lillian Lee. 2001. On the effectiveness of the skew
divergence for statistical language analysis. In Arti-
fzcialIntelligence and Statistics 2001, pages 65–72.
Dekang Lin. 1998. Automatic retreival and clustering
of similar words. In Proceedings of the 17th Inter-
national Conference on Computational Linguistics
(COLING-98), pages 768–773, Montreal, Canada.
Saif Mohammad and Graeme Hirst. 2005.
Distributional measures as proxies for
semantic relatedness. In submission,
http://www.cs.toronto.edu/compling/Publications.
Saif Mohammad and Graeme Hirst. 2006. Determin-
ing word sense dominance using a thesaurus. In
Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL), Trento, Italy.
Patrick Pantel. 2005. Inducing ontological co-
occurrence vectors. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL-05), pages 125–132, Ann Arbor,
Michigan.
Siddharth Patwardhan and Ted Pedersen. 2006. Us-
ing WordNet based context vectors to estimate the
semantic relatedness of concepts. In Proceedings of
the EACL 2006 Workshop Making Sense of Sense—
Bringing Computational Linguistics and Psycholin-
guistics Together, pages 1–8, Trento, Italy.
Roy Rada, Hafedh Mili, Ellen Bicknell, and Maria
Blettner. 1989. Development and application of a
metric on semantic nets. IEEE Transactions on Sys-
tems, Man, and Cybernetics, 19(1):17–30.
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual correlates of synonymy. Communica-
tions of the ACM, 8(10):627–633.
Hinrich Sch¨utze and Jan O. Pedersen. 1997. A
cooccurrence-based thesaurus and two applications
to information retreival. Information Processing
and Management, 33(3):307–318.
David Yarowsky. 1992. Word-sense disambiguation
using statistical models of Roget’s categories trained
on large corpora. In Proceedings of the 14th Inter-
national Conference on Computational Linguistics
(COLING-92), pages 454–460, Nantes, France.
Sen Yoshida, Takashi Yukawa, and Kazuhiro
Kuwabara. 2003. Constructing and examin-
ing personalized cooccurrence-based thesauri on
web pages. In Proceedings of the 12th Interna-
tional World Wide Web Conference, pages 20–24,
Budapest, Hungary.
</reference>
<page confidence="0.999833">
43
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9981795">Distributional Measures of A Task-oriented Evaluation</title>
<author confidence="0.978076">Saif Mohammad</author>
<author confidence="0.978076">Graeme</author>
<affiliation confidence="0.999645">Department of Computer University of</affiliation>
<address confidence="0.951345">Toronto, ON M5S 3G4,</address>
<abstract confidence="0.997054743083004">We propose a framework to derive the distance between concepts from distributional measures of word co-occurrences. We use the categories in a published thesaurus as coarse-grained concepts, allowing all possible distance values to be stored in a concept–concept matrix roughly .01% the size of that created by existing measures. We show that the newly proposed concept-distance measures outperform traditional distributional word-distance measures in the tasks of (1) ranking word pairs in order of semantic distance, and (2) correcting realword spelling errors. In the latter task, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional conceptdistance measures. 1 Semantic and distributional measures Measures of distance of meaning are of two kinds. first kind, which we will refer to as semanrely on the structure of a resource such as WordNet or, in some cases, a semantic network, and hence they measure the distance between the concepts or word-senses that the nodes of the resource represent. Examples include the measure for MeSH proposed by Rada et al. (1989) and those for WordNet proposed by Leacock and Chodorow (1998) and Jiang and Conrath (1997). (Some of the more successful measures, such as Jiang–Conrath, also use information content derived from word frequency.) Typically, these measures rely on an extensive hierarchy of hyponymy relationships for nouns. Therefore, these measures are expected to perform poorly when used to estimate distance between senses of part-of-speech pairs other than noun–noun, not just because the WordNet hierarchies for other parts of speech are less well developed, but also because the hierarchies for the different parts of speech are not well connected. The second kind of measures, which we will to as are inspired by the maxim “You shall know a word by the company it keeps” (Firth, 1957). These measures rely simply on raw text, and hence are much less resource-hungry than the semantic measures; but they measure the distance between words rather than word-senses or concepts. In these measures, two words are considered close if they occur in similar contexts. The context (or “company”) of target word is represented by its which lists the strength of association between the target and each of the lexical, syntactic, and/or semantic units that co-occur with Commonly used of strength of asconditional probability (0 to 1) and mutual information Commonly used units of co-occurrence with the target other and so we speak of the disprofile of a word (lexical The co-occurring words may be all those in a predetermined window around the target, or may be reto those that have a certain syntactic or semantic relation with the target word. We will refer to the kind of DPs as Usually in our experiments, we set negative PMI values to 0, because Church and Hanks (1990), in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus. 35 of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP pages 35–43, July 2006. Association for Computational Linguistics Table 1: Measures of DP distance and measures of strength of association. DP distance Strength of association divergence conditional probability cosine pointwise mutual information Jensen–Shannon divergence Lin the latter case, separate association values are calculated for each of the different relations between the target and the co-occurring units. We will refer such DPs as Typical relation-free DPs are those of Sch¨utze and Pedersen (1997) and Yoshida et al. (2003). Typical relation-constrained DPs are those of Lin (1998) and Lee (2001). Below are contrived, plausible, examples of each for the word the numbers are conditional probabilities. relation-free DP ... relation-constrained DP noun–qualifying ... The distance between two words, given their is calculated using a of DP dissuch as cosine. While any of the measures of DP distance may be used with any of the measures of strength of association (see Table 1), practice divergence (ASD), cosine, and Jensen–Shannon divergence (JSD) are used with conditional probability (CP), whereas Lin is used with PMI, resulting in the distributional measures 2001), (Sch¨utze and Pedersen, and (Lin, 1998), respectively. a modification of Kullback-Leibler divergence that overcomes the latter’s problem of division by zero, which can be caused by data sparseis another relative entropy–based (like but it is symmetric. are distance measures that give scores between 0 (identical) and infinity (maximally disandare similarity measures that give scores between 0 (maximally distant) and 1 (identical). See Mohammad and Hirst (2005) for a detailed study of these and other measures. 2 The distributional hypothesis and its limitations The distributional hypothesis (Firth, 1957) states that words that occur in similar contexts tend to be semantically similar. It is often suggested, therefore, that a distributional measure can act as a a semantic measure: the distance between the DPs of words will approximate the distance between their senses. But when words have more than one sense, it is not at all clear what semantic distance between them actually means. A word in each of its senses is likely to co-occur different sets of words. For example, in the ‘financial institution’ sense is likely to cowith money, accounts, so on, whereas the ‘river bank’ sense might have words as erosion, it. If we define the distance between two words, at least one of which is ambiguous, to be the closest distance between some sense of one and some sense of the other, then distributional distance between words may indeed be used in place of semantic distance between concepts. However, because measures of distributional distance depend on occurrences of the target word in all its senses, this substitution is inaccurate. For example, observe that both DPWs have words that co-occur with its ‘throbbing arteries’ sense and words that co-occur with its ‘edible seed’ sense. Relation-free DPs of its two separate senses might be as follows: arteries’: ... seeds’: (.14), . . . Thus, it is clear that different senses of a word have different distributional profiles (“different company”). Using a single DP for the word will mean the union of those profiles. While this might be useful for certain applications, we believe that in a number of tasks (including estimating linguistic distance), acquiring different DPs for the different senses is not only more intuitive, but also, as we will show through experiments in Section 5, useful. We argue that proof senses or concepts (DPCs) be used to infer semantic properties of the senses: “You shall know a sense by the company it keeps.” 36 3 Conceptual grain size and storage requirements As applications for linguistic distance become more sophisticated and demanding, it becomes attractive to pre-compute and store the distance values between all possible pairs of words or senses. But both kinds of measures have large space requirements to do this, requiring matrices of size where the size of the vocabulary (perhaps 100,000 for most languages) in the case of distributional measures and the number of senses (75,000 just for nouns in WordNet) in the case of semantic measures. It is generally accepted, however, that WordNet senses are far too fine-grained (Agirre and Lopez de Lacalle Lekuona (2003) and citations therein). the other hand, published thesauri, such as Rogroup near-synonymous and semantically related words into a relatively small of between 800 and 1100—that roughly correspond to very coarse concepts or senses (Yarowsky, 1992). Words with more than one sense are listed in more than one category. A published thesaurus thus provides us with a very coarse human-developed set or invenof senses that are more intuitive and discernible than the “concepts” generated by dimensionality-reduction methods such as latent semantic analysis. Using coarse senses from a known inventory means that the senses can be represented unambiguously by a large number of possibly ambiguous words (conveniently available in the thesaurus)—a feature that we exploited in our earlier work (Mohammad and Hirst, 2006) to determine useful estimates of the strength of association between a concept and co-occurring words. In this paper, we go one step further and use the idea of a very coarse sense inventory to develop a framework for distributional measures of concepts that can more naturally and more accurately be used in place of semantic measures word senses. We use the The- 1986) as a sense inventory and repository of words pertaining to each sense. It has 812 categories with around 176,000 word tokens and 98,000 word types. This allows us to have smaller distance matrisize just 812 (roughly .01% the size use the terms This is in contrast to studies, such as that of Cooper (2005), that attempt to make a principled distinction between them. of matrices required by existing measures). We evaluate our distributional concept-distance measures on two tasks: ranking word pairs in order of their semantic distance, and correcting realword spelling errors. We compare performance with distributional word-distance measures and the WordNet-based concept-distance measures. 4 Distributional measures of concept-distance 4.1 Capturing distributional profiles of concepts use relation-free DPWs and DPCs—in our experiments, as they allow determination of semantic properties of the target from just its co-occurring words. Determining lexical DPWs simply involves making word–word co-occurrence counts in a corpus. A direct method to determine lexical DPCs, on the other hand, requires information about which words occur with which concepts. This means that the text from which counts are made has to be sense annotated. Since existing labeled data is minimal and manual annotation is far too expensive, indirect means must be used. In an earlier paper (Mohammad and Hirst, 2006), we showed how this can be done with simple word sense disambiguation and bootstrapping techniques. Here, we summarize the method. we create a comatrix (WCCM) the Corpus (BNC) the The WCCM has the following form:</abstract>
<degree confidence="0.6793556"></degree>
<abstract confidence="0.977475112244899">cell corresponding to word catecontains the number of times a window of words in the corpus) with of the words listed under category the Intuitively, the cell captures the of times A contingency table for a single word and single category can be created by simply collapsing all other rows and columns into one and summing their frequencies. Applying a suitable statistic, such as odds 37 BNC BNC Thesaurus matrix word–word co-occurrence counting matrix co-occurrence counting bootstrapping and sense disambiguation distributional measures distributional measures relatedness of relatedness of Figure 1: Distributional word-distance. Figure 2: Distributional concept-distance. ratio, on the contingency table gives the strength of association between a concept (category) and co-occurring word. Therefore, the WCCM can be used to create the lexical DP for any concept. The matrix that is created after one pass of the which we call the although noisy (as it is created from raw text and not senseannotated data), captures strong associations between categories and co-occurring words. Therefore the intended sense (thesaurus category) of a word in the corpus can now be determined using frequencies of co-occurring words and its various as evidence. A new WCCM is created, after a second pass of the corpus, in the cell contains the number of times word used in sense with We have shown (Mohammad and Hirst, 2006) that the bootstrapped WCCM captures word–category cooccurrences much more accurately than the base WCCM, using the task of determining word sense as a test bed. 4.2 Applying distributional measures to DPCs Recall that in computing distributional worddistance, we consider two target words to be distributionally similar (less distant) if they occur in similar contexts. The contexts are represented by the DPs of the target words, where a DP gives the strength of association between the target and the co-occurring units. A distributional measure uses a measure of DP distance to determine the distance between two DPs and thereby between the two target words (see Figure 1). The various measures differ in what statistic they use to calculate the of association and the measure of DP disresults were achieved in the task of determining predominant senses of 27 words in 11 target texts with a wide range of sense distributions over their two most dominant senses. tance they use (see Mohammad and Hirst (2005) for details). For example, following is the cosine for distance between words using relation-free lexical DPWs, with conditional probability of the co-occurring word given the target as the strength of association: = the set of words that co-occur with x a pre-determined window. order to calculate distributional conceptconsider the same scenario, except that the targets are now senses or concepts. Two concepts are closer if their DPs are similar, and these DPCs require the strength of association between target their co-occurring words. The associations can be estimated from the bootstrapped WCCM, described in Section 4.1 above. Any of the distributional measures used for DPWs can now be used to estimate concept-distance with DPCs. Figure 2 illustrates our methodology. Below is the formula for cosine with conditional probabilities when applied to concepts: = the set of words that co-occur with x a pre-determined window. We will refer to such measures as distributional of concept-distance in contrast to the earlier-described distribumeasures of word-distance and WordNet-based (or semantic) measures of We shall refer 38 to these three kinds of distance measures as Individual measures in each kind be referred to simply as A distributional measure of concept-distance be used to populate a small 812 distance matrix a cell pertaining to concepts contains the distance between the two concepts. In contrast, a word–word distance matrix for a conservative vocabulary of 100,000 word types will have size 100,000 and a WordNet-based concept–concept distance matrix will have a size just for nouns. Our conceptconcept distance matrix is roughly .01% the size of these matrices. Note that the DPs we are using are relation-free because (1) we use all co-occurring words (not just those that are related to the target by certain syntactic or semantic relations) and (2) the WCCM, as described in Section 4.1, does not maintain separate counts for the different relations between the target and co-occurring words. Creating a larger matrix with separate counts for the different relawould lead to 5 Evaluation To evaluate the distributional concept-distance measures, we used them in the tasks of ranking word pairs in order of their semantic distance and of correcting real-word spelling errors, and compared our results to those that we obtained on the same tasks with distributional word-distance measures and those that Budanitsky and Hirst (2006) obtained with WordNet-based semantic measures. The distributional concept-distance measures a bootstrapped WCCM created from the the The word-distance measures used a word–word co-occurrence matrix from the The not lemmatized, part of speech tagged, or chunked. The vocabulary was restricted to the words present in the thesaurus (about 98,000 word types) both to provide a level evaluation platform and to keep the matrix to a manageable size. Co-occurrence counts less than 5 were reset to 0, and words that co-occurred with more than 2000 other words stoplisted (543 in all). We used and populate corresponding concept–concept distance matrices and Lin (1998) used relation-constrained DPs, in our experiments all DPs are relation-free. Table 2: Correlation of distributional measures with human ranking. Best results for each measure-type are shown in boldface. Measure Measure-type closest average .45 .60 .54 .69 .42 .48 .61 .52 .71 .59 word–word distance matrices. Applications that require distance values will enjoy a run-time benefit if the distances are precomputed. While it is easy to completely populate the concept–concept co-occurrence matrix, completely populating the word–word distance matrix is a non-trivial task beof memory and time 5.1 Ranking word pairs A direct approach to evaluating linguistic distance measures is to determine how close they are to human judgment and intuition. Given a set of word-pairs, humans can rank them in order of their distance—placing near-synonyms on one end of the ranking and unrelated pairs on the other. Rubenstein and Goodenough (1965) provide a “gold-standard” list of 65 human-ranked word-pairs (based on the responses of 51 subjects). One automatic word-distance estimator, then, is deemed to be more accurate than another if its ranking of word-pairs correlates more closely with this human ranking. Measures of conceptdistance can perform this task by determining word-distance for each word-pair by finding the concept-distance between all pairs of senses of the two words, and choosing the distance of the closest sense pair. This is based on the assumption that when humans are asked to judge the semantic distance between a pair of words, they implicitly consider its closest senses. For example, most people agree that semantically related, even though both have multiple senses— most of which are unrelated. Alternatively, the method could take the average of the distance of all pairs of senses. we wanted to perform experiments with both concept–concept and word–word distance matrices, we populated them as and when new distance values were calculated. 39 Table 3: Hirst and St-Onge metrics for evaluation of real-word spelling correction. ratio no. of ratio no. of of no. of non-malaps no. of true-alarms no. of true-suspects no. of false-alarms no. of false-suspects ratio no. of true-alarms no. of no. of no. of non-malaps corrected no. of no. of false-alarms no. of non-malaps accuracy of correctedmalaps no. of true-alarms Table 2 lists correlations of human rankwith those created using distributional mea- Observe that give markedly higher correlation values than Also, using the distance of closest sense pair (for andgives much better results than using the average distance of all relevant sense pairs. (We do not report distance for andbecause they give very large distance values when sensepairs are unrelated—values that dominate the averages, overwhelming the others, and making the results meaningless.) These correlations are, however, notably lower than those obtained by the best WordNet-based measures (not shown in the table), which fall in the range .78 to .84 (Budanitsky and Hirst, 2006). 5.2 Real-word spelling error correction The set of Rubenstein and Goodenough word pairs is much too small to safely assume that measures that work well on them do so for the entire English vocabulary. Consequently, semantic measures have traditionally been evaluated through applications that use them, such as the work by Hirst Budanitsky (2005) on correcting errors If a word in a text is not “semantically close” to any other in its context, then it is considered a sus- If the suspect has a spelling-variant that close” to a word in its context, then the suspect is declared a probable real-word error and an is raised; the related is considered its Hirst and Budanitsky tested the method on 500 articles the 1987–89 Street Journal for their experiments, replacing every 200th word by a spelling-variant. We adopt this method and this test data, but whereas Hirst and Budanitsky used WordNet-based semantic measures, we use distrimeasures and In order to determine whether two words are “semantically close” or not as per any measure distance, a be set. If the distance between two words is less than the threshold, they will be considered Hirst and Budanitsky (2005) pointed out that there is a notably wide band between 1.83 and 2.36 (on a scale of 0–4), such that all Rubenstein and Goodenough word pairs were assigned values either higher than 2.36 or lower than 1.83 by human subjects. They argue that somewhere within this band is a suitable threshold between semantically close and semantically distant, and therefore set thresholds for the WordNet-based measures such that there was maximum overlap in what the measures and human judgments considered semantically close and distant. Following this idea, we use an automatic method to determine thresholds the various andmeasures. Given a list of Rubenstein and Goodenough word pairs ordered according to a distance measure, we repeatedly consider the mean of all condistance values as Then we determine the number of word-pairs correctly classified as semantically close or semantically distant for each candidate threshold, considering which side of the band they lie as per human judgments. The candidate threshold with highest accuracy is chosen as the threshold. We follow Hirst and St-Onge (1998) in the metrics that we use to evaluate real-word spelling corthey are listed in Table 3. ratio ratio the processes of identifysuspects and raising alarms, respectively. Deratio the product of the two, and measures overall performance in detecting the errors. ratio overall correction performance, and is the “bottom-line” statistic that we focus on. Values greater than 1 for each of these ratios indicate results better than random guessing. The ability of the system to determine the intended word, given that it has correctly detected an error, indicated by the accuracy to 1). ratio 40 4: Real-word error correction using distributional word-distance distributional and Hirst and Budanitsky’s (2005) results using WordNet-based measures Best results for each measure-type are shown in boldface. Measure suspect ratio alarm ratio detection correction accuracy correction detection F correction performance ratio ratio P R 3.36 1.78 5.98 0.84 5.03 7.37 45.53 12.69 10.66 2.91 1.64 4.77 0.85 4.06 5.97 37.15 10.28 8.74 3.29 1.77 5.82 0.83 4.88 7.19 44.32 12.37 10.27 3.63 2.15 7.78 0.84 6.52 9.38 58.38 16.16 13.57 4.11 2.54 10.43 0.91 9.49 12.19 25.28 16.44 14.96 4.00 2.51 10.03 0.90 9.05 11.77 26.99 16.38 14.74 3.58 2.46 8.79 0.90 7.87 10.47 34.66 16.08 14.47 3.02 2.60 7.84 0.88 6.87 9.45 36.86 15.04 13.24 Hirst–St-Onge 4.24 1.95 8.27 0.93 7.70 9.67 26.33 14.15 13.16 Jiang–Conrath 4.73 2.97 14.02 0.92 12.91 14.33 46.22 21.88 20.13 Leacock–Chodrow 3.23 2.72 8.80 0.83 7.30 11.56 60.33 19.40 16.10 Lin 3.57 2.71 9.70 0.87 8.48 9.56 51.56 16.13 14.03 Resnik 2.58 2.75 7.10 0.78 5.55 9.00 55.00 15.47 12.07 Notice that the correction ratio is the product of the detection ratio and correction accuracy. The over- (single-point) precision of true-alarms / of alarms), recall of true-alarms / no. malapropisms), and of detection are also computed. The product of detection and correction accuracy, which we will can also be used as a bottom-line performance metric. 4 details the performance of measures. For comparison, results obtained by Hirst and Budanitsky (2005) the use of measures are also shown. Observe that the correction ratio results the measures are poor compared to the concept-distance meaare clearly superior, in particular and Moreover, if we consider correction ratio to the bottom-line statistic, then the outperform all measures except the Jiang–Conrath measure. If we consider correction performance to be the bottom-line statistic, then again we see that the distributional concept-distance measures outperform the wordmeasures, except in the case of which gives slightly poorer results with conceptdistance. Also, in contrast to correction ratio values, using the Leacock–Chodorow measure results in relatively higher correction performance values the best measures. While it is clear that the Leacock–Chodorow measure is relatively less accurate in choosing the right spellingvariant for an alarm (correction accuracy), detecratio and detection present contrary pictures of relative performance in detection. As correction ratio is determined by the product of a number of ratios, each evaluating the various stages of malapropism correction (identifying suspects, raising alarms, and applying the correction), we believe it is a better indicator of overall performance than correction performance, which is not-so-elegant product of an and accuracy. However, no matter which of the two is chosen as the bottom-line performance statistic, the results show that the newly proposed distributional concept-distance measures are clearly superior to word-distance measures. Further, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional concept-distance measures consistently with respect to both bottom-line statistics. 6 Related Work and Pedersen (2006) create vectors a WordNet sense by adding the co-occurrence vectors of the words in its WordNet gloss. The distance between two is then determined by the cosine of the an- 41 gle between their aggregate vectors. However, as we pointed out in Mohammad and Hirst (2005), such aggregate co-occurrence vectors are expected to be noisy because they are created from data that is not sense-annotated. Therefore, we employed simple word sense disambiguation and bootstrapping techniques on our base WCCM to create more-accurate co-occurrence vectors, which gave markedly higher accuracies in the task of determining word sense dominance. In the experiments described in this paper, we used these bootstrapped co-occurrence vectors to determine concept-distance. Pantel (2005) also provides a way to create co-occurrence vectors for WordNet senses. The lexical co-occurrence vectors of words in a leaf node are propagated up the WordNet hierarchy. A parent node inherits those co-occurrences that are shared by its children. Lastly, co-occurrences not pertaining to the leaf nodes are removed from its vector. Even though the methodology attempts at associating a WordNet node or sense with only those co-occurrences that pertain to it, no attempt is made at correcting the frequency After all, frequency (or association) is likely not the same as frequency (or assosimply because have senses than as well. The co-occurrence frequency of a parent is the weighted sum of cooccurrence frequencies of its children. The frequencies of the child nodes are used as weights. Sense ambiguity issues apart, this is still probbecause a parent concept (say, may co-occur much more frequently (or infrequently) a word than its children (such as, araquatic bird, trogon, others). In contrast, the bootstrapped WCCM we use not only identifies which words co-occur with which concepts, but also has more sophisticated estimates of the co-occurrence frequencies. 7 Conclusion We have proposed a framework that allows distributional measures to estimate concept-distance using a published thesaurus and raw text. We evaluated them in comparison with traditional distributional word-distance measures and WordNetbased measures through their ability in ranking word-pairs in order of their human-judged linguistic distance, and in correcting real-word spelling errors. We showed that distributional conceptdistance measures outperformed word-distance measures in both tasks. They do not perform as well as the best WordNet-based measures in ranking a small set of word pairs, but in the task of correcting real-word spelling errors, they beat all WordNet-based measures except for Jiang- Conrath (which is markedly better) and Leacock- Chodorow (which is slightly better if we consider correction performance as the bottom-line statistic, but slightly worse if we rely on correction ratio). It should be noted that the Rubenstein and Goodenough word-pairs used in the ranking task, as well as all the real-word spelling errors in the correction task are nouns. We expect that the WordNet-based measures will perform poorly when other parts of speech are involved, as those hierarchies of WordNet are not as extensively developed. On the other hand, our DPC-based measures do not rely on any hierarchies (even if they exist in a thesaurus) but on sets of words that unambiguously represent each sense. Further, because our measures are tied closely to the corpus from which co-occurrence counts are made, we expect the use of domain-specific corpora to result in even better results. All the distributional measures that we have in this paper are is, the distributional profiles of the target word or concept are based on their co-occurrence with words a text. By contrast, would be based on information such as what concepts usually co-occur with the target word or concept. Semantic profiles of words can be obtained from the WCCM itself (using the row entry for the word). It would be interesting to see how distributional measures of word-distance that use these semantic DPs of words perform. We also intend to explore the use of semantic DPs of concepts from a co-occurrence A CCCM can be created from the WCCM by setting the row entry for a concept or category to be the average of WCCM row values for all the words pertaining to it. Both DPWand WordNet-based measures have large space and time requirements for precomputing and storing all possible distance values for a language. However, by using the categories of a thesaurus as very coarse concepts, precomputing and storing all possible distance values for our DPC-based measures requires a matrix of 42 only about 800 This level of conceptcoarseness might seem drastic at first glance, but we have shown that distributional measures of distance between these coarse concepts are quite useful. Part of our future work will be to try an intermediate degree of coarseness (still much coarser than WordNet) by using the paragraph subdivisions of the thesaurus instead of its categories to see if this gives even better results. Acknowledgments We thank Afsaneh Fazly, Siddharth Patwardhan, and the CL group at the University of Toronto for their valuable feedback. We thank Alex Budanitsky for helping us adapt his malapropismcorrection software to work with distributional measures. This research is financially supported by the Natural Sciences and Engineering Research Council of Canada and the University of Toronto.</abstract>
<note confidence="0.689135875">References Eneko Agirre and O. Lopez de Lacalle Lekuona. 2003. WordNet word senses. In of the Conference on Recent Advances in Natural Lan- Processing Bulgaria. Bernard, editor. 1986. Macquarie The- Macquarie Library, Sydney, Australia. Alexander Budanitsky and Graeme Hirst. 2006. Eval-</note>
<abstract confidence="0.801348409090909">uating WordNet-based measures of semantic dis- 32(1). Kenneth Church and Patrick Hanks. 1990. Word association norms, mutual information and lexicography. 16(1):22–29. Martin C. Cooper. 2005. A mathematical model of historical semantics and the grouping of word into concepts. 31(2):227–248. John R. Firth. 1957. A synopsis of linguistic theory In in Linguistic Analysis (special ofthe Philological pages 1–32, Oxford. The Philological Society. Graeme Hirst and Alexander Budanitsky. 2005. Correcting real-word spelling errors by restoring lexcohesion. Language 11(1):87–111. Graeme Hirst and David St-Onge. 1998. Lexical chains as representations of context for the detection and correction of malapropisms. In Christiane editor, An Electronic Lexical chapter 13, pages 305–332. The MIT</abstract>
<note confidence="0.866696136363636">Press, Cambridge, MA. Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical In of International Conference on Research on Computational Linguistics Taiwan. Claudia Leacock and Martin Chodorow. 1998. Combining local context and WordNet similarity for word sense identification. In Christiane Fellbaum, An Electronic Lexical chapter 11, pages 265–283. The MIT Press, Cambridge, MA. Lillian Lee. 2001. On the effectiveness of the skew for statistical language analysis. In Artiand Statistics pages 65–72. Dekang Lin. 1998. Automatic retreival and clustering similar words. In of the 17th International Conference on Computational Linguistics pages 768–773, Montreal, Canada. Saif Mohammad and Graeme Hirst. 2005. Distributional measures as proxies for relatedness.</note>
<web confidence="0.607395">http://www.cs.toronto.edu/compling/Publications.</web>
<note confidence="0.882386647058823">Saif Mohammad and Graeme Hirst. 2006. Determining word sense dominance using a thesaurus. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Lin- Trento, Italy. Patrick Pantel. 2005. Inducing ontological covectors. In of the 43rd Annual Meeting of the Association for Computational pages 125–132, Ann Arbor, Michigan. Siddharth Patwardhan and Ted Pedersen. 2006. Using WordNet based context vectors to estimate the relatedness of concepts. In of the EACL 2006 Workshop Making Sense of Sense— Bringing Computational Linguistics and Psycholinpages 1–8, Trento, Italy. Roy Rada, Hafedh Mili, Ellen Bicknell, and Maria</note>
<abstract confidence="0.722865461538462">Blettner. 1989. Development and application of a on semantic nets. Transactions on Sys- Man, and 19(1):17–30. Herbert Rubenstein and John B. Goodenough. 1965. correlates of synonymy. Communicaof the 8(10):627–633. Hinrich Sch¨utze and Jan O. Pedersen. 1997. A cooccurrence-based thesaurus and two applications information retreival. Processing 33(3):307–318. David Yarowsky. 1992. Word-sense disambiguation using statistical models of Roget’s categories trained large corpora. In of the 14th Inter-</abstract>
<note confidence="0.836243571428572">national Conference on Computational Linguistics pages 454–460, Nantes, France. Sen Yoshida, Takashi Yukawa, and Kazuhiro Kuwabara. 2003. Constructing and examining personalized cooccurrence-based thesauri on pages. In of the 12th Interna- World Wide Web pages 20–24,</note>
<address confidence="0.961226">Budapest, Hungary.</address>
<intro confidence="0.43828">43</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>O Lopez de Lacalle Lekuona</author>
</authors>
<title>Clustering WordNet word senses.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP’03),</booktitle>
<marker>Agirre, Lekuona, 2003</marker>
<rawString>Eneko Agirre and O. Lopez de Lacalle Lekuona. 2003. Clustering WordNet word senses. In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP’03), Bulgaria.</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>The Macquarie Thesaurus. Macquarie Library,</booktitle>
<editor>J.R.L. Bernard, editor.</editor>
<location>Sydney, Australia.</location>
<marker>1986</marker>
<rawString>J.R.L. Bernard, editor. 1986. The Macquarie Thesaurus. Macquarie Library, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based measures of semantic distance.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="17476" citStr="Budanitsky and Hirst (2006)" startWordPosition="2778" endWordPosition="2781">tions) and (2) the WCCM, as described in Section 4.1, does not maintain separate counts for the different relations between the target and co-occurring words. Creating a larger matrix with separate counts for the different relations would lead to relation-constrained DPs. 5 Evaluation To evaluate the distributional concept-distance measures, we used them in the tasks of ranking word pairs in order of their semantic distance and of correcting real-word spelling errors, and compared our results to those that we obtained on the same tasks with distributional word-distance measures and those that Budanitsky and Hirst (2006) obtained with WordNet-based semantic measures. The distributional concept-distance measures used a bootstrapped WCCM created from the BNC and the Macquarie Thesaurus. The word-distance measures used a word–word co-occurrence matrix created from the BNC alone. The BNC was not lemmatized, part of speech tagged, or chunked. The vocabulary was restricted to the words present in the thesaurus (about 98,000 word types) both to provide a level evaluation platform and to keep the matrix to a manageable size. Co-occurrence counts less than 5 were reset to 0, and words that co-occurred with more than 2</context>
<context position="21605" citStr="Budanitsky and Hirst, 2006" startWordPosition="3425" endWordPosition="3428">r correlation values than Distribword measures. Also, using the distance of the closest sense pair (for Coscp and Linpmi) gives much better results than using the average distance of all relevant sense pairs. (We do not report average distance for ASDcp and JSDcp because they give very large distance values when sensepairs are unrelated—values that dominate the averages, overwhelming the others, and making the results meaningless.) These correlations are, however, notably lower than those obtained by the best WordNet-based measures (not shown in the table), which fall in the range .78 to .84 (Budanitsky and Hirst, 2006). 5.2 Real-word spelling error correction The set of Rubenstein and Goodenough word pairs is much too small to safely assume that measures that work well on them do so for the entire English vocabulary. Consequently, semantic measures have traditionally been evaluated through applications that use them, such as the work by Hirst and Budanitsky (2005) on correcting real-word spelling errors (or malapropisms). If a word in a text is not “semantically close” to any other word in its context, then it is considered a suspect. If the suspect has a spelling-variant that is “semantically close” to a w</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based measures of semantic distance. Computational Linguistics, 32(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="3342" citStr="Church and Hanks (1990)" startWordPosition="533" endWordPosition="536">sociation are conditional probability (0 to 1) and pointwise mutual information (—∞ to ∞)1. Commonly used units of co-occurrence with the target are other words, and so we speak of the lexical distributional profile of a word (lexical DPW). The co-occurring words may be all those in a predetermined window around the target, or may be restricted to those that have a certain syntactic (e.g., verb–object) or semantic (e.g., agent–theme) relation with the target word. We will refer to the former kind of DPs as relation-free. Usually in 1In our experiments, we set negative PMI values to 0, because Church and Hanks (1990), in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus. 35 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 35–43, Sydney, July 2006. c�2006 Association for Computational Linguistics Table 1: Measures of DP distance and measures of strength of association. DP distance Strength of association α-skew divergence conditional probability cosine pointwise mutual information Jensen–Shannon divergence Lin the latter cas</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Church and Patrick Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin C Cooper</author>
</authors>
<title>A mathematical model of historical semantics and the grouping of word meanings into concepts.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="10246" citStr="Cooper (2005)" startWordPosition="1645" endWordPosition="1646">y coarse sense inventory to develop a framework for distributional measures of concepts that can more naturally and more accurately be used in place of semantic measures of word senses. We use the Macquarie Thesaurus (Bernard, 1986) as a sense inventory and repository of words pertaining to each sense. It has 812 categories with around 176,000 word tokens and 98,000 word types. This allows us to have much smaller concept–concept distance matrices of size just 812 x 812 (roughly .01% the size 2We use the terms senses and concepts interchangeably. This is in contrast to studies, such as that of Cooper (2005), that attempt to make a principled distinction between them. of matrices required by existing measures). We evaluate our distributional concept-distance measures on two tasks: ranking word pairs in order of their semantic distance, and correcting realword spelling errors. We compare performance with distributional word-distance measures and the WordNet-based concept-distance measures. 4 Distributional measures of concept-distance 4.1 Capturing distributional profiles of concepts We use relation-free lexical DPs—both DPWs and DPCs—in our experiments, as they allow determination of semantic pro</context>
</contexts>
<marker>Cooper, 2005</marker>
<rawString>Martin C. Cooper. 2005. A mathematical model of historical semantics and the grouping of word meanings into concepts. Computational Linguistics, 31(2):227–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930–55.</title>
<date>1957</date>
<booktitle>In Studies in Linguistic Analysis (special volume ofthe Philological Society),</booktitle>
<pages>1--32</pages>
<publisher>The Philological Society.</publisher>
<location>Oxford.</location>
<contexts>
<context position="2168" citStr="Firth, 1957" startWordPosition="338" endWordPosition="339">m word frequency.) Typically, these measures rely on an extensive hierarchy of hyponymy relationships for nouns. Therefore, these measures are expected to perform poorly when used to estimate distance between senses of part-of-speech pairs other than noun–noun, not just because the WordNet hierarchies for other parts of speech are less well developed, but also because the hierarchies for the different parts of speech are not well connected. The second kind of measures, which we will refer to as distributional measures, are inspired by the maxim “You shall know a word by the company it keeps” (Firth, 1957). These measures rely simply on raw text, and hence are much less resource-hungry than the semantic measures; but they measure the distance between words rather than word-senses or concepts. In these measures, two words are considered close if they occur in similar contexts. The context (or “company”) of a target word is represented by its distributional profile (DP), which lists the strength of association between the target and each of the lexical, syntactic, and/or semantic units that co-occur with it. Commonly used measures of strength of association are conditional probability (0 to 1) an</context>
<context position="5786" citStr="Firth, 1957" startWordPosition="900" endWordPosition="901">fication of Kullback-Leibler divergence that overcomes the latter’s problem of division by zero, which can be caused by data sparseness. JSDcp is another relative entropy–based measure (like ASDcp) but it is symmetric. JSDcp and ASDcp are distance measures that give scores between 0 (identical) and infinity (maximally distant). Linpmi and Coscp are similarity measures that give scores between 0 (maximally distant) and 1 (identical). See Mohammad and Hirst (2005) for a detailed study of these and other measures. 2 The distributional hypothesis and its limitations The distributional hypothesis (Firth, 1957) states that words that occur in similar contexts tend to be semantically similar. It is often suggested, therefore, that a distributional measure can act as a proxy for a semantic measure: the distance between the DPs of words will approximate the distance between their senses. But when words have more than one sense, it is not at all clear what semantic distance between them actually means. A word in each of its senses is likely to co-occur with different sets of words. For example, bank in the ‘financial institution’ sense is likely to cooccur with interest, money, accounts, and so on, wher</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John R. Firth. 1957. A synopsis of linguistic theory 1930–55. In Studies in Linguistic Analysis (special volume ofthe Philological Society), pages 1–32, Oxford. The Philological Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>Alexander Budanitsky</author>
</authors>
<title>Correcting real-word spelling errors by restoring lexical cohesion.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="21957" citStr="Hirst and Budanitsky (2005)" startWordPosition="3483" endWordPosition="3486">ominate the averages, overwhelming the others, and making the results meaningless.) These correlations are, however, notably lower than those obtained by the best WordNet-based measures (not shown in the table), which fall in the range .78 to .84 (Budanitsky and Hirst, 2006). 5.2 Real-word spelling error correction The set of Rubenstein and Goodenough word pairs is much too small to safely assume that measures that work well on them do so for the entire English vocabulary. Consequently, semantic measures have traditionally been evaluated through applications that use them, such as the work by Hirst and Budanitsky (2005) on correcting real-word spelling errors (or malapropisms). If a word in a text is not “semantically close” to any other word in its context, then it is considered a suspect. If the suspect has a spelling-variant that is “semantically close” to a word in its context, then the suspect is declared a probable real-word spelling error and an “alarm” is raised; the related spelling-variant is considered its correction. Hirst and Budanitsky tested the method on 500 articles from the 1987–89 Wall Street Journal corpus for their experiments, replacing every 200th word by a spelling-variant. We adopt t</context>
<context position="26613" citStr="Hirst and Budanitsky (2005)" startWordPosition="4223" endWordPosition="4226">k 2.58 2.75 7.10 0.78 5.55 9.00 55.00 15.47 12.07 Notice that the correction ratio is the product of the detection ratio and correction accuracy. The overall (single-point) precision P (no. of true-alarms / no. of alarms), recall R (no. of true-alarms / no. of malapropisms), and F-score (2�P�R P�R ) of detection are also computed. The product of detection F-score and correction accuracy, which we will call correction performance, can also be used as a bottom-line performance metric. Table 4 details the performance of Distribword and Distribconcept measures. For comparison, results obtained by Hirst and Budanitsky (2005) with the use of WNetconcept measures are also shown. Observe that the correction ratio results for the Distribword measures are poor compared to Distribconcept measures; the concept-distance measures are clearly superior, in particular ASDcp and Coscp. Moreover, if we consider correction ratio to be the bottom-line statistic, then the Distribconcept measures outperform all WNetconcept measures except the Jiang–Conrath measure. If we consider correction performance to be the bottom-line statistic, then again we see that the distributional concept-distance measures outperform the worddistance m</context>
</contexts>
<marker>Hirst, Budanitsky, 2005</marker>
<rawString>Graeme Hirst and Alexander Budanitsky. 2005. Correcting real-word spelling errors by restoring lexical cohesion. Natural Language Engineering, 11(1):87–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, chapter 13,</booktitle>
<pages>305--332</pages>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="24144" citStr="Hirst and St-Onge (1998)" startWordPosition="3835" endWordPosition="3838">ng this idea, we use an automatic method to determine thresholds for the various Distribword and Distribconcept measures. Given a list of Rubenstein and Goodenough word pairs ordered according to a distance measure, we repeatedly consider the mean of all consecutive distance values as candidate thresholds. Then we determine the number of word-pairs correctly classified as semantically close or semantically distant for each candidate threshold, considering which side of the band they lie as per human judgments. The candidate threshold with highest accuracy is chosen as the threshold. We follow Hirst and St-Onge (1998) in the metrics that we use to evaluate real-word spelling correction; they are listed in Table 3. Suspect ratio and alarm ratio evaluate the processes of identifying suspects and raising alarms, respectively. Detection ratio is the product of the two, and measures overall performance in detecting the errors. Correction ratio indicates overall correction performance, and is the “bottom-line” statistic that we focus on. Values greater than 1 for each of these ratios indicate results better than random guessing. The ability of the system to determine the intended word, given that it has correctl</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Graeme Hirst and David St-Onge. 1998. Lexical chains as representations of context for the detection and correction of malapropisms. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, chapter 13, pages 305–332. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of International Conference on Research on Computational Linguistics (ROCLING X),</booktitle>
<contexts>
<context position="1452" citStr="Jiang and Conrath (1997)" startWordPosition="221" endWordPosition="224">asures, only that proposed by Jiang and Conrath outperforms the best distributional conceptdistance measures. 1 Semantic and distributional measures Measures of distance of meaning are of two kinds. The first kind, which we will refer to as semantic measures, rely on the structure of a resource such as WordNet or, in some cases, a semantic network, and hence they measure the distance between the concepts or word-senses that the nodes of the resource represent. Examples include the measure for MeSH proposed by Rada et al. (1989) and those for WordNet proposed by Leacock and Chodorow (1998) and Jiang and Conrath (1997). (Some of the more successful measures, such as Jiang–Conrath, also use information content derived from word frequency.) Typically, these measures rely on an extensive hierarchy of hyponymy relationships for nouns. Therefore, these measures are expected to perform poorly when used to estimate distance between senses of part-of-speech pairs other than noun–noun, not just because the WordNet hierarchies for other parts of speech are less well developed, but also because the hierarchies for the different parts of speech are not well connected. The second kind of measures, which we will refer to</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of International Conference on Research on Computational Linguistics (ROCLING X), Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, chapter 11,</booktitle>
<pages>265--283</pages>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1423" citStr="Leacock and Chodorow (1998)" startWordPosition="216" endWordPosition="219">ask, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional conceptdistance measures. 1 Semantic and distributional measures Measures of distance of meaning are of two kinds. The first kind, which we will refer to as semantic measures, rely on the structure of a resource such as WordNet or, in some cases, a semantic network, and hence they measure the distance between the concepts or word-senses that the nodes of the resource represent. Examples include the measure for MeSH proposed by Rada et al. (1989) and those for WordNet proposed by Leacock and Chodorow (1998) and Jiang and Conrath (1997). (Some of the more successful measures, such as Jiang–Conrath, also use information content derived from word frequency.) Typically, these measures rely on an extensive hierarchy of hyponymy relationships for nouns. Therefore, these measures are expected to perform poorly when used to estimate distance between senses of part-of-speech pairs other than noun–noun, not just because the WordNet hierarchies for other parts of speech are less well developed, but also because the hierarchies for the different parts of speech are not well connected. The second kind of mea</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow. 1998. Combining local context and WordNet similarity for word sense identification. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, chapter 11, pages 265–283. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>On the effectiveness of the skew divergence for statistical language analysis.</title>
<date>2001</date>
<booktitle>In ArtifzcialIntelligence and Statistics</booktitle>
<pages>65--72</pages>
<contexts>
<context position="4288" citStr="Lee (2001)" startWordPosition="673" endWordPosition="674">n for Computational Linguistics Table 1: Measures of DP distance and measures of strength of association. DP distance Strength of association α-skew divergence conditional probability cosine pointwise mutual information Jensen–Shannon divergence Lin the latter case, separate association values are calculated for each of the different relations between the target and the co-occurring units. We will refer to such DPs as relation-constrained. Typical relation-free DPs are those of Sch¨utze and Pedersen (1997) and Yoshida et al. (2003). Typical relation-constrained DPs are those of Lin (1998) and Lee (2001). Below are contrived, but plausible, examples of each for the word pulse; the numbers are conditional probabilities. relation-free DP pulse: beat (.28), racing (.2), grow (.13), beans (.09), heart (.04), ... relation-constrained DP pulse: &lt;beat, subject–verb&gt; (.34), &lt;racing, noun–qualifying adjective&gt; (.22), &lt;grow, subject–verb&gt; (.14), ... The distance between two words, given their DPs, is calculated using a measure of DP distance, such as cosine. While any of the measures of DP distance may be used with any of the measures of strength of association (see Table 1), in practice α-skew diverge</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lillian Lee. 2001. On the effectiveness of the skew divergence for statistical language analysis. In ArtifzcialIntelligence and Statistics 2001, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retreival and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics (COLING-98),</booktitle>
<pages>768--773</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="4273" citStr="Lin (1998)" startWordPosition="670" endWordPosition="671">2006 Association for Computational Linguistics Table 1: Measures of DP distance and measures of strength of association. DP distance Strength of association α-skew divergence conditional probability cosine pointwise mutual information Jensen–Shannon divergence Lin the latter case, separate association values are calculated for each of the different relations between the target and the co-occurring units. We will refer to such DPs as relation-constrained. Typical relation-free DPs are those of Sch¨utze and Pedersen (1997) and Yoshida et al. (2003). Typical relation-constrained DPs are those of Lin (1998) and Lee (2001). Below are contrived, but plausible, examples of each for the word pulse; the numbers are conditional probabilities. relation-free DP pulse: beat (.28), racing (.2), grow (.13), beans (.09), heart (.04), ... relation-constrained DP pulse: &lt;beat, subject–verb&gt; (.34), &lt;racing, noun–qualifying adjective&gt; (.22), &lt;grow, subject–verb&gt; (.14), ... The distance between two words, given their DPs, is calculated using a measure of DP distance, such as cosine. While any of the measures of DP distance may be used with any of the measures of strength of association (see Table 1), in practice</context>
<context position="18257" citStr="Lin (1998)" startWordPosition="2901" endWordPosition="2902"> word-distance measures used a word–word co-occurrence matrix created from the BNC alone. The BNC was not lemmatized, part of speech tagged, or chunked. The vocabulary was restricted to the words present in the thesaurus (about 98,000 word types) both to provide a level evaluation platform and to keep the matrix to a manageable size. Co-occurrence counts less than 5 were reset to 0, and words that co-occurred with more than 2000 other words were stoplisted (543 in all). We used ASDcp (α = 0.99), Coscp, JSDcp, and Linpmi4 to populate corresponding concept–concept distance matrices and 4Whereas Lin (1998) used relation-constrained DPs, in our experiments all DPs are relation-free. Table 2: Correlation of distributional measures with human ranking. Best results for each measure-type are shown in boldface. Measure Measure-type Distribword Distribconcept closest average ASDcp .45 .60 Coscp .54 .69 .42 JSDcp .48 .61 Linpmi .52 .71 .59 word–word distance matrices. Applications that require distance values will enjoy a run-time benefit if the distances are precomputed. While it is easy to completely populate the concept–concept co-occurrence matrix, completely populating the word–word distance matri</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retreival and clustering of similar words. In Proceedings of the 17th International Conference on Computational Linguistics (COLING-98), pages 768–773, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures as proxies for semantic relatedness. In</title>
<date>2005</date>
<note>submission, http://www.cs.toronto.edu/compling/Publications.</note>
<contexts>
<context position="5640" citStr="Mohammad and Hirst (2005)" startWordPosition="877" endWordPosition="880">, resulting in the distributional measures ASDcp (Lee, 2001), Coscp (Sch¨utze and Pedersen, 1997), JSDcp, and Linpmi (Lin, 1998), respectively. ASDcp is a modification of Kullback-Leibler divergence that overcomes the latter’s problem of division by zero, which can be caused by data sparseness. JSDcp is another relative entropy–based measure (like ASDcp) but it is symmetric. JSDcp and ASDcp are distance measures that give scores between 0 (identical) and infinity (maximally distant). Linpmi and Coscp are similarity measures that give scores between 0 (maximally distant) and 1 (identical). See Mohammad and Hirst (2005) for a detailed study of these and other measures. 2 The distributional hypothesis and its limitations The distributional hypothesis (Firth, 1957) states that words that occur in similar contexts tend to be semantically similar. It is often suggested, therefore, that a distributional measure can act as a proxy for a semantic measure: the distance between the DPs of words will approximate the distance between their senses. But when words have more than one sense, it is not at all clear what semantic distance between them actually means. A word in each of its senses is likely to co-occur with di</context>
<context position="14525" citStr="Mohammad and Hirst (2005)" startWordPosition="2324" endWordPosition="2327">the target words, where a DP gives the strength of association between the target and the co-occurring units. A distributional measure uses a measure of DP distance to determine the distance between two DPs and thereby between the two target words (see Figure 1). The various measures differ in what statistic they use to calculate the strength of association and the measure of DP dis3Near-upper-bound results were achieved in the task of determining predominant senses of 27 words in 11 target texts with a wide range of sense distributions over their two most dominant senses. tance they use (see Mohammad and Hirst (2005) for details). For example, following is the cosine formula for distance between words w1 and w2 using relation-free lexical DPWs, with conditional probability of the co-occurring word given the target as the strength of association: Coscp(w1,w2) = ∑ w2C(w1)[C(w2) (P(wjw1) XP(wjw2)) �∑w2C(w1)P(wjw1)2 X�∑w2C(w2)P(wjw2)2 Here, C(x) is the set of words that co-occur with word x within a pre-determined window. In order to calculate distributional conceptdistance, consider the same scenario, except that the targets are now senses or concepts. Two concepts are closer if their DPs are similar, and th</context>
<context position="28864" citStr="Mohammad and Hirst (2005)" startWordPosition="4556" endWordPosition="4559">l concept-distance measures are clearly superior to word-distance measures. Further, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional concept-distance measures consistently with respect to both bottom-line statistics. 6 Related Work Patwardhan and Pedersen (2006) create aggregate co-occurrence vectors for a WordNet sense by adding the co-occurrence vectors of the words in its WordNet gloss. The distance between two senses is then determined by the cosine of the an41 gle between their aggregate vectors. However, as we pointed out in Mohammad and Hirst (2005), such aggregate co-occurrence vectors are expected to be noisy because they are created from data that is not sense-annotated. Therefore, we employed simple word sense disambiguation and bootstrapping techniques on our base WCCM to create more-accurate co-occurrence vectors, which gave markedly higher accuracies in the task of determining word sense dominance. In the experiments described in this paper, we used these bootstrapped co-occurrence vectors to determine concept-distance. Pantel (2005) also provides a way to create co-occurrence vectors for WordNet senses. The lexical co-occurrence </context>
</contexts>
<marker>Mohammad, Hirst, 2005</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2005. Distributional measures as proxies for semantic relatedness. In submission, http://www.cs.toronto.edu/compling/Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Determining word sense dominance using a thesaurus.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="9466" citStr="Mohammad and Hirst, 2006" startWordPosition="1507" endWordPosition="1510">concepts or senses (Yarowsky, 1992). Words with more than one sense are listed in more than one category. A published thesaurus thus provides us with a very coarse human-developed set or inventory of word senses or concepts2 that are more intuitive and discernible than the “concepts” generated by dimensionality-reduction methods such as latent semantic analysis. Using coarse senses from a known inventory means that the senses can be represented unambiguously by a large number of possibly ambiguous words (conveniently available in the thesaurus)—a feature that we exploited in our earlier work (Mohammad and Hirst, 2006) to determine useful estimates of the strength of association between a concept and co-occurring words. In this paper, we go one step further and use the idea of a very coarse sense inventory to develop a framework for distributional measures of concepts that can more naturally and more accurately be used in place of semantic measures of word senses. We use the Macquarie Thesaurus (Bernard, 1986) as a sense inventory and repository of words pertaining to each sense. It has 812 categories with around 176,000 word tokens and 98,000 word types. This allows us to have much smaller concept–concept </context>
<context position="11359" citStr="Mohammad and Hirst, 2006" startWordPosition="1807" endWordPosition="1810">use relation-free lexical DPs—both DPWs and DPCs—in our experiments, as they allow determination of semantic properties of the target from just its co-occurring words. Determining lexical DPWs simply involves making word–word co-occurrence counts in a corpus. A direct method to determine lexical DPCs, on the other hand, requires information about which words occur with which concepts. This means that the text from which counts are made has to be sense annotated. Since existing labeled data is minimal and manual annotation is far too expensive, indirect means must be used. In an earlier paper (Mohammad and Hirst, 2006), we showed how this can be done with simple word sense disambiguation and bootstrapping techniques. Here, we summarize the method. First, we create a word–category cooccurrence matrix (WCCM) using the British National Corpus (BNC) and the Macquarie Thesaurus. The WCCM has the following form: c1 c2 ::: cj ::: w1 m11 m12 ::: m1j ::: w2 m21 m22 ::: m2j ::: ... ... ... .. .:::::: wi mi1 mi2 ::: mij ::: ... ... ... ... ... ... A cell mij, corresponding to word wi and category cj, contains the number of times wi co-occurs (in a window of ±5 words in the corpus) with any of the words listed under ca</context>
<context position="13475" citStr="Mohammad and Hirst, 2006" startWordPosition="2153" endWordPosition="2156">y concept. The matrix that is created after one pass of the corpus, which we call the base WCCM, although noisy (as it is created from raw text and not senseannotated data), captures strong associations between categories and co-occurring words. Therefore the intended sense (thesaurus category) of a word in the corpus can now be determined using frequencies of co-occurring words and its various senses as evidence. A new bootstrapped WCCM is created, after a second pass of the corpus, in which the cell mij contains the number of times any word used in sense cj co-occurs with wi. We have shown (Mohammad and Hirst, 2006) that the bootstrapped WCCM captures word–category cooccurrences much more accurately than the base WCCM, using the task of determining word sense dominance3 as a test bed. 4.2 Applying distributional measures to DPCs Recall that in computing distributional worddistance, we consider two target words to be distributionally similar (less distant) if they occur in similar contexts. The contexts are represented by the DPs of the target words, where a DP gives the strength of association between the target and the co-occurring units. A distributional measure uses a measure of DP distance to determi</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006. Determining word sense dominance using a thesaurus. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Inducing ontological cooccurrence vectors.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05),</booktitle>
<pages>125--132</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="29365" citStr="Pantel (2005)" startWordPosition="4630" endWordPosition="4631"> cosine of the an41 gle between their aggregate vectors. However, as we pointed out in Mohammad and Hirst (2005), such aggregate co-occurrence vectors are expected to be noisy because they are created from data that is not sense-annotated. Therefore, we employed simple word sense disambiguation and bootstrapping techniques on our base WCCM to create more-accurate co-occurrence vectors, which gave markedly higher accuracies in the task of determining word sense dominance. In the experiments described in this paper, we used these bootstrapped co-occurrence vectors to determine concept-distance. Pantel (2005) also provides a way to create co-occurrence vectors for WordNet senses. The lexical co-occurrence vectors of words in a leaf node are propagated up the WordNet hierarchy. A parent node inherits those co-occurrences that are shared by its children. Lastly, co-occurrences not pertaining to the leaf nodes are removed from its vector. Even though the methodology attempts at associating a WordNet node or sense with only those co-occurrences that pertain to it, no attempt is made at correcting the frequency counts. After all, word]–word2 co-occurrence frequency (or association) is likely not the sa</context>
</contexts>
<marker>Pantel, 2005</marker>
<rawString>Patrick Pantel. 2005. Inducing ontological cooccurrence vectors. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05), pages 125–132, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ted Pedersen</author>
</authors>
<title>Using WordNet based context vectors to estimate the semantic relatedness of concepts.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop Making Sense of Sense— Bringing Computational Linguistics and Psycholinguistics Together,</booktitle>
<pages>1--8</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="28564" citStr="Patwardhan and Pedersen (2006)" startWordPosition="4506" endWordPosition="4509">correction), we believe it is a better indicator of overall performance than correction performance, which is a not-so-elegant product of an F-score and accuracy. However, no matter which of the two is chosen as the bottom-line performance statistic, the results show that the newly proposed distributional concept-distance measures are clearly superior to word-distance measures. Further, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional concept-distance measures consistently with respect to both bottom-line statistics. 6 Related Work Patwardhan and Pedersen (2006) create aggregate co-occurrence vectors for a WordNet sense by adding the co-occurrence vectors of the words in its WordNet gloss. The distance between two senses is then determined by the cosine of the an41 gle between their aggregate vectors. However, as we pointed out in Mohammad and Hirst (2005), such aggregate co-occurrence vectors are expected to be noisy because they are created from data that is not sense-annotated. Therefore, we employed simple word sense disambiguation and bootstrapping techniques on our base WCCM to create more-accurate co-occurrence vectors, which gave markedly hig</context>
</contexts>
<marker>Patwardhan, Pedersen, 2006</marker>
<rawString>Siddharth Patwardhan and Ted Pedersen. 2006. Using WordNet based context vectors to estimate the semantic relatedness of concepts. In Proceedings of the EACL 2006 Workshop Making Sense of Sense— Bringing Computational Linguistics and Psycholinguistics Together, pages 1–8, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Rada</author>
<author>Hafedh Mili</author>
<author>Ellen Bicknell</author>
<author>Maria Blettner</author>
</authors>
<title>Development and application of a metric on semantic nets.</title>
<date>1989</date>
<journal>IEEE Transactions on Systems, Man, and Cybernetics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="1361" citStr="Rada et al. (1989)" startWordPosition="206" endWordPosition="209"> correcting realword spelling errors. In the latter task, of all the WordNet-based measures, only that proposed by Jiang and Conrath outperforms the best distributional conceptdistance measures. 1 Semantic and distributional measures Measures of distance of meaning are of two kinds. The first kind, which we will refer to as semantic measures, rely on the structure of a resource such as WordNet or, in some cases, a semantic network, and hence they measure the distance between the concepts or word-senses that the nodes of the resource represent. Examples include the measure for MeSH proposed by Rada et al. (1989) and those for WordNet proposed by Leacock and Chodorow (1998) and Jiang and Conrath (1997). (Some of the more successful measures, such as Jiang–Conrath, also use information content derived from word frequency.) Typically, these measures rely on an extensive hierarchy of hyponymy relationships for nouns. Therefore, these measures are expected to perform poorly when used to estimate distance between senses of part-of-speech pairs other than noun–noun, not just because the WordNet hierarchies for other parts of speech are less well developed, but also because the hierarchies for the different </context>
</contexts>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Roy Rada, Hafedh Mili, Ellen Bicknell, and Maria Blettner. 1989. Development and application of a metric on semantic nets. IEEE Transactions on Systems, Man, and Cybernetics, 19(1):17–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="19263" citStr="Rubenstein and Goodenough (1965)" startWordPosition="3051" endWordPosition="3054"> that require distance values will enjoy a run-time benefit if the distances are precomputed. While it is easy to completely populate the concept–concept co-occurrence matrix, completely populating the word–word distance matrix is a non-trivial task because of memory and time constraints.5 5.1 Ranking word pairs A direct approach to evaluating linguistic distance measures is to determine how close they are to human judgment and intuition. Given a set of word-pairs, humans can rank them in order of their distance—placing near-synonyms on one end of the ranking and unrelated pairs on the other. Rubenstein and Goodenough (1965) provide a “gold-standard” list of 65 human-ranked word-pairs (based on the responses of 51 subjects). One automatic word-distance estimator, then, is deemed to be more accurate than another if its ranking of word-pairs correlates more closely with this human ranking. Measures of conceptdistance can perform this task by determining word-distance for each word-pair by finding the concept-distance between all pairs of senses of the two words, and choosing the distance of the closest sense pair. This is based on the assumption that when humans are asked to judge the semantic distance between a pa</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John B. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
<author>Jan O Pedersen</author>
</authors>
<title>A cooccurrence-based thesaurus and two applications to information retreival.</title>
<date>1997</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>33</volume>
<issue>3</issue>
<marker>Sch¨utze, Pedersen, 1997</marker>
<rawString>Hinrich Sch¨utze and Jan O. Pedersen. 1997. A cooccurrence-based thesaurus and two applications to information retreival. Information Processing and Management, 33(3):307–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92),</booktitle>
<pages>454--460</pages>
<location>Nantes, France.</location>
<contexts>
<context position="8876" citStr="Yarowsky, 1992" startWordPosition="1416" endWordPosition="1417"> size of the vocabulary (perhaps 100,000 for most languages) in the case of distributional measures and the number of senses (75,000 just for nouns in WordNet) in the case of semantic measures. It is generally accepted, however, that WordNet senses are far too fine-grained (Agirre and Lopez de Lacalle Lekuona (2003) and citations therein). On the other hand, published thesauri, such as Roget’s and Macquarie, group near-synonymous and semantically related words into a relatively small number of categories—typically between 800 and 1100—that roughly correspond to very coarse concepts or senses (Yarowsky, 1992). Words with more than one sense are listed in more than one category. A published thesaurus thus provides us with a very coarse human-developed set or inventory of word senses or concepts2 that are more intuitive and discernible than the “concepts” generated by dimensionality-reduction methods such as latent semantic analysis. Using coarse senses from a known inventory means that the senses can be represented unambiguously by a large number of possibly ambiguous words (conveniently available in the thesaurus)—a feature that we exploited in our earlier work (Mohammad and Hirst, 2006) to determ</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>David Yarowsky. 1992. Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora. In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92), pages 454–460, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sen Yoshida</author>
<author>Takashi Yukawa</author>
<author>Kazuhiro Kuwabara</author>
</authors>
<title>Constructing and examining personalized cooccurrence-based thesauri on web pages.</title>
<date>2003</date>
<booktitle>In Proceedings of the 12th International World Wide Web Conference,</booktitle>
<pages>20--24</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="4215" citStr="Yoshida et al. (2003)" startWordPosition="660" endWordPosition="663"> Language Processing (EMNLP 2006), pages 35–43, Sydney, July 2006. c�2006 Association for Computational Linguistics Table 1: Measures of DP distance and measures of strength of association. DP distance Strength of association α-skew divergence conditional probability cosine pointwise mutual information Jensen–Shannon divergence Lin the latter case, separate association values are calculated for each of the different relations between the target and the co-occurring units. We will refer to such DPs as relation-constrained. Typical relation-free DPs are those of Sch¨utze and Pedersen (1997) and Yoshida et al. (2003). Typical relation-constrained DPs are those of Lin (1998) and Lee (2001). Below are contrived, but plausible, examples of each for the word pulse; the numbers are conditional probabilities. relation-free DP pulse: beat (.28), racing (.2), grow (.13), beans (.09), heart (.04), ... relation-constrained DP pulse: &lt;beat, subject–verb&gt; (.34), &lt;racing, noun–qualifying adjective&gt; (.22), &lt;grow, subject–verb&gt; (.14), ... The distance between two words, given their DPs, is calculated using a measure of DP distance, such as cosine. While any of the measures of DP distance may be used with any of the meas</context>
</contexts>
<marker>Yoshida, Yukawa, Kuwabara, 2003</marker>
<rawString>Sen Yoshida, Takashi Yukawa, and Kazuhiro Kuwabara. 2003. Constructing and examining personalized cooccurrence-based thesauri on web pages. In Proceedings of the 12th International World Wide Web Conference, pages 20–24, Budapest, Hungary.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>