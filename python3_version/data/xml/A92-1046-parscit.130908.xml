<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.045133">
<title confidence="0.986376">
The Role of Testing in Grammar Engineering
</title>
<author confidence="0.998907">
Martin Volk
</author>
<affiliation confidence="0.9991185">
University of Koblenz-Landau
Institute of Computational Linguistics
</affiliation>
<address confidence="0.911891">
Rheinau 3-4
5400 Koblenz, Germany
(+49)-261-9119-469
</address>
<email confidence="0.952734">
e-mail volkObrian.uni-koblenz.de
</email>
<sectionHeader confidence="0.999349" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99988675">
In the past grammars have been developed either with an
art approach (building up a coherent system; prescrip-
tive grammars like the Latin grammars of the Middle
Ages) or with a science approach (describing the laws of
nature; descriptive and contrastive grammars). We pro-
pose to regard grammar development in Computational
Linguistics as an engineering task analogous to software
engineerifig: one that requires analysis, specification, im-
plementation, testing, integration and maintenance.
The different phases in the software development pro-
cess correspond to phases in grammar development in
the following way:
</bodyText>
<listItem confidence="0.9327264">
• The problem analysis and definition phase corre-
sponds to an analysis of the linguistic data (texts
of written or spoken language).
• Problem specification means setting up grammar
rules that describe the observed data. The gram-
mar formalism thus provides the formal language
for the specification.
• The implementation phase includes putting the ru-
les into the specific format of the computational
grammar system. This is a computer program to
process a grammar in the framework of a grammar
• theory. The implementation effort decreases the clo-
ser the format of the grammar approaches the for-
mat of the computational system.
• The testing phase comprises checking the grammar
implementation against the linguistic data, i.e. jud-
ging grammaticality and the assigned structure.
• Integration, installation and maintenance are no dif-
ferent in the context of an NLP system than in other
software systems.
</listItem>
<bodyText confidence="0.9939662">
Our project focusses on the testing aspect of the pro-
cess. Testing can never be exhaustive but must be re-
presentative. We therefore propose an archive of test
sentences (hence: ATS) to govern the incremental deve-
lopment and the testing of grammar implementations.
</bodyText>
<subsectionHeader confidence="0.588755">
2 Construction of an ATS
</subsectionHeader>
<bodyText confidence="0.99987424">
Towards the goal of a comprehensive collection of test
sentences we have restricted ourselves to the construc-
tion of an ATS that represents specific syntactic pheno-
mena. The archive aims to be a representative sample
of all syntactic phenomena of a natural language, in our
case German.
The ATS must contain grammatical sentences as well
as ungrammatical strings. The grammatical sentences
are systematically collected by varying one syntactic
phenomenon at a time. E.g. we vary first the subca-
tegory of the verb and then we vary verb tense, etc. For
every phenomenon we have to construct ungrammatical
strings to check against overgeneration by the grammar.
These strings are found by manipulating the plyliome-
non in question in such ways as to make it ungramma-
tical. A syntactic feature must be varied over all values
of its domain. E.g. the feature case in German has the
values nominative, genitive, dative, and accusative. A
noun phrase (NP) that needs to appear in the nomina-
tive in a given sentence will then result in three ungram-
matical strings when the other cases are assigned.
It must be noted that the set of ungrammatical strings
gets very large when it comes to problems such as
word order where the permutation of all the words in
a sentence is necessary to enumerate all possibilities. In
this case we need heuristics to find the most appropriate
test sentences. E.g. in German the order of NPs in
a sentence is variable with certain restrictions whereas
the word order within the NP is relatively fixed. The-
refore we are much more likely to encounter problems
in NP order when setting up our grammar. As a result
we will have to focus on ungrammatical strings with NP
order problems. In contrast to grammatical sentences
ungrammatical strings are only seldom found naturally
(e.g. errors of language learners) and it will be intere-
sting to study whether these occurrences (at least the
most frequent ones) correspond to our constructed ex-
amples.
The judgement of grammatical versus ungrammatical
strings is subjective and has little to say about the ac-
ceptability of a sentence in a real-world communication.
Thus our ATS will model competence rather than per-
formance in the Chomskyan sense.
For the practical use the ATS must be organized in
a modular fashion, enabling the user to adapt and ex-
tend the archive according to his needs and convictions.
Furthermore it must be documented why a sentence has
been entered into the archive, since every sentence dis-
plays a multitude of syntactic information, only some of
which is relevant in our domain.
</bodyText>
<page confidence="0.99006">
257
</page>
<sectionHeader confidence="0.817371" genericHeader="method">
3 Testing with an ATS
</sectionHeader>
<bodyText confidence="0.99998362962963">
The ATS can be useful in many respects. First, it can
govern the development process of a grammar in that it
provides the linguistic data in a concise fashion. Gram-
mar rules can be incrementally constructed to account
for the given sentences. Organizing the ATS around syn-
tactic phenomena of increasing complexity supports in-
cremental grammar development. After each phenome-
non has been formalized, the grammar can be checked
against the test sentences, thus facilitating the retrie-
val of problematical sections in the grammar. The goal
is to set up the archive in such a way that incremental
grammar development does not require total retesting
of all the previous material but only of the recent re-
levant phenomena. But foremost the ATS is meant to
support the testing of the grammar for completeness (all
sentences that should be accepted are accepted by the
grammar) and soundness (the grammar does not accept
any sentence that should not be accepted).
In testing a grammar we need to distinguish between
using the grammar for analysis or synthesis. In ana-
lysis the ATS can be used to provide input sentences
for the parsing process. In synthesis the ATS can be
used for comparison with the generated sentences and
thus minimize the human judgement effort to the lefto-
ver sentences. The grammatical ones of this group can
be used to complete the ATS.
We see three major advantages in using an ATS.
</bodyText>
<listItem confidence="0.9627842">
1. Organizing the ATS in equivalence classes around
syntactic phenomena facilitates incremental gram-
mar development and problem driven testing.
2. Compared to working with NL corpora the ATS avo-
ids redundant testing of frequently occuring syntac-
tic phenomena. The ATS can thus serve as a testbed
before the grammar is used on real (&amp;quot;unconstruc-
ted&amp;quot; ) texts.
3. The ATS will help to compare the performance of
different implementations within the same forma-
</listItem>
<bodyText confidence="0.911285714285714">
lism as well as across linguistic theories. Running
an LFG implementation against a GPSG implemen-
tation will show the respective adequacy of the theo-
ries for particular syntactic phenomena.
In order to apply an ATS in practice we have built a
workbench for experimentation with grammar develop-
ment that contains an archive of this nature (see Volk
and Ridder, 1991). The workbench is designed as a tuto-
rial system for students of syntax analysis in Computa-
tional Linguistics. Its ATS contains 350 sentences for 15
syntactic phenomena. The workbench comes with a lexi-
con, a morphology component, a special purpose editor
and output procedures for linguistic type tree output.
The program is written in Prolog and runs on PCs.
</bodyText>
<sectionHeader confidence="0.998304" genericHeader="method">
4 Similar work
</sectionHeader>
<bodyText confidence="0.999879518518518">
Concerning the ATS the approach most similar to our
own is by Nerbonne and coworkers (1991). They assem-
ble a database of constructed sentences in an attempt
to exhaustively cover syntactic phenomena. So far they
have tackled coordination and verb government with se-
veral hundred sentences for both. They have not. yet.
included their &amp;quot;diagnostic database&amp;quot; in any test system.
This work also reports on attempts to build up sentence
collections for English.
Other comparable approaches towards grammar engi-
neering are by Erbach (1991) and by Erbach and Arens
(1991). The first describes a system that allows for the
parametrization of and experimentation with different
parsing strategies. The user can specify priorities to in-
crementally optimize the parsing process. We believe,
however, that lacking a broad collection of test sentences
this system cannot be sufficiently evaluated and there-
fore we see our approach as complementary to theirs.
In another attempt Erbach and Arens (1991) try to
evaluate grammars by generating a &amp;quot;representative set of
sentences&amp;quot; in a systematic way. They limit their lexicon
and grammar, and starting with sentences of length 1,
they generate sentences with increasing length. It is not
clear how they intend to check the resulting sentences
other than by human judgement. An ATS that is ad-
apted to their lexicon could be compared against these
sentences.
</bodyText>
<sectionHeader confidence="0.995694" genericHeader="method">
5 Future directions
</sectionHeader>
<bodyText confidence="0.999987875">
Future work will focus on two aspects. First, we will
try to apply testing techniques from software enginee-
ring to our domain of grammar development. In parti-
cular we hope to demonstrate that building a grammar
implementation is a special case of declarative program-
ming, since most recent grammar formalisms (notably
the unification-based theories) are declarative in nature.
This needs to go together with test statistics and pre-
cise information on how to incrementally improve the
grammar.
Second, in the long run it will be necessary to add
sentences that exceed pure syntactic testing and check
for semantic regularities. It is by no means clear how
the test sentences for semantics should be collected since
there is no set of agreed upon semantic features that
could be varied.
</bodyText>
<sectionHeader confidence="0.999182" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995787">
Gregor Erbach. An Environment for Experimentation
with Parsing Strategies. (IWBS Report 167) Stuttgart:
Wissenschaftliches Zentrum der IBM Deutschland. April
1991.
Gregor Erbach and Roman Arens. Evaluation von
Grammatiken fiir die Analyse natiirlicher Sprache durch
Generierung einer reprisentativen Satzmenge. Procee-
dings of GWAI-91, pages 126-129, Bonn, September
1991.
John Nerbonne et al. A diagnostic tool for German syn-
tax. (Research Report RR-91-18) Saarbriicken: DFKI.
July 1991.
Martin Volk and Hanno Ridder. GTU (Grammatik Test
Umgebung) Manual. (Manuscript) Institute of Com-
putational Linguistics. University of Koblenz-Landau.
1991.
</reference>
<page confidence="0.996134">
258
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.661127">
<title confidence="0.999779">The Role of Testing in Grammar Engineering</title>
<author confidence="0.999978">Martin Volk</author>
<affiliation confidence="0.9999465">University of Koblenz-Landau Institute of Computational Linguistics</affiliation>
<address confidence="0.999115">Rheinau 3-4 5400 Koblenz, Germany</address>
<phone confidence="0.744228">(+49)-261-9119-469</phone>
<email confidence="0.863651">e-mailvolkObrian.uni-koblenz.de</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gregor Erbach</author>
</authors>
<title>An Environment for Experimentation with Parsing Strategies.</title>
<date>1991</date>
<booktitle>Wissenschaftliches Zentrum der IBM Deutschland.</booktitle>
<tech>(IWBS Report 167) Stuttgart:</tech>
<contexts>
<context position="7755" citStr="Erbach (1991)" startWordPosition="1259" endWordPosition="1260">e tree output. The program is written in Prolog and runs on PCs. 4 Similar work Concerning the ATS the approach most similar to our own is by Nerbonne and coworkers (1991). They assemble a database of constructed sentences in an attempt to exhaustively cover syntactic phenomena. So far they have tackled coordination and verb government with several hundred sentences for both. They have not. yet. included their &amp;quot;diagnostic database&amp;quot; in any test system. This work also reports on attempts to build up sentence collections for English. Other comparable approaches towards grammar engineering are by Erbach (1991) and by Erbach and Arens (1991). The first describes a system that allows for the parametrization of and experimentation with different parsing strategies. The user can specify priorities to incrementally optimize the parsing process. We believe, however, that lacking a broad collection of test sentences this system cannot be sufficiently evaluated and therefore we see our approach as complementary to theirs. In another attempt Erbach and Arens (1991) try to evaluate grammars by generating a &amp;quot;representative set of sentences&amp;quot; in a systematic way. They limit their lexicon and grammar, and starti</context>
</contexts>
<marker>Erbach, 1991</marker>
<rawString>Gregor Erbach. An Environment for Experimentation with Parsing Strategies. (IWBS Report 167) Stuttgart: Wissenschaftliches Zentrum der IBM Deutschland. April 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Erbach</author>
<author>Roman Arens</author>
</authors>
<title>Evaluation von Grammatiken fiir die Analyse natiirlicher Sprache durch Generierung einer reprisentativen Satzmenge.</title>
<date>1991</date>
<booktitle>Proceedings of GWAI-91,</booktitle>
<pages>126--129</pages>
<location>Bonn,</location>
<contexts>
<context position="7786" citStr="Erbach and Arens (1991)" startWordPosition="1263" endWordPosition="1266">ogram is written in Prolog and runs on PCs. 4 Similar work Concerning the ATS the approach most similar to our own is by Nerbonne and coworkers (1991). They assemble a database of constructed sentences in an attempt to exhaustively cover syntactic phenomena. So far they have tackled coordination and verb government with several hundred sentences for both. They have not. yet. included their &amp;quot;diagnostic database&amp;quot; in any test system. This work also reports on attempts to build up sentence collections for English. Other comparable approaches towards grammar engineering are by Erbach (1991) and by Erbach and Arens (1991). The first describes a system that allows for the parametrization of and experimentation with different parsing strategies. The user can specify priorities to incrementally optimize the parsing process. We believe, however, that lacking a broad collection of test sentences this system cannot be sufficiently evaluated and therefore we see our approach as complementary to theirs. In another attempt Erbach and Arens (1991) try to evaluate grammars by generating a &amp;quot;representative set of sentences&amp;quot; in a systematic way. They limit their lexicon and grammar, and starting with sentences of length 1, </context>
</contexts>
<marker>Erbach, Arens, 1991</marker>
<rawString>Gregor Erbach and Roman Arens. Evaluation von Grammatiken fiir die Analyse natiirlicher Sprache durch Generierung einer reprisentativen Satzmenge. Proceedings of GWAI-91, pages 126-129, Bonn, September 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>A diagnostic tool for German syntax.</title>
<date>1991</date>
<tech>(Research Report RR-91-18) Saarbriicken: DFKI.</tech>
<marker>Nerbonne, 1991</marker>
<rawString>John Nerbonne et al. A diagnostic tool for German syntax. (Research Report RR-91-18) Saarbriicken: DFKI. July 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Hanno Ridder</author>
</authors>
<date>1991</date>
<institution>GTU (Grammatik Test Umgebung) Manual. (Manuscript) Institute of Computational Linguistics. University of Koblenz-Landau.</institution>
<contexts>
<context position="6847" citStr="Volk and Ridder, 1991" startWordPosition="1111" endWordPosition="1114">redundant testing of frequently occuring syntactic phenomena. The ATS can thus serve as a testbed before the grammar is used on real (&amp;quot;unconstructed&amp;quot; ) texts. 3. The ATS will help to compare the performance of different implementations within the same formalism as well as across linguistic theories. Running an LFG implementation against a GPSG implementation will show the respective adequacy of the theories for particular syntactic phenomena. In order to apply an ATS in practice we have built a workbench for experimentation with grammar development that contains an archive of this nature (see Volk and Ridder, 1991). The workbench is designed as a tutorial system for students of syntax analysis in Computational Linguistics. Its ATS contains 350 sentences for 15 syntactic phenomena. The workbench comes with a lexicon, a morphology component, a special purpose editor and output procedures for linguistic type tree output. The program is written in Prolog and runs on PCs. 4 Similar work Concerning the ATS the approach most similar to our own is by Nerbonne and coworkers (1991). They assemble a database of constructed sentences in an attempt to exhaustively cover syntactic phenomena. So far they have tackled </context>
</contexts>
<marker>Volk, Ridder, 1991</marker>
<rawString>Martin Volk and Hanno Ridder. GTU (Grammatik Test Umgebung) Manual. (Manuscript) Institute of Computational Linguistics. University of Koblenz-Landau. 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>