<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000144">
<title confidence="0.992914">
Bayesian Inference for Zodiac and Other Homophonic Ciphers
</title>
<author confidence="0.992679">
Sujith Ravi and Kevin Knight
</author>
<affiliation confidence="0.851133666666667">
University of Southern California
Information Sciences Institute
Marina del Rey, California 90292
</affiliation>
<email confidence="0.999507">
{sravi,knight}@isi.edu
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914411764706">
We introduce a novel Bayesian approach for
deciphering complex substitution ciphers. Our
method uses a decipherment model which
combines information from letter n-gram lan-
guage models as well as word dictionaries.
Bayesian inference is performed on our model
using an efficient sampling technique. We
evaluate the quality of the Bayesian deci-
pherment output on simple and homophonic
letter substitution ciphers and show that un-
like a previous approach, our method consis-
tently produces almost 100% accurate deci-
pherments. The new method can be applied
on more complex substitution ciphers and we
demonstrate its utility by cracking the famous
Zodiac-408 cipher in a fully automated fash-
ion, which has never been done before.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997030625">
Substitution ciphers have been used widely in the
past to encrypt secrets behind messages. These
ciphers replace (English) plaintext letters with ci-
pher symbols in order to generate the ciphertext se-
quence.
There exist many published works on automatic
decipherment methods for solving simple letter-
substitution ciphers. Many existing methods use
dictionary-based attacks employing huge word dic-
tionaries to find plaintext patterns within the ci-
phertext (Peleg and Rosenfeld, 1979; Ganesan and
Sherman, 1993; Jakobsen, 1995; Olson, 2007).
Most of these methods are heuristic in nature and
search for the best deterministic key during deci-
pherment. Others follow a probabilistic decipher-
ment approach. Knight et al. (2006) use the Expec-
tation Maximization (EM) algorithm (Dempster et
al., 1977) to search for the best probabilistic key us-
ing letter n-gram models. Ravi and Knight (2008)
formulate decipherment as an integer programming
problem and provide an exact method to solve sim-
ple substitution ciphers by using letter n-gram mod-
els along with deterministic key constraints. Corlett
and Penn (2010) work with large ciphertexts con-
taining thousands of characters and provide another
exact decipherment method using an A* search al-
gorithm. Diaconis (2008) presents an analysis of
Markov Chain Monte Carlo (MCMC) sampling al-
gorithms and shows an example application for solv-
ing simple substitution ciphers.
Most work in this area has focused on solving
simple substitution ciphers. But there are variants
of substitution ciphers, such as homophonic ciphers,
which display increasing levels of difficulty and
present significant challenges for decipherment. The
famous Zodiac serial killer used one such cipher sys-
tem for communication. In 1969, the killer sent a
three-part cipher message to newspapers claiming
credit for recent shootings and crimes committed
near the San Francisco area. The 408-character mes-
sage (Zodiac-408) was manually decoded by hand in
the 1960’s. Oranchak (2008) presents a method for
solving the Zodiac-408 cipher automatically with a
dictionary-based attack using a genetic algorithm.
However, his method relies on using plaintext words
from the known solution to solve the cipher, which
departs from a strict decipherment scenario.
In this paper, we introduce a novel method for
</bodyText>
<page confidence="0.977721">
239
</page>
<note confidence="0.979365">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 239–247,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.969439">
solving substitution ciphers using Bayesian learn-
ing. Our novel contributions are as follows:
</bodyText>
<listItem confidence="0.8093168125">
• We present a new probabilistic decipherment
approach using Bayesian inference with sparse
priors, which can be used to solve different
types of substitution ciphers.
• Our new method combines information from
word dictionaries along with letter n-gram
models, providing a robust decipherment
model which offsets the disadvantages faced by
previous approaches.
• We evaluate the Bayesian decipherment output
on three different types of substitution ciphers
and show that unlike a previous approach, our
new method solves all the ciphers completely.
• Using the Bayesian decipherment, we show for
the first time a truly automated system that suc-
cessfully solves the Zodiac-408 cipher.
</listItem>
<sectionHeader confidence="0.876716" genericHeader="method">
2 Letter Substitution Ciphers
</sectionHeader>
<bodyText confidence="0.985931166666667">
We use natural language processing techniques to
attack letter substitution ciphers. In a letter substi-
tution cipher, every letter p in the natural language
(plaintext) sequence is replaced by a cipher token c,
according to some substitution key.
For example, an English plaintext
</bodyText>
<equation confidence="0.910895833333333">
“H E L L O W O R L D ...”
may be enciphered as:
“N O E E I T I M E L ...”
according to the key:
p:ABCDEFGHIJKLMNOPQRSTUVWXYZ
c:XYZLOHANBCDEFGIJKMPQRSTUVW
</equation>
<bodyText confidence="0.999875133333333">
where, “ ” represents the space character (word
boundary) in the English and ciphertext messages.
If the recipients of the ciphertext message have
the substitution key, they can use it (in reverse) to
recover the original plaintext. The sender can en-
crypt the message using one of many different ci-
pher systems. The particular type of cipher system
chosen determines the properties of the key. For ex-
ample, the substitution key can be deterministic in
both the encipherment and decipherment directions
as shown in the above example—i.e., there is a 1-to-
1 correspondence between the plaintext letters and
ciphertext symbols. Other types of keys exhibit non-
determinism either in the encipherment (or decipher-
ment) or both directions.
</bodyText>
<subsectionHeader confidence="0.998338">
2.1 Simple Substitution Ciphers
</subsectionHeader>
<bodyText confidence="0.999972125">
The key used in a simple substitution cipher is deter-
ministic in both the encipherment and decipherment
directions, i.e., there is a 1-to-1 mapping between
plaintext letters and ciphertext symbols. The exam-
ple shown earlier depicts how a simple substitution
cipher works.
Data: In our experiments, we work with a 414-
letter simple substitution cipher. We encrypt an
original English plaintext message using a randomly
generated simple substitution key to create the ci-
phertext. During the encipherment process, we pre-
serve spaces between words and use this information
for decipherment—i.e., plaintext character “ ” maps
to ciphertext character “ ”. Figure 1 (top) shows
a portion of the ciphertext along with the original
plaintext used to create the cipher.
</bodyText>
<subsectionHeader confidence="0.999296">
2.2 Homophonic Ciphers
</subsectionHeader>
<bodyText confidence="0.99318">
A homophonic cipher uses a substitution key that
maps a plaintext letter to more than one cipher sym-
bol.
For example, the English plaintext:
</bodyText>
<equation confidence="0.583744">
“H E L L O W O R L D ...”
may be enciphered as:
“65 82 51 84 05 60 54 42 51 45 ...”
</equation>
<bodyText confidence="0.587094">
according to the key:
</bodyText>
<figure confidence="0.81762375">
A: 09 12 33 47 53 67 78 92
B: 48 81
...
E: 14 16 24 44 46 55 57 64 74 82 87
...
L: 51 84
...
Z: 02
</figure>
<bodyText confidence="0.99186">
Here, “ ” represents the space character in both
English and ciphertext. Notice the non-determinism
involved in the enciphering direction—the English
</bodyText>
<page confidence="0.98852">
240
</page>
<bodyText confidence="0.998323451612903">
letter “L” is substituted using different symbols (51,
84) at different positions in the ciphertext.
These ciphers are more complex than simple sub-
stitution ciphers. Homophonic ciphers are generated
via a non-deterministic encipherment process—the
key is 1-to-many in the enciphering direction. The
number of potential cipher symbol substitutes for a
particular plaintext letter is often proportional to the
frequency of that letter in the plaintext language—
for example, the English letter “E” is assigned more
cipher symbols than “Z”. The objective of this is
to flatten out the frequency distribution of cipher-
text symbols, making a frequency-based cryptanaly-
sis attack difficult.
The substitution key is, however, deterministic in
the decipherment direction—each ciphertext symbol
maps to a single plaintext letter. Since the ciphertext
can contain more than 26 types, we need a larger
alphabet system—we use a numeric substitution al-
phabet in our experiments.
Data: For our decipherment experiments
on homophonic ciphers, we use the same
414-letter English plaintext used in Sec-
tion 2.1. We encrypt this message using a
homophonic substitution key (available from
http://www.simonsingh.net/The Black Chamber/ho
mophoniccipher.htm). As before, we preserve
spaces between words in the ciphertext. Figure 1
(middle) displays a section of the homophonic
cipher (with spaces) and the original plaintext
message used in our experiments.
</bodyText>
<subsectionHeader confidence="0.9171235">
2.3 Homophonic Ciphers without spaces
(Zodiac-408 cipher)
</subsectionHeader>
<bodyText confidence="0.991074787878788">
In the previous two cipher systems, the word-
boundary information was preserved in the cipher.
We now consider a more difficult homophonic ci-
pher by removing space characters from the original
plaintext.
The English plaintext from the previous example
now looks like this:
“HELLOWORLD ...”
and the corresponding ciphertext is:
“65 82 51 84 05 60 54 42 51 45 ...”
Without the word boundary information, typical
dictionary-based decipherment attacks fail on such
ciphers.
Zodiac-408 cipher: Homophonic ciphers with-
out spaces have been used extensively in the past to
encrypt secret messages. One of the most famous
homophonic ciphers in history was used by the in-
famous Zodiac serial killer in the 1960’s. The killer
sent a series of encrypted messages to newspapers
and claimed that solving the ciphers would reveal
clues to his identity. The identity of the Zodiac killer
remains unknown to date. However, the mystery
surrounding this has sparked much interest among
cryptanalysis experts and amateur enthusiasts.
The Zodiac messages include two interesting ci-
phers: (1) a 408-symbol homophonic cipher without
spaces (which was solved manually by hand), and
(2) a similar looking 340-symbol cipher that has yet
to be solved.
Here is a sample of the Zodiac-408 cipher mes-
sage:
and the corresponding section from the original
English plaintext message:
</bodyText>
<equation confidence="0.971010222222222">
I L I K E K I L L I N G P E O P L
E B E C A U S E I T I S S O M U C
H F U N I T I S M O R E F U N T H
A N K I L L I N G W I L D G A M E
I N T H E F O R R E S T B E C A U
S E M A N I S T H E M O S T D A N
G E R O U E A N A M A L O F A L L
T O K I L L S O M E T H I N G G I
...
</equation>
<bodyText confidence="0.999975">
Besides the difficulty with missing word bound-
aries and non-determinism associated with the key,
the Zodiac-408 cipher poses several additional chal-
lenges which makes it harder to solve than any
standard homophonic cipher. There are spelling
mistakes in the original message (for example,
the English word “PARADISE” is misspelt as
</bodyText>
<page confidence="0.986339">
241
</page>
<bodyText confidence="0.9999615">
“PARADICE”) which can divert a dictionary-based
attack. Also, the last 18 characters of the plaintext
message does not seem to make any sense (“EBE-
ORIETEMETHHPITI”).
Data: Figure 1 (bottom) displays the Zodiac-408
cipher (consisting of 408 tokens, 54 symbol types)
along with the original plaintext message. We run
the new decipherment method (described in Sec-
tion 3.1) and show that our approach can success-
fully solve the Zodiac-408 cipher.
</bodyText>
<sectionHeader confidence="0.996997" genericHeader="method">
3 Decipherment
</sectionHeader>
<bodyText confidence="0.9999729">
Given a ciphertext message c1...cn, the goal of de-
cipherment is to uncover the hidden plaintext mes-
sage p1...pn. The size of the keyspace (i.e., num-
ber of possible key mappings) that we have to navi-
gate during decipherment is huge—a simple substi-
tution cipher has a keyspace size of 26!, whereas a
homophonic cipher such as the Zodiac-408 cipher
has 2654 possible key mappings.
Next, we describe a new Bayesian decipherment
approach for tackling substitution ciphers.
</bodyText>
<subsectionHeader confidence="0.997558">
3.1 Bayesian Decipherment
</subsectionHeader>
<bodyText confidence="0.997578225806452">
Bayesian inference methods have become popular
in natural language processing (Goldwater and Grif-
fiths, 2007; Finkel et al., 2005; Blunsom et al., 2009;
Chiang et al., 2010). Snyder et al. (2010) proposed
a Bayesian approach in an archaeological decipher-
ment scenario. These methods are attractive for their
ability to manage uncertainty about model parame-
ters and allow one to incorporate prior knowledge
during inference. A common phenomenon observed
while modeling natural language problems is spar-
sity. For simple letter substitution ciphers, the origi-
nal substitution key exhibits a 1-to-1 correspondence
between the plaintext letters and cipher types. It is
not easy to model such information using conven-
tional methods like EM. But we can easily spec-
ify priors that favor sparse distributions within the
Bayesian framework.
Here, we propose a novel approach for decipher-
ing substitution ciphers using Bayesian inference.
Rather than enumerating all possible keys (26! for
a simple substitution cipher), our Bayesian frame-
work requires us to sample only a small number of
keys during the decipherment process.
Probabilistic Decipherment: Our decipherment
method follows a noisy-channel approach. We are
faced with a ciphertext sequence c = c1...cn and
we want to find the (English) letter sequence p =
p1...pn that maximizes the probability P(p|c).
We first formulate a generative story to model the
process by which the ciphertext sequence is gener-
ated.
</bodyText>
<listItem confidence="0.9538054">
1. Generate an English plaintext sequence p =
p1...pn, with probability P(p).
2. Substitute each plaintext letter pi with a cipher-
text token ci, with probability P(ci|pi) in order
to generate the ciphertext sequence c = c1...cn.
</listItem>
<bodyText confidence="0.992360333333333">
We build a statistical English language model
(LM) for the plaintext source model P(p), which
assigns a probability to any English letter sequence.
Our goal is to estimate the channel model param-
eters 0 in order to maximize the probability of the
observed ciphertext c:
</bodyText>
<equation confidence="0.9906365">
EP(c) = arg max
θ p
E= arg max
θ p
E= arg max
θ p
</equation>
<bodyText confidence="0.9999614">
We estimate the parameters 0 using Bayesian
learning. In our decipherment framework, a Chinese
Restaurant Process formulation is used to model
both the source and channel. The detailed genera-
tive story using CRPs is shown below:
</bodyText>
<listItem confidence="0.998490125">
1. i ← 1
2. Generate the English plaintext letter p1, with
probability P0(p1)
3. Substitute p1 with cipher token c1, with proba-
bility P0(c1|p1)
4. i ← i + 1
5. Generate English plaintext letter pi, with prob-
ability
</listItem>
<equation confidence="0.999266272727273">
α · P0(pi|pi−1) + Ci−1
1 (pi−1, pi)
α + Ci−1
1 (pi−1)
arg max
θ
Pθ(p, c) (1)
P(p) · Pθ(c|p) (2)
n
P(p) · Pθ(ci|pi) (3)
i=1
</equation>
<page confidence="0.987757">
242
</page>
<table confidence="0.945037666666667">
Plaintext: D E C I P H E R M E N T I S T H E A N A L Y S I S O F D O C U M E N T S
W R I T T E N I N A N C I E N T L A N G U A G E S W H E R E T H E ...
Ciphertext: i n g c m p n q s n w f c v f p n o w o k t v c v h u i h g z s n w f v
r q c f f n w c w o w g c n w f k o w a z o a n v r p n q n f p n ...
Bayesian solution: D E C I P H E R M E N T I S T H E A N A L Y S I S O F D O C U M E N T S
W R I T T E N I N A N C I E N T L A N G U A G E S W H E R E T H E ...
Plaintext: D E C I P H E R M E N T I S T H E A N A L Y S I S
O F D O C U M E N T S W R I T T E N I N ...
Ciphertext: 79 57 62 93 95 68 44 77 22 74 59 97 32 86 85 56 82 67 59 67 84 52 86 73 11
99 10 45 90 13 61 27 98 71 49 19 60 80 88 85 20 55 59 32 91 ...
Bayesian solution: D E C I P H E R M E N T I S T H E A N A L Y S I S
O F D O C U M E N T S W R I T T E N I N ...
Ciphertext:
Plaintext:
Bayesian solution (final decoding): I L I K E K I L L I N G P E O P L E B E C A U S E
(with spaces shown): I T I S S O M U C H F U N I T I A M O R E F U N T
H A N K I L L I N G W I L D G A M E I N T H E F O
R R E S T B E C A U S E M A N I S T H E M O A T D
</table>
<figure confidence="0.882883666666667">
A N G E R T U E A N A M A L O F A L L ...
I L I K E K I L L I N G P E O P L E B E C A U S E
I T I S S O M U C H F U N I T I A M O R E
F U N T H A N K I L L I N G W I L D G A M E I N
T H E F O R R E S T B E C A U S E M A N I S T H E
M O A T D A N G E R T U E A N A M A L O F A L L ...
</figure>
<figureCaption confidence="0.989467">
Figure 1: Samples from the ciphertext sequence, corresponding English plaintext message and output from Bayesian
decipherment (using word+3-gram LM) for three different ciphers: (a) Simple Substitution Cipher (top), (b) Homo-
phonic Substitution Cipher with spaces (middle), and (c) Zodiac-408 Cipher (bottom).
</figureCaption>
<page confidence="0.994297">
243
</page>
<listItem confidence="0.988813">
6. Substitute pi with cipher token ci, with proba-
bility
</listItem>
<equation confidence="0.9522274">
Q · P0(cih) + Ci−1
1 (pi, ci)
Q + Ci−1
1 (pi)
7. With probability PQnit, quit; else go to Step 4.
</equation>
<bodyText confidence="0.998480620253165">
This defines the probability of any given deriva-
tion, i.e., any plaintext hypothesis corresponding to
the given ciphertext sequence. The base distribu-
tion P0 represents prior knowledge about the model
parameter distributions. For the plaintext source
model, we use probabilities from an English lan-
guage model and for the channel model, we spec-
ify a uniform distribution (i.e., a plaintext letter can
be substituted with any given cipher type with equal
probability). Ci−1
1 represents the count of events
occurring before plaintext letter pi in the derivation
(we call this the “cache”). α and Q represent Dirich-
let prior hyperparameters over the source and chan-
nel models respectively. A large prior value implies
that characters are generated from the base distribu-
tion P0, whereas a smaller value biases characters
to be generated with reference to previous decisions
inside the cache (favoring sparser distributions).
Efficient inference via type sampling: We use a
Gibbs sampling (Geman and Geman, 1984) method
for performing inference on our model. We could
follow a point-wise sampling strategy, where we
sample plaintext letter choices for every cipher to-
ken, one at a time. But we already know that the
substitution ciphers described here exhibit determin-
ism in the deciphering direction,1 i.e., although we
have no idea about the key mappings themselves,
we do know that there exists only a single plaintext
letter mapping for every cipher symbol type in the
true key. So sampling plaintext choices for every
cipher token separately is not an efficient strategy—
our sampler may spend too much time exploring in-
valid keys (which map the same cipher symbol to
different plaintext letters).
Instead, we use a type sampling technique similar
to the one proposed by Liang et al. (2010). Under
1This assumption does not strictly apply to the Zodiac-408
cipher where a few cipher symbols exhibit non-determinism in
the decipherment direction as well.
this scheme, we sample plaintext letter choices for
each cipher symbol type. In every step, we sample
a new plaintext letter for a cipher type and update
the entire plaintext hypothesis (i.e., plaintext letters
at all corresponding positions) to reflect this change.
For example, if we sample a new choice pnew for
a cipher symbol which occurs at positions 4,10,18,
then we update plaintext letters p4, p10 and p18 with
the new choice pnew.
Using the property of exchangeability, we derive
an incremental formula for re-scoring the probabil-
ity of a new derivation based on the probability of
the old derivation—when sampling at position i, we
pretend that the area affected (within a context win-
dow around i) in the current plaintext hypothesis oc-
curs at the end of the corpus, so that both the old
and new derivations share the same cache.2 While
we may make corpus-wide changes to a derivation
in every sampling step, exchangeability allows us to
perform scoring in an efficient manner.
Combining letter n-gram language models with
word dictionaries: Many existing probabilistic ap-
proaches use statistical letter n-gram language mod-
els of English to assign P(p) probabilities to plain-
text hypotheses during decipherment. Other de-
cryption techniques rely on word dictionaries (using
words from an English dictionary) for attacking sub-
stitution ciphers.
Unlike previous approaches, our decipherment
method combines information from both sources—
letter n-grams and word dictionaries. We build an
interpolated word+n-gram LM and use it to assign
P(p) probabilities to any plaintext letter sequence
p1...pn.3 The advantage is that it helps direct the
sampler towards plaintext hypotheses that resemble
natural language—high probability letter sequences
which form valid words such as “H E L L O” in-
stead of sequences like “‘T X H R T”. But in ad-
dition to this, using letter n-gram information makes
</bodyText>
<footnote confidence="0.771594444444445">
2The relevant context window that is affected when sam-
pling at position i is determined by the word boundaries to the
left and right of i.
3We set the interpolation weights for the word and n-gram
LM as (0.9, 0.1). The word-based LM is constructed from a
dictionary consisting of 9,881 frequently occurring words col-
lected from Wikipedia articles. We train the letter n-gram LM
on 50 million words of English text available from the Linguis-
tic Data Consortium.
</footnote>
<page confidence="0.997162">
244
</page>
<bodyText confidence="0.98575914893617">
our model robust against variations in the origi-
nal plaintext (for example, unseen words or mis-
spellings as in the case of Zodiac-408 cipher) which
can easily throw off dictionary-based attacks. Also,
it is hard for a point-wise (or type) sampler to “find
words” starting from a random initial sample, but
easier to “find n-grams”.
Sampling for ciphers without spaces: For ciphers
without spaces, dictionaries are hard to use because
we do not know where words start and end. We in-
troduce a new sampling operator which counters this
problem and allows us to perform inference using
the same decipherment model described earlier. In
a first sampling pass, we sample from 26 plaintext
letter choices (e.g., “A”, “B”, “C”, ...) for every ci-
pher symbol type as before. We then run a second
pass using a new sampling operator that iterates over
adjacent plaintext letter pairs pi_1i pi in the current
hypothesis and samples from two choices—(1) add
a word boundary (space character “ ”) between pi_1
and pi, or (2) remove an existing space character be-
tween pi_1 and pi.
For example, given the English plaintext hypoth-
esis “... A B O Y ...”, there are two sam-
pling choices for the letter pair A,B in the second
step. If we decide to add a word boundary, our new
plaintext hypothesis becomes “... A B O Y
...”.
We compute the derivation probability of the new
sample using the same efficient scoring procedure
described earlier. The new strategy allows us to ap-
ply Bayesian decipherment even to ciphers without
spaces. As a result, we now have a new decipher-
ment method that consistently works for a range of
different types of substitution ciphers.
Decoding the ciphertext: After the sampling run
has finished,4 we choose the final sample as our En-
glish plaintext decipherment output.
4For letter substitution decipherment we want to keep the
language model probabilities fixed during training, and hence
we set the prior on that model to be high (α = 104). We use
a sparse prior for the channel ((/ = 0.01). We instantiate a key
which matches frequently occurring plaintext letters to frequent
cipher symbols and use this to generate an initial sample for the
given ciphertext and run the sampler for 5000 iterations. We
use a linear annealing schedule during sampling decreasing the
temperature from 10 --+ 1.
</bodyText>
<sectionHeader confidence="0.9912" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.98724025">
We run decipherment experiments on different types
of letter substitution ciphers (described in Sec-
tion 2). In particular, we work with the following
three ciphers:
</bodyText>
<listItem confidence="0.735747125">
(a) 414-letter Simple Substitution Cipher
(b) 414-letter Homophonic Cipher (with spaces)
(c) Zodiac-408 Cipher
Methods: For each cipher, we run and compare the
output from two different decipherment approaches:
1. EM Method using letter n-gram LMs follow-
ing the approach of Knight et al. (2006). They
use the EM algorithm to estimate the chan-
</listItem>
<bodyText confidence="0.995088333333333">
nel parameters 0 during decipherment training.
The given ciphertext c is then decoded by us-
ing the Viterbi algorithm to choose the plain-
text decoding p that maximizes P(p)·Pθ(c|p)&amp;quot;
stretching the channel probabilities.
2. Bayesian Decipherment method using
word+n-gram LMs (novel approach described
in Section 3.1).
Evaluation: We evaluate the quality of a particular
decipherment as the percentage of cipher tokens that
are decoded correctly.
Results: Figure 2 compares the decipherment per-
formance for the EM method with Bayesian deci-
pherment (using type sampling and sparse priors)
on three different types of substitution ciphers. Re-
sults show that our new approach (Bayesian) out-
performs the EM method on all three ciphers, solv-
ing them completely. Even with a 3-gram letter LM,
our method yields a +63% improvement in decipher-
ment accuracy over EM on the homophonic cipher
with spaces. We observe that the word+3-gram LM
proves highly effective when tackling more complex
ciphers and cracks the Zodiac-408 cipher. Figure 1
shows samples from the Bayesian decipherment out-
put for all three ciphers. For ciphers without spaces,
our method automatically guesses the word bound-
aries for the plaintext hypothesis.
</bodyText>
<page confidence="0.99476">
245
</page>
<table confidence="0.995262111111111">
Method LM Accuracy (%) on 414-letter Accuracy (%) on 414-letter Accuracy (%) on Zodiac-
Simple Substitution Cipher Homophonic Substitution 408 Cipher
Cipher (with spaces)
1. EM 2-gram 83.6 30.9
3-gram 99.3 32.6 0.3*
(*28.8 with 100 restarts)
2. Bayesian 3-gram 100.0 95.2 23.0
word+2-gram 100.0 100.0
word+3-gram 100.0 100.0 97.8
</table>
<figureCaption confidence="0.992945">
Figure 2: Comparison of decipherment accuracies for EM versus Bayesian method when using different language
models of English on the three substitution ciphers: (a) 414-letter Simple Substitution Cipher, (b) 414-letter Homo-
phonic Substitution Cipher (with spaces), and (c) the famous Zodiac-408 Cipher.
</figureCaption>
<bodyText confidence="0.918076571428571">
For the Zodiac-408 cipher, we compare the per-
formance achieved by Bayesian decipherment under
different settings:
• Letter n-gram versus Word+n-gram LMs—
Figure 2 shows that using a word+3-gram LM
instead of a 3-gram LM results in +75% im-
provement in decipherment accuracy.
</bodyText>
<listItem confidence="0.942103833333333">
• Sparse versus Non-sparse priors—We find that
using a sparse prior for the channel model (Q =
0.01 versus 1.0) helps for such problems and
produces better decipherment results (97.8%
versus 24.0% accuracy).
• Type versus Point-wise sampling—Unlike
</listItem>
<bodyText confidence="0.968386769230769">
point-wise sampling, type sampling quickly
converges to better decipherment solutions.
After 5000 sampling passes over the entire
data, decipherment output from type sampling
scores 97.8% accuracy compared to 14.5% for
the point-wise sampling run.5
We also perform experiments on shorter substitu-
tion ciphers. On a 98-letter simple substitution ci-
pher, EM using 3-gram LM achieves 41% accuracy,
whereas the method from Ravi and Knight (2009)
scores 84% accuracy. Our Bayesian method per-
forms the best in this case, achieving 100% with
word+3-gram LM.
</bodyText>
<sectionHeader confidence="0.999523" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.982769">
In this work, we presented a novel Bayesian deci-
pherment approach that can effectively solve a va-
</bodyText>
<footnote confidence="0.8452635">
5Both sampling runs were seeded with the same random ini-
tial sample.
</footnote>
<bodyText confidence="0.999739733333333">
riety of substitution ciphers. Unlike previous ap-
proaches, our method combines information from
letter n-gram language models and word dictionar-
ies and provides a robust decipherment model. We
empirically evaluated the method on different substi-
tution ciphers and achieve perfect decipherments on
all of them. Using Bayesian decipherment, we can
successfully solve the Zodiac-408 cipher—the first
time this is achieved by a fully automatic method in
a strict decipherment scenario.
For future work, there are other interesting deci-
pherment tasks where our method can be applied.
One challenge is to crack the unsolved Zodiac-340
cipher, which presents a much harder problem than
the solved version.
</bodyText>
<sectionHeader confidence="0.997364" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999475">
The authors would like to thank the reviewers for
their comments. This research was supported by
NSF grant IIS-0904684.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999282071428572">
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-
borne. 2009. A Gibbs sampler for phrasal syn-
chronous grammar induction. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the Asian Federa-
tion of Natural Language Processing (ACL-IJCNLP),
pages 782–790.
David Chiang, Jonathan Graehl, Kevin Knight, Adam
Pauls, and Sujith Ravi. 2010. Bayesian inference for
finite-state transducers. In Proceedings of the Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics - Human Language
Technologies (NAACL/HLT), pages 447–455.
</reference>
<page confidence="0.978999">
246
</page>
<reference confidence="0.999367885714286">
Eric Corlett and Gerald Penn. 2010. An exact A* method
for deciphering letter-substitution ciphers. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1040–1047.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical
Society, Series B, 39(1):1–38.
Persi Diaconis. 2008. The Markov Chain Monte Carlo
revolution. Bulletin of the American Mathematical So-
ciety, 46(2):179–205.
Jenny Finkel, Trond Grenager, and Christopher Manning.
2005. Incorporating non-local information into infor-
mation extraction systems by Gibbs sampling. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL), pages 363–
370.
Ravi Ganesan and Alan T. Sherman. 1993. Statistical
techniques for language recognition: An introduction
and guide for cryptanalysts. Cryptologia, 17(4):321–
366.
Stuart Geman and Donald Geman. 1984. Stochastic re-
laxation, Gibbs distributions and the Bayesian restora-
tion of images. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 6(6):721–741.
Sharon Goldwater and Thomas Griffiths. 2007. A fully
Bayesian approach to unsupervised part-of-speech tag-
ging. In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages 744–
751.
Thomas Jakobsen. 1995. A fast method for cryptanalysis
of substitution ciphers. Cryptologia, 19(3):265–274.
Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Ya-
mada. 2006. Unsupervised analysis for decipherment
problems. In Proceedings of the Joint Conference of
the International Committee on Computational Lin-
guistics and the Association for Computational Lin-
guistics, pages 499–506.
Percy Liang, Michael I. Jordan, and Dan Klein. 2010.
Type-based MCMC. In Proceedings of the Conference
on Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 573–
581.
Edwin Olson. 2007. Robust dictionary attack of short
simple substitution ciphers. Cryptologia, 31(4):332–
342.
David Oranchak. 2008. Evolutionary algorithm for de-
cryption of monoalphabetic homophonic substitution
ciphers encoded as constraint satisfaction problems. In
Proceedings of the 10th Annual Conference on Genetic
and Evolutionary Computation, pages 1717–1718.
Shmuel Peleg and Azriel Rosenfeld. 1979. Break-
ing substitution ciphers using a relaxation algorithm.
Comm. ACM, 22(11):598–605.
Sujith Ravi and Kevin Knight. 2008. Attacking deci-
pherment problems optimally with low-order n-gram
models. In Proceedings of the Empirical Methods in
Natural Language Processing (EMNLP), pages 812–
819.
Sujith Ravi and Kevin Knight. 2009. Probabilistic meth-
ods for a Japanese syllable cipher. In Proceedings
of the International Conference on the Computer Pro-
cessing of Oriental Languages (ICCPOL), pages 270–
281.
Benjamin Snyder, Regina Barzilay, and Kevin Knight.
2010. A statistical model for lost language decipher-
ment. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
1048–1057.
</reference>
<page confidence="0.997974">
247
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.908691">
<title confidence="0.99989">Bayesian Inference for Zodiac and Other Homophonic Ciphers</title>
<author confidence="0.999871">Sujith Ravi</author>
<author confidence="0.999871">Kevin Knight</author>
<affiliation confidence="0.9997425">University of Southern California Information Sciences Institute</affiliation>
<address confidence="0.998274">Marina del Rey, California 90292</address>
<abstract confidence="0.993748111111111">We introduce a novel Bayesian approach for deciphering complex substitution ciphers. Our method uses a decipherment model which combines information from letter n-gram language models as well as word dictionaries. Bayesian inference is performed on our model using an efficient sampling technique. We evaluate the quality of the Bayesian decipherment output on simple and homophonic letter substitution ciphers and show that unlike a previous approach, our method consistently produces almost 100% accurate decipherments. The new method can be applied on more complex substitution ciphers and we demonstrate its utility by cracking the famous Zodiac-408 cipher in a fully automated fashion, which has never been done before.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Chris Dyer</author>
<author>Miles Osborne</author>
</authors>
<title>A Gibbs sampler for phrasal synchronous grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP),</booktitle>
<pages>782--790</pages>
<contexts>
<context position="11313" citStr="Blunsom et al., 2009" startWordPosition="1849" endWordPosition="1852">e c1...cn, the goal of decipherment is to uncover the hidden plaintext message p1...pn. The size of the keyspace (i.e., number of possible key mappings) that we have to navigate during decipherment is huge—a simple substitution cipher has a keyspace size of 26!, whereas a homophonic cipher such as the Zodiac-408 cipher has 2654 possible key mappings. Next, we describe a new Bayesian decipherment approach for tackling substitution ciphers. 3.1 Bayesian Decipherment Bayesian inference methods have become popular in natural language processing (Goldwater and Griffiths, 2007; Finkel et al., 2005; Blunsom et al., 2009; Chiang et al., 2010). Snyder et al. (2010) proposed a Bayesian approach in an archaeological decipherment scenario. These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference. A common phenomenon observed while modeling natural language problems is sparsity. For simple letter substitution ciphers, the original substitution key exhibits a 1-to-1 correspondence between the plaintext letters and cipher types. It is not easy to model such information using conventional methods like EM. But we can easil</context>
</contexts>
<marker>Blunsom, Cohn, Dyer, Osborne, 2009</marker>
<rawString>Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Osborne. 2009. A Gibbs sampler for phrasal synchronous grammar induction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP), pages 782–790.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Adam Pauls</author>
<author>Sujith Ravi</author>
</authors>
<title>Bayesian inference for finite-state transducers.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL/HLT),</booktitle>
<pages>447--455</pages>
<contexts>
<context position="11335" citStr="Chiang et al., 2010" startWordPosition="1853" endWordPosition="1856"> decipherment is to uncover the hidden plaintext message p1...pn. The size of the keyspace (i.e., number of possible key mappings) that we have to navigate during decipherment is huge—a simple substitution cipher has a keyspace size of 26!, whereas a homophonic cipher such as the Zodiac-408 cipher has 2654 possible key mappings. Next, we describe a new Bayesian decipherment approach for tackling substitution ciphers. 3.1 Bayesian Decipherment Bayesian inference methods have become popular in natural language processing (Goldwater and Griffiths, 2007; Finkel et al., 2005; Blunsom et al., 2009; Chiang et al., 2010). Snyder et al. (2010) proposed a Bayesian approach in an archaeological decipherment scenario. These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference. A common phenomenon observed while modeling natural language problems is sparsity. For simple letter substitution ciphers, the original substitution key exhibits a 1-to-1 correspondence between the plaintext letters and cipher types. It is not easy to model such information using conventional methods like EM. But we can easily specify priors that </context>
</contexts>
<marker>Chiang, Graehl, Knight, Pauls, Ravi, 2010</marker>
<rawString>David Chiang, Jonathan Graehl, Kevin Knight, Adam Pauls, and Sujith Ravi. 2010. Bayesian inference for finite-state transducers. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL/HLT), pages 447–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Corlett</author>
<author>Gerald Penn</author>
</authors>
<title>An exact A* method for deciphering letter-substitution ciphers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1040--1047</pages>
<contexts>
<context position="2061" citStr="Corlett and Penn (2010)" startWordPosition="304" endWordPosition="307">; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an A* search algorithm. Diaconis (2008) presents an analysis of Markov Chain Monte Carlo (MCMC) sampling algorithms and shows an example application for solving simple substitution ciphers. Most work in this area has focused on solving simple substitution ciphers. But there are variants of substitution ciphers, such as homophonic ciphers, which display increasing levels of difficulty and present significant challenges for decipherment. The famous Zodiac serial killer used one suc</context>
</contexts>
<marker>Corlett, Penn, 2010</marker>
<rawString>Eric Corlett and Gerald Penn. 2010. An exact A* method for deciphering letter-substitution ciphers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1040–1047.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="1751" citStr="Dempster et al., 1977" startWordPosition="255" endWordPosition="258">o generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an A* search algorithm. Diaconis (2008) presents an analysis of Markov Chain Monte Carlo (MCMC) sampling algorithms and shows an example application for solving simple substi</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Persi Diaconis</author>
</authors>
<title>The Markov Chain Monte Carlo revolution.</title>
<date>2008</date>
<journal>Bulletin of the American Mathematical Society,</journal>
<volume>46</volume>
<issue>2</issue>
<contexts>
<context position="2216" citStr="Diaconis (2008)" startWordPosition="329" endWordPosition="330">ent. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an A* search algorithm. Diaconis (2008) presents an analysis of Markov Chain Monte Carlo (MCMC) sampling algorithms and shows an example application for solving simple substitution ciphers. Most work in this area has focused on solving simple substitution ciphers. But there are variants of substitution ciphers, such as homophonic ciphers, which display increasing levels of difficulty and present significant challenges for decipherment. The famous Zodiac serial killer used one such cipher system for communication. In 1969, the killer sent a three-part cipher message to newspapers claiming credit for recent shootings and crimes commi</context>
</contexts>
<marker>Diaconis, 2008</marker>
<rawString>Persi Diaconis. 2008. The Markov Chain Monte Carlo revolution. Bulletin of the American Mathematical Society, 46(2):179–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>363--370</pages>
<contexts>
<context position="11291" citStr="Finkel et al., 2005" startWordPosition="1845" endWordPosition="1848">n a ciphertext message c1...cn, the goal of decipherment is to uncover the hidden plaintext message p1...pn. The size of the keyspace (i.e., number of possible key mappings) that we have to navigate during decipherment is huge—a simple substitution cipher has a keyspace size of 26!, whereas a homophonic cipher such as the Zodiac-408 cipher has 2654 possible key mappings. Next, we describe a new Bayesian decipherment approach for tackling substitution ciphers. 3.1 Bayesian Decipherment Bayesian inference methods have become popular in natural language processing (Goldwater and Griffiths, 2007; Finkel et al., 2005; Blunsom et al., 2009; Chiang et al., 2010). Snyder et al. (2010) proposed a Bayesian approach in an archaeological decipherment scenario. These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference. A common phenomenon observed while modeling natural language problems is sparsity. For simple letter substitution ciphers, the original substitution key exhibits a 1-to-1 correspondence between the plaintext letters and cipher types. It is not easy to model such information using conventional methods lik</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 363– 370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Ganesan</author>
<author>Alan T Sherman</author>
</authors>
<title>Statistical techniques for language recognition: An introduction and guide for cryptanalysts.</title>
<date>1993</date>
<journal>Cryptologia,</journal>
<volume>17</volume>
<issue>4</issue>
<pages>366</pages>
<contexts>
<context position="1465" citStr="Ganesan and Sherman, 1993" startWordPosition="211" endWordPosition="214"> cracking the famous Zodiac-408 cipher in a fully automated fashion, which has never been done before. 1 Introduction Substitution ciphers have been used widely in the past to encrypt secrets behind messages. These ciphers replace (English) plaintext letters with cipher symbols in order to generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) wor</context>
</contexts>
<marker>Ganesan, Sherman, 1993</marker>
<rawString>Ravi Ganesan and Alan T. Sherman. 1993. Statistical techniques for language recognition: An introduction and guide for cryptanalysts. Cryptologia, 17(4):321– 366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Donald Geman</author>
</authors>
<title>Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images.</title>
<date>1984</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>6</volume>
<issue>6</issue>
<contexts>
<context position="16620" citStr="Geman and Geman, 1984" startWordPosition="3091" endWordPosition="3094">xt letter can be substituted with any given cipher type with equal probability). Ci−1 1 represents the count of events occurring before plaintext letter pi in the derivation (we call this the “cache”). α and Q represent Dirichlet prior hyperparameters over the source and channel models respectively. A large prior value implies that characters are generated from the base distribution P0, whereas a smaller value biases characters to be generated with reference to previous decisions inside the cache (favoring sparser distributions). Efficient inference via type sampling: We use a Gibbs sampling (Geman and Geman, 1984) method for performing inference on our model. We could follow a point-wise sampling strategy, where we sample plaintext letter choices for every cipher token, one at a time. But we already know that the substitution ciphers described here exhibit determinism in the deciphering direction,1 i.e., although we have no idea about the key mappings themselves, we do know that there exists only a single plaintext letter mapping for every cipher symbol type in the true key. So sampling plaintext choices for every cipher token separately is not an efficient strategy— our sampler may spend too much time</context>
</contexts>
<marker>Geman, Geman, 1984</marker>
<rawString>Stuart Geman and Donald Geman. 1984. Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6):721–741.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>744--751</pages>
<contexts>
<context position="11270" citStr="Goldwater and Griffiths, 2007" startWordPosition="1840" endWordPosition="1844">408 cipher. 3 Decipherment Given a ciphertext message c1...cn, the goal of decipherment is to uncover the hidden plaintext message p1...pn. The size of the keyspace (i.e., number of possible key mappings) that we have to navigate during decipherment is huge—a simple substitution cipher has a keyspace size of 26!, whereas a homophonic cipher such as the Zodiac-408 cipher has 2654 possible key mappings. Next, we describe a new Bayesian decipherment approach for tackling substitution ciphers. 3.1 Bayesian Decipherment Bayesian inference methods have become popular in natural language processing (Goldwater and Griffiths, 2007; Finkel et al., 2005; Blunsom et al., 2009; Chiang et al., 2010). Snyder et al. (2010) proposed a Bayesian approach in an archaeological decipherment scenario. These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference. A common phenomenon observed while modeling natural language problems is sparsity. For simple letter substitution ciphers, the original substitution key exhibits a 1-to-1 correspondence between the plaintext letters and cipher types. It is not easy to model such information using con</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Thomas Griffiths. 2007. A fully Bayesian approach to unsupervised part-of-speech tagging. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 744– 751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Jakobsen</author>
</authors>
<title>A fast method for cryptanalysis of substitution ciphers.</title>
<date>1995</date>
<journal>Cryptologia,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="1481" citStr="Jakobsen, 1995" startWordPosition="215" endWordPosition="216">-408 cipher in a fully automated fashion, which has never been done before. 1 Introduction Substitution ciphers have been used widely in the past to encrypt secrets behind messages. These ciphers replace (English) plaintext letters with cipher symbols in order to generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large cip</context>
</contexts>
<marker>Jakobsen, 1995</marker>
<rawString>Thomas Jakobsen. 1995. A fast method for cryptanalysis of substitution ciphers. Cryptologia, 19(3):265–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Anish Nair</author>
<author>Nishit Rathod</author>
<author>Kenji Yamada</author>
</authors>
<title>Unsupervised analysis for decipherment problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics,</booktitle>
<pages>499--506</pages>
<contexts>
<context position="1679" citStr="Knight et al. (2006)" startWordPosition="244" endWordPosition="247">ers replace (English) plaintext letters with cipher symbols in order to generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an A* search algorithm. Diaconis (2008) presents an analysis of Markov Chain Monte Carlo (MCMC) sampli</context>
<context position="22721" citStr="Knight et al. (2006)" startWordPosition="4096" endWordPosition="4099"> and run the sampler for 5000 iterations. We use a linear annealing schedule during sampling decreasing the temperature from 10 --+ 1. 4 Experiments and Results We run decipherment experiments on different types of letter substitution ciphers (described in Section 2). In particular, we work with the following three ciphers: (a) 414-letter Simple Substitution Cipher (b) 414-letter Homophonic Cipher (with spaces) (c) Zodiac-408 Cipher Methods: For each cipher, we run and compare the output from two different decipherment approaches: 1. EM Method using letter n-gram LMs following the approach of Knight et al. (2006). They use the EM algorithm to estimate the channel parameters 0 during decipherment training. The given ciphertext c is then decoded by using the Viterbi algorithm to choose the plaintext decoding p that maximizes P(p)·Pθ(c|p)&amp;quot; stretching the channel probabilities. 2. Bayesian Decipherment method using word+n-gram LMs (novel approach described in Section 3.1). Evaluation: We evaluate the quality of a particular decipherment as the percentage of cipher tokens that are decoded correctly. Results: Figure 2 compares the decipherment performance for the EM method with Bayesian decipherment (using </context>
</contexts>
<marker>Knight, Nair, Rathod, Yamada, 2006</marker>
<rawString>Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Yamada. 2006. Unsupervised analysis for decipherment problems. In Proceedings of the Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics, pages 499–506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Type-based MCMC.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>573--581</pages>
<contexts>
<context position="17403" citStr="Liang et al. (2010)" startWordPosition="3221" endWordPosition="3224">at a time. But we already know that the substitution ciphers described here exhibit determinism in the deciphering direction,1 i.e., although we have no idea about the key mappings themselves, we do know that there exists only a single plaintext letter mapping for every cipher symbol type in the true key. So sampling plaintext choices for every cipher token separately is not an efficient strategy— our sampler may spend too much time exploring invalid keys (which map the same cipher symbol to different plaintext letters). Instead, we use a type sampling technique similar to the one proposed by Liang et al. (2010). Under 1This assumption does not strictly apply to the Zodiac-408 cipher where a few cipher symbols exhibit non-determinism in the decipherment direction as well. this scheme, we sample plaintext letter choices for each cipher symbol type. In every step, we sample a new plaintext letter for a cipher type and update the entire plaintext hypothesis (i.e., plaintext letters at all corresponding positions) to reflect this change. For example, if we sample a new choice pnew for a cipher symbol which occurs at positions 4,10,18, then we update plaintext letters p4, p10 and p18 with the new choice p</context>
</contexts>
<marker>Liang, Jordan, Klein, 2010</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2010. Type-based MCMC. In Proceedings of the Conference on Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 573– 581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edwin Olson</author>
</authors>
<title>Robust dictionary attack of short simple substitution ciphers.</title>
<date>2007</date>
<journal>Cryptologia,</journal>
<volume>31</volume>
<issue>4</issue>
<pages>342</pages>
<contexts>
<context position="1495" citStr="Olson, 2007" startWordPosition="217" endWordPosition="218"> fully automated fashion, which has never been done before. 1 Introduction Substitution ciphers have been used widely in the past to encrypt secrets behind messages. These ciphers replace (English) plaintext letters with cipher symbols in order to generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts conta</context>
</contexts>
<marker>Olson, 2007</marker>
<rawString>Edwin Olson. 2007. Robust dictionary attack of short simple substitution ciphers. Cryptologia, 31(4):332– 342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Oranchak</author>
</authors>
<title>Evolutionary algorithm for decryption of monoalphabetic homophonic substitution ciphers encoded as constraint satisfaction problems.</title>
<date>2008</date>
<booktitle>In Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation,</booktitle>
<pages>1717--1718</pages>
<contexts>
<context position="2948" citStr="Oranchak (2008)" startWordPosition="439" endWordPosition="440">ving simple substitution ciphers. Most work in this area has focused on solving simple substitution ciphers. But there are variants of substitution ciphers, such as homophonic ciphers, which display increasing levels of difficulty and present significant challenges for decipherment. The famous Zodiac serial killer used one such cipher system for communication. In 1969, the killer sent a three-part cipher message to newspapers claiming credit for recent shootings and crimes committed near the San Francisco area. The 408-character message (Zodiac-408) was manually decoded by hand in the 1960’s. Oranchak (2008) presents a method for solving the Zodiac-408 cipher automatically with a dictionary-based attack using a genetic algorithm. However, his method relies on using plaintext words from the known solution to solve the cipher, which departs from a strict decipherment scenario. In this paper, we introduce a novel method for 239 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 239–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics solving substitution ciphers using Bayesian learning. Our novel contributions are as fo</context>
</contexts>
<marker>Oranchak, 2008</marker>
<rawString>David Oranchak. 2008. Evolutionary algorithm for decryption of monoalphabetic homophonic substitution ciphers encoded as constraint satisfaction problems. In Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation, pages 1717–1718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shmuel Peleg</author>
<author>Azriel Rosenfeld</author>
</authors>
<title>Breaking substitution ciphers using a relaxation algorithm.</title>
<date>1979</date>
<journal>Comm. ACM,</journal>
<volume>22</volume>
<issue>11</issue>
<contexts>
<context position="1438" citStr="Peleg and Rosenfeld, 1979" startWordPosition="207" endWordPosition="210"> demonstrate its utility by cracking the famous Zodiac-408 cipher in a fully automated fashion, which has never been done before. 1 Introduction Substitution ciphers have been used widely in the past to encrypt secrets behind messages. These ciphers replace (English) plaintext letters with cipher symbols in order to generate the ciphertext sequence. There exist many published works on automatic decipherment methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. </context>
</contexts>
<marker>Peleg, Rosenfeld, 1979</marker>
<rawString>Shmuel Peleg and Azriel Rosenfeld. 1979. Breaking substitution ciphers using a relaxation algorithm. Comm. ACM, 22(11):598–605.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Attacking decipherment problems optimally with low-order n-gram models.</title>
<date>2008</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>812--819</pages>
<contexts>
<context position="1843" citStr="Ravi and Knight (2008)" startWordPosition="271" endWordPosition="274">nt methods for solving simple lettersubstitution ciphers. Many existing methods use dictionary-based attacks employing huge word dictionaries to find plaintext patterns within the ciphertext (Peleg and Rosenfeld, 1979; Ganesan and Sherman, 1993; Jakobsen, 1995; Olson, 2007). Most of these methods are heuristic in nature and search for the best deterministic key during decipherment. Others follow a probabilistic decipherment approach. Knight et al. (2006) use the Expectation Maximization (EM) algorithm (Dempster et al., 1977) to search for the best probabilistic key using letter n-gram models. Ravi and Knight (2008) formulate decipherment as an integer programming problem and provide an exact method to solve simple substitution ciphers by using letter n-gram models along with deterministic key constraints. Corlett and Penn (2010) work with large ciphertexts containing thousands of characters and provide another exact decipherment method using an A* search algorithm. Diaconis (2008) presents an analysis of Markov Chain Monte Carlo (MCMC) sampling algorithms and shows an example application for solving simple substitution ciphers. Most work in this area has focused on solving simple substitution ciphers. B</context>
</contexts>
<marker>Ravi, Knight, 2008</marker>
<rawString>Sujith Ravi and Kevin Knight. 2008. Attacking decipherment problems optimally with low-order n-gram models. In Proceedings of the Empirical Methods in Natural Language Processing (EMNLP), pages 812– 819.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Probabilistic methods for a Japanese syllable cipher.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on the Computer Processing of Oriental Languages (ICCPOL),</booktitle>
<pages>270--281</pages>
<contexts>
<context position="25583" citStr="Ravi and Knight (2009)" startWordPosition="4532" endWordPosition="4535">for the channel model (Q = 0.01 versus 1.0) helps for such problems and produces better decipherment results (97.8% versus 24.0% accuracy). • Type versus Point-wise sampling—Unlike point-wise sampling, type sampling quickly converges to better decipherment solutions. After 5000 sampling passes over the entire data, decipherment output from type sampling scores 97.8% accuracy compared to 14.5% for the point-wise sampling run.5 We also perform experiments on shorter substitution ciphers. On a 98-letter simple substitution cipher, EM using 3-gram LM achieves 41% accuracy, whereas the method from Ravi and Knight (2009) scores 84% accuracy. Our Bayesian method performs the best in this case, achieving 100% with word+3-gram LM. 5 Conclusion In this work, we presented a novel Bayesian decipherment approach that can effectively solve a va5Both sampling runs were seeded with the same random initial sample. riety of substitution ciphers. Unlike previous approaches, our method combines information from letter n-gram language models and word dictionaries and provides a robust decipherment model. We empirically evaluated the method on different substitution ciphers and achieve perfect decipherments on all of them. U</context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Probabilistic methods for a Japanese syllable cipher. In Proceedings of the International Conference on the Computer Processing of Oriental Languages (ICCPOL), pages 270– 281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
<author>Kevin Knight</author>
</authors>
<title>A statistical model for lost language decipherment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1048--1057</pages>
<contexts>
<context position="11357" citStr="Snyder et al. (2010)" startWordPosition="1857" endWordPosition="1860">cover the hidden plaintext message p1...pn. The size of the keyspace (i.e., number of possible key mappings) that we have to navigate during decipherment is huge—a simple substitution cipher has a keyspace size of 26!, whereas a homophonic cipher such as the Zodiac-408 cipher has 2654 possible key mappings. Next, we describe a new Bayesian decipherment approach for tackling substitution ciphers. 3.1 Bayesian Decipherment Bayesian inference methods have become popular in natural language processing (Goldwater and Griffiths, 2007; Finkel et al., 2005; Blunsom et al., 2009; Chiang et al., 2010). Snyder et al. (2010) proposed a Bayesian approach in an archaeological decipherment scenario. These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference. A common phenomenon observed while modeling natural language problems is sparsity. For simple letter substitution ciphers, the original substitution key exhibits a 1-to-1 correspondence between the plaintext letters and cipher types. It is not easy to model such information using conventional methods like EM. But we can easily specify priors that favor sparse distribut</context>
</contexts>
<marker>Snyder, Barzilay, Knight, 2010</marker>
<rawString>Benjamin Snyder, Regina Barzilay, and Kevin Knight. 2010. A statistical model for lost language decipherment. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1048–1057.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>