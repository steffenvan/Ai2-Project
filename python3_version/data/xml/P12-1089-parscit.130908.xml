<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008244">
<title confidence="0.99306">
Discriminative Learning for Joint Template Filling
</title>
<author confidence="0.861376">
Einat Minkov
</author>
<affiliation confidence="0.8937575">
Information Systems
University of Haifa
</affiliation>
<address confidence="0.782314">
Haifa 31905, Israel
</address>
<email confidence="0.99901">
einatm@is.haifa.ac.il
</email>
<author confidence="0.990127">
Luke Zettlemoyer
</author>
<affiliation confidence="0.994099">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.621141">
Seattle, WA 98195, USA
</address>
<email confidence="0.998945">
lsz@cs.washington.edu
</email>
<sectionHeader confidence="0.993899" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999931055555556">
This paper presents a joint model for tem-
plate filling, where the goal is to automati-
cally specify the fields of target relations such
as seminar announcements or corporate acqui-
sition events. The approach models mention
detection, unification and field extraction in
a flexible, feature-rich model that allows for
joint modeling of interdependencies at all lev-
els and across fields. Such an approach can,
for example, learn likely event durations and
the fact that start times should come before
end times. While the joint inference space is
large, we demonstrate effective learning with
a Perceptron-style approach that uses simple,
greedy beam decoding. Empirical results in
two benchmark domains demonstrate consis-
tently strong performance on both mention de-
tection and template filling tasks.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999571375">
Information extraction (IE) systems recover struc-
tured information from text. Template filling is an IE
task where the goal is to populate the fields of a tar-
get relation, for example to extract the attributes of a
job posting (Califf and Mooney, 2003) or to recover
the details of a corporate acquisition event from a
news story (Freitag and McCallum, 2000).
This task is challenging due to the wide range
of cues from the input documents, as well as non-
textual background knowledge, that must be consid-
ered to find the best joint assignment for the fields
of the extracted relation. For example, Figure 1
shows an extraction from CMU seminar announce-
ment corpus (Freitag and McCallum, 2000). Here,
the goal is to perform mention detection and extrac-
tion, by finding all of the text spans, or mentions,
</bodyText>
<table confidence="0.944852166666667">
Date 5/5/1995
Start Time 3:30PM
Location Wean Hall 5409
Speaker Raj Reddy
Title Some Necessary Conditions for a Good User Interface
End Time –
</table>
<figureCaption confidence="0.998516">
Figure 1: An example email and its template. Field men-
tions are highlighted in the text, grouped by color.
</figureCaption>
<bodyText confidence="0.999617117647059">
that describe field values, unify these mentions by
grouping them according to target field, and normal-
izing the results within each group to provide the
final extractions. Each of these steps requires sig-
nificant knowledge about the target relation. For ex-
ample, in Figure 1, the mention “3:30” appears three
times and provides the only reference to a time. We
must infer that this is the starting time, that the end
time is never explicitly mentioned, and also that the
event is in the afternoon. Such inferences may not
hold in more general settings, such as extraction for
medical emergencies or related events.
In this paper, we present a joint modeling and
learning approach for the combined tasks of men-
tion detection, unification, and template filling, as
described above. As we will see in Section 2, pre-
vious work has mostly focused on learning tagging
</bodyText>
<page confidence="0.981042">
845
</page>
<note confidence="0.9857455">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 845–853,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.99978435483871">
models for mention detection, which can be diffi-
cult to aggregate into a full template extraction, or
directly learning template field value extractors, of-
ten in isolation and with no reasoning across differ-
ent fields in the same relation. We present a simple,
feature-rich, discriminative model that readily incor-
porates a broad range of possible constraints on the
mentions and joint field assignments.
Such an approach allows us to learn, for each tar-
get relation, an integrated model to weight the dif-
ferent extraction options, including for example the
likely lengths for events, or the fact that start times
should come before end times. However, there are
significant computation challenges that come with
this style of joint learning. We demonstrate empiri-
cally that these challenges can be solved with a com-
bination of greedy beam decoding, performed di-
rectly in the joint space of possible mention clusters
and field assignments, and structured Perceptron-
style learning algorithm (Collins, 2002).
We report experimental evaluations on two bench-
mark datasets in different genres, the CMU semi-
nar announcements and corporate acquisitions (Fre-
itag and McCallum, 2000). In each case, we evalu-
ated both template extraction and mention detection
performance. Our joint learning approach provides
consistently strong results across every setting, in-
cluding new state-of-the-art results. We also demon-
strate, through ablation studies on the feature set, the
need for joint modeling and the relative importance
of the different types of joint constraints.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99994749122807">
Research on the task of template filling has focused
on the extraction of field value mentions from the
underlying text. Typically, these values are extracted
based on local evidence, where the most likely entity
is assigned to each slot (Roth and Yih, 2001; Siefkes,
2008). There has been little effort towards a compre-
hensive approach that includes mention unification,
as well as considers the structure of the target rela-
tional schema to create semantically valid outputs.
Recently, Haghighi and Klein (2010) presented
a generative semi-supervised approach for template
filling. In their model, slot-filling entities are first
generated, and entity mentions are then realized in
text. Thus, their approach performs coreference at
slot level. In addition to proper nouns (named en-
tity mentions) that are considered in this work, they
also account for nominal and pronominal noun men-
tions. This work presents a discriminative approach
to this problem. An advantage of a discriminative
framework is that it allows the incorporation of rich
and possibly overlapping features. In addition, we
enforce label consistency and semantic coherence at
record level.
Other related works perform structured relation
discovery for different settings of information ex-
traction. In open IE, entities and relations may be in-
ferred jointly (Roth and Yih, 2002; Yao et al., 2011).
In this IE task, the target relation must agree with the
entity types assigned to it; e.g., born-in relation re-
quires a place as its argument. In addition, extracted
relations may be required to be consistent with an
existing ontology (Carlson et al., 2010). Compared
with the extraction of tuples of entity mention pairs,
template filling is associated with a more complex
target relational schema.
Interestingly, several researchers have attempted
to model label consistency and high-level relational
constraints using state-of-the-art sequential models
of named entity recognition (NER). Mainly, pre-
determined word-level dependencies were repre-
sented as links in the underlying graphical model
(Sutton and McCallum, 2004; Finkel et al., 2005).
Finkel et al. (2005) further modelled high-level se-
mantic constraints; for example, using the CMU
seminar announcements dataset, spans labeled as
start time or end time were required to be seman-
tically consistent. In the proposed framework we
take a bottom-up approach to identifying entity men-
tions in text, where given a noisy set of candidate
named entities, described using rich semantic and
surface features, discriminative learning is applied
to label these mentions. We will show that this ap-
proach yields better performance on the CMU semi-
nar announcement dataset when evaluated in terms
of NER. Our approach is complimentary to NER
methods, as it can consolidate noisy overlapping
predictions from multiple systems into coherent sets.
</bodyText>
<sectionHeader confidence="0.980298" genericHeader="method">
3 Problem Setting
</sectionHeader>
<bodyText confidence="0.9984745">
In the template filling task, a target relation r is pro-
vided, comprised of attributes (also referred to as
</bodyText>
<page confidence="0.998985">
846
</page>
<figureCaption confidence="0.9999645">
Figure 2: The relational schema for the seminars domain.
Figure 3: A record partially populated from text.
</figureCaption>
<bodyText confidence="0.993472814285715">
fields, or slots) A(r). Given a document d, which
is known to describe a tuple of the underlying re-
lation, the goal is to populate the fields with values
based on the text.
The relational schema. In this work, we describe
domain knowledge through an extended relational
database schema R. In this schema, every field of
the target relation maps to a tuple of another rela-
tion, giving rise to a hierarchical view of template
filling. Figure 2 describes a relational schema for
the seminar announcement domain. As shown, each
field of the seminar relation maps to another rela-
tion; e.g., speaker’s values correspond to person tu-
ples. According to the outlined schema, most re-
lations (e.g., person) consist of a single attribute,
whereas the date and time relations are characterised
with multiple attributes; for example, the time rela-
tion includes the fields of hour, minutes and ampm.
We will make use of limited domain knowledge,
expressed as relation-level constraints that are typi-
cally realized in a database. Namely, the following
tests are supported for each relation.
Tuple validity. This test reflects data integrity. The
attributes of a relation may be defined as mandatory
or optional. Mandatory attributes are denoted with a
solid boundary in Figure 2 (e.g., seminar.date), and
optional attributes are denoted with a dashed bound-
ary (e.g., seminar.title). Similar constraints can be
posed on a set of attributes; e.g., either day-of-month
or day-of-week must be populated in the date rela-
tion. Finally, a combination of field values may be
required to be valid, e.g., the values of day, month,
year and day-of-week must be consistent.
Tuple contradiction. This function checks
whether two valid tuples v1 and v2 are inconsis-
tent, implying a negation of possible unification of
these tuples. In this work, we consider date and time
tuples as contradictory if they contain semantically
different values for some field; tuples of location,
person and title are required to have minimal over-
lap in their string values to avoid contradiction.
Template filling. Given document d, the hierar-
chical schema R is populated in a bottom-up fash-
ion. Generally, parent-free relations in the hierar-
chy correspond to generic entities, realized as en-
tity mentions in the text. In Figure 2, these relations
are denoted by double-line boundary, including lo-
cation, person, title, date and time; every tuple of
these relations maps to a named entity mention.1
Figure 3 demonstrates the correct mapping of
named entity mentions to tuples, as well as tuple uni-
fication, for the example shown in Figure 1. For ex-
ample, the mentions “Wean 5409” and “Wean Hall
5409” correspond to tuples of the location relation,
where the two tuples are resolved into a unified set.
To complete template filling, the remaining relations
of the schema are populated bottom-up, where each
field links to a unified set of populated tuples. For
example, in Figure 3, the seminar.location field is
linked to {“Wean Hall 5409”,“Wean 5409”j.
Value normalization of the unified tuples is an-
other component of template filling. We partially ad-
dress normalization: tuples of semantically detailed
(multi-attribute) relations, e.g., date and time, are re-
solved into their semantic union, while textual tuples
(e.g., location) are normalized to the longest string
in the set. In this work, we assume that each tem-
plate slot contains at most one value. This restriction
can be removed, at the cost of increasing the size of
the decoding search space.
</bodyText>
<footnote confidence="0.599528666666667">
1In the multi-attribute relations of date and time, each at-
tribute maps to a text span, where the set of spans at tuple-level
is required to be sequential (up to a small distance d).
</footnote>
<page confidence="0.996092">
847
</page>
<sectionHeader confidence="0.987512" genericHeader="method">
4 Structured Learning
</sectionHeader>
<bodyText confidence="0.9999528">
Next, we describe how valid candidate extrac-
tions are instantiated (Sec. 4.1) and how learning
is applied to assess the quality of the candidates
(Sec. 4.2), where beam search is used to find the top
scoring candidates efficiently (Sec. 4.3).
</bodyText>
<subsectionHeader confidence="0.998483">
4.1 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.999975757575758">
Named entity recognition. A set of candidate men-
tions Sd(a) is extracted from document d per each
attribute a of a relation r E L, where L is the set
of parent-free relations in T. We aim at high-recall
extractions; i.e., Sd(a) is expected to contain the cor-
rect mentions with high probability. Various IE tech-
niques, as well as an ensemble of methods, can be
employed for this purpose. For each relation r E L,
valid candidate tuples Ed(r) are constructed from
the candidate mentions that map to its attributes.
Unification. For every relation r E L, we con-
struct candidate sets of unified tuples, IQ(r) C
Ed(r)}. Naively, the number of candidate sets is
exponential in the size of Ed(t). Importantly, how-
ever, the tuples within a candidate unification set are
required to be non-contradictory. In addition, the
text spans that comprise the mentions within each
set must not overlap. Finally, we do not split tuples
with identical string values between different sets.
Candidate tuples. To construct the space of candi-
date tuples of the target relation, the remaining rela-
tions r E IT −L} are visited bottom-up, where each
field a E A(r) is mapped in turn to a (possibly uni-
fied) populated tuple of its type. The valid (and non-
overlapping) combinations of field mappings consti-
tute a set of candidate tuples of r.
The candidate tuples generated using this proce-
dure are structured entities, constructed using typed
named entity recognition, unification, and hierarchi-
cal assignment of field values (Figure 3). We will
derive features that describe local and global prop-
erties of the candidate tuples, encoding both surface
and semantic information.
</bodyText>
<subsectionHeader confidence="0.993947">
4.2 Learning
</subsectionHeader>
<bodyText confidence="0.996856">
We employ a discriminative learning algorithm, fol-
lowing Collins (2002). Our goal is to find the candi-
</bodyText>
<listItem confidence="0.798302590909091">
Algorithm 1: The beam search procedure
1. Populate every low-level relation r E L from text d:
• Construct a set of candidate valid tuples Ed(r) given
high-recall typed candidate text spans Sd(a), a E A(r).
• Group Ed(r) into possibly overlapping unified sets,
{Cd(r) C Ed(r)}.
2. Iterate bottom-up through relations r E {T − L}:
• Initialize the set of candidate tuples Ed(r) to an empty
set.
• Iterate through attributes a E A(r):
– Retrieve the set of candidate tuples (or unified tuple
sets) Ed(r′), where r′ is the relation that attribute a
links to in T. Add an empty tuple to the set.
– For every pair of candidate tuples e E Ed(r) and
e′ E Ed(r′), modify e by linking attribute a(e) to
tuple e′.
– Add the modified tuples, if valid, to Ed(r).
– Apply Equation 1 to rank the partially filled candi-
date tuples e E Ed(r). Keep the k top scoring can-
didates in Ed(r), and discard the rest.
3. Apply Equation 1 to output a ranked list of extracted records
Ed(r*), where r* is the target relation.
</listItem>
<bodyText confidence="0.813567">
date that maximizes:
</bodyText>
<equation confidence="0.956458333333333">
m
F(y, a) = E αjfj(y,d,T) (1)
j=1
</equation>
<bodyText confidence="0.999929625">
where fj(d, y, T), j = 1,.., m, are pre-defined fea-
ture functions describing a candidate record y of the
target relation given document d and the extended
schema T. The parameter weights αj are to be
learned from labeled instances. The training pro-
cedure involves initializing the weights α� to zero.
Given a, an inference procedure is applied to find
the candidate that maximizes Equation 1. If the top-
scoring candidate is different from the correct map-
ping known, then: (i) α� is incremented with the fea-
ture vector of the correct candidate, and (ii) the fea-
ture vector of the top-scoring candidate is subtracted
from a. This procedure is repeated for a fixed num-
ber of epochs. Following Collins, we employ the av-
eraged Perceptron online algorithm (Collins, 2002;
Freund and Schapire, 1999) for weight learning.
</bodyText>
<subsectionHeader confidence="0.997096">
4.3 Beam Search
</subsectionHeader>
<bodyText confidence="0.9999666">
Unfortunately, optimal local decoding algorithms
(such as the Viterbi algorithm in tagging problems
(Collins, 2002)) can not be applied to our prob-
lem. We therefore propose using beam search to ef-
ficiently find the top scoring candidate. This means
</bodyText>
<page confidence="0.988062">
848
</page>
<bodyText confidence="0.999939142857143">
that rather than instantiate the full space of valid can-
didate records (Section 4.1), we are interested in in-
stantiating only those candidates that are likely to be
assigned a high score by F. Algorithm 1 outlines
the proposed beam search procedure. As detailed,
only a set of top scoring tuples of size k (beam size)
is maintained per relation r E T during candidate
generation. A given relation is populated incremen-
tally, having each of its attributes a E A(r) map in
turn to populated tuples of its type, and using Equa-
tion 1 to find the k highest scoring partially popu-
lated tuples; this limits the number of candidate tu-
ples evaluated to k2 per attribute, and to nk2 for a
relation with n attributes. While beam search is effi-
cient, performance may be compromised compared
with an unconstrained search. The beam size k al-
lows controlling the trade-off between performance
and cost. An advantage of the proposed approach is
that rather than output a single prediction, a list of
coherent candidate tuples may be generated, ranked
according to Equation 1.
</bodyText>
<sectionHeader confidence="0.991235" genericHeader="method">
5 Seminar Extraction Task
</sectionHeader>
<bodyText confidence="0.9997577">
Dataset The CMU seminar announcement dataset
(Freitag and McCallum, 2000) includes 485 emails
containing seminar announcements. The dataset has
been originally annotated with text spans referring to
four slots: speaker, location, stime, and etime. We
have annotated this dataset with two additional at-
tributes: date and title.2 We consider this corpus as
an example of semi-structured text, where some of
the field values appear in the email header, in a tabu-
lar structure, or using special formatting (Califf and
Mooney, 1999; Minkov et al., 2005).3
We used a set of rules to extract candidate named
entities per the types specified in Figure 2.4 The
rules encode information typically used in NER, in-
cluding content and contextual patterns, as well as
lookups in available dictionaries (Finkel et al., 2005;
Minkov et al., 2005). The extracted candidates are
high-recall and overlapping. In order to increase
recall further, additional candidates were extracted
based on document structure (Siefkes, 2008). The
</bodyText>
<footnote confidence="0.9791806">
2A modified dataset is available on the author’s homepage.
3Such structure varies across messages. Otherwise, the
problem would reduce to wrapper learning (Zhu et al., 2006).
4The rule language used is based on cascaded finite state
machines (Minorthird, 2008).
</footnote>
<bodyText confidence="0.989027">
recall for the named entities of type date and time is
near perfect, and is estimated at 96%, 91% and 90%
for location, speaker and title, respectively.
Features The categories of the features used are
described below. All features are binary and typed.5
Lexical. These features indicate the value and
pattern of words within the text spans correspond-
ing to each field. For example, lexical features per
Figure 1 include location.content.word.wean, loca-
tion.pattern.capitalized. Similar features are derived
for a window of three words to the right and to the
left of the included spans. In addition, we observe
whether the words that comprise the text spans ap-
pear in relevant dictionaries: e.g., whether the spans
assigned to the location field include words typi-
cal of location, such as “room” or “hall”. Lex-
ical features of this form are commonly used in
NER (Finkel et al., 2005; Minkov et al., 2005).
Structural. It has been previously shown that
the structure available in semi-structured documents
such as email messages is useful for information ex-
traction (Minkov et al., 2005; Siefkes, 2008). As
shown in Figure 1, an email message includes a
header, specifying textual fields such as topic, dates
and time. In addition, space lines and line breaks are
used to emphasize blocks of important information.
We propose a set of features that model correspon-
dence between the text spans assigned to each field
and document structure. Specifically, these features
model whether at least one of the spans mapped to
each field appears in the email header; captures a
full line in the document; is indent; appears within
space lines; or in a tabular format. In Figure 1, struc-
tural active features include location.inHeader, lo-
cation.fullLine, title.withinSpaceLines, etc.
Semantic. These features refer to the semantic
interpretation of field values. According to the re-
lational schema (Figure 2), date and time include
detailed attributes, whereas other relations are rep-
resented as strings. The semantic features encoded
therefore refer to date and time only. Specifically,
these features indicate whether a unified set of tu-
ples defines a value for all attributes; for example,
in Figure 1, the union of entities that map to the
date field specify all of the attribute values of this
relation, including day-of-month, month, year, and
5Real-value features were discretized into segments.
</bodyText>
<page confidence="0.995958">
849
</page>
<table confidence="0.999926166666667">
Date Stime Etime Location Speaker Title
Full model 96.1 99.3 98.7 96.4 87.5 69.5
No structural features 94.9 99.1 98.0 96.1 83.8 65.1
No semantic features 96.1 98.7 95.4 96.4 87.5 69.5
No unification 87.2 97.0 95.1 94.5 76.0 62.7
Individual fields 96.5 97.2 - 96.4 86.8 64.5
</table>
<tableCaption confidence="0.99322">
Table 1: Seminar extraction results (5-fold CV): Field-level F1
</tableCaption>
<table confidence="0.999893166666667">
Date Stime Etime Location Speaker Title
SNOW (Roth and Yih, 2001) - 99.6 96.3 75.2 73.8 -
BIEN (Peshkin and Pfeffer, 2003) - 96.0 98.8 87.1 76.9 -
Elie (Finn, 2006) - 98.5 96.4 86.5 88.5 -
TIE (Siefkes, 2008) - 99.3 97.1 81.7 85.4 -
Full model 96.3 99.1 98.0 96.9 85.8 67.7
</table>
<tableCaption confidence="0.999433">
Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1
</tableCaption>
<bodyText confidence="0.998827785714286">
day-of-week. Another feature encodes the size of the
most semantically detailed named entity that maps
to a field; for example, the most detailed entity men-
tion of type stime in Figure 1 is “3:30”, compris-
ing of two attribute values, namely hour and min-
utes. Similarly, the total number of semantic units
included in a unified set is represented as a feature.
These features were designed to favor semantically
detailed mentions and unified sets. Finally, domain-
specific semantic knowledge is encoded as features,
including the duration of the seminar, and whether a
time value is round (minutes divide by 5).
In addition to the features described, one may
be interested in modeling cross-field information.
We have experimented with features that encode
the shortest distance between named entity mentions
mapping to different fields (measured in terms of
separating lines or sentences), based on the hypoth-
esis that field values typically co-appear in the same
segments of the document. These features were not
included in the final model since their contribution
was marginal. We leave further exploration of cross-
field features in this domain to future work.
Experiments We conducted 5-fold cross vali-
dation experiments using the seminar extraction
dataset. As discussed earlier, we assume that a sin-
gle record is described in each document, and that
each field corresponds to a single value. These
assumptions are violated in a minority of cases.
In evaluating the template filling task, only exact
matches are accepted as true positives, where partial
matches are counted as errors (Siefkes, 2008). No-
tably, the annotated labels as well as corpus itself are
not error-free; for example, in some announcements
the date and day-of-week specified are inconsistent.
Our evaluation is strict, where non-empty predicted
values are counted as errors in such cases.
Table 1 shows the results of our full model us-
ing beam size k = 10, as well as model variants.
In order to evaluate the contribution of the proposed
features, we eliminated every feature group in turn.
As shown in the table, removing the structural fea-
tures hurt performance consistently across fields. In
particular, structure is informative for the title field,
which is otherwise characterised with low content
and contextual regularity. Removal of the semantic
features affected performance on the stime and etime
fields, modeled by these features. In particular, the
optional etime field, which has fewer occurrences in
the dataset, benefits from modeling semantics.
An important question to be addressed in evalu-
ation is to what extent the joint modeling approach
contributes to performance. In another experiment
we therefore mimic the typical scenario of template
filling, in which the value of the highest scoring
named entity is assigned to each field. In our frame-
work, this corresponds to a setting in which a unified
set includes no more than a single entity. The results
are shown in Table 1 (‘no unification’). Due to re-
duced evidence given a single entity versus a a coref-
erent set of entities, this results in significantly de-
graded performance. Finally, we experimented with
populating every field of the target schema indepen-
dently of the other fields. While results are overall
comparable on most fields, this had negative impact
on the title field. This is largely due to erroneous as-
signments of named entities of other types (mainly,
person) as titles; such errors are avoided in the full
joint model, where tuple validity is enforced.
Table 2 provides a comparison of the full model
</bodyText>
<page confidence="0.98779">
850
</page>
<table confidence="0.99965125">
Date Stime Etime Location Speaker Title
(Sutton and McCallum, 2004) - 96.7 97.2 88.1 80.4 -
(Finkel et al., 2005) - 97.1 97.9 90.0 84.2 -
Full model 95.4 97.1 97.9 97.0 86.5 75.5
</table>
<tableCaption confidence="0.9994">
Table 3: Seminar extraction results: Token-level F1
</tableCaption>
<bodyText confidence="0.999942023255814">
against previous state-of-the-art results. These re-
sults were all obtained using half of the corpus for
training, and its remaining half for evaluation; the
reported figures were averaged over five random
splits. For comparison, we used 5-fold cross vali-
dation, where only a subset of each train fold that
corresponds to 50% of the corpus was used for train-
ing. Due to the reduced training data, the results are
slightly lower than in Table 1. (Note that we used the
same test examples in both cases.) The best results
per field are marked in boldface. The proposed ap-
proach yields the best or second-best performance
on all target fields, and gives the best performance
overall. While a variety of methods have been ap-
plied in previous works, none has modeled template
filling in a joint fashion. As argued before, joint
modeling is especially important for irregular fields,
such as title; we provide first results on this field.
Previously, Sutton and McCallum (2004) and
later Finkel et-al. (2005), applied sequential models
to perform NER on this dataset, identifying named
entities that pertain to the template slots. Both of
these works incorporated coreference and high-level
semantic information to a limited extent. We com-
pare our approach to their work, having obtained and
used the same 5-fold cross validation splits as both
works. Table 3 shows results in terms of token F1.
Our results evaluated on the named mention recogni-
tion task are superior overall, giving comparable or
best performance on all fields. We believe that these
results demonstrate the benefit of performing men-
tion recognition as part of a joint model that takes
into account detailed semantics of the underlying re-
lational schema, when available.
Finally, we evaluate the global quality of the ex-
tracted records. Rather than assess performance at
field-level, this stricter evaluation mode considers a
whole tuple, requiring the values assigned to all of
its fields to be correct. Overall, our full model (Table
1) extracts globally correct records for 52.6% of the
examples. To our knowledge, this is the first work
that provides this type of evaluation on this dataset.
Importantly, an advantage of the proposed approach
</bodyText>
<figureCaption confidence="0.998786">
Figure 4: The relational schema for acquisitions.
</figureCaption>
<bodyText confidence="0.999862833333333">
is that it readily outputs a ranked list of coherent pre-
dictions. While the performance at the top of the
output lists was roughly comparable, increasing k
gives higher oracle recall: the correct record was
included in the output k-top list 69.7%, 76.1% and
80.4% of the time, for k = 5, 10, 20 respectively.
</bodyText>
<sectionHeader confidence="0.988091" genericHeader="method">
6 Corporate Acquisitions
</sectionHeader>
<bodyText confidence="0.99996984">
Dataset The corporate acquisitions corpus con-
tains 600 newswire articles, describing factual or po-
tential corporate acquisition events. The corpus has
been annotated with the official names of the parties
to an acquisition: acquired, purchaser and seller, as
well as their corresponding abbreviated names and
company codes.6 We describe the target schema us-
ing the relational structure depicted in Figure 4. The
schema includes two relations: the corp relation de-
scribes a corporate entity, including its full name,
abbreviated name and code as attributes; the target
acquisition relation includes three role-designating
attributes, each linked to a corp tuple.
Candidate name mentions in this strictly gram-
matical genre correspond to noun phrases. Docu-
ments were pre-processed to extract noun phrases,
similarly to Haghighi and Klein (2010).
Features We model syntactic features, following
Haghighi and Klein (2010). In order to compen-
sate for parsing errors, shallow syntactic features
were added, representing the values of neighboring
verbs and prepositions (Cohen et al., 2005). While
newswire documents are mostly unstructured, struc-
tural features are used to indicate whether any of the
purchaser, acquired and seller text spans appears in
</bodyText>
<footnote confidence="0.972766333333333">
6In this work, we ignore other fields annotated, as they are
inconsistently defined, have low number of occurrences in the
corpus, and are loosely inter-related semantically.
</footnote>
<page confidence="0.98743">
851
</page>
<table confidence="0.9996325">
purname purabr purcode acqname acqabr acqcode sellname sellabr sellcode
TIE (batch) 55.7 58.1 - 53.5 55.0 - 31.8 25.8 -
TIE (inc) 51.6 55.3 - 49.2 51.7 - 26.0 24.0 -
Full model 48.9 55.0 70.2 50.7 55.2 67.2 33.2 36.8 55.4
Model variants:
No inter-type and struct. ftrs 45.1 50.5 66.8 49.8 53.9 66.4 34.9 42.2 56.0
No semantic features 42.6 38.4 58.1 40.5 36.5 44.8 32.2 26.6 46.6
Individual roles 43.9 48.7 62.5 45.0 47.2 52.7 34.1 40.3 47.8
</table>
<tableCaption confidence="0.968147">
Table 4: Corp. acquisition extraction results: Field-level F1
</tableCaption>
<table confidence="0.9993595">
purname purabr purcode acqname acqabr acqcode sellname sellabr sellcode
TIE (batch) 52.6 40.5 - 49.2 43.7 28.7 16.4 -
TIE (inc) 48.4 38.6 - 44.7 42.7 - 23.6 14.5 -
Full model 45.0 48.3 69.8 46.4 59.5 66.9 31.6 33.0 55.0
</table>
<tableCaption confidence="0.999578">
Table 5: Corp. acquisition extraction results: Entity-level F1
</tableCaption>
<bodyText confidence="0.99996221875">
the article’s header. Semantic features are applied
to corp tuples: we model whether the abbreviated
name is a subset of the full name; whether the cor-
porate code forms exact initials of the full or abbre-
viated names; or whether it has high string similarity
to any of these values. Finally, cross-type features
encode the shortest string between spans mapping
to different roles in the acquisition relation.
Experiments We applied beam search, where
corp tuples are extracted first, and acquisition tuples
are constructed using the top scoring corp entities.
We used a default beam size k = 10. The dataset is
split into a 300/300 train/test subsets.
Table 4 shows results of our full model in terms of
field-level F1, compared against TIE, a state-of-the-
art discriminative system (Siefkes, 2008). Unfortu-
nately, we can not directly compare against a gener-
ative joint model evaluated on this dataset (Haghighi
and Klein, 2010).7 The best results per attribute are
shown in boldface. Our full model performs bet-
ter overall than TIE trained incrementally (similarly
to our system), and is competitive with TIE using
batch learning. Interestingly, the performance of our
model on the code fields is high; these fields do
not involve boundary prediction, and thus reflect the
quality of role assignment.
Table 4 also shows the results of model vari-
ants. Removing the inter type and structural fea-
tures mildly hurt performance, on average. In con-
trast, the semantic features, which account for the
semantic cohesiveness of the populated corp tuples,
are shown to be necessary. In particular, remov-
</bodyText>
<footnote confidence="0.856598666666667">
7They report average performance on a different set of
fields; in addition, their results include modeling of pronouns
and nominal mentions, which are not considered here.
</footnote>
<bodyText confidence="0.999946769230769">
ing them degrades the extraction of the abbreviated
names; these features allow prediction of abbrevi-
ated names jointly with the full corporate names,
which are more regular (e.g., include a distinctive
suffix). Finally, we show results of predicting each
role filler individually. Inferring the roles jointly
(‘full model’) significantly improves performance.
Table 5 further shows results on NER, the task of
recovering the sets of named entity mentions per-
taining to each target field. As shown, the proposed
joint approach performs overall significantly better
than previous results reported. These results are con-
sistent with the case study of seminar extraction.
</bodyText>
<sectionHeader confidence="0.986189" genericHeader="conclusions">
7 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.999990578947368">
We presented a joint approach for template filling
that models mention detection, unification, and field
extraction in a flexible, feature-rich model. This ap-
proach allows for joint modeling of interdependen-
cies at all levels and across fields. Despite the com-
putational challenges of this joint inference space,
we obtained effective learning with a Perceptron-
style approach and simple beam decoding.
An interesting direction of future research is
to apply reranking to the output list of candidate
records using additional evidence, such as support-
ing evidence on the Web (Banko et al., 2008). Also,
modeling additional features or feature combina-
tions in this framework as well as effective feature
selection or improved parameter estimation (Cram-
mer et al., 2009) may boost performance. Finally,
it is worth exploring scaling the approach to unre-
stricted event extraction, and jointly model extract-
ing more than one relation per document.
</bodyText>
<page confidence="0.997218">
852
</page>
<sectionHeader confidence="0.995885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881710526315">
Michele Banko, Michael J. Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2008. Open in-
formation extraction from the web. In Proceedings of
IJCAI.
Mary Elaine Califf and Raymond J. Mooney. 1999. Re-
lational learning of pattern-match rules for information
extraction. In AAAI/IAAI.
Mary Elaine Califf and Raymond J. Mooney. 2003.
Bottom-up relational learning of pattern matching
rules for information extraction. Journal of Machine
Learning Research, 4.
Andrew Carlson, Justin Betteridge, Richard C. Wang, Es-
tevam R. Hruschka Jr., and Tom M. Mitchell. 2010.
Coupled semi-supervised learning for information ex-
traction. In Proceedings of WSDM.
William W. Cohen, Einat Minkov, and Anthony Toma-
sic. 2005. Learning to understand web site update re-
quests. In Proceedings of the international joint con-
ference on Artificial intelligence (IJCAI).
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Koby Crammer, Alex Kulesza, and Mark Dredze. 2009.
Adaptive regularization of weight vectors. In Ad-
vances in Neural Information Processing Systems
(NIPS).
Jenny Rose Finkel, Trond Grenager, , and Christopher D.
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In Proceedings ofACL.
Aidan Finn. 2006. A multi-level boundary classification
approach to information extraction. In PhD thesis.
Dayne Freitag and Andrew McCallum. 2000. In-
formation extraction with hmm structures learned by
stochastic optimization. In AAAI/IAAI.
Yoav Freund and Rob Schapire. 1999. Large margin
classification using the perceptron algorithm. Machine
Learning, 37(3).
Aria Haghighi and Dan Klein. 2010. An entity-level ap-
proach to information extraction. In Proceedings of
ACL.
Einat Minkov, Richard C. Wang, and William W. Cohen.
2005. Extracting personal names from emails: Ap-
plying named entity recognition to informal text. In
HLT/EMNLP.
Minorthird. 2008. Methods for identifying names and
ontological relations in text using heuristics for in-
ducing regularities from data. http://http://
minorthird.sourceforge.net.
Leonid Peshkin and Avi Pfeffer. 2003. Bayesian infor-
mation extraction network. In Proceedings of the in-
ternational joint conference on Artificial intelligence
(IJCAI).
Dan Roth and Wen-tau Yih. 2001. Relational learning
via propositional algorithms: An information extrac-
tion case study. In Proceedings of the international
joint conference on Artificial intelligence (IJCAI).
Dan Roth and Wen-tau Yih. 2002. Probabilistic reason-
ing for entity and relation recognition. In COLING.
Christian Siefkes. 2008. In An Incrementally Trainable
Statistical Approach to Information Extraction. VDM
Verlag.
Charles Sutton and Andrew McCallum. 2004. Collec-
tive segmentation and labeling of distant entities in in-
formation extraction. In Technical Report no. 04-49,
University ofMassachusetts.
Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew
McCallum. 2011. Structured relation discovery using
generative models. In Proceedings ofEMNLP.
Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and Wei-
Ying Ma. 2006. Simultaneous record detection and
attribute labeling in web data extraction. In Proc. of
the ACMSIGKDD Intl. Conf. on Knowledge Discovery
and Data Mining (KDD).
</reference>
<page confidence="0.999333">
853
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.742498">
<title confidence="0.999039">Discriminative Learning for Joint Template Filling</title>
<author confidence="0.873772">Einat Minkov</author>
<affiliation confidence="0.981034">Information Systems University of Haifa</affiliation>
<address confidence="0.998894">Haifa 31905, Israel</address>
<email confidence="0.9994">einatm@is.haifa.ac.il</email>
<author confidence="0.919596">Luke</author>
<affiliation confidence="0.9998185">Computer Science &amp; University of</affiliation>
<address confidence="0.998503">Seattle, WA 98195,</address>
<email confidence="0.999831">lsz@cs.washington.edu</email>
<abstract confidence="0.996261842105263">This paper presents a joint model for template filling, where the goal is to automatically specify the fields of target relations such as seminar announcements or corporate acquisition events. The approach models mention detection, unification and field extraction in a flexible, feature-rich model that allows for joint modeling of interdependencies at all levels and across fields. Such an approach can, for example, learn likely event durations and the fact that start times should come before end times. While the joint inference space is large, we demonstrate effective learning with a Perceptron-style approach that uses simple, greedy beam decoding. Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template filling tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2008</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2008. Open information extraction from the web. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Elaine Califf</author>
<author>Raymond J Mooney</author>
</authors>
<title>Relational learning of pattern-match rules for information extraction.</title>
<date>1999</date>
<booktitle>In AAAI/IAAI.</booktitle>
<contexts>
<context position="17366" citStr="Califf and Mooney, 1999" startWordPosition="2815" endWordPosition="2818">ent candidate tuples may be generated, ranked according to Equation 1. 5 Seminar Extraction Task Dataset The CMU seminar announcement dataset (Freitag and McCallum, 2000) includes 485 emails containing seminar announcements. The dataset has been originally annotated with text spans referring to four slots: speaker, location, stime, and etime. We have annotated this dataset with two additional attributes: date and title.2 We consider this corpus as an example of semi-structured text, where some of the field values appear in the email header, in a tabular structure, or using special formatting (Califf and Mooney, 1999; Minkov et al., 2005).3 We used a set of rules to extract candidate named entities per the types specified in Figure 2.4 The rules encode information typically used in NER, including content and contextual patterns, as well as lookups in available dictionaries (Finkel et al., 2005; Minkov et al., 2005). The extracted candidates are high-recall and overlapping. In order to increase recall further, additional candidates were extracted based on document structure (Siefkes, 2008). The 2A modified dataset is available on the author’s homepage. 3Such structure varies across messages. Otherwise, the</context>
</contexts>
<marker>Califf, Mooney, 1999</marker>
<rawString>Mary Elaine Califf and Raymond J. Mooney. 1999. Relational learning of pattern-match rules for information extraction. In AAAI/IAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Elaine Califf</author>
<author>Raymond J Mooney</author>
</authors>
<title>Bottom-up relational learning of pattern matching rules for information extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>4</volume>
<contexts>
<context position="1338" citStr="Califf and Mooney, 2003" startWordPosition="195" endWordPosition="198">ations and the fact that start times should come before end times. While the joint inference space is large, we demonstrate effective learning with a Perceptron-style approach that uses simple, greedy beam decoding. Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template filling tasks. 1 Introduction Information extraction (IE) systems recover structured information from text. Template filling is an IE task where the goal is to populate the fields of a target relation, for example to extract the attributes of a job posting (Califf and Mooney, 2003) or to recover the details of a corporate acquisition event from a news story (Freitag and McCallum, 2000). This task is challenging due to the wide range of cues from the input documents, as well as nontextual background knowledge, that must be considered to find the best joint assignment for the fields of the extracted relation. For example, Figure 1 shows an extraction from CMU seminar announcement corpus (Freitag and McCallum, 2000). Here, the goal is to perform mention detection and extraction, by finding all of the text spans, or mentions, Date 5/5/1995 Start Time 3:30PM Location Wean Ha</context>
</contexts>
<marker>Califf, Mooney, 2003</marker>
<rawString>Mary Elaine Califf and Raymond J. Mooney. 2003. Bottom-up relational learning of pattern matching rules for information extraction. Journal of Machine Learning Research, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Richard C Wang</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Coupled semi-supervised learning for information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of WSDM.</booktitle>
<contexts>
<context position="6395" citStr="Carlson et al., 2010" startWordPosition="1001" endWordPosition="1004">hat it allows the incorporation of rich and possibly overlapping features. In addition, we enforce label consistency and semantic coherence at record level. Other related works perform structured relation discovery for different settings of information extraction. In open IE, entities and relations may be inferred jointly (Roth and Yih, 2002; Yao et al., 2011). In this IE task, the target relation must agree with the entity types assigned to it; e.g., born-in relation requires a place as its argument. In addition, extracted relations may be required to be consistent with an existing ontology (Carlson et al., 2010). Compared with the extraction of tuples of entity mention pairs, template filling is associated with a more complex target relational schema. Interestingly, several researchers have attempted to model label consistency and high-level relational constraints using state-of-the-art sequential models of named entity recognition (NER). Mainly, predetermined word-level dependencies were represented as links in the underlying graphical model (Sutton and McCallum, 2004; Finkel et al., 2005). Finkel et al. (2005) further modelled high-level semantic constraints; for example, using the CMU seminar anno</context>
</contexts>
<marker>Carlson, Betteridge, Wang, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010. Coupled semi-supervised learning for information extraction. In Proceedings of WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Einat Minkov</author>
<author>Anthony Tomasic</author>
</authors>
<title>Learning to understand web site update requests.</title>
<date>2005</date>
<booktitle>In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</booktitle>
<contexts>
<context position="28697" citStr="Cohen et al., 2005" startWordPosition="4638" endWordPosition="4641">scribes a corporate entity, including its full name, abbreviated name and code as attributes; the target acquisition relation includes three role-designating attributes, each linked to a corp tuple. Candidate name mentions in this strictly grammatical genre correspond to noun phrases. Documents were pre-processed to extract noun phrases, similarly to Haghighi and Klein (2010). Features We model syntactic features, following Haghighi and Klein (2010). In order to compensate for parsing errors, shallow syntactic features were added, representing the values of neighboring verbs and prepositions (Cohen et al., 2005). While newswire documents are mostly unstructured, structural features are used to indicate whether any of the purchaser, acquired and seller text spans appears in 6In this work, we ignore other fields annotated, as they are inconsistently defined, have low number of occurrences in the corpus, and are loosely inter-related semantically. 851 purname purabr purcode acqname acqabr acqcode sellname sellabr sellcode TIE (batch) 55.7 58.1 - 53.5 55.0 - 31.8 25.8 - TIE (inc) 51.6 55.3 - 49.2 51.7 - 26.0 24.0 - Full model 48.9 55.0 70.2 50.7 55.2 67.2 33.2 36.8 55.4 Model variants: No inter-type and </context>
</contexts>
<marker>Cohen, Minkov, Tomasic, 2005</marker>
<rawString>William W. Cohen, Einat Minkov, and Anthony Tomasic. 2005. Learning to understand web site update requests. In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="4206" citStr="Collins, 2002" startWordPosition="665" endWordPosition="666"> assignments. Such an approach allows us to learn, for each target relation, an integrated model to weight the different extraction options, including for example the likely lengths for events, or the fact that start times should come before end times. However, there are significant computation challenges that come with this style of joint learning. We demonstrate empirically that these challenges can be solved with a combination of greedy beam decoding, performed directly in the joint space of possible mention clusters and field assignments, and structured Perceptronstyle learning algorithm (Collins, 2002). We report experimental evaluations on two benchmark datasets in different genres, the CMU seminar announcements and corporate acquisitions (Freitag and McCallum, 2000). In each case, we evaluated both template extraction and mention detection performance. Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results. We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints. 2 Related Work Research on the task of template </context>
<context position="13586" citStr="Collins (2002)" startWordPosition="2164" endWordPosition="2165">ach field a E A(r) is mapped in turn to a (possibly unified) populated tuple of its type. The valid (and nonoverlapping) combinations of field mappings constitute a set of candidate tuples of r. The candidate tuples generated using this procedure are structured entities, constructed using typed named entity recognition, unification, and hierarchical assignment of field values (Figure 3). We will derive features that describe local and global properties of the candidate tuples, encoding both surface and semantic information. 4.2 Learning We employ a discriminative learning algorithm, following Collins (2002). Our goal is to find the candiAlgorithm 1: The beam search procedure 1. Populate every low-level relation r E L from text d: • Construct a set of candidate valid tuples Ed(r) given high-recall typed candidate text spans Sd(a), a E A(r). • Group Ed(r) into possibly overlapping unified sets, {Cd(r) C Ed(r)}. 2. Iterate bottom-up through relations r E {T − L}: • Initialize the set of candidate tuples Ed(r) to an empty set. • Iterate through attributes a E A(r): – Retrieve the set of candidate tuples (or unified tuple sets) Ed(r′), where r′ is the relation that attribute a links to in T. Add an e</context>
<context position="15435" citStr="Collins, 2002" startWordPosition="2499" endWordPosition="2500">ded schema T. The parameter weights αj are to be learned from labeled instances. The training procedure involves initializing the weights α� to zero. Given a, an inference procedure is applied to find the candidate that maximizes Equation 1. If the topscoring candidate is different from the correct mapping known, then: (i) α� is incremented with the feature vector of the correct candidate, and (ii) the feature vector of the top-scoring candidate is subtracted from a. This procedure is repeated for a fixed number of epochs. Following Collins, we employ the averaged Perceptron online algorithm (Collins, 2002; Freund and Schapire, 1999) for weight learning. 4.3 Beam Search Unfortunately, optimal local decoding algorithms (such as the Viterbi algorithm in tagging problems (Collins, 2002)) can not be applied to our problem. We therefore propose using beam search to efficiently find the top scoring candidate. This means 848 that rather than instantiate the full space of valid candidate records (Section 4.1), we are interested in instantiating only those candidates that are likely to be assigned a high score by F. Algorithm 1 outlines the proposed beam search procedure. As detailed, only a set of top </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Alex Kulesza</author>
<author>Mark Dredze</author>
</authors>
<title>Adaptive regularization of weight vectors.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS).</booktitle>
<marker>Crammer, Kulesza, Dredze, 2009</marker>
<rawString>Koby Crammer, Alex Kulesza, and Mark Dredze. 2009. Adaptive regularization of weight vectors. In Advances in Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL.</booktitle>
<marker>Finkel, Grenager, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, , and Christopher D. Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aidan Finn</author>
</authors>
<title>A multi-level boundary classification approach to information extraction.</title>
<date>2006</date>
<note>In PhD thesis.</note>
<contexts>
<context position="21016" citStr="Finn, 2006" startWordPosition="3402" endWordPosition="3403">relation, including day-of-month, month, year, and 5Real-value features were discretized into segments. 849 Date Stime Etime Location Speaker Title Full model 96.1 99.3 98.7 96.4 87.5 69.5 No structural features 94.9 99.1 98.0 96.1 83.8 65.1 No semantic features 96.1 98.7 95.4 96.4 87.5 69.5 No unification 87.2 97.0 95.1 94.5 76.0 62.7 Individual fields 96.5 97.2 - 96.4 86.8 64.5 Table 1: Seminar extraction results (5-fold CV): Field-level F1 Date Stime Etime Location Speaker Title SNOW (Roth and Yih, 2001) - 99.6 96.3 75.2 73.8 - BIEN (Peshkin and Pfeffer, 2003) - 96.0 98.8 87.1 76.9 - Elie (Finn, 2006) - 98.5 96.4 86.5 88.5 - TIE (Siefkes, 2008) - 99.3 97.1 81.7 85.4 - Full model 96.3 99.1 98.0 96.9 85.8 67.7 Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1 day-of-week. Another feature encodes the size of the most semantically detailed named entity that maps to a field; for example, the most detailed entity mention of type stime in Figure 1 is “3:30”, comprising of two attribute values, namely hour and minutes. Similarly, the total number of semantic units included in a unified set is represented as a feature. These features were designed to favor se</context>
</contexts>
<marker>Finn, 2006</marker>
<rawString>Aidan Finn. 2006. A multi-level boundary classification approach to information extraction. In PhD thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
<author>Andrew McCallum</author>
</authors>
<title>Information extraction with hmm structures learned by stochastic optimization.</title>
<date>2000</date>
<booktitle>In AAAI/IAAI.</booktitle>
<contexts>
<context position="1444" citStr="Freitag and McCallum, 2000" startWordPosition="213" endWordPosition="216">arge, we demonstrate effective learning with a Perceptron-style approach that uses simple, greedy beam decoding. Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template filling tasks. 1 Introduction Information extraction (IE) systems recover structured information from text. Template filling is an IE task where the goal is to populate the fields of a target relation, for example to extract the attributes of a job posting (Califf and Mooney, 2003) or to recover the details of a corporate acquisition event from a news story (Freitag and McCallum, 2000). This task is challenging due to the wide range of cues from the input documents, as well as nontextual background knowledge, that must be considered to find the best joint assignment for the fields of the extracted relation. For example, Figure 1 shows an extraction from CMU seminar announcement corpus (Freitag and McCallum, 2000). Here, the goal is to perform mention detection and extraction, by finding all of the text spans, or mentions, Date 5/5/1995 Start Time 3:30PM Location Wean Hall 5409 Speaker Raj Reddy Title Some Necessary Conditions for a Good User Interface End Time – Figure 1: A</context>
<context position="4375" citStr="Freitag and McCallum, 2000" startWordPosition="687" endWordPosition="691">xample the likely lengths for events, or the fact that start times should come before end times. However, there are significant computation challenges that come with this style of joint learning. We demonstrate empirically that these challenges can be solved with a combination of greedy beam decoding, performed directly in the joint space of possible mention clusters and field assignments, and structured Perceptronstyle learning algorithm (Collins, 2002). We report experimental evaluations on two benchmark datasets in different genres, the CMU seminar announcements and corporate acquisitions (Freitag and McCallum, 2000). In each case, we evaluated both template extraction and mention detection performance. Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results. We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints. 2 Related Work Research on the task of template filling has focused on the extraction of field value mentions from the underlying text. Typically, these values are extracted based on local evidence, where the most lik</context>
<context position="16913" citStr="Freitag and McCallum, 2000" startWordPosition="2744" endWordPosition="2747"> find the k highest scoring partially populated tuples; this limits the number of candidate tuples evaluated to k2 per attribute, and to nk2 for a relation with n attributes. While beam search is efficient, performance may be compromised compared with an unconstrained search. The beam size k allows controlling the trade-off between performance and cost. An advantage of the proposed approach is that rather than output a single prediction, a list of coherent candidate tuples may be generated, ranked according to Equation 1. 5 Seminar Extraction Task Dataset The CMU seminar announcement dataset (Freitag and McCallum, 2000) includes 485 emails containing seminar announcements. The dataset has been originally annotated with text spans referring to four slots: speaker, location, stime, and etime. We have annotated this dataset with two additional attributes: date and title.2 We consider this corpus as an example of semi-structured text, where some of the field values appear in the email header, in a tabular structure, or using special formatting (Califf and Mooney, 1999; Minkov et al., 2005).3 We used a set of rules to extract candidate named entities per the types specified in Figure 2.4 The rules encode informat</context>
</contexts>
<marker>Freitag, McCallum, 2000</marker>
<rawString>Dayne Freitag and Andrew McCallum. 2000. Information extraction with hmm structures learned by stochastic optimization. In AAAI/IAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Rob Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>37</volume>
<issue>3</issue>
<contexts>
<context position="15463" citStr="Freund and Schapire, 1999" startWordPosition="2501" endWordPosition="2504">he parameter weights αj are to be learned from labeled instances. The training procedure involves initializing the weights α� to zero. Given a, an inference procedure is applied to find the candidate that maximizes Equation 1. If the topscoring candidate is different from the correct mapping known, then: (i) α� is incremented with the feature vector of the correct candidate, and (ii) the feature vector of the top-scoring candidate is subtracted from a. This procedure is repeated for a fixed number of epochs. Following Collins, we employ the averaged Perceptron online algorithm (Collins, 2002; Freund and Schapire, 1999) for weight learning. 4.3 Beam Search Unfortunately, optimal local decoding algorithms (such as the Viterbi algorithm in tagging problems (Collins, 2002)) can not be applied to our problem. We therefore propose using beam search to efficiently find the top scoring candidate. This means 848 that rather than instantiate the full space of valid candidate records (Section 4.1), we are interested in instantiating only those candidates that are likely to be assigned a high score by F. Algorithm 1 outlines the proposed beam search procedure. As detailed, only a set of top scoring tuples of size k (be</context>
</contexts>
<marker>Freund, Schapire, 1999</marker>
<rawString>Yoav Freund and Rob Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning, 37(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>An entity-level approach to information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5285" citStr="Haghighi and Klein (2010)" startWordPosition="828" endWordPosition="831"> need for joint modeling and the relative importance of the different types of joint constraints. 2 Related Work Research on the task of template filling has focused on the extraction of field value mentions from the underlying text. Typically, these values are extracted based on local evidence, where the most likely entity is assigned to each slot (Roth and Yih, 2001; Siefkes, 2008). There has been little effort towards a comprehensive approach that includes mention unification, as well as considers the structure of the target relational schema to create semantically valid outputs. Recently, Haghighi and Klein (2010) presented a generative semi-supervised approach for template filling. In their model, slot-filling entities are first generated, and entity mentions are then realized in text. Thus, their approach performs coreference at slot level. In addition to proper nouns (named entity mentions) that are considered in this work, they also account for nominal and pronominal noun mentions. This work presents a discriminative approach to this problem. An advantage of a discriminative framework is that it allows the incorporation of rich and possibly overlapping features. In addition, we enforce label consis</context>
<context position="28456" citStr="Haghighi and Klein (2010)" startWordPosition="4603" endWordPosition="4606">sition: acquired, purchaser and seller, as well as their corresponding abbreviated names and company codes.6 We describe the target schema using the relational structure depicted in Figure 4. The schema includes two relations: the corp relation describes a corporate entity, including its full name, abbreviated name and code as attributes; the target acquisition relation includes three role-designating attributes, each linked to a corp tuple. Candidate name mentions in this strictly grammatical genre correspond to noun phrases. Documents were pre-processed to extract noun phrases, similarly to Haghighi and Klein (2010). Features We model syntactic features, following Haghighi and Klein (2010). In order to compensate for parsing errors, shallow syntactic features were added, representing the values of neighboring verbs and prepositions (Cohen et al., 2005). While newswire documents are mostly unstructured, structural features are used to indicate whether any of the purchaser, acquired and seller text spans appears in 6In this work, we ignore other fields annotated, as they are inconsistently defined, have low number of occurrences in the corpus, and are loosely inter-related semantically. 851 purname purabr </context>
<context position="30755" citStr="Haghighi and Klein, 2010" startWordPosition="4979" endWordPosition="4982"> features encode the shortest string between spans mapping to different roles in the acquisition relation. Experiments We applied beam search, where corp tuples are extracted first, and acquisition tuples are constructed using the top scoring corp entities. We used a default beam size k = 10. The dataset is split into a 300/300 train/test subsets. Table 4 shows results of our full model in terms of field-level F1, compared against TIE, a state-of-theart discriminative system (Siefkes, 2008). Unfortunately, we can not directly compare against a generative joint model evaluated on this dataset (Haghighi and Klein, 2010).7 The best results per attribute are shown in boldface. Our full model performs better overall than TIE trained incrementally (similarly to our system), and is competitive with TIE using batch learning. Interestingly, the performance of our model on the code fields is high; these fields do not involve boundary prediction, and thus reflect the quality of role assignment. Table 4 also shows the results of model variants. Removing the inter type and structural features mildly hurt performance, on average. In contrast, the semantic features, which account for the semantic cohesiveness of the popu</context>
</contexts>
<marker>Haghighi, Klein, 2010</marker>
<rawString>Aria Haghighi and Dan Klein. 2010. An entity-level approach to information extraction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Extracting personal names from emails: Applying named entity recognition to informal text.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<contexts>
<context position="17388" citStr="Minkov et al., 2005" startWordPosition="2819" endWordPosition="2822">be generated, ranked according to Equation 1. 5 Seminar Extraction Task Dataset The CMU seminar announcement dataset (Freitag and McCallum, 2000) includes 485 emails containing seminar announcements. The dataset has been originally annotated with text spans referring to four slots: speaker, location, stime, and etime. We have annotated this dataset with two additional attributes: date and title.2 We consider this corpus as an example of semi-structured text, where some of the field values appear in the email header, in a tabular structure, or using special formatting (Califf and Mooney, 1999; Minkov et al., 2005).3 We used a set of rules to extract candidate named entities per the types specified in Figure 2.4 The rules encode information typically used in NER, including content and contextual patterns, as well as lookups in available dictionaries (Finkel et al., 2005; Minkov et al., 2005). The extracted candidates are high-recall and overlapping. In order to increase recall further, additional candidates were extracted based on document structure (Siefkes, 2008). The 2A modified dataset is available on the author’s homepage. 3Such structure varies across messages. Otherwise, the problem would reduce </context>
<context position="19020" citStr="Minkov et al., 2005" startWordPosition="3079" endWordPosition="3082">te the value and pattern of words within the text spans corresponding to each field. For example, lexical features per Figure 1 include location.content.word.wean, location.pattern.capitalized. Similar features are derived for a window of three words to the right and to the left of the included spans. In addition, we observe whether the words that comprise the text spans appear in relevant dictionaries: e.g., whether the spans assigned to the location field include words typical of location, such as “room” or “hall”. Lexical features of this form are commonly used in NER (Finkel et al., 2005; Minkov et al., 2005). Structural. It has been previously shown that the structure available in semi-structured documents such as email messages is useful for information extraction (Minkov et al., 2005; Siefkes, 2008). As shown in Figure 1, an email message includes a header, specifying textual fields such as topic, dates and time. In addition, space lines and line breaks are used to emphasize blocks of important information. We propose a set of features that model correspondence between the text spans assigned to each field and document structure. Specifically, these features model whether at least one of the sp</context>
</contexts>
<marker>Minkov, Wang, Cohen, 2005</marker>
<rawString>Einat Minkov, Richard C. Wang, and William W. Cohen. 2005. Extracting personal names from emails: Applying named entity recognition to informal text. In HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minorthird</author>
</authors>
<title>Methods for identifying names and ontological relations in text using heuristics for inducing regularities from data. http://http:// minorthird.sourceforge.net.</title>
<date>2008</date>
<contexts>
<context position="18113" citStr="Minorthird, 2008" startWordPosition="2931" endWordPosition="2932">s encode information typically used in NER, including content and contextual patterns, as well as lookups in available dictionaries (Finkel et al., 2005; Minkov et al., 2005). The extracted candidates are high-recall and overlapping. In order to increase recall further, additional candidates were extracted based on document structure (Siefkes, 2008). The 2A modified dataset is available on the author’s homepage. 3Such structure varies across messages. Otherwise, the problem would reduce to wrapper learning (Zhu et al., 2006). 4The rule language used is based on cascaded finite state machines (Minorthird, 2008). recall for the named entities of type date and time is near perfect, and is estimated at 96%, 91% and 90% for location, speaker and title, respectively. Features The categories of the features used are described below. All features are binary and typed.5 Lexical. These features indicate the value and pattern of words within the text spans corresponding to each field. For example, lexical features per Figure 1 include location.content.word.wean, location.pattern.capitalized. Similar features are derived for a window of three words to the right and to the left of the included spans. In additio</context>
</contexts>
<marker>Minorthird, 2008</marker>
<rawString>Minorthird. 2008. Methods for identifying names and ontological relations in text using heuristics for inducing regularities from data. http://http:// minorthird.sourceforge.net.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Peshkin</author>
<author>Avi Pfeffer</author>
</authors>
<title>Bayesian information extraction network.</title>
<date>2003</date>
<booktitle>In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</booktitle>
<contexts>
<context position="20974" citStr="Peshkin and Pfeffer, 2003" startWordPosition="3391" endWordPosition="3394">e date field specify all of the attribute values of this relation, including day-of-month, month, year, and 5Real-value features were discretized into segments. 849 Date Stime Etime Location Speaker Title Full model 96.1 99.3 98.7 96.4 87.5 69.5 No structural features 94.9 99.1 98.0 96.1 83.8 65.1 No semantic features 96.1 98.7 95.4 96.4 87.5 69.5 No unification 87.2 97.0 95.1 94.5 76.0 62.7 Individual fields 96.5 97.2 - 96.4 86.8 64.5 Table 1: Seminar extraction results (5-fold CV): Field-level F1 Date Stime Etime Location Speaker Title SNOW (Roth and Yih, 2001) - 99.6 96.3 75.2 73.8 - BIEN (Peshkin and Pfeffer, 2003) - 96.0 98.8 87.1 76.9 - Elie (Finn, 2006) - 98.5 96.4 86.5 88.5 - TIE (Siefkes, 2008) - 99.3 97.1 81.7 85.4 - Full model 96.3 99.1 98.0 96.9 85.8 67.7 Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1 day-of-week. Another feature encodes the size of the most semantically detailed named entity that maps to a field; for example, the most detailed entity mention of type stime in Figure 1 is “3:30”, comprising of two attribute values, namely hour and minutes. Similarly, the total number of semantic units included in a unified set is represented as a feature</context>
</contexts>
<marker>Peshkin, Pfeffer, 2003</marker>
<rawString>Leonid Peshkin and Avi Pfeffer. 2003. Bayesian information extraction network. In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Relational learning via propositional algorithms: An information extraction case study.</title>
<date>2001</date>
<booktitle>In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</booktitle>
<contexts>
<context position="5030" citStr="Roth and Yih, 2001" startWordPosition="790" endWordPosition="793">plate extraction and mention detection performance. Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results. We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints. 2 Related Work Research on the task of template filling has focused on the extraction of field value mentions from the underlying text. Typically, these values are extracted based on local evidence, where the most likely entity is assigned to each slot (Roth and Yih, 2001; Siefkes, 2008). There has been little effort towards a comprehensive approach that includes mention unification, as well as considers the structure of the target relational schema to create semantically valid outputs. Recently, Haghighi and Klein (2010) presented a generative semi-supervised approach for template filling. In their model, slot-filling entities are first generated, and entity mentions are then realized in text. Thus, their approach performs coreference at slot level. In addition to proper nouns (named entity mentions) that are considered in this work, they also account for nom</context>
<context position="20917" citStr="Roth and Yih, 2001" startWordPosition="3380" endWordPosition="3383"> in Figure 1, the union of entities that map to the date field specify all of the attribute values of this relation, including day-of-month, month, year, and 5Real-value features were discretized into segments. 849 Date Stime Etime Location Speaker Title Full model 96.1 99.3 98.7 96.4 87.5 69.5 No structural features 94.9 99.1 98.0 96.1 83.8 65.1 No semantic features 96.1 98.7 95.4 96.4 87.5 69.5 No unification 87.2 97.0 95.1 94.5 76.0 62.7 Individual fields 96.5 97.2 - 96.4 86.8 64.5 Table 1: Seminar extraction results (5-fold CV): Field-level F1 Date Stime Etime Location Speaker Title SNOW (Roth and Yih, 2001) - 99.6 96.3 75.2 73.8 - BIEN (Peshkin and Pfeffer, 2003) - 96.0 98.8 87.1 76.9 - Elie (Finn, 2006) - 98.5 96.4 86.5 88.5 - TIE (Siefkes, 2008) - 99.3 97.1 81.7 85.4 - Full model 96.3 99.1 98.0 96.9 85.8 67.7 Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1 day-of-week. Another feature encodes the size of the most semantically detailed named entity that maps to a field; for example, the most detailed entity mention of type stime in Figure 1 is “3:30”, comprising of two attribute values, namely hour and minutes. Similarly, the total number of semantic un</context>
</contexts>
<marker>Roth, Yih, 2001</marker>
<rawString>Dan Roth and Wen-tau Yih. 2001. Relational learning via propositional algorithms: An information extraction case study. In Proceedings of the international joint conference on Artificial intelligence (IJCAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Probabilistic reasoning for entity and relation recognition.</title>
<date>2002</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="6117" citStr="Roth and Yih, 2002" startWordPosition="953" endWordPosition="956">ence at slot level. In addition to proper nouns (named entity mentions) that are considered in this work, they also account for nominal and pronominal noun mentions. This work presents a discriminative approach to this problem. An advantage of a discriminative framework is that it allows the incorporation of rich and possibly overlapping features. In addition, we enforce label consistency and semantic coherence at record level. Other related works perform structured relation discovery for different settings of information extraction. In open IE, entities and relations may be inferred jointly (Roth and Yih, 2002; Yao et al., 2011). In this IE task, the target relation must agree with the entity types assigned to it; e.g., born-in relation requires a place as its argument. In addition, extracted relations may be required to be consistent with an existing ontology (Carlson et al., 2010). Compared with the extraction of tuples of entity mention pairs, template filling is associated with a more complex target relational schema. Interestingly, several researchers have attempted to model label consistency and high-level relational constraints using state-of-the-art sequential models of named entity recogni</context>
</contexts>
<marker>Roth, Yih, 2002</marker>
<rawString>Dan Roth and Wen-tau Yih. 2002. Probabilistic reasoning for entity and relation recognition. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Siefkes</author>
</authors>
<title>In An Incrementally Trainable Statistical Approach to Information Extraction.</title>
<date>2008</date>
<publisher>VDM Verlag.</publisher>
<contexts>
<context position="5046" citStr="Siefkes, 2008" startWordPosition="794" endWordPosition="795"> mention detection performance. Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results. We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints. 2 Related Work Research on the task of template filling has focused on the extraction of field value mentions from the underlying text. Typically, these values are extracted based on local evidence, where the most likely entity is assigned to each slot (Roth and Yih, 2001; Siefkes, 2008). There has been little effort towards a comprehensive approach that includes mention unification, as well as considers the structure of the target relational schema to create semantically valid outputs. Recently, Haghighi and Klein (2010) presented a generative semi-supervised approach for template filling. In their model, slot-filling entities are first generated, and entity mentions are then realized in text. Thus, their approach performs coreference at slot level. In addition to proper nouns (named entity mentions) that are considered in this work, they also account for nominal and pronomi</context>
<context position="17847" citStr="Siefkes, 2008" startWordPosition="2891" endWordPosition="2892">ere some of the field values appear in the email header, in a tabular structure, or using special formatting (Califf and Mooney, 1999; Minkov et al., 2005).3 We used a set of rules to extract candidate named entities per the types specified in Figure 2.4 The rules encode information typically used in NER, including content and contextual patterns, as well as lookups in available dictionaries (Finkel et al., 2005; Minkov et al., 2005). The extracted candidates are high-recall and overlapping. In order to increase recall further, additional candidates were extracted based on document structure (Siefkes, 2008). The 2A modified dataset is available on the author’s homepage. 3Such structure varies across messages. Otherwise, the problem would reduce to wrapper learning (Zhu et al., 2006). 4The rule language used is based on cascaded finite state machines (Minorthird, 2008). recall for the named entities of type date and time is near perfect, and is estimated at 96%, 91% and 90% for location, speaker and title, respectively. Features The categories of the features used are described below. All features are binary and typed.5 Lexical. These features indicate the value and pattern of words within the te</context>
<context position="19217" citStr="Siefkes, 2008" startWordPosition="3110" endWordPosition="3111">eatures are derived for a window of three words to the right and to the left of the included spans. In addition, we observe whether the words that comprise the text spans appear in relevant dictionaries: e.g., whether the spans assigned to the location field include words typical of location, such as “room” or “hall”. Lexical features of this form are commonly used in NER (Finkel et al., 2005; Minkov et al., 2005). Structural. It has been previously shown that the structure available in semi-structured documents such as email messages is useful for information extraction (Minkov et al., 2005; Siefkes, 2008). As shown in Figure 1, an email message includes a header, specifying textual fields such as topic, dates and time. In addition, space lines and line breaks are used to emphasize blocks of important information. We propose a set of features that model correspondence between the text spans assigned to each field and document structure. Specifically, these features model whether at least one of the spans mapped to each field appears in the email header; captures a full line in the document; is indent; appears within space lines; or in a tabular format. In Figure 1, structural active features in</context>
<context position="21060" citStr="Siefkes, 2008" startWordPosition="3411" endWordPosition="3412">year, and 5Real-value features were discretized into segments. 849 Date Stime Etime Location Speaker Title Full model 96.1 99.3 98.7 96.4 87.5 69.5 No structural features 94.9 99.1 98.0 96.1 83.8 65.1 No semantic features 96.1 98.7 95.4 96.4 87.5 69.5 No unification 87.2 97.0 95.1 94.5 76.0 62.7 Individual fields 96.5 97.2 - 96.4 86.8 64.5 Table 1: Seminar extraction results (5-fold CV): Field-level F1 Date Stime Etime Location Speaker Title SNOW (Roth and Yih, 2001) - 99.6 96.3 75.2 73.8 - BIEN (Peshkin and Pfeffer, 2003) - 96.0 98.8 87.1 76.9 - Elie (Finn, 2006) - 98.5 96.4 86.5 88.5 - TIE (Siefkes, 2008) - 99.3 97.1 81.7 85.4 - Full model 96.3 99.1 98.0 96.9 85.8 67.7 Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1 day-of-week. Another feature encodes the size of the most semantically detailed named entity that maps to a field; for example, the most detailed entity mention of type stime in Figure 1 is “3:30”, comprising of two attribute values, namely hour and minutes. Similarly, the total number of semantic units included in a unified set is represented as a feature. These features were designed to favor semantically detailed mentions and unified set</context>
<context position="22819" citStr="Siefkes, 2008" startWordPosition="3693" endWordPosition="3694">These features were not included in the final model since their contribution was marginal. We leave further exploration of crossfield features in this domain to future work. Experiments We conducted 5-fold cross validation experiments using the seminar extraction dataset. As discussed earlier, we assume that a single record is described in each document, and that each field corresponds to a single value. These assumptions are violated in a minority of cases. In evaluating the template filling task, only exact matches are accepted as true positives, where partial matches are counted as errors (Siefkes, 2008). Notably, the annotated labels as well as corpus itself are not error-free; for example, in some announcements the date and day-of-week specified are inconsistent. Our evaluation is strict, where non-empty predicted values are counted as errors in such cases. Table 1 shows the results of our full model using beam size k = 10, as well as model variants. In order to evaluate the contribution of the proposed features, we eliminated every feature group in turn. As shown in the table, removing the structural features hurt performance consistently across fields. In particular, structure is informat</context>
<context position="30625" citStr="Siefkes, 2008" startWordPosition="4960" endWordPosition="4961"> of the full or abbreviated names; or whether it has high string similarity to any of these values. Finally, cross-type features encode the shortest string between spans mapping to different roles in the acquisition relation. Experiments We applied beam search, where corp tuples are extracted first, and acquisition tuples are constructed using the top scoring corp entities. We used a default beam size k = 10. The dataset is split into a 300/300 train/test subsets. Table 4 shows results of our full model in terms of field-level F1, compared against TIE, a state-of-theart discriminative system (Siefkes, 2008). Unfortunately, we can not directly compare against a generative joint model evaluated on this dataset (Haghighi and Klein, 2010).7 The best results per attribute are shown in boldface. Our full model performs better overall than TIE trained incrementally (similarly to our system), and is competitive with TIE using batch learning. Interestingly, the performance of our model on the code fields is high; these fields do not involve boundary prediction, and thus reflect the quality of role assignment. Table 4 also shows the results of model variants. Removing the inter type and structural feature</context>
</contexts>
<marker>Siefkes, 2008</marker>
<rawString>Christian Siefkes. 2008. In An Incrementally Trainable Statistical Approach to Information Extraction. VDM Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction. In</title>
<date>2004</date>
<tech>Technical Report no. 04-49,</tech>
<institution>University ofMassachusetts.</institution>
<contexts>
<context position="6861" citStr="Sutton and McCallum, 2004" startWordPosition="1063" endWordPosition="1066">n relation requires a place as its argument. In addition, extracted relations may be required to be consistent with an existing ontology (Carlson et al., 2010). Compared with the extraction of tuples of entity mention pairs, template filling is associated with a more complex target relational schema. Interestingly, several researchers have attempted to model label consistency and high-level relational constraints using state-of-the-art sequential models of named entity recognition (NER). Mainly, predetermined word-level dependencies were represented as links in the underlying graphical model (Sutton and McCallum, 2004; Finkel et al., 2005). Finkel et al. (2005) further modelled high-level semantic constraints; for example, using the CMU seminar announcements dataset, spans labeled as start time or end time were required to be semantically consistent. In the proposed framework we take a bottom-up approach to identifying entity mentions in text, where given a noisy set of candidate named entities, described using rich semantic and surface features, discriminative learning is applied to label these mentions. We will show that this approach yields better performance on the CMU seminar announcement dataset when</context>
<context position="24858" citStr="Sutton and McCallum, 2004" startWordPosition="4023" endWordPosition="4026">ven a single entity versus a a coreferent set of entities, this results in significantly degraded performance. Finally, we experimented with populating every field of the target schema independently of the other fields. While results are overall comparable on most fields, this had negative impact on the title field. This is largely due to erroneous assignments of named entities of other types (mainly, person) as titles; such errors are avoided in the full joint model, where tuple validity is enforced. Table 2 provides a comparison of the full model 850 Date Stime Etime Location Speaker Title (Sutton and McCallum, 2004) - 96.7 97.2 88.1 80.4 - (Finkel et al., 2005) - 97.1 97.9 90.0 84.2 - Full model 95.4 97.1 97.9 97.0 86.5 75.5 Table 3: Seminar extraction results: Token-level F1 against previous state-of-the-art results. These results were all obtained using half of the corpus for training, and its remaining half for evaluation; the reported figures were averaged over five random splits. For comparison, we used 5-fold cross validation, where only a subset of each train fold that corresponds to 50% of the corpus was used for training. Due to the reduced training data, the results are slightly lower than in T</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>Charles Sutton and Andrew McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. In Technical Report no. 04-49, University ofMassachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Aria Haghighi</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Structured relation discovery using generative models.</title>
<date>2011</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="6136" citStr="Yao et al., 2011" startWordPosition="957" endWordPosition="960">In addition to proper nouns (named entity mentions) that are considered in this work, they also account for nominal and pronominal noun mentions. This work presents a discriminative approach to this problem. An advantage of a discriminative framework is that it allows the incorporation of rich and possibly overlapping features. In addition, we enforce label consistency and semantic coherence at record level. Other related works perform structured relation discovery for different settings of information extraction. In open IE, entities and relations may be inferred jointly (Roth and Yih, 2002; Yao et al., 2011). In this IE task, the target relation must agree with the entity types assigned to it; e.g., born-in relation requires a place as its argument. In addition, extracted relations may be required to be consistent with an existing ontology (Carlson et al., 2010). Compared with the extraction of tuples of entity mention pairs, template filling is associated with a more complex target relational schema. Interestingly, several researchers have attempted to model label consistency and high-level relational constraints using state-of-the-art sequential models of named entity recognition (NER). Mainly,</context>
</contexts>
<marker>Yao, Haghighi, Riedel, McCallum, 2011</marker>
<rawString>Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings ofEMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Zaiqing Nie</author>
<author>Ji-Rong Wen</author>
<author>Bo Zhang</author>
<author>WeiYing Ma</author>
</authors>
<title>Simultaneous record detection and attribute labeling in web data extraction.</title>
<date>2006</date>
<booktitle>In Proc. of the ACMSIGKDD Intl. Conf. on Knowledge Discovery and Data Mining (KDD).</booktitle>
<contexts>
<context position="18026" citStr="Zhu et al., 2006" startWordPosition="2916" endWordPosition="2919">ules to extract candidate named entities per the types specified in Figure 2.4 The rules encode information typically used in NER, including content and contextual patterns, as well as lookups in available dictionaries (Finkel et al., 2005; Minkov et al., 2005). The extracted candidates are high-recall and overlapping. In order to increase recall further, additional candidates were extracted based on document structure (Siefkes, 2008). The 2A modified dataset is available on the author’s homepage. 3Such structure varies across messages. Otherwise, the problem would reduce to wrapper learning (Zhu et al., 2006). 4The rule language used is based on cascaded finite state machines (Minorthird, 2008). recall for the named entities of type date and time is near perfect, and is estimated at 96%, 91% and 90% for location, speaker and title, respectively. Features The categories of the features used are described below. All features are binary and typed.5 Lexical. These features indicate the value and pattern of words within the text spans corresponding to each field. For example, lexical features per Figure 1 include location.content.word.wean, location.pattern.capitalized. Similar features are derived for</context>
</contexts>
<marker>Zhu, Nie, Wen, Zhang, Ma, 2006</marker>
<rawString>Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and WeiYing Ma. 2006. Simultaneous record detection and attribute labeling in web data extraction. In Proc. of the ACMSIGKDD Intl. Conf. on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>