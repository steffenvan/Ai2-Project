<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021332">
<title confidence="0.980761">
Fast Online Lexicon Learning for Grounded Language Acquisition
</title>
<author confidence="0.997939">
David L. Chen
</author>
<affiliation confidence="0.9994015">
Department of Computer Science
The University of Texas at Austin
</affiliation>
<address confidence="0.983285">
1616 Guadalupe, Suite 2.408
Austin, TX 78701, USA
</address>
<email confidence="0.999631">
dlcc@cs.utexas.edu
</email>
<sectionHeader confidence="0.998679" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99651475">
Learning a semantic lexicon is often an impor-
tant first step in building a system that learns
to interpret the meaning of natural language.
It is especially important in language ground-
ing where the training data usually consist of
language paired with an ambiguous perceptual
context. Recent work by Chen and Mooney
(2011) introduced a lexicon learning method
that deals with ambiguous relational data by
taking intersections of graphs. While the al-
gorithm produced good lexicons for the task of
learning to interpret navigation instructions, it
only works in batch settings and does not scale
well to large datasets. In this paper we intro-
duce a new online algorithm that is an order
of magnitude faster and surpasses the state-
of-the-art results. We show that by changing
the grammar of the formal meaning represen-
tation language and training on additional data
collected from Amazon’s Mechanical Turk we
can further improve the results. We also in-
clude experimental results on a Chinese trans-
lation of the training data to demonstrate the
generality of our approach.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997480952381">
Learning to understand the semantics of human lan-
guages has been one of the ultimate goals of natural
language processing (NLP). Traditional learning ap-
proaches have relied on access to parallel corpora of
natural language sentences paired with their mean-
ings (Mooney, 2007; Zettlemoyer and Collins, 2007;
Lu et al., 2008; Kwiatkowski et al., 2010). How-
ever, constructing such semantic annotations can be
difficult and time-consuming. More recently, there
has been work on learning from ambiguous super-
vision where a set of potential sentence meanings
are given, only one (or a small subset) of which are
correct (Chen and Mooney, 2008; Liang et al., 2009;
Bordes et al., 2010; Chen and Mooney, 2011). Given
the training data, the system needs to infer the cor-
recting meaning for each training sentence.
Building a lexicon of the formal meaning repre-
sentations of words and phrases, either implicitly
or explicitly, is usually an important step in infer-
ring the meanings of entire sentences. In particu-
lar, Chen and Mooney (2011) first learned a lexicon
to help them resolve ambiguous supervision of re-
lational data in which the number of choices is ex-
ponential. They represent the perceptual context as
a graph and allow each sentence in the training data
to align to any connected subgraph. Their lexicon
learning algorithm finds the common connected sub-
graph that occurs with a word by taking intersections
of the graphs that represent the different contexts in
which the word appears. While the algorithm pro-
duced a good lexicon for their application of learn-
ing to interpret navigation instructions, it only works
in batch settings and does not scale well to large
datasets. In this paper we introduce a novel online
algorithm that is an order of magnitude faster and
also produces better results on their navigation task.
In addition to the new lexicon learning algorithm,
we also look at modifying the meaning representa-
tion grammar (MRG) for their formal semantic lan-
guage. By using a MRG that correlates better to the
structure of natural language, we further improve the
performance on the navigation task. Since our al-
</bodyText>
<page confidence="0.974415">
430
</page>
<note confidence="0.9857425">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 430–439,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999566">
gorithm can scale to larger datasets, we present re-
sults on collecting and training on additional data
from Amazon’s Mechanical Turk. Finally, we show
the generality of our approach by demonstrating our
system’s ability to learn from a Chinese translation
of the training data.
</bodyText>
<sectionHeader confidence="0.995576" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999973636363636">
A common way to learn a lexicon across many dif-
ferent contexts is to find the common parts of the for-
mal representations associated with different occur-
rences of the same words or phrases (Siskind, 1996).
For graphical representations, this involves find-
ing the common subgraph between multiple graphs
(Thompson and Mooney, 2003; Chen and Mooney,
2011). In this section we review the lexicon learning
algorithm introduced by Chen and Mooney (2011)
as well as the overall task they designed to test se-
mantic understanding of navigation instructions.
</bodyText>
<subsectionHeader confidence="0.971189">
2.1 Navigation Task
</subsectionHeader>
<bodyText confidence="0.999124307692308">
The goal of the navigation task is to build a sys-
tem that can understand free-form natural-language
instructions and follow them to move to the in-
tended destination (MacMahon et al., 2006; Shimizu
and Haas, 2009; Matuszek et al., 2010; Kollar et
al., 2010; Vogel and Jurafsky, 2010; Chen and
Mooney, 2011). Chen and Mooney (2011) de-
fined a learning task in which the only supervi-
sion the system receives is in the form of observ-
ing how humans behave when following sample
navigation instructions in a virtual world. For-
mally, the system is given training data in the
form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)},
where ei is a written natural language instruction, ai
is an observed action sequence, and wi is a descrip-
tion of the virtual world. The goal is then to build a
system that can produce the correct aj given a pre-
viously unseen (ej, wj) pair.
Since the observed actions ai only consists of
low-level actions (e.g. turn left, turn right, walk for-
ward) and not high-level concepts (e.g. turn your
back against the wall and walk to the couch), Chen
and Mooney first use a set of rules to automatically
construct the space of reasonable plans using the ac-
tion trace and knowledge about the world. The space
is represented compactly using a graph as shown in
</bodyText>
<figureCaption confidence="0.95492">
Figure 1: Examples of landmarks plans constructed by
Chen and Mooney (2011) and how they computed the in-
tersection of two graphs.
Figure 1. This is what they called a landmarks plan
and consists of the low-level observed actions in-
terleaved with verification steps indicating what ob-
jects should be observed after each action.
</figureCaption>
<bodyText confidence="0.999873">
Given that these landmarks plans contain a lot of
extraneous details, Chen and Mooney learn a lexicon
and use it to identify and remove the irrelevant parts
of the plans. They use a greedy method to remove
nodes from the graphs that are not associated with
any of the words in the instructions. The remain-
ing refined landmarks plans are then treated as su-
pervised training data for a semantic-parser learner,
KRISP (Kate and Mooney, 2006). Once a seman-
tic parser is trained, it can be used at test time to
transform novel instructions into formal navigation
plans which are then carried out by a virtual robot
(MacMahon et al., 2006).
</bodyText>
<subsectionHeader confidence="0.999704">
2.2 Lexicon Learning
</subsectionHeader>
<bodyText confidence="0.999857416666667">
The central component of the system is the lexi-
con learning process which associates words and
short phrases (n-grams) to their meanings (con-
nected graphs). To learn the meaning of an n-gram
w, Chen and Mooney first collect all navigation
plans g that co-occur with w. This forms the ini-
tial candidate meaning set for w. They then repeat-
edly take the intersections between the candidate
meanings to generate additional candidate mean-
ings. They use the term intersection to mean a max-
imal common subgraph (i.e. it is not a subgraph of
any other common subgraphs). In general, there are
</bodyText>
<page confidence="0.998275">
431
</page>
<bodyText confidence="0.999781727272727">
multiple possible intersections between two graphs.
In this case, they bias toward finding large connected
components by greedily removing the largest com-
mon connected subgraph from both graphs until the
two graphs have no overlapping nodes. The out-
put of the intersection process consists of all the re-
moved subgraphs. An example of the intersection
operation is shown in Figure 1.
Once the list of candidate meanings are generated,
they are ranked by the following scoring metric for
an n-gram w and a graph g:
</bodyText>
<equation confidence="0.792811">
Score(w, g) = p(g|w) − p(g|mow)
</equation>
<bodyText confidence="0.999816833333333">
Intuitively, the score measures how much more
likely a graph g appears when w is present compared
to when it is not. The probabilities are estimated by
counting how many examples contain the word w or
graph g, ignoring multiple occurrences in a single
example.
</bodyText>
<sectionHeader confidence="0.997111" genericHeader="method">
3 Online Lexicon Learning Algorithm
</sectionHeader>
<bodyText confidence="0.999817925925926">
While the algorithm presented by Chen and Mooney
(2011) produced good lexicons, it only works in
batch settings and does not scale well to large
datasets. The bottleneck of their algorithm is the in-
tersection process which is time-consuming to per-
form. Moreover, their algorithm requires taking
many intersections between many different graphs.
Even though they use beam-search to limit the size
of the candidate set, if the initial candidate meaning
set for a n-gram is large, it can take a long time to
take just one pass through the list of all candidates.
Moreover, reducing the beam size could also hurt the
quality of the lexicon learned.
In this section, we present another lexicon learn-
ing algorithm that is much faster and works in an on-
line setting. The main insight is that most words or
short phrases correspond to small graphs. Thus, we
concentrate our attention on only candidate mean-
ings that are less than a certain size. Using this con-
straint, we generate all the potential small connected
subgraphs for each navigation plan in the training
examples and discard the original graph. Pseudo-
code for the new algorithm, Subgraph Generation
Online Lexicon Learning (SGOLL) algorithm, is
shown in Algorithm 1.
As we encounter each new training example
which consists of a written navigation instruction
</bodyText>
<sectionHeader confidence="0.3053685" genericHeader="method">
Algorithm 1 SUBGRAPH GENERATION ONLINE
LEXICON LEARNING (SGOLL)
</sectionHeader>
<bodyText confidence="0.571916333333333">
input A sequence of navigation instructions
and the corresponding navigation plans
(e1, p1), ... , (en, pn)
</bodyText>
<listItem confidence="0.98987734375">
output Lexicon, a set of phrase-meaning pairs
1: main
2: for training example (ei, pi) do
3: Update((ei,pi))
4: end for
5: OutputLexicon()
6: end main
8: function Update(training example (ei, pi))
9: for n-gram w that appears in ei do
10: for connected subgraph g of pi such that
the size of g is less than or equal to m do
11: Increase the co-occurrence count of g
and w by 1
12: end for
13: end for
14: Increase the count of examples, each n-gram
w and each subgraph g
15: end function
18: function OutputLexicon()
19: for n-gram w that has been observed do
20: if Number of times w has been observed is
less than minSup then
21: skip w
22: end if
23: for subgraph g that has co-occurred with w
do
24: if score(w, g) &gt; threshold t then
25: add (w, g) to Lexicon
26: end if
27: end for
28: end for
29: end function
</listItem>
<page confidence="0.99553">
432
</page>
<bodyText confidence="0.999957770833334">
and the corresponding navigation plan, we first seg-
ment the instruction into word tokens and construct
n-grams from them. From the corresponding navi-
gation plan, we find all connected subgraphs of size
less than or equal to m. We then update the co-
occurrence counts between all the n-grams w and
all the connected subgraphs g. We also update the
counts of how many examples we have encountered
so far and counts of the n-grams w and subgraphs
g. At any given time, we can compute a lexicon
using these various counts. Specifically, for each
n-gram w, we look at all the subgraphs g that co-
occurred with it, and compute a score for the pair
(w, g). If the score is higher than the threshold t, we
add the entry (w, g) to the lexicon. We use the same
scoring function as Chen and Mooney, which can be
computed efficiently using the counts we keep. In
contrast to Chen and Mooney’s algorithm though,
we add the constraint of minimum support by not
creating lexical entries for any n-gram w that ap-
peared in less than minSup training examples. This
is to prevent rarely seen n-grams from receiving high
scores in our lexicon simply due to their sparsity.
Unless otherwise specified, we compute lexical en-
tries for up to 4-grams with threshold t = 0.4, max-
imum subgraph size m = 3, and minimum support
minSup = 10.
It should be noted that SGOLL can also become
computationally intractable if the sizes of the nav-
igations plans are large or if we set the maximum
subgraph size m to a large number. Moreover, the
memory requirement can be quite high if there are
many different subgraphs g associated with each n-
gram w. To deal with such scalability issues, we
could use beam-search and only keep the top k can-
didates associated with each w. Another important
step is to define canonical orderings of the nodes in
the graphs. This allows us to determine if two graphs
are identical in constant time and also lets us use a
hash table to quickly update the co-occurrence and
subgraph counts. Thus, even given a large number
of subgraphs for each training example, each sub-
graph can be processed very quickly. Finally, this
algorithm readily lends itself to being parallelized.
Each processor would get a fraction of the training
data and compute the counts individually. Then the
counts can be merged together at the end to produce
the final lexicon.
</bodyText>
<subsectionHeader confidence="0.978584">
3.1 Changing the Meaning Representation
Grammar
</subsectionHeader>
<bodyText confidence="0.999900227272727">
In addition to introducing a new lexicon learning
algorithm, we also made another modification to
the original system proposed by Chen and Mooney
(2011). To train a semantic parser using KRISP
(Kate and Mooney, 2006), they had to supply a
MRG, a context-free grammar, for their formal nav-
igation plan language. KRISP learns string-kernel
classifiers that maps natural language substrings to
MRG production rules. Consequently, it is impor-
tant that the production rules in the MRG mirror the
structure of natural language (Kate, 2008).
The original MRG used by Chen and Mooney is a
compact grammar that contains many recursive rules
that can be used to generate an infinite number of ac-
tions or arguments. While these rules are quite ex-
pressive, they often do not correspond well to any
words or phrases in natural language. To alleviate
this problem, we designed another MRG by expand-
ing out many of the rules. For example, the original
MRG contained the following production rules for
generating an infinite number of travel actions from
the root symbol S.
</bodyText>
<table confidence="0.952348">
*S -&gt; *Action
*Action -&gt; *Action, *Action
*Action -&gt; *Travel
*Travel -&gt; Travel( )
*Travel -&gt; Travel( steps: *Num )
</table>
<bodyText confidence="0.999777">
We expand out the production rules as shown be-
low to map S directly to specific travel actions so
they correspond better to patterns such as “go for-
ward” or “walk N steps”.
</bodyText>
<table confidence="0.946958285714286">
*S -&gt; Travel( )
*S -&gt; Travel( steps: *Num )
*S -&gt; Travel( ), *Action
*S -&gt; Travel( steps: *Num ), *Action
*Action -&gt; *Action, *Action
*Action -&gt; Travel( )
*Action -&gt; Travel( steps: *Num )
</table>
<bodyText confidence="0.996616166666667">
While this process of expanding the produc-
tion rules resulted in many more rules, these ex-
panded rules usually correspond better with words
or phrases in natural language. We still retain some
of the recursive rules to ensure that the formal lan-
guage remains as expressive as before.
</bodyText>
<page confidence="0.998971">
433
</page>
<sectionHeader confidence="0.8248015" genericHeader="method">
4 Collecting Additional Data with
Mechanical Turk
</sectionHeader>
<bodyText confidence="0.999981833333333">
One of the motivations for studying ambiguous su-
pervision is the potential ease of acquiring large
amounts of training data. Without requiring seman-
tic annotations, a human only has to demonstrate
how language is used in context which is generally
simple to do. We validate this claim by collecting
additional training data for the navigation domain
using Mechanical Turk (Snow et al., 2008).
There are two types of data we are interested in
collecting: natural language navigation instructions
and follower data. Thus, we created two tasks on
Mechanical Turk. The first one asks the workers
to supply instructions for a randomly generated se-
quence of actions. The second one asks the workers
to try to follow a given navigation instruction in our
virtual environment. The latter task is used to gener-
ate the corresponding action sequences for instruc-
tions collected from the first task.
</bodyText>
<subsectionHeader confidence="0.984823">
4.1 Task Descriptions
</subsectionHeader>
<bodyText confidence="0.99996716">
To facilitate the data collection, we first recreated
the 3D environments used to collect the original data
(MacMahon et al., 2006). We built a Java appli-
cation that allows the user to freely navigate the
three virtual worlds constructed by MacMahon et
al. (2006) using the discrete controls of turning left,
turning right, and moving forward one step.
The follower task is fairly straightforward using
our application. The worker is given a navigation
instruction and placed at the starting location. They
are asked to follow the navigation instruction as best
as they could using the three discrete controls. They
could also skip the problem if they did not under-
stand the instruction or if the instruction did not de-
scribe a viable route. For each Human Intelligence
Task (HIT), we asked the worker to complete 5 fol-
lower problems. We paid them $0.05 for each HIT,
or 1 cent per follower problem. The instructions
used for the follower problems were mainly col-
lected from our Mechanical Turk instructor task with
some of the instructions coming from data collected
by MacMahon (2007) that was not used by Chen and
Mooney (2011).
The instructor task is slightly more involved be-
cause we ask the workers to provide new navigation
</bodyText>
<table confidence="0.9997">
Chen &amp; Mooney MTurk
# instructions 3236 1011
Vocabulary size 629 590
Avg. # words 7.8 (5.1) 7.69 (7.12)
Avg. # actions 2.1 (2.4) 1.84 (1.24)
</table>
<tableCaption confidence="0.994859333333333">
Table 1: Statistics about the navigation instruction cor-
pora. The average statistics for each instruction are
shown with standard deviations in parentheses.
</tableCaption>
<bodyText confidence="0.999988142857143">
instructions. The worker is shown a 3D simulation
of a randomly generated action sequence between
length 1 to 4 and asked to write short, free-form in-
structions that would lead someone to perform those
actions. Since this task requires more time to com-
plete, each HIT consists of only 3 instructor prob-
lems. Moreover, we pay the workers $0.10 for each
HIT, or about 3 cents for each instruction they write.
To encourage quality contributions, we use a
tiered payment structure (Chen and Dolan, 2011)
that rewards the good workers. Workers who have
been identified to consistently provide good instruc-
tions were allowed to do higher-paying version of
the same HITs that paid $0.15 instead of $0.10.
</bodyText>
<subsectionHeader confidence="0.994048">
4.2 Data Statistics
</subsectionHeader>
<bodyText confidence="0.999985428571429">
Over a 2-month period we accepted 2,884 follower
HITs and 810 instructor HITs from 653 workers.
This corresponds to over 14,000 follower traces and
2,400 instructions with most of them consisting of
single sentences. For instructions with multiple sen-
tences, we merged all the sentences together and
treated it as a single sentence. The total cost of
the data collection was $277.92. While there were
2,400 instructions, we filtered them to make sure
they were of reasonable quality. First, we discarded
any instructions that did not have at least 5 follower
traces. Then we looked at all the follower traces and
discarded any instruction that did not have majority
agreement on what the correct path is.
Using our strict filter, we were left with slightly
over 1,000 instructions. Statistics about the new
corpus and the one used by Chen and Mooney can
be seen in Table 1. Overall, the new corpus has a
slightly smaller vocabulary, and each instruction is
slightly shorter both in terms of the number of words
and the number of actions.
</bodyText>
<page confidence="0.999327">
434
</page>
<sectionHeader confidence="0.999475" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999988142857143">
We evaluate our new lexicon learning algorithm as
well as the other modifications to the navigation sys-
tem using the same three tasks as Chen and Mooney
(2011). The first task is disambiguating the train-
ing data by inferring the correct navigation plans as-
sociated with each training sentence. The second
task is evaluating the performance of the semantic
parsers trained on the disambiguated data. We mea-
sure the performance of both of these tasks by com-
paring to gold-standard data using the same partial
correctness metric used by Chen and Mooney which
gives credit to a parse for producing the correct ac-
tion type and additional credit if the arguments were
also correct. Finally, the third task is to complete the
end-to-end navigation task. There are two versions
of this task, the complete task uses the original in-
structions which are several sentences long and the
other version uses instructions that have been man-
ually split into single sentences. Task completion
is measured by the percentage of trials in which the
system reached the correct destination (and orienta-
tion in the single-sentence version).
We follow the same evaluation scheme as Chen
and Mooney and perform leave-one-map-out exper-
iments. For the first task, we build a lexicon using
ambiguous training data from two maps, and then
use the lexicon to produce the best disambiguated
semantic meanings for those same data. For the sec-
ond and third tasks, we train a semantic parser on the
automatically disambiguated data, and test on sen-
tences from the third, unseen map.
For all comparisons to the Chen and Mooney re-
sults, we use the performance of their refined land-
marks plans system which performed the best over-
all. Moreover, it provides the most direct compari-
son to our approach since both use a lexicon to re-
fine the landmarks plans. Other than the modifi-
cations discussed, we use the same components as
their system including using KRISP to train the se-
mantic parsers and using the execution module from
MacMahon et al. (2006) to carry out the navigation
plans.
</bodyText>
<subsectionHeader confidence="0.967369">
5.1 Inferring Navigation Plans
</subsectionHeader>
<bodyText confidence="0.9829385">
First, we examine the quality of the refined naviga-
tion plans produced using SGOLL’s lexicon. The
</bodyText>
<table confidence="0.999497">
Precision Recall F1
Chen and Mooney 78.54 78.10 78.32
SGOLL 87.32 72.96 79.49
</table>
<tableCaption confidence="0.9126915">
Table 2: Partial parse accuracy of how well each algo-
rithm can infer the gold-standard navigation plans.
</tableCaption>
<table confidence="0.9997688">
Precision Recall F1
Chen and Mooney 90.22 55.10 68.37
SGOLL 92.22 55.70 69.43
SGOLL with 88.36 57.03 69.31
new MRG
</table>
<tableCaption confidence="0.997757">
Table 3: Partial parse accuracy of the semantic parsers
trained on the disambiguated navigation plans.
</tableCaption>
<bodyText confidence="0.999965">
precision, recall, and F1 (harmonic mean of preci-
sion and recall) of these plans are shown in Table 2.
Compared to Chen and Mooney, the plans produced
by SGOLL has higher precision and lower recall.
This is mainly due to the additional minimum sup-
port constraint we added which discards many noisy
lexical entries from infrequently seen n-grams.
</bodyText>
<subsectionHeader confidence="0.999646">
5.2 Training Semantic Parsers
</subsectionHeader>
<bodyText confidence="0.999922777777778">
Next we look at the performance of the semantic
parsers trained on the inferred navigation plans. The
results are shown in Table 3. Here SGOLL per-
forms almost the same as Chen and Mooney, with
slightly better precision. We also look at the effect of
changing the MRG. Using the new MRG for KRISP
to train the semantic parser produced slightly lower
precision but higher recall, with similar overall F1
score.
</bodyText>
<subsectionHeader confidence="0.997973">
5.3 Executing Navigation Plans
</subsectionHeader>
<bodyText confidence="0.999918166666666">
Finally, we evaluate the system on the end-to-end
navigation task. In addition to SGOLL and SGOLL
with the new MRG, we also look at augmenting each
of the training splits with the data we collected using
Mechanical Turk.
Completion rates for both the single-sentence
tasks and the complete tasks are shown in Table 4.
Here we see the benefit of each of our modifications.
SGOLL outperforms Chen and Mooney’s system on
both versions of the navigation task. Using the new
MRG to train the semantic parsers further improved
performance on both tasks. Finally, augmenting the
</bodyText>
<page confidence="0.998284">
435
</page>
<table confidence="0.997351625">
Single-sentence Complete
Chen and Mooney 54.40% 16.18%
SGOLL 57.09% 17.56%
SGOLL with new 57.28% 19.18%
MRG
SGOLL with new 57.62% 20.64%
MRG and
MTurk data
</table>
<tableCaption confidence="0.992989">
Table 4: End-to-end navigation task completion rates.
</tableCaption>
<table confidence="0.9992525">
Computation Time
Chen and Mooney (2011) 2,227.63
SGOLL 157.30
SGOLL with MTurk data 233.27
</table>
<tableCaption confidence="0.999874">
Table 5: The time (in seconds) it took to build the lexicon.
</tableCaption>
<bodyText confidence="0.993029333333333">
training data with additional instructions and fol-
lower traces collected from Mechanical Turk pro-
duced the best results.
</bodyText>
<subsectionHeader confidence="0.997359">
5.4 Computation Times
</subsectionHeader>
<bodyText confidence="0.999987588235294">
Having established the superior performance of our
new system compared to Chen and Mooney’s, we
next look at the computational efficiency of SGOLL.
The average time (in seconds) it takes for each al-
gorithm to build a lexicon is shown in Table 5.
All the results are obtained running the algorithms
on Dell PowerEdge 1950 servers with 2x Xeon
X5440 (quad-core) 2.83GHz processors and 32GB
of RAM. Here SGOLL has a decidedly large advan-
tage over the lexicon learning algorithm from Chen
and Mooney, requiring an order of magnitude less
time to run. Even after incorporating the new Me-
chanical Turk data into the training set, SGOLL still
takes much less time to build a lexicon. This shows
how inefficient it is to perform graph intersection op-
erations and how our online algorithm can more re-
alistically scale to large datasets.
</bodyText>
<subsectionHeader confidence="0.9992">
5.5 Experimenting with Chinese Data
</subsectionHeader>
<bodyText confidence="0.998172">
In addition to evaluating the system on English data,
we also translated the corpus used by Chen and
Mooney into Mandarin Chinese.1 To run our sys-
</bodyText>
<footnote confidence="0.960793">
1The translation can be downloaded at http://www.cs.
utexas.edu/˜ml/clamp/navigation/
</footnote>
<bodyText confidence="0.999924083333333">
tem, we first segmented the sentences using the
Stanford Chinese Word Segmenter (Chang et al.,
2008). We evaluated using the same three tasks as
before. This resulted in a precision, recall, and F1
of 87.07, 71.67, and 78.61, respectively for the in-
ferred plans. The trained semantic parser’s preci-
sion, recall, and F1 were 88.87, 58.76, and 70.74, re-
spectively. Finally, the system completed 58.70% of
the single-sentence task and 20.13% of the complete
task. All of these numbers are very similar to the En-
glish results, showing the generality of the system in
its ability to learn other languages.
</bodyText>
<subsectionHeader confidence="0.949987">
5.6 Discussion
</subsectionHeader>
<bodyText confidence="0.999988264705882">
We have introduced a novel, online lexicon learn-
ing algorithm that is much faster than the one pro-
posed by Chen and Mooney and also performs bet-
ter on the navigation tasks they devised. Having
a computationally efficient algorithm is critical for
building systems that learn from ambiguous super-
vision. Compared to systems that train on super-
vised semantic annotations, a system that only re-
ceives weak, ambiguous training data is expected to
have to train on much larger datasets to achieve sim-
ilar performance. Consequently, such system must
be able to scale well in order to keep the learning
process tractable. Not only is SGOLL much faster in
building a lexicon, it can also be easily parallelized.
Moreover, the online nature of SGOLL allows the
lexicon to be continually updated while the system
is in use. A deployed navigation system can gather
new instructions from the user and receive feedback
about whether it is performing the correct actions.
As new training examples are collected, we can up-
date the corresponding n-gram and subgraph counts
without rebuilding the entire lexicon.
One thing to note though is that while SGOLL
makes the lexicon learning step much faster and
scalable, another bottleneck in the overall system
is training the semantic parser. Existing semantic-
parser learners such as KRISP were not designed to
scale to very large datasets and have trouble training
on more than a few thousand examples. Thus, de-
signing new scalable algorithms for learning seman-
tic parsers is critical to scaling the entire system.
We have performed a pilot data collection of new
training examples using Mechanical Turk. Even
though the instructions were collected from very dif-
</bodyText>
<page confidence="0.998365">
436
</page>
<bodyText confidence="0.999885888888889">
ferent sources (paid human subjects from a univer-
sity for the original data versus workers recruited
over the Internet), we showed that adding the new
data into the training set improved the system’s per-
formance on interpreting instructions from the orig-
inal corpus. It verified that we are indeed collecting
useful information and that non-experts are fully ca-
pable of training the system by demonstrating how
to use natural language in relevant contexts.
</bodyText>
<sectionHeader confidence="0.99992" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999994781818182">
The earliest work on cross-situational word learning
was by Siskind (1996) who developed a rule-based
system to solve the referential ambiguity problem.
However, it did not handle noise and was tested only
on artificial data. More recently, Fazly et al. (2010)
proposed a probabilistic incremental model that can
learn online similar to our algorithm and was tested
on transcriptions of child-directed speech. However,
they generated the semantic representations from the
text itself rather than from the environment. More-
over, the referential ambiguity was introduced artifi-
cially by including the correct semantic representa-
tion of the neighboring sentence.
Our work falls into the larger framework of learn-
ing the semantics of language from weak supervi-
sion. This problem can be seen as an alignment
problem where each sentence in the training data
needs to be aligned to one or more records that rep-
resent its meaning. Chen and Mooney (2008) previ-
ously introduced another task that aligns sportscast-
ing commentaries to events in a simulated soccer
game. Using an EM-like retraining method, they
alternated between building a semantic parser and
estimating the most likely alignment. Liang et al.
(2009) developed an unsupervised approach using a
generative model to solve the alignment problem.
They demonstrated improved results on matching
sentences and events on the sportscasting task and
also introduced a new task of aligning weather fore-
casts to weather information. Kim and Mooney
(2010) further improved the generative alignment
model by incorporating the full semantic parsing
model from Lu et al. (2008). This resulted in a
joint generative model that outperformed all previ-
ous results. In addition to treating the ambiguous
supervision problem as an alignment problem, there
have been other approaches such as treating it as a
ranking problem (Bordes et al., 2010), or a PCFG
learning problem (Borschinger et al., 2011).
Parallel to the work of learning from ambigu-
ous supervision, other recent work has also looked
at training semantic parsers from supervision other
than logical-form annotations. Clarke et al. (2010)
and Liang et al. (2011) trained systems on question
and answer pairs by automatically finding semantic
interpretations of the questions that would generate
the correct answers. Artzi and Zettlemoyer (2011)
use conversation logs between a computer system
and a human user to learn to interpret the human
utterances. Finally, Goldwasser et al. (2011) pre-
sented an unsupervised approach of learning a se-
mantic parser by using an EM-like retraining loop.
They use confidence estimation as a proxy for the
model’s prediction quality, preferring models that
have high confidence about their parses.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999937947368421">
Learning the semantics of language from the per-
ceptual context in which it is uttered is a useful ap-
proach because only minimal human supervision is
required. In this paper we presented a novel online
algorithm for building a lexicon from ambiguously
supervised relational data. In contrast to the pre-
vious approach that computed common subgraphs
between different contexts in which an n-gram ap-
peared, we instead focus on small, connected sub-
graphs and introduce an algorithm, SGOLL, that is
an order of magnitude faster. In addition to being
more scalable, SGOLL also performed better on the
task of interpreting navigation instructions. In addi-
tion, we showed that changing the MRG and collect-
ing additional training data from Mechanical Turk
further improve the performance of the overall nav-
igation system. Finally, we demonstrated the gener-
ality of the system by using it to learn Chinese navi-
gation instructions and achieved similar results.
</bodyText>
<sectionHeader confidence="0.998836" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.976301">
The research in this paper was supported by the Na-
tional Science Foundation (NSF) under the grants
IIS-0712097 and IIS-1016312. We thank Lu Guo for
performing the translation of the corpus into Man-
darin Chinese.
</bodyText>
<page confidence="0.998077">
437
</page>
<sectionHeader confidence="0.9961" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999247847619047">
Yoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping
semantic parsers from conversations. In Proceedings
of the 2011 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP-11).
Antoine Bordes, Nicolas Usunier, and Jason Weston.
2010. Label ranking under ambiguous supervision for
learning semantic correspondences. In Proceedings of
the 27th International Conference on Machine Learn-
ing (ICML-2010).
Benjamin Borschinger, Bevan K. Jones, and Mark John-
son. 2011. Reducing grounded learning tasks to gram-
matical inference. In Proceedings of the 2011 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP-11).
Pi-Chuan Chang, Michel Galley, and Chris Manning.
2008. Optimizing Chinese word segmentation for ma-
chine translation performance. In Proceedings of the
ACL Third Workshop on Statistical Machine Transla-
tion.
David L. Chen and William B. Dolan. 2011. Collecting
highly parallel data for paraphrase evaluation. In Pro-
ceedings of the 49th Annual Meeting of the Association
for Computational Linguistics (ACL-2011), Portland,
OR, June.
David L. Chen and Raymond J. Mooney. 2008. Learn-
ing to sportscast: A test of grounded language ac-
quisition. In Proceedings of 25th International Con-
ference on Machine Learning (ICML-2008), Helsinki,
Finland, July.
David L. Chen and Raymond J. Mooney. 2011. Learn-
ing to interpret natural language navigation instruc-
tions from observations. In Proceedings of the 25th
AAAI Conference on Artificial Intelligence (AAAI-11).
James Clarke, Dan Goldwasser, Ming-Wei Chang, and
Dan Roth. 2010. Driving semantic parsing from
the worlds response. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL-2010), pages 18–27.
Afsaneh Fazly, Afra Alishahi, and Suzanne Steven-
son. 2010. A probabilistic computational model of
cross-situational word learning. Cognitive Science,
34(6):1017–1063.
Dan Goldwasser, Roi Reichart, James Clarke, and Dan
Roth. 2011. Confidence driven unsupervised semantic
parsing. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics (ACL-
11).
Rohit J. Kate and Raymond J. Mooney. 2006. Us-
ing string-kernels for learning semantic parsers. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics (COLING/ACL-06), pages 913–920, Sydney, Aus-
tralia, July.
Rohit J. Kate. 2008. Transforming meaning repre-
sentation grammars to improve semantic parsing. In
Proceedings of the Twelfth Conference on Compu-
tational Natural Language Learning (CoNLL-2008),
pages 33–40, Manchester, UK, August.
Joohyun Kim and Raymond J. Mooney. 2010. Genera-
tive alignment and semantic parsing for learning from
ambiguous supervision. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics
(COLING-10).
Thomas Kollar, Stefanie Tellex, Deb Roy, and Nicholas
Roy. 2010. Toward understanding natural language
directions. In Proceedings of the 5th ACM/IEEE In-
ternational Conference on Human-Robot Interaction
(HRI).
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilistic
CCG grammars from logical form with higher-order
unification. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing
(EMNLP-10).
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less supervi-
sion. In Joint Conference of the 47th Annual Meeting
of the Association for Computational Linguistics and
the 4th International Joint Conference on Natural Lan-
guage Processing of the Asian Federation of Natural
Language Processing (ACL-IJCNLP).
Percy Liang, Michael I. Jordan, and Dan Klein. 2011.
Learning dependency-based compositional semantics.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics (ACL-11).
Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-
moyer. 2008. A generative model for parsing natural
language to meaning representations. In Proceedings
of the 2008 Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP-08), Honolulu, HI,
October.
Matt MacMahon, Brian Stankiewicz, and Benjamin
Kuipers. 2006. Walk the talk: Connecting language,
knowledge, and action in route instructions. In Pro-
ceedings of the Twenty-First National Conference on
Artificial Intelligence (AAAI-06).
Matt MacMahon. 2007. Following Natural Language
Route Instructions. Ph.D. thesis, Electrical and Com-
puter Engineering Department, University of Texas at
Austin.
Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010.
Following directions using statistical machine transla-
tion. In Proceedings of the 5th ACM/IEEE Interna-
tional Conference on Human-Robot Interaction (HRI).
</reference>
<page confidence="0.986157">
438
</page>
<reference confidence="0.999696545454546">
Raymond J. Mooney. 2007. Learning for semantic pars-
ing. In A. Gelbukh, editor, Computational Linguistics
and Intelligent Text Processing: Proceedings of the 8th
International Conference, CICLing 2007, Mexico City,
pages 311–324. Springer Verlag, Berlin.
Nobuyuki Shimizu and Andrew Haas. 2009. Learning to
follow navigational route instructions. In Proceedings
of the Twenty-first International Joint Conference on
Artificial Intelligence (IJCAI-2009).
Jeffrey M. Siskind. 1996. A computational study
of cross-situational techniques for learning word-to-
meaning mappings. Cognition, 61(1):39–91, October.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and An-
drew Y. Ng. 2008. Cheap and fast - but is it good?
evaluating non-expert annotations for natural language
tasks. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing
(EMNLP-08).
Cynthia A. Thompson and Raymond J. Mooney. 2003.
Acquiring word-meaning mappings for natural lan-
guage interfaces. Journal of Artificial Intelligence Re-
search, 18:1–44.
Adam Vogel and Dan Jurafsky. 2010. Learning to fol-
low navigational directions. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics (ACL-10).
Luke S. Zettlemoyer and Michael Collins. 2007. Online
learning of relaxed CCG grammars for parsing to logi-
cal form. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL-07), pages 678–687, Prague, Czech
Republic, June.
</reference>
<page confidence="0.99927">
439
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.889963">
<title confidence="0.999998">Fast Online Lexicon Learning for Grounded Language Acquisition</title>
<author confidence="0.999949">L David</author>
<affiliation confidence="0.9942205">Department of Computer The University of Texas at</affiliation>
<address confidence="0.952481">1616 Guadalupe, Suite Austin, TX 78701,</address>
<email confidence="0.999818">dlcc@cs.utexas.edu</email>
<abstract confidence="0.99965496">Learning a semantic lexicon is often an important first step in building a system that learns to interpret the meaning of natural language. It is especially important in language grounding where the training data usually consist of language paired with an ambiguous perceptual context. Recent work by Chen and Mooney (2011) introduced a lexicon learning method that deals with ambiguous relational data by taking intersections of graphs. While the algorithm produced good lexicons for the task of learning to interpret navigation instructions, it only works in batch settings and does not scale well to large datasets. In this paper we introduce a new online algorithm that is an order of magnitude faster and surpasses the stateof-the-art results. We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon’s Mechanical Turk we can further improve the results. We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Bootstrapping semantic parsers from conversations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-11).</booktitle>
<contexts>
<context position="29657" citStr="Artzi and Zettlemoyer (2011)" startWordPosition="4943" endWordPosition="4946"> to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2011) presented an unsupervised approach of learning a semantic parser by using an EM-like retraining loop. They use confidence estimation as a proxy for the model’s prediction quality, preferring models that have high confidence about their parses. 7 Conclusion Learning the semantics of language from the perceptual context in which it is uttered is a useful approach because only minimal human supervision is required. In this paper we presented a novel onlin</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping semantic parsers from conversations. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Jason Weston</author>
</authors>
<title>Label ranking under ambiguous supervision for learning semantic correspondences.</title>
<date>2010</date>
<booktitle>In Proceedings of the 27th International Conference on Machine Learning (ICML-2010).</booktitle>
<contexts>
<context position="1981" citStr="Bordes et al., 2010" startWordPosition="312" endWordPosition="315">as been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is usually an important step in inferring the meanings of entire sentences. In particular, Chen and Mooney (2011) first learned a lexicon to help them resolve ambiguous supervision of relational data in which the number of choices is exponential. They represent the perceptual context as a graph and allow each sentence in the training data to align to any con</context>
<context position="29196" citStr="Bordes et al., 2010" startWordPosition="4874" endWordPosition="4877"> model to solve the alignment problem. They demonstrated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2</context>
</contexts>
<marker>Bordes, Usunier, Weston, 2010</marker>
<rawString>Antoine Bordes, Nicolas Usunier, and Jason Weston. 2010. Label ranking under ambiguous supervision for learning semantic correspondences. In Proceedings of the 27th International Conference on Machine Learning (ICML-2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Borschinger</author>
<author>Bevan K Jones</author>
<author>Mark Johnson</author>
</authors>
<title>Reducing grounded learning tasks to grammatical inference.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-11).</booktitle>
<contexts>
<context position="29251" citStr="Borschinger et al., 2011" startWordPosition="4883" endWordPosition="4886">trated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2011) presented an unsupervised approach of learning a s</context>
</contexts>
<marker>Borschinger, Jones, Johnson, 2011</marker>
<rawString>Benjamin Borschinger, Bevan K. Jones, and Mark Johnson. 2011. Reducing grounded learning tasks to grammatical inference. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Michel Galley</author>
<author>Chris Manning</author>
</authors>
<title>Optimizing Chinese word segmentation for machine translation performance.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Third Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="24631" citStr="Chang et al., 2008" startWordPosition="4142" endWordPosition="4145">ew Mechanical Turk data into the training set, SGOLL still takes much less time to build a lexicon. This shows how inefficient it is to perform graph intersection operations and how our online algorithm can more realistically scale to large datasets. 5.5 Experimenting with Chinese Data In addition to evaluating the system on English data, we also translated the corpus used by Chen and Mooney into Mandarin Chinese.1 To run our sys1The translation can be downloaded at http://www.cs. utexas.edu/˜ml/clamp/navigation/ tem, we first segmented the sentences using the Stanford Chinese Word Segmenter (Chang et al., 2008). We evaluated using the same three tasks as before. This resulted in a precision, recall, and F1 of 87.07, 71.67, and 78.61, respectively for the inferred plans. The trained semantic parser’s precision, recall, and F1 were 88.87, 58.76, and 70.74, respectively. Finally, the system completed 58.70% of the single-sentence task and 20.13% of the complete task. All of these numbers are very similar to the English results, showing the generality of the system in its ability to learn other languages. 5.6 Discussion We have introduced a novel, online lexicon learning algorithm that is much faster th</context>
</contexts>
<marker>Chang, Galley, Manning, 2008</marker>
<rawString>Pi-Chuan Chang, Michel Galley, and Chris Manning. 2008. Optimizing Chinese word segmentation for machine translation performance. In Proceedings of the ACL Third Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>William B Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-2011),</booktitle>
<location>Portland, OR,</location>
<contexts>
<context position="17686" citStr="Chen and Dolan, 2011" startWordPosition="2991" endWordPosition="2994">ation instruction corpora. The average statistics for each instruction are shown with standard deviations in parentheses. instructions. The worker is shown a 3D simulation of a randomly generated action sequence between length 1 to 4 and asked to write short, free-form instructions that would lead someone to perform those actions. Since this task requires more time to complete, each HIT consists of only 3 instructor problems. Moreover, we pay the workers $0.10 for each HIT, or about 3 cents for each instruction they write. To encourage quality contributions, we use a tiered payment structure (Chen and Dolan, 2011) that rewards the good workers. Workers who have been identified to consistently provide good instructions were allowed to do higher-paying version of the same HITs that paid $0.15 instead of $0.10. 4.2 Data Statistics Over a 2-month period we accepted 2,884 follower HITs and 810 instructor HITs from 653 workers. This corresponds to over 14,000 follower traces and 2,400 instructions with most of them consisting of single sentences. For instructions with multiple sentences, we merged all the sentences together and treated it as a single sentence. The total cost of the data collection was $277.9</context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David L. Chen and William B. Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-2011), Portland, OR, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to sportscast: A test of grounded language acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of 25th International Conference on Machine Learning (ICML-2008),</booktitle>
<location>Helsinki, Finland,</location>
<contexts>
<context position="1940" citStr="Chen and Mooney, 2008" startWordPosition="304" endWordPosition="307">derstand the semantics of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is usually an important step in inferring the meanings of entire sentences. In particular, Chen and Mooney (2011) first learned a lexicon to help them resolve ambiguous supervision of relational data in which the number of choices is exponential. They represent the perceptual context as a graph and allow each sentence</context>
<context position="28261" citStr="Chen and Mooney (2008)" startWordPosition="4731" endWordPosition="4734">ne similar to our algorithm and was tested on transcriptions of child-directed speech. However, they generated the semantic representations from the text itself rather than from the environment. Moreover, the referential ambiguity was introduced artificially by including the correct semantic representation of the neighboring sentence. Our work falls into the larger framework of learning the semantics of language from weak supervision. This problem can be seen as an alignment problem where each sentence in the training data needs to be aligned to one or more records that represent its meaning. Chen and Mooney (2008) previously introduced another task that aligns sportscasting commentaries to events in a simulated soccer game. Using an EM-like retraining method, they alternated between building a semantic parser and estimating the most likely alignment. Liang et al. (2009) developed an unsupervised approach using a generative model to solve the alignment problem. They demonstrated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment mod</context>
</contexts>
<marker>Chen, Mooney, 2008</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2008. Learning to sportscast: A test of grounded language acquisition. In Proceedings of 25th International Conference on Machine Learning (ICML-2008), Helsinki, Finland, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI-11).</booktitle>
<contexts>
<context position="2005" citStr="Chen and Mooney, 2011" startWordPosition="316" endWordPosition="319">timate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is usually an important step in inferring the meanings of entire sentences. In particular, Chen and Mooney (2011) first learned a lexicon to help them resolve ambiguous supervision of relational data in which the number of choices is exponential. They represent the perceptual context as a graph and allow each sentence in the training data to align to any connected subgraph. Their l</context>
<context position="4275" citStr="Chen and Mooney, 2011" startWordPosition="683" endWordPosition="686">larger datasets, we present results on collecting and training on additional data from Amazon’s Mechanical Turk. Finally, we show the generality of our approach by demonstrating our system’s ability to learn from a Chinese translation of the training data. 2 Background A common way to learn a lexicon across many different contexts is to find the common parts of the formal representations associated with different occurrences of the same words or phrases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision</context>
<context position="5841" citStr="Chen and Mooney (2011)" startWordPosition="957" endWordPosition="960">ption of the virtual world. The goal is then to build a system that can produce the correct aj given a previously unseen (ej, wj) pair. Since the observed actions ai only consists of low-level actions (e.g. turn left, turn right, walk forward) and not high-level concepts (e.g. turn your back against the wall and walk to the couch), Chen and Mooney first use a set of rules to automatically construct the space of reasonable plans using the action trace and knowledge about the world. The space is represented compactly using a graph as shown in Figure 1: Examples of landmarks plans constructed by Chen and Mooney (2011) and how they computed the intersection of two graphs. Figure 1. This is what they called a landmarks plan and consists of the low-level observed actions interleaved with verification steps indicating what objects should be observed after each action. Given that these landmarks plans contain a lot of extraneous details, Chen and Mooney learn a lexicon and use it to identify and remove the irrelevant parts of the plans. They use a greedy method to remove nodes from the graphs that are not associated with any of the words in the instructions. The remaining refined landmarks plans are then treate</context>
<context position="8235" citStr="Chen and Mooney (2011)" startWordPosition="1364" endWordPosition="1367">ocess consists of all the removed subgraphs. An example of the intersection operation is shown in Figure 1. Once the list of candidate meanings are generated, they are ranked by the following scoring metric for an n-gram w and a graph g: Score(w, g) = p(g|w) − p(g|mow) Intuitively, the score measures how much more likely a graph g appears when w is present compared to when it is not. The probabilities are estimated by counting how many examples contain the word w or graph g, ignoring multiple occurrences in a single example. 3 Online Lexicon Learning Algorithm While the algorithm presented by Chen and Mooney (2011) produced good lexicons, it only works in batch settings and does not scale well to large datasets. The bottleneck of their algorithm is the intersection process which is time-consuming to perform. Moreover, their algorithm requires taking many intersections between many different graphs. Even though they use beam-search to limit the size of the candidate set, if the initial candidate meaning set for a n-gram is large, it can take a long time to take just one pass through the list of all candidates. Moreover, reducing the beam size could also hurt the quality of the lexicon learned. In this se</context>
<context position="13028" citStr="Chen and Mooney (2011)" startWordPosition="2208" endWordPosition="2211">table to quickly update the co-occurrence and subgraph counts. Thus, even given a large number of subgraphs for each training example, each subgraph can be processed very quickly. Finally, this algorithm readily lends itself to being parallelized. Each processor would get a fraction of the training data and compute the counts individually. Then the counts can be merged together at the end to produce the final lexicon. 3.1 Changing the Meaning Representation Grammar In addition to introducing a new lexicon learning algorithm, we also made another modification to the original system proposed by Chen and Mooney (2011). To train a semantic parser using KRISP (Kate and Mooney, 2006), they had to supply a MRG, a context-free grammar, for their formal navigation plan language. KRISP learns string-kernel classifiers that maps natural language substrings to MRG production rules. Consequently, it is important that the production rules in the MRG mirror the structure of natural language (Kate, 2008). The original MRG used by Chen and Mooney is a compact grammar that contains many recursive rules that can be used to generate an infinite number of actions or arguments. While these rules are quite expressive, they of</context>
<context position="16788" citStr="Chen and Mooney (2011)" startWordPosition="2841" endWordPosition="2844">re asked to follow the navigation instruction as best as they could using the three discrete controls. They could also skip the problem if they did not understand the instruction or if the instruction did not describe a viable route. For each Human Intelligence Task (HIT), we asked the worker to complete 5 follower problems. We paid them $0.05 for each HIT, or 1 cent per follower problem. The instructions used for the follower problems were mainly collected from our Mechanical Turk instructor task with some of the instructions coming from data collected by MacMahon (2007) that was not used by Chen and Mooney (2011). The instructor task is slightly more involved because we ask the workers to provide new navigation Chen &amp; Mooney MTurk # instructions 3236 1011 Vocabulary size 629 590 Avg. # words 7.8 (5.1) 7.69 (7.12) Avg. # actions 2.1 (2.4) 1.84 (1.24) Table 1: Statistics about the navigation instruction corpora. The average statistics for each instruction are shown with standard deviations in parentheses. instructions. The worker is shown a 3D simulation of a randomly generated action sequence between length 1 to 4 and asked to write short, free-form instructions that would lead someone to perform those</context>
<context position="19120" citStr="Chen and Mooney (2011)" startWordPosition="3232" endWordPosition="3235">follower traces and discarded any instruction that did not have majority agreement on what the correct path is. Using our strict filter, we were left with slightly over 1,000 instructions. Statistics about the new corpus and the one used by Chen and Mooney can be seen in Table 1. Overall, the new corpus has a slightly smaller vocabulary, and each instruction is slightly shorter both in terms of the number of words and the number of actions. 434 5 Experiments We evaluate our new lexicon learning algorithm as well as the other modifications to the navigation system using the same three tasks as Chen and Mooney (2011). The first task is disambiguating the training data by inferring the correct navigation plans associated with each training sentence. The second task is evaluating the performance of the semantic parsers trained on the disambiguated data. We measure the performance of both of these tasks by comparing to gold-standard data using the same partial correctness metric used by Chen and Mooney which gives credit to a parse for producing the correct action type and additional credit if the arguments were also correct. Finally, the third task is to complete the end-to-end navigation task. There are tw</context>
<context position="23179" citStr="Chen and Mooney (2011)" startWordPosition="3905" endWordPosition="3908"> Mechanical Turk. Completion rates for both the single-sentence tasks and the complete tasks are shown in Table 4. Here we see the benefit of each of our modifications. SGOLL outperforms Chen and Mooney’s system on both versions of the navigation task. Using the new MRG to train the semantic parsers further improved performance on both tasks. Finally, augmenting the 435 Single-sentence Complete Chen and Mooney 54.40% 16.18% SGOLL 57.09% 17.56% SGOLL with new 57.28% 19.18% MRG SGOLL with new 57.62% 20.64% MRG and MTurk data Table 4: End-to-end navigation task completion rates. Computation Time Chen and Mooney (2011) 2,227.63 SGOLL 157.30 SGOLL with MTurk data 233.27 Table 5: The time (in seconds) it took to build the lexicon. training data with additional instructions and follower traces collected from Mechanical Turk produced the best results. 5.4 Computation Times Having established the superior performance of our new system compared to Chen and Mooney’s, we next look at the computational efficiency of SGOLL. The average time (in seconds) it takes for each algorithm to build a lexicon is shown in Table 5. All the results are obtained running the algorithms on Dell PowerEdge 1950 servers with 2x Xeon X5</context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI-11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Dan Goldwasser</author>
<author>Ming-Wei Chang</author>
<author>Dan Roth</author>
</authors>
<title>Driving semantic parsing from the worlds response.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010),</booktitle>
<pages>18--27</pages>
<contexts>
<context position="29451" citStr="Clarke et al. (2010)" startWordPosition="4913" endWordPosition="4916">d the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2011) presented an unsupervised approach of learning a semantic parser by using an EM-like retraining loop. They use confidence estimation as a proxy for the model’s prediction quality, preferring models that have high confidence about their parses. 7 Conc</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the worlds response. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010), pages 18–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Afra Alishahi</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A probabilistic computational model of cross-situational word learning.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>6</issue>
<contexts>
<context position="27576" citStr="Fazly et al. (2010)" startWordPosition="4623" endWordPosition="4626">ernet), we showed that adding the new data into the training set improved the system’s performance on interpreting instructions from the original corpus. It verified that we are indeed collecting useful information and that non-experts are fully capable of training the system by demonstrating how to use natural language in relevant contexts. 6 Related Work The earliest work on cross-situational word learning was by Siskind (1996) who developed a rule-based system to solve the referential ambiguity problem. However, it did not handle noise and was tested only on artificial data. More recently, Fazly et al. (2010) proposed a probabilistic incremental model that can learn online similar to our algorithm and was tested on transcriptions of child-directed speech. However, they generated the semantic representations from the text itself rather than from the environment. Moreover, the referential ambiguity was introduced artificially by including the correct semantic representation of the neighboring sentence. Our work falls into the larger framework of learning the semantics of language from weak supervision. This problem can be seen as an alignment problem where each sentence in the training data needs to</context>
</contexts>
<marker>Fazly, Alishahi, Stevenson, 2010</marker>
<rawString>Afsaneh Fazly, Afra Alishahi, and Suzanne Stevenson. 2010. A probabilistic computational model of cross-situational word learning. Cognitive Science, 34(6):1017–1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Roi Reichart</author>
<author>James Clarke</author>
<author>Dan Roth</author>
</authors>
<title>Confidence driven unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL11).</booktitle>
<contexts>
<context position="29800" citStr="Goldwasser et al. (2011)" startWordPosition="4966" endWordPosition="4969">Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2011) presented an unsupervised approach of learning a semantic parser by using an EM-like retraining loop. They use confidence estimation as a proxy for the model’s prediction quality, preferring models that have high confidence about their parses. 7 Conclusion Learning the semantics of language from the perceptual context in which it is uttered is a useful approach because only minimal human supervision is required. In this paper we presented a novel online algorithm for building a lexicon from ambiguously supervised relational data. In contrast to the previous approach that computed common subgr</context>
</contexts>
<marker>Goldwasser, Reichart, Clarke, Roth, 2011</marker>
<rawString>Dan Goldwasser, Roi Reichart, James Clarke, and Dan Roth. 2011. Confidence driven unsupervised semantic parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Using string-kernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL-06),</booktitle>
<pages>913--920</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="6531" citStr="Kate and Mooney, 2006" startWordPosition="1075" endWordPosition="1078">s is what they called a landmarks plan and consists of the low-level observed actions interleaved with verification steps indicating what objects should be observed after each action. Given that these landmarks plans contain a lot of extraneous details, Chen and Mooney learn a lexicon and use it to identify and remove the irrelevant parts of the plans. They use a greedy method to remove nodes from the graphs that are not associated with any of the words in the instructions. The remaining refined landmarks plans are then treated as supervised training data for a semantic-parser learner, KRISP (Kate and Mooney, 2006). Once a semantic parser is trained, it can be used at test time to transform novel instructions into formal navigation plans which are then carried out by a virtual robot (MacMahon et al., 2006). 2.2 Lexicon Learning The central component of the system is the lexicon learning process which associates words and short phrases (n-grams) to their meanings (connected graphs). To learn the meaning of an n-gram w, Chen and Mooney first collect all navigation plans g that co-occur with w. This forms the initial candidate meaning set for w. They then repeatedly take the intersections between the candi</context>
<context position="13092" citStr="Kate and Mooney, 2006" startWordPosition="2219" endWordPosition="2222">hus, even given a large number of subgraphs for each training example, each subgraph can be processed very quickly. Finally, this algorithm readily lends itself to being parallelized. Each processor would get a fraction of the training data and compute the counts individually. Then the counts can be merged together at the end to produce the final lexicon. 3.1 Changing the Meaning Representation Grammar In addition to introducing a new lexicon learning algorithm, we also made another modification to the original system proposed by Chen and Mooney (2011). To train a semantic parser using KRISP (Kate and Mooney, 2006), they had to supply a MRG, a context-free grammar, for their formal navigation plan language. KRISP learns string-kernel classifiers that maps natural language substrings to MRG production rules. Consequently, it is important that the production rules in the MRG mirror the structure of natural language (Kate, 2008). The original MRG used by Chen and Mooney is a compact grammar that contains many recursive rules that can be used to generate an infinite number of actions or arguments. While these rules are quite expressive, they often do not correspond well to any words or phrases in natural la</context>
</contexts>
<marker>Kate, Mooney, 2006</marker>
<rawString>Rohit J. Kate and Raymond J. Mooney. 2006. Using string-kernels for learning semantic parsers. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL-06), pages 913–920, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
</authors>
<title>Transforming meaning representation grammars to improve semantic parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL-2008),</booktitle>
<pages>33--40</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="13409" citStr="Kate, 2008" startWordPosition="2270" endWordPosition="2271">to produce the final lexicon. 3.1 Changing the Meaning Representation Grammar In addition to introducing a new lexicon learning algorithm, we also made another modification to the original system proposed by Chen and Mooney (2011). To train a semantic parser using KRISP (Kate and Mooney, 2006), they had to supply a MRG, a context-free grammar, for their formal navigation plan language. KRISP learns string-kernel classifiers that maps natural language substrings to MRG production rules. Consequently, it is important that the production rules in the MRG mirror the structure of natural language (Kate, 2008). The original MRG used by Chen and Mooney is a compact grammar that contains many recursive rules that can be used to generate an infinite number of actions or arguments. While these rules are quite expressive, they often do not correspond well to any words or phrases in natural language. To alleviate this problem, we designed another MRG by expanding out many of the rules. For example, the original MRG contained the following production rules for generating an infinite number of travel actions from the root symbol S. *S -&gt; *Action *Action -&gt; *Action, *Action *Action -&gt; *Travel *Travel -&gt; Tra</context>
</contexts>
<marker>Kate, 2008</marker>
<rawString>Rohit J. Kate. 2008. Transforming meaning representation grammars to improve semantic parsing. In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL-2008), pages 33–40, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joohyun Kim</author>
<author>Raymond J Mooney</author>
</authors>
<title>Generative alignment and semantic parsing for learning from ambiguous supervision.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10).</booktitle>
<contexts>
<context position="28815" citStr="Kim and Mooney (2010)" startWordPosition="4814" endWordPosition="4817"> or more records that represent its meaning. Chen and Mooney (2008) previously introduced another task that aligns sportscasting commentaries to events in a simulated soccer game. Using an EM-like retraining method, they alternated between building a semantic parser and estimating the most likely alignment. Liang et al. (2009) developed an unsupervised approach using a generative model to solve the alignment problem. They demonstrated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-fo</context>
</contexts>
<marker>Kim, Mooney, 2010</marker>
<rawString>Joohyun Kim and Raymond J. Mooney. 2010. Generative alignment and semantic parsing for learning from ambiguous supervision. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Kollar</author>
<author>Stefanie Tellex</author>
<author>Deb Roy</author>
<author>Nicholas Roy</author>
</authors>
<title>Toward understanding natural language directions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI).</booktitle>
<contexts>
<context position="4747" citStr="Kollar et al., 2010" startWordPosition="761" endWordPosition="764">For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision the system receives is in the form of observing how humans behave when following sample navigation instructions in a virtual world. Formally, the system is given training data in the form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)}, where ei is a written natural language instruction, ai is an observed action sequence, and wi is a description of the virtual world. The goal is then to build a system that can produce the correct aj given a previously unseen (ej, wj</context>
</contexts>
<marker>Kollar, Tellex, Roy, Roy, 2010</marker>
<rawString>Thomas Kollar, Stefanie Tellex, Deb Roy, and Nicholas Roy. 2010. Toward understanding natural language directions. In Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP-10).</booktitle>
<contexts>
<context position="1653" citStr="Kwiatkowski et al., 2010" startWordPosition="258" endWordPosition="261">representation language and training on additional data collected from Amazon’s Mechanical Turk we can further improve the results. We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach. 1 Introduction Learning to understand the semantics of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is usually an important step in </context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higher-order unification. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP).</booktitle>
<contexts>
<context position="1960" citStr="Liang et al., 2009" startWordPosition="308" endWordPosition="311">of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is usually an important step in inferring the meanings of entire sentences. In particular, Chen and Mooney (2011) first learned a lexicon to help them resolve ambiguous supervision of relational data in which the number of choices is exponential. They represent the perceptual context as a graph and allow each sentence in the training dat</context>
<context position="28522" citStr="Liang et al. (2009)" startWordPosition="4770" endWordPosition="4773">cluding the correct semantic representation of the neighboring sentence. Our work falls into the larger framework of learning the semantics of language from weak supervision. This problem can be seen as an alignment problem where each sentence in the training data needs to be aligned to one or more records that represent its meaning. Chen and Mooney (2008) previously introduced another task that aligns sportscasting commentaries to events in a simulated soccer game. Using an EM-like retraining method, they alternated between building a semantic parser and estimating the most likely alignment. Liang et al. (2009) developed an unsupervised approach using a generative model to solve the alignment problem. They demonstrated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-11).</booktitle>
<contexts>
<context position="29475" citStr="Liang et al. (2011)" startWordPosition="4918" endWordPosition="4921">t model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers. Artzi and Zettlemoyer (2011) use conversation logs between a computer system and a human user to learn to interpret the human utterances. Finally, Goldwasser et al. (2011) presented an unsupervised approach of learning a semantic parser by using an EM-like retraining loop. They use confidence estimation as a proxy for the model’s prediction quality, preferring models that have high confidence about their parses. 7 Conclusion Learning the sema</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2011. Learning dependency-based compositional semantics. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
<author>Hwee Tou Ng</author>
<author>Wee Sun Lee</author>
<author>Luke S Zettlemoyer</author>
</authors>
<title>A generative model for parsing natural language to meaning representations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-08),</booktitle>
<location>Honolulu, HI,</location>
<contexts>
<context position="1626" citStr="Lu et al., 2008" startWordPosition="254" endWordPosition="257">e formal meaning representation language and training on additional data collected from Amazon’s Mechanical Turk we can further improve the results. We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach. 1 Introduction Learning to understand the semantics of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or explicitly, is us</context>
<context position="28934" citStr="Lu et al. (2008)" startWordPosition="4832" endWordPosition="4835">ting commentaries to events in a simulated soccer game. Using an EM-like retraining method, they alternated between building a semantic parser and estimating the most likely alignment. Liang et al. (2009) developed an unsupervised approach using a generative model to solve the alignment problem. They demonstrated improved results on matching sentences and events on the sportscasting task and also introduced a new task of aligning weather forecasts to weather information. Kim and Mooney (2010) further improved the generative alignment model by incorporating the full semantic parsing model from Lu et al. (2008). This resulted in a joint generative model that outperformed all previous results. In addition to treating the ambiguous supervision problem as an alignment problem, there have been other approaches such as treating it as a ranking problem (Bordes et al., 2010), or a PCFG learning problem (Borschinger et al., 2011). Parallel to the work of learning from ambiguous supervision, other recent work has also looked at training semantic parsers from supervision other than logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) trained systems on question and answer pairs by automatica</context>
</contexts>
<marker>Lu, Ng, Lee, Zettlemoyer, 2008</marker>
<rawString>Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettlemoyer. 2008. A generative model for parsing natural language to meaning representations. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-08), Honolulu, HI, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt MacMahon</author>
<author>Brian Stankiewicz</author>
<author>Benjamin Kuipers</author>
</authors>
<title>Walk the talk: Connecting language, knowledge, and action in route instructions.</title>
<date>2006</date>
<booktitle>In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06).</booktitle>
<contexts>
<context position="4679" citStr="MacMahon et al., 2006" startWordPosition="749" endWordPosition="752">h different occurrences of the same words or phrases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision the system receives is in the form of observing how humans behave when following sample navigation instructions in a virtual world. Formally, the system is given training data in the form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)}, where ei is a written natural language instruction, ai is an observed action sequence, and wi is a description of the virtual world. The goal is then to build a syst</context>
<context position="6726" citStr="MacMahon et al., 2006" startWordPosition="1110" endWordPosition="1113">these landmarks plans contain a lot of extraneous details, Chen and Mooney learn a lexicon and use it to identify and remove the irrelevant parts of the plans. They use a greedy method to remove nodes from the graphs that are not associated with any of the words in the instructions. The remaining refined landmarks plans are then treated as supervised training data for a semantic-parser learner, KRISP (Kate and Mooney, 2006). Once a semantic parser is trained, it can be used at test time to transform novel instructions into formal navigation plans which are then carried out by a virtual robot (MacMahon et al., 2006). 2.2 Lexicon Learning The central component of the system is the lexicon learning process which associates words and short phrases (n-grams) to their meanings (connected graphs). To learn the meaning of an n-gram w, Chen and Mooney first collect all navigation plans g that co-occur with w. This forms the initial candidate meaning set for w. They then repeatedly take the intersections between the candidate meanings to generate additional candidate meanings. They use the term intersection to mean a maximal common subgraph (i.e. it is not a subgraph of any other common subgraphs). In general, th</context>
<context position="15789" citStr="MacMahon et al., 2006" startWordPosition="2672" endWordPosition="2675">a we are interested in collecting: natural language navigation instructions and follower data. Thus, we created two tasks on Mechanical Turk. The first one asks the workers to supply instructions for a randomly generated sequence of actions. The second one asks the workers to try to follow a given navigation instruction in our virtual environment. The latter task is used to generate the corresponding action sequences for instructions collected from the first task. 4.1 Task Descriptions To facilitate the data collection, we first recreated the 3D environments used to collect the original data (MacMahon et al., 2006). We built a Java application that allows the user to freely navigate the three virtual worlds constructed by MacMahon et al. (2006) using the discrete controls of turning left, turning right, and moving forward one step. The follower task is fairly straightforward using our application. The worker is given a navigation instruction and placed at the starting location. They are asked to follow the navigation instruction as best as they could using the three discrete controls. They could also skip the problem if they did not understand the instruction or if the instruction did not describe a via</context>
<context position="20972" citStr="MacMahon et al. (2006)" startWordPosition="3543" endWordPosition="3546">me data. For the second and third tasks, we train a semantic parser on the automatically disambiguated data, and test on sentences from the third, unseen map. For all comparisons to the Chen and Mooney results, we use the performance of their refined landmarks plans system which performed the best overall. Moreover, it provides the most direct comparison to our approach since both use a lexicon to refine the landmarks plans. Other than the modifications discussed, we use the same components as their system including using KRISP to train the semantic parsers and using the execution module from MacMahon et al. (2006) to carry out the navigation plans. 5.1 Inferring Navigation Plans First, we examine the quality of the refined navigation plans produced using SGOLL’s lexicon. The Precision Recall F1 Chen and Mooney 78.54 78.10 78.32 SGOLL 87.32 72.96 79.49 Table 2: Partial parse accuracy of how well each algorithm can infer the gold-standard navigation plans. Precision Recall F1 Chen and Mooney 90.22 55.10 68.37 SGOLL 92.22 55.70 69.43 SGOLL with 88.36 57.03 69.31 new MRG Table 3: Partial parse accuracy of the semantic parsers trained on the disambiguated navigation plans. precision, recall, and F1 (harmoni</context>
</contexts>
<marker>MacMahon, Stankiewicz, Kuipers, 2006</marker>
<rawString>Matt MacMahon, Brian Stankiewicz, and Benjamin Kuipers. 2006. Walk the talk: Connecting language, knowledge, and action in route instructions. In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt MacMahon</author>
</authors>
<title>Following Natural Language Route Instructions.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Electrical and Computer Engineering Department, University of Texas at Austin.</institution>
<contexts>
<context position="16744" citStr="MacMahon (2007)" startWordPosition="2834" endWordPosition="2835">aced at the starting location. They are asked to follow the navigation instruction as best as they could using the three discrete controls. They could also skip the problem if they did not understand the instruction or if the instruction did not describe a viable route. For each Human Intelligence Task (HIT), we asked the worker to complete 5 follower problems. We paid them $0.05 for each HIT, or 1 cent per follower problem. The instructions used for the follower problems were mainly collected from our Mechanical Turk instructor task with some of the instructions coming from data collected by MacMahon (2007) that was not used by Chen and Mooney (2011). The instructor task is slightly more involved because we ask the workers to provide new navigation Chen &amp; Mooney MTurk # instructions 3236 1011 Vocabulary size 629 590 Avg. # words 7.8 (5.1) 7.69 (7.12) Avg. # actions 2.1 (2.4) 1.84 (1.24) Table 1: Statistics about the navigation instruction corpora. The average statistics for each instruction are shown with standard deviations in parentheses. instructions. The worker is shown a 3D simulation of a randomly generated action sequence between length 1 to 4 and asked to write short, free-form instructi</context>
</contexts>
<marker>MacMahon, 2007</marker>
<rawString>Matt MacMahon. 2007. Following Natural Language Route Instructions. Ph.D. thesis, Electrical and Computer Engineering Department, University of Texas at Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>Dieter Fox</author>
<author>Karl Koscher</author>
</authors>
<title>Following directions using statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI).</booktitle>
<contexts>
<context position="4726" citStr="Matuszek et al., 2010" startWordPosition="757" endWordPosition="760">rases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision the system receives is in the form of observing how humans behave when following sample navigation instructions in a virtual world. Formally, the system is given training data in the form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)}, where ei is a written natural language instruction, ai is an observed action sequence, and wi is a description of the virtual world. The goal is then to build a system that can produce the correct aj given a prev</context>
</contexts>
<marker>Matuszek, Fox, Koscher, 2010</marker>
<rawString>Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010. Following directions using statistical machine translation. In Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Learning for semantic parsing.</title>
<date>2007</date>
<booktitle>Computational Linguistics and Intelligent Text Processing: Proceedings of the 8th International Conference, CICLing 2007, Mexico City,</booktitle>
<pages>311--324</pages>
<editor>In A. Gelbukh, editor,</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="1578" citStr="Mooney, 2007" startWordPosition="248" endWordPosition="249">s. We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon’s Mechanical Turk we can further improve the results. We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach. 1 Introduction Learning to understand the semantics of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and</context>
</contexts>
<marker>Mooney, 2007</marker>
<rawString>Raymond J. Mooney. 2007. Learning for semantic parsing. In A. Gelbukh, editor, Computational Linguistics and Intelligent Text Processing: Proceedings of the 8th International Conference, CICLing 2007, Mexico City, pages 311–324. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuyuki Shimizu</author>
<author>Andrew Haas</author>
</authors>
<title>Learning to follow navigational route instructions.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty-first International Joint Conference on Artificial Intelligence (IJCAI-2009).</booktitle>
<contexts>
<context position="4703" citStr="Shimizu and Haas, 2009" startWordPosition="753" endWordPosition="756"> of the same words or phrases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision the system receives is in the form of observing how humans behave when following sample navigation instructions in a virtual world. Formally, the system is given training data in the form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)}, where ei is a written natural language instruction, ai is an observed action sequence, and wi is a description of the virtual world. The goal is then to build a system that can produce the </context>
</contexts>
<marker>Shimizu, Haas, 2009</marker>
<rawString>Nobuyuki Shimizu and Andrew Haas. 2009. Learning to follow navigational route instructions. In Proceedings of the Twenty-first International Joint Conference on Artificial Intelligence (IJCAI-2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey M Siskind</author>
</authors>
<title>A computational study of cross-situational techniques for learning word-tomeaning mappings.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<issue>1</issue>
<contexts>
<context position="4126" citStr="Siskind, 1996" startWordPosition="664" endWordPosition="665">l Linguistics, pages 430–439, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics gorithm can scale to larger datasets, we present results on collecting and training on additional data from Amazon’s Mechanical Turk. Finally, we show the generality of our approach by demonstrating our system’s ability to learn from a Chinese translation of the training data. 2 Background A common way to learn a lexicon across many different contexts is to find the common parts of the formal representations associated with different occurrences of the same words or phrases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010</context>
<context position="27390" citStr="Siskind (1996)" startWordPosition="4595" endWordPosition="4596"> Turk. Even though the instructions were collected from very dif436 ferent sources (paid human subjects from a university for the original data versus workers recruited over the Internet), we showed that adding the new data into the training set improved the system’s performance on interpreting instructions from the original corpus. It verified that we are indeed collecting useful information and that non-experts are fully capable of training the system by demonstrating how to use natural language in relevant contexts. 6 Related Work The earliest work on cross-situational word learning was by Siskind (1996) who developed a rule-based system to solve the referential ambiguity problem. However, it did not handle noise and was tested only on artificial data. More recently, Fazly et al. (2010) proposed a probabilistic incremental model that can learn online similar to our algorithm and was tested on transcriptions of child-directed speech. However, they generated the semantic representations from the text itself rather than from the environment. Moreover, the referential ambiguity was introduced artificially by including the correct semantic representation of the neighboring sentence. Our work falls</context>
</contexts>
<marker>Siskind, 1996</marker>
<rawString>Jeffrey M. Siskind. 1996. A computational study of cross-situational techniques for learning word-tomeaning mappings. Cognition, 61(1):39–91, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Cheap and fast - but is it good? evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-08).</booktitle>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Y. Ng. 2008. Cheap and fast - but is it good? evaluating non-expert annotations for natural language tasks. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Raymond J Mooney</author>
</authors>
<title>Acquiring word-meaning mappings for natural language interfaces.</title>
<date>2003</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>18--1</pages>
<contexts>
<context position="4251" citStr="Thompson and Mooney, 2003" startWordPosition="679" endWordPosition="682">stics gorithm can scale to larger datasets, we present results on collecting and training on additional data from Amazon’s Mechanical Turk. Finally, we show the generality of our approach by demonstrating our system’s ability to learn from a Chinese translation of the training data. 2 Background A common way to learn a lexicon across many different contexts is to find the common parts of the formal representations associated with different occurrences of the same words or phrases (Siskind, 1996). For graphical representations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in wh</context>
</contexts>
<marker>Thompson, Mooney, 2003</marker>
<rawString>Cynthia A. Thompson and Raymond J. Mooney. 2003. Acquiring word-meaning mappings for natural language interfaces. Journal of Artificial Intelligence Research, 18:1–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Dan Jurafsky</author>
</authors>
<title>Learning to follow navigational directions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-10).</booktitle>
<contexts>
<context position="4773" citStr="Vogel and Jurafsky, 2010" startWordPosition="765" endWordPosition="768">ntations, this involves finding the common subgraph between multiple graphs (Thompson and Mooney, 2003; Chen and Mooney, 2011). In this section we review the lexicon learning algorithm introduced by Chen and Mooney (2011) as well as the overall task they designed to test semantic understanding of navigation instructions. 2.1 Navigation Task The goal of the navigation task is to build a system that can understand free-form natural-language instructions and follow them to move to the intended destination (MacMahon et al., 2006; Shimizu and Haas, 2009; Matuszek et al., 2010; Kollar et al., 2010; Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Chen and Mooney (2011) defined a learning task in which the only supervision the system receives is in the form of observing how humans behave when following sample navigation instructions in a virtual world. Formally, the system is given training data in the form: {(e1, a1, w1), (e2, a2, w2),... , (en, an, wn)}, where ei is a written natural language instruction, ai is an observed action sequence, and wi is a description of the virtual world. The goal is then to build a system that can produce the correct aj given a previously unseen (ej, wj) pair. Since the observed</context>
</contexts>
<marker>Vogel, Jurafsky, 2010</marker>
<rawString>Adam Vogel and Dan Jurafsky. 2010. Learning to follow navigational directions. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-07),</booktitle>
<pages>678--687</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1609" citStr="Zettlemoyer and Collins, 2007" startWordPosition="250" endWordPosition="253">t by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon’s Mechanical Turk we can further improve the results. We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach. 1 Introduction Learning to understand the semantics of human languages has been one of the ultimate goals of natural language processing (NLP). Traditional learning approaches have relied on access to parallel corpora of natural language sentences paired with their meanings (Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). However, constructing such semantic annotations can be difficult and time-consuming. More recently, there has been work on learning from ambiguous supervision where a set of potential sentence meanings are given, only one (or a small subset) of which are correct (Chen and Mooney, 2008; Liang et al., 2009; Bordes et al., 2010; Chen and Mooney, 2011). Given the training data, the system needs to infer the correcting meaning for each training sentence. Building a lexicon of the formal meaning representations of words and phrases, either implicitly or </context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-07), pages 678–687, Prague, Czech Republic, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>