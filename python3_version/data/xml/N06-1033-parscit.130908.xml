<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997441">
Synchronous Binarization for Machine Translation
</title>
<author confidence="0.995015">
Hao Zhang
</author>
<affiliation confidence="0.9838695">
Computer Science Department
University of Rochester
</affiliation>
<address confidence="0.786728">
Rochester, NY 14627
</address>
<email confidence="0.998937">
zhanghao@cs.rochester.edu
</email>
<author confidence="0.998669">
Daniel Gildea
</author>
<affiliation confidence="0.9928105">
Computer Science Department
University of Rochester
</affiliation>
<address confidence="0.835579">
Rochester, NY 14627
</address>
<email confidence="0.999195">
gildea@cs.rochester.edu
</email>
<author confidence="0.991519">
Liang Huang
</author>
<affiliation confidence="0.982889">
Dept. of Computer &amp; Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.802742">
Philadelphia, PA 19104
</address>
<email confidence="0.998385">
lhuang3@cis.upenn.edu
</email>
<author confidence="0.998484">
Kevin Knight
</author>
<affiliation confidence="0.9915035">
Information Sciences Institute
University of Southern California
</affiliation>
<address confidence="0.668635">
Marina del Rey, CA 90292
</address>
<email confidence="0.999408">
knight@isi.edu
</email>
<sectionHeader confidence="0.995671" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9991296875">
Systems based on synchronous grammars
and tree transducers promise to improve
the quality of statistical machine transla-
tion output, but are often very computa-
tionally intensive. The complexity is ex-
ponential in the size of individual gram-
mar rules due to arbitrary re-orderings be-
tween the two languages, and rules ex-
tracted from parallel corpora can be quite
large. We devise a linear-time algorithm
for factoring syntactic re-orderings by bi-
narizing synchronous rules when possible
and show that the resulting rule set signif-
icantly improves the speed and accuracy
of a state-of-the-art syntax-based machine
translation system.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993563288888889">
Several recent syntax-based models for machine
translation (Chiang, 2005; Galley et al., 2004) can
be seen as instances of the general framework of
synchronous grammars and tree transducers. In this
framework, both alignment (synchronous parsing)
and decoding can be thought of as parsing problems,
whose complexity is in general exponential in the
number of nonterminals on the right hand side of a
grammar rule. To alleviate this problem, we investi-
gate bilingual binarization to factor the synchronous
grammar to a smaller branching factor, although it is
not guaranteed to be successful for any synchronous
rule with arbitrary permutation. In particular:
• We develop a technique called synchronous bi-
narization and devise a fast binarization algo-
rithm such that the resulting rule set allows ef-
ficient algorithms for both synchronous parsing
and decoding with integrated n-gram language
models.
• We examine the effect of this binarization
method on end-to-end machine translation
quality, compared to a more typical baseline
method.
• We examine cases of non-binarizable rules in a
large, empirically-derived rule set, and we in-
vestigate the effect on translation quality when
excluding such rules.
Melamed (2003) discusses binarization of multi-
text grammars on a theoretical level, showing the
importance and difficulty of binarization for efficient
synchronous parsing. One way around this diffi-
culty is to stipulate that all rules must be binary
from the outset, as in inversion-transduction gram-
mar (ITG) (Wu, 1997) and the binary synchronous
context-free grammar (SCFG) employed by the Hi-
ero system (Chiang, 2005) to model the hierarchical
phrases. In contrast, the rule extraction method of
Galley et al. (2004) aims to incorporate more syn-
tactic information by providing parse trees for the
target language and extracting tree transducer rules
that apply to the parses. This approach results in
rules with many nonterminals, making good bina-
rization techniques critical.
Suppose we have the following SCFG, where su-
perscripts indicate reorderings (formal definitions of
</bodyText>
<page confidence="0.959161">
256
</page>
<note confidence="0.9966325">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 256–263,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<figureCaption confidence="0.995863333333333">
Figure 1: A pair of synchronous parse trees in the
SCFG (1). The dashed curves indicate pairs of syn-
chronous nonterminals (and sub trees).
</figureCaption>
<bodyText confidence="0.548092">
SCFGs can be found in Section 2):
</bodyText>
<equation confidence="0.6433105">
S NP(1) VP(2) PP(3), NP(1) PP(3) VP(2)
NP Powell, Baoweier
</equation>
<bodyText confidence="0.952996866666667">
VP held a meeting, juxing le huitan
PP with Sharon, yu Shalong
Decoding can be cast as a (monolingual) parsing
problem since we only need to parse the source-
language side of the SCFG, as if we were construct-
ing a CFG projected on Chinese out of the SCFG.
The only extra work we need to do for decoding
is to build corresponding target-language (English)
subtrees in parallel. In other words, we build syn-
chronous trees when parsing the source-language in-
put, as shown in Figure 1.
To efficiently decode with CKY, we need to bi-
narize the projected CFG grammar.&apos; Rules can be
binarized in different ways. For example, we could
binarize the first rule left to right or right to left:
</bodyText>
<sectionHeader confidence="0.9599735" genericHeader="method">
S NP VPP-VP
VPP-VP PP VP
</sectionHeader>
<bodyText confidence="0.999486538461538">
We call those intermediate symbols (e.g. VPP-VP) vir-
tual nonterminals and corresponding rules virtual
rules, whose probabilities are all set to 1.
These two binarizations are no different in the
translation-model-only decoding described above,
just as in monolingual parsing. However, in the
source-channel approach to machine translation, we
need to combine probabilities from the translation
model (an SCFG) with the language model (an n-
gram), which has been shown to be very impor-
tant for translation quality (Chiang, 2005). To do
bigram-integrated decoding, we need to augment
each chart item (X, i, j) with two target-language
</bodyText>
<footnote confidence="0.908899666666667">
1Other parsing strategies like the Earley algorithm use an
internal binary representation (e.g. dotted-rules) of the original
grammar to ensure cubic time complexity.
</footnote>
<bodyText confidence="0.903145833333333">
boundary words u and v to produce a bigram-item
like u X v \ , following the dynamic program-
(i j
ming algorithm of Wu (1996).
Now the two binarizations have very different ef-
fects. In the first case, we first combine NP with PP:
</bodyText>
<equation confidence="0.9526845">
� Powell ··· Powell � �with ··· Sharon �
NP : p PP : q
1 2 2 4
� Powell ··· Powell ··· with ··· Sharon �
VNP-PP : pq
1 4
</equation>
<bodyText confidence="0.964371">
where p and q are the scores of antecedent items.
This situation is unpleasant because in the target-
language NP and PP are not contiguous so we can-
not apply language model scoring when we build the
VNP-PP item. Instead, we have to maintain all four
boundary words (rather than two) and postpone the
language model scoring till the next step where VNP-PP
is combined with C held ··· meeting l
/I to form an S item.
</bodyText>
<sectionHeader confidence="0.439039" genericHeader="method">
2 VP 4
</sectionHeader>
<bodyText confidence="0.999872045454546">
We call this binarization method monolingual bina-
rization since it works only on the source-language
projection of the rule without respecting the con-
straints from the other side.
This scheme generalizes to the case where we
have n nonterminals in a SCFG rule, and the decoder
conservatively assumes nothing can be done on lan-
guage model scoring (because target-language spans
are non-contiguous in general) until the real nonter-
minal has been recognized. In other words, target-
language boundary words from each child nonter-
minal of the rule will be cached in all virtual non-
terminals derived from this rule. In the case of
m-gram integrated decoding, we have to maintain
2(m − 1) boundary words for each child nontermi-
nal, which leads to a prohibitive overall complex-
ity of O(|w|3+2n(m−1)), which is exponential in rule
size (Huang et al., 2005). Aggressive pruning must
be used to make it tractable in practice, which in
general introduces many search errors and adversely
affects translation quality.
In the second case, however:
</bodyText>
<equation confidence="0.974405333333333">
� with ··· Sharon � �held ··· meeting �
PP : r VP : s
2 4 4 7
� held ··· Sharon �
VPP-VP : rs · Pr(with  |meeting)
2 7
</equation>
<bodyText confidence="0.9980205">
Here since PP and VP are contiguous (but
swapped) in the target-language, we can include the
</bodyText>
<figure confidence="0.999552818181818">
S
S
Baoweier
yu
Shalong
VP
juxing le
huitan
VP
held
a meeting
PP
with
Sharon
NP
Powell
PP
NP
(1)
S VNP-PP VP
VNP-PP NP PP
or
</figure>
<page confidence="0.543284">
257
</page>
<figureCaption confidence="0.997946">
Figure 2: The alignment pattern (left) and alignment
matrix (right) of the synchronous production.
</figureCaption>
<bodyText confidence="0.93092675">
language model score by adding Pr(with  |meeting),
and the resulting item again has two boundary
words. Later we add Pr(held  |Powell) when the
resulting item is combined with � Powell ��� Powell
</bodyText>
<equation confidence="0.652947">
1 2
NP to
</equation>
<bodyText confidence="0.999651">
form an S item. As illustrated in Figure 2, VPP-VP has
contiguous spans on both source and target sides, so
that we can generate a binary-branching SCFG:
</bodyText>
<equation confidence="0.984176">
S → NP(1) VPP-VP(2), NP(1) VPP-VP(2)
(2) VPP-VP → VP(1) PP(2), PP(2) VP(1)
</equation>
<bodyText confidence="0.999947">
In this case m-gram integrated decoding can be
done in O(|w|3+4(m−1)) time which is much lower-
order polynomial and no longer depends on rule size
(Wu, 1996), allowing the search to be much faster
and more accurate facing pruning, as is evidenced in
the Hiero system of Chiang (2005) where he restricts
the hierarchical phrases to be a binary SCFG. The
benefit of binary grammars also lies in synchronous
parsing (alignment). Wu (1997) shows that parsing
a binary SCFG is in O(|w|6) while parsing SCFG is
NP-hard in general (Satta and Peserico, 2005).
The same reasoning applies to tree transducer
rules. Suppose we have the following tree-to-string
rules, following Galley et al. (2004):
</bodyText>
<equation confidence="0.996329">
S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2
NP(NNP(Powell)) → Baoweier
</equation>
<listItem confidence="0.968277333333333">
(3) VP(VBD(held), NP(DT(a) NPS(meeting)))
→ juxing le huitan
PP(TO(with), NP(NNP(Sharon))) → yu Shalong
</listItem>
<bodyText confidence="0.999742739130435">
where the reorderings of nonterminals are denoted
by variables xi.
Notice that the first rule has a multi-level left-
hand side subtree. This system can model non-
isomorphic transformations on English parse trees
to “fit” another language, for example, learning that
the (S (V O)) structure in English should be trans-
formed into a (V S O) structure in Arabic, by look-
ing at two-level tree fragments (Knight and Graehl,
2005). From a synchronous rewriting point of view,
this is more akin to synchronous tree substitution
grammar (STSG) (Eisner, 2003). This larger locality
is linguistically motivated and leads to a better pa-
rameter estimation. By imagining the left-hand-side
trees as special nonterminals, we can virtually cre-
ate an SCFG with the same generative capacity. The
technical details will be explained in Section 3.2.
In general, if we are given an arbitrary syn-
chronous rule with many nonterminals, what are the
good decompositions that lead to a binary grammar?
Figure 2 suggests that a binarization is good if ev-
ery virtual nonterminal has contiguous spans on both
sides. We formalize this idea in the next section.
</bodyText>
<sectionHeader confidence="0.964461" genericHeader="method">
2 Synchronous Binarization
</sectionHeader>
<bodyText confidence="0.999982">
A synchronous CFG (SCFG) is a context-free
rewriting system for generating string pairs. Each
rule (synchronous production) rewrites a nontermi-
nal in two dimensions subject to the constraint that
the sequence of nonterminal children on one side is
a permutation of the nonterminal sequence on the
other side. Each co-indexed child nonterminal pair
will be further rewritten as a unit.2 We define the
language L(G) produced by an SCFG G as the pairs
of terminal strings produced by rewriting exhaus-
tively from the start symbol.
As shown in Section 3.2, terminals do not play
an important role in binarization. So we now write
rules in the following notation:
</bodyText>
<equation confidence="0.9998055">
X → X(1)
1 ...X(n)
n , X(π(1))
π(1) ...X(π(n)) π(n)
</equation>
<bodyText confidence="0.979663285714286">
where each Xi is a variable which ranges over non-
terminals in the grammar and π is the permutation
of the rule. We also define an SCFG rule as n-ary
if its permutation is of n and call an SCFG n-ary if
its longest rule is n-ary. Our goal is to produce an
equivalent binary SCFG for an input n-ary SCFG.
2In making one nonterminal play dual roles, we follow the
definitions in (Aho and Ullman, 1972; Chiang, 2005), origi-
nally known as Syntax Directed Translation Schema (SDTS).
An alternative definition by Satta and Peserico (2005) allows
co-indexed nonterminals taking different symbols in two di-
mensions. Formally speaking, we can construct an equivalent
SDTS by creating a cross-product of nonterminals from two
sides. See (Satta and Peserico, 2005, Sec. 4) for other details.
</bodyText>
<figure confidence="0.997073771428571">
source (Chinese)
target (English)
NP
NP
VP
PP
VPP-VP
VP
PP
English boundary words
meeting
Sharon
Powell
Powell
with
held
1 2 4 7
PP
NP
Chinese indices
VPP-VP
VP
258
(5,4)
(2,3)
2 3
5 4
(2,3,5,4)
2 (3,5,4)
3 (5,4)
5 4
(a) (b) (c)
(2,3,5,4)
O(Iw16) parsable
SCFG bSCFG SCFG-2
</figure>
<figureCaption confidence="0.726786">
Figure 3: (a) and (b): two binarization patterns
for (2, 3, 5, 4). (c): alignment matrix for the non-
binarizable permuted sequence (2, 4, 1, 3)
</figureCaption>
<bodyText confidence="0.9995635">
However, not every SCFG can be binarized. In
fact, the binarizability of an n-ary rule is determined
by the structure of its permutation, which can some-
times be resistant to factorization (Aho and Ullman,
1972). So we now start to rigorously define the bi-
narizability of permutations.
</bodyText>
<subsectionHeader confidence="0.991801">
2.1 Binarizable Permutations
</subsectionHeader>
<bodyText confidence="0.999735666666667">
A permuted sequence is a permutation of consec-
utive integers. For example, (3, 5, 4) is a permuted
sequence while (2, 5) is not. As special cases, single
numbers are permuted sequences as well.
A sequence a is said to be binarizable if it is a
permuted sequence and either
</bodyText>
<listItem confidence="0.9967496">
1. a is a singleton, i.e. a = (a), or
2. a can be split into two sub sequences, i.e.
a = (b; c), where b and c are both binarizable
permuted sequences. We call such a division
(b; c) a binarizable split of a.
</listItem>
<bodyText confidence="0.991206">
This is a recursive definition. Each binarizable
permuted sequence has at least one hierarchical bi-
narization pattern. For instance, the permuted se-
quence (2, 3, 5, 4) is binarizable (with two possible
binarization patterns) while (2, 4,1, 3) is not (see
Figure 3).
</bodyText>
<subsectionHeader confidence="0.998902">
2.2 Binarizable SCFG
</subsectionHeader>
<bodyText confidence="0.999177666666667">
An SCFG is said to be binarizable if the permu-
tation of each synchronous production is binariz-
able. We denote the class of binarizable SCFGs as
bSCFG. This set represents an important subclass
of SCFG that is easy to handle (parsable in O(|w|6))
and covers many interesting longer-than-two rules.3
</bodyText>
<footnote confidence="0.780885">
3Although we factor the SCFG rules individually and de-
fine bSCFG accordingly, there are some grammars (the dashed
</footnote>
<figureCaption confidence="0.993409">
Figure 4: Subclasses of SCFG. The thick arrow de-
notes the direction of synchronous binarization. For
clarity reasons, binary SCFG is coded as SCFG-2.
</figureCaption>
<construct confidence="0.388265">
Theorem 1. For each grammar G in bSCFG, there
exists a binary SCFG G&apos;, such that L(G&apos;) = L(G).
</construct>
<bodyText confidence="0.999850666666667">
Proof. Once we decompose the permutation of n
in the original rule into binary permutations, all
that remains is to decorate the skeleton binary parse
with nonterminal symbols and attach terminals to
the skeleton appropriately. We explain the technical
details in the next section.
</bodyText>
<sectionHeader confidence="0.990733" genericHeader="method">
3 Binarization Algorithms
</sectionHeader>
<bodyText confidence="0.995239230769231">
We have reduced the problem of binarizing an SCFG
rule into the problem of binarizing its permutation.
This problem can be cast as an instance of syn-
chronous ITG parsing (Wu, 1997). Here the parallel
string pair that we are parsing is the integer sequence
(1...n) and its permutation (7r(1)...7r(n)). The goal
of the ITG parsing is to find a synchronous tree that
agrees with the alignment indicated by the permu-
tation. In fact, as demonstrated previously, some
permutations may have more than one binarization
patterns among which we only need one. Wu (1997,
Sec. 7) introduces a non-ambiguous ITG that prefers
left-heavy binary trees so that for each permutation
there is a unique synchronous derivation (binariza-
tion pattern).
However, this problem has more efficient solu-
tions. Shapiro and Stephens (1991, p. 277) infor-
mally present an iterative procedure where in each
pass it scans the permuted sequence from left to right
and combines two adjacent sub sequences whenever
possible. This procedure produces a left-heavy bi-
narization tree consistent with the unambiguous ITG
and runs in O(n2) time since we need n passes in the
worst case. We modify this procedure and improve
circle in Figure 4), which can be binarized only by analyzing
interactions between rules. Below is a simple example:
</bodyText>
<equation confidence="0.861576">
S X(1) X(2) X(3) X(4), X(2) X(4) X(1) X(3)
X a, a
</equation>
<page confidence="0.99597">
259
</page>
<figure confidence="0.971675818181818">
iteration stack input action
1 5 3 4 2
1 5 3 4 2 shift
1 1 5 3 4 2 shift
2 1 5 3 4 2 shift
3 1 5 3 4 2 shift
1 5 3-4 2 reduce [3,4]
1 3-5 2 reduce (5,[3,4])
4 1 3-5 2 shift
1 2-5 reduce (2, (5, [3, 4]))
1-5 reduce [1, (2, (5, [3, 4]))]
</figure>
<figureCaption confidence="0.819062666666667">
Figure 5: Example of Algorithm 1 on the input
(1, 5, 3, 4, 2). The rightmost column shows the
binarization-trees generated at each reduction step.
</figureCaption>
<bodyText confidence="0.928518">
it into a linear-time shift-reduce algorithm that only
needs one pass through the sequence.
</bodyText>
<subsectionHeader confidence="0.999284">
3.1 The linear-time skeleton algorithm
</subsectionHeader>
<bodyText confidence="0.999563666666667">
The (unique) binarization tree bi(a) for a binariz-
able permuted sequence a is recursively defined as
follows:
</bodyText>
<listItem confidence="0.96554525">
• if a = (a), then bi(a) = a;
• otherwise let a = (b; c) to be the rightmost
binarizable split of a. then
�
</listItem>
<equation confidence="0.992426">
[bi(b), bi(c)] b1 &lt; c1
bi(a) =
(bi(b), bi(c)) b1 � c1�
</equation>
<bodyText confidence="0.999983071428572">
For example, the binarization tree for (2, 3, 5, 4)
is [[2, 3], (5, 4)], which corresponds to the binariza-
tion pattern in Figure 3(a). We use [] and () for
straight and inverted combinations respectively, fol-
lowing the ITG notation (Wu, 1997). The rightmost
split ensures left-heavy binary trees.
The skeleton binarization algorithm is an instance
of the widely used left-to-right shift-reduce algo-
rithm. It maintains a stack for contiguous subse-
quences discovered so far, like 2-5, 1. In each it-
eration, it shifts the next number from the input and
repeatedly tries to reduce the top two elements on
the stack if they are consecutive. See Algorithm 1
for details and Figure 5 for an example.
</bodyText>
<construct confidence="0.95570775">
Theorem 2. Algorithm 1 succeeds if and only if the
input permuted sequence a is binarizable, and in
case of success, the binarization pattern recovered
is the binarization tree of a.
</construct>
<bodyText confidence="0.999465774193548">
260 Proof. —*: it is obvious that if the algorithm suc-
ceeds then a is binarizable using the binarization
pattern recovered.
+—: by a complete induction on n, the length of a.
Base case: n = 1, trivial.
Assume it holds for all n&apos; &lt; n.
If a is binarizable, then let a = (b; c) be its right-
most binarizable split. By the induction hypothesis,
the algorithm succeeds on the partial input b, reduc-
ing it to the single element
on the stack and re-
covering its binarization tree bi(b).
Let c =
c2). If
is binarizable and trig-
gers our binarizer to make a straight combination
of (b;
must be true that
nation. We claim that c2 must be binarizable in this
situation. So, (b,
right of the rightmost binarizable split (b; c), which
is a contradiction. A similar contradiction will arise
if b and
can make an inverted concatenation.
Therefore, the algorithm will scan through the
whole c as if from the empty stack. By the in-
duction hypothesis again, it will reduce c into s[1]
on the stack and recover its binarization tree bi(c).
Since b and c are combinable, the algorithm re-
duces s[0] and s[1] in the last step, forming the bi-
nari
</bodyText>
<equation confidence="0.985828">
s[0]
(c1;
c1
c1),
(c1;
c1;
c1
</equation>
<bodyText confidence="0.9280485">
zation tree for a, which is either [bi(b), bi(c)] or
(bi(b), bi(c)).
based on the property of permutations, it
c2) is a valid straight concate-
c2) is a binarizable split to the
are exactly n shifts and at most
reductions, and
n−1
O(1) time.
The running time of Algorithm 1 is linear in n, the
length of the input sequence. This is because there
each shift or reduction takes
</bodyText>
<subsectionHeader confidence="0.999996">
3.2 Binarizing tree-to-string transducers
</subsectionHeader>
<bodyText confidence="0.940589666666667">
Without loss of generality, we have discussed how
to binarize synchronous productions involving only
nonterminals through binarizing the corresponding
skeleton permutations. We still need to tackle a few
technical problems in the actual system.
First, we are dealing with tree-to-string trans-
ducer rules. We view each left-hand side subtree
as a monolithic nonterminal symbol and factor each
transducer rule into two SCFG rules: one from
the root nonterminal to the subtree, and the other
from the subtree to the leaves. In this way we can
uniquely reconstruct the tree-to-string derivation us-
ing the two-step SCFG deri
vation. For example,
Algorithm 1 The Linear-time Binarization Algorithm
</bodyText>
<listItem confidence="0.927453071428571">
1: function BINARIZABLE(a)
2: top +— 0 &gt; stack top pointer
3: PUSH(a1, al) &gt; initial shift
4: for i +— 2 to |a |do &gt; for each remaining element
5: PUSH(ai, ai) &gt; shift
6: while top &gt; 1 and CONSECUTIVE(s[top], s[top − 1]) do &gt; keep reducing if possible
7: (p, q) +— COMBINE(s[top], s[top − 1])
8: top +— top − 2
9: PUSH(p, q)
10: return (top = 1) &gt; if reduced to a single element then the input is binarizable, otherwise not
11: function CONSECUTIVE((a, b), (c, d))
12: return (b = c − 1) or (d = a − 1) &gt; either straight or inverted
13: function COMBINE((a, b), (c, d))
14: return (min(a, c), max(b, d))
</listItem>
<bodyText confidence="0.727244666666667">
consider the following tree-to-string rule:
DT x2:NN
the
We create a specific nonterminal, say, T859, which
is a unique identifier for the left-hand side subtree
and generate the following two SCFG rules:
</bodyText>
<equation confidence="0.975501666666667">
ADJP T859 (1), T859 (1)
RB(1) resp. for the NN(2) PP(3),
T859 RB(1) fuze PP(3) de NN(2)
</equation>
<bodyText confidence="0.9978783125">
Second, besides synchronous nonterminals, ter-
minals in the two languages can also be present, as
in the above example. It turns out we can attach the
terminals to the skeleton parse for the synchronous
nonterminal strings quite freely as long as we can
uniquely reconstruct the original rule from its binary
parse tree. In order to do so we need to keep track of
sub-alignments including both aligned nonterminals
and neighboring terminals.
When binarizing the second rule above, we first
run the skeleton algorithm to binarize the under-
lying permutation (1, 3, 2) to its binarization tree
[1, (3, 2)]. Then we do a post-order traversal to the
skeleton tree, combining Chinese terminals (one at
a time) at the leaf nodes and merging English termi-
nals greedily at internal nodes:
</bodyText>
<figure confidence="0.731458">
T859 [1,(3,2)]
V[RB, fuze]1 V(V[PP, de], resp. for the NN)(3,2)
�
RB fuze
3 2
PP de
</figure>
<bodyText confidence="0.955313">
A pre-order traversal of the decorated binarization
tree gives us the following binary SCFG rules:
</bodyText>
<equation confidence="0.999348333333333">
T859 V1(1) V2(2), V1(1) V2(2)
V1 RB(1), RB(1) fuze
V2 resp. for the NN(1) V(2)
3 , V(2)
3 NN(1)
V3 PP(1), PP(1) de
</equation>
<bodyText confidence="0.998103">
where the virtual nonterminals are:
</bodyText>
<footnote confidence="0.883592">
V1: V[RB, fuze]
V2: V(V[PP, de], resp. for the NN)
V3: V[PP, de]
</footnote>
<bodyText confidence="0.999211777777778">
Analogous to the “dotted rules” in Earley pars-
ing for monolingual CFGs, the names we create
for the virtual nonterminals reflect the underlying
sub-alignments, ensuring intermediate states can be
shared across different tree-to-string rules without
causing ambiguity.
The whole binarization algorithm still runs in time
linear in the number of symbols in the rule (includ-
ing both terminals and nonterminals).
</bodyText>
<sectionHeader confidence="0.999601" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.890799">
In this section, we answer two empirical questions.
</bodyText>
<figure confidence="0.993537333333333">
PP
IN
NP-C
ADJP
x0:RB JJ
responsible
x0 fuze x1 de x2
NPB
for
x1:PP
[1, (3,2)]
1 (3,2)
V[PP, de]3 NN2
261
# of rules
percentage (%)
100
1e+07
8e+06
80
6e+06
60
4e+06
40
2e+06
20
0
0
0 5 10 15 20 25 30 35 40
length
</figure>
<figureCaption confidence="0.951283666666667">
Figure 6: The solid-line curve represents the distribution of all rules against permutation lengths. The
dashed-line stairs indicate the percentage of non-binarizable rules in our initial rule set while the dotted-line
denotes that percentage among all permutations.
</figureCaption>
<subsectionHeader confidence="0.997807">
4.1 How many rules are binarizable?
</subsectionHeader>
<bodyText confidence="0.999969916666667">
It has been shown by Shapiro and Stephens (1991)
and Wu (1997, Sec. 4) that the percentage of binariz-
able cases over all permutations of length n quickly
approaches 0 as n grows (see Figure 6). However,
for machine translation, it is more meaningful to
compute the ratio of binarizable rules extracted from
real text. Our rule set is obtained by first doing word
alignment using GIZA++ on a Chinese-English par-
allel corpus containing 50 million words in English,
then parsing the English sentences using a variant
of Collins parser, and finally extracting rules using
the graph-theoretic algorithm of Galley et al. (2004).
We did a “spectrum analysis” on the resulting rule
set with 50,879,242 rules. Figure 6 shows how the
rules are distributed against their lengths (number
of nonterminals). We can see that the percentage
of non-binarizable rules in each bucket of the same
length does not exceed 25%. Overall, 99.7% of
the rules are binarizable. Even for the 0.3% non-
binarizable rules, human evaluations show that the
majority of them are due to alignment errors. It is
also interesting to know that 86.8% of the rules have
monotonic permutations, i.e. either taking identical
or totally inverted order.
</bodyText>
<subsectionHeader confidence="0.991668">
4.2 Does synchronous binarizer help decoding?
</subsectionHeader>
<bodyText confidence="0.853386384615385">
We did experiments on our CKY-based decoder with
two binarization methods. It is the responsibility of
the binarizer to instruct the decoder how to compute
the language model scores from children nontermi-
nals in each rule. The baseline method is mono-
lingual left-to-right binarization. As shown in Sec-
tion 1, decoding complexity with this method is ex-
ponential in the size of the longest rule and since we
postpone all the language model scorings, pruning
in this case is also biased.
system bleu
monolingual binarization 36.25
synchronous binarization 38.44
</bodyText>
<tableCaption confidence="0.8894515">
alignment-template system 37.00
Table 1: Syntax-based systems vs. ATS
</tableCaption>
<bodyText confidence="0.999979482758621">
To move on to synchronous binarization, we first
did an experiment using the above baseline system
without the 0.3% non-binarizable rules and did not
observe any difference in BLEU scores. So we
safely move a step further, focusing on the binariz-
able rules only.
The decoder now works on the binary translation
rules supplied by an external synchronous binarizer.
As shown in Section 1, this results in a simplified de-
coder with a polynomial time complexity, allowing
less aggressive and more effective pruning based on
both translation model and language model scores.
We compare the two binarization schemes in
terms of translation quality with various pruning
thresholds. The rule set is that of the previous sec-
tion. The test set has 116 Chinese sentences of no
longer than 15 words. Both systems use trigram as
the integrated language model. Figure 7 demon-
strates that decoding accuracy is significantly im-
proved after synchronous binarization. The number
of edges proposed during decoding is used as a mea-
sure of the size of search space, or time efficiency.
Our system is consistently faster and more accurate
than the baseline system.
We also compare the top result of our syn-
chronous binarization system with the state-of-the-
art alignment-template approach (ATS) (Och and
Ney, 2004). The results are shown in Table 1. Our
system has a promising improvement over the ATS
</bodyText>
<page confidence="0.995618">
262
</page>
<figureCaption confidence="0.9254685">
Figure 7: Comparing the two binarization methods
in terms of translation quality against search effort.
</figureCaption>
<bodyText confidence="0.9963895">
system which is trained on a larger data-set but tuned
independently.
</bodyText>
<sectionHeader confidence="0.999105" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999233961538462">
Modeling reorderings between languages has been a
major challenge for machine translation. This work
shows that the majority of syntactic reorderings, at
least between languages like English and Chinese,
can be efficiently decomposed into hierarchical bi-
nary reorderings. From a modeling perspective, on
the other hand, it is beneficial to start with a richer
representation that has more transformational power
than ITG or binary SCFG. Our work shows how to
convert it back to a computationally friendly form
without harming much of its expressiveness. As a
result, decoding with n-gram models can be fast and
accurate, making it possible for our syntax-based
system to overtake a comparable phrase-based sys-
tem in BLEU score. We believe that extensions of
our technique to more powerful models such as syn-
chronous tree-adjoining grammar (Shieber and Sch-
abes, 1990) is an interesting area for further work.
Acknowledgments Much of this work was done
when H. Zhang and L. Huang were visiting
USC/ISI. The authors wish to thank Wei Wang,
Jonathan Graehl and Steven DeNeefe for help with
the experiments. We are also grateful to Daniel
Marcu, Giorgio Satta, and Aravind Joshi for discus-
sions. This work was partially supported by NSF
ITR IIS-09325646 and NSF ITR IIS-0428020.
</bodyText>
<sectionHeader confidence="0.996084" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999650761904762">
Albert V. Aho and Jeffery D. Ullman. 1972. The The-
ory of Parsing, Translation, and Compiling, volume 1.
Prentice-Hall, Englewood Cliffs, NJ.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL-05, pages 263–270, Ann Arbor, Michigan.
Jason Eisner. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proceedings ofACL-
03, companion volume, Sapporo, Japan.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In Pro-
ceedings ofHLT/NAACL-04.
Liang Huang, Hao Zhang, and Daniel Gildea. 2005. Ma-
chine translation as lexicalized parsing with hooks. In
Proceedings ofIWPT-05, Vancouver, BC.
Kevin Knight and Jonathan Graehl. 2005. An overview
of probabilistic tree transducers for natural language
processing. In Conference on Intelligent Text Process-
ing and Computational Linguistics (CICLing). LNCS.
I. Dan Melamed. 2003. Multitext grammars and syn-
chronous parsers. In Proceedings of NAACL-03, Ed-
monton.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics, 30(4).
Giorgio Satta and Enoch Peserico. 2005. Some computa-
tional complexity results for synchronous context-free
grammars. In Proceedings of HLT/EMNLP-05, pages
803–810, Vancouver, Canada, October.
L. Shapiro and A. B. Stephens. 1991. Bootstrap percola-
tion, the Schr¨oder numbers, and the n-kings problem.
SIAM Journal on Discrete Mathematics, 4(2):275–
280.
Stuart Shieber and Yves Schabes. 1990. Synchronous
tree-adjoining grammars. In COLING-90, volume III,
pages 253–258.
Dekai Wu. 1996. A polynomial-time algorithm for sta-
tistical machine translation. In 34th Annual Meeting
of the Association for Computational Linguistics.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
</reference>
<figure confidence="0.998203454545454">
3e+09 4e+09 5e+09 6e+09 7e+09
# of edges proposed during decoding
bleu scores
38.5
37.5
36.5
35.5
34.5
33.5
synchronous binarization
monolingual binarization
</figure>
<page confidence="0.986027">
263
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.209782">
<title confidence="0.999894">Synchronous Binarization for Machine Translation</title>
<author confidence="0.981603">Hao</author>
<affiliation confidence="0.999618">Computer Science University of</affiliation>
<address confidence="0.856457">Rochester, NY</address>
<email confidence="0.999407">zhanghao@cs.rochester.edu</email>
<author confidence="0.944333">Daniel</author>
<affiliation confidence="0.9996585">Computer Science University of</affiliation>
<address confidence="0.866672">Rochester, NY</address>
<email confidence="0.999054">gildea@cs.rochester.edu</email>
<author confidence="0.886495">Liang</author>
<affiliation confidence="0.999874">Dept. of Computer &amp; Information University of</affiliation>
<address confidence="0.534307">Philadelphia, PA</address>
<email confidence="0.997576">lhuang3@cis.upenn.edu</email>
<author confidence="0.948354">Kevin</author>
<affiliation confidence="0.999579">Information Sciences University of Southern</affiliation>
<author confidence="0.687948">Marina del Rey</author>
<author confidence="0.687948">CA</author>
<email confidence="0.999246">knight@isi.edu</email>
<abstract confidence="0.999520058823529">Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output, but are often very computationally intensive. The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large. We devise a linear-time algorithm for factoring syntactic re-orderings by binarizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Albert V Aho</author>
<author>Jeffery D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling,</booktitle>
<volume>1</volume>
<publisher>Prentice-Hall,</publisher>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="10967" citStr="Aho and Ullman, 1972" startWordPosition="1800" endWordPosition="1803">ing exhaustively from the start symbol. As shown in Section 3.2, terminals do not play an important role in binarization. So we now write rules in the following notation: X → X(1) 1 ...X(n) n , X(π(1)) π(1) ...X(π(n)) π(n) where each Xi is a variable which ranges over nonterminals in the grammar and π is the permutation of the rule. We also define an SCFG rule as n-ary if its permutation is of n and call an SCFG n-ary if its longest rule is n-ary. Our goal is to produce an equivalent binary SCFG for an input n-ary SCFG. 2In making one nonterminal play dual roles, we follow the definitions in (Aho and Ullman, 1972; Chiang, 2005), originally known as Syntax Directed Translation Schema (SDTS). An alternative definition by Satta and Peserico (2005) allows co-indexed nonterminals taking different symbols in two dimensions. Formally speaking, we can construct an equivalent SDTS by creating a cross-product of nonterminals from two sides. See (Satta and Peserico, 2005, Sec. 4) for other details. source (Chinese) target (English) NP NP VP PP VPP-VP VP PP English boundary words meeting Sharon Powell Powell with held 1 2 4 7 PP NP Chinese indices VPP-VP VP 258 (5,4) (2,3) 2 3 5 4 (2,3,5,4) 2 (3,5,4) 3 (5,4) 5 4 </context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Albert V. Aho and Jeffery D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling, volume 1. Prentice-Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05,</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="1236" citStr="Chiang, 2005" startWordPosition="165" endWordPosition="166">achine translation output, but are often very computationally intensive. The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large. We devise a linear-time algorithm for factoring syntactic re-orderings by binarizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system. 1 Introduction Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al., 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers. In this framework, both alignment (synchronous parsing) and decoding can be thought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of a grammar rule. To alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to a smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation. In particular: • We develop </context>
<context position="2788" citStr="Chiang, 2005" startWordPosition="404" endWordPosition="405">re typical baseline method. • We examine cases of non-binarizable rules in a large, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules. Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing. One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases. In contrast, the rule extraction method of Galley et al. (2004) aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses. This approach results in rules with many nonterminals, making good binarization techniques critical. Suppose we have the following SCFG, where superscripts indicate reorderings (formal definitions of 256 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 256–263, New York, June 2006. c�2</context>
<context position="4898" citStr="Chiang, 2005" startWordPosition="749" endWordPosition="750">could binarize the first rule left to right or right to left: S NP VPP-VP VPP-VP PP VP We call those intermediate symbols (e.g. VPP-VP) virtual nonterminals and corresponding rules virtual rules, whose probabilities are all set to 1. These two binarizations are no different in the translation-model-only decoding described above, just as in monolingual parsing. However, in the source-channel approach to machine translation, we need to combine probabilities from the translation model (an SCFG) with the language model (an ngram), which has been shown to be very important for translation quality (Chiang, 2005). To do bigram-integrated decoding, we need to augment each chart item (X, i, j) with two target-language 1Other parsing strategies like the Earley algorithm use an internal binary representation (e.g. dotted-rules) of the original grammar to ensure cubic time complexity. boundary words u and v to produce a bigram-item like u X v \ , following the dynamic program(i j ming algorithm of Wu (1996). Now the two binarizations have very different effects. In the first case, we first combine NP with PP: � Powell ··· Powell � �with ··· Sharon � NP : p PP : q 1 2 2 4 � Powell ··· Powell ··· with ··· Sh</context>
<context position="8129" citStr="Chiang (2005)" startWordPosition="1331" endWordPosition="1332"> Later we add Pr(held |Powell) when the resulting item is combined with � Powell ��� Powell 1 2 NP to form an S item. As illustrated in Figure 2, VPP-VP has contiguous spans on both source and target sides, so that we can generate a binary-branching SCFG: S → NP(1) VPP-VP(2), NP(1) VPP-VP(2) (2) VPP-VP → VP(1) PP(2), PP(2) VP(1) In this case m-gram integrated decoding can be done in O(|w|3+4(m−1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG. The benefit of binary grammars also lies in synchronous parsing (alignment). Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005). The same reasoning applies to tree transducer rules. Suppose we have the following tree-to-string rules, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3) VP(VBD(held), NP(DT(a) NPS(meeting))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of </context>
<context position="10982" citStr="Chiang, 2005" startWordPosition="1804" endWordPosition="1805">the start symbol. As shown in Section 3.2, terminals do not play an important role in binarization. So we now write rules in the following notation: X → X(1) 1 ...X(n) n , X(π(1)) π(1) ...X(π(n)) π(n) where each Xi is a variable which ranges over nonterminals in the grammar and π is the permutation of the rule. We also define an SCFG rule as n-ary if its permutation is of n and call an SCFG n-ary if its longest rule is n-ary. Our goal is to produce an equivalent binary SCFG for an input n-ary SCFG. 2In making one nonterminal play dual roles, we follow the definitions in (Aho and Ullman, 1972; Chiang, 2005), originally known as Syntax Directed Translation Schema (SDTS). An alternative definition by Satta and Peserico (2005) allows co-indexed nonterminals taking different symbols in two dimensions. Formally speaking, we can construct an equivalent SDTS by creating a cross-product of nonterminals from two sides. See (Satta and Peserico, 2005, Sec. 4) for other details. source (Chinese) target (English) NP NP VP PP VPP-VP VP PP English boundary words meeting Sharon Powell Powell with held 1 2 4 7 PP NP Chinese indices VPP-VP VP 258 (5,4) (2,3) 2 3 5 4 (2,3,5,4) 2 (3,5,4) 3 (5,4) 5 4 (a) (b) (c) (2,</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of ACL-05, pages 263–270, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Learning non-isomorphic tree mappings for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL03, companion volume,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="9251" citStr="Eisner, 2003" startWordPosition="1508" endWordPosition="1509">))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of nonterminals are denoted by variables xi. Notice that the first rule has a multi-level lefthand side subtree. This system can model nonisomorphic transformations on English parse trees to “fit” another language, for example, learning that the (S (V O)) structure in English should be transformed into a (V S O) structure in Arabic, by looking at two-level tree fragments (Knight and Graehl, 2005). From a synchronous rewriting point of view, this is more akin to synchronous tree substitution grammar (STSG) (Eisner, 2003). This larger locality is linguistically motivated and leads to a better parameter estimation. By imagining the left-hand-side trees as special nonterminals, we can virtually create an SCFG with the same generative capacity. The technical details will be explained in Section 3.2. In general, if we are given an arbitrary synchronous rule with many nonterminals, what are the good decompositions that lead to a binary grammar? Figure 2 suggests that a binarization is good if every virtual nonterminal has contiguous spans on both sides. We formalize this idea in the next section. 2 Synchronous Bina</context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In Proceedings ofACL03, companion volume, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings ofHLT/NAACL-04.</booktitle>
<contexts>
<context position="1258" citStr="Galley et al., 2004" startWordPosition="167" endWordPosition="170">tion output, but are often very computationally intensive. The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large. We devise a linear-time algorithm for factoring syntactic re-orderings by binarizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system. 1 Introduction Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al., 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers. In this framework, both alignment (synchronous parsing) and decoding can be thought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of a grammar rule. To alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to a smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation. In particular: • We develop a technique called syn</context>
<context position="2887" citStr="Galley et al. (2004)" startWordPosition="418" endWordPosition="421">lly-derived rule set, and we investigate the effect on translation quality when excluding such rules. Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing. One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases. In contrast, the rule extraction method of Galley et al. (2004) aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses. This approach results in rules with many nonterminals, making good binarization techniques critical. Suppose we have the following SCFG, where superscripts indicate reorderings (formal definitions of 256 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 256–263, New York, June 2006. c�2006 Association for Computational Linguistics Figure 1: A pair of synchronous parse trees in the SC</context>
<context position="8533" citStr="Galley et al. (2004)" startWordPosition="1393" endWordPosition="1396">1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG. The benefit of binary grammars also lies in synchronous parsing (alignment). Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005). The same reasoning applies to tree transducer rules. Suppose we have the following tree-to-string rules, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3) VP(VBD(held), NP(DT(a) NPS(meeting))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of nonterminals are denoted by variables xi. Notice that the first rule has a multi-level lefthand side subtree. This system can model nonisomorphic transformations on English parse trees to “fit” another language, for example, learning that the (S (V O)) structure in English should be transformed into a (V S O) structure in Arabic, by looking at two-level tree fragments (Knight and Graehl, 2005). From a</context>
<context position="22777" citStr="Galley et al. (2004)" startWordPosition="3858" endWordPosition="3861">t has been shown by Shapiro and Stephens (1991) and Wu (1997, Sec. 4) that the percentage of binarizable cases over all permutations of length n quickly approaches 0 as n grows (see Figure 6). However, for machine translation, it is more meaningful to compute the ratio of binarizable rules extracted from real text. Our rule set is obtained by first doing word alignment using GIZA++ on a Chinese-English parallel corpus containing 50 million words in English, then parsing the English sentences using a variant of Collins parser, and finally extracting rules using the graph-theoretic algorithm of Galley et al. (2004). We did a “spectrum analysis” on the resulting rule set with 50,879,242 rules. Figure 6 shows how the rules are distributed against their lengths (number of nonterminals). We can see that the percentage of non-binarizable rules in each bucket of the same length does not exceed 25%. Overall, 99.7% of the rules are binarizable. Even for the 0.3% nonbinarizable rules, human evaluations show that the majority of them are due to alignment errors. It is also interesting to know that 86.8% of the rules have monotonic permutations, i.e. either taking identical or totally inverted order. 4.2 Does sync</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings ofHLT/NAACL-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Machine translation as lexicalized parsing with hooks.</title>
<date>2005</date>
<booktitle>In Proceedings ofIWPT-05,</booktitle>
<location>Vancouver, BC.</location>
<contexts>
<context position="6788" citStr="Huang et al., 2005" startWordPosition="1085" endWordPosition="1088">ve n nonterminals in a SCFG rule, and the decoder conservatively assumes nothing can be done on language model scoring (because target-language spans are non-contiguous in general) until the real nonterminal has been recognized. In other words, targetlanguage boundary words from each child nonterminal of the rule will be cached in all virtual nonterminals derived from this rule. In the case of m-gram integrated decoding, we have to maintain 2(m − 1) boundary words for each child nonterminal, which leads to a prohibitive overall complexity of O(|w|3+2n(m−1)), which is exponential in rule size (Huang et al., 2005). Aggressive pruning must be used to make it tractable in practice, which in general introduces many search errors and adversely affects translation quality. In the second case, however: � with ··· Sharon � �held ··· meeting � PP : r VP : s 2 4 4 7 � held ··· Sharon � VPP-VP : rs · Pr(with |meeting) 2 7 Here since PP and VP are contiguous (but swapped) in the target-language, we can include the S S Baoweier yu Shalong VP juxing le huitan VP held a meeting PP with Sharon NP Powell PP NP (1) S VNP-PP VP VNP-PP NP PP or 257 Figure 2: The alignment pattern (left) and alignment matrix (right) of th</context>
</contexts>
<marker>Huang, Zhang, Gildea, 2005</marker>
<rawString>Liang Huang, Hao Zhang, and Daniel Gildea. 2005. Machine translation as lexicalized parsing with hooks. In Proceedings ofIWPT-05, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>An overview of probabilistic tree transducers for natural language processing.</title>
<date>2005</date>
<booktitle>In Conference on Intelligent Text Processing and Computational Linguistics (CICLing). LNCS.</booktitle>
<contexts>
<context position="9125" citStr="Knight and Graehl, 2005" startWordPosition="1487" endWordPosition="1490">, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3) VP(VBD(held), NP(DT(a) NPS(meeting))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of nonterminals are denoted by variables xi. Notice that the first rule has a multi-level lefthand side subtree. This system can model nonisomorphic transformations on English parse trees to “fit” another language, for example, learning that the (S (V O)) structure in English should be transformed into a (V S O) structure in Arabic, by looking at two-level tree fragments (Knight and Graehl, 2005). From a synchronous rewriting point of view, this is more akin to synchronous tree substitution grammar (STSG) (Eisner, 2003). This larger locality is linguistically motivated and leads to a better parameter estimation. By imagining the left-hand-side trees as special nonterminals, we can virtually create an SCFG with the same generative capacity. The technical details will be explained in Section 3.2. In general, if we are given an arbitrary synchronous rule with many nonterminals, what are the good decompositions that lead to a binary grammar? Figure 2 suggests that a binarization is good i</context>
</contexts>
<marker>Knight, Graehl, 2005</marker>
<rawString>Kevin Knight and Jonathan Graehl. 2005. An overview of probabilistic tree transducers for natural language processing. In Conference on Intelligent Text Processing and Computational Linguistics (CICLing). LNCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Multitext grammars and synchronous parsers.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-03,</booktitle>
<location>Edmonton.</location>
<contexts>
<context position="2383" citStr="Melamed (2003)" startWordPosition="342" endWordPosition="343">onous rule with arbitrary permutation. In particular: • We develop a technique called synchronous binarization and devise a fast binarization algorithm such that the resulting rule set allows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models. • We examine the effect of this binarization method on end-to-end machine translation quality, compared to a more typical baseline method. • We examine cases of non-binarizable rules in a large, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules. Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing. One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases. In contrast, the rule extraction method of Galley et al. (2004) aims to incorporate more syntactic information by providing parse trees for the target language</context>
</contexts>
<marker>Melamed, 2003</marker>
<rawString>I. Dan Melamed. 2003. Multitext grammars and synchronous parsers. In Proceedings of NAACL-03, Edmonton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="25330" citStr="Och and Ney, 2004" startWordPosition="4268" endWordPosition="4271">. The rule set is that of the previous section. The test set has 116 Chinese sentences of no longer than 15 words. Both systems use trigram as the integrated language model. Figure 7 demonstrates that decoding accuracy is significantly improved after synchronous binarization. The number of edges proposed during decoding is used as a measure of the size of search space, or time efficiency. Our system is consistently faster and more accurate than the baseline system. We also compare the top result of our synchronous binarization system with the state-of-theart alignment-template approach (ATS) (Och and Ney, 2004). The results are shown in Table 1. Our system has a promising improvement over the ATS 262 Figure 7: Comparing the two binarization methods in terms of translation quality against search effort. system which is trained on a larger data-set but tuned independently. 5 Conclusion Modeling reorderings between languages has been a major challenge for machine translation. This work shows that the majority of syntactic reorderings, at least between languages like English and Chinese, can be efficiently decomposed into hierarchical binary reorderings. From a modeling perspective, on the other hand, i</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Enoch Peserico</author>
</authors>
<title>Some computational complexity results for synchronous context-free grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-05,</booktitle>
<pages>803--810</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="8396" citStr="Satta and Peserico, 2005" startWordPosition="1373" endWordPosition="1376"> S → NP(1) VPP-VP(2), NP(1) VPP-VP(2) (2) VPP-VP → VP(1) PP(2), PP(2) VP(1) In this case m-gram integrated decoding can be done in O(|w|3+4(m−1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG. The benefit of binary grammars also lies in synchronous parsing (alignment). Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005). The same reasoning applies to tree transducer rules. Suppose we have the following tree-to-string rules, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3) VP(VBD(held), NP(DT(a) NPS(meeting))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of nonterminals are denoted by variables xi. Notice that the first rule has a multi-level lefthand side subtree. This system can model nonisomorphic transformations on English parse trees to “fit” another language, for example, learning that the (S (V O)) structure in E</context>
<context position="11101" citStr="Satta and Peserico (2005)" startWordPosition="1819" endWordPosition="1822">ow write rules in the following notation: X → X(1) 1 ...X(n) n , X(π(1)) π(1) ...X(π(n)) π(n) where each Xi is a variable which ranges over nonterminals in the grammar and π is the permutation of the rule. We also define an SCFG rule as n-ary if its permutation is of n and call an SCFG n-ary if its longest rule is n-ary. Our goal is to produce an equivalent binary SCFG for an input n-ary SCFG. 2In making one nonterminal play dual roles, we follow the definitions in (Aho and Ullman, 1972; Chiang, 2005), originally known as Syntax Directed Translation Schema (SDTS). An alternative definition by Satta and Peserico (2005) allows co-indexed nonterminals taking different symbols in two dimensions. Formally speaking, we can construct an equivalent SDTS by creating a cross-product of nonterminals from two sides. See (Satta and Peserico, 2005, Sec. 4) for other details. source (Chinese) target (English) NP NP VP PP VPP-VP VP PP English boundary words meeting Sharon Powell Powell with held 1 2 4 7 PP NP Chinese indices VPP-VP VP 258 (5,4) (2,3) 2 3 5 4 (2,3,5,4) 2 (3,5,4) 3 (5,4) 5 4 (a) (b) (c) (2,3,5,4) O(Iw16) parsable SCFG bSCFG SCFG-2 Figure 3: (a) and (b): two binarization patterns for (2, 3, 5, 4). (c): align</context>
</contexts>
<marker>Satta, Peserico, 2005</marker>
<rawString>Giorgio Satta and Enoch Peserico. 2005. Some computational complexity results for synchronous context-free grammars. In Proceedings of HLT/EMNLP-05, pages 803–810, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shapiro</author>
<author>A B Stephens</author>
</authors>
<title>Bootstrap percolation, the Schr¨oder numbers, and the n-kings problem.</title>
<date>1991</date>
<journal>SIAM Journal on Discrete Mathematics,</journal>
<volume>4</volume>
<issue>2</issue>
<pages>280</pages>
<contexts>
<context position="14623" citStr="Shapiro and Stephens (1991" startWordPosition="2414" endWordPosition="2417">Here the parallel string pair that we are parsing is the integer sequence (1...n) and its permutation (7r(1)...7r(n)). The goal of the ITG parsing is to find a synchronous tree that agrees with the alignment indicated by the permutation. In fact, as demonstrated previously, some permutations may have more than one binarization patterns among which we only need one. Wu (1997, Sec. 7) introduces a non-ambiguous ITG that prefers left-heavy binary trees so that for each permutation there is a unique synchronous derivation (binarization pattern). However, this problem has more efficient solutions. Shapiro and Stephens (1991, p. 277) informally present an iterative procedure where in each pass it scans the permuted sequence from left to right and combines two adjacent sub sequences whenever possible. This procedure produces a left-heavy binarization tree consistent with the unambiguous ITG and runs in O(n2) time since we need n passes in the worst case. We modify this procedure and improve circle in Figure 4), which can be binarized only by analyzing interactions between rules. Below is a simple example: S X(1) X(2) X(3) X(4), X(2) X(4) X(1) X(3) X a, a 259 iteration stack input action 1 5 3 4 2 1 5 3 4 2 shift 1</context>
<context position="22204" citStr="Shapiro and Stephens (1991)" startWordPosition="3764" endWordPosition="3767">periments In this section, we answer two empirical questions. PP IN NP-C ADJP x0:RB JJ responsible x0 fuze x1 de x2 NPB for x1:PP [1, (3,2)] 1 (3,2) V[PP, de]3 NN2 261 # of rules percentage (%) 100 1e+07 8e+06 80 6e+06 60 4e+06 40 2e+06 20 0 0 0 5 10 15 20 25 30 35 40 length Figure 6: The solid-line curve represents the distribution of all rules against permutation lengths. The dashed-line stairs indicate the percentage of non-binarizable rules in our initial rule set while the dotted-line denotes that percentage among all permutations. 4.1 How many rules are binarizable? It has been shown by Shapiro and Stephens (1991) and Wu (1997, Sec. 4) that the percentage of binarizable cases over all permutations of length n quickly approaches 0 as n grows (see Figure 6). However, for machine translation, it is more meaningful to compute the ratio of binarizable rules extracted from real text. Our rule set is obtained by first doing word alignment using GIZA++ on a Chinese-English parallel corpus containing 50 million words in English, then parsing the English sentences using a variant of Collins parser, and finally extracting rules using the graph-theoretic algorithm of Galley et al. (2004). We did a “spectrum analys</context>
</contexts>
<marker>Shapiro, Stephens, 1991</marker>
<rawString>L. Shapiro and A. B. Stephens. 1991. Bootstrap percolation, the Schr¨oder numbers, and the n-kings problem. SIAM Journal on Discrete Mathematics, 4(2):275– 280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In COLING-90, volume III,</booktitle>
<pages>253--258</pages>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Stuart Shieber and Yves Schabes. 1990. Synchronous tree-adjoining grammars. In COLING-90, volume III, pages 253–258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>A polynomial-time algorithm for statistical machine translation.</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5295" citStr="Wu (1996)" startWordPosition="815" endWordPosition="816">h to machine translation, we need to combine probabilities from the translation model (an SCFG) with the language model (an ngram), which has been shown to be very important for translation quality (Chiang, 2005). To do bigram-integrated decoding, we need to augment each chart item (X, i, j) with two target-language 1Other parsing strategies like the Earley algorithm use an internal binary representation (e.g. dotted-rules) of the original grammar to ensure cubic time complexity. boundary words u and v to produce a bigram-item like u X v \ , following the dynamic program(i j ming algorithm of Wu (1996). Now the two binarizations have very different effects. In the first case, we first combine NP with PP: � Powell ··· Powell � �with ··· Sharon � NP : p PP : q 1 2 2 4 � Powell ··· Powell ··· with ··· Sharon � VNP-PP : pq 1 4 where p and q are the scores of antecedent items. This situation is unpleasant because in the targetlanguage NP and PP are not contiguous so we cannot apply language model scoring when we build the VNP-PP item. Instead, we have to maintain all four boundary words (rather than two) and postpone the language model scoring till the next step where VNP-PP is combined with C h</context>
<context position="8003" citStr="Wu, 1996" startWordPosition="1309" endWordPosition="1310">hronous production. language model score by adding Pr(with |meeting), and the resulting item again has two boundary words. Later we add Pr(held |Powell) when the resulting item is combined with � Powell ��� Powell 1 2 NP to form an S item. As illustrated in Figure 2, VPP-VP has contiguous spans on both source and target sides, so that we can generate a binary-branching SCFG: S → NP(1) VPP-VP(2), NP(1) VPP-VP(2) (2) VPP-VP → VP(1) PP(2), PP(2) VP(1) In this case m-gram integrated decoding can be done in O(|w|3+4(m−1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG. The benefit of binary grammars also lies in synchronous parsing (alignment). Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005). The same reasoning applies to tree transducer rules. Suppose we have the following tree-to-string rules, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3)</context>
</contexts>
<marker>Wu, 1996</marker>
<rawString>Dekai Wu. 1996. A polynomial-time algorithm for statistical machine translation. In 34th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="2689" citStr="Wu, 1997" startWordPosition="389" endWordPosition="390"> effect of this binarization method on end-to-end machine translation quality, compared to a more typical baseline method. • We examine cases of non-binarizable rules in a large, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules. Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing. One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases. In contrast, the rule extraction method of Galley et al. (2004) aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses. This approach results in rules with many nonterminals, making good binarization techniques critical. Suppose we have the following SCFG, where superscripts indicate reorderings (formal definitions of 256 Proceedings of the Human Language Tech</context>
<context position="8281" citStr="Wu (1997)" startWordPosition="1355" endWordPosition="1356"> contiguous spans on both source and target sides, so that we can generate a binary-branching SCFG: S → NP(1) VPP-VP(2), NP(1) VPP-VP(2) (2) VPP-VP → VP(1) PP(2), PP(2) VP(1) In this case m-gram integrated decoding can be done in O(|w|3+4(m−1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG. The benefit of binary grammars also lies in synchronous parsing (alignment). Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005). The same reasoning applies to tree transducer rules. Suppose we have the following tree-to-string rules, following Galley et al. (2004): S(x0:NP, VP(x2:VP, x1:PP)) → x0 x1 x2 NP(NNP(Powell)) → Baoweier (3) VP(VBD(held), NP(DT(a) NPS(meeting))) → juxing le huitan PP(TO(with), NP(NNP(Sharon))) → yu Shalong where the reorderings of nonterminals are denoted by variables xi. Notice that the first rule has a multi-level lefthand side subtree. This system can model nonisomorphic transf</context>
<context position="13995" citStr="Wu, 1997" startWordPosition="2317" endWordPosition="2318"> SCFG is coded as SCFG-2. Theorem 1. For each grammar G in bSCFG, there exists a binary SCFG G&apos;, such that L(G&apos;) = L(G). Proof. Once we decompose the permutation of n in the original rule into binary permutations, all that remains is to decorate the skeleton binary parse with nonterminal symbols and attach terminals to the skeleton appropriately. We explain the technical details in the next section. 3 Binarization Algorithms We have reduced the problem of binarizing an SCFG rule into the problem of binarizing its permutation. This problem can be cast as an instance of synchronous ITG parsing (Wu, 1997). Here the parallel string pair that we are parsing is the integer sequence (1...n) and its permutation (7r(1)...7r(n)). The goal of the ITG parsing is to find a synchronous tree that agrees with the alignment indicated by the permutation. In fact, as demonstrated previously, some permutations may have more than one binarization patterns among which we only need one. Wu (1997, Sec. 7) introduces a non-ambiguous ITG that prefers left-heavy binary trees so that for each permutation there is a unique synchronous derivation (binarization pattern). However, this problem has more efficient solutions</context>
<context position="16196" citStr="Wu, 1997" startWordPosition="2718" endWordPosition="2719">gorithm that only needs one pass through the sequence. 3.1 The linear-time skeleton algorithm The (unique) binarization tree bi(a) for a binarizable permuted sequence a is recursively defined as follows: • if a = (a), then bi(a) = a; • otherwise let a = (b; c) to be the rightmost binarizable split of a. then � [bi(b), bi(c)] b1 &lt; c1 bi(a) = (bi(b), bi(c)) b1 � c1� For example, the binarization tree for (2, 3, 5, 4) is [[2, 3], (5, 4)], which corresponds to the binarization pattern in Figure 3(a). We use [] and () for straight and inverted combinations respectively, following the ITG notation (Wu, 1997). The rightmost split ensures left-heavy binary trees. The skeleton binarization algorithm is an instance of the widely used left-to-right shift-reduce algorithm. It maintains a stack for contiguous subsequences discovered so far, like 2-5, 1. In each iteration, it shifts the next number from the input and repeatedly tries to reduce the top two elements on the stack if they are consecutive. See Algorithm 1 for details and Figure 5 for an example. Theorem 2. Algorithm 1 succeeds if and only if the input permuted sequence a is binarizable, and in case of success, the binarization pattern recover</context>
<context position="22217" citStr="Wu (1997" startWordPosition="3769" endWordPosition="3770">swer two empirical questions. PP IN NP-C ADJP x0:RB JJ responsible x0 fuze x1 de x2 NPB for x1:PP [1, (3,2)] 1 (3,2) V[PP, de]3 NN2 261 # of rules percentage (%) 100 1e+07 8e+06 80 6e+06 60 4e+06 40 2e+06 20 0 0 0 5 10 15 20 25 30 35 40 length Figure 6: The solid-line curve represents the distribution of all rules against permutation lengths. The dashed-line stairs indicate the percentage of non-binarizable rules in our initial rule set while the dotted-line denotes that percentage among all permutations. 4.1 How many rules are binarizable? It has been shown by Shapiro and Stephens (1991) and Wu (1997, Sec. 4) that the percentage of binarizable cases over all permutations of length n quickly approaches 0 as n grows (see Figure 6). However, for machine translation, it is more meaningful to compute the ratio of binarizable rules extracted from real text. Our rule set is obtained by first doing word alignment using GIZA++ on a Chinese-English parallel corpus containing 50 million words in English, then parsing the English sentences using a variant of Collins parser, and finally extracting rules using the graph-theoretic algorithm of Galley et al. (2004). We did a “spectrum analysis” on the re</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>